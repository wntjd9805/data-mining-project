Deep AUC Maximization (DAM) is a novel approach to training deep neural networks that focuses on maximizing the AUC score of the model on a given dataset. While previous works have primarily focused on optimizing AUC through stochastic algorithms, there is a lack of research on the generalization performance of large-scale DAM on challenging tasks. This study aims to make DAM more practical for real-world applications, particularly in medical image classification.  To achieve this, the study introduces a new margin-based min-max surrogate loss function called AUC margin loss. This loss function is more robust than the commonly used AUC square loss while still benefiting from efficient stochastic optimization. The DAM method is then extensively evaluated on four difficult medical image classification tasks: chest x-ray classification for identifying diseases, skin lesion classification for melanoma identification, mammogram classification for breast cancer screening, and microscopic image classification for tumor tissue identification.  The empirical studies demonstrate that the proposed DAM method significantly improves the performance of optimizing cross-entropy loss and outperforms the existing AUC square loss on these medical image classification tasks. In fact, the DAM method achieved first place in the Stanford CheXpert competition on August 31, 2020. This work is the first to successfully apply DAM to large-scale medical image datasets.  Additionally, ablation studies are conducted to further highlight the advantages of the new AUC margin loss over the AUC square loss on benchmark datasets. The proposed method is implemented in the open-sourced library LibAUC, which can be accessed at www.libauc.org or through the GitHub address https://github.com/Optimization-AI/LibAUC.  Figure 1 illustrates the optimization of different AUC losses on a toy dataset using a two-layer neural network with ELU activation. The top row shows the optimization of AUC square loss, while the bottom row shows the optimization of the new AUC margin loss. The initial decision boundary is depicted in the first column, followed by the addition of easy examples and retraining the model using AUC loss in the middle column. In the last column, the addition of noisily labeled data is shown, demonstrating the superior robustness of the AUC margin loss compared to the AUC square loss.