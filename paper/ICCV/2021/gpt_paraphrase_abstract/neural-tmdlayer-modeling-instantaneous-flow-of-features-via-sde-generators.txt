We explore how stochastic differential equation (SDE) concepts can inspire enhancements to current algorithms in computer vision. Our approach is influenced by both explicit and implicit strategies for data augmentation and group equivariance, but is based on recent findings in the SDE literature regarding the estimation of infinitesimal generators for a particular class of stochastic processes. When the requirements of a task align with the properties and behavior of the processes we can efficiently handle, we introduce a straightforward and efficient plug-in layer that can be seamlessly integrated into existing network architectures with minimal modifications and a small number of additional parameters. We demonstrate promising results in various vision tasks, such as few-shot learning, point cloud transformers, and deep variational segmentation, achieving improvements in efficiency or performance.