Personalized video highlight detection has gained attention as a way to shorten long videos based on user preferences. However, current methods that rely on user history alone fail to capture the diverse interests of users, resulting in vague preference representation. To address this, we propose a preference reasoning framework called PR-Net. PR-Net considers the diverse interests by generating distinct user-specific preferences for each frame in the video. These preferences are formed by weighting and summing the user's history highlights related to the frame. Additionally, comprehensive preferences are formed by combining the user-specific preferences with a learnable generic preference, allowing for a more overall highlight measurement. We calculate the degree of highlight and non-highlight for each frame by comparing their semantic similarity to the comprehensive and non-highlight preferences, respectively. To overcome annotation ambiguity, we introduce a bi-directional contrastive loss that ensures a compact and differentiable metric space. Our method outperforms state-of-the-art techniques, achieving a relative improvement of 12% in mean accuracy precision.