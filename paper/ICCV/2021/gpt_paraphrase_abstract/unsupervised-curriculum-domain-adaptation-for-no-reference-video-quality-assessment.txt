Convolutional neural networks (C-NNs) have been successful in video quality assessment (VQA) tasks, but their reliance on annotated data poses challenges for model generalization in VQA. Recent advancements in domain adaptation techniques have made it possible to adapt models trained on source data to unlabeled target data. However, the subjective nature of VQA tasks, caused by distortion diversity and content variation in collected videos, hampers adaptation performance. To address this, we propose a curriculum-style unsupervised domain adaptation approach for the cross-domain no-reference VQA problem. Our approach consists of two stages. In the first stage, we adapt between the source and target domains to predict the rating distribution for target samples, which better captures the subjective nature of VQA. Based on this adaptation, we split the target domain data into confident and uncertain subdomains using an uncertainty-based ranking function that measures prediction confidences. In the second stage, we treat samples in the confident subdomain as easy tasks in a curriculum and conduct fine-level adaptation between the two subdomains to fine-tune the prediction model. Extensive experiments on benchmark datasets demonstrate the superiority of our method in terms of both accuracy and speed compared to other methods. The source code for our approach is available at https://github.com/cpf0079/UCDA.