This paper addresses the issue of few-shot image classification, which involves training a classifier to recognize new classes and domains with limited labeled samples. Existing methods tackle this problem by adapting visual representations to new domains or selecting relevant ones from multiple domain-specific feature extractors. The authors propose a new approach called URL, which learns a universal set of visual representations by distilling knowledge from multiple domain-specific networks. This is achieved through co-aligning their features using adapters and centered kernel alignment. The authors also demonstrate that these universal representations can be further refined for previously unseen domains using an efficient adaptation step inspired by distance learning methods. The proposed model is evaluated in the Meta-Dataset benchmark and outperforms previous methods while maintaining high efficiency.