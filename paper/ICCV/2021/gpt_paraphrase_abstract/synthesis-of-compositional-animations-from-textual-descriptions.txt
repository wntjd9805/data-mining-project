This study addresses the challenges of animating 3D characters and controlling robots using natural language instructions. The aim is to generate realistic movements from complex and unstructured sentences. To tackle this, the researchers propose a new technique called generative compositional actions. This approach utilizes a hierarchical two-stream sequential model to map natural language sentences to 3D pose sequences. The model learns separate representations for upper body and lower body movements. It is capable of generating plausible pose sequences for both simple and complex sentences describing single or multiple actions. The proposed model is evaluated on the KIT Motion-Language Dataset, and the results demonstrate a significant improvement in text-based motion synthesis compared to existing methods. Both objective evaluations and subjective user studies confirm the high quality of the synthesized motions, which closely resemble the ground-truth motion captures.