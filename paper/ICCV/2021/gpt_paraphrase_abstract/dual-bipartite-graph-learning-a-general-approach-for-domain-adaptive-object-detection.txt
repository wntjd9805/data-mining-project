Domain Adaptive Object Detection (DAOD) aims to transfer knowledge from a labeled source domain to an unlabeled target domain, reducing the need for large-scale annotated data. Existing DAOD methods use local feature alignment and domain adversarial training, along with ad-hoc detection pipelines, to achieve feature adaptation. However, these approaches are limited to specific types of object detectors and do not explore cross-domain topological relations. In this study, we formulate DAOD as an open-set domain adaptation problem, where foregrounds (pixel or region) are considered the "known class" and backgrounds (pixel or region) are the "unknown class". To address this, we propose a new approach called Dual Bipartite Graph Learning (DBGL) for DAOD. DBGL captures cross-domain interactions at both the pixel-level and semantic-level by increasing the distinction between foregrounds and backgrounds and modeling the cross-domain dependencies among different semantic categories. Experimental results demonstrate that DBGL, combined with one-stage and two-stage detectors, outperforms existing methods on standard DAOD benchmarks.