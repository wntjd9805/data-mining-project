This paper presents a new method called geometry-aware self-training (GAST) for unsupervised domain adaptation of object point cloud classification. The point cloud representation of an object often varies due to inconsistent data acquisition procedures, leading to domain discrepancy across datasets. The goal of GAST is to improve discrimination on unseen distributions of point-based geometries in a practical and feasible way.   GAST achieves this by learning a domain-shared representation of semantic categories through two self-supervised geometric learning tasks. Firstly, a linear mixup of point cloud samples with their self-generated rotation labels is used to capture the global topological configuration of local geometries. Secondly, a novel curvature-aware distortion localization is employed to normalize the diverse point distribution across datasets.   Experimental results on the PointDA-10 dataset demonstrate that GAST outperforms state-of-the-art methods significantly. The paper provides source codes and pre-trained models of GAST, which are available at https://github.com/zou-longkun/GAST.