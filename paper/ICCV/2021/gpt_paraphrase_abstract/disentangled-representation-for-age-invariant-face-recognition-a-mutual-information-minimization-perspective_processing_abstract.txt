Recent advancements in general face recognition have been notable, but challenges still persist when it comes to recognizing faces with significant age gaps. This is due to the considerable changes in facial appearance and bone structure that occur over time. To address this issue, disentanglement of face representations into components that are dependent on identity and age is crucial for achieving age-invariant face recognition (AIFR). In this study, we propose a multi-task learning framework called mutual information minimization (MT-MIM) that aims to learn disentangled representations through information constraints. Our method trains a disentanglement network to minimize the mutual information between the identity and age components of a face image from the same individual, thus reducing the impact of age variations during the identification process. We use mutual information as a metric to quantitatively assess the level of disentanglement achieved. The resulting identity-dependent representations are then utilized for age-invariant face recognition. We evaluate the performance of MT-MIM on widely used face aging datasets (FG-NET, MORPH Album 2, CACD, and AgeDB) and observe significant improvements compared to previous state-of-the-art methods. Notably, our method surpasses the baseline models by more than 0.4% on MORPH Album 2 and over 0.7% on CACD subsets, demonstrating impressive enhancements at high accuracy levels of above 99% and an average of 94%.