The Transformer-based detector is a novel approach in object detection that aims to achieve high performance without relying on prior knowledge-driven components like anchors, proposals, and NMS. The current state-of-the-art model, DETR, consists of a CNN-based backbone and a paired transformer encoder-decoder. While the CNN extracts local features, the transformer captures global contexts. However, this pipeline is not concise enough. In this study, we propose WB-DETR (DETR-based detector Without Backbone) to demonstrate that the dependence on CNN feature extraction for a transformer-based detector is not necessary. WB-DETR consists of only an encoder and a decoder without a CNN backbone. For each input image, WB-DETR directly encodes the local features into individual tokens. To address the transformer's limitation in modeling local information, we introduce an LIE-T2T (local information enhancement tokens to token) module that enhances the internal information of tokens after unfolding. Experimental results show that WB-DETR, the first pure-transformer detector without CNN, achieves comparable accuracy and faster inference speed with only half the number of parameters compared to the DETR baseline.