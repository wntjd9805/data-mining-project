In the past two years, there has been a shift from human-designed data augmentation strategies to automatically learned augmentation policies. Recent research has demonstrated that the success of automated methods is attributed to their ability to increase the diversity of augmented data. However, two important factors are still missing: a clear definition and measurement of diversity, and a quantifiable relationship between diversity and its regularization effects. To address this gap, we propose a diversity measure called Variance Diversity and theoretically establish its connection to the regularization effect of data augmentation. Through experiments, we confirm that the improvement in test accuracy achieved by automated data augmentation is highly correlated with Variance Diversity. We introduce a sampling-based framework called DivAug, which directly maximizes Variance Diversity and enhances the regularization effect without the need for a separate search process. DivAug performs comparably to state-of-the-art methods but with better efficiency. Additionally, in the semi-supervised setting, our framework outperforms RandAugment and improves the performance of semi-supervised learning algorithms, making it highly relevant to real-world problems with limited labeled data. The code for DivAug is available at https://github.com/warai-0toko/DivAug.