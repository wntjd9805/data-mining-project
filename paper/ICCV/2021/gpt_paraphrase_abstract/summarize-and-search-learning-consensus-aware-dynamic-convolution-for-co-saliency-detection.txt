Current methods for co-saliency detection lack robustness, scalability, and stability in the consensus knowledge summarization process and simply fuse consensus features with image features in the object searching process. In this study, we introduce a new consensus-aware dynamic convolution model that explicitly and effectively performs the "summarize and search" process. To summarize consensus image features, we utilize an effective pooling method to summarize robust features for each image and then aggregate cross-image consensus cues using the self-attention mechanism. This approach ensures scalability and stability. We also generate dynamic kernels from consensus features to encode the summarized consensus knowledge, generating two types of kernels to summarize fine-grained image-specific consensus object cues and coarse group-wise common knowledge. By employing dynamic convolution at multiple scales, we can effectively perform object searching. Additionally, we propose a novel and effective data synthesis method to train our network. Experimental results on four benchmark datasets demonstrate the effectiveness of our method. The code and saliency maps are available at https://github.com/nnizhang/CADC.