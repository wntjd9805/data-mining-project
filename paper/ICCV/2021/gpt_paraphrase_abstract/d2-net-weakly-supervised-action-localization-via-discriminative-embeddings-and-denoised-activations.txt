This study introduces D2-Net, a weakly-supervised temporal action localization framework that aims to locate actions in videos using video-level supervision. The main contribution of this work is the development of a new loss formulation that simultaneously improves the discriminability of latent embeddings and the robustness of the output temporal class activations, even in the presence of foreground-background noise caused by weak supervision. The proposed formulation consists of a discriminative loss term and a denoising loss term. The discriminative term incorporates a classification loss and employs a top-down attention mechanism to enhance the distinguishability of latent foreground-background embeddings. The denoising loss term addresses the foreground-background noise in class activations by maximizing intra-video and inter-video mutual information through a bottom-up attention mechanism. This approach emphasizes activations in the foreground regions and suppresses those in the background regions, resulting in more reliable predictions. The effectiveness of D2-Net is demonstrated through comprehensive experiments on multiple benchmarks, including THUMOS14 and ActivityNet1.2. D2-Net outperforms existing methods on all datasets, achieving improvements of up to 2.3% in terms of mean Average Precision (mAP) at IoU=0.5 on THUMOS14. The source code for D2-Net is publicly available at https://github.com/naraysa/D2-Net.