The problem of rigidly registering point clouds with partial overlaps has traditionally been solved in two stages: (a) identifying correspondences between the point clouds, and (b) filtering these correspondences to select the most reliable ones for estimating the transformation. Recently, there have been advances in using deep neural networks to address both steps simultaneously. In this study, we build upon these previous works and introduce PCAM, a neural network that utilizes a pointwise product of cross-attention matrices. This allows for the integration of both low-level geometric details and high-level contextual information to identify point correspondences. Additionally, the cross-attention matrices enable the exchange of contextual information between the point clouds at each layer, improving the construction of matching features within the overlapping regions. Experimental results demonstrate that PCAM outperforms state-of-the-art methods that also solve steps (a) and (b) jointly using deep neural networks.