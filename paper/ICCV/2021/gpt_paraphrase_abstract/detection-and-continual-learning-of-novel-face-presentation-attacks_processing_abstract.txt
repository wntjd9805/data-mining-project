Advancements in deep learning and the availability of large datasets have resulted in significant improvements in the field of face presentation attack detection. However, even with these advancements, state-of-the-art systems are still susceptible to new and previously unseen types of attacks. Additionally, these systems lack the ability to adapt and identify these new attack types after an initial detection.To address this issue, this paper introduces a method that enables a deep neural network to identify anomalies in the observed input data, indicating potential new types of attacks. This is achieved by reducing the confidence level of the network for data points that fall outside the distribution of the training samples. Furthermore, experience replay is utilized to update the model and incorporate knowledge about new attack types while retaining the previously learned ones.The effectiveness of the proposed method is demonstrated through experimental results on two benchmark datasets, as well as a newly introduced dataset that encompasses a wide range of attack types. By utilizing this approach, the system is able to continually detect and adapt to new types of attacks, enhancing its overall performance and robustness.