The recent advancements in multi-agent problems, such as human motion forecasting and robot navigation in crowds, have relied on learning socially-aware motion representations. However, existing representations learned with neural networks struggle to generalize in closed-loop predictions, particularly when it comes to outputting colliding trajectories. This issue stems from the non-i.i.d. nature of sequential prediction and the lack of well-distributed training data.To address this problem, this study proposes a solution that explicitly models negative examples through self-supervision. The authors introduce a social contrastive loss that helps regularize the extracted motion representation by distinguishing between ground-truth positive events and synthetic negative events. They also construct informative negative samples based on their prior knowledge of rare but dangerous circumstances.The proposed method significantly reduces collision rates in trajectory forecasting, behavioral cloning, and reinforcement learning algorithms, surpassing the performance of state-of-the-art methods on various benchmarks. The code for this method is available at the provided GitHub link.