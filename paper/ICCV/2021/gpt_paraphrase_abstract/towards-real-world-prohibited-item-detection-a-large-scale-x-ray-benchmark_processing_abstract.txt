Automatic security inspection using computer vision technology is a difficult task in real-world situations because of factors like intra-class variance, class imbalance, and occlusion. Previous methods have struggled to address cases where prohibited items are intentionally concealed in cluttered objects due to the lack of large-scale datasets, limiting their applicability in real-world scenarios. To tackle this, we have created a comprehensive dataset called PIDray, which encompasses a wide range of real-world scenarios for prohibited item detection, with a particular focus on deliberately hidden items. Our dataset includes 12 categories of prohibited items, with 47,677 X-ray images that are meticulously annotated with high-quality segmentation masks and bounding boxes. This dataset is currently the largest of its kind for prohibited item detection. Additionally, we have developed a powerful baseline method called the selective dense attention network (SDANet), which comprises a dense attention module and a dependency refinement module. The dense attention module, consisting of spatial and channel-wise dense attentions, is designed to learn discriminative features and enhance performance. The dependency refinement module exploits the dependencies of multi-scale features. Through extensive experiments on the PIDray dataset, we have demonstrated that our proposed method outperforms state-of-the-art techniques, particularly in detecting deliberately hidden items. The PIDray dataset is publicly available for further research and development.