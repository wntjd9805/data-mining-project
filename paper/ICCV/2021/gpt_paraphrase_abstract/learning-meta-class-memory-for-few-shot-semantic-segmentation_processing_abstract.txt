Current methods for few-shot semantic segmentation treat the task as a foreground-background segmentation problem, assuming that each class is independent. This paper introduces the concept of a meta-class, which represents shared meta information among all classes. To explicitly learn meta-class representations, the authors propose a novel method called MM-Net. MM-Net utilizes learnable memory embeddings to store meta-class information during training and transfer it to novel classes during inference. Additionally, for the k-shot scenario, an image quality measurement module is introduced to select high-quality support images. The proposed method achieves state-of-the-art results in both 1-shot and 5-shot settings on the PASCAL-5i and COCO datasets. Notably, MM-Net achieves a 37.5% mIoU on the COCO dataset in the 1-shot setting, surpassing the previous state-of-the-art by 5.1%.