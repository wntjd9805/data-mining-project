This abstract discusses the potential of event-based video frame interpolation, which utilizes event cameras to capture motion signals for motion-aware synthesis. However, training existing frameworks for this task is challenging due to the requirement of high frame-rate videos with synchronized events. In this study, the authors propose a novel weakly supervised framework that addresses this issue by 1) correcting image appearance using information from events and 2) replacing motion dynamics modeling with attention mechanisms. They introduce subpixel attention learning, which efficiently searches for high-resolution correspondence on a low-resolution feature grid. Despite being trained on low frame-rate videos, their framework outperforms existing models trained with full high frame-rate videos (and events) on both the GoPro dataset and a new real event-based dataset. The authors provide access to their codes, models, and dataset at: https://github.com/YU-Zhiyang/WEVI.