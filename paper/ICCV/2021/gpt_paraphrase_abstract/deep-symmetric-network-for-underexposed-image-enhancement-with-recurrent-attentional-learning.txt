This paper focuses on enhancing underexposed images through a deep symmetric network. The network utilizes invertible neural networks (INN) to enable bidirectional feature learning between the underexposed image and its enhanced version. To ensure mutual propagation, two pairs of encoder-decoder with the same pre-trained parameters are constructed. This approach mitigates color bias and effectively recovers the content of the image. Additionally, a new recurrent residual-attention module (RRAM) is proposed to gradually perform desired color adjustments. Ablation experiments are conducted to evaluate the individual contributions of each component in the architecture. The proposed method achieves state-of-the-art results in underexposed image enhancement, as demonstrated through extensive experiments on two datasets. The code for the method is available at https://www.shaopinglu.net/proj-iccv21/ImageEnhancement.html.