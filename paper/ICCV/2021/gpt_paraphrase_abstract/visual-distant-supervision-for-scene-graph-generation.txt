Scene graph generation, which involves identifying objects and their relationships in images, is crucial for various computer vision applications. However, existing scene graph models heavily rely on supervised learning with large amounts of labeled data, which requires significant human annotation efforts. In this study, we introduce a new approach called visual distant supervision for training scene graph models without the need for human-labeled data. The core idea is to align common knowledge bases with images to automatically create a substantial amount of labeled data, providing distant supervision for visual relation learning. To address the noise in distantly labeled data, we propose a framework that iteratively estimates probabilistic relation labels and eliminates noisy instances. Extensive experiments demonstrate that our distantly supervised model outperforms strong weakly supervised and semi-supervised baselines. Moreover, by incorporating human-labeled data in a semi-supervised manner, our model achieves significant improvements over state-of-the-art fully supervised models, such as a 8.3 micro- and 7.8 macro-recall@50 improvements for predicate classification in the Visual Genome evaluation. The data and code for this paper are publicly available at https://github.com/thunlp/VisualDS.