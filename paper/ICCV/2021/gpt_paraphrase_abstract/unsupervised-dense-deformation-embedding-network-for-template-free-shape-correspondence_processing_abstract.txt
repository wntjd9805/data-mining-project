Recent research has shown a growing interest in shape correspondence through 3D deformation learning. However, current deep learning methods in this field require dense annotations to learn per-point translations, resulting in a highly complex deformation process. Additionally, these methods struggle to capture the local geometric details of the original shape when using global feature embedding.To overcome these challenges, we propose a new approach called the Unsupervised Dense Deformation Embedding Network (UD2E-Net). This network learns to predict deformations between non-rigid shapes using dense local features. We address the difficulty of matching deformation-variant local features by developing an Extrinsic-Intrinsic Autoencoder. This autoencoder encodes extrinsic geometric features from a source shape into intrinsic coordinates in a shared canonical shape. The decoder then synthesizes corresponding target features based on this encoding. Furthermore, we introduce a bounded maximum mean discrepancy loss to mitigate the distribution divergence between the synthesized and original features.To learn natural deformations without dense supervision, we incorporate a coarse parameterized deformation graph. We propose a novel trace and propagation algorithm to improve both the quality and efficiency of the deformation. Our UD2E-Net surpasses state-of-the-art unsupervised methods by 24% on the Faust Inter challenge and even outperforms supervised methods by 13% on the Faust Intra challenge.