Gait recognition is a crucial biometric technology used in various fields. Current frameworks for gait recognition either focus on global appearances or local regions of the human body to extract descriptors from each gait frame. However, global information-based representations overlook frame details, while local region-based descriptors fail to capture relations between neighboring regions, resulting in reduced discriminativeness. To address this, we propose a new feature extraction and fusion framework called the Global and Local Feature Extractor (GLFE). The GLFE module combines global and local features using multiple global and local convolutional layers (GLConv) in a principled manner. Additionally, we introduce a novel operation called Local Temporal Aggregation (LTA) to preserve spatial information by reducing temporal resolution and obtaining higher spatial resolution. By incorporating the GLFE and LTA, our method significantly enhances the discriminativeness of visual features, leading to improved gait recognition performance. Extensive experiments demonstrate that our approach surpasses state-of-the-art methods on two popular datasets.