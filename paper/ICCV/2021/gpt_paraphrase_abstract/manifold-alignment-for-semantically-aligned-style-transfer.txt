Most existing methods for style transfer assume that styles can be represented using global statistics, such as Gram matrices or covariance matrices. These methods aim to make the output image and the style image have similar global statistics. Another approach is to consider local style patterns, where algorithms swap similar local features between the content and style images. However, these existing methods overlook the semantic structure of the content image, which can result in a loss of content structure in the output image.   This paper introduces a new assumption that image features from the same semantic region form a manifold, and an image with multiple semantic regions follows a multi-manifold distribution. Based on this assumption, the style transfer problem is formulated as aligning two multi-manifold distributions. The proposed framework, called Manifold Alignment based Style Transfer (MAST), allows semantically similar regions between the output and style images to share similar style patterns. Additionally, the manifold alignment method is flexible, allowing user editing or the use of semantic segmentation maps as guidance for style transfer.   To enable the method to be applied to photorealistic style transfer, a new adaptive weight skip connection network structure is proposed to preserve the content details. Extensive experiments demonstrate the effectiveness of the proposed framework for both artistic and photorealistic style transfer. The code for the framework is available at https://github.com/NJUHuoJing/MAST.