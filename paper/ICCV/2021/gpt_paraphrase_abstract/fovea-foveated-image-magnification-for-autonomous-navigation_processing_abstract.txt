Efficiently processing high-resolution video streams is crucial for safety in robotics applications like autonomous driving. Downsampling images is a commonly used technique to meet latency requirements, but it limits the ability of object detectors to identify small objects. This paper proposes an attentional approach that magnifies specific regions while keeping a small input size. These magnified regions are determined based on the likelihood of containing an object, which can be estimated from a dataset-wide prior or a frame-level prior using recent object predictions. The magnification is achieved through a KDE-based mapping that transforms bounding boxes into warping parameters, which are then used in an image sampler with anti-cropping regularization. The detector receives the warped image and produces bounding box outputs in the original space using differentiable backward mapping. This regional magnification enables algorithms to effectively utilize high-resolution input without the need for high-resolution processing. Experimental results on the Argoverse-HD and BDD100K datasets demonstrate that our proposed method improves detection AP compared to the standard Faster R-CNN, both with and without finetuning. Moreover, our method achieves a new streaming AP record on Argoverse-HD, surpassing the previous state-of-the-art, indicating a superior accuracy-latency tradeoff.