We introduce the Voxel Transformer (VoTr), a new and effective Transformer-based backbone for 3D object detection from point clouds. Existing voxel-based 3D detectors with conventional 3D convolutional backbones struggle to capture large context information, which is essential for object recognition and localization, due to limited receptive fields. To address this issue, we propose a Transformer-based architecture that incorporates self-attention to enable long-range relationships between voxels. However, applying the standard Transformer directly to voxels is challenging because non-empty voxels are naturally sparse but numerous. To overcome this, we present the sparse voxel module and the submanifold voxel module, which effectively operate on both empty and non-empty voxel positions. Additionally, we propose two attention mechanisms, Local Attention and Dilated Attention, to enlarge the attention range while maintaining computational efficiency comparable to convolutional counterparts. We also introduce Fast Voxel Query to accelerate the querying process in multi-head attention. VoTr consists of a series of sparse and submanifold voxel modules and can be applied in most voxel-based detectors. Our proposed VoTr consistently outperforms convolutional baselines while maintaining computational efficiency on the KITTI dataset and the Waymo Open dataset.