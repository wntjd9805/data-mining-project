Recently, there has been significant progress in the field of self-supervised Multi-view stereo (MVS) with the use of a pre-text task of image reconstruction. However, the effectiveness of this pretext task in self-supervised MVS has not been comprehensively explained and previous methods have been built upon intuition rather than solid explanations. To address this, our proposal focuses on estimating the epistemic uncertainty in self-supervised MVS to understand what the model ignores. Specifically, we categorize the limitations into two types: ambiguous supervision in the foreground and invalid supervision in the background. To overcome these issues, we introduce a novel framework called Uncertainty reduction Multi-view Stereo (U-MVS) for self-supervised learning. To tackle ambiguous supervision in the foreground, we incorporate an additional correspondence prior with a flow-depth consistency loss. This allows us to regularize the 3D stereo correspondence in MVS using the dense 2D correspondence of optical flows. To handle invalid supervision in the background, we utilize Monte-Carlo Dropout to obtain an uncertainty map and subsequently filter out unreliable supervision signals in the invalid regions. Through extensive experiments on the DTU and Tank&Temples benchmark datasets, we demonstrate that our U-MVS framework outperforms other unsupervised MVS methods and achieves competitive performance compared to supervised approaches.