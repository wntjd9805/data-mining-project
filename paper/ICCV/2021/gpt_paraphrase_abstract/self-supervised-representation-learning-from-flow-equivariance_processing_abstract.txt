Self-supervised representation learning has been successful in learning meaningful features, but it often relies on multiple crops of simple images with few objects. In contrast, humans learn representations in a complex world by observing object movement, deformation, pose variation, and ego motion. Inspired by this, we propose a new self-supervised learning framework that can be applied to videos of complex scenes with multiple moving objects. Our framework utilizes a flow equivariance objective, which encourages the network to predict the features of another frame by applying a flow transformation to the current frame's features. The representations learned from high-resolution raw video can be easily used for tasks on static images. Experimental results on semantic segmentation, instance segmentation, and object detection benchmarks demonstrate that our approach outperforms previous state-of-the-art methods such as SimCLR and BYOL.