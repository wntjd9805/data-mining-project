The main objective of video highlight detection is to identify interesting moments in an unedited video. While previous efforts have primarily focused on analyzing the visual component, we argue that both the audio and visual components should be considered together to achieve the best results. In this paper, we propose an audio-visual network for video highlight detection. Our approach incorporates a bi-modal attention mechanism that captures the interaction between the audio and visual components, producing combined representations to enhance highlight detection. Additionally, we introduce a noise sentinel technique to effectively discount any noisy visual or audio elements. Through empirical evaluations on two benchmark datasets, we demonstrate that our approach outperforms existing methods and achieves superior performance in video highlight detection.