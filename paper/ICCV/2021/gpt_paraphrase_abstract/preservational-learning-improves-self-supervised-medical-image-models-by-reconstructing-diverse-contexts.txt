Preserving maximal information is a key principle in the design of self-supervised learning methods. While contrastive learning is commonly used to achieve this by contrasting image pairs, we argue that this approach alone is not fully optimal for preservation. We propose an additional explicit solution called Preservational Learning, which aims to reconstruct diverse image contexts to preserve more information in learned representations. Combining Preservational Learning with contrastive loss, we introduce Preservational Contrastive Representation Learning (PCRL) for self-supervised medical representation learning. PCRL demonstrates superior performance compared to both self-supervised and supervised approaches in various classification and segmentation tasks. The code for PCRL is available at https://github.com/Luchixiang/PCRL.