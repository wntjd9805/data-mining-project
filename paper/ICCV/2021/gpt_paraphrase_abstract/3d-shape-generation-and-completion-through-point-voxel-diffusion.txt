We present a new method for probabilistic generative modeling of 3D shapes called Point-Voxel Diffusion (PVD). Unlike existing models that deterministically convert a latent vector into a shape, PVD offers a unified, probabilistic approach for generating shapes and completing multi-modal shapes conditionally. PVD combines denoising diffusion models with the hybrid, point-voxel representation of 3D shapes. It involves a series of denoising steps that reverse the diffusion process from observed point cloud data to Gaussian noise. The model is trained by optimizing a variational lower bound to the likelihood function, both unconditionally and conditionally. Experimental results show that PVD can generate high-quality shapes, complete partial point clouds, and generate multiple completion results from single-view depth scans of real objects.