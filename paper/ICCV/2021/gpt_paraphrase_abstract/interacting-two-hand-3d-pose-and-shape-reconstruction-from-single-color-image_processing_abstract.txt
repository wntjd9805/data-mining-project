This paper introduces a new deep learning framework that can reconstruct the 3D hand poses and shapes of two interacting hands using only a single color image. Existing methods for single hand pose estimation do not work well in scenarios with two hands due to occlusion and a larger solution space. To overcome these challenges, the authors propose a hand pose-aware attention module that extracts features specific to each individual hand. Additionally, they leverage the contextual information between the interacting hands to refine the hand pose and shape accuracy using a context-aware cascaded refinement technique. Extensive experiments on benchmark datasets show that the proposed method achieves highly accurate 3D hand pose and shape predictions from single color images, outperforming existing approaches. The code for this method is available on the project webpage: https://baowenz.github.io/Intershape/.