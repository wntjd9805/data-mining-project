Understanding the 3D world without supervision is currently a significant challenge in computer vision due to the high cost of obtaining annotations for deep network training. This paper focuses on the problem of unsupervised viewpoint estimation. The authors propose a self-supervised learning approach where image reconstruction is used to predict the camera viewpoint. The method leverages pairs of images of the same object taken from unknown viewpoints during training. By combining viewpoint information from one image with appearance information from the other, the network can learn efficiently using a perspective spatial transformer. The proposed approach outperforms existing unsupervised methods on synthetic data and achieves competitive results on the challenging PASCAL3D+ dataset.