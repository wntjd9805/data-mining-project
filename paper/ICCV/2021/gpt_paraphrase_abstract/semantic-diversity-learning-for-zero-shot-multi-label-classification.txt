Training a neural network model to identify multiple labels associated with an image, including unseen labels, is a difficult task, especially for images that represent a wide range of labels. However, it is crucial to address this challenge as it reflects real-world scenarios like image retrieval of natural images. The conventional approach of using a single embedding vector to represent an image is inadequate for accurately ranking both relevant seen and unseen labels. This study introduces an end-to-end model training method for multi-label zero-shot learning that accommodates the semantic diversity of images and labels. We propose the use of an embedding matrix with principal embedding vectors trained using a customized loss function. Additionally, we suggest assigning higher weights in the loss function to image samples that exhibit greater semantic diversity to promote diversity in the embedding matrix. Extensive experiments demonstrate that our proposed method significantly improves the quality of the zero-shot model in tag-based image retrieval, achieving state-of-the-art results on popular datasets such as NUS-Wide, COCO, and Open Images.