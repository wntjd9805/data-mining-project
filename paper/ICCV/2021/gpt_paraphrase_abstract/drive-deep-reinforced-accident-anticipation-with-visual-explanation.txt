Traffic accident anticipation is crucial for the safety of self-driving systems. Existing approaches focus on capturing spatial and temporal context before an accident occurs, but lack visual explanation and ignore dynamic interaction with the environment. This paper presents DRIVE, a method that combines bottom-up and top-down visual attention mechanisms to visually explain the decision-making process in accident anticipation. The proposed stochastic multi-task agent is trained using a reinforcement learning algorithm with dense anticipation and sparse fixation rewards. Experimental results demonstrate that DRIVE outperforms other models on real-world traffic accident datasets. The code and pre-trained model are available at https://www.rit.edu/actionlab/drive.