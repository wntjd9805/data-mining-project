Motion is a crucial factor in video prediction, often used to separate video content into static and dynamic components. While most previous methods focus on deterministic motion modeling, there are stochastic approaches that can capture the inherent uncertainty of future predictions. However, existing stochastic models either neglect explicit reasoning about motion or rely on restrictive assumptions about the static part. In this study, we propose a stochastic model that considers both appearance and motion in videos by predicting future frames based on the motion history. By explicitly reasoning about motion, our model achieves comparable performance to current stochastic models. Moreover, incorporating the motion history allows us to predict consistent dynamics several frames ahead. Our model not only performs well on generic video prediction datasets but also significantly outperforms state-of-the-art models on challenging real-world autonomous driving datasets, which involve complex motion and dynamic backgrounds.