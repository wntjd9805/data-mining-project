Deep learning is a powerful tool for various tasks, but it requires a large amount of annotated data, which is costly and time-consuming to obtain. To address this issue, active learning has been introduced as a method to selectively annotate informative samples in an unlabeled dataset by querying an oracle. This paper proposes a new approach to active learning in deep learning, where the oracle is only consulted for data annotation when the unlabeled sample is believed to have a high loss. The approach utilizes a measurement called Temporal Output Discrepancy (TOD), which estimates the sample loss by evaluating the discrepancy of outputs from models at different optimization steps. Theoretical investigation shows that TOD provides a lower-bound estimate of the accumulated sample loss, allowing for the selection of informative unlabeled samples. Based on TOD, the approach also develops a sampling strategy for unlabeled data and an unsupervised learning criterion to improve model performance using the unlabeled data. The simplicity of TOD makes the active learning approach efficient, flexible, and applicable to various tasks. Extensive experiments demonstrate that the proposed approach outperforms state-of-the-art active learning methods in image classification and semantic segmentation tasks.