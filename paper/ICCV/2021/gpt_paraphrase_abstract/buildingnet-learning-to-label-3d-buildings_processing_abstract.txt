We present BuildingNet, a comprehensive dataset of 3D building models with consistent exterior labeling. We also introduce a graph neural network that utilizes spatial and structural relationships to label building meshes. The dataset was created through a combination of crowdsourcing and expert guidance, resulting in 513K annotated mesh primitives grouped into 292K semantic part components across 2K building models. It encompasses various building categories such as houses, churches, skyscrapers, town halls, libraries, and castles. In addition, we provide a benchmark for evaluating mesh and point cloud labeling. Compared to existing benchmarks like ShapeNet and PartNet, buildings pose greater structural complexity, making our dataset valuable for developing algorithms that can handle large-scale geometric data for vision and graphics tasks like 3D semantic segmentation, part-based generative models, correspondences, texturing, and point cloud analysis of real-world buildings. Furthermore, our mesh-based graph neural network demonstrates significant performance improvements over several baselines for labeling 3D meshes. The dataset and code can be accessed through our project page at www.buildingnet.org.