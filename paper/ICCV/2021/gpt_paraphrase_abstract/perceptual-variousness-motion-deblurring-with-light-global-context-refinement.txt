Deep learning algorithms have made significant advancements in the field of dynamic scene deblurring. However, there are still a few challenges that need to be addressed. Firstly, the degree and scale of blur in different regions of a blurred image can vary greatly. The traditional approach of using input pyramids or downscaling-upscaling is limited in its ability to handle large variations in blur scale. Secondly, while the nonlocal block has been proven to be effective in image enhancement tasks, it comes with high computational and memory costs.   To tackle these challenges, we propose a new module called the Light Global Context Refinement (LGCR) module. This module is lightweight and globally analyzes the image, offering better performance than the nonlocal unit at a significantly lower cost. Additionally, we introduce the Perceptual Variousness Block (PVB) and a PVB-piling strategy. By incorporating multiple PVBs, our method is able to effectively detect and handle blur with varying degrees and scales.   We conducted comprehensive experiments using different benchmarks and assessment metrics to evaluate the performance of our method. The results demonstrate that our approach surpasses the state-of-the-art in motion deblurring.