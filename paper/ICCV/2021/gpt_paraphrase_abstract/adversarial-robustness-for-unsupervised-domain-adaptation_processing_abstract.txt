Extensive research on Unsupervised Domain Adaptation (UDA) has demonstrated successful transfer of knowledge between labeled source domains and unlabeled target domains using deep models. However, current UDA models primarily focus on enhancing generalization without considering the crucial aspect of adversarial robustness in real-world applications. Traditional adversarial training methods are inadequate for improving adversarial robustness in UDA models on unlabeled target domains, as they rely on supervised loss functions to generate adversarial examples.

To address this limitation, we propose a novel approach that leverages intermediate representations learned by robust ImageNet models to enhance the robustness of UDA models. Our method aligns the features of the UDA model with the robust features learned by ImageNet pre-trained models during domain adaptation training. By utilizing both labeled and unlabeled domains, our approach instills robustness without requiring any adversarial intervention or labeled data during the domain adaptation process. 

Experimental results demonstrate that our method significantly improves adversarial robustness compared to the baseline, while maintaining high accuracy on various UDA benchmarks.