Language bias is a significant problem in Visual Question Answering (VQA), where models often rely on dataset biases rather than considering the image information for their decisions. This leads to a decrease in performance when dealing with out-of-distribution data and inadequate visual explanations. Through experimental analysis of existing robust VQA methods, we identify two sources of language bias: distribution bias and shortcut bias. To address this bias, we propose a new debiasing framework called GreedyGradient Ensemble (GGE). GGE combines multiple biased models to train an unbiased base model. Using a greedy strategy, GGE prioritizes overfitting the biased data distribution, forcing the base model to focus on solving examples that are challenging for biased models. Our experiments demonstrate that our method effectively utilizes visual information and achieves state-of-the-art performance on diagnosing dataset VQA-CP, all without the need for additional annotations.