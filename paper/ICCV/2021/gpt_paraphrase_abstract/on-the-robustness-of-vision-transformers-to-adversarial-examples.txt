Recent advancements in attention-based networks have demonstrated that Vision Transformers have the potential to achieve state-of-the-art performance on various image classification tasks. As a result, Transformers are emerging as a promising alternative to traditional convolutional neural networks (CNNs). However, unlike CNNs, the robustness of Vision Transformers against adversarial examples has not been extensively investigated. In this study, we evaluate the security of Vision Transformers in the face of adversarial attacks.  Our analysis of transformer security consists of three main parts. Firstly, we assess the performance of Vision Transformers under standard white-box and black-box attacks. Secondly, we investigate the transferability of adversarial examples between CNNs and transformers. Surprisingly, we find that adversarial examples do not readily transfer between these two architectures. Building upon this observation, we propose a simple ensemble defense strategy combining CNNs and transformers. Unfortunately, through the introduction of a novel attack called the self-attention blended gradient attack, we demonstrate that such an ensemble is not secure against a white-box adversary. However, we show that under a black-box adversary, the ensemble can achieve remarkable robustness without compromising clean accuracy.  To conduct our analysis, we employ six types of white-box attacks and two types of black-box attacks. Our study encompasses multiple Vision Transformers, Big Transfer Models, and CNN architectures trained on CIFAR-10, CIFAR-100, and ImageNet datasets.  In summary, this study investigates the robustness of Vision Transformers against adversarial examples. Our findings reveal the limitations of existing defense strategies and the unique characteristics of Vision Transformers in terms of security. While an ensemble of CNNs and transformers can offer robustness against black-box attacks, it remains vulnerable to white-box attacks. These insights contribute to a deeper understanding of the security implications of using Vision Transformers in image classification tasks.