This study proposes a two-step approach for extracting useful information from complex videos. The first step involves condensing the video sequence into a synthetic frame, followed by utilizing an off-the-shelf image recognition system on the synthetic frame. The paper introduces an Informative Frame Synthesis (IFS) architecture that incorporates three objective tasks: appearance reconstruction, video categorization, and motion estimation. Additionally, two regularizers, adversarial learning and color consistency, are employed to enhance the visual quality of the synthetic frame. By jointly learning the frame synthesis in an end-to-end manner, the generated frame aims to contain the necessary spatio-temporal information for video analysis. Extensive experiments on the Kinetics dataset demonstrate the superior performance of IFS compared to baseline methods, as well as its notable improvements on image-based 2D networks and clip-based 3D networks. Furthermore, IFS achieves comparable results to state-of-the-art methods while requiring less computational resources.