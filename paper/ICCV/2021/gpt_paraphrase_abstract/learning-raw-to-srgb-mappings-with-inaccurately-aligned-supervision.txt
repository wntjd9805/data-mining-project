Learning how to convert RAW images to sRGB format has become a popular topic in recent years. However, the challenge lies in the color inconsistency between the input raw image and the target sRGB image. This inconsistency often leads to inaccurate alignment and blurry results. To address this issue, we propose a joint learning model that combines image alignment and RAW-to-sRGB mapping.   In our approach, we introduce a global color mapping (GCM) module to generate an initial sRGB image based on the input raw image. This module preserves the spatial location of pixels while adjusting the color towards the target sRGB image. We then use a pre-trained optical flow estimation network to warp the target sRGB image and align it with the GCM output.   To improve the accuracy of the alignment, we leverage the warped target sRGB image to learn the RAW-to-sRGB mapping. By training the model in this way, we can reduce the impact of inaccurately aligned supervision. Once the training is complete, the GCM module and optical flow network can be detached, resulting in no additional computation cost during inference.   Experimental results demonstrate that our method outperforms existing techniques on ZRR and SR-RAW datasets. Our joint learning model allows a lightweight backbone to achieve superior quantitative and qualitative performance on the ZRR dataset. The code for our method is available at https://github.com/cszhilu1998/RAW-to-sRGB.