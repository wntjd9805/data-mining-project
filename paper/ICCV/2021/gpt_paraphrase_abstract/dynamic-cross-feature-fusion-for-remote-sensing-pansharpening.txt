Deep Convolution Neural Networks (CNNs) have been widely used for pansharpening and have achieved impressive results. However, most existing approaches focus on single-scale feature fusion, which limits their ability to fully consider the relationships between high-level semantics and low-level features. Despite the depth of the network, this leads to suboptimal performance. To address this limitation, we propose a novel network called Dynamic Cross Feature Fusion Network (DCFNet) for pan-sharpening. DCFNet consists of multiple parallel branches, with a high-resolution branch serving as the backbone and low-resolution branches progressively added to enhance the overall representation of information. To improve the relationships between these branches, we introduce dynamic cross feature transfers, allowing for the exchange of information between different branches to obtain high-resolution representations. Additionally, we leverage contextualized features to further enhance information fusion. Through extensive experiments, we demonstrate that DCFNet outperforms previous methods in terms of both quantitative indicators and visual quality. Our proposed network provides a more comprehensive representation of the data and effectively captures the relationships between different feature scales, leading to superior pansharpening performance.