The existing detectors face challenges in accurately classifying imbalanced data and experience a drop in performance when the distribution of training data is heavily skewed. This paper suggests using the mean classification score during training to indicate the accuracy of classification for each category. To address this issue, the paper introduces two methods: Equilibrium Loss (EBL) and Memory-augmented Feature Sampling (MFS). EBL adjusts the decision boundary for weak classes by employing a score-guided loss margin, while MFS enhances the adjustment of the decision boundary by oversampling the instance features of these weak classes. The combined use of EBL and MFS helps achieve classification equilibrium in long-tailed detection, significantly improving the performance of tail classes without compromising the performance of head classes. The proposed method is evaluated on LVIS using MaskR-CNN with different backbones, such as ResNet-50-FPN and ResNet-101-FPN. The results demonstrate the superiority of the proposed approach, with a 15.6 AP improvement in the detection performance of tail classes compared to the most recent long-tailed object detectors. The code for the proposed method is available at https://github.com/fcjian/LOCE.