Reconstruction-based methods are crucial for detecting anomalies in images without supervision. However, existing models like autoencoders struggle due to the difficulty in controlling the generalizability of deep neural networks. In this study, we propose a new approach by viewing image reconstruction as a divide-and-assemble procedure. Surprisingly, by adjusting the granularity of division on feature maps, we can control the model's reconstruction capability for both normal and abnormal samples. Finer granularity leads to better reconstruction, while coarser granularity results in poorer reconstruction. By finding the right granularity, we can maximize the gap between the reconstruction error of normal and abnormal samples. To implement this approach, we incorporate a novel multi-scale block-wise memory module into an autoencoder network. Additionally, we introduce adversarial learning and explore the semantic latent representation of the discriminator, which enhances the detection of subtle anomalies. Our method achieves state-of-the-art performance on the challenging MVTec AD dataset, surpassing the vanilla autoencoder model by 10.1% in terms of the AUROC score.