Most semi-supervised learning models use consistency-based techniques to utilize unlabeled images. However, when these models are applied to human pose estimation, which involves highly imbalanced class distribution, they often fail and incorrectly predict all pixels in unlabeled images as background. This happens because the decision boundary tends to pass through dense areas of the minor class, causing more and more pixels to be misclassified as background. In this study, we propose a simple yet effective approach to address this issue. For each image, we create a pair of easy-hard augmentations and use the more accurate predictions from the easy image to guide the network in learning pose information from the hard image. This approach ensures that the network improves in a "monotonic" manner, preventing collapse. We evaluate our method on state-of-the-art pose estimators and observe significant performance improvements on three public datasets.