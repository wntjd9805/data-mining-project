Recent studies in vehicle re-identification (ReID) have focused on developing official benchmarks to improve the identification of distinguishable patterns in vehicles. However, creating these benchmarks requires significant human effort. In this paper, we aim to achieve similar results without increasing the workload. We propose a novel framework that effectively encodes both local geometric features and global representations to differentiate between vehicle instances. Our framework is optimized using only the supervision provided by official ID labels. We leverage self-supervised representation learning to discover geometric features, as we observe that objects in ReID share similar geometric characteristics. To condense these features, we introduce an interpretable attention module that utilizes local maxima aggregation instead of fully automatic learning. This module provides a physically reasonable response map and a mechanism that is easily understandable. To the best of our knowledge, we are the first to utilize self-supervised learning for discovering geometric features in vehicle ReID. We conduct comprehensive experiments on three popular datasets for vehicle ReID, namely VeRi-776, CityFlow-ReID, and VehicleID. Our results demonstrate state-of-the-art performance and promising visualization outcomes. Additionally, we showcase the scalability of our approach in other ReID tasks, such as person ReID and multi-target multi-camera (MTMC) vehicle tracking.