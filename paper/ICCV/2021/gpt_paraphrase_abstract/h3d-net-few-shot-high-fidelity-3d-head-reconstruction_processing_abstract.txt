Recent advancements in learning approaches have shown promising results in multi-view 3D reconstruction by using neural representations that implicitly capture surface geometry. However, these techniques require a large number of input views and computationally demanding optimizations. This paper addresses these limitations specifically for few-shot full 3D head reconstruction. We enhance coordinate-based representations with a probabilistic shape prior to facilitate faster convergence and improved generalization with as few as three input images. Initially, we learn a shape model of 3D heads from incomplete raw scans using implicit representations. During testing, we simultaneously train two coordinate-based neural networks for modeling geometry and estimating surface radiance using implicit differentiable rendering. To optimize this process, we adopt a two-stage strategy where the learned prior initializes and constrains the geometry in an initial optimization phase. Subsequently, the prior is fine-tuned to the scene. This approach enables high-fidelity head reconstructions with detailed representations of hair and shoulders, consistently outperforming both state-of-the-art 3D Morphable Models and non-parametric methods in the few-shot scenario and when larger sets of views are available.