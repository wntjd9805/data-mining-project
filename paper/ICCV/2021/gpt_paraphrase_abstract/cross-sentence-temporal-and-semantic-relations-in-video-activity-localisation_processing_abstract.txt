Recently, there has been a growing interest in video activity localisation, which involves automatically identifying the most important visual segments in videos based on their corresponding language descriptions. However, the current method of training supervised models for this task is costly and prone to ambiguity and subjective bias. In this study, we propose a more accurate weakly-supervised solution by introducing Cross-Sentence Relations Mining (CRM) in the generation and matching of video moment proposals. This approach uses a paragraph description of activities instead of per-sentence temporal annotations. We specifically explore two types of cross-sentence relational constraints: temporal ordering and semantic consistency among sentences. Unlike existing weakly-supervised techniques that only consider correlations within sentences, our approach takes into account the context of the entire paragraph. This is important because individual sentences can be ambiguous when considered in isolation. Our experiments on two publicly available datasets demonstrate the superiority of our approach over state-of-the-art weakly supervised methods, particularly for complex video activity descriptions.