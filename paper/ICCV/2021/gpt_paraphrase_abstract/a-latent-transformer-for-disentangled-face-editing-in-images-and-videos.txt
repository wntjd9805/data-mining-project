The movie post-production industry faces difficulties in achieving high-quality facial image editing while maintaining control and preserving identity. Existing methods often struggle with entangled facial attributes and loss of identity, and are often limited to specific tasks. To overcome these limitations, we propose a solution that involves editing facial attributes using the latent space of a StyleGAN generator. We train a dedicated latent transformation network and incorporate disentanglement and identity preservation terms in the loss function. Additionally, we introduce a pipeline for extending our face editing technique to videos. Our model successfully achieves disentangled, controllable, and identity-preserving facial attribute editing, even with real images and videos. Through extensive experiments on various datasets, we demonstrate that our model surpasses other state-of-the-art methods in terms of visual quality and quantitative evaluation.