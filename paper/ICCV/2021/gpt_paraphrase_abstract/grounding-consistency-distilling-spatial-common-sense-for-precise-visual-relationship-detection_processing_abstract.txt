Scene Graph Generators (SGGs) are models that create a directed graph from an image, with each edge representing a predicted subject-predicate-object triplet. However, current SGGs rely heavily on the context of relationships, such as the subject and object, leading to imprecise predictions. For example, if the model has seen many instances of a person wearing a shirt, it may wrongly assume that every person is wearing a shirt. This issue arises due to the lack of negative examples for most relationships, preventing models from effectively learning predicates even with ample positive examples.

To address this problem, we thoroughly investigate the context bias issue in existing SGGs and find that all state-of-the-art models suffer from the same vulnerabilities. In response, we propose a semi-supervised approach called Grounding Consistency Distillation (GCD). This approach enforces predicted triplets to be consistently grounded back to the image, improving the spatial reasoning ability of the model. GCD is model-agnostic and leverages unlabeled samples to retain valuable context information without memorizing annotations.

Furthermore, we discover that current evaluation metrics overlook unlabeled samples, making them incapable of reflecting context bias. To overcome this limitation, we introduce hard-negatives into the evaluation process and reformulate precision as a reliable metric. Through extensive experimental comparisons, we demonstrate significant quantitative improvements, with up to a 70% relative precision boost on the VG200 dataset. Additionally, qualitative improvements highlight the significance of our GCD method and revised metrics in advancing scene understanding through graph generation.

Our GCD method and metrics are crucial for addressing the context bias issue in SGGs and enhancing their performance. The code for our approach is available at https://github.com/deeplab-ai/grounding-consistent-vrd.