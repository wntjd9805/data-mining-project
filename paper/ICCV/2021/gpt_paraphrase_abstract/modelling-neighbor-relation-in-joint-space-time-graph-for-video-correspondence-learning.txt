This paper introduces a novel self-supervised technique for acquiring reliable visual correspondence from unlabeled videos. The method involves representing correspondence as paths in a joint space-time graph, where grid patches from frames serve as nodes and are connected by two types of edges: neighbor relations for aggregation strength within frames, and similarity relations for transition probability across frames. By leveraging the cycle-consistency in videos, the proposed contrastive learning objective distinguishes dynamic objects from neighboring and temporal views. Unlike previous methods, this approach actively explores neighbor relations to establish a latent association between central instances and their neighbors over time, leading to improved instance discrimination. Remarkably, the learned representation outperforms state-of-the-art self-supervised methods across various visual tasks such as video object propagation, part propagation, and pose keypoint tracking without requiring fine-tuning. Additionally, the self-supervised method even surpasses some fully supervised algorithms designed specifically for these tasks.