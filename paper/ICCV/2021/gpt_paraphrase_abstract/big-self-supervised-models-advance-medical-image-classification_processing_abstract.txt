This study examines the effectiveness of self-supervised learning as a pre-training strategy for medical image classification. While self-supervised pretraining followed by supervised fine-tuning has been successful in image recognition, it has not been widely explored in medical image analysis. The researchers conduct experiments on two different tasks: dermatology condition classification and multi-label chest X-ray classification. They demonstrate that self-supervised learning on ImageNet, followed by additional self-supervised learning on unlabeled medical images, significantly improves the accuracy of medical image classifiers. The researchers propose a novel method called Multi-Instance Contrastive Learning (MICLe) that utilizes multiple images of the underlying pathology per patient case, when available, to create more informative positive pairs for self-supervised learning. By combining their contributions, they achieve a 6.7% improvement in top-1 accuracy for dermatology classification and a 1.1% improvement in mean AUC for chest X-ray classification, surpassing strong supervised baselines pretrained on ImageNet. Furthermore, they demonstrate that large self-supervised models are resilient to distribution shift and can effectively learn with a small number of labeled medical images.