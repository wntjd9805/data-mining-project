Abstract
Active learning aims to reduce labeling costs by select-ing only the most informative samples on a dataset. Few existing works have addressed active learning for object de-tection. Most of these methods are based on multiple mod-els or are straightforward extensions of classiﬁcation meth-ods, hence estimate an image’s informativeness using only the classiﬁcation head. In this paper, we propose a novel deep active learning approach for object detection. Our approach relies on mixture density networks that estimate a probabilistic distribution for each localization and classi-ﬁcation head’s output. We explicitly estimate the aleatoric and epistemic uncertainty in a single forward pass of a sin-gle model. Our method uses a scoring function that aggre-gates these two types of uncertainties for both heads to ob-tain every image’s informativeness score. We demonstrate the efﬁcacy of our approach in PASCAL VOC and MS-COCO datasets. Our approach outperforms single-model based methods and performs on par with multi-model based methods at a fraction of the computing cost. Code is avail-able at https://github.com/NVlabs/AL-MDN . 1.

Introduction
The performance of deep detection networks is depen-dent on the size of the labeled data [31, 32]. Motivated by this, researchers have explored smart strategies to select the most informative samples in the dataset for labeling, known as active learning [35]. Typically, this is done by devising a scoring function that computes the network’s uncertainty, selecting to label the samples for which the network is least conﬁdent with regard to its predictions [2, 4, 40].
In general, the predictive uncertainty is decomposed into aleatoric and epistemic uncertainty [15, 20]. The former refers to the inherent noise in the data, such as sensor noise, and can be attributed to occlusions or lack of visual fea-tures [10, 24]. The latter refers to the uncertainty caused by the lack of knowledge of the model and is inversely pro-portional to the density of training data [38]. Modeling and distinguishing these two types of uncertainty is very impor-Figure 1: Our approach predicts aleatoric and epistemic un-certainties for both the localization and classiﬁcation heads in a single forward pass of a single model. We propose an scoring function that aggregates epistemic and aleatoric un-certainties from both heads into single value. Then, those data points with the top-K scores are sent for labeling. tant in active learning, as it allows the deep learning mod-els to know about their limitations [21, 38], i.e., recognize suspicious predictions in the sample (aleatoric uncertainty) and recognize samples that do not resemble the training set (epistemic uncertainty). To compute these types of uncer-tainty, researchers use multi-model based approaches, such as ensembles [2] or Monte Carlo (MC) dropout [13]. These methods reach good results but come with several limita-tions [11, 16]. In particular, by being multi-models, they require a much higher computing cost, and in the case of en-sembles, they also increase the number of the network’s pa-rameters [2]. Additionally, they rely only on classiﬁcation uncertainty, totally ignoring the localization uncertainty.
In this paper, we propose a novel active learning ap-proach for deep object detection. Our approach uses a single model with a single forward pass, signiﬁcantly re-ducing the computing cost compared to multiple model-based methods. Despite this, our method reaches high ac-curacy. To manage so, our method utilizes both localization and classiﬁcation-based aleatoric and epistemic uncertain-ties. As shown in Fig. 1, we base our method on a mix-ture density networks [3] that learns a Gaussian mixture model (GMM) for each of the network’s outputs, i.e., lo-calization and classiﬁcation, to compute both aleatoric and
epistemic uncertainties. To efﬁciently train the network, we propose a loss function that serves as a regularizer for in-consistent data, leading to more robust models. Our method estimates every image’s informativeness score by aggregat-ing all of the localization and classiﬁcation-based uncertain-ties for every object contained in the image. We empirically show that leveraging both types of uncertainty coming from classiﬁcation and localization heads is a critical factor for improving the accuracy. We demonstrate the beneﬁts of our approach on PASCAL VOC [9] and MS-COCO [30] in a single-stage architecture such as SSD [31], and show generalized performance in a two-stage architecture such as
Faster-RCNN [32]. Our approach consistently outperforms single-model based methods, and compared to methods us-ing multi-models, our approach yields a similar accuracy while signiﬁcantly reducing the computing cost.
In summary, our contributions are the following:
• We propose a novel deep active learning method for object detection that leverages the aleatoric and epis-temic uncertainties, by considering both the localiza-tion and classiﬁcation information. Our method is efﬁ-cient and uses a single forward pass in a single model.
• We propose a novel loss to train the GMM-based ob-ject detection network that leads to overall perfor-mance improvements in the network.
• We demonstrate the effectiveness of our approach us-ing different models on two different datasets. 2.