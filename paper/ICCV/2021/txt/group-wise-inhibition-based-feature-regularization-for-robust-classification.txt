Abstract
The convolutional neural network (CNN) is vulnerable to degraded images with even very small variations (e.g. corrupted and adversarial samples). One of the possible reasons is that CNN pays more attention to the most dis-criminative regions, but ignores the auxiliary features when learning, leading to the lack of feature diversity for ﬁnal judgment. In our method, we propose to dynamically sup-press signiﬁcant activation values of CNN by group-wise inhibition, but not ﬁxedly or randomly handle them when training. The feature maps with different activation dis-tribution are then processed separately to take the feature independence into account. CNN is ﬁnally guided to learn richer discriminative features hierarchically for robust clas-siﬁcation according to the proposed regularization. Our method is comprehensively evaluated under multiple set-tings, including classiﬁcation against corruptions, adver-sarial attacks and low data regime. Extensive experimental results show that the proposed method can achieve signiﬁ-cant improvements in terms of both robustness and general-ization performances, when compared with the state-of-the-art methods. Code is available at https://github. com/LinusWu/TENET_Training. 1.

Introduction
Recent advances in convolutional neural networks (CNNs) have led to far-reaching improvements in computer vision tasks [11, 20]. However, vulnerability of CNNs to image variations, including image corruptions [10] and ad-versarial samples [8], has not been well resolved yet. Re-searchers are thus exploring various ways to improve the network robustness against these variations.
Adversarial training [10, 30, 32] is a typical solution to improve the robustness of CNNs, which includes the at-†Equal Contribution
∗Corresponding Author
Figure 1. Some solutions to improve the robustness of CNN. Un-like with the regular training (a), adversarial training (b) widely utilizes adversarial samples to train a robust CNN. Data augmenta-tion and regularization based method (c) improves the robustness performance by ﬁlling up new samples surrounding the decision boundary. The proposed regularization method (d) enables net-work to increase the representation space (e.g. red auxiliary axis in d1) of the features learned by the CNN, and achieves better ro-bustness against corrupted and adversarial samples, with various projections on new planes (e.g. d2 and d3). Best viewed in color. tacked samples into the training data, as shown in Fig. 1 (b).
Since adversarial training may impair the generalization performance, there is often an inherent trade-off between classiﬁcation accuracy and adversarial robustness [29, 30].
In order to improve the robustness and generalization si-multaneously, data augmentation and regularization meth-ods (e.g. Random Erasing [33], Augmix [14], Cutout[7],
and their importance evaluation, the group-wise reversed map is proposed to suppress the activation values corre-sponding to the most signiﬁcant discriminative regions, and guide the network to learn more auxiliary information in less signiﬁcant regions. As shown in the second row of
Fig. 2, the suppression of most signiﬁcant discriminative regions is beneﬁcial for exploring more diverse features in
CNNs. Experimental results show that the proposed method can improve the top-1 error rate of adversarial training from 36.37% to 31.75%, and outperforms regularization meth-ods signiﬁcantly in terms of classiﬁcation accuracy based on small sample. In summary,
• A group-wise inhibition based regularization method is proposed to explore auxiliary features and promote feature diversity.
• Feature maps with different activation distribution are processed separately to learn richer discriminative fea-tures hierarchically to better represent images.
• Our proposed method achieves competitive perfor-mances in terms of adversarial robustness and gener-alization compared with related variants and the state of the arts. 2.