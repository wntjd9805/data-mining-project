Abstract
Recently, directly detecting 3D objects from 3D point clouds has received increasing attention. To extract object representation from an irregular point cloud, existing meth-ods usually take a point grouping step to assign the points to an object candidate so that a PointNet-like network could be used to derive object features from the grouped points.
However, the inaccurate point assignments caused by the hand-crafted grouping scheme decrease the performance of 3D object detection.
In this paper, we present a simple yet effective method for directly detecting 3D objects from the 3D point cloud. In-stead of grouping local points to each object candidate, our method computes the feature of an object from all the points in the point cloud with the help of an attention mechanism in the Transformers [42], where the contribution of each point is automatically learned in the network training. With an improved attention stacking scheme, our method fuses object features in different stages and generates more ac-curate object detection results. With few bells and whistles, the proposed method achieves state-of-the-art 3D object de-tection performance on two widely used benchmarks, Scan-Net V2 and SUN RGB-D. The code and models are pub-licly available at https://github.com/zeliu98/
Group-Free-3D 1.

Introduction 3D object detection on point cloud simultaneously local-izes and recognizes 3D objects from a 3D point set. As a fundamental technique for 3D scene understanding, it plays an important role in many applications such as autonomous driving, robotics manipulation, and augmented reality.
Different from 2D object detection that works on 2D reg-ular images, 3D object detection takes irregular and sparse
*This work is done when Ze Liu is an intern at MSRA.
†Contact person
Figure 1. With the heuristic point grouping step, all points in blue box of RoI-Pooling or blue ball of Voting are assigned and aggre-gated to derive the object features, resulting in wrong assignments.
Our group-free based approach automatically learn the contribu-tion of all points to each object, which has ability to alleviate the drawbacks of the hand-crafted grouping. point cloud as input, which makes it difﬁcult to directly ap-ply techniques used for 2D object detection techniques. Re-cent studies [27, 35, 26, 51] infer the object location and ex-tract object features directly from the irregular input point cloud for object detection. In these methods, a point group-ing step is required to assign a group of points to each object candidate, and then computes object features from assigned groups of points. For this purpose, different grouping strate-gies have been investigated. Frustum-PointNet [27] applies the Frustum envelop of a 2D proposal box for point group-ing. Point R-CNN [35] groups points within the 3D box proposals to objects. VoteNet [26] determines the group as the points which vote to the same (or spatially-close) center point. Although these hand-crafted grouping schemes fa-cilitate 3D object detection, the complexity and diversity of objects in real scene may lead to wrong point assignments (shown in Figure. 1) and degrade the 3D object detection performance.
In this paper, we propose a simple yet effective tech-nique for detecting 3D objects from point clouds without the
handcrafted grouping step. The key idea of our approach is to take all points in the point cloud for computing features for each object candidate, in which the contribution of each point is determined by an automatically learned attention module. Based on this idea, we adapt the Transformer to ﬁt for 3D object detection, which could simultaneously model the object-object and object-pixel relationships, and extract the object features without handcrafted grouping.
To further release the power of the transformer architec-ture, we improve it in two aspects. First, we propose to iteratively reﬁne the prediction of objects by updating the spatial encoding of objects in different stages, while the original application of Transformers adopt the ﬁxed spatial encoding. Second, we use the ensemble of detection results predicted at all stages during inference, instead of only us-ing the results in the last stage as the ﬁnal results. These two modiﬁcations efﬁciently improve the performance of 3D object detection with few computational overheads.
We validate our method with both ScanNet V2 [6] and SUN RGB-D [52] benchmarks. Results show that our method is effective and robust to the quality of ini-tial object candidates, where even a simple farthest point sampling approach has been able to produce strong re-sults on ScanNet V2 and SUN RGB-D benchmarks. For the SUN RGB-D dataset, our method with the ensem-ble scheme results in signiﬁcant performance improvement (+3.8 mAP@0.25). With few bells and whistles, the pro-posed approach achieved state-of-the-art performance on both benchmarks.
We believe that our method also advocates a strong po-tential by using the attention mechanism or Transformers for point cloud modeling, as it naturally addresses the in-trinsic irregular and sparse distribution problems encoun-tered by 3D point clouds. This is contrary to 2D image modeling, where such modeling tools mainly act as a chal-lenger or a complementary component to the mature grid modeling tools such as ConvNets variants [16, 32, 46] and
RoI Align [2, 5]. 2.