Abstract
Visible-Infrared person re-identiﬁcation (VI-ReID) aims to match cross-modality pedestrian images, breaking through the limitation of single-modality person ReID in dark environment. In order to mitigate the impact of large modality discrepancy, existing works manually design var-ious two-stream architectures to separately learn modality-speciﬁc and modality-sharable representations.
Such a manual design routine, however, highly depends on mas-sive experiments and empirical practice, which is time con-suming and labor intensive.
In this paper, we system-atically study the manually designed architectures, and identify that appropriately separating Batch Normalization (BN) layers is the key to bring a great boost towards cross-modality matching. Based on this observation, the essen-tial objective is to ﬁnd the optimal separation scheme for each BN layer. To this end, we propose a novel method, named Cross-Modality Neural Architecture Search (CM-NAS). It consists of a BN-oriented search space in which the standard optimization can be fulﬁlled subject to the cross-modality task. Equipped with the searched archi-tecture, our method outperforms state-of-the-art counter-parts in both two benchmarks, improving the Rank-1/mAP by 6.70%/6.13% on SYSU-MM01 and by 12.17%/11.23% on RegDB. Code is released at https://github.com/
JDAI-CV/CM-NAS. 1.

Introduction
Person re-identiﬁcation (ReID) refers to matching pedes-trian images acquired from disjoint cameras [20, 53, 62]. In recent years, it has received substantial attention due to its signiﬁcant practical value in video surveillance [47]. Con-ventional person ReID is only devoted to single-modality,
∗Equal contribution.
†Corresponding author. i.e. all the pedestrian images are taken by visible cameras during day time. Beneﬁting from the strenuous efforts of researchers, impressive achievements have been made on most benchmarks [57, 1, 54]. Nevertheless, the visible cam-eras cannot image clearly in dark environment, which im-pedes the popularization and application of person ReID
[39]. To overcome this obstacle, in addition to the visible (VIS) cameras, infrared (IR) cameras that are robust to il-lumination variants are also equipped in many surveillance scenarios [5]. Therefore, in practice, we often need to match
VIS and IR pedestrian images, raising the task of VI-ReID.
Modality discrepancy, caused by different wavelengths of VIS and IR images, is one of the most difﬁcult chal-lenges in VI-ReID. Existing works have manually designed various two-stream architectures [49, 50, 24] to mitigate the impact of the large modality discrepancy. Speciﬁcally, as exempliﬁed in Fig. 2, some layers are separated into two branches to learn modality-speciﬁc representations for
VIS an IR data respectively, while the remaining layers are shared to learn modality-sharable representations. The in-tuition behind this design is that VIS and IR images con-tain both modality-speciﬁc information, e.g. the spectrum, and modality-sharable information, e.g. the identity. At this point, an obvious problem is raised: which layers should be separated into two branches and which layers should be shared? Some methods separate the layers in the ﬁrst one
[47, 50] or ﬁve [52] blocks, while some others even share the whole network [42]. There is still no consensus on the optimal design of the neural architecture for VI-ReID.
In this paper, to investigate the impact of different sep-aration schemes, we manually design a total of 195 differ-ent two-stream architectures. Given that Batch Normaliza-tion (BN) plays a crucial role in learning modality distri-butions [45], we also perform separation in units of BN layers, in addition to the entire block as usual. As illus-trated in Section 3.1, after comprehensively comparing the performances of all the architectures, we obtain two major
observations: (1) only separating BN layers in the block is superior than separating the entire block; (2) separating two blocks of BN layers generally outperforms separating a single one. With these in mind, we arrive at a conclusion that appropriately separating all BN layers is the key to bring a great boost towards cross-modality match-ing. As a consequence, the essential objective is to ﬁnd the optimal separation scheme for each BN layer in the back-bone. However, there are a great deal of potential separation schemes. Speciﬁcally, the backbone ResNet50 [14] con-tains 53 BN layers, leading to a total of 253 possible archi-tectures. It is time consuming and labor intensive to manu-ally traverse through all the possible architectures. To tackle this intractable problem, inspired by recently thriving Neu-ral Architecture Search (NAS) technique [25, 16, 34, 6], we propose a novel Cross-Modality NAS (CM-NAS) to auto-matically determine whether each BN layer separates or not.
A BN-oriented search space is elaborately built in which the standard optimization can be fulﬁlled subject to the cross-modality task. Note that it is infeasible to directly apply ex-isting single-modality NAS methods like Auto-ReID [30], because its search space is powerless to bridge the modal-ity discrepancy, as discussed in Section 4.2.
In contrast, our designed search space supports to learn both modality-speciﬁc and modality-sharable representations via switch-ing corresponding separating and sharing operations, which
ﬁrst opens the door of NAS to cross-modality matching.
Without bells and whistles, our method exceeds all state-of-the-art methods on both two VI-ReID benchmarks. On
SYSU-MM01, our method achieves an improvement of 6.70% and 6.13% in terms of the Rank-1 accuracy and the mAP score. On RegDB, our method promotes the two indicators by 12.17% and 11.23%, respectively. Com-pared with the baseline ResNet50, our method increases the Rank-1/mAP by 7.50%/6.70% on SYSU-MM01 and by 8.73%/8.35% on RegDB, with a small additional pa-rameters and no extra computational costs. We hope this simple yet effective method will be a solid foundation to facilitate future research in VI-ReID.
To sum up, we make the following three contributions:
• We systematically analyze 195 different manually de-signed architectures, and identify the signiﬁcance of separating BN layers. This conclusion motivates us to develop a BN-oriented search algorithm.
• A novel CM-NAS is proposed to automatically search the optimal separation scheme for BN layers, which
ﬁlls the blank of NAS in cross-modality matching.
• Our method signiﬁcantly surpasses state-of-the-art competitors in both two benchmarks, improving the
Rank-1/mAP by 6.70%/6.13% on SYSU-MM01 and by 12.17%/11.23% on RegDB. Code will be released to aid future research in VI-ReID. 2.