Abstract
We describe a simple pre-training approach for point clouds. It works in three steps: 1. Mask all points occluded in a camera view; 2. Learn an encoder-decoder model to reconstruct the occluded points; 3. Use the encoder weights as initialisation for downstream point cloud tasks.
We ﬁnd that even when we pre-train on a single dataset (ModelNet40), this method improves accuracy across dif-ferent datasets and encoders, on a wide range of down-stream tasks. Speciﬁcally, we show that our method out-performs previous pre-training methods in object classi-ﬁcation, and both part-based and semantic segmentation tasks. We study the pre-trained features and ﬁnd that they lead to wide downstream minima, have high transforma-tion invariance, and have activations that are highly cor-related with part labels. Code and data are available at: https://github.com/hansen7/OcCo 1.

Introduction
There has been a ﬂurry of exciting new point cloud models for object detection [27, 52, 64] and segmenta-tion [22, 26, 57, 65]. These methods rely on large scale point cloud datasets that are labelled. Unfortunately, la-belling point clouds is challenging for a number of reasons: (1) Point clouds can be sparse, occluded, and at low resolu-tions, making the identity of points ambiguous; (2) Datasets that are not sparse can easily reach hundreds of millions of points (e.g., small dense point clouds for object clas-siﬁcation [63] and large vast point clouds for reconstruc-tion [66]); (3) Labelling individual points or drawing 3D bounding boxes are both more time-consuming and error-prone than labelling 2D images [50]. These challenges have impeded the deployment of point cloud models into new real world settings where labelled data is scarce.
However, current 3D sensing modalities (i.e., 3D scan-ners, stereo cameras, lidars) have enabled the creation of large unlabelled repositories of point cloud data [13, 41].
This has inspired a recent line of work on unsupervised pre-training methods to learn point cloud model initialisation.
Initial work used latent generative models such as genera-tive adversarial networks (GANs) [1, 14, 54] and autoen-Figure 1: The relative improvement over random ini-tialisation of multiple pre-training methods: Jigsaw [42], cTree [44], and OcCo (ours) for various downstream tasks. coders [15, 29, 59]. These have been recently outperformed by self-supervised objectives [42, 56, 2, 44, 20, 61].
Inspired by this recent line of work, we propose Oc-clusion Completion (OcCo), an unsupervised pre-training method that consists of: (a) a mechanism to generate masked point clouds via view-point occlusions, and (b) a completion task to reconstruct the occluded point cloud.
The idea of occlusion+completion is grounded in three ob-servations: (1) A pre-trained model that is accurate at com-pleting occluded point clouds needs to understand spatial and semantic properties of these point clouds. (2) 3D scene completion [45, 9, 19] has been shown to be a useful aux-iliary task for learning representations for visual localisa-tion [43]. (3) Mask-based completion tasks have become the de facto standard for learning pre-trained representa-tions in natural language processing [11, 32, 36] and are widely used in pre-training for images [35] and graphs [24].
We demonstrate that pre-training on a single object-level dataset (ModelNet40) can improve the performance of a range of downstream tasks, even on completely different datasets. Speciﬁcally we ﬁnd that OcCo has the follow-ing properties compared to other initialisation techniques: 1) Improved sample efﬁciency in few-shot learning experi-ments; 2) Improved generalisation in object classiﬁcation, object part segmentation, and semantic segmentation; 3)
Wider local minima found after ﬁne-tuning; 4) More seman-Figure 2: Overview of OcCo. 1. Take any point cloud dataset and generate occluded objects for each input by (a) randomly sampling a camera view-point, and (b) removing points hidden from that view-point (for all experiments we use the same occluded dataset generated from ModelNet40); 2. Train an encoder-decoder model to complete the occluded point clouds (the encoder can be any model that learns representations of point clouds, the decoder can be any completion model); 3. Use the learned encoder weights as initialisation for any downstream task (e.g., few-shot learning, object classiﬁcation, part/semantic segmentation). We show that OcCo outperforms a variety of pre-training methods across multiple models and tasks. tically meaningful representations as described via network dissection [4, 5]; 5) Better clustering quality under jittering, translation, and rotation transformations. 2.