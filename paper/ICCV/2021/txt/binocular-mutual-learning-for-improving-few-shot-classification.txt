Abstract
Most of the few-shot learning methods learn to transfer knowledge from datasets with abundant labeled data (i.e., the base set). From the perspective of class space on base set, existing methods either focus on utilizing all classes un-der a global view by normal pretraining, or pay more atten-tion to adopt an episodic manner to train meta-tasks within few classes in a local view. However, the interaction of the two views is rarely explored. As the two views capture com-plementary information, we naturally think of the compati-bility of them for achieving further performance gains. In-spired by the mutual learning paradigm and binocular par-allax, we propose a unified framework, namely Binocular
Mutual Learning (BML), which achieves the compatibility of the global view and the local view through both intra-view and cross-view modeling. Concretely, the global view learns in the whole class space to capture rich inter-class relationships. Meanwhile, the local view learns in the lo-cal class space within each episode, focusing on matching positive pairs correctly. In addition, cross-view mutual in-teraction further promotes the collaborative learning and the implicit exploration of useful knowledge from each oth-er. During meta-test, binocular embeddings are aggregated together to support decision-making, which greatly improve the accuracy of classification. Extensive experiments con-ducted on multiple benchmarks including cross-domain val-idation confirm the effectiveness of our method1. 1.

Introduction
Conventional classification methods heavily rely on mas-sive labeled data [32] with diverse visual variations. How-ever, in many realistic scenarios, only limited labeled data is available [43, 26], thereby giving rise to the investigation of few-shot classification (FSC), where only few available training data is given for the learning of new visual con-cepts. Such a setting makes FSC a challenging problem, since novel classes are unpredictable and the sampling of
∗Xi Qiu (qiuxi@megvii.com) is the corresponding author. 1https://github.com/ZZQzzq/BML
Table 1. Comparison of BML with several representative methods from mi-from the view of base class space. Accuracy (Acc.) niImageNet [39]. Obviously, the unified perspective of BML is more effective. w/ global w/ local
MAML [10]
MatchingNet [39]
RelationNet [35]
ProtoNet [33]
Rethink [36]
DC [24]
CloserLook [6]
DeepEMD [45]
FEAT [44]
Meta-Baseline [7]
Neg-Cosine [25]
Our BML (cid:37) (cid:34) (cid:34) (cid:34) (cid:34) (cid:37) (cid:34) (cid:34) strategy one-stage one-stage one-stage one-stage one-stage one-stage one-stage two-stage two-stage two-stage two-stage one-stage
Acc. 63.1 55.3 65.3 68.2 82.1 79.0 75.7 82.4 82.1 79.3 81.6 83.6 few shots is also biased.
In order to overcome those d-ifficulties, many effective approaches have been proposed in recent years, which can be mainly summarized into t-wo categories according to training strategies. The first category is fine-tuning based paradigms [29, 24, 6, 7, 36], which learn classifiers in the whole base class space with a straightforward purpose of maximize differences between classes. Since all base classes are visible under each iter-ation, we refer to this kind of methods as the global view.
The other promising strategy is metric-based meta-training schemes [9, 39, 33, 35, 27, 44, 18, 13], which only tune on a few classes in each episode. The main idea comes from metric learning and the purpose is to match unlabeled query to its correct class with a small labeled support set. Because the visible range of base classes for each meta-task is limit-ed, we oppositely call them the local view.
Considering that single view (whether global or local) is relatively weak, it is not enough to provide adequate knowl-edge for accurate classification. What’s more, the com-bination of dual views fits well with the characteristics of
“people deepen their perception through two eyes”. To this end, we propose this new Binocular Mutual Learning (BM-L) paradigm, which equips the network with a global view
and a local view simultaneously. The combination of t-wo complementary views works like a binocular system, and the mutual interaction [47] through two views further promotes their cooperation and calibrates the inappropri-ate expression caused by single “biased” view. Concretely,
BML generates better expression through both intra-view and cross-view modeling. The intra-view training captures view-specific knowledge, where two balanced feature space are built, one focuses on inter-class relationship perception (global view) and the other pays attention on matching de-tails (local view). Meanwhile, the cross-view mutual inter-action facilitates the implicit knowledge transfer from each other. To balance “binocular parallax”, we enlarge the opti-mization difficulty of the local view, so that the global view can learn more useful knowledge from mutual interaction (For more details, please refer to Section.3.2.2).
Clearly, BML paradigm has two advantages: strong transferability and high time-efficiency, which are manifest-ed from the following comparisons. Concretely, compared with single view based methods mentioned above, BML has two complementary views, so that more transferable
In contrast, sin-and reliable knowledge can be learned. gle global training lacks additional constraints, making it easy to over-fit on base patterns [12]. Meanwhile, single local training is restricted by local perspectives, whose per-formance is heavily depend on the configuration of tasks, not to mention the complex structures. Moreover, compared with two-stage methods which firstly excute global training and then tune the embedding with local training, BML u-nifies the two views in a one-stage framework and enables the promotion of each other. By contrast, two-stage meth-ods [34, 6, 45, 44, 25] are time-consuming. They focus on how to better learn embedding in the first stage to provide stronger features for the second stage of optimization [25], but ignore that local view and global view can promote each other in a unified manner.
We highlight the advantages of BML compared with sev-eral typical approaches in Table 1. As the first batch of methods to consider the combination of dual views, we pro-pose an elegant compatibility strategy: binocular mutual learning, which is inspired by the fact that human beings usually perceive the world through two eyes (benefit from appropriate binocular parallax). The two complementary views simulate the binocular mode, and the mutual inter-action calibrates deviation. Extensive experiments confirm the effectiveness of BML, which is mainly reflected on the stable performance under different granularity evaluation.
No matter facing coarse-grained (e.g., miniImageNet [39]) or fine-grained (e.g. CUB [40]) situation, BML performs well. However, single view based methods cannot handle all the situations. This confirm that the unified framework does facilitate the mutual calibration of the two views. In summary, the contributions of this paper are as follows:
• We closely analyze the status quo of FSC and pro-pose an efficient one-stage Binocular Mutual Learning paradigm: BML, which elegantly aggregate the global view and the local view through both intra-view and cross-view modeling.
• To enhance mutual learning, we propose an elastic loss to readjust the optimization difficulty of the local view, which promotes the bidirectional implicit knowledge transfer.
• Extensive experiments on multiple benchmarks in-cluding cross-domain validation verify the effective-ness of our framework. 2.