Abstract
Even though CCTV cameras are widely deployed for traffic surveillance and have therefore the potential of be-coming cheap automated sensors for traffic speed analysis, their large-scale usage toward this goal has not been re-ported yet. A key difficulty lies in fact in the camera calibra-tion phase. Existing state-of-the-art methods perform the calibration using image processing or keypoint detection techniques that require high-quality video streams, yet typ-ical CCTV footage is low-resolution and noisy. As a result, these methods largely fail in real-world conditions. In con-trast, we propose two novel calibration techniques whose only inputs come from an off-the-shelf object detector. Both methods consider multiple detections jointly, leveraging the fact that cars have similar and well-known 3D shapes with normalized dimensions. The first one is based on minimiz-ing an energy function corresponding to a 3D reprojection error, the second one instead learns from synthetic training data to predict the scene geometry directly. Noticing the lack of speed estimation benchmarks faithfully reflecting the actual quality of surveillance cameras, we introduce a novel dataset collected from public CCTV streams. Experimen-tal results conducted on three diverse benchmarks demon-strate excellent speed estimation accuracy that could enable the wide use of CCTV cameras for traffic analysis, even in challenging conditions where state-of-the-art methods com-pletely fail. Additional information can be found on our project web page: https://rebrand.ly/nle-cctv 1.

Introduction
Being able to accurately measure the traffic speed on road networks is important for many applications like live intelligent transportation system and itinerary planning, traffic analysis [24, 40], and anomaly detection [18, 10].
This is normally achieved through dedicated hardware sen-sors like roadside radar sensors on highways, inductive loop detectors at intersections, GPS data collected from probe fleet, etc. [32, 23]. Nevertheless, such equipment is expen-sive and can hardly be deployed quickly and at a large scale.
Figure 1. Cars in the BrnoCompSpeed [44] benchmark (left) and our CCTV dataset (right) displayed at their actual apparent size.
Calibration methods [16, 43, 9, 5, 4] are based on image pro-cessing techniques (estimating angles of lines on moving cars, green lines) or keypoint localization (colored crosses) that are both highly impacted by image quality and resolution. Applying the same techniques on actual CCTV footage, where the resolution is low and quality often mediocre, turns out to be nearly impossible.
Traffic surveillance cameras, often (improperly) dubbed
CCTVs, are already widely deployed for manual traffic monitoring. Since they are directly filming roads and ve-they provide a rich flow of video data that im-hicles, plicitly contains nearly all relevant traffic information.
It has therefore been noted that CCTV cameras have the potential to be turned into traffic speed sensors at little cost [2, 32, 30, 18, 28, 23]. In this paper, we precisely fo-cus on this particular problem, i.e. the estimation of vehi-cle speed from monocular videos captured via surveillance cameras. This is in fact a challenging problem. As a mat-ter of fact, there is to the best of our knowledge no large-scale usage of CCTV cameras for automated traffic speed surveillance, despite the public availability of CCTV real-time video streams [23, 2, 30, 18].
One of the explanation lies in the fact that state-of-the-art approaches often assume that cameras are already calibrated [42, 35], which is rarely the case for CCTVs.
Still, recent methods were developed to automatically cali-brate cameras by looking for specific clues on moving ve-hicles [17, 43, 9, 6, 6, 5]. For instance, one solution is to look for straight edges perpendicular to the car motion and parallel to the ground (green lines in Fig. 1), as the 1
icated physical sensors, has been considered actively since at least two decades [42, 19, 21] (see [34] for a compre-hensive survey). The vast majority of approaches, includ-ing modern ones [17, 18, 22, 28, 33, 35, 46, 23, 6, 5], can be formulated as a 3-step pipeline consisting of (1) detecting and (2) tracking vehicles, followed by (3) con-verting displacements from pixels to meters. Earlier works achieved vehicle detection via handcrafted methods such as background subtraction [15, 19, 21]. Nowadays, object de-tectors based on deep networks (e.g. Faster-RCNN [41]), and possibly fine-tuned to CCTVs conditions [27], are pre-ferred due to their robustness and superior performance
[18, 43, 28, 46]. Temporally connecting these detections in order to form vehicle tracks can then be performed ei-ther heuristicly (e.g. Kalman filter [8], [17, 46]) or with learned models [28]. The last step involves to convert each track, i.e. the pixel coordinates of a given vehicle along time, to meters in a world coordinate system. To the best of our knowledge, this step is systematically performed un-der the planar road assumption, which assumes that a ho-mography directly maps image pixels to metric coordinates
[27, 28, 33, 35, 44, 46, 43, 23, 30, 17, 18].
Camera calibration. Estimating the homography that re-lates the camera view with the road plane essentially boils down to calibrating the camera. This step is critical for the accuracy of vehicle speed measurements, as the speed es-timation is highly sensitive to the calibration quality. The calibration consists of determining the intrinsic and extrin-sic camera parameters describing, e.g., the focal length and camera 3D pose (translation and rotation) [13]. We refer the reader to [44] for a more detailed review on camera cal-ibration and now only include a brief description of exist-ing methods. Calibration parameters are either manually entered by the user [42] or estimated automatically from
CCTV footage. Manual methods typically require the user to annotate several points on the road with known coor-dinates [42, 44, 36, 35]. Automatic methods usually as-sume a straight planar road and rely on detecting vanishing points as an intersection of road markings (i.e. line paint-ings) [12, 11, 21] or from vehicle motion [13, 17, 16, 43].
Note that finding the vanishing points is not sufficient to fully calibrate the camera as it yields an homography up to an unknown scaling factor. This factor also needs to be es-timated accurately since it affects all speeds linearly. Semi-automatic approaches therefore adopt some form of man-ual annotations where several known distances are typically carefully measured on the image by an operator [18, 28, 46].
FullACC and its improved version [16, 43] have been pro-posed to overcome these limitations and perform a fully-automatic calibration. After recovering the vanishing points using image-processing techniques, the scaling factor is es-timated by fine-grained categorization of the vehicles (SUV,
...), retrieving a corresponding 3D CAD sedan, combi,
Figure 2. Example of frames from typical CCTV cameras. Resolu-tion and quality are typically low and cars can appear quite small. apparent angle between perpendicular edges is related to the camera focal [16, 43]. Another option is to localize certain keypoints (colored crosses in Fig. 1) which, com-bined with the knowledge of the corresponding 3D car model, establish 2D-3D correspondences that lead to the camera 3D pose [9, 6, 6, 5]. These techniques, however, are complex and highly sensitive to noise, hence high-quality footage with high-resolution is required in practice. The
BrnoCompSpeed dataset [44], which serves as benchmark for all these methods, incidentally comprises only high-resolution videos (2M Pixels) captured with high-quality optics that are unlikely to be encountered in field condi-tions. CCTV footage typically consists of low-quality, low-resolution and blurry/noisy video clips with tiny-looking cars, as exemplified in Fig. 1 and 2.
In this paper, we take a radically different approach for estimating the speed of vehicles solely based on vehicle detections that are output by an off-the-shelf object detec-tor. As a first contribution, we propose a novel calibration method based on minimizing a 3D reprojection error that leverages general assumptions about the 3D shape and di-mension of cars. As a second contribution, we propose a trainable version of the first method that instead learns to predict the scene geometry directly. Both approaches can handle non-straight roads and recover the full camera cal-ibration in order to calculate vehicle speeds. Finally, as a third contribution, we introduce a novel dataset collected from public CCTV video streams and annotated with GPS tracks. Our experiments demonstrate excellent performance on synthetic and real data, even in challenging conditions. 2.