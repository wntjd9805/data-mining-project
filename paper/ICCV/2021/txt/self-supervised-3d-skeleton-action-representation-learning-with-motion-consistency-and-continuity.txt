Abstract
Recently, self-supervised learning (SSL) has been proved very effective and it can help boost the performance in learning representations from unlabeled data in the image domain. Yet, very little is explored about its usefulness in 3D skeleton-based action recognition understanding. Directly applying existing SSL techniques for 3D skeleton learning, however, suffers from trivial solutions and imprecise rep-resentations. To tackle these drawbacks, we consider per-ceiving the consistency and continuity of motion at different playback speeds are two critical issues. To this end, we pro-pose a novel SSL method to learn the 3D skeleton represen-tation in an efficacious way. Specifically, by constructing a positive clip (speed-changed) and a negative clip (motion-broken) of the sampled action sequence, we encourage the positive pairs closer while pushing the negative pairs to force the network to learn the intrinsic dynamic motion con-sistency information. Moreover, to enhance the learning features, skeleton interpolation is further exploited to model the continuity of human skeleton data. To validate the effec-tiveness of the proposed method, extensive experiments are conducted on Kinetics, NTU60, NTU120, and PKUMMD datasets with several alternative network architectures. Ex-perimental evaluations demonstrate the superiority of our approach and through which, we can gain significant per-formance improvement without using extra labeled data. 1.

Introduction
In recent years, 3D action recognition based on skeleton has made remarkable progress through learning discrimina-†Corresponding authors.
Figure 1. An illustrative example (i.e., “jump up”) of our main idea. (a) Motion consistency. Although the two clips are sampled consecutively (1x speed) and alternately (2x speed), respectively, we can easily tell they are similar because they share the same underlying skeletal movements and the consistent motion trends. (b) Motion continuity. When the sampling interval is set to 2 frames, the complemented motion of the interval frames should make the whole temporal motion look natural and coherent. tive features with deep learning networks [31, 33, 37, 49].
However, these methods rely heavily on supervision, and collecting such labels is very time-consuming and labor-intensive. This makes the development of unsupervised learning techniques and the use of a large amount of unla-beled data the urgent needs, and among them a powerful ap-proach is self-supervised learning (SSL). In image domain, as images contain rich information that is beneficial to fea-ture extraction, many effective SSL techniques [3, 6, 11, 38] are well exploited. Comparatively, for tasks over skeleton data which represent a person by 3D coordinate positions of key joints, it becomes very challenging to leverage SSL techniques to learn discriminative motion representation.
Some recent methods [53, 18] attempt to solve these challenges by directly adopting the existing video SSL tech-niques on skeleton data such as using motion prediction [7], jigsaw puzzle recognition [26] and temporal clip orders pre-diction [48] as pretext tasks. As for sequence data, play-back rate perception [1, 43] achieves great success and is the most common way to model spatial-temporal information, which can help networks to learn representative motion fea-tures. However, directly applying these methods to skeleton data suffer from two limitations: (1) Human skeleton mo-tions in nature move at different speeds, and predicting dif-ferent absolute playback speeds of the sequence is ambigu-ous, which will yield trivial solutions as mentioned in [11].
Namely, the network can easily predict the corresponding rates by simply remembering certain frames, this is harm-ful to features representation learning. (2) Unlike the video data, 3D skeleton only contains dynamic motion informa-tion but without appearance information. Such methods as in [46, 43] that explore instance appearance features are not suitable for the skeleton data, which will cause imprecise learning representations. Therefore, how to extend the ex-isting SSL methods to the skeleton domain is a challenging task and has not been well explored.
Motivation. Inspired by human visual intuition, we ob-serve that perceiving the motion consistency and continuity are two critical issues for learning motion representation.
As shown in Figure 1(a), the same motion clips with differ-ent playback speeds look similar to each other since they share the intrinsic motion consistency (i.e., squat-down, leg-lifted). Further to say, we will not consider of an ac-celerating “walking” motion (i.e., 2x playback speed) as a
“jumping” motion because they don’t have the same under-lying motion. In addition, as shown in Figure 1(b), we argue that it is possible for us to imagine the correlation between the missing frames when we have fully learned the motion since each clip has the property of motion continuity.
Based on the above observation, we propose a novel SSL method to learn the 3D skeleton representation in an ef-ficacious way. Specifically, we construct two clips from the same sampled motion sequence as positive and negative pairs, respectively. Then we train the networks to distin-guish their intrinsic motion consistency instead of predict-ing the specific playback speed of each video clip. The pos-itive pairs are with the same motion but different playback speeds, while the negative pairs are with the same playback speeds but motion-broken. Our objective is to pull the posi-tive closer while pushing the negative farther to the original clip in the latent space. In this sense, the networks can pay more attention to the skeleton dynamic motion information so as to learn discriminative feature representation.
Moreover, to encourage the networks to learn the en-hanced motion features, we design a skeleton interpolation module, which aims to model the motion continuity of hu-man skeleton data. In this task, the input actions at different playback speeds are reconstructed to the actions of a par-ticular interpolation rate. Namely, some accelerating mo-tion can complement the dynamic information of the miss-ing frames (e.g., a 2x playback speed motion can be inter-polated into a 1x playback speed motion) to establish the learning of motion coherence, so as to have better represen-tation of the underlying motion features.
In the proposed self-supervised framework, we utilize different deep neural networks as our backbones to learn skeleton representation. To validate the effectiveness of our approach in deep learning for 3D skeleton-based action un-derstanding, we conduct massive experiments covering dif-ferent settings, including self-supervised pre-training, fine-tuning on downstream tasks and semi-supervised training.
Experimental results show the superiority of our proposed method and we can significantly boost the performance without using any extra labeled data. The main contribu-tions of our paper can be summarized as follows:
• We propose a novel approach for self-supervised skele-ton representation learning by perceiving motion con-sistency and continuity, through which, we can drive the network to learn the discriminative motion repre-sentation features.
• By constructing speed-changed and motion-broken clips, we encourage the positive pairs closer while pushing the negative pairs to force the network to learn the intrinsic motion consistency information. More-over, skeleton interpolation is further exploited to model the continuity of human skeleton data to en-hance the learning features.
• Extensive experimental evaluations on three network architectures under several settings show the effec-tiveness of our proposed approach powered by self-supervised pre-training. We consider these findings will encourage more research on unsupervised pretext task design for 3D skeleton action understanding. 2.