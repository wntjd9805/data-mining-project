Abstract
This paper studies the problem of novel category discov-ery on single- and multi-modal data with labels from differ-ent but relevant categories. We present a generic, end-to-end framework to jointly learn a reliable representation and as-sign clusters to unlabelled data. To avoid over-ﬁtting the learnt embedding to labelled data, we take inspiration from self-supervised representation learning by noise-contrastive estimation and extend it to jointly handle labelled and un-labelled data.
In particular, we propose using category discrimination on labelled data and cross-modal discrimina-tion on multi-modal data to augment instance discrimination used in conventional contrastive learning approaches. We further employ Winner-Take-All (WTA) hashing algorithm on the shared representation space to generate pairwise pseudo labels for unlabelled data to better predict cluster assignments. We thoroughly evaluate our framework on large-scale multi-modal video benchmarks Kinetics-400 and
VGG-Sound, and image benchmarks CIFAR10, CIFAR100 and ImageNet, obtaining state-of-the-art results. 1.

Introduction
With the tremendous advances in deep learning, recent machine learning models have shown superior performance on many tasks, such as image recognition [9, 30], object de-tection [54, 41], image segmentation [7], etc. While the state-of-the-art models might even outperform human in these tasks, the success of these models heavily relies on the huge amount of data with human annotations under the closed-world assumption. Applying deep learning in real (open) world brings many new challenges: it is cost-inhibitive to identify and annotate all categories, and new categories could keep emerging. Conventional methods struggle on handling unlabelled data from new categories [13]. On the ﬂip side, real world provides rich unlabeled data, which are often multi-modal (e.g., video and audio), allowing more possi-* Corresponding author. bilities for machine learning models to learn in a similar way as human. Indeed, humans learn from multi-modal data everyday with text, videos, audios, etc.
In this paper, we focus on automatically learning to dis-cover new categories in the open world setting. Similar to recent works [18, 16] which transfer knowledge from la-belled images of a few classes to other unlabelled image collections, we formulate the problem as partitioning unla-belled data from unknown categories into proper semantic groups, while some labelled data from other categories are available. This is a more realistic setting than pure unsu-pervised clustering which may produce equally valid data partitions following different unconstrained criteria (e.g., im-ages can be clustered by texture, color, illumination, etc) and closed-world recognition which can not handle unlabelled data from new categories without any labels. Meanwhile, our setting is more similar to the human cognition process where humans can easily learn the concept of a new object by transferring knowledge from known objects.
Speciﬁcally, we introduce a ﬂexible end-to-end frame-work to discover categories in unlabelled data, with the goal of utilizing both labelled and unlabelled data to build unbi-ased feature representation, while transferring more knowl-In particular, we edge from labelled to unlabelled data. extend the conventional contrastive learning [6, 19] to con-sider both instance discrimination and category discrimina-tion to learn a reliable feature representation on labelled and unlabelled data. We also demonstrate that the cross-modal discrimination would further beneﬁt representation learning on data with multi-modalities. To leverage more of unlabelled data, we employ the Winner-Take-All (WTA) hashing [48] on the shared representation space to generate pair-wise pseudo labels on-the-ﬂy, which is the key for ro-bust knowledge transfer from the labelled data to unlabelled data. With the weak pseudo labels, the model can be trained with a simple binary cross-entropy loss on the unlabelled data together with the standard cross-entropy loss on the labelled data. This way our model can simultaneously learn feature representation and perform the cluster assignment
using an uniﬁed loss function.
The main contributions of the paper can be summarized as follows: (1) we propose a generic, end-to-end framework for novel category discovery that can be trained jointly on la-belled and unlabelled data; (2) to the best of our knowledge, we are the ﬁrst to extend contrastive learning in novel cate-gory discovery task by category discrimination on labelled data and cross-modal discrimination on multi-modal data; (3) we propose a strategy to employ WTA hashing on the shared representation space of both labelled and unlabelled data to generate additional (pseudo) supervision on unlabeled data; and (4) we thoroughly evaluate our end-to-end framework on challenging large scale multi-modal video benchmarks and single-modal image benchmarks, outperforming existing methods by a signiﬁcant margin. 2.