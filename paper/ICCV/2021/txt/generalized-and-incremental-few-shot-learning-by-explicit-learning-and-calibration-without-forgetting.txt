Abstract
Both generalized and incremental few-shot learning have to deal with three major challenges: learning novel classes from only few samples per class, preventing catastrophic forgetting of base classes, and classifier calibration across novel and base classes. In this work we propose a three-stage framework that allows to explicitly and effectively address these challenges. While the first phase learns base classes with many samples, the second phase learns a calibrated classifier for novel classes from few samples while also pre-venting catastrophic forgetting. In the final phase, calibra-tion is achieved across all classes. We evaluate the proposed framework on four challenging benchmark datasets for im-age and video few-shot classification and obtain state-of-the-art results for both generalized and incremental few shot learning. 1.

Introduction
In this paper we are interested in two practically important learning scenarios, namely generalized few-shot learning (GFSL) [13, 36, 32, 39] and incremental few-shot learning (IFSL) [43, 6]. In both scenarios it is possible to learn a performant classifier for a set of base classes for which many training samples exist. However, for the novel classes, only few training samples are available such that a novel class learning is challenging. Additionally, in generalized few-shot learning and in incremental learning it is important to prevent catastrophic forgetting of the base classes during novel class learning. Last, but not least, classifier calibration across classes has to be addressed, due to the imbalance in the amount of training samples. While previous work focuses on addressing a subset of these challenges [13, 36, 23, 43, 6], in this paper we aim to address all three.
To this end, we propose a three phase framework to explicitly address these challenges. The first phase is devoted to general representation learning as in previous work [13, 36, 47]. Here, we utilize a large base dataset https://github.com/annusha/LCwoF
Figure 1: Overview of the performance of our framework during different phases. J indicates performance in the joint space, B and
N denote performance in the base and novel spaces respectively.
During the 1st phase we train the model on the base classes. During the 2nd phase we try to achieve a high performance on novel classes in the joint space and prevent forgetting of base classes. In the 3rd phase we calibrate the two classifiers and achieve balanced performance between base and novel classes. T-SNE plots show the performance of the test samples at each phase. The symbol size shows the confidence of the model for the sample. for pretraining and obtain high performance for base clas-sification. In the second phase we concentrate on learning novel classes. In contrast to the prior work, we pay spe-cial attention to training a calibrated classifier for the novel classes while simultaneously preventing catastrophic for-getting for the base classes. More specifically we propose base-normalized cross entropy that amplifies the softmax output of novel classes to overcome the bias towards the base classes, and simultaneously enforce the model to pre-serve previous knowledge via explicit weight constraints. In the third phase we address the problem of calibrating the overall model across base and novel classes. In Fig. 1 we show how the model develops during all three phases by plotting the test accuracy of base and novel classes in the
separate and joint spaces. The contributions of this work are as follows: (1) A framework to explicitly address the problems of gen-eralized few-shot-learning by balancing between learning novel classes, forgetting base classes and calibration across them in three phases; (2) Base-normalized cross-entropy to overcome the bias learned by the model on the base classes in combination with weight constraints to mitigate the forgetting problem in the second phase; (3) An extensive study to evaluate the proposed framework on images and videos showing state-of-the-art results for generalized and incremental few shot learning. 2.