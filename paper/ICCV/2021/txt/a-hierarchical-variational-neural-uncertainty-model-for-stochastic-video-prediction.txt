Abstract
Predicting the future frames of a video is a challenging task, in part due to the underlying stochastic real-world phenomena. Prior approaches to solve this task typically estimate a latent prior characterizing this stochasticity, how-ever do not account for the predictive uncertainty of the (deep learning) model. Such approaches often derive the training signal from the mean-squared error (MSE) between the generated frame and the ground truth, which can lead to sub-optimal training, especially when the predictive un-certainty is high. Towards this end, we introduce Neural
Uncertainty Quantiﬁer (NUQ) - a stochastic quantiﬁcation of the model’s predictive uncertainty, and use it to weigh the MSE loss. We propose a hierarchical, variational frame-work to derive NUQ in a principled manner using a deep,
Bayesian graphical model. Our experiments on three bench-mark stochastic video prediction datasets show that our proposed framework trains more effectively compared to the state-of-the-art models (especially when the training sets are small), while demonstrating better video generation quality and diversity against several evaluation metrics. 1.

Introduction
Extrapolating the present into the future is a task essential to predictive reasoning and planning. When artiﬁcial intel-ligence systems are deployed to work side-by-side with hu-mans, it is critical that they reason about their visual context and generate plausible futures so that they can anticipate the potential needs of humans or catastrophic risks and be better equipped. Such a visual future generation framework could also beneﬁt applications such as video surveillance [57], hu-man action recognition and forecasting [49, 55] as well as simulation of real-world scenarios to train robot learning algorithms, including autonomous driving [28]. However, such applications have a high element of stochasticity, which makes this prediction task challenging.
Figure 1. Qualitative results vis-á-vis state-of-the-art video predic-tion baselines using the proposed NUQ framework on the BAIR
Push dataset [15], trained using only 2,000 samples (rather than the full 40K samples). Regions with high motion are shown by a red box. Also shown is an estimate of the per-frame scaled uncer-tainty estimated by our model. Note that the robotic arm changes direction at t = 8, which is reﬂected in the predicted uncertainty.
The resurgence of deep neural networks, especially the ad-vent of generative adversarial networks [20], has enabled sig-niﬁcant progress in the development of frameworks for gen-erating visual data, such as images [30]. While, temporally-evolving extensions of such image generation techniques have shown beneﬁts in artiﬁcially producing video sequences for deterministic visual contexts [54, 56, 19, 37, 29], they usually fail to model real-world sequences that are often highly stochastic. Several recent works in video generation, thus design modules to factor in data stochasticity while making predictions [39, 2, 13, 8]. Speciﬁcally, such meth-ods assume a latent stochastic prior, from which random samples are drawn, in order to generate future frames. In
Babaeizadeh et al. [2], this stochastic prior is assumed to follow a ﬁxed normal distribution, which is sampled at every time step, while Denton and Fergus [13], learn this prior from data. The latter’s key insight is to use a variational posterior to guide the learning of the prior to produce the sufﬁcient statistics of the normal distribution governing the prior. Such stochastic methods typically employ a determin-istic decoder (a neural network) that combines an embedding
of the visual context and a random sample from the stochas-tic prior to generate a future video frame. The variance in this prior accounts for the stochasticity underlying the data.
To train such models, the mean-squared error (MSE) is then minimized by comparing the predictions against the true video frames.
Nonetheless existing stochastic methods have largely ig-nored the predictive uncertainty (aleatoric uncertainty) [31] of the models, which might adversarially impact downstream tasks that leverage these predictions. From a machine learn-ing stand point, ignoring the predictive uncertainty might lead to the model being unnecessarily penalized (via the
MSE), even if it makes a very uncertain prediction that ends up being different from the ground-truth. This can destabi-lize the training of the underlying neural networks, leading to slower convergence or requiring larger training data. This is of importance because such data might be expensive or sometimes even difﬁcult to collect (e.g., predicting the next human actions in instruction videos, or a rare trafﬁc incident), and thus effective training with limited data is essential.
In this work, we rise up to these challenges by quantifying the predictive uncertainty of a stochastic frame prediction model and using it to calibrate its training objective. In par-ticular a stochastic estimate of the predictive uncertainty, derived from the latent space of the model, is used to weigh the MSE. That is, when the uncertainty is high, the MSE is down-weighted proportionately, and vice versa; thereby regularizing the backpropagation gradients to train the frame generation module. Moreover, this uncertainty estimate can be used for downstream tasks, such as for example, regulat-ing the manuevers in autonomous driving [28, 55]. We call our scheme, Neural Uncertainty Quantiﬁer (NUQ).
We observe that the weight on the MSE that NUQ in-troduces, basically amounts to the variance of the normal distribution governing the generated output. Thus, an obvi-ous consideration would be to estimate the variance directly from the output. However, this may be cumbersome due to the very high dimensionality of the output space (order of the number of pixels). We instead, choose to derive it from the variance of the latent space prior, which has far fewer dimensions. Speciﬁcally, NUQ leverages a variational, deep, hierarchical, graphical model to bridge the variance of the latent space prior and that of the output. Our framework is trained end-to-end. Sample generations by our framework is shown in Figure 1. In addition, inspired by the recent successes of generative adversarial networks [20, 37, 39], we propose a variant of our framework that uses a novel sequence discriminator, in an adversarial setting. This dis-criminator module helps to constrain the space of possible output frames, while enforcing motion regularities in the generated videos.
To empirically verify our intuitions, we present experi-ments on a synthetic (Stochastic Moving MNIST [13]) and two challenging real world datasets: KTH-Action [47], and
BAIR push [15] for the task of future frame generation. Our results show that our framework converges faster than prior stochastic video generation methods, and leads to state-of-the-art video generation quality, even when the dataset size is small, while exhibiting generative diversity in the predicted frames. Below, we summarize the main contributions of this paper: 1. We present Neural Uncertainty Quantiﬁer (NUQ), a deep, Bayesian network that learns to estimate the pre-dictive uncertainty of stochastic frame generation mod-els, which can be leveraged to control the training up-dates, for faster and improved convergence of predictive models. 2. We propose a novel, hierarchical, variational training scheme that allows for incorporating problem-speciﬁc knowledge into the predictions via hyperpriors on the uncertainty estimate. 3. Experimental results demonstrate our framework’s bet-ter video generation and faster training capabilities, even with small training sets compared to recent state-of-the-art methods on stochastic video generation tasks, across multiple datasets. 2.