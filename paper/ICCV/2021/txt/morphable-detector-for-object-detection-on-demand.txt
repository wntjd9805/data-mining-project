Abstract
Many emerging applications of intelligent robots need to explore and understand new environments, where it is desirable to detect objects of novel classes on the fly with minimum online efforts. This is an object detection on de-mand (ODOD) task. It is challenging, because it is impos-sible to annotate a large number of data on the fly, and the embedded systems are usually unable to perform back-propagation which is essential for training. Most exist-ing few-shot detection methods are confronted here as they need extra training. We propose a novel morphable detector (MD), that simply “morphs” some of its changeable param-eters online estimated from the few samples, so as to detect novel classes without any extra training. The MD has two sets of parameters, one for the feature embedding and the other for class representation (called “prototypes”). Each class is associated with a hidden prototype to be learned by integrating the visual and semantic embeddings. The learn-ing of the MD is based on the alternate learning of the fea-ture embedding and the prototypes in an EM-like approach which allows the recovery of an unknown prototype from a few samples of a novel class. Once an MD is learned, it is able to use a few samples of a novel class to directly compute its prototype to fulfill the online morphing process.
We have shown the superiority of the MD in Pascal [12],
COCO [27] and FSOD [13] datasets. 1.

Introduction
In applications, like robotics exploration and au-tonomous driving, the systems need to explore and under-stand new environments, where it is desirable to detect ob-jects of novel classes on the fly with minimum online hu-man supervision and interaction. This is an object detection on demand (ODOD) task. ODOD is very challenging be-cause it is impossible to collect a large amount of data on the fly, and the computing resources are generally not powerful enough for computationally intensive and time-consuming
Figure 1: Comparison with other detection tasks. Different from other few-shot detection tasks, Object Detection on
Demand requires no extra training. training on board, not to mention that many embedded sys-tems are unable to perform back-propagation which is es-sential for training. In embedded systems, the detection task is usually carried out on a computationally limited platform where the neural networks are locked after the system is built due to resource limits [19]. The prevailing few-shot detection (FSD) [20, 49, 47, 46, 48] methods are confronted here as they generally need to perform extra training for ob-jects from novel classes.
To this end, we define Object Detection on Demand (ODOD) specifically as detecting the novel classes with-out extra training while preserving the existing knowledge, given (1) a detector offline trained using base class data, (2) no access to base class data (3) a few samples for novel classes. The ODOD can be regarded as a special few-shot detection task and the differences of ODOD from other de-tection tasks are listed in Fig 1 .
The prevailing few-shot detectors (FSD) aim to train a detector using base class data and further train it with a few samples from novel classes. However, extra training is unfeasible in the ODOD task. Furthermore, to keep the performance for the base classes, these FSDs have to use
the base class data in extra training, otherwise, they suffer from catastrophic forgetting [29] - a significant performance degradation, when the past data are not available. Other few-shot detectors [13, 18] use a siamese network and take
“query-target” pairs as input so as to detect all instances of the “target” object appearing in the “query” image. How-ever, as the target representation is always changing during the training, the model learns less discriminative represen-tations. As a result, the model’s generalizability to unseen samples of the base classes is limited.
In this paper, we present a novel morphable detector (MD) that simply “morphs” some of its changeable pa-rameters online estimated from the few samples, so as to detect novel classes without any extra training. Different from most existing object detectors, this novel MD has two sets of parameters, one for the feature embedding (i.e. the network parameters), and the other for class representation (called “prototypes”) as illustrated in Fig 2. We view the
MD for recognizing visual samples of different classes as if they live in a common space called feature space. Each class is associated with a prototype which is the targeted coordi-nate of each class in the feature space. Therefore, for each object proposal, the MD learns a feature vector whose sim-ilarity with prototypes is regarded as the foreground classi-fication score. As it is hard to assign one prototype to the background, the MD directly regresses a background score from the visual features as shown in Fig 2. Once an MD is learned, it is able to use a few samples of a novel class to directly compute its prototype to fulfill the online morphing process (details are in 3.3).
The learning of the MD is based on the alternate learning of the feature embedding and the prototypes in an EM-like approach as shown in Fig 3. The prototype is regarded as a hidden variable to be learned by integrating the visual and semantic embeddings. In ”E”-step, we fix the network pa-rameters and update the prototypes by combining the cur-rent prototypes and the feature vectors of the training sam-ples on the trained model (details are in Sec. 3.2.2). In ”M”-step, the prototypes are fixed and the network is trained us-ing the updated prototypes. The prototypes are initialized with semantic vectors which bring useful external informa-tion from textual data. But note that directly using seman-tic vectors as prototypes without the proposed EM-like al-gorithm still suffers from limited generalizability (to novel classes) because the external information does not directly examine visual appearances while the model concerns itself with recognizing visual features. Therefore, the joint learn-ing of the feature embedding and prototypes allows better recovery of an unknown prototype from a few samples of a novel class. Our approach is different from the existing approach, such as RepNet [21] which learns representatives for each class from the visual data in an end-to-end training.
The proposed MD learns the representatives (prototypes) by an EM-like approach where the visual and semantic infor-mation are integrated to improve the model’s generalizabil-ity (to novel classes).
Overall, the contributions of this work are four-fold:
• We study a special few-shot detection task, Object De-tection on Demand, which is rarely discussed in the literature and can not be solved by many existing Few-shot detection methods.
• We present a novel morphable detector (MD) which can be online morphed to detect the novel classes with-out extra training.
• We propose to learn the MD by joint visual and seman-tic embedding in an EM-like approach.
• Extensive experiments are performed on different datasets to demonstrate the superiority of the MD over other methods. 2.