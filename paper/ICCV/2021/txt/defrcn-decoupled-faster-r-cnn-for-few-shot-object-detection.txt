Abstract
Few-shot object detection, which aims at detecting novel objects rapidly from extremely few annotated examples of previously unseen classes, has attracted significant research interest in the community. Most existing approaches employ the Faster R-CNN as basic detection framework, yet, due to the lack of tailored considerations for data-scarce scenario, their performance is often not satisfactory. In this paper, we look closely into the conventional Faster R-CNN and an-alyze its contradictions from two orthogonal perspectives, namely multi-stage (RPN vs. RCNN) and multi-task (clas-sification vs. localization). To resolve these issues, we pro-pose a simple yet effective architecture, named Decoupled
Faster R-CNN (DeFRCN). To be concrete, we extend Faster
R-CNN by introducing Gradient Decoupled Layer for multi-stage decoupling and Prototypical Calibration Block for multi-task decoupling. The former is a novel deep layer with redefining the feature-forward operation and gradient-backward operation for decoupling its subsequent layer and preceding layer, and the latter is an offline prototype-based classification model with taking the proposals from detec-tor as input and boosting the original classification scores with additional pairwise scores for calibration. Extensive experiments on multiple benchmarks show our framework is remarkably superior to other existing approaches and es-tablishes a new state-of-the-art in few-shot literature 1. 1.

Introduction
Recently, deep neural networks have achieved state-of-the-art on a variety of visual tasks, e.g. image classification
[9, 17, 18] and object detection [4, 8, 14, 15, 23, 33, 34, 36].
However, these leaps of performance arrive only when a large amount of annotated data is available. Since it is often labor-intensive to obtain adequate labelled data, the number of available samples severely limits the applications of cur-rent vision systems. Besides, compared to the ability of hu-man to quickly extract novel concepts from extremely few examples, these deep models are still far from satisfactory.
*Xi Qiu (qiuxi@megvii.com) is the corresponding author. 1https://github.com/er-muyue/DeFRCN
Figure 1: FSOD performance (mAP) on COCO [24] novel set at different shot numbers. The proposed DeFRCN is remarkably superior to other state-of-the-art approaches.
It is thus of attracting major research interest on few-shot learning [6, 21, 22, 29, 38, 40, 44], which employs the idea of learning novel concepts rapidly and generalizing well in data-scarce scenario. As one of the research branches, few-shot object detection (FSOD) is a much more challenging task than both few-shot classification and object detection
[5, 19, 46, 51, 53]. At present, most FSOD approaches pre-fer to follow the meta-learning paradigm to acquire more task-level knowledge and generalize better to novel classes.
However, these methods usually suffer from a complicated training process and data organization, which results in lim-ited application scenarios. In contrast, the finetune-based methods that exist as another research branch of FSOD, are very simple and efficient [46]. By adopting a two-stage fine-tuning scheme, this series is comparable to meta methods.
Yet, due to most parameters are pre-trained on base domain and then frozen on novel set, they may fall down the severe shift in data distribution and underutilization of novel data.
Regardless of the meta-based or finetune-based method,
Faster R-CNN [36] has been widely used as the basic de-tector and achieved good performance. However, its origi-nal architecture is designed for conventional detection and lacks of tailored consideration for few-shot scenario, which limits the upper bound of existing approaches. Concretely,
standard Faster R-CNN [36], DeFRCN additionally con-tains two Gradient Decoupled Layer (GDL) and an offline
Prototypical Calibration Block (PCB). The former ones are inserted between the shared backbone and RPN, mean-while, between the backbone and RCNN to adjust the de-gree of decoupling among three modules, and the latter is parallel to the box classifier for further score calibra-tion. Specifically, during the forward-backward propaga-tion, GDL performs a learnable affine transformation on the forward feature maps and simply multiplies the back-ward gradient by a constant, which decouples the subse-quent module and preceding module efficiently. Moreover,
PCB is initially equipped with a well pre-trained classifi-cation model (e.g. ImageNet Pretrain) and a set of novel support prototypes. Then it takes the region proposals from few-shot detector as input and boosts the original softmax scores with additional prototype-based pairwise scores. As an interesting by-product, we find that just adopting PCB only in the inference phase can greatly improve the perfor-mance of few-shot detectors, with no extra training effort, which makes the PCB data-efficient and plug-and-play.
The main contributions of our approach are three-folds:
• We look closely into the conventional Faster R-CNN and propose a simple yet effective architecture for few-shot detection, named Decoupled Faster R-CNN, which can be learned end-to-end via straightforward fine-tuning.
• To deal with the data-scarce scenario, we further present two novel modules, i.e. GDL and PCB, to perform de-coupling among multiple components of Faster R-CNN and boost classification performance respectively.
• DeFRCN is remarkably superior to SOTAs on various benchmarks, revealing the effectiveness of our approach. 2.