Abstract
Person Re-Identification (ReID) has achieved remark-able performance along with the deep learning era. How-ever, most approaches carry out ReID only based upon holistic pedestrian regions.
In contrast, real-world sce-narios involve occluded pedestrians, which provide par-tial visual appearances and destroy the ReID accuracy. A common strategy is to locate visible body parts by auxil-iary model, which however suffers from significant domain gaps and data bias issues. To avoid such problematic mod-els in occluded person ReID, we propose the Occlusion-Aware Mask Network (OAMN). In particular, we incor-porate an attention-guided mask module, which requires guidance from labeled occlusion data. To this end, we propose a novel occlusion augmentation scheme that pro-duces diverse and precisely labeled occlusion for any holis-tic dataset. The proposed scheme suits real-world scenarios better than existing schemes, which consider only limited types of occlusions. We also offer a novel occlusion uni-fication scheme to tackle ambiguity information at the test phase. The above three components enable existing atten-tion mechanisms to precisely capture body parts regardless of the occlusion. Comprehensive experiments on a variety of person ReID benchmarks demonstrate the superiority of
OAMN over state-of-the-arts. 1.

Introduction
Person Re-Identification (ReID) aims to identify the same pedestrian captured by different cameras under vary-ing viewpoints, lights, and locations. Along with the deep learning era, ReID approaches based on Convolution Neu-*Corresponding author. (a) Occluded pedestrians (b) RGA-S (c) Ours
Figure 1: Examples of occluded pedestrians and illustra-tions of introducing attentions. (a) shows examples of oc-cluded pedestrians. (b) and (c) illustrate the attention intro-duced by RGA-S [33] and our proposed OAMN. (b) may erroneously focus on the occlusion, but (c) does not. ral Networks (CNNs) have achieved remarkable perfor-mance [2, 32, 14, 12]. However, these approaches carry out ReID only based upon the holistic pedestrian regions, which ignore the occlusion that happens frequently in real-world scenarios as shown in Figure 1a.
Identifying occluded pedestrians faces essential chal-lenges. In particular, the occluded pedestrian contains fewer distinguishable features from the pedestrian itself, while in-troducing ambiguity information from the occluded regions.
Such ambiguity, like rich texture and noise, misleads the ap-pearance representation. Existing approaches typically em-ploy auxiliary models to obtain information for occluded body parts to assist the learning procedure, such as captur-ing body-part features with Human parsing [10], separating
We propose an occlusion unification scheme to tackle this problem. First, we label the target pedestrian’s occlusion type by learning an auxiliary occlusion grader. Second, we mitigate the diversity by occluding all gallery images with the same type of occlusion as the target pedestrian, namely the “occlude them all” strategy (with few exceptions as de-tailed in Section 3.4). Hence, the original ambiguity infor-mation is unified, allowing the attention module to precisely capture body parts regardless of the occlusion.
In summary, we propose an Occlusion-Aware Mask Net-work (OAMN) to address the occlusion problem in per-son ReID. OAMN employs three innovative components: the attention-guided mask module, occlusion augmentation, and occlusion unification. These components enable exist-ing attention mechanisms to precisely capture body parts regardless of the occlusion, as shown in Figure 1c. OAMN tackles several challenges to finally bring attention mecha-nisms to occluded person ReID.
We summarize our contributions as follows. 1. We propose the Occlusion-Aware Mask Network, an efficient and effective approach to address the occlu-sion problem in person ReID. We enable attention mechanisms to precisely capture body parts regardless of the occlusion. 2. We propose a new occlusion augmentation scheme to produce diverse occluded images and precise labels for any holistic datasets. We propose a novel occlusion unification scheme to unify ambiguity at the test phase. 3. We evaluate the proposed OAMN in three person
ReID datasets containing occlusions. Quantitative re-sults show that OAMN achieves state-of-the-art perfor-mance, with the rank-1 accuracy of 62.6%, 86.0%, and 77.3% on Occluded-DukeMTMC, Partial-ReID, and
Partial-iLIDS, respectively. 2.