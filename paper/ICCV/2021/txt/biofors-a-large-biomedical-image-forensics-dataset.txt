Abstract
Research in media forensics has gained traction to com-bat the spread of misinformation. However, most of this research has been directed towards content generated on social media. Biomedical image forensics is a related prob-lem, where manipulation or misuse of images reported in biomedical research documents is of serious concern. The problem has failed to gain momentum beyond an academic discussion due to an absence of benchmark datasets and
In this paper we present BioFors1 – standardized tasks. the ﬁrst dataset for benchmarking common biomedical im-age manipulations. BioFors comprises 47,805 images ex-Images tracted from 1,031 open-source research papers. in BioFors are divided into four categories – Microscopy,
Blot/Gel, FACS and Macroscopy. We also propose three tasks for forensic analysis – external duplication detection, internal duplication detection and cut/sharp-transition de-tection. We benchmark BioFors on all tasks with suitable state-of-the-art algorithms. Our results and analysis show that existing algorithms developed on common computer vi-sion datasets are not robust when applied to biomedical im-ages, validating that more research is required to address the unique challenges of biomedical image forensics. 1.

Introduction
Multimedia forensic research has branched off into sev-eral sub-domains to tackle various forms of misinforma-tion and manipulation. Popular forensic research prob-lems include detection of digital forgeries such as deepfakes
[31, 41], copy-move and splicing manipulations [52, 53, 51] or semantic forgeries [40, 23]. These forensic-research ar-eas essentially deal with social media content. A related but distinct research domain is biomedical image forensics; i.e. detection of research misconduct in biomedical publications
[4, 13, 5]. Research misconduct can appear in several forms such as plagiarism, fabrication and falsiﬁcation. Scientiﬁc misconduct has consequences beyond ethics and leads to re-Figure 1. Real world examples of suspicious duplications in biomedical images. Top and bottom rows show duplications be-tween images in the same and different documents respectively. tractions [5] and by one estimate $392, 582 of ﬁnancial loss for each retracted article [46]. The general scope of scien-tiﬁc misconduct and unethical behavior is broad. In this pa-per we focus on detection of manipulation or inappropriate duplication of scientiﬁc images in biomedical literature.
Duplication and tampering of protein, cell, tissue and other experimental images has become a nuisance in the biomedical sciences community. As the description sug-gests, duplication involves reusing part of images generated by one experiment to misrepresent results for unrelated ex-periments. Tampering of images involves pixel- or patch-level forgery to hide unfavorable aspects of the image or to produce favorable results. Biomedical image forgeries can be more difﬁcult for a human to detect than manipu-lated images on social media due to the presence of arbitrary and confusing patterns and lack of real-world semantic con-text. Detecting forgeries is further complicated by manipu-lations involving images across different documents. Figure 1 shows reported examples2 of inappropriate duplications in 2https://scienceintegritydigest.com/2020/11/11/46-papers-from-a-1https://github.com/ISICV/BioFors royan-institute-professor/ 1
different publications. The difﬁculty of noticing such ma-nipulations coupled with a high paper-per-reviewer ratio of-ten leads to these manipulations going unnoticed during the review process. It may come under scrutiny later leading to possible retractions [5]. While the problem has received the attention of the biomedical community, to the best of our knowledge there is no publicly available biomedical image forensics dataset, detection software or standardized task for benchmarking. We address these issues by releasing the ﬁrst biomedical image forensics dataset (BioFors) and proposing benchmarking tasks.
The objective of our work is to advance biomedical forensic research to identify suspicious images with high conﬁdence. We hope that BioFors will promote the devel-opment of algorithms and software which can help review-ers identify manipulated images in research documents.
The ﬁnal decision regarding malicious, mistaken or justi-ﬁed intent behind a suspicious image is to be left to the forensic analyst. This is important due to cases of dupli-cation/tampering that are justiﬁed with citation, explana-tion, harmlessness or naive mistake as detailed in [4]. Bio-Fors comprises 47,805 manually cropped images belonging to four major categories — (1) Microscopy, (2) Blot/Gel, (3) Macroscopy and (4) Flow-cytometry or Fluoroscence-activated cell sorting (FACS). It covers popular biomedi-cal image manipulations with three forgery detection tasks.
The dataset and its collection along with the forgery detec-tion tasks are detailed in Section 3.
The contributions of our work are:
• A large scale biomedical image forensics dataset with real-world forgeries
• A computation friendly taxonomy of forgery detection tasks that can be matched with standard computer vi-sion tasks for benchmarking and evaluation
• Extensive analysis explaining the challenges of biomedical forensics and the loss in performance of standard computer vision models when applied to biomedical images 2.