Abstract
In this paper we propose BlockCopy, a scheme that ac-celerates pretrained frame-based CNNs to process video more efﬁciently, compared to standard frame-by-frame pro-cessing. To this end, a lightweight policy network deter-mines important regions in an image, and operations are applied on selected regions only, using custom block-sparse convolutions. Features of non-selected regions are simply copied from the preceding frame, reducing the number of computations and latency. The execution policy is trained using reinforcement learning in an online fashion without requiring ground truth annotations. Our universal frame-work is demonstrated on dense prediction tasks such as pedestrian detection, instance segmentation and semantic segmentation, using both state of the art (Center and Scale
Predictor, MGAN, SwiftNet) and standard baseline net-works (Mask-RCNN, DeepLabV3+). BlockCopy achieves signiﬁcant FLOPS savings and inference speedup with min-imal impact on accuracy. 1.

Introduction
Most contemporary convolutional neural networks (CNN) are trained on images and process video frame-by-frame, for simplicity or due to the lack of large annotated video datasets. For instance, the popular COCO dataset [21] for large-scale object detection does not include video se-quences. However, video typically contains a considerable amount of redundancy in the temporal domain, with some image regions being almost static. Image-based convolu-tional neural networks do not take advantage of temporal and spatial redundancies to improve efﬁciency: they ap-ply the same operations on every pixel and every frame.
Representation warping has been proposed to save compu-tations [8, 51, 17], but optical ﬂow is expensive and warping cannot cope with large changes such as newly appearing ob-jects. Other video processing methods, e.g. using 3D con-Figure 1: BlockCopy accelerates existing CNNs by sparsely executing convolutions, while copying features from previ-ous executions in non-important regions. In this example on pedestrian detection, inference speed is more than doubled with negligible increase in detection miss rate. volutions or recurrent neural networks [18, 28, 22], focus on improving accuracy by using temporal information, instead of reducing computations by exploiting redundancies.
In this work, we propose a method to improve the ef-ﬁciency and inference speed of convolutional neural net-works for dense prediction tasks, by combining tempo-ral feature propagation with sparse convolutions as illus-trated in Figure 1. A lightweight, trainable policy net-work selects important image regions, and the expensive task network sparsely executes convolutions on selected re-gions only. Features from non-important regions are simply copied from the previous execution, thereby saving compu-tations.
The policy network is trained with reinforcement learn-ing in an online fashion: the output of the large task net-work, for example Mask-RCNN [12], serves as supervisory signal to train the online policy. Using online reinforcement learning has several advantages. First, no labeled data is re-quired and off-the-shelf networks can be optimized during deployment without designing a separate training pipeline.
Second, online training allows the network to ﬁne-tune the policy to the task and dataset at deployment time. Finally, models of different computational costs can be obtained by simply adjusting the policy’s computational target parame-ter.
The main contributions of this work are as follows:
• We propose BlockCopy to adapt existing CNNs for more efﬁcient video processing, using block-sparse convolutions and temporal feature propagation. Our framework is implemented in PyTorch, using custom
CUDA operations.
• We utilize reinforcement learning to train a policy net-work in an online fashion without requiring ground-truth labels.
• We demonstrate our method on pedestrian detec-tion, instance segmentation and semantic segmentation tasks and show that existing off-the-shelf CNNs can be signiﬁcantly accelerated without major compromises in accuracy.
• We show that BlockCopy improves the accuracy-speed trade-off by comparison with existing methods, lower resolution and lower frame rate baselines.
The code is available online1. 2.