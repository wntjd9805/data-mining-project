Abstract
Since 2014 transfer learning has become the key driver for the improvement of spatial saliency prediction—however, with stagnant progress in the last 3-5 years. We conduct a large-scale transfer learning study which tests different Ima-geNet backbones, always using the same read out architec-ture and learning protocol adopted from DeepGaze II. By re-placing the VGG19 backbone of DeepGaze II with ResNet50 features we improve the performance on saliency prediction from 78% to 85%. However, as we continue to test better Im-ageNet models as backbones—such as EfficientNetB5—we observe no additional improvement on saliency prediction.
By analyzing the backbones further, we find that generaliza-tion to other datasets differs substantially, with models being consistently overconfident in their fixation predictions. We show that by combining multiple backbones in a principled manner a good confidence calibration on unseen datasets can be achieved. This new model “DeepGaze IIE” yields a significant leap in benchmark performance in and out-of-domain with a 15 percent point improvement over DeepGaze
II to 93% on MIT1003, marking a new state of the art on the
MIT/Tuebingen Saliency Benchmark in all available metrics (AUC: 88.3%, sAUC: 79.4%, CC: 82.4%). 1.

Introduction
Saliency detection is involved in many sensory modalities.
It summarizes the associated mechanisms as the ability of humans and animals to allocate their attention to the most important subsets of the data. In vision, this means attending to the elements of a visual input that stand out from their neighbouring regions, and visual saliency is usually opera-* indicates joint first authorship tionalized by measuring fixations locations. Accordingly, in computer vision, saliency prediction currently refers to either predicting fixation locations or detecting salient objects.
Early on, researchers found out that the locations of fix-ations are statistically influenced by features of the visual stimuli that include both high-level properties such as people
[41] and low-level ones such as spatial contrast [33]. Soon after the Feature Integration Theory emerged [38], Koch and Ullmann outlined a computational mechanism to model attention [21] which was implemented thirteen years later by Itti et al [15].
The Itti-Koch model was the first to predict a saliency map from any arbitrary image without the need to precompute elementary features allowing for a wide range of applications.
This paved the way for many interesting saliency prediction models [2, 20, 42] leading up to the present day where deep learning models are dominating the field [39, 25, 28, 32, 16, 23] driven by large scale saliency datasets [19, 17, 1]. As the saliency domain has substantially less data compared to some of the more prominent computer vision tasks, transfer learning has become the key driver for the improvement of
Figure 1. By leveraging the diversity of different backbones, our new saliency model DeepGaze IIE very is able to predict human fixation locations very accurately.
spatial saliency prediction. One of the earliest works on transfer learning for deep learning is DeCAF [6], where the authors used features extracted by a deep CNN that was trained on object recognition, leveraging a large dataset to tackle generic tasks that lacked labeled data. Following this transfer learning scheme, they outperformed the state-of-the-art on various vision challenges. Inspired by the huge success of deep convolutional models in the domain of classification and particularly the ImageNet benchmark [5], DeepGaze I
[25] was the first to transfer ImageNet learned features to the domain of saliency. Since then all high-performing saliency models use ImageNet as pretext task.
To this day, the problem of spatial saliency is far from solved and the simple case of the MIT300 benchmark [18] illustrates a substantial gap between existing models and the lower bound on the explainable information (e.g., IG of 0.951 vs 1.317 and sAUC of 0.784 vs 0.823). In 2014, the introduction of deep learning and transfer learning in particular, ushered a new era for saliency prediction after several years of stagnating performance. Similarly, there has been only gradual progress in the recent 3-5 years, notwith-standing the significant amount of models proposed during that time (Figure 2). From a machine learning point of view, the task of saliency prediction is conceptually interesting as it requires well-calibrated probabilistic predictions that are less critical in the much more common setting of highly deterministic classification problems.
In this work, we significantly improve spatial saliency modeling by studying how to achieve well-calibrated proba-bilistic predictions. Beyond proposing a new state-of-the-art model, we make a systematic analysis of the extent to which higher ImageNet performance leads to higher performance in the saliency domain. Specifically, we utilize a broad range of models that have achieved state of the art on ImageNet as fixed feature backbones for the saliency prediction task, us-ing a pointwise nonlinear read out following the DeepGaze
II architecture and learning schedule as described in [28].
Additionally, we study the complementarity between these models and leverage it by conducting an ensemble learning approach which ends up yielding a new state of the art, clos-ing the gap between models and inter-observer consistency in all metrics.
To gain additional insights into the differences between the backbones, we study the confidence calibration of the models based on them. Confidence calibration is especially relevant when applying models in out-of-domain contexts where we would expect a good model to realize the domain shift and decrease its confidence accordingly [31]. Many established confidence calibration measures [9] are not appli-cable in situations of very high stochasticity such as fixation prediction, therefore we propose a new method for testing confidence calibration which can be applied on datasets with high entropy. Instead of being well calibrated or conserva-tively underconfident, we find that most individual models are highly overconfident on out-of-domain data, while our ensemble models show much better confidence calibration, which makes them more trustworthy on unseen datasets. 2.