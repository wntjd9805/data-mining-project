Abstract
Unsupervised Domain Adaptation (UDA) for semantic segmentation has been actively studied to mitigate the do-main gap between label-rich source data and unlabeled tar-get data. Despite these efforts, UDA still has a long way to go to reach the fully supervised performance. To this end, we propose a Labeling Only if Required strategy, La-bOR, where we introduce a human-in-the-loop approach to adaptively give scarce labels to points that a UDA model is uncertain about. In order to find the uncertain points, we generate an inconsistency mask using the proposed adap-tive pixel selector and we label these segment-based regions to achieve near supervised performance with only a small fraction (about 2.2%) ground truth points, which we call
“Segment based Pixel-Labeling (SPL).” To further reduce the efforts of the human annotator, we also propose “Point based Pixel-Labeling (PPL),” which finds the most repre-sentative points for labeling within the generated inconsis-tency mask. This reduces efforts from 2.2% segment label
→ 40 points label while minimizing performance degrada-tion. Through extensive experimentation, we show the ad-vantages of this new framework for domain adaptive seman-tic segmentation while minimizing human labor costs. 1.

Introduction
Semantic segmentation enables understanding of image scenes at the pixel level, and is critical for various real-world applications such as autonomous driving [41] or sim-ulated learning for robots [13]. Unfortunately, the pixel level understanding task in deep learning requires tremen-dous labeling efforts in both time and cost. Therefore, un-supervised domain adaptation (UDA) [15] addresses this problem by utilizing and transferring the knowledge of label-rich data (source data) to unlabeled data (target data), which can reduce the labeling cost dramatically [40]. Ac-cording to the adaptation methodology, UDA can be largely divided into Adversarial learning based [27, 37, 51, 52, 54]
DA and Self-training based [31, 34, 47, 57, 59] DA. While the former focuses on minimizing task-specific loss for
Figure 1. Average Pixel Label per image vs. Performance.
Our novel human-in-the-loop framework, LabOR (PPL and SPL) significantly outperforms not only previous UDA state-of-the-art models (e.g., IAST [31]) but also DA model with few labels(e.g.,
WDA [38]). Note that our PPL requires negligible number of la-bel to achieve such performance improvements (25 labeled points per image), and our SPL shows the performance comparable with fully supervised learning (0.1% mIoU gap). Detailed performance can be found in Table. 1 and Fig. 5. source domain and domain adversarial loss, the self-training strategy retrains the model with generated target-specific pseudo labels. Among them, IAST [31] achieves state-of-the-art performance in UDA by effectively mixing adversar-ial based and self-training based strategies.
Despite the relentless efforts in developing UDA mod-els, the performance limitations are clear as it still lags far behind the fully supervision model. As visualized in Fig. 1, the recent UDA methods remain at around (∼50% mIoU) which is far below the performance of full supervision (∼65% mIoU) on GTA5 [41] → Cityscapes [8].
Motivated by the limitation of UDA, we present a new perspective of domain adaptation by utilizing a minute portion of pixel-level labels in an adaptive human-in-the-loop manner. We name this framework Labling Only if
Required (LabOR), which is described in Fig. 2. Unlike conventional self-training based UDA that retrains the target network with the pseudo labels generated from the model predictions, we utilize the model predictions to find uncer-tain regions that require human annotations and train these regions with ground truth labels in a supervised manner. In particular, we find regions where the two different classi-fiers mismatch in predictions. In order to effectively find the mismatched regions, we introduce additional optimiza-tion step to maximize the discrepancy between the two clas-sifiers like [7, 43]. Therefore, by comparing the respective predictions from the two classifiers on a pixel level, we cre-ate a mismatched area that we call the inconsistency mask which can be regarded uncertain pixels. We call this frame-work the “Adaptive Pixel Selector” which guides a human annotator to label on proposed pixels. This results in the use of a very small number of pixel-level labels to maxi-mize performance. Depending on how we label the pro-posed areas, we propose two different labeling strategies, namely “Segment based Pixel-Labeling (SPL)” and “Point based Pixel-Labeling (PPL).” While SPL labels every pix-els on the inconsistency mask in a segment-like manner,
PPL places its focus more on the labeling effort efficiency by finding the representative points within a proposed seg-ment. We empirically show that the two proposed “Pixel-Labeling” options not only help a model achieve near su-pervised performance but also reduces human labeling costs dramatically.
We summarize our contributions as follows: 1. We design a new framework of domain adaptation for semantic segmentation, LabOR, by utilizing a small fraction of pixel-level labels with an adaptive human-in-the-loop pixel selector. 2. We propose two labeling options, Segment based
Pixel-Labeling (SPL) and Point based Pixel-Labeling (PPL), and show that these methods are especially ad-vantageous in performance compared to UDA and la-beling efficiency respectively. 3. We conduct extensive experiments to show that our model outperforms previous UDA model by a signifi-cant margin even with very few pixel-level labels. 2.