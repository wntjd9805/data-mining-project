Abstract
The existence of noisy data is prevalent in both the train-ing and testing phases of machine learning systems, which inevitably leads to the degradation of model performance.
There have been plenty of works concentrated on learning with in-distribution (IND) noisy labels in the last decade, i.e., some training samples are assigned incorrect labels that do not correspond to their true classes. Nonetheless, in real application scenarios, it is necessary to consider the inﬂuence of out-of-distribution (OOD) samples, i.e., sam-ples that do not belong to any known classes, which has not been sufﬁciently explored yet. To remedy this, we study a new problem setup, namely Learning with Open-world
Noisy Data (LOND). The goal of LOND is to simultane-ously learn a classiﬁer and an OOD detector from datasets with mixed IND and OOD noise. In this paper, we propose a new graph-based framework, namely Noisy Graph Clean-ing (NGC), which collects clean samples by leveraging ge-ometric structure of data and model predictive conﬁdence.
Without any additional training effort, NGC can detect and reject the OOD samples based on the learned class proto-types directly in testing phase. We conduct experiments on multiple benchmarks with different types of noise and the re-sults demonstrate the superior performance of our method against state of the arts. 1.

Introduction
Deep neural networks (DNNs) have gained popularity in a variety of applications. Despite their success, DNNs often rely on the availability of large-scale labeled train-ing datasets. In practice, data annotation inevitably intro-duces label noise, and it is extremely expensive and time-consuming to clean up the corrupted labels. The existence
*Equal contribution. †Corresponding author. This work was supported by Alibaba Group through Alibaba Innovative Research Program and the
National Natural Science Foundation of China (61772262).
Figure 1: A demonstration of the LOND setup. We use green boxes to represent clean samples while yellow and red boxes are IND and OOD noisy samples, respectively. of label noise can be problematic for overparameterized deep networks, as they may overﬁt to label noise even on randomly-assigned labels [54]. Therefore, mitigating the effects of noisy labels becomes a critical issue.
When learning with noisy labels (LNL), plenty of promising methods have been proposed to improve the gen-eralization [39, 7, 42, 22, 40, 56, 48, 49, 47]. Many exist-ing methods work by analyzing output predictions to iden-tify mislabeled samples [51, 35, 21] or reweighting sam-ples to alleviate the inﬂuence of noisy labels [36, 1]. Note that, these methods are particularly designed to deal with in-distribution (IND) label noise. Some other works also consider the existence of out-of-distribution (OOD) noise in training datasets [41, 20]. Their basic assumption is that clean samples are clustered together while OOD samples are widely scattered in the feature space.
Although signiﬁcant performance improvement is achieved, most existing LNL works only take account of
OOD samples in training phase, while the existence of OOD samples in testing phase is neglected, which is crucial for machine learning systems in real applications [10, 19, 38].
In this paper, we study this practical problem, i.e., the ex-2. We propose a new graph-based noisy label learning framework, NGC, which corrects IND noisy labels and sieves out OOD samples by utilizing the conﬁ-dence of model predictions and geometric structure of data. Without any additional training effort, NGC can detect and reject OOD samples at testing time. 3. We evaluate NGC on multiple benchmark datasets un-der various noise types as well as real-world tasks.
Experimental results demonstrate the superiority of
NGC over the state-of-the-art methods.
The rest of the paper is organized as follows. First, we introduce some related work. Then, we present the stud-ied learning problem and the proposed framework. Further-more, we experimentally analyze the proposed method. Fi-nally, we conclude this paper. 2.