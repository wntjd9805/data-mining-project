Abstract
Recently, some approaches are proposed to harness deep convolutional networks to facilitate superpixel segmenta-tion. The common practice is to first evenly divide the image into a pre-defined number of grids and then learn to asso-ciate each pixel with its surrounding grids. However, sim-ply applying a series of convolution operations with lim-ited receptive fields can only implicitly perceive the rela-tions between the pixel and its surrounding grids. Con-sequently, existing methods often fail to provide an effec-tive context when inferring the association map. To rem-edy this issue, we propose a novel Association Implantation (AI) module to enable the network to explicitly capture the relations between the pixel and its surrounding grids.
The proposed AI module directly implants the grid fea-tures to the surrounding of its corresponding central pixel, and conducts convolution on the padded window to adap-tively transfer knowledge between them. With such an im-plantation operation, the network could explicitly harvest the pixel-grid level context, which is more in line with the target of superpixel segmentation comparing to the pixel-wise relation. Furthermore, to pursue better boundary pre-cision, we design a boundary-perceiving loss to help the network discriminate the pixels around boundaries in hid-den feature level, which could benefit the subsequent infer-ring modules to accurately identify more boundary pixels.
Extensive experiments on BSDS500 and NYUv2 datasets show that our method could achieve state-of-the-art per-formance. Code and pre-trained model are available at https://github.com/wangyxxjtu/AINet-ICCV2021. 1.

Introduction
Superpixels are image regions formed by grouping im-age pixels similar in color and other low-level properties, which could be viewed as an over-segmentation of image.
The process of extracting superpixels is known as super-pixel segmentation. Comparing to pixels, superpixel pro-†Corresponding author
‡Co-corresponding author
Figure 1: Different from the SCN [54] that implicitly learns the association using the cascaded convolutions, our AINet proposes to implant the corresponding grid features to the surrounding of the pixel to explicitly perceive the relation between each pixel and its neighbor grids. vides a more effective representation for image data. With such a compact representation, the computational efficiency of vision algorithms could be improved [22, 12, 46]. Con-sequently, superpixel could benefit many vision tasks like semantic segmentation [13, 53, 60, 58, 59], object detec-tion [10, 40], optical flow estimation [15, 32, 44, 52], and even adversarial attack [8]. In light of the fundamental im-portance of superpixels in computer vision, superpixel seg-mentation attracts much attention since it is first introduced by Ren and Malik [38] in 2003.
The common practice for superpixel segmentation is to first split the image into grid cells and then estimate the membership of each pixel to its adjacent grids, by which the grouping could be performed. Meanwhile, the mem-bership estimation plays the key role in superpixel seg-mentation. Traditional approaches usually utilize the hand-craft features and estimate the relevance of pixel to its neighbor grids based on clustering or graph-based meth-ods [1, 31, 25, 28, 2], however, these methods all suffer from the weakness of the hand-craft features and are diffi-cult to integrate into other trainable deep frameworks. In-spired by the success of deep neural networks in many computer version problems, researchers recently attempts
to adopt the deep learning technique to superpixel segmen-tation [18, 54, 47]. As mentioned in abstract, previous deep methods attempt to assign pixels by learning the associa-tion of each pixel to its surrounding grids using the fully convolutional networks [41]. The popular solutions like
SCN [54], SSN [18] employ the U-net architecture [39] to predict the association, i.e., the 9-way probabilities, for each pixel. Although stacking convolution layers can enlarge the receptive field and help study the pixel-grid wise probabili-ties, introducing low-level features with skip connection in the final layer will pollute the probabilities due to the added pixel-pixel wise information, since the ultimate target is to predict the association between the target pixel and its 9-neighbor grids instead of its 9-neighbor pixels.
To tackle this weakness, we propose to directly implant the grid features to the surrounding of the corresponding pixel using an association implantation (AI) module. Fig. 1 simply shows the core idea of our AI module, before feed-ing the last features into the prediction layer, our AI module is performed: for each pixel, we place the corresponding grid features to its neighbors, then a convolution with 3 × 3 kernel is followed, this convolution is no longer to capture the pixel-pixel relation but the relation between pixel and its 9 neighbor grids, providing the consistent context with the target of superpixel segmentation. Our proposed AI module provides a simple and intuitive way to allow the network to harvest the pixel-neighbor grids context in an explicit fash-ion, which is exactly required by superpixel segmentation.
Comparing to existing methods, such a design is more con-sistent with the target of superpixel segmentation and could give more beneficial support for the subsequent association map inferring.
Besides, a satisfactory superpixel algorithm should acc-tually identify the boundary pixels, however, some designs towards this target still missed among existing works. To pursue better boundary precision, we augment the optimiza-tion with a boundary-perceiving loss. To be specific, we first sample a set of small local patches on the pixel embed-ding map along the boundaries. Then, the features with the same/different labels in each patch are treated as the posi-tive/negative samples, on which a classification procedure is performed to enhance the compactness of the features with the same label while distinguish the different semantic fea-tures. Our boundary-perceiving loss encourages the model to pay more attention to discriminate the features around boundaries, consequently, more boundary pixels could be identified.
Quantitative and qualitative results on BSDS500 [3] and
NYUv2 [42] datasets demonstrate that the proposed method achieves more outstanding performance against the state-of-the-art superpixel segmentation methods. In summary, we make the following contributions in this work:
• We propose a novel AI module to directly capture the relation between the pixel and its surrounding grid cells, such a design builds a more consistent architec-ture with the target of superpixel segmentation.
• A boundary-perceiving loss is designed to discrimi-nate the features with different semantic labels around boundaries, which could help the network accurately identify boundary pixels and improve the boundary precision. 2.