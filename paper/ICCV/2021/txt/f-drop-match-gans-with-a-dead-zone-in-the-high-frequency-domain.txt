Abstract
Generative adversarial networks built from deep convo-lutional neural networks (GANs) lack the ability to exactly replicate the high-frequency components of natural images.
To alleviate this issue, we introduce two novel training tech-niques called frequency dropping (F-Drop) and frequency matching (F-Match). The key idea of F-Drop is to ﬁlter out unnecessary high-frequency components from the in-put images of the discriminators. This simple modiﬁcation prevents the discriminators from being confused by pertur-bations of the high-frequency components. In addition, F-Drop makes the GANs focus on ﬁtting in the low-frequency domain, in which there are the dominant components of natural images. F-Match minimizes the difference between real and fake images in the frequency domain for generating more realistic images. F-Match is implemented as a regu-larization term in the objective functions of the generators; it penalizes the batch mean error in the frequency domain.
F-Match helps the generators to ﬁt in the high-frequency domain ﬁltered out by F-Drop to the real image. We exper-imentally demonstrate that the combination of F-Drop and
F-Match improves the generative performance of GANs in both the frequency and spatial domain on multiple image benchmarks. 1.

Introduction
Generative adversarial networks built from deep convo-lutional networks (GANs) [10, 11, 20, 22] have attracted much attention in the computer vision community and have been utilized in various applications because they can synthesize diverse images with high-ﬁdelity to the target datasets. The training of GANs is formulated as a competi-tive game played by two neural networks called a generator and a discriminator; the generator is optimized to produce fake images that can fool the discriminator, and the discrim-inator is optimized to distinguish the real images from the fake images through min-max optimization. In theory, the model replicates training data as the optimal result. How-ever, recent studies have revealed that GANs fail to replicate
Figure 1. Sensitivities of discriminators in the frequency domain.
The sensitivity is measured by single Fourier attack (SFA) [26], which perturbs each frequency component of an image. As the sensitivity, we plot the average differences between outputs of nor-mal and attacked discriminators over 128 images in the AFHQ-Cat dataset (512 × 512) on each pixel. The differences in the low-frequency domain are located near the center of each ﬁgure, and the differences in the high-frequency domains are at the edges.
Our method outperforms the baseline (StyleGAN2-ADA) in terms of the robustness against the SFA on the high-frequency compo-nents. data in the frequency domain [7, 8]. Durall et al. [7] and
Frank et al. [8] have reported that the frequency character-istics of the generated images in the high-frequency domain are different from those of real images (we refer to this dif-ference as the frequency gap). They have also shown that the generated images can be easily detected as fakes with al-most 100% accuracy by assessing the frequency gap. While the previous studies mainly focus on the aliasing caused by upsampling in CNNs as the cause of the frequency gap, modifying the upsampling is insufﬁcient for correcting the
ﬂaws in the frequency domain [8].
In this study, we ex-plore another cause of the frequency gaps to reduce them.
Since spatial and frequency domains are dual, reducing the frequency gaps can improve the generative performances of
GANs in the spatial domain.
We hypothesize that the frequency gap is caused by the sensitivity of the discriminators to the perturbations in the
In GANs for image generation, high-frequency domain. discriminators are usually implemented as CNN-based bi-nary classiﬁers. As shown in [26, 30], CNN-based classi-ﬁers are sensitive to perturbations of the frequency com-ponents. Moreover, Wang et al. [27] have reported that
CNN-based classiﬁers predict labels depending on high-frequency components that are hardly recognizable to hu-mans. Accordingly, we conjecture that the discriminators of
GANs are also sensitive to the high-frequency components of the input images. Indeed, our experiments demonstrate the sensitivity of the discriminator in the frequency domain: the output of the discriminator is signiﬁcantly changed by single Fourier attack [26], which perturbs each frequency component of an image (Fig. 1, left). The sensitivity of the discriminators prevents the generators from learning data because the generators are optimized to fool the discrimina-tors by perturbing high-frequency components rather than by replicating data.
To alleviate the sensitivity of the discriminators and the frequency gap, we present two novel techniques, called frequency dropping (F-Drop) and frequency matching (F-Match). The main idea of F-Drop is to ﬁlter out high-frequency components from the inputs of the discrimina-tors (for both real and generated images) and thereby the discriminators concentrate on lower frequency components, which are the dominant components in natural images [29].
We insert a low-pass ﬁlter, which ﬁlters out frequency com-ponents above a certain threshold from images, before the input layer of the discriminators. F-Drop, (i) transforms
RGB images into the frequency domain by using discrete cosine transform (DCT), (ii) performs ﬁltering in the fre-quency domain by element-wise multiplication, and (iii) transforms the images back into RGB space by using in-verse discrete cosine transform (IDCT). Since RGB im-ages are used as input, F-Drop does not require any mod-iﬁcations to the original network architectures. By apply-ing F-Drop, the discriminators become robust against high-frequency perturbations (Fig. 1, right), and thus, the gen-erators can dedicate themselves to fooling the discrimina-tors by learning the remaining lower frequency components.
However, since F-Drop simply transforms the input of the discriminators, the generators are still free to synthesize the high-frequency components ﬁltered out during the training.
Hence, to synthesize realistic frequency components, we propose F-Match, which minimizes the mean error in the frequency domain. F-Match is a simple mini-batch-based regularization term for the objective function of the genera-tors; it can utilize arbitrary frequency transformations (e.g.,
DFT and DCT) and loss functions (e.g., the squared and ab-solute error). We experimentally found that the best func-tion for F-Match is the mean squared error in DCT space.
Our experiments show that, in various settings, the com-bination of F-Drop and F-Match succeeds in synthesizing more realistic images in both the frequency and spatial do-mains compared with the conventional techniques [4, 7, 8].
Our contributions are summarized as follows:
•
•
We demonstrate that the discriminators of GANs are sensitive to perturbations of high-frequency compo-nents through the experiments applying single Fourier attack to discriminators.
We propose two simple techniques for GANs called F-Drop and F-Match for reducing the frequency gap be-tween real and generated images. F-Drop ﬁlters out the high-frequency components from the input images of the discriminators, and F-Match minimizes the mean error in the frequency domain by adding a regulariza-tion term to the objective function of the generators.
•
We conﬁrm that our methods can improve the quality of the generated images on various image datasets. 2.