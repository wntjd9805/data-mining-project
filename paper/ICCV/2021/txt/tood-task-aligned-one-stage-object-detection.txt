Abstract
One-stage object detection is commonly implemented by optimizing two sub-tasks: object classiﬁcation and localiza-tion, using heads with two parallel branches, which might lead to a certain level of spatial misalignment in predic-tions between the two tasks.
In this work, we propose a
Task-aligned One-stage Object Detection (TOOD) that ex-plicitly aligns the two tasks in a learning-based manner.
First, we design a novel Task-aligned Head (T-Head) which offers a better balance between learning task-interactive and task-speciﬁc features, as well as a greater ﬂexibility to learn the alignment via a task-aligned predictor. Second, we propose Task Alignment Learning (TAL) to explicitly pull closer (or even unify) the optimal anchors for the two tasks during training via a designed sample assignment scheme and a task-aligned loss. Extensive experiments are con-ducted on MS-COCO, where TOOD achieves a 51.1 AP at single-model single-scale testing. This surpasses the recent one-stage detectors by a large margin, such as ATSS [30] (47.7 AP), GFL [14] (48.2 AP), and PAA [9] (49.0 AP), with fewer parameters and FLOPs. Qualitative results also demonstrate the effectiveness of TOOD for better aligning the tasks of object classiﬁcation and localization. Code is available at https://github.com/fcjian/TOOD. 1.

Introduction
Object detection aims to localize and recognize objects of interest from natural images, and is a fundamental yet challenging task in computer vision. It is commonly formu-lated as a multi-task learning problem by jointly optimizing object classiﬁcation and localization [4, 6, 7, 16, 22, 32].
The classiﬁcation task is designed to learn discriminative features that focus on the key or salient part of an object,
∗Equal contributions. † Corresponding author.
Result
Score
IoU
Figure 1. Illustration of detection results (‘Result’) and spatial distributions of classiﬁcation scores (‘Score’) and localization scores (‘IoU’) predicted by ATSS [30] (top row) and the proposed
TOOD (bottom row). Ground-truth is indicated by yellow boxes, and a white arrow means the main direction of the best anchor
In the ‘Result’ column, a away from the center of an object. red/green patch is the location of the best anchor for classiﬁca-tion/localization, while a red/green box means an object bounding box predicted from the anchor in the red/green patch (if they coin-cide, we only show the red patches and boxes). while the localization task works on precisely locating the whole object with its boundaries. Due to the divergence of learning mechanisms for classiﬁcation and localization, spatial distributions of the learned features by the two tasks can be different, causing a certain level of misalignment when predictions are made by using two separate branches.
Recent one-stage object detectors attempted to predict consistent outputs of the two separate tasks, by focusing on the center of an object [3, 10, 27, 30]. They assume that an anchor (i.e., an anchor-point for an anchor-free detector, or an anchor-box for an anchor-based detector) at the cen-ter of the object is likely to give more accurate predictions for both classiﬁcation and localization. For example, re-cent FCOS [27] and ATSS [30] both use a centerness branch
to enhance classiﬁcation scores predicted from the anchors near the center of the object, and assign larger weights to the localization loss for the corresponding anchors. Besides,
FoveaBox [10] regards the anchors inside a predeﬁned cen-tral region of the object as positive samples. Such heuristic designs have achieved excellent results, but these methods might suffer from two limitations: (1) Independence of classiﬁcation and localization. Re-cent one-stage detectors perform object classiﬁcation and localization independently by using two separate branches in parallel (i.e., heads). Such a two-branch design might cause a lack of interaction between the two tasks, leading to an inconsistency in predictions when performing them. As shown in the ‘Result’ column in Figure 1, an ATSS detector recognizes an object of ‘Dining table’ (indicated by the an-chor shown with a red patch), but localizes another object of ‘Pizza’ more accurately (red bounding box). (2) Task-agnostic sample assignment. Most anchor-free detectors use a geometry-based assignment scheme to se-lect anchor-points near the center of an object for both clas-siﬁcation and localization [3, 10, 30], while anchor-based detectors often assign anchor-boxes by computing IoUs be-tween the anchor boxes and ground truth [22, 23, 30]. How-ever, the optimal anchors for classiﬁcation and localization are often inconsistent, and may vary considerably depend-ing on the shape and characteristics of the objects. The widely used sample assignment scheme is task agnostic, and thus may be difﬁcult to make an accurate yet consis-tent prediction for the two tasks, as demonstrated in ‘Score’ and ‘IoU’ distributions of ATSS in Figure 1. The ‘Result’ column also illustrates that a spatial location of the best lo-calization anchor (green patch) can be not at the center of the object, and it is not well aligned with the best classiﬁ-cation anchor (red patch). As a result, a precise bounding box may be suppressed by the less accurate one during Non-Maximum Suppression (NMS).
To address such limitations, we propose a Task-aligned
One-stage Object Detection (TOOD) that aims to align the two tasks more accurately by designing a new head struc-ture with an alignment-oriented learning approach:
Task-aligned head.
In contrast to the conventional head in one-stage object detection where classiﬁcation and local-ization are implemented separately by using two branches in parallel, we design a Task-aligned head (T-head) to en-hance an interaction between the two tasks. This allows the two tasks to work more collaboratively, which in turn aligns their predictions more accurately. T-head is conceptually simple: it computes task-interactive features, and makes predictions via a novel Task-Aligned Predictor (TAP). Then it aligns spatial distributions of the two predictions accord-ing to the learning signals provided by a task alignment learning, as described next.
Task alignment learning. To further overcome the mis-alignment problem, we propose a Task Alignment Learning (TAL) to explicitly pull closer the optimal anchors for the two tasks. It is performed by designing a sample assign-ment scheme and a task-aligned loss. The sample assign-ment collects training samples (i.e., positives or negatives) by computing a degree of task-alignment at each anchor, whereas the task-aligned loss gradually uniﬁes the best an-chors for predicting both classiﬁcation and localization dur-ing the training. Therefore, at inference, a bounding box with the highest classiﬁcation score and jointly having the most precise localization can be preserved.
The proposed T-head and learning strategy can work col-laboratively towards making predictions with high quality in both classiﬁcation and localization. The main contribu-tions of this work can be summarized as follows: (1) we de-sign a new T-head to enhance the interaction between clas-siﬁcation and localization while maintaining their charac-teristics, and further align the two tasks at the predictions; (2) we propose TAL to explicitly align the two tasks at the identiﬁed task-aligned anchors, as well as providing learn-ing signals for the proposed predictor; (3) we conducted ex-tensive experiments on MSCOCO [17], where our TOOD achieved a 51.1 AP, surpassing recent one-stage detectors such as ATSS [30], GFL [14] and PAA [9], by a large mar-gin. Qualitative results further validate the effectiveness of our task-alignment approaches. 2.