Abstract
The classiﬁcation and regression head are both indis-pensable components to build up a dense object detector, which are usually supervised by the same training samples and thus expected to have consistency with each other for
In detecting objects accurately in the detection pipeline. this paper, we break the convention of the same training samples for these two heads in dense detectors and explore a novel supervisory paradigm, termed as Mutual Supervi-sion (MuSu), to respectively and mutually assign training samples for the classiﬁcation and regression head to en-sure this consistency. MuSu deﬁnes training samples for the regression head mainly based on classiﬁcation predict-ing scores and in turn, deﬁnes samples for the classiﬁcation head based on localization scores from the regression head.
Experimental results show that the convergence of detec-tors trained by this mutual supervision is guaranteed and the effectiveness of the proposed method is veriﬁed on the challenging MS COCO benchmark. We also ﬁnd that tiling more anchors at the same location beneﬁts detectors and leads to further improvements under this training scheme.
We hope this work can inspire further researches on the in-teraction of the classiﬁcation and regression task in detec-tion and the supervision paradigm for detectors, especially separately for these two heads. 1.

Introduction
Object detection has been drawing interest from re-searchers for decades as one of the fundamental visual tasks in the computer vision community, especially with the rise of convolutional neural networks (CNNs). The commu-nity has witnessed the fast evolution of both the method-ology and the performance of detectors from region-based ones [8, 24, 10, 1, 4, 18], to one-stage dense ones [20, 23, 22, 29, 37, 32] and then to end-to-end transformer-based detectors [3, 41]. Among these methods, one-stage detec-tors, also known as dense detectors, are favored in terms of both the speed and accuracy, as well as the fast conver-gence due to their tiling anchors densely to cover objects (cid:66): Corresponding author (lmwang@nju.edu.cn).
Inconsistency from the classiﬁcation head and re-Figure 1. gression head between spatial distributions of classiﬁcation conﬁ-dence and IoUs with ground truth predicted in a converged FCOS detector and our MuSu-trained detector. The brighter the pixel looks, the higher the value stands for. The classiﬁcation conﬁ-dence is a product of the output of the classiﬁcation head and cen-terness estimation as FCOS does in the NMS process. Note that this input image is a training image in MS COCO and the con-verged FCOS still suffers the inconsistency between classiﬁcation and regression head. Our MuSu alleviates this inconsistency. of various scales and aspect ratios and directly predicting bounding boxes with labels with these anchors.
As detection task is about classifying and localizing simultaneously, object detectors are expected to produce bounding boxes with both correct classiﬁcation labels and
ﬁne localization, and of course dense detectors are no ex-ceptions. For a dense detector, these two tasks are usually done with specialized classiﬁcation and regression heads.
For the same input feature map from the backbone network, these two heads are expected to function differently: the classiﬁcation head translates it into classiﬁcation scores in-variant with small shifts while the regression head trans-forms it to shift-equivalent localizing offsets from anchors to bounding boxes, which incurs intrinsic inconsistency be-tween these two tasks.
An accurate dense object detector is supposed to produce high-quality bounding boxes with correct labels, which re-quires that these two heads of different functionalities coor-dinate at the same spatial location of ﬁnal outputs. In other words, converged detectors should ensure spatial consis-tency on where the maximum classiﬁcation and localizing scores appear for an object. However, even for a converged detector, this goal is hard to achieve and the maximum clas-siﬁcation score and the most accurate localizing box for an object frequently appear at different locations for a training image as the input image depicted in Figure 1. This incon-sistency hurts the performance of ﬁnal models in the current detection pipeline, especially in the process of the common post-processing non-maximum suppression (NMS), which only keeps the box with the maximum classiﬁcation score among overlapping ones without the consideration of local-izing accuracy. As a result, bounding boxes with ﬁner lo-calization but lower classiﬁcation scores are suppressed and such detectors lead to inferior performance.
To tackle this problem, previous work focuses on input features and network structures of these heads and disentan-gles the classiﬁcation and regression heads from feature or structural perspectives. Different from those, we delve into this problem from the view of the supervision for these two heads, speciﬁcally, the deﬁnition of the training samples re-spectively for both them, and alleviate this inconsistency by proposing mutual supervision (MuSu) for dense detectors.
MuSu separates the deﬁnition of training samples for classiﬁcation and regression head and then makes them dependent on each other mutually. As illustrated in Fig-ure 2, training samples are not shared between two heads.
Training targets for classiﬁcation are adaptively determined by IoU (Intersection over Union) scores between predicted boxes and ground-truth boxes from the regression head.
Alike, training samples for the regression head are deﬁned by classifying scores from the classiﬁcation head. Next,
MuSu translates scores of these training samples for these two heads to soft targets by associating weights to losses of each spatial location. By this means, MuSu aims to force the consistency between these two heads by the mutual as-signment in the training phase. Under this mutual supervi-sion scheme, MuSu also enjoys the advantage of the training samples adaptively emerging from the network itself, which are refrained from being hand-crafted by expert knowledge.
Moreover, MuSu is exempt from any hand-crafted geomet-ric prior and also get rids of subtle treatments to different pyramid levels. In this sense, MuSu makes a big step fur-ther to fully adaptive sample assignment and unleashes the power of a detector more comprehensively.
We carry out extensive ablation experiments on MS
COCO dataset [21] to validate the effectiveness of our
In particular, MuSu boosts the proposed MuSu method.
FCOS detector with ResNet-50 backbone to a 40.6 AP in the COCO validation set under the common 90k training scheme without the sacriﬁce of the inference speed. More-over, we investigate that tiling more anchors at the same location will beneﬁt the detector under this mutual supervi-sion scheme, pushing to 40.9 AP over the competitive one-anchor counterpart. We argue that our method of mutual su-pervision for the classiﬁcation and regression head exploits multiple anchor settings more fully and thus boosts the per-formance higher, in contrast to [35]. We also utilize MuSu to train models with large backbones to compare state-of-the-art models and our models achieve promising results on
COCO test-dev set. 2.