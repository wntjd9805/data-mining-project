Abstract
One of the important research topics in image genera-tive models is to disentangle the spatial contents and styles for their separate control. Although StyleGAN can generate content feature vectors from random noises, the resulting spatial content control is primarily intended for minor spa-tial variations, and the disentanglement of global content and styles is by no means complete. Inspired by a mathe-matical understanding of normalization and attention, here we present a novel hierarchical adaptive Diagonal spatial
ATtention (DAT) layers to separately manipulate the spatial contents from styles in a hierarchical manner. Using DAT and AdaIN, our method enables coarse-to-ﬁne level disen-tanglement of spatial contents and styles. In addition, our generator can be easily integrated into the GAN inversion framework so that the content and style of translated images from multi-domain image translation tasks can be ﬂexibly controlled. By using various datasets, we conﬁrm that the proposed method not only outperforms the existing models in disentanglement scores, but also provides more ﬂexible control over spatial features in the generated images. 1.

Introduction
Recent development of Generative Adversarial Net-works (GAN) [11] has enabled the generation of high-quality images that are indistinguishable to the human eye. 1
Despite its high performance, disentangling the attributes of the generated images is still an open problem.
For example, the content and style disentanglement is an important issue in many image generation tasks such as faces. Here, contents refer to the spatial information such as face direction, expression, whereas styles are related with other features such as color, makeup, gender. StyleGAN
[18], which shows the state-of-the-art performance in image generation, tries to disentangle the style and content using the AdaIN codes [15] and the content feature vectors from random per-pixel noises, respectively. The AdaIN layer then combines the style and the content features to gener-ate more realistic features at each resolution (see Fig. 2(a)).
However, the content control by per-pixel noises is mostly for minor spatial variations so that the disentanglement of global contents and styles is by no means complete.
Recently, generative models that simultaneously use
AdaIN and independent content latent codes [19, 1] have shown good performance in separating global style and con-tent information. For example, in recent structured noise injection (SNI) approach [1], the latent code for content is generated by an additional neural network, which is used as an input tensor of the image generator composed of subse-quent layers for style control using AdaIN (see Fig. 2(b)).
Although SNI showed good performance in disentangle-ment, one of the major drawbacks is that the size of the input tensor is limited to relatively small resolution (e.g. 4×4). Therefore, the intended content control often fails to work properly due to the limited capacity.
To address these issues, here we introduce a novel Di-agonal spatial ATtention (DAT) module to manipulate the content feature in a hierarchical manner. Speciﬁcally, the content code is applied to multiple layer features as diagonal attention maps at various resolutions as shown in Fig. 2(c).
Despite the simplicity of diagonal attention, one of the im-portant advantages of DAT is that the image content and style can be modulated independently in a symmetric man-ner; and similar to AdaIN for the styles, DAT enables the hierarchical control of the spatial content. These lead to an effective disentanglement of the content and style compo-nents in generated images
In addition, our method can be easily integrated into the state-of-the-art GAN inversion [42], allowing much more
ﬂexible post-hoc control of the content and style in the translated images from the multi-domain image translation. 2.