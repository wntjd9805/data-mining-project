Abstract
Recent advances in high-ﬁdelity semantic image editing heavily rely on the presumably disentangled latent spaces of the state-of-the-art generative models, such as Style-GAN. Speciﬁcally, recent works show that it is possible to achieve decent controllability of attributes in face images via linear shifts along with latent directions. Several recent methods address the discovery of such directions, implic-itly assuming that the state-of-the-art GANs learn the latent spaces with inherently linearly separable attribute distribu-tions and semantic vector arithmetic properties.
In our work, we show that nonlinear latent code manip-ulations realized as ﬂows of a trainable Neural ODE are beneﬁcial for many practical non-face image domains with more complex non-textured factors of variation. In partic-ular, we investigate a large number of datasets with known attributes and demonstrate that certain attribute manipula-tions are challenging to obtain with linear shifts only. 1.

Introduction
Generative Adversarial Networks (GANs) [13] have sig-niﬁcantly advanced techniques for image processing and controllable generation, such as semantic image-to-image translation [15, 9, 22, 34, 35] and image editing via ma-nipulating the internal GAN activations [5, 10] or gen-erator parameters [4, 8]. Moreover, since the GAN la-tent spaces are known to possess semantically meaning-ful vector space arithmetic, a plethora of recent works ex-plore these spaces to discover the interpretable directions
[27, 29, 11, 16, 26, 31, 14, 25]. The directions identiﬁed by these methods are then used to manipulate user-speciﬁed image attributes, which is shown to be particularly success-ful for face images [29].
While a large number of methods exploring the latent spaces of pretrained GANs have recently been developed, most of them learn linear latent controls, and more com-plex nonlinear latent transformations are hardly addressed.
We conjecture that this limitation could arise because most of the latent editing literature is biased to the human face datasets, where linear transformations are sufﬁcient for de-cent editing quality [29].
In this work, we demonstrate that in the general case, the linear latent shifts cannot be used universally for all do-mains and attributes, and more complex nonlinear transfor-mations are needed. To this end, we analyze how different attribute values are distributed in the latent spaces of GANs trained on several synthetic and real datasets with known at-tribute labels. Our analysis shows that for non-face images, many attributes cannot be controlled by linear shifts. To mitigate this issue, we propose an alternative parametriza-tion of the latent transformation based on the recent Neural
ODE work [7]. Our parametrization allows for gradient-based optimization and can be used within existing methods for latent space exploration [29]. Through extensive experi-ments, we show that the proposed nonlinear transformations are much more appealing for the purposes of controllable generation. In particular, we show that nonlinear transfor-mations are more beneﬁcial for edits requiring global con-tent changes, such as changing appearance of a scene.
To sum up, our contributions are the following:
• We analyze the distributions of different attribute val-ues in the GAN latent spaces and show that linear la-tent controls are typically not sufﬁcient beyond the hu-man face domain.
*Equal contribution
• We propose a Neural ODE-based parametrization of 1
the latent transformation that allows for learning the nonlinear controls. On several non-face datasets, we show that usage of this parametrization results in higher editing quality conﬁrmed qualitatively and quantitatively. eral cases of inadequacy caused by linear editing and pro-vides a rigorous quantitative comparison with non-linear techniques on several datasets. 3. GAN-based image editing
• We propose a technique to analyze the learned Neu-ral ODE models and reveal the attributes that require nonlinear latent transformations.
In this section, we remind on current approaches to con-trollable image generation and editing via GANs and dis-cuss their possible weaknesses. 2.