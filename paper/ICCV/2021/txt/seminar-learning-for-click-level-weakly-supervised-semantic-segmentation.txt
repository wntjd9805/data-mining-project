Abstract
Annotation burden has become one of the biggest barri-ers to semantic segmentation. Approaches based on click-level annotations have therefore attracted increasing atten-tion due to their superior trade-off between supervision and annotation cost. In this paper, we propose seminar learn-ing, a new learning paradigm for semantic segmentation with click-level supervision. The fundamental rationale of seminar learning is to leverage the knowledge from differ-ent networks to compensate for insufficient information pro-vided in click-level annotations. Mimicking a seminar, our seminar learning involves a teacher-student and a student-student module, where a student can learn from both skill-ful teachers and other students. The teacher-student mod-ule uses a teacher network based on the exponential mov-ing average to guide the training of the student network.
In the student-student module, heterogeneous pseudo-labels are proposed to bridge the transfer of knowledge among students to enhance each other’s performance. Experimen-tal results demonstrate the effectiveness of seminar learn-ing, which achieves the new state-of-the-art performance of 72.51% (mIOU), surpassing previous methods by a large margin of up to 16.88% on the Pascal VOC 2012 dataset.
Figure 1. Weakly supervised segmentation with the click-level an-notations. (a) A generic model trained only with click-level anno-tations overfits to the labels and cannot recognize the whole object. (b) Previous works (e.g. regularized loss) apply low-dimensional continuity information to the training, also failing to correctly seg-ment the object. (c) With seminar learning, our teacher-student module enables the network to generalize to the whole object, as indicated by the arrows. Meanwhile, by integrating diverse in-formation from the two networks, the student-student module can smooth the boundary area in the marked boxes. 1.

Introduction
Semantic segmentation is a fundamental task, where each pixel of an image is labeled into a predefined set of classes.
In the field of computer vision, it has made great progress in many applications, such as automatic driving, scene understanding, and medical diagnosis [30]
[48]. Recently, deep convolutional neural networks (CNNs) have achieved remarkable success in a variety of seman-tic segmentation tasks [9, 30]. However, they require large amounts of pixel-level annotations for training. The acqui-sition process of pixel-level annotations is extremely time-∗Corresponding author: Feng Zheng (Email: f.zheng@ieee.org). This work is supported by the National Natural Science Foundation of China under Grant No. 61972188. consuming and labor-intensive.
In order to alleviate the burden of annotations, weakly supervised semantic segmentation has become increasingly popular, as it only requires coarse annotations, such as box-level [12], image-level [33], scribble-level [24], or click-level [4] supervision. Among these, click-level supervision only annotates one pixel for each object in an image. Fur-ther, it not only provides valuable location information, but is also one of the cheapest form of weakly supervision [4].
It has high research potential in terms of the trade-off be-tween information and time costs.
As commonly known, it is challenging to achieve sat-isfactory performance with limited supervision information during model training. For instance, with click-level pat-terns, if only learning from one labeled pixel, the model cannot infer the entire range of an object, especially the edges, which will eventually weaken the segmentation per-formance. An effective way to compensate weak super-vision information is to introduce more prior information.
For example, ‘What’s the point’ [4] incorporates an object-ness prior into network training, which helps distinguish between foreground and background.
‘ScribbleSup’ [24] uses an additional graphical model to propagate information from click-level annotations. ‘Regularized Loss’ [44] de-signs a regularization item based on dense conditional ran-dom field (CRF) for classifying nearby pixels with similar colors into the same category. These models only focus on low-dimensional continuity between labeled pixels and oth-ers pixels, which is limited to local annotation information in click-level supervision. Therefore, these models cannot properly segment the entire object and still underperform.
Considering the nature of click-level supervised seman-tic segmentation, we make two observations: 1) A large number of unlabeled pixels are not well used, but could pro-vide broader information, which can expand the learning range of networks from a single annotated pixel to an entire object. 2) If a network is trained under different conditions, such as using different random seeds, the predictions will vary greatly. This uncertainty causes that different networks capture distinctive and diverse information, which could be aggregated to complement each other.
Inspired by these observations, we propose seminar learning, a novel learning paradigm for click-level weakly supervised semantic segmentation by introducing more ef-fective information. The essence of our seminar learning is to complement the deficiency of networks by leveraging the knowledge provided from the predictions of other networks.
As shown in Fig. 1, seminar learning framework consists teacher-student module and student-of two components: student module. Notably, the teacher-student module is ex-ploited to expand the learning range of networks. We use an exponential moving average (EMA) based teacher net-work for generalized prediction and prevent the student net-work from overfitting to click-level labels, which has a simi-lar workflow to semi-supervised mean-teacher [45] method.
However, compared to mean-teacher, our module is able to operate on unlabeled pixels in each image instead of un-labeled images. The student-student module is applied to refine segmentation boundaries by aggregating diversity in-formation of student networks. To improve the efficiency of information transfer, we propose heterogeneous pseudo-labels as bridges between student networks, which based on the prediction of a fully trained student to guide the other. In summary, we make several major contributions as follows:
• We propose a novel learning paradigm, called seminar learning, that can learn to leverage more supervisory information provided by a group of networks.
• We treat the click-level supervised semantic segmenta-tion task as a semi-supervised pixel classification task per image, and propose a novel pixel consistency loss, which enables a student to learn from a teacher using unlabeled pixels.
• The novel concept of heterogeneous pseudo-labels is proposed, which is a more effective medium to en-able the supervisory information to be shared among diverse networks by the student-student module.
• We conduct extensive experiments to verify the effec-tiveness of the proposed seminar learning, which out-performs previous SOTA works [44] by a large margin (from 55.63% to 72.51% in terms of the mIOU metric). 2.