Abstract
Document unwarping attempts to undo physical de-formations of the paper and recover a ’ﬂatbed’ scanned document-image for downstream tasks such as OCR. Cur-rent state-of-the-art relies on global unwarping of the doc-ument which is not robust to local deformation changes.
Moreover, a global unwarping often produces spurious warping artifacts in less warped regions to compensate for severe warps present in other parts of the document. In this paper, we propose the ﬁrst end-to-end trainable piece-wise unwarping1 method that predicts local deformation ﬁelds and stitches them together with global information to ob-tain an improved unwarping. The proposed piece-wise for-mulation results in 4% improvement in terms of multi-scale structural similarity (MS-SSIM) and shows better perfor-mance in terms of OCR metrics, character error rate (CER) and word error rate (WER) compared to the state-of-the-art. 1.

Introduction
Document images captured using mobile devices often contain artifacts due to the physical shape of the paper, cam-era pose or complex lighting conditions. Therefore, unlike images captured with high ﬁdelity using ﬂatbed scanners, mobile captured documents are ill-suited for digitization.
To improve the image quality for downstream tasks, such as OCR, document unwarping is used to minimize the vis-ible distortion between a captured document image and its
ﬂatbed-scanned version. With multiple sources of distor-tion due to camera viewpoint, paper shape and illumina-tion, the task of unwarping document images in-the-wild is inherently challenging and a long-standing research prob-lem in the domain of document analysis. Most solutions to date, ﬁrst estimate the deformed 3D shape, and then un-warp the image to make it planar. There is a large body of work in 3D shape-based unwarping, some relying on spe-1Project page: https://sagniklp.github.io/PiecewiseUnwarp/
This project was initiated when Sagnik Das was an intern at AWS.
Figure 1. Comparison to state of the art with the proposed piece-wise approach: (a) Our method (left) show local improve-ments, text-lines are more aligned (highlighted with dashed green-line) and leads to better unwarping on the edges compared to [7] on the right. (b) Original image (left), result of the proposed approach (center) and that of global unwarping [7] (right) shows that global unwarping introduces additional warping (highlighted in box). (c)
Artifacts due to the absence of stitching reconstruction loss in [14], columns 1, & 3 show our results without such artifacts. ciﬁc hardware such as stereo [33, 28] and structured light
[3, 23], or using 2D images to estimate 3D using shape-from-shading [30, 35] or multi-view images [27, 34]. With respect to image based document unwarping, traditional ap-proaches detect the boundary of a document [4], or explic-itly predict text-lines [26, 21]. Generally, these traditional approaches are not very accurate, e.g. textline based meth-ods work as expected only if there exist enough textlines in
the image. With the progress of deep learning, most of the recent methods have become end-to-end and data-driven.
End-to-end deep learning based document unwarping approaches such as DocUNet [19], DewarpNet [7] and
CREASE [20] directly predict the global unwarping map.
However, these approaches mainly focus on global infor-mation and tend to overlook local information. This of-ten results in (1) less robust local unwarping, (2) unex-pected warping as shown in Fig. 1 (a) (b). There are few approaches that successfully apply local unwarping be it through using patches [14] or 2D segments [8]. Notably, none of these piece-wise methods are end-to-end trainable, and therefore have difﬁculty in generalizing well to ar-bitrary scenarios such as large deformation of the paper.
Moreover, optimization based patch stitching used in [14, 8] often lead to undesired stitching artifacts in the output un-warped images (see ﬁgure 1c).
Inspired by these facts, in this paper, we propose the ﬁrst end-to-end trainable piece-wise unwarping approach made possible by a novel fully-differentiable feature-level stitch-ing module for the local unwarping maps. Our goal is to leverage local information for better document unwarping.
Speciﬁcally, we argue that learning local and global defor-mation separately through the use of patches, as well as learning the appropriate patch stitching will better utilize local shape deformations. A local approach is also moti-vated by the fact that a complexly folded/warped document is a combination of multiple simpler deformations which are easier to be approximated locally.
Our approach consists of three trainable modules: (a) shape network (SNet), (b) piece-wise unwarping network (PUNet) and, (c) global stitching network (GSNet). The
SNet takes the image as input and outputs a 3D shape of the paper. The PUNet takes 3D shape patches as input and regresses local unwarping maps. The GSNet takes the lo-cal patches as input and outputs a global unwarping map to unwarp the input image. All three networks are trained end-to-end with losses on local and global unwarping map regression, and ﬁnal unwarped image reconstruction. The main contributions of our paper are:
First, a novel end-to-end trainable framework that esti-mates document unwarping in a piece-wise manner, focus-ing on unwarping the local deformations.
Second, a fully differentiable stitching network that takes the per-patch unwarping map as input and produces a global unwarping map. This stitching module is end-to-end train-able, and generates artifact free unwarped images, which improves upon prior stitching-based works [14].
Third, we show signiﬁcant improvement in local un-warping quality, with the proposed piece-wise approach.
We improve the prior state-of-the-art in terms of the image similarity metric, MS-SSIM and show more stable perfor-mance in terms of OCR error metrics. 2.