Abstract
Training sample re-weighting is an effective approach for tackling data biases such as imbalanced and corrupted labels. Recent methods develop learning-based algorithms to learn sample re-weighting strategies jointly with model training based on the frameworks of reinforcement learning and meta learning. However, depending on additional unbiased reward data is limiting their general applicability.
Furthermore, existing learning-based sample re-weighting methods require nested optimizations of models and weight-ing parameters, which requires expensive second-order computation. This paper addresses these two problems and presents a novel learning-based fast sample re-weighting (FSR) method that does not require additional reward data.
The method is based on two key ideas: learning from history to build proxy reward data and feature sharing to reduce the optimization cost. Our experiments show the proposed method achieves competitive results compared to state of the arts on label noise robustness and long-tailed recogni-tion, and does so while achieving significantly improved training efficiency. The source code is publicly available https://github.com/google-research/ at google-research/tree/master/ieg. 1.

Introduction
The performance of DNNs is dependent on the scale of training datasets and the quality of labels. Data biases are inevitable in practice, and in particular, noisy labels [51, 61] or imbalanced classes [9, 25] can negatively influence the model performance.
Sample re-weighting is an effective strategy that has been explored to address problems caused by data biases [5]. The underline principle of sample re-weighting is as simple as upgrading the weights of good samples and downgrading the weights of bad samples. Finding effective weights that can optimize the model training with stochastic gradient descent (SGD) is a dynamic process. The optimal weight of a sam-ple can change over model training phases. Over-weighting simple samples at later phases while under-weighting hard samples at early phases can cause negative effects to the
Figure 1. Overview of the proposed method compared with typical method for meta re-weighting. Our method is fast and does not need reward data. overall DNN accuracy [16]. In light of the advances in meta learning and reinforcement learning (RL), there is a growing interest in learning-to-learn based algorithms to optimize sample weights jointly with model training [44, 47, 20, 57].
This problem well resembles the design of MAML [13]: in-corporating meta optimization inside the supervised training for sample weight optimization. The meta-objective of re-weighting is usually defined as finding the optimal weight per sample such that the trained model has the best objective on an additional reward (a.k.a. validation) dataset. Moreover, such reward dataset is required to be unbiased and to have reasonable size. For example, in label noise robust training problems, this unbiased reward dataset is expected to have clean and class-balanced labels. This extra requirement has been noted to be problematic, but how to remove such a requirement remains unanswered [6].
From an optimization and efficiency perspective, although this problem can be directly formulated as an RL problem, the training computation is very expensive [15, 57]. There-fore, most existing work follows the more efficient meta learning framework, assuming that the weight optimization with respect to reward signals is a fully differentiable prob-lem. Even so, similarly to MAML, the overall computation still requires a second-order unroll of DNN computation graphs, which increases the memory requirement and train-ing time complexity significantly [44]. Such a limitation hinders the applicability of the method to large-scale DNNs, and emphasizes the importance of the need for further im-proving efficiency.
In this paper, we present a new fast sample re-weighting (FSR) method to overcome the two aforementioned problems
(Figure 1): a) removing reward data dependence and b) improving training efficiency. To this end we make the following contributions:
• We leverage a dictionary (essentially an extra buffer) to monitor the training history reflected by the model updates during meta optimization periodically, and pro-pose a valuation function to discover meaningful sam-ples from training data as the proxy of reward data. The unbiased dictionary keeps being updated and provides reward signals to optimize sample weights.
• Motivated by an investigation we conducted into the mechanism of sample weight meta-objective, instead of maintaining model states for both model and sample weight updates separately, we propose to enable fea-ture sharing for saving the computation cost used for maintaining respective states. The proposed method demonstrates significant improvement in training effi-ciency, which is a desirable feature for large-scale DNN training compared to previous learning-based sample weighting methods.
• Because our proposed method does not rely on addi-tional reward data, we can directly apply it to tackle common data biases, including noisy labels and long-tailed recognition, as well as more challenging com-plex of these two types of label corruption. Since fast re-weighting ability of FSR is orthogonal to domain-specific techniques, we also propose a momentum re-labeling technique with MixUp regularization to en-hance the performance of FSR in noise robust training.
Extensive experiments demonstrate our competitive per-formance compared to previous methods. 2.