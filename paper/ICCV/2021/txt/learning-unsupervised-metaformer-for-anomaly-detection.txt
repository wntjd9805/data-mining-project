Abstract
Anomaly detection (AD) aims to address the task of clas-sification or localization of image anomalies. This paper addresses two pivotal issues of reconstruction-based ap-proaches to AD in images, namely, model adaptation and reconstruction gap. The former generalizes an AD model to tackling a broad range of object categories, while the latter provides useful clues for localizing abnormal regions. At the core of our method is an unsupervised universal model, termed as Metaformer, which leverages both meta-learned model parameters to achieve high model adaptation capa-bility and instance-aware attention to emphasize the focal regions for localizing abnormal regions, i.e., to explore the reconstruction gap at those regions of interest. We jus-tify the effectiveness of our method with SOTA results on the MVTec AD dataset of industrial images and highlight the adaptation flexibility of the universal Metaformer with multi-class and few-shot scenarios. 1.

Introduction
The principal goal of image Anomaly Detection (AD) is to classify whether an image depicts an abnormal ver-sion of the target object and if exist, localize those regions of anomaly. The technique to detect the various anoma-lies of interest is crucial for industrial inspection to ensure that the resulting products meet the required standards [15].
However, since the anomalies (or the defects) can deviate from the normal ones in numerous ways, it is hard to ex-haustively pre-define an anomaly prior and collect enough anomaly data for training an anomaly detection model. In-stead, most of the previous methods use anomaly-free data to construct its representative distribution for indirectly dis-criminating the deviated data as anomalies. Hence, the AD task is also known as out-of-distribution detection.
Driven by the attempt to model the one-class distribu-tion of the anomaly-free data, the embedding-based [5, 28] and the reconstruction-based methods [24, 35, 39] comprise the two main trends for tackling the AD problem. The former seeks to learn an embedding function for making
Figure 1. Model adaptation and reconstruction gap are two piv-otal issues of reconstruction-based anomaly detection. Top: most
AD techniques train a specific model for each category. Such an approach would become demanding as the number of categories increases. Bottom: we instead propose to train a universal model,
Metaformer with instance-aware ability to simultaneously address the two key issues. Note that I − ˆI and I − ˜I respectively denote the reconstruction errors with or without instance-aware attention. the anomaly-free data close to each other in the embedding space, and the latter aims to leverage a neural network for reconstructing each sample of the normal class. To deter-mine the anomalies, the embedding-based methods draw on the resulting learned metrics, while the reconstruction-based ones employ reconstruction errors by contrast.
We resolve the AD problem from the reconstruction-based point of view. Our formulation particularly pays at-tention to explore two key factors, reconstruction gap and model adaptation, in designing an effective AD framework. (See Figure 1.) Most of the reconstruction-based AD tech-niques include an autoencoder component. As the training data are typically sufficient and all from the “normal” class, a well-trained autoencoder is expected to satisfactorily re-construct such samples not only in training but also in infer-ence. The assumption implies that the reconstruction gap can be used to detect anomalies if a given image is out of the distribution of the normal class. Different from most existing reconstruction-based AD methods merely predict-ing the image-level anomalies, our approach introduces the instance-aware attention to further regulate the reconstruc-tion gap for precisely localizing the pixel-level abnormal re-gions. Regarding the issue of model adaptation, we observe that prior arts on AD often need to collect a large number of anomaly-free examples to train an additional AD model for classifying a new object category. In real-world applica-tions, an AD system could be deployed on edge devices of limited computational power, and such a data-eager training strategy may not be practical. To overcome the concern, we design a meta-learning strategy that enables our universal
AD model to be fine-tuned with only a few anomaly-free supporting examples for handling a novel category.
The cornerstone of our method is the Metaformer, which leverages the meta-learned model parameters to effectively carry out the few-shot fine-tuning for performing AD of a novel object category and employs the instance-aware at-tention to emphasize the abnormal focal regions. Briefly speaking, the proposed Metaformer is a transformer-based instance-aware autoencoder that learns its model parame-ters using an unsupervised meta-learning strategy. Figure 1 overviews the proposed AD model. Figure 2 illustrates the steps of our meta-training, meta-testing, and inference. Fig-ure 3 sketches the key components of our Metaformer.
To enable the Metaformer for efficient model adaptation, we learn its model parameters with an unsupervised meta-training strategy. Namely, the training comprises numerous few-shot image reconstruction tasks to obtain the parame-ters for the universal model, which can be rapidly fine-tuned using a few anomaly-free examples from each underlying novel class in meta-testing. It follows that the fine-tuned
Metaformer is ready for performing the AD inference for the novel object category. We note that the meta-training stage does not have access to any of the images used in the meta-testing stage and the testing/inference stage of a novel category. In addition, to empower the Metaformer to more precisely uncover the abnormal regions, we introduce instance-aware attention to regularize the autoencoder (AE) to focus on the instance area while reconstructing an im-age. In our formulation, we first establish the instance prior based on saliency prediction and then carry out the AE reg-ularization via an attention mechanism.
To the best of our knowledge, the proposed method is the first to address the image AD task by employing an adaptive instance-aware reconstruction method. We characterize our main contributions as follows:
• We introduce unsupervised few-shot meta-training to learn the universal Metaformer that exhibits the effi-cient flexibility of model adaptation to an arbitrary ob-ject category of interest.
• We couple the instance-aware attention mechanism with the autoencoder such that anomaly detection based on reconstruction gap can emphasize the area of target object rather than the distracting background.
• We provide extensive experimental results and com-parisons to demonstrate that our method achieves the overall SOTA performance on both the anomaly clas-sification and anomaly localization. 2.