Abstract
Recovering dense human poses from images plays a crit-ical role in establishing an image-to-surface correspon-dence between RGB images and the 3D surface of the hu-man body, serving the foundation of rich real-world appli-cations, such as virtual humans, monocular-to-3d recon-struction. However, the popular DensePose-COCO dataset relies on a sophisticated manual annotation system, lead-ing to severe limitations in acquiring the denser and more
In this work, we in-accurate annotated pose resources. troduce a new 3D human-body model with a series of de-coupled parameters that could freely control the genera-tion of the body. Furthermore, we build a data generation system based on this decoupling 3D model, and construct an ultra dense synthetic benchmark UltraPose, containing around 1.3 billion corresponding points. Compared to the existing manually annotated DensePose-COCO dataset, the synthetic UltraPose has ultra dense image-to-surface cor-respondences without annotation cost and error. Our pro-posed UltraPose provides the largest benchmark and data resources for lifting the model capability in predicting more accurate dense poses. To promote future researches in this field, we also propose a transformer-based method to model the dense correspondence between 2D and 3D worlds. The proposed model trained on synthetic UltraPose can be ap-plied to real-world scenarios, indicating the effectiveness of our benchmark and model.1 1.

Introduction
In computer vision, establishing correspondences from 2D images to 3D human body models is a fundamental task for analyzing human action, which facilitates several application scenarios, such as texture transfer [7, 20, 25], virtual try-on [15, 19, 33, 34], and 3D human reconstruc-tion [8, 32]. Based on the Skinned Multi-Person Linear (SMPL) model [18], DensePose [9] takes a single RGB image as input and maps pixels to corresponding sur-face points on the SMPL model, obtaining more accurate instance-level human analysis with these predicted denser relationships. Recently, several methods [22, 23, 35] have been proposed for dense pose estimation, while the results show that it is still a very challenging problem.
One of the limitations of the current DensePose system is that the SMPL is a model for academic research and is not widely recognized in the industry, which limits its applica-tion value in real-world scenarios. As a skinned model that can represent a wide variety of body shapes, SMPL has only 10 blend shapes that do not have a clear physical meaning and may affect each other. Therefore, some problems arise when applying SMPL model, such as poor controllability which makes it difficult to adjust the human body into the targeted shape.
There are also some limitations in the popular
DensePose-COCO dataset [9]. On the one hand, it only col-lects 50K persons, not covering various poses and shapes, which makes the model perform poorly in situations such as sideways and occlusion. On the other hand, the quality of manual annotations is intrinsically limited as described in [22]. Under some ambiguity and self-occlusion condi-tions, the annotators need to mark the exact point correspon-dences, resulting in huge annotation errors.
In this work, to address the limitations of SMPL, we adopt an industry-recognized Daz2 model as the base hu-man body model. Then, we propose a new 3D model,
DeepDaz, containing a group of well-designed decoupling parameters that can control the generation of a variety of human bodies. These parameters have a specific physical meaning and are decoupled with each other, enabling hu-mans to adjust the human body freely rather than relying
* Equal contribution. † Corresponding authors. 1 Dataset and code: https://github.com/MomoAILab/ultrapose 2Daz: https://www.daz3d.com/
Figure 1. Visualization comparison of annotations on DensePose-COCO and our proposed UltraPose benchmark. The DensePose-COCO data (above) has relatively sparse point annotations, while our UltraPose (below) has ultra dense annotations, providing a depth map of the human body simultaneously. Besides, we also show their UV space comparison of annotation on the right, in which DensePose-COCO data has obvious annotation errors. For instance, there are many inner-part (blue lines) errors and inter-part (purple lines) errors. However, our UltraPose is generated with an error-free label that all the annotated and ground-truth points coincide perfectly. on professional CG design. Our DeepDaz model is also compatible with the CG industry that can be freely edited in mainstream design software, thus leading to an excellent performance and application value.
Based on the DeepDaz model, we build a data gener-ation system and further propose an ultra dense synthetic dataset, UltraPose, which contains 500K persons and 1.3B corresponding point annotations on the surface of DeepDaz model. Figure 1 show the comparison between DensePose-COCO dataset and our UltraPose, which has several appeal-ing properties. First, UltraPose has an ultra dense annota-tion with around 2.6K points in one person (about 25 times of DensePose-COCO) for pose estimation, which can pro-mote researches on instance-level human analysis. Second, based on the established data generation system, we can ac-quire quantities of data with rich diversity and no manual annotation costs. Third, the generated data annotations are absolute truth values without any error, and perfectly repre-sent the corresponding relationship between the 2D image and the surface of human body. Fourth, the UltraPose also provides the 3D parameters and depth information of the human body for further research.
Tackling such a large-scale and diverse benchmark is still challenging, requiring the model to have strong semantic feature representation capabilities. Inspired by [3], we de-sign a new transformer-based model for dense pose esti-mation task. It combines the merits of Transformers [31] and U-Net [27] simultaneously, and also uses the prior key-points knowledge to assist in prediction. Our proposed model obtains state-of-the-art accuracy on the UltraPose benchmark, and more importantly, can be directly applied to real-world scenarios, achieving impressive performance.
In summary, the major contributions of this work are three-fold:
• We replace the SMPL model with DeepDaz, a new hu-man body 3D decoupling model, which can be used to generate various poses easily and is compatible with
CG industry design standards.
• We propose a realistic human body generation sys-tem and a new large-scale synthesized benchmark, Ul-traPose, which contains 1.3 billion points annotation without any annotation cost or error.
• A transformer-based method that can extract informa-tive visual representations for ultra dense pose estima-tion. After being trained on the UltraPose dataset, our proposed methods also can be applied to real-world dense pose estimation. 2.