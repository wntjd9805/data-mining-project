Abstract
In this work, we tackle the problem of single image-based 3D shape retrieval (IBSR), where we seek to find the most matched shape of a given single 2D image from a shape repository. Most of the existing works learn to embed 2D images and 3D shapes into a common feature space and perform metric learning using a triplet loss. In-spired by the great success in recent contrastive learning works on self-supervised representation learning, we pro-pose a novel IBSR pipeline leveraging contrastive learning.
We note that adopting such cross-modal contrastive learn-ing between 2D images and 3D shapes into IBSR tasks is non-trivial and challenging: contrastive learning requires very strong data augmentation in constructed positive pairs to learn the feature invariance, whereas traditional metric learning works do not have this requirement. Moreover, ob-ject shape and appearance are entangled in 2D query im-ages, thus making the learning task more difficult than con-trasting single-modal data. To mitigate the challenges, we propose to use multi-view grayscale rendered images from the 3D shapes as a shape representation. We then introduce a strong data augmentation technique based on color trans-fer, which can significantly but naturally change the appear-ance of the query image, effectively satisfying the need for contrastive learning. Finally, we propose to incorporate a novel category-level contrastive loss that helps distinguish similar objects from different categories, in addition to clas-sic instance-level contrastive loss. Our experiments demon-strate that our approach achieves the best performance on
* Corresponding Author is Lin Gao all the three popular IBSR benchmarks, including Pix3D,
Stanford Cars, and Comp Cars, outperforming the previous state-of-the-art from 4% - 15% on retrieval accuracy. 1.

Introduction
Multimedia retrieval including image retrieval and 3D shape retrieval is one of the fundamental problems in com-puter vision. Thanks to the development of deep learning and 3D shape datasets with rich object categories such as
ShapeNet [7], 3D shape retrieval from single realistic im-ages has recently gained more attention, owing to its wide range of applications, including scene reconstruction, 3D printing, virtual reality and e-commerce platforms.
However, despite significant progress achieved with pi-oneering works, using single images to retrieve the corre-sponding 3D shapes is still a challenging problem because of the domain gap. In order to handle this gap, one common direction in previous works is to address the retrieval task by mapping 3D shapes and query images into a common em-bedding space. [15] embeds 3D shapes and 2D images into a common low-level representation space using location fields. [12] assigns a texture to a 3D shape based on a tex-ture code encoded from the 2D image to generate hard sam-ples. Both [15, 12] are modified from triplet loss [56] for metric learning, which nearly always requires hard-negative mining for good performance, as proved by [48].
[30] proves that triplet loss is a special case of the contrastive loss when the numbers of positives and nega-tives are both one, which means that batch contrastive ap-proaches subsume or significantly outperform traditional
triplet loss. The use of many negatives in contrastive learn-ing for each anchor helps the model achieve state of the art performance without the need for hard-negative mining, which can be difficult to tune properly. Therefore, we in-troduce contrastive learning into the area of IBSR. The data studied by traditional contrastive learning are all of the same type, which is different from our task.
[27, 28] perform cross-modal retrieval by applying contrastive learning, and aim to learn discriminative and modal-invariant features for data from different modalities. However, the retrieval per-formance will drop in the more fine-grained IBSR task if different rendered images are mapped to the one center em-bedding. Therefore, the introduction of contrastive learning into the task of IBSR is worth exploring.
Data augmentation plays a critical role in defining effec-tive predictive tasks with contrastive learning. In [10], it is proved that contrastive learning needs stronger data aug-mentation, which helps to avoid the high complexity of the network architecture. It is also proved that it is critical to compose cropping with color augmentation in order to learn generalizable features. From another aspect, [12] finds that objects in 2D images entangled with the color make the net-work ineffective to push away negative pairs in the IBSR task. In order to combine the above two mentioned points at the same time, we introduce the color transfer mecha-nism [44] as a simple but powerful solution, which applies the colors of one image to another. The color transfer mech-anism not only performs data augmentation on the input query images, but also effectively decouples the object and color in 2D images.
With the help of contrastive learning accompanied by the color transfer mechanism, we propose an efficient approach to image-based 3D shape retrieval task from both instance and category levels. 3D shapes are first converted into multi-view grayscale images.
Instead of mapping multi-view images of the same object into one center embed-ding, our approach processes them by an attention mecha-nism with query image into query-specific embeddings. In-spired by [30], we design an instance loss based on self-supervised contrastive loss to pull augmented embeddings of query image closer to embeddings of its ground-truth 3D shape renderings than embeddings of all other 3D shapes.
The instance loss ensures the exact shape retrieval accuracy.
Similar to the instance loss, the category loss pulls embed-dings of 3D shape renderings with the same category label as query image closer than embeddings of 3D shapes with different labels. The category loss is a cross-modal super-vised loss, which effectively leverages the label information to push apart embeddings from different categories. In such a way, both instance and category losses avoid hard example mining existing in the triplet loss.
In order to evaluate the performance of our novel image-based 3D shape retrieval approach, we evaluate it on three challenging real-world datasets: Pix3D [50] (bed, chair, sofa, table), Comp [55] (car), and Stanford [55] (car).
Quantitative results show that our approach significantly outperforms the state-of-the-art.
In summary, the key contributions of this work are:
• We propose a novel approach with a cross-modal
Instance-Category loss, which is based on contrastive learning from instance and category levels, for image-based 3D shape retrieval.
• We introduce the color transfer mechanism into con-trastive learning, which is a more powerful color aug-mentation that augmenting training images. It applies another training image as a reference, improving the robustness of the network and helping the network ex-tract color-independent features.
• Our proposed novel approach outperforms the previ-ous state-of-the-arts (SOTAs) on standard real-world benchmark datasets by 4% - 15% on the retrieval ac-curacy. 2.