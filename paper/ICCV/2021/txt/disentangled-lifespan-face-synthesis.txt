Abstract
A lifespan face synthesis (LFS) model aims to generate a set of photo-realistic face images of a person’s whole life, given only one snapshot as reference. The generated face image given a target age code is expected to be age-sensitive reflected by bio-plausible transformations of shape and texture, while being identity preserving. This is ex-tremely challenging because the shape and texture char-acteristics of a face undergo separate and highly nonlin-ear transformations w.r.t. age. Most recent LFS models are based on generative adversarial networks (GANs) whereby age code conditional transformations are applied to a la-tent face representation. They benefit greatly from the re-cent advancements of GANs. However, without explic-itly disentangling their latent representations into the tex-ture, shape and identity factors, they are fundamentally lim-ited in modeling the nonlinear age-related transformation on texture and shape whilst preserving identity.
In this work, a novel LFS model is proposed to disentangle the
*Equal contribution key face characteristics including shape, texture and iden-tity so that the unique shape and texture age transforma-tions can be modeled effectively. This is achieved by ex-tracting shape, texture and identity features separately from an encoder. Critically, two transformation modules, one conditional convolution based and the other channel atten-tion based, are designed for modeling the nonlinear shape and texture feature transformations respectively. This is to accommodate their rather distinct aging processes and ensure that our synthesized images are both age-sensitive and identity preserving. Extensive experiments show that our LFS model is clearly superior to the state-of-the-art al-ternatives. Codes and demo are available on our project website: https://senhe.github.io/projects/ iccv_2021_lifespan_face. 1.

Introduction
What would a young adult look like as an infant and what will she/he resemble in 20 or even 40 years time? Lifespan face synthesis or face aging and rejuvenation aims to answer these questions by synthesizing the face of a person’s whole
life given only a snapshot. It is an intriguing problem but also has many applications, e.g. cross-age face recognition
[25] and finding lost children [36]. It has therefore attracted a great deal of attention recently [38, 37, 7, 31, 43, 24].
Lifespan face synthesis (LFS) is a challenging face at-tribute editing problem. Compared to other face attribute editing works [9, 21, 40] where many attributes such as glasses, hair style and smiling are manipulated with a sin-gle model, LFS focuses on one attribute only, namely age.
However, age editing is arguably the hardest task out of all the attributes. It is thus typically studied on its own. This is because aging is an extremely complex face transformation process. In particular, over the lifespan of a person, the face experiences changes in both shape and texture [20]. Fur-ther, such changes are nonlinear over time and rather differ-ent for shape and texture: a face’s appearance changes are first dominated by shape deformation from baby to young adult because of the growth of bones of skull; such changes then primarily take the form of texture transformation when an adult grows older, e.g. colors of beard and hair, wrinkles.
Therefore, an ideal LFS model must meet three require-ments [7, 31, 43, 24]: (1) Age-sensitive reflected by bio-plausible shape and texture transformations: Given a reference face image and a random target age, the gener-ated face image should have valid shape deformation as well as texture transformation compared to the reference face image. In particular, the highly nonlinear transforma-tions mentioned above need to be respected. (2) Identity-preserving: no matter how large the age gap is between the target and reference, the generated image must depict the same person. (3) Reconfigurable: When the target age is the same as the age of the reference face image, the gener-ated face image should be as similar to the reference image as possible.
However, despite the best efforts of researchers in the past two decades, none of the existing LFS models can meet all three requirements. Before the deep learning era, LFS models are either ‘prototype’ based [35, 34, 14] modeling mean age appearance for different age groups, or ‘physical’ based [33, 34] with explicitly modeling of the underlying biological aging mechanism. The former omits personal-ized information. While the later one requires images of same persons over the whole lifespan which is infeasible to scale. More recent methods [36, 22, 1, 42, 38, 37, 7, 31, 43, 24] benefit from the advancements in deep generative adver-sarial networks (GANs) [5, 2]. Using these methods, a la-tent face representation encompassing information of shape, texture and identity is transformed conditional on the target age before being fed into an image generator. Thanks to the recent breakthroughs in GANs such as Style-GAN [12, 13], these models can now generate incredibly high quality face images. But as shown in Fig. 1, they still fail in one or more of the three requirements.
This is because none of these models can effectively dis-entangle a face representation into shape, texture and iden-tity related parts. Such a disentanglement is crucial for LFS because without the disentanglement, it is impossible to ap-ply different age-conditional manipulations to these differ-ent representations to model the aforementioned nonlinear transformations in shape and texture appearance, whilst be-ing identity-preserving. As a result, it is difficult to avoid unwanted editing. For example, identity can be changed as illustrated in the first row in Fig. 1. Furthermore, some in-compatible transformation may occur, yielding unrealistic effects in the generated images (glasses start to appear in age group 2 of the middle row example).
In this work, for the first time we propose a LFS model that explicitly disentangles a learned latent face representa-tion into shape, texture and identity. Our model is a con-ditional GAN with an encoder-decoder architecture. First, features of different layers of a shared CNN encoder are ex-tracted and subject to different feature extraction modules.
Second, to model the distinct nonlinear transformations on shape and texture with respect to age, two novel feature transformation modules are developed for shape and tex-ture. They are based on conditional convolution and chan-nel attention respectively to reflect the intrinsically differ-ent aging effects on shape and texture. Last but not least, to facilitate the disentanglement of shape and texture, a regu-larization loss is introduced on shape based on the intuition that shape changes are small when an adult is growing older
[30]. As shown in Fig. 1, our disentanglement LFS model can effectively overcome the limitations of the state-of-the-art competitors and meet all three requirements simultane-ously.
The contributions of this paper are as follows: (1) for the first time, we explicitly model the face’s shape, texture and identity characteristics in an end-to-end trained lifes-pan face synthesis (LFS) model. (2) To model the separate nonlinear aging processes on shape and texture, we propose separate shape and texture transformation modules based on conditional convolution and channel attention respectively, as well as a shape regularization loss to facilitate the dis-entanglement. (3) Extensive experiments are carried out to demonstrate that our model is much superior to the state-of-the-art alternatives. 2.