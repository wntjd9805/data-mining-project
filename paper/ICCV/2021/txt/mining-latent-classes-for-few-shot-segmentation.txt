Abstract
Few-shot segmentation (FSS) aims to segment unseen classes given only a few annotated samples. Existing meth-ods suffer the problem of feature undermining, i.e., poten-tial novel classes are treated as background during train-ing phase. Our method aims to alleviate this problem and enhance the feature embedding on latent novel classes. In our work, we propose a novel joint-training framework.
Based on conventional episodic training on support-query pairs, we introduce an additional mining branch that ex-ploits latent novel classes via transferable sub-clusters, and a new rectification technique on both background and fore-ground categories to enforce more stable prototypes. Over and above that, our transferable sub-cluster has the abil-ity to leverage extra unlabeled data for further feature en-hancement. Extensive experiments on two FSS benchmarks demonstrate that our method outperforms previous state-of-the-art by a large margin of 3.7% mIOU on PASCAL-5i and 7.0% mIOU on COCO-20i at the cost of 74% fewer pa-rameters and 2.5x faster inference speed. The source code is available at https://github.com/LiheYoung/
MiningFSS. 1.

Introduction
Advanced by fully convolutional neural networks, se-mantic segmentation has achieved impressive progress [25, 60, 4, 19, 54]. Nevertheless, fully-supervised semantic seg-mentation demands a large amount of pixel-wise annota-tions which are exhaustive to acquire. This problem urges the need for few-shot segmentation where only a handful of annotations are required for novel classes. In this setting, however, methods with conventional training paradigm [25]
*Corresponding author.
†The work of Yinghuan Shi and Lihe Yang was supported by National
Key Research and Development Program of China (2019YFC0118300).
The work of Lei Qi was supported by China Postdoctoral Science Founda-tion funded project (2021M690609).
Figure 1. Illustration of the few-shot segmentation framework and the latent novel classes in the background. Typical FSS setting is only concerned about the current support class, and treats other latent classes as background in each episode of the training. The latent classes, however, are fundamentally different from the real backgrounds, and deserve better exploitation. easily suffer overfitting. In view of this, recent FSS works aim to learn a generic manner from seen classes and adapt to the unseen classes via the few shots, namely supports.
The recent research on few-shot segmentation [38, 59, 50, 24, 47] has gained some progress. Shaban et al. [38] first proposed a siamese network on support-query pairs and alleviated the overfitting problem. Later works developed non-parametric bidirectional alignment mechanisms [50], fine-grained part-aware prototypes [24], multi-scale feature enhancement modules [47] etc.
Despite their success, we notice that these methods rarely exploit the inherent problems of FSS, namely the fea-ture undermining problem and the prototype bias problem: 1) the feature undermining problem is that embeddings of the latent novel classes are over-smoothed when learnt as the background in typical FSS. As shown in Figure 1, only current support class is concerned about in each episode,
the latent novel class person is incorrectly treated as back-ground. 2) The prototype bias problem is caused by the fact that few shots cannot mimic the real class-wise statistics, making it sub-optimal to merely utilize the current supports for prototype estimation. In our work, we aim to exploit the latent novel classes and develop prototypes with less bias to narrow down the gap between few shots and real statistics.
For the exploitation of latent novel class, a related field is the self-supervised learning, that defines pretexts such as solving jigsaws [29], predicting rotations [11] and discrimi-nating instances [14, 5], to mine the unlabeled open set im-ages. These methods, mainly work as pre-trained models and still require sufficient data for other downstream tasks, such as detection, segmentation etc. This is mainly due to that more features on finer scales are required which are not aimed at by current self-supervised techniques. Beyond self-supervised learning, semi-supervised learning also ex-ploits the unlabeled data that has the same category scope with the labeled data. It, however, is not aimed at knowl-edge transfer, and it cannot mine latent classes explicitly which are disjoint with known classes.
For the prototype bias problem, PGNet [56] develops an attention module based on pyramid graphs to fuse support features. PPNet [24] attempts to modify support prototypes based on superpixels from extra samples. However, they do not take full use of whole training set. In addition, the pro-totype bias, i.e. background features from the supports, is rarely tackled exclusively from its inherent characteristics.
In our work, we propose a novel latent class mining strategy with pseudo labeling, and a novel prototype recti-fication technique, based on the metric learning framework on support-query pairwise inputs. We consider every pixel matters in the training set, which implies that even the tem-porally annotated backgrounds can contain novel classes, and an explicit mining can enhance the feature discrimina-tion. In particular, 1) our auxiliary branch exploits latent novel classes from the backgrounds in the training set via semantic sub-clusters transferred from the annotated base classes. More than that, our method can leverage extra un-labeled data for further feature enhancement. Note that, our method is also well fit for more realistic settings, where plenty of additional novel classes may exist due to limited labor for annotation or the fact that novel classes have not been required or discovered while labeling. 2) On the other hand, we propose a novel technique to rectify the proto-types of both the foreground classes and the background. As aforementioned, we suppose background takes much more information than the support prior, and we propose to model the background via broader set, namely the whole training set, via an moving average. In addition, we improve PP-Net [24] by incorporating more stable region features for the foreground prototype rectification.
In summary, our contributions lie in four folds:
• We propose a novel framework that mines latent ob-ject and learns the pairwise metric jointly. Taking ad-vantage of the novel framework, our method can be applied to unseen classes directly without further train-ing or fine-tuning, and meanwhile it does not suffer the feature undermining problem.
• We propose a novel prototype rectification technique to alleviate the prototype bias problem by incorporat-ing a stable global background prototype and relevant foreground region neighbors.
• We conduct extensive experiments proving that our takes fewer parameters, evaluates at faster model speed, and achieves better performance.
• Extension experiments on the unlabeled data from different sources prove that our latent class mining method can exploit unlabeled data and boost the per-formance further. 2.