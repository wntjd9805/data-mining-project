Abstract
Neural Radiance Fields (NeRF) [31] have recently gained a surge of interest within the computer vision community for its power to synthesize photorealistic novel views of real-world scenes. One limitation of NeRF, however, is its re-quirement of accurate camera poses to learn the scene rep-resentations. In this paper, we propose Bundle-Adjusting
Neural Radiance Fields (BARF) for training NeRF from im-perfect (or even unknown) camera poses — the joint problem of learning neural 3D representations and registering cam-era frames. We establish a theoretical connection to classical image alignment and show that coarse-to-ﬁne registration is also applicable to NeRF. Furthermore, we show that naïvely applying positional encoding in NeRF has a negative impact on registration with a synthesis-based objective. Experi-ments on synthetic and real-world data show that BARF can effectively optimize the neural scene representations and re-solve large camera pose misalignment at the same time. This enables view synthesis and localization of video sequences from unknown camera poses, opening up new avenues for visual localization systems (e.g. SLAM) and potential appli-cations for dense 3D mapping and reconstruction. 1.

Introduction
Humans have strong capabilities of reasoning about 3D geometry through our vision from the slightest ego-motion.
When watching movies, we can immediately infer the 3D spatial structures of objects and scenes inside the videos.
This is because we have an inherent ability of associating spatial correspondences of the same scene across continuous observations, without having to make sense of the relative camera or ego-motion. Through pure visual perception, not only can we recover a mental 3D representation of what we are looking at, but meanwhile we can also recognize where we are looking at the scene from.
Simultaneously solving for the 3D scene representation from RGB images (i.e. reconstruction) and localizing the given camera frames (i.e. registration) is a long-standing chicken-and-egg problem in computer vision — recovering
Figure 1: Training NeRF requires accurate camera poses for all images. We present BARF for learning 3D scene repre-sentations from imperfect (or even unknown) camera poses by jointly optimizing for registration and reconstruction. the 3D structure requires observations with known camera poses, while localizing the cameras requires reliable corre-spondences from the reconstruction. Classical methods such as structure from motion (Sf M) [17, 44] or SLAM [13, 32] approach this problem through local registration followed by global geometric bundle adjustment (BA) on both the structure and cameras. Sf M and SLAM systems, however, are sensitive to the quality of local registration and easily fall into suboptimal solutions. In addition, the sparse nature of output 3D point clouds (often noisy) limits downstream vision tasks that requires dense geometric reasoning.
Closely related to 3D reconstruction from imagery is the problem of view synthesis. Though not primarily purposed for recovering explicit 3D structures, recent advances on photorealistic view synthesis have opted to recover an inter-mediate dense 3D-aware representation (e.g. depth [15, 61], multi-plane images [71, 51, 55], or volume density [27, 31]), followed by neural rendering techniques [14, 29, 47, 54] to 1
synthesize the target images. In particular, Neural Radiance
Fields (NeRF) [31] have demonstrated its remarkable ability for high-ﬁdelity view synthesis. NeRF encodes 3D scenes with a neural network mapping 3D point locations to color and volume density. This allows the scenes to be represented with compact memory footprint without limiting the reso-lution of synthesized images. The optimization process of the network is constrained to obey the principles of classical volume rendering [23], making the learned representation interpretable as a continuous 3D volume density function.
Despite its notable ability for photorealistic view synthe-sis and 3D scene representation, a hard prerequisite of NeRF (as well as other view synthesis methods) is accurate cam-era poses of the given images, which is typically obtained through auxiliary off-the-shelf algorithms. One straightfor-ward way to circumvent this limitation is to additionally optimize the pose parameters with the NeRF model via back-propagation. As discussed later in the paper, however, naïve pose optimization with NeRF is sensitive to initialization. It may lead to suboptimal solutions of the 3D scene representa-tion, degrading the quality of view synthesis.
In this paper, we address the problem of training NeRF representations from imperfect camera poses — the joint problem of reconstructing the 3D scene and registering the camera poses (Fig. 1). We draw inspiration from the suc-cess of classical image alignment methods and establish a theoretical connection, showing that coarse-to-ﬁne regis-tration is also critical to NeRF. Speciﬁcally, we show that positional encoding [57] of input 3D points plays a cru-cial role — as much as it enables ﬁtting to high-frequency functions [53], positional encoding is also more susceptible to suboptimal registration results. To this end, we present
Bundle-Adjusting NeRF (BARF), a simple yet effective strat-egy for coarse-to-ﬁne registration on coordinate-based scene representations. BARF can be regarded as a type of photo-metric BA [8, 2, 26] using view synthesis as the proxy objec-tive. Unlike traditional BA, however, BARF can learn scene representations from scratch (i.e. from randomly initialized network weights), lifting the reliance of local registration subprocedures and allowing for more generic applications.
In summary, we present the following contributions:
• We establish a theoretical connection between classical image alignment to joint registration and reconstruc-tion with Neural Radiance Fields (NeRF).
• We show that susceptibility to noise from positional encoding affects the basin of attraction for registration, and we present a simple strategy for coarse-to-ﬁne registration on coordinate-based scene representations.
• Our proposed BARF can successfully recover scene representations from imperfect camera poses, allowing for applications such as view synthesis and localization of video sequences from unknown poses. 2.