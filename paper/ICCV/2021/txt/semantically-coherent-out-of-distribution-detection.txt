Abstract
Dataset-Dependent Out-of-Distribution (DD-OOD) Splitting
!! : CIFAR-10
!" : Tiny-ImageNet
Current out-of-distribution (OOD) detection bench-marks are commonly built by deﬁning one dataset as in-distribution (ID) and all others as OOD. However, these benchmarks unfortunately introduce some unwanted and impractical goals, e.g., to perfectly distinguish CIFAR dogs from ImageNet dogs, even though they have the same se-mantics and negligible covariate shifts.
These unreal-istic goals will result in an extremely narrow range of model capabilities, greatly limiting their use in real appli-cations. To overcome these drawbacks, we re-design the benchmarks and propose the semantically coherent out-of-distribution detection (SC-OOD). On the SC-OOD bench-marks, existing methods suffer from large performance degradation, suggesting that they are extremely sensitive to low-level discrepancy between data sources while ig-noring their inherent semantics. To develop an effective
SC-OOD detection approach, we leverage an external un-labeled set and design a concise framework featured by unsupervised dual grouping (UDG) for the joint model-ing of ID and OOD data. The proposed UDG can not only enrich the semantic knowledge of the model by ex-ploiting unlabeled data in an unsupervised manner, but also distinguish ID/OOD samples to enhance ID classiﬁ-cation and OOD detection tasks simultaneously. Exten-sive experiments demonstrate that our approach achieves the state-of-the-art performance on SC-OOD benchmarks.
Code and benchmarks are provided on our project page: https://jingkang50.github.io/projects/scood. 1.

Introduction
Although dominated on visual recognition [1, 2], deep learning models are still notorious for the following two drawbacks: 1) their performance endures a signiﬁcant drop when test data distribution has a large covariate shift from
Semantically Coherent Out-of-Distribution (SC-OOD) Splitting
!! : CIFAR-10 + Selected Tiny-ImageNet  !" : Remains
Figure 1: Dataset-dependent OOD (DD-OOD) vs. Se-mantically Coherent OOD (SC-OOD). We notice that a certain number of DD-OOD samples have the same seman-tics as ID, with negligible covariate shifts. Here, we redirect these samples back to ID in the SC-OOD setting. training [3]; 2) they tend to recklessly classify a test image into a certain training class, even though it has a semantic shift from training, that is, it may not belong to any training class [4]. Those defects seriously reduce the model trust-worthiness and hinder their deployment in real, especially high-risk applications [5, 6]. To solve the problem, out-of-distribution (OOD) detection aims to distinguish and reject test samples with either covariate shifts or semantic shifts or both, so as to prevent models trained on in-distribution (ID) data from producing unreliable predictions [4].
Existing OOD detection methods mostly focus on cal-ibrating the distribution of the softmax layer [4] through temperature scaling [7], generative models [8, 9], or en-semble methods [10, 11]. Other solutions collect enor-mous OOD samples to learn the ID/OOD discrepancy dur-Table 1: Performance of ODIN [7], MCD [14], and
Energy-Based OOD (EBO) [15] on DD-OOD/SC-OOD settings. Previous methods achieve nearly perfect results on DD-OOD but suffer a drastic drop on SC-OOD. 1
Method
FPR95
AUROC
"
DD SC DD SC DD SC
"
#
AUPR
ODIN (ICLR18) 0.46 55.0
EBO (NeurIPS20) 1.56 50.6 0.01 68.6
MCD (ICCV19) 99.8 88.8 99.5 90.4 99.9 88.9 99.8 84.2 99.4 85.4 99.9 82.1 ing training [12, 13, 14]. Appealing experimental results are achieved by existing methods. For example, MCD [14] reports near-perfect scores across the classic benchmarks.
The OOD detection problem seems completely solved.
However, by scrutinizing the common-used OOD detec-tion benchmarks [4, 7, 13], we discover some irrational-ity on OOD splitting. Under the assumption that differ-ent datasets represent different data distributions, current benchmarks are commonly built by deﬁning one dataset as
ID and all others as OOD. Figure 1-a shows one popular benchmark that uses the entire CIFAR-10 test data as ID and the entire Tiny-ImageNet test data as OOD. However, we observed that around 15% Tiny-ImageNet test samples actually shares the same semantics with CIFAR-10’s ID cat-egories (ref. Section 4). For example, Tiny-ImageNet con-tains six dog-breeds (e.g. golden retriever, Chihuahua) that match CIFAR-10’s class of dog, while their covariate shifts are negligible.
In this case, the perfect performance on the above dataset-dependent OOD (DD-OOD) benchmarks may indicate that models are attempting to overﬁt the low-level discrepancy on the negligible covariate shifts between data sources while ignoring inherent semantics. This fails to meet the requirement of realistic model deployment.
To overcome the drawbacks of the DD-OOD bench-marks, in this work, we re-design semantically coher-ent out-of-distribution detection (SC-OOD) benchmarks, which re-organize ID/OOD set based on semantics and only focus on real images where the covariate shift can be ig-nored, as depicted in Figure 1-b. In this case, the ID set be-comes semantically coherent and different from OOD. Ex-isting methods suffer a large performance degradation on revised SC-OOD benchmarks as shown in Table 1, indicat-ing that the OOD detection problem is still unresolved. 1
For an effective SC-OOD approach, we leverage an ex-ternal unlabeled set like OE [13]. Different from OE [13] whose unlabeled set is purely OOD, our unlabeled set is contaminated by a portion of ID samples. We believe it is 1In Table 1, both DD and SC-OOD benchmarks consider CIFAR-10 as
ID and Tiny-ImageNet as OOD. All methods are tested using their released
DenseNet models. AUPR corresponds to AUPR-Out in Section 4. a more realistic setting, as a powerful image crawler can easily prepare millions of unlabeled data but will inevitably introduce ID samples that are expensive to be puriﬁed.
With a realistic unlabeled set for SC-OOD, we design an elegant framework featured by unsupervised dual group-ing (UDG) for the joint modeling of labeled and unlabeled data. The proposed UDG enhances the semantic expres-sion ability of the model by exploring unlabeled data with an unsupervised deep clustering task, and the grouping in-formation generated by the auxiliary task can also dynami-cally separate the ID and OOD samples in the unlabeled set.
ID samples separated from the unlabeled set will join other given ID samples for classiﬁer training, and the rest will be forced to produce a uniform posterior distribution like other
OE methods [13]. In this way, ID classiﬁcation and OOD detection performances are simultaneously improved.
To summarize, the contributions of our paper are: 1)
We highlight the problem of current OOD detection bench-marks and re-design them to address semantic coherency in out-of-distribution detection. 2) A concise framework us-ing realistic unlabeled data is proposed, featuring the un-supervised dual grouping which not only enriches the se-mantic knowledge of the model in an unsupervised man-ner, but also distinguishes ID/OOD samples to enhance ID classiﬁcation and OOD detection tasks simultaneously. 3)
Extensive experiments demonstrate our approach achieves state-of-the-art performance on SC-OOD benchmarks. 2.