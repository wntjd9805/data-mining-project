Abstract
Person Re-IDentiﬁcation (ReID) aims at re-identifying persons from non-overlapping cameras. Existing person
ReID studies focus on horizontal-view ReID tasks, in which the person images are captured by the cameras from a (nearly) horizontal view. In this work we introduce a new
ReID task, bird-view person ReID, which aims at searching for a person in a gallery of horizontal-view images with the query images taken from a bird’s-eye view, i.e., an elevated view of an object from above. The task is important because there are a large number of video surveillance cameras cap-turing persons from such an elevated view at public places.
However, it is a challenging task in that the images from the bird view (i) provide limited person appearance information and (ii) have a large discrepancy compared to the persons in the horizontal view. We aim to facilitate the develop-ment of person ReID from this line by introducing a large-scale real-world dataset for this task. The proposed dataset, named BV-Person, contains 114k images of 18k identities in which nearly 20k images of 7.4k identities are taken from the bird’s-eye view. We further introduce a novel model for this new ReID task. Large-scale experiments are performed to evaluate our model and 11 current state-of-the-art ReID models on BV-Person to establish performance benchmarks from multiple perspectives. The empirical results show that our model consistently and substantially outperforms the state-of-the-art models on all ﬁve datasets derived from
BV-Person. Our model also achieves state-of-the-art per-formance on two general ReID datasets. The BV-Person dataset is available at: https://git.io/BVPerson 1.

Introduction
Person Re-IDentiﬁcation (ReID) aims at searching the images of the same person across non-overlapping cameras.
The task has been widely studied, achieving great progress
*CY and GP equally contributed to this work.
†Corresponding author, e-mail: jile.jjl@alibaba-inc.com
Figure 1 – (A) Horizontal-view ReID vs. (B) Bird-view ReID.
In (A), the images from both of the query and gallery sets are captured from a (nearly) horizontal view, in which the angle be-tween the horizontal ground and the line from camera to person is small (less than 40o). By contrast, in (B), the query images are captured from an elevated view, in which the correspond-ing angle is large (e.g., larger than 80o). The large discrepancy between these two views makes the bird-view ReID task partic-ularly challenging. in the last few years [3, 6, 9, 12, 16, 19, 20, 24, 26, 28, 31, 32, 37, 38, 40, 41, 43]. Existing person ReID studies focus on horizontal-view based re-identiﬁcation, in which all the images are captured by the cameras that are in nearly the same horizontal line with persons. That is, the camera and the person are nearly at the same horizontal level, with a small angle (less than 40o) between the line from camera to person and the ground (see Figure 1(A)). The horizontal-view images often present the whole body of the person and each part of the body is distributed evenly in the image.
In this work we introduce a new ReID task, bird-view person ReID, which aims at searching for a person in a gallery of horizontal-view images with the query images taken from a bird’s-eye view, i.e., an elevated view of an object from above (see Figure 1(B)). The task is important because there are a large number of video surveillance cam-eras capturing persons from such an elevated view at pub-lic places, such as cashier-less stores, ATM machines, the check-out/check-in point of hotels and supermarkets, for safety and security purposes. However, the bird-view ReID is particularly challenging in that the images from the bird view (i) provide limited person appearance information and (ii) have a large discrepancy compared to the persons in the horizontal view. These challenges are due to the large an-gle between the line from camera to person and the ground (e.g., larger than 80o), as illustrated in Figure 1(B).
Although there is increasing application demand of bird-view ReID, to our best knowledge, no results have been reported in this research line. A related task is Occluded
ReID [8, 9, 11, 13, 16, 22, 29, 33, 46, 48, 49] as bird-view
ReID is similar to the problem of matching the head and shoulder parts with the lower body parts ‘occluded’ by the upper body parts. One fundamental difference here is that in bird-view ReID, there does not exist occlusion objects as in occluded ReID. As a result, occluded ReID models are fo-cused on handling different occlusion objects, whereas bird-view ReID does not involve occlusion objects and focuses on learning person features that can well generalize from the horizontal view to the bird’s-eye view.
To facilitate the development of bird-view ReID, we
ﬁrst introduce a large-scale dataset for this task, termed
BV-Person, which contains 114k images of 18k identi-ties, with nearly 20k images of 7.4k identities captured un-der the bird’s-eye view. We then divide BV-Person into
ﬁve datasets of different problem complexities, providing testbeds for diverse application scenarios. We further ana-lyze the major challenges presented in this task and propose a novel model with three modules speciﬁcally designed to learning discriminative features for bird-view ReID. In summary, this work makes four major contributions:
• We introduce a new and critical person ReID task, bird-view ReID, which aims to re-identify persons across multiple cameras with the query images taken from an elevated view of the persons. The task has im-portant applications in different domains but presents some unique challenges to the current ReID models due to the large discrepancy of the persons under the normal view and the bird view.
• We create the ﬁrst dataset for bird-view ReID to facil-itate and promote the development and evaluation of models in this line. The proposed dataset, called BV-Person, contains 114k images from 18k persons, in-cluding 20k images from 7.4k persons taken from the bird’s-eye view in diverse scenes and angles.
• We propose a novel multi-scale cross attention-based model that learns to attend to discriminative body parts shared by diverse images of the same identity from a single view or both views. The resulting model sub-stantially reduces the feature discrepancy between the bird view and the horizontal view.
• Large-scale empirical evaluation is performed to eval-uate our model and 11 existing state-of-the-art ReID models on BV-Person to establish performance bench-marks from multiple perspectives.
Our large-scale evaluation results show that our model outperforms the 11 state-of-the-art ReID models by 4.2%-9.3% in R-1 and 2.8%-9.6% in mAP across ﬁve different settings of our BV-Person dataset. Additionally, our model also performs comparatively good to the recently proposed models on two general ReID benchmarks, indicating its good applicability in diverse real-world application settings. 2.