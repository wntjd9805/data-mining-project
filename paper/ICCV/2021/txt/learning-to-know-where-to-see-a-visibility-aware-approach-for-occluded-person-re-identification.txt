Abstract
Person re-identification (ReID) has gained an impressive progress in recent years. However, the occlusion is still a common and challenging problem for recent ReID methods.
Several mainstream methods utilize extra cues (e.g., human pose information) to distinguish human parts from obsta-cles to alleviate the occlusion problem. Although achieving inspiring progress, these methods severely rely on the fine-grained extra cues, and are sensitive to the estimation error in the extra cues. In this paper, we show that existing meth-ods may degrade if the extra information is sparse or noisy.
Thus we propose a simple yet effective method that is robust to sparse and noisy pose information. This is achieved by discretizing pose information to the visibility label of body parts, so as to suppress the influence of occluded regions.
We show in our experiments that leveraging pose informa-tion in this way is more effective and robust. Besides, our method can be embedded into most person ReID models easily. Extensive experiments validate the effectiveness of our model on common occluded person ReID datasets. 1.

Introduction
Person re-identification (ReID) [6, 26] aims to match im-ages of a person across disjoint cameras, which is widely used in video surveillance, security and smart city. Despite the great progress in the recent years, there is still some practical problems that remain unsolved. Especially, occlu-sion [31] is one common problem that deteriorates the per-son ReID performance in real-word scenarios. In practice, people can be easily occluded by some obstacles (e.g. bag-gage, counters, cars, trees) or walk out of the camera fields,
*Corresponding author: Wei-Shi Zheng, Xing Sun
Figure 1. (a), (b) illustrate the relationship between the pose gran-ularity and the estimation error on existing person ReID datasets using the off-the-shelf pose estimator. The existing state-of-the-art methods heavily rely on the fine-grained pose cues but suffer noisy pose detections. Thus, they are hard to directly learn an occlusion-robust feature. (c) illustrates our basic idea. Our model learns a robust mapping from imperfect pose cues to the visibility of body parts to alleviate the effect of occlusion. making the prediction results prone to error.
In recent years, plenty of efforts [31, 32, 17, 4, 21, 11] have been made to solve this occluded person ReID prob-lem. Usually, they adopt extra cues, such as pose or human parsing, to assist in judging the occlusion scenarios. How-ever, these methods assume the existence of fine-grained and error-free extra cues, which is difficult to achieve in practical scenarios. For example, [17, 4] utilizes 18 pose keypoints. And if we use less keypoints, the performance could drop. However, such fine-grained keypoints may come with high estimation error in practice. As illustrated in Fig. 1 (a) to (b), we can see that as the granularity of pose improves, the estimation error also increases, and the estimation error may degrade the robustness of the existing
ReID model. In this paper, we aim to find a solution to han-dle the occlusion problem without heavily relying on the pose information, i.e., it can achieve comparable/superior performance with coarse pose information.
2.