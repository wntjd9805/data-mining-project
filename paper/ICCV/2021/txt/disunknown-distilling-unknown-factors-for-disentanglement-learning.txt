Abstract
Disentangling data into interpretable and independent factors is critical for controllable generation tasks. With the availability of labeled data, supervision can help en-force the separation of specific factors as expected. How-ever, it is often expensive or even impossible to label every single factor to achieve fully-supervised disentanglement.
In this paper, we adopt a general setting where all factors that are hard to label or identify are encapsulated as a sin-gle unknown factor. Under this setting, we propose a flexi-ble weakly-supervised multi-factor disentanglement frame-work DisUnknown, which Distills Unknown factors for en-abling multi-conditional generation regarding both labeled and unknown factors. Specifically, a two-stage training approach is adopted to first disentangle the unknown fac-tor with an effective and robust training method, and then train the final generator with the proper disentanglement of all labeled factors utilizing the unknown distillation. To demonstrate the generalization capacity and scalability of our method, we evaluate it on multiple benchmark datasets qualitatively and quantitatively and further apply it to vari-ous real-world applications on complicated datasets. 1.

Introduction
Disentanglement learning is the task of breaking down the tangled high-dimensional data variation into inter-pretable factors. In the desired disentangled representation, each dimension corresponds to a distinct factor of variables, such that when one factor changes, the others remain unaf-fected [3]. Disentanglement learning thus enables various downstream tasks such as transfer learning and few-shot learning, as well as challenging controllable image synthe-sis applications (e.g. [47, 14]).
With the availability of fully-labeled data, supervised disentanglement has seen much progress [29, 38, 15, 1, 14].
However, ground-truth labels are not always accessible,
*Corresponding author. while even human labeling could be prohibitively expen-sive or inconsistent. Thus, fully-supervised approaches of-ten have a hard time generalizing to common scenarios where labels are only partially available or even entirely missing. In light of this, unsupervised disentanglement ap-proaches [10, 20, 27, 50, 42] have been proposed to address these challenges. However, most of them rely on the strong assumption that the target data is well-structured enough to be cleanly decoupled into explanatory and recoverable factors. And more importantly, there is no guarantee that these factors could be explicitly controlled with respect to the true intended semantics in specific manipulation scenar-ios. Therefore, weakly-supervised disentanglement, a nice mix of the best of both worlds, has recently become popu-lar for more flexible learning [29, 45, 8, 17]. Unfortunately, although state-of-the-art performance is achieved on certain two-factor class-content disentanglement tasks [8, 17], most existing methods in this category are still unable to extract factor-aware latent representation, which is essential for manipulating individual factors especially when multiple ones are presented. In conclusion, no solution seems com-pletely satisfactory yet on multi-factor disentanglement, due to the limited generalizability and insufficient performance.
In this paper, we propose a weakly-supervised multi-factor disentanglement learning framework, which handles arbitrary numbers of factors through explicit and near-orthogonal latent representation. Given that challenging factors that are hard to label or interpret exist in most tasks, the key idea to our approach is a general setting of N -factor disentanglement with N âˆ’ 1 factors labeled and a single factor unknown, where all the remaining task-irrelevant or difficult-to-label factors are flexibly encapsulated as one un-known factor. We find such a setting highly effective and practical in real scenarios. Take face motion retargeting as an example, facial expression could be a good candidate for the unknown factor since it is much more difficult to pre-cisely label than others such as the identity and the pose.
Thanks to its flexibility, our method naturally adapts to var-ious tasks with varying domains (e.g. cartoon and real pho-tos), data types (e.g. images, skeletons, and landmarks), in-tegrity (well-structured or in-the-wild), and label continuity (discrete or continuous).
To this end, our framework consists of two major stages: 1) Unknown Factor Distillation and 2) Multi-Conditional
Generation. Specifically, we extract the unknown factor us-ing an adversarial training method in the first stage, and then embed all labeled factors to the latent space as the second stage, which are used to condition the final generation. The core of our method lies in the joint adversarial training of factor encoders and discriminative classifiers, which explic-itly disentangles unknown and known factors without intro-ducing leakage between their disentangled representations.
The performance of our approach is extensively evalu-ated on several benchmark datasets, both qualitatively and quantitatively. Furthermore, we demonstrate the general-ization capacity and practical robustness of the framework on multiple challenging tasks using complicated real-world datasets without any additional manual labeling effort.
Our contributions are: 1) A flexible weakly-supervised disentanglement learning framework that models data as a combination of labeled/unlabeled factors, which scales well to different datasets and benefits various challenging tasks; 2) A two-stage training architecture that explicitly learns disentangled representations for both labeled and unknown semantic factors, enabling mutual exclusive manipulation in the dimension of each factor; 3) A set of learning strategies to improve the effectiveness and robustness of adversarial training throughout our pipeline, which could potentially inspire future research; 4) State-of-the-art performance and wide range of practical uses on multiple challenging tasks including controllable image generation. 2.