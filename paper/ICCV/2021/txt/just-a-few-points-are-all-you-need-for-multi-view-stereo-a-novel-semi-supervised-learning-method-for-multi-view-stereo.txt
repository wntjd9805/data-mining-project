Abstract
While learning-based multi-view stereo (MVS) methods have recently shown successful performances in quality and efﬁciency, limited MVS data hampers generalization to un-seen environments. A simple solution is to generate vari-ous large-scale MVS datasets, but generating dense ground truth for 3D structure requires a huge amount of time and resources. On the other hand, if the reliance on dense ground truth is relaxed, MVS systems will generalize more smoothly to new environments. To this end, we ﬁrst intro-duce a novel semi-supervised multi-view stereo framework called a Sparse Ground truth-based MVS Network (SGT-MVSNet) that can reliably reconstruct the 3D structures even with a few ground truth 3D points. Our strategy is to divide the accurate and erroneous regions and individu-ally conquer them based on our observation that a proba-bility map can separate these regions. We propose a self-supervision loss called the 3D Point Consistency Loss to enhance the 3D reconstruction performance, which forces the 3D points back-projected from the corresponding pixels by the predicted depth values to meet at the same 3D co-ordinates. Finally, we propagate these improved depth pre-dictions toward edges and occlusions by the Coarse-to-ﬁne
Reliable Depth Propagation module. We generate the spare ground truth of the DTU dataset for evaluation and exten-sive experiments verify that our SGT-MVSNet outperforms the state-of-the-art MVS methods on the sparse ground truth setting. Moreover, our method shows comparable recon-struction results to the supervised MVS methods though we only used tens and hundreds of ground truth 3D points. 1.

Introduction
Multi-view Stereo (MVS) has been an important prob-lem in computer vision, which reconstructs dense 3D geom-etry from multi-view images. The industrial applicability of (a) Dense ground truth (b) Sparse ground truth (1 × 10−5) (c) Point-MVSNet (Dense GT) (d) Ours (Sparse GT)
Figure 1: Visualization of a dense ground truth and our sparse ground truth of scan14, and multi-view reconstruc-tion results of scan13 of the DTU dataset [7] by Point-MVSNet [1] trained with dense ground truths and our SGT-MVSNet trained with sparse ground truths. This sparse ground truth generated by random sampling with 1 × 10−5 ratio contain around 30 to 40 3D points. Note that original dense ground truth 3D structures consist of approximately 3 × 106 points. 3D reconstruction such as autonomous driving and robotics has attracted extensive research for decades. Recent MVS studies [15, 16, 1, 17, 11] successfully incorporate tradi-tional approaches to the learning-based methods and im-prove 3D reconstruction quality under the blessing of the
MVS datasets [7, 10]. However, contrary to such increas-ing dependence on datasets, there have been fundamental difﬁculties in collecting dense ground truth 3D structures, which eventually hamper the generalization to unseen do-mains. Speciﬁcally, collecting an accurate and completed ground truth 3D structure generally takes several hours with a ﬁxed active sensor. And the collection process even re-quires a subsequent labor-intensive post-process to remove outliers like dynamic objects which move through the ﬁeld of view during the collection period [7, 10]. These harsh conditions are not available on dynamic places like a road.
Thus, a semi-supervised multi-view stereo algorithm, which can be trained even with incomplete ground truth 3D struc-ture, is necessary to ease the generalization of the model on the unseen environment.
In this paper, we ﬁrst explore a novel semi-supervised
MVS problem called a Sparse Ground truth-based MVS (SGT-MVS) problem, which assumes that only the sparse ground truth 3D structure is available for training. We ﬁrst investigate its fundamental characteristics to discover key aspects for solving the SGT-MVS problem. Speciﬁcally, though the relatively scarce depth information inevitably degrades the 3D reconstruction quality overall, the system-atic depth reasoning principle of MVS enables the MVS networks to reasonably estimate depth values on the non-occluded region even with a few ground truth 3D points.
Nevertheless, the depth reasoning principle fundamentally suffers from prediction difﬁculties in occluded pixels of the given multi-view images and edge pixels. Learning-based
MVS methods are able to solve these difﬁculties using the contextual information of the nearby non-occluded regions for the occluded pixels and highly discriminative features for the edge pixels since they can directly supervise the ex-act depth values on the occluded regions or edges. Sparse ground truth basically cannot guarantee the contextual and highly discriminative features to such level.
Based on our observations, we focus on improving the discriminability on the accurately predicted non-occluded regions while propagating the accurate depth values to edges, occlusions, and erroneous non-occluded regions. We use a probability map to detect theses erroneous regions since the MVS network cannot determine a certain depth value due to the fundamental prediction difﬁculty. Thus, by treating the probability like a conﬁdence map, we ﬁrst separate the accurately predicted regions and erroneous re-gions according to the probability value. Then, we apply loss function named 3D Point Consistency Loss to enhance the 3D reconstruction performance on the accurately pre-dicted region by regressing the 3D points back-projected from the corresponding pixels to actually meet in the 3D world, where the back-projection means a transformation from a pixel in an image plane to a 3D point in a world frame. Since the corresponding pixels are likely to be back-projected into the distinctive 3D points due to the inaccu-rate depth values, it is reasonable to match them in the 3D world for better reconstruction quality. Finally, we propa-gate these improved predictions toward the low conﬁdence regions through our Coarse-to-ﬁne Reliable Depth Propaga-tion module. To verify our method on the semi-supervised
SGT-MVS problem, we generate sparse ground truth from the original dense 3D structures by randomly sampling at ratios of 1 × 10−5 and 1 × 10−4. As shown in Fig. 1, while original dense ground truth 3D structures consist of approx-imately 3×106 points, our sparse ground truth 3D structures only consist of tens and hundreds of 3D points, respectively, for each 3D structure. We compared our SGT-MVSNet with the state-of-the-art MVS networks on the same sparse ground truth and conﬁrm that our method can succesfully solve the SGT-MVS problem. Moreover, SGT-MVSNet matches the capacity of other state-of-the-art MVS net-works, though we only used tens and hundreds of ground truth 3D points.
To summarize, our contributions are threefold:
• We ﬁrst introduce a novel semi-supervised multi-view stereo problem called Sparse Ground truth-based MVS (SGT-MVS) problem.
• We introduce SGT-MVSNet, a semi-supervised MVS framework suitable for the sparse ground truth that consists of the 3D Point Consistency Loss and the
Coarse-to-ﬁne Reliable Depth Propagaion module.
• Extensive experiments verify that our method success-fully solve the semi-supervised MVS problem with the sparse ground truth. The reconstruction performance of SGT-MVSNet is comparable to the supervised MVS methods even though we only used a few points. 2.