Abstract
Interpreting the decision logic behind effective deep con-volutional neural networks (CNN) on images complements the success of deep learning models. However, the existing methods can only interpret some speciﬁc decision logic on individual or a small number of images. To facilitate hu-man understandability and generalization ability, it is im-portant to develop representative interpretations that inter-pret common decision logics of a CNN on a large group of similar images, which reveal the common semantics data contributes to many closely related predictions. In this pa-per, we develop a novel unsupervised approach to produce a highly representative interpretation for a large number of similar images. We formulate the problem of ﬁnding rep-resentative interpretations as a co-clustering problem, and convert it into a submodular cost submodular cover prob-lem based on a sample of the linear decision boundaries of a
CNN. We also present a visualization and similarity ranking method. Our extensive experiments demonstrate the excel-lent performance of our method. 1.

Introduction
Interpretability becomes more and more important for machine learning [40, 48]. As a fundamental deep learn-ing model, the interpretability of convolutional neural net-works (CNNs) [26, 34] has been intensively explored [9, 45, 47, 50, 61, 72]. For example, many interpretation meth-ods [12, 48, 50, 56] have been proposed to interpret the spe-ciﬁc decision logic of a CNN on a single input image or a small group of images. However, the challenge of inter-pretation on CNNs for image classiﬁcation is still far from being settled. An interpretation accommodating only one individual image or a small group of images is highly sen-sitive to the noise contained in the interpreted image [20],
*Peter Cho-Ho Lam and Lingyang Chu contribute equally in this work.
Please refer to [35] for the complete version of this paper. and thus cannot be robustly reused to interpret the predic-tions on a large group of unseen images [3, 16, 57].
To tackle the challenge, we advocate seeking represen-tative interpretations [7], which interpret the common de-cision logic of a CNN. A representative interpretation is more convincing, because it can be validly reused to inter-pret the same decision logic that governs the predictions on a large number of unseen images [7]. Moreover, a repre-sentative interpretation also provides a deeper insight into the common semantic of a large number of similar im-ages [21, 32, 70]. Such common semantics are generally believed to be captured by CNNs to achieve excellent pre-diction performance [18, 72, 73].
However, interpreting the common decision logic of a
CNN on a large group of similar images in an unsupervised manner is a novel problem that has not been systematically studied in literature [21]. Can we straight-forwardly extend the existing interpretation methods to produce representa-tive interpretations on a CNN? Unfortunately, many exist-ing methods [9, 12, 45, 50, 48] focus on interpreting the speciﬁc decision logic of a CNN on a single input image or a small group of images, and thus cannot produce represen-tative interpretations. More critically, it is difﬁcult to pro-duce a representative interpretation without knowing a large group of similar images that are predicted by a common decision logic of a CNN. As discussed in Section 2, some concept-based interpretation methods summarize the com-mon decision-making concepts from a group of conceptu-ally similar images. However, those methods are either lim-ited to sophisticatedly customized CNN models [11, 70], or require a large set of conceptually annotated images [18, 73] that are too expensive to obtain in most real world applica-tions [21].
In this paper, we propose the novel unsupervised task of
ﬁnding representative interpretations on convolutional neu-ral networks. The goal is to ﬁnd and visualize the common decision logic of a CNN that governs the predictions on an input image and a large set of similar images. We make a series of technical contributions as follows.
We model the common decision logic of a CNN on a group of similar images as a decision region formed by a set of pieces of the decision boundaries of the CNN. All images contained in this decision region are predicted as the same class by the same decision logic characterized by the decision boundary pieces. We formulate our task as a co-clustering problem to simultaneously ﬁnd the largest group of similar images and the corresponding decision region containing them. We further convert the co-clustering prob-lem into an NP-hard submodular cost submodular cover problem, and develop an efﬁcient heuristic method to solve it without requiring any conceptual image annotations or any modiﬁcations to CNNs. To produce understandable in-terpretations for the images contained in a decision region, we visualize the boundaries of the decision region as heat maps to identify important image regions for predictions.
We also rank the similar images according to their seman-tic distances to the input image. Last, we conduct exten-sive experiments to examine the interpretation quality and reusability of our representative interpretations. 2.