Abstract
The recently proposed Detection Transformer (DETR) model successfully applies Transformer to objects detec-tion and achieves comparable performance with two-stage object detection frameworks, such as Faster-RCNN. How-ever, DETR suffers from its slow convergence. Training
DETR [4] from scratch needs 500 epochs to achieve a high accuracy. To accelerate its convergence, we propose a sim-ple yet effective scheme for improving the DETR framework, namely Spatially Modulated Co-Attention (SMCA) mech-anism. The core idea of SMCA is to conduct location-aware co-attention in DETR by constraining co-attention responses to be high near initially estimated bounding box locations. Our proposed SMCA increases DETR’s conver-gence speed by replacing the original co-attention mech-anism in the decoder while keeping other operations in
DETR unchanged. Furthermore, by integrating multi-head and scale-selection attention designs into SMCA, our fully-fledged SMCA can achieve better performance compared to DETR with a dilated convolution-based backbone (45.6 mAP at 108 epochs vs. 43.3 mAP at 500 epochs). We perform extensive ablation studies on COCO dataset to validate SMCA. Code is released at https://github. com/gaopengcuhk/SMCA-DETR. 1.

Introduction
The recently proposed DETR [4] has significantly sim-plified object detection pipeline by removing hand-crafted anchor [33] and non-maximum suppression (NMS) [2].
However, the convergence speed of DETR is slow com-pared with two-stage [13, 12, 33] or one-stage [25, 31, 23] detectors (500 vs. 40 epochs). Slow convergence of DETR makes it difficult for researchers to further extend the algo-rithm and thus hinders its widespread usage.
In DETR, there are a series of object query vectors re-sponsible for detecting objects at different spatial locations.
Each object query interacts with the spatial visual features
Figure 1. Comparison of DETR-DC5 trained for 500 epochs, and our proposed SMCA trained for 50 epochs and 108 epochs. The convergence speed of the proposed SMCA is faster than DETR. encoded by a Convolution Neural Network (CNN) [16], adaptively collects information from spatial locations with a co-attention mechanism, and then estimates the bound-ing box locations and object categories. However, in the decoder of DETR, the co-attended visual regions for each object query might be unrelated to the bounding box to be predicted by the query. Thus the decoder of DETR needs long training epochs to search for the properly co-attended regions to accurately identify the corresponding objects.
Motivated by this observation, we propose a novel module named Spatially Modulated Co-attention (SMCA), which is a plug-and-play module to replace the existing co-attention mechanism in DETR and achieves faster con-vergence and improved performance with simple modifi-cations. The proposed SMCA dynamically predicts ini-tial center and scale of the box corresponding to each ob-ject query to generate a 2D spatial Gaussian-like weight map. The weight map is element-wisely multiplied with the co-attention feature maps of object query and image fea-tures to more effectively aggregate query-related informa-tion from the visual feature map. In this way, the spatial weight map effectively modulates the search range of each object query’s co-attention to be properly around the ini-tially estimated object center and scale. By leveraging the predicted Gaussian-distributed spatial prior, our SMCA can significantly speed up the training of DETR.
Although naively incorporating the spatially-modulated co-attention mechanism into DETR speeds up the conver-gence, the performance is worse compared with DETR (41.0 mAP at 50 epochs, 42.7 at 108 epochs vs. 43.3 mAP at 500 epochs). Motivated by the effectiveness of multi-head attention-based Transformer [38] and multi-scale fea-ture [22] in previous research work, our SMCA is further augmented with the multi-scale visual feature encoding in the encoder and the multi-head attention in the decoder. For multi-scale visual feature encoding in the encoder, instead of naively rescaling and upsampling the multi-scale features from the CNN backbone to form a joint multi-scale feature map, Intra-scale and multi-scale self-attention mechanisms are introduced to directly and efficiently propagate infor-mation between the visual features of multiple scales. For the proposed multi-scale self-attention, visual features at all spatial locations of all scales interact with each other via self-attention. However, as the number of all spatial loca-tions at all scales is quite large and leads to large compu-tational cost, we introduce the intra-scale self-attention to alleviate the heavy computation. The properly combined intra-scale and multi-scale self-attention achieve efficient and discriminative multi-scale feature encoding. In the de-coder, each object query can adaptively select features of proper scales via the proposed scale-selection attention. For the multiple co-attention heads in the decoder, all heads es-timate head-specific object centers and scales to generate a series of different spatial weight maps for spatially modu-lating the co-attention features. Each of the multiple heads aggregates visual information from slightly different loca-tions and thus improves the detection performance.
Our SMCA is motivated by the following research.
DRAW [14] proposed a differential read-and-write opera-tor with dynamically predicted Gaussian sampling points.
We summarize our contributions below: 1) We propose a novel Spatial Modulated Co-Attention (SMCA), which can accelerate the convergence of DETR by conducting location-constrained object regression. SMCA is a plug-and-play module in the original DETR. The basic version of SMCA without multi-scale features and multi-head at-tention can already achieve 41.0 mAP at 50 epochs and 42.7 mAP at 108 epochs.
It takes 265 V100 GPU hours to train the basic version of SMCA for 50 epochs. 2) Our full SMCA further integrates multi-scale features and multi-head spatial modulation, which can further significantly im-prove and surpass DETR with much fewer training itera-tions. SMCA can achieve 43.7 mAP at 50 epochs and 45.6 mAP at 108 epochs, while DETR-DC5 achieves 43.3 mAP at 500 epochs. It takes 600 V100 GPU hours to train the full SMCA for 50 epochs. 3) We perform extensive abla-tion studies on COCO 2017 dataset to validate the proposed
SMCA module and the network design. 2.