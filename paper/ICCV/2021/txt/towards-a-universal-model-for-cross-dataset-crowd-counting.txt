Abstract
This paper proposes to handle the practical problem of learning a universal model for crowd counting across scenes and datasets. We dissect that the crux of this prob-lem is the catastrophic sensitivity of crowd counters to scale shift, which is very common in the real world and caused by factors such as different scene layouts and image reso-lutions. Therefore it is difﬁcult to train a universal model that can be applied to various scenes. To address this prob-lem, we propose scale alignment as a prime module for es-tablishing a novel crowd counting framework. We derive a closed-form solution to get the optimal image rescaling factors for alignment by minimizing the distances between their scale distributions. A novel neural network together with a loss function based on an efﬁcient sliced Wasser-stein distance is also proposed for scale distribution es-timation. Beneﬁting from the proposed method, we have learned a universal model that generally works well on sev-eral datasets where can even outperform state-of-the-art models that are particularly ﬁne-tuned for each dataset sig-niﬁcantly. Experiments also demonstrate the much better generalizability of our model to unseen scenes. 1.

Introduction
Recently, crowd counting has drawn great attention since it has a variety of applications in the real world. Count-ing people in the crowd is a challenging task due to se-∗Corresponding author
Acknowledgements. This work is funded by National Key Research and
Development Project of China under Grant No. 2020AAA0105600 and 2019YFB1312000, National Natural Science Foundation of China under
Grant No. 62006183 and 62076195, China Postdoctoral Science Founda-tion under Grant No. 2020M683489, and the Fundamental Research Funds for the Central Universities under Grant No. xzy012020013. (a) (b)
Figure 1. (a) Scale distributions (in log-domain) of crowds in four different datasets (before alignment). (b) Scale distributions aligned by our method. Note that there exist signiﬁcant scale shifts within and across the datasets before alignment, while the distri-butions can be well aligned through our method. vere occlusions and large scale variations of objects caused by factors such as different scene layouts, image resolu-tions, and viewpoint changes. State-of-the-art crowd coun-ters [55, 44, 28] usually pre-train deep neural networks on large-scale classiﬁcation datasets like ImageNet [9] and then particularly ﬁne-tune for each crowd counting dataset.
Despite the fact that signiﬁcant progress has been made, ex-isting methods usually follow the training-testing protocol within a single dataset and suffer from signiﬁcant cross-dataset performance degeneration. On the one hand, the accuracy drops a lot when models are applied to unseen datasets (Table. 6). On the other hand, the model jointly trained on multiple datasets is often inferior to models speciﬁcally learned on each dataset (Table. 2), even though much more training images are used. Such poor general-izability of existing crowd counters has seriously restricted their applications in the real scenario.
This paper proposes the practical problem of universal cross-dataset crowd counting for real-world applications.
The goal is to effectively absorb knowledge from more training data to improve the counting performance and re-duce deployment cost by obtaining a universal model that can be applied to various scenes. Even though generaliza-tion poses a challenge for any machine learning problem, it is especially grievous for crowd counting in two critical respects.
First of all, human annotation is highly labor-intensive for crowd counting, where scenes could be over-crowded with severe occlusions. According to [14], the entire anno-tation process of UCF-QNRF involved 2,000 human-hours to its completion merely for 1,535 images. Datasets re-leased before that are even much smaller [13, 60]. Due to such a small volume of some existing datasets, the learned crowd counters may easily suffer from overﬁtting to some extent [50]. Moreover, crowd density and scale distribu-tions often vary substantially from scene to scene, and even for different subareas within the same image due to factors such as different scene layouts and perspective effects. For example, the image resolution in UCF-QNRF [14] ranges from 0.08 to 66.65 megapixels, where the number of per-sons contained ranges from 49 to 12,865. The scale vari-ation becomes severe when we take into account multiple datasets together. As shown in Fig. 1(a), there exists a sig-niﬁcant scale shift between different datasets, and the aver-age resolution of UCF-QNRF [14] is three times about that of Shanghai A [60] ( Table. 1).
Because of such scale shift and data bias, it is difﬁcult to directly train a universal model using images from multiple sources.
To further clarify this problem, we investigate how ro-bust crowd counting is against scale shift quantitatively.
We test the performance of a state-of-the-art crowd counter
BL [28] concerning simple image rescaling. We rescale the testing images of UCF-QNRF from 0.75 to 1.5 and dis-sect how this can affect the models trained on images with their original resolutions, i.e., scale is shifted from −25% to +50%. The experimental results are catastrophic as can be seen from Fig. 2. For instance, the MAE of BL [28] in-creases more than 10 points from 88.7 to 100.3 and 103.5 when scales are shifted by −25% and +50%, respectively.
Moreover, there is still a loss of accuracy by 3 points even if we slightly enlarge (+15% shift) images, albeit such a slight ampliﬁcation does not introduce signiﬁcant distortion visually or any information loss.
Inspired by the fact that facial analysis tasks such as face recognition [43, 33] and expression estimation [3] of-ten beneﬁt from face alignment before analyzing the face in unconstrained environments, we indicate a prime mod-ule (termed scale alignment) before counting crowds in the scene. Such a step aims to align scale distributions to fa-cilitates learning a single model in various scenes. We ﬁrst calculate the scale distributions of all scenes and then nor-malize them to a “standard” one, which is represented by the Wasserstein barycenter [32] of all distributions. Scale
E
A
M 100.3 100 92.5 80 84.9 80.6
−25% −15% 88.7 79.2 0%
BL
SDA+BL 91.7 80.1 98.3 82.9 103.5 85.4
+15%
+35%
+50% scale shift
Figure 2. Robustness of crowd counting against scale shift. The curves show the results of BL [28] with respect to different scale shifts of testing images on UCF-QNRF while trained on original resolutions, e.g., +50% denotes that testing images are rescaled by a factor of 1.5. Our proposed method SDA+BL is much more robust than BL. shift can be quantiﬁed as the sum of Wasserstein distances from each scale distribution to the barycenter. Then, our tar-get is to ﬁnd the distribution transformation and the corre-sponding image transformation to minimize the scale shift.
Particularly, the translation of distribution in the logarithmic domain corresponds to image rescaling. On this basis, we derive a closed-form solution to obtain the optimal trans-lations and their corresponding rescaling factors. We can easily handle intra-image scale variations at a ﬁner level by dividing the image into patches and seek the rescaling factor for each patch. As shown in Fig. 1 (b), the scale shift be-tween different datasets can be greatly reduced after scale alignment. Moreover, we propose SDNet to predict scale distributions of scenes end-to-end without the need to de-tect each person. With noticing that scale distributions are highly correlated with spatial positions due to perspective effects, we propose a novel objective function based on a joint distribution representation of scale and position and sliced Wasserstein distance [17] to trained SDNet. To be summarized, we make the following contributions:
• We propose to address the practical problem of uni-versal cross-dataset crowd counting. We establish a prime building block termed scale alignment for crowd counting and demonstrate its necessity to this problem.
• We present a scale alignment method by translating scale distributions to their Wasserstein barycenter and derive a closed-form solution to get the optimal trans-lations and corresponding image rescaling factors.
• We propose a novel neural network (SDNet) to directly predict scale distributions for various scenes without detecting each person. A novel loss function based on a joint distribution representation of scale and position and efﬁcient sliced Wasserstein distance is also pro-posed to optimize SDNet.
Figure 3. The overall framework of our method. First, we divide images into non-overlapping patches and feed them into SDNet to predict their scale distributions. Then, we perform scale distribution alignment and obtain the optimal rescaling factor for each patch. Finally, we rescale patches and use them to learn the counting model. 2.