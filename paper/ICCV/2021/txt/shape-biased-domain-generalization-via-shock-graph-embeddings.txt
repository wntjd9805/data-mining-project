Abstract
There is an emerging sense that the vulnerability of Im-age Convolutional Neural Networks (CNN), i.e., sensitiv-ity to image corruptions, perturbations, and adversarial at-tacks, is connected with Texture Bias. This relative lack of
Shape Bias is also responsible for poor performance in Do-main Generalization (DG). The inclusion of a role of shape alleviates these vulnerabilities and some approaches have achieved this by training on negative images, images en-dowed with edge maps, or images with conﬂicting shape and texture information. This paper advocates an explicit and complete representation of shape using a classical com-puter vision approach, namely, representing the shape con-tent of an image with the shock graph of its contour map.
The resulting graph and its descriptor is a complete repre-sentation of contour content and is classiﬁed using recent
Graph Neural Network (GNN) methods. The experimen-tal results on three domain shift datasets, Colored MNIST,
PACS, and VLCS demonstrate that even without using ap-pearance the shape-based approach exceeds classical Im-age CNN based methods in domain generalization. 1.

Introduction
The incredible success of deep learning methods has out-paced our understanding of how they work. An avalanche of new Convolutional Neural Networks (CNN) methods, many with computer vision applications, have been developed in the context of improving performance without a simultane-ous development of fundamental understanding of its mech-anisms. This has side-lined an integration with the tradi-tional classical AI/computer vision approaches and cogni-tive science studies. The insight from the classical meth-ods on representation and search is ignored mainly because it is not clear how to integrate the two paradigms: one of developing representations based on feedback from de-gree of success [43], and one on developing representations based on the more classic geometric and world scene rea-soning [53].
Hand in hand with the continued success of CNNs in difﬁcult problems such as image classiﬁcation [57, 26, 49, 50, 56, 44, 37, 13, 65, 74, 5, 45, 47, 18, 60], their vulner-abilities have also been identiﬁed.
Image CNNs struggle with “domain shift” i.e., when the training conditions (res-olutions, sensors, etc.) do not match the conditions of the operating domain. Small corruptions e.g., noise, blur, fog, etc., and perturbations which do not affect human percep-tion [2] affect the performance of Image CNNs as bench-marked by [34].
In particular, when these small changes are adversarial, i.e., targeted to the architecture of the CNN for maximal effect [67, 30, 54, 12], the performance can be seriously affected (adversarial attack).
There is an emerging understanding that underlying these vulnerabilities is a lack of representation of shape.
While initially it was argued, e.g., by visualizations in [78], that Image CNNs construct low-level primitives such as cor-ners and edges in lower layers, which in turn lead to more complex shapes in higher layers [61, 43, 41] there is increas-ing evidence that appearance (texture bias) and not global shape (shape bias) is the cornerstone of correct classiﬁca-tion by CNNs [10, 66]. Baker et al [3] explored the role of object shape in CNNs trained for image classiﬁcation and found that the global object shape, which is arguably the most important cue for human categorization of objects, is not represented. Similarly, Geirhos et al. [25] show that
Image CNNs only rely on object texture rather than object shape and show how with proper training the introduction of a shape bias improves performance. In the ﬁeld of cogni-tive science, Malhotra and Bowers [52] systematically ex-plore the impact of non-shape features in the categoriza-tion performance of CNNs on the CIFAR-10 [42] dataset.
They conclude that even though the CNN mimics the hi-erarchical architecture and learning processes of biological vision, they pick up optimal features to perform prediction which do not include shape. They conjecture that the lack of an intrinsic shape bias in a typical Image CNN architec-ture can be the key to susceptibility to adversarial attacks.
Zhang and Zhu [79] ﬁnd that adversarially trained networks are less texture-biased and more shape-biased. More re-cently [4] shows that CNNs performance is an inversion of human performance with respect to global and local shape priors in that Image CNNs capture only local shape infor-mation while humans capture absolute shape information.
See also [13, 75]. a)
Figure 1. Observe that shape is dominant in forming perception when object features have not been experienced before (a), or are completely contradictory where the percept is a giraffe and not a zebra (b) [70]. b) a) b) c)
Figure 2. a) Various images of an elephant across the four domains from the PACS [44] dataset. b) The shape of an object as captured by a binary mask of the images. c) The shock graph of the con-tour map colored in green (shock dynamics are not shown). We encourage readers to zoom in.
Shape is an object constancy that dominates object tex-ture, Figure 1, and is invariant to image corruption or pertur-bation. Observe in Figure 2a, that the objects in the images taken from standard domain generalization datasets exhibit signiﬁcant variation in color and/or texture. Observe that af-ter delineation of the object of interest, Figure 2b, the varia-tion in shape is much less than the appearance. This concept of “shape constancy” has long been a pillar of classic com-puter vision and recognized as one of the most important cues in biological object recognition [6, 7]. We conjecture that the strong bias of Image CNNs to texture cues cou-pled with the inability to capture global shape cues is limit-ing their capability to generalize. Several researchers have aimed to increase the shape bias of CNNs, for example by training on negative images which preserve shape but not appearance [35]. Borji augments the training by including edge maps [9]. Li et al. [51] augment training data with images with conﬂicting shape and texture information, e.g., an image of chimpanzee shape but with lemon texture, un-der simultaneous shape and texture supervision to develop each independently. It is clear from these studies that the enhancing and emphasizing the shape cue in the training process improves performance.
This paper advocates a complete and explicit represen-tation of shape. Instead of forcing the Image CNN to learn shape indirectly, shape is directly extracted and represented based on the most advanced understanding of classical com-puter vision. In other words, each image is augmented with an explicit representation of its shape content. In fact, the image itself is discarded for the purpose of this study and we solely train on the explicit shape representation to com-pletely characterize how far image classiﬁcation can pro-ceed on a shape-only platform.
The segmented images in Figure 2b represent the canoni-cal deﬁnition of “shape” in the computer vision community.
Shape descriptors aim to capture regional and/or boundary properties of this binary shape. A sampling of popular de-scriptors include shape context [55], medial axis descrip-tors [29, 73], and shape tree [23], just to name a few among many. The vast majority of approaches then rely on some form of assignment or graph matching algorithms to deﬁne a distance, and that distance is subsequently used in shape classiﬁcation pipelines. The medial axis [8] of a segmented shape is a particular favorite as it captures invariances for many deformations.
Since segmentation itself is a difﬁcult problem, the no-tion of shape must be surmised directly from edges or re-gions. The shock graph [38, 39, 27], a reﬁnement of medial axis descriptors, has made the leap from binary images to real images [58, 59]. Observe in Figure 2c, the shock graph of the original images, Figure 2a, captures the “skeleton” of these various elephants. We can see the delineation of the various common parts of the elephant, distinctive trunk and legs, shared among all elephant exemplars despite originat-ing from disparate domains. Further motivating factors for why we use the shock graph is that it is robust to articula-tions and occlusion of the underlying shape which are more common in realistic image acquisition settings. Its state of the art performance on standard shape datasets [64] is an additional reason to use it in this research.
The shock graph is a complete representation of image contours in that they can be reconstructed back from the shock graph, which encodes both the axis and the dynamics along the axis. In this sense the shock graph is a complete representation of the object contours embedded in an image.
Thus, training can take place on the shock graph instead of
the original image. Observe, however, that the image pixel topology is now replaced with a graph topology. Recent advancements in Graph Neural Networks (GNN) [77, 80] can capture the information in the graph for the purpose of classiﬁcation. Speciﬁcally, our pipeline is one of transform-ing the image to an edge map, a contour map, and then a shock graph which is subsequently trained on using a graph neural network for classiﬁcation. This represents a novel use of graph neural networks as the vast majority of ap-plications of graph neural networks have focused on graph machine learning tasks (node labeling, edge labeling, and graph classiﬁcation) predominantly for social networks or in chemistry with molecule graphs. We show that this rep-resentation of shape information via a shock graph and us-ing GNN to train on them leads to excellent classiﬁcation performance, even though the appearance is not taken into account. Future work will likely enhance this performance further when both cues are utilized.
Our contributions can be summarized as follows. 1) To the best of our knowledge the ﬁrst paper to revisit classic shape descriptors in a modern setting for domain gener-alization 2) A novel approach of using an image-to-graph transformation instead of the traditional Image CNN in-put. 3) Combining shock-graphs with graph neural net-works to achieve state of the art graph classiﬁcation per-formance comparable to the image classiﬁcation perfor-mance achieved by standard Image CNN architectures. 4)
A novel image-to-graph framework that shows the power of the shape bias, with the potential to integrate texture cues.
From a high-level perspective, the paper also shows that it is possible to bring to bear lessons learned from classi-cal computer vision in the context of modern deep learning techniques. 2.