Abstract
This paper focuses on the regression of multiple 3D peo-ple from a single RGB image. Existing approaches pre-dominantly follow a multi-stage pipeline that first detects people in bounding boxes and then independently regresses their 3D body meshes. In contrast, we propose to Regress all meshes in a One-stage fashion for Multiple 3D Peo-ple (termed ROMP). The approach is conceptually simple, bounding box-free, and able to learn a per-pixel representa-tion in an end-to-end manner. Our method simultaneously predicts a Body Center heatmap and a Mesh Parameter map, which can jointly describe the 3D body mesh on the pixel level. Through a body-center-guided sampling pro-cess, the body mesh parameters of all people in the im-age are easily extracted from the Mesh Parameter map.
Equipped with such a fine-grained representation, our one-stage framework is free of the complex multi-stage process and more robust to occlusion. Compared with state-of-the-art methods, ROMP achieves superior performance on the challenging multi-person benchmarks, including 3DPW and CMU Panoptic. Experiments on crowded/occluded datasets demonstrate the robustness under various types of occlusion. The code, released at https://github. com/Arthur151/ROMP, is the first real-time implemen-tation of monocular multi-person 3D mesh regression. 1.

Introduction
Recently, great progress has been made in monocular 3D human pose and shape estimation, particularly in im-ages with a single person [20, 22, 23, 48, 51]. However, for more general scenes with multiple people, it is crucial to deal with truncation by the image frame, person-person oc-clusion, and environmental occlusion. Robustness to such occlusions is critical for real-world applications.
Existing approaches [15, 22, 52, 53] follow a multi-*This work was done when Yu Sun was an intern at JD AI Research.
â€ Corresponding author.
Figure 1. Given a challenging multi-person image like (a), the state-of-the-art approaches, e.g., VIBE [22] (left), fail to deal with truncation, scene occlusion, and person-person occlusion. The reason lies in the multi-stage design (b), where the bounding-box-level features are often implicit, ambiguous, and inseparable in multi-person cases. We propose to regress all meshes in one single stage for multiple 3D people. Specifically, we develop an explicit pixel-level representation (c) for fine-grained one-stage estimation that increases robustness to truncation and occlusion while signif-icantly reducing computational complexity. stage design that equips the single-person method with a 2D person detector to handle multi-person scenes. Gener-ally, they first detect regions with people and then extract the bounding-box-level features, which are used to regress each single 3D human mesh [11, 20, 21, 22, 23, 24, 39, 47, 51, 60]. However, as shown in Fig. 1, this strategy is prone
to fail in cases of multi-person occlusion and truncation.
Specifically, as shown in Fig. 1(b), when two people over-lap, it is hard for the multi-stage method to estimate diverse body meshes from similar image patches. The ambiguity of the implicit bounding-box-level representation results in failure for such inseparable multi-person cases.
For multi-person 2D pose estimation, this problem has been tackled via a subtle and effective bottom-up frame-work. The paradigm first detects all body joints and then assigns them to different people by grouping body joints.
This pixel-level body-joint representation enables their im-pressive performance in crowded scenes [7, 8, 40]. How-ever, it is non-trivial to extend this bottom-up one-stage pro-cess beyond joints [15]. Unlike 2D pose estimation, which predicts dozens of body joints, we need to regress a human body mesh with thousands of vertices, making it hard to follow the paradigm of body joint detection and grouping.
Instead, we introduce ROMP, a one-stage network for re-gressing multiple 3D people in a per-pixel prediction fash-ion. It directly estimates multiple differentiable maps from the whole image, from which we can easily parse out the 3D meshes of all people. Specifically, as shown in Fig. 1(c),
ROMP predicts a Body Center heatmap and a Mesh Param-eter map, representing the 2D position of the body center and the parameter vectors of the corresponding 3D body mesh, respectively. Via a simple parameter sampling pro-cess, we extract 3D body mesh parameter vectors of all peo-ple from the Mesh Parameter map at the body center loca-tions described by the heatmap. Then we put the sampled mesh parameter vectors into the SMPL body model [33] to derive multi-person 3D meshes. Following the guidance of body centers during training, the ambiguity of the re-gression target is greatly alleviated in crowded multi-person scenes. Additionally, in contrast to the local, bounding-box-level, features learned by traditional methods, end-to-end learning from the whole image forces the model to learn ap-propriate features from the holistic scene to predict bodies with occlusion. This holistic approach captures the com-plexity of real-world scenes, enabling the generalization and robustness to complex multi-person cases.
Moreover, since the body centers of severely overlap-ping people may collide at the same 2D position, we further develop an advanced collision-aware representation (CAR).
The key idea is to construct a repulsion field of body centers, where close body centers are analogous to positive charges that are pushed apart by mutual repulsion.
In this way, the body centers of the overlapping people are more dis-tinguishable. Especially in the case of severe overlap, most part of the human body is invisible. Mutual repulsion will push the center to the visible body area, meaning that the model tends to sample 3D mesh parameters estimated from the position centered on the visible body parts. It improves the robustness under heavy person-person occlusion.
Compared with previous state-of-the-art methods for multi-person [15, 52, 53] and single-person [22, 23] 3D mesh regression, ROMP achieves superior performance on challenging benchmarks, including 3DPW [49] and
CMU Panoptic [18]. Experiments on person-person oc-clusion datasets (Crowdpose [28] and 3DPW-PC, a person-occluded subset of 3DPW [49]) demonstrate the effective-ness of the proposed CAR under person-person occlusion.
To further evaluate it in general cases, we test ROMP on images from the Internet and web camera videos. With the same backbone as the multi-stage counterparts, ROMP runs in real-time (over 30 FPS) on a 1070Ti GPU.
In summary, the contributions are: (1) To the best of our knowledge, ROMP is the first one-stage method for monocular multi-person 3D mesh regression, along with an open-source real-time implementation. Its simple yet effec-tive framework leads to superior accuracy and efficiency. (2) The proposed explicit body-center-guided representa-tion facilitates the pixel-level human mesh regression in an end-to-end manner. (3) We develop a collision-aware rep-resentation to deal with cases of severe overlap. 2.