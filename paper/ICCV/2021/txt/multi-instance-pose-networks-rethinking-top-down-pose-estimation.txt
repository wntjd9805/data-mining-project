Abstract
A key assumption of top-down human pose estimation approaches is their expectation of having a single per-son/instance present in the input bounding box. This often leads to failures in crowded scenes with occlusions. We propose a novel solution to overcome the limitations of this fundamental assumption. Our Multi-Instance Pose Network (MIPNet) allows for predicting multiple 2D pose instances within a given bounding box. We introduce a Multi-Instance
Modulation Block (MIMB) that can adaptively modulate channel-wise feature responses for each instance and is parameter efﬁcient. We demonstrate the efﬁcacy of our ap-proach by evaluating on COCO, CrowdPose, and OCHuman datasets. Speciﬁcally, we achieve 70.0 AP on CrowdPose and 42.5 AP on OCHuman test sets, a signiﬁcant improve-ment of 2.4 AP and 6.5 AP over the prior art, respectively.
When using ground truth bounding boxes for inference, MIP-Net achieves an improvement of 0.7 AP on COCO, 0.9 AP on
CrowdPose, and 9.1 AP on OCHuman validation sets com-pared to HRNet. Interestingly, when fewer, high conﬁdence bounding boxes are used, HRNet’s performance degrades (by 5 AP) on OCHuman, whereas MIPNet maintains a rela-tively stable performance (drop of 1 AP) for the same inputs. 1.

Introduction
Human pose estimation aims at localizing 2D human anatomical keypoints (e.g., elbow, wrist, etc.) in a given image. Current human pose estimation methods can be categorized as top-down or bottom-up methods. Top-down methods [6, 13, 33, 40, 41, 43, 44] take as input an image region within a bounding box, generally the output of a human detector, and reduce the problem to the simpler task of single human pose estimation. Bottom-up methods [3, 22, 29, 32], in contrast, start by independently localizing keypoints in the entire image, followed by grouping them into 2D human pose instances.
The single human assumption made by top-down ap-proaches limits the inference to a single conﬁguration of hu-man joints (a single instance) that can best explain the input.
⇤Work done during an internship at Amazon
†Now at Waymo
Figure 1: 2D pose estimation networks often fail in presence of heavy occlusion. (Left) Bounding boxes corresponding to two per-sons. (Middle) For both bounding boxes, HRNet predicts the pose for the front person and misses the occluded person. (Right) MIP-Net allows multiple instances for each bounding box and recovers the pose of the occluded person.
Top-down pose estimation approaches [6, 16, 30, 40, 44] are currently the best performers on datasets such as COCO [25],
MPII [2]. However, when presented with inputs containing multiple humans like crowded or occluded instances, top-down methods are forced to select a single plausible con-ﬁguration per human detection. In such cases, top-down methods may erroneously identify pose landmarks corre-sponding to the occluder (person in the front). See, for example, Fig. 1 (Middle). Therefore, on datasets such as
CrowdPose [23] and OCHuman [48], which have a relatively higher proportion of occluded instances (Table 1), the perfor-mance of top-down methods suffer due to the single person assumption [8, 23, 48].
In this paper, we rethink the architecture for top-down 2D pose estimators by predicting multiple pose instances for the input bounding box. The key idea of our proposed architecture is to allow the model to predict more than one pose instance for each bounding box. We demonstrate that this conceptual change improves the performance of top-Dataset
COCO
CrowdPose
OCHuman
IoU> 0.5 1.2K (1%) 2.9K (15%) 3.2K (68%)
AP0 AP0.9 APgt
+1.9
+2.3
+8.2
+0.7
+0.9
+9.1 0.0
+0.8
+4.2
Figure 2: Heatmap predictions for a few keypoints from HRNet vs
MIPNet. HRNet only focuses on the foreground person. MIPNet enables prediction of the multiple instances from the same input bounding box by varying λ during inference. down methods, especially for images with crowding and heavy occlusion. A na¨ıve approach to predict multiple in-stances per bounding box would be to add multiple predic-tion heads to an existing top-down network with a shared feature-extraction backbone. However, such an approach fails to learn different features corresponding to the vari-ous instances. A brute-force approach would then be to replicate the feature-extraction backbone, though at a cost of an N -fold increase in parameters, for N instances. In contrast, our approach enables predicting multiple instances for any existing top-down architecture with a small increase in the number of parameters (< 3%) and inference time (< 9ms, 16%). Technically, our approach can handle N > 2 instances. However, as shown in Figure 4, number of ex-amples with 3+ annotated pose instances per ground truth bounding box in existing datasets is extremely small. Thus, similar to [35, 48], we primarily focus on the dominant occlusion scenario involving two persons.
To enable efﬁcient training and inference of multiple in-stances in a given bounding box, we propose a novel Multi-Instance Modulation Block (MIMB). MIMB modulates the feature tensors based on a scalar instance-selector, , and al-lows the network to index on one of the N instances (Fig. 2).
MIMB can be incorporated in any existing feature-extraction backbone, with a relatively simple (< 15 lines) code change (refer supplemental). At inference, for a given bounding box, we vary the instance-selector  to generate multiple pose predictions (Fig. 3).
⇠
Since top-down approaches rely on the output from an object detector, they typically process a large number of bounding box hypotheses. For example, HRNet [40] uses more than 100K bounding boxes from Faster R-CNN [37] 6000 persons in the COCO val to predict 2D pose for dataset. Many of these bounding boxes overlap and major-ity have low detection scores (< 0.4). This also adversely impacts the inference time, which increases linearly with the number of input bounding boxes. As shown in Fig. 5, using fewer, high conﬁdence bounding boxes degrades the performance of HRNet from 37.8 to 32.8 AP on OCHuman, a degradation of 5 AP in performance. In contrast, MIPNet is robust and maintains a relatively stable performance for the same inputs (drop of 1 AP). Intuitively, our method can predict the 2D pose instance corresponding to a mis-detected
Table 1: MIPNet’s relative improvement in AP compared to HRNet-W48 on the val set, using Faster R-CNN (AP0: all, AP0.9: high conﬁdence) and ground truth (APgt) bounding boxes. For each dataset, the number (%) of instances with occlusion IoU > 0.5 is reported [35]. Datasets with more occlusions and crowding demonstrate higher gains. bounding box based on predictions from its neighbors.
Overall, MIPNet outperforms top-down methods and oc-clusion speciﬁc methods on various datasets as shown in
Table 1. For challenging datasets such as CrowdPose and
OCHuman, containing a larger proportion of cluttered scenes (with multiple overlapping people), MIPNet sets a new state-of-the-art achieving 70.0 AP and 42.5 AP respectively on the test set outperforming bottom-up methods. Our main contributions are
•
•
•
We advance top-down 2D pose estimation methods by addressing limitations caused by the single person as-sumption during training and inference. Our approach achieves the state-of-the-art results on CrowdPose and
OCHuman datasets.
MIPNet allows predicting multiple pose instances for a given bounding box efﬁciently by modulating feature responses for each instance independently.
The ability to predict multiple instances makes MIPNet resilient to bounding box conﬁdence and allows it to deal with missing bounding boxes with minimal impact on performance. 2.