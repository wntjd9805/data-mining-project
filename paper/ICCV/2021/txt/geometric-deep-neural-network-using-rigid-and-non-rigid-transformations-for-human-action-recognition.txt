Abstract
Deep Learning architectures, albeit successful in most computer vision tasks, were designed for data with an un-derlying Euclidean structure, which is not usually fulfilled since pre-processed data may lie on a non-linear space.
In this paper, we propose a geometry aware deep learn-ing approach using rigid and non rigid transformation opti-mization for skeleton-based action recognition. Skeleton se-quences are first modeled as trajectories on Kendall’s shape space and then mapped to the linear tangent space. The re-sulting structured data are then fed to a deep learning archi-tecture, which includes a layer that optimizes over rigid and non rigid transformations of the 3D skeletons, followed by a CNN-LSTM network. The assessment on two large scale skeleton datasets, namely NTU-RGB+D and NTU-RGB+D 120, has proven that the proposed approach outperforms existing geometric deep learning methods and exceeds re-cently published approaches with respect to the majority of configurations. 1.

Introduction
Human behavior analysis via diverse data types has emerged as an active research issue in computer vision due to 1) the wide spectrum of not yet fully explored applica-tion domains, e.g., human-computer interaction, intelligent surveillance security, virtual reality, etc., and 2) the devel-opment of advanced sensors such as Intel RealSense, Asus
Xtion and the Microsoft Kinect [49], which yield various data modalities, e.g., RGB and depth image sequences, and videos. Conventionally, these modalities have been utilized, solely [23, 37], or merged (e.g., RGB + optical flow), for action recognition tasks [35, 9] using multiple classifica-tion techniques, and resulted in excellent results. With the development of human pose estimation algorithms [8, 6], the problem of human joint (i.e., key-points) localization was solved and reliable acquisition of accurate 3D skeleton data became possible. In comparison with former modal-ities, skeleton data, a topological representation of the hu-man body using joints and bones, appears to be less com-putationally expensive, and more robust in front of intricate backgrounds and with respect to variable conditions includ-ing viewpoints, scales and motion speeds. An efficient way to analyze 3D skeleton motions is to consider their shapes independently of undesirable transformations; the resulting representation space of skeleton data is then non linear.
Accordingly, we represent 3D skeleton landmarks in the
Kendall shape space [16] that defines shape as the geomet-ric information that remains when location, scaling and ro-tational effects are filtered out. A sequence of skeletons is then modeled as a trajectory on this space. Thus, to an-alyze and classify such data, it is more suitable to con-sider the geometry of the underlying space. This remains a challenging problem since most commonly used tech-niques were designed for linear data. Deep learning archi-tectures, despite their efficiency in many computer vision applications, usually ignore the geometry of the underlying data space. Therefore, geometric deep learning architec-tures have been introduced to remedy this issue. To the best of our knowledge, the main previous geometric deep learn-ing approaches were designed on feature spaces (e.g., SPD matrices, Grassmann manifold, Lie groups [14, 13]) or on the 3D human body manifold [2, 28]. The literature that considers this problem on shape spaces is scarce. Actually, an extension of a conventional deep architecture on a pre-shape space has been recently proposed in [10], and an auto encoder-decoder has been extended to a shape space for gait analysis in [11].
In this work, we propose a novel geometric deep learning approach on Kendall’s shape space, denoted KShapeNet, for skeleton-based action recognition. Skeleton sequences are first modeled as trajectories on Kendall’s shape space by filtering out scale and rigid transformations. Then, the se-quences are mapped to a linear tangent space and the result-ing structured data are fed into a deep learning architecture.
The latter includes a novel layer that learns the best rigid or non rigid transformation to be applied to the 3D skeletons to accurately recognize the actions.
Contributions: The main contributions of this paper are: 1. We introduce a novel deep architecture on Kendall’s shape space that deeply learns transformations of the skeletons for action recognition tasks. 2. The proposed deep network includes a novel transfor-mation layer that optimizes over rigid and non rigid transformations of skeletons to increase action recog-nition accuracy.
Organization of the paper The rest of the paper is orga-nized as follows. In Section 2, we briefly review existing so-lutions for action recognition and geometric deep learning.
Section 3 describes geometric modeling of skeleton trajec-tories on Kendall’s shape space. In Section 4, we introduce the proposed geometric deep architecture, KShapeNet. Ex-perimental settings, results and discussions are reported in
Section 5. Section 6 concludes the paper and summarizes a few directions for future work. 2.