Abstract
We present a novel solution to the garment animation problem through deep learning. Our contribution allows animating any template outﬁt with arbitrary topology and geometric complexity. Recent works develop models for garment edition, resizing and animation at the same time by leveraging the support body model (encoding garments as body homotopies). This leads to complex engineering solu-tions that suffer from scalability, applicability and compati-bility. By limiting our scope to garment animation only, we are able to propose a simple model that can animate any outﬁt, independently of its topology, vertex order or con-nectivity. Our proposed architecture maps outﬁts to ani-mated 3D models into the standard format for 3D anima-tion (blend weights and blend shapes matrices), automati-cally providing of compatibility with any graphics engine.
We also propose a methodology to complement supervised learning with an unsupervised physically based learning that implicitly solves collisions and enhances cloth quality. 1.

Introduction
Virtual dressed human animation has been a topic of interest for decades due to its numerous applications in entertainment and videogame industries, and recently, in virtual and augmented reality. Depending on the appli-cation we ﬁnd two main classical computer graphics ap-proaches. On the one hand, Physically Based Simulation (PBS) [6, 17, 23, 24, 29, 30, 33] approaches are able to obtain highly realistic cloth dynamics at the expense of a huge computational cost. On the other hand, Linear Blend
Skinning (LBS) [12, 13, 15, 20, 31, 32] and Pose Space
Deformation (PSD) [3, 4, 16, 18] models are suitable for environments with limited computational resources or real-time performance demand. To do so, realism is highly com-promised. Then, computer graphics approaches present a trade-off between realism and computational performance.
Figure 1: We present a novel approach for outﬁt animation.
Our methodology allows generalization to unseen outﬁts. It can handle multiple layers of cloth, arbitrary topology and complex geometric details without retraining.
Deep learning has already proven successful in complex 3D tasks [5, 10, 19, 21, 25, 26, 28]. Due to the interest in the topic and the recently available 3D datasets on gar-ments, we see the scientiﬁc community pushing this re-search line [1, 2, 7, 8, 9, 14, 22, 27]. Most proposals are built as non-linear PSD models learnt through deep learn-ing. These methods yield models describing one or few garment types and, therefore, they lack on generalization capabilities. To overcome this, recent works propose encod-ing garment types as a subset of body vertices [7, 22]. This allows generalizing to more garments, yet bounds its rep-resentation capacity to body homotopies only. Thus, these approaches need to model each garment individually and cannot handle details such as pockets nor multiple layers of cloth, heavily hurting their scalability and applicability in real life scenarios.
We propose learning a mapping from the space of tem-plate outﬁts to the space of animated 3D models. We will show how this allows generalization to completely unseen garments with arbitrary topology and vertex connectivity.
We can achieve this by identifying edition/resizing and an-imation as separate tasks, and focusing on the latter. Our method works with whole outﬁts (instead of single gar-ments), multiple layers of cloth and resolutions, while also allowing complex geometric details (see Fig. 1 for some
examples). Furthermore, we achieve this with a simple and small-sized neural network. The list of our contributions is as follows:
• Outﬁt Generalization. To the best of our knowledge, our proposal is the only work able to animate com-pletely unseen outﬁts without additional training. This greatly increases applicability in scenarios with ever-growing number of outﬁts, such as virtual try-ons and videogames, where customization is key.
• Compatibility. Our methodology does not predict gar-ment vertex locations, but blend weights and blend shapes matrices. This is the standard on 3D animation, and it is therefore compatible with all graphics engines.
Also, it beneﬁts from the exhaustive optimization on animation pipelines. Pose Space Deformations are a speciﬁc case of blend shapes that are combined con-sistently with object pose.
• Physical Consistency.