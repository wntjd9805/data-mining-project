Abstract
Vision-Dialog Navigation (VDN) requires an agent to ask questions and navigate following the human responses to find target objects. Conventional approaches are only allowed to ask questions at predefined locations, which are built upon expensive dialogue annotations, and inconvenience the real-word human-robot communication and cooperation.
In this paper, we propose a Self-Motivated Communication
Agent (SCoA) that learns whether and what to communi-cate with human adaptively to acquire instructive informa-tion for realizing dialogue annotation-free navigation and enhancing the transferability in real-world unseen environ-ment. Specifically, we introduce a whether-to-ask (WeTA) policy, together with uncertainty of which action to choose, to indicate whether the agent should ask a question. Then, a what-to-ask (WaTA) policy is proposed, in which, along with the oracle’s answers, the agent learns to score ques-tion candidates so as to pick up the most informative one for navigation, and meanwhile mimic oracle’s answering.
Thus, the agent can navigate in a self-Q&A manner even in real-world environment where the human assistance is often unavailable. Through joint optimization of communication and navigation in a unified imitation learning and reinforce-ment learning framework, SCoA asks a question if necessary and obtains a hint for guiding the agent to move towards the target with less communication cost. Experiments on seen and unseen environments demonstrate that SCoA shows not only superior performance over existing baselines without dialog annotations, but also competing results compared with rich dialog annotations based counterparts. 1.

Introduction
The richness and generalizability of natural language have significantly boosted the prosperity of navigation tasks in which the agents are encouraged to navigate in the indoor environment to reach the target [1, 27, 3, 34]. In particular, the Vision-Dialog Navigation (VDN) [26, 35, 20, 18], where
*Equal contribution.
†Corresponding author.
Figure 1: Our Self-Motivated Communication Agent (SCoA) learns whether and what to communicate with human adap-tively to acquire instructive information for guiding the navi-gation without using any dialog annotations. the question-answering dialogs can be conducted in a human-robot communication manner to facilitate the navigation, has attracted increasing attention in the field of visual navigation.
Cutting-edge practice implements VDN on the premise of tremendous dialog annotations and the dialog occurs in hand-crafted locations during navigation. For example, [26, 35] require to annotate question-answering pairs at fixed locations of the environment in advance to assist the agent training. On the contrary, Roman et al. [20] utilized these dialog annotations to pre-train a language model, which is then plugged into the navigation model for dialog generation at every given step interval. In [18], dialog happens only if the agent enters a pre-annotated assistant zone where strong language instructions and image views are provided by the oracle to guide the agent to move towards the target.
Despite the progress, the massive dialog annotations re-quired in existing researches result in two major drawbacks that barricade the real-world deployment of the trained agents: First, the communication is inflexible since the agents are only allowed to ask questions at predefined lo-cations that may contain bias induced by annotators, not at the time when communication is needed. Second, the learning cost is expensive since existing methods are built upon large amounts of labor-intensive dialog annotations. To solve the above problems, we argue that the agent should be able to adaptively communicate with the oracle if necessary,
and such communication should be built upon no or fewer human-annotated dialogs to fit real-world applications.
To this end, we propose Self-Motivated Communication
Agent (SCoA), which, as illustrated in Fig. 1, learns to decide whether and what to communicate with human to acquire instructive feedback for guiding the navigation when unsure where to go. As shown in Fig. 2, our SCoA comprises two major components including a whether-to-ask (WeTA) mod-ule which learns to predict whether to communicate with the oracle, and a what-to-ask (WaTA) module which learns to generate an informative question for moving towards the target. Specifically, WeTA aims to learn a probability which is used to suggest the agent communicating with the oracle when it is uncertain of which action to take. We propose to model the uncertainty by computing the entropy of the action probability distribution, which in turn serves as the pseudo label to guide the learning of our WeTA. As for WaTA, it first generates some question candidates on-the-fly based on a small set of direction-related sentences as references1 to get rid of the expensive dialog annotations. By consider-ing the features of language information of the target and vision information of the views, we build a question score vector to pick up the most beneficial question for navigation.
By considering the features of question candidates and the optimal next-step view observed by the oracle, an answer score vector is further introduced, which plays as a teacher to guide the learning of the question scores. In this way, our agent can navigate in a self-Q&A manner even when the human is invisible in real-world unseen environment.
Beyond the uncertainty constraint on whether to ask at each navigation step, we formulate the communication as well as the navigation in a unified imitation learning and reinforcement learning framework, which is further equipped with a communication frequency penalty and a navigation progress reward. As result, the agent can reach the target with as little communication cost as possible.
The main contributions in this paper are three-fold:
• Our SCoA tackles the challenging problem of inflexi-ble and annotation-dependent communication for real-world vision-dialog navigation by learning to adaptively determine whether and what to communicate with hu-man to acquire instructive feedback for navigation.
• The communication and navigation are jointly opti-mized in the unified framework comprising imitation learning and reinforcement learning, to drive the agent to reach target position with less communication cost.
• The performance of our SCoA is demonstrated to be superior over the baselines without using dialog anno-tations, and even comparable to the counterparts with 1The size of our sentence set is around twenty, a magnitude reduction compared with the ten thousand dialog annotations in existing researches. rich dialog annotations, which proves the ability of our
SCoA to generate informative questions for navigation. 2.