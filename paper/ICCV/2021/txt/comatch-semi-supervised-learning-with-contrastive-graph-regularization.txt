Abstract
Semi-supervised learning has been an effective paradigm for leveraging unlabeled data to reduce the reliance on labeled data. We propose CoMatch, a new semi-supervised learning method that uniﬁes dominant approaches and addresses their limitations. CoMatch jointly learns two representations of the training data, their class probabilities and low-dimensional embeddings.
The two representations interact with each other to jointly evolve. The embeddings impose a smoothness constraint on the class probabilities to improve the pseudo-labels, whereas the pseudo-labels regularize the structure of the embeddings through graph-based contrastive learning.
CoMatch achieves state-of-the-art performance on multiple datasets.
It achieves substantial accuracy improvements on the label-scarce CIFAR-10 and STL-10. On ImageNet with 1% labels, CoMatch achieves a top-1 accuracy of 66.0%, outperforming FixMatch [32] by 12.6%.
Furthermore, CoMatch achieves better representation learning performance on downstream tasks, outper-forming both supervised learning and self-supervised learning. Code and pre-trained models are available at https://github.com/salesforce/CoMatch/. 1.

Introduction
Semi-supervised learning (SSL) – learning from few la-beled data and a large amount of unlabeled data – has been a long-standing problem in computer vision and ma-chine learning. Recent state-of-the-art methods mostly fol-low two trends: (1) using the model’s class prediction to produce a pseudo-label for each unlabeled sample as the label to train against [19, 2, 1, 32]; (2) unsupervised or self-supervised pre-training, followed by supervised ﬁne-tuning [5, 14, 13, 3] and pseudo-labeling [6].
However, existing methods have several limitations.
Pseudo-labeling (also called self-training) methods heav-ily rely on the quality of the model’s class prediction, thus suffering from conﬁrmation bias where the prediction mis-takes would accumulate. Self-supervised learning methods are task-agnostic, and the widely adopted contrastive learn-ing [5, 14] may learn representations that are suboptimal for the speciﬁc classiﬁcation task. Another branch of meth-ods explore graph-based semi-supervised learning [24, 17], but have yet shown competitive performance especially on larger datasets such as ImageNet [9].
We propose CoMatch, a new semi-supervised learning method that addresses the existing limitations. A concep-tual illustration is shown in Figure 1.
In CoMatch, each image has two compact representations: a class probability produced by the classiﬁcation head and a low-dimensional embedding produced by the projection head. The two rep-resentations interact with each other and jointly evolve in a co-training framework. Speciﬁcally, the classiﬁcation head is trained using memory-smoothed pseudo-labels, where pseudo-labels are reﬁned by aggregating information from nearby samples in the embedding space. The projection head is trained using contrastive learning on a pseudo-label graph, where samples with similar pseudo-labels are trained to have similar embeddings. CoMatch uniﬁes dominant ideas including consistency regularization, entropy mini-mization, contrastive learning, and graph-based SSL.
We perform experiments on multiple datasets and compare with state-of-the-art semi-supervised and self-supervised methods. CoMatch substantially outperforms all baselines across all benchmarks, especially in label-scarce scenarios. On CIFAR-10 with 4 labeled samples per class,
CoMatch outperforms FixMatch [32] by 6.11% in accuracy.
On STL-10, CoMatch outperforms FixMatch by 13.27%.
On ImageNet with only 1% of labels, CoMatch achieves a top-1 accuracy of 66.0% (67.1% with self-supervised pre-training), whereas the best baseline (MoCov2 [7] followed by FixMatch [32]) has an accuracy of 59.9%. Furthermore, we demonstrate that CoMatch achieves better representa-tion learning performance on down-stream image classiﬁ-cation and object detection tasks, outperforming both su-pervised learning and self-supervised learning. 2.