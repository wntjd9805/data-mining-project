Abstract
In this paper, we propose Hierarchical Action Segmen-tation Refiner (HASR), which can refine temporal action segmentation results from various models by understand-ing the overall context of a given video in a hierarchical way. When a backbone model for action segmentation es-timates how the given video can be segmented, our model extracts segment-level representations based on frame-level features, and extracts a video-level representation based on the segment-level representations. Based on these hierar-chical representations, our model can refer to the overall context of the entire video, and predict how the segment la-bels that are out of context should be corrected. Our HASR can be plugged into various action segmentation models (MS-TCN, SSTDA, ASRF), and improve the performance of state-of-the-art models based on three challenging datasets (GTEA, 50Salads, and Breakfast). For example, in 50Sal-ads dataset, the segmental edit score improves from 67.9% to 77.4% (MS-TCN), from 75.8% to 77.3% (SSTDA), from 79.3% to 81.0% (ASRF). In addition, our model can refine the segmentation result from the unseen backbone model, which was not referred to when training HASR. This gen-eralization performance would make HASR be an effective tool for boosting up the existing approaches for temporal action segmentation. Our code is available at https:
//github.com/cotton-ahn/HASR_iccv2021. 1.

Introduction
Enabling an intelligent agent to understand a human ac-tion from videos is crucial for various applications such as interactive robots, surveillance, and activity analysis. Re-garding this, one main line of research would be a video action recognition [14, 1, 7], which predicts the action class label for properly trimmed videos. On the other hand, there exist researches for understanding untrimmed videos with fine-grained class labels [19, 27, 21], so that agents can lo-calize or segment human actions from long-term videos. In this paper, we focus on a task of temporal action segmenta-tion, which is to divide video frames into segments as well as to predict action class labels for the segments.
Figure 1. An illustration of how the proposed Hierarchical Action
Segmentation Refiner (HASR) works. HASR refines the action segmentation result from the backbone model, after understanding the overall context of the entire video in a hierarchical way. This example is obtained when HASR is applied to improve the perfor-mance of MS-TCN [5], given a video of making a hot-dog as an input. It shows that the label of ‘stir’, which is not relevant to a hot-dog, changes to the ‘background’ (no action) label.
Researches in temporal action segmentation have been improved to successfully segment thousands of video frames recorded with 15 fps [5, 3, 10]. However, we find out that existing state-of-the-art models sometimes gener-ate segmentation results including action labels that are out of overall context. For example, as shown in Figure 1, the label of ‘stir’ appears when the input video is about making a hot-dog. We claim that this phenomenon happens since existing approaches focus on frame-level feature informa-tion, but not on the overall context of the video.
In this paper, we propose a Hierarchical Action Segmen-tation Refiner (HASR), which can extract the hierarchical video representations to understand the overall context, and exploit them to refine the results from action segmentation backbone models. Here, the action segmentation backbone models refer to any existing approaches for a temporal ac-tion segmentation task, such as MS-TCN [5], SSTDA [3] and ASRF [10]. Figure 1 shows an illustration of how
HASR works. Based on the action segmentation results from a backbone model, HASR extracts segment-level rep-resentations based on given frame-level features, and ex-tracts a video-level representation based on the segment-level representations. With these hierarchical video repre-sentations, our model predicts how the segment labels that are out of context should be corrected.
HASR is trained in a supervised way, by referring to the segmentation results from the pretrained backbone models as well as the ground truth segment information. The in-teresting point is, after HASR is trained to learn how to re-fine the segmentation results from backbone models A, B and C, it is also effective for refining the results from an-other unseen backbone model D. We validate this gener-alization performance from experiments, and show that our model can be extensively used to improve the segmentation results from unseen backbone models. Our contribution can be summarized as follows:
• We propose Hierarchical Action Segmentation Refiner (HASR), which can refine the action segmentation re-sults from the backbone model by understanding the overall context of the entire video in a hierarchical way. HASR can be plugged into various backbone models, and it is also possible to use HASR to refine segmentation results from unseen backbone models.
• Our approach can boost up the performance of exist-ing state-of-the-art action segmentation models. For example, based on the 50Salads dataset [22], our model improves the segmental edit score from 67.9% to 77.4% for MS-TCN [5], from 75.8% to 77.3% for
SSTDA [3], from 79.3% to 81.0% for ASRF [10]. 2.