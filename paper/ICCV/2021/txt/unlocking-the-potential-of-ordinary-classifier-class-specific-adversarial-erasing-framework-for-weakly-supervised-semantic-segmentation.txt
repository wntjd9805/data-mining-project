Abstract
Weakly supervised semantic segmentation (WSSS) using image-level classification labels usually utilizes the Class
Activation Maps (CAMs) to localize objects of interest in images. While pointing out that CAMs only highlight the most discriminative regions of the classes of interest, adver-sarial erasing (AE) methods have been proposed to further
In this paper, we explore the less discriminative regions. review the potential of the pre-trained classifier which is trained on the raw images. We experimentally verify that the ordinary classifier1 already has the capability to acti-vate the less discriminative regions if the most discrimina-tive regions are erased to some extent. Based on that, we propose a class-specific AE-based framework that fully ex-ploits the potential of an ordinary classifier. Our framework (1) adopts the ordinary classifier to notify the regions to be erased and (2) generates a class-specific mask for erasing by randomly sampling a single specific class to be erased (target class) among the existing classes on the image for obtaining more precise CAMs. Specifically, with the guid-ance of the ordinary classifier, the proposed CAMs Gen-eration Network (CGNet) is enforced to generate a CAM of the target class while constraining the CAM not to in-trude the object regions of the other classes. Along with the pseudo-labels refined from our CAMs, we achieve the state-of-the-art WSSS performance on both PASCAL VOC 2012 and MS-COCO dataset only with image-level supervi-sion. The code is available at https://github.com/
KAIST-vilab/OC-CSE. 1.

Introduction
Deep learning has been spotlighted for its effective-ness and evolved to achieve a higher level of perfor-mance than conventional techniques. In semantic segmen-tation [6, 7, 30, 41, 42], it has also achieved significant per-formance improvement. However, unlike other tasks such
*The first two authors contributed equally. In alphabetical order. 1Throughout this paper, we will refer to a classifier pre-trained on raw images as a term ‘ordinary classifier’.
Figure 1: Qualitative comparison between the CAMs of baseline (ordinary classifier [2]) and ours on the PASCAL
VOC 2012. From 1 to 6: original images, ground truth seg-mentations, baseline CAMs, our CAMs at epoch 1, 5, 9. as object detection and classification, semantic segmen-tation requires dense pixel-level annotated labels that are time-consuming and costly to acquire. Accordingly, many attempts have been made for weakly-supervised semantic segmentation (WSSS) that only uses image-level classifica-tion labels [1–3, 10, 22, 33, 34, 37], scribbles [24, 31], and bounding boxes [8, 16, 26]. Among them, the most widely used approach is to utilize only image-level classification labels that can be easily obtained on massive amounts of data. In order to localize the object regions with the image-level labels, most existing approaches [1–3,5,10–12,23,28, 29, 33, 34, 37] utilize Class Activation Maps (CAMs) [40], represent the importance of image regions for the class pre-diction. To the best of our knowledge, most of the exist-ing WSSS researches have pointed out that the CAMs high-light only the most discriminative regions rather than the whole object regions (e.g. 1.3 and 2.3 in Fig. 1). To dispel this under-activation issue, Adversarial Erasing (AE) meth-ods [13, 22, 34, 39] have been widely used. They mask out the most highlighted parts of the CAMs from the image, and then a new classifier is trained on the masked images to seek the less highlighted regions.
In this paper, with a simple experiment inspired by the
AE methods in Fig. 2 (which will be explained in Sec. 3), we review the potential of the ordinary classifier. We find that the ordinary classifier already has sufficient capability to identify the less discriminative regions without additional training. So, in our view, it is redundant to train a new classifier for the masked images as in existing AE methods.
We experimentally verify that aggregating such regions us-ing an ordinary classifier can be beneficial to generate the pseudo-labels for WSSS.
To fully exploit the potential of the ordinary classifier, we propose a class-specific AE-based framework that ag-gregates the regions from the most discriminative to the less discriminative. Our framework is composed of two networks: a CAMs Generating Network (CGNet) and the ordinary classifier used for guidance. First, we randomly sample a single class to be erased (target class) among the existing classes on the image. Then, the CAM of the target class is picked up among the CAMs generated by CGNet for masking the input image in a back-propagable manner. Fi-nally, from the masked image, the ordinary classifier makes a prediction score of each class. We train the CGNet to lower the score of the erased target class, while the scores of the other existing classes are kept high.
The main advantage of the proposed class-specific eras-ing method is that it enables the CGNet to generate more precise CAMs. When all existing classes are simulta-neously erased from the image in a class-agnostic man-ner [22], a confusion of the CGNet at the object boundaries between different classes cannot be resolved. Our class-specific erasing method can reduce such confusion by pe-nalizing the intrusion of the CAMs at the object boundaries.
Figure 1 is a qualitative comparison between the CAMs of the baseline [2] (ordinary classifier) and the CGNet in the proposed framework. It shows that the localization ability of our CAMs gets better as the training proceeds, which supports the effectiveness of the proposed framework in a qualitative manner. We also conduct extensive ablation studies in Sec. 5.3 and experimentally verify that the pro-posed framework achieves additional performance gain in mean Intersection over Union (mIoU).
The contributions of our work are four-fold:
• We experimentally verify that an ordinary classifier has sufficient capability to segment the whole object region.
• To exploit the potential of the ordinary classifier, we pro-pose an adversarial erasing-based framework.
• We design a class-specific erasing method that fully uti-lizes multi-class images which yields CAMs with more accurate boundaries.
• We achieve new state-of-the-art performance both on the
PASCAL VOC 2012 val/test set and MS-COCO val set in the WSSS task with only the image-level classification labels. 2.