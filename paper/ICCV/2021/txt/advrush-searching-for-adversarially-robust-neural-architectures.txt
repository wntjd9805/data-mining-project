Abstract
Deep neural networks continue to awe the world with their remarkable performance. Their predictions, however, are prone to be corrupted by adversarial examples that are imperceptible to humans. Current efforts to improve the ro-bustness of neural networks against adversarial examples are focused on developing robust training methods, which update the weights of a neural network in a more robust direction. In this work, we take a step beyond training of the weight parameters and consider the problem of design-ing an adversarially robust neural architecture with high intrinsic robustness. We propose AdvRush, a novel ad-versarial robustness-aware neural architecture search algo-rithm, based upon a ﬁnding that independent of the training method, the intrinsic robustness of a neural network can be represented with the smoothness of its input loss landscape.
Through a regularizer that favors a candidate architecture with a smoother input loss landscape, AdvRush success-fully discovers an adversarially robust neural architecture.
Along with a comprehensive theoretical motivation for Ad-vRush, we conduct an extensive amount of experiments to demonstrate the efﬁcacy of AdvRush on various benchmark datasets. Notably, on CIFAR-10, AdvRush achieves 55.91% robust accuracy under FGSM attack after standard training and 50.04% robust accuracy under AutoAttack after 7-step
PGD adversarial training. 1.

Introduction
The rapid growth and integration of deep neural net-works in every-day applications have led researchers to ex-plore the susceptibility of their predictions to malicious ex-ternal attacks. Among proposed attack mechanisms, ad-versarial examples [56], in particular, raise serious security concerns because they can cause neural networks to make erroneous predictions with the slightest perturbations in the input data that are indistinguishable to the human eyes. This
*Correspondence to: Sungroh Yoon <sryoon@snu.ac.kr>.
Figure 1. Standard accuracy vs. robust accuracy evaluation results on CIFAR-10 for various neural architectures and the neural ar-chitecture searched by AdvRush. All architectures are adversar-ially trained using 7-step PGD and evaluated under AutoAttack.
AdvRush architecture achieves both standard accuracy-wise and robust accuracy-wise optimal frontiers. interesting property of adversarial examples has been draw-ing much attention from the deep learning community, and ever since their introduction, a plethora of defense meth-ods have been proposed to improve the robustness of neural networks against adversarial examples [33, 60, 65]. How-ever, there remains one important question that is yet to be explored extensively: Can the adversarial robustness of a neural network be improved by utilizing an architecture with high intrinsic robustness? And if so, is it possible to automatically search for a robust neural architecture?
We tackle the problem of searching for a robust neu-ral architecture by employing Neural Architecture Search (NAS) [69]. Due to the heuristic nature of designing a neural architecture, it used to take machine learning engi-neers with years of experience and expertise to fully ex-ploit the power of neural networks. NAS, a newly budding branch of automated machine learning, aims to automate this labor-intensive architecture search process. As the neu-ral architectures discovered automatically through NAS be-gin to outperform hand-crafted architectures across various domains [8, 39, 44, 57, 67], more emphasis is being placed on the proper choice of an architecture to improve the per-formance of a neural network on a target task.
The primary objective of the existing NAS algorithms is concentrated on improving the standard accuracy, and thus, they do not consider the robustness of the searched architec-ture during the search process. Consequently, they provide no guarantee of robustness for the searched architecture, since the “no free lunch” theorem for adversarial robustness prevents neural networks from obtaining sufﬁcient robust-ness without additional effort [4, 13, 68]. In addition, the trade-off between the standard accuracy and the adversarial robustness indicates that maximizing the standard accuracy and the adversarial robustness cannot go hand in hand [58], further necessitating a NAS algorithm designed speciﬁcally for adversarial robustness.
In this work, we propose a novel adversarial robustness-aware NAS algorithm, named AdvRush, which is a short-hand for “Adversarially Robust Architecture Rush.” Ad-vRush is inspired by a ﬁnding that the degree of curva-ture in the neural network’s input loss landscape is highly correlated with intrinsic robustness, regardless of how its weights are trained [68]. Therefore, by favoring a candidate architecture with a smoother input loss landscape during the search phase, AdvRush discovers a neural architecture with high intrinsic robustness. As shown in Figure 1, after undergoing an identical adversarial training procedure, the searched architecture of AdvRush simultaneously achieves the best standard and robust accuracies on CIFAR-10.
We provide comprehensive experimental results to demonstrate that the architecture searched by AdvRush is indeed equipped with high intrinsic robustness. On
CIFAR-10, standard-trained AdvRush achieves 55.91% ro-bust accuracy (2.50% improvement from PDARTS [8]) un-der FGSM, and adversarially-trained AdvRush achieves 50.04% robust from
RobNet-free [22]) under AutoAttack. Furthermore, we evaluate the robust accuracy of AdvRush on CIFAR-100,
SVHN, and Tiny-ImageNet to investigate its transferabil-ity; across all datasets, AdvRush consistently shows a sub-stantial increase in the robust accuracy compared to other architectures. For the sake of reproducibility, the code and representative model ﬁles of AdvRush will be made pub-licly available on github. accuracy (3.04% improvement
Our contributions can be summarized as follows:
• We propose AdvRush, a novel NAS algorithm for dis-covering a robust neural architecture. Because Ad-vRush does not require independent adversarial train-ing of candidate architectures for evaluation, its search process is highly efﬁcient.
• The effectiveness of AdvRush is demonstrated through comprehensive evaluation under a number of adversar-ial attacks. Furthermore, we validate the transferability of AdvRush to various benchmark datasets.
• We provide extensive theoretical justiﬁcation for Ad-vRush and complement it with the visual analysis of the discovered architecture. In addition, we provide a meaningful insight into what makes a neural architec-ture more robust against adversarial perturbations. 2.