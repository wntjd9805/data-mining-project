Abstract
Weakly supervised instance segmentation (WSIS) with only image-level labels has recently drawn much atten-tion. To date, bottom-up WSIS methods reﬁne discrimi-native cues from classiﬁers with sophisticated multi-stage training procedures, which also suffer from inconsistent object boundaries. And top-down WSIS methods are for-mulated as cascade detection-to-segmentation pipeline, in which the quality of segmentation learning heavily depends on pseudo masks generated from detectors. In this paper, we propose a uniﬁed parallel detection-and-segmentation learning (PDSL) framework to learn instance segmentation with only image-level labels, which draws inspiration from both top-down and bottom-up instance segmentation ap-proaches. The detection module is the same as the typi-cal design of any weakly supervised object detection, while the segmentation module leverages self-supervised learning to model class-agnostic foreground extraction, following by self-training to reﬁne class-speciﬁc segmentation. We fur-ther design instance-activation correlation module to im-prove the coherence between detection and segmentation branches. Extensive experiments verify that the proposed method outperforms baselines and achieves the state-of-the-art results on PASCAL VOC and MS COCO. 1.

Introduction
Instance segmentation [1, 2] is one of the fundamen-tal tasks in computer vision, which aims to simultaneously localize bounding boxes, classify target categories and es-*Corresponding author.
Figure 1: The overall ﬂowchart of PDSL framework. timate segmentation masks of object instances in images.
Despite its signiﬁcant progress in recent years, the domi-nant paradigms require a large number of training images with instance-level pixel-wise human annotations. How-ever, collecting such fully-labelled training data is labor-intensive [3] and restricts applicability of instance segmen-tation in many downstream high-level vision tasks, ranging from autonomous driving, pose estimation to image synthe-sis. Thus, it has motivated the exploration of weakly super-vised instance segmentation (WSIS), especially the setting where only image-level labels are used during training.
WSIS is an extremely challenging task with only a few attempts in previous literature. The bottom-up WSIS meth-ods [4, 5, 6, 7, 8, 9] used classiﬁcation networks to iden-tify object instances from discriminative localization cues in the images. While this is a promising line of works, the initial localization cues are quite coarse and not consis-tent with object boundaries [10], which over-concentrates on discriminative parts of objects and under-estimates small instances [11]. Moreover, those methods suffer from so-phisticated and multi-stage training processes to reﬁne in-termediate results, which also rely on class activation maps and segmentation proposals. On the other hand, the top-down methods [10, 12] requires weakly supervise object detection (WSOD) to generate pseudo-ground-truth masks by leveraging gradient of image pixels w.r.t. detection re-sults. Such detection-to-segmentation multi-task cascade causes the quality of pseudo masks heavily depending on
WSOD, which limits further improvement with large mar-gins. Although obtaining end-to-end pipeline, the top-down approaches have signiﬁcantly inferior performance com-pared to the bottom-up ones with sophisticated training pro-cedures prevailing in public benchmarks [13, 14].
To conquer the aforementioned limitations, we pro-pose a uniﬁed parallel detection-and-segmentation learn-ing (PDSL) framework to learn instance segmentation with only image-level labels, which draws inspiration from both top-down and bottom-up instance segmentation ap-proaches. Our motivation is to parallel top-down detec-tion and bottom-up segmentation via correlation learning in an end-to-end manner. The proposed PDSL frame-work has three advantages. First, compared to top-down
WSIS methods, PDSL decouples the generation of pseudo-ground-truth masks from detectors and explores bottom-up object cues to learn segmentation, which models class-agnostic to class-speciﬁc foreground masks progressively.
Second, compared to bottom-up methods, PDSL imposes bounding-box constraint from detection module on segmen-tation learning, which are encouraged to match up with ob-ject boundaries. Third, PDSL further collaborates detection module with segmentation learning by explicitly modelling correlations between them.
To this end, the proposed PDSL consists of three key components: object detection, image segmentation and cor-relation learning modules, as illustrated in Fig. 1. First, the detection branch is the same as the typical design of any top-down detectors learned from image-level labels. Second, the segmentation branch leverages self-supervised learning to model class-agnostic foreground extraction, which is fol-lowed by self-training to learn class-speciﬁc object segmen-tation constrained by bounding boxes. Third, to improve the coherence between detection and segmentation, we fur-ther propose instance-activation correlation learning, which impose a high correlation between two branches for acti-vation of the same object instances. Extensive experiments on PASCAL VOC [13] and MS COCO [14] show that the proposed PDSL outperforms baseline models and achieves the state-of-the-art results. For the ﬁrst time, we show that a top-down approach delivers competitive WSIS results.
The contributions of this work are three folds:
• We propose a cooperative parallel detection-and-segmentation learning framework to learn instance segmentation with only image-level labels.
It intro-duces bottom-up object cues to top-down pipeline and disentangles segmentation supervision from detectors.
• The segmentation branch cooperates self-supervised learning and self-training to model from class-agnostic foreground extraction to class-speciﬁc object segmen-tation progressively, while the detection branch uti-lizes off-the-shelf WSOD methods to mine object in the form of bounding boxes.
• We further propose instance-activation correlation module to enhance the coherence between detection and segmentation branches. 2.