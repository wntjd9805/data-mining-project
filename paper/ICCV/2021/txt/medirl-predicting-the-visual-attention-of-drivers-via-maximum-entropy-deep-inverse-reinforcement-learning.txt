Abstract
Inspired by human visual attention, we propose a novel inverse reinforcement learning formulation using Maximum
Entropy Deep Inverse Reinforcement Learning (MEDIRL) for predicting the visual attention of drivers in accident-prone situations. MEDIRL predicts fixation locations that lead to maximal rewards by learning a task-sensitive re-ward function from eye fixation patterns recorded from at-tentive drivers. Additionally, we introduce EyeCar, a new driver attention dataset in accident-prone situations. We conduct comprehensive experiments to evaluate our pro-posed model on three common benchmarks: (DR(eye)VE,
BDD-A, DADA-2000), and our EyeCar dataset. Results in-dicate that MEDIRL outperforms existing models for pre-dicting attention and achieves state-of-the-art performance.
We present extensive ablation studies to provide more in-sights into different features of our proposed model.1 1.

Introduction
Autonomous vehicles have witnessed significant ad-vances in recent years. These vehicles promise better safety and freedom from the prolonged and monotonous task of driving. However, one of the remaining safety challenges of vision-based models integrated into these vehicles is how to quickly identify important visual cues and under-stand risks involved in traffic environments at a time of urgency [51]. Humans have an incredible visual attention ability to quickly detect the most relevant stimuli, to direct attention to potential hazards in complex situations [43], and to select only a relevant fraction of perceived informa-tion for more in-depth processing [53]. Humans are able to guide their attention by a combination of bottom-up (stimuli driven, e.g., color and intensity) and top-down (task driven, e.g., current goals or intention) mechanisms [13, 27]. 1The code and dataset are provided for reproducibility in https:// github.com/soniabaee/MEDIRL-EyeCar.
Figure 1: Given a driving video and corresponding eye fixa-tions as inputs, MEDIRL learns to model the fixation selec-tion as a sequence of states and actions (St, At). MEDIRL then predicts a maximally-rewarding fixation location by perceptually parsing a scene to extract rich visual informa-tion (environment) and accumulating a sequence of visual cues through fixations (state).
During task-specific activities, the goal-directed behav-ior of humans along with their underlying target-based se-lective attention, enables drivers to ignore objects and un-necessary details in their field of view that are irrelevant to their decisions [7, 8]. For example, at one moment, a driver’s goal might be to initiate an overtaking maneuver, thus a nearby vehicle becomes the target object. Later, the driver may need to stop abruptly to avoid an accident, thereby the brake light of the car in front becomes the target object. Despite recent progress in computer vision models for autonomous systems [28, 63], they are still behind the foveal vision ability of humans [42, 61, 69].
Inverse reinforcement learning (IRL) algorithms are ca-pable to address this problem by learning to imitate the ef-ficient attention allocation produced by an expert, i.e. an attentive driver [41]. It is important that autonomous ve-hicles leverage human visual attention mechanisms to im-prove their performance, especially for better safety in crit-ical situations where rare events can be encountered. In this paper, we introduce Maximum Entropy Deep Inverse Rein-forcement Learning (MEDIRL) to learn task-specific visual
attention policies to reliably predict attention in imminent rear-end collisions.
Prior efforts in bottom-up saliency models commonly prioritize pixel location (e.g., free-viewing fixation) [31, 44, 49]. These models do not fully capture driver attention in goal-directed behavior [15, 61, 61, 32]. Moreover, video-based saliency models usually aggregate spatial features guided by saliency maps in each frame [57, 26, 25, 64].
However, most of these fixation prediction models utilized a particular source of information [61, 45, 17], and did not consider to jointly process spatial and temporal informa-tion [57, 25]. In this work, we aim to predict eye fixation patterns made prior to critical situations, where these pat-terns can be either spatial (fixation map) or spatiotempo-ral (fixation sequences) features.
Inverse reinforcement learning (IRL) is an advanced form of imitation learning [74, 60] that enables a learn-ing agent to acquire skills from expert demonstrations [52].
Our proposed MEDIRL model learns a sequence of eye fix-ations by considering each fixation as a potential source of reward [65]. We leverage collective visual information that has been deemed relevant for video saliency in prior works [39, 44, 9]. For example, if an autonomous system tries to locate the salient regions of a driving scene before an imminent rear-end collision, the desired visual behavior can be demonstrated by studying the attention of a driver who effectively detects brake lights.
In this way, the learning agent can infer a reward function explaining experts’ be-havior and optimize its own behavior accordingly. To this end, our proposed model predicts driver attention where a fixation pattern is represented as state-action pairs. Given a video frame input paired with eye fixations, MEDIRL pre-dicts a maximally-rewarding fixation location (action) by perceptually parsing a scene to extract rich visual informa-tion (environment), and accumulating a sequence of visual cues through fixations (state) (see Figure 1).
Additionally, we introduce EyeCar, a new driver atten-tion dataset in accident-prone situations. EyeCar is es-sential for training goal-directed attention models as it is the only dataset capturing attention before accidents in an environment with high traffic density. We exhaustively evaluate our proposed model on three common bench-marks (DR(eye)VE [45], BDD-A [62], DADA-2000 [17]) as well as our own EyeCar dataset. The experimental results show that MEDIRL outperforms state-of-the-art models on driver attention prediction. We also conduct extensive abla-tion studies to determine which input features are most im-portant for driver attention prediction in critical situations.
Our contributions can be summarized as follows:
• We propose MEDIRL, a novel IRL formulation for predicting driver visual attention in accident-prone sit-uations. MEDIRL uses maximum entropy deep in-verse reinforcement learning to predict maximally-rewarding fixation locations.
• We introduce EyeCar, a new driver attention dataset comprised of rear-end collisions videos for the goal-directed attention problem in critical driving situations.
• Extensive experimental evaluation on three driver at-tention benchmark datasets: DR(eye)VE [45], BDD-A [62], DADA-2000 [17], and EyeCar. Results show that MEDIRL outperforms existing models for atten-tion prediction and achieves state-of-the-art perfor-mance. Besides, we present ablation studies showing target (brake light), non-target (context), and driving tasks are important for predicting driver attention. 2.