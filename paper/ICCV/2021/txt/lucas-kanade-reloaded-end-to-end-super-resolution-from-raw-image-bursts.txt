Abstract
This presentation addresses the problem of reconstruct-ing a high-resolution image from multiple lower-resolution snapshots captured from slightly different viewpoints in space and time. Key challenges for solving this super-resolution problem include (i) aligning the input pictures with sub-pixel accuracy, (ii) handling raw (noisy) images for maximal faithfulness to native camera data, and (iii) designing/learning an image prior (regularizer) well suited to the task. We address these three challenges with a hy-brid algorithm building on the insight from [45] that alias-ing is an ally in this setting, with parameters that can be learned end to end, while retaining the interpretability of classical approaches to inverse problems. The effectiveness of our approach is demonstrated on synthetic and real im-age bursts, setting a new state of the art on several bench-marks and delivering excellent qualitative results on real raw bursts captured by smartphones and prosumer cam-eras. Our code is available at https://github.com/ bruno-31/lkburst.git. 1.

Introduction
The problem of reconstructing high-resolution (HR) im-ages from lower-resolution (LR) ones comes in multiple ﬂa-vors, that may signiﬁcantly differ from each other in both technical detail and overall objectives. When a single LR image is available, the corresponding inverse problem is severely ill-posed, requiring very strong priors about the type of picture under consideration [18, 47]. For natural images, data-driven methods based on convolutional neural networks (CNNs) have proven to be very effective [26, 44].
Generative adversarial networks (GANs) have also been used to synthesize impressive HR images that may, how-1
ever, contain “hallucinated” high-frequency details [9, 28].
In the true super-resolution setting [31, 39, 47],1 where multiple LR frames are available, HR details are present in the data, but they are spread among multiple misaligned images, with technical challenges such as recovering sub-pixel registration, but also the promise of recovering veridi-cal information in applications ranging from amateur pho-tography to astronomy, biological and medical imaging, mi-croscopy imaging, and remote sensing.
Videos are of course a rich source of multiple, closely-related pictures of the same scene, with several recent ap-proaches to super-resolution in this domain, often combin-ing data-driven priors from CNNs with self-similarities be-tween frames [21, 27, 43]. However, most digital videos are produced by a complex pipeline mapping raw sensor data to possibly compressed, lower-resolution frames, resulting in a loss of high-frequency details and spatially-correlated noise that may be very difﬁcult to invert [12]. With the abil-ity of modern smartphone and prosumer cameras to record raw image bursts, on the other hand, there is a new oppor-tunity to restore the corresponding frames before the im-age signal processor (ISP) of the camera produces irreme-diable damage [4, 45]. This is the problem addressed in this presentation, and it is challenging for several reasons: (i) images typically contain unknown motions due to hand tremor,2 making subpixel alignment difﬁcult; (ii) convert-ing noisy raw sensor data to full-color images is in itself a difﬁcult problem known as demosaicking [22, 25]; and (iii) effective image priors are often data driven, thus requiring a differentiable estimation procedure for end-to-end learning.
In this paper, we jointly address these issues and propose a new approach that retains the interpretability of classi-cal inverse problem formulations while allowing end-to-end learning of models parameters. This may be seen as a bridge between the “old world” of signal processing and the “brave new one” of data-driven black boxes, without sacriﬁcing in-terpretability: On the one hand, we address an inverse prob-lem with a model-based optimization procedure alternating motion and HR image estimation steps, directly building on classical work from the 1980s [1, 29] and 1990s [16].
On the other hand, we also fully exploit modern technology in the form of a plug-and-play prior [6, 42] that gracefully mixes deep neural networks with variational approaches. In turn, unrolling the optimization procedure [7, 25, 48] allows us to learn the model parameters end to end by using train-ing data with synthetic motions [4].
Since aliasing produces low-frequency artefacts associ-ated with undersampled high-frequency components of the original signal, it is typically considered a nuisance, mo-1“Single-image super-resolution” has become a popular nickname for single-image upsampling under strong priors; here, we use the classical deﬁnition of super-resolution from multiple LR snapshots [39, 47]. 2Image bursts acquired on a tripod may also present subpixel misalign-ments in practice due to ﬂoor vibrations, as observed in our experiments. tivating camera manufacturers to add anti-aliasing (optical)
ﬁlters in front of the sensor.3 Yet, aliased images carry high-frequency information, which may be recovered from mul-tiple shifted measurements. Perhaps surprisingly, aliasing is thus an ally in the context of super-resolution, a fact al-ready noted in earlier references, see [41]. As shown in the rest of this presentation, our approach to raw burst super-resolution also exploits this insight, and it achieves a new state of the art on several standard benchmarks that use synthetic motion for ground truth. It also gives excellent qualitative results on real data obtained with smartphone and prosumer cameras. Interestingly, as illustrated by Fig-ure 1, our method has turned out to be surprisingly robust to noise given the particularly challenging setting of raw image super-resolution, which involves simultaneous blind denoising, demosaicking, registration, and upsampling.
Summary of contributions.
• To the best of our knowledge, we propose the ﬁrst model-based architecture learnable end to end for joint image alignment and super-resolution from raw image bursts.
• We introduce a new differentiable image registration mo-dule that can be applied to images of different resolutions, is readily integrable in neural architectures, and may ﬁnd other uses beyond super-resolution.
• We show that our approach gives excellent results on both real image bursts (with up to ×4 upsampling for raw im-ages) and synthetic ones (up to ×16 for RGB images). 2.