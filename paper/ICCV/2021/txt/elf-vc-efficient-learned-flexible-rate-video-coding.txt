Abstract
While learned video codecs have demonstrated great promise, they have yet to achieve sufficient efficiency for practical deployment.
In this work, we propose several novel ideas for learned video compression which allow for improved performance for the low-latency mode (I- and P-frames only) along with a considerable increase in compu-tational efficiency. In this setting, for natural videos our ap-proach compares favorably across the entire R-D curve un-der metrics PSNR, MS-SSIM and VMAF against all main-stream video standards (H.264, H.265, AV1) and all ML codecs. At the same time, our approach runs at least 5x faster and has fewer parameters than all ML codecs which report these figures.
Our contributions include a flexible-rate framework al-lowing a single model to cover a large and dense range of bitrates, at a negligible increase in computation and pa-rameter count; an efficient backbone optimized for ML-based codecs; and a novel in-loop flow prediction scheme which leverages prior information towards more efficient compression.
We benchmark our method, which we call ELF-VC (Ef-ficient, Learned and Flexible Video Coding) on popular video test sets UVG and MCL-JCV under metrics PSNR,
MS-SSIM and VMAF. For example, on UVG under PSNR, it reduces the BD-rate by 44% against H.264, 26% against
H.265, 15% against AV1, and 35% against the current best
ML codec. At the same time, on an NVIDIA Titan V GPU our approach encodes/decodes VGA at 49/91 FPS, HD 720 at 19/35 FPS, and HD 1080 at 10/18 FPS. 1.

Introduction
The trends of growth of video capture and consumption are staggering. Every day, 1.5 billion hours of videos are watched across YouTube, Netflix and Facebook, and 23 mil-lion new cameras are added into circulation [44, 20, 36, 21].
In the last few years, ML-based compression algorithms have shown promise in their potential to mitigate some of this global video congestion. The ML subfield of end-to-*Equal contribution
Figure 1: BD-Rate for ML-based codecs relative to AV1 as a function of encode/decode time on HD 1080 videos
[41, 13, 28, 26] (UVG dataset, PSNR metric). Our approach reduces the BD-rate by 54% relative to the current fastest
ML codec which reports speed [26], while running 5x faster. end methods for image compression has grown rapidly with hundreds of papers (for instance, [4, 32, 5]) which demon-strate unequivocally that learned approaches can achieve improved coding efficiency relative to their hard-coded counterparts.
These approaches have, in turn, planted the seeds for
ML-based video coding algorithms. Even though end-to-end video coding research has only taken its first few steps, it is clear that learned approaches have the potential to yield significant bitrate savings over the existing standards
[33, 28, 13, 12, 27]. However, there still exists an ele-phant in the room: is it possible for ML-based approaches to achieve sufficient flexibility and efficiency to become prac-tical in the real world?
We propose a new ML video codec, ELF-VC (Effi-cient, Learned and Flexible-Rate Video Coding) for the low-latency mode, which aims to improve three key weak-nesses of ML-based video compression: bitrate flexibility, compression efficiency, and speed.
Bitrate flexibility Traditional codecs can dynamically ad-just the bitrate to achieve a target bandwidth or target com-pression quality as a function of the complexity of the video and changing network conditions. Most existing ML codecs, however, represent each point on the R-D curve with a separate model, which is impractical due to param-eter explosion and model loading inefficiency. In contrast,
ELF is able to support a large and dense range of bitrates on a per-frame basis with a single set of parameters. area. The traditional codecs have been exceptionally well-engineered and tuned, and have been difficult for the ML community to match both in terms of compression fidelity but also computational efficiency.
Compression Efficiency While ML-based codecs have shown improved compression efficiency over H.265, no ML codec has yet to outperform the standards across the en-tire PSNR curve. Moreover, no benchmarks have been pre-sented on the VMAF metric, nor against AV1, as ML codecs have not compared favorably in these settings. We bench-mark ELF on popular video test sets UVG and MCL-JCV under metrics PSNR, MS-SSIM and VMAF. In the low-latency mode, for natural videos ELF compares favorably across the entire R-D curve against the standards, and all other ML codecs. For example, on UVG under PSNR, ELF reduces the BD-rate by 44% against H.264, 26% against
H.265, 15% against AV1, 35% against the next-best ML codec [2], and 54% against the next-fastest ML-codec [26] (while running 5x faster).
Speed For any practical application encoding must run at a reasonable frame rate, and decoding must run in real-time. Research on learned video compression has focused on improving the R-D curve, often at the expense of speed.
For instance, autoregressive approaches inherently cannot be parallelized, resulting in methods that take many seconds to decode a single frame. In contrast, ELF runs at least 5x faster than all other ML codecs which report timings, and with fewer parameters. On an NVIDIA Titan V GPU, ELF encodes/decodes VGA at 49/91 FPS, HD 720 at 19/35 FPS, and HD 1080 at 10/18 FPS.
Our primary contributions are: 1. A novel framework for efficient rate control for learned video coding. This allows a single model to encode each frame with a wide range of bitrates, at a negligible increase to computation and parameter count. 2. A backbone specifically optimized to achieve strong performance on compression tasks while remaining computationally efficient. 3. An in-loop flow predictor, a novel module that utilizes previously transmitted information to get a strong ini-tial estimate of the motion for the current frame. 1.1.