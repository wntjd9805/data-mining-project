Abstract
Deep learning-based methods for video pedestrian de-tection and tracking require large volumes of training data to achieve good performance. However, data acquisition in crowded public environments raises data privacy concerns – we are not allowed to simply record and store data with-out the explicit consent of all participants. Furthermore, the annotation of such data for computer vision applica-tions usually requires a substantial amount of manual ef-fort, especially in the video domain. Labeling instances of pedestrians in highly crowded scenarios can be challenging even for human annotators and may introduce errors in the training data. In this paper, we study how we can advance different aspects of multi-person tracking using solely syn-thetic data. To this end, we generate MOTSynth, a large, highly diverse synthetic dataset for object detection and tracking using a rendering game engine. Our experiments show that MOTSynth can be used as a replacement for real data on tasks such as pedestrian detection, re-identification, segmentation, and tracking. 1.

Introduction standing research history, with applications ranging from autonomous driving to visual surveillance. Since the ad-vent of deep learning, the community has been investigating how to effectively leverage neural networks [41, 45, 54, 69, 13, 65, 42, 25, 75, 6, 10, 78, 80, 38] to advance the field.
However, all these approaches are data-hungry, and data collection and labeling are notoriously difficult and expen-sive. Moreover, dataset collection in public environments1 raises privacy concerns. In fact, European Union already passed privacy-protecting laws such as General Data Pro-tection Regulations (GDPR [2]) to protect the privacy of its citizens that prohibit the acquisition of personal visual data without authorization; ethical issues regarding privacy are also critical in the US, where datasets for training person re-identification modules such as DukeMTMC [62] were taken offline due to privacy concerns [33].
A possible solution for the aforementioned issues is to employ virtual worlds. The community has already recog-nized the potential of synthetic data, successfully used for benchmarking [44] or to compensate for the lack of training data [3, 9]. To the best of our knowledge, so far, synthetic data could fully replace recorded data only for low-level tasks such as optical flow estimation [21]. For higher-level tasks, such as object detection, tracking and segmentation,
Object detection and tracking in crowded real-world sce-narios are challenging and difficult problems with long-1Crowded public scenes are especially difficult to record during the
COVID-19 pandemic. 1
existing methods usually need mixed synthetic and real data and employ alternate training scheme [3] or domain adap-tation [9] and randomization [72] techniques.
In this paper, we aim to answer a challenging question:
Can we advance state-of-the-art methods in pedestrian de-tection and tracking using only synthetic data? To this end, we created MOTSynth, a large synthetic dataset for pedes-trian detection, tracking, and segmentation, designed to re-place recorded data. MOTSynth comes in a bundle with temporally consistent bounding boxes and instance segmen-tation labels, pose occlusion information, and depth maps.
As shown in the field of robot reinforcement learning [72] and vision [73], synthetic datasets should significantly vary in terms of lighting, pose, and textures to ensure that the neural network learns all invariances present in the real world. Based on these insights, we generate a large and diverse dataset that varies in terms of environments, camera viewpoints, object textures, lighting conditions, weather, seasonal changes, and object identities (see Fig. 1). Our ex-perimental evaluation confirms that diversity plays a pivotal role in bridging the synthetic-to-real gap.
The main focus of our study is on how MOTSynth can help us to advance pedestrian detection, re-identification, and tracking by studying how different aspects of these tasks can benefit from our data. To this end, we first train several state-of-the-art models for pedestrian detec-tion, segmentation, re-identification, frame-to-frame regres-sion and association on synthetic data and evaluate their performance on the real-world pedestrian tracking dataset
MOTChallenge [18]. Our experiments show that mod-els, trained on synthetic data are on-par with state-of-the-art on MOTChallenge MOT17&MOT20, while extremely crowded MOT20 still require fine-tuning. Second, we show that prior synthetic datasets [24, 43] are not suitable for bridging the synth-to-real gap for the task of pedestrian de-tection and tracking. Moreover, we confirm that the diver-sity in MOTSynth is a key for bridging this gap – and is far more important than the sheer amount of data. In addition to a thorough experimental analysis, MOTSynth also opens the door to future research on how different components, such as depth and human pose, can be used to advance multi-object tracking in a well-controlled environment.
To summarize, the main contributions of this paper are the following: (i) we open source the largest synthetic dataset for pedestrian detection and tracking with more than 1.3 million densely annotated frames and 40 million pedes-trian instances; (ii) we show that such a diverse dataset can be a complete substitute for real-world data for high-level tasks such as pedestrian detection and tracking in several scenarios, as well as re-identification and tracking with seg-mentation; (iii) we provide a comprehensive analysis on how such synthetic worlds can be used to advance the state-of-the-art in pedestrian tracking and detection. 2.