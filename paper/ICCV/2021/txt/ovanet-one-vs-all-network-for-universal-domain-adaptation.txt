Abstract
Universal Domain Adaptation (UNDA) aims to handle both domain-shift and category-shift between two datasets, where the main challenge is to transfer knowledge while rejecting “unknown” classes which are absent in the la-beled source data but present in the unlabeled target data.
Existing methods manually set a threshold to reject ”un-known” samples based on validation or a pre-defined ratio of “unknown” samples, but this strategy is not practical.
In this paper, we propose a method to learn the thresh-old using source samples and to adapt it to the target do-main. Our idea is that a minimum inter-class distance in the source domain should be a good threshold to decide be-tween “known” or “unknown” in the target. To learn the inter- and intra-class distance, we propose to train a one-vs-all classifier for each class using labeled source data.
Then, we adapt the open-set classifier to the target domain by minimizing class entropy. The resulting framework is the simplest of all baselines of UNDA and is insensitive to the value of a hyper-parameter, yet outperforms baselines with a large margin. Implementation is available at https:// github.com/VisionLearningGroup/OVANet. 1.

Introduction
Deep neural networks can learn highly discriminative representations for image recognition tasks [6, 30, 14, 26, 12] given a large amount of training data, but do not gen-eralize well to novel domains. Collecting a large amount of annotated data in novel domains incurs a high annota-tion cost. To tackle this issue, domain adaptation trans-fers knowledge from a label-rich training domain to a label-scarce novel domain [1]. Traditional unsupervised domain adaptation (UDA) assumes that the source domain and the target domain completely share the sets of categories, i.e., closed-set DA. But, this assumption does not often hold in practice. There are several possible situations: the target domain contains categories absent in the source (unknown categories), i.e., open-set DA (ODA) [4, 29]; the source do-main includes categories absent in the target (source pri-Figure 1: Existing open-set or universal domain adaptation meth-ods handle unknown samples by manually setting a threshold to re-ject them, either by validation or prior knowledge about the target domain. If set incorrectly, it can mistakenly reject known classes as shown here, e.g., car and truck. Instead, we propose to learn the threshold by training one-vs-all classifiers for each class. vate categories); i.e., partial DA (PDA) [5]; a mixture of
ODA and PDA, called open-partial DA (OPDA). Many ap-proaches have been tailored for a specific setting, but a true difficulty is that we cannot know the category shift in ad-vance.
The task of universal domain adaptation (UNDA) was proposed [37, 28] to account for the uncertainty about the category-shift. The assumption is that the label distributions of labeled and unlabeled data can be different, but we can-not know the difference in advance. Since estimating the label distributions of unlabeled data is very hard in real ap-plications, the setting is very practical. Although we focus on a domain shift problem in this paper, the setting also ap-plies to a semi-supervised learning problems [11].
In this task, our goal is to have a model that can cate-gorize target samples into either one of the correct known labels or the unknown label. The main technical difficulty is that no supervision is available to distinguish unknown samples from known ones; that is, we do not know how many of them are unknown nor the properties of the un-known instances. Obtaining this prior knowledge without manual labeling is hard in practice.
To allow a model to learn the concept of unknown, existing UNDA and ODA methods employ various tech-niques: rejecting a certain ratio of target samples [3], vali-dating a threshold to decide unknown by using labeled tar-get samples [7], and synthetically generating unknown in-stances [15]. Rejecting some ratio of target samples works well if the ratio is accurate. But, estimating the ratio is hard without having labeled target samples. Validation with labeled target samples violates the assumption of UNDA.
Synthesized unknown instances define the concept of the unknown for a learned model, but tuning the generation process requires validation with labeled samples since the generated data is not necessarily similar to real unknown data. In summary, as the center of Fig. 1 describes, these existing methods manually define the threshold to reject un-known instances. To achieve a practical solution, we need an approach that does not need the ratio of unknown sam-ples nor any validation to set the threshold.
We cast a question to solve the problem: can we leverage the inter-class distance between source categories to learn the threshold? We assume that the minimum inter-class dis-tance is a good threshold to determine whether a sample comes from the class since it defines a minimum margin from other classes. If the distance between a sample and a class is smaller than the margin, the sample should belong to the class. If the sample does not lie within the margin for any classes, it should be unknown. Fig. 1 illustrates the idea. Car and truck share similar features but belong to different classes. If a model knows the margin between the two classes, it can distinguish unknown classes, e.g., bug and bone, from car and truck.
Given this insight, we explore a simple yet powerful idea: training a one-vs-all (OVA) classifier for every class in the source domain. We train the classifier to categorize inputs other than the corresponding class as negatives. The classifier learns a boundary between positive and negative classes, i.e., employs inter-class distance to learn the bound-If all of the classifiers regard the input as negative, ary. we assume the input is from unknown classes. Therefore, a model can learn the threshold to reject unknown classes by using source samples.
In addition, we propose novel hard-negative classifier sampling, which updates open-set classifiers of a positive and a hard negative class for each source sample, to efficiently learn the minimum inter-class distance for each class. The technique makes a model scal-able to a large number of classes. For unlabeled target sam-ples, we propose to apply open-set entropy minimization (OEM), where the entropy of the one-vs-all classifiers is minimized. This allows a model to align unlabeled target samples to either known or unknown classes. Our method is significantly simpler than existing methods since it has only one unique hyper-parameter that controls the trade-off between the classification loss of source samples and OEM, yet shows great robustness to different label distributions of the target domain.
In experiments, we extensively evaluate our method on universal domain adaptation benchmarks and vary the pro-Method
UAN [37]
CMU [7]
USFDA [15]
ROS [3]
DANCE [28]
OVANet
No. of HP 2 3 3 4 3 1
Threshold
Validated
Validated
Synthesize unknown samples
Reject 50% of target data
Decide by No. of classes
Learned by source
Table 1: Comparison of open-set and universal DA methods.
HP denotes hyper-parameter. Note that USFDA [15] leverages synthetically generated negatives, which requires a complicated process to generate them. portion of shared and unknown classes. This simple method outperforms various baselines that explicitly or implicitly employ the ratio of unknown samples. Moreover, the pro-posed way of detecting unknown classes is effective to set a threshold to reject unknown classes in semi-supervised learning. 2.