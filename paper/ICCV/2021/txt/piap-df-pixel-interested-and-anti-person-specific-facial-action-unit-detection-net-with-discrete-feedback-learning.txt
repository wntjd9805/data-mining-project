Abstract
Facial Action Units (AUs) are of great significance in communication. Automatic AU detection can improve the understanding of psychological conditions and emotional status. Recently, several deep learning methods have been proposed to detect AUs automatically. However, several challenges, such as poor extraction of fine-grained and ro-bust local AUs information, model overfitting on person-specific features, as well as the limitation of datasets with wrong labels, remain to be addressed. In this paper, we pro-pose a joint strategy called PIAP-DF to solve these prob-lems, which involves 1) a multi-stage Pixel-Interested learn-ing method with pixel-level attention for each AU; 2) an
Anti Person-Specific method aiming to eliminate features associated with any individual as much as possible; 3) a semi-supervised learning method with Discrete Feedback, designed to effectively utilize unlabeled data and mitigate the negative impacts of wrong labels. Experimental results on the two popular AU detection datasets BP4D and DISFA prove that PIAP-DF can be the new state-of-the-art method.
Compared with the current best method, PIAP-DF improves the average F1 score by 3.2% on BP4D and by 0.5% on
DISFA. All modules of PIAP-DF can be easily removed af-ter training to obtain a lightweight model for practical ap-plication. 1.

Introduction
Facial expression, a natural way of human communi-cation in peopleâ€™s daily lives, is also an intuitive reflec-tion of human emotions, mental states, and conscious-ness when analyzing emotion recognition tasks. There are some popular facial expression topics categorized as mi-croexpressions. Microexpressions are reflected by rapid and unconscious spontaneous facial movements, and stud-ies have shown that microexpressions cannot be concealed
[8]. These characteristics make the detection of microex-pressions necessary in some specific situations, such as the diagnosis of depressed patients [9] and conversations of criminals. Moreover, microexpression detection also has a potential value in many other emotion recognition tasks
[15, 32, 35, 43]. In previous studies, the Facial Action Cod-ing System (FACS) [13] method is often used to encode mi-croexpressions. In FACS, each expression is considered as a combination of multiple action units (AU). By detecting the AU, FACS can effectively eliminate the ambiguity prob-lem in microexpression annotation. Therefore, a reliable
AU detection system is of great importance for the analysis of facial microexpressions.
In FACS, different AUs are associated with specific fa-cial muscles, which in turn correspond to the features of different regions of the face. Sometimes one AU may also correspond to more than one region. Therefore, lo-cal information is essential for AU detection. Traditional
[3, 7, 10, 19, 26, 42] approaches use manual methods to rep-resent different local regions . In recent years, deep learning methods for facial expression detection are gaining popular-ity and some results have been achieved. Early work used simple CNN for learning. Later, deeper neural networks were employed to improve performance. Due to the im-Figure 1. a) Comparison of patch and PI method on AU6, marked as the red border and the blue border, respectively. b) PI Maps on
AU2 and AU6. The predefined PI Maps are generated with land-mark information. After the second stage of PI, we have refined
PI Maps, shown as binary and the heatmap views.
Figure 2. Overview of PIAP and Semi-Supervised Learning of Discrete Feedback. portance of local features for facial AU detection, previous works typically use facial landmarks to localize these re-gions or divide the face into patches. In practice, however,
AU annotators are sometimes unable to give the exact re-gion of the AU. In other words, the artificially defined AU region correlations are actually not robust prior knowledge.
Besides, the giant Patch does not fit the AU-related region well. As shown in Figure 1, these regions are not always rectangles, such as AU6, nor fixed due to uncertainties in the head pose and other factors. In addition, as mentioned earlier, some AUs are simultaneously associated with mul-tiple and fine-grained regions. Therefore, the idea of using a simple landmark-based patch is not very effective. In ad-dition, AU detection should be independent of any specific individual. Due to the limited number of participants in cur-rent AU datasets, trained models can be poorly generalized.
Therefore, it is necessary to remove person-specific effects on the model.
Recently, self-supervised and semi-supervised learning has made huge leaps. Contrastive learning usually makes the model capable of outputting approximate encodings for different views of the same sample and distinguishing be-tween encodings of different samples, while pseudo-based methods expect models to output low-entropy predictions on the samples never been seen before. It has been proven that self-supervised and semi-supervised learning be effec-tive in improving the generalization ability of the model.
In this paper, we propose PIAP-DF, a set of comprehen-sive policies for AU detection networks. PIAP integrates two learning strategies, Pixel-Interested (PI) learning and
Anti Person-Specific (AP) learning. PI is devoted to pro-viding pixel-level attention for each AU, whereas AP tries to remove person-specific features. Besides PIAP, we also propose Discrete Feedback (DF) technique based on semi-supervised learning, which aims to reduce the effect of mis-labeling and improve the robustness. We use EfficientNet-B1 [39] as our AU encoder. In our architecture, PI, AP, and
DF can be removed after training to obtain a lightweight network for real-world scenarios.
The main contributions of this paper: 1) We propose a Pixel-Interested learning method to improve the perfor-mance of AU detection. PI ensures that the irregular local information and pixel-level correlation of AUs can be re-tained in the deep layer during forward propagation, thus providing effective supervision of AU detection. 2) We pro-pose an Anti Person-Specific learning method. We elimi-nate person-specific features from the hidden layer of the network with the help of the same encoder trained on the fa-cial recognition dataset. AP allows the model to focus more on the features of the AU itself on a limited dataset of par-ticipants, improving the generality of the network. 3) Based on the characteristics of the dataset and task, we propose a semi-supervised learning strategy with discrete feedback.
By utilizing an appropriate amount of additional data and randomly inactivated labels, DF could reduce the impact of mislabeling on training and improve network robustness. 2.