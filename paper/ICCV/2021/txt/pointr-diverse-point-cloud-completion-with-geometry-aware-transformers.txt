Abstract
Point clouds captured in real-world applications are of-ten incomplete due to the limited sensor resolution, single viewpoint, and occlusion. Therefore, recovering the com-plete point clouds from partial ones becomes an indispens-able task in many practical applications. In this paper, we present a new method that reformulates point cloud com-pletion as a set-to-set translation problem and design a new model, called PoinTr that adopts a transformer encoder-decoder architecture for point cloud completion. By rep-resenting the point cloud as a set of unordered groups of points with position embeddings, we convert the point cloud to a sequence of point proxies and employ the transform-ers for point cloud generation. To facilitate transformers to better leverage the inductive bias about 3D geometric structures of point clouds, we further devise a geometry-aware block that models the local geometric relationships explicitly. The migration of transformers enables our model to better learn structural knowledge and preserve detailed information for point cloud completion. Furthermore, we propose two more challenging benchmarks with more di-verse incomplete point clouds that can better reflect the real-world scenarios to promote future research. Experi-mental results show that our method outperforms state-of-the-art methods by a large margin on both the new bench-marks and the existing ones. Code is available at https:
//github.com/yuxumin/PoinTr. 1.

Introduction
Recent developments in 3D sensors largely boost re-searches in 3D computer vision. One of the most com-monly used 3D data format is the point cloud, which re-quires less memory to store but convey detailed 3D shape
*Equal contribution.
â€ Corresponding author.
Figure 1: PoinTr is designed for point cloud completion task. It takes the downsampled partial point clouds as inputs (gray points), and predicts the missing parts and upsamples the known parts si-multaneously (blue points). We propose to formulate the point cloud completion task as a set-to-set translation task and use a transformer encoder-decoder architecture to learn the complex de-pendencies among the point groups. Furthermore, we design two new benchmarks with more diverse tasks (i.e., upsampling and completion of point cloud), more diverse categories (i.e., from 8 categories to 55 categories), more diverse viewpoints (i.e., from 8 viewpoints to all possible viewpoints) and more diverse levels of incompleteness (i.e., missing 25% to 75% points of the ground-truth point clouds) to better reflect the real-world scenarios and promote future research. information. However, point cloud data from existing 3D sensors are not always complete and satisfactory because of inevitable self-occlusion, light reflection, limited sensor resolution, etc. Therefore, recovering complete point clouds from partial and sparse raw data becomes an indispensable task with ever-growing significance.
Over the years, researchers have tried many approaches 1
to tackle this problem in the realm of deep learning. Early attempts on point cloud completion [6, 15, 30, 31, 23, 36, 20, 19, 51, 47, 40] try to migrate mature methods from 2D completion tasks to 3D point clouds by voxelization and 3D convolutions. However, these methods suffer from a heavy computational cost that grows cubically as the spa-tial resolution increases. With the success of PointNet and
PointNet++ [25, 26], directly processing 3D coordinates becomes the mainstream of point cloud based 3D anal-ysis. The technique is further applied to many pioneer works [1, 49, 35, 16, 22, 14, 29] in point cloud comple-tion task, in which an encoder-decoder based architecture is designed to generate complete point clouds. However, the bottleneck of such methods lies in the max-pooling opera-tion in the encoding phase, where fine-grained information is lost and can hardly be recovered in the decoding phase.
Reconstructing complete point cloud is a challenging problem since the structural information required in the completion task runs counter to the unordered and un-structured nature of point cloud data. Therefore, learning structural features and long-range correlations among lo-cal parts of the point cloud becomes the key ingredient to-wards better point cloud completion. In this paper, we pro-pose to adopt Transformers [37], one of the most success-ful architecture in Natural Language Processing (NLP), to learn the structural information of pairwise interactions and global correlations for point cloud completion. Our model, named PoinTr, is characterized by five key components: 1) Encoder-Decoder Architecture: We adopt the encoder-decoder architecture to convert point cloud completion as a set-to-set translation problem. The self-attention mech-anism of transformers models all pairwise interactions be-tween elements in the encoder, while the decoder reasons about the missing elements based on the learnable pairwise interactions among features of the input point cloud and queries; 2) Point Proxy: We represent the set of point clouds in a local region as a feature vector called Point Proxy. The input point cloud is convert to a sequence of Point Prox-ies, which are used as the inputs of our transformer model; 3) Geometry-aware Transformer Block: To facilitate trans-formers to better leverage the inductive bias about 3D ge-ometric structures of point clouds, we design a geometry-aware block that models the geometric relations explicitly; 4) Query Generator: We use dynamic queries instead of fixed queirs in the decoder, which are generated by a query generation module that summarizes the features produced by the encoder and represents the initial sketch of the miss-ing points; 5) Multi-Scale Point Cloud Generation: We de-vise a multi-scale point generation module to recover the missing point cloud in a coarse-to-fine manner.
As another contribution, we argue that existing bench-marks are not representative enough to cover real-world sce-narios of incompleted point clouds. Therefore, we intro-duce two more challenging benchmarks that contain more diverse tasks (i.e., joint upsampling and completion of point cloud), more object categories (i.e., from 8 categories to 55 categories), more diverse views points (i.e., from 8 view-points to all possible viewpoints) and more diverse level of incompleteness (i.e., missing 25% to 75% points of the ground-truth point clouds). We evaluate our method on both the new benchmarks and the widely used PCN dataset [49] and KITTI benchmark [10]. Experiments demonstrate that
PointTr outperforms previous state-of-the-art methods on all benchmarks by a large margin. The main contributions of this paper are summarized in Figure 1. 2.