Abstract
Test-time augmentation—the aggregation of predictions across transformed versions of a test input—is a common practice in image classification. Traditionally, predictions
In this paper, we are combined using a simple average. present 1) experimental analyses that shed light on cases in which the simple average is suboptimal and 2) a method to address these shortcomings. A key finding is that even when test-time augmentation produces a net improvement in accuracy, it can change many correct predictions into incorrect predictions. We delve into when and why test-time augmentation changes a prediction from being correct to incorrect and vice versa. Building on these insights, we present a learning-based method for aggregating test-time augmentations. Experiments across a diverse set of models, datasets, and augmentations show that our method delivers consistent improvements over existing approaches. 1.

Introduction
Data augmentation—the expansion of a dataset by adding transformed copies of each example—is a common practice in image classification. Typically, data augmenta-tion is performed when a model is being trained. However, it can also be used at test-time to obtain greater robustness
[25, 30, 8], improved accuracy [19, 32, 28, 16, 20], or es-timates of uncertainty [20, 29, 1, 34]. Test-Time Augmen-tation (TTA) entails pooling predictions from several trans-formed versions of a given test input to obtain a “smoothed” prediction. For example, one could average the predictions from various cropped versions of a test image, so that the final prediction is robust to any single unfavorable crop.
TTA is popular because it is easy to use. It is simple to put into practice with off-the-shelf libraries [24, 6], makes no change to the underlying model, and requires no addi-tional data. However, despite its popularity, there is rela-tively little research on the design choices involved in TTA.
TTA depends on two choices: which augmentations to in-clude, and how to aggregate the resulting predictions. We focus on the latter.
Figure 1: Percentage of predictions corrected (orange) and corrupted (blue) by standard TTA. Past work on
TTA typically only examines the net improvement (green).
This paper analyzes how standard TTA, which simply av-erages model predictions on transformed versions of a test image, can produce corruptions, and proposes a method that accounts for these factors.
Fig. 1 shows the performance of a TTA policy that in-cludes flips, crops, and scales applied to several models on
ImageNet [10]. While the net improvement (green) is posi-tive for each network architecture, a sizeable number of pre-dictions are also changed to be incorrect (blue). Past TTA work typically only examines the net improvement, without considering why a TTA policy may actually degrade perfor-mance for many classes.
The goal of our work is twofold: (1) to understand which predictions TTA changes and why for a particular model and dataset and (2) to develop a method based on these in-sights that increases TTA performance. To do this, we first provide an empirical analysis of the corruptions introduced by TTA, and discuss implications for the design of TTA policies. Following this analysis, we present a learning-based method for TTA that depends upon these factors. In contrast to work on learning the choice of augmentations
[21, 17, 27], we focus specifically on how we can learn to aggregate augmentation predictions. The solution we propose—learning optimal weights per augmentation, for
a given dataset and model—can be applied in conjunction with other methods.
The proposed method represents a lightweight replace-ment for the simple average. Our method can offer a Top-1 accuracy increase of up to 2.5%, and is nearly free in terms of model size, training time, and implementation burden.
Our contributions are as follows:
• We provide insights into TTA that reveal why certain predictions are changed from correct to incorrect, and vice versa. We derive these insights from extensive ex-periments on ImageNet and Flowers-102 and include practical takeaways for the use of TTA.
• We develop a TTA aggregation method that learns to aggregate predictions from different transformations for a given model and dataset. Our method sig-nificantly outperforms existing approaches, providing consistent accuracy gains across numerous architec-tures, datasets, and augmentation policies. We also show that the combination of TTA with smaller models can match the performance of larger models. 2.