Abstract
We propose three novel solvers for estimating the rela-tive pose of a multi-camera system from afﬁne correspon-dences (ACs). A new constraint is derived interpreting the relationship of ACs and the generalized camera model. Us-ing the constraint, we demonstrate efﬁcient solvers for two types of motions assumed. Considering that the cameras undergo planar motion, we propose a minimal solution us-ing a single AC and a solver with two ACs to overcome the degenerate case. Also, we propose a minimal solution using two ACs with known vertical direction, e.g., from an IMU.
Since the proposed methods require signiﬁcantly fewer cor-respondences than state-of-the-art algorithms, they can be efﬁciently used within RANSAC for outlier removal and ini-tial motion estimation. The solvers are tested both on syn-thetic data and on real-world scenes from the KITTI odom-etry benchmark. It is shown that the accuracy of the esti-mated poses is superior to the state-of-the-art techniques. 1.

Introduction
Relative pose estimation from two views of a camera, or a multi-camera system is regarded as a fundamental prob-lem in computer vision [22, 10, 45, 46, 51], which plays an important role in simultaneous localization and map-ping (SLAM) and structure-from-motion (SfM). Thus, im-proving the accuracy, efﬁciency and robustness of relative pose estimation algorithms is always an important research topic [30, 50, 1, 16, 6, 12, 31]. Motivated by the fact that multi-camera systems are available in self-driving cars, mi-cro aerial vehicles or AR headsets, this paper investigates the problem of estimating the relative pose of multi-camera systems from afﬁne correspondences (ACs), see Fig. 1.
Since a multi-camera system contains multiple individ-∗Corresponding author.
Figure 1. An afﬁne correspondence in camera Ci between consec-utive frames k and k +1. The local afﬁne transformation A relates the inﬁnitesimal patches around point correspondence (xij, x(cid:48) ij). ual cameras connected by being ﬁxed to a single rigid body, it has the advantage of large ﬁeld-of-view and high accu-racy [47, 14]. The main difference of a multi-camera sys-tem and a standard pinhole camera is the absence of a single projection center [41]. Due to the different camera model, the relative pose estimation problem of multi-camera sys-tems [24] is different from the monocular cameras [39, 18], which results in different equations. In order to remove out-lier matches, most of the state-of-the-art SLAM and SfM pipelines using a multi-camera system [21, 23] apply the relative pose estimation algorithms repeatedly in a robust estimation framework, e.g. the Random Sample Consensus (RANSAC) [13]. This outlier removal process has to be ef-ﬁcient, which directly affects the real-time performance of
SLAM and SfM. The computational complexity and, thus, the processing time of the RANSAC procedure depends ex-ponentially on the number of points required for the relative pose estimation of multi-camera system.
Therefore, exploring the minimal solutions for relative pose estimation of multi-camera system is of signiﬁcant importance and has received sustained attention [24, 32, 10, 25, 33, 50, 28]. The idea of deriving minimal solu-tions for relative pose estimation of multi-camera systems ranges back to the work of Stew´enius et al. with the 6-point method [24]. Then other classical works have been subse-quently proposed, such as the 17-point linear method [32] and techniques based on iterative optimization [27]. The minimal number of necessary points can be further reduced by taking additional motion constraints into account [29] or exploiting the measurements from other sensors, like an inertial measurement unit (IMU) [30, 48, 49, 34, 36].
Typically, the assumption of planar motion or considering known vertical direction are common for self-driving cars and ground robots [9, 20, 18, 44, 31], which makes the out-lier removal more efﬁcient and numerically more stable.
All previously mentioned relative pose solvers estimate the pose parameters from a set of point correspondences (PCs), e.g., coming from SIFT [35] or SURF [7] detectors.
Due to containing more information about the underlying surface geometry than PCs, ACs enable to estimate the pose from fewer correspondences.
In this paper, we focus on the relative pose estimation of a multi-camera system from
ACs, instead of PCs. The contributions of this paper are:
• A new constraint that interprets the relationship of ACs and the generalized camera model is derived under general motion. This constraint can be easily gener-alized to special cases of multi-camera motion, e.g., planar motion and known vertical direction.
• When the motion is planar (i.e., the body to which the cameras are ﬁxed moves on a plane; 3DOF), a single
AC is sufﬁcient to recover the planar motion of a multi-camera system. In order to deal with the degenerate case of the 1AC solver, we also propose a new method to estimate the relative pose from two ACs. The point-based solver [29] requires at least two PCs and requires the Ackermann motion model to hold.
• A third solver is proposed for the case when the verti-cal direction is known (4DOF), e.g., from an IMU at-tached to the multi-camera system. We show that two
ACs are enough to recover the relative pose. In con-trast, the point-based solver requires four PCs [30, 48]. 2.