Abstract
Data augmentation is vital for deep learning neural net-works. By providing massive training samples, it helps to improve the generalization ability of the model. Weakly supervised semantic segmentation (WSSS) is a challeng-ing problem that has been deeply studied in recent years, conventional data augmentation approaches for WSSS usu-ally employ geometrical transformations, random crop-ping and color jittering. However, merely increasing the same contextual semantic data does not bring much gain to the networks to distinguish the objects, e.g., the correct image-level classification of “aeroplane” may be not only due to the recognition of the object itself, but also its co-occurrence context like “sky”, which will cause the model to focus less on the object features. To this end, we present a Context Decoupling Augmentation (CDA) method, to change the inherent context in which the objects appear and thus drive the network to remove the dependence be-tween object instances and contextual information. To vali-date the effectiveness of the proposed method, extensive ex-periments on PASCAL VOC 2012 and COCO datasets with several alternative network architectures demonstrate that
CDA can boost various popular WSSS methods to the new state-of-the-art by a large margin. Code is available at https://github.com/suyukun666/CDA 1.

Introduction
Semantic segmentation is a foundation in the computer vision field, which aims to predict the pixel-wise classi-fication of the images and it enjoys a wide range of ap-plications. Recently, benefiting from the deep neural net-†Corresponding authors.
Figure 1. Illustration of the difference between conventional aug-mentation approaches and our method. Classical data augmenta-tion consists of generating images obtained by basic geometrical transformations or color changes of original training images. Con-text Decoupling Augmentation (CDA) aims to randomly paste the given object instances into the scenes, so as to decouple the inher-ent context position of the original objects in the image. works, modern semantic segmentation models [7, 8, 31, 33] have achieved remarkable progress with massive human-annotated labeled data. However, collecting pixel-level labels is very time-consuming and labor-intensive, which shifts much research attention to weakly supervised seman-tic segmentation (WSSS). There exist various types of weak supervision for semantic segmentation like using bounding boxes [10, 24], scribbles [30, 40], points [4], and image-level labels [21, 2, 1, 43, 50]. Among them, image-level class labels have been widely used since they demand the least annotation efforts and are already provided in existing large-scale image datasets.
In this paper, we focus on augmentation for WSSS with
image-level labels, which is crucial for deep learning net-works. As shown in Figure 1 upper part, given a training image, traditional data augmentation methods utilize some geometrical transformations, such as rotation, scaling, flip-ping, and even some color conversions to increase the di-versity of images to avoid overfitting. However, for weakly supervised semantic segmentation, adjusting the image as a whole and maintain the same contextual semantic relation will not significantly help the networks to mine the object areas. For example, “sofa” always appears in the room in the datasets, therefore, the trained network may not only recognize the objects depending on the instance features but also their co-occurrence context information [29]. Specifi-cally, when object instances often appear at the same time with some accompanying backgrounds, it will cause the net-works to yield confounding bias. Namely, the networks can perform classification task well is not due to successfully distinguishing the characteristics of objects, but to being aware of the appearance of certain contextual semantic in-formation, which is harmful to mine the object regions.
Based on this observation, we propose a Context Decou-pling Augmentation (CDA) method, designing for disas-sembling the inherent contextual information of the original image. As shown in Figure 1 bottom half, the “cat” shows in the “sky”, and the “sofa” falls on the “road”. Although some of these scene collocations rarely appear in life, the models can pay more attention to the objects correspond-ing to the classification labels. Unlike the fully-supervised data augmentation approaches [13], we cannot access the object instance labels to extract the objects under the weakly supervised setting. Therefore, we first adopt off-the-shelf
WSSS approaches to obtain the object instances that have been well-segmented. Secondly, we randomly paste the se-lected foreground instances into the input images to get the new enhanced images and put them into the model for train-ing together with the original ones without augmentation.
In this way, we can break the dependency between objects and contextual background, and the models will focus on the internal information of the foreground instances rather than the context information to predict the categories they belong to. Besides, we use an online training technique to conduct data augmentation, which means that the combina-tion of the raw input images and the object instances to be pasted are different each time. This greatly increases the diversity of combinations of various scenes and object in-stances, and thus enhance the decoupling capability of the networks.
In the proposed context decoupling augmentation frame-work, we utilize different WSSS networks as our baselines.
To verify the effectiveness of our proposed method, ex-tensive experiments show that CDA can improve pseudo-masks more than 2.8% mIoU on average. We achieve new state-of-the-art performance by 66.1% mIoU on the val set and 66.8% mIoU on the test set of PASCAL VOC 2012 [15], and 33.7% mIoU on the val set of COCO [32].
The main contributions of our paper can be summarized as follows:
• We present a generally applicable data augmentation approach for weakly supervised semantic segmenta-tion, which, to the best of our knowledge, has not been well explored.
• The proposed context decoupling augmentation (CDA) method does not require additional data and it can remove the correlation between foreground object instances and background context information, which can drive the network focus on object regions rather than the background.
• Experiments on PASCAL VOC 2012 and COCO show the effectiveness of our proposed method and CDA can boost the performance of different WSSS methods to the new state-of-the-art by a large margin. 2.