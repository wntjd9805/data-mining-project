Abstract
Existing video super-resolution (SR) algorithms usually assume that the blur kernels in the degradation process are known and do not model the blur kernels in the restora-tion. However, this assumption does not hold for blind video SR and usually leads to over-smoothed super-resolved frames. In this paper, we propose an effective blind video
SR algorithm based on deep convolutional neural network-s (CNNs). Our algorithm ﬁrst estimates blur kernels from low-resolution (LR) input videos. Then, with the estimated blur kernels, we develop an effective image deconvolution method based on the image formation model of blind video
SR to generate intermediate latent frames so that sharp im-age contents can be restored well. To effectively explore the information from adjacent frames, we estimate the motion
ﬁelds from LR input videos, extract features from LR videos by a feature extraction network, and warp the extracted fea-tures from LR inputs based on the motion ﬁelds. Moreover, we develop an effective sharp feature exploration method which ﬁrst extracts sharp features from restored intermedi-ate latent frames and then uses a transformation operation based on the extracted sharp features and warped features from LR inputs to generate better features for HR video restoration. We formulate the proposed algorithm into an
∗Corresponding author. end-to-end trainable framework and show that it performs favorably against state-of-the-art methods. 1.

Introduction
Blind video super-resolution (SR) aims to estimate high-resolution (HR) frames from a low-resolution (LR) se-quence with unknown blur kernels.
It is a fundamental problem in the vision and graphics communities and has re-ceived active research efforts within the last decade as high-deﬁnition devices have been widely used in our daily lives.
As the HR sequences are usually contaminated by unknown blur, it is quite challenging to restore HR videos from low-resolution sequences.
Since blind video SR is an ill-posed problem, conven-tional methods usually develop kinds of hand-crafted priors to make this problem well-posed and estimate latent HR im-age in a variational approach [9, 1, 5, 33, 23, 27]. In spite of achieving decent results, these algorithms usually need to solve complex energy functions or involve complicated matching processes, and the performance is limited by the hand-crafted priors. In addition, most of these algorithms usually assume that the blur kernel is known or predeﬁned (e.g., Bicubic kernel) and do not model blur kernels in the restoration, which cannot effectively capture the intrinsic
characteristics of video SR [23].
Motivated by the ﬁrst end-to-end trainable network for single image SR [7], lots of methods based on deep convo-lutional neural networks (CNNs) have been proposed [18, 8, 11, 46, 22, 20]. These approaches achieve decent results in single image SR, but cannot be easily applied to the video
SR problem as the temporal information are not considered.
To overcome this problem, most existing algorithms focus on developing effective motion ﬁelds and alignment estima-tion methods. For example, the subpixel motion compensa-tion based on optical ﬂow [37], deformable alignment net-works [38, 40], and spatial alignment networks [24, 4, 43].
To better restore latent frames, the recurrent approaches and
Generative Adversarial Networks (GANs) have been de-veloped [6, 25]. These methods signiﬁcantly promote the progress of video SR. However, they usually assume the blur kernel is known and ﬁxed (e.g., Bicubic kernel), which does not model unknown blur kernels and thus leads to over-smoothed results when handling the blind video SR prob-lem (Figure 1(e)-(f)).
In addition, simply combining ex-isting deblurring and video SR methods does not solve the blind SR problem well as shown in Figure 1(g).
Instead of assuming known blur kernels, several algo-rithms explicitly estimate blur kernels for SR [28, 10, 48, 2].
These algorithms show that using the estimated blur ker-nels for image SR is able to improve the results signiﬁ-cantly [28, 2]. However, these algorithms are mainly de-veloped for single image SR which cannot be extended to video SR directly as shown in Figure 1(c)-(d). The method-s [23, 27] simultaneously estimate underlying motion ﬁelds and blur kernels for image restoration. However, the perfor-mance is limited by the hand-crafted image priors. More-over, these hand-crafted image priors usually lead to com-plex optimization problems which are difﬁcult to solve.
To overcome the above problems, we propose an effec-tive video SR algorithm that simultaneously estimates un-derlying blur kernels, motion ﬁelds, and latent HR videos by deep CNN models so that our method can not only avoid the hand-crafted priors but also effectively estimate blur k-ernels and motion ﬁelds for better video restoration. The proposed algorithm explicitly estimates blur kernels from
LR input videos and then develops an effective image de-convolution model based on the image formation of video
SR to generate intermediate latent frames with sharp struc-tural details. To explore sharper structural details of the restored intermediate latent images and information of the adjacent frames, we fuse the features extracted from LR videos based on motion ﬁeld estimation and transform the sharp features of the intermediate latent images for better
HR video restoration. By training the proposed algorithm in an end-to-end manner, it is able to generate clearer im-ages with ﬁner structural details (Figure 1). To the best of our knowledge, this is the ﬁrst algorithm that develops deep
CNNs based on a variational approach for blind video SR.
The main contributions are summarized as follows:
• We propose an effective blind video SR algorithm that simultaneously estimates blur kernels, motion ﬁelds, and latent images by deep CNN models.
• We develop an effective image deconvolution method based on the image formation of video SR to generate intermediate latent frames with sharp structural details.
• We develop a sharp feature exploration method to ex-plore sharp features from the restored intermediate la-tent frames for HR video restoration.
• We formulate the proposed algorithm into an end-to-end trainable network and show that it performs favor-ably against state-of-the-art methods on both bench-mark datasets and real-world videos. 2.