Abstract
We present a ﬂexible and high-performance framework, named Pyramid R-CNN, for two-stage 3D object detection from point clouds. Current approaches generally rely on the points or voxels of interest for RoI feature extraction on the second stage, but cannot effectively handle the spar-sity and non-uniform distribution of those points, and this may result in failures in detecting objects that are far away.
To resolve the problems, we propose a novel second-stage module, named pyramid RoI head, to adaptively learn the features from the sparse points of interest. The pyramid RoI head consists of three key components. Firstly, we propose the RoI-grid Pyramid, which mitigates the sparsity problem by extensively collecting points of interest for each RoI in a pyramid manner. Secondly, we propose RoI-grid Atten-tion, a new operation that can encode richer information from sparse points by incorporating conventional attention-based and graph-based point operators into a uniﬁed for-mulation. Thirdly, we propose the Density-Aware Radius
Prediction (DARP) module, which can adapt to different point density levels by dynamically adjusting the focusing range of RoIs. Combining the three components, our pyra-mid RoI head is robust to the sparse and imbalanced cir-cumstances, and can be applied upon various 3D back-bones to consistently boost the detection performance. Ex-tensive experiments show that Pyramid R-CNN outperforms the state-of-the-art 3D detection models by a large margin on both the KITTI dataset and the Waymo Open dataset. 1.

Introduction 3D object detection is a key component of perception systems for robotics and autonomous driving, aiming at detecting vehicles, pedestrians, and other objects with 3D point clouds as input.
In this paper, we propose a gen-eral two-stage 3D detection framework, named Pyramid R-CNN, which can be applied on multiple 3D backbones to enhance the detection adaptability and performance.
Among the existing 3D detection frameworks, two-stage detection models [39, 30, 27, 5, 28] surpass most single-1 The Chinese University of Hong Kong 2 Huawei Noah’s Ark Lab 3 HKUST 4 Sun Yat-Sen University
† Corresponding author: xdliang328@gmail.com
Figure 1. Statistical results on the KITTI dataset. Blue bars de-note the distribution of the number of object points. Orange bars denote the distribution of the number of points gathered by RoIs in Pyramid R-CNN. Our approach can mitigate the sparsity and imbalanced distribution problems of point clouds. stage 3D detectors [45, 37, 14, 38, 29] with remarkable mar-gins owing to the RoI reﬁnement stage. Different from the 2D counterparts [9, 8, 26, 11, 2] which apply RoIPool [8] or RoIAlign [11] to crop dense feature maps on the sec-ond stage, the 3D detection models generally perform var-ious RoI feature extraction operations on the Points of In-terest. For example, Point R-CNN [29] utilizes a point-based backbone to generate 3D proposals, treats the points near the proposals as Points of Interest and applies Region
Pooling on those sparse points for box reﬁnement; Part-A2
Net [30] utilizes a voxel-based backbone for proposal gen-eration, uses the upsampled voxel points as Points of Inter-est, and applies sparse convolutions on those voxel points for each RoI; PV-RCNN [27] encodes the whole scene into a set of keypoints, and utilizes keypoints as Points of Inter-est for RoI-grid Pooling. Those Points of Interest originate from raw point clouds and contain rich ﬁne-grained infor-mation, which is required for the RoI reﬁnement stage.
However, the Points of Interest inevitably suffer from the sparsity and non-uniform distribution characteristics of in-put point clouds. As is demonstrated by the statistical re-sults on the KITTI dataset [7] in Figure 1: 1) Point clouds can be quite sparse in certain objects. More than 7% of total objects have less than 10 points, and their visualized shapes are mostly incomplete. Thus it is hard to identify their cate-gories without enough context information. 2) The distribu-tion of object points is extremely imbalanced. The number of object points ranges from less than 10 to more than 500 on KITTI, and current RoI operations cannot handle the im-balanced conditions effectively. 3) The number of Points of
Interest only accounts for a small proportion of input points or voxels, e.g. 2k keypoints in [27] relative to the 15k total input points, which exacerbates the above problems.
To overcome the above limitations, we propose Pyramid
R-CNN, a general two-stage 3D detection framework that can effectively detect objects and adapt along with envi-ronmental changes. Our main contribution lies in the de-sign of a novel RoI feature extraction head, named pyra-mid RoI head, which can be applied on multiple 3D back-bones and Points of Interest. pyramid RoI head consists of three key components. Firstly, we propose RoI-grid Pyra-mid. Given the observation that Points of Interest inside
RoIs are too sparse for object recognition, our RoI-grid
Pyramid captures more Points of Interest outside RoIs while still maintaining ﬁne-grained geometric details, by extend-ing the standard one-level RoI-grid to a pyramid structure.
Secondly, we propose RoI-grid Attention, an effective op-eration to extract RoI-grid features from Points of Interest.
RoI-grid Attention leverages the advantages of the graph-based and attention-based point operators by combining those formulas into a uniﬁed formulation, and it can adapt to different sparsity situations by dynamically attending to the crucial Points of Interest near the RoIs. Thirdly, we pro-pose the Density-Aware Radius Prediction (DARP) mod-ule, which can predict the feature extraction radius of each
RoI, conditioning on the neighboring distribution of Points of Interest. Thus we can address the imbalanced distribu-tion problem by adaptively adjusting the focusing range for each RoI. Combining all the above components, the pyra-mid RoI head shows adaptability to different point cloud sparsity levels and can accurately detect the 3D objects with only a few points. Our Pyramid R-CNN is compati-ble with the point-based [29], voxel-based [30] and point-voxel-based [27] frameworks, and signiﬁcantly boosts the detection accuracy.
We summarize our key contributions as follows: 1) We propose Pyramid R-CNN, a general two-stage framework that can be applied on multiple backbones for accurate and robust 3D object detection. 2) We propose the pyramid RoI head, which combines the RoI-grid Pyramid, RoI-grid Attention, and the Density-Aware Radius Prediction (DARP) module together to miti-gate the sparsity and non-uniform distribution problems. 3) Pyramid R-CNN consistently outperforms the base-lines, achieves 82.08% moderate car mAP on the KITTI dataset, and ranks 1st among the LiDAR-only methods on the Waymo test leaderboard for vehicle detection. 2.