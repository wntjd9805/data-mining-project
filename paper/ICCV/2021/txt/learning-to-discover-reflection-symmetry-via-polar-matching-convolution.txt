Abstract
The task of reﬂection symmetry detection remains chal-lenging due to signiﬁcant variations and ambiguities of symmetry patterns in the wild. Furthermore, since the lo-cal regions are required to match in reﬂection for detecting a symmetry pattern, it is hard for standard convolutional networks, which are not equivariant to rotation and reﬂec-tion, to learn the task. To address the issue, we introduce a new convolutional technique, dubbed the polar matching convolution, which leverages a polar feature pooling, a self-similarity encoding, and a systematic kernel design for axes of different angles. The proposed high-dimensional kernel convolution network effectively learns to discover symme-try patterns from real-world images, overcoming the limita-tions of standard convolution. In addition, we present a new dataset and introduce a self-supervised learning strategy by augmenting the dataset with synthesizing images. Exper-iments demonstrate that our method outperforms state-of-the-art methods in terms of accuracy and robustness. 1.

Introduction
The world is built on symmetry. From the physical struc-tures of nature, the biological patterns of life, to the arti-facts of human, symmetries reveal themselves almost ev-erywhere. Perception of such symmetries plays a crucial role at different levels of human vision [38]; it provides hu-mans with pre-attentive cues for early visual analysis and also acts as an integral part for 3D object perception under perspective distortion. Among common groups of symme-try, the most basic and popular form is reﬂection, mirror, or bilateral symmetry, which is the focus of this work. The task of reﬂection symmetry detection is to discover reﬂec-tive patterns from images by detecting their axes of sym-metry. Despite the apparent simplicity of the mathematical concept [40] and the long history of research [24], the prob-lem remains challenging due to signiﬁcant variations and ambiguities of symmetry patterns in the wild.
*Equal contributions.
Figure 1. Feature matching in reﬂection symmetry. Perception of reﬂection symmetry requires matching features of corresponding regions in reﬂection with respect to its symmetry axis. Grids repre-sent feature maps, and red squares denote corresponding regions.
One of the most promising directions for tackling the challenge would be to learn from data [15]. While deep convolutional neural networks (CNNs) have made remark-able progress in a wide range of computer vision problems, there has been little work for learning symmetry detection on real-world images. Previous work [14] adapts a CNN [3] to regress a dense heatmap of symmetry axes for symmetry detection. While the results demonstrate the effectiveness of learning, the method does not consider the limitation of conventional CNNs in learning symmetry. As illustrated in
Fig. 1, discovering symmetry requires recognizing match-ing pairs of local regions in reﬂection, and this may make it hard for CNNs, which are neither invariant nor equivariant to reﬂection [8, 20], to learn the task. Furthermore, the ro-tational freedom of the symmetry axis makes it even harder since conventional CNNs are not invariant to rotation ei-ther. Standard convolution alone is not effective in learning the required properties solely from data.
In this work, we introduce a new convolutional tech-nique, dubbed the polar matching convolution (PMC), which leverages a polar feature pooling, a self-similarity en-coding, and a systematic kernel design for axes of different angles. On the basis of symmetrically matched feature pairs in a polar structure, the polar matching kernel computes the conﬁdence of symmetry by exploiting both local similarities
and geometric layouts of local patterns. The proposed con-volution neural network learns to discover symmetry pat-terns with the high-dimensional kernel that effectively com-pares corresponding features in reﬂection with respect to the possible candidate axes of symmetry. We also present a new symmetry detection dataset and introduce a self-supervised learning strategy using synthesized images. The experi-mental evaluation on the SDRW [23] benchmark and our dataset shows that the proposed method, PMCNet, outper-forms state-of-the-art methods in accuracy and robustness. 2.