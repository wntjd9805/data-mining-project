Abstract
Casual photography is often performed in uncontrolled lighting that can result in low quality images and degrade the performance of downstream processing. We consider the problem of estimating surface normal and reﬂectance maps of scenes depicting people despite these conditions by supplementing the available visible illumination with a single near infrared (NIR) light source and camera, a so-called “dark ﬂash image”. Our method takes as input a single color image captured under arbitrary visible light-ing and a single dark ﬂash image captured under controlled front-lit NIR lighting at the same viewpoint, and computes a normal map, a diffuse albedo map, and a specular inten-sity map of the scene. Since ground truth normal and re-ﬂectance maps of faces are difﬁcult to capture, we propose a novel training technique that combines information from two readily available and complementary sources: a stereo depth signal and photometric shading cues. We evaluate our method over a range of subjects and lighting conditions and describe two applications: optimizing stereo geometry and ﬁlling the shadows in an image. 1.

Introduction
In casual mobile photography, images are often cap-tured under poor lighting conditions. Controlling the visible lighting or supplementing it with a ﬂash is often too difﬁ-cult or too disruptive to be practical. On the other hand, the near infrared (NIR) lighting in a scene can be much more easily controlled and is invisible to the user. In this paper, we demonstrate how a single “dark ﬂash” NIR image and a single visible image taken under uncontrolled lighting can be used to recover high quality maps of the surface nor-mals, diffuse albedos, and specular intensities in the scene.
We collectively refer to the albedo and specular intensity estimates as a “reﬂectance map”. Exposing these signals within a photography pipeline opens up a range of appli-cations from reﬁning independent depth estimates to digi-tally manipulating the lighting in the scene. Although our method is applicable to many types of objects, we focus on
*Work done while Zhihao Xia was an intern at Google.
RGB Input
NIR Input
Normal Map
Figure 1: Estimating surface geometry from a single RGB image is challenging. We augment this input with a sin-gle NIR “dark ﬂash” image captured at the same time, and present a network that can estimate high quality normal maps and reﬂectance maps (not shown) under a wide range of visible lighting conditions. faces - the most common photography subject at the short ranges over which active illumination is effective.
Our use of controlled NIR lighting provides a number of beneﬁts. First, the ambient NIR light in a scene is usu-ally weak or completely absent in indoor environments and is signiﬁcantly attenuated by atmospheric absorption out-doors, which means it is often practical to control this as-pect of a scene. Second, it results in a more tractable es-timation problem in contrast to single-image “shape from
shading” and intrinsic image decomposition techniques that must simultaneously reason about shape, material proper-ties, and lighting. Third, it provides a stable source of in-formation about the shape and appearance of the scene even under very challenging visible lighting. By locating the NIR light source near the camera, this setup minimizes shadows in the scene while producing specular highlights along sur-faces that are nearly perpendicular to the viewing direction, giving a useful cue for determining surface orientations.
We present a deep neural network that takes as input one
RGB image captured under uncontrolled visible lighting and one monochrome NIR image captured from the same viewpoint, but under controlled lighting provided by a sin-gle source located near the camera. The network generates a surface normal and reﬂectance estimate (diffuse albedo
+ specular intensity) at each pixel. We train this network by combining two imperfect but complementary cues: a stereo depth map that provides a reliable estimate of the low-frequency components of the scene’s 3d shape along with photometric cues that convey higher-frequency geo-metric details. These measurements are far easier to obtain than ground truth geometry and appearance measurements.
We explicitly model the specular reﬂectance of human skin in a photometric loss term that guides our training along with a prior on the albedo map that favors piecewise con-stant variation [3].
We compare our technique to a baseline learning ap-proach that uses only a single RGB image as input and state-of-the-art methods for single image intrinsic image decom-position [27] and relighting [21]. We are able to produce overall more stable and more accurate outputs even in very challenging visible light conditions. We also present two applications of integrating our technique in a mobile pho-In all, this paper makes the following tography pipeline. contributions:
• A new network architecture for estimating dense nor-mal and reﬂectance maps from a single RGB+NIR im-age pair.
• A new training strategy that combines two independent and complementary signals: one from stereo triangula-tion and the other from photometric cues in RGB and
NIR, along with a hardware setup for collecting this data. Notably, our training is guided by a physically-based image formation model that reproduces both dif-fuse and surface reﬂectance.
• We demonstrate two applications of our method in a modern photography pipeline: optimizing depths com-puted by an independent stereo technique and reducing shadows in an image post-capture. 2.