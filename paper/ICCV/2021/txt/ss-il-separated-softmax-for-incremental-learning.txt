Abstract
We consider class incremental learning (CIL) problem, in which a learning agent continuously learns new classes from incrementally arriving training data batches and aims to predict well on all the classes learned so far. The main challenge of the problem is the catastrophic forgetting, and for the exemplar-memory based CIL methods, it is gener-ally known that the forgetting is commonly caused by the classiﬁcation score bias that is injected due to the data im-balance between the new classes and the old classes (in the exemplar-memory). While several methods have been pro-posed to correct such score bias by some additional post-processing, e.g., score re-scaling or balanced ﬁne-tuning, no systematic analysis on the root cause of such bias has been done. To that end, we analyze that computing the softmax probabilities by combining the output scores for all old and new classes could be the main cause of the bias. Then, we propose a new method, dubbed as Sepa-rated Softmax for Incremental Learning (SS-IL), that con-sists of separated softmax (SS) output layer combined with task-wise knowledge distillation (TKD) to resolve such bias.
Throughout our extensive experimental results on several large-scale CIL benchmark datasets, we show our SS-IL achieves strong state-of-the-art accuracy through attaining much more balanced prediction scores across old and new classes, without any additional post-processing. 1.

Introduction
Incremental or continual learning, in which the agent continues to learn incremental arrival of new training data, is one of the grand challenges in artiﬁcial intelligence and machine learning. Such setting, which does not assume the full availability of old training data, is recently gaining more attention particularly from the perspective of real-world ap-plications. The reason is storing all the training data, which can easily become large-scale, in one batch often becomes
∗Equal contribution.
†Corresponding autho r. unrealistic for memory- and computation-constrained appli-cations, such as mobile phones or robots. Therefore, the continuous yet effective update of the learning agent with-out accessing the full data received so far is indispensable.
A viable candidate for such agent is the end-to-end learn-ing based deep neural network (DNN) models. Following the recent success in many different applications [14, 3, 7], the DNN-based incremental learning methods have been also actively pursued in recent years. Despite some promis-ing results, they also possess a critical limitation: the catas-trophic forgetting, which refers to the problem that the gen-eralization performance on the old data severely degrades after a naive ﬁne-tuning of the model with the new data.
In this paper, we focus on the DNN-based class in-cremental learning (CIL), which we refer to learning a classiﬁer to classify new object classes from every incre-mental training data and testing the classiﬁer on all the classes learned so far. Among several different proposed approaches, the exemplar-memory based ones [28, 8, 31, 35, 4, 5], which allow to store small amount of training data from old classes in a separate memory, have been shown to be effective in mitigating the catastrophic forgetting.
The main challenge of using the exemplar-memory in
CIL is to resolve the severe data imbalance between the training data points for the new classes and for the old classes (in the exemplar-memory). That is, the naive ﬁne-tuning with such imbalanced data would heavily skew the prediction scores toward the newly learned classes, hence, the accuracy for the old classes would dramatically drop, resulting in a signiﬁcant forgetting. Recently, several state-of-the-art methods [8, 31, 35, 4, 5] proposed to correct such score bias by some additional post-processing steps, e.g., score re-scaling or balanced ﬁne-tuning, after learning the classiﬁcation models.
While above mentioned methods were effective to some extent in terms of improving the accuracy, we argue that they lack systematic analyses on the main reason of such bias and that some component of their schemes, e.g., knowl-edge distillation (KD) [15], was naively used without any
proper justiﬁcations [31, 23, 35, 20]. To that regard, in this paper, we ﬁrst analyze the root cause of such classiﬁcation score bias, then propose a method that mitigates the cause in a sensible way. Namely, we argue that the bias is in-jected by the fact that the softmax probability used in the ordinary cross-entropy loss is always computed by combin-ing the output scores of all classes, which forces the heavy penalization of the output scores for the old classes due to the data imbalance. Furthermore, we show that a naive use of the General KD (GKD) method, which also combines the output scores of all old classes to compute the soft tar-get, may preserve the bias and even hurt the accuracy, if the prediction bias is already present in the model.
To resolve above issues, we propose Separated-Softmax for Incremental Learning (SS-IL), which consists of two main components. Firstly, we devise separated softmax (SS) output layer that mutually blocks the ﬂow of the score gradients between the old and new classes, thus, mitigates the imbalanced penalization of the output probabilities for the old classes. Secondly, we show the Task-wise KD (TKD)
[25], which also computes the soft target for the distilla-tion in a task-separated manner, is particularly well-suited for our SS layer, since it attempts to preserve the task-wise knowledge without preserving the prediction bias that may remain across the tasks. In order to show the effectiveness of our approach, we carried out extensive experimental val-idations on several large-scale CIL benchmarks with var-ious scenarios and fairly compared our SS-IL with recent strong baselines by reproducing all of them. As a result, we convincingly show our SS-IL achieves strong state-of-the-art accuracy via adequately balancing the prediction scores across old and new classes, without any additional post-processing.
In summary, our contribution is threefold:
• We propose a novel separated softmax (SS) layer, which prevents the old class scores from being overly penalized throughout the gradient steps.
• We show that using GKD in CIL may preserve the bias of the model, while TKD can bring synergy when par-ticularly combined with SS that has the same intuition.
• We carry out extensive experimental validation of our
SS-IL on several large-scale benchmarks with various
CIL scenarios and fairly compared with recent, all-reproduced state-of-the-art baselines. 2.