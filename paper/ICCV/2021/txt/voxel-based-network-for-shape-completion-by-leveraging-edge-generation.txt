Abstract
Deep learning technique has yielded significant improve-ments in point cloud completion with the aim of completing missing object shapes from partial inputs. However, most existing methods fail to recover realistic structures due to over-smoothing of fine-grained details.
In this paper, we develop a voxel-based network for point cloud completion by leveraging edge generation (VE-PCN). We first embed point clouds into regular voxel grids, and then generate complete objects with the help of the hallucinated shape edges. This decoupled architecture together with a multi-scale grid feature learning is able to generate more re-alistic on-surface details. We evaluate our model on the publicly available completion datasets and show that it outperforms existing state-of-the-art approaches quantita-tively and qualitatively. Our source code is available at https:// github.com/ xiaogangw/ VE-PCN. 1.

Introduction 3D shape completion is a fundamental problem in com-puter vision and robotic perception. The aim is to recon-struct complete object topologies from sparse and incom-plete observations, e.g. raw data collected by RGB-D or
LiDAR sensors. Since incompleteness and irregularity of input point clouds impose difficulties on down-stream tasks such as 3D object classification [25, 26, 39, 16], segmenta-tion [25, 26, 17] and detection [3, 24, 44, 49], several point cloud completion methods [46, 31, 36, 20, 41, 28] are pro-posed to improve the quality of the point clouds. Although existing works have achieved impressive results, they are limited to low-fidelity outputs. In this work, we focus on generating high-quality 3D objects from occluded inputs.
Numerous methods have attempted to achieve shape completion from different representations, e.g. meshes [9, 34], implicit fields [4, 18, 21, 30] and point clouds [46, 31, 36, 20, 41, 28, 2, 48, 14, 37, 38, 40, 43, 12, 10]. Meshes represent object shapes by a set of vertices and edges. De-spite their ability to reconstruct complex object structures, it is difficult to change shape topologies during training due
Figure 1: We propose an edge-guiding and voxel-based point cloud completion network to reconstruct complete points from incomplete inputs. Under the guidance of hal-lucinated edges and the help of gridding structures, we are able to generate fine-grained details for the thin structures. to the fixed vertex connection patterns. Implicit fields rep-resent shapes by signed distance functions (SDF) [23] that are more flexible to achieve arbitrary resolutions. How-ever, learning an accurate SDF requires a large amount of sampling for a single object. In contrast, point clouds are concise 3D shape representations and easier to add new points during training. Nonetheless, previous point cloud shape completion works [46, 31] are struggling at synthe-sizing surface details since point clouds are unordered and challenging to control. To alleviate this problem, recent works [20, 36, 43] propose to add a skip connection be-tween the partial input and the decoder and have shown bet-ter reconstruction on object details. Despite the effort, the results for complex topologies are still inferior because of unrealistic points generated on the missing part.
In view of these limitations, we propose a voxel-based shape completion network that leverages the generated ob-ject edges to recover more fine-grained details. The voxel representation has also been used in GRNet [43], where a
Gridding and Gridding Reverse layer are proposed for con-version between unordered points and 3D grids. However, their voxel representation is only used to reconstruct low-resolution shapes, and additional multi-layer perceptrons (MLPs) [25] are applied for denser point set generation. To fully integrate the voxel representation for completion in an end-to-end manner, we generate points for every grid cell by predicting a binary classification score that indicates a cell being empty or occupied and a probability density value that estimates the number of points in the cell inspired by [19].
This operation is differentiable everywhere and thus makes it easier to generate accurate coordinates according to vari-ous shape topologies. Moreover, the end-to-end grid strat-egy allows us to approximate object shapes without running into memory issues since we can sample an arbitrary num-ber of points for each grid cell. In this way, we are able to use a lower voxel resolution, e.g. 32 × 32 × 32 compared to 64 × 64 × 64 in GRNet, and concurrently achieve su-perior results. In addition, we introduce a multi-scale grid transformation module to learn critical object shapes in dif-ferent resolutions, while GRNet only considers the full res-olutional inputs.
Although the voxel representation is shown to be supe-rior on calculating local features [43, 11, 35], it is challeng-ing to generate arbitrary thin structures for various objects.
We thus further introduce an edge generator to enhance our network. Since object structures are well-represented by their edges or contours, it is beneficial to incorporate the edge information when generating complete 3D shapes.
Several examples of edge generation and point cloud com-pletion are shown in Figure 1.
We evaluate our model on both the synthetic and real-world datasets. Qualitative and quantitative experiments are compared against existing state-of-the-art schemes. Our key contributions are as follows:
• We design a multi-scale voxel-based network to gen-erate fine-grained details for point cloud completion.
• We incorporate object structure information into the shape completion by leveraging edge generation.
• We achieve state-of-the-art performances on different point cloud completion datasets. 2.