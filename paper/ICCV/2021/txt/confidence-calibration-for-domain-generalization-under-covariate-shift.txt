Abstract
Existing calibration algorithms address the problem of covariate shift via unsupervised domain adaptation. How-ever, these methods suffer from the following limitations: 1) they require unlabeled data from the target domain, which may not be available at the stage of calibration in real-world applications and 2) their performance depends heav-ily on the disparity between the distributions of the source and target domains. To address these two limitations, we present novel calibration solutions via domain generaliza-tion. Our core idea is to leverage multiple calibration do-mains to reduce the effective distribution disparity between the target and calibration domains for improved calibration transfer without needing any data from the target domain.
We provide theoretical justification and empirical experi-mental results to demonstrate the effectiveness of our pro-posed algorithms. Compared against state-of-the-art cal-ibration methods designed for domain adaptation, we ob-serve a decrease of 8.86 percentage points in expected cali-bration error or, equivalently, an increase of 35 percentage points in improvement ratio for multi-class classification on the Office-Home dataset. 1.

Introduction
Deep neural networks (DNNs) have demonstrated high accuracy for tasks such as classification and detection given adequate data and supervision [34, 29]. However, for real-world applications, the ability to indicate how much users should trust model predictions can be even more crucial than just having an accurate but unpredictable model [2, 12, 28]. While discriminative networks provide confidence scores that can be used as a heuristic measure of the prob-ability of correct classification, such scores are not guar-anteed to match the true probabilities of correct classifica-tion [9]. A recent development, referred to as model cali-bration, addresses this problem directly [24, 9].
A classifier is calibrated with respect to a distribution (or a dataset sampled from that distribution) if its predicted probability of being correct matches its true probability. If the distribution changes, calibration is usually lost, and this has been demonstrated empirically [20]. Recent work has
Figure 1: Calibration for domain adaptation with a single source domain may suffer from a large variance of the den-sity ratio (i.e., P T /P S) caused by disjoint P S and P T and, therefore, a large calibration error as shown in (a). Our proposed calibration algorithms for domain generalization leverage multiple calibration domains to reduce the dispar-ity between P C and P T for a decreased variance of the den-sity ratio P T /P C and, in turn, improved calibration perfor-mance, as shown in (b) and (c). begun to investigate the problem of calibration in the con-text of transfer learning, specifically in an unsupervised do-main adaptation scenario under the assumption of covariate shift [22, 32, 20]. However, these methods need at least unlabeled data from the target domain, which may not be available at the stages of training and calibration in real-world applications. Furthermore, as these methods are de-signed to handle a single source domain, there may be an undesired disparity between selected source and target do-mains either due to the limited availability of sources or un-certainties (e.g., extreme weather/unexplored terrain) in the target. Fig. 1(a) notionally depicts such a scenario. This disparity results in a large variance of the density ratio de-fined as P T /P S, which significantly degrades the accuracy of calibration [20, 4].
To tackle the aforementioned limitations of calibration transfer via domain adaptation, we focus instead on cali-bration for domain generalization. Our key idea is to use multiple source domains and cluster their labeled data into groups. We then fit post-hoc calibration parameters to each group. The class probability of a test example is calibrated using the calibration parameters of the group that is nearest (in Euclidean distance) to the test example. By using many calibration domains, we increase the likelihood of overlap in the distributions, which in theory will improve the ef-fectiveness of cross-domain calibration [20, 4]. By learn-ing calibration parameters separately for each group, we in-crease the likelihood that each test query will be adjusted by the best calibration correction.
We study two calibration methods within each cluster.
Both are based on temperature scaling [9]. The first com-putes a fixed scaling temperature for each group (Fig. 1(c)).
The second fits a regression model to these fixed tempera-tures to enable extrapolating the temperature to points out-side the clusters. We compare these two methods against a baseline that computes one temperature for scaling based on the union of all the calibration data (Fig. 1(b)). We refer to our methods as cluster-level and the baseline as set-level.
Notably, while Fig. 1 depicts a notional scenario where the source and target domains have no overlap and the calibra-tion domains bridge the gap, our methods will also work well in cases where the source is closer to the target, as long as at least one of the calibration domains is also close to the target.
Our major contributions include the following: 1) We propose novel solutions to calibrate a classifica-tion model for domain generalization. Our proposed algo-rithms are trained to produce accurate confidence predic-tions without needing any data from the target domain. 2) We provide theoretical error bounds for our proposed calibration methods and demonstrate the advantage of our methods in maximizing the overlap between the supports of the target and calibration distributions, a critical factor that determines the generalization performance of calibration. 3) We justify the proposed algorithms with experimen-tal results on real-world data. A decrease of 8.86 percent-age points in expected calibration error or, equivalently, an increase of 35 percentage points in improvement ratio is achieved on the Office-Home dataset [30] compared against state-of-the-art (SOTA) calibration methods designed for domain adaptation. 2.