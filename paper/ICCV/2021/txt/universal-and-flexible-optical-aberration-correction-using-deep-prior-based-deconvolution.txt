Abstract
High quality imaging usually requires bulky and expen-sive lenses to compensate geometric and chromatic aberra-tions. This poses high constraints on the optical hash or low cost applications. Although one can utilize algorithmic reconstruction to remove the artifacts of low-end lenses, the degeneration from optical aberrations is spatially varying and the computation has to trade off efﬁciency for perfor-mance. For example, we need to conduct patch-wise opti-mization or train a large set of local deep neural networks to achieve high reconstruction performance across the whole image. In this paper, we propose a PSF aware deep net-work, which takes the aberrant image and PSF map as input and produces the latent high quality version via in-corporating deep priors, thus leading to a universal and
ﬂexible optical aberration correction method. Speciﬁcally, we pre-train a base model from a set of diverse lenses and then adapt it to a given lens by quickly reﬁning the param-eters, which largely alleviates the time and memory con-sumption of model learning. The approach is of high ef-ﬁciency in both training and testing stages. Extensive re-sults verify the promising applications of our proposed ap-proach for compact low-end cameras. The code is available at https://github.com/leehsiu/UABC (a) (b) (c)
Figure 1: One example of computationally reconstructing high quality image with a simple lens. (a) A camera with a simple double glued lens (Thorlabs, AC254-075-A-ML). (b) The calibrated PSF of the camera in (a). (c) The input degenerated image (upper row) and our reconstruction re-sult (bottom row). 1.

Introduction
Optical aberration is one of the most common degener-ation in real lens-based imaging systems. Due to the de-viation from ideal thin-lens model, the simple/single lens elements suffer from chromatic, spherical aberration and coma aberrations, and degenerate the imaging quality sig-niﬁcantly. To cancel out these artifacts, modern camera lenses are usually made of a complex combination of sev-eral (even dozens of) lens elements with carefully designed
In a nutshell, exist-parameters (aka. ing techniques achieve high imaging quality via such com-lens prescription).
*lixiu15@mails.tsinghua.edu.cn plex design, at the expense of high cost, bulky weight and inevitable lens ﬂare. With the rapid development of large pixel count digital sensors (e.g. 100 mega-pixel scale), ef-fective compensation of lens aberration is highly desired.
To achieve light-weighted and low-cost high-quality imaging, computational optical aberration correction has been exploited during the past decades. Different from advanced optical design, computational methods employ a simple lens for imaging and remove the aberration after-wards with algorithms. Mathematically, the lens aberra-tion can be formulated as convolution with spatially varying kernels, and the compensation is conducted by deconvolu-tion with the assistance of image priors. These computa-tional methods can be either non-blind or blind depending on whether the aberration model, i.e., Point Spread Func-tion (PSF) is calibrated beforehand. The former measure the
PSF using specially designed systems [26, 7, 11] or estimat-ing it from degenerated images using some developed algo-rithms explicitly [23, 30, 28], deconvolution is conducted afterwards. The latter usually jointly estimates the PSF and the latent sharp image in an iterative manner [35]. Consid-ering the fact that the PSF is ﬁxed for a given lens, and the estimation of PSF has already been extensively studied, we focus on the non-blind case in this paper.
As illustrated in Fig. 1(b), the PSF by lens aberration is spatially non-uniform and varying across color channels as well. Previously, researchers have proposed a series of algorithms for non-uniform deconvolution, includes pixel-wise deconvolution [6, 33, 5] and patch-wise deconvolu-tion [7, 23, 36, 8]. The later one assumes that the PSF varies smoothly in the spatial dimension thus can be approximated locally uniform. The deconvolution in this situation is usu-ally faster than the pixel-wise methods. This assumption also holds for the PSF caused by the aberration of a low-end lens.
Recently, deep neural network has also been exploited for image deconvolution and has shown encouraging re-sults [27, 3]. However, handling non-uniformity is still challenging for end-to-end deep learning. Using a single network weight setting for different sub-regions with dif-ferent PSF will either requires a large model capacity or leads to an average performance. While training a series of models speciﬁcally for each sub-region is quite time consuming.
In this paper, we propose to combine deep network and model-based deconvolution into an iterative framework. Prior-guided deconvolution is conducted lo-cally and explicitly models the physical degeneration pro-cess, which ensures the high ﬁdelity and easy adaption to different lenses. A single global deep projection network is applied to the whole image to suppress ringing artifacts and eliminate blocking artifacts. Meanwhile, we propose to pretrain a base model from a large set of diverse lenses ﬁrst and then adapt it to a speciﬁc lens quickly, greatly simplify the training process for different lenses.
The main contributions of this paper are as follows.
• We propose a PSF-aware deep network to address the spatially varying degeneration caused by lens aberra-tion, by decoupling the physical imaging model and deep network prior.
• The model training is built on a pre-trained base model plus a fast adaption procedure to different lenses.
Thus, it is of high efﬁciency and high feasibility.
• The approach achieves state-of-the-art performance but with much higher running efﬁciency.
We conduct synthetic and qualitative experiments to demonstrate the training efﬁciency and performance of the proposed method. We also get promising results on real data captured by low end lenses, please refer to Fig. 1, and more results in Fig. 9. 2.