Abstract
Level 5 autonomy for self-driving cars requires a robust visual perception system that can parse input images under any visual condition. However, existing semantic segmenta-tion datasets are either dominated by images captured un-der normal conditions or are small in scale. To address this, we introduce ACDC, the Adverse Conditions Dataset with
Correspondences for training and testing semantic segmen-tation methods on adverse visual conditions. ACDC con-sists of a large set of 4006 images which are equally dis-tributed between four common adverse conditions: fog, nighttime, rain, and snow. Each adverse-condition image comes with a high-quality ﬁne pixel-level semantic anno-tation, a corresponding image of the same scene taken un-der normal conditions, and a binary mask that distinguishes between intra-image regions of clear and uncertain seman-tic content. Thus, ACDC supports both standard semantic segmentation and the newly introduced uncertainty-aware semantic segmentation. A detailed empirical study demon-strates the challenges that the adverse domains of ACDC pose to state-of-the-art supervised and unsupervised ap-proaches and indicates the value of our dataset in steering future progress in the ﬁeld. Our dataset and benchmark are publicly available. 1.

Introduction
Most of the prominent large-scale image-based datasets for driving scene understanding, including Cityscapes [8],
Vistas [28] and KITTI [13], are dominated by images cap-tured under normal visual conditions, i.e., at daytime and in clear weather. Yet, vision applications such as autonomous driving impose a strict requirement on perception algo-rithms to maintain satisfactory performance in adverse do-mains. Although there are recent efforts to include ad-verse visual domains in large-scale datasets, such as Oxford
RobotCar [27] and BDD100K [55], these efforts focus ei-ther on localization/mapping tasks [27,49] or on recognition tasks which do not involve dense pixel-level outputs, such as object detection [3, 42, 55]. For instance, while a notable 40% of the object detection set of BDD100K pertains to nighttime, only 3% of the images in its semantic segmenta-tion set, namely 345 images, are captured at nighttime [40].
In addition, the pixel-level annotation process for adverse-condition images is kept identical in [55] to the normal-condition case, which leads to errors in the ground truth and renders it unreliable [40]. In contrast, seminal previous work [8] has underlined the need for specialized techniques and datasets for pixel-level semantic scene understanding in adverse visual conditions, due to the inherent aleatory uncertainty in images captured in such conditions. These render entire image regions indiscernible even for humans.
ACDC constitutes a response to this need for a large-scale driving dataset specialized to adverse conditions, in terms of (i) size, (ii) domain adversity, and (iii) featured tasks. ACDC includes 4006 images with high-quality pixel-level semantic annotations, which are distributed equally among four common adverse conditions in real-world driv-ing environments, namely fog, nighttime, rain, and snow, thus featuring a scale of the same order as Cityscapes.
The dataset was deliberately recorded with the respective adverse conditions clearly present. Thus, a large domain shift from the normal clear-weather daytime conditions was achieved. Moreover, for each adverse-condition image, a corresponding normal-condition image of the same scene from approximately the same viewpoint is provided, in-tended for use by weakly supervised methods.
As to the tasks that our dataset supports, apart from stan-dard semantic segmentation, we add the task of uncertainty-aware semantic segmentation. For the latter we intro-1
s l e x i p f o r e b m u n 1010 108 106 d a o r k l a w e d i s
. d l i u b l l a w e c n e f
. t e g e v n i a r r e t r a c n i a r t k c u r t s u b e l c y c i b e l c y c r o t o m y k s e l o p n g i s c
ﬁ f a r t t h g i l c
ﬁ f a r t n o s r e p r e d i r
ﬂat construction nature vehicle sky object human
Figure 1. Number of ﬁnely annotated pixels per class in ACDC. duce a specialized annotation protocol and a dedicated per-formance metric, termed average uncertainty-aware IoU (AUIoU). The key characteristic of uncertainty-aware se-mantic segmentation is the principled inclusion of im-age regions with indiscernible semantic content—invalid regions—in annotation and evaluation.
In particular, the annotation protocol for our adverse-condition images lever-ages privileged information in the form of the correspond-ing normal-condition images and the original adverse-condition videos, which enables to reliably assign legiti-mate semantic labels to invalid regions and to include them in the evaluation both for standard and uncertainty-aware semantic segmentation. For the latter task, the separation of labeled pixels into invalid and valid is encoded in a binary mask. While both tasks require a hard semantic prediction, the uncertainty-aware task additionally expects a conﬁdence map prediction. AUIoU is designed to take into account both the semantic and the conﬁdence prediction and to re-ward predictions with low conﬁdence on invalid pixels and high conﬁdence on valid pixels. The requirement for an ad-ditional conﬁdence prediction is relevant for safety-oriented applications, as it can help the downstream decision-making system avoid the fatal consequences of a low-conﬁdence prediction being false, e.g. when a pedestrian is missed.
Apart from being a challenging benchmark for super-vised semantic segmentation approaches, ACDC is a well-suited test bed for domain adaptation. A multitude of recent works [7, 15, 22, 23, 26, 41, 43, 44, 46, 48, 51, 53, 59, 60, 62, 65, 66] have focused on unsupervised domain adaptation (UDA) for semantic segmentation, but most of them are validated only on an artiﬁcial synthetic-to-real setting, using GTA5 [34] and SYNTHIA [36] as source datasets and Cityscapes [8] as the target dataset. The normal-to-adverse domain adaptation scenario for seman-tic segmentation, which is much more relevant for real-world deployment of autonomous cars due to the difﬁculty of both acquiring and annotating adverse-condition data, has largely been overlooked.
In particular, much fewer works consider normal-to-adverse adaptation in their exper-iments [10,11,32,37,38,39,40] and whenever they do, they either restrict the target adverse domain to a single condi-tion, e.g. nighttime [10, 39, 40], fog [37, 38], or rain [11], or do not include a quantitative evaluation on the real tar-get domain altogether [32]. We attribute this fragmentation of normal-to-adverse adaptation works to the absence of a general large-scale dataset for semantic segmentation that evenly covers the majority of common adverse conditions and provides reliable ground truth for a sound evaluation in such challenging domains. ACDC answers exactly the need for such a dataset and will serve as a test bed for unsuper-vised and weakly supervised domain adaptation. Experi-ments such as Cityscapes→ACDC adaptation are straight-forward thanks to the identical label sets of the two datasets, which facilitates validation of new domain adaptation ap-proaches in the normal-to-adverse setting.
We experiment with ACDC in four main directions: evaluation of models pre-trained on normal conditions, su-pervised learning in adverse conditions, unsupervised and weakly supervised normal-to-adverse domain adaptation, and evaluation of uncertainty-aware semantic segmentation baselines and oracles. Results show that access to ground-truth annotations under adverse conditions is indispens-able for achieving high performance, as pre-trained mod-els severely deteriorate under adverse conditions. More-over, the real-world Cityscapes→ACDC adaptation sce-nario poses signiﬁcant challenges to all state-of-the-art
UDA methods, which recover at best only a small por-tion of the performance gain over the source-domain model compared to using full supervision. This underlines the need for UDA methods that perform better when handling adverse target domains and highlights the importance of
ACDC in steering future work in this direction. Finally, the uncertainty-aware annotations of ACDC create signiﬁcant room for improvement over simple conﬁdence prediction baselines and help promote future work on semantic seg-mentation methods that simultaneously models uncertainty. 2.