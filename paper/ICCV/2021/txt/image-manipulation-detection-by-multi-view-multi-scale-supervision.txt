Abstract
The key challenge of image manipulation detection is how to learn generalizable features that are sensitive to ma-nipulations in novel data, whilst speciﬁc to prevent false alarms on authentic images. Current research emphasizes the sensitivity, with the speciﬁcity overlooked. In this pa-per we address both aspects by multi-view feature learn-ing and multi-scale supervision. By exploiting noise dis-tribution and boundary artifact surrounding tampered re-gions, the former aims to learn semantic-agnostic and thus more generalizable features. The latter allows us to learn from authentic images which are nontrivial to be taken into account by current semantic segmentation network based methods. Our thoughts are realized by a new network which we term MVSS-Net. Extensive experiments on ﬁve bench-mark sets justify the viability of MVSS-Net for both pixel-level and image-level manipulation detection. 1.

Introduction
Digital images can now be manipulated with ease and often in a visually imperceptible manner [11]. Copy-move (copy and move elements from one region to another region in a given image), splicing (copy elements from one image and paste them on another image) and inpainting (removal of unwanted elements) are three common types of image manipulation that could lead to misinterpretation of the vi-sual content [1, 19, 23]. This paper targets at auto-detection of images subjected to these types of manipulation. We aim to not only discriminate manipulated images from the au-thentic, but also pinpoint tampered regions at the pixel level.
Unsurprisingly, the state-of-the-arts are deep learning based [14, 21, 26, 27, 29], speciﬁcally focusing on pixel-level manipulation detection [21, 26, 29]. With only two
*Xinru Chen and Chengbo Dong contribute equally to this work.
†Corresponding author: Xirong Li (xirong@ruc.edu.cn).
Figure 1. Image manipulation detection by the state-of-the-arts. The ﬁrst three rows are copy-move, splicing and inpainting, followed by three authentic images (thus with blank mask). Our model strikes a good balance between sensitivity and speciﬁcity. classes (manipulated versus authentic) in consideration, the task appears to be a simpliﬁed case of image semantic seg-mentation. However, an off-the-shelf semantic segmenta-tion network is suboptimal for the task, as it is designed to capture semantic information, making the network dataset-dependent and do not generalize. Prior research [29] re-ports that DeepLabv2 [4] trained on the CASIAv2 dataset
[8] performs well on the CAISAv1 dataset [7] homologous to CASIAv2, yet performs poorly on the non-homologous
COVER dataset [25]. A similar behavior of FCN [18] is also observed in this study. Hence, the key question is how to design and train a deep neural network capable of learn-ing semantic-agnostic features that are sensitive to manipu-lations, whilst speciﬁc to prevent false alarms?
In order to learn semantic-agnostic features, image con-Figure 2. Conceptual diagram of the proposed MVSS-Net model. We use the edge-supervised branch and the noise-sensitive branch to learn semantic-agnostic features for manipulation detection, and multi-scale supervision to strike a balance between model sensitivity and speciﬁcity. Non-trainable layers such as sigmoid (σ) and global max pooling (GMP) are shown in gray. tent has to be suppressed. Depending on at what stage the suppression occurs, we categorize existing methods into two groups, i.e. noise-view methods [14, 16, 26, 27, 30] and edge-supervised methods [21, 29]. Given the hypothesis that novel elements introduced by slicing and/or inpainting differ from the authentic part in terms of their noise dis-tributions, the ﬁrst group of methods aim to exploit such discrepancy. The noise map of an input image, generated either by pre-deﬁned high-pass ﬁlters [9] or by their train-able counterparts [2, 16], is fed into a deep network, either alone [16, 27] or together with the input image [14, 26, 30].
Note that the methods are ineffective for detecting copy-move which introduces no new element. The second group of methods concentrate on ﬁnding boundary artifact as ma-nipulation trace around a tampered region, implemented by adding an auxiliary branch to reconstruct the region’s edge
[21, 29]. Note that the prior art [29] uniformly concatenates features from different layers of the backbone as input of the auxiliary branch. As such, there is a risk that deeper-layer features, which are responsible for manipulation detection, remain semantic-aware and thus not generalizable.
To measure a model’s generalizability, a common eval-uation protocol [14, 21, 26, 29] is to ﬁrst train the model on a public dataset, say CASIAv2 [8], and then test it on other public datasets such as NIST16 [12], Columbia [13], and
CASIAv1 [7]. To our surprise, however, the evaluation is performed exclusively on manipulated images, with met-rics w.r.t pixel-level manipulation detection reported. The speciﬁcity of the model, which reveals how it handles au-thentic images and is thus crucial for real-world usability, is ignored. As shown in Fig. 1, their serious false alarm over authentic images leads to unavailability in practical work.
In fact, as current methods [14, 21, 26] mainly use pixel-wise segmentation losses to which an authentic example can contribute is marginal, it is nontrivial for these methods to improve their speciﬁcity by learning from the authentic.
Inspired by the Border Network [28], which aggregates features progressively to predict object boundaries, and Le-sionNet [24] that incorporates an image classiﬁcation loss for retinal lesion segmentation, we propose multi-view fea-ture learning with multi-scale supervision for image manip-ulation detection. To the best of our knowledge (Table 1), we are the ﬁrst to jointly exploit the noise view and the boundary artifact to learn manipulation detection features.
Moreover, such a joint exploitation is nontrivial. To com-bine the best of the two worlds, new network structures are needed. Our contributions are as follows:
• We propose MVSS-Net as a new network for image manip-ulation detection. As shown in Fig. 2, MVSS-Net contains novel elements designed for learning semantic-agnostic and thus more generalizable features.
• We train MVSS-Net with multi-scale supervision, allow-ing us to learn from authentic images, which are ignored by the prior art, and consequently improve the model speci-ﬁcity substantially.
• Extensive experiments on two training sets and ﬁve test sets show that MVSS-Net compares favorably against the state-of-the-art. 2.