Abstract
Nowadays advanced image editing tools and technical skills produce tampered images more realistically, which can easily evade image forensic systems and make authen-ticity verification of images more difficult. To tackle this challenging problem, we introduce TransForensics, a novel image forgery localization method inspired by Transform-ers. The two major components in our framework are dense self-attention encoders and dense correction modules. The former is to model global context and all pairwise inter-actions between local patches at different scales, while the latter is used for improving the transparency of the hidden layers and correcting the outputs from different branches.
Compared to previous traditional and deep learning meth-ods, TransForensics not only can capture discriminative representations and obtain high-quality mask predictions but is also not limited by tampering types and patch se-quence orders. By conducting experiments on main bench-marks, we show that TransForensics outperforms the state-of-the-art methods by a large margin. 1.

Introduction
Image is an important medium for information transmis-sion. Recently, tampered images generated by image edit-ing techniques are commonly confused to be real ones, and are increasingly used in fake news creation, academic fraud, and criminal offenses. When tampering occurs in a digital image, we usually expect that the tampered regions can be found through image forensic analyses. However, captur-ing discriminative features of tampered regions with multi-ple forgery types (e.g. splicing, copy-move, removal) is still a challenge and often requires exploiting the characteristics of different tampering artifacts.
Unlike semantic object segmentation methods [33, 43] that do predictions of all meaningful object regions, image forensics makes predictions of tampering locations only.
∗Equal contribution.
†Corresponding author.
Figure 1. Examples from three common image forgery datasets.
Four authentic images (top) with their corresponding tampered im-ages (medium) and ground-truth masks (bottom).
The former focuses on analyzing the content of different re-gions to understand visual concepts, while the latter needs to generalize some other artifacts (e.g. inconsistent local noise variances) created by different manipulation tech-niques. As shown in Fig.1, the well-manipulated images are usually realistic, where the content of fake and genuine regions is likely to be similar.
If we directly use seman-tic segmentation network for image forensics, the network would localize both original and manipulated regions, while the original ones are the wrong predictions for image foren-sics. The work of Bappy et al. [3] also have demonstrated that semantic segmentation approaches do not perform well for image manipulations.
The key to image forensics is characterizing different tempering artifacts that are often hidden in tiny details of the images. Previous methods mainly employ traditional hand-crafted features, such as error level analysis (ELA)
[20], discrete cosine transform (DCT) [5], and steganalysis rich model (SRM) [15], to learn local inconsistencies from invisible traces, but they usually apply only to a specific manipulation type. In fact, the boundary formation of tam-pered (smoother) and authentic regions (sharper) within an image is different [3, 4]. With the success of deep learning approaches, recent works focus on checking feature consis-tency or learning boundary discrepancy via convolutional
neural networks (CNNs) [10, 28, 35, 42] or recurrent neural networks (RNNs) [3, 4], which allow to capture tampering features and perform better than traditional methods.
However, the major shortcoming of deep learning meth-ods is that they heavily depend on hand-designed patch se-quence orders and manipulation types. Specifically, RNNs based methods split an image into a series of patches and use a long-short term memory (LSTM) network to learn the correlations between them. These networks can receive the sequential inputs, but cannot retain the spatial location in-formation. In contrast, the methods combining hand-crafted features with deep features [2, 38, 41, 42] achieve the state-of-the-art (SOTA) performance, but they usually assume that tampering type is known beforehand. Taking these facts into consideration, here we show how a spatial atten-tion network can be used within an image forgery localiza-tion framework to model all pairwise interactions between patches (including rich statistical features) of an image, yet maintain the global structure and alleviate ordering tech-niques and manipulation types limitation.
Framework overview In this paper, the goal of our sys-tem is to predict binary masks for image forgery localiza-tion. Firstly, we use a fully convolutional network (FCN) as backbone for feature extraction. Then, self-attention en-coders are used to model rich interactions between points in feature maps at different scales. For improving the perfor-mance, dense correction modules are used in our network, which helps to learn more discriminative representations from the early layers and performs results correction.
Main contributions
In this work, the main contributions are as follows. First, we propose a novel image forgery lo-calization method, called TransForensics. To the best of our knowledge, it is the first attempt in image forensics to model all pairwise relations, yet maintain the spatial structure be-tween patches with the self-attention mechanism. Second, we introduce a dense correction architecture, which adds the direct supervision for the hidden layers, and corrects the outputs from different branches by multiplication. Experi-ments show that our method outperforms the SOTA meth-ods by a large margin.
Structure of the paper The paper is organized as follows.
We first review related work in Section 2. Then, Section 3 introduces the proposed dense attention network for image forgery localization in detail. Section 4 shows the experi-mental datasets, details, results and analysis. Finally, Sec-tion 5 gives the conclusion of this paper. 2.