Abstract
In this work, we present a new multi-view depth estima-tion method that utilizes both conventional SfM reconstruc-tion and learning-based priors over the recently proposed neural radiance fields (NeRF). Unlike existing neural net-work based optimization method that relies on estimated correspondences, our method directly optimizes over im-plicit volumes, eliminating the challenging step of matching pixels in indoor scenes. The key to our approach is to utilize the learning-based priors to guide the optimization process of NeRF. Our system firstly adapts a monocular depth net-work over the target scene by finetuning on its sparse SfM reconstruction. Then, we show that the shape-radiance am-biguity of NeRF still exists in indoor environments and pro-pose to address the issue by employing the adapted depth priors to monitor the sampling process of volume render-ing. Finally, a per-pixel confidence map acquired by er-ror computation on the rendered image can be used to fur-*Corresponding author. ther improve the depth quality. Experiments show that our proposed framework significantly outperforms state-of-the-art methods on indoor scenes, with surprising findings pre-sented on the effectiveness of correspondence-based opti-mization and NeRF-based optimization over the adapted
In addition, we show that the guided opti-depth priors. mization scheme does not sacrifice the original synthesis capability of neural radiance fields, improving the render-ing quality on both seen and novel views. Code is available at https://github.com/weiyithu/NerfingMVS. 1.

Introduction
Reconstructing 3D scenes from multi-view posed im-ages, also named as multi-view stereo (MVS), has been a fundamental topic in computer vision over decades. The application varies from robotics, 3D modeling, to virtual reality, etc. Conventional multi-view stereo approaches
[2, 9, 13, 60] densely match pixels across views by compar-ing the similarity of cross-view image patches. While pro-ducing impressive results, those methods often suffer from poorly textured regions, thin structures and non-Lambertian surfaces, especially in real-world indoor environments.
Recently, with the success of deep neural networks, sev-eral learning-based methods [17, 20, 24, 53] are proposed to tackle the multi-view stereo problem often by employing a cost volume based architecture. Those methods perform a direct neural network inference at test time for multi-view depth estimation and achieve remarkable performance on benchmarks. However, due to the lack of constraints at in-ference, the predicted depth maps across views are often not consistent and the photometric consistency is often violated.
To address this issue, [29] proposed a test-time optimiza-tion framework that optimizes over learning-based priors acquired from single-image depth estimation. While being computationally inefficient, the method produces accurate and consistent depth maps that are available for various vi-sual effects. However, the optimization formulation of this method relies heavily on an optical flow network [16] to es-tablish correspondences, which becomes problematic when estimated correspondences are unreliable.
In this paper, we present a new neural network based optimization framework for multi-view depth estimation based on the recently proposed neural radiance fields [33].
Instead of relying on estimated correspondences and cross-view depth reprojection for optimization [29], our method directly optimizes over volumes. However, we show that the shape-radiance ambiguity [61] of NeRF becomes the bottleneck on estimating accurate per-view depths in indoor scenes. To address the issue, we propose a guided optimiza-tion scheme to help train NeRF with learning-based depth priors. Specifically, our system firstly adapts a monocu-lar depth network onto the test scene by finetuning on its
SfM reconstruction. Then, we employ the adapted depth priors to guide the sampling process of volume rendering for NeRF. Finally, we acquire a confidence map from the rendered RGB image of NeRF and improve the depth map with a post-filtering step.
Our findings indicate that the scene-specific depth prior adaptation significantly improves the depth quality. How-ever, performing existing correspondence-based optimiza-tion on the adapted depth priors will surprisingly degrade the performance. On the contrary, with direct optimiza-tion over neural radiance fields, our method consistently improves the depth quality over adapted depth priors. This phenomenon demonstrates the potential of exploiting neural radiance fields for accurate depth estimation.
Experiments show that our proposed framework signifi-cantly improves upon state-of-the-art multi-view depth esti-mation methods on tested indoor scenes. In addition, the guided optimization from learning-based priors can help improve the rendering quality of neural radiance fields on both seen and novel views, achieving comparable or even better quality with state-of-the-art novel view synthe-sis methods. This indicates that SfM reconstruction, while demonstrated to be effective on helping image-based view synthesis in [39, 40], can also help improve the synthesis quality on neural implicit representations. 2.