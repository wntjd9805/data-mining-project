Abstract
Recent learning-based multi-view stereo (MVS) methods show excellent performance with dense cameras and small depth ranges. However, non-learning based approaches still outperform for scenes with large depth ranges and sparser wide-baseline views, in part due to their PatchMatch opti-mization over pixelwise estimates of depth, normals, and visibility. In this paper, we propose an end-to-end trainable
PatchMatch-based MVS approach that combines advantages of trainable costs and regularizations with pixelwise esti-mates. To overcome the challenge of the non-differentiable
PatchMatch optimization that involves iterative sampling and hard decisions, we use reinforcement learning to minimize expected photometric cost and maximize likelihood of ground truth depth and normals. We incorporate normal estimation by using dilated patch kernels and propose a recurrent cost regularization that applies beyond frontal plane-sweep algo-rithms to our pixelwise depth/normal estimates. We evaluate our method on widely used MVS benchmarks, ETH3D and
Tanks and Temples (TnT). On ETH3D, our method outper-forms other recent learning-based approaches and performs comparably on advanced TnT. 1.

Introduction
Multi-view stereo (MVS) aims to reconstruct 3D scene ge-ometry from a set of RGB images with known camera poses, with many important applications such as robotics [25], self-driving cars [8], infrastructure inspection [7, 13], and map-ping [31]. Non-learning based MVS methods [5, 26, 32, 34, 41] evolved to support pixelwise estimates of depths, normals, and source view selection, with PatchMatch based iterative optimization and cross-image consistency checks.
Recent learning-based MVS methods [12, 15, 16, 39, 40] tend to use frontal plane sweeps, evaluating the same set of depth candidates for each pixel based on the same im-ages. The trainable photometric scores and cost-volume regularization of the learning-based methods leads to excel-Image
Ground Truth
COLMAP [27]
Ours
Figure 1. We propose PatchMatch-RL, an end-to-end trainable
PatchMatch-based MVS approach that combines advantages of trainable costs and regularizations with pixelwise estimates of depth, normal, and visibility. The left half of the bottom images is the depth, and the right half is the normals. We show that our method can achieve smoother and more complete depth and normal map estimation over the existing approach (COLMAP). lent performance with dense cameras and small depth ranges, as evidenced in the DTU [2] and Tanks-and-Temples (TnT) benchmarks [18], but the pixelwise non-learning based ap-proach outperforms for scenes with large depth ranges and slanted surfaces observed with sparser wide-baseline views, as evidenced in the ETH3D benchmark [28].
Our paper aims to incorporate pixelwise depth, normal, and view estimates into an end-to-end trainable system with advantages from both approaches:
• Pixelwise depth and normal prediction efficiently models scenes with large depth ranges and slanted sur-faces.
• Pixelwise view selection improves robustness to occlu-sion and enables reconstruction from sparser images.
*Work done outside of Amazon
Code available at https://github.com/leejaeyong7/patchmatch-rl
• Learned photometric cost functions improve corre-spondence robustness. 1
• Learned regularization and contextual inference en-able completion of textureless and glossy surfaces.
One challenge is that PatchMatch optimization and pix-elwise view selection involve iterative sampling and hard decisions that are not differentiable. We propose a reinforce-ment learning approach to minimize expected photometric cost and maximize discounted rewards for reaching a good final solution. Our techniques can also be used to enable learning for other PatchMatch applications (e.g. [3, 14, 21]), though we focus on MVS only. Estimating 3D normals of pixels is also challenging because convolutional features tend to be smooth so that neighboring cells add little new information, and patch-wise photometric costs are memory intensive. We find that with shallower feature channels and dilated patch kernels, we effectively estimate pixel normals.
A third challenge is how to perform regularization or global inference. Each pixel has its own depth/normal estimate, so cost-volume based regularization does not apply. We pro-pose a recurrent cost regularization that updates a hidden state via message passing that accounts for depth/normal similarities between pixels.
In summary, our main contribution is an end-to-end trainable PatchMatch-based MVS approach that combines advantages of trainable costs and regularizations with pixel-wise estimates, requiring multiple innovations:
• Reinforcement learning approach to train end-to-end within a PatchMatch sampling based optimization.
• Use of normal estimates in learning-based MVS, en-abled by trainable PatchMatch optimization and CNN patch features.
• Depth/normal regularization that applies beyond frontal to our pixelwise plane-sweep algorithms; e.g. depth/normal estimates.
In experiments, our system outperforms other recent learning-based methods on ETH3D and performs similarly on TnT, and our ablation study validates the importance of pixelwise normal and view selection estimates. 2.