Abstract
Regression-based methods have recently shown promis-ing results in reconstructing human meshes from monocular images. By directly mapping raw pixels to model param-eters, these methods can produce parametric models in a feed-forward manner via neural networks. However, mi-nor deviation in parameters may lead to noticeable mis-alignment between the estimated meshes and image evi-dences. To address this issue, we propose a Pyramidal
Mesh Alignment Feedback (PyMAF) loop to leverage a fea-ture pyramid and rectify the predicted parameters explicitly based on the mesh-image alignment status in our deep re-gressor. In PyMAF, given the currently predicted parame-ters, mesh-aligned evidences will be extracted from finer-resolution features accordingly and fed back for parameter rectification. To reduce noise and enhance the reliability of these evidences, an auxiliary pixel-wise supervision is im-posed on the feature encoder, which provides mesh-image correspondence guidance for our network to preserve the most related information in spatial features. The efficacy of our approach is validated on several benchmarks, in-cluding Human3.6M, 3DPW, LSP, and COCO, where ex-perimental results show that our approach consistently im-proves the mesh-image alignment of the reconstruction. The project page with code and video results can be found at https://hongwenzhang.github.io/pymaf. 1.

Introduction
Aiming at the same goal of producing natural and well-aligned results, two different paradigms for human mesh recovery have been investigated in the research commu-nity. Optimization-based methods [5, 29, 63] explicitly fit
*: Equal contribution. (cid:66): Corresponding authors. (a) (b) (c) (d)
Figure 1: Illustration of our main idea. (a) The commonly-used iterative error feedback. (b) Our mesh alignment feed-back. (c) Mesh-aligned evidences extracted from a feature pyramid. (d) Our approach PyMAF improves the mesh-image alignment of the estimated mesh. the models to 2D evidences, which can typically produce results with accurate mesh-image alignments but tend to be slow and sensitive to the initialization. Alternatively, regression-based ones [22, 42, 27, 26] suggest to directly predict model parameters from images, which have shown very promising results, and yet still suffer from the coarse alignment between predicted meshes and image evidences.
For parametric models like SMPL [34], the joint poses are represented as the relative rotations with respect to their parent joints, which means that minor rotation errors ac-cumulated along the kinematic chain can result in notice-In order to generate well-able drifts of joint positions. aligned results, optimization-based methods [5, 29] design data terms in the objective function so that the alignment between the projection of meshes and 2D evidences can be explicitly optimized. Similar strategies are also exploited in regression-based methods [22, 42, 27, 26] to impose 2D supervisions upon the projection of estimated meshes in the training procedure. However, during testing, these deep re-gressors either are open-loop or simply include an Iterative
Error Feedback (IEF) loop [22] in their architectures. As shown in Fig. 1(a), IEF reuses the same global features in its feedback loop, making its regressors hardly perceive the mesh-image misalignment in the inference phase.
As suggested in previous works [44, 38, 32, 50], neural networks tend to retain high-level information and discard detailed local features when reducing the spatial size of fea-ture maps. To leverage spatial information in the regression networks, it is essential to extract pixel-wise contexts for fine-grained perception. Several attempts have been made to leverage pixel-wise representations such as part segmen-tation [40] or dense correspondences [59, 66] in their re-gression networks. Though these regressors take pixel-level evidences into consideration, it is still challenging for them to learn structural priors and get hold of spatial details at the same time based merely on high-resolution contexts.
Motivated by above observations, we design a Pyrami-dal Mesh Alignment Feedback (PyMAF) loop in our regres-sion network to exploit multi-scale contexts for better mesh-image alignment of the reconstruction. The central idea of our approach is to correct parametric deviations explicitly and progressively based on the alignment status.
In Py-MAF, mesh-aligned evidences will be extracted from spa-tial features according to the 2D projection of the estimated mesh and then fed back to regressors for parameter updates.
As illustrated in Fig. 1, the mesh alignment feedback loop can take advantage of more informative features for param-eter correction in comparison with the commonly used it-erative error feedback loop [22, 7]. To leverage multi-scale contexts, mesh-aligned evidences are extracted from a fea-ture pyramid so that coarse-aligned meshes can be corrected with large step sizes based on the lower-resolution features.
Moreover, to enhance the reliability of the spatial cues, an auxiliary task is imposed on the highest-resolution feature to infer pixel-wise dense correspondences, which provides guidance for the image encoder to preserve the mesh-image alignment information. The contributions of this work can be summarized as follows:
• A mesh alignment feedback loop is introduced for regression-based human mesh recovery, where mesh-aligned evidences are exploited to correct parametric er-rors explicitly so that the estimated meshes can be better-aligned with input images.
• A feature pyramid is further incorporated with the mesh alignment feedback loop so that the regression network can leverage multi-scale alignment contexts.
• An auxiliary pixel-wise supervision is imposed on the im-age encoder so that its spatial features can be more infor-mative and the mesh-aligned evidences can be more rele-vant and reliable. 2.