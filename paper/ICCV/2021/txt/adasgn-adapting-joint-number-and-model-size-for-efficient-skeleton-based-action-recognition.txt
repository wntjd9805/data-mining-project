Abstract
Existing methods for skeleton-based action recogni-tion mainly focus on improving the recognition accuracy, whereas the efficiency of the model is rarely considered. Re-cently, there are some works trying to speed up the skeleton modeling by designing light-weight modules. However, in addition to the model size, the amount of the data involved in the calculation is also an important factor for the running speed, especially for the skeleton data where most of the joints are redundant or non-informative to identify a spe-cific skeleton. Besides, previous works usually employ one fix-sized model for all the samples regardless of the difficulty of recognition, which wastes computations for easy sam-ples. To address these limitations, a novel approach, called
AdaSGN, is proposed in this paper, which can reduce the computational cost of the inference process by adaptively controlling the input number of the joints of the skeleton on-the-fly. Moreover, it can also adaptively select the opti-mal model size for each sample to achieve a better trade-off between the accuracy and the efficiency. We conduct ex-tensive experiments on three challenging datasets, namely,
NTU-60, NTU-120 and SHREC, to verify the superiority of the proposed approach, where AdaSGN achieves compara-ble or even higher performance with much lower GFLOPs compared with the baseline method. 1.

Introduction
Action recognition is a popular research topic due to its wide range of application scenarios such as human-computer interaction and video surveillance [2, 29, 7, 25].
Recently, different with conventional approaches that use
RGB sequences for input, exploiting the skeleton data for action recognition has drawn increasingly more atten-tion [38, 4, 27, 19]. Biologically, human is able to recognize
*Corresponding Author
Figure 1. GFLOPs v.s. accuracy on NTU-60 (CS) dataset for state-of-the-art methods. the action category by observing only the motion of joints even without the appearance information [10]. Skeleton is such a data modality that consists of only the 2D/3D po-sitions of the human key joints. Compared with the RGB data, it has smaller amount of data, higher-level semantic information and stronger robustness for complicated envi-ronment.
In early stage, approaches for skeleton-based action recognition mainly focus on designing various hand-crafted features [33]. With the success of the deep learning, vari-ous deep networks have been proposed for skeleton-based action recognition [39, 14, 12, 1, 38, 27]. However, the computational complexity of the state-of-the-art deep net-works are too heavier, most of which are higher than 15
GFLOPs [3]. For example, the representative GCN-based work, i.e., ST-GCN [38], costs 16.2 GFLOPs for one action sample. In the practical application scenario, speed is an important factor. Thus, how to speed up the current meth-ods is a valuable-researched topic.
Recently, some works propose to speed up the skeleton modeling by designing light-weight models, such as Shift-GCN [3] and SGN [40]. However, in addition to the model size, the amount of the data involved in the calculation is also an important factor affecting the running time, which is rarely considered in previous works. Especially for the
skeleton data, to identify a specific action, many of the joints in the skeleton sequence are actually redundant. For example, to recognize the action “swipe right”, the global motion information is the key factor, which means the tra-jectory of the central point is discriminative enough for recognition. Thus, for various samples, it is unnecessary to always use all the joints for computation. Besides, for a specific action sequence, there are multiple stages, such as the starting stage, the course stage and the ending stage [41].
Some of the stages are always non-informative, e.g., the be-ginning and the ending, which should not been exhaustively analysed with all of the joints. Furthermore, the difficulty of recognition varies for different actions. Previous works em-ploy one fix-sized model for all the samples, which wastes computations for easy samples. For example, it is obvious that distinguishing the “walking” vs. “lying” is easier than distinguishing the “brushing hair” vs. “brushing teeth”, so instead of using the same model, it is better to apply big models for hard samples whereas applying small models for easy samples.
To address these limitations, we propose a novel ap-proach, called adaptive SGN (AdaSGN), for efficient skeleton-based action recognition. SGN [40] is already a very light-weight (only 0.7M) model for skeleton-based ac-tion recognition and is the baseline method in this paper.
Compared with SGN, our AdaSGN can further reduce more than half of the GFLOPs with even higher performance. In detail, AdaSGN learns a policy network to adaptively se-lect the optimal joint number and the optimal model size to control the trade-off between the accuracy and the effi-ciency. The policy network is designed as a light-weight module and is calculated with the features of the smallest number of joints, which costs nearly no additional compu-tational cost. It outputs policies according to the input sam-ple to decide on-the-fly which model size and which joint number should be used for each skeleton. Because the deci-sions are in a discrete distribution and the decision process is non-differentiable, we employ the Straight-Through (ST)
Gumbel Estimator [9] to back-propagate gradients. Thus, the proposed method is a fully differentiable framework and can be trained in an end-to-end manner. The training loss is the combination of an efficiency loss and an accuracy loss, where the proportions of the two terms can be adjusted to control the accuracy-efficiency trade-off.
To verify the superiority of the proposed approaches, extensive experiments are performed on three popular datasets, namely, NTU-60, NTU-120 and SHREC, where our method achieves comparable or even higher perfor-mance with much lower GFLOPs.
For example, we achieve +0.5%/+0.4% improvements of accuracy using only 39.6%/31.3% GFLOPs on CS/CV benchmarks of the
NTU-60 dataset compared with the baseline method. Fig-ure 1 shows the GFLOPs vs. accuracy diagram on the CS benchmark of the NTU-60 dataset.
Our contributions can be summarized as follows: (1) We propose a novel approach that can adaptively select both the optimal joint number and the optimal model size for efficient skeleton modeling. (2) We design a light-weight policy network and train it with the ST Gumbel Estimator to make it highly efficient. (3) We conduct extensive ex-periments on three benchmark datasets to demonstrate the superiority of our approach over state-of-the-art methods.
Code is released1. 2.