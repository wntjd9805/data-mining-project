Abstract
In this paper, we introduce a new framework for unsu-pervised deep homography estimation. Our contributions are 3 folds. First, unlike previous methods that regress 4 offsets for a homography, we propose a homography flow representation, which can be estimated by a weighted sum of 8 pre-defined homography flow bases. Second, consider-ing a homography contains 8 Degree-of-Freedoms (DOFs) that is much less than the rank of the network features, we propose a Low Rank Representation (LRR) block that re-duces the feature rank, so that features corresponding to the dominant motions are retained while others are rejected.
Last, we propose a Feature Identity Loss (FIL) to enforce the learned image feature warp-equivariant, meaning that the result should be identical if the order of warp opera-tion and feature extraction is swapped. With this constraint, the unsupervised optimization is achieved more effectively and more stable features are learned. Extensive experi-ments are conducted to demonstrate the effectiveness of all the newly proposed components, and results show that our approach outperforms the state-of-the-art on the homog-raphy benchmark datasets both qualitatively and quanti-tatively. Code is available at https://github.com/ megvii-research/BasesHomo 1.

Introduction
Homography is a fundamental and important image alignment model that has been widely used for image reg-istration [1]. A homography is a 3 × 3 matrix that contains 8 Degree-of-Freedoms (DOFs), with each 2 for scale, trans-lation, rotation and perspective [9]. Traditionally, a homog-raphy is often estimated by detecting and matching image features [16, 20], and then solving a Direct Linear Trans-form (DLT) [9] with outlier removal [7]. In contrast, deep homography methods take two images as the network input, and directly output a homography matrix [5]. Compared
*Corresponding author
Figure 1. (a) Previous deep homography methods estimate 4 mo-tion offsets and solve a DLT for the result. (b) We construct 8 flow motion bases by modifying matrix elements of a homography, and then regress 8 weights to combine the flow bases for the result. with traditional methods that highly rely on the extracted feature matches, deep methods are more robust.
Deep methods can be classified into two categories, su-pervised [5, 14] and unsupervised [28, 18]. The former one adopts synthesized examples with ground-truth labels to train the network while the latter one directly minimizes the photometric or feature differences between two images. As synthesized examples cannot reflect scene parallax and dy-namic objects, unsupervised methods often generalize bet-ter than the supervised ones. For unsupervised methods,
Nguyen et al. [18] minimized error over the entire image while Zhang et al. [28] proposed to learn a mask to skip outlier regions during the minimization.
It is not optimal to directly regress the elements of a homography matrix, as they are with different magnitudes.
Current solution is to regress 4 offsets [5, 14, 28, 18], which is equivalent to a homography if feeds them to the DLT solver (Fig. 1(a)).
In this work, we start from a new di-rection by proposing a “homography flow” representation (Fig. 1(b)). Specifically, we first generate 8 flow bases by modifying the entries of a homography matrix one at
Figure 2. Our network pipeline takes grayscale image patches Ia and Ib as input, and produces 8 weights to combine 8 pre-defined homography bases to produce a homography flow as output. The network consists of two modules, a warp-equivariant feature extractor f (·) and a homography estimator h(·), with 2 inserted LRR blocks to reduce the rank of the motion features. a time. As such, 8 homography matrices are obtained, each of which can be further translated into a flow map given the image coordinates, yielding 8 homography flow bases.
In small-baseline scenarios, a homography flow can be re-constructed inside the space spanned by these flow bases by learning combinational weights.
As homography has only 8 DOFs, the homography flow lies in a low-rank subspace. However, the rank of the mo-tion features through a network are usually much higher than that of a homography. From this observation, we pro-pose to decrease the rank of the features by projecting them into their subspaces. Specifically, the projection contains two steps, including discovering the subspace bases of the features maps and then transforming feature maps into the subspace. To achieve this projection, we propose a Low
Rank Representation (LRR) block, that can be plugged into a normal CNN and be trained end-to-end for the feature rank reduction. When the rank is reduced, features corre-sponding to the dominant motions, i.e. motions that could be described by a homography, are often retained. Features induced from non-dominant motions, e.g., multi-depth and dynamic contents, are often removed or suppressed.
Besides, the triplet loss of previous method still intro-duces trivial solutions [28]. Specifically, the feature warp-equivariance cannot be well preserved during the unsuper-vised training, while this property should have held ide-ally, i.e. f (W(I)) = W(f (I)), where W, f (·) represent the warp operation and feature extraction. The lack of fea-ture warp-equivariance results in the incorrect optimization of triplet loss, whose convergence direction is dominated by the distances between target features (anchors) and source features (negatives). However, the closer distances between target features (anchors) and warped source features (pos-itives) are more essential regarding the alignment task. To this end, we propose a “Feature Identity Loss” (FIL) to en-force the image feature to be warp-equivariant. It is demon-strated that with FIL, our model can achieve more effective unsupervised optimization and learn more stable features.
We demonstrate the effectiveness of all the newly pro-posed techniques and components by extensive experiments and ablation studies. The experimental results also ver-ify that our method outperforms the state-of-the-arts on the public benchmark both qualitatively and quantitatively. To sum up, our contributions are as follows:
• We propose a new representation “homography flow” that assembles 8 pre-computed flow bases for unsuper-vised deep homography estimation.
• We propose a new LRR block that reduces motion fea-ture rank so as to reject motion noises implicitly.
• We propose a new FIL loss that enforces the warp-equivariance of the learned image feature to facilitate a stable unsupervised optimization. 2.