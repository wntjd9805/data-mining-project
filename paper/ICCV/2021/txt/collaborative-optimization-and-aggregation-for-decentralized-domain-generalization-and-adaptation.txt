Abstract
Contemporary domain generalization (DG) and multi-source unsupervised domain adaptation (UDA) methods mostly collect data from multiple domains together for joint optimization. However, this centralized training paradigm poses a threat to data privacy and is not applicable when data are non-shared across domains.
In this work, we propose a new approach called Collaborative Optimiza-tion and Aggregation (COPA), which aims at optimizing a generalized target model for decentralized DG and UDA, where data from different domains are non-shared and pri-vate. Our base model consists of a domain-invariant fea-ture extractor and an ensemble of domain-speciﬁc classi-ﬁers. In an iterative learning process, we optimize a local model for each domain, and then centrally aggregate lo-cal feature extractors and assemble domain-speciﬁc classi-ﬁers to construct a generalized global model, without shar-ing data from different domains. To improve generaliza-tion of feature extractors, we employ hybrid batch-instance normalization and collaboration of frozen classiﬁers. For better decentralized UDA, we further introduce a predic-tion agreement mechanism to overcome local disparities to-wards central model aggregation. Extensive experiments on
ﬁve DG and UDA benchmark datasets show that COPA is capable of achieving comparable performance against the state-of-the-art DG and UDA methods without the need for centralized data collection in model training. 1.

Introduction
Deep neural networks have advanced signiﬁcantly over the past decade and achieved promising performance for many visual recognition tasks. However, due to the pres-ence of data bias [33] between training and test data (a.k.a. domain shift [28]), models elaborately optimized with labeled training data from some source domains usu-ally suffer from signiﬁcant performance degradation on new target domains. To resolve this problem, domain general-ization (DG) [52, 40, 15] and unsupervised domain adap-tation (UDA) [35, 38, 26] have been intensively studied, which aim at generalizing models learned on source do-mains to new target domains.
Traditionally, DG and UDA can use a single source do-main for generalization learning by adversarial data aug-mentation or domain alignment [37, 25]. But real-world data are usually collected from different domains under dif-ferent conditions (e.g., style and environment), so recent studies focus more on multi-source DG [15] and UDA [26], yielding better generalization performance.
In this work, we also focus on multi-source DG and UDA. Contemporary multi-source DG [31, 47, 50] and UDA [2, 26, 51] share the assumption that training data are collected from multi-ple domains to jointly optimize a generalized model. While
DG focuses on direct deployment on unseen new target do-mains, UDA utilizes unlabeled data from target domains to further reduce domain discrepancy. However, this central-ized model learning paradigm is not applicable when source data from different domains cannot be shared for joint training, due to either data privacy or storage/transmission limitations. To address this problem, several recent stud-ies [27, 7] resort to federated learning [21, 12] for devel-oping decentralized UDA by federated adversarial train-ing [27] or knowledge distillation [7]. However, these meth-ods rely heavily on unlabeled target domain data for learn-ing a global model and fail to resolve the more challenging decentralized DG problem.
In this work, we study the problems of decentralized
DG and UDA, which aim at optimizing a generalized tar-get model via decentralized learning with non-shared data from multiple domains. To this end, we propose a new approach called Collaborative OPtimization and Aggrega-tion (COPA). Fig. 1 illustrates our approach. For decen-tralized DG (steps 1, 3 and 5):
In each source domain (step 1), we optimize a local model, which consists of a domain-invariant feature extractor and an ensemble of domain-speciﬁc classiﬁers, using non-shared and private lo-cal training data. Next (step 3), we centrally aggregate lo-cal feature extractors as a global domain-invariant feature
Figure 1. An overview of the proposed Collaborative Optimization and Aggregation (COPA) approach to decentralized DG and UDA. In decentralized DG, steps 1, 3 and 5 are iteratively performed, while in decentralized UDA, steps 1-5 are iteratively performed (with central unlabeled data from a target domain). Note that source labeled data from different domains are non-shared and Ct only exists for UDA. extractor and assemble domain-speciﬁc classiﬁers as an en-semble of classiﬁers. Together they represent a generalized global model which is then used to update local models to facilitate the collaborative optimization (step 5). For decen-tralized UDA (steps 1-5): Given additional unlabeled train-ing data from a target domain, we measure centrally the prediction agreement among local models (step 2) to gen-erate weights for model aggregation and pseudo labels for model ﬁne-tuning (step 4). This collaborative optimization and aggregation process is iterative, and it allows us to learn a generalized global model for both decentralized DG and
UDA without sharing local data across domains.
Contributions. We propose a new approach called Col-laborative Optimization and Aggregation (COPA) to re-solve both decentralized DG and UDA problems. This differs from the conventional centralized DG and UDA methods [31, 51, 26] that collect data from different do-mains together for joint training. We optimize domain-invariant feature extractors for central aggregation and domain-speciﬁc classiﬁers for central ensembling. This approach enables more selective knowledge disentangle-ment between domain-invariant feature representations and domain-speciﬁc classiﬁcation information. This differs from aggregating all parameters indiscriminately of local models for constructing a global model [21, 27, 7]. For better decentralized UDA, we further introduce a prediction agreement mechanism to facilitate central model aggrega-tion. We conduct extensive experiments on ﬁve DG and
UDA benchmark datasets and show that COPA decentral-ized learning approach is capable of achieving comparable performance against the state-of-the-art methods. 2.