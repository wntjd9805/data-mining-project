Abstract
This paper studies Semi-Supervised Domain Adaptation (SSDA), a practical yet under-investigated research topic that aims to learn a model of good performance using un-labeled samples and a few labeled samples in the target domain, with the help of labeled samples from a source domain. Several SSDA methods have been proposed re-cently, which however fail to fully exploit the value of the few labeled target samples.
In this paper, we propose
Enhanced Categorical Alignment and Consistency Learn-ing (ECACL), a holistic SSDA framework that incorporates multiple mutually complementary domain alignment tech-niques. ECACL includes two categorical domain alignment techniques that achieve class-level alignment, a strong data augmentation based technique that enhances the model’s generalizability and a consistency learning based technique that forces the model to be robust with image perturbations.
These techniques are applied on one or multiple of the three inputs (labeled source, unlabeled target, and labeled target) and align the domains from different perspectives. ECACL uniﬁes them together and achieves fairly comprehensive domain alignments that are much better than the existing methods: For example, ECACL raises the state-of-the-art accuracy from 68.4 to 81.1 on VisDA2017 and from 45.5 to 53.4 on DomainNet for the 1-shot setting. Our code is avail-able at https://github.com/kailigo/pacl. 1.

Introduction
Domain adaptation investigates techniques of avoiding severe performance drop when deploying a model on a new domain (target) that has domain gap with the one (source) which the model is trained on. Most existing research fo-cuses on Unsupervised Domain Adaptation (UDA) where a model is trained jointly with unlabeled target data and la-beled source data. Many effective UDA approaches have been proposed, from early works that project data from both
*Work done when Kai Li was with Northeastern University. domains to a shared feature space [13, 34], to recent ones that are based on adversarial learning [43, 28].
This paper makes a slight diversion from the mainstream
UDA research direction and investigates how much it can help if we are further provided with a few (e.g., one sam-ple per class) labeled target samples. We call these scarce labeled target samples as “landmarks”. This is a practical (with minimal labeling effort) yet under-investigated prob-lem and is referred as semi-supervised domain adaptation (SSDA). Preliminary works before the deep learning era use landmarks to more precisely measure the data distribution mismatch between source and target domains, either based on Maximum Mean Discrepancy (MMD) or domain invari-ant subspace learning [1, 10, 50]. Recent ones revisit this problem and establish new evaluation benchmarks in the deep learning context [38, 18]. However, these prior works have not fully realized the value of the precious landmarks:
They are mainly used to optimize the cross-entropy loss along with the labeled source samples that are of a much greater amount; the contribution of the landmarks is sig-niﬁcantly diluted and thus the learned model shall still be biased towards the source domain.
In this paper, we propose Enhanced Categorical Align-ment and Consistency Learning (ECACL), a SSDA frame-work which uniﬁes multiple techniques that align domains from different complementary perspectives. As we have ac-cess to a few labeled samples from the target domain, i.e., landmarks, we can align the domains in a supervised way by explicitly aligning samples of the same category from the two domains. We propose two techniques to achieve this objective. The ﬁrst one is based on the prototypical loss
[40, 23]. We calculate a target prototype for each class by averaging feature embeddings of the landmarks from that class. Then, source samples are aligned with the target pro-totype from the same class. The second one is based on the triplet loss. We explicitly push source samples close to the landmarks from the same class and apart from the land-marks from the different classes.
Overﬁtting would likely occur since the number of land-marks is small. An intuitive approach to this is data aug-mentation. But rather than employing some commonly used techniques, e.g., image ﬂipping, we harvest a recently pro-posed one, RandAugment [7] which produces highly per-turbed images by applying various image transformations on an image. We apply RandAugment on both labeled source samples and landmarks, which makes the categorical alignment non-trivial to achieve and thus enhances model generalibility.
Consistency learning has recently been proved a very successful solution to various label scarce problems [41, 46, 5]. Inspired by this, we introduce consistency learning to cope the SSDA problem. Speciﬁcally, we apply simultane-ously a light data augmentation (e.g., image ﬂipping) and a strong augmentation (e.g., RandAugment) on each unla-beled target image, and obtain two versions for each im-age. We enforce the consistency constraint by producing a pseudo label from the lightly augmented version, and use the pseudo label as the ground truth label for the strongly augmented version for supervised learning. By requiring different perturbed versions of the same image being pre-dicted with the same label, we encourage the model to be ro-bust to changes in the image space and thus be more capable of handling the domain gap. Besides, since unlabeled target samples share the same label space as the labeled source samples, this constraint facilitates label propagation from the labeled source domain to the unlabeled target domain.
Integrating the above techniques that align domains from different perspectives using different combinations of the inputs, we reach the holistic SSDA framework, ECACL. We show in the experiments that ECACL signiﬁcantly advances the state-of-the-art performance on the common evaluation benchmarks. For example, ECACL lifts the state-of-the-art mean accuracy from 68.4 to 81.1 on VisDA2017 and from 45.5 to 53.4 on DomainNet for the 1-shot setting
In summary, the contributions of this paper are as fol-lows: (1) We propose ECACL, a holistic SSDA framework that incorporates multiple complementary domain align-ment techniques. Although each of the incorporated tech-nique is not fundamentally new, we are the ﬁrst to introduce them to address the SSDA problem and assemble them in a holistic framework. (2) We conduct a comprehensive ab-lation study and analysis of ECACL, which offer insights on drawing connections among seemingly distinct tasks and identifying contributing techniques. (3) We signiﬁcantly advance the state-of-the-art performance for SSDA. 2.