Abstract
In this work, we study the problem of human-object in-teraction (HOI) detection with large vocabulary object cat-egories. Previous HOI studies are mainly conducted in the regime of limit object categories (e.g., 80 categories). Their solutions may face new difficulties in both object detection and interaction classification due to the increasing diver-sity of objects (e.g., 1000 categories). Different from pre-vious methods, we formulate the HOI detection as a query problem. We propose a unified model to jointly discover the target objects and predict the corresponding interac-tions based on the human queries, thereby eliminating the need of using generic object detectors, extra steps to as-sociate human-object instances, and multi-stream interac-tion recognition. This is achieved by a repurposed Trans-former unit and a novel cascade detection over multi-scale feature maps. We observe that such a highly-coupled solu-tion brings benefits for both object detection and interac-tion classification in a large vocabulary setting. To study the new challenges of the large vocabulary HOI detection, we assemble two datasets from the publicly available SWiG and 100 Days of Hands datasets. Experiments on these datasets validate that our proposed method can achieve a notable mAP improvement on HOI detection with a faster inference speed than existing one-stage HOI detectors. Our code is available at https://github.com/scwangdyd/ large_vocabulary_hoi_detection. 1.

Introduction
Discovering human interactions with objects plays a vi-tal role in human-centric visual understanding and provides a means to understand human intentions, actions, and activ-ities. The goal is to detect one or multiple tuples <human, verb, object> to indicate the positions of human and objects within the image, and through the verb predict how they interact with each other (e.g., holding something, re-pairing something, etc.).
While recent studies on human-object interaction (HOI) detection [1, 23, 52, 46, 9, 16, 20, 43, 40, 27] have achieved great progress, they have largely focused on the regime with a limited variety of objects (e.g., 80 COCO objects [26]). In
Figure 1: In this work, we aim to detect the human interactions with large-vocabulary object categories, where there are a large number of interactions and only a few data samples available for-most categories. reality, humans can interact with a large variety of objects in our visual world. We can see various human interac-tions with daily objects from YouTube videos [8] or Internet data [36]. Nevertheless, it remains an under-explored prob-lem for HOI detection in the regime of large-vocabulary object categories, where there are a large number of inter-actions and only a few data samples available for most in-teractions. In this setting, existing approaches would face new difficulties due to the greater diversity of objects and contexts.
The main goal of this work is to study the new challenges of discovering human interactions with large-vocabulary objects. For HOI detection, the common practice is to de-compose the problem into two parts: (1) person and object instances detection; (2) instance matching and interaction classification. Depending on whether the two parts are con-ducted sequentially or in parallel, existing works can be fur-ther divided into the two-stage solutions [20, 19, 52, 40, 9] or end-to-end one-stage solutions [7, 23, 46, 17]. Regard-less of which type of solutions, existing methods usually in-stantiate the object detection part as generic detectors, e.g.,
Faster RCNN [34], CenterNet [5], RetineNet [25], etc. As previous HOI studies are mainly conducted in the same cat-egory space as COCO detection [26], it is viable to use
the common architecture with the pre-training weights to ease the training and ensure the detection results. However, a new and large category space may pose challenges for
HOI detection as the generic object detectors may perform poorly in the low-sample regime [12] and it is still an open problem to learn the effective detectors in large-vocabulary case. Different from the work of large-vocabulary object detection [12, 39, 45, 18, 37, 48], we would like to explore an effective HOI-specific solution to find the target objects by using the interaction clues.
Another challenge is the combinatorial explosion of the interactions when more object categories are involved.
Given the combination nature of interactions, it is intuitively appealing to decouple the interaction detection into separate action and object predictions and then merge their scores to produce the final interaction score. Previous methods often approach this using completely separate or parallel branches. We observe that such an approach would become sub-optimal in the large-vocabulary scenario as the action and object predictions often conflict with each other and result in invalid combinations. Although the invalid com-binations can be filtered out based on prior knowledge or external resources [50], we opine that invalid combinations can be effectively alleviated by coupling the interaction and object classification.
In this paper, we propose a new strategy to address the
HOI task and formulate it as a query problem. As the per-son is often the dominant class, conventional detectors can usually give a reliable result. We thus first detect humans in the image and use them as queries to search for corre-sponding interactions and target objects. We aim to develop a unified model powered by Transformers [41] to jointly de-tect the objects interacting with the given human query and predict their interactions. This alleviates the need of using generic object detectors, multi-stream interaction recogni-tion, and additional human-object instance matching pro-cess. The main idea is to find the region that may include the target objects by comparing the human query feature with the image feature at all sliding window positions. Then, we update the human query feature by progressively aggregat-ing the context information from regions with high attention scores. The updated feature will be used to predict both the action and object classes and regress the bounding box. To better improve the detection capability, we propose a new cascade detection pipeline and enable the use of multi-scale and high-resolution feature maps.
Our contributions are summarized below. (1) To the best of our knowledge, we are the first to study the HOI de-tection in the regime of large-vocabulary object categories. (2) To enable the study, we assemble an HOI dataset with 1000 object categories from SWiG [32]. Besides, we com-pose a subset from 100DOH dataset [36] and annotate them with âˆ¼300 object categories for hand-object interaction. (3)
We propose a new one-stage and end-to-end strategy by jointly detecting the target objects and interactions. This is achieved by using a repurposed Transformer unit and a new cascade detection framework over multi-scale feature maps. (4) Experimental results demonstrate that our method achieves a better result and faster inference speed than ex-isting one-stage HOI detectors. 2.