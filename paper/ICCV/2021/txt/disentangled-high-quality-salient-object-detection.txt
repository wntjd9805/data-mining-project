Abstract 1.

Introduction
Aiming at discovering and locating most distinctive ob-jects from visual scenes, salient object detection (SOD) plays an essential role in various computer vision systems.
Coming to the era of high resolution, SOD methods are facing new challenges. The major limitation of previous methods is that they try to identify the salient regions and estimate the accurate objects boundaries simultaneously with a single regression task at low-resolution. This prac-tice ignores the inherent difference between the two diffi-cult problems, resulting in poor detection quality. In this paper, we propose a novel deep learning framework for high-resolution SOD task, which disentangles the task into a low-resolution saliency classification network (LRSCN) and a high-resolution refinement network (HRRN). As a pixel-wise classification task, LRSCN is designed to cap-ture sufficient semantics at low-resolution to identify the definite salient, background and uncertain image regions.
HRRN is a regression task, which aims at accurately re-fining the saliency value of pixels in the uncertain region to preserve a clear object boundary at high-resolution with limited GPU memory. It is worth noting that by introducing uncertainty into the training process, our HRRN can well address the high-resolution refinement task without using any high-resolution training data. Extensive experiments on high-resolution saliency datasets as well as some widely used saliency benchmarks show that the proposed method achieves superior performance compared to the state-of-the-art methods.
*Corresponding author and equal contribution to first author. This work was supported by National Natural Science Foundation of China 61906036 and the Fundamental Research Funds for the Central Univer-sities (2242021k30056).
Salient object detection (SOD) is derived with the goal of accurately detecting and segmenting the most distinctive objects from visual scenes. As a preliminary step, it plays an essential role in various visual systems, such as video ob-ject segmentation [43], light field image segmentation [39], image-sentence matching [18], person re-identification [23] and instance segmentation [64].
Recently, the rapid development of the commodity imag-ing and display device, has resulted in higher requirements for the producing and editing of high-resolution (e.g., 720p, 1080p and 4K) images. Salient object detection as well as many state-of-the-art computer vision tasks are facing var-ious challenges when encountering high-resolution scenar-ios. A good high-resolution salient object detection method should not only accurately detect the whole salient object but also predict the precise boundaries of salient objects.
Despite the conventional Deep Neural Networks (DNNS) based SOD models have achieved remarkable performance at low-resolution (e.g., typical size 224 × 224, 384 × 384), they often fail to generate high quality detection results for high-resolution images. The major reason for this drawback is that the most previous methods try to identify the salient regions and estimate the accurate objects boundaries simul-taneously in one step, which are two difficult and inherently different problems for high-resolution salient object detec-tion. To address the first problem, a network is required to capture sufficient semantics by maintaining a larger re-ceptive field. However, since the memory usage increases dramatically along with the image resolution, it is imprac-tical for these models to directly learn sufficient semantics for high-resolution images. One plausible way is introduc-ing downsample operations, but the structure details are in-evitably lost during the downsampling, which however is precisely the key to solving the second problem.
Unfortunately, most of the existing low-resolution SOD
network. In the very recent work, Zeng et al. [52] proposed to train their SOD network by using high-resolution images with accurate annotation. However, such high-quality im-age annotation requires heavy labor costs. In our paper, we argue that it is unnecessary to use such accurately annotated high-resolution images in network training. By introducing uncertainty [19] in the training process, our HRRN can well address the high-resolution refinement task only using the low-resolution training datasets with poor annotation.
Our major contributions can be summarized as:
• We provide a new perspective that high-resolution salient object detection should be disentangled into two tasks, and demonstrate that the disentanglement of the two tasks is essential for improving the perfor-mance of DNN based SOD models.
• Motivated by the principle of disentanglement, we pro-pose a novel framework for high-resolution salient ob-ject detection, which uses LRSCN to capture sufficient semantics at low-resolution and HRRN for accurate boundary refinement at high-resolution.
• We make the earliest efforts to introduce the uncer-tainty into SOD network training, which empowers
HRRN to well address the high-resolution refinement task without any high-resolution training datasets.
• We perform extensive experiments to demonstrate the proposed method refreshes the SOTA performance on high-resolution saliency datasets as well as some widely used saliency benchmarks by a large margin. 2.