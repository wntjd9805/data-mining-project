Abstract
Deep Convolution Neural Networks have been adopted for pansharpening and achieved state-of-the-art perfor-mance. However, most of the existing works mainly fo-cus on single-scale feature fusion, which leads to fail-ure in fully considering relationships of information be-tween high-level semantics and low-level features, despite the network is deep enough. In this paper, we propose a dynamic cross feature fusion network (DCFNet) for pan-sharpening. Speciﬁcally, DCFNet contains multiple par-allel branches, including a high-resolution branch served as the backbone, and the low-resolution branches progres-sively supplemented into the backbone. Thus our DCFNet can represent the overall information well. In order to en-hance the relationships of inter-branches, dynamic cross feature transfers are embedded into multiple branches to obtain high-resolution representations. Then contextual-ized features will be learned to improve the fusion of in-formation. Experimental results indicate that DCFNet sig-niﬁcantly outperforms the prior arts in both quantitative in-dicators and visual qualities. 1.

Introduction
Pansharpening is a crucial technique in the ﬁeld of re-mote sensing image processing, which aims at fusing a low-resolution multispectral (LRMS) image and a high-resolution (HR) panchromatic (PAN) image to generate a
ﬁnal HR image with the same spectral resolution as the MS image. The outcome of the pansharpening can provide a better visual interpretation, on the other hand, it is con-ducive to further processing, e.g., land monitoring, mineral exploration, and change detection.
The major point for handling pansharpening task [33,
∗Corresponding author.
PAN
LRMS
FusionNet
DCFNet
Figure 1: The visual comparison on an original-resolution
WorldView-3 dataset. First row: the original PAN and up-sampled low-resolution MS (LRMS) images. Second row: the pansharpened image by FusionNet [4] and DCFNet. 11, 19] is able to recover more spatial details while re-taining more complete spectral information. The tradi-tional methods can be roughly divided into three cate-gories [18, 21, 14], i.e., component substitution (CS) meth-ods, multi-resolution analysis (MRA) methods, variational optimization (VO) approaches. Recently, with the impres-sive development driven by deep learning (DL), the ex-isting convolutional neural network (CNN) based meth-ods [4, 6, 27, 28, 29, 30, 32] for pansharpening have achieved encouraging performances. This is attributed to the strong nonlinear ﬁtting ability of the CNN, which can well depict the relationship between LRMS image, PAN im-age, and the desired high-resolution multispectral (HRMS) image.
By observing the existing CNN-based methods, it is con-cluded that the PAN and LRMS images are used as the input
of the network, and a number of different network architec-tures are designed to perform the fusion processing. Our in-tuitive reasoning is that whether the information in the data can be fully utilized and mined is closely related to the net-work structure. In recent years, many advanced networks have emerged for different computer vision tasks. A typ-ical example is ResNet [9], which designs the module of residual learning and has become the basic feature extrac-tion module in general computer vision problems. In [12], a feature pyramid network (FPN) is developed, which could efﬁciently extract various scale features. On its basis, its en-hanced architecture provides us with more possibilities for feature fusion and characterization [12, 8, 17].
Although the effectiveness of deep convolutional net-works has been proven in computer vision tasks, when it comes to the pansharpening, the defects of information dis-tortion caused by deepening the network are what exactly required to be mitigated. And the existing networks have not adequately considered the cross-scale gap between low-resolution and high-resolution images well to coordinate the relationship between the main feature and supplementary information.
In this paper, we present a novel architecture for pan-sharpening, namely a dynamic cross feature fusion network (DCFNet). The proposed DCFNet contains three parallel branches, one branch maintains the same resolution as the
PAN image and serves as the main branch, which is spa-tial reduction-free. One of the remaining two branches has the same spatial resolution as the MS image, and the other is twice that of the MS image. On the whole, the infor-mation between the three branches is dynamically fused.
Features extracted from low spatial resolution are gradu-ally injected into the main branch, maintaining high resolu-tion while supplementing the information provided by low-resolution branch species. Extensive experiments demon-strate that DCFNet can generate reliable results.
To sum up, the contributions of this paper are summa-rized as follows: 1. We propose a novel architecture named DCFNet, which is the ﬁrst network with cross-scale parallel branches designed for pansharpening. Beneﬁt from the information ﬁdelity capabilities of high-resolution branches, our model can perform the spatial reduction-free fusion. 2. We design a pyramid cross feature transition layer, which helps multi-resolution branches to capture inter-branches features. And dynamic branch fusion with few parameters is adopted to make the network more effective. As a result, DCFNet signiﬁcantly outper-forms the state-of-the-art methods on a wide range of datasets obtained by various satellite sensors. 3. The proposed DCFNet has a distinctive structure. It has two special variants, namely the famous U-Net and
SegNet, which indicates our network can also be ap-plied in more visual tasks. 2. Notations and