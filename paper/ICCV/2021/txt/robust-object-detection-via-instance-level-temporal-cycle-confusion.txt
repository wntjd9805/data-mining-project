Abstract
Building reliable object detectors that are robust to do-main shifts, such as various changes in context, viewpoint, and object appearances, is critical for real-world applica-tions. In this work, we study the effectiveness of auxiliary self-supervised tasks to improve the out-of-distribution gen-eralization of object detectors. Inspired by the principle of maximum entropy, we introduce a novel self-supervised task, instance-level temporal cycle confusion (CycConf), which operates on the region features of the object detectors. For each object, the task is to find the most different object pro-posals in the adjacent frame in a video and then cycle back to itself for self-supervision. CycConf encourages the object de-tector to explore invariant structures across instances under various motions, which leads to improved model robustness in unseen domains at test time. We observe consistent out-of-domain performance improvements when training object detectors in tandem with self-supervised tasks on various do-main adaptation benchmarks with static images (Cityscapes,
Foggy Cityscapes, Sim10K) and large-scale video datasets (BDD100K and Waymo open data)1. 1.

Introduction
Object detection has achieved remarkable performance on in-domain data [2, 32]. However, contemporary visual per-ception models still suffer significant performance degrada-tion under domain shifts, raising concerns for safety critical applications such as autonomous driving [5, 23].
Prior works [1, 3, 17, 21, 33, 51] have designed domain adaptive object detectors, which align the unlabeled target domain data and labeled source domain data in the feature space to tackle the distribution shift problem. These ap-proaches perform well when they have access to excessive unlabeled data in the target domain. More recently, an-other line of work improves model robustness to domain shift [22, 48], image corruption and distortion [13] through
*Equal contribution. The authors are listed in alphabetical order. 1The models are released at https://xinw.ai/cyc-conf
Figure 1: We introduce a self-supervised task, instance-level tem-poral cycle confusion (CycConf), which mixes up instance features to encourage learning invariant structures across instances. The object detector trained in tandem with the auxiliary self-supervised task is more robust to domain shifts. pre-training [14], self-supervision [15], and data augmen-tation [16]. These studies are largely conducted on image classification, and the effectiveness is unknown for structural prediction tasks like object detection.
In this work, we revisit the idea of auxiliary self-supervised tasks to improve out-of-domain generalization of object detectors. Through empirical studies, we find the widely used self-supervised tasks such as image rotation [10] and Jigsaw [26], used in tandem with the fully supervised object detector in the source domain, can consistently im-prove the object detector’s out-of-domain performance (e.g., evaluating on different datasets or different scenes) without using target data. Surprisingly, we also find that jointly train-ing the object detector and the rotation task outperforms the complicated feature alignment approaches by a large mar-gin on a range of unsupervised domain adaptation (UDA) benchmarks, where the test domain is known during training.
These findings indicate the usage of auxiliary self-supervised tasks can be a general solution to improve model robustness under various assumptions about the amount of unlabeled target data available. 1
While the findings are inspiring, we take a step further to ask, what would be a good self-supervised task for out of domain object detection? Here we introduce a new self-supervised task, instance-level cycle confusion (CycConf), which operates on the region features of the object detec-tors as shown in Figure 1. For a pair of frames in a video sequence, the CycConf task is to find the most different ob-jects through time in the frames. Inspired by the principle of maximum entropy [18, 19], CycConf mixes up the instance features to encourage the model to explore invariant struc-tures across instances which may be under various motion, viewpoint and lightning conditions. In contrast to object tracking, which finds identical objects through time, Cyc-Conf encourages cross-instance matching which increases confusion among instances and encourages the object de-tector to explore the latent structures of the instances that are invariant to changing environments. Therefore, the ob-ject detector trained in tandem with CycConf has improved robustness to domain shifts.
To evaluate the effectiveness of our new self-supervised task, we construct a benchmark of out-of-domain gen-eralization for object detection using the video datasets
BDD100K [48] and Waymo Open data [39], which are the largest contemporary driving video datasets in the open source community. The datasets contain various object scales and diverse scenes, which is a good testbed for new model designs. In this benchmark, we consider various out-of-domain scenarios (e.g., generalization across different time of day, camera views and datasets). The proposed Cyc-Conf task improves the baseline model by 2 to 5 points in av-erage precision (AP50), outperforming other self-supervised tasks when evaluating the object detector in unseen domains.
Our contributions can be summarized as follows.
• We show the adoption of auxiliary self-supervised tasks is a general solution to improve the robustness of object detectors to domain shifts under various assumptions.
• We introduce instance-level cycle confusion (CycConf), a novel self-supervised task on instance features, which improves the object detectors’ robustness.
• The proposed approach achieves state-of-art performances on a range of domain adaptation benchmarks. We addition-ally introduce an out-of-domain generalization benchmark for object detection using large-scale driving videos. 2.