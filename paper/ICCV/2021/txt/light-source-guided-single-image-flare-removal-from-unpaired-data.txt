Abstract
Causally-taken images often suffer from ﬂare artifacts, due to the unintended reﬂections and scattering of light in-side the camera. However, as ﬂares may appear in a vari-ety of shapes, positions, and colors, detecting and remov-ing them entirely from an image is very challenging. Exist-ing methods rely on predeﬁned intensity and geometry pri-ors of ﬂares, and may fail to distinguish the difference be-tween light sources and ﬂare artifacts. We observe that the conditions of the light source in the image play an impor-tant role in the resulting ﬂares. In this paper, we present a deep framework with light source aware guidance for single-image ﬂare removal (SIFR). In particular, we ﬁrst de-tect the light source regions and the ﬂare regions separately, and then remove the ﬂare artifacts based on the light source aware guidance. By learning the underlying relationships between the two types of regions, our approach can remove different kinds of ﬂares from the image.
In addition, in-stead of using paired training data which are difﬁcult to collect, we propose the ﬁrst unpaired ﬂare removal dataset and new cycle-consistency constraints to obtain more di-verse examples and avoid manual annotations. Extensive experiments demonstrate that our method outperforms the baselines qualitatively and quantitatively. We also show that our model can be applied to ﬂare effect manipulation (e.g., adding or changing image ﬂares). 1.

Introduction
Image ﬂares are common and often undesirable light ar-tifacts, caused by taking pictures of a scene with a very bright light source [1, 24]. Part of the light undergoes inter-reﬂection among the optical elements inside the camera, producing some unexpected light artifacts in the image [23].
These artifacts tend to appear more often with smartphone cameras, due to the poor anti-reﬂective coatings.
The presence of ﬂare artifacts can affect the visual qual-ity of images, and may inhibit understanding of underlying object/scene information and hamper the performances of existing vision tasks [31], e.g., semantic segmentation and depth estimation. However, automatically detecting and re-Figure 1. Single-image ﬂare removal (SIFR). Given an input im-age with ﬂare artifacts (pointed to by red arrows), existing meth-ods, (b) and (c), can only handle limited ﬂare types (e.g., ﬂare spot) without removing the entire ﬂare or wrongly consider other regions as ﬂares (e.g., the cloud in the ﬁrst row). In contrast, our light source aware model (d) can remove the ﬂare more accurately. moving them can be very challenging. Different combina-tions of lens properties and environment settings, includ-ing light source position, characteristics of the lens, and the camera angle to the light source, may lead to different types of ﬂares with diverse shapes, colors, and positions.
Professional photographers may apply preventative mea-sures during the image capturing process, such as optimized barrel design, lens hood, or anti-reﬂective coating, to help eliminate the ﬂares. Unfortunately, these hardware solu-tions can hardly eliminate the entire ﬂare artifacts [20, 22].
This is probably due to the diverse causes of image ﬂares.
They also cannot be applied to existing images already with
ﬂare artifacts. There have been a few attempts to remove these undesirable ﬂares from images automatically by uti-lizing predeﬁned intensity and geometry priors of ﬂare arti-facts [30, 4]. However, these methods can only handle lim-ited ﬂare types (e.g., ﬂare spot), as shown in Fig. 1(b). Re-cently, with the popularity of deep neural networks, a deep model [31] is proposed to learn to remove different types of
ﬂare artifacts from paired synthetic training data. Although it is shown to outperform existing traditional methods, it does not generalize well to diverse real-world images, as shown in Fig. 1(c).
From our study, we have made two observations. First, we observe that the light source plays an important role in the visual appearances of the generating ﬂares, e.g., a series of streaks radiating outward from the light source to form a star-shaped effect, glare as a bright region around the light source that fades gradually, and a series of circles or rings in the image. These imply that the shape, brightness, and position of the light source encode useful cues about the ap-pearances of the ﬂares. Through learning such light source aware guidance, we can detect and remove ﬂares more reli-ably. Second, it is not easy to collect a large-scale dataset of image ﬂare pairs with diversity. Typically, the user needs to manually adjust the camera parameters in order to obtain a
ﬂare image, and then use preventative measures to obtain a
ﬂare-free image. Unfortunately, this setting often produces training pairs with inconsistent colors and exposures, due to the change of the environmental lighting.
Inspired by the above observations, we propose a light source guided learning framework with unpaired data for single-image ﬂare removal (SIFR). First, we detect the light source region and the ﬂare region separately with two branches. Given a single image as input, we propose a Light
Source Detection (LSD) module to predict a light source mask, and a Flare Detection (FD) module to predict a ﬂare mask. Second, we estimate a ﬂare-free image based on the
ﬂare mask and the light source aware guidance using the
Flare Removal (FR) module. Finally, we feed the predicted light source mask and the ﬂare-free image through a Flare
Generation (FG) module to learn the inverse mapping to reconstruct the input ﬂare image. By imposing the cycle-consistency constraints [34] and learning the underlying re-lationships between the ﬂare region and the light source re-gion, we make the ﬁrst attempt to address the ﬂare removal problem through a uniﬁed framework that integrates both
ﬂare removal and ﬂare generation tasks. Our approach al-lows training of the model with unpaired data, which are much cheaper to collect.
We conduct extensive experiments to evaluate the effec-tiveness of the proposed approach. The experimental results show that our approach is effective in removing the ﬂare ar-tifacts, compared with the baselines. We also show that our model can be applied to image editing, allowing the user to manipulate the ﬂare effect in the image by changing the position or size of the light source.
To sum up, we make the ﬁrst effort to utilize the light source information to guide the SIFR task, and propose a deep framework to learn from unpaired data with new cycle-consistency constraints. We also construct the ﬁrst unpaired ﬂare and ﬂare-free image dataset with diverse sce-narios. Extensive evaluations demonstrate the effectiveness of our method, both quantitatively and qualitatively, and the beneﬁts of it on the ﬂare effect manipulation task. 2.