Abstract
The prevalence of relation networks in computer vision is in stark contrast to underexplored point-based methods. In this paper, we explore the possibilities of local relation op-erators and survey their feasibility. We propose a scalable and efﬁcient module, called group relation aggregator. The module computes a feature of a group based on the aggre-gation of the features of the inner-group points weighted by geometric relations and semantic relations. We adopt this module to design our RPNet. We further verify the expand-ability of RPNet, in terms of both depth and width, on the tasks of classiﬁcation and segmentation. Surprisingly, em-pirical results show that wider RPNet ﬁts for classiﬁcation, while deeper RPNet works better on segmentation. RPNet achieves state-of-the-art for classiﬁcation and segmentation on challenging benchmarks. We also compare our local aggregator with PointNet++, with around 30% parameters and 50% computation saving. Finally, we conduct experi-ments to reveal the robustness of RPNet with regard to rigid transformation and noises. 1.

Introduction
Point cloud processing has attracted considerable atten-tion for its advantages in various applications, including au-tonomous driving, augmented reality, and robotics. Though easily accessible, unlike other visual elements (i.e., images), point clouds can be difﬁcult to learn due to irregularity.
To duplicate the success of convolutional networks on regular grids [24, 43], some prior works change point clouds into multi-view images [12, 10] or regular volumes [53, 12] before convolution. However, image-based projection and voxelization reduce the resolution of point clouds and re-sult in the damage of internal geometric information. These explicit transformations also lead to complex preprocessing and signiﬁcant computations.
PointNet [38] diverts the attention to the methods of pro-cessing raw point clouds. To handle irregular points, it adopts point-wise multi-layer perceptrons (MLP) to learn on points independently and utilize a symmetric function to obtain the global information. For the ignorance of local structures, PointNet++ [40] further introduces set abstrac-tion (SA) (shown in Fig. 1 left) as the local aggregator to build the hierarchical networks. However, this aggregator keeps learning on points independently, losing the sight of shape awareness.
When a local aggregator independently learns on points, the shape ambiguity problem has been exposed: since no points inside the set react with others, the aggregator will be sensitive to the coordinates S ∈ RN ×3 and be confused about the outline and the geometric information of the set.
Here N is the number of points inside the set. The shape ambiguity problem causes the damage to the robustness and generalization of an aggregator.
In general, an excellent aggregator is underdeveloped for two reasons: it should discriminatively describe the under-lying shape of point sets, and it should be robust to rigid transformation (i.e., translation, rotation) as well as noises.
For a preliminary exploration, RS-CNN [33] computes a point feature from the aggregation of features weighted by predeﬁned geometric relations (low-level relation) between the point Si and its neighbors N (Si) (shown in Fig. 1 mid-dle). Based on the low-level relations instead of coordinates only, RS-CNN is insensitive to coordinates and robust to rigid transformation. However, RS-CNN is insufﬁcient to learn semantic relations (high-level relations) for the lack of interaction between features.
In this case, self-attention [47] (shown in Fig. 1 right) may be a good instance as the supplement for high-level relations. Self-attention achieves great success on natural language processing. Recent work [64, 19] has shown that self-attention can be a viable alternative for convolution on images. However, self-attention can be depressing for sig-niﬁcant computations as well as a large number of param-eters. The goal of this work is to extend grid-based self-attention to irregular points with a high-efﬁciency strategy.
To this end, we propose group relation aggregator (GRA) to learn from both low-level and high-level relations.
Compared with self-attention and SA, our designed bottle-Figure 1. Comparison of some prior works. We input each module with one centroid (query) and its neighbors (keys) of features or coordinates. PointNet++ [40] (left) learns on points independently and lacks the interaction between points. RS-CNN [33] (middle) focuses on low-level relation learning, while self-attention (right) in Transformer [47] learns from high-level relations between features.
Here the input group in self-attention is in the global scope. neck version of GRA is obviously efﬁcient in terms of com-putation and the number of parameters. With bottleneck
GRA, we construct the efﬁcient point-based networks RP-Net.
Speciﬁcally, we construct each point set by taking a sam-pled point Si as the centroid and its neighbors N (Si), cor-responding to features Fi and N (Fi) respectively. To ex-ploit a point set, we force GRA to learn attention of the set from both predeﬁned geometric priors (i.e., Euclidean distance between Si and N (Si)) and feature-level inter-action (i.e., mapping through a linear layer followed by matrix multiplication and scaled dot-product on Si and
N (Fi)). By applying the attention to the transformed features N (Fi) (i.e. mapping through a linear layer), the weighted features can reﬂect the geometric shape as well as semantic information of a point set. This proposed module beneﬁts from the geometric priors in terms of shape aware-ness and robustness to rigid transformation, while the fea-ture interaction enables the adaptation to content and the robustness to noises.
Considering the efﬁciency of GRA, we introduce the bot-tleneck concept to this module. The output of the ﬁrst linear layer has the identical channels to the input. We cut down its output channels with a speciﬁc factor. Though this be-havior harms the model quality (discussed in [47]), we add a mapping after the relation operation. Cross-channel atten-tion also helps the module to explore channel-wise. All the changes turn our module into a high-efﬁciency version.
With our proposed module, we construct RPNet with re-spect to width (RPNet-W) and depth (RPNet-D). We then evaluate these two types of models on the datasets of clas-siﬁcation (i.e., ModelNet40 [53]) and segmentation (i.e.,
ScanNet v2 [6], S3DIS [1]). The results show that our method outperforms point-based methods by a large mar-gin, and even achieves comparable performance with all convolution-based methods in a state of high-efﬁciency. In-terestingly, our model may obtain extra accuracy on classi-ﬁcation by increasing the width, while deep model works better than wide model on segmentation in terms of efﬁ-ciency and accuracy.
Our key contributions are manifold:
• A novel scalable local aggregator for point clouds is proposed. It encodes the geometric and semantic rela-tions between points;
• An expandable and high-efﬁciency hierarchy RPNet is proposed. Equipped with the bottleneck version of our aggregator, extensive RPNet keeps efﬁcient;
• Experiments on the challenging benchmarks of clas-indicate that RPNet siﬁcation and segmentation, achieves state of the arts. 2.