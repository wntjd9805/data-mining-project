Abstract
One challenge of object recognition is to generalize to new domains, to more classes and/or to new modalities.
This necessitates methods to combine and reuse existing datasets that may belong to different domains, have par-tial annotations, and/or have different data modalities. This paper formulates this as a multi-source domain adapta-tion and label unification problem, and proposes a novel method for it. Our method consists of a partially-supervised adaptation stage and a fully-supervised adaptation stage.
In the former, partial knowledge is transferred from multi-ple source domains to the target domain and fused therein.
Negative transfer between unmatching label spaces is miti-gated via three new modules: domain attention, uncertainty maximization and attention-guided adversarial alignment.
In the latter, knowledge is transferred in the unified label space after a label completion process with pseudo-labels.
Extensive experiments on three different tasks - image clas-sification, 2D semantic image segmentation, and joint 2D-3D semantic segmentation - show that our method outper-forms all competing methods significantly. 1.

Introduction
The development of object recognition is carried by two pillars: large-scale data annotation and deep neural net-works. With new applications coming out every day, re-searchers need to constantly develop new methods and cre-ate new datasets. While we are able to develop novel neu-ral networks for new tasks, the creation of new datasets can hardly keep up due to its huge cost.
In the liter-ature, a diverse set of learning paradigms, such as self-learning [13], semi-supervised learning [17] and transfer learning [6], have been developed to come to the rescue. We enrich this repository by developing a method to combine multiple existing datasets that have been annotated in differ-ent domains, for smaller-scale tasks (fewer classes), and/or with fewer data modalities. The importance of the method
Figure 1: mDALU learns a complete-class and complete-modality object recognition model for a new, unlabeled tar-get domain, by using multiple datasets with partial-class an-notation and partial data modality as source domains. can be justified by the fact that as time goes, research goals will become more and more ambitious, so object recogni-tion models for more classes, new domains, and/or more data modalities are necessary.
To address this, we propose a multi-source domain adap-tation and label unification (mDALU) problem. In this set-ting, there are multiple source domains and an unlabeled target domain. In each source domain, only samples (im-ages, pixels, or LiDAR points) belonging to a subset of classes are labeled; the rest are unlabeled. The subsets of classes having labels can be different over different source domains, and can have inconsistent taxonomies, e.g., truck is labeled as “truck” in one source domain but labeled as
“vehicle” together with other types of vehicles in another.
Further, the data modalities in different source domains can also be different, e.g., one contains images and the other contains LiDAR point clouds. The goal is to obtain an ob-ject recognition model for all classes in the target domain.
Fig. 1 shows an exemplar setting of mDALU. A compari-son to other domain adaptation settings, in Table 1, shows that mDALU is very flexible.
This goal is challenging. Firstly, there is the notori-ous issue of negative transfer. While negative transfer is
Domain Adaptation Setting
Unsupervised Domain Adaptation [10]
Partial Domain Adaptation [3]
Multi-Source Domain Adaptation [26, 43]
Category-Shift Multi-Source Domain Adaptation [39]
Multi-Modal Domain Adaptation [18]
Multi-Source Open-Set Domain Adaptation [27, 25]
Multi-Source Domain Adaptation and Label Unification (mDALU)
Can Handle Multiple
Source Domains?
No
No
Yes
Yes
Yes
Yes
Yes
Can Handle Multiple
Data Modalities?
No
No
No
No
Yes
No
Yes
Can Handle Different Label
Spaces of Source Domains?
−
−
No
Yes
No
No
Yes
Change of Label Space Size from Source to Target Domain
Same Size
Reduced
Same Size
Increased
Same Size
Same Size + 1∗
Increased
Can Handle Partial
Annotations?
No
No
No
No
No
Yes
Yes
Can Handle Inconsistent
Taxonomy?
−
−
No
No
No
No
Yes
Table 1: Comparison between our mDALU and other domain adaptation settings (see Sec. 2 for details). It is clear that mDALU offers a very flexible and general setting. ∗ “1” means an additional “unknown” class in the target domain. an issue also for standard transfer and multi-task learning, it is especially severe in our mDALU task due to the in-fluence of unlabeled classes. To address this, we propose three novel modules, termed domain attention, uncertainty maximization and attention-guided adversarial alignment, to avoid making confident predictions for unlabeled sam-ples in the source domains, and to enable robust distribu-tion alignment between the source domains and the target domain. The method with the aforementioned modules and attention-guided prediction fusion is able to generate good results in the unified label space and on the target domain.
In order to further improve the results, we need to fuse the supervision of all partial datasets to transfer the supervi-sion in the unified label space. To this aim, we propose a pseudo-label based supervision fusion module. In particu-lar, we generate pseudo-labels for the unlabeled samples in the source domains and all samples in the target domain.
Standard supervised learning is then performed in the uni-fied label space for the final model.
To showcase the effectiveness of our method, we evalu-ate it on three different tasks: image classification, 2D se-mantic image segmentation, and joint 2D-3D semantic seg-mentation. Synthetic and real data, and images and LiDAR point clouds are involved. Also, non-overlapping, partially-overlapping and fully-overlapping label spaces, and consis-tent and inconsistent taxonomies across source domains are covered. Experiments show that our method outperforms all competing methods significantly. 2.