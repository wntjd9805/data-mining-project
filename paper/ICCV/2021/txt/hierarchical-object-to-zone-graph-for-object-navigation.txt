Abstract
The goal of object navigation is to reach the expected objects according to visual information in the unseen envi-ronments. Previous works usually implement deep models to train an agent to predict actions in real-time. However, in the unseen environment, when the target object is not in egocentric view, the agent may not be able to make wise decisions due to the lack of guidance. In this paper, we pro-pose a hierarchical object-to-zone (HOZ) graph to guide the agent in a coarse-to-fine manner, and an online-learning mechanism is also proposed to update HOZ according to the real-time observation in new environments. In particu-lar, the HOZ graph is composed of scene nodes, zone nodes and object nodes. With the pre-learned HOZ graph, the real-time observation and the target goal, the agent can constantly plan an optimal path from zone to zone. In the estimated path, the next potential zone is regarded as sub-goal, which is also fed into the deep reinforcement learning model for action prediction. Our methods are evaluated on the AI2-Thor simulator. In addition to widely used evalu-ation metrics SR and SPL, we also propose a new evalua-tion metric of SAE that focuses on the effective action rate.
Experimental results demonstrate the effectiveness and ef-ficiency of our proposed method. The code is available at https://github.com/sx-zhang/HOZ.git. 1.

Introduction
Visual navigation task requires the agent to reach a speci-fied goal. Conventional methods usually require spatial lay-out information, such as maps of the environments, which can be easily obtained in seen environments while unavail-able in unseen environments. Therefore, how to efficiently navigate to the target in unseen environments is typically challenging.
*Corresponding author.
Figure 1. Overview of object navigation with HOZ graph. At the beginning, agent locates at the Current Zone (zone6, blue) and the goal FloorLamp belongs to Target Zone (zone4, red). The HOZ graph plans a real-time optimal path (zone6 − zone1 − zone2 − zone4). Then agent’s next sub-goal is zone1 (green). In the same way, the agent keeps updating sub-goal until it arrives at the target.
Note that each color implies specific location and direction where agent can observe similar views.
With the visual input of egocentric observation, previous works [29, 27, 28] learn a deep reinforcement learning pol-icy by maximizing the reward. The key challenge in those works is the generalization to unseen environments [38], especially when the target is not in the sight. Therefore, more recent works [40, 9] attempt to embed prior knowl-edge, such as object graph and relation graph, to improve the navigation model’s generalization ability. In particular,
Yang et al. [40] construct an object-to-object graph, which provides correlated objects as auxiliary information to lo-cate the target object. Their object graph is too general to fit into specific environments. Additionally, Du et al. [9] pro-pose to learn object relation graph, which fits the testing en-vironments better than the general object graph. The above approaches focus on constructing object-oriented graph to provide some clues to the navigation when the target is not
in the view. However, since object relations and spatial lay-out are usually inconsistent in different environments, the generalization ability of the above methods are still limited.
Motivated by enhancing the generalization ability of the navigation model, we carry out this study from two aspects: 1) learning an adaptive spatial knowledge representation that is applicable to various environments; 2) adapting the learned knowledge to guide navigation in the unseen envi-ronments. Besides, regions in larger area are considered in our knowledge, which are denoted as zones. Compared with objects, larger zones are more likely to be observed by agent. Thus our core idea for navigation guidance is zone.
In this paper we propose the hierarchical object-to-zone (HOZ) graph to capture the prior knowledge of scene layout for object navigation (see Figure 1). During training, we construct a general HOZ graph from all scenes, as rooms in the same scene category have same spatial structures.
Each scene node corresponds to a scene-wise HOZ graph, whose zone nodes are obtained by matching and merging the room-wise HOZ graphs. For each room-wise HOZ graph, each zone node represents a group of relevant ob-jects and each zone edge models the adjacent probability of two zones. Then we train a zone-to-action LSTM pol-icy via deep reinforcement learning in the photo-realistic simulator AI2-Thor [19]. For each episode, the pre-learned
HOZ graph helps to plan an optimal path from current zone to target zone, thus deducing the next potential zone on the path as a sub-goal. The sub-goal is embedded with graph convolutional network (GCN) to predict actions. Consider-ing that different environments have diverse zone layouts, we also propose an online-learning mechanism to update the general learned HOZ graph according to current un-seen environment. In this way, the initial HOZ graph will evolve towards current environment’s specific layout and help agent to navigate successfully. Note that the update only holds for an episode and each episode starts from the initial HOZ graph. In addition to widely used evaluation metrics Success Rate (SR) and Success weighted by Path
Length (SPL), we also propose a new evaluation metric of
Success weighted by Action Efficiency (SAE) that consid-ers the efficiency of the navigation action into SR. Our ex-periments show that the HOZ graph outperforms the base-line by a large margin. In summary, our contributions are as follows:
• We propose to learn the hierarchical object-to-zone (HOZ) graph that captures prior knowledge to guide object navigation agent with easier sub-goals.
• We propose a new evaluation metric named Success weighted by Action Efficiency (SAE).
• By integrating HOZ graph into a zone-to-action pol-icy, the navigation performance can be significantly improved in SR, SPL and SAE metrics. 2.