Abstract
Image inpainting aims to complete the missing or cor-rupted regions of images with realistic contents. The preva-lent approaches adopt a hybrid objective of reconstruction and perceptual quality by using generative adversarial net-works. However, the reconstruction loss and adversarial loss focus on synthesizing contents of different frequencies and simply applying them together often leads to inter-frequency conflicts and compromised inpainting. This pa-per presents WaveFill, a wavelet-based inpainting network that decomposes images into multiple frequency bands and fills the missing regions in each frequency band separately and explicitly. WaveFill decomposes images by using dis-crete wavelet transform (DWT) that preserves spatial in-It applies L1 reconstruction loss to formation naturally. the decomposed low-frequency bands and adversarial loss to high-frequency bands, hence effectively mitigate inter-frequency conflicts while completing images in spatial do-main. To address the inpainting inconsistency in different frequency bands and fuse features with distinct statistics, we design a novel normalization scheme that aligns and fuses the multi-frequency features effectively. Extensive experi-ments over multiple datasets show that WaveFill achieves superior image inpainting qualitatively and quantitatively.
Figure 1.
Image inpainting often faces a dilemma of reconstruc-tion and perceptual quality: L1/L2 loss focuses on the reconstruc-tion of global low-frequency structures while adversarial loss fo-cuses on generating high-frequency texture details. State-of-the-art approaches implicitly tackle this issue by weighted summing of the two objectives (e.g. in GMCNN [35]) or employing a Coarse-to-Fine strategy (e.g. in GC [40]), but tend to produce inconsistent distributions with missing details or artifacts. The proposed Wave-Fill disentangles images into multiple frequency bands and applies relevant losses to different bands separately, which mitigates inter-frequency conflicts and produces more realistic structures and de-tails. The distances between the ground-truth histogram and pre-diction histograms in both low-frequency (LF) and high-frequency (HF) are evaluated by Earth Moverâ€™s Distance (EMD) [30]. 1.

Introduction
As an ill-posed problem, image inpainting is not to re-cover the original images for corrupted regions but to syn-thesize alternative contents that are visually plausible and semantically reasonable.
It has been widely investigated in various image editing tasks such as object removal, old photo restoration, movie restoration, and so on. Realis-tic and high-fidelity image inpainting remains a challeng-ing task especially when the corrupted regions are large and
*Corresponding author have complex texture and structural patterns.
State-of-the-art image inpainting methods leverage gen-erative adversarial networks (GANs) [10] heavily for gen-erating realistic high-frequency details [28]. But they often face a dilemma of perceptual quality and reconstruction that share a perception-distortion trade-off [4]. Specifically, the adversarial loss in GANs tends to recover high-frequency texture details and improve the perceptual quality [31, 8], while the L1/L2 loss in reconstruction focuses more on recovering low-frequency global structures [28]. Concur-rently optimizing the two objectives in spatial domain tends to introduce inter-frequency conflicts as illustrated in Fig. 1.
GMCNN [35] balances the two objectives by weighted sum, but it still works in spatial domain with mixed frequency and struggles to generate more realistic high-frequency de-tails due to the inter-frequency conflicts. Gate Convolution (GC) [40] mitigates this issue by adopting a Coarse-to-Fine strategy [39, 32, 29, 20, 40] that first predicts global low-frequency structures and then refines high-frequency texture details. The coarse estimation network is generally trained with L1 loss, but the inter-frequency conflicts still exist in the refinement network. Moreover, the two-stage network often suffers from inconsistency in generated structure and texture details due to the lack of effective alignment and fu-sion of multi-stage features [21].
To address the aforementioned issues, we design Wave-Fill, an innovative image inpainting framework that em-ploys wavelet transform to complete corrupted image re-gions at multiple frequency bands separately. Specifically, we convert images into wavelet domain with 2D discrete wavelet transform (DWT) [6] where the images can be dis-entangled into multiple frequency bands accurately without losing spatial information. The disentanglement allows us to apply adversarial (or L1) loss to the high-frequency (or low-frequency) branches explicitly and separately, which greatly mitigates the content conflicts as introduced by con-currently optimizing the two different objectives over en-In addition, we design tangled features in spatial space. a novel frequency region attentive normalization (FRAN) scheme that aggregates attention from low frequency to high frequency to align and fuse the multi-frequency fea-tures. FRAN ensures the consistency across multiple fre-quency bands and helps suppress artifacts and preserve tex-ture details effectively. The separately completed features in different frequency bands are then transformed back to the spatial domain via inverse discrete wavelet transform (IDWT) to produce the final completion.
The contributions of this work can be summarized in three aspects. First, we propose WaveFill, an innova-tive image inpainting technique that synthesizes corrupted image regions at different frequency bands explicitly and separately, which effectively mitigates the inter-frequency conflicts while minimizing adversarial and reconstruction losses. Second, we design a novel normalization scheme that enables attentive alignment and fusion of the multi-frequency features with effective artifact suppression and detail preservation. Third, extensive experiments over mul-tiple datasets show that the proposed WaveFill achieves su-perior inpainting as compared with the state-of-the-art. 2.