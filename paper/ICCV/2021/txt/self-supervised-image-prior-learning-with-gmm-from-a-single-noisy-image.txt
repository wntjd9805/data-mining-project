Abstract
The lack of clean images undermines the practicability of supervised image prior learning methods, of which the training schemes require a large number of clean images.
To free image prior learning from the image collection bur-den, a novel Self-Supervised learning method for Gaussian
Mixture Model (SS-GMM) is proposed in this paper. It can simultaneously achieve the noise level estimation and the image prior learning directly from only a single noisy im-age. This work is derived from our study on eigenvalues of the GMM’s covariance matrix. Through statistical experi-ments and theoretical analysis, we conclude that (1) covari-ance eigenvalues for clean images hold the sparsity; and that (2) those for noisy images contain sufficient informa-tion for noise estimation. The first conclusion inspires us to impose a sparsity constraint on covariance eigenvalues dur-ing the learning process to suppress the influence of noise.
The second conclusion leads to a self-contained noise esti-mation module of high accuracy in our proposed method.
This module serves to estimate the noise level and auto-matically determine the specific level of the sparsity con-straint. Our final derived method requires only minor mod-ifications to the standard expectation-maximization algo-rithm. This makes it easy to implement. Very interestingly, the GMM learned via our proposed self-supervised learn-ing method can even achieve better image denoising per-formance than its supervised counterpart, i.e., the EPLL.
Also, it is on par with the state-of-the-art self-supervised deep learning method, i.e., the Self2Self. Code is available at https://github.com/HUST-Tan/SS-GMM. 1.

Introduction
Image modeling and prior learning play key roles in the design of an image denoising algorithm. Traditional im-age modeling methods are generally hand-designed. These
*Corresponding author. This work was supported in part by the Na-tional Natural Science Foundation of China (NNSFC), under Grant Nos. 61672253 and 62071197. Part of this work was done when Haosen was interning in SmartMore Co., Ltd.
Figure 1. Average PSNR of image denoising results for three noise levels σ=15, 25, 50 on Set12 and BSD68. These results are calcu-lated based on Table 1. Comparison methods include a) the non-learning method: BM3D [8]; b) GMM-related methods: EPLL
[33], PGPD [30] and NL-Bayes [16]; c) Self-supervised deep learning methods: N2V [15], DIP [28] and S2S [22]; d) Our pro-posed self-supervised GMM (SS-GMM). methods can be classified into two main categories [13], i.e., the analysis-based methods and the synthesis-based ones.
The analysis-based methods directly model the image it-self [26, 4, 5, 17, 18], while synthesis-based methods model coefficients of an image in a transform-domain [10, 12, 23, 11]. The main drawback of traditional hand-designed methods is that images in the real world are too complex to be effectively modeled with simplified assumptions. To tackle this problem, the data-driven learning method is uti-lized as an alternative. Some representatives in this branch include [25, 33, 27, 7, 32]. These methods have indeed achieved great success in image denoising tasks. However, their state-of-the-art performances are based on acquiring a large number of clean images, which are generally unavail-able in practice. This undermines the practicability of these methods.
To reduce or even eliminate the image collection bur-den, the self-supervised learning method, which only re-quires noisy images themselves during the training process, has attracted more and more attention. One recent work in this field is the deep image prior (DIP) [28]. It performs the self-supervised learning for the generator network with an early-stopping strategy. Since the early-stopping strat-egy acts as an implicit constraint on network parameters
[14], an idea coming to our mind is that imposing reason-In summary, our main contributions are:
• Conducting a detailed study on the influence of Gaus-sian noise on GMM’s parameters, especially on the co-variance eigenvalues, through statistical experiments and theoretical analysis.
• Proposing a self-contained noise level estimation mod-ule for our proposed self-supervised algorithm to achieve noise level estimation and to help determine the level of the sparsity constraint.
• Developing an efficient self-supervised learning algo-rithm, which is easy to implement, for the GMM to achieve the image prior learning from only a single noisy image. 2.