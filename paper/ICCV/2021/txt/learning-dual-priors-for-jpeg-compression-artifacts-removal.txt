Abstract
Deep learning (DL)-based methods have achieved great success in solving the ill-posed JPEG compression artifacts removal problem. However, as most DL architectures are designed to directly learn pixel-level mapping relationship-s, they largely ignore semantic-level information and lack sufﬁcient interpretability. To address the above issues, in this work, we propose an interpretable deep network to learn both pixel-level regressive prior and semantic-level discriminative prior. Speciﬁcally, we design a variation-al model to formulate the image de-blocking problem and propose two prior terms for the image content and gradi-ent, respectively. The content-relevant prior is formulated as a DL-based image-to-image regressor to perform as a de-blocker from the pixel-level. The gradient-relevant pri-or serves as a DL-based classiﬁer to distinguish whether the image is compressed from the semantic-level. To effec-tively solve the variational model, we design an alternating minimization algorithm and unfold it into a deep network architecture. In this way, not only the interpretability of the deep network is increased, but also the dual priors can be well estimated from training samples. By integrating the t-wo priors into a single framework, the image de-blocking problem can be well-constrained, leading to a better per-formance. Experiments on benchmarks and real-world use cases demonstrate the superiority of our method to the ex-isting state-of-the-art approaches. 1.

Introduction
With the rapid development of consumer devices (e.g., digital cameras and smartphones) and wireless network, the number of images and videos has achieved explosive
∗Corresponding author: Zheng-Jun Zha. This work was supported in part by the National Key Research and Development Program of China under Grant 2020AAA0105702; in part by the National Natural Science
Foundation of China (NSFC) under Grants U19B2038 and 61901433; in part by the University Synergy Innovation Program of Anhui Province un-der Grant GXXT-2019-025; and in part by the USTC Research Funds of the Double First-Class Initiative under Grant YD2100002003. growth, which has brought more pressure and challenges to storage and transmission systems. To save the storage capacity and transmission bandwidth, captured images and videos are usually compressed to reduce information re-dundancy. Lossy compression algorithms, e.g., Joint Pho-tographic Experts Group (JPEG) [43] and High Efﬁcien-cy Video Coding (HEVC) [41], have been widely explored to achieve this goal. However, due to the inevitable sig-nal loss during compression, these compression algorithms usually generate visually unpleasing compression artifact-s. These artifacts not only decrease the visual quality, but also degrade the performance of downstream computer vi-sion systems, especially at high compression ratios. There-fore, removing compression artifacts is an important post-processing task and has attracted more attention in recent years [20,30]. We refer the reader to review articles [28,30] for more details. In this paper, we focus on alleviating still image degradation caused by JPEG compression, which is one of the most prevalent compression standards.
JPEG compression ﬁrst applies the discrete cosine trans-formation (DCT) on 8×8 pixel blocks. Then, these DCT co-efﬁcients are coarsely quantized to remove high-frequency details to save space. Due to the independent processing on each pixel block and the removal of high-frequency details, compressed images usually suffer from blocking and blur-ring artifacts. In addition, using a large quantization step, banding artifacts will appear in smooth areas. Some recent studies have proposed methods to remove undesirable JPEG compression artifacts. According to the design mechanism, these methods can be roughly classiﬁed into two categories: model-based methods and deep learning (DL)-based meth-ods. Early model-based works perform ﬁltering to remove compression artifacts. For instance, Foi et al. [12] propose a shape-adaptive DCT ﬁltering method for compression ar-tifacts reduction. On the other hand, since multiple latent clear versions can be estimated from a single compressed image, this task is essentially an ill-posed inverse problem, which requires prior knowledge to constrain it. Along this research direction, many researchers formulate this prob-lem as a minimization of a variational model with favor-able prior terms. Based on the maximum a posterior (MAP) framework, many prior models, e.g., quantization step [55], sparse representation [3] and low rank [59], have been de-veloped. Although these model-driven methods have shown good performance, the representation abilities of handcraft-ed priors are limited, which leads to unstable results when processing compressed images with complex structures.
In the past few years, DL-based methods have achieved signiﬁcant progress of JEPG artifacts removal [8, 57, 63].
Due to the powerful nonlinear capacity [16, 21, 22, 29, 53] and huge amounts of training data, these methods can learn the inverse mapping of compression degradations, and thus produce better results than model-driven methods. Howev-er, most of current DL-based methods adopt feed-forward networks to directly predict clear images, making them like black boxes and lack interpretability.
In addition, since these DL-based methods only learn pixel-level mappings, semantic-level information is not fully explored and exploit-ed, which further limits their performance improvement.
Different from these methods, we propose an inter-pretable deep network by combining advantages of both the model-based methods and data-driven DL models. Specif-ically, we introduce an effective algorithm with DL to learn a pixel-level regressive prior for image content and a semantic-level discriminative prior for image gradient, re-spectively. First, we model the content-relevant prior as an image-to-image regressor to perform de-blocking, and de-sign the gradient-relevant prior as binary classiﬁer to distin-guish whether the image is compressed. Then, the image de-blocking problem is formulated as a minimization of a variational model with the two proposed priors. To effec-tively solve the model, we design an alternating minimiza-tion scheme based on the gradient descent technique and half-quadratic splitting method. Finally, the iterative algo-rithm is unfolded into a deep network architecture, in which the two priors can be automatically learned through an ef-fective network training strategy. We show that our method is able to predict visually pleasing de-blocked images while removing undesirable JPEG artifacts sufﬁciently. The con-tributions of this work are as follows:
• We propose two effective priors to describe the image content and image gradient from the pixel-level and semantic-level, respectively. By using the two priors as the regularizer, we introduce a new variational model for the JPEG compression artifacts removal.
• We propose an alternating minimization algorithm, which is based on the gradient descent technique and half-quadratic splitting method, to solve the variational model. By unfolding the algorithm, we design a new deep network architecture for the image de-blocking problem. In this way, the two proposed priors can be automatically estimated from training samples. In ad-dition, since the feed-forward process mimics the pro-cessing ﬂow of the alternating minimization algorithm, the interpretability of the deep model is increased.
• We collect a new dataset containing compressed/clear image pairs based on the popular online social soft-ware WeChat. This dataset aims to complement the ex-isting Twitter dataset [8] to serve the relevant research communities. Extensive experiments show that our proposed network performs favorably against state-of-the-arts on both benchmarks and real-world use cases. 2.