Abstract
Domain adaptation for semantic segmentation aims to improve the model performance in the presence of a distri-bution shift between source and target domain. Leverag-ing the supervision from auxiliary tasks (such as depth esti-mation) has the potential to heal this shift because many visual tasks are closely related to each other. However, such a supervision is not always available. In this work, we leverage the guidance from self-supervised depth esti-mation, which is available on both domains, to bridge the domain gap. On the one hand, we propose to explicitly learn the task feature correlation to strengthen the target semantic predictions with the help of target depth estima-tion. On the other hand, we use the depth prediction dis-crepancy from source and target depth decoders to approx-imate the pixel-wise adaptation difﬁculty. The adaptation difﬁculty, inferred from depth, is then used to reﬁne the target semantic segmentation pseudo-labels. The proposed method can be easily implemented into existing segmenta-tion frameworks. We demonstrate the effectiveness of our approach on the benchmark tasks SYNTHIA-to-Cityscapes and GTA-to-Cityscapes, on which we achieve the new state-of-the-art performance of 55.0% and 56.6%, respectively.
Our code is available at https://qin.ee/corda. 1.

Introduction
The task of semantic segmentation requires models to assign pixel-level category labels to given scenes. While deep learning models have achieved good performance on benchmark datasets with the help of a large amount of high quality annotated training data [1, 48], they still face the real-world challenge of the domain shift between training and test data because of the variance in illumination, appear-ance, viewpoints, backgrounds, etc. Unsupervised domain adaptation (UDA) can potentially heal this domain gap by aligning the domain distributions [40], or recursively reﬁn-ing the target pseudo-labels [55].
*The corresponding author
Figure 1. We propose to use self-supervised depth estima-tion (green) to improve semantic segmentation performance under the unsupervised domain adaptation setup. We explicitly learn the task feature correlation (orange) between semantics and depth and use it to improve the target semantics. We use the adaptation dif-ﬁculty (blue) approximated by depth prediction discrepancy of the target image from two domain-speciﬁc depth decoders to reﬁne our target semantic pseudo-label. The proposed correlation-aware domain adaptation method can largely improve the segmentation performance in the target domain.
In recent years, motivated by the success of multi-task learning [49, 44], auxiliary tasks (such as depth estima-tion) have been increasingly used to help the adaptation. As auxiliary tasks are often coupled with the semantics, they have been proved to be beneﬁcial for the main segmentation task [19]. Existing works [41, 3] typically utilize the easy-to-access depth information from a synthetic source domain to train an auxiliary depth network but do not take target depth into account because of its inaccessibility. Inspired by recent progress on self-supervised depth estimation, where depth can be trained from stereo pairs [7, 8] or video se-quences [54], we propose to make use of self-supervised depth estimates for the domains (the source domain and/or target domain) on which ground-truth depth is not available.
The additional self-supervised depth estimation can fa-cilitate us to explicitly learn the correlation between tasks to 1
improve the ﬁnal semantic segmentation performance. The learning of the correlation is motivated by the fact that the correlation between tasks is more invariant across domains than the individual modalities. As mentioned by previous works [3], sky is always faraway, roads and sideways are always ﬂat. These domain-robust correlations between se-mantics and depth have the potential to largely improve the target semantic segmentation performance in the presence of a domain shift.
To this end, we propose to exploit such a correlation in two ways. On the one hand, we propose to explicitly learn the task feature correlation between depth and semantics.
This is achieved by using domain-shared multi-modal dis-tillation modules to model the interaction and complemen-tarity between semantics and depth features. The corre-lation learned from the source domain can be shared and transferred to the target domain to improve target segmen-tation performance. On the other hand, we make use of the correlation to reﬁne the target semantic pseudo-labels.
We approximate the adaptation difﬁculty by calculating the discrepancy between the predictions of the domain-speciﬁc depth decoders. As depth and semantics are coupled, we make the assumption that the estimated adaptation difﬁ-culty can be transferred from depth to semantics. We pro-pose to use this relation to guide the semantic segmentation pseudo-label reﬁnement on the target domain. Combining the two ways of correlation exploitation leads to our pro-posed Correlation-Aware Domain Adaptation (CorDA) ap-proach. We illustrate the two ways to utilize the correlation in Figure 1.
It is also worth mentioning that our strategies can be im-plemented easily. The self-supervised depth estimation can be learned from easy-to-access image sequences or stereo images and the proposed correlation learning module can be readily incorporated into existing UDA networks for se-mantic segmentation. We demonstrate the effectiveness of our proposed approach on the benchmark tasks SYNTHIA-to-Cityscapes and GTA-to-Cityscapes, on which we achieve new state-of-the-art segmentation performance.
Our contributions are summarized as follows:
• We propose a novel UDA framework which effectively utilizes self-supervised depth estimation available on both domains to improve semantic segmentation.
• Speciﬁcally, we explicitly learn the correlation be-tween modalities and share it across domains. Further-more, we reﬁne the semantic pseudo-labels by using the adaptation difﬁculty approximated by depth pre-diction discrepancy.
• Despite of the simplicity, our proposed approach segmentation per-achieves new state-of-the-art formance on the benchmark tasks SYNTHIA-to-Cityscapes and GTA-to-Cityscapes. 2.