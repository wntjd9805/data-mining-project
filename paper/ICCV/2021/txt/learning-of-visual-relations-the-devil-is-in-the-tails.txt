Abstract
Significant effort has been recently devoted to modeling visual relations. This has mostly addressed the design of architectures, typically by adding parameters and increas-ing model complexity. However, visual relation learning is a long-tailed problem, due to the combinatorial nature of joint reasoning about groups of objects. Increasing model complexity is, in general, ill-suited for long-tailed problems due to their tendency to overfit. In this paper, we explore an alternative hypothesis, denoted the Devil is in the Tails.
Under this hypothesis, better performance is achieved by keeping the model simple but improving its ability to cope with long-tailed distributions. To test this hypothesis, we de-vise a new approach for training visual relationships mod-els, which is inspired by state-of-the-art long-tailed recog-nition literature. This is based on an iterative decoupled training scheme, denoted Decoupled Training for Devil in the Tails (DT2). DT2 employs a novel sampling approach,
Alternating Class-Balanced Sampling (ACBS), to capture the interplay between the long-tailed entity and predicate distributions of visual relations. Results show that, with an extremely simple architecture, DT2-ACBS significantly out-performs much more complex state-of-the-art methods on scene graph generation tasks. This suggests that the de-velopment of sophisticated models must be considered in tandem with the long-tailed nature of the problem. 1.

Introduction
Scene graphs provide a compact structured description of complex scenes and the semantic relationships between objects/entities. Modeling and learning such visual rela-tions benefit several high-level Vision-and-Language tasks such as caption generation [45, 44], visual question an-swering [16], image retrieval [20, 34], image generation
[19, 24, 33] and robotic manipulation planning [29]. Scene
*Authors have equal contributions.
Figure 1. The devil is in the tails: Architecture design and learning process of visual relations need to consider the long-tailed nature of both entity and predicate class distributions. graph generation requires the understanding of the loca-tions and the class associated with the entity as well as the relationship between a pair of entities. The relation-ship between a pair of entities is usually formulated as a
< subject − predicate − object > tuple, where subject and object are two entities. Scene graph generation (SGG) faces the challenges from both the long-tailed entity recog-nition problem and visual relation recognition problem.
While long-tailed entity recognition has been addressed in the literature [28, 1, 5, 21], the imbalance becomes more prevalent for the SGG tasks, owing to the severe long-tailed nature of the predicate distribution. Take Figure 1 for ex-ample. While the class of the subject (“ball”) is popular, the class of the object (“robot”) and the predicate (“kicking”) can be infrequent, leading to the rare occurrence of the tu-ple “robot-kicking-ball”. This shows that even when the entity class distribution is balanced, the imbalanced pred-icate class distribution can lead to a more imbalanced tu-ple distribution. Of course, such imbalance issues can be exacerbated if both entity classes and predicate classes are skewed (e.g. “tripod-mounted-on-donkey”). The combina-tion of long-tailed entity and predicate classes makes SGG
a more challenging problem.
While the long-tailed problem poses a great challenge to
SGG tasks, it has not been well addressed in the SGG liter-ature. Existing works [48, 43, 3, 32, 49] instead focused on designing more complex models, primarily by adding archi-tectural enhancements that increase model size. While this has enabled encouraging performance under the Recall@k (R@k) metric, this metric is biased toward the highly popu-lated classes. This suggests that prior works may be overfit-ting on popular predicate classes (e.g. on/has), but their per-formances could degrade on the less frequent classes (e.g. eating/riding). Such a bias towards the populated classes is problematic, because predicates lying in the tails often provide more informative depictions of scene content. The failure to predict tail classes could lead to a less informative scene graph , limiting the effectiveness of scene graphs for intended applications. In this paper, we explore the hypoth-esis that the Devil is in the tails. Under this hypothesis, vi-sual relation learning is better addressed by a simple model of improved ability to cope with long-tailed distributions.
To investigate this hypothesis, we first analyze the distri-bution of entity and predicate classes in the Visual Genome dataset. As shown in Figure 2, both distributions are heavily skewed, but with different magnitude. The imbalance in the predicate distribution is more severe than that in the entity distribution. To the best of our knowledge, none of the ex-isting SGG methods considered the jointly long-tailed dis-tributions of entity and predicate classes. To address this, we propose a new approach to visual relationship learning, based on a simpler architecture than those in the literature but a more sophisticated training procedure, denoted De-coupled Training for Devil in the Tails (DT2).
DT2 is a generalization of the decoupled training pro-cedures that have recently become popular for long-tailed recognition [21].
It consists of an alternative sampling scheme that produces distributions balanced for entities and predicates. This is accompanied by a novel sampling scheme, Alternating Class-Balanced Sampling (ACBS), which captures the interplay between the two different long-tailed distributions through an implementation of learn-ing without forgetting [26] based on a mechanism that in-troduces memory between the sampling iterations, using knowledge distillation. With DT2, we show that a simple ar-chitecture with 10× fewer parameters significantly outper-forms prior, and more sophisticated, architectures designed for SGG, under the mRecall@K metric, which is suited for measuring the performance of a long-tailed dataset. Abla-tion studies of different sampling schemes as well as analy-sis of performance on classes of different popularity further validate our hypothesis.
Overall, the paper makes three contributions. 1) We de-vise a simple model architecture with the decoupled train-ing scheme, namely DT2, suited for the long-tailed SGG tasks. 2) We propose a novel sampling strategy, Alternat-ing Class-Balanced Sampling (ACBS), to capture the in-terplay between different long-tailed distributions of entities and relations. 3) The combined DT2-ACBS significantly outperforms state-of-the-art methods of more complex ar-chitectures on all SGG tasks on the Visual Genome bench-mark. The code is available on the project website1. 2.