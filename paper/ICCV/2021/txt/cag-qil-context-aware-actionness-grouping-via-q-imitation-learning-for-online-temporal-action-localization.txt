Abstract
Temporal action localization has been one of the most popular tasks in video understanding, due to the importance of detecting action instances in videos. However, not much progress has been made on extending it to work in an on-line fashion, although many video related tasks can benefit by going online with the growing video streaming services.
To this end, we introduce a new task called Online Temporal
Action Localization (On-TAL), in which the goal is to imme-diately detect action instances from an untrimmed stream-ing video. The online setting makes the new task very chal-lenging as the actionness decision for every frame has to be made without access to future frames and also because post-processing methods cannot be used to modify past action proposals. We propose a novel framework, Context-Aware
Actionness Grouping (CAG) as a solution for On-TAL and train it with the imitation learning algorithm, which allows us to avoid sophisticated reward engineering. Evaluation of our work on THUMOS14 and Activitynet1.3 shows sig-nificant improvement over non-naive baselines, demonstrat-ing the effectiveness of our approach. As a by-product, our method can also be used for the Online Detection of Ac-tion Start (ODAS), in which our method also outperforms previous state-of-the-art models. 1.

Introduction
Fueled by flourishing video platforms, video understand-ing tasks are drawing substantial attention in the com-puter vision research community. Among many video un-derstanding tasks, Temporal Action Localization (TAL), the task of extracting action instances from an untrimmed video, has been one of the most popular topics. A plethora of works have been done in TAL [32, 30, 5, 8, 44, 22, 43, 39, 41, 19, 1], implying the importance of action instances
Figure 1. Example of play-by-play system applied on the video from THUMOS14. in video understanding
However, detecting action instances from streaming videos has received no attention, even though more video streaming services are being provided which require real-time and online approaches. In contrast, many online al-gorithms are being introduced in other video understand-ing tasks such as object detection and tracking [2, 36, 28], video object segmentation [25], and video instance segmen-tation [40]. We argue that temporal action localization can also benefit by going online, as it can provide valuable in-formation for many practical real-world applications that in-volve online video understanding.
Popular sports websites provide a feature called live play-by-play system that shows the progress of a sports game in real-time. To be able to develop an AI-based play-by-play system, the algorithm needs to detect both the start, the end time and the class information of the occurring action in an online manner. Previous temporal action lo-calization methods cannot be used as they operate in an offline fashion, requiring the whole video sequence to be seen. Figure 1 shows an application of the online temporal
frame labels from the streaming video. As it provides per-frame labeling, On-TAL can be solved by taking OAD as an intermediate procedure; training a binary OAD model that distinguishes action frames and grouping them. However, this approach has limitations that are not negligible: action fragmentation and action tick (Figure 2). These problems occur due to the model’s unawareness of its decision con-text, not considering its past decision sequence although it is essential in making a correct decision for the current frame.
Therefore, we propose augmenting context information into the actionness grouping process, forming Context-Aware Actionness Grouping (CAG). Underline the fact that in the CAG setting, the model’s decision at the current frame affects what the model will decide in the future. In-corporating this recurrency to training is the main objective of our paper because standard supervised learning methods cannot tackle it properly. Hence, we formulated CAG as a
Markov Decision Process (MDP), and tried to apply rein-forcement learning [33]. With this, the transition dynamics can be naturally integrated into the training process.
Nevertheless, what would be the best reward scheme for our MDP still remains unclear. This is critical because mis-designed hand-crafted reward function would lead to sub-optimal policy. In order to resolve the issue, we adopt the imitation learning (IL) [27], which tries to follow not only an immediate expert action at a state but also the whole tra-jectory produced by the expert policy. By this, we can avoid an exhaustive search for the optimal reward function for our
MDP.
We evaluate our models on two popular video datasets,
THUMOS14 [18] and Activitynet1.3 [6]. We compare our model with various baselines and show that our model,
CAG with imitation learning, significantly outperforms the other models. Moreover, as our model also can be used as online detection of action start (ODAS), we evaluated our model on the ODAS task. Surprisingly, our model outper-forms state-of-the-art ODAS models.
The main contribution of our paper is summarized as fol-lows:
• We introduce a new challenging task, Online Tempo-ral Action Localization (On-TAL). Due to its ability to process streaming videos and promptly respond with instance-level information of actions, it opens the door for various real-time video understanding applications, for which previous video-related tasks cannot be used.
Figure 2. Limitations of simple extension of OAD to On-TAL: (a) action tick and (b) fragmentation. α sequence represents a series of actionness scores from a binary OAD model.
In the case of action tick, the model emits very short action instances because
α slightly exceeds the threshold (0.5) although there is no action.
Action fragmentation refers to the opposite situation. To avoid these problems, the model should be aware of its decision context and be conservative in changing its decision. action localization in the play-by-play system for the live sports broadcasting. Another important use of the online version of the temporal action localization can be found in the robotics domain. For a robot to interact with humans in real-time, it needs the information about the whole action instance before deciding how to react.
To this end, we suggest a new challenging task, On-line Temporal Action Localization, or On-TAL, which aims to produce action instances from an untrimmed streaming video on the fly. As the name suggests, the final output of
On-TAL is the same as offline TAL – action instances with the start and the end timestamps. But in the On-TAL set-ting, an action instance needs to be produced as soon as the action ends, which poses several challenges differentiating it from offline TAL as follows:
• Without accessing future frames, a model has to decide whether the current frame contains an action or not be-cause it needs to return an action instance immediately when the action ends. Note that this decision making occurs for every frame.
• As the action instance is produced promptly and one cannot go back in time, modification of past proposals is strictly prohibited, making it impossible to use pre-vailing post-processing methods such as (Soft-) Non-Maximum Suppression (NMS) [3].
With these constraints, we cannot simply extend previ-ous TAL approaches for the online setting since most pre-vious TAL methods require the whole video to be seen and use the NMS technique to eliminate duplicate proposals.
Online Action Detection (OAD) is a popular online video processing task whose objective is to extract per-• For On-TAL, we devise an original framework, CAG, which takes into account not only the frame context but also the model’s own decision context. To train
CAG, we formalize the CAG framework into a Markov
Decision Process (MDP) and propose a novel training method using imitation learning.
• Its effectiveness and robustness are validated by ex-tensive experiments on popular video datasets: THU-MOS14 and Activitynet1.3. Besides, our model can also be used for ODAS, outperforming previous ODAS algorithms. 2.