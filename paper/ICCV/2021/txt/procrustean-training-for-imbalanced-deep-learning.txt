Abstract (a) training set accuracy (b) classification ratio
Neural networks trained with class-imbalanced data are known to perform poorly on minor classes of scarce train-ing data. Several recent works attribute this to over-fitting to minor classes. In this paper, we provide a novel explana-tion of this issue. We found that a neural network tends to first under-fit the minor classes by classifying most of their data into the major classes in early training epochs. To cor-rect these wrong predictions, the neural network then must focus on pushing features of minor class data across the de-cision boundaries between major and minor classes, lead-ing to much larger gradients for features of minor classes.
We argue that such an under-fitting phase over-emphasizes the competition between major and minor classes, hinders the neural network from learning the discriminative knowl-edge that can be generalized to test data, and eventually results in over-fitting. To address this issue, we propose a novel learning strategy to equalize the training progress across classes. We mix features of the major class data with those of other data in a mini-batch, intentionally weakening their features to prevent a neural network from fitting them first. We show that this strategy can largely balance the training accuracy and feature gradients across classes, ef-fectively mitigating the under-fitting then over-fitting prob-lem for minor class data. On several benchmark datasets, our approach achieves the state-of-the-art accuracy, espe-cially for the challenging step-imbalanced cases. 1.

Introduction
Deep neural networks [21, 25, 37, 55, 56] trained with class-imbalanced data, of which we have ample data for some “major” classes and limited data for the other “minor” classes, are known to perform poorly on minor classes [3, 45, 61]. As many real-world data sets are class-imbalanced by nature, especially those for recognizing a large number of objects [17, 35, 44, 59, 60], this problem has attracted increasing attention recently in both the machine learning and computer vision communities [5, 9, 30, 58, 52, 66].
Many works have attempted to explain this problem and
Figure 1. The training progress of a neural network on class-imbalanced data. We trained a ResNet-32 [21] on a long-tailed
CIFAR-10 data set [36]. We only showed two classes for clarity.
Class-1 and class-10 have 5000 and 50 training instances, respec-tively. (a) training accuracy per class along the epochs. (b) clas-sification ratio: the numbers of training instances classified into a class divided by the number of training instances which truly belong to that class, along the epochs. Minor classes need longer time to achieve almost a 100% training accuracy, and most of their instances are classified into the major classes in early epochs. develop corresponding solutions. Some attribute this to the mismatch between training and test data distributions
[5, 7, 20, 32, 29, 64, 57, 26, 49]1 or under-fitting to minor classes [40, 41]. Others attribute this to the poor feature learning [12, 13, 22, 23, 77, 19, 70, 79] or over-fitting to mi-nor classes [1, 72, 33]. That is, a neural network can easily fit the limited amount of minor class data to obtain ∼ 100% training accuracy, but just cannot generalize to the test data.
One particular finding made by [72, 33] is the feature de-viation between training and test data: for minor classes, the training and test features generated by the learned neu-ral network2 deviate from each other, making the learned decision boundary not applicable to test data.
In this paper, we present a novel finding that links these two lines of explanations. We analyzed the training progress of a neural network (i.e., its training accuracy along the epochs; see Figure 1). We found that, while a neu-ral network eventually fits the minor class data, it only hap-pens when the training is about to converge. In fact, in most of the early training process, the neural network classifies most of the minor class training data into major classes, es-1During testing, one usually assumes class-balanced test data or com-putes average per-class accuracy. 2Here the features mean the neural network’s outputs before the last fully-connected layer.
sentially under-fitting the minor class data. To correct these wrong predictions, the neural network then must focus on pushing features of the minor class data across the decision boundaries between major and minor classes.
We argue that, this initial under-fitting phase of minor classes exaggerates the competition between major and mi-nor classes, forcing the neural network to overly learn the discriminative knowledge that cannot be generalized and ul-timately leading to feature deviation and over-fitting. Con-cretely, in training the feature extractor fθ(x)3 using a loss function ℓ, we found that the gradients assigned to features of minor class data (i.e., ∇fθ (x)ℓ) are much higher than those for major class data (as will be analyzed in section 3).
This finding provides an explanation to feature deviation
[33, 72]: the exaggerated gradients push the features of mi-nor class training data further away than where they need to be, thus deviating from the features of the test data.
To address this issue, we propose a novel, simple yet ef-fective learning strategy to alleviate the under-fitting then over-fitting problem for minor class data. The core idea is to equalize the training progress between major and minor classes by suppressing a neural network’s tendency to first fit major class data — hence making it procrustean across classes. We achieve this by weakening the features of major class data at every mini-batch. Concretely, for a major class datum, we mix its feature with that of another data (i.e., a convex interpolation), such that the resulting features will likely move toward or even across the decision boundary (thus misclassified). We showed that, this learning strat-egy can effectively balance not only the training accuracy across classes, but also the gradients assigned to features.
The resulting neural network therefore suffers less feature deviation and over-fitting for minor classes.
We validate our approach on several benchmark data sets, including CIFAR-10 [36], CIFAR-100 [36], TinyIm-ageNet [38], and iNaturalist [60]. Our approach achieves the state-of-the-art results on many of the experimental set-tings, especially for the more challenging step-imbalanced cases. By analyzing the learned features, we also observe much smaller feature deviations, essentially resolving one fundamental issue in class-imbalanced deep learning. 2.