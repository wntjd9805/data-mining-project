Abstract
How do the neural networks distinguish two images? It is of critical importance to understand the matching mech-anism of deep models for developing reliable intelligent systems for many risky visual applications such as surveil-lance and access control. However, most existing deep met-ric learning methods match the images by comparing fea-ture vectors, which ignores the spatial structure of images and thus lacks interpretability. In this paper, we present a deep interpretable metric learning (DIML) method for more transparent embedding learning. Unlike conventional metric learning methods based on feature vector compari-son, we propose a structural matching strategy that explic-itly aligns the spatial embeddings by computing an optimal matching ﬂow between feature maps of the two images. Our method enables deep models to learn metrics in a more human-friendly way, where the similarity of two images can be decomposed to several part-wise similarities and their contributions to the overall similarity. Our method is model-agnostic, which can be applied to off-the-shelf backbone net-works and metric learning methods. We evaluate our method on three major benchmarks of deep metric learning includ-ing CUB200-2011, Cars196, and Stanford Online Products, and achieve substantial improvements over popular metric learning methods with better interpretability. Code is avail-able at https://github.com/wl-zhao/DIML. 1.

Introduction
Visual similarity plays an important role in a range of vision tasks including image retrieval [32], person identiﬁ-cation [4] and image clustering [30]. Recent advances in learning visual similarity are mostly driven by Deep Metric
Learning (DML), which leverages deep neural networks to
∗Equal contribution.
†Corresponding author.
Figure 1: The main idea of the proposed deep interpretable metric learning (DIML) method. Unlike most existing deep metric learning methods that match the images by comparing feature vectors, we propose a structural matching strategy that explicitly aligns the spatial embeddings by computing an optimal matching ﬂow between feature maps of the two images to improve the interpretability of visual similarity. learn an embedding space where the embedding similarity in this space can meaningfully reﬂect the semantic similarity between samples. A variety of deep metric learning methods have been proposed and have shown strong superiority in learning accurate and generalizable visual similarities on var-ious tasks [7, 40, 16]. Despite the great progress in learning discriminative embeddings, deep metric learning methods with better interpretability have drawn limited attention from the community. Understanding the underlying matching mechanism of deep metric learning models is of critical im-portance for developing reliable intelligent systems for many risky visual applications such as surveillance [33] and access control [21].
To improve the transparency of deep visual models, many efforts have been made recently by either explaining the ex-isting models [50, 31, 1, 2] or modifying models to achieve better interpretability [46, 47]. For example, visual attri-bution methods leverage correlation or gradient to ﬁnd the important regions that have high contributions to the ﬁnal prediction. [46] and [47] propose to add part constraints
and tree structures to construct interpretable CNN models respectively. However, these methods are only designed for explaining the reasoning process of how the output of a deep model is produced and did not consider the interaction be-tween samples. Although they achieve promising results on image classiﬁcation [50, 2], visual question answering [31], and image generation [1], they cannot explain how visual similarity is composed. Therefore, how to improve the inter-pretability of deep metric learning methods is still an open problem that has barely been visited in previous works.
In this paper, we present a deep interpretable metric learn-ing (DIML) framework as a ﬁrst step towards more trans-parent embedding learning. Different from most existing deep metric learning methods that match the images by di-rectly comparing feature vectors, we propose to leverage the spatial structure of images during matching to improve interpretability, as illustrated in Figure 1. More speciﬁcally, we measure the similarity of two images by computing an optimal matching ﬂow between the feature maps using the optimal transport theory such that the similarity can be de-composed into several part-wise similarities with different contributions to the overall similarity. Our framework con-sists of three key components: 1) Structural Similarity (SS). Unlike most existing deep metric learning methods that match the images by comparing feature vectors, we pro-pose a new similarity/distance metric by measuring the sim-ilarity of corresponding parts in the feature maps based on the optimal matching ﬂow; 2) Spatial Cross-Correlation (CC). To handle the view variance in the image retrieval problem, we propose to use spatial cross-correlation as the initial marginal distribution to compute the optimal trans-port plan; 3) Multi-scale Matching (MM). We also devise a multi-scale matching strategy to better incorporate exist-ing metric learning methods and enable us to adaptively adjust the extra computational cost in large-scale search problems. Since our method is model-agnostic and our con-tribution is orthogonal to previous deep metric learning meth-ods on architectures [14], objective functions [32, 16] and sampling strategies [42, 49], our method can be applied to off-the-shelf backbone networks and metric learning meth-ods even without training. Extensive experimental study on three major benchmarks of deep metric learning including
CUB200-2011 [38], Cars196 [17] and Stanford Online Prod-ucts (SOP) [24] shows that our method enables us to achieve more interpretable metric learning while substantially im-proving various metric learning methods with or without re-training the models. 2.