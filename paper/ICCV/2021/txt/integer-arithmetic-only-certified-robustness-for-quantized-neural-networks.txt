Abstract
Adversarial data examples have drawn significant atten-tion from the machine learning and security communities.
A line of work on tackling adversarial examples is certified robustness via randomized smoothing that can provide a the-oretical robustness guarantee. However, such a mechanism usually uses floating-point arithmetic for calculations in in-ference and requires large memory footprints and daunting computational costs. These defensive models cannot run efficiently on edge devices nor be deployed on integer-only logical units such as Turing Tensor Cores or integer-only
ARM processors. To overcome these challenges, we propose an integer randomized smoothing approach with quantiza-tion to convert any classifier into a new smoothed classifier, which uses integer-only arithmetic for certified robustness against adversarial perturbations. We prove a tight robust-ness guarantee under ℓ2-norm for the proposed approach.
We show our approach can obtain a comparable accuracy and 4× ∼ 5× speedup over floating-point arithmetic certi-fied robust methods on general-purpose CPUs and mobile devices on two distinct datasets (CIFAR-10 and Caltech-101). 1.

Introduction
Recent works in deep learning have demonstrated that well-trained deep neural networks can easily make wrong predictions with high confidence when a sample is perturbed with a small but adversarially-chosen noise [37, 13, 32]. To defend against these attacks, several works have proposed to develop defensive techniques and improve the robustness of deep neural networks[1, 28, 26, 41]. A recent promis-ing line of work focuses on developing certifiably robust classifiers that promise no adversarially perturbed examples within a certified region can alter the classification result
[6, 42, 23]. Such certified defenses provide a rigorous guar-antee against norm-bounded perturbation attacks and, more importantly, ensure effectiveness under future stronger at-*Corresponding Author. tacks [6, 25, 23, 38]. One primary theoretical tool for pro-viding the robustness guarantee is randomized smoothing, which derives a smoothed classifier from the base classi-fier via injecting designated noises, e.g., Gaussian noise.
Multiple repeated inferences through the base classifier (i.e.,
Monte-Carlo estimation) are required to approximate the smoothed classification result for robustly predicting or cer-tifying a single example.
Despite the promising results achieved by many certified robustness algorithms, existing methods almost exclusively focus on floating-point (FP) represented neural networks.
However, the vastly adopted compressed neural network models are considered indispensable when one wishes to deploy the networks on storage-, computing resources- and power consumption-limited platforms such as edge devices, mobile devices, and embedded systems. In practice, one of the most successful and mainstream compression methods is quantization [20, 8, 44, 47]. Quantization is a simple yet effective technique that compresses deep neural networks into smaller sizes by replacing model weights and activations from 32-bit floating-point (FP32) with low-bit precision, e.g., 8-bit integer (int8) [47]. Both storage and computational complexity can be reduced using low-bit quantized neural networks [20]. Moreover, Jacob et al. [20] have proposed an integer-arithmetic-only quantization framework that further accelerates inference by using integer multiplication and accumulation for calculation. Performing inference using integer-arithmetic-only operations has several advantages in real application scenarios. For example, it resolves the limitation that floating-point networks cannot be deployed onto digital computing devices such as the recent Turing
Tensor Cores or traditional integer-only ARM processors.
Moreover, computing with integer arithmetic significantly reduces computing power, making them attractive for energy-constrained edge deployment and some cost-sensitive cloud data centers [10].
Given the under-studied situation of the certified robust-ness for quantized neural networks, the following research questions naturally arise: Q1. Are adversarial perturbations still effective on quantized neural networks? Q2. Can we reuse the current certified robustness defenses on quantized
Figure 1. A demonstration of the adversarial perturbation attacks on undefended full precision network (blue) and 8-bit integer network (yellow). The x-axis represents the radius of the noise projected into clean images under ℓ∞ ball (parameterized by ε). Given 100 clean images, the full precision and quantized network achieved 93% and 91% accuracy, respectively. When images are attacked by Projected Gradient Descent attack targeting the full precision model, the accuracy of both classifiers begins to drop. Details are deferred to Supplement. neural networks? Q3. If not, how can we design a certifiably robust defense making full considerations of the characteris-tics of quantized neural networks? Q1 and Q2 can be readily answered as follows,
For Q1, we consider the following demonstrating example.
We generate adversarial perturbations using Projected Gradi-ent Descent attack [29] and inject the perturbations to 100 randomly selected clean images from CIFAR-10. The result is presented in Figure 1. Although the quantized network manifests slightly stronger robustness than the full precision model, adversarial perturbations can still sabotage the classi-fication performance of the quantized neural network even when the perturbation noise is small. More severely, since the adversarial perturbation used in the example does not consider the characteristics of the quantized neural network as a priori, stronger attacks can be devised once such in-formation is exploited. Thus, it is pressing for us to study certified robustness for quantized neural networks.
For Q2, a new certified robustness mechanism tailored to quantized neural networks is indeed necessary. The reason is that existing certified robustness methods rely on floating-point operations, which are incompatible with integer-arithmetic-only devices. Sometimes even when de-ployed on platforms that do support floating-point operations, a new integer-arithmetic-only certified robustness method can still be desirable due to the efficiency reason, especially considering that most certified robustness methods invoke repeated inferences to certify on a single example and incur large inference time.
As a result, our main effort in this paper is to answer
Q3 with a novel and first integer-arithmetic-only certified robustness mechanism for quantized neural networks against adversarial perturbation attacks. An illustration of our frame-work and comparison with the existing certified robustness defenses is in Figure 2. In summary, we make the following
Figure 2. A comparison of certification procedure between IntRS and the floating-point network. Certification requires repeating inference N times. Compared with original floating-point network,
IntRS achieves comparable certified accuracy with less inference time. contributions:
• We devise a new integer-arithmetic-only randomized smoothing mechanism (abbreviated as IntRS) by incor-porating the discrete Gaussian noise. More importantly, we rigorously calibrate the certified robustness behav-ior of IntRS in theory. In practice, we introduce the quantization- and discrete data augmentation- aware as well as the common Monte-Carlo-based estimation.
• We perform experiments with 1) two different base neural network architectures with medium and large scales; 2) two different datasets; 3) two different types of computing devices (general-purpose computer and mobile device), which verify that IntRS achieves sim-ilar robustness and accuracy performance, and 4× to 5× efficiency improvement in the inference stage over existing floating-point randomized smoothing method for the original full precision neural networks. 2.