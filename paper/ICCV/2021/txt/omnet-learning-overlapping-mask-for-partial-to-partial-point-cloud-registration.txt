Abstract
Point cloud registration is a key task in many compu-tational fields. Previous correspondence matching based methods require the inputs to have distinctive geometric structures to fit a 3D rigid transformation according to point-wise sparse feature matches. However, the accuracy of transformation heavily relies on the quality of extracted features, which are prone to errors with respect to partial-ity and noise. In addition, they can not utilize the geomet-ric knowledge of all the overlapping regions. On the other hand, previous global feature based approaches can utilize the entire point cloud for the registration, however they ig-nore the negative effect of non-overlapping points when ag-gregating global features. In this paper, we present OM-Net, a global feature based iterative network for partial-to-partial point cloud registration. We learn overlapping masks to reject non-overlapping regions, which converts the partial-to-partial registration to the registration of the same shape. Moreover, the previously used data is sampled only once from the CAD models for each object, resulting in the same point clouds for the source and reference. We propose a more practical manner of data generation where a CAD model is sampled twice for the source and reference, avoid-ing the previously prevalent over-fitting issue. Experimental results show that our method achieves state-of-the-art per-formance compared to traditional and deep learning based methods. Code is available at https://github.com/megvii-research/OMNet. 1.

Introduction
Point cloud registration is a fundamental task that has been widely used in various computational fields, e.g., aug-mented reality [2, 6, 4], 3D reconstruction [14, 19] and au-tonomous driving [38, 10].
It aims to predict a 3D rigid transformation aligning two point clouds, which may be po-tentially obscured by partiality and contaminated by noise.
*Corresponding author
Figure 1. Our OMNet shows robustness to the various overlapping ratios of inputs. All inputs are transformed by the same 3D rigid transformation. Error(R) and Error(t) are isotropic errors.
Iterative Closest Point (ICP) [3] is a well-known algo-rithm for the registration problem, where 3D transforma-tions are estimated iteratively by singular value decomposi-tion (SVD) given the correspondences obtained by the clos-est point search. However, ICP easily converges to local minima because of the non-convexity problem. For this reason, many methods [23, 9, 28, 5, 20, 35] are proposed to improve the matching or search larger transformation space, and one prominent work is the Go-ICP [35], which uses a branch-and-bound algorithm to cross the local minima. Un-fortunately, it is much slower than the original ICP. All these methods are sensitive to the initial positions.
Recently, several deep learning (DL) based approaches are proposed [32, 1, 33, 27, 36, 13, 17, 37] to handle the large rotation angles. Roughly, they could be di-vided into two categories: correspondence matching based methods and global feature based methods. Deep Clos-est Point (DCP) [32] determines the correspondences from learned features. DeepGMR [37] integrates Gaussian Mix-ture Model (GMM) to learn pose-invariant point-to-GMM
correspondences. However, they do not take the partiality of inputs into consideration. PRNet [33], RPMNet [36] and
IDAM [17] are presented to mitigate this problem by using
Gumbel–Softmax [15] with Sinkhorn normalization [31] or a convolutional neural network (CNN) to calculate match-ing matrix. However, these methods require the inputs to have distinctive local geometric structures to extract reli-able sparse 3D feature points. As a result, they can not uti-lize the geometric knowledge of the entire overlapping point clouds. In contrast, global feature based methods overcome this issue by aggregating global features before estimating transformations, e.g., PointNetLK [1], PCRNet [27] and
Feature-metric Registration (FMR) [13]. However, all of them ignore the negative effect of non-overlapping regions.
In this paper, we propose OMNet: an end-to-end iterative network that estimates 3D rigid transformations in a coarse-to-fine manner while preserving robustness to noise and partiality. To avoid the negative effect of non-overlapping points, we predict overlapping masks for the two inputs separately at each iteration. Given the accurate overlap-ping masks, the non-overlapping points are rejected dur-ing the aggregation of global features, which converts the partial-to-partial registration to the registration of the same shape. As such, regressing rigid transformation becomes easier given global features without interferes. This desen-sitizes the initial position of the inputs and enhances the ro-bustness to noise and partiality. Fig. 1 shows the robustness of our method to the inputs with different overlapping ra-tios. Experiments show that our approach achieves state-of-the-art performance compared with previous algorithms.
Furthermore, ModelNet40 [34] dataset is adopted for the registration [32, 1, 33, 27, 36, 13, 17, 37], which has been originally applied to the task of classification and segmen-tation. Previous works follow the data processing of Point-Net [21], which has two problems: (1) a CAD model is sampled only once during the point cloud generation, yield-ing the same source and the reference points, which of-ten causes over-fitting issues; (2) ModelNet40 dataset in-volves some axisymmetrical categories where it is reason-able to obtain an arbitrary angle on the symmetrical axis.
We propose a more suitable method to generate a pair of point clouds. Specifically, the source and reference point clouds are randomly sampled from the CAD model sepa-rately. Meanwhile, the data of axisymmetrical categories are removed. In summary, our main contributions are:
• We propose a global feature based registration network
OMNet, which is robust to noise and different partial manners by learning masks to reject non-overlapping regions. Mask prediction and transformation estima-tion can be mutually reinforced during iteration.
• We expose the over-fitting issue and the axisymmetri-cal categories that existed in the ModelNet40 dataset when adopted to the registration task. In addition, we propose a more suitable method to generate data pairs for the registration task.
• We provide qualitative and quantitative comparisons with other works under clean, noisy and different par-tial datasets, showing state-of-the-art performance. 2.