Abstract
Object localisation, in the context of regular images, of-ten depicts objects like people or cars.
In these images, there is typically a relatively small number of objects per class, which usually is manageable to annotate. However, outside the setting of regular images, we are often con-fronted with a different situation. In computational pathol-ogy, digitised tissue sections are extremely large images, whose dimensions quickly exceed 250’000 × 250’000 pix-els, where relevant objects, such as tumour cells or lympho-cytes can quickly number in the millions. Annotating them all is practically impossible and annotating sparsely a few, out of many more, is the only possibility. Unfortunately, learning from sparse annotations, or sparse-shot learning, clashes with standard supervised learning because what is not annotated is treated as a negative. However, assigning negative labels to what are true positives leads to confu-sion in the gradients and biased learning. To this end, we present exclusive cross-entropy, which slows down the bi-ased learning by examining the second-order loss deriva-tives in order to drop the loss terms corresponding to likely biased terms. Experiments on nine datasets and two differ-ent localisation tasks, detection with YOLLO and segmenta-tion with Unet, show that we obtain considerable improve-ments compared to cross-entropy or focal loss, while often reaching the best possible performance for the model with only 10-40% of annotations. 1.

Introduction
With the advent of deep learning and big datasets, object localisation, be it bounding box detection [1, 2, 3, 4, 5, 6], semantic segmentation [7, 8, 9], or instance segmentation
[10, 11, 12, 13], has progressed with leaps and bounds ever since deformable part models [14, 15] and selective search
[16, 17]. The basic assumption for all above localisation methods is that all relevant objects in the image are anno-Figure 1: Left: A digitised tissue section containing mil-lions of cells. An image typically corresponds to only a small part of smaller coloured-in regions in the whole slide.
Only a handful of annotations are available, and after great effort (about 6’000 annotations in our data). Right: with red the non-exhaustively annotated objects in a small 1’000 by 1’000 region of a tissue slide image, roughly 30% of the total number of objects in green (right). tated. This is a reasonable assumption for regular images like in PASCAL VOC 2007 [18] or MSCOCO [19], con-taining on average 512 × 512 -or sometimes up to 1’000 × 1’000- images with no more than a dozen objects per class per image. Outside the realm of regular images, however, we are often confronted with a different situation: digi-tised tissue sections are typically very large images, of file size around 1-10 GB, whose dimensions can quickly ex-ceed 250’000 × 250’000 px, where relevant objects, such as tumour cells or lymphocytes can quickly number in the millions. Annotating them all, even relying on regions-of-interest, can be hard and in practice only sparse annotations are feasible. In this paper we focus on learning from sparse annotations, coined sparse-shot learning, especially when the objective is localising an extreme numbers of objects.
Learning from sparse annotations clashes with super-vised learning, especially in the context of object locali-sation.
In the absence of any other knowledge, the typ-ical assumption is to assign a negative label to all loca-tions in the image that are not annotated as (true) positives.
This is a suboptimal choice on two grounds. For one, it is
very likely that the annotator could not annotate all relevant objects or that simply they missed many of them. When blindly assuming as negative all unannotated areas, for ex-ample in digitised tissue sections, the unannotated objects often amount to more than 90% of the total number of ob-jects [20, 21, 22]. Secondly and more importantly though, assigning a negative label to what is in reality a true pos-itive leads to conflicting gradients [23], that in turn guide the model to poor convergence and generalisation. Sparse-shot learning describes a setting, where standard supervised methods are ill-suited, both from a practical and method-ological perspective [24].
Learning given missing, or few, annotations has been ex-plored in the past, albeit in different scenarios than sparse-shot learning.
In weakly supervised learning [25, 26] an image-level label is provided, without localisation. The model is then asked to jointly infer likely object locations, as well as learn an accurate classification model. How-ever, when there exist no image-level label, as is the case in many object detection datasets, this type of weak learning cannot infer any localisation labels. Some weakly super-vised learning approaches include creating weak pseudo-labels for objects based on confident predictions [27, 28].
Sparse-shot learning is similar in that it assumes all unan-notated areas to be potentially negatives, so in a way they correspond to weak negative labels. A key difference is that sparse-shot learning focuses on rejecting specific subsets of these weak negative labels that are likely to add bias and, it does not create new positive labels for object detection.
Focusing on whole images rather than locations in im-ages, in semi-supervised learning [29] the goal is to learn from both annotated and unannotated images. Unanno-tated images are hence leveraged to learn better and more general image-level classifiers. Similarly, few-shot learn-ing [30] utilises a small number of exhaustively annotated images. Sparse-shot learning, on the other hand, describes a succinctly different setting often encountered in practice: learning localisation models from large images, where only a minute portion of the relevant locations are annotated dur-ing training. In this work, our contributions are as follows: 1. We introduce the problem of sparse-shot setting, which is predominant in several imaging scenarios in medical imaging, where acquiring high-quality exhaustive an-notations is quite often downright impossible. 2. We provide an analysis showing that the likely culprit leading to poor optimisations with sparse-shot learning is the high speed of learning attributed to biased an-notations, and not the biased annotations themselves.
To this end, we introduce a novel learning objective coined exclusive cross-entropy (ECE) that incorporates a simple cut-off threshold to discard samples contribut-ing large second-order derivatives to the loss, which are the ones speeding up biased learning. 3. Via extensive experimentation on nine datasets and two state-of-the-art architectures, YOLLO [4] and
Unet [7], we show that the exclusive cross-entropy generalises in both detection and segmentation. Inter-estingly, the learned models trained in data, where only 10-40% of the annotations are provided, often reach the same performance as the same models trained with exhaustive annotations, especially in segmenta-tion tasks. 2.