Abstract
Existing halftoning algorithms usually drop colors and
ﬁne details when dithering color images with binary dot patterns, which makes it extremely difﬁcult to recover the original information. To dispense the recovery trouble in fu-ture, we propose a novel halftoning technique that converts a color image into binary halftone with full restorability to the original version. The key idea is to implicitly embed those previously dropped information into the halftone pat-terns. So, the halftone pattern not only serves to reproduce the image tone, maintain the blue-noise randomness, but al-so represents the color information and ﬁne details. To this end, we exploit two collaborative convolutional neural net-works (CNNs) to learn the dithering scheme, under a non-trivial self-supervision formulation. To tackle the ﬂatness degradation issue of CNNs, we propose a novel noise incen-tive block (NIB) that can serve as a generic CNN plug-in for performance promotion. At last, we tailor a guiding-aware training scheme that secures the convergence direction as regulated. We evaluate the invertible halftones in multiple aspects, which evidences the effectiveness of our method. 1.

Introduction
Halftoning is commonly used in the printing indus-try [44] to reproduce tone with limited colors, e.g. black and white, due to the cost consideration. During this pro-cess, both the color and ﬁne details of the original image are inevitably lost. This makes the originals nearly impossible to be recovered from these degraded halftones. Even the state-of-the-art inverse halftoning methods [48, 16] can on-ly recover an approximate grayscale version, since the color is usually dropped before halftoning. Apparently, resolving this dilemma requires a fore-looking halftoning technique that retains the necessary information for restoration. This paper makes the ﬁrst attempt to explore this novel problem.
Traditional halftoning methods distribute halftone dots
*Corresponding author. (a) (b) (c) (d)
Figure 1. Observation: the halftone variants of David (a) (b) (c) present similar visual quality but with different binary patterns, as the overlaid RGB image visualized in (d). It indicates the possi-bility of modulating the patterns for additional usage. mainly for tone reproduction, and we observe that this tar-get still permits certain perturbation in term of the desired binary pattern, as evidenced in Figure 1.
It indicates the possibility of utilizing such degree of freedom for addition-al usage, i.e. embedding the potentially missing color in-formation and ﬁne details. Formally, this brings out a new concept, i.e. reversible halftoning, which converts a color image to a halftone that possesses restorability to the origi-nal color version. Inspired by invertible grayscale [47], we adopt the invertible generative model to formulate our prob-lem. However, generating quality halftones is much more challenging than decolorization. First, convolutional neural networks (CNN) that work with spatially shared kernels is not native for halftoning, which suffer from ﬂatness degra-dation (as detailed in Section 3.1). Figure 3 illustrates an ex-ample that CNNs fail to introduce spatial variation in those
ﬂat regions. Second, it is non-trivial to achieve both com-plex visual simulation and accurate information embedding via optimization over 1-bit pixels. Furthermore, the discrete binary pattern poses challenge to capturing its properties via general pixel-wise metrics.
To address ﬂatness degradation, we propose a Noise In-centive Block (NIB) that introduces spatial variation to the feature space but still reserves the information intactness
In fact, NIB is a through training along with the CNNs. model-agnostic plug-in and hence applicable to other rel-evant applications (see Section 4.3). We ﬁnd that the e-quipping the dithering network with NIB breaks the obsta-cle of ﬂatness degradation and make it feasible to dither
constant-valued images. Importantly, this feature enables us to formulate the blue-noise proﬁle through low-frequency penalization on constant-grayness halftone. To achieve the binary halftone, we append the dithering network with a binary gate that takes gradient propagation tricks to allow training with quantization. The model is trained end-to-end with highly mixed objectives, which is formulated as four loss terms: binarization loss, blue-noise loss, halftone con-formity loss, and invertibility loss. Indeed, these partially conﬂicting loss terms complicate the training, especially in the case of inaccurate proxy gradient from the binary gate.
These challenges are circumvented by our guiding-aware training scheme.
Comparative evaluation and ablation study illustrate the advantages of our proposed method, and application explo-ration tells the generic usability of our proposed noise in-centive block. The paper contributes in:
• The innovative idea of reversible halftoning, which of-fers a brand new functionality to existing halftoning applications. It saves the ill-posed inverse halftoning problem at the source.
• A model-agnostic plug-in, noise incentive block that addresses the ﬂatness degradation of CNNs. It ﬁnds general applicability in image synthesis tasks.
• An effective measurement for discrete halftoning pat-terns, which may inspire further exploration in relevant direction, e.g. manga screentone processing. 2.