Abstract
Graph-based predictors have recently shown promising results on neural architecture search (NAS). Despite their efficiency, current graph-based predictors treat all opera-tions equally, resulting in biased topological knowledge of cell architectures. Intuitively, not all operations are equally significant during forwarding propagation when aggregat-ing information from these operations to another opera-tion. To address the above issue, we propose a Hierar-chical Operation-adaptive Predictor (HOP) for NAS. HOP contains an operation-adaptive attention module (OAM) to capture the diverse knowledge between operations by learn-ing the relative significance of operations in cell architec-tures during aggregation over iterations. In addition, a cell-hierarchical gated module (CGM) further refines and en-riches the obtained topological knowledge of cell architec-tures, by integrating cell information from each iteration of
OAM. The experimental results compared with state-of-the-art predictors demonstrate the capability of our proposed
HOP. 1.

Introduction
Recently, neural architecture search (NAS) has aroused significant interest due to its capability to automate the
*Corresponding Author. This work was supported in part by the
National Natural Science Foundation of China under Grants 61822113, the Science and Technology Major Project of Hubei Province (Next-Generation AI Technologies) under Grant 2019AEA170, and supported by project 62002090. GM was supported by Australian Research Council
Project DE210101624. Dr Baosheng Yu is supported by ARC project FL-170100117. This work was done by Ziye Chen when he was an intern in
JD Explore Academy, China. architecture engineering process [43, 17]. NAS has ob-tained competitive results compared with hand-crafted ar-chitectures in various tasks, such as image classification
[18, 28], object detection [31, 25], and semantic segmenta-tion [10, 38]. Current NAS algorithms can be roughly clas-sified into four categories: reinforcement learning-based methods, evolution-based methods, gradient-based meth-ods, and predictor-based methods.
Reinforcement learning-based methods [48, 2] construct an architecture by deriving discrete components with val-idation accuracy as a reward. Evolution-based methods
[12, 14] utilize mutations and combinations of components to generate architectures. Gradient-based methods [13, 34] construct a continuous search space where the architectures share parameters in a super-network. However, the above three types of methods are either time-consuming or space-consuming.
In contrast, predictor-based methods aim to train a predictor that directly predicts the performance of given network architectures concerning network architec-tures’ topological knowledge. Due to the flexibility and low computational cost, predictor-based methods have attracted increasing attention recently. Current predictor-based meth-ods mainly have two types: the sequence-based predictor
[16, 30] and the graph-based predictor [6, 24]. We focus on exploring graph-based predictors for cell search.
The graph-based predictors model cell architectures as directed acyclic graphs (DAG) [8, 18] and accordingly use graph neural networks (GNNs) [22] to encode the archi-tectures’ topological knowledge. However, current graph-based predictors generally treat all operations equally. They consequently fail to capture the diverse knowledge in the details of architectures, i.e., not all operations are equally significant during forwarding propagation when aggregat-ing information from these operations to another operation.
To address the above issue, we propose a Hierarchical
Operation-adaptive Predictor (HOP) for NAS. The main contributions of HOP lie in three fold:
• Within HOP, we design an operation-adaptive attention module (OAM) for learning the relative significance of operations when aggregating information flow from these operations to a given node. OAM naturally mod-els the information flow processes during the forward-ing propagation of network architectures. Through it-erations, the diverse knowledge of each operation is effectively aggregated in the corresponding node em-bedding. As far as we know, this is the first work of
NAS to discuss the relative significance of operations.
• HOP proposes a cell-hierarchical gated module (CGM) for integrating hierarchical knowledge of cell embeddings from different iterations of OAM. The cell embeddings are obtained by averaging the node em-beddings in the corresponding iterations. The inte-grated knowledge comprehensively captures the topo-logical knowledge and is used for performance predic-tion. CGM could effectively refine and enrich the ob-tained topological knowledge of architectures and thus improve the performance.
• We conduct extensive experiments on commonly used benchmarks. The experimental results demonstrate that HOP achieves the new state-of-the-art. Specifi-cally, we compare the performance of GATES [18], which is a representative GCN-based predictor, and
HOP. GATES is the state-of-the-art graph-based pre-dictor that does not consider relative significance be-tween operations. As shown in the experiments, HOP significantly outperforms GCN, which indicate the ne-cessity of considering relative significance of opera-tions. Moreover, the experiments also demonstrate that
HOP has high interpretability of the cell architectures and probably could inspire new network architecture designs. 2.