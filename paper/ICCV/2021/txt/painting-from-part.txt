Abstract 1.

Introduction
This paper studies the problem of painting the whole image from part of it, namely painting from part or part-painting for short, involving both inpainting and outpaint-ing. To address the challenge of taking full advantage of both information from local domain (part) and knowl-edge from global domain (dataset), we propose a novel part-painting method according to the observations of re-lationship between part and whole, which consists of three stages: part-noise restarting, part-feature repainting, and part-patch refining, to paint the whole image by leverag-ing both feature-level and patch-level part as well as pow-erful representation ability of generative adversarial net-work. Extensive ablation studies show efficacy of each stage, and our method achieves state-of-the-art perfor-mance on both inpainting and outpainting benchmarks with free-form parts, including our new mask dataset for irreg-ular outpainting. Our code and dataset are available at https://github.com/zhenglab/partpainting.
*Corresponding author: Haiyong Zheng (zhenghaiyong@ouc.edu.cn).
This work was supported by the National Natural Science Foundation of China under Grant Nos. 61771440 and 41776113, and the Fundamental
Research Funds for the Central Universities under Grant No. 202061002.
Given a part of an image, human have the natural abil-ity to paint the unseen region (e.g., outside or inside the part) [37]. Painting from part, or part-painting for short, is the task to paint a whole reasonable and realistic image according to a part of the image, which can be widely used in many computer vision applications such as view expan-sion [58, 47, 40], texture synthesis [25, 49, 42], image edit-ing [3, 60, 9], and object removal [28, 55]. Due to intrinsic complexity of the part in an image (e.g., diverse shapes and different positions), part-painting is full of challenges.
Specifically, in order to paint a reasonable and realistic whole image from a part, it is indispensable to not only re-quire information from the given part (local domain), but also learn knowledge from other similar images (global do-main). However, the multiple properties of the parts lead to fiendish complexity and huge uncertainty of the balance between local domain and global domain for part-painting.
Thus, how to make full use of information from local do-main (part) and knowledge from global domain (dataset) while keeping a proper balance between them, is essential and crucial for painting from part.
Recent advances in part-painting, i.e., image inpaint-ing [51, 39, 55, 32, 38, 29] and image outpainting [48,
43, 17], mainly feed the part as input into convolutional neural networks (CNNs) and learn from dataset to com-plete the whole painting. For inside part-painting (image inpainting), the unknown region is usually small and lo-cated inside the part, it is able to fill a small number of missing pixels via convolution with surrounding pixels that are coherent with missing ones, thus yielding promising re-sults [35, 53, 54, 28, 50, 27]. But for outside part-painting (image outpainting), the unknown region locates outside the part and is usually large, making this task tends to be a generative problem with more challenges, and recent stud-ies tackle it by first extending the part via feature expan-sion or reconstruction and then generating the result via adversarial learning [48, 17]. Therefore, current inpaint-ing and outpainting methods are not easy to be applied to each other: the former is hard to paint large reasonable content outside [48, 43], and the latter can not handle free-form cases due to the design of requiring square part in-put [48, 17]. Moreover, both of previous painting methods mainly “look” the part once in the beginning, which can not take enough advantage of the information from part (e.g., pixels, patches, features) during painting. In this work, we take both inpainting and outpainting with free-form parts into account as a unified part-painting framework.
We tackle part-painting basically relying on the follow-ing two observations: (1) both low-level and high-level fea-tures of the part have a strong statistical correlation with the whole image features [41, 44], and (2) small patches from the part have a high probability of abundantly recurring in the whole image [15, 61]. Figure 1(d) shows the t-SNE [30] visualizing embeddings of three flower exemplars with the parts and corresponding whole image for each, which indi-cates that (1) different whole images have relatively inde-pendent distributions while the parts are strongly correlated to corresponding whole image, and (2) the parts of every exemplar have very similar visual characteristics to the cor-responding whole image.
Therefore, for painting from part, in order to make bet-ter use of information from part (local domain), we lever-age both feature-level and patch-level information of part (part-feature and part-patch) during painting; while, to bal-ance the painting guidance between part information (lo-cal domain) and dataset knowledge (global domain), we de-vise a learnable adaptive strategy for both feature-level re-construction and patch-level fusion; furthermore, we start painting from the noise sampled from local part distribu-tion (part-noise), to ensure more reasonable and realis-tic synthesis via powerful representation of generative ad-versarial network (GAN). Specifically, we build a novel
GAN-based network architecture for part-painting, includ-ing three stages in correlation with part-noise, part-feature and part-patch, where, part-noise is sampled from the distri-bution of part encoding, part-feature is extracted from part in multiple levels and injected into both high-level and low-level synthesis for further repainting, and part-patch is ob-tained from part mask of repainted whole image then uti-lized to find and replace the most strongly correlated patch from the unknown region for final refining.
Our contributions include: (1) we propose a new part-painting task, involving both image inpainting and image outpainting from free-form parts, as well as a novel archi-tecture to solve it; (2) we devise three stages, i.e., part-noise restarting, part-feature repainting, and part-patch re-fining, for guiding and optimizing the part-painting; (3) our method achieves state-of-the-art performance on both in-painting and outpainting benchmarks with free-form parts, including our new built irregular image outpainting dataset. 2.