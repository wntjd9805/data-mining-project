Abstract
CNNs perform remarkably well when the training and test distributions are i.i.d, but unseen image corruptions can cause a surprisingly large drop in performance.
In various real scenarios, unexpected distortions, such as ran-dom noise, compression artefacts or weather distortions are common phenomena. Improving performance on corrupted images must not result in degraded i.i.d performance – a challenge faced by many state-of-the-art robust approaches.
Image corruption types have different characteristics in the frequency spectrum and would benefit from a targeted type of data augmentation, which, however, is often unknown
In this paper, we introduce a mixture of during training. two expert models specializing in high and low-frequency robustness, respectively. Moreover, we propose a new reg-ularization scheme that minimizes the total variation (TV) of convolution feature-maps to increase high-frequency ro-bustness. The approach improves on corrupted images without degrading in-distribution performance. We demon-strate this on ImageNet-C and also for real-world corrup-tions on an automotive dataset, both for object classifica-tion and object detection. 1.

Introduction
Robustness to distribution shift is possibly the core chal-lenge in deep learning. CNNs show strong performance when training and test set samples are independent and identically distributed (i.i.d). This led to strong claims of obtaining superhuman performance on the challenging Ima-geNet dataset. However, such claims have somewhat dimin-ished as the community, driven by practical applications, started testing on out-of-distribution (OOD) test sets. Un-like human vision, CNNs are affected even by small per-turbations in the input. Simply adding random noise to the
ImageNet test set is sufficient to almost triple the classifica-tion error [15].
Why does performance drop so severely under distribu-tion shift? One explanation is that models rely on spurious, unstable correlations present in the i.i.d training and test
Figure 1: Improving clean and corruption errors. Each item shows the error of a model on ImageNet (y-axis) and on
ImageNet-C (x-axis). All models use a ResNet50 back-bone. Orange: The proposed RoHL approach – Robust mixture of a HF (high-frequency) and a LF (low-frequency) expert model. Blue: An ensemble trained with the state-of-the-art approach AugMix + DeepAugment. Gray: Other approaches. dataset to obtain low training and test errors. When, due to distribution shift, these unstable correlations are miss-ing, performance drops severely. Although there has been substantial prior work [12, 15, 24, 29, 35] investigating this problem, it is far from being fully understood, let alone solved. The most successful remedies to-date are well-chosen data augmentation schemes [7, 14, 17, 26, 11] and adversarial training [10, 26, 32]. Geirhos et al. [12] pro-posed the texture hypothesis, where they show that classifi-cation models learn feature representations biased towards textures. Many of these texture features are unstable and get destroyed, for example, due to weather effects or digital corruptions.
The texture hypothesis can also be regarded from a
Fourier perspective [35]. Yin et al. [35] showed that models achieve reasonable performance (∼60% accuracy) on the i.i.d test set of ImageNet even with strong low or high pass filtering applied to the input images during training and test-ing.
This indicates the existence of many input-output corre-lations in low-frequency and high-frequency domains. They also showed that the performance degradation on corrupted data varies across the frequency spectrum. For instance, standard models trained on clean images are inherently bi-ased to be more robust towards low-frequency corruptions compared to high-frequency ones. It might seem that such biases can be easily fixed with data augmentation. How-ever, data augmentation comes with robustness trade-offs, i.e., many transformations improve performance on some types of corruptions but reduce performance on clean im-ages. In realistic scenarios, the dominant fraction of data is typically clean and not corrupted. Therefore, clean perfor-mance must not be ignored.
To avoid such trade-offs, we propose RoHL — Robust mixture of a HF (high-frequency) and a LF (low-frequency) expert model. To build the HF expert model, we apply
TV minimization [2] on the activations of the first con-volutional layer, as well as generic augmentations that af-fect high-frequency components in the image. The HF ex-pert is robust to high-frequency corruptions whereas the
LF expert, based on plain contrast augmentation, is robust to low-frequency corruptions. We show that having such complementary models improves performance both on cor-rupted and clean images. Also compared to a standard two-member ensemble it adds robustness at no additional cost.
An overview of its effectiveness is shown in Fig. 1.
In summary, we make two contributions: (1) We pro-pose a new regularization scheme that enforces convolu-tional feature maps to have a low total variation (TV). We show that this boosts high-frequency robustness and is com-plementary to other high-frequency augmentation opera-(2) We introduce the idea of mixing two experts tions. that specialize in high-frequency and low-frequency robust-ness. We show that this mixture is complementary to di-verse data augmentation, such as AugMix [17] and Deep-Augment [14]. 2.