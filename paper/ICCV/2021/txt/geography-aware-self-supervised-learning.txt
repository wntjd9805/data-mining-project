Abstract
Contrastive learning methods have signiﬁcantly nar-rowed the gap between supervised and unsupervised learn-ing on computer vision tasks. In this paper, we explore their application to geo-located datasets, e.g. remote sensing, where unlabeled data is often abundant but labeled data is scarce. We ﬁrst show that due to their different char-acteristics, a non-trivial gap persists between contrastive and supervised learning on standard benchmarks. To close the gap, we propose novel training methods that exploit the spatio-temporal structure of remote sensing data. We lever-age spatially aligned images over time to construct tempo-ral positive pairs in contrastive learning and geo-location to design pre-text tasks. Our experiments show that our proposed method closes the gap between contrastive and supervised learning on image classiﬁcation, object detec-tion and semantic segmentation for remote sensing. More-over, we demonstrate that the proposed method can also be applied to geo-tagged ImageNet images, improving down-stream performance on various tasks. 1.

Introduction
Inspired by the success of self-supervised learning meth-ods [2, 12], we explore their application to large-scale re-mote sensing datasets (satellite images) and geo-tagged nat-ural image datasets. It has been recently shown that self-supervised learning methods perform comparably well or even better than their supervised learning counterpart on im-age classiﬁcation, object detection, and semantic segmenta-tion on traditional computer vision datasets [20, 9, 12, 2, 1].
However, their application to remote sensing images is largely unexplored, despite the fact that collecting and la-beling remote sensing images is particularly costly as anno-tations often require domain expertise [33, 15, 4].
In this direction, we ﬁrst experimentally evaluate the per-*Equal Contribution. Contact: {kayush, buzkent}@cs.stanford.edu formance of an existing self-supervised contrastive learning method, MoCo-v2 [12], on remote sensing datasets, ﬁnding a performance gap with supervised learning using labels.
For instance, on the Functional Map of the World (fMoW) image classiﬁcation benchmark [4], we observe an 8% gap in top 1 accuracy between supervised and self-supervised methods.
To bridge this gap, we propose geography-aware con-trastive learning to leverage the spatio-temporal structure of remote sensing data. In contrast to typical computer vi-sion images, remote sensing data are often geo-located and might provide multiple images of the same location over time. Contrastive methods encourage closeness of represen-tations of images that are likely to be semantically similar (positive pairs). Unlike contrastive learning for traditional computer vision images where different views (augmenta-tions) of the same image serve as a positive pair, we pro-pose to use temporal positive pairs from spatially aligned images over time. Utilizing such information allows the representations to be invariant to subtle variations over time (e.g., due to seasonality). This can in turn result in more discriminative features for tasks focusing on spatial vari-ation, such as object detection or semantic segmentation (but not necessarily for tasks involving temporal variation such as change detection). In addition, we design a novel unsupervised learning method that leverages geo-location information, i.e., knowledge about where the images were taken. More speciﬁcally, we consider the pretext task of predicting where in the world an image comes from, similar to [10, 11]. This can complement the information-theoretic objectives typically used by self-supervised learning meth-ods by encouraging representations that reﬂect geographical information, which is often useful in remote sensing tasks.
Finally, we integrate the two proposed methods into a single geography-aware contrastive learning objective.
Our experiments on the functional Map of the World [4] dataset consisting of high spatial resolution satellite images show that we improve MoCo-v2 baseline signiﬁcantly. In particular, we improve it by ∼ 8% classiﬁcation accuracy
Figure 1: Left shows the original MoCo-v2 [2] framework. Right shows the schematic overview of our approach. when testing the learned representations on image classi-ﬁcation, ∼ 2% AP on object detection, ∼ 1% mIoU on semantic segmentation, and ∼ 3% top-1 accuracy on land cover classiﬁcation.
Interestingly, our geography-aware learning can even outperform the supervised learning coun-terpart on temporal data classiﬁcation by ∼ 2%. To fur-ther demonstrate the effectiveness of our geography-aware learning approach, we extract the geo-location information of ImageNet images using FLICKR API similar to [6], which provides us with a subset of 543,435 geo-tagged Im-ageNet images. We extend the proposed approaches to geo-located ImageNet, and show that geography-aware learning can improve the performance of MoCo-v2 by ∼ 2% on im-age classiﬁcation, showing the potential application of our approach to any geo-tagged dataset. Figure 1 shows our contributions in detail. 2.