Abstract
This paper considers matching images of low-light scenes, aiming to widen the frontier of SfM and visual
SLAM applications. Recent image sensors can record the brightness of scenes with more than eight-bit precision, available in their RAW-format image. We are interested in making full use of such high-precision information to match extremely low-light scene images that conventional meth-ods cannot handle. For extreme low-light scenes, even if some of their brightness information exists in the RAW for-mat images’ low bits, the standard raw image processing on cameras fails to utilize them properly. As was recently shown by Chen et al.[14], CNNs can learn to produce im-ages with a natural appearance from such RAW-format im-ages. To consider if and how well we can utilize such infor-mation stored in RAW-format images for image matching, we have created a new dataset named MID (matching in the dark). Using it, we experimentally evaluated combinations of eight image-enhancing methods and eleven image match-ing methods consisting of classical/neural local descriptors and classical/neural initial point-matching methods. The results show the advantage of using the RAW-format images and the strengths and weaknesses of the above component methods. They also imply there is room for further research. 1.

Introduction
Structure-from-motion (SfM) [24, 58] and visual SLAM (simultaneous localization and mapping) [38, 53] have been used for real-world applications for a while. The main-stream methods use point correspondences between multi-ple views of a scene. They first detect keypoints and ex-tract the descriptor of the local feature at each keypoint
[31, 35, 2, 44]. They then find initial point correspondences between images and eliminate outliers from them, finally estimating the geometric parameters such as camera poses, etc.
SfM and visual SLAM have the potential to widen their application fields. One important target is the application to extremely low-light environments, such as outdoor scenes at night under moonlight or indoor scenes with insufficient illumination. Making it possible to use SfM and visual
SLAM in these environments is essential for real-world ap-plications, such as autonomous vehicles that can operate at night.
Owing to the advancement of image sensors, they can record incoming light with more than eight bits (e.g., 14 bits). However, standard raw image processing employed on many cameras cannot make full use of the information existing in the lower bits of the sensor signal; it reduces mosaic artifacts on the sensor signal, adjusts the white bal-ance and contrast, and then converts the processed signal into the standard format of eight-bit RGB images (we will refer to this raw image processing as RIP in this paper).
This limitation arguably comes from the requirement for versatility against all sorts of scenes with various lighting conditions in addition to reducing the number of bits. In extreme low-light scenes, even when some details of the scenes’ brightness are stored in the low bits of their RAW signals, the standard RIP often yields mostly black images.
The study of SID (see-in-the-dark) [14] well proves such limitation of the image pipeline, in which the authors show that a CNN can learn to convert such RAW-format images of dark scenes into brightened images with a natural appear-ance.
It is very likely that we can do the same with SfM and visual SLAM applied to low-light scenes, i.e., extracting the information present in the lower bits of the RAW signals to make SfM/visual SLAM work. The question is how to
It is noteworthy that the goal is not to generate do this. natural looking bright images as SID does but to achieve the optimal performance for SfM and visual SLAM.
There are potentially several directions to achieve the goal. One is to develop a keypoint detector and a feature descriptor that work directly on the RAW-format images.
Even if keypoint detectors and descriptors are not good
enough, it could be possible to attain the necessary level of matching performance by strengthening the subsequent steps in the pipeline. Recently, CNNs have been applied to these steps, leading to promising results, such as outlier re-moval in the initial correspondences [37, 12] and establish-ing initial matching [45]. In parallel to these, the applica-tion of image enhancement methods for RAW-format low-light images in a pre-processing stage of image matching could be useful, e.g., SID [14] and others [13, 57]. Methods for more general image restoration would be applied to the
RAW-format images [63, 29].
As above, we can think of multiple different approaches to making SfM and visual SLAM methods applicable to low light environments. To promote further studies, we need a dataset to evaluate the above approaches in a multi-faceted fashion. Aiming at widening their application field toward lower-light scenes, it is necessary to examine how underex-posed the image will be that each approach can deal with.
There is currently no dataset that can be used for this pur-pose. Considering these, we create a dataset having the fol-lowing features:
• To examine each method’s limit with underexposed images, we acquire multiple RAW-format images at each scene’s position with 48 = (6 shutter speeds × 8 ISO settings) exposure settings ranging from ex-treme to mildly underexposure settings. The camera is mounted on a tripod while capturing all the images.
• We additionally provide long-exposure images, using which as the ground truth, one can evaluate image restoration methods on the task of estimating it from one of the underexposed images.
• The current standard for the evaluation of image matching methods is to measure the accuracy of the downstream task, i.e., the estimation of geometric pa-rameters, as was pointed out in recent studies [27].
Therefore, we acquire images from two positions to form stereo pairs for each scene along with their ground truth relative pose. To obtain the ground truth pose, we capture a good quality image with a long-exposure setting for each scene position.
• The dataset contains diverse scenes consisting of 54 outdoor and 54 indoor scenes.
Using this dataset, we experimentally evaluate several i.e., existing component methods for the SfM pipeline, detecting keypoints and extracting descriptors [31], find-ing initial point correspondences, and removing outliers from them [20, 12, 45]. We choose classical methods and learning-based methods for each. We also evaluate the effectiveness of image enhancement, including classi-cal image-enhancing methods with/without denoising [16], and a CNN-based method [14, 62]. The results show the importance of using the RAW-format images instead of us-ing the processed images by the standard RIP. They further provide the strengths and weaknesses of the above compo-nent methods, also showing that there is room for further improvement. 2.