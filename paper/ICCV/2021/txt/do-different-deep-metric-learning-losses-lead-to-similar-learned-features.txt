Abstract
Recent studies have shown that many deep metric learn-ing loss functions perform very similarly under the same experimental conditions. One potential reason for this un-expected result is that all losses let the network focus on similar image regions or properties. In this paper, we in-vestigate this by conducting a two-step analysis to extract and compare the learned visual features of the same model architecture trained with different loss functions: First, we compare the learned features on the pixel level by corre-lating saliency maps of the same input images. Second, we compare the clustering of embeddings for several image properties, e.g. object color or illumination. To provide in-dependent control over these properties, photo-realistic 3D car renders similar to images in the Cars196 dataset are generated. In our analysis, we compare 14 pretrained mod-els from a recent study and find that, even though all mod-els perform similarly, different loss functions can guide the model to learn different features. We especially find differ-ences between classification and ranking based losses. Our analysis also shows that some seemingly irrelevant prop-erties can have significant influence on the resulting em-bedding. We encourage researchers from the deep metric learning community to use our methods to get insights into the features learned by their proposed methods.
Figure 1. Given the standard DML setting with a neural network that maps input images to an embedding space (grey box), we pro-pose two analysis methods. First, we identify pixels that are im-portant for the network to create the embedding. We then com-pare them qualitatively and quantitatively between loss functions.
Second, we investigate the influence of image properties on the clustering behavior in the embedding space and compare them be-tween loss functions. 1.

Introduction
In deep metric learning (DML), a neural network is trained to map input images to ùëö-dimensional embedding vectors, that should be close to each other if the corre-sponding inputs share a given class. Thus, the network has to learn to extract discriminating input features to embed an image. Many loss functions have been introduced that can be categorized into ranking based losses [12], classi-fication based losses [47], and hybrid methods combining both approaches [13]. Ranking based losses compare pairs, triplets, or higher-order tuples of data points to calculate a loss. Classification based methods usually learn one or multiple class representations and train the network to map inputs to the corresponding class embeddings.
In recent studies, different DML loss functions were shown to lead to similar test performances if compared fairly [23, 26]. Musgrave et al. [23] identify flaws in the evaluation settings of many DML papers and conduct a fair comparison between DML methods by testing several com-mon loss functions with the same benchmark datasets, ar-chitecture, and test metrics. Their study finds very similar
In general, re-performances for all of the tested losses. search has shown that even with similar performance, neu-ral networks might learn to focus on different [5] and some-times even undesired input features [18] to form an output.
In this paper, we analyze and compare what features are paid attention to by neural networks trained with common
DML loss functions. We propose two new analysis methods to get insights into the underlying processes of the network (see Figure 1) and apply them to the 14 pretrained models provided by Musgrave et al. (shown in Table 1).
The first proposed analysis method adapts a gradient-based explanation approach to DML, highlighting image pixels that lead the network to output the image represen-tation [30]. Such visualizations can be used to make qual-itative statements about the learned features on pixel level.
Quantifying differences between loss functions is then pos-sible by computing metrics inspired by the visual saliency literature [19, 25]. In our experiments, we identify a large difference between classification and ranking based loss functions on the Stanford Online Products dataset [33].
Our second proposed analysis method measures the in-fluence of image properties, e.g. the rotation or color of an object, on the embeddings. Usually in DML, networks learn to differentiate one specific property, e.g. the car model for the Cars196 dataset [17], such that images of the same car model have similar embeddings and different car models are farther apart in embedding space. For testing, the network‚Äôs ability to cluster new car images regarding their model is measured. Due to its training objective, other properties such as a car‚Äôs color or environmental illumination should have minimal influence on the embedding, since the dataset contains images of the same car model in different colors and in different lighting conditions. If the network makes use of a property to output an embedding, images of the same property are likely to be clustered as well, potentially less pronounced. We propose to measure the clustering be-havior of embeddings regarding different image properties to assess their importance. To ensure the properties are not correlated, we generate a large image dataset consisting of photo-realistic car renders. Since measuring the cluster-ing behavior with the common metric R-Precision depends on the number of possible property values, we propose a property-independent extension, Normalized R-Precision, that enables the comparison of multiple properties at once.
Our experiments show that properties used by the models are fairly consistent across all loss functions for our gener-ated dataset. Surprisingly, some undesired properties show significant influence on the embedding.
Our contributions are: 1. We propose two methods to analyze the learned features of DML methods, one on pixel level and one on image property level. 2. We introduce a new measure called Normalized R-Precision making it pos-sible to compare the influence of different image properties and a large dataset of 3D car renders with known properties. 3. Applying our new methods, we inspect 14 common DML loss functions and find that classification and ranking ap-proaches tend to learn different features, depending on the dataset. 4. We make our code and data available to enable researchers to better understand their proposed methods.1
The paper is structured as follows: Section 2 discusses related work and the setup of our experiments. In Section 3, we describe and apply our pixel level analysis method. The property analysis is conducted in Section 4. Section 5 and
Section 6 discuss and conclude our work. 2.