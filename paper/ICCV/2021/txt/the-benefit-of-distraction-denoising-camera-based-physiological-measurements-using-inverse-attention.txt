Abstract
Attention networks perform well on diverse computer vi-sion tasks. The core idea is that the signal of interest is stronger in some pixels (“foreground”), and by selectively focusing computation on these pixels, networks can extract subtle information buried in noise and other sources of cor-ruption. Our paper is based on one key observation: in many real-world applications, many sources of corruption, such as illumination and motion, are often shared between the “foreground” and the “background” pixels. Can we utilize this to our advantage? We propose the utility of inverse attention networks, which focus on extracting in-formation about these shared sources of corruption. We show that this helps to effectively suppress shared covari-ates and amplify signal information, resulting in improved performance. We illustrate this on the task of camera-based physiological measurement where the signal of interest is weak and global illumination variations and motion act as signiﬁcant shared sources of corruption. We perform ex-periments on three datasets and show that our approach of inverse attention produces state-of-the-art results, increas-ing the signal-to-noise ratio by up to 5.8 dB, reducing heart rate and breathing rate estimation errors by as much as 30
%, recovering subtle waveform dynamics, and generalizing from RGB to NIR videos without retraining. 1.

Introduction
Attention mechanisms have been successfully applied in many areas of machine learning and computer vi-sion [25, 45], including object detection [32], activity recog-nition [37], language tasks [1, 49], machine translation [2], and camera-based physiological measurement [5]. Atten-tion networks often perform well because they can identify pixels that are most likely to contain strong signals of in-terest. By focusing on pixels useful for the task of inter-est and ignoring the remaining regions, attention networks are often robust to diverse sources of variations in a video.
Figure 1. Temporal changes of hair (green) and skin (red) pixel in-tensities in a video are often correlated, e.g., when large head mo-tion is present. Physiological signals are very subtle and strongest in the skin but are easily corrupted. We propose an approach using the regions ignored by most attention mechanisms (such as hair) to provide estimates of these corruptions and learn a denoising map-ping to remove them from the physiological signal of interest.
In this paper, we refer to the regions containing the signal of interest as the “foreground” and the other regions as the
“background”. We focus on a counter-intuitive question – is there important information contained within the “back-ground” regions that are typically ignored by attention mod-els? And, can we exploit the information in those regions to improve the quality of estimation for the underlying signals of interest in the “foreground”? If noise or variations not related to the signal of interest are present in the video, they will likely corrupt the signal of interest. If these corruptions are random, then keeping as many “foreground” pixels as possible and ignoring the noisy “background” pixels is suf-ﬁcient for a model to work well. However, these variations are often not random, but rather they are caused by a spe-ciﬁc source which likely similarly affects multiple regions in the video.
To illustrate the effectiveness of using the inverse atten-Figure 2. Pulse and breathing signals output by a state-of-the-art CAN network and our denoising method (both shown in red). Our method produces cleaner signals, free from motion artifacts (still present in the benchmark method), better matching the ground truth signal’s (shown in black) subtle dynamics and shape. Notice the zoomed-in portions in the pulse waveforms with easily identiﬁable dicrotic notch and diastolic peaks in our outputs which are absent in the benchmark output. tion for denoising temporal signals, we focus on the predic-tion problem of camera-based physiological measurement as an exemplar application for our approach. Physiological signals derived from a video are extremely subtle and are easily corrupted by any variation in a video that may alter the recorded image intensities. Therefore, this is a good and challenging application to illustrate the denoising capability of our method. For example, large head motion will often similarly affect skin regions in the “foreground” as well as several regions in the “background”, such as the hair or the wall behind the person (see Fig. 1 for an illustration.) By using the “background” regions, not containing the signal, we can learn about the sources of these corruptions and use that information to suppress changes we are not interested in in the “foreground” pixels. We use an inverse of the at-tention mask to select the “background” regions and to learn an estimate of the corruptions present in a video.
Our application scenario is motivated by how the SARS-CoV-2 (COVID-19) pandemic has rapidly changed the face of healthcare [3, 38]. Recent research in computer vision has led to the development of camera-based physiological measurement techniques that leverage cameras and com-puter vision algorithms [40, 46, 34, 7, 48, 5]. Camera-based vital signs could improve the current telemedicine technol-ogy, and also enable applications where wearing contact devices for extended periods may be infeasible, such as long-term human-computer-interaction (HCI) studies [23], driver monitoring [30], or face anti-spooﬁng [17, 31]. Con-volutional networks currently provide state-of-the-art per-formance on heart rate (HR) and breathing rate (BR) mea-surement from video [5, 50, 18]. While the convolutional neural networks may be able to accurately learn what fea-tures in the image are important for ﬁnding the physiolog-ical signals, they may not be able to learn a good repre-sentation of all other variations which may be present in the video but are not related to the signal of interest be-cause of a wide range of factors that can constitute these corruptions. We refer to any variations not related to the physiological signals as “corruptions” because they all de-grade the signal quality.
In the context of camera-based physiology, these corruptions can be caused by head mo-tion [9], facial expressions [52], speech, ambient light varia-tions [30], video compression artifacts [50, 29], and camera sensor noise [14]. Such corruptions may also vary greatly across videos and datasets. Therefore, it is hard for any model to explicitly capture a good representation of such diverse variations and to remove them from the signals of interest. While the sources of corruptions may not be iden-tical in the “foreground” and in the “background” regions, the variations in different regions of a video are often highly correlated because they are often caused by the same source (e.g., illumination variations from a ﬂickering light bulb or video compression artifacts affecting all regions in a frame).
The key observation we make is that regions ignored by an attention mechanism in a network likely contain infor-mation about sources of corruption that are also present in the regions used by the attention mechanism to compute the physiological signals. Using these “distraction” regions that were ignored by the attention masks offers a way to estimate these variations independently for each video without mak-ing assumptions about the nature of the sources of the cor-ruptions. The only assumption we make is that most regions ignored by the attention masks do not contain the signals of interest and consequently contain the corruptions that we want to suppress. This assumption should hold true as long as the attention mechanisms are able to segment the video to some degree, which is usually the case.
We demonstrate that regions outside of the attention
mask can be used to estimate the irrelevant intensity vari-ations which corrupt the signal of interest. Once we have an estimate of those variations, we can learn a denois-ing mapping to remove them from the recovered signals.
Our approach outperforms state-of-the-art methods on three datasets across a range of HR and BR error measures and also generalizes well to new data, even data recorded with different imaging modalities, such as near-infrared (NIR), without any additional training. Our proposed approach can even recover very subtle waveform dynamics, such as the clearly visible dicrotic notch and diastolic peaks, shown in
Fig. 2, which is currently challenging for video-based meth-ods. Obtaining clean and more accurate waveforms is use-ful for determining important health metrics, such as blood pressure [8], which is infeasible with most existing meth-ods. Our method also obtained cleaner breathing signals compared to the baseline (Fig. 2). The idea of using the in-verse attention regions is likely very useful in a wide range of vision tasks, where the attention networks are used to make temporal predictions, such as activity recognition or video deblurring. However, in this work, we only focused on the physiological measurement application.
The core contributions of this paper are to: (1) pro-pose the use of inverse attention masks for generating esti-mates of variations which corrupt the signals of interest, (2) present a novel method for denoising camera-based physio-logical measurement using this approach, (3) evaluate our method on three datasets showing state-of-the-art perfor-mance on pulse and breathing measurement, (4) demon-strate that our approach generalizes to NIR data without further training. Supplementary material, including code, models, video examples, and additional experimental re-sults, are provided with this submission.1 2.