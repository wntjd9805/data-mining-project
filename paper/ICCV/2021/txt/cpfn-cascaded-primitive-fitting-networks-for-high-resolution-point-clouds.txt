Abstract
Representing human-made objects as a collection of base primitives has a long history in computer vision and reverse engineering.
In the case of high-resolution point cloud scans, the challenge is to be able to detect both large primitives as well as those explaining the detailed parts. While the classical RANSAC approach requires case-specific parameter tuning, state-of-the-art networks are lim-ited by memory consumption of their backbone modules such as PointNet++ [27], and hence fail to detect the fine-scale primitives. We present Cascaded Primitive Fitting
Networks (CPFN) that relies on an adaptive patch sam-pling network to assemble detection results of global and local primitive detection networks. As a key enabler, we present a merging formulation that dynamically aggregates the primitives across global and local scales. Our evalua-tion demonstrates that CPFN improves the state-of-the-art
SPFN performance by 13 − 14% on high-resolution point cloud datasets and specifically improves the detection of fine-scale primitives by 20 − 22%. Our code is available at: https://github.com/erictuanle/CPFN 1.

Introduction
Representing 3D shapes with a compact set of atomic primitives is a well-established idea that has been evolved over the decades [2, 23]. While the idea has been mainly exploited for machine perception in a way to parse objects, most human-made objects are indeed modeled as a com-position of geometric primitives. In CAD, modeling tech-niques such as Constructive Solid Geometry (CSG) [18] or building a binary tree of simple primitives, have been conventional practices. Hence, for scanned data of human-made objects, converting them into a form to reflect how they were modeled is important not only for the perception but also for enabling editing capabilities in downstream ap-plications. The problem of precisely fitting primitives to the input scan is, however, more challenging than coarsely parsing and abstracting the shape.
For such a model fitting problem, RANSAC [7] is the de
∗This work was partly done when E. Lê interned and M. Sung worked at Adobe Research.
Figure 1. A side-by-side comparison between SPFN [20] and our
CPFN. Our cascaded networks are designed to accurately detect and fit small primitives in a high-resolution point cloud. facto standard technique in computer vision. The algorithm of Schnabel et al. [31] or Li et al. [21] which iteratively runs
RANSAC to find fitting primitives has been implemented in popular geometry processing libraries such as CGAL [24] and applied to solve the primitive fitting problem with many real scan data. However, such an unsupervised approach of-ten suffers from the combinatorial complexity nature of the problem. From an optimization perspective, different prim-itive configurations can potentially result in similarly small fitting errors, although the iterative heuristic algorithm can-not take into account all the possible configurations. Fur-thermore, an undesired set of primitives can even result in a smaller fitting error due to noise in the input. While the
RANSAC-based approach deals with the noise to some ex-tent with some threshold parameters, the input-specific pa-rameter tuning requires substantial manual effort.
To tackle the challenge, Li et al. [20] recently proposed a supervised framework called SPFN that learns the best con-figuration of primitives for each 3D scan from a large col-lection of CAD data. Instead of directly regressing the prim-itive parameters, their network employs PointNet++ [27] as an encoder of the input point cloud and predicts per-point information, including association from a point to a primi-tive, primitive type, and surface normal. A subsequent dif-ferentiable module computes the best primitive parameters minimizing the fitting error through an analytic formulation.
While SPFN [20] demonstrated successful results, the challenge remains in handling high-resolution data. Even affordable 3D scanners are now capable of capturing local geometric details with high-resolution (e.g., point sets with 100k+ points). However, efficiently processing the high-resolution 3D data in neural networks raises a memory limit issue with consumer GPUs. Even with a simple point cloud processing architecture such as PointNet [26], the order of 10k points is the limit in training, whereas scans may in-clude points in the order of 100k to 1M. Downsampling the input point cloud results in information loss for fine-scale details and thus fails to fit small primitives (see Figure 1 for example results with missed features by SPFN on typical high-resolution scans).
In this work, we propose a novel framework named Cas-caded Primitive Fitting Networks (CPFN), which is particu-larly developed to capture local details in scans and fit small primitives. Our framework cascades two fitting networks: one for processing the entire input point cloud, and the other for processing local patches of the input. Both of them are
SPFNs [20] but trained separately with global/local input data. Our design breaks the problem into three steps: first, adaptively sampling patches in regions of small details; suit-ably regressing primitives in (detected) regions of fine de-tails; and merging the global and local primitives to get a multi-scale output.
The framework includes a patch selection network trained to detect regions with small primitives so that lo-cal patches fed to the local fitting network can be sampled in those regions at test time. Our key idea is in the merg-ing algorithm that aggregates the per-point outputs of both networks and produces the final fitted primitives. The merg-ing process is formulated as a binary program, although we empirically found that a Hungarian algorithm [17] can ob-tain a near-optimum solution in most cases. In experiments, we demonstrate that our cascaded networks outperform a single SPFN trained with downsampled point clouds in fit-ting primitives in all scales with a performance boost of 13 − 14%. The improvement reaches 20 − 22% for smaller primitives. We also show that the fitting performance of the local fitting network can be improved when it takes global contextual information of the entire input point cloud from the global fitting network.
In summary, our key contributions are as follows.
• We propose CPFN, a primitive fitting framework lever-aging two cascaded networks to adaptively detect both small and large primitives.
• Our merging algorithm ensembles the per-point infor-mation predicted by the two networks efficiently and produces the final fitted primitives.
• Our experiments demonstrate that the performance of the local fitting network benefits from feeding contex-tual information learned by the global fitting network. 2.