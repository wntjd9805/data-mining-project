Abstract
Most monocular depth sensing methods use convention-ally captured images that are created without considering scene content. In contrast, animal eyes have fast mechani-cal motions, called saccades, that control how the scene is imaged by the fovea, where resolution is highest. In this pa-per, we present the SaccadeCam framework for adaptively distributing resolution onto regions of interest in the scene.
Our algorithm for adaptive resolution is a self-supervised network and we demonstrate results for end-to-end learning for monocular depth estimation. We also show preliminary results with a real SaccadeCam hardware prototype. 1.

Introduction
Deep depth estimation from a single view has been ef-fective at demonstrating the rich geometric cues available in an image [51, 49, 36, 52, 10]. Additionally, these re-sults are improved by using other cues, such as sparse LI-DAR or stereo measurements [55, 66, 35, 6]. Our key idea is to notice that most previous monocular approaches as-sume a nearly equal distribution of sensor pixels across the camera’s field-of-view (FOV). In contrast, animal eyes dis-tribute resolution unevenly using fast, mechanical motion, or saccades, that change where the eye’s fovea views the scene with high acuity. In this paper, we present Saccade-Cam, a new algorithmic and hardware framework for vi-sual attention control that automatically distributes resolu-tion onto a scene to improve monocular depth estimation. 1.1. Why Leverage Attention for Depth Sensing?
Many methods seek to replicate the biological advan-tages of attention, such as computational efficiency. How-ever, most efforts apply attention within network training and testing, after images have been captured [48, 59, 34, 63, 29]. Our framework complements existing attention-based learning, since SaccadeCam leverages visual atten-tion to distribute resolution during image capture, and deep attention mechanisms can still be applied after the capture of a SaccadeCam image. Since SaccadeCam can leverage
Figure 1: Our method learns to distribute resolution onto re-gions that improve self-supervised monocular depth estima-tion while using the same number of pixels as conventional equiangular cameras. attention during image capture, it can extract novel efficien-cies, particularly for bandwidth of image data. The potential for bandwidth reduction is important — Marr observed that to have foveal resolution everywhere “...would be wasteful, unnecessary and in violation of our own experience as per-ceivers...” [39]. SaccadeCam extracts the biological band-width advantages of attention, which impacts platforms that need perception within strict budgetary constraints, such as small robots and long-range drones. We show SaccadeCam results for distributing visual attention (using the proxy of image resolution) to improve depth estimation. Our con-tributions are:
• We define a new problem of distributing image resolu-tion under a fixed camera bandwidth around the scene with the goal of succeeding at depth estimation (Sect. 2 and Table 2).
• We design an end-to-end network that controls reso-lution distribution, showing that SaccadeCam images outperform conventional distribution of resolution and can detect important objects for robot navigation, such as poles, signs and distant vehicles (Sect. 3, Table 3 and Fig. 3, Sect. 5 Fig. 4).
• We validate our method on a real hardware prototype that images multiple fovea per frame. We also present a generalized selection algorithm to extract discrete fovea from the attention mask. (Sect. 5).
Method (with few examples)
Deep Attention Mechanisms [59, 62, 29]
Compressive Imaging [14]
Monocular Depth Estimation [51, 25]
Monocular Guided Upsampling [11, 19]
Adaptive Guided Upsampling [4, 6]
End-to-end Optics [9]
Learned Zoom [65]
Adaptive Zoom [56]
SaccadeCam (Ours)
Adaptive
✓
×
×
×
✓
×
×
✓
✓
Test Input
Mono/Mono+X
Mono/Mono+X
Mono
Mono+X
Mono+X
Mono
Mono
Mono
Mono
Depth Recovery Attention during image capture
✓
✓
✓
✓
✓
✓
×
×
✓
×
×
×
×
×
×
×
×
✓
Self/Semi/Guided
All
All
All
Semi/Guided
Guided
Guided
Guided
Self
Self
Table 1: SaccadeCam Framework vs. Other Alternatives: To our knowledge, ours is the only work that provides adaptive, monocular depth estimation by manipulating attention inside the camera, during image capture, while being self-supervised. 1.2.