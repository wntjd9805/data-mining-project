Abstract
Instance segmentation can detect where the objects are in an image, but hard to understand the relationship be-tween them. We pay attention to a typical relationship, relative saliency. A closely related task, salient object detection, predicts a binary map highlighting a visually salient region while hard to distinguish multiple objects. Di-rectly combining two tasks by post-processing also leads to poor performance. There is a lack of research on relative saliency at present, limiting the practical applications such as content-aware image cropping, video summary, and im-age labeling.
In this paper, we study the Salient Object Ranking (SOR) task, which manages to assign a ranking order of each de-tected object according to its visual saliency. We propose the first end-to-end framework of the SOR task and solve it in a multi-task learning fashion. The framework han-dles instance segmentation and salient object ranking si-multaneously. In this framework, the SOR branch is inde-pendent and flexible to cooperate with different detection methods, so that easy to use as a plugin. We also intro-duce a Position-Preserved Attention (PPA) module tailored for the SOR branch. It consists of the position embedding stage and feature interaction stage. Considering the im-portance of position in saliency comparison, we preserve absolute coordinates of objects in ROI pooling operation and then fuse positional information with semantic features in the first stage. In the feature interaction stage, we ap-ply the attention mechanism to obtain proposals’ contextu-alized representations to predict their relative ranking or-ders. Extensive experiments have been conducted on the
ASR dataset. Without bells and whistles, our proposed method outperforms the former state-of-the-art method sig-nificantly. The code will be released publicly available on https://github.com/EricFH/SOR. 1.

Introduction
Instance segmentation has made tremendous progress in recent years [14, 28]. To get a deeper understanding of images, exploring the relationship between objects af-*Corresponding author.
Figure 1. The salient object ranking (SOR) task assigns a ranking order to each detected object according to their visual saliency.
Instance segmentation can detect objects but can not obtain the re-lationship between them. In the meantime, salient object detection can highlighting the most attractive regions but can not distinguish them. (Best viewed in color.) ter detecting their locations is meaningful for researchers.
A typical relationship is relative saliency that compares which one is more attractive than another. Salient Ob-ject Detection (SOD) is a closely related task aiming to locate regions where attract human visual attention. Most works formulate this task as a pixel-wise binary predic-tion task [54, 55, 16, 19, 43, 45, 20, 29, 26, 32, 36, 53].
Since SOD predicts all salient areas at pixel-level rather than instance-level, it has limitations distinguishing multi-ple objects in real scenes. (shown in Fig. 1)
Salient Object Ranking (SOR) is a recently proposed problem introduced by [22] handling scenes of multiple ob-jects. It assigns a unique ranking order to every detected ob-ject according to its visual saliency. The salient ranking or-ders of objects in an image reflect human attention shifting process [39], which helps researchers explore how humans
Figure 2. The proposed end-to-end salient object ranking (SOR) architecture is based on a multi-task learning framework. Semantic features from the shared feature extractor are concatenated with positional coordinate maps before ROI pooling. Then detection branch (shown in the blue box) predicts instance segmentation results. The SOR branch (shown in the green box) combines semantic features with position embedding and interacts features between proposals. It employs a novel Position-Preserved Attention (PPA) module to get contextualized representations and makes the final ranking prediction via FC layers.
In the meantime, substantial down-interpret an image. stream applications are in huge demand of SOR. Represen-tative ones, such as content-aware image cropping [56, 7], image parsing [25, 40], and image captioning [50, 51], can not be well solved by employing current object detection and SOD methods.
Works on the SOR task are limited. We can categorize them into FCN-based [22, 47] and Detection-based [39].
FCN-based methods predict saliency ranking orders pixel by pixel as SOD does. Pixels in the same instance could be predicted to different ranking orders. It does not meet the requirement of SOR, which aims at assigning the same ranking order for the same object. Although complicated post-processing cooperated with other detection models can relieve this issue, the performance is unstable. Siris et al. [39] proposes a Detection-based method. It first trains a detector extracting features of each proposal. Then it combines top-down and bottom-up information with pro-posals’ features to predict their ranking orders. However, this network can not be trained end-to-end. Detection loss and SOR loss are hard to be optimized jointly. The methods mentioned above do not fully utilize positional information, which is a significant factor in ranking objects’ saliency.
That is to say, an object in the center tends to be more at-tractive than one in the corner. Also, an object with a larger scale is usually more eye-catching than a smaller one. An-other essential factor is the correlation between objects. A more attractive object will lower the visual saliency of oth-ers. (shown in Fig. 3)
In this paper, we propose an end-to-end framework for the first time of the SOR task and solve it in a multi-task learning fashion. In this framework, the detection and salient object ranking branches are parallel rather than se-quential. We can optimize SOR loss and detection loss jointly to achieve better performance. The SOR branch completes an independent ranking prediction task. So it could be considered as a flexible plugin with diverse de-tection methods.
We further introduce the Position-Preserved Attention (PPA) module tailored for the SOR branch. PPA consists of the position embedding stage and the feature interaction stage. In the position embedding stage, besides semantic features extracted from ROI pooling [38, 14], positional in-formation of each object is considered. Both absolute po-sitions in the image and the relative position between each other help rank objects’ saliency. However, the common
ROI pooling operation will crop object-level features from the whole feature map and lost objects’ positional informa-tion. To address this issue, we concatenate positional coor-dinate maps with the whole feature map before ROI pool-ing. Then we pass them into ROI pooling together. This position-preserved pooling process finally obtains the cor-responding positional information of each object. After fus-ing semantic features and position embedding, we get richer features of each object.
Since SOR aims at obtaining relative saliency ranking between each other rather than a specific salient label, the feature interaction stage is of vital importance. In this stage, the attention mechanism is utilized to make objects receive other objects’ features and obtain contextualized represen-tations to predict their relative ranking orders. We employ the encoder of Transformer [41] to implement the attention mechanism. Each object-level feature is considered as a vi-sual token, which is the input of the encoder of Transformer.
Extensive experiments have been conducted on the ASR dataset [39], a recently proposed salient object ranking dataset. Without bells and whistles, our method outper-forms the former state-of-the-art method significantly.
In summary, the main contributions of this work include:
• We propose the first end-to-end framework of the SOR task and solve it in a multi-task learning fashion. We can optimize SOR loss and detection loss jointly to achieve better performance. The SOR branch is flexi-ble to cooperate with other detection methods.
• We introduce a Position-Preserved Attention (PPA) module tailored for the SOR branch, which preserves absolute coordinates of objects in ROI pooling opera-tion and then fuses positional information with seman-tic features. In the feature interaction stage, an atten-tion mechanism is applied between each object to ob-tain contextualized representations.
• Our method outperforms the former state-of-the-art method significantly on the ASR dataset. It can serve as a strong baseline to facilitate future research on
SOR. 2.