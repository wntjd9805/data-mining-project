Abstract
Self-attention networks have revolutionized natural lan-guage processing and are making impressive strides in im-age analysis tasks such as image classification and object detection. Inspired by this success, we investigate the ap-plication of self-attention networks to 3D point cloud pro-cessing. We design self-attention layers for point clouds and use these to construct self-attention networks for tasks such as semantic scene segmentation, object part segmentation, and object classification. Our Point Transformer design im-proves upon prior work across domains and tasks. For ex-ample, on the challenging S3DIS dataset for large-scale se-mantic scene segmentation, the Point Transformer attains an mIoU of 70.4% on Area 5, outperforming the strongest prior model by 3.3 absolute percentage points and crossing the 70% mIoU threshold for the first time. 1.

Introduction 3D data arises in many application areas such as au-tonomous driving, augmented reality, and robotics. Unlike images, which are arranged on regular pixel grids, 3D point clouds are sets embedded in continuous space. This makes 3D point clouds structurally different from images and pre-cludes immediate application of deep network designs that have become standard in computer vision, such as networks based on the discrete convolution operator.
A variety of approaches to deep learning on 3D point clouds have arisen in response to this challenge. Some vox-elize the 3D space to enable the application of 3D discrete convolutions [23, 32]. This induces massive computational and memory costs and underutilizes the sparsity of point sets in 3D. Sparse convolutional networks relieve these limi-tations by operating only on voxels that are not empty [9, 3].
Other designs operate directly on points and propagate in-formation via pooling operators [25, 27] or continuous con-volutions [42, 37]. Another family of approaches connect the point set into a graph for message passing [44, 19].
In this work, we develop an approach to deep learning on point clouds that is inspired by the success of transformers
Figure 1. The Point Transformer can serve as the backbone for var-ious 3D point cloud understanding tasks such as object classifica-tion, object part segmentation, and semantic scene segmentation. in natural language processing [39, 45, 5, 4, 51] and image analysis [10, 28, 54]. The transformer family of models is particularly appropriate for point cloud processing because the self-attention operator, which is at the core of trans-former networks, is in essence a set operator: it is invariant to permutation and cardinality of the input elements. The application of self-attention to 3D point clouds is therefore quite natural, since point clouds are essentially sets embed-ded in 3D space.
We flesh out this intuition and develop a self-attention layer for 3D point cloud processing. Based on this layer, we construct Point Transformer networks for a variety of 3D understanding tasks. We investigate the form of the self-attention operator, the application of self-attention to local neighborhoods around each point, and the encoding of po-sitional information in the network. The resulting networks are based purely on self-attention and pointwise operations.
We show that Point Transformers are remarkably effec-tive in 3D deep learning tasks, both at the level of detailed object analysis and large-scale parsing of massive scenes.
In particular, Point Transformers set the new state of the art on large-scale semantic segmentation on the S3DIS dataset (70.4% mIoU on Area 5), shape classification on Model-Net40 (93.7% overall accuracy), and object part segmenta-tion on ShapeNetPart (86.6% instance mIoU). Our full im-plementation and trained models will be released upon ac-ceptance. In summary, our main contributions include the following.
• We design a highly expressive Point Transformer layer for point cloud processing. The layer is invariant to permutation and cardinality and is thus inherently suited to point cloud processing.
• Based on the Point Transformer layer, we construct high-performing Point Transformer networks for clas-sification and dense prediction on point clouds. These networks can serve as general backbones for 3D scene understanding.
• We report extensive experiments over multiple do-mains and datasets. We conduct controlled studies to examine specific choices in the Point Transformer de-sign and set the new state of the art on multiple highly competitive benchmarks, outperforming long lines of prior work. 2.