Abstract
Pedestrian trajectory prediction is challenging due to its uncertain and multimodal nature. While generative adver-sarial networks can learn a distribution over future trajec-tories, they tend to predict out-of-distribution samples when the distribution of future trajectories is a mixture of multi-ple, possibly disconnected modes. To address this issue, we propose a multi-generator model for pedestrian trajectory prediction. Each generator specializes in learning a distri-bution over trajectories routing towards one of the primary modes in the scene, while a second network learns a cat-egorical distribution over these generators, conditioned on the dynamics and scene input. This architecture allows us to effectively sample from specialized generators and to sig-niﬁcantly reduce the out-of-distribution samples compared to single generator methods. 1.

Introduction
To safely navigate through crowded scenes, intelligent agents such as autonomous vehicles or social robots need to anticipate human motion. Predicting human trajectories is particularly difﬁcult because future actions are multimodal: given a past trajectory, there exist several plausible future paths, depending on the scene layout and social interactions among pedestrians. Recent methods leverage conditional generative adversarial networks (GANs) [14, 16, 34, 22] to learn a distribution over trajectories. These methods present signiﬁcant improvements over deterministic models [1, 18].
However, they suffer from limitations observed in the con-text of GANs [38, 20] that manifest in mode collapse or pre-diction of undesired out-of-distribution (OOD) samples, ef-fectively yielding non-realistic trajectories. Mode collapse can be tackled with best-of-many sampling [6] or regular-izations of the latent space [22, 2] but the problem of OOD samples remains unsolved. These OOD samples are par-ticularly problematic in real-world applications where high
*Equal contribution. precision of predictions matters. Imagine an autonomous vehicle driving through crowded environments and interact-ing with pedestrians. To ensure the safety of pedestrians, the vehicle needs to anticipate their future motion and react ac-cordingly, e.g., brake or turn. As a consequence, unrealistic predictions may lead to sudden reactions that pose danger to other trafﬁc participants.
To understand why OOD samples are produced by state-of-the-art GAN methods, we need to understand the un-derlying geometry of the problem. Consider a pedestrian reaching the junction in Figure 1a. There are three plausible main directions that the pedestrian can take, namely, going straight, left, or right. Furthermore, there exist several paths that route towards these directions. While all recent works agree that such trajectory distribution is inherently multi-modal, we further observe that the distribution consists of several disconnected modes. Each mode is shown in Fig-ure 1c in different colors, and as we can observe, the three modes are disconnected in space. Existing GAN models do not consider this property, and hence generate undesirable
OOD samples in between modes, visualized as red trajec-tories in Figure 1b. This is an inherent problem of single-generator GANs, as they cannot learn a mapping from a continuous latent space to a disconnected, multimodal tar-get distribution [38].
In this paper, we address this issue and explicitly focus on learning such disconnected multimodal distributions for pedestrian trajectory prediction. To this end, we propose a novel multi-generator GAN that treats the multimodal target distribution as a mixture of multiple continuous trajectory distributions by optimizing a continuous generator for each mode. Unlike previous multi-generator models [19, 7], our model needs to adapt to the selection of generators to differ-ent scenes, e.g., two- and three-way junctions. For this, we employ a ﬁxed number of generators and allow the model to learn the necessary number of modes directly from vi-sual scene information. Towards this end, we train a sec-ond module estimating the categorical probability distribu-tion over the individual generators, conditioned on the input observations. At test time, we ﬁrst select a speciﬁc gener-!"
!"
!"#
!"%
!"$ (a) Target Distribution pD (b) Single Generator distribution pG (c) Multi-generator distribution
Figure 1: The ﬁgure illustrates a pedestrian reaching a junction (black) including (a) the multimodal target distribution of future paths, (b) learned future trajectory distribution by a single generator GAN predicting out-of-distribution samples (red), and (c) learned trajectory distribution of multi-generator mixture model. ator based on its categorical probability and sample then trajectories specialized to that particular mode present in the scene. For measuring the quality of the predictions, we extend the concept of traditional L2 error measures with a precision and recall metric [36, 23]. Our experimental eval-uation shows that our proposed model overcomes state-of-the-art and single-generator methods when comparing the behavior of predicting OOD samples.
We summarize our main contributions as follows: (i) we discuss the limitations of single generator GANs and propose a novel multi-generator method that learns a mul-timodal distribution over future trajectories, conditioned on the visual input. To this end, we (ii) present a model that estimates a conditional distribution over the generators and elaborate a training scheme that allows us to jointly train our model end-to-end. Finally, (iii) we introduce recall and pre-cision metrics for pedestrian trajectory prediction to mea-sure the quality of the entire predictive distribution, and in particular OOD samples. We demonstrate our method’s ef-ﬁciency and robustness through extensive ablations. The source code of the model and experiments is available: https://github.com/selﬂein/MG-GAN. 2.