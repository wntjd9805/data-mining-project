Abstract
Image
Prediction
Ground Truth
In this work, we devote to address the challenging problem of scene parsing. It is well known that pixels in an image are highly correlated with each other, especially those from the same semantic region, while treating pixels independently fails to take advantage of such correlations.
In this work, we treat each respective region in an image as a whole, and capture the structure topology as well as the affinity among different regions. To this end, we first divide the entire feature maps to different regions and extract respective global features from them. Next, we construct a directed graph whose nodes are regional features, and the bi-directional edges connecting every two nodes are the affinities between the regional features they represent. After that, we transfer the affinity-aware nodes in the directed graph back to corresponding regions of the image, which helps to model the region dependencies and mitigate unrealistic results.
In addition, to further boost the correlation among pixels, we propose a region-level loss that evaluates all pixels in a region as a whole and motivates the network to learn the exclusive regional feature per class. With the proposed approach, we achieves new state-of-the-art segmentation results on PASCAL-Context,
ADE20K, and COCO-Stuff consistently. 1.

Introduction
Scene parsing (or semantic segmentation), as one of the most fundamental tasks in computer vision, targets at segmenting an image to different regions and assigning each region a specific class label. Parsing errors exist widely in previous methods, due to the diverse appearances and
In the complicated topology structures among objects. this paper, we propose an approach that constructs affinity dependency among different semantic regions, helps to reason global affinities among objects/stuff in the given image and mitigates the deviated segmentation results.
The scene parsing can be regarded as a pixel-level
†Henghui Ding (ding0093@ntu.edu.sg) is the corresponding author.
Figure 1: Common errors in scene parsing: “spot”, ambi-guous, and unrealistic predictions. classification task (i.e., recognition) as well as a region cluster task (i.e., segmentation). Previous works pay more attention to recognition than region cluster, resulting in
“spot” predictions, ambiguous results and unrealistic re-sults, as shown in Figure 1. Previous attempts to these issues mainly revolved around capturing large receptive fields for each pixel, like the pyramid [8, 81] and the non-local [20] receptive fields. These context methods, though build implicit connections among different pixels, aim at aggregating context for each pixel and thereby do not take advantage of the region-level correlations.
In this work, we focus more on region clustering and attribute the errors in Figure 1 to the lack of region-level constrains for each pixel and insufficient regional correlations. Concretely we boost scene parsing by ap-plying region-level constraints and establishing connections among regions. We split the feature maps to various regions and regard pixels in each respective region as a whole to explore the region-level correlations. This approach helps cluster the features from the same region and thus remove the “spot” pieces in prediction.
To this end, we first generate a coarse segmentation mask (e.g., the
prediction in Figure. 1) to define the regions in feature maps. We then propose a graph-based region affinity reasoning (GRAr) module to place region-level constraints onto these split regions. The occurrence of the error spots and ambiguous/unrealistic results is significantly reduced.
The edges are vital for determination of the connections among nodes in a graph. Unlike previous graph-based works [10, 40, 27] that learn edges from scratch, we utilize affinity information from training samples via statistics.
Different affinities among semantic classes are observed, as some objects frequently co-occur in images, while some objects never appear together. Therefore, it is advantageous to model the complicated affinities and spatial dependencies among different objects. However, the class-affinity has not been well investigated in previous graph methods.
Here, we calculate the coexistence times between each two classes and list them as a confusion matrix to represent the affinities. For each category, its supporters and opponents are achieved by examining the confusion matrix, intuitively watching who supports and who suppresses its existence.
For instance, the class “pillow” in ADE20K [83], has supporters of “bed” and “sofa” and opponent of “bus”.
Using these category affinity information, we capture the topology structure among different regions and the affinity dependency of different categories. A directed graph is constructed then, in which each node represents a semantic region and each edge represents the directed affinity con-nection between the two nodes.
Furthermore, we propose a semantic region loss to
From the facilitate the region-level feature clustering. discussion in [4], the training objectives of FCN-based segmentation networks is always based on the assumption that pixels are independent. Whereas, it is also well known that each pixel in a given scene image is highly correlated with other pixels, and treating them independently during training fails to utilize the correlation among pixels. Some context works exploit such correlation implicitly, while their training objective functions still regard pixels as in-dependent. In this work, we propose a semantic region loss (SR-Loss) that treat pixels in the same region as a whole to explicitly boost the inner correlations. The SR-Loss formulates a region-level recognition task and prompts the network to learn the regional-level features for respective class.
The main contributions of this paper are summarized as follows:
• We propose a bi-directional graph according to statis-tics of class-correlations in training samples, and infer region affinity based on this graph.
• We provide the computed affinity-aware features for corresponding regions to improve feature representa-tions and mitigate the unrealistic results.
• We propose a semantic region loss that offers region-level recognition supervision, motivating the network to learn the discriminative region-level features for each class.
• The proposed approach achieves new state-of-the-art performance consistently on three popular scene pars-ing benchmarks, PASCAL-Context, ADE20K, and
COCO-Stuff. 2.