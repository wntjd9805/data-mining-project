Abstract
We introduce HuMoR: a 3D Human Motion Model for
Robust Estimation of temporal pose and shape. Though substantial progress has been made in estimating 3D hu-man motion and shape from dynamic observations, recov-ering plausible pose sequences in the presence of noise and occlusions remains a challenge. For this purpose, we propose an expressive generative model in the form of a conditional variational autoencoder, which learns a distribution of the change in pose at each step of a motion sequence.
Furthermore, we introduce a ﬂexi-ble optimization-based approach that leverages HuMoR as a motion prior to robustly estimate plausible pose and shape from ambiguous observations. Through extensive evaluations, we demonstrate that our model generalizes to diverse motions and body shapes after training on a large motion capture dataset, and enables motion recon-struction from multiple input modalities including 3D key-points and RGB(-D) videos.
See the project page at geometry.stanford.edu/projects/humor. 1.

Introduction
As humans, we are constantly moving in, interacting with, and manipulating the world around us. Thus, applica-tions such as action recognition [79, 80] or holistic dynamic indoor scene understanding [15] require accurate percep-tion of 3D human pose, shape, motion, contacts, and inter-action. Extensive previous work has focused on estimat-ing 2D or 3D human pose [13, 52, 53], shape [57, 26, 67], and motion [37] from videos. These are challenging prob-lems due to the large space of articulations, body shape, and appearance variations. Even the best methods struggle to accurately capture a wide variety of motions from vary-ing input modalities, producing noisy or overly-smoothed motions (especially at ground contact, i.e., footskate), and struggle with occlusions (e.g., walking behind a couch as in Fig. 1).
We focus on the problem of building a robust human mo-tion model that can address these challenges. To date, most motion models directly represent sequences of likely poses
— e.g., in PCA space [55, 77, 70] or via future-predicting autoregressive processes [75, 76, 61]. However, purely pose-based predictions either make modeling environment interactions and generalization beyond training poses dif-ﬁcult, or quickly diverge from the space of realistic mo-tions. On the other hand, explicit physical dynamics mod-els [63, 43, 69, 62, 12, 11] are resource intensive and re-quire knowledge of unobservable physical quantities. While generative models potentially offer the required ﬂexibility, building an expressive, generalizable and robust model for realistic 3D human motions remains an open problem.
To address this, we introduce a learned, autoregressive, generative model that captures the dynamics of 3D human
motion, i.e., how pose changes over time. Rather than de-scribing likely poses, the Human Motion Model for Robust
Estimation (HuMoR) models a probability distribution of possible pose transitions, formulated as a conditional vari-ational autoencoder [72]. Though not explicitly physics-based, its components correspond to a physical model: the latent space can be interpreted as generalized forces, which are inputs to a dynamics model with numerical integration (the decoder). Moreover, ground contacts are explicitly pre-dicted and used to constrain pose estimation at test time.
After training on the large AMASS motion capture dataset [51], we use HuMoR as a motion prior at test time for 3D human perception from noisy and partial observa-tions across different input modalities such as RGB(-D) video and 2D or 3D joint sequences, as illustrated in Fig. 1 (left).
In particular, we introduce a robust test-time opti-mization strategy which interacts with HuMoR to estimate the parameters of 3D motion, body shape, the ground plane, and contact points as shown in Fig. 1 (middle/right). This interaction happens in two ways: (i) by parameterizing the motion in the latent space of HuMoR, and (ii) using Hu-MoR priors in order to regularize the optimization towards the space of plausible motions.
Comprehensive evaluations reveal that our method sur-passes the state-of-the-art on a variety of visual inputs in terms of accuracy and physical plausibility of motions un-der partial and severe occlusions. We further demonstrate that our motion model generalizes to diverse motions and body shapes on common generative tasks like sampling and future prediction. In a nutshell, our contributions are:
• HuMoR, a generative 3D human motion prior modeled by a novel conditional VAE which enables expressive and general motion reconstruction and generation,
• A subsequent robust test-time optimization approach that uses HuMoR as a strong motion prior jointly solving for pose, body shape, and ground plane / contacts,
• The capability to operate on a variety of inputs, such as
RGB(-D) video and 2D/3D joint position sequences, to yield accurate and plausible motions and contacts, exem-pliﬁed through extensive evaluations.
Our work, more generally, suggests that neural nets for dynamics problems can beneﬁt from architectures that model transitions, allowing control structures that emulate classical physical formulations. 2.