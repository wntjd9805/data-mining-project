Abstract
Group activity recognition aims to understand the ac-In order to solve tivity performed by a group of people. it, modeling complex spatio-temporal interactions is the key. Previous methods are limited in reasoning on a prede-fined graph, which ignores the inherent person-specific in-teraction context. Moreover, they adopt inference schemes that are computationally expensive and easily result in the over-smoothing problem.
In this paper, we manage to achieve spatio-temporal person-specific inferences by proposing Dynamic Inference Network (DIN), which com-poses of Dynamic Relation (DR) module and Dynamic Walk (DW) module. We firstly propose to initialize interaction fields on a primary spatio-temporal graph. Within each interaction field, we apply DR to predict the relation ma-trix and DW to predict the dynamic walk offsets in a joint-processing manner, thus forming a person-specific interac-tion graph. By updating features on the specific graph, a person can possess a global-level interaction field with a local initialization. Experiments indicate both modules’ ef-fectiveness. Moreover, DIN1 achieves significant improve-ment compared to previous state-of-the-art methods on two popular datasets under the same setting, while costing much less computation overhead of the reasoning module. 1.

Introduction
Group activity recognition (GAR) aims to infer an over-all activity performed by a group of people in the scene
It has aroused research
[9, 22, 4, 45, 32, 43, 15, 48]. interests due to various applications, including surveil-lance/sports video analysis, social scene understanding, etc.
The critical problem that lies in GAR is to infer a group-level activity representation given a video clip, which asks for elaborately designed reasoning modules.
*Corresponding author. 1Codes are available at https://github.com/JacobYuan7/
DIN_GAR.
Figure 1. Examples of right set and right pass group activity.
The red bounding box annotated with a star is the person perform-ing the key action for the activity. The grey arrow denotes the key interaction linking the starred person and the semantically impor-tant person, which is always not aligned in the spatial or temporal domain. The person indices do not start from 1 because we only illustrate part of the images.
Recently proposed reasoning modules mainly incorpo-rate spatio-temporal interactive factors to get a refined ac-tivity representation. Modeling of agents’ interactions has been widely studied. The mostly adopted methods are re-current neural networks [1, 49], the attention mechanism
[41, 19] and graph neural networks (GNNs) [38, 13, 44].
GNNs have been a frequently adopted method in GAR
[32, 43, 46, 31], which performs message passing on a con-structed semantic graph and achieves competitive results on publicly available benchmarks.
However, previous methods using GNNs stick to a paradigm that models the interaction between individuals on a predefined graph as shown in Figure 2. It is a feasi-ble way but bears several drawbacks: i) Those who interact with a given person should be person-specific but not pre-defined. Like in Figure 1, a person will interact with people depending on their own context: the 8th person in the left video interacts with the 9th person who is about to spike the ball; the 10th person in the right video interacts with the 9th person who is about to set the ball. A predefined graph ii) Previous prede-can not suit every person’s inference. fined graph models infer interactions on a fully-connected
[43] or criss-cross [46, 31] graph which is shown in Figure
matrices and DW that allows for the locally initialized interaction field to update features globally. Both are proved useful by experiments.
• We prove by experiments that a small size of initialized interaction field is sufficient for existing datasets. We use a case visualization to exemplify that interaction graphs can capture the key person and key interactions, and a locally initialized interaction field can cover a global-level interaction field with proposed modules.
• DIN achieves state-of-the-art performances under the setting of the same backbone and input modality on two widely used benchmarks, while costing much less computation overhead of the reasoning module. 2.