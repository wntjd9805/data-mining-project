Abstract
Generating an interpretable and compact representation of 3D shapes from point clouds is an important and chal-lenging problem. This paper presents CSG-Stump Net, an unsupervised end-to-end network for learning shapes from point clouds and discovering the underlying constituent modeling primitives and operations as well. At the core is a three-level structure called CSG-Stump, consisting of a complement layer at the bottom, an intersection layer in the middle, and a union layer at the top. CSG-Stump is proven to be equivalent to CSG in terms of representation, therefore inheriting the interpretable, compact and editable nature of CSG while freeing from CSG’s complex tree struc-tures. Particularly, the CSG-Stump has a simple and regu-lar structure, allowing neural networks to give outputs of a constant dimensionality, which makes itself deep-learning friendly. Due to these characteristics of CSG-Stump, CSG-Stump Net achieves superior results compared to previous
CSG-based methods and generates much more appealing shapes, as confirmed by extensive experiments. 1.

Introduction
Shape is a geometric form, which helps us understand objects, surrounding environments and even the world.
Therefore shape modeling and understanding has always been a research topic in computer vision and graphics. Vari-ous representations have been developed for 3D shapes. Ex-amples are point clouds [23, 24, 35, 30], 3D voxels [34], im-plicit fields [16, 19, 5, 10, 4, 26, 17], meshes [9, 1, 32, 22, 36], and parametric representations [28, 11]. With the ad-Project Page: https://kimren227.github.io/projects/CSGStump/
† Indicates corresponding author
The work is partially supported by a joint WASP/NTU project (04INS000440C130).
Figure 1. A CAD model (a) can be represented as either a CSG representation (b) or a CSG-Stump representation (c). CSG-Stump is equivalent to CSG but frees from CSG’s irregular tree structure.
Thus CSG-Stump is more friendly to optimization formulation and network designs. Here nodes “I”, “U”, “D”, and “C” denote inter-section, union, difference, and (shape) complement, respectively. vance in 3D acquisition technologies, point clouds are eas-ily generated, but they are a set of unstructured points and lack explicit high-level structure and semantic information.
There is a great demand for converting point clouds to high-level shape representations that help recognize and under-stand the shapes, supporting the designer to re-create new products and facilitate various applications such as building
the digital twins of products and systems [15]. Particularly, reverse engineering (RE) technologies, especially recon-structing implicit or parametric (CAD) models from point clouds, have been extensively studied in engineering. How-ever, most prior art involves a tedious and time-consuming process and has difficulty in fully addressing the require-ments of the industry, which actually indicates a need of a paradigm shift.
In recent years, deep learning has achieved substantial success in areas such as computer vision and natural lan-guage processing and shows great potential in solving com-plex problems that are difficult to be solved with traditional techniques. The exploration of deep learning techniques for high-level shape reconstruction from point clouds also gains much popularity.
In particular, a few works exploit neu-ral network techniques for parsing point cloud models into their Constructive Solid Geometry (CSG) tree [13], which is a widely used 3D representation and modeling process-ing in the CAD industry. CSG models a shape by iteratively performing Boolean operations on simple parametric prim-itives, usually followed by a binary tree (see Fig. 1). Thus
CSG is an ideal model for providing compact representa-tion, high interpretability, and editability. However, the bi-nary CSG-Tree structure introduces two challenges: 1) it is difficult to define a CSG-Tree with a fixed dimension for-mulation; 2) the iterative nature of CSG-Tree construction cannot be formulated as matrix operations and a long se-quence optimization suffers varnishing gradients.
CSG-Net [28] pioneers deep learning based CSG pars-ing by employing an RNN for the tree structure prediction.
However, CSG-Net requires expensive annotations with ex-pert knowledge, which is difficult to scale. BSP-Net [3] and CVX-Net [7] propose to leverage a set of paramet-ric hyperplanes to represent a shape, but abundant hyper-planes are needed to approximate curved surfaces. Over-all, these methods are still not efficient, interpretable, or easy-editable. More importantly, these methods assume a frozen combination among predicted hyperplanes during in-ference, which effectively collapses into a fixed order of operations, limiting its theoretical representability. UCSG-Net[11] proposes the CSG-Layer to generate highly inter-pretable shapes by a multi-layer CSG-Tree iteratively, but only a few layers can be supported (five layers in UCSG-Net) because of the optimization difficulty, which greatly restricts the diversity and representation capability.
In this paper, we propose CSG-Stump, a novel and sys-tematic reformulation of CSG-Tree. CSG-Stump has a fixed tree structure of only three layers (hence the name stump).
We prove that CSG-Stump is equivalent to typical CSG-Tree in terms of representation, i.e., we can represent any complex CSG shape by our three-layer CSG-Stump (see
Fig.1). Therefore, CSG-Stump inherits the ideal character-istics of CSG-Tree, allowing highly compact, interpretable and editable shape representation while freeing from the limitations of a tree structure. Moreover, CSG-Stump gives rise to two additional advantages: 1) High representation capability. The maximum representation capability can be realistically achieved with CSG-Stump, as opposed to a conventional CSG-Tree that needs many layers for complex shapes. 2) Deep learning-friendly. The consistent structure of CSG-Stump allows neural networks to give fixed dimen-sion output, making network design much easier.
We also propose two methods to automatically con-struct CSG-Stump from unstructured raw inputs, e.g., point clouds. The first approach is to detect basic primitives using off-the-shelf methods, e.g. RANSAC [27], and then convert the problem to a Binary Programming problem to estimate the primitive constructive relations. To overcome the is-sues such as precision requirements on the inputs, manual parameter tuning and scalability due to the combinational nature of the problem, we in the second approach design a simple end-to-end network for joint primitive detection and CSG-Stump estimation (see Sec. 4). This data-driven approach is more efficient. Moreover, it can learn useful priors for primitive detection and assembly from large scale data. Notably, this network is trained in an unsupervised manner, i.e., without the need of expensive annotations of
CSG parsing trees from trained professionals. Experimen-tal results show that our CSG-Stump exhibits remarkable representation capability while preserving the interpretable, compact and editable nature of CSG representation.
In summary, the paper has the following contributions:
• We propose CSG-Stump, a three-layer reformulation of the classic CSG-Tree for a better interpretable, trainable and learning friendly representation, and provide theoret-ical proof of the equivalence between CSG-Stump and
CSG-Tree.
• We demonstrate that CSG-Stump is highly compatible with deep learning. With its help, even a simple unsu-pervised end-to-end network can perform dynamic shape abstraction.
• Extensive experiments are conducted to show that CSG-Stump achieves state-of-the-art results both quantitatively and qualitatively while allowing further edits and manip-ulation. 2.