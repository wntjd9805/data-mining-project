Abstract 1.

Introduction
This paper introduces an unsupervised loss for training parametric deformation shape generators. The key idea is to enforce the preservation of local rigidity among the generated shapes. Our approach builds on an approxi-mation of the as-rigid-as possible (or ARAP) deformation energy. We show how to develop the unsupervised loss via a spectral decomposition of the Hessian of the ARAP energy. Our loss nicely decouples pose and shape vari-ations through a robust norm. The loss admits simple closed-form expressions.
It is easy to train and can be plugged into any standard generation models, e.g., varia-tional auto-encoder (VAE) and auto-decoder (AD). Experi-mental results show that our approach outperforms exist-ing shape generation approaches considerably on public benchmark datasets of various shape categories such as hu-man, animal and bone. Our code and data are available at https://github.com/GitBoSun/ARAPReg.
This paper considers learning a parametric mesh gener-ator from a deformable shape collection with shapes that exhibit the same topology but undergo large geometric vari-ations (see examples below of a deforming human, animal, and bone). This problem arises in numerous visual comput-ing and relevant ﬁelds such as recovery of neural morpho-genesis, data-driven shape reconstruction, and image-based reconstruction, to name just a few (c.f. [54]).
Deformable shapes differ from many other visual objects (e.g., images and videos) because there are natural con-straints underlying the shape space. One such example is the local rigidity constraint; namely, corresponding surface patches among neighboring shapes in the shape space un-dergo approximately rigid transformations. This constraint manifests the preservation of geometric features (e.g., fa-cial features of humans and toes of animals) among local neighborhoods of the underlying shape space. An inter-esting problem thus is the use of this constraint to train shape generators from a collection of training shapes, where
the local rigidity constraint accurately and efﬁciently propa-gates features of the training shapes to new synthetic shapes produced by the generator.
In this paper, we study how to model the local rigidity constraint as an unsupervised loss functional for genera-tive modeling. The proposed loss can be combined with standard mesh generators such as variational auto-encoders (VAEs) [44, 28, 39, 7] and auto-decoders (ADs) [59, 61].
A key property of our loss functional is that it is consistent with other training losses. This property offers multiple ad-vantages. For example, the learned generator is insensitive to the tradeoff parameters among the loss terms. As another example, the training procedure converges faster than the setting where loss terms may compete against each other.
Our approach, called ARAPReg, builds on the es-tablished as-rigid-as-possible (or ARAP) deformation model [43, 49, 55] that measures the non-rigid deforma-tion between two shapes.
Its key ingredients include use oof the Hessian of the ARAP deformation model to de-rive an explicit regularizer for the Jacobian of the shape generator and a robust norm on the Hessian to model pose and shape variations of deformable shapes. The out-come is a simple closed-form formulation for training mesh generators. ARAPReg differs from prior works that en-force ARAP losses between synthetic shapes and a base shape [17, 27, 63], that may introduce competing losses when the underlying shape space has large deformations.
We have evaluated ARAPReg across a variety of pub-lic benchmark datasets such as DFAUST [5], SMAL [66], and an in-house benchmark dataset of Bone. The evalua-tions include both generator settings of VAE and AD. Ex-perimental results show that ARAPReg leads to consider-able performance gains across state-of-the-art deformable shape generators both qualitatively and quantitatively. As shown in Figure 1 for example, the interpolated shapes us-ing ARAPReg greatly preserve the local geometric details of the generated shapes and avoids unrealistic shape poses. main. The second category of approaches builds upon re-current procedures for geometric synthesis. This method-ology has been extensively applied for primitive-based as-sembly [26, 40, 41, 65].
[18] extended this approach to meshes, in which edge contraction operations are applied recursively. The third category of approaches [60, 51] de-forms a base mesh to generate new meshes, where the de-formation is learned from data. The last category utilizes surface parameterization [42, 31, 16, 4].
While these approaches focused on adopting generative modeling methodologies under the mesh setting, ARAPReg studies the novel problem of explicitly enforcing an ARAP loss among synthetic shapes with similar latent codes.
Regularization for generative modeling. Regularization losses have been explored in prior works for 3D generative modeling. In [36], Peebles et al. studied a Hessian regular-ization term for learning generative image models. A spec-tral regularization loss is introduced in [2] for 3D generative modeling. Several works [52, 50, 21, 3] studied geometric regularizations for image-based reconstruction. In contrast,
ARAPReg focuses on regularization terms that are consis-tent with other terms. Several other works [17, 27, 63] em-ployed ARAP losses between any synthetic shapes with a base shape. The novelty of ARAPReg is that it is consis-tent with other loss terms even when the underlying shape space presents large deformations. The reason is that the lo-cal rigidity constraint is only enforced among neighboring shapes in the underlying shape space. Our initial experi-ments show that enforcing ARAP losses between synthetic shapes and a base shape leads to worse results than dropping the ARAP losses.
Shape space modeling. Finally, ARAPReg is relevant to early works on modeling tangent spaces of shape mani-folds [23, 20, 58]. However, unlike the applications in shape interpolation [23], shape segmentation [20], and mesh-based geometric design [37, 58], ARAPReg focuses on de-vising an unsupervised loss for network training. 2.