Abstract
This paper aims to reconstruct physically plausible hand motion from monocular color images. Existing frame-by-frame estimating approaches can not guarantee the physi-cal plausibility (e.g. penetration, jittering) directly. In this paper, we embed physical constraints on the per-frame esti-mated motions in both spatial and temporal space. Our key idea is to adopt a self-supervised learning strategy to train a novel encoder-decoder, named TravelNet, whose training motion data is prepared by the physics engine using discrete pose states. TravelNet captures key pose states from hand motion sequences as compact motion descriptors, inspired by the concept of keyframes in animation. Finally, it man-ages to extract those key states out of perturbations without manual annotations, and reconstruct the motions preserv-In the experiments, ing details and physical plausibility. we show that the outputs of the TravelNet contain both ﬁn-ger synergism and time consistency. Through the proposed framework, hand motions can be accurately reconstructed and ﬂexibly re-edited, which is superior to the state-of-the-art methods. 1.

Introduction
Plausible human hand motions are of paramount impor-tance in many applications. In VR/AR, reconstructing plau-sible hand motion facilitates closer interaction. In manip-ulation planning, designing a plausible hand motion makes a bionic hand more intelligent to assist the disabled. Con-∗Corresponding author. E-mail: yangangwang@seu.edu.cn. All the authors from Southeast University are afﬁliated with the Key Laboratory of
Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China.
ventionally, high ﬁdelity hand motions are collected by data gloves [1, 2] or specialized hardware devices [4], though they are expensive and cumbersome.
In recent years, with extensive hand pose datasets, deep learning has witnessed the rapid progress of hand pose es-timation from depth images [35, 30] and monocular color images [60, 20, 58]. Theoretically, most of them can be extended to estimate motions with appropriate temporal or recurrent modules [18, 5] and plenty of motion sequences.
However, due to the diversity and composability of hand motions, it is challenging to prepare and label those se-quences ofﬂine.
To solve the difﬁculties of hand motion collection, a few methods [28, 34] attempted to reﬁne the results of per-frame estimation by avoiding high-frequency jittering. Recently,
Yang et al. [51] proposed a synthesis method that gener-ated a motion sequence by performing linear interpolation among sample states in the dataset and ﬁnds the nearest pose instances in the dataset. However, this product might not be physically plausible (shown as Fig. 7) because it can not guarantee the existence of a dense and continuous path composed of linear transients between any two pose states.
There are two main challenges to learn physically plau-sible hand motions. The ﬁrst one is that it is laborious to prepare sufﬁciently diverse as well as plausible motion data.
The second one is that it is difﬁcult to distinguish the infor-mative pose states from the jitter ones without any anno-tations.
In this paper, we focus on the problem of learn-ing physically plausible hand motions from a set of dis-crete hand pose states, which are estimated from monoc-ular color images. Our key idea is to train a novel encoder-decoder network, named TravelNet, whose training motion data is prepared with the help of a physics engine. Travel-Net manages to ﬁnd key pose states out of the perturbation and reconstruct the motion that preserves details and physi-cal plausibility.
Nevertheless, it is hard to deﬁne and annotate key pose states in a motion sequence. To solve the obstacles, we propose a novel self-supervised paradigm to perform train-ing. Speciﬁcally, we ensure that the embedded space out-putted by the encoder of TravelNet remains in the same pose manifold as the input space (as shown in Fig. 3). The de-coder is ﬁrst trained to output the motion with discrete pose states, where hand motions are guided by an inverse dy-namic solver from the physical engine. This well-trained decoder assists the training of the decoder for the next step.
Finally, the encoder and decoder are combined with ﬁne-tuning on a limited number of real hand motion sequences as a domain adaption strategy.
To ensure the physical plausibility of hand motion train-ing data, we build a hand model incorporating physical con-straints in the physical engine [3] to detect collisions and calculate inverse dynamics effortlessly. A pose state that passes the penetration validation is called a physical pose state because it is physically plausible. We then map ex-tensive hand poses from multi-modal hand datasets [53, 54, 61, 13, 57, 40, 46, 25] to the above physical pose states, which provide abundant primitives and prior knowledge for generating plausible motion sequences.
The main contributions of this work are summarized as follows.
• A novel learning paradigm that can extract key pose states robustly and reconstruct the hand motion in a self-supervised manner;
• A physical pose bound to a dynamic hand model is adopted as the compact descriptor of hand motion;
• An archive containing 2.5M physical hand poses are created for plausible motion generation by an inverse dynamic solver.
The dataset and codes will be publicly available at https:
//www.yangangwang.com. 2.