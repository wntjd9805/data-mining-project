Abstract
Deep features have been proven powerful in building ac-curate dense semantic correspondences in various previ-ous works. However, the multi-scale and pyramidal hier-archy of convolutional neural networks has not been well studied to learn discriminative pixel-level features for se-mantic correspondence. In this paper, we propose a multi-scale matching network that is sensitive to tiny seman-tic differences between neighboring pixels. We follow the coarse-to-ﬁne matching strategy and build a top-down fea-ture and matching enhancement scheme that is coupled with the multi-scale hierarchy of deep convolutional neu-ral networks. During feature enhancement, intra-scale en-hancement fuses same-resolution feature maps from multi-ple layers together via local self-attention and cross-scale enhancement hallucinates higher-resolution feature maps along the top-down pathway. Besides, we learn comple-mentary matching details at different scales thus the over-all matching score is reﬁned by features of different se-mantic levels gradually. Our multi-scale matching net-work can be trained end-to-end easily with few additional
*Corresponding author: wfge@fudan.edu.cn learnable parameters. Experimental results demonstrate that the proposed method achieves state-of-the-art perfor-mance on three popular benchmarks with high computa-tional efﬁciency. The code has been released at https:
//github.com/wintersun661/MMNet. 1.

Introduction
Finding pixel-wise correspondences between a pair of semantically similar images has been a longstanding funda-mental problem in computer vision. They have been proven useful for many tasks including optical ﬂow [16, 45, 46], ge-ometric matching [39, 32, 50], disparity estimation [36, 60], object recognition [9, 54, 58], semantic segmentation [17, 24] and etc. Due to large intra-class variations in color, scale, orientation, illumination and non-rigid deformations, the problem of semantic correspondence remains very chal-lenging. With the breakthrough in representation learning, semantic correspondence has achieved impressive improve-ments in various scenarios.
Despite that deep features have improved matching ac-curacy signiﬁcantly, the multi-scale and hierarchical struc-tures of deep convolutional neural networks have not been
It is explored thoroughly for semantic correspondence.
well-known that convolutional neural networks can extract features of different semantic levels in a bottom-up man-ner [57]. Bottom convolutional layers close to the input im-age act like low level feature descriptors, and are sensitive to colors, edges, textures and other low level statistics. Top convolutional layers contain high level semantics which are similar among neighboring points in feature maps. Meth-ods like NC-Net [40], DualRC-Net [27] and GOCor [49] use the features from the topmost layer as the feature repre-sentation. However, in semantic correspondence, the am-biguity between neighboring pixels in the topmost layer leads to inferior performance. Hyperpixel ﬂow [21] and its extension [35] combine features at different semantic lev-els to generate reliable feature representation and achieve improved results. However, they have not thoroughly ex-ploited the multi-scale and hierarchical structure of deep convolutional neural networks.
Given an image pair, human usually tends to glance at the whole images, and then compare details carefully to es-tablish semantic correspondence. It is similar to a coarse-to-ﬁne matching scheme. In a convolutional neural network, neurons in the top layers have larger receptive ﬁelds while neurons in the bottom layers have relatively small recep-tive ﬁelds, which means top layers are rich in semantics but have relatively weak localization ability while the bottom layers are strong in localization but have less semantics. It will be helpful to follow the multi-scale and hierarchical structure of convolutional neural networks to ﬁnd semantic correspondence in a coarse-to-ﬁne manner.
In this paper, we propose a new multi-scale matching network to produce reliable semantic correspondence by in-tegrating features of different semantic levels hierarchically and learn complementary matching details in a coarse-to-ﬁne manner. The multi-scale matching network consists of an encoder and a decoder. The encoder is a typical convolu-tional neural network pretrained on the ImageNet ILSVRC dataset [43].
It contains many layers to capture seman-tic information at different levels. We divide the feature maps in the encoder into ﬁve convolutional groups with re-spect to their resolutions. The decoder has two top-down hierarchical enhancement pathways across different scales.
The ﬁrst one is the feature enhancement pathway which up-samples spatially coarser, but semantically stronger feature maps and fuse them with features from lateral connections to hallucinate higher resolution features. The second one is the matching enhancement pathway that learns ﬁner and complementary matching details to enhance coarser match-ing results from a lower resolution. We start from the ﬁrst layer in the decoder to generate the coarsest matching re-sults, and upsample and enhance them with complementary matching details at different semantic levels.
To increase ﬁne-grained details in feature maps, during intra-scale feature enhancement, we fuse all feature maps from the same convolutional group in the encoder not just the feature map of the last layer. We also design a trans-former with a local self-attention mechanism to enhance features that are discriminative among neighboring pixels.
Besides, we supervise matching detail learning at different scales to make sure the network learns reliable semantic correspondences. Our multi-scale matching network adds relatively few learnable parameters with little extra compu-tational cost, and can be trained in an end-to-end manner easily.
In summary, the main contributions of this work can be summarized as follows:
• We propose a multi-scale matching network that uti-lizes the multi-scale and hierarchical structure of deep convolutional neural network to learn semantic corre-spondences in a coarse-to-ﬁne manner. Two top-down pathways in the decoder are built to couple the back-bone encoder. The feature enhancement pathway in-creases the representation power of feature maps with intra-scale enhancement and cross-scale enhancement.
The matching enhancement pathway learns matching details that are complementary to matching results from coarser levels.
• We design a novel intra-scale feature enhancement module that simultaneously fuses all the feature maps in each convolutional group and further increases the discriminative ability of the fused feature map with a local transformer.
• Experimental results demonstrate that our multi-scale matching network achieves state-of-the-art perfor-mance on multiple popular benchmarks, including PF-PASCAL [11], CUB [53] and SPair-71k [34]. 2.