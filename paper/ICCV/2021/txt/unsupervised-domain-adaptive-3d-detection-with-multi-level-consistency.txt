Abstract
Deep learning-based 3D object detection has achieved unprecedented success with the advent of large-scale au-tonomous driving datasets. However, drastic performance degradation remains a critical challenge for cross-domain deployment. In addition, existing 3D domain adaptive de-tection methods often assume prior access to the target do-main annotations, which is rarely feasible in the real world.
To address this challenge, we study a more realistic set-ting, unsupervised 3D domain adaptive detection, which only utilizes source domain annotations. 1) We first com-prehensively investigate the major underlying factors of the domain gap in 3D detection. Our key insight is that geomet-ric mismatch is the key factor of domain shift. 2) Then, we propose a novel and unified framework, Multi-Level Con-sistency Network (MLC-Net), which employs a teacher-student paradigm to generate adaptive and reliable pseudo-targets. MLC-Net exploits point-, instance- and neural statistics-level consistency to facilitate cross-domain trans-fer. Extensive experiments demonstrate that MLC-Net out-performs existing state-of-the-art methods (including those using additional target domain information) on standard benchmarks. Notably, our approach is detector-agnostic, which achieves consistent gains on both single- and two-stage 3D detectors. Code will be released. 1.

Introduction
With the prevalent use of LiDARs for autonomous vehi-cles and mobile robots, 3D object detection on point clouds has drawn increasing research attention. Large-scale 3D ob-ject detection datasets [11, 35, 3] in recent years has em-powered deep learning-based models [32, 42, 41, 21, 31, 43, 25, 34, 33, 50, 45] to achieve remarkable success. How-*Equal contribution
†Corresponding author
Figure 1: Visualization of detection results for domain adapta-tion from KITTI to Waymo dataset. Left: Predictions of base-line model trained on KITTI dataset and directly tested on Waymo dataset. The model can classify and localize the objects, but produces inaccurate box scale due to geometric mismatch. The predicted boxes are therefore noticeably smaller than the ground truth. Right: Predictions of our domain-adaptive MLC-Net, which demonstrates accurate bounding box scale even though MLC-Net is trained without access to any target domain annotations. Best viewed in color. ever, deep learning models trained on one dataset (source domain) often suffer tremendous performance degradation when evaluated on another dataset (target domain). We in-vestigate the bounding box scale mismatch problem (e.g., vehicle size in the U.S. is noticeably larger than that in Ger-many), which is found to be a major contributor to the do-main gap, in alignment with previous work [38]. This is unique to 3D detection: compared to 2D bounding boxes that can have a large variety of size, depending on the dis-tance of the object from the camera, 3D bounding boxes have a more consistent size in the same dataset, regard-less of the objects’ location relative to the LiDAR sensor.
Hence, the detector tends to memorize a narrow and dataset-specific distribution of bounding box size from the source domain (Figure 2).
Unfortunately, existing works are inadequate to address the domain gap with a realistic setup. Recent methods on domain adaptive 3D detection either require some labeled data from the target domain for finetuning or utilize some additional statistics (such as the mean size) of the target domain [38]. However, such knowledge of the target do-Figure 2: A study on the domain shift for 3D detection. Here we take KITTI as the source dataset and Waymo as the target dataset. Our key insights include: 1) distribution of object dimensions varies drastically across datasets, indicating geometric mismatch can be a key factor for the domain gap; 2) directly applying a model trained on KITTI to Waymo (referred to as the baseline in the figure) is ineffective: the model continues to predict box dimensions close to the source domain; 3) our MLC-Net is effective in addressing the geometric mismatch, and the distributions of its predictions on the target domain accurately align with the ground truth. Best viewed in color. main is not always available. In addition, popular 2D unsu-pervised domain adaptation methods that leverage feature alignment techniques [8, 29, 48, 15, 6, 14, 40, 19, 22, 17, 46, 18, 47, 37] to mitigate domain shift are not readily trans-ferable to 3D detection. While these methods are effective in handling domain gaps due to lighting, color, and texture variations, such information is unavailable in point clouds.
Instead, point clouds pose unique challenges such as the ge-ometric mismatch discussed above.
Therefore, we propose MLC-Net for unsupervised do-main adaptive 3D detection. MLC-Net is designed to tackle two major challenges. First, to create meaningful scale-adaptive targets to facilitate the learning, MLC-Net em-ploys the mean teacher [36] learning paradigm. The teacher model is essentially a temporal ensemble of student mod-els: the parameters of the teacher model are updated by an exponential moving average window on student mod-els of preceding iterations. Our analyses show that the mean teacher produces accurate and stable supervision for the student model without any prior knowledge of the tar-get domain. To the best of our knowledge, we are the first to introduce the mean teacher paradigm in unsuper-vised domain adaptive 3D detection. Second, to design scale-related consistency losses and construct useful cor-respondences of teacher-student predictions to initiate gra-dient flow, we design MLC-Net to enforce consistency at three levels. 1) Point-level. As point clouds are unstruc-tured, point-based region proposals or equivalents [32, 42] are common. Hence, we sample the same subset of points and share them between the teacher and student. We re-tain the indices of the points that allow 3D augmentation methods to be applied without losing the correspondences. 2) Instance-level. Matching region proposals can be erro-neous, especially at the initial stage when the quality of re-gion proposals is substandard. Hence, we resort to transfer-ring teacher region proposals to students to circumvent the matching process. 3) Neural statistics-level. As the teacher model only accesses the target domain input, the mismatch between the batch statistics hinders effective learning. We thus transfer the student’s statistics, which is gathered from both the source and the target domain, to the teacher to achieve a more stable training behavior.
MLC-Net shows remarkable compatibility with popular mainstream 3D detectors, allowing us to implement it on both two-stage [32] and single-stage [42] detectors. More-over, we verify our design through rigorous experiments across multiple widely used 3D object detection datasets
[11, 35, 3]. Our method outperforms baselines by convinc-ing margins, even surprisingly surpassing existing methods that utilize additional information. In summary, our main contributions are:
• We formulate and study unsupervised domain adaptive 3D detection, a pragmatic, yet underexplored task that requires no annotations of the target domain. We com-prehensively investigate the major underlying factors of the domain gap in 3D detection and find geometric mismatch is the key factor.
• We propose a concise yet effective mean-teacher paradigm that leverages three levels of consistency to facilitate cross-domain transfer, achieving a significant performance boost that is consistent across multiple popular public datasets.
• We validate our hypothesis on the unique challenges associated with point clouds and verify our proposed approach with comprehensive evaluations, which we hope would lay a strong foundation for future research. 2.