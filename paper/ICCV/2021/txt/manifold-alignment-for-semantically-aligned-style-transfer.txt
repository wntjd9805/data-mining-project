Abstract
Most existing style transfer methods follow the assump-tion that styles can be represented with global statistics (e.g., Gram matrices or covariance matrices), and thus ad-dress the problem by forcing the output and style images to have similar global statistics. An alternative is the assump-tion of local style patterns, where algorithms are designed to swap similar local features of content and style images.
However, the limitation of these existing methods is that they neglect the semantic structure of the content image which may lead to corrupted content structure in the output. In this paper, we make a new assumption that image features from the same semantic region form a manifold and an im-age with multiple semantic regions follows a multi-manifold distribution. Based on this assumption, the style trans-fer problem is formulated as aligning two multi-manifold distributions and a Manifold Alignment based Style Trans-fer (MAST) framework is proposed. The proposed frame-work allows semantically similar regions between the out-put and the style image share similar style patterns. More-over, the proposed manifold alignment method is flexible to allow user editing or using semantic segmentation maps
∗Corresponding author. as guidance for style transfer. To allow the method to be applicable to photorealistic style transfer, we propose a new adaptive weight skip connection network structure to preserve the content details. Extensive experiments verify the effectiveness of the proposed framework for both artis-tic and photorealistic style transfer. Code is available at https://github.com/NJUHuoJing/MAST. 1.

Introduction
The goal of style transfer is to synthesize an output im-age by transferring the target style to a given content image.
Currently, most methods [5, 8, 13, 12] make the assumption that image styles can be represented by global statistics of deep features, such as Gram matrices or covariance matri-ces. Such global statistics capture the style from the whole image, and are applied to the content image without differ-entiation of the contents inside. However, for images con-taining different semantic parts, such global statistics are in-sufficient to represent the multiple styles required for proper style transfer. As shown in the first two rows of Figure 1, although the overall appearances of the results from Gatys et al. [5], AdaIN [8], WCT [13] and LST [12] look like the style image, they sometimes fail to preserve the local se-mantic structure of the content image, leading to corrupted
image content. Another kind of style transfer methods is the local patch based methods [1, 23, 11, 15, 6], where the as-sumption is that local features of the content image can be replaced with local features of the style image to produce stylized output. However, the local content features may be mismatched to features that do not share similar semantic meanings, leading to artifacts [29]. See the result of Avatar-Net [23] in the first row of Figure 1, where the tiger’s eyes appear on the bus in the stylized image. Therefore, in many situations, neither the global statistics based nor local patch based methods are suitable. Recently, some works [29, 10] have proposed style transfer based on locally aligned se-mantics and have achieved better results in terms of content structure preserving and style transfer within similar seman-tic regions. However, existing works either contain multiple stages [29] or have many terms to balance [10], making the overall algorithm inefficient and hard to tune. To address these limitations, we make a new assumption in transfer-ring different styles and propose a simple and efficient style transfer method with impressive results.
Specifically, in this paper, we make the assumption that image features from the same semantic region form a single manifold. Therefore, for an image with multiple objects, all the features in this image follow a multi-manifold dis-tribution. The style transfer problem thus becomes a prob-lem of aligning two multi-manifold distributions of the style and the content features. Based on this assumption, we propose a manifold alignment based style transfer (MAST) framework. The proposed manifold alignment method is based on subspace learning, and learns a projection matrix to project the content features into the style features’ sub-space. In the style features’ subspace, content features and style features sharing the same or similar semantic mean-ings (i.e., having large feature similarities) are forced to be close, i.e., the locally aligned semantic information between content and style features is preserved. This makes the se-mantically aligned image regions in the output and the style images have similar style patterns. The proposed manifold alignment method can be easily plugged into many existing auto-encoder based style transfer structures [13]. Example results are given in the 1st and 2nd rows of Figure 1. More-over, by using user-defined region correspondence of con-tent and style images, the proposed method can be easily extended to support user editing or use semantic segmenta-tion maps as guidance. Examples are given in the 3rd row of Figure 1.
Applying the proposed framework to photorealistic style transfer requires fully preserving the details of content im-ages. However, existing auto-encoder based style transfer structures can lead to loss of detailed information and re-sult in distortions in the output. We therefore propose a new adaptive weight skip connection (AWSC) structure to preserve the detailed spatial features of the content image.
We further extend our manifold alignment method as an orthogonal constrained optimization problem, which com-pared with the non-orthogonal version is proved to be able to fully preserve the content structure during style transfer.
The new AWSC structure together with the orthogonal con-strained manifold alignment is shown effective for photore-alistic style transfer.
The main contributions of this paper are as follows:
Firstly, we introduce the novel view that style trans-fer can be treated as a manifold alignment problem, and propose a new manifold alignment algorithm for align-ing multi-manifold distributions to address the semantically aligned style transfer problem.
Secondly, we show that the algorithm is flexible to al-low user editing or using semantic segmentation maps as guidance in style transfer. Extensive experiments show the proposed algorithm achieves promising results.
Lastly, we extend the algorithm for photorealistic style transfer with a new adaptive weight skip connection struc-ture and orthogonal constraints, which is shown to produce high quality photorealistic style transfer results. 2.