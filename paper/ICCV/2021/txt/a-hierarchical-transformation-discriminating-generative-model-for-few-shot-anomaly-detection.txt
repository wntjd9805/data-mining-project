Abstract
Anomaly detection, the task of identifying unusual sam-ples in data, often relies on a large set of training samples.
In this work, we consider the setting of few-shot anomaly detection in images, where only a few images are given at training. We devise a hierarchical generative model that captures the multi-scale patch distribution of each training image. We further enhance the representation of our model by using image transformations and optimize scale-specific patch-discriminators to distinguish between real and fake patches of the image, as well as between different transfor-mations applied to those patches. The anomaly score is obtained by aggregating the patch-based votes of the correct transformation across scales and image regions. We demon-strate the superiority of our method on both the one-shot and few-shot settings, on the datasets of Paris, CIFAR10,
MNIST and FashionMNIST as well as in the setting of defect detection on MVTec. In all cases, our method outperforms the recent baseline methods. 1.

Introduction
Anomaly detection [5, 1] is the task of detecting unusual samples in the data. In the typical setting of one class clas-sification [20], given a large collection of samples from the normal (non-anomalous) data, the learner is asked to classify novel samples as either normal or anomalous. In this paper, we aim to solve this problem given very few training samples, including the case of a single training sample. Our study is motivated by the scarcity of training samples in many visual domains, as well as by the human ability to solve this task after observing a very limited number of samples [7, 8].
Our model relies on two main components. The first component is a hierarchical generative model that captures the internal patch statistics of one or few images at multiple scales. This component follows the recent successes of deep generative models to generate multiple, varied, natural look-*Equal contribution ing images, given a single training image [28, 12, 35]. We generalize this setting to few images, by adding condition-ing on the image index, thus enabling information sharing between multiple training images.
Modeling patches at different scales, allows the detection of anomalies both in global properties, such as color or large-scale structural changes, and in local regions. The multi-scale patch based approach is also useful when considering the task of defect detection, where the anomaly may only manifest in few well localized regions.
The second component is a self-supervised learning task.
Recent approaches [10, 3, 11] have shown that, in the many-shot case, a classifier trained on a proxy task, such as iden-tifying the transformation applied to the input, accurately captures novel samples that are similar to the training data, and thus can distinguish between normal and anomalous samples. We utilize such a proxy task in the context of our multi-scale generative model. For each scale, the gen-erated patches are transformed according to a predefined set of transformations. A discriminator is asked to distin-guish between real and fake samples, as well as between the transformations performed.
Our method builds these components into a single model.
At test time, a sample is considered anomalous, if many of its patches, at all scales, are determined anomalous, according to the learned patch-specific discriminators. In a comprehen-sive set of the experiments, we demonstrate that the proposed method outperforms recent baselines on anomaly detection benchmarks. This is true for the one-shot, five-shot and ten-shot settings. When the number of training samples in-creases, our method is shown to improve in performance.
In the field of defect detection, we show that our method outperforms, in the few shot setting, the state of the art in localizing the anomalous patch.
To conclude, our work comprises the following contribu-tions: (1) Presenting a method for few-shot anomaly detec-tion which on the conceptual level is novel. (2) The method can easily be extended to the problem of few-shot defect detection. (3) We offer a number of unique components: (i)
Multiclass discriminator which is trained adversarially using
labels from SSL task (ii) A novel use of a discriminator at test time (iii) Applying transformations on patches at different scales, and not on full-size images (as [10]). (iv) Extending the hierarchical GAN of [28] to multiple images using a novel conditional generator. (4) The proposed method is extensively evaluated on five datasets and achieves better performance compared to the baselines. 2.