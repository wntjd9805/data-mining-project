Abstract
As a challenging task of high-level video understanding, weakly supervised temporal action localization has been attracting increasing attention. With only video annota-tions, most existing methods seek to handle this task with a localization-by-classification framework, which generally adopts a selector to select snippets of high probabilities of actions or namely the foreground. Nevertheless, the ex-isting foreground selection strategies have a major limita-tion of only considering the unilateral relation from fore-ground to actions, which cannot guarantee the foreground-action consistency. In this paper, we present a framework named FAC-Net based on the I3D backbone, on which three branches are appended, named class-wise foreground clas-sification branch, class-agnostic attention branch and mul-tiple instance learning branch. First, our class-wise fore-ground classification branch regularizes the relation be-tween actions and foreground to maximize the foreground-the class-agnostic at-background separation. Besides, tention branch and multiple instance learning branch are adopted to regularize the foreground-action consistency and help to learn a meaningful foreground classifier. Within each branch, we introduce a hybrid attention mechanism, which calculates multiple attention scores for each snip-pet, to focus on both discriminative and less-discriminative snippets to capture the full action boundaries. Experimen-tal results on THUMOS14 and ActivityNet1.3 demonstrate the state-of-the-art performance of our method. 1.

Introduction
Temporal action localization in videos has been widely used in various fields [39, 38]. This task aims to localize action instances in untrimmed videos along the temporal di-mension. Most existing methods [45, 35, 42, 49, 4, 18, 20] are trained in a fully supervised manner. However, such
*Corresponding author.
Figure 1. An example of the action of “HammerThrow”. The bar-code is the ground-truth (GT). The following line charts are fore-ground selection scores and frame-wise classification scores. We show the results of two representative methods STPN [31] (atten-tion mechanism) and W-TALC [26] (multiple instance learning). It is obvious that these methods cannot guarantee foreground-action consistency, leading to compromising results. a requirement of frame-level annotations does not suit real-world applications since densely annotating large-scale videos is expensive and time-consuming. To address this difficulty, weakly supervised methods [14, 1, 41] have been developed with only video-level labels, which are much eas-ier to annotate. Among diverse weak supervisions, video-level category labels are the easiest to collect and are thus most commonly used [41, 26, 31].
Because of the absence of frame-wise annotations, exist-ing works mainly embrace a localization-by-classification pipeline [41, 44], in which an important component is the selector to select snippets with high probabilities of ac-tions, or namely the foreground. Existing mechanisms for foreground selection can be categorized into two main strategies, i.e., attention mechanism [26, 19] and multi-ple instance learning (MIL) [31]. However, both strate-gies have their intrinsic drawbacks. As shown in Fig. 1, the attention mechanism (either class-agnostic attention or class-wise attention) usually suffers from the discrepancy
[37, 50, 19] between classification and detection, i.e., the attention scores being concentrated around most discrim-inative action snippets or wrongly focus on background snippets. On the other hand, the multiple instance learn-ing should rely on a temporal top-k pooling operation, but there is no guarantee that all the top-k snippets would be foreground, since the number k is generally defined by hu-mans. In summary, existing approaches lack the ability to maintain consistency between foreground and actions, that is, the foreground and actions should be mutually inclusive.
In this work, we propose to tackle the action localiza-tion problem by explicitly modeling and regularizing the foreground-action consistency. Given the insight that ex-isting foreground selection strategies only consider the uni-lateral relation from foreground to actions, we propose a framework to further take bilateral relations into considera-tion. Based on a common video backbone, our method ap-pends three branches on top of it. The first branch, named as class-wise foreground classification branch (CW branch,
Sec.3.2), seeks to model the action-to-foreground relation.
Meanwhile, it acts similarly to the noise contrastive esti-mation (NCE) [6, 28], which actually maximizes a lower bound on mutual information (MI) between the foreground feature and the feature of ground truth action, leading to bet-ter foreground-background separation. The second branch (CA branch, Sec.3.3) introduces a class-agnostic attention mechanism that to model the reverse foreground-to-action relation for complementing the first branch, so as to build the foreground-action consistency. Moreover, it enables to learn a semantically meaningful foreground feature. The third branch (MIL branch, Sec.3.4) is an MIL-like pipeline to further improve video classification and facilitate the learning of class-wise attention in the CW branch.
Within each branch, we adopt a hybrid attention mecha-nism to ease the attention learning and promote precise fore-ground prediction. In addition to focusing on key frames in the video, the hybrid attention mechanism can learn to accommodate less-discriminative snippets, which benefits capturing accurate action boundaries. To evaluate the ef-fectiveness of our method, we perform experiments on two benchmarks, THUMOS14 [11] and ActivityNet1.3 [2]. Ex-perimental results on the two benchmarks demonstrate the superior performance over state-of-the-art approaches.
Our main contributions are three-fold. (a) We introduce a class-wise foreground classification pipeline to improve the robustness of foreground prediction. This pipeline mod-els and regularizes the foreground-action consistency that is mostly ignored by existing methods. (b) We propose a hy-brid attention mechanism to improve the attention learning and help to capture accurate action boundaries. (c) The pro-posed class-wise foreground classification pipeline can play a complementary role over existing methods to consistently improve the action localization performance. 2.