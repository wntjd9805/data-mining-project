Abstract
In this paper, we propose HF2-VAD, a Hybrid framework that integrates Flow reconstruction and Frame prediction seamlessly to handle Video Anomaly Detection. Firstly, we design the network of ML-MemAE-SC (Multi-Level Mem-ory modules in an Autoencoder with Skip Connections) to memorize normal patterns for optical flow reconstruction so that abnormal events can be sensitively identified with larger flow reconstruction errors. More importantly, condi-tioned on the reconstructed flows, we then employ a Con-ditional Variational Autoencoder (CVAE), which captures the high correlation between video frame and optical flow, to predict the next frame given several previous frames. By
CVAE, the quality of flow reconstruction essentially influ-ences that of frame prediction. Therefore, poorly recon-structed optical flows of abnormal events further deterio-rate the quality of the final predicted future frame, mak-ing the anomalies more detectable. Experimental results demonstrate the effectiveness of the proposed method. Code is available at https://github.com/LiUzHiAn/hf2vad. 1.

Introduction
Video Anomaly Detection (VAD) refers to the identifi-cation of events that do not conform to expected behav-iors [3] in a video, with one example shown in Figure 1.
This is an open and very challenging task as abnormal events usually much less happen than normal ones and the forms of abnormal events are unbounded in practical ap-plications [25]. Obviously, it is impossible to collect all kinds of abnormal data in advance. Therefore, a typical so-lution to video anomaly detection is to train an unsupervised learning model on normal data, and those events or activi-ties that are recognized by the trained model as outliers are then deemed as anomalies.
*Corresponding author: nieyongwei@scut.edu.cn
Figure 1. An anomaly example from CUHK Avenue [29] dataset.
Here “running” is identified as an anomaly event on the walking avenue, and the blue dashed rectangles denote ground-truth ab-normal sections where a person is running. The blue curve is the result of HF2-VAD, the red curve is the result with flow recon-struction only, and the green curve is the result with a CVAE based frame prediction model conditioned on original flows. Area Un-der the Receiver Operation Characteristic (AUROC) is calculated.
As can be seen, HF2-VAD that combines flow reconstruction and reconstructed-flow guided future prediction performs the best.
Nowadays deep learning has shown great success in many real-world tasks such as visual recognition [13, 12, 14, 26], object detection [19, 28, 27, 15], shadow detection and removal [4, 44, 49, 48, 18], trajectory prediction [41], and image captioning [5]. Rather than traditional hand-crafted feature based methods [1, 20, 2, 34], a lot of modern deep neural network based methods [11, 45, 50, 31, 25, 30, 8, 36, 38, 47, 43, 24] have been proposed for VAD. In the era of deep learning, reconstruction and future prediction are two prevalent VAD paradigms. Reconstruction-based meth-ods [11, 31, 8, 36, 7, 38] typically train autoencoders on normal data. At test time, abnormal data often incurs larger reconstruction errors, making them detectable from normal ones. Taking advantage of temporal characteristics of video frames, prediction-based methods [25, 30, 47] train a net-work to predict the next frame based on the given previous frames and use prediction error for anomaly measuring. Re-cently, several works [50, 46, 35] are proposed to combine these two paradigms in a hybrid manner. Although these state-of-the-art methods have been able to detect anomalies in most cases, the results are still far from perfect.
In this paper, we propose a novel hybrid framework in a combination of flow reconstruction and flow-guided frame prediction, named as “HF2-VAD”, for video anomaly de-tection. As illustrated in Figure 2, the Conditional VAE (CVAE) based future frame prediction model accepts both previous video frames and optical flows as input. But in-stead of original flows, we reconstruct them in advance and then input the reconstructed flows into the CVAE model.
Inspired by [8, 38], we design a Multi-Level Memory-augmented Autoencoder with Skip Connections (ML-MemAE-SC) for optical flow reconstruction. Multiple memory modules are employed to memorize normal pat-terns at different feature levels, while skip connections are added between encoder and decoder to compensate for the strong information compression due to the memories. We observe that such a well-designed flow reconstruction net-work can reconstruct normal flows more clearly while pro-ducing larger reconstruction error for abnormal input.
We use the model of CVAE [42] for future frame pre-diction. On one hand, it takes the reconstructed flows by ML-MemAE-SC as condition, unifying the reconstruc-tion module into the prediction pipeline naturally. On the other hand, by maximizing the quantity of evidence lower bound (ELBO) induced from the variables of observed video frames and reconstructed optical flows, the CVAE module essentially encodes the consistency between the in-put frames and flows when taking them for the future frame prediction.
The above design facilitates to utilize the quality gap between the reconstructed normal and abnormal flows to improve the VAD accuracy of the CVAE-based prediction module. That is, the reconstructed normal flows usually have higher quality, with which the prediction module can successfully predict the future frame with smaller predic-tion error.
In contrast, the reconstructed abnormal flows usually have lower quality, thus leading to future frame with larger prediction error. We use both the flow reconstruc-tion and frame prediction errors as our final anomaly de-tection cues. In summary, the following aspects distinguish our work from the previous works [25, 8, 7, 47, 36, 30, 47]:
• First of all, multi-level memory modules are utilized in an encoder-decoder structure with skip connections, which guarantees normal patterns are well memorized so that the abnormal events or activities are sensitively identified.
• Second, we design the HF2-VAD hybrid method that predicts future frame from both previous video frames and the corresponding optical flows but with the flows being reconstructed beforehand. The reconstruction error enlarges the prediction error so that anomaly can be more easily detected.
• Finally, we conduct extensive experiments on three public datasets which show that our proposed HF2-VAD achieves better anomaly detection performance than state-of-the-art methods. 2.