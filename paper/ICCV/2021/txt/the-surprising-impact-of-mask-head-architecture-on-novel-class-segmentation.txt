Abstract
Instance segmentation models today are very accurate when trained on large annotated datasets, but collect-ing mask annotations at scale is prohibitively expensive.
We address the partially supervised instance segmentation problem in which one can train on (signiﬁcantly cheaper) bounding boxes for all categories but use masks only for a subset of categories. In this work, we focus on a popular family of models which apply differentiable cropping to a feature map and predict a mask based on the resulting crop.
Under this family, we study Mask R-CNN and discover that instead of its default strategy of training the mask-head with a combination of proposals and groundtruth boxes, train-ing the mask-head with only groundtruth boxes dramati-cally improves its performance on novel classes. This train-ing strategy also allows us to take advantage of alternative mask-head architectures, which we exploit by replacing the typical mask-head of 2-4 layers with signiﬁcantly deeper off-the-shelf architectures (e.g. ResNet, Hourglass models).
While many of these architectures perform similarly when trained in fully supervised mode, our main ﬁnding is that they can generalize to novel classes in dramatically differ-ent ways. We call this ability of mask-heads to general-ize to unseen classes the strong mask generalization effect and show that without any specialty modules or losses, we can achieve state-of-the-art results in the partially super-vised COCO instance segmentation benchmark. Finally, we demonstrate that our effect is general, holding across un-derlying detection methodologies (including anchor-based, anchor-free or no detector at all) and across different back-bone networks. Code and pre-trained models are available at https://git.io/deepmac. 1.

Introduction
Large labeled datasets like COCO [32] are crucial for deep neural network based instance segmentation methods
[16, 3, 38]. However, collecting groundtruth masks can take > 10× more time than bounding box annotations. In
COCO [32], mask annotations required ≈ 80 seconds on average whereas methods such as Extreme Clicking [37] yield bounding boxes in 7 seconds. (a) ResNet-4 (b) ResNet-12 (c) ResNet-20 (d) Hourglass-20
Figure 1: The effect of mask-head architecture on mask predictions for unseen classes. Despite never having seen masks from the ‘parking meter’,
‘pizza’ or ‘mobile phone’ class, the rightmost mask-head architecture can segment these classes correctly. From left to right, we show better mask-head architectures predicting better masks. Moreover, this difference is only apparent when evaluating on unseen classes — if we evaluate on seen classes, all four architectures exhibit similar performance.
Given that boxes are much cheaper to annotate than masks, we address the “partially supervised” instance seg-mentation problem [20], where all classes have bounding box annotations but only a subset of classes have mask an-notations. We will refer to classes with mask annotations as
“seen” categories and classes without as “unseen”. Doing well on this task requires the model to generalize in a strong sense, producing correct masks on unseen classes.
We consider a general family of crop-then-segment in-stance segmentation models where one extracts a feature map over an image, then given a tight bounding box around an instance, performs a differentiable crop (e.g.
ROIAlign [16]). The cropped feature map is then fed to a mask-head subnetwork to yield a ﬁnal mask prediction.
This mask prediction is performed in a class-agnostic man-ner so that a model trained from a subset of classes can be applied unchanged to novel classes.
One “na¨ıve” baseline in this family is to adapt Mask R-CNN [16] to produce class-agnostic masks. But this ap-proach is known to perform abysmally on unseen classes (e.g. on the standard partially supervised COCO bench-mark, it achieves < 20% mask mAP on unseen classes vs > 40% on seen,
[20]). Thus previous approaches have used, e.g., ofﬂine-trained shape priors [27] or specialty losses [10] yielding signiﬁcantly improved results.
As a starting point, we revisit “na¨ıve” Mask R-CNN to better understand the reasons for its poor performance. Our
ﬁrst ﬁnding is that the typical strategy of training the Mask
R-CNN mask-head with a combination of groundtruth and proposed (typically noisy) boxes is a major culprit that in-hibits its performance on novel classes. While training with noisy proposals gives slightly better results when fully su-pervised, we show that simply training the mask-head with only groundtruth boxes has a surprising impact on its per-formance on unseen classes (+9 mAP) (note that we follow the usual procedure of using predicted boxes at test time).
We next zoom out beyond Mask R-CNN to the more gen-eral family of crop-then-segment models. Our second ma-jor ﬁnding is that in the context of using the above slightly modiﬁed training regime, the architecture of the mask-head takes on a disproportionately impactful role in generaliza-tion to unseen classes. More speciﬁcally, we ﬁnd that mask-heads that might perform similarly under full supervision can behave differently under partial supervision, generaliz-ing to unseen classes in strikingly different ways.
While it is natural to experiment with different mask-head architectures, we note that their role in generalization has not been studied extensively in prior literature likely for the following reasons: (1) the choice of mask-head archi-tecture has limited impact in the fully supervised setting, (2) heavier mask-heads adversely impact running time. and (3) as noted above, in architectures like Mask R-CNN, the beneﬁts of using better mask-heads are not necessarily real-ized in the default training regimen. Thus most prior works in instance segmentation have settled on using shallow (2-4 layer) fully connected or convolution based mask-heads.
In our COCO experiments, we ﬁnd that the difference between worst and best architectures is only 1% (absolute mAP) on seen classes but can be 7% on unseen classes (examples in Figure 1). This difference is visually palpable and subsequently changes the calculus for deciding whether it’s worth using a heavier mask-head.
We refer to this effect of certain mask-head architectures on unseen classes as the “strong mask generalization ef-fect” and illustrate it with 3 representative model classes: an anchor-free and anchor-based model, and one that dis-cards detection altogether. We show that our effect is gen-eral, holding across underlying detection methodologies (or no detector at all) and across different backbone networks.
We also identify architectural characteristics (such as depth and encoder-decoder arrangements) that empirically yield strong mask generalization properties.
One main ﬁnding is that deeper mask-heads gener-alize better despite being counter-intuitively more over-parameterized than shallower ones. Our anchor-based model, based on Mask R-CNN [16], employs mask-heads that are 20+ layers deep and we thus refer to this model as Deep-MARC (for Deep Mask-heads Above R-CNN).
Similarly, our anchor-free model, which we use for most ablations, is based on CenterNet [55] and is called Deep-MAC (for Deep Mask-heads Above CenterNet). Using out-of-the-box mask-head architectures, we show that both
Deep-MAC and Deep-MARC surpass the state-of-the-art
[10] in the COCO partially supervised instance segmenta-tion setting with 35.5 % and 38.7 % mAP respectively.
Due to space limitations, we have relegated a number of auxiliary ﬁndings to the Appendix. Among them, we show that: (1) two-stage training (i.e. self-distillation) helps, al-lowing us to achieve 40.4% mask mAP on unseen cate-gories (Section B.2); (2) our models have reached a likely saturation point in terms of mask quality on COCO (Sec-tion B.1) — the implication is that future improvements on this particular benchmark are far more likely to come from detection; and (3) we demonstrate that we can achieve sur-prisingly strong mask generalization results with just 1 seen class (depending on the class, Section C).
We summarize our main contributions as follows:
• We identify the strong mask generalization effect in partially supervised instance segmentation and show that it is general, holding across underlying detectors like Mask R-CNN [16] and CenterNet [55] or without a detector, and across different backbones (Section 6).
• In order it to unlock strong mask generalization, is necessary to train using tight we show that groundtruth boxes instead of a combination of groundtruth and noisy proposals. We revisit vanilla
Mask R-CNN with this insight and show that this change alone dramatically improves the performance on unseen classes (Section 5).
• We identify characteristics of mask-head architectures that lead to strong mask generalization (Section 7).
Among other things, we ﬁnd that Hourglass [36] architectures offer excellent performance. We use these ﬁndings to achieve state-of-the-art results on the
COCO partially supervised instance segmentation task (Section 8) with our CenterNet and Mask R-CNN based models, Deep-MAC and Deep-MARC .
2.