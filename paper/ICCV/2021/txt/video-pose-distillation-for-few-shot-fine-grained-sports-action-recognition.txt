Abstract
Human pose is a useful feature for fine-grained sports action understanding. However, pose estimators are often unreliable when run on sports video due to domain shift and factors such as motion blur and occlusions. This leads to poor accuracy when downstream tasks, such as action recognition, depend on pose. End-to-end learning circum-vents pose, but requires more labels to generalize.
We introduce Video Pose Distillation (VPD), a weakly-supervised technique to learn features for new video do-mains, such as individual sports that challenge pose esti-mation. Under VPD, a student network learns to extract robust pose features from RGB frames in the sports video, such that, whenever pose is considered reliable, the fea-tures match the output of a pretrained teacher pose detec-tor. Our strategy retains the best of both pose and end-to-end worlds, exploiting the rich visual patterns in raw video frames, while learning features that agree with the athletes’ pose and motion in the target video domain to avoid over-fitting to patterns unrelated to athletes’ motion.
VPD features improve performance on few-shot, fine-grained action recognition, retrieval, and detection tasks in four real-world sports video datasets, without requiring ad-ditional ground-truth pose annotations. 1.

Introduction
Analyzing sports video requires robust algorithms to au-tomate fine-grained action recognition, retrieval, and detec-tion in large-scale video collections. Human pose is a useful feature when sports are centered around people.
State-of-the-art skeleton-based deep learning techniques for action recognition [31, 57] rely on accurate 2D pose detection to extract the athletes’ motion, but the best pose detectors [45, 54] routinely fail on fast-paced sports video with complex blur and occlusions, often in frames cru-cial to the action (Figure 1). To circumvent these issues, end-to-end learned models operate directly on the video stream [7, 13, 28, 43, 51, 62]. However, because they con-sume pixel instead of pose inputs, when trained with few labels, they tend to latch onto specific visual patterns [9, 52]
Figure 1: Limitations of current 2D pose detectors. State-of-the-art pose estimators [45] produce noisy and incor-rect results in frames with challenging motions, common in sports video. Here are examples from figure skating, tennis, gymnastics, and diving where pose estimates are incorrect. rather than the fine-grained motion (e.g., an athlete’s clothes or the presence of a ball). As a result, prior pose and end-to-end methods often generalize poorly on fine-grained tasks in challenging sports video, when labels are scarce. While collecting large datasets with fine action and pose annota-tions is possible, doing so for each new sport does not scale.
We propose Video Pose Distillation (VPD), a weakly-supervised technique in which a student network learns to extract robust pose features from RGB video frames in a new video domain (a single sport). VPD is designed such that, whenever pose is reliable, the features match the out-put of a pretrained teacher pose detector. Our strategy re-tains the best of both pose and end-to-end worlds. First, like directly supervised end-to-end methods, our student can ex-ploit the rich visual patterns present in the raw frames, in-cluding but not limited to the athlete’s pose, and continue to operate when pose estimation is unsuccessful. Second, by constraining our descriptors to agree with the pose estima-tor whenever high-confidence pose is available, we avoid the pitfall of overfitting to visual patterns unrelated to the athlete’s action. And third, weak pose supervision allows us to enforce an additional constraint: we require that the stu-dent predicts not only instantaneous pose but also its tem-poral derivative. This encourages our features to pick up on visual similarities over time (e.g., an athlete progress-ing from pose to pose). When we train the student with weak-supervision over a corpus of unlabeled sports video, the student learns to ‘fill-in the gaps’ left by the noisy pose teacher. Together, these properties lead to a student network whose features outperform the teacher’s pose output when used in downstream applications.
VPD features improve performance on few-shot, fine-grained action recognition, retrieval, and detection tasks in the target sport domain, without requiring additional ground-truth action or pose labels. We demonstrate the ben-efits of VPD on four diverse sports video datasets with fine-grained action labels: diving [27], floor exercises [40], ten-nis [58], and a new dataset for figure skating. In a few-shot
— limited supervision — setting, action recognition models trained with distilled VPD features can significantly outper-form models trained directly on features from the teacher as well as baselines from prior skeleton-based and end-to-end learning work. For instance, when restricted to between 8 and 64 training examples per class from diving and floor ex-ercises, the two datasets that are most challenging for pose,
VPD features improve fine-grained classification accuracy by 6.8 to 22.8% and by 5.0 to 10.5%, respectively, over the next best method(s). Even when labels are plentiful, VPD remains competitive, achieving superior accuracy on three of the four test datasets. To summarize, VPD surpasses its teacher in situations where leveraging pose is crucial (e.g., few-shot) and is also competitive when end-to-end methods dominate (e.g., unreliable pose and the high-data / full su-pervision setting). Finally, we show applications of VPD features to fine-grained action retrieval and few-shot tem-poral detection tasks.
This paper makes the following contributions: 1. A weakly-supervised method, VPD, to adapt pose fea-tures to new video domains, which significantly im-proves performance on downstream tasks like action recognition, retrieval, and detection in scenarios where 2D pose estimation is unreliable. 2. State-of-the-art accuracy in few-shot, fine-grained ac-tion understanding tasks using VPD features, for a va-riety of sports. On action recognition, VPD features perform well with as few as 8 examples per class and remain competitive or state-of-the-art even as the train-ing data is increased. 3. A new dataset (figure skating) and extensions to three datasets of real-world sports video, to include tracking of the performers, in order to facilitate future research on fine-grained sports action understanding. 2.