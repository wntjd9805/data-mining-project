Abstract
Learning-based image denoising methods have been bounded to situations where well-aligned noisy and clean images are given, or samples are synthesized from prede-termined noise models, e.g., Gaussian. While recent gener-ative noise modeling methods aim to simulate the unknown distribution of real-world noise, several limitations still ex-ist. In a practical scenario, a noise generator should learn to simulate the general and complex noise distribution with-out using paired noisy and clean images. However, since existing methods are constructed on the unrealistic assump-tion of real-world noise, they tend to generate implausi-ble patterns and cannot express complicated noise maps.
Therefore, we introduce a Clean-to-Noisy image genera-tion framework, namely C2N, to imitate complex real-world noise without using any paired examples. We construct the noise generator in C2N accordingly with each component of real-world noise characteristics to express a wide range of noise accurately. Combined with our C2N, conventional denoising CNNs can be trained to outperform existing un-supervised methods on challenging real-world benchmarks by a large margin. 1.

Introduction
Image denoising aims to remove unintended signals from a given noisy observation. The task has been consid-ered as one of the fundamental vision problems and handled by numerous studies [9, 14, 17]. While recent deep convo-lutional neural networks (CNNs) have achieved promising performance [50, 51, 19, 11, 36], several challenges pre-vent them from being used for practical applications. A primary limitation of the learning-based approaches is that they are usually data-driven, where training on a speciﬁc dataset does not guarantee generalization to a real-world scenarios [53, 19].
The noise from a typical camera pipeline is different to the conventional assumption for ideal noise in several as-*Authors contributed equally. (a) Clean (b) GT (c) C2N (d) DIDN [48]
Figure 1: Examples of generated and denoised image from our proposed method. (a) Clean image, (b) Ground truth noisy image, (c) Generated noisy image from the pro-posed C2N, (d) Denoising results of DIDN [48] trained on the images generated by our C2N. Our C2N can accurately imitate the real noise without using paired examples. pects. For instance, a widely-used Additive White Gaus-sian Noise (AWGN) formulation assumes that the term is signal-independent [10, 28], while real-world noises are not. Therefore, it is difﬁcult to generalize a denoising algo-rithm toward real-world images when the model is trained on synthetic examples. As an alternative, few studies have collected well-aligned noisy and clean image pairs in the wild [2, 40] so that the following denoising methods can be trained in a supervised manner. While such an approach is an effective way to deal with real-world noise, it remains challenging to acquire large-scale pairs due to several prac-tical issues. Recent self-supervised approaches [28, 6] deal with the limitations by using noisy samples as the target output, whose supervision would lead a model to estimate the actual value on average. However, they usually leverage some statistical properties of the noise, which are insufﬁ-cient to represent the real-world cases [2, 40].
On the other hand, generation-based approaches [12, 22] have been proposed to deal with challenging real-world sit-uations. These approaches ﬁrst train a noise generator [16] on target noisy images to produce pseudo-noisy images paired to other clean images, which are used later to train a denoising model. Following the successful results of the earlier methods [12, 10] for synthetic noise reduction, re-cent attempts [1, 22] to apply this method to real-world noise have been introduced. Still, in a situation where no paired clean images are given to the target noisy images, a generation-based method that successfully imitates real-world noise has not been suggested.
In this paper, we introduce C2N(Clean to Noisy), a novel generative noise modeling framework trained without any paired data. The C2N can learn a variety of complex noise distributions successfully and generates accurate noisy im-ages from arbitrary clean images. We achieve state-of-the-art performance by training existing denoising models with the generated pairs from our C2N framework. Our contri-butions is summarized as follows:
• We propose a novel noise generator with explicit modules to express noise terms of according characteristics, en-abling the generator to imitate more accurate real-world noise.
• Our C2N framework successfully simulates target noise distribution without any handcrafted formulations or un-realistic assumptions.
• With the data pairs generated by C2N, we train denois-ing models that outperform state-of-the-art unsupervised methods for denoising real photographs. 2.