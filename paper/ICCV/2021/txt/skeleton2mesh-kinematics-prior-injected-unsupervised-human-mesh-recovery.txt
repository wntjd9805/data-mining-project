Abstract
In this paper, we decouple unsupervised human mesh re-covery into the well-studied problems of unsupervised 3D pose estimation, and human mesh recovery from estimated 3D skeletons, focusing on the latter task. The challenges of the latter task are two folds: (1) pose failure (i.e., pose mismatching – different skeleton deﬁnitions in dataset and
SMPL , and pose ambiguity – endpoints have arbitrary joint angle conﬁgurations for the same 3D joint coordinates). (2) shape ambiguity (i.e., the lack of shape constraints on body conﬁguration). To address these issues, we propose Skele-ton2Mesh, a novel lightweight framework that recovers hu-man mesh from a single image. Our Skeleton2Mesh con-tains three modules, i.e., Differentiable Inverse Kinematics (DIK), Pose Reﬁnement (PR) and Shape Reﬁnement (SR) modules. DIK is designed to transfer 3D rotation from estimated 3D skeletons, which relies on a minimal set of kinematics prior knowledge. Then PR and SR modules are utilized to tackle the pose ambiguity and shape ambiguity respectively. All three modules can be incorporated into
Skeleton2Mesh seamlessly via an end-to-end manner. Fur-thermore, we utilize an adaptive joint regressor to allevi-ate the effects of skeletal topology from different datasets.
Results on the Human3.6M dataset for human mesh recov-ery demonstrate that our method improves upon the previ-ous unsupervised methods by 32.6% under the same setting.
Qualitative results on in-the-wild datasets exhibit that the recovered 3D meshes are natural, realistic. Our project is available at https://sites.google.com/view/skeleton2mesh. 1.

Introduction
Recovering human mesh from in-the-wild monocular images has been a promising goal in the vision commu-nity. This is considered as a crucial step for a variety of downstream applications such as robot interaction [38],
*equal contribution
†corresponding author
Model-based methods
Paired 3D Sup.
Unpaired 3D Sup.
Temporal
Information
Optimized
Module
SMPLify [4]
Song et al. [46]
NBF [40]
Pavlakos et al. [42]
HMR [22]
SPIN [27]
PoseNet [48]
Ours
✗
✗
✓
✓
✗
✗
✗
✗
✓
✓
✗
✗
✓
✓
✗
✗
✗
✗
✗
✗
✗
✗
✓
✗
✓
✓
✓
✗
✗
✓
✗
✗
Table 1: Characteristic comparison of our method against previous model-based methods, in terms of supervision sig-nals and the usage of optimized module. augmented reality [16], animation industry [1], etc. Recent methods based on parametric models, such as SCAPE [2],
SMPL [22] and SMPL-X [41] can be simply divided into two categories: regression-based and optimization-based.
Regression-based methods [22, 49] or Optimization-based methods [4, 13, 30] rely on 3D annotations or opti-mized module. Different from above, our method requires 3D supervision training scheme but free from 3D annota-tion (i.e., 3D skeleton, β or θ in SMPL), optimized module, and temporal information (illustrated in Tab. 1).
Speciﬁcally, unsupervised human mesh recovery aims to recover the SMPL model, which is comprised of pose pa-rameters (3D rotation) and shape parameters. (a) In terms of pose parameters, most existing methods [22, 14] directly regress 3D rotation from images or 2D pose. However, these methods all heavily rely on paired or unpaired 3D an-notations. However, we can easily see that the SMPL model with 3D rotation alone is similar to the corresponding 3D skeleton, disregarding the shape information. Recent un-supervised 3D pose estimation [6] has achieved promising performance, which motivates us to use estimated 3D skele-ton to facilitate human mesh recovery [14, 48]. HybrIK exploits inverse kinematics process to establish strict cor-respondence between 24 3D joints and 24 3D rotations pro-vided by SMPL model, which heavily relies on supervised
3D annotation. Notably, 24 3D joints (includes hands and feet) and 24 3D rotations are highly difﬁcult to obtain. (b)
In terms of shape parameters, most recent methods [22, 27] exploit discriminator by unpaired 3D pose (such as CMU prior [27]) or simple regularizer via the average shape [48] to obtain more valid 3D human mesh. However, unpaired 3D pose is also expensive to capture and a simple regular-izer based on the average shape is unable to capture more reasonable shape for speciﬁc human character. This inspires us to use silhouettes to obtain more valid shape.
Figure 1: Transforming 3D skeleton to mesh is an ill-posed problem with no unique solution. Notably, pose failure is comprised of pose mismatching and pose ambiguity.
To this end, we decouple human mesh recovery into the well-studied problems of unsupervised 3D pose esti-mation [6], and unsupervised human mesh recovery from estimated 3D skeleton, focusing on the latter. Speciﬁcally, the challenges of the latter task are two folds (see Fig. 1): (1a.) Pose mismatching. Different skeleton deﬁnitions, mismatching joint numbers, and the cases that a single 3D skeleton possibly corresponds to multiple 3D meshes, which causes the large accuracy gap between pose estima-tion and reconstruction [14, 27, 43, 51]. (1b.) Pose am-biguity. Pose ambiguity refers to ambiguities in rotations of endpoints. In other words, endpoints have arbitrary joint angle conﬁgurations for the same 3D joint coordinates. (2.)
Shape ambiguity. It can be easily seen that we are unable to obtain sufﬁcient shape information from 3D skeleton.
In this paper, we propose Skeleton2Mesh, a novel lightweight framework that recovers human mesh from a single image. Our Skeleton2Mesh consists of three mod-ules, i.e., DIK, PR, and SR modules. These three modules would be discussed in detail as follows: (a) Differentiable inverse kinematics module. Inverse kinematics methods have been studied to enable robots to imitate human body motion from a person. We are thus motivated to design the differentiable inverse kinematics (DIK) module to infer 3D rotations from the estimated 3D skeletons. DIK module re-lies on a minimal set of prior knowledge that deﬁnes the underlying kinematic 3D structure, and it can be incorpo-rated into our framework seamlessly without any trainable parameters. (b) Pose reﬁnement module. Most existing unsupervised 3D pose estimation methods commonly out-put 3D skeleton with 14-17 joints [6, 32]), which do not es-timate hand or foot. Furthermore, the head positions cross datasets are different from each other. For example, the head position in Human3.6M dataset [18] and that in 3DHP dataset [36] are different. Thus it is unreasonable to trans-form these joints to the corresponding uniform 3D rotation.
To this end, we use a pose reﬁnement module to address above issues. (c) Shape reﬁnement module. Extra shape information is obtained by silhouettes from the off-the-shelf detector. We exploit the shape reﬁnement module to allevi-ate shape ambiguity. In summary, all the modules can be integrated into the lightweight framework seamlessly in an end-to-end manner.
We benchmark the proposed approach on various 3D hu-man pose datasets and it outperforms state-of-the-art un-supervised methods [48, 49] by 4.0 mm PMPJPE on Hu-man3.6M [18], 7.6 AUC on MPI-INF-3DHP [36] and 11.8 mm PMPJPE on Surreal [50]. 2.