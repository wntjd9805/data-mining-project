Abstract
We consider the problem of Federated Learning (FL) where numerous decentralized computational nodes collab-orate with each other to train a centralized machine learn-ing model without explicitly sharing their local data sam-ples. Such decentralized training naturally leads to issues of imbalanced or differing data distributions among the lo-cal models and challenges in fusing them into a central model. Existing FL methods deal with these issues by either sharing local parameters or fusing models via online dis-tillation. However, such a design leads to multiple rounds of inter-node communication resulting in substantial band-width consumption, while also increasing the risk of data leakage and consequent privacy issues. To address these problems, we propose a new distillation-based FL frame-work that can preserve privacy by design, while also con-suming substantially less network communication resources when compared to the current methods. Our framework engages in inter-node communication using only publicly available and approved datasets, thereby giving explicit pri-vacy control to the user. To distill knowledge among the various local models, our framework involves a novel en-semble distillation algorithm that uses both final prediction as well as model attention. This algorithm explicitly consid-ers the diversity among various local nodes while also seek-ing consensus among them. This results in a comprehensive technique to distill knowledge from various decentralized nodes. We demonstrate the various aspects and the asso-ciated benefits of our FL framework through extensive ex-periments that produce state-of-the-art results on both clas-sification and segmentation tasks on natural and medical images. 1.

Introduction
Modern deep learning algorithms rely on massive anno-tated datasets for many practical applications [63, 21, 18].
In most cases, however, this data is physically located across multiple disparate locations and regulated by dif-Figure 1. A schematic illustration of the proposed privacy-preserving federated learning framework compared to traditional update or parameter-sharing based federated learning frameworks.
Traditional FL frameworks transfer gradients or parameter updates produced with private data from local nodes to a server, risking pri-vacy leakage. Our framework only transfers products of unlabeled public data. ferent entities. This results in the challenges of central-izing the physically dispersed data, with the primary con-cerns being privacy and network bandwidth issues. Conse-quently, federated learning (FL) [46, 54, 17] has emerged as an important topic where a single centralized model is trained in a distributed, decentralized fashion using model fusion/distillation techniques.
While some similarities exist, there are many more unique challenges that make FL substantially different from distributed learning. First, privacy is a critical considera-tion, and maintaining it is of utmost importance, particu-larly for applications such as healthcare [44, 3]. Second, one needs to be able to train centralized models efficiently and not get bogged down by network communication is-sues. Communication bandwidth may be quite pronounced depending on the task (e.g. image and video applications) and quantity of data (e.g., model parameters) being shared
Figure 2. Overview of the proposed FedAD framework. among local nodes. Finally, given that raw data typically resides locally, the data collection and preprocessing mech-anisms may vary substantially among the local nodes, lead-ing to a situation where common assumptions such as inde-pendent and identically distributed sampling do not hold.
The current state-of-the-art FL techniques approach the aforementioned issues by repeatedly sharing local model parameters or their gradients during the training pro-cess [34, 47, 12, 24, 58, 49, 19, 30, 8]. However, for many applications, these parameter-based communication meth-ods suffer from impractical network bandwidth overhead, are limited only to models with homogeneous architectures, and more importantly, have many known security weak-nesses [4]. While some methods have taken a step towards data protection in medical imaging [26, 27], there are also counter arguments in the literature that show local private data can get exposed as a result of using publicly shared gradients in the FL technical pipeline [61].
Distillation-based techniques that aggregate locally-computed logits [16, 22, 4, 28, 62] form the basis for an-other line of work for building central models from multi-ple local models, helping eliminate the need for each lo-cal model to follow the same architecture. While some recent methods distill with public data to get around data privacy issues [22, 4], they assume both the public and pri-vate data are sampled from the same underlying distribu-tion. This assumption invariably exposes private data to security risks and attacks. While the recently proposed
FedDF [28] method provides some relaxations (e.g., pub-lic data can be unlabeled and domain robust, i.e., sampled from another domain), it still exchanges model parameters recursively, resulting in privacy vulnerabilities due to model memorization [61, 4]. Despite the known bottleneck of communication in FL, all the above methods jointly (online) optimize the central and local models by synchronizing lo-cal inferred predictions. This approach requires a high de-gree of synchronization and communication bandwidth. It is clear that these co-distillation methods require recursive communication primarily because these methods ensemble with dark knowledge, such as averaging to soften labels, leaving structural knowledge unexplored. In other words, in addition to distilling the final what (i.e., logits), using more feature information depicting the why (e.g., attention maps) should lead to improved performance and efficiency, which is largely ignored by the current state-of-the-art.
In this work, we present a new distillation-based feder-ated learning framework to address the aforementioned is-sues (Figure 1). First, our framework presents stronger pri-vacy guarantees of local data by only using model outputs of unlabeled public data during distillation without any ex-change of local model parameters or gradients. This, by de-sign, eliminates the vulnerabilities identified by prior work.
Second, in our framework, local models are fully trained and then distilled to the central server, in contrast to prior works [28, 4, 22] that synchronously update local models through online distillation.
Our key insight is that such well-trained local mod-els, as opposed to incremental snapshots of “half-baked” models [28, 4, 22], provide more structural knowledge about their expertise. This design choice immediately en-ables top-down class-specific attention maps that capture the fully-trained local model’s reasoning process (note that for methods that do online distillation, this would not be possible since their attention maps would be incomplete due to incremental training). We ensemble local knowledge with both predicted logits and these attention maps, captur-ing each local model’s final output as well as the underly-ing reasoning process. We also use these attention maps to capture the knowledge diversity across models and reach a consensus to effectively coordinate local expertise in the FL
paradigm. This in-depth ensemble strategy enables our fed-erated distillation to be completed in an offline fashion in a single round (which we call one-shot), helping keep local model training independent and asynchronous. This results in a FL framework that is substantially more efficient and flexible when compared to prior art.
To demonstrate efficacy, we conduct extensive experi-ments on CIFAR10/100 and large-scale chest x-ray datasets.
We also show our framework is flexible to be used in other tasks by conducting preliminary proof-of-concept experi-ments on the segmentation tasks, where we demonstrate the state-of-the-art privacy/performance trade-offs compared to prior methods.
To summarize, our key contributions are below:
• We propose a one-shot federated learning framework with one-way distillation to explicitly preserve the pri-vacy of local data by only distilling model outputs on unlabeled and domain robust public data.
• Our framework addresses the communication ineffi-ciencies of prior work by communicating high-level logits and model-agnostic attention maps.
• We introduce a seminal distillation algorithm that ag-gregates structural knowledge with explicit balance be-tween both local model diversity as well as consensus to deal with the inherent heterogeneity of decentralized federated learning.
• We show that the proposed framework can be extended to other applications such as semantic segmentation with evaluations on Cityscapes and BraTS dataset. 2.