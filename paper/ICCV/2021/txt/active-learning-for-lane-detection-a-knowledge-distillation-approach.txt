Abstract
Lane detection is a key task for autonomous driving ve-hicles. Currently, lane detection relies on a huge amount of annotated images, which is a heavy burden. Active learning has been proposed to reduce annotation in many computer vision tasks, but no effort has been made for lane detection.
Through experiments, we find that existing active learning methods perform poorly for lane detection, and the reasons are twofold. On one hand, most methods evaluate data un-certainties based on entropy, which is undesirable in lane detection because it encourages to select images with very few lanes or even no lane at all. On the other hand, ex-isting methods are not aware of the noise of lane annota-tions, which is caused by heavy occlusion and unclear lane marks. In this paper, we build a novel knowledge distillation framework and evaluate the uncertainty of images based on the knowledge learnt by the student model. We show that the proposed uncertainty metric overcomes the above two problems. To reduce data redundancy, we explore the in-fluence sets of image samples, and propose a new diversity metric for data selection. Finally we incorporate the uncer-tainty and diversity metrics, and develop a greedy algorithm for data selection. The experiments show that our method achieves new state-of-the-art on the lane detection bench-marks. In addition, we extend this method to common 2D object detection and the results show that it is also effective. 1.

Introduction
Lane detection is a crucial task for autonomous driving.
Recently, great advances have been made by deep learning to improve the lane detection performance [33, 31, 8]. How-ever, a deep model requires a huge amount of training data in order to yield a satisfying result. Due to the large aspect ratio and the special shape of lanes, it is highly expensive and cumbersome to annotate a sufficiently large dataset.
Active learning is a well-known technique to reduce the annotation cost [34, 42, 25]. It is proposed to select the most informative data items from the unlabeled dataset according
Figure 1: Examples of noisy annotations. All the lanes ex-cept the rightmost one are invisible (occluded or unclear) in the original image. Their locations are annotated by guess-ing and can be misleading to a lane detection model. to some policy. The selected data items are then annotated manually and added to the training set. Various selection policies have been proposed. Compared to the random se-lection, these policies manage to reduce the annotation cost by a large margin, and in the meanwhile, they are able to achieve a competitive, or even better, training performance.
However, though active learning has been fruitful in im-age classification [3, 42, 39], object detection [2, 6, 19], semantic segmentation [38, 41], and other non-computer-vision areas [30, 15, 32], we find that for the lane detection task, the existing methods are not so effective. The rea-sons are twofold. On one hand, entropy is widely used to estimate the uncertainty of images. The images with high-est entropy values are considered informative. But in prac-tice, we observe that entropy-based methods are prone to selecting images with very few lanes. These images pro-vide less useful information than normal ones, and there-fore a model trained using them does not perform well. On the other hand, lane annotations are often noisy. For ex-ample, on the CULane dataset [29], many annotations are made in regions where there are no visible lane marks at all. An example image is shown in Fig. 1. In these regions, annotators decide the location of an invisible lane just by guessing. The guessed annotations are often incorrect and can bring heavy noise. Existing methods do not model the noisy lane annotations, and are therefore easily disturbed.
Figure 2: Framework of our proposed method. We build three models, the large teacher model, the small student model, and the student model distilled by the teacher (Student-KD in the figure). The prediction gaps of three models on each unlabeled image are used to estimate the uncertainty. The diversity score of an image is estimated based on its influence set, extracted from the outcome of the student model. The uncertainty and diversity scores are combined as the final score for data selection.
In this paper, we propose the first active learning method for lane detection, as shown in Fig. 2. It is able to solve the two above-mentioned problems (i.e., unsuitable entropy metric and label noise). To get rid of estimating the entropy, we propose to use Knowledge Distillation (KD) to explore uncertain samples. We regard the lane detection model to be deployed as the student (denoted as Student-KD in Fig. 2), and train it together with a large teacher model. We use their prediction gap as the basic estimation of uncertainty.
In addition, we also use KD to solve the label noise prob-lem. We find that useful knowledge can be transferred from the teacher to the student, but label noise is difficult to trans-fer. On images with noisy labels, the prediction gaps be-tween the teacher and the student are generally larger than those on normal images. However, a large prediction gap between the teacher and the student does not necessarily in-dicate high label noise. There can be knowledge, i.e., label with no noise, which is naturally difficult for the student to learn. To distinguish noise from hard-to-learn knowledge, we train another student model (denoted as Student in Fig. 2) that has the same structure as Student-KD. The difference is that we train it independently without knowledge distilla-tion from the teacher. We also measure the prediction gap between the two students. Since label noise is random, on a noisy image, the prediction gap between any pair of the three models is likely to be large. On the contrary, a small prediction gap between any pair of the models indicates that the label noise is likely to be low. Based on these obser-vations, we propose a novel uncertainty metric that is able to capture both the knowledge and the noise. Images with more knowledge and less noise are selected. ric that uses influence sets [23] to estimate the diversity of a selected set. In the data selection phase, we calculate the similarity between unlabeled images based on their feature maps. Given the pair-wise similarity, we build the influence set for each image based on its reverse nearest neighbors and estimate the diversity score. Then, the uncertainty score and diversity score are combined as the final score for data selection (see Fig. 2). We formulate the data selection as a set cover problem, and use a greedy algorithm to solve it.
We perform extensive experiments on the most widely used benchmarks [29, 4]. The results show that our method achieves state-of-the-art performance on all the datasets. In addition, we adapt our method to 2D object detection and test it on a benchmark. The results show that our method outperforms a recent active learning method specifically de-signed for 2D object detection, and is therefore extendable to other visual recognition tasks.
Our contributions are summarized as follows: 1. We propose the first active learning method for lane detection. A knowledge distillation framework is built to solve the two specific problems in lane detection, the unsuitable entropy and label noise problems. We are also the first to explore knowledge distillation in the data selection of active learning. 2. We propose a novel uncertainty metric that is able to capture both knowledge and noise. Besides, we present a diversity metric based on reverse nearest neighbors to solve the data redundancy problem. The combination of the two metrics is not only effective but also extendable to other visual recognition tasks.
Uncertainty is not the only factor to decide the informa-tiveness of a sample. Data redundancy can lead to waste in annotation cost [37]. Therefore, diversity is also a key factor for efficient data selection. We present a new diversity met-3. The experiments on two widely used lane detection benchmarks show that our method outperforms recent active learning methods. We also demonstrate the ef-fectiveness of our method for object detection.
2.