Abstract
We present Region Similarity Representation Learning (ReSim), a new approach to self-supervised representation learning for localization-based tasks such as object detec-tion and segmentation. While existing work has largely focused on solely learning global representations for an entire image, ReSim learns both regional representations for localization as well as semantic image-level represen-tations. ReSim operates by sliding a fixed-sized window across the overlapping area between two views (e.g., im-age crops), aligning these areas with their corresponding convolutional feature map regions, and then maximizing the feature similarity across views. As a result, ReSim learns spatially and semantically consistent feature repre-sentation throughout the convolutional feature maps of a neural network. A shift or scale of an image region, e.g., a shift or scale of an object, has a corresponding change in the feature maps; this allows downstream tasks to leverage these representations for localization. Through object de-tection, instance segmentation, and dense pose estimation experiments, we illustrate how ReSim learns representa-tions which significantly improve the localization and clas-sification performance compared to a competitive MoCo-v2 baseline: +2.7 APbb 75 VOC, +1.1 APbb 75 COCO, and +1.9
APmk Cityscapes. Code and pre-trained models are released at: https://github.com/Tete-Xiao/ReSim 1.

Introduction
Recently, self-supervised pre-training has outperformed supervised pre-training for a number of computer vision ap-plications such as image classification and object detection
[4, 5, 6]. Much of this recent progress comes from exploit-ing the instance discrimination task [1, 14, 37, 52, 56], in which a network learns image-level features that are invari-ant to certain image augmentations. Specifically, instance discrimination maximizes the similarity of two views of an image, where each view is an augmented version of an im-*: Equal contribution.
Figure 1. Existing instance discrimination-based self-supervised learning frameworks learn representations by augmenting an im-age into two different views (e.g., cropping/scaling the input im-age) and then maximizing the similarity between the image fea-tures for the entire views. In this work, we present Region Sim-ilarity Representation Learning (ReSim), which learns represen-tations by maximizing the similarity of corresponding sub-image regions throughout the convolutional layers of a network. In the above example, instance discrimination learns to map both views to the same features, despite the fact that the dog’s eyes and ears are in different locations. On the other hand, ReSim learns features which explicitly align these changes with corresponding changes in the convolutional feature maps. age, while minimizing its similarity to views which origi-nate from other images [4, 5, 7].
Chen et al. [5] compared a diverse set of possible aug-mentations, and found that random cropping and scaling have the largest impact on downstream ImageNet [9] classi-fication performance. Several follow-up works have further explored augmentation policies and confirmed this find-ing [43, 47, 53]. Through cropping and scaling augmen-tations and similarity maximization, the network learns to map various scales and crops of an image to the same fea-ture representations. For example, an image crop of the top half of a dog’s body and the right half of a dog’s body would map to the same representation in the embedding space, which a downstream task could then classify as “dog”.
However, instance discrimination uses global image-level feature representations for these views, which is ob-tained by average pooling the final convolutional feature
Figure 2. ReSim takes two different views of an image as input, i.e., a query and key view obtained by cropping/scaling an image. The views have an associated overlapping area as highlighted in each of the above views. Both views are encoded using the same network (CNN), e.g., a ResNet-50 [27]. Before the final convolutional layers in the network, ReSim slides a fixed-size window over the overlapping area between the two views, aligns window regions with corresponding regions in the convolutional feature maps using Precise RoI Pooling from [30], and then maximizes the similarity between these features. Earlier layers use smaller sliding windows as the feature maps have higher spatial resolution. Furthermore, similar to Feature Pyramid Networks [33], the feature maps are combined with semantic top-down features from later convolution layers, as indicated by the blue arrows and “[P3]/[P4]/[P5]” layers. The feature maps following the final convolutional layer are used for instance discrimination learning following either [6] or [7]. map. It does not enforce any type of spatial consistency in the convolutional features (see Figure 1, “instance discrim-ination” path). For example, different crops that scale and shift the dog’s ear will not necessarily have a corresponding scale and shift in the convolutional feature maps through-out the network – instance discrimination only optimizes the final globally pooled features. This is problematic for downstream tasks such as object detection that leverage the spatial information from the convolutional feature maps for object localization.
To address this issue, we introduce Region Similarity
Representation Learning (ReSim): a self-supervised pre-training method which learns spatially consistent features across multiple convolutional layers. Inspired by the Re-gion Proposal Network (RPN) used in Faster-RCNN [44],
ReSim operates by sliding a fixed-size window across the overlapping region between two image views, mapping the corresponding regions in each view to their associated re-gions in the convolutions layers throughout the network, and then maximizing the similarity of these convolution fea-ture regions, along with the global similarity objective. See
Figure 1 for a high-level difference between ReSim and ex-isting instance discrimination techniques, and see Figure 2 for a detailed description of the full ReSim pipeline.
As we show, maximizing the similarity of these convo-lutional feature map regions leads to representations that improve object localization for downstream detection and instance segmentation tasks. Furthermore, we extend the framework to learn features at various scales by using slid-ing windows of multiple sizes at different feature maps.
We adopt the Feature Pyramid Network (FPN) design from
Lin et al. [33], a design which naturally incorporates fea-ture hierarchies and propagates stronger semantic features to earlier convolutional layers through the top-down path.
Region-level self-supervised similarity learning trains fea-ture pyramid layers without labeled supervision and leads to further improvement on downstream tasks.
We conduct object detection, instance segmentation, and dense pose estimation experiments on PASCAL VOC [17],
COCO [34], and Cityscapes [8] and show that ReSim learns representations which significantly improve the classifica-tion and localization performance compared to a MoCo-v2 baseline, i.e., +2.7 APbb 75 on COCO, and +1.9 APmk on Cityscapes. 75 on VOC, +1.1 APbb 2.