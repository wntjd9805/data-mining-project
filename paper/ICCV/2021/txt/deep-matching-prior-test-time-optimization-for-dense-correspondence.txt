Abstract
Conventional techniques to establish dense correspon-dences across visually or semantically similar images fo-cused on designing a task-speciﬁc matching prior, which is difﬁcult to model in general. To overcome this, recent learning-based methods have attempted to learn a good matching prior within a model itself on large training data.
The performance improvement was apparent, but the need for sufﬁcient training data and intensive learning hinders their applicability. Moreover, using the ﬁxed model at test time does not account for the fact that a pair of images may require their own prior, thus providing limited performance and poor generalization to unseen images.
In this paper, we show that an image pair-speciﬁc prior can be captured by solely optimizing the untrained match-ing networks on an input pair of images. Tailored for such test-time optimization for dense correspondence, we present a residual matching network and a conﬁdence-aware con-trastive loss to guarantee a meaningful convergence. Ex-periments demonstrate that our framework, dubbed Deep
Matching Prior (DMP), is competitive, or even outper-forms, against the latest learning-based methods on several benchmarks for geometric matching and semantic match-ing, even though it requires neither large training data nor intensive learning. With the networks pre-trained, DMP at-tains state-of-the-art performance on all benchmarks. 1.

Introduction
Establishing dense correspondences across visually or semantically similar images facilitates a variety of computer vision applications [45, 44, 28, 37]. Unlike sparse corre-spondence [48, 5, 76] that detects sparse points and ﬁnds matches across them, dense correspondence [45, 6, 35, 37] aims at ﬁnding matches at each pixel and thus can beneﬁt from prior1 knowledge about matches among nearby pixels.
Typically, stereo matching [32, 6] and optical ﬂow [24, 65] modeled the prior term that makes the correspondence
∗Corresponding author 1It can also be called a smoothness or a regularizer in literature. (a) (b) (c) (d) (e) (f) (g) (h)
Figure 1. Visualization of DMP results: (a) source image, (b) tar-get image, results of (c) winner-takes-all (WTA) and (d) learning-based method (e.g., GLU-Net [70]). As the iteration evolves (e), (f), (g), and (h), DMP with untrained networks estimates more op-timal correspondence ﬁelds by optimizing the networks on a single pair of images, while learning-based methods utilize pre-trained and ﬁxed networks at test time, thus providing limitation. smooth while aligning discontinuities to image boundaries.
Some methods [45, 67, 19, 38] for semantic matching also exploited this to regularize the correspondence within a lo-cal neighborhood. Although they can be formulated in var-ious ways, these optimization-based methods [45, 67, 19, 38] formulate an objective function with explicitly deﬁned matching data and prior terms and minimize the objective on a single image pair. These methods are capable of mak-ing corrections to the estimated correspondence during op-timization, but they require a task-speciﬁc prior, which is complex to formulate.
Unlike these learning-free methods [45, 67, 19, 38], recent methods [55, 66, 61, 49, 70] cast this task as a learning problem, seeking to learn a matching model to directly regress the correspondence. The model, of-ten implemented based on convolutional neural networks (CNNs) [64, 22], is generally trained on large datasets of image pairs, based on the belief that an optimal matching prior can be learned from such observations. As proven in literature [49, 70], these learning-based methods outper-form traditional optimization-based methods [45, 19, 38],
which can be attributed to their high capacity to learn a good matching prior. They, however, often require large training data with ground-truth correspondences, which are notori-ously hard to collect, or intensive learning [49, 70], which hinders their applicability. In addition, a pair of images may require their own prior, and thus using pre-trained and ﬁxed parameters at test time may provide limited and poor gen-eralization performance to unseen image pairs.
In this paper, we show that, for the ﬁrst time, the match-ing prior must not necessarily be learned from large training data; instead, it can be captured by optimizing the untrained matching networks on a single pair of images, proving that the structure of the networks is sufﬁcient to capture a great deal of matching statistics. Our framework, dubbed Deep
Matching Prior (DMP), requires neither large training sets nor intensive training, but it is competitive against learning-based methods [55, 66, 49, 61, 70, 62] or even outperforms, and does not suffer from the generalization issue.
Such a test-time optimization for dense correspondence, however, is extremely hard to converge due to the limited samples, high-dimensional search space, and non-convexity of the objective. To elevate the stability and boost the con-vergence, we propose a residual matching network, which exploits a distilled information from matching correlation that plays as a guidance for providing a good starting match and suppressing the possibility of getting stuck in local minima. We also propose a conﬁdence-aware contrastive loss that only takes the matches with high conﬁdence to eliminate the ambiguous matches. Fig. 1 visualizes the results of DMP in comparison with recent learning-based method [70].
The presented approach is evaluated on several bench-marks for dense correspondence and examined in an abla-tion study. The extensive experiments show that our model produces competitive results and even outperforms other learning-based methods [55, 66, 61, 49, 70], and once the networks are pre-trained, state-of-the-art performance is at-tained on all the benchmarks in experiments. 2.