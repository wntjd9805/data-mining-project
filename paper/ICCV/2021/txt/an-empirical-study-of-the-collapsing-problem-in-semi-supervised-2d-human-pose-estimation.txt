Abstract
Images under
Augmentations
Network
Heatmap (cid:55)(cid:85)(cid:68)(cid:81)(cid:86)(cid:73)(cid:82)(cid:85)(cid:80)(cid:72)(cid:71)(cid:3)(cid:43)(cid:72)(cid:68)(cid:87)(cid:80)(cid:68)(cid:83)
Most semi-supervised learning models are consistency-based, which leverage unlabeled images by maximizing the similarity between different augmentations of an image. But when we apply them to human pose estimation that has ex-tremely imbalanced class distribution, they often collapse and predict every pixel in unlabeled images as background.
We ﬁnd this is because the decision boundary passes the high-density areas of the minor class so more and more pixels are gradually mis-classiﬁed as background. In this work, we present a surprisingly simple approach to drive the model to learn in the correct direction. For each image, it composes a pair of easy-hard augmentations and uses the more accurate predictions on the easy image to teach the network to learn pose information of the hard one. The ac-curacy superiority of teaching signals allows the network to be “monotonically” improved which effectively avoids collapsing. We apply our method to the state-of-the-art pose estimators and it further improves their performance on three public datasets. 1.

Introduction 2D human pose estimation has many practical applica-tions such as 3D pose modeling [48, 35, 23] and action recognition [37, 38]. The early works in deep learning try to regress joint coordinates from images directly [34, 5].
But most recent ones adopt the heatmap-based framework
[33, 39, 24, 30, 41] because it provides better supervision.
But there is a more important but less explored problem of learning robust models that perform well on unseen wild images. One solution is to ﬁt the “whole” world by in-ﬁnitely increasing training images. The other is to transfer pre-trained models to new domains by unsupervised ﬁne-tuning. The common basis behind the two approaches is
Semi-Supervised Learning (SSL)— how to leverage unla-beled images to obtain a generalizable model?
Images (cid:1846)(cid:3032) (cid:1835)(cid:3032) (cid:1835) (cid:1846)(cid:3035) (cid:1835)(cid:3035) (cid:1858)(cid:3087) (cid:1858)(cid:3087) (cid:1846)(cid:3032)(cid:1372)(cid:3035) (cid:1834)(cid:3087)(cid:481)(cid:3032) (cid:1846)(cid:3032)(cid:1372)(cid:3035)(cid:4666)(cid:1834)(cid:3087)(cid:481)(cid:3032)(cid:4667)
Teacher (cid:1834)(cid:3087)(cid:481)(cid:3035) (cid:1865)(cid:1861)(cid:1866) (cid:36)(cid:3087)
Student
Figure 1. Our approach to avoid “collapsing” in semi-supervised human pose estimation. For each unlabeled image, we compose an easy and hard image pair Ie and Ih using two augmentation methods Te and Th, respectively, and feed them to the network fθ. We use the heatmaps Te→h(Hθ,e) on the easy image to teach the network to learn about the hard image. Te→h maps the two heatmaps of the augmented images. Lθ represents the consistency loss. The accuracy superiority allows the network to be “mono-tonically” improved which avoids collapsing.
The previous SSL works have primarily focused on the classiﬁcation task. In general, there are two strategies to ex-plore unlabeled images. The ﬁrst is Pseudo labeling [26, 42] which ﬁrst learns an initial model on only labeled images in a supervised way. Then, for each unlabeled image, it applies the initial model to obtain hard or soft pseudo labels repre-senting its category. Finally, it learns the ultimate model on the combined dataset of labeled and pseudo-labeled im-ages. However, the performance of the method is largely limited by that of the initial model which is learned only on the labeled images and ﬁxed thereafter.
The second class of methods [2, 19, 27, 28, 31] learn about unlabeled images by requiring the network to have similar predictions for different augmentations of the same image. They are better than the pseudo labeling methods because the accuracy is not limited by the ﬁxed labeling network. However, when we apply them to 2D pose esti-mation, we ﬁnd that all of them encounter the collapsing problem meaning that, within few training iterations, the models begin to predict every pixel in unlabeled images as background. As a result, the prediction accuracy becomes even worse than the initial supervised model.
The collapsing problem is not identiﬁed as a serious is-sue in previous works because most of them were only eval-uated on the well-balanced classiﬁcation task. But we ﬁnd it is vital for tasks with severe class imbalance such as human pose estimation, which has not received sufﬁcient attention.
It occurs because when the network makes different predic-tions on the corresponding pixels, it lacks sufﬁcient infor-mation to determine the correct optimization path. Blindly minimizing their discrepancy causes the decision boundary to be incorrectly formed due to imbalance and pass through the high-density area of the minor class as revealed in [14].
It leads to the situation where a growing number of pixels are mis-classiﬁed as background.
In this work, a simple approach is presented to address the collapsing problem. We ﬁrst introduce the concept of easy-hard augmentation pair and, by deﬁnition, a network should obtain better average accuracy on a certain dataset with easy augmentation than on the same dataset with hard augmentation. Then, for each unlabeled image, we com-pose an easy and a hard augmentation, feed them to the network and obtain two heatmap predictions. We use the accurate predictions on the easy augmentation to teach the network to learn about the corresponding hard augmenta-tion (see Figure 1). However, the hard augmentation will not be used for teaching the network to learn about the easy augmentation, which avoids high response samples being pulled to background as illustrated in Figure 2. The relative accuracy superiority of the teaching signals allows the net-work to be “monotonically” improved which stabilizes the training and avoids collapsing.
Our approach is general and applies to most consistency-based SSL methods such as [17, 19] for stopping collapsing.
We empirically validate it on a simple baseline as well as on the state-of-the-art method [17] which jointly learns two models. Both methods collapse in their original setting and our easy-hard augmentation strategy helps avoid the prob-lem. We extensively evaluate them on three public datasets of COCO [22], MPII [1] and H36M [15]. When the num-ber of labeled images is small, our approach increases the mean Average Precision (AP) by about 13% (from 31.5% to 44.6%) compared to the supervised counterpart which only uses labeled data for training. As a comparison, the pseudo labeling methods of [42] and [26] only get 37.2% and 37.6% mean AP, respectively. More importantly, when we apply our method to the best 2D pose estimator and use all available labeled training images, it can further im-prove the performance by a decent margin by exploring un-labeled images. We also report results when our approach is used for semi-supervised pre-training and domain adap-tation tasks. The versatile practical applications in various settings validate the values of this work. 2.