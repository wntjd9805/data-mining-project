Abstract
In this work, for the first time, we address the prob-lem of universal cross-domain retrieval, where the test data can belong to classes or domains which are unseen during training. Due to dynamically increasing number of cate-gories and practical constraint of training on every possi-ble domain, which requires large amounts of data, gener-alizing to both unseen classes and domains is important.
Towards that goal, we propose SnMpNet (Semantic Neigh-bourhood and Mixture Prediction Network), which incor-porates two novel losses to account for the unseen classes and domains encountered during testing. Specifically, we introduce a novel Semantic Neighborhood loss to bridge the knowledge gap between seen and unseen classes and en-sure that the latent space embedding of the unseen classes is semantically meaningful with respect to its neighboring classes. We also introduce a mix-up based supervision at image-level as well as semantic-level of the data for training with the Mixture Prediction loss, which helps in efficient re-trieval when the query belongs to an unseen domain. These losses are incorporated on the SE-ResNet50 backbone to obtain SnMpNet. Extensive experiments on two large-scale datasets, Sketchy Extended and DomainNet, and thorough comparisons with state-of-the-art justify the effectiveness of the proposed model. 1.

Introduction
Due to the availability of large amount of data in different domains of multi-media, cross-domain retrieval has gained significant attention.
It addresses the chal-lenging problem of retrieving relevant data from a do-main (say, image), when the query belongs to a differ-ent domain (e.g. sketch, painting etc.). As motiva-tion for our work, we focus on the specific application of sketch-based image retrieval (SBIR) [14][34], which has wide range of applications in e-commerce, forensic data matching, etc. Considering the dynamic real-world,
* Equal contribution. where the search dataset is always being augmented with new categories of data, recently, the focus has shifted to zero-shot SBIR (ZS-SBIR) or generalized ZS-SBIR (GZS-SBIR) [26][32][4][15][5][7], in which, the query and search set samples belong to classes not seen during training.
The generic architecture for ZS-SBIR (or other cross-domain retrieval applications) consists of two parallel branches, each consisting of a feature extractor and a clas-sifier, to learn the latent-space representations of the data from individual domains (here, sketches and images). The domain gap in this latent space is bridged by the semantic descriptions [19][22] of the seen classes. During testing, the query sketch and search set images are projected to this space and compared directly for retrieval. But if the query belongs to a different domain, say painting, then this net-work needs to be re-trained, with painting and images as the two domains. This not only requires the training to be performed for every domain-pair with sufficient amount of data, but also, the query domain needs to be known a-priori.
Here, we attempt a more realistic and significantly more challenging cross-domain retrieval scenario, where the query data can belong not only to unseen classes, but also to unseen domains - which we term as universal cross-domain retrieval (UCDR). It is a combination of two well-studied, but separate problems in literature, namely, ZS-SBIR, which accounts for test data from unseen classes and domain generalization (DG) [28][10], which accounts for test data from unseen domains in the classification. To this end, we propose SnMpNet (Semantic Neighbourhood and Mixture Prediction Network), which is a single-branch network consisting of a feature extractor and classifier, for learning a domain-independent embedding of input data, that also generalizes to unseen category test data. For gener-alizing to unseen classes, we propose Semantic Neighbour-hood Loss, to represent the unseen classes in terms of their relative positions with the seen classes.
In addition, we exploit the mix-up technique [33] to populate our training set with samples created through both inter-class and inter-domain mixing to prepare for unseen domains of query sam-ples during testing. To better generalize across domains, we propose a novel Mixture Prediction Loss. The contributions
of this work are summarized below: (1) We propose a novel framework SnMpNet, to address the universal cross-domain retrieval scenario, where the query data may belong to seen / unseen classes, along with seen / unseen domains. To the best of our knowledge, this is the first work in literature addressing this extremely challeng-ing problem. (2) We propose two novel losses, namely Semantic Neigh-bourhood loss and Mixture Prediction loss, to account for unseen classes and unseen domains during testing. (3) Extensive experiments and analysis of the proposed framework on Sketchy-Extended [24] and DomainNet [21] datasets are reported along with other state-of-the-art ap-proaches modified for this application. 2.