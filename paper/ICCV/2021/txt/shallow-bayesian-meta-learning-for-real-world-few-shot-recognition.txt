Abstract
Many state-of-the-art few-shot learners focus on develop-ing eﬀective training procedures for feature representations, before using simple (e.g., nearest centroid) classiﬁers. We take an approach that is agnostic to the features used, and focus exclusively on meta-learning the ﬁnal classiﬁer layer. Specif-ically, we introduce MetaQDA, a Bayesian meta-learning generalisation of the classic quadratic discriminant analysis.
This approach has several beneﬁts of interest to practition-ers: meta-learning is fast and memory eﬃcient, without the need to ﬁne-tune features. It is agnostic to the oﬀ-the-shelf features chosen, and thus will continue to beneﬁt from future advances in feature representations. Empirically, it leads to excellent performance in cross-domain few-shot learn-ing, class-incremental few-shot learning, and crucially for real-world applications, the Bayesian formulation leads to state-of-the-art uncertainty calibration in predictions. 1.

Introduction
Few-shot recognition methods aim to solve classiﬁcation problems with limited labelled training data, motivating a large body of work [62]. Contemporary approaches to few-shot recognition are characterized by a focus on deep meta-learning [23] methods that provide data eﬃcient learning of new categories by using auxiliary data to train a model designed for rapid adaptation to new categories
[8, 68], or for synthesizing a classiﬁer for new categories in a feed-forward manner [38, 43]. Most of these meta-learning methods have been intimately interwoven with the training algorithm and/or architecture of the deep network that they build upon. For example, many have relied on episodic training schemes [52, 59], where few-shot learning problems are simulated at each iteration of training; diﬀerentiable optimisers [3, 30], or new neural network modules [55, 15]
∗Xueting and Debin contributed equally to this research, code is available https://github.com/Open-Debin/Bayesian_MQDA to facilitate data eﬃcient learning and recognition.
Against this backdrop, a handful of recent studies
[61, 14, 4, 37, 64, 60] have pushed back against deep meta-learning. They have observed, for example, that a well tuned convolutional network pre-trained for multi-class recognition and combined with a simple linear or nearest centroid clas-siﬁer can match or outperform state-of-the-art meta-learners.
Even self-supervised pre-training [37] has led to feature ex-tractors that outperform many meta-learners. These analyses raise the question: is meta-learning indeed beneﬁcial, or is focusing on improving conventional pre-training suﬃcient?
We take a position in defense of meta-learning for few-shot recognition. To disentangle the inﬂuences of meta-learning per-se and feature learning discussed above, we restrict ourselves to ﬁxed pre-trained features and conduct no feature learning in this study. It shows that meta-learning, even in its shallowest form, can boost few-shot learning above and beyond whatever is provided by the pre-trained features alone.
We take an amortized Bayesian inference approach [15, 21] to shallow meta-learning. During meta-testing, we infer a distribution over classiﬁer parameters given the support set; and during meta-training we learn a feed-forward inference procedure for these parameters. While the limited recent work in Bayesian meta-learning is underpinned by amortized
Variational Inference [15], our approach relies instead on con-jugacy [12]. Speciﬁcally, we build upon the classic Quadratic
Discriminant Analysis (QDA) [9] classiﬁer and extended it with a Bayesian prior, an inference pipeline for the QDA parameter posterior given the support set, and gradient-based meta-training. We term the overall framework MetaQDA.
MetaQDA has several practical beneﬁts for real-world deployments. Firstly, MetaQDA allows meta-learning to be conducted in the resource constrained scenario without end-to-end training [24], while providing superior performance to
ﬁxed-feature approaches [61, 4, 37]. Furthermore by decom-posing representation learning from classiﬁer meta-learning,
MetaQDA is expected to beneﬁt from continued progress in CNN architectures and training strategies.
Indeed our empirical results show our feature-agnostic strategy beneﬁts
a diverse range of classic and recent feature representations.
Secondly, as computer vision systems begin to be deployed in high-consequence applications where safety [28] or fair societal outcomes [5] are at stake, their calibration becomes as equally, or more, important as their actual accuracy. E.g.,
Models must reliably report low-certainty in those cases where they do make mistakes, thus allowing their decisions in those cases to be reviewed. Indeed, proper calibration is a hard requirement for deployment in many high importance applications [17, 40]. Crucially, we show that our Bayesian
MetaQDA leads to signiﬁcantly better calibrated models than the standard classiﬁers in the literature.
Finally, we show that MetaQDA has particularly good performance in cross-domain scenarios where existing methods are weak [4], but which are ubiquitious in prac-tical applications, where there is invariably insuﬃcient domain-speciﬁc data to conduct in-domain meta-learning
[18]. Furthermore, as a Bayesian formulation, MetaQDA is inherently suited to the highly practical, but otherwise hard to achieve setting of incremental [56, 45] few-shot learning, where it achieves state of the art performance ‘out of the box’.
To summarize our contributions: (i) We present MetaQDA, a novel and eﬃcient Bayesian approach to classiﬁer meta-learning based on conjugacy. (ii) We empirically demonstrate that MetaQDA’s eﬃcient ﬁxed feature learning provides excellent performance across a variety of settings and metrics including conventional, cross-domain, class-incremental, and probability calibrated few-shot learning. (iii) We shed light on the meta-learning vs vanilla pre-training debate by disentan-gling the two and showing a clear beneﬁt from meta-learning, across a variety of ﬁxed feature representations. 2.