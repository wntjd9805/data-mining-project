Abstract
Sparse voxel-based 3D convolutional neural networks (CNNs) are widely used for various 3D vision tasks. Sparse voxel-based 3D CNNs create sparse non-empty voxels from the 3D input and perform 3D convolution operations on them only. We propose a simple yet effective padding scheme
— interpolation-aware padding to pad a few empty voxels adjacent to the non-empty voxels and involve them in the 3D
CNN computation so that all neighboring voxels exist when computing point-wise features via the trilinear interpolation.
For fine-grained 3D vision tasks where point-wise features are essential, like semantic segmentation and 3D detection, our network achieves higher prediction accuracy than the existing networks using the nearest neighbor interpolation or the normalized trilinear interpolation with the zero-padding or the octree-padding scheme. Through extensive compar-isons on various 3D segmentation and detection tasks, we demonstrate the superiority of 3D sparse CNNs with our padding scheme in conjunction with feature interpolation. 1.

Introduction
Effective 3D representations for 3D deep learning like voxels [2, 30], point sets [19, 12], and polygonal meshes [25, 11], have been actively studied in recent years. Among them, voxel-based representations are natural extensions from 2D pixels and are compatible with regular-grid-based convolutional operations and suitable for fast GPU process-ing. However, due to the high cost of memory storage and
CNN computation on dense 3D grids, dense-voxel-based 3D CNNs are limited to coarse resolution inputs like 323 grids, and cannot handle and generate high-resolution 3D contents. To overcome this limitation, sparse-voxel-based
CNNs [26, 21, 9, 3] are proved to be a computational and memory-efficient solution, where only voxels around 3D shapes are created for storing feature channels. With regard to the prediction accuracy on 3D tasks, spare-voxel-based
CNNs dominate several large-scale benchmarks, including
ScanNet segmentation [6], KITTI segmentation [1], and
ScanNet detection [18]. (a) (b) (c) (d)
Figure 1: Various padding schemes for a 2D point set (upper) and a 3D point set (bottom). (a): sparse pixels/voxels without padding, i.e. , zero padding; (b): with 1-ring padding; (c): with quadtree-padding or octree-padding; (d): with our interpolation-aware padding. Red circles present 2D points sampled from a 2D bunny shape, 3D points are omitted here as they are hidden inside the voxels.
Sparse-voxel-based CNNs can be used naturally for ex-tracting features for each discrete voxel. However, point-wise features are essential for fine-grained tasks, like 3D segmentation and detection. A common practice in sparse-voxel-based CNNs is to assign the feature of the nearest voxel to the point, i.e. , using the nearest neighbor inter-polation [26, 9]. To extract distinguishable point features within the same voxel, voxel-based trilinear interpolation can be adopted. The trilinear interpolation requires query-ing features from the nearby eight voxels, whereas some nearby voxels may not exist due to the sparse-voxel rep-resentation. Specifically, octree-based 3D CNNs [26, 27] perform the CNN computation on 8 sibling octants of non-empty octants (see Fig. 1-(c)); the recent sparse-voxel-based
CNNs [9, 3, 22] use Hash tables to index the non-empty voxels, and perform the CNN computation only in the non-empty voxels (see Fig. 1-(a)). To do the interpolation, exist-ing works either assign zero features to those non-existing voxels [3], or use normalized interpolation weights to com-promising the missing voxels [28, 23].
We observe that current interpolation schemes are
not optimal, and even yield worse performance than the nearest-neighbor interpolation in some experiments. Our key idea is to let the network learn features for the empty voxels, and use these learned features to do the interpolation, instead of using zero features. To this end, a na¨ıve solution is to pad 1-ring neighbors of all original non-empty voxels when building the sparse voxel grids, denoted as 1-ring padding (see Fig. 1-(b)). Then these augmented voxels can be used as the input of CNNs, and all voxel features required by the interpolation can be computed by CNNs. However, this may incur great computation and memory costs. Considering that what we need are the point features, we can only pad those voxels required by the interpolation of each point (see Fig. 1-(d)). We term our padding scheme as interpolation-aware padding. With our padding scheme, the interpolation is well-defined for each point, and the network performance can be greatly improved compared with the previous interpolation schemes. Compared with the 1-ring padding, the memory cost of interpolation-aware padding is also much less.
Our improved interpolation also facilitates the network design. Previous sparse-voxel-based CNNs for segmentation and detection output the features of discrete voxels [26, 3], the resolution of the output voxels has to be high enough to differentiate different points, otherwise the performance may decrease dramatically. With well-defined interpolation, our network instead outputs coarse resolution voxel features to extract expressive point-wise features, and further reduces the computation and memory cost. Apart from the benefits of the interpolation, we also compare the four different padding schemes in Fig. 1. Interestingly, our experiments reveal that padding itself also boosts the network prediction accuracy, even without the trilinear interpolation.
Our contributions include the improved interpolation for sparse-voxel CNNs by the interpolation-aware padding scheme, and network architectures for 3D segmentation and detection which can produce point-wise features without using very high-resolution voxels. To validate the efficacy and superiority of our method, we performed a series of experiments and comparisons on several typical 3D seman-tic segmentation and 3D detection tasks. Compared with the network using zero-padding and without interpolation, our network with the same number of trainable parameters improves the mean Intersection over Union (mIoU) of seg-mentation on PartNet [17], ScanNet [6] and KITTI [1] by 2.2, 2.0, and 2.4, respectively, and improves the mAP of detection on ScanNet [6] by 2.0. Compared with the 1-ring padding, our interpolation-aware padding scheme is more practical with less memory consumption. In the supplemen-tal material, we provide our code for reproducing all the results easily. We believe our effective interpolation and sparse padding scheme will be a powerful plug-in for sparse 3D CNNs and benefit more broad applications. 2.