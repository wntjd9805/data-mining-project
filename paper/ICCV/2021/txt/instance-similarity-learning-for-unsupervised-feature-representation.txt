Abstract
In this paper, we propose an instance similarity learn-ing (ISL) method for unsupervised feature representation.
Conventional methods assign close instance pairs in the feature space with high similarity, which usually leads to wrong pairwise relationship for large neighborhoods be-cause the Euclidean distance fails to depict the true se-mantic similarity on the feature manifold. On the contrary, our method mines the feature manifold in an unsupervised manner, through which the semantic similarity among in-stances is learned in order to obtain discriminative repre-sentations. Speciﬁcally, we employ the Generative Adver-sarial Networks (GAN) to mine the underlying feature man-ifold, where the generated features are applied as the prox-ies to progressively explore the feature manifold so that the semantic similarity among instances is acquired as reliable pseudo supervision. Extensive experiments on image clas-siﬁcation demonstrate the superiority of our method com-pared with the state-of-the-art methods. The code is avail-able at https://github.com/ZiweiWangTHU/ISL.git. 1.

Introduction
Deep neural networks have achieved the state-of-the-art performance in various vision applications such as face recognition [7, 45, 34], object detection [41, 33, 30], image retrieval [14, 42, 32] and many others. However, most suc-cessful deep neural networks are trained with strong super-vision, which requires a large amount of labeled data with expensive annotation cost and strictly limits the deployment of deep models. Hence, it is desirable to train deep neural networks with only the unlabeled data while achieving com-parable performance with supervised learning.
To enable deep neural networks to learn from the unla-beled data, unsupervised learning methods have been wide-∗Corresponding author
Figure 1. The difference among clustering methods, instance speciﬁcity analysis methods, neighborhood discovery methods and our method. The clustering methods are error-prone because of the complicated inter-class boundaries, and the instance speci-ﬁcity analysis methods are weakly discriminative due to the am-biguous supervision that treats each sample as an independent class. Meanwhile, the neighborhood discovery methods regard the instances close to the anchor as similar samples and fails to depict the true semantic similarity in large neighborhoods on the feature manifold. On the contrary, we mine the feature manifold and learn the instance-to-instance relationship with reliable semantic simi-larity, so that informative features can be obtained. ly studied recently. The clustering methods [24, 47, 3] shown in the ﬁrst column of Figure 1 provide pseudo labels to train the networks according to the cluster indexes, which are error-prone due to the complex inter-class boundaries.
The instance speciﬁcity analysis methods [46, 2, 38, 16, 21] depicted in the second column of Figure 1 regard every s-ingle sample as an independent class to avoid clustering.
However, the offered supervision is ambiguous and results in weak class discrimination. Meanwhile, designing pre-text tasks with self-supervised learning [8, 51, 44] shares the same limitations of instance speciﬁcity analysis method-s due to the discrepancy between the auxiliary supervision and the target task. In order to mitigates the disadvantages of clustering and instance speciﬁcity analysis, neighbor-hood discovery methods [22, 54, 23] have been proposed, which explore the local neighbors progressively with class consistency maximization by mining instance-to-instance correlation. They simply assign high similarity to pairs that have short Euclidean distance in the feature space. While the representations lie in the implicit feature manifold that is continuous in the Euclidean space, the Euclidean distance only reveals the true semantic similarity in extremely small neighborhoods and fails to provide the informative pseudo supervision for large neighborhoods due to the inconsisten-cy with the distance measured on the feature manifold. As a result, the feature discriminality is still limited as shown in the third column of Figure 1.
In this paper, we present an ISL method to learn the semantic similarity among instances for unsupervised fea-ture representation. Unlike the conventional methods that assign high similarity to close pairs according to the Eu-clidean distance in the feature space, our method mines the feature manifold in an unsupervised manner and learn-s the semantic similarity among different samples, so that the reliable instance-to-instance relationship in large neigh-borhoods is applied to supervise the representation learn-ing models as demonstrated in the last column of Figure 1. More speciﬁcally, we employ the Generative Adversarial
Network (GAN) [13] to mine the underlying feature man-ifold, and Figure 2 depicts the overall pipeline of the pro-posed method. The generator yields the proxy feature that mines positives for each anchor instance based on the sam-pled triplet, and the discriminator predicts the conﬁdence score that the generated proxy is semantically similar with the mined pseudo positive samples. Since the Euclidean distance reveals the sample similarity in small neighbor-hoods, the instances near the proxy feature with high conﬁ-dence score are added to the positive sample set of the given anchor. In order to explore richer instance-wise relation and exploit the semantics of the mined positive sample set si-multaneously, the generated proxy is enforced to be similar with negative instances and the mined pseudo positive sam-ples during the training process of GANs. With the reliable pseudo supervision, we employ the contrastive loss with hard positive enhancement to learn discriminative features.
Extensive experiments on CIFAR-10 [28], CIFAR-100 [28],
SVHN [36] and ImageNet [6] datasets for image classiﬁca-tion demonstrate that the proposed ISL outperforms most of the existing unsupervised learning methods. Moreover, our ISL can be integrated with state-of-the-art unsupervised features to further enhance the performance. 2.