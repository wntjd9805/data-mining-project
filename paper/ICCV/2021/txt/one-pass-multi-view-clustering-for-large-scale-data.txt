Abstract
Existing non-negative matrix factorization based multi-view clustering algorithms compute multiple coefficient ma-trices respect to different data views, and learn a common consensus concurrently. The final partition is always ob-tained from the consensus with classical clustering tech-niques, such as k-means. However, the non-negativity con-straint prevents from obtaining a more discriminative em-bedding. Meanwhile, this two-step procedure fails to unify multi-view matrix factorization with partition generation closely, resulting in unpromising performance. Therefore, we propose an one-pass multi-view clustering algorithm by removing the non-negativity constraint and jointly optimize the aforementioned two steps.
In this way, the generated partition can guide multi-view matrix factorization to pro-duce more purposive coefficient matrix which, as a feed-back, improves the quality of partition. To solve the resul-tant optimization problem, we design an alternate strategy which is guaranteed to be convergent theoretically. More-over, the proposed algorithm is free of parameter and of
In linear complexity, making it practical in applications. addition, the proposed algorithm is compared with recent advances in literature on benchmarks, demonstrating its ef-fectiveness, superiority and efficiency. 1.

Introduction
With the wide spread of multi-view data, multi-view clustering (MvC) algorithms are proposed to maximally in-tegrate complementary information among views and reveal the underlying data structure for clustering [10, 18]. Most of them are developed on classical clustering methods, such as non-negative matrix factorization, k-means, spectral clus-tering, etc. [26, 21, 9, 17]. Therefore, MvC approaches can be roughly classified according to this criterion. In the pa-per, we concentrates on non-negative matrix factorization based ones.
*Corresponding author
Non-negative Matrix Factorization (NMF) [14] is one of the most fundamental clustering techniques in machine learning and data engineering tasks. It factorizes the input data into two parts, i.e. coefficient and base matrices [12].
Orthogonality [5] and low rank constraint [29] are widely explored in matrix factorization, achieving promising per-formance. In MvC setting, Gao et al. obtain the coefficient matrices via performing NMF on each data view, then push them towards a common consensus [6]. On the contrary, some researches assume that all views share an underlying consensus manifold, thus employ a single coefficient ma-trix to capture the intrinsic data structure [7]. Upon the two aforementioned frameworks, a large number of researchers
[27, 30, 24, 7, 25] borrow the manifold regularization in [2] to further improve clustering performance. In specific, each view can be regarded as a manifold and manifold regular-ization is able to preserve the local geometry structure of data [30]. However, it requires building one or more simi-larity graphs, introducing higher computational and storage complexities, O(n2) or even O(n3) sometimes [27]. Nev-ertheless, Gao et al. impose orthogonality on the base ma-trix explicitly [7], while Zhang et al. do so implicitly [27], where the both are validated to be effective in experiment.
However, the aforementioned approaches limit the dis-criminative embedding learning by imposing non-negativity and fail to unify multi-view matrix factorization with par-tition generation closely, leading to unsatisfying perfor-mance. To address the issues, we propose an One-pass
Multi-view Clustering (OPMC) algorithm. First, we re-move the non-negativity constraint on both coefficient and base matrices. Instead of explicitly combining the objec-tives of matrix factorization and k-means in a unified for-mulation, we approximate the coefficient matrix with a con-sensus hard partition matrix and a view-specific centroid matrix, where no additional parameter is introduced. The overview of OPMC is presented in Fig. 1. It can be ob-served that the generated hard partition guides multi-view matrix factorization to produce more purposive coefficient matrix which, as a feedback, improves the quality of parti-tion. In order to validate effectiveness of the proposal, we
Figure 1. Overview of the proposed OPMC algorithm (Taking the data of two views as an example). Two semantic parts are concerned, including multi-view matrix factorization and partition generation. From left to right, the hard partition matrix passes through two view-specific transformations by multiply a centroid matrix respectively. Then, a coefficient matrix is obtained corresponding to each view. Note that, we use dotted line to represent coefficient matrix, for it does not explicitly given in our algorithm. By multiplying the coefficient matrices with base matrices, the data views can be reconstructed. From right to left, dotted arrows indicate that the clustering information flows from original data views to the consensus hard partition step by step. design an ablation study by comparing single-view OPMC with ONMF [5]. Besides, extensive experiments are con-ducted and OPMC establishes state-of-the-art performance compared with recent advances on six benchmarks. Finally, the contributions are summarized as follows: 1) We find removing the non-negativity constraint and uni-fying matrix factorization with partition generation can improve the clustering performance, and validate their effectiveness with an ablation study. 2) We propose a non-parametric OPMC algorithm to ad-dress the multi-view data clustering problem. It achieves state-of-the-art performance on six benchmarks. 3) We design an alternate strategy to solve the resultant op-timization problem. Its convergence and computational complexity (O(n)) are analyzed theoretically and exper-imentally. 2.