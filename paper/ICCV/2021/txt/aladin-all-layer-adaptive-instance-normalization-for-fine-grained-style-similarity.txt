Abstract
We present ALADIN (All Layer AdaIN); a novel archi-tecture for searching images based on the similarity of their artistic style. Representation learning is critical to visual search, where distance in the learned search embedding re-flects image similarity. Learning an embedding that dis-criminates fine-grained variations in style is hard, due to the difficulty of defining and labelling style. ALADIN takes a weakly supervised approach to learning a representation for fine-grained style similarity of digital artworks, leverag-ing BAM-FG, a novel large-scale dataset of user generated content groupings gathered from the web. ALADIN sets a new state of the art accuracy for style-based visual search over both coarse labelled style data (BAM) and BAM-FG; a new 2.62 million image dataset of 310,000 fine-grained style groupings also contributed by this work. 1.

Introduction
Digital artwork spans a broad range of content depicted in diverse visual styles. Learning a representation suit-able for searching artwork based on visual style is an open challenge, particularly when discriminating between subtle, fine-grained [39, 37, 25] variations in style. This is due to the difficulties of both (i) defining a suitable fine-grained ontology to label styles and (ii) the expert annotation task.
Research to date has therefore focused upon coarse-grain discrimination of a limited number of styles [17, 6].
Artistic style is the distinctive appearance of an artwork; i.e. how an artist has depicted their subject matter [8]. Style may be characterized, non-exhaustively, by visual attributes such as the texture, strokes, media, shading, or layout of an artwork; the challenge of identifying a complete list of at-tributes is long-standing and unsolved [7]. Our core contri-bution is to learn fine-grained artistic style similarity (Fig. 1) and do so via a weakly supervised approach that does not rely upon explicit labelling of style or style attributes in images. Our technical contributions are three-fold: 1. ALADIN Fine-grained Style Embedding. We pro-pose ALADIN; a novel architecture to learn a search em-bedding for image style. ALADIN is an encoder-decoder (E-D) network, that pools Adaptive Instance Normalization (AdaIN) statistics across its style encoder layers to learn a discriminative search embedding capable of both discrimi-nating subtle fine-grained of style (e.g. variations in sketch-ing style) as well as coarse-grained styles (e.g. sketch, wa-tercolor, etc.). Image stylization networks [14, 10, 15] have previously used AdaIN for style transfer, but these perform poorly for measuring similarlity (c.f. subsec 5.2). For the first time, ALADIN explicitly disentangles content and style within an E-D network to show how AdaIN may be harnessed for fine-grained style search. 2. Behance Artistic Media Fine-Grained (BAM-FG) dataset. We contribute a new 2.62 million image dataset of artwork within 310K fine-grained style groupings, gath-ered from a creative portfolio website (Behance.net). Dig-ital artists publish to Behance.net in micro-collections (‘projects’) comprising images of a related visual theme.
On the assumption that image co-occurrence within these groups implies a weak cue for style similarity, we sample millions of such co-occurrences. Further, we partition and clean this noisy co-occurrence data via a large-scale crowd annotation task in which distinct style-coherent sub-groups of images within projects are identified with high consensus (yielding 1.62 million images and 135K groups). 3. Weakly supervised learning of fine-grained style.
We present the first study into representation learning for fine-grained artistic style similarity, taking a weakly super-vised approach. Prior style-based visual search learns only coarse-grain style discrimination directly from explicitly la-belled data (e.g. via proxy classification tasks [17] or deep metric learning [6]). We train ALADIN using supervised contrastive learning [4, 19] to achieve a state of the art per-formance at both coarse and fine-grained style search with-out requiring any explicit coarse of fine-grained categoriza-tion of image style.
Note that we distinguish between noisy and weak super-vision. The supervision is weak because there is no fine-grained style ontology to label images explicitly; instead, a weak proxy via implicit project groupings is the basis for learning. These groupings may be noisy or be cleaned up via crowd annotation, but supervision remains weak, as the data is not explicitly labelled to fine-grained styles. We show via objective and subjective user trials that raw project groupings are sufficient to train a state of the art model for fine-grained style similarity. Our cleaned data is used both for evaluating and enhancing fine-grained style discrimina-tion of ALADIN. 2.