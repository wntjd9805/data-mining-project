Abstract
In digital pathology, both detection and classification of cells are important for automatic diagnostic and prognos-tic tasks. Classifying cells into subtypes, such as tumor cells, lymphocytes or stromal cells is particularly challeng-ing. Existing methods focus on morphological appearance of individual cells, whereas in practice pathologists often infer cell classes through their spatial context. In this pa-per, we propose a novel method for both detection and clas-sification that explicitly incorporates spatial contextual in-formation. We use the spatial statistical function to describe local density in both a multi-class and a multi-scale manner.
Through representation learning and deep clustering tech-niques, we learn advanced cell representation with both ap-pearance and spatial context. On various benchmarks, our method achieves better performance than state-of-the-arts, especially on the classification task. 1.

Introduction
We propose the first joint cell detection and classification method that explicitly learns a spatial-context-aware repre-sentation of cells. We demonstrate that incorporating spatial context will significantly improve the performance, espe-cially for the classification task.
Identification of various types of cells such as tumor cells, lymphocytes, and stromal cells from whole-slide his-tology images is an important step towards automatic di-agnosis and prognosis in digital pathology. The spatial ar-rangement of different cells can comprehensively character-ize the interaction between tumor and immune cells and be correlated with clinical outcomes [29, 48, 23]. One good ex-ample is the detection and measurement of tumor infiltrat-ing lymphocytes (TILs), i.e., lymphocytes residing within the border of invasive tumors [36]. The prevalence of TILs has been shown to be associated with better clinical out-comes [37, 38, 41]. Aside from lymphocytes, the presence of isolated or small clusters of tumor cells at the invasive tumor front, a phenomenon known as tumor budding, is a prognosis biomarker associated with an increased risk of lymph node metastasis in colorectal carcinoma and other solid malignancies [28]. Other examples include the assess-ment of lymphovascular invasion and perineural invasion
[27] and the identification and measurement of intraepithe-lial lymphocytes for the diagnosis of celiac disease [34]. All these studies necessitate an effective algorithm to accurately identify cells of different types.
Multi-class cell identification involves both cell detec-tion and cell classification. Cell detection has been stud-ied extensively in the past few decades [40, 21, 45]. Exist-ing approaches either adopt the object detection algorithm from computer vision [20, 47], or treat the problem as an instance segmentation problem and segment nuclei one-by-one [18, 19, 32, 25, 30]. Although segmentation methods provide detailed nuclei morphology, their training requires highly detailed and thus time-consuming nuclei mask anno-tation. To circumvent this bottleneck, one may use weakly-supervised methods [31, 46, 43, 11] to segment nuclei based only on point annotations, i.e., points placed at the centers of nuclei. Point annotation is a much more affordable anno-tation for large scale training.
Despite the success in the cell detection, our progress on cell classification is not as advanced. Indeed, classification is a challenging task even for human experts. Cells of differ-ent kinds can manifest with similar appearance. Meanwhile, cells of the same type may exhibit large variation of mor-phology and texture in regions of neoplasia and inflamma-tion. To correctly classify cells in such challenging scenar-ios, pathologists not only use appearance, but also rely on the contextual information of surrounding cells, their spatial relationships and tissue architecture. For example, degen-erating or apoptotic cells often cluster together within the luminal spaces of gland forming tumors and can be readily identified in this context despite the spectrum of morpho-logic features they display; a context which can be identified through cellular architectural patterns in a larger scale. Sim-ilarly, architectural patterns can be used to help distinguish reactive stromal cells from tumor cells when their shape and chromatin pattern are indistinguishable.
module, we introduce pseudo-labels generated by cluster-ing of the deep representation. These pseudo-labels serve as a connection between cell class labels and K-functions, thus facilitate the collaboration of different modules and the fusion of appearance and spatial information. See Figure 2 for an overview of our model.
We apply our method, called MCSpatNet, to a joint cell detection and classification task. We evaluate our method on three benchmark datasets (breast cancer, colorectal can-cer and lung cancer), all of which with multi-class point annotations.1 Our method outperforms various SOTA base-lines, demonstrating the power of the spatial-context-aware representation.
To summarize, our contributions are as follows:
• We propose a novel cell detection and classification method which, for the first time, explicitly learns a spatial-context-aware representation of cells via multi-task learning.
• We introduce spatial statistical functions (K-function) as an effective descriptor of cells’ spatial context.
• We introduce spatial context prediction module and deep clustering module to facility learning of the rep-resentation.
• Our code is available here: https://github. com/TopoXLab/MCSpatNet 1.1.