Abstract
Current 3D object detection paradigms highly rely on extensive annotation efforts, which makes them not prac-tical in many real-world industrial applications. Inspired by that a human driver can keep accumulating experiences from self-exploring the roads without any tutor’s guidance, we first step forwards to explore a simple yet effective self-supervised learning framework tailored for LiDAR-based 3D object detection. Although the self-supervised pipeline has achieved great success in 2D domain, the characteris-tic challenges (e.g., complex geometry structure and various 3D object views) encountered in the 3D domain hinder the direct adoption of existing techniques that often contrast the 2D augmented data or cluster single-view features. Here we present a novel self-supervised 3D Object detection frame-work that seamlessly integrates the geometry-aware con-trast and clustering harmonization to lift the unsupervised 3D representation learning, named GCC-3D. First, GCC-3D introduces a Geometric-Aware Contrastive objective to learn spatial-sensitive local structure representation. This objective enforces the spatially close voxels to have high feature similarity. Second, a Pseudo-Instance Clustering harmonization mechanism is proposed to encourage that different views of pseudo-instances should have consistent similarities to clustering prototype centers. This module endows our model semantic discriminative capacity. Exten-sive experiments demonstrate our GCC-3D achieves signif-icant performance improvement on data-efficient 3D object detection benchmarks (nuScenes and Waymo). Moreover, our GCC-3D framework can achieve state-of-the art per-formances on all popular 3D object detection benchmarks. 1.

Introduction
LiDAR-based 3D object detection has been a long-standing task in visual perceptions systems for autonomous
*Both authors contributed equally to this work.
†Corresponding Author: xdliang328@gmail.com
Figure 1. We finetune CenterPoint-pp detector from scratch, with
GCC-3D pretrain or with Click-supervised pretrain and report per-formance on Waymo and nuScenes dataset. Our GCC-3D model show consistent significant improvements over the scratch model and learn more robust feature than Click-supervised pre-train driving, attracting increasing industry and research atten-tion recently due to its great advantage of high 3D local-ization precision and complementary to the 2D perception
[43, 2, 29, 47, 33]. Different from the 2D detection problem, 3D object detectors transform sparse and unorganized point clouds into the structured 3D bounding box representations, including shape, orientation and semantic class. Almost all recent 3D object detectors are built upon fully supervised frameworks, while obtaining such large-scale and precise annotations for numerous instances in diverse self-driving scenarios is labor-intensive and time-consuming, e.g., it takes hundreds of hours to annotate just one hour of driving scene data [31]. This hinders the model improvement and deployment over ever-changing self-driving environments for LiDAR-based 3D object detection. Thus, a desirable self/unsupervised 3d object detection framework that can effortlessly lift the 3d representation learning purely using raw data is highly demanded but rarely explored.
Nonetheless, in the area of 2D image recognition [30, 20, 14] and natural language understanding [12], self-supervised pre-training over unlabeled data has yielded a significant performance boosting in downstream tasks when the labeled data is scarce. Thus, it is interesting to ask a
question: Does there also exist an effective self-supervised pre-training algorithm that can significantly alleviate the heavy annotation burden in 3D object detection by fully exploiting abundant unlabeled point cloud data? Existing works mostly focus on low-level task [50, 10, 16] (e.g., reg-istration) and single object [17, 9, 1, 21] (like reconstruc-tion, classification and part segmentation). Recently, Point-Contrast [44] demonstrated that unsupervised pretraining can boost the performance on indoor scene understanding tasks. However, several limitations of PointContrast hin-der its direct adoption into LiDAR-based 3D detection: 1)
Static Partial Views: Multiple partial views [53] setup is claimed to be a crucial component of [44], requiring the object/scene to be static. This is usually not available in outdoor scenes of autonomous driving scenarios. 2) Incon-sistent Contrast: It assigns hard labels to matched and un-matched pairs, which is contradictory to the fact that the randomly sampled unmatched pairs can have very similar structure; 3) Lack of Semantic Information: Semantic rep-resentation is important for high-level scene understanding tasks like 3D object detection. This kind of representation is not modeled during pre-training.
To advance the research on LiDAR-based 3D ob-ject detection into an unsupervised/self-supervised era and resolve the above-mentioned issues in designing a proper self-supervised scheme, we present a novel self-supervised 3D detection framework that seamlessly inte-grates the geometric-sensitive and semantic-consistent rep-resentations, named GCC-3D. Our framework is the first one focusing on autonomous driving scenario without static partial views setup [53]. Firstly, to alleviate the inconsis-tent contrast problem, GCC-3D exploits an important prop-erty of 3D data: two spatially close voxels in 3D space are very likely to have similar local geometric structures or be-long to the same object. We inject this prior to our learn-ing objective and use the geometric distance between voxels to guide feature similarity during contrastive feature learn-ing. This geometric-aware contrastive objective can help learn local structural features of point clouds properly. The voxel-level features with geometric information will be ag-gregated as the embedding of pseudo instances, which are obtained from the sequential information in datasets. Sec-ondly, we endow our model semantic property by defining a clustering harmonization phase. During training, we as-sign labels to each instance embedding by using K-means clustering following [41]. However, the commonly used hard labeling strategy [41] violates that some prototypes can be similar or represent the same semantic classes, and ne-glects the heterogeneous similarities between embeddings of pseudo-instances and is prone to ”class collision” [3] problem. To alleviate this problem, we introduce a new har-monization term that encourages different pseudo-instances views to have consistent similarities with clustering proto-type centers. This term is easily injected into the current self-clustering framework. By integrating the geometry-aware contrast and pseudo-instance clustering harmoniza-tion, our GCC-3D can capture both local structure and con-text semantic information, which can improve our model’s localization and classification capacity.
To better validate the self-supervised capability of cur-rent models in Lidar-based 3D object detection, we con-duct extensive experiments in popular 3D object detection benchmarks (Waymo [39], nuScenes [5]) with limited su-pervised data, called data-efficient benchmarks. The meth-ods are required to first pre-train only on the unlabeled data and then fine-tune it using limited labeled data to re-duce the annotation effort. Our unsupervised framework
GCC-3D can achieve consistent significant improvement over random initialized models on the data-efficient bench-marks. Notably, our pre-trained CenterPoint-voxel model achieves 67.29% mAP on Waymo (with 20% labeled data) and 57.3% mAP on nuScenes, a separate 4.1% and 1.95% relative improvement over previous state-of-the-art method
[49]. After transferring our pre-trained model on Waymo to KITTI [18], we witness a 2.1% relative improvement over KITTI state-of-the-art method [36]. With 5% labeled data, our self-supervised model demonstrates over 6.3% and 5.6% relative improvement in mAP compared to PointCon-trast [44] on Waymo and nuScenes. Our contributions can be summarized as follows:
• We make the first attempt to propose a simple yet ef-fective self-supervised LiDAR-based 3D object detec-tion framework for alleviating the demand for exten-sive human annotations, towards a more flexible and scalable self-driving system.
• We propose a novel GCC-3D that is the first self-supervised learning mechanism to integrate both geometry-aware structure contrast and harmonized se-mantic pseudo-instance clustering. This method suc-cessfully self-explores and enhances the 3D instance-level representation from both the geometry and se-mantic perspectives.
• Our GCC-3D framework can achieve state-of-the-art performances on all popular 3D object detection benchmarks, i.e., 67.29% mAP on Waymo (20% la-beled data) and 57.3% mAP on nuScenes. 2.