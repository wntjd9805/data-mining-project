Abstract
Most existing Siamese-based tracking methods execute the classiﬁcation and regression of the target object based on the similarity maps. However, they either employ a sin-gle map from the last convolutional layer which degrades the localization accuracy in complex scenarios or sepa-rately use multiple maps for decision making, introduc-ing intractable computations for aerial mobile platforms.
Thus, in this work, we propose an efﬁcient and effective hierarchical feature transformer (HiFT) for aerial track-ing. Hierarchical similarity maps generated by multi-level convolutional layers are fed into the feature transformer to achieve the interactive fusion of spatial (shallow layers) and semantics cues (deep layers). Consequently, not only the global contextual information can be raised, facilitat-ing the target search, but also our end-to-end architecture with the transformer can efﬁciently learn the interdepen-dencies among multi-level features, thereby discovering a tracking-tailored feature space with strong discriminabil-ity. Comprehensive evaluations on four aerial benchmarks have proven the effectiveness of HiFT. Real-world tests on the aerial platform have strongly validated its practicability with a real-time speed. Our code is available at https:
//github.com/vision4robotics/HiFT. 1.

Introduction
Visual object tracking1, aiming to estimate the location of object frame by frame given the initial state, has drawn considerable attention due to its prosperous applications es-pecially for unmanned aerial vehicles (UAVs), e.g., aerial cinematography [5], visual localization [48], and collision warning [19]. Despite the impressive progress, efﬁcient and effective aerial tracking remains a challenging task due to limited computational resources and various difﬁculties like fast motion, low-resolution, frequent occlusion, etc.
In the visual tracking community, deep learning (DL)-based trackers [44, 35, 9, 2, 31, 53, 18, 17, 6] stand out on
#0247
#0262
#0291
#0015
#0167
#0182
#0270
HiFT (ours)
#0321
SiamBAN
#0338
SiamCAR
SiamRPN++_Res
Figure 1. Qualitative comparison of the proposed HiFT with state-of-the-arts [23, 8, 31] on three challenging sequences (BMX4,
RaceCar1 from DTB70 [34], and Car16 from UAV20L [39]). Ow-ing to the effective tracking-tailored feature space produced by the hierarchical feature transformer, our HiFT tracker can achieve robust performance under various challenges with a satisfactory tracking speed while other trackers lose effectiveness. account of using the convolutional neural network (CNN) with robust representation capability. However, lightweight
CNNs like AlexNet [30] can hardly extract robust features which are vital for tracking performance in complex aerial scenarios. Using a larger kernel size or a deeper back-bone [31] can alleviate the aforementioned shortcoming yet the efﬁciency and practicability will be sacriﬁced. In liter-ature, the dilated convolution [49] proposed to expand the receptive ﬁeld and avoid the loss of resolution caused by the pooling layer. Unfortunately, it still suffers from unsta-ble performance while handling small objects.
Recently, the transformer has demonstrated huge poten-tial in many domains with an encoder-decoder structure [1].
Inspired by the superior performance of the transformer in modeling global relationships, we try to exploit its architec-ture in aerial tracking to effectively fuse multi-level2 fea-tures to achieve promising performance. Meanwhile, the loss of efﬁciency caused by the computations of multiple layers and the deﬁciency of the transformer in handling
∗Corresponding Author 1This work targets single object tracking (SOT). 2We use the hierarchical feature to denote the feature maps from mul-tiple convolutional layers.
small objects (pointed out in [52]) can be mitigated simul-taneously.
In speciﬁc, since the target object in visual tracking can be an arbitrary object, the learned object queries in the orig-inal transformer structure hardly generalize well in visual tracking. Therefore, we adopt low-resolution features from the deeper layer to replace object queries. Meantime, we also feed the shallow layers into the transformer to discover a tracking-tailored feature space with strong discriminabil-ity by end-to-end training, which implicitly models the re-lationship of spatial information from high-resolution lay-ers and semantic cues from low-resolution layers. More-over, to further handle the insufﬁciency faced with low-resolution objects [52], we design a novel feature modu-lation layer in the transformer to fully explore the interde-pendencies among multi-level features. The proposed hier-archical feature transformer (HiFT) tracker has efﬁciently achieved robust performance under complex scenarios, as shown in Fig. 1. The main contributions of this work are as follows:
• We propose a novel hierarchical feature transformer to learn relationships amongst multi-level features, thereby discovering a tracking-tailored feature space with strong discriminability for aerial tracking.
• We design a neat feature modulation layer and classiﬁ-cation label to further exploit the hierarchical features in Siamese networks and improve the tracking accu-racy in handling the small objects.
• Comprehensive evaluations on four authoritative aerial benchmarks have validated the promising performance of HiFT against other state-of-the-art (SOTA) trackers, even those equipped with deeper backbones.
• Real-world tests are conducted on a typical aerial plat-form, demonstrating the superior efﬁciency and effec-tiveness of HiFT in real-world scenarios. 2.