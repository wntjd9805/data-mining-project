Abstract
Scene graph generation aims to identify objects and their relations in images, providing structured image representa-tions that can facilitate numerous applications in computer vision. However, scene graph models usually require su-pervised learning on large quantities of labeled data with intensive human annotation. In this work, we propose vi-sual distant supervision, a novel paradigm of visual rela-tion learning, which can train scene graph models without any human-labeled data. The intuition is that by aligning commonsense knowledge bases and images, we can auto-matically create large-scale labeled data to provide distant supervision for visual relation learning. To alleviate the noise in distantly labeled data, we further propose a frame-work that iteratively estimates the probabilistic relation la-bels and eliminates the noisy ones. Comprehensive exper-imental results show that our distantly supervised model outperforms strong weakly supervised and semi-supervised baselines. By further incorporating human-labeled data in a semi-supervised fashion, our model outperforms state-of-the-art fully supervised models by a large margin (e.g., 8.3 micro- and 7.8 macro-recall@50 improvements for predi-cate classification in Visual Genome evaluation). We make the data and code for this paper publicly available at https://github.com/thunlp/VisualDS. 1.

Introduction
Scene graph generation aims to identify objects and their relations in real-world images. For example, the scene graph shown in Figure 1 depicts the image with several rela-tional triples, such as (person, riding, horse) and (horse, standing on, beach). Such structured representations indicates equal contribution
*
â€  Corresponding author: Z.Liu (liuzy@tsinghua.edu.cn)
Figure 1. An example from Visual Genome [22] based on the re-fined relation schemes from Chen et al. [5], where human anno-tation from Visual Genome, weak supervision information from the corresponding caption, and raw relation labels from distant su-pervision are shown respectively. Correct relation labels are high-lighted in bold. By aligning commonsense knowledge bases and images, visual distant supervision can create large-scale labeled data without any human efforts to facilitate visual relation learn-ing. Best viewed in color. provide deep understanding of the semantic content of im-ages, and have facilitated state-of-the-art models in numer-ous applications in computer vision, such as visual question answering [17, 42], image retrieval [21, 38], image caption-ing [50, 12] and image generation [20].
Tremendous efforts have been devoted to generating scene graphs from images [48, 26, 49, 29, 57]. How-ever, scene graph models usually require supervised learn-ing on large quantities of human-labeled data. Manually constructing large-scale datasets for visual relation learning is extremely labor-intensive and time-consuming [29, 22].
Moreover, even with the human-labeled data, scene graph models usually suffer from the long-tail relation distribu-Figure 2. Number of labeled instances of top 3,000 relationships from Visual Genome annotation and visual distant supervision. tion in real-world scenarios. Figure 2 shows the statistics on Visual Genome [22], where over 98% of the top 3, 000 relation categories do not have sufficient labeled instances and are thus ignored by most scene graph models.
To address the problems, a promising direction is to uti-lize large-scale unlabeled data with minimal human efforts via semi-supervised or weakly supervised learning. Chen et al. [5] propose to first learn a simple relation predictor using several human-labeled seed instances for each relation, and then assign soft labels to unlabeled data to train scene graph models. However, semi-supervised models still require hu-man annotation that scales linearly with the number of re-lations. Moreover, learning from limited seed instances is vulnerable to high variance and subjective annotation bias.
Some works have also explored learning from weakly su-pervised relation labels, which are obtained by parsing the captions of the corresponding images [58, 32]. However, due to reporting bias [11], captions only summarize a few salient relations in images, and ignore less salient and back-ground relations, e.g., (rock, covering, beach) in Fig-ure 1. The resultant models will thus be biased towards a few salient relations, which cannot well serve scene graph generation that aims to exhaustively extract all reasonable relational triples in the scene.
In this work, we propose visual distant supervision, a novel paradigm of visual relation learning, which can train scene graph models without any human-labeled data. The intuition is that commonsense knowledge bases encode re-lation candidates between objects, which are likely to be ex-pressed in images. For example, as shown in Figure 1, mul-tiple relation candidates, e.g., riding, sitting on and watching, can be retrieved from commonsense knowl-edge bases for the object pair person and horse, where riding and sitting on are actually expressed in the given image. By aligning commonsense knowledge bases and images, we can create large-scale labeled data to pro-vide distant supervision for visual relation learning with-out any human efforts. Since the distant supervision is pro-vided by knowledge bases, the relations can be exhaustively labeled between all object pairs. We note that many rea-sonable relation labels from distant supervision are missing in Visual Genome even after intensive human annotations, e.g., (wave, covering, beach) in Figure 1.
Moreover, distant supervision can also alleviate the long-tail problem. As shown in Figure 2, using the same num-ber of images, distant supervision can produce 1-3 orders of magnitude more labeled relation instances than its human-labeled counterpart. Note that the number of distantly la-beled relation instances can be arbitrarily large, given the nearly unlimited image data on the Web.
Distant supervision is convenient in training scene graph models without human-labeled data. When human-annotated data is available, distantly labeled data can also be incorporated in a semi-supervised fashion to surpass fully supervised models. We show that after pre-training on dis-tantly labeled data, simple fine-tuning on human-labeled data can lead to significant improvements over strong fully supervised models.
Despite its potential, we note distant supervision may in-troduce noise in relation labels, e.g., (person, watching, horse) in Figure 1. The reason is that distant supervi-sion only provides relation candidates based on object cat-egories, whereas the actual relations between two objects in an image usually depend on the image content. In prin-ciple, the noise in distantly labeled data can be alleviated by maximizing the coherence between distant labels and vi-sual patterns of object pairs. Previous works have shown that without specially designed denoising methods, neural models are capable of detecting noisy labels to some extent, and learning meaningful signals from noisy data [19, 8]. In this work, to better alleviate the noise in distantly labeled data, we further propose a framework that iteratively esti-mates the probabilistic relation labels and eliminates noisy ones. The framework can be realized by optimizing the co-herence of internal statistics of distantly labeled data, and can also be seamlessly integrated with external semantic signals (e.g., image-caption retrieval models), or human-labeled data to achieve better denoising results.
Comprehensive experimental results show that, with-out using any human-labeled data, our distantly super-vised model outperforms strong weakly supervised and semi-supervised baseline methods. By further incorporat-ing human-labeled data in a semi-supervised fashion, our model outperforms state-of-the-art fully supervised mod-els by a large margin (e.g., 8.3 micro- and 7.8 macro-recall@50 improvements for predicate classification task in
Visual Genome evaluation). Based on the experiments, we discuss multiple promising directions for future research.
Our contributions are threefold: (1) We propose vi-sual distant supervision, a novel paradigm of visual rela-tion learning, which can train scene graph models without any human-labeled data, and also improve fully supervised models. (2) We propose a denoising framework to alleviate the noise in distantly labeled data. (3) We conduct compre-hensive experiments which demonstrate the effectiveness of visual distant supervision and the denoising framework.
2.