Abstract
We introduce an evaluation methodology for visual ques-tion answering (VQA) to better diagnose cases of shortcut learning. These cases happen when a model exploits spuri-ous statistical regularities to produce correct answers but does not actually deploy the desired behavior. There is a need to identify possible shortcuts in a dataset and as-sess their use before deploying a model in the real world.
The research community in VQA has focused exclusively on question-based shortcuts, where a model might, for ex-ample, answer “What is the color of the sky” with “blue” by relying mostly on the question-conditional training prior and give little weight to visual evidence. We go a step fur-ther and consider multimodal shortcuts that involve both questions and images. We ﬁrst identify potential shortcuts in the popular VQA v2 training set by mining trivial pre-dictive rules such as co-occurrences of words and visual elements. We then introduce VQA-CounterExamples (VQA-CE), an evaluation protocol based on our subset of Coun-terExamples i.e. image-question-answer triplets where our rules lead to incorrect answers. We use this new eval-uation in a large-scale study of existing approaches for
VQA. We demonstrate that even state-of-the-art models per-form poorly and that existing techniques to reduce biases are largely ineffective in this context. Our ﬁndings sug-gest that past work on question-based biases in VQA has only addressed one facet of a complex issue. The code for our method is available at https://github.com/ cdancette/detect-shortcuts 1.

Introduction
Visual Question Answering (VQA) is a popular task that aims at developing models able to answer free-form ques-tions about the contents of given images. The research com-*Equal contribution †Work done before April 2021 and joining Tesla munity introduced several datasets [5, 23, 26, 27] to study various topics such as multimodal fusion [7] and visual rea-soning [4, 22]. The popular VQA v2 dataset [21] is the largest dataset of photographs of real scenes and human-provided questions. Because of strong selection biases and annotation artifacts, these datasets have served as a test-bed for the study of dataset biases and shortcut learning [18] (we will use the term “shortcut” exclusively in the rest of the pa-per). These spurious correlations correspond to superﬁcial statistical patterns in the training data that allow predicting correct answers without deploying the desirable behavior.
Issues of shortcut learning have become an increasing con-cern for other tasks in vision and natural language process-ing [18, 14]. In extreme cases, shortcuts in VQA may allow guessing the answer without even looking at the image [1].
Some shortcuts can be more subtle and involve both textual and visual elements. For instance, training questions con-taining What sport are strongly associated with the answer tennis when they co-occur with a racket in the image (see
Figure 1). However, some examples can be found in the validation set, such as What sport ﬁeld is in the background
?, that lead to a different answer (soccer) despite a racquet being present in the image. Because of such exceptions, a model that strongly relies on simple co-occurrences will fail on unusual questions and scenes. Our work studies such multimodal patterns and their impact on VQA models.
The presence of dataset biases in VQA datasets is well known [1, 21, 23, 29], but existing evaluation protocols are limited to text-based shortcuts. Our work introduces
VQA-CounterExamples (VQA-CE for short) which is an
It is easy evaluation protocol for multimodal shortcuts. to reproduce and can be used on any model trained on
VQA v2, without requiring retraining. We ﬁrst start with a method to discover superﬁcial statistical patterns in a given
VQA dataset that could be the cause of shortcut learning.
We discover a collection of co-occurrences of textual and visual elements that are strongly predictive of certain an-Figure 1. Overview of this work. We ﬁrst mine simple predictive rules in the training data such as: what + sport + racketV → tennis.
We then search for counterexamples in the validation set that identify some rules as undesirable statistical shortcuts. Finally, we use the counterexamples as a new challenging test set and evaluate existing VQA models like UpDown [3] and VilBERT [31]. swers in the training data and often transfer to the valida-tion set. For instance, we discover a rule that relies on the appearance of the words “what”,“they”,“playing” together with the object “controller” in the image to always predict the correct answer “wii”. We consider this rule to be a short-cut since it could fail on arbitrary images with other con-trollers, as it happens in the real world. Thus, our method can be used to reﬂect biases of the datasets that can poten-tially be learned by VQA models.
We go one step further and identify counterexamples in the validation set where the shortcuts produce an incorrect answer. These counterexamples form a new challenging evaluation set for our VQA-CE evaluation protocol. We found that the accuracy of existing VQA models is signif-icantly degraded on this data. More importantly, we found that most current approaches for reducing biases and short-cuts are ineffective in this context. They often reduce the average accuracy over the full evaluation set without signif-icant improvement on our set of counterexamples. Finally, we identify shortcuts that VQA models may be exploiting.
We ﬁnd several shortcuts giving predictions highly corre-lated with existing models’ predictions. When they lead to incorrect answers on some examples from the validation set,
VQA models also provide incorrect answers. This tends to show that VQA models exploit these multimodal shortcuts.
In summary, the contributions of this paper are as follows. 1. We propose a method to discover shortcuts which rely on the appearance of words in the question and visual elements in the image to predict the correct answer. By applying it to the widely-used VQA v2 training set, we found a high number of multimodal shortcuts that are predictive on the validation set. 2. We introduce the VQA-CE evaluation protocol to as-sess the VQA models’ reliance on these shortcuts. By running a large-scale evaluation of recent VQA ap-proaches, we found that state-of-the-art models exploit these shortcuts and that bias-reduction methods are inef-fective in this context. 2.