Abstract
Deep AUC Maximization (DAM) is a new paradigm for learning a deep neural network by maximizing the AUC score of the model on a dataset. Most previous works of
AUC maximization focus on the perspective of optimiza-tion by designing efﬁcient stochastic algorithms, and stud-ies on generalization performance of large-scale DAM on difﬁcult tasks are missing.
In this work, we aim to make
DAM more practical for interesting real-world applications (e.g., medical image classiﬁcation). First, we propose a new margin-based min-max surrogate loss function for the AUC score (named as the AUC min-max-margin loss or simply AUC margin loss for short). It is more robust than the commonly used AUC square loss, while enjoy-ing the same advantage in terms of large-scale stochas-tic optimization. Second, we conduct extensive empirical studies of our DAM method on four difﬁcult medical im-age classiﬁcation tasks, namely (i) classiﬁcation of chest x-ray images for identifying many threatening diseases, (ii) classiﬁcation of images of skin lesions for identifying melanoma, (iii) classiﬁcation of mammogram for breast cancer screening, and (iv) classiﬁcation of microscopic im-ages for identifying tumor tissue. Our studies demonstrate that the proposed DAM method improves the performance of optimizing cross-entropy loss by a large margin, and also achieves better performance than optimizing the ex-isting AUC square loss on these medical image classiﬁca-tion tasks. Speciﬁcally, our DAM method has achieved the 1st place on Stanford CheXpert competition on Aug. 31, 2020. To the best of our knowledge, this is the ﬁrst work that makes DAM succeed on large-scale medical image datasets.
We also conduct extensive ablation studies to demonstrate the advantages of the new AUC margin loss over the
AUC square loss on benchmark datasets. The proposed method is implemented in our open-sourced library LibAUC (www.libauc.org) whose github address is https:
//github.com/Optimization-AI/LibAUC.
Figure 1. An illustrative example for optimizing different AUC losses on a toy data for learning a two-layer neural network with
ELU activation. The top row is optimizing the AUC square loss and the bottom row is optimizing the new AUC margin loss. The
ﬁrst column depicts the initial decision boundary (dashed line) pre-trained on a set of examples. In the middle column, we add some easy examples to the training set and retrain the model by optimiz-ing the AUC loss. In the last column, we add some noisily labeled data (blue circled data) to the training set and retrain the model by optimizing the AUC loss. The results demonstrate the new AUC margin loss is more robust than the AUC square loss. 1.

Introduction
In the last decade, we have seen great progress in deep learning (DL) techniques for medical image classi-ﬁcation driven by large-scale medical datasets. For ex-ample, Stanford machine learning group led by Andrew
Ng has collected and released a high-quality large-scale
Chest X-Ray dataset for detecting chest and lung diseases, which contains 224,316 high-quality X-rays images from 65,240 patients [22]. Various deep learning methods have been designed and evaluated on this dataset by participat-ing the CheXpert competition organized by Stanford ML group [22], and many of them have achieved radiologist-level performance on detecting certain related diseases. Es-teva et al. [10] have trained a CNN using a dataset of 129,450 clinical images consisting of 2,032 different dis-eases, and achieved dermatologist-level performance for
classiﬁcation of skin lesions. Wu et al. [39] have trained a deep neural network for breast cancer screening on a large-scale medical dataset, which includes 229,426 digital screening mammography exams (1,001,093 images) from 141,473 patients. Their model is as accurate as an experi-enced radiologist. Despite these great efforts, an important question remains:
“Can we design a generic method that can further im-prove the performance of DL on these medical datasets without relying on domain knowledge”?
In this paper, we provide an afﬁrmative answer to this question. Our solution is to optimize a novel loss for DL instead of optimizing the standard cross-entropy loss in the previous works. In particular, we choose to maximize the
AUC score (a.k.a the area under the ROC curve) for DL.
There are several beneﬁts of maximizing AUC score over minimizing the cross-entropy loss. First, in medical classiﬁ-cation tasks the AUC score is the default metric for evaluat-ing and comparing different methods. Directly maximizing
AUC score can potentially lead to the largest improvement in the model’s performance. Second, the datasets in medical image classiﬁcation tasks are usually imbalanced (e.g., the number of malignant cases is usually much less than benign cases). AUC is more suitable for handling imbalanced data distribution since maximizing AUC aims to rank the pred-ication score of any positive data higher than any negative data. However, AUC maximization is much more challeng-ing than minimizing mis-classifcation error since AUC is much more sensitive to model change. A simple example in Appendix F shows that by changing the prediction scores of a few examples, the mis-classiﬁcation error rate keep un-changed but the AUC score drops signiﬁcantly.
AUC maximization has been studied in the community of machine learning [12, 41, 27, 23, 11]. However, existing methods for AUC maximization are still not satisfactory for practical use. The foremost challenge for AUC maximiza-tion is to determine a surrogate loss for the AUC score. A naive way is to use a pairwise surrogate loss based on the deﬁnition of the AUC score. However, optimizing a generic pairwise loss on training data suffers from a severe scalabil-ity issue, which makes it not practical for DL on large-scale datasets. Several studies have made attempts to address the scalability issue [23, 43, 41, 27]. One promising solution is to maximize the pairwise square loss for AUC by utilizing its special form [41, 27]. However, our study reveals that the AUC square loss has adverse effect when trained with easy data and is sensitive to the noisy data.
To address these issues, we propose a new margin-based surrogate loss in the min-max form for AUC (referred to as the AUC min-max-margin loss and the AUC margin loss for short), which is inspired by addressing the two issues of the AUC square loss. In particular, the AUC margin loss has two features that can alleviate the two issues, making it more robust to noisy data and not adversely affected by easy data. We will explain it with more details in the tech-nical section and use a toy example in Figure 1 to illustrate the robustness of AUC margin loss over AUC square loss.
Moreover, the min-max form of the AUC margin loss make it enjoy the same beneﬁt as the AUC square loss in terms of scalability, making it more attractive than conventional pairwise margin-based surrogate loss for AUC maximiza-tion. In particular, we are able to directly employ existing large-scale optimization algorithms [15] designed for max-imizing the AUC square loss to maximize our AUC margin loss with one line change of the code.
To demonstrate the effectiveness of our deep AUC maxi-mization method, we conduct empirical studies on four dif-ﬁcult medical image classiﬁcation tasks, namely classiﬁca-tion of X-ray images for detecting chest diseases, classi-ﬁcation of images of skin lesions, classiﬁcation of mam-mograms for breast cancer screening and classiﬁcation of microscopic images of tumor tissue. Our deep AUC maxi-mization method has achieved great success on these difﬁ-cult tasks. Speciﬁcally, we achieved the 1st place on Stan-ford CheXpert competition on Aug. 31, 2020, and Top 1% rank on Kaggle 2020 Melanoma classiﬁcation competition.
In CheXpert competition, our method is ranked 1 out of 150+ submissions, with a 2%+ improvement over Stanford baseline on a private testing data. In Kaggle competition, our ensembled model is ranked 33 out of 3314 teams. How-ever, our best single model is better than the winning team’s best model by more than 2%. Besides these medical tasks, we also conduct extensive ablation studies on benchmark datasets to compare the proposed AUC margin loss with the
AUC square loss and traditional classiﬁcation losses includ-ing cross-entropy and focal loss. Before ending this section, we summarize our contributions below:
• We proposed a new robust surrogate loss for AUC maxi-mization, which is more robust than the AUC square loss but enjoys the same beneﬁt of large-scale optimization.
• We conducted extensive empirical studies of the DAM method on a broad range of medical image classiﬁcation data, and demonstrated its superb performance compared with standard DL methods.
To the best of our knowledge, this is the ﬁrst comprehensive study of DAM on large-scale medical image classiﬁcation datasets. 2.