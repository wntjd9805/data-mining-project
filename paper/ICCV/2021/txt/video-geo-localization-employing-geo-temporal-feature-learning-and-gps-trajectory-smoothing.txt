Abstract
In this paper, we address the problem of video geo-localization by proposing a Geo-Temporal Feature Learn-ing (GTFL) Network to simultaneously learn the discrimi-native features for the query video frames and the gallery images for estimating the geo-spatial trajectory of a query video. Based on a transformer encoder architecture, our
GTFL model encodes query and gallery data separately, via two dedicated branches. The proposed GPS Loss and
Clip Triplet Loss exploit the geographical and temporal proximity between the frames and the clips to jointly learn the query and the gallery features. We also propose a deep learning approach to trajectory smoothing by pre-dicting the outliers in the estimated GPS positions and learning the offsets to smooth the trajectory. We build a large dataset from four different regions of USA; New
York, San Francisco, Berkeley and Bay Area using BDD driving videos as query, and by collecting corresponding
Google StreetView (GSV) Images for gallery. Extensive evaluations of proposed method on this new dataset are pro-vided . Code and dataset details is publicly available at https://github.com/kregmi/VTE. 1.

Introduction
Image based geo-localization has attracted a lot of in-terest in computer vision community, where a query im-age is matched with geo-tagged reference images in the gallery, and the GPS location of the best matching refer-ence image is assigned to the query image. Existing works in image geo-localization solve the same-view (ground to ground) [26, 35, 44], as well as the cross-view (ground to aerial) [2, 4, 12, 14, 17, 24, 25, 27, 32, 39] image match-ing problems by learning robust features for the query and the gallery set. With the increase in video data, there has never been more urgency of geo-localizing the video clips, where GPS trajectory corresponding to a query video is determined.
In this work, we explore the task of video geo-localization for the same-view data, where both query
Figure 1: Sample geo-spatial trajectories for a subset of video clips from San Francisco Area of BDD dataset [42]. The ground truth trajectories are shown in green and their estimated geo-trajectories obtained by the proposed method are shown in red. videos and gallery images are from the ground views. More specifically, given a query video recorded from a moving camera, we want to determine the GPS coordinates of each frame in the video.
One possible way to solve this problem is to treat each frame in the video independently and apply frame-based matching methods to determine the GPS location of each frame. Earlier works in video geo-localization [9, 37] are based on classical computer vision methods, where first the
SIFT descriptors [19] are computed for each frame in the clip as well as for the images in the gallery set (reference database). Then, for each frame in the query video the best matching reference image is computed and its correspond-ing GPS location is assigned to the query frame and the pre-dicted GPS trajectory is obtained by connecting the frame
GPS locations. Vaca-Castano et al. [37] use Bayesian Fil-tering to enforce temporal consistency on the estimated po-sitions in order to obtain smooth trajectory. Recent works
[11, 13, 45] use 2D CNN networks to obtain frame-level features instead of SIFT features for query frames and the gallery images, and follow the same approach for image matching. The features for each frame in the clip are ex-pressed independent to each other, thus predicted GPS lo-cations may not be smooth enough to represent a realistic trajectory of the moving camera since no temporal close-ness between the frames is exploited directly while learning
the features for the clips.
In this paper, we propose to leverage the geo-temporal proximity between the video frames while learning their features, in order to enforce the predicted locations of the consecutive video frames to be close to each other. Mo-tivated by the recent success of deep learning methods in video understanding and the effectiveness of transformer networks [38] to incorporate long range context dependen-cies between the inputs, we propose to use transformer based architecture to learn feature representations for the frames of the query videos. The network captures the co-herent features for the video frames and hence provides smoother predicted trajectories.
In addition to exploiting the temporal proximity between the frames within a clip, we propose to use a novel GPS loss to learn smoother fea-tures for clips that are geographically closer to each other.
Typical imagery captures areas containing vegetation, land-marks and landscapes unique to those areas and can ex-tend over a small geographical region. So, the clips over this geographical region should share similar feature repre-sentations. Thus, we propose to learn similar features for video clips corresponding to the same geographical loca-tions by constraining the training of our proposed network by using GPS loss. Once the GPS locations for the query video are estimated, earlier works used b-spline [9] and minimum spanning tree based trajectory reconstruction al-gorithms [37] to smooth the initial estimates of these GPS positions. In this work, we propose a transformer encoder based trajectory smoothing network to determine the out-liers in a set of estimated GPS locations for the query clip, and smooth the GPS values if they are determined to be noisy by the network.
There is no publicly available large-scale dataset for video geo-localization to evaluate the capability of the pro-posed framework. The dataset of Vaca-Castano et al. [37] consists of only 45 query videos making it impractical to train deep learning methods. Heng et al. [11] use dataset with image pairs that does not fit into our problem formu-lation. Therefore, in this work, we build a new video geo-localization benchmark dataset by utilizing Berkeley Driv-ing Dataset (BDD) videos [42] and by collecting matching
Google StreetView (GSV) images. The BDD videos are used as query videos and the GSV images form our gallery set. The dataset covers four different regions of the USA;
San Francisco, Berkeley, Bay Area and New York. We pro-vide evaluations on query videos from all four regions.
In summary, we make the following contributions in this paper: (1) We propose a novel geo-temporal feature learn-ing approach to learn coherent features for the query video frames for the problem of video geo-localization; (2) We propose a novel GPS loss to learn geographically smoother features; (3) We propose a novel trajectory smoothing net-work to refine the initial GPS predictions to obtain a smooth trajectory; and (4) We build a new video geo-localization dataset and provide extensive evaluations on query videos from four different regions of the USA. 2.