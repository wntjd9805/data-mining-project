Abstract
Data-driven sky models have gained much attention in outdoor illumination prediction recently, showing superior performance against analytical models. However, naively compressing an outdoor panorama into a low-dimensional latent vector, as existing models have done, causes two ma-jor problems. One is the mutual interference between the
HDR intensity of the sun and the complex textures of the surrounding sky, and the other is the lack of ﬁne-grained control over independent lighting factors due to the entan-gled representation. To address these issues, we propose a hierarchical disentangled sky model (HDSky) for out-door illumination prediction. With this model, any outdoor panorama can be hierarchically disentangled into several factors based on three well-designed autoencoders. The
ﬁrst autoencoder compresses each sunny panorama into a sky vector and a sun vector with some constraints. The sec-ond autoencoder and the third autoencoder further disen-tangle the sun intensity and the sky intensity from the sun vector and the sky vector with several customized loss func-tions respectively. Moreover, a uniﬁed framework is de-signed to predict all-weather sky information from a single outdoor image. Through extensive experiments, we demon-strate that the proposed model signiﬁcantly improves the accuracy of outdoor illumination prediction.
It also al-lows users to intuitively edit the predicted panorama (e.g., changing the position of the sun while preserving others), without sacriﬁcing physical plausibility. 1.

Introduction
Outdoor illumination prediction based on a single in-put image is a key task for many applications ranging from scene understanding and reconstruction to augmented real-ity (AR). However, the diverse weather conditions and the
†Corresponding authors.
Figure 1. We propose HDSky, the ﬁrst disentangled data-driven model for all-weather outdoor illumination. As the learned latent vector is disentangled into several independent and meaningful factors, state-of-the-art performance on outdoor illumination pre-diction can be achieved, leading to consistent shading and shad-ows in AR rendering and enabling intuitive illumination editing with physical plausibility. complex interaction between illumination and other scene properties (e.g., surface reﬂectance and geometric varia-tions) make this problem highly challenging.
Due to the success of deep learning, learning-based methods [9, 4, 33, 8] have emerged recently and achieved state-of-the-art performance by employing powerful deep neural networks to automatically learn the mapping be-tween an image of limited ﬁeld-of-view (FoV) and a given
sky model. To make the problem tractable, some ap-proaches resort to analytical sky models. For instance,
Hold-Geoffroy et al. [9] adopted the Hoˇsek-Wilkie sky (HW) model [10, 23] to encode 360◦ high dynamic range (HDR) illumination with as few as 4 parameters. However, this model only works well for clear skies. Zhang et al. [33] employed the Lalonde-Matthews (LM) model [17] to repre-sent all-weather outdoor illumination, but they cannot faith-fully predict the sky color due to the limited expressiveness of the LM model. Generally, analytical models fail to fully capture the complexities of real-world atmospheric condi-tions.
Recently, data-driven sky models [28, 4, 8], which com-press complex outdoor illumination into a low-dimensional latent vector, become popular in outdoor illumination pre-diction and achieve state-of-the-art performance. After training on large-scale datasets, data-driven sky models can reproduce a much wider range of outdoor illumination than most analytical models, with far less bias. However, naively compressing an outdoor panorama into a low-dimensional latent vector with neural networks would cause two major problems. First, a single vector is hard to reﬂect the HDR intensity of the sun and the diverse weather conditions si-multaneously. Consequently, the intensity of the sun would be lowered in order to match the correct sky color and tex-tures, leading to low accuracy in prediction and inconsis-tent shading and shadows in AR applications. Second, in-tuitively editing outdoor illumination based on a single la-tent vector is challenging due to the conﬂated representa-tion. For instance, it is difﬁcult to change the position of the sun while preserving other properties.
To tackle the above problems, we propose HDSky, a new data-driven sky model which is hierarchically trained on HDR panoramas to disentangle each outdoor HDR panorama into several meaningful factors. After manually classifying an input panorama into sunny or cloudy, three autoencoders are well designed to generate the disentan-gled representation for sunny panoramas. The ﬁrst autoen-coder compresses each sunny panorama into a sky vector and a sun vector by imposing constraints on the sky and sun based on the information theory. These two vectors are ex-pected to recover the original panorama after proper fusion.
The second autoencoder further disentangles the sun vector into the sun intensity and the residual factor with several customized loss functions. The third autoencoder disentan-gles the sky intensity from the sky vector. For the cloudy panorama, a single autoencoder is required to compress the panorama into a sky vector. Another autoencoder is also utilized to disentangle the sky intensity from the sky vector.
With HDSky, we are able to achieve higher accuracy in outdoor illumination prediction than previous methods based on conﬂated representations [8], since the entangle-ment among different sky properties (e.g., the intensity of the sun and the color of the sky) is avoided. Speciﬁcally, for an FoV-limited image, we ﬁrst predict its weather con-dition (sunny or cloudy) and then estimate each individual factor using several CNNs which are trained jointly on the
SUN360 dataset [32] with properly designed loss functions.
Utilizing the trained decoders of HDSky, we can fuse the disentangled factors and recover the full HDR panorama that can be used directly in AR rendering, guaranteeing con-sistent shading and shadows. The disentangled representa-tion allows us to intuitively edit the predicted outdoor illu-mination, achieving more vivid results with limited manual assistance.
The contributions of our work can be summarized as fol-lows.
• We introduce HDSky, a novel data-driven sky model that hierarchically disentangles an outdoor panorama into several interpretable vectors based on the infor-mation theory.
• We propose a uniﬁed framework that can predict all-weather sky information from a single outdoor image, achieving state-of-the-art performance in outdoor illu-mination prediction.
• We develop an intuitive editing tool based on HDSky that allows to alter the predicted outdoor illumination with ﬁne-grained control and physical plausibility. 2.