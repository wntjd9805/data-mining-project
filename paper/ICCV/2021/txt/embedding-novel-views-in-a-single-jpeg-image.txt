Abstract
We propose a novel approach for embedding novel views in a single JPEG image while preserving the perceptual fi-delity of the modified JPEG image and the restored novel views. We adopt the popular novel view synthesis repre-sentation of multiplane images (MPIs). Our model first en-codes 32 MPI layers (totally 128 channels) into a 3-channel
JPEG image that can be decoded for MPIs to render novel views, with an embedding capacity of 1024 bits per pixel.
We conducted experiments on public datasets with different novel view synthesis methods, and the results show that the proposed method can restore high-fidelity novel views from a slightly modified JPEG image. Furthermore, our method is robust to JPEG compression, color adjusting, and crop-ping. Our source code will be publicly available. 1.

Introduction
Novel view synthesis allows users to view a photograph in 3D from different viewpoints, which creates a more im-mersive experience than a 2D image. While the perfor-mance of novel view synthesis models has improved sig-nificantly in recent years, sharing the 3D photo rendered by novel view synthesis on social networks remains unsolved yet. As shown in Fig. 1, how can User A share a novel view synthesis model with others on social networks? One plau-sible strategy is to embed the novel synthesis model (MPI model) into a single embedding image (in JPEG format) that looks like an ordinary image. When User B receives the em-bedding image shared by User A, User B can view it as an ordinary 2D image; on the other hand, User C with a plugin (a restoration network) can see this image in 3D from the restored novel view synthesis model from the embedding image.
To enable such user-friendly applications, we propose a novel approach that embeds an MPI into a single embed-ding image that can be converted back to MPI. In this work, we mainly focus on MPI because it is a popular representa-tion in several state-of-the-art novel view synthesis frame-works [6, 7, 11, 21, 24, 32]. With our proposed approach,
*Joint first authors
Figure 1. An application of our method. Our approach can embed an MPI into a JPEG image, and then share it on social networks.
With our restoration network (as a plugin), users can view this image in 3D from different viewpoints. Meanwhile, users without our restoration network can still view this image as an ordinary 2D image. users can easily share a 3D photograph via a 2D embedding image on social media (e.g., Facebook and Twitter). The embedding image is simply a standard JPEG image, which is a compressed image format widely adopted in social me-dia or websites. Our proposed method can be implemented as an extension of web browsers or a lightweight plugin of apps. Users without the plugin can see the scene as a JPEG image, while users with the plugin can view this scene from different viewpoints. Our method saves network traffic and storage space benefited from the small file size of the JPEG format with a high compression rate.
Embedding a novel view synthesis model in a single image is a novel and research-worthy task. Compared to steganography, this problem has different objectives and is arguably more challenging. Our objective is not to keep the hidden information undetected. Instead, our objective is to make the embedding image visually pleasing without evident artifacts while the restored novel views are nearly perfect. Existing steganography models commonly hide a short message (a hyperlink [22], light field information [27],
Figure 2. (a) is the ground-truth image. (b) is the embedding image that embeds a 32-layer MPI. (c) and (d) are examples of recovered
MPI (RGB and Alpha) from (b). (e) is a novel view synthesized from recovered MPI decoded from the embedding image. Our method can achieve high-fidelity novel views while preserving the visual quality of the embedding image. The reported two values in (b) and (e) are
PSNR and SSIM. or a vector [33]) and a small number of images [10, 34] into a reference image. A direct application of previous tech-niques in our setting generates low-quality results for em-bedding images and the restored MPIs.
It is extremely challenging to embed a 32-layer MPI in a JPEG image, because it is equivalent to embed 32 × 4 × 8 = 1024 bits of information into a single pixel. Although the layers in the MPIs are correlated, the MPIs store the content and depth information of multiple views, thus the information amount to be embedded is still high. Moreover, the JPEG format is ubiquitously used, especially on social media, for its high compression rate. Thus we choose this lossy compression format as the format of our embedding images.
In our framework, we design a specific neural network architecture, which contains an encoder and a lightweight decoder, based on the property of MPIs. Moreover, we in-troduce a novel frequency-domain loss and adversarial loss to suppress weird high-frequency artifacts that previous ap-proaches usually have. Besides, because users often retouch the images shared on social media, we apply a set of image perturbations to make our framework robust to real-world scenarios.
We conduct experiments to evaluate the performance of our proposed model compared to several baselines. Our model significantly outperforms other baselines in novel view synthesis quality and perceptual performance. While the rendered frames in novel views can reach a high fidelity of 36.68 PSNR, the embedding image can still be preserved similar to the reference image. A visual example is shown in Figure 2.
Our contributions can be summarized as follows:
• We propose the first dedicated model that can embed
MPIs in JPEG images.
• We introduce adversarial training and frequency do-main loss to suppress high-frequency artifacts in the embedding image.
• Our system can embed MPIs in JPEG images in nearly-imperceptible form and restore high-fidelity novel views synthesis. Moreover, our system is robust to a range of image manipulations such as JPEG com-pression, color adjusting, and cropping. 2.