Abstract
Given a collection of images, humans are able to dis-cover landmarks by modeling the shared geometric structure across instances. This idea of geometric equivariance has been widely used for the unsupervised discovery of object landmark representations. In this paper, we develop a simple and effective approach by combining instance-discriminative and spatially-discriminative contrastive learning. We show that when a deep network is trained to be invariant to ge-ometric and photometric transformations, representations emerge from its intermediate layers that are highly predictive of object landmarks. Stacking these across layers in a “hy-percolumn” and projecting them using spatially-contrastive learning further improves their performance on matching and few-shot landmark regression tasks. We also present a uniﬁed view of existing equivariant and invariant represen-tation learning approaches through the lens of contrastive learning, shedding light on the nature of invariances learned.
Experiments on standard benchmarks for landmark learning, as well as a new challenging one we propose, show that the proposed approach surpasses prior state-of-the-art. 1.

Introduction
Learning in the absence of labels is a challenge for exist-ing machine learning and computer vision systems. Despite recent advances, the performance of unsupervised learning remains far below that of supervised learning, especially for few-shot image understanding tasks. This paper considers the task of unsupervised learning of object landmarks from a collection of images. The goal is to learn representations that can be used to establish correspondences across objects, and to predict landmarks such as eyes and noses when provided with a few labeled examples.
One way of inferring structure is to reason about the global appearance in terms of disentangled factors such as geometry and texture. This is the basis of alignment based [27, 37] and generative modeling based approaches
Code and data are available at https://people.cs.umass. edu/~zezhoucheng/contrastive_landmark/
Figure 1. Equivariant and invariant learning. (a) Equivariant learning requires representations across locations to be invariant to a geometric transformation g while being distinctive across locations. (b) Invariant learning encourages the representations to be invariant to transformations while being distinctive across images. Thus both can be seen as instances of contrastive learning. (c) A hypercolumn feature and its compact representation are highly predictive of object landmarks. for landmark discovery [28, 29, 47, 57, 61, 65]. An alternate is to learn a representation that geometrically transforms in the same way as the object, a property called geometric equivariance (Fig. 1a) [49–51]. However, useful invariances may not be learned (e.g., the raw pixel representation itself is equivariant), limiting their applicability in the presence of clutter, occlusion, and inter-image variations.
A different line of work has proposed instance dis-criminative contrastive learning as an unsupervised objec-tive [3, 5, 13, 21, 23, 25, 26, 40, 52, 58, 69]. The goal is to learn a representation Φ that has higher similarity between an image x and its transformation x(cid:48) than with a different one z, i.e., (cid:104)Φ(x), Φ(x(cid:48))(cid:105) (cid:29) (cid:104)Φ(x), Φ(z)(cid:105), as illustrated in
Fig. 1b. A combination of geometric (e.g., cropping and scaling) and photometric (e.g., color jittering and blurring) 1
transformations are used to encourage the representation to be invariant to these transformations while being dis-tinctive across images. Recent work [5–7, 23] has shown that contrastive learning is effective, even outperforming
ImageNet [12] pre-training on various tasks. However, to predict landmarks a representation cannot be invariant to geometric transformations. This paper asks the question: are equivariant losses necessary for unsupervised landmark discovery? In particular, do representations predictive of ob-ject landmarks automatically emerge in intermediate layers of a deep network trained to be invariant to image transfor-mations? While empirical evidence suggests that semantic parts emerge when deep networks are trained on supervised tasks [18, 68], is it also the case for unsupervised learning?
This work aims to address these by presenting a uniﬁed view of the equivariant and invariant learning approaches.
We show that when a deep network is trained to be in-variant to geometric and photometric transformations, its intermediate-layer representations are highly predictive of landmarks (Fig. 1b). The emergence of invariance and the loss of geometric equivariance is gradual in the representa-tion hierarchy, a phenomenon that has been studied empiri-cally [31, 63] and theoretically [1, 53, 54]. This observation motivates a hypercolumn representation [22], which we ﬁnd to be more effective for landmark predictions (Fig. 1c).
We also observe that objectives used in equivariant learn-ing can be seen as a contrastive loss between representations across locations within the same image, as opposed to invari-ant learning where the loss is applied across images (Fig. 1).
This observation sheds light on the nature of the invariances learned by the two approaches. It also allows us to obtain a compact representation of the high-dimensional hyper-columns simply by learning a linear projection under the spatially contrastive objective. The projection results in spa-tially distinctive representations and signiﬁcantly improves the landmark matching performance (Tab. 1 and Fig. 2).
To validate these claims, we perform experiments by train-ing deep networks using Momentum Contrast (MoCo) [23] on several landmark matching and detection benchmarks.
Other than commonly used ones, we also present a com-parison by learning on a challenging dataset of birds from the iNaturalist dataset [55] and evaluating on the CUB dataset [56]. We show that the contrastive-learned repre-sentations (without supervised regression) can be predictive in landmark matching experiments. For landmark detection, we adapt the commonly used linear evaluation setting by varying the number of labeled examples (Fig. 3 & 4). Our approach is simple, yet it offers consistent improvements over prior approaches [28, 49–51, 65] (Tab. 2). While the hy-percolumn representation leads to a larger embedding dimen-sion, it comes at a modest cost as our approach outperforms the prior state-of-the-art [49], with as few as 50 annotated training examples on the AFLW benchmark [30] (Fig. 4).
Furthermore, we use dimensionality reduction based on the equivariant learning to improve the performance on land-mark matching (Tab. 1), as well as landmark prediction in the low data regime (Tab. 4). 2.