Abstract
Conditional Generative Adversarial Networks (cGANs) extend the standard unconditional GAN framework to learning joint data-label distributions from samples, and have been established as powerful generative models ca-pable of generating high-fidelity imagery. A challenge of training such a model lies in properly infusing class infor-mation into its generator and discriminator. For the dis-criminator, class conditioning can be achieved by either (1) directly incorporating labels as input or (2) involving labels in an auxiliary classification loss. In this paper, we show that the former directly aligns the class-conditioned fake-and-real data distributions P (image|class) (data match-ing), while the latter aligns data-conditioned class distribu-tions P (class|image) (label matching). Although class sep-arability does not directly translate to sample quality and becomes a burden if classification itself is intrinsically dif-ficult, the discriminator cannot provide useful guidance for the generator if features of distinct classes are mapped to the same point and thus become inseparable. Motivated by this intuition, we propose a Dual Projection GAN (P2GAN) model that learns to balance between data matching and la-bel matching. We then propose an improved cGAN model with Auxiliary Classification that directly aligns the fake and real conditionals P (class|image) by minimizing their f -divergence. Experiments on a synthetic Mixture of Gaus-sian (MoG) dataset and a variety of real-world datasets in-cluding CIFAR100, ImageNet, and VGGFace2 demonstrate the efficacy of our proposed models. 1.

Introduction
Generative Adversarial Networks (GANs) [7] are an al-gorithmic framework that allows implicit generative mod-It has at-eling of data distribution from samples [29]. tracted great attention due to its ability to model very high-dimensional data, such as images or videos and to produce sharp and faithful samples [16, 38, 3]. Conditional GAN (cGAN) [25, 33, 28] is an extension of GAN that utilizes the label information and aims to learn the joint distribution of data and label. Thanks to its ability to control over the generative process by conditioning on labels, it has been widely adopted in real-world problems including class-conditional image generation [31, 33, 5], text-to-image gen-eration [35, 39], image-to-image generation [14, 40], text-to-video synthesis [22, 1, 10, 9], domain adaptation [13, 26] etc.
Different conditional GANs differ in the way how data and labels are incorporated in the discriminator. Class con-ditioning can be achieved by either (1) conditioning the dis-criminator directly on labels or their embeddings [25, 14, 28], or by (2) incorporating an auxiliary classification loss in the objective, as in (T)AC-GANs[25, 6]. Recently, cGAN has received a major update that changed the label from being concatenated [25, 35, 39] to being projected [28].
The projection discriminator takes the inner product be-tween the label embedding and the data/image embedding, and remains to be the choice of many state-of-the-art meth-ods [38, 3].
In this paper, we first give insights on projection dis-criminators. We point out that the success of projection can be explained by its flexible form. By tying real and fake class embeddings as their difference, a projection dis-criminator can ideally realize two extremes in a single form: (1) matching conditional label distributions P (class|image) (label matching), and (2) matching conditional data dis-tributions P (image|class) (data matching). Moreover, the visualization of data embeddings of trained projection dis-criminators does not show obvious patterns of class clus-tering. This suggests that projection may bias towards con-ditional data matching. Although label matching does not
Figure 1: Illustrative figures visualize the learning schema of conditional discriminator losses. The color indicates how real/fake embeddings interact during discriminator training. The green/red boundary indicates (unconditional) real/fake decision boundary. Triangles represent class embeddings, and circles indicate image embeddings (e.g. vp y is blue triangle in
AC-GAN since it is class embedding and is trained on both real and fake data). Solid blue and red lines represent pull/push forces respectively. Black arrows indicate the forces that a fake image embedding receives. directly translate to the fidelity of generated samples, it is still desirable for generating high-quality images. For ex-ample, the discriminator would not provide useful guidance for the generator if features of distinct classes are mapped to the same point and thus become inseparable.
To this end, we propose a new conditional generative ad-versarial network, namely Dual Projection GAN (P2GAN).
The main feature of our design is to inherit the flexibil-ity of projection while performing explicit label matching.
Realized by auxiliary classification losses, label matching enables the discriminator to exploit useful information for the generator. However, if such task is intrinsically dif-ficult (such as ImageNet [36]), label matching becomes a burden. In an extreme case when the auxiliary classifica-tion task failed completely, (T)AC-GANs will degrade to an unconditional GAN while P2GAN degrades to a projec-tion GAN. We also present adaptive approaches to weighing data matching and label matching. Furthermore, we respec-tively propose two variants for explicit data matching and label matching: (1) direct data matching GAN (DM-GAN), (2) and f -cGAN which aligns the fake and real condition-als P (class|image) by minimizing their f -divergence. Fi-nally, we conduct extensive experiments on various datasets to show the efficacy of the proposed models. 2.