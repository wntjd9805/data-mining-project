Abstract
We present a novel pyramidal output representation to ensure parsimony with our “specialize and fuse” process for semantic segmentation. A pyramidal “output” represen-tation consists of coarse-to-fine levels, where each level is
“specialize” in a different class distribution (e.g., more stuff than things classes at coarser levels). Two types of pyramidal outputs (i.e., unity and semantic pyramid) are “fused” into the final semantic output, where the unity pyramid indicates unity-cells (i.e., all pixels in such cell share the same seman-tic label). The process ensures parsimony by predicting a relatively small number of labels for unity-cells (e.g., a large cell of grass) to build the final semantic output. In addition to the “output” representation, we design a coarse-to-fine contextual module to aggregate the “features” representa-tion from different levels. We validate the effectiveness of each key module in our method through comprehensive abla-tion studies. Finally, our approach achieves state-of-the-art performance on three widely-used semantic segmentation datasets—ADE20K, COCO-Stuff, and Pascal-Context. 1.

Introduction
Given an RGB image, semantic segmentation defines se-mantic labels for all pixels as “output”. Recent methods on semantic segmentation widely exploit deep neural networks.
One major research direction is designing new contextual modules [4, 5, 6, 13, 27, 28, 29, 34] exploring better “feature” representation in the networks. We argue that leveraging the structure in the “output” representation could open up op-portunities orthogonal to the current endeavors. We observe that a large portion of pixels in most images share the same label at a coarse spatial level (e.g., stuff classes like sky and grass, or central region of objects). This observation induces a parsimonious strategy to dynamically predict semantic la-bels at a coarser level according to the spatial distribution of classes in each input image.
∗The authors contribute equally to this paper.
We proposed a novel pyramidal output representation to ensure parsimony with our “specialize and fuse” process (Fig. 1). Firstly, rather than a single-level output, a pyra-midal output starting from the coarsest level to the finest level is designed so that each level is learned to “specialize” in a different class distribution (e.g., more stuff than things classes at coarser levels). Specifically, two types of pyra-midal output (unity and semantic pyramid) are predicted.
Unity pyramid identifies whether a patch of pixels (referred to as a cell) shares the same label (referred to as a unity-cell) (Fig. 1-first row), and semantic pyramid consists of semantic labels at multiple levels (Fig. 1-second row). Finally, the semantic pyramid are “fused” into one single semantic out-put according to the unity-cells across levels (Fig. 1-bottom panel). Note that our “specialize and fuse” process ensures parsimony by predicting a relatively small number of labels for unity-cells (e.g., a large cell of grass) to build the final se-mantic output. In addition to the “output” representation, we design a coarse-to-fine contextual module to aggregate the
“features” representation from different levels for improving semantic pyramid prediction.
Our main contributions are as follows: i) we introduce a pyramidal “output” representation and a “specialize and fuse” process to allow each level to specialize in different class distribution and ensure parsimony; ii) we design a contextual module to aggregate the “features” representation from dif-ferent levels for further improvements; iii) we showcase the effectiveness of our method on ADE20K, COCO-Stuff, and
Pascal-Context. Our method with both HRNet and ResNet as the backbone can achieve results on par with or better than the recent state-of-the-art methods. 2.