Abstract
This paper addresses the problem of 3D human body shape and pose estimation from an RGB image. This is of-ten an ill-posed problem, since multiple plausible 3D bodies may match the visual evidence present in the input - partic-ularly when the subject is occluded. Thus, it is desirable to estimate a distribution over 3D body shape and pose conditioned on the input image instead of a single 3D re-construction. We train a deep neural network to estimate a hierarchical matrix-Fisher distribution over relative 3D joint rotation matrices (i.e. body pose), which exploits the human body’s kinematic tree structure, as well as a Gaus-sian distribution over SMPL body shape parameters. To fur-ther ensure that the predicted shape and pose distributions match the visual evidence in the input image, we implement a differentiable rejection sampler to impose a reprojection loss between ground-truth 2D joint coordinates and sam-ples from the predicted distributions, projected onto the im-age plane. We show that our method is competitive with the state-of-the-art in terms of 3D shape and pose metrics on the SSP-3D and 3DPW datasets, while also yielding a structured probability distribution over 3D body shape and pose, with which we can meaningfully quantify prediction uncertainty and sample multiple plausible 3D reconstruc-tions to explain a given input image. 1.

Introduction 3D human body shape and pose estimation from an
RGB image is a challenging computer vision problem, partly due to its under-constrained nature wherein mul-tiple 3D human bodies may explain a given 2D image, especially when the subject is significantly occluded, as is common for in-the-wild images. Several recent works
[53, 20, 27, 26, 46, 63, 12, 37, 14, 40, 39, 54, 35, 52] use deep neural networks to regress a single body shape and pose solution, which can result in impressive 3D body re-constructions given sufficient visual evidence in the input image. However, when visual evidence of the subject’s shape and pose is obscured, e.g. due to occluding objects
Figure 1. 3D reconstruction samples and per-vertex uncertainty corresponding to the predicted hierarchical shape and pose dis-tributions computed from the given input images. or self-occlusions, a single solution does not fully describe the space of plausible 3D reconstructions. In contrast, we aim to estimate a structured probability distribution over 3D body shape and pose, conditioned on the input image, thereby allowing us to sample any number of plausible 3D reconstructions and quantify prediction uncertainty over the 3D body surface, as shown in Figure 1.
We use the SMPL body model [32] to represent human shape and pose. Identity-dependent body shape is param-eterised by coefficients of a PCA basis - hence, a simple multivariate Gaussian distribution over the shape parame-ters is suitable. Body pose is parameterised by relative 3D joint rotations along the SMPL kinematic tree, which may be represented using rotation matrices. Regressing rotation matrices using neural networks is non-trivial, since they lie in SO(3), a non-linear 3D manifold with a different topol-ogy to R3×3 or R9, the space in which unconstrained neu-ral network outputs lie. However, one can define proba-bility density functions over the Lie group SO(3), such as the matrix-Fisher distribution [33, 11, 22], the parameter of which is an element of R3×3 and may be easily regressed with a neural network [34]. We propose a hierarchical prob-ability distribution over relative 3D joint rotations along the
SMPL kinematic tree, wherein the probability density func-tion of each joint’s relative rotation matrix is a matrix-Fisher distribution conditioned on the parents of that joint in the
kinematic tree. We train a deep neural network to predict the parameters of such a distribution over body pose, along-side a Gaussian distribution over SMPL shape.
Moreover, to ensure that 3D bodies sampled from the predicted distributions match the 2D input image, we im-plement a reprojection loss between predicted samples and ground-truth visible 2D joint annotations. To allow for the backpropagation of gradients through the sampling op-eration, we present a differentiable rejection sampler for matrix-Fisher distributions over relative 3D joint rotations.
Finally, a key obstacle for SMPL body shape regression from in-the-wild images is the lack of training datasets with accurate and diverse body shape labels [46]. To overcome this, we follow [46, 52, 40, 47] and utilise synthetic data, randomly generated on-the-fly during training. Inspired by
[7], we use convolutional edge filters to close the large synthetic-to-real gap and show that using edge-based inputs yields better performance than commonly-used silhouette-based inputs [46, 52, 47, 40], due to improved robustness and capacity to retain visual shape information.
In summary, our main contributions are as follows:
• Given an input image, we predict a novel hierarchical matrix-Fisher distribution over relative 3D joint rota-tion matrices, whose structure is explicitly informed by the SMPL kinematic tree, alongside a Gaussian distri-bution over SMPL shape parameters.
• We present a differentiable rejection sampler to sample any number of plausible 3D reconstructions and quan-tify prediction uncertainty over the body surface. This enables a reprojection loss between predicted samples and ground-truth coordinates of visible 2D joints, fur-ther ensuring that the predicted distributions are con-sistent with the input image.
• We use simple convolutional edge filters to improve the random synthetic training framework used by [46, 47]. Edge filtering is a computationally-cheap and ro-bust method for closing the domain gap between syn-thetic RGB training data and real RGB test data. 2.