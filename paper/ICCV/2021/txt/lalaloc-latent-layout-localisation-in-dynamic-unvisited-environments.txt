Abstract
We present LaLaLoc to localise in environments with-out the need for prior visitation, and in a manner that is robust to large changes in scene appearance, such as a full rearrangement of furniture. Specifically, LaLaLoc per-forms localisation through latent representations of room layout. LaLaLoc learns a rich embedding space shared be-tween RGB panoramas and layouts inferred from a known floor plan that encodes the structural similarity between lo-cations. Further, LaLaLoc introduces direct, cross-modal pose optimisation in its latent space. Thus, LaLaLoc en-ables fine-grained pose estimation in a scene without the need for prior visitation, as well as being robust to dy-namics, such as a change in furniture configuration. We show that in a domestic environment LaLaLoc is able to ac-curately localise a single RGB panorama image to within 8.3cm, given only a floor plan as a prior. 1.

Introduction
Camera relocalisation is a fundamental problem in com-puter vision. Image-based relocalisation represents the goal of estimating the camera pose of an unseen image, given some prior knowledge about the surrounding environment.
In this paper, we tackle the task of localisation in an environ-ment that has not been previously visited, and one in which there may be considerable scene dynamics – an area where significant scope for improvement has been identified [37].
To address this, we propose to localise with respect to a known floor plan and the layout visible at a location within the scene. Floor plan-based localisation is particu-larly suited for the long-term localisation setting as, while objects and furniture may have moved, items represented in a structural floor plan, such as walls, floors and ceilings, will remain static. Therefore, it enables localisation over a long period of time without requiring continual re-training or re-mapping. In addition, in this formulation we only need the floor plan as prior, thus removing the need for previous visitation of the target environment, i.e. without a training trajectory of images.
We present LaLaLoc, which performs floor plan-based localisation through latent representations of room layout.
This layout latent space is cross-modal, shared between layouts inferred from the floor plan and the RGB panora-mas queried at inference time. More specifically LaLaLoc performs localisation in two stages, depicted in Figure 1.
The first stage provides a coarse estimate of pose through cross-modal retrieval. For the second stage, we propose a cross-modal direct optimisation of pose through differen-tiable rendering.
Differentiable rendering has been shown to be effective for object pose estimation [23, 12]. But these works typi-cally rely on like-for-like rendering losses, such as the pix-elwise error between the rendered and target images. How-ever, since LaLaLoc operates across multiple modes of data between query and prior, the prediction of a common data mode would be required for the comparison losses. Instead, we propose to optimise for pose directly in the layout la-tent space. Through this formulation, LaLaLoc is able to accurately align the floor plan to a cluttered RGB panorama without ever explicitly predicting its layout.
The contributions of this paper can be summarised as:
• We propose LaLaLoc, a highly accurate localisation method that is robust to scene dynamics such as the configuration of furniture, and able to localise in a new scene without prior visitation.
• We introduce direct pose optimisation in the latent space. This allows for cross-modal pose optimisation, without the need for a decoder to traverse data modes for the computation of the matching cost.
• Through experimental evaluation, we demonstrate the accuracy of LaLaLoc as well as validate its formula-tion. This includes showing that the representation of room layout has significant influence on the efficacy of layout-based localisation and cannot be used inter-changeably.
Figure 1. Overview of localisation using LaLaLoc. In the retrieval stage, the query image is mapped to the layout latent space by Φimage .
We then sample a grid of poses from a known floor plan, render their layouts, and compute their respective latent representation through
Φlayout . An initial pose estimate is found by a nearest neighbour search within this shared latent space. The nearest neighbour pose is then used as an initialisation for direct pose optimisation with our proposed latent pose optimisation. This is a gradient-based optimisation of pose conducted in the shared latent space, thus removing the need to decode into a common data mode. Our Vogel Disc resampling stage is ommitted from this viusalisation for clarity. 2.