Abstract
Generative Adversarial Networks (GANs) have wit-nessed prevailing success in yielding outstanding images, however, they are burdensome to deploy on resource-constrained devices due to ponderous computational costs and hulking memory usage. Although recent efforts on com-pressing GANs have acquired remarkable results, they still exist potential model redundancies and can be further com-pressed. To solve this issue, we propose a novel online multi-granularity distillation (OMGD) scheme to obtain lightweight GANs, which contributes to generating high-ﬁdelity images with low computational demands. We of-fer the ﬁrst attempt to popularize single-stage online dis-tillation for GAN-oriented compression, where the pro-gressively promoted teacher generator helps to reﬁne the discriminator-free based student generator. Complemen-tary teacher generators and network layers provide com-prehensive and multi-granularity concepts to enhance vi-sual ﬁdelity from diverse dimensions. Experimental re-sults on four benchmark datasets demonstrate that OMGD successes to compress 40× MACs and 82.5× parameters on Pix2Pix and CycleGAN, without loss of image qual-1These authors contributed equally to this work. ity. It reveals that OMGD provides a feasible solution for the deployment of real-time image translation on resource-constrained devices. Our code and models are made public at: https://github.com/bytedance/OMGD 1.

Introduction
Recently, Generative Adversarial Networks (GANs) [16] have achieved prominent results in diversiﬁed visual appli-cations, such as image synthesis [39, 40, 34, 64, 5] and image-to-image translation [23, 66, 10, 26, 11, 47]. Albeit with varying degrees of progress, most of its recent suc-cesses [23, 66, 47, 64, 10, 5] are involved in huge resource demands. It is arduous to popularize such models that re-quire tremendous computational costs, which becomes a critical bottleneck as this model is deployed on resource-constrained mobile phones or other lightweight IoT devices
[21, 50, 30, 9]. To alleviate such expensive and unwieldy computational costs, GAN compression becomes a newly-raised and crucial task. A great deal of mainstream model compression techniques [29, 28, 56, 38, 57, 33] are em-ployed to learn efﬁcient GAN, including knowledge distil-lation [30, 1, 49, 8, 13, 15, 31, 20, 9, 24], channel pruning
[30, 31, 49] and nerual architecture search [15, 30, 31].
Figure 2: Performance-MACs trade-off between OMGD and existing competitive methods including GAN compression [30],
CAT [24], DMAD [31], GAN-Slimming [49], AutoGAN-Distiller [13] and Co-Evolution [45]. (cid:3) denotes the U-Net style generator and (cid:63) is the Res-Net style. OMGD signiﬁcantly outperforms these methods with much less computational costs.
“Baseline” denotes that the model is trained with naive GAN loss.
However, the above compression algorithms primarily they tend to straightfor-exist threefold issues. Firstly, wardly resort to the mature model compression techniques
[7, 63, 19], which are not customized for GAN and lack exploration of complex characteristics and structures for
GAN. Secondly, they usually formulate GAN compression as a multi-stages task. For example, [30] needs to pre-train, distillate, evolute, and ﬁne-tune sequentially. The distillation-based methods [30, 31, 13, 9, 8, 49, 24] should pre-train a teacher generator and then distill the student one.
An end-to-end approach is essential to reduce the compli-cated time and computational resources in the multi-stages setting. Thirdly, the current state-of-the-art methods are still burdened with high computational costs. For instance, the best model [31] requires 3G MACs, which is relatively high for deployment on lightweight edge devices.
To overcome the above issues, we craft to propose a novel Online Multi-Granularity Distillation (OMGD) framework for learning efﬁcient GANs. We abandon the complex multi-stage compression process and design a
GAN-oriented online distillation strategy to obtain the com-pressed model in one step. We can excavate potential com-plementary information from multiple levels and granular-ities to assist in the optimization of compressed models.
These concepts can be regarded as auxiliary supervision cues, which is very critical to break through the bottleneck of capacity for models with low computational costs. The contributions of OMGD can be summarized as follows:
• To the best of our knowledge, we offer the ﬁrst at-tempt to popularize distillation to an online scheme in the ﬁeld of GAN compression and optimize the student generator in a discriminator-free and ground-truth-free setting. This scheme trains the teacher and student alternatively, promoting these two generators iteratively and progressively. The progressively opti-mized teacher generator helps to warm up the student and guide the optimization direction step by step.
• We further extend the online distillation strategy into a multi-granularity scheme from two perspectives. On the one hand, we employ different structure based teacher generators to capture more complementary cues and enhance visual ﬁdelity from more diversi-ﬁed dimensions. On the other hand, besides the con-cepts of the output layer, we also transfer the channel-wise granularity information from intermediate layers to play as additional supervisory signals.
• Extensive
[66], horse→zebra summer→winter experiments on widely-used datasets (i.e.,
[66], edges→shoes [60] and cityscapes [12]) demonstrate that OMGD can reduce the computation of two essential conditional GAN models including pix2pix
[23] and CycleGAN [66] by 40× regarding MACs, without loss of the visual ﬁdelity of generated images.
It reveal that OMGD is efﬁcient and robust for various benchmark datasets, diverse conditional GAN, network architectures as well as problem settings (paired or unpaired). Compared with the existing competitive approaches, OMGD helps to obtain better image quality with much less computational costs (see Figure 1 and 2). Furthermore, OMGD 0.5× (only requires 0.333G MACs) successes to achieve impressive results, which provides a feasible solution for deployment on resource-constrained devices and even breaks the barriers to real-time image translation on mobile devices. 2.