Abstract
We present an unsupervised learning framework for de-composing images into layers of automatically discovered object models. Contrary to recent approaches that model im-age layers with autoencoder networks, we represent them as explicit transformations of a small set of prototypical images.
Our model has three main components: (i) a set of object pro-totypes in the form of learnable images with a transparency channel, which we refer to as sprites; (ii) differentiable para-metric functions predicting occlusions and transformation parameters necessary to instantiate the sprites in a given image; (iii) a layered image formation model with occlu-sion for compositing these instances into complete images including background. By jointly learning the sprites and occlusion/transformation predictors to reconstruct images, our approach not only yields accurate layered image decom-positions, but also identifies object categories and instance parameters. We first validate our approach by providing results on par with the state of the art on standard multi-object synthetic benchmarks (Tetrominoes, Multi-dSprites,
CLEVR6). We then demonstrate the applicability of our model to real images in tasks that include clustering (SVHN,
GTSRB), cosegmentation (Weizmann Horse) and object dis-covery from unfiltered social network images. To the best of our knowledge, our approach is the first layered image decomposition algorithm that learns an explicit and shared concept of object type, and is robust enough to be applied to real images. 1.

Introduction
Figure 1: Our approach learns without supervision to decom-pose images into layers modeled as transformed instances of prototypical objects called sprites. We show an example of decomposition on CLEVR [30] (top) and examples of discov-ered sprites for Tetrominoes [21] and GTSRB [60] (bottom).
Transparency is visualized using light gray checkerboards.
The aim of this paper is to learn without any supervision a layered decomposition of images, where each layer is a transformed instance of a prototypical object. Such an inter-pretable and layered model of images could be beneficial for a plethora of applications like object discovery [16, 6], image edition [72, 21], future frame prediction [71], object pose estimation [53] or environment abstraction [1, 44]. Recent works in this direction [6, 21, 46] typically learn layered im-age decompositions by generating layers with autoencoder networks. In contrast, we explicitly model them as transfor-mations of a set of prototypical images with transparency, which we refer to as sprites. These sprites are mapped onto their instances through geometric and colorimetric transfor-mations resulting in what we call object layers. An image is then assembled from ordered object layers so that each layer occludes previous ones in regions where they overlap.
Our composition model is reminiscent of the classic com-puter graphics sprite model, popular in console and arcade games from the 1980s. While classical sprites were simply placed at different positions and composited with a back-ground, we revisit the notion in a spirit similar to Jojic and
Frey’s work on video modeling [31] by using the term in a more generic sense: our sprites can undergo rich geometric transformations and color changes.
We jointly learn in an unsupervised manner both the sprites and parametric functions predicting their transfor-mations to explain images. This is related to the recent deep transformation-invariant (DTI) method designed for clustering by Monnier et al. [51]. Unlike this work, how-ever, we handle images that involve a variable number of objects with limited spatial supports, explained by different transformations and potentially occluding each other. This makes the problem very challenging because objects cannot be treated independently and the possible number of image compositions is exponential in the number of layers.
We experimentally demonstrate in Section 4.1 that our method is on par with the state of the art on the synthetic datasets commonly used for image decomposition evalua-tion [21]. Because our approach explicitly models image compositions and object transformations, it also enables us to perform simple and controlled image manipulations on these datasets. More importantly, we demonstrate that our model can be applied to real images (Section 4.2), where it successfully identifies objects and their spatial extent. For example, we report an absolute 5% increase upon the state of the art on the popular SVHN benchmark [52] and good cosegmentation results on the Weizmann Horse database [4].
We also qualitatively show that our model successfully dis-criminates foreground from background on challenging sets of social network images.
Contributions. To summarize, we present:
• an unsupervised learning approach that explains images as layered compositions of transformed sprites with a background model;
• strong results on standard synthetic multi-object bench-marks using the usual instance segmentation evaluation, and an additional evaluation on semantic segmentation, which to the best of our knowledge has never been re-ported by competing methods; and
• results on real images for clustering and cosegmentation, which we believe has never been demonstrated by earlier unsupervised image decomposition models.
Code and data are available on our project webpage. 2.