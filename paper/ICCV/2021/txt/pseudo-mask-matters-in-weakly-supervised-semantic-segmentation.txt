Abstract
Most weakly supervised semantic segmentation (WSSS) methods follow the pipeline that generates pseudo-masks initially and trains the segmentation model with the pseudo-masks in fully supervised manner after. However, we
ﬁnd some matters related to the pseudo-masks, including high quality pseudo-masks generation from class activation maps (CAMs), and training with noisy pseudo-mask super-vision. For these matters, we propose the following designs to push the performance to new state-of-art: (i) Coefﬁcient of Variation Smoothing to smooth the CAMs adaptively; (ii) Proportional Pseudo-mask Generation to project the ex-panded CAMs to pseudo-mask based on a new metric indi-cating the importance of each class on each location, in-stead of the scores trained from binary classiﬁers. (iii) Pre-tended Under-Fitting strategy to suppress the inﬂuence of noise in pseudo-mask; (iv) Cyclic Pseudo-mask to boost the pseudo-masks during training of fully supervised semantic segmentation (FSSS). Experiments based on our methods achieve new state-of-art results on two changeling weakly supervised semantic segmentation datasets, pushing the mIoU to 70.0% and 40.2% on PAS-CAL VOC 2012 and MS
COCO 2014 respectively. Codes including segmentation framework are released at https://github.com/Eli-YiLi/PMM 1.

Introduction
Semantic segmentation is a fundamental computer vi-sion problem and requires time-consuming pixel-level man-ual annotations. To reduce the annotation burden, weakly-supervised semantic segmentation approaches have been proposed using scribble annotations [23, 32], bounding boxes [36, 9, 16] , points [3] or image-level labels [17, 27, 28, 2, 33]. In this paper, we focus on weakly-supervised se-mantic segmentation with image-level labels due to its eas-ily available annotations.
Almost all the latest WSSS algorithms require pseudo-mask derived from CAM to train the FSSS model. Instead of the pseudo-mask, previous works mainly focus on the generation of CAMs, or the post-process of them. We ob-serve that there are some matters about pseudo-mask that are not handled appropriately as follows: (i) argmax oper-ation on the CAMs along the channel dimension projects multi-label class activation maps (CAMs) to single-label pseudo-masks, but the image-level classiﬁcation for gener-ating CAMs does not consider the conﬂicts of predictions on target locations; (ii) CAMs generated by the classiﬁca-tion model tend to focus on the most discriminative part and result in partial activations; (iii) the noise in pseudo-masks is inevitable and impedes the training of fully-supervised semantic segmentation (FSSS). (iv) the predictions of FSSS are usually more accurate than supervisory signals (pseudo-masks).
In this paper, we propose a series of strategies to boost the efﬁciency of pseudo-masks in aspects of both genera-tion and utilization. Speciﬁcally, in the pseudo-mask gen-eration step, we ﬁrstly compute the Coefﬁcient of Varia-tion (cv) for each channel of CAMs, and then reﬁne CAMs via exponential functions with cv as the control coefﬁcient.
This operation smooths the CAMs and could alleviate the partial response problem introduced by the classiﬁcation pipeline. Instead of projecting the three-dimensional CAM after dense-CRF [18] directly to two-dimensional pseudo-mask with the argmax operation on scores as in previous studies, we equip each pixel a scalar which is computed as the proportion between the pixel’s attention and the atten-tion sum of the channels over the whole image. Intuitively the scalar represents the importance of the corresponding pixel based on which the ﬁnal pseudo-masks are generated.
In the FSSS training step, we propose a Pretended Under-ﬁtting Strategy which suppresses the losses of the noise la-bels in the pseudo-masks. In addition, the model is evalu-ated on validation dataset and we update the masks cycli-cally in condition that prediction from model is better than the pseudo-masks, rather than use the ﬁxed pseudo-masks generated in the ﬁrst step.
Applying our methods to a baseline algorithm called
SEAM [33], we achieve new state-of-the-art results on
two challenging weakly-supervised semantic segmentation benchmarks. In particular, our approach reach the mIoU of 70.0% and 40.2% on In PASCAL VOC 2012 [10] and MS
COCO 2014 [24] validation sets respectively.
The contributions of this paper are three-fold:
• We generate high-quality pseudo-masks by the pro-posed Proportional Pseudo-mask Generation with Co-efﬁcient of Variation Smoothing. The Coefﬁcient of
Variation Smoothing expands the activation area of
CAMs to overcome the partial response problem based on the CAM’s coefﬁcient of variation, and the Pro-portional Pseudo-mask Generation computes the im-portance of each location for each class independently, based on which the ﬁnal pseudo-masks are generated.
• We realize the effective utilization of pseudo-masks via reducing the inﬂuence of noise by our Pretended
Under-ﬁtting Strategy, and narrow the gap between ground-truths and pseudo-masks via Cyclic Pseudo-masks. The pixel-wise losses are reweighted to sup-press the noises in the Pretended Under-ﬁtting Strategy and pseudo-masks are reﬁned in a iterative manner.
• We conduct extensive experiments to validate the effectiveness of our proposed approach (Pseudo-mask Matters, PMM), and demonstrate that our ap-proach achieves new state-of-the-art results on two challenging weakly-supervised semantic segmentation datasets. 2.