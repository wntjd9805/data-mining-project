Abstract
Effectively structuring deep knowledge plays a pivotal role in transfer from teacher to student, especially in seman-tic vision tasks. In this paper, we present a simple knowl-edge structure to exploit and encode information inside the detection system to facilitate detector knowledge distilla-tion. Specifically, aiming at solving the feature imbalance problem while further excavating the missing relation inside semantic instances, we design a graph whose nodes corre-spond to instance proposal-level features and edges repre-sent the relation between nodes. To further refine this graph, we design an adaptive background loss weight to reduce node noise and background samples mining to prune trivial edges. We transfer the entire graph as encoded knowledge representation from teacher to student, capturing local and global information simultaneously.
We achieve new state-of-the-art results on the chal-lenging COCO object detection task with diverse student-teacher pairs on both one- and two-stage detectors. We also experiment with instance segmentation to demonstrate robustness of our method.
It is notable that distilled
Faster R-CNN with ResNet18-FPN and ResNet50-FPN yields 38.68 and 41.82 Box AP respectively on the COCO benchmark, Faster R-CNN with ResNet101-FPN signifi-cantly achieves 43.38 AP, which outperforms ResNet152-FPN teacher about 0.7 AP. Code: https://github. com/dvlab-research/Dsig. 1.

Introduction
Thanks to massive visual data and computing power, there is increasing advancement of advanced object detec-tors driven by deep networks. The backbone networks, such as ResNet [10] and VGG [30], facilitate modern de-tectors to advance high-level vision research. These de-tectors are powerful and contain numerous weights. They consume considerable storage as well as computation, mak-ing it hard to be deployed on mobile devices. Parallel to previous research of network pruning [7, 6] and net-work quantization [24, 42, 13, 16, 6], knowledge distilla-tion [11, 41, 14, 23, 39, 27] transfers knowledge from the (a) Original Image (b) Ground Truth (c) student (d) teacher (e) pixel matching method [35] (f) ours with relation distillation
Figure 1. We use t-SNE [34] to show the topological structure of the proposal’s features in different trained detectors on test image.
Each marker represents one proposal’s features. teacher model to a much smaller student model. tributes in an effective way for network compression [6].
It con-Feature Imbalance: Methods of [11, 27] for knowledge distillation mostly dedicate to classifier distillation where only the logits (to the final softmax layer) are considered.
However, transferring large global feature maps from the teacher to student needs global feature regression, and may introduces many trivial pixels to match.
To distill useful information in feature maps, methods of [35, 31] pay attention to foreground location and use human-made masks to extract close-to-instance features, leaving a level of pixels unused in the whole feature maps.
Consequently, covering masks on feature maps may cause
very few background features distilled, still losing useful information in distillation. These two extreme cases raise an essential question: how to leverage background features and reach a promising balance?
Missing Instance-level Relations: Additionally, all pre-vious methods [15, 35, 31] adopt the scheme to individually transfer knowledge from teacher features to the student in pixel level. In fact, object instances in a single image show latent relation [12, 22] among each other, which is impor-tant for the sampled instance features to form knowledge base to facilitate later classification and regression tasks.
To better understand the relation, we visualize it using t-SNE [34], which depicts the different topological structure of instances in trained models in Figure 1. It reveals that the relation space of the student and teacher is quite different in terms of both shape and intensity w.r.t. the same test image.
Moreover, after the student is distilled with only pixel-to-pixel regression [35], the topological structure is no longer aligned with the teacher though it looks like better classified than the student baseline. Here thus comes another major question: how to better utilize the latent relation inside deep neural networks?
Our Contributions: We address these two problems and define an effective structured instance graph based on each Region of Interest (RoI) in the detection system. In our graph, nodes correspond to the features of RoI instances, we collect these regional features that are sampled in the sub-sequent classification and regression tasks.
Edges represent the relations between nodes and are measured by their feature similarity. As the architectures of student/teacher are heterogeneous in width and depth, their output is with different topological structure, shedding light on pairwise interrelation distillation. Different from pixel-to-pixel distillation, pairwise interrelation distillation utilizes information within a number of instances and intro-duces a new type of regularization for student training.
The nodes are devised to overcome the feature imbal-ance problem and the edges excavate the missing instance relation. Rather than transferring the nodes and edges sep-arately, we directly distill the structured graph from teacher to student via a simple loss function, to close the gap be-tween their knowledge space. In Figure 1(f), intuitively, dis-tilling the entire graph via our method is actually to match local feature patches while capturing the global topological structures in the meantime.
However, distilling the graph is not easy. First, a large proportion of background nodes in distillation provide too much noisy supervision compared with foreground nodes.
Second, dense connection between nodes also contains massive background-related edges (linked with background node). These two issues both add harmful regularization to overwhelm the distillation process. Here we introduce two techniques. For nodes, we control the background node loss as adaptive concerning the foreground/background ra-tios. For edges, we design the