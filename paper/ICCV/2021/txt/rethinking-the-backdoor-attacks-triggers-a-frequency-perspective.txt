Abstract
Backdoor attacks have been considered a severe security threat to deep learning. Such attacks can make models per-form abnormally on inputs with predefined triggers and still retain state-of-the-art performance on clean data. While backdoor attacks have been thoroughly investigated in the image domain from both attackers’ and defenders’ sides, an analysis in the frequency domain has been missing thus far.
This paper first revisits existing backdoor triggers from a frequency perspective and performs a comprehensive anal-ysis. Our results show that many current backdoor attacks exhibit severe high-frequency artifacts, which persist across different datasets and resolutions. We further demonstrate these high-frequency artifacts enable a simple way to de-tect existing backdoor triggers at a detection rate of 98.50% without prior knowledge of the attack details and the target model. Acknowledging previous attacks’ weaknesses, we propose a practical way to create smooth backdoor trig-gers without high-frequency artifacts and study their de-tectability. We show that existing defense works can ben-efit by incorporating these smooth triggers into their design consideration. Moreover, we show that the detector tuned over stronger smooth triggers can generalize well to unseen weak smooth triggers. In short, our work emphasizes the importance of considering frequency analysis when design-ing both backdoor attacks and defenses in deep learning. 1.

Introduction
Backdoor attacks are the attacks where adversaries delib-erately manipulate a proportion of the training data [11, 5], or the model’s parameters [18], to make the model rec-ognize a backdoor trigger as the desired target label(s).
When the backdoor trigger is introduced during test-time, the poisoned model exhibits a particular output behavior of the adversary’s choosing (e.g., a misclassification). Back-*Yi Zeng and Won Park contributed equally. door triggers have been demonstrated to perform malicious tasks on security-concerned deep learning services, such as converting the label of a stop sign [11] or misidentifying faces [5], thereby posing significant risks.
State-of-the-art backdoor triggers are designed to be in-conspicuous to human observers. One idea of generating such triggers is to use patterns of commonplace objects [18, 30]. For instance, one could use glasses–commonplace ob-jects appearing in a face image–as a trigger to backdoor a face recognition model, thereby hiding the triggers “in the human psyche.” Another approach to generate “hidden” or “invisible” triggers is to inject imperceptible perturba-tions via solving a norm-constrained optimal attack prob-lem [17, 24] or leveraging GANs [25].
Previous research on backdoor data detection either identifies outliers directly in the image space [22] or ana-lyzes the network activations based on an image input [23, 20, 3, 15]. In contrast, we provide a comprehensive anal-ysis of the frequency spectrum across various existing trig-gers and multiple datasets. We find that all existing ideas of generating samples contain triggers exhibit severe high-frequency artifacts. We provide a detailed analysis of the causes of the high-frequency artifacts for different triggers and show that these artifacts stem from either the trigger pattern per se or the methodology of inserting the trigger.
Based on these insights, we demonstrate that the fre-quency domain can efficiently identify potential backdoor data in both the training and test phase. We build a detec-tion pipeline based on a simple supervised learning frame-work and proper data augmentation as a demonstration. It can identify existing backdoor triggers at a detection rate of 98.5% without prior knowledge of the types of backdoor attacks used. A high detection rate is still maintained even when the data used for training and testing the detector have different input distributions and are from different datasets.
Given that present triggers are easily detectable in the frequency domain, our natural question is whether or not effective backdoor triggers can be designed without high-frequency artifacts (which we will refer to as smooth trig-1
gers hereinafter). A straightforward approach to generating smooth triggers is to apply a low-pass filter to existing trig-gers directly. However, in our experiments, we find this simple approach cannot achieve a satisfying attack success rate. To design more effective smooth triggers, we first for-mulate the trigger design problem as a bilevel optimization problem and then propose a practical heuristic algorithm to create triggers. Our experiments show that our proposed triggers outperform simple low-pass filtered triggers. We further study the detectability of the triggers and show how existing defense works can benefit from smooth triggers in their design. Our experiments also demonstrate that detec-tors trained over strong, smooth triggers can generalize well to unseen weak smooth triggers.
Overall, our work highlights the importance of the over-looked frequency analysis in the design of both backdoor attacks and defenses. We open-source the experiment codes and welcome the public to contribute to future develop-ments1. Our key contributions are summarized as follows: 1) We perform a comprehensive frequency-domain analy-sis of existing backdoors triggers, revealing severe high-frequency artifacts commonly across different datasets and resolutions. 2) We present a detailed analysis of the causes of these artifacts. 3) We show the effectiveness of employ-ing frequency representations for detecting existing trig-gers. 4) We propose a practical way of generating effective smooth triggers that do not exhibit high-frequency artifacts and provide actionable insights into their detectability. 2.