Abstract
The ability to ﬁnd correspondences in visual data is the essence of most computer vision tasks. But what are the right correspondences? The task of visual correspondence is well deﬁned for two different images of same object instance. In case of two images of objects belonging to same category, visual correspondence is reasonably well-deﬁned in most cases. But what about correspondence between two objects of completely different category – e.g., a shoe and a bottle?
Does there exist any correspondence? Inspired by humans’ ability to: (a) generalize beyond semantic categories and; (b) infer functional affordances, we introduce the problem of functional correspondences in this paper. Given images of two objects, we ask a simple question: what is the set of correspondences between these two images for a given task?
For example, what are the correspondences between a bottle and shoe for the task of pounding or the task of pouring.
We introduce a new dataset: FunKPoint that has ground truth correspondences for 10 tasks and 20 object categories.
We also introduce a modular task-driven representation for attacking this problem and demonstrate that our learned representation is effective for this task. But most importantly, because our supervision signal is not bound by semantics, we show that our learned representation can generalize better on few-shot classiﬁcation problem. We hope this paper will inspire our community to think beyond semantics and focus more on cross-category generalization and learning representations for robotics tasks. 1.

Introduction
To perceive an affordance is not to classify an object.
The fact that a stone is a missile does not imply that it cannot be other things as well. It can be a paperweight, a bookend, a hammer, or a pendulum bob.
James J. Gibson
Computer vision and visual representation learning has been bound by shackles of semantic categories. Our train-ing data is built with semantic categories - ImageNet has
* Authors contributed equally
Figure 1: Given a pair of images, functional correspondence establish correspon-dence between points that are functionally the same. In this example, we hold the body of the bottle when pouring but the neck when pounding, therefore we can estab-lish correspondence (bottle body, shoe front) for pouring and correspondence (bottle neck, shoe front) for pounding. 1K categories of breeds of dogs, cats and mushrooms. Our supervision is semantic categories. And our evaluation tasks are semantic – image classiﬁcation, object detection, image segmentation and list goes on. So it is not surprising that our approaches are bound by the limits of semantic cate-gories. Our representations are not effective in capturing affordances for robotics tasks. And our representations fail to generalize effectively to new object categories due to focus on learning intra-class invariances. On the other hand, hu-mans have marvelous ability to think beyond categories. We can use a screwdriver for opening screws but also to clean printer, hammer nails and what-not. Clearly, our current semantically-driven computer vision needs rethinking.
In classical computer vision, semantics did not play such an important role. Instead, correspondence was cited as one of the most important tasks in the ﬁeld of computer vision. It is also the fundamental goal of visual representation learning – an embedding space where similar objects/parts/pixels have similar embedding. In an anecdotal conversation about the three most important problems in computer vision, Takeo
Kanade stated that they are “Correspondence, Correspon-dence, Correspondence". Yet, this fundamental task of visual correspondence is ambiguous and ill-deﬁned. What is visual correspondence? Does there exist correspondence between any pair of images? The visual correspondence problem is 1
most well-deﬁned and often studied in context of tracking and multi-view reconstruction where the goal is to create correspondences between two images of same object [55].
It has also been studied in the context of semantic categories where the goal is to create correspondences between images of object instances from same categories [29, 39]. But it of-ten stops at cat what are the right correspondences between two seemingly different object categories (for example, a bottle and a shoe)?
In contrast, we humans can identify correspondences be-tween semantically different objects. We unconsciously use this ability to transfer our object manipulation skills to novel objects in order to efﬁciently accomplish everyday tasks.
Speciﬁcally, humans possess three interesting capabilities: (a) the ability to visually infer affordances for objects, (b) the ability to generalize beyond semantic categories and (c) the ability to adapt affordances for different tasks. In order to facilitate exploration of these capabilities, we introduce the problem of functional correspondence. Given images of two objects, we ask a simple question: for a given task, what would be the set of correspondence between two objects?
For example, the correspondences between shoe and bottle for the task of pouring are shown in the ﬁgure 1. The grasp locations are shown by green, storage by orange and pouring spout by red keypoints. On the the other hand, the corre-spondences between shoe and bottle for the task of pounding (hitting with a force) are quite different and shown in ﬁgure 1.
Note that the correspondence between two objects is driven by both 3D shape and physical/material properties.
We also introduce a new dataset called FunKPoint (Sec-tion 3). FunKPoint has ground-truth keypoints labeled for 10 tasks across 20 object categories. We also propose a mod-ular task-driven architecture. More speciﬁcally, our modular architecture computes the image representation given an input task. We show our architecture is highly effective in modeling functional correspondences although there is still a signiﬁcant gap with respect to human performance.
But most importantly, in proof-of-concept experiments, we demonstrate the underlying promise of learning functional correspondence. Because our task has functional supervision and there is cross-category supervision, our representation can outperform semantically-learned representations for few-shot learning. 1.1. Why Functional Correspondence?
In this paper, we introduce the problem of functional correspondence. We believe this task forms the core of visual learning because of the following reasons: (a) Object Affordances and Functional Representa-tions: Ability to predict object affordances is a cornerstone of human intelligence and a key requirement for robotics tasks. The task of functional correspondence allows us to learn functional representations useful for robotics tasks. But more importantly, beyond predicting primary affordances (screwdriver is used for screwing), humans are really good at predicting secondary affordances (how we can use novel objects to fulﬁl the task – e.g. using screwdriver to clean paper jam in printer). Modeling functional correspondences across different object categories should help in predicting novel use of objects. (b) Generalization Beyond Semantic Categories: Un-like other vision tasks such as object classiﬁcation/detection or even learning 3D from image collections, this task cuts across object semantics. It attempts to model commonalities across different categories of object and hence open up the possibility of generalization beyond semantic categories. (c) Task-Driven Representation: Finally, the ground-truth is conditioned on the task itself, the correspondences between pair of objects depends on how you envision using these objects. This allows us to formulate a task-driven rep-resentation (unlike current existing task-agnostic ConvNet representations). 2.