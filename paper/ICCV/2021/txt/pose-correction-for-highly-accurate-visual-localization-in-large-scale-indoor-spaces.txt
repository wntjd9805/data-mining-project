Abstract
Indoor visual localization is significant for various ap-plications such as autonomous robots, augmented reality, and mixed reality. Recent advances in visual localization have demonstrated their feasibility in large-scale indoor spaces through coarse-to-fine methods that typically em-ploy three steps: image retrieval, pose estimation, and pose selection. However, further research is needed to improve the accuracy of large-scale indoor visual localization. We demonstrate that the limitations in the previous methods can be attributed to the sparsity of image positions in the database, which causes view-differences between a query and a retrieved image from the database. In this paper, to address this problem, we propose a novel module, named pose correction, that enables re-estimation of the pose with local feature matching in a similar view by reorganizing the local features. This module enhances the accuracy of the initially estimated pose and assigns more reliable ranks.
Furthermore, the proposed method achieves a new state-of-the-art performance with an accuracy of more than 90 % within 1.0 m in the challenging indoor benchmark dataset
InLoc for the first time. 1 1.

Introduction
Indoor visual localization is a common solution for in-door applications such as autonomous robots, augmented reality, and mixed reality [8, 19, 32, 35]. However, even though recent advances in visual localization have demon-strated remarkable performances in urban environments and small indoor spaces [4, 5, 6, 7, 22, 23, 28], long-term vi-sual localization in large-scale indoor spaces remains chal-lenging due to similar places, repetitive patterns, featureless scenes, occluded scenes, and highly dynamic features [54].
Recently, it was reported that visual localization can
*Equally contributed to this work. 1Code available at http://github.com/JanghunHyeon/PCLoc
Figure 1. The hierarchical model, including pose correction. The pose correction step updates the initially estimated pose X − to
X +. The main information used in each step is shown below the box. be successfully scaled-up in indoor spaces using InLoc
[54] and HFNet [42]. These works employ a hierarchi-cal (coarse-to-fine) structure in which the algorithm re-trieves several candidates using the lightest feature and sub-sequently estimates the poses of the selected few with more intensive features. The black boxes in Figure 1 describe the hierarchical model constituted by
- Image retrieval: retrieve many candidates with indirect features such as NetVLAD [1], GeM [37], AP-GeM
[38], and i-GeM [19].
- Pose estimation: estimate candidates’ pose with direct features such as SuperPoint [10] and D2Net [13].
- Pose selection: select the final pose with given 3D in-formation such as pose verification (PV) [54, 55] and covisibility clustering [42].
These frameworks are de facto standards because many successful studies have inherited these structures [13, 14, 17, 19, 40, 41, 43, 50, 51, 55]. However, we argue that there is further scope for improvement because the accuracy of re-cent state-of-the-art methods [14, 17, 43] is approximately 80 % within 1.0 m in large-scale indoor spaces [54], where it often reaches over 90 % in outdoor benchmark datasets
[3, 45, 47]. We determine that the sparsity of image posi-tions in the database is the reason for the performance gap
because it is difficult to construct the database densely in large-scale indoor spaces [54]. The sparsity causes view-difference between a query image and a retrieved image.
For example, when a query pose is far from the database image pose, the common view in both images tends to be small. Thus, the pose estimation module in existing meth-ods yields inaccurate output as the local features that appear in both the query and the database image are not sufficient for accurate estimation.
In this work, to circumvent the sparsity issue and im-prove the accuracy, we propose a novel module called “Pose
Correction,” as shown in the yellow box in Figure 1, which reorganizes local features that can be observed from the es-timated pose (X −). Note that this approach has an effect similar to that of estimating the query pose using an image located near the query pose. Figure 2(a) depicts an exam-ple where the query and database poses are far from each other. Owing to the view-difference, only a few features match between the query and database images, as shown in
Figure 2(b). However, if we reconstruct the local features that can be observed in X − and associate the two sets of features, more inliers appear, which circumvent the sparsity problem and resolve the view-difference problem as in Fig-ure 2(c). This yields an updated pose (X +) whose accuracy is superior to X −. From the given candidates, once all X + candidates have been re-estimated, it is natural to reset their ranks in the order of the reliability of the matching. We evaluate the reliability using the number of inliers between the query and X + and provide more reliable candidates to the pose selection module.
In addition, we propose an extended pose correction that utilizes the properties of the pose correction step and also reduces redundant features that might be used during the pose update. We also modify the PV proposed in [54] such that the accuracy can be enhanced as far as possible.
Experiments were conducted on the most well-known in-door benchmark dataset, InLoc [54]. We validated our pro-posed method by comparing it with existing state-of-the-art methods [13, 14, 17, 40, 42, 43, 54, 55]. Further, we eval-uated our method on an M-site dataset [19] to confirm the relevance of our results. Our proposed method performed significantly better and achieved state-of-the-art results for large-scale indoor visual localization. Moreover, we also conducted ablation studies to demonstrate the superiority of the extended pose correction and the effect of the iterating pose correction.
The contributions of this work are as follows. 1) To the best of our knowledge, it is the first work to address the problem of the view-difference due to the sparsity in the database and to propose a novel module, i.e., pose correc-tion, to resolve the problem. 2) We extend pose correction based on its natural properties and verify improvements in accuracy. 3) Additionally, we propose modified PV (MPV),
Figure 2. (a) Query and database poses are far from each other.
The visible local features in the query image are represented with a red x. (b) Owing to the sparsity that causes view-difference, there are few feature matches between the query and the database images. (c) Local feature matching with the query and the reorga-nized features that can be observed in X − yields a greater number of matches than the ones in (b) circumventing the sparsity prob-lem. Here, the background image at X − is rendered for visualiza-tion. LF denotes local feature. which improves the performance further. 4) As a result, the proposed method outperforms recent works by a no-table margin and achieves a new state-of-the-art in the pub-lic benchmark dataset. 2.