Abstract
We propose PR-RRN, a novel neural-network based method for Non-rigid Structure-from-Motion (NRSfM). PR-RRN consists of Residual-Recursive Networks (RRN) and two extra regularization losses. RRN is designed to effec-tively recover 3D shape and camera from 2D keypoints with novel residual-recursive structure. As NRSfM is a highly under-constrained problem, we propose two new pairwise regularization to further regularize the reconstruction. The
Rigidity-based Pairwise Contrastive Loss regularizes the shape representation by encouraging higher similarity be-tween the representations of high-rigidity pairs of frames than low-rigidity pairs. We propose minimum singular-value ratio to measure the pairwise rigidity. The Pairwise
Consistency Loss enforces the reconstruction to be consis-tent when the estimated shapes and cameras are exchanged between pairs. Our approach achieves state-of-the-art per-formance on CMU MOCAP and PASCAL3D+ dataset. 1.

Introduction
The reconstruction of 3D object shapes and camera mo-tions from 2D observations is an important problem in com-puter vision. When the object is rigid, this problem is de-fined as rigid Structure-from-Motion (SfM) and it can be solved reliably using existing methods like [40]. Non-Rigid
Structure-from-Motion (NRSfM) relaxes the assumption of a rigid object in SfM to a deforming one, leading to a more general and challenging problem.
NRSfM is known to be an under-constrained problem if the shape is allowed to deform arbitrarily in each observa-tion. To make this problem tractable, a standard assumption is that in each frame the 3D shape is a linear combination of a small number of basis shapes [4]. With this assump-tion, NRSfM is formulated as factorizing the stacked ob-*Corresponding author.
Figure 1. Illustration of pairwise losses. (a) Proposed pairwise contrastive regularization ‘pushes’ or ‘pulls’ the representations based on pairwise rigidity (similarity) of 2D shapes. (b) Consistent regularization forces the networks to produce consistent shape and camera estimation given new views of estimated shapes. servation matrix into three component matrices: cameras, coefficients and basis. Previous researches exploit various constraints to solve this factorization problem, involving orthogonal constraint on the camera matrix [11, 47], re-stricting the basis to 3D shapes [46]. Different from those constraints on cameras or basis, another important category of approaches applied constraints to the coefficient matrix, including smooth trajectories over time in original coeffi-cient matrix [15, 3] or in low-dimensional manifold [16], prior distributions [25, 41] and spatial smoothness [17]. In neural-network based models, the latent representation can be thought of as the ‘coefficients’, and Sidhu et al. [37] first apply latent space constraints for sequential dense recon-struction. These constraints reduce the indeterminacy of the
NRSfM task and potentially lead to better reconstruction.
However, regularizing the reconstruction is difficult when the data is large-scale and orderless. In such cases, assuming a representation manifold or using temporal smoothness is not possible. To tackle this, we propose to regularize the non-rigid shape reconstruction in a pairwise manner. Compared to a strong global assumption of shapes, pairwise information are much easier to obtain, therefore the regularization can be achieved effectively.
In this paper, we introduce Pairwise-Regularized Resi-dual-Recursive Networks (PR-RRN), a novel neural-network based model for NRSfM. PR-RRN consists of a
Residual-Recursive Network (RRN) and two novel losses:
Pairwise Contrastive Loss and Pairwise Consistency Loss.
RRN alone can reconstruct the non-rigid shapes accurately, and it is further improved by pairwise losses. RRN con-tains a shape estimation network and a rotation estima-tion network, and the shape estimation network is con-structed with a novel Residual-Recursive module, which is capable to enhance the reconstruction compared to a stan-dard convolution layer with the same number of param-eters. And the rotation estimation network is designed to estimate the camera matrix from the 2D input. Fur-thermore, two pairwise losses regularize the reconstruc-tion in two different aspects, as shown in Fig. 1. Inspired by recent advances in unsupervised representation learning
[18, 42, 39, 48, 36, 35], the proposed Pairwise Contrastive
Loss encourages higher similarity between the latent repre-sentations of high-rigidity pairs of inputs than low-rigidity pairs. The pairwise rigidity is obtained by a novel mea-surement minimal singular-value ratio. The Pairwise Con-sistency Loss enforces the reconstruction to be consistent when the estimated shapes and cameras are exchanged be-tween pairs and reprojected as new inputs. The experimen-tal results show that PR-RRN achieves state-of-the-art re-construction performance on large-scale human motion and categorical objects datasets.
Our contributions are summarized as following:
• We introduce a novel Residual-Recursive Network for non-rigid shapes reconstruction, which achieves state-of-the-art performance on CMU MOCAP Dataset.
• We propose Pairwise Contrastive Loss and Consis-tency Loss to further improve RNN. These two losses can regularize the reconstruction without assuming a global shape distribution.
• We design a novel pairwise rigidity measurement mini-mal singular-value ratio. It is easy to compute and can be used to test the rigidity of a pair of 2D observations. 2.