Abstract
In semantic segmentation tasks, input images can often have more than one plausible interpretation, thus allowing for multiple valid labels. To capture such ambiguities, re-cent work has explored the use of probabilistic networks that can learn a distribution over predictions. However, these do not necessarily represent the empirical distribution ac-curately. In this work, we present a strategy for learning a calibrated predictive distribution over semantic maps, where the probability associated with each prediction reﬂects its ground truth correctness likelihood. To this end, we propose a novel two-stage, cascaded approach for calibrated adver-sarial reﬁnement: (i) a standard segmentation network is trained with categorical cross entropy to predict a pixelwise probability distribution over semantic classes and (ii) an adversarially trained stochastic network is used to model the inter-pixel correlations to reﬁne the output of the ﬁrst network into coherent samples. Importantly, to calibrate the reﬁnement network and prevent mode collapse, the ex-pectation of the samples in the second stage is matched to the probabilities predicted in the ﬁrst. We demonstrate the versatility and robustness of the approach by achieving state-of-the-art results on the multigrader LIDC dataset and on a modiﬁed Cityscapes dataset with injected ambiguities. In addition, we show that the core design can be adapted to other tasks requiring learning a calibrated predictive dis-tribution by experimenting on a toy regression dataset. We provide an open source implementation of our method at https://github.com/EliasKassapis/CARSSS. 1.

Introduction
Real-world datasets are often riddled with ambiguities, allowing for multiple valid solutions for a given input. These can emanate from an array of sources, such as sensor noise, occlusions, inconsistencies during manual data annotation, or an ambiguous label space [38]. Despite the fact that the empirical distribution can be multimodal, the majority of the ambiguous data conventional segmentation pipeline input image argmax unconﬁdent prediction
F sampling
CAR p((cid:15))
G sample labels
Figure 1: Conceptual diagram of stochastic semantic seg-mentation: blue and red pixels are separable by several differ-ent vertical boundaries, resulting in multiple valid labels. F is a network parametrising a factorised categorical likelihood, which captures the pixelwise data ambiguity. Extracting the mode via the argmax operation deterministically yields a single coherent prediction, while direct sampling gives mul-tiple incoherent ones. Instead, calibrated adversarial reﬁne-ment (CAR) uses a second stochastic adversarial network, G, which reﬁnes the output of F into diverse, coherent labels. research encompassing semantic segmentation focuses on optimising models that assign only a single solution to each input image [47, 26, 53, 9, 10, 11, 7, 8], and are thus often incapable of capturing the entire empirical distribution.
These approaches typically model each pixel indepen-dently with a factorised categorical likelihood, and there-fore do not consider inter-pixel correlations during sampling (see Fig. 13b in Appendix B.3). Further, since maximising the likelihood on noisy datasets leads to unconﬁdent pre-dictions in regions of label inconsistencies, direct sampling yields incoherent semantic maps. Alternatively, coherent predictions can be obtained by applying the argmax func-tion, essentially extracting the mode of the likelihood. This, however, comes at the cost of limiting the model’s repre-sentation capabilities to deterministic, one-to-one mappings between inputs and outputs (see Fig. 1).
Here we consider the problem of stochastic semantic seg-mentation: the task of semantically segmenting ambiguous images with an arbitrary number of valid labels, each with a distinct probability of occurrence. To this end, an ideal model should capture joint pixel dependencies and leverage uncertainty information to sample multiple coherent hypothe-ses. Further, it is important that the empirical occurrence frequency of each sampled segmentation variant reﬂects its ground truth correctness likelihood; that is, the predictive distribution should be calibrated [17, 34]. Such a system would be especially useful for semi-automatic safety-critical applications, e. g. medical imaging and map making, where it is crucial to identify ambiguous input and cross-examine all possible interpretations and their corresponding likelihoods before making an important decision [1, 42, 39].
In this work, we introduce calibrated adversarial reﬁne-ment (CAR): a two-stage, cascaded framework for learning a calibrated, multimodal predictive distribution. In the ﬁrst stage, we train a standard network with categorical cross en-tropy to estimate pixelwise class probabilities, as well as the associated aleatoric uncertainty estimates [28]. In the second, an adversarial network, capable of modelling the inter-pixel dependencies, is used to sample realistic, coherent predic-tions (see bottom of Fig. 1). The sample diversity is then calibrated relatively to the distribution predicted in the ﬁrst stage, via an additional loss term. Our key contributions are:
•
•
•
We propose a novel cascaded architecture for adver-sarial reﬁnement that allows sampling of an arbitrary number of coherent segmentation maps.
We introduce a novel loss term, called the calibration loss, that facilitates learning of calibrated stochastic mappings and mitigates mode collapse in conditional adversarial learning.
Our model can be trained independently or used to augment any black-box semantic segmentation model. 2.