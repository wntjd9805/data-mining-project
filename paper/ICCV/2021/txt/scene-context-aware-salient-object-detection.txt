Abstract literature, they often fail
Salient object detection identifies objects in an image that grab visual attention. Although contextual features are considered in recent in real-world complex scenarios. We observe that this is mainly due to two issues: First, most existing datasets consist of simple foregrounds and backgrounds that hardly represent real-life scenarios.
Second, current methods only learn contextual features of salient objects, which are insufficient to model high-level semantics for saliency reasoning in complex scenes. To address these problems, we first construct a new large-scale dataset with complex scenes in this paper. We then propose a context-aware learning approach to explicitly exploit the semantic scene contexts. Specifically, two modules are proposed to achieve the goal: 1) a Semantic Scene Context Refinement mod-ule to enhance contextual features learned from salient objects with scene context, and 2) a Contextual Instance
Transformer to learn contextual relations between objects and scene context. To our knowledge, such high-level semantic contextual information of image scenes is under-explored for saliency detection in the literature. Extensive experiments demonstrate that the proposed approach techniques in complex sce-outperforms state-of-the-art narios for saliency detection, and transfers well to other existing datasets. The code and dataset are available at https://github.com/SirisAvishek/Scene_
Context_Aware_Saliency. 1.

Introduction
Salient object detection explores the problem of identi-fying objects that “pop-out” and grab visual attention in an image or video. The task has been widely used as a pre-processing step for many vision applications such as im-age/video compression [59, 11], video object segmentation
[50], image captioning [56], and image parsing [21]. All these vision tasks are proposed for real-world images with
Image
GT
CPD-R [54]
EGNet [68]
Ours
Figure 1: Examples of real-world complex scenarios where exist-ing methods (e.g. [54, 68]) may not capture semantic scene con-texts well, leading to incorrect detection of distractors. Whereas our model is able to capture semantic contexts of the scenes. complex scenes.
Recently, saliency research has grown rapidly through the success of CNNs, which are able to capture better feature representations compared to hand-crafted features
[32, 5, 57]. State-of-the-art saliency models mainly extract and aggregate contextual information from spatial relations, including multi-scale and local-global features in various manners [67, 30, 37]. Although good performance has been demonstrated, these models are mainly trained on binary saliency labels that are class-agnostic. Training on such la-bels only can limit the ability of networks to learn semantic contextual features (higher-level understanding) that would otherwise help model various relationship of objects within complex image scenes [29, 65]. Fig. 1 shows two exam-ples of real-world complex scenarios where existing models perform poorly. The top row shows a kitchen scene with a salient person and a distractor (e.g., fridge with similar tex-ture). Existing models can not capture the semantic knowl-edge of the distractor and are unable to differentiate it from the person’s attire, resulting in incorrect saliency for that distractor. It is a similar case for the bottom row which in-volves a bedroom scene with a salient person surrounded by many distractors (e.g., clothes and objects with similar tex-ture). The above observations motivate us to ask the ques-tion: Can we learn and use discriminative semantic con-text to improve saliency modeling in challenging complex scenes with rich context?
Further to our observations, we find that most of the ex-(a) ECSSD [57] (b) PASCAL-S [24] (c) HKU-IS [23] (d) DUT-OMRON [58] (e) DUTS [45] (f) CapSal [65] (g) Ours
Figure 2: Comparison between existing datasets and the proposed new challenging dataset. Existing popular salient object datasets (a – f) are not very challenging. In contrast, our proposed dataset (g) contains more complex scenes due to the increase in the number of objects in the foreground/background as well as non-salient distractors. isting salient object detection datasets [36, 4, 57, 24, 23, 58, 45] consist of images with few objects and simple back-grounds. Example images from these datasets are illustrated in Fig. 2(a-f). These images are relatively simple for salient object detection in the wild, where images are typically complex with lots of objects and complex backgrounds, as shown in Fig. 2(g).
Psychological studies suggest that semantic scene con-text influences eye movements and attention [43], revealing the relationship between salient objects and the surround-ing image scenes. To the best of our knowledge, saliency detection with high-level scene context and spatial context is under-explored, with only two related works [65, 29] ad-dressing a similar problem. Zhang et al. [65] propose to leverage captions as the semantic scene context for improv-ing salient object prediction. However, reliance on gener-ated captions can be detrimental to saliency prediction, es-pecially if they are incorrect. On the other hand, DSCLRCN
[29] derives their scene context features from an image-level scene classification model, whereas the extracted fea-tures are too abstract, containing only an overall representa-tion without capturing object relationships within the scene.
The above-mentioned limitations further motivate us to explore the use of semantic scene and spatial context for salient object detection in real-world scenarios with com-plex scenes. To this end, we first construct a novel dataset comprising of images with rich context (more details in
Sec. 3). We then propose a context-aware saliency model-ing framework to leverage semantic scene context features.
Specifically, we introduce Instance Context Segmentation and Stuff Context Segmentation to semantically segment
Things and Stuff. These two components perform panop-tic segmentation on the whole scene, providing detailed se-mantics of a given image. However, we find that not all the semantic information play an effective role in defining the semantic scene context of an image. As a result, we pro-pose a novel Semantic Scene Context Refinement (SSCR) module to fuse and augment information of salient object features with surrounding semantic scene context for im-proving saliency reasoning. To further exploit semantic scene context, we propose a Contextual Instance Trans-former (CIT) to capture the relationship between objects and the scene context.
In summary, our main contributions include:
• We propose a semantic scene context-aware frame-work for salient object detection, which explores the semantic relationship between salient objects and the scene context.
• We propose a Semantic Scene Context Refinement module to extract and enhance semantic scene con-text features that are highly related to the image scene.
We further propose a new Contextual Instance Trans-former to learn the contextual relations between ob-jects and scene context for saliency reasoning.
• We build (and will make available) a new salient ob-ject detection dataset with real-world complex scenes to consider semantic scene contexts.
• Extensive experiments demonstrate that the proposed approach outperforms the state-of-the-art methods on our dataset and also generalizes well to existing datasets. 2.