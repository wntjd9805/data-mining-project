Abstract training procedures [85, 36].
Continually learning in the real world must overcome many challenges, among which noisy labels are a common
In this work, we present a replay-and inevitable issue. based continual learning framework that simultaneously addresses both catastrophic forgetting and noisy labels for the first time. Our solution is based on two observations; (i) forgetting can be mitigated even with noisy labels via self-supervised learning, and (ii) the purity of the replay buffer is crucial. Building on this regard, we propose two key compo-nents of our method: (i) a self-supervised replay technique named Self-Replay which can circumvent erroneous train-ing signals arising from noisy labeled data, and (ii) the Self-Centered filter that maintains a purified replay buffer via centrality-based stochastic graph ensembles. The empirical results on MNIST, CIFAR-10, CIFAR-100, and WebVision with real-world noise demonstrate that our framework can maintain a highly pure replay buffer amidst noisy streamed data while greatly outperforming the combinations of the state-of-the-art continual learning and noisy label learning methods. 1.

Introduction
The most natural form of input for an intelligent agent occurs sequentially. Hence, the ability to continually learn from sequential data has gained much attention in recent machine learning research. This problem is often coined as continual learning, for which three representative ap-proaches have been proposed [57, 67, 20] including re-play [52, 29, 66, 73, 70, 44], regularization [38, 91, 3], and expansion techniques [71, 89].
At the same time, learning from data riddled with noisy labels is an inevitable scenario that an intelligent agent must overcome. There have been multiple lines of work to learn amidst noisy labels such as loss regularization [84, 96, 31], data re-weighting [68, 72], label cleaning [64, 42, 61], and
∗Equal Contribution
In this work, we aim to jointly tackle the problems of continual learning and noisy label classification, which to the best of our knowledge have not been studied in prior work. Noisy labels and continual learning are inevitable for real-world machine learning, as data comes in a stream possibly polluted with label inconsistency. Hence, the two are bound to intersect; we believe exploring this intersection may glean evidence for promising research directions and hopefully shed light on the development of sustainable real-world machine learning algorithms.
We take on the replay-based approach to tackle continual learning since it has often shown superior results in terms of performance and memory efficiency even with simplic-ity. Yet, we discover that replaying a noisy buffer inten-sifies the forgetting process due to the fallacious mapping of previously attained knowledge. Moreover, existing noisy label learning approaches show great limitations when cop-ing within the online task-free setting [2, 65, 43, 37].
In their original forms, they assume that the whole dataset is given to purify the noise and thus are hampered by a small amount of data stored only in the replay buffer to either reg-ularize, re-weight, or decide on its validity.
We begin by backtracking the root of the problem; if we naively store a sampled set of the noisy input stream into the replay buffer, it becomes riddled with noise, worsen-ing the amount of forgetting. Thus, we discover the key to success is maintaining a pure replay buffer, which is the ma-jor motive of our novel framework named Self-Purified Re-play (SPR). At the heart of our framework is self-supervised learning [16, 12, 30, 24], which allows to circumvent the er-roneous training signals arising from the incorrect pairs of data and labels. Within the framework, we present our novel
Self-Replay and Self-Centered filter that collectively cleanse noisy labeled data and continually learn from them. The
Self-Replay mitigates the noise intensified catastrophic for-getting, and the Self-Centered filter achieves a highly clean replay buffer even when restricted to a small portion of data at a time.
We outline the contributions of this work as follows.
1. To the best of our knowledge, this is the first work to tackle noisy labeled continual learning. We discover noisy labels exacerbate catastrophic forgetting, and it is critical to filter out such noise from the input data stream before storing them in the replay buffer. 2. We introduce a novel replay-based framework named
Self-Purified Replay (SPR), for noisy labeled contin-ual learning. SPR can not only maintain a clean replay buffer but also effectively mitigate catastrophic forget-ting with a fixed parameter size. 3. We evaluate our approach on three synthetic noise benchmarks of MNIST [41], CIFAR-10 [40], CIFAR-100 [40] and one real noise dataset of WebVision [49].
Empirical results validate that SPR significantly out-performs many combinations of the state-of-the-art continual learning and noisy label learning methods. 2. Problem Statement 2.1. Noisy Labeled Continual Learning
We consider the problem of online task-free continual learning for classification where a sample {xt, yt} enters at each time step t in a non i.i.d manner without task labels.
While previous works [66, 65, 43] assume {xt, yt} are cor-rect (clean) samples, we allow the chance that a large por-tion of the data is falsely labeled. 2.2. Motivation: Noise induced Amnesia
We discover that if the data stream has noisy labels, it traumatically damages the continual learning model, analo-gous to retrograde amnesia [75], the inability to recall ex-perience of the past. We perform some preliminary exper-iments on a sequential version of symmetric noisy MNIST and CIFAR-10 [53, 84] using experience replay with the conventional reservoir sampling technique [69, 94].
The empirical results in Figure 1 show that when trained with noisy labels, the model becomes much more prone to catastrophic forgetting [20, 57, 78, 67]. As the noise level increases from 0% to 60%, sharp decreases in accuracy are seen. Surprisingly, the dotted red circle in Figure 1(b) shows that in CIFAR-10 a fatally hastened forgetting occurs no matter the amount of noise.
We speculate that a critical issue that hinders the contin-ual model is the corrupted replay buffer. An ideal replay buffer should shield the model from noisy labels altogether by being vigilant of all the incoming data for the mainte-nance of a clean buffer. 3. Approach to Noisy Labeled Continual
Learning
We design an approach to continual learning with noisy labels by realizing the two interrelated subgoals as follows.
Figure 1. A noisy labeled continual learning on the symmetric noisy in (a) MNIST [41] and (b) CIFAR-10 [40] when using expe-rience replay with the conventional reservoir sampling [94, 69]. At the end of each task, the accuracy of the first task (T1) is plotted.
It shows that the noisy labels accelerate catastrophic forgetting.
Notably, the dotted red circle in (b) indicates the significantly has-tened forgetting process.
G1. Reduce forgetting even with noisy labels: The ap-proach needs to mitigate catastrophic forgetting amidst learning from noisy labeled data.
G2. Filter clean data: The method should learn represen-tations such that it identifies the noise as anomalies.
Moreover, it should enable this from a small amount of data since we do not have access to the entire dataset in online continual learning.
Figure 2 overviews the proposed framework consisting of two buffers and two networks. The delayed buffer D temporarily stocks the incoming data stream, and the pu-rified buffer P maintains the cleansed data. The base net-work addresses G1 via self-supervised replay (Self-Replay) training (Section 3.1). The expert network is a key com-ponent of Self-Centered filter that tackles G2 by obtaining confidently clean samples via centrality (Section 3.2). Both networks have the same architecture (e.g., ResNet-18) with separate parameters.
Algorithm 1 outlines the training and filtering procedure.
Whenever the delayed buffer D is full, The Self-Centered filter powered by the expert network filters the clean sam-ples from D to the purified buffer P. Then, the base network is trained via the self-supervision loss with the samples in
D ∪ P. The detail will be discussed in Section 3.1–3.2.
At any stage of learning, we can perform downstream tasks (i.e., classification) by duplicating the base network into the inference network, adding a final softmax layer, and finetuning it using the samples in P. Algorithm 2 outlines this inference phase.
Algorithm 1 Training and filtering phase of SPR
Input: Training data (xt, yt), ..., (xT , yT ) and initial pa-rameters of base network θ.
D = P = {} // Initialize delayed and purified buffer for t = 1 to T do if D is full then
P ← P ∪ Self-Centered Filter(D) (section 3.2)
θ ← Self-Replay using D ∪ P (section 3.1) reset D else update D with (xt, yt) end if end for
Algorithm 2 Test phase of SPR
Input: Test data (xt, yt), ..., (xT , yT ), parameters of the base network θ, and purified buffer P
ψ = copy(θ) // Duplicate base model to inference model
ψ ← supervised finetune using P for t = 1 to T do downstream classification for (xt, yt) using ψ end for to as the negatives. The updated objective becomes
Lself = − 2(Bd+Bp) (cid:88) log i=1 euT (cid:80)2(Bd+Bp) k=1 i uj /τ 1k̸=ieuT i uk/τ
. (1)
We denote (xi, xj) as the positives and xk as the negatives. ui = g(xi) is the ℓ2 normalized feature, and τ > 0 is the
||g(xi)||2 temperature. Every time when the delayed buffer is full, we train the base network with this loss.
Empirical supports. Figure 3 shows some empirical re-sults about the validity of Self-Replay for noisy labeled con-tinual learning.
• Figure 3(a) shows a quantitative examination on down-stream classification tasks. indicates that self-supervised learning leads to a better representation, and eventually outperforms the supervised one by no-ticeable margins.
It
• Figure 3(b) exemplifies the superiority of Self-Replay in continual learning. We contrast the performances of continually trained Self-Replay (as proposed) against intermittently trained Self-Replay, which trains offline with only the samples in the purified buffer at the end of each task. The colored areas in Figure 3(b) indicate how much the continually learned representations alle-viate the forgetting and benefit the knowledge transfers among the past and future tasks.
Figure 2. Illustration of the Self-Purified Replay (SPR) framework.
We specify the training and filtering phase (in the yellow shade) in
Algorithm 1, and the test phase (in the purple shade) in Algor-tihm 2. 3.1. Self-Replay
Learning with noisy labeled data [64, 5, 54, 28] results in erroneous backpropagating signals when falsely paired x and y exist in the training set. Hence, we circumvent this error via learning only from x (without y) using contrastive self-supervised learning techniques [7, 12, 30, 24]. That is, the framework first focuses on learning general repre-sentations via self-supervised learning from all incoming x.
Subsequently, the downstream task (i.e., supervised classi-fication) finetunes the representation using only the samples in the purified buffer P. Building on this concept in terms of continual learning leads to Self-Replay, which mitigates forgetting while learning general representations via self-supervised replay of the samples in the delayed and purified buffer (D ∪ P).
Specifically, we add a projection head g(·) (i.e., a one-layer MLP) on top of the average pooling layer of the base network, and train it using the normalized temperature-scaled cross-entropy loss [12]. For a minibatch from D and
P with a batch size of Bd, Bp ∈ N respectively, we apply random image transformations (e.g., cropping, color jitter, horizontal flip) to create two correlated views of each sam-ple, referred to as positives. Then, the loss is optimized to attract the features of the positives closer to each other while repelling them from the other samples in the batch, referred
where N (v) is the neighboring set of v, λ is a constant and av,u is the truncated similarity value within (0, 1]. Eq. 2 can be rewritten in vector notation as Ac = λc, where c is a vectorized centrality over V . The principal eigenvector c can be computed by the power method [82], and it corre-sponds to the eigenvector centrality for the vertices in V .
Beta Mixture Models. The centrality quantifies which samples are the most influential (or the cleanest) within the data of identical class labels. However, the identically la-beled data contains both clean and noisy labeled samples, in which the noisy ones may deceptively manipulate the cen-trality score, leading to an indistinct division of the clean and noisy samples’ centrality scores. Hence, we compute the probability of cleanliness per sample via fitting a Beta mixture model (BMM) [33] to the centrality scores as p(c) =
Z (cid:88) z=1
πzp(c|z), (3) where c > 0 is the centrality score, πz is the mixing co-efficients, and Z ∈ N is the number of components. Beta distribution for p(c|z) is a suitable choice due to the skewed nature of the centrality scores. We set Z = 2, indicating the clean and noisy components, and it is empirically the best in terms of accuracy and computation cost. We use the EM algorithm [15] to fit the BMM through which we obtain the posterior probability p(z|c) =
πzp(c|αz, βz) j=1 πjp(c|αj, βj) (cid:80)Z
, (4) where αz, βz > 0 are the latent distribution parameters.
Please refer to the appendix for details of computing p(z|c).
Among the Z = 2 components, we can easily iden-tify the clean component as the one that has the higher c scores (i.e., a larger cluster). Then, the clean posterior p(z = clean|c) defines the probability that centrality c be-longs to the clean component, which is used as the proba-bility to enter and exit the purified buffer, P. After the se-lected samples enters our full purified buffer, the examples with the lowest p(z = clean|c) are sampled out accordingly. 3.2.1 Stochastic Ensemble
Since our goal is to obtain the most clean samples as pos-sible, we want to further sort out the possibly noisy sam-ples. We achieve this by introducing a stochastic ensemble of BMMs, enabling a more noise robust posterior than the non-stochastic posterior p(z = clean|c) in the previous sec-tion.
First, we prepare for stochastic ensembling by sampling multiple binary adjacency matrices {A} from a Bernoulli
Figure 3. Empirical support for Self-Replay with ResNet18 as (a) Comparison of overall ac-the base network on CIFAR-10. curacy of the finetuned downstream classification between self-supervised and supervised representations trained on various noise rates. The self-supervised indicates that the base network trained using only x as proposed, while the supervised means training with possibly noisy (x, y) pairs. (b) The benefits of continual Self-Replay over the intermittent Self-Replay by comparing the test set accuracy of finetuned models. The intermittent Self-Replay means training only with contents of the purified buffer up to and includ-ing the current task. 3.2. Self-Centered Filter
The goal of the Self-Centered filter is to obtain confi-dently clean samples; specifically, it assigns the probability of being clean to all the samples in the delayed buffer.
Expert Network. The expert network is prepared to fea-turize the samples in the delayed buffer. These features are used to compute the centrality of the samples, which is the yardstick of selecting clean samples. Inspired by the success of self-supervised learning good representations in
Self-Replay, the expert network is also trained with the self-supervision loss in Eq. 1 with only difference that we use the samples in D only (instead of D ∪ P for the base network).
Centrality. At the core of the Self-Centered filter lies centrality [59], which is rooted in graph theory to identify the most influential vertices within a graph. We use a variant of the eigenvector centrality [6], which is grounded on the concept that a link to a highly influential vertex contributes to centrality more than a link to a lesser influential vertex.
First, weighted undirected graphs G := (V, E) are con-structed per unique class label in the delayed buffer. We assume that the clean samples form the largest clusters in the graph of each class. Each vertex v ∈ V is a sample of the class, and the edge e ∈ E is weighted by the cosine sim-ilarity between the features from the expert network. For the adjacency matrix A = (av,u)|V |×|V |. Then the eigenvector centrality is formulated as cv = 1
λ (cid:88) cu = u∈N (v) 1
λ (cid:88) u∈V av,ucu, (2)
Figure 4. Illustration of graph manipulation via Stochastic Ensem-ble, which severs weak and uncommon connections and proba-bilistically focus on confident and clean data within the graph. distribution over A. For each class l, we impose a condi-tional Bernoulli distribution over A as p(A|Dl) = (cid:89) (cid:18)
Bern
Aij|ReLU di,dj ∈Dl (cid:18) di · dj (cid:19)(cid:19)
||di||||dj||
, (5) where Dl is the set of penultimate feature of class l from the expert network. We find that it is empirically helpful to truncate the dissimilar values to 0 (ReLU) and use the co-sine similarity value as the probability. We replace the zeros in A with a small positive value to satisfy the requirement of Perron-Frobenius theorem1. Then, our reformulated ro-bust posterior probability is p(z|Dl) ∝ (cid:90)
A p(z|cent(A))dp(A|Dl), (6) where cent(·) is the centrality scores from Eq. 2, and p(z|cent(A)) can be obtained in the same manner as the non-stochastic posterior in the previous section. We ap-proximate the integral using Monte Carlo sampling for which we use Emax as the sample size. Essentially, we fit the mixture models on different stochastic graphs to prob-abilistically carve out more confidently noisy samples by retaining the strong and dense connections while severing weak or uncommon connections. This is conceptually illus-trated in Figure 4.
Empirical Supports. Figure 5 shows some empirical evidence where the stochastic ensemble addresses the two issues to achieve a noise robust posterior p(z|Dl).
• First, a small portion of noisy samples are falsely con-fident and are consequently assigned a high central-ity score. Stochastic ensembling is able to suppress 1 Perron-Frobenius theorem states when A has positive entries, it has a unique largest real eigenvalue, whose corresponding eigenvector have strictly positive components.
Figure 5. Comparison of non-stochastic and Stochastic Ensem-ble on CIFAR-10 with 40% noise. Stochastic Ensemble produces more confidently clean samples by shifting p(c|z = noisy)·p(z = noisy) to the left, and suppressing the cases where p(c|z = noisy) · p(z = noisy) dips below p(c|z = clean) · p(z = clean). these noisy samples, as indicated in Figure 5, where the mode of p(c|z = noisy) · p(z = noisy) (red curve) is shifted to the left by a noticeable margin.
• Second, there are some cases where p(c|z = noisy) · p(z = noisy) drops below the p(c|z = clean) · p(z = clean) leading to a high p(z = clean|c) for the noisy instances, indicated with red circles in Figure 5. The stochastic ensemble of differing As can mitigate such problematic cases to drown out the unexpected noise. 4.