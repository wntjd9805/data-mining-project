Abstract
In this work, we propose an adversarial unsupervised do-main adaptation (UDA) method under inherent conditional and label shifts, in which we aim to align the distributions w.r.t. both p(x|y) and p(y). Since labels are inaccessible in a target domain, conventional adversarial UDA methods assume that p(y) is invariant across domains and rely on aligning p(x) as an alternative to the p(x|y) alignment. To address this, we provide a thorough theoretical and empiri-cal analysis of the conventional adversarial UDA methods under both conditional and label shifts, and propose a novel and practical alternative optimization scheme for adversar-ial UDA. Specifically, we infer the marginal p(y) and align p(x|y) iteratively at the training stage, and precisely align the posterior p(y|x) at the testing stage. Our experimental results demonstrate its effectiveness on both classification and segmentation UDA and partial UDA. 1.

Introduction
Deep learning methods are highly reliant on the large volume of labeled training datasets and the independent and identically distributed (i.i.d.) assumption of the training and testing data [6, 28]. The real world implementation scenarios, however, can be significantly diverse, and it can be costly to label datasets in every target environment [31]. To address this, unsupervised domain adaptation (UDA) can be used to transfer knowledge learned from a labeled source domain to different unlabeled target domains [13, 34, 33].
One of the predominant streams in UDA makes use of
Figure 1. Plots of the UDA performance with different levels of label shift using KL(ps(y), pt(y)) as a metric. Our CLS is more robust to label shift than conventional adversarial training (TDDA), maximum discrepancy (MCD), dropout (ADR), and self-training (CBST). the adversarial training [12, 32, 27, 30], which hinges on a discriminator to enforce ps(f (x)) = pt(f (x)), where f (·) is a feature extractor. It results in a domain invariant representa-tion under the covariate shif t assumption [39]. However, the covariate shif t assumption is not realistic in lieu of conditional shif t w.r.t. p(x|y), since each class may have its own appearance shift protocol. For example, a street lamp is sparkly in the night, while a pedestrian is shrouded in darkness.
Essentially, we would expect the fine-grained class-wise alignment w.r.t. p(x|y), while p(y) in a target domain is inaccessible in UDA. Assuming that there is no con-cept shift (i.e., ps(y|f (x)) = pt(y|f (x))) and label shift (i.e., ps(y) = pt(y))), and given the Bayes’ theorem, p(f (x)|y) = p(y|f (x))p(f (x))
, adversarial UDA can align p(f (x)|y) if ps(f (x)) = pt(f (x)). The label shift, i.e., dif-p(y) 1
Then, we can estimate pt(y), assuming that ps(x|y) and pt(x|y) are aligned using feature-level mean match-ing, which is incorporated into an alternative optimization framework. The precise target label distribution and a decent classifier are expected after sufficient round-based iterations.
At last, we use these two parts to align the posterior pt(y|x), i.e., target classifier.
Our contributions are summarized as follows:
• We explore both the conditional and label shifts in adver-sarial UDA, and give a thorough theoretical and empirical analysis of the conventional UDA methods under this as-sumption.
• An alternative optimization scheme is proposed to align the conditional and label distributions at the training stage, following the infer, align, and iterate scheme. Finally, we align the posterior pt(y|x) at the testing stage.
• We propose a practical and scalable method to align the conditional shift with the class-level balancing parameter.
We extensively evaluate our method on both popular UDA classification and semantic segmentation benchmarks. It can be naturally generalized to partial UDA. 2.