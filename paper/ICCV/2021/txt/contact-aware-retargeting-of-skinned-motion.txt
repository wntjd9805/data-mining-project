Abstract
This paper introduces a motion retargeting method that preserves self-contacts and prevents interpenetration. Self-contacts, such as when hands touch each other or the torso or the head, are important attributes of human body lan-guage and dynamics, yet existing methods do not model or preserve these contacts. Likewise, interpenetration, such as a hand passing into the torso, are a typical artifact of mo-tion estimation methods. The input to our method is a hu-man motion sequence and a target skeleton and character geometry. The method identifies self-contacts and ground contacts in the input motion, and optimizes the motion to apply to the output skeleton, while preserving these con-tacts and reducing interpenetration. We introduce a novel geometry-conditioned recurrent network with an encoder-space optimization strategy that achieves efficient retarget-ing while satisfying contact constraints. In experiments, our results quantitatively outperform previous methods and we conduct a user study where our retargeted motions are rated as higher-quality than those produced by recent works. We also show our method generalizes to motion estimated from human videos where we improve over previous works that produce noticeable interpenetration. 1.

Introduction
Self-contact, where one part of a person’s body comes into contact with another part, is crucial to how we perceive human motion. Self-contact often indicates different behav-iors or emotional states. For example, people might rest their head in their hands if they are concerned or thought-ful, whereas certain dance moves require one’s hands to be placed on one’s hips. Conversely, implausible self-contacts, such as hands passing through each other, ruin the physi-cal plausibility of a motion. Hence, handling self-contact is crucial for reconstructing, interpreting, and synthesizing human motion. Note that synthesizing contact for a skinned character requires knowledge of the character’s 3D geome-try; it cannot be accurately determined from skeleton alone.
This paper introduces a motion retargeting algorithm that preserves both self-contact and ground contact, while also reducing interpenetration. Our retargeting algorithm takes an input human motion and a target character, and produces a plausible animation that manifests how that target charac-ter might perform the input motion. Our method first iden-tifies self-contact and foot contacts in the input motion. We use an energy function that preserves these contacts in the output motion, while reducing interpenetration in the out-put. We reason about self-contacts from the character’s ge-ometry and foot contacts from the character skeleton, in or-der to guarantee that contacts will be accurately transferred in the skinned and rendered motion. Our approach gener-alizes to any mesh geometry and topology regardless of the number of vertices in the mesh.
Due to the difficultly of directly optimizing a full mo-tion sequence, we build on previous work and train a Re-current Neural Network (RNN) to perform retargeting. We find that an RNN does not perfectly satisfies contact con-straints given its efficient inference. Therefore, we propose encoder-space optimization, in which we refine the RNN’s predictions by iteratively optimizing the hidden units of
RNN’s encoder. This process allows our method to ef-ficiently satisfy constraints, by taking advantage of the
RNN’s smooth, disentangled encoder-space.
Since hands often participate in meaningful self-contacts (e.g., contacts from hands to head, hands to hand, hands to hip), we focus our analysis on contacts between the hands and the rest of the character geometry. Note that our use of geometry means that the output style will depend on char-acter mesh: a bulkier character is more constrained in their movements, which is reflected in our results. We evaluate our method on various complex motion sequences as well as a wide range of character geometries from skinny to bulky.
We show that our method provides a good balance between preserving input motion properties while preserving self-contacts and reducing implausible interpenetration. In our qualitative and quantitative experiments, we outperform the state-of-the-art learning-based motion retargeting methods.
In addition, we qualitatively show our method generalizes to real scenarios by retargeting motion extracted from hu-man videos. Our method improves upon methods that only consider the skeleton when estimating the motion. 2.