Abstract
Many super-resolution (SR) models are optimized for high performance only and therefore lack efﬁciency due to large model complexity. As large models are often not prac-tical in real-world applications, we investigate and pro-pose novel loss functions, to enable SR with high percep-tual quality from much more efﬁcient models. The represen-tative power for a given low-complexity generator network can only be fully leveraged by strong guidance towards the optimal set of parameters. We show that it is possible to improve the performance of a recently introduced efﬁcient generator architecture solely with the application of our
In particular, we use a Fourier proposed loss functions. space supervision loss for improved restoration of missing high-frequency (HF) content from the ground truth image and design a discriminator architecture working directly in the Fourier domain to better match the target HF distribu-tion. We show that our losses’ direct emphasis on the fre-quencies in Fourier-space signiﬁcantly boosts the percep-tual image quality, while at the same time retaining high restoration quality in comparison to previously proposed loss functions for this task. The performance is further im-proved by utilizing a combination of spatial and frequency domain losses, as both representations provide complemen-tary information during training. On top of that, the trained generator achieves comparable results with and is 2.4× and 48× faster than state-of-the-art perceptual SR methods
RankSRGAN and SRFlow respectively. 1.

Introduction
Super-resolution (SR) deals with the problem of recon-structing the high-frequency (HF) information from a low-resolution (LR) image x ∈ RH×W ×C, which are inher-ently lost after downsampling the high-resolution (HR) im-age y ∈ RrH×rW ×C due to the lower Nyquist frequency in the LR space (r denotes the scaling factor). Recent sin-gle image SR (SISR) methods [4, 17, 22, 19, 10, 14] have shown remarkable success at reconstructing the missing HF details, with emphasis on accurate restoration of the fre-Figure 1. Runtime [ms] vs. perceptual quality (LPIPS) [36] com-parison with state-of-the-art methods on DIV2K validation set.
The disk area is proportional to the number of parameters. We achieve the fastest runtimes with comparable perceptual quality to much larger networks. quency content in the ground truth frames. This is typically performed with supervised training, where the ground truth images y are downsampled with a known kernel, e.g. bicu-bic, to obtain the LR input images x.
While it may be desirable in some applications to re-store the frequencies as close to the target as possible with minimal assumptions, the ill-posed problem limits the SR networks to generate higher frequency components, as the training promotes conservative estimates imposed by the pixel-wise supervision losses. This usually results in blurry images, which appear to be of lower quality than their re-spective HR counterparts.
This issue has been addressed in the literature [20, 32] by employing different losses, that are designed to promote the higher frequencies for perceptually more pleasing im-ages. These supervised objectives are often used in com-bination with generative adversarial networks [8] (GAN) for additional distribution learning of the HF space. Condi-tional GAN-based learning enables the generation of plau-sible high frequencies without the need for strict ground truth accuracy. A lot of research has been devoted to design such perceptual losses and to ﬁnd suitable combinations for pleasing results.
Recently, more and more deep learning based algo-rithms are implemented on smartphones, which requires low-complexity networks for fast inference and inexpen-sive deployment. Therefore, the design focus is slowly shifting from high-quality, high-performance methods with high-complexity networks to more efﬁcient enhancers, which upscale faster and require less resources.
In con-trast to empowering a deep neural network’s performance by simply increasing its complexity, which is generally straight-forward, ﬁnding an efﬁcient network with high-performance is a much harder challenge. Searching for effective low-complexity networks with high performance, that are on par with state-of-the-art methods, is the ultimate challenge in network design.
Three main ingredients are necessary in order to maxi-mize performance and efﬁciency of deep neural networks.
First, the best architecture design for the task has to be de-termined. Usually, this task is performed manually by ex-perts. In addition to handcrafted designs, neural architec-ture search algorithms [7, 6, 21] have recently been pro-posed to automate this task. Second, the design of the opti-mal loss function is imperative to fully leverage a network’s performance. Third, the amount and quality of data plays a key role to maximize performance. A large portion of ex-isting literature in SR deals with the ﬁrst point. We regard the solution to the third point as straight-forward, as data can be collected efﬁciently for most applications.
In this paper we propose a solution to the second point and try to maximize the performance of a recently proposed efﬁcient low-complexity network [14, 35] for perceptual SR, solely by the application of our proposed loss functions.
The design of perceptual losses predominantly focuses on the spatial domain [32, 20]. However, SR is tightly coupled to the frequency domain, as only high frequencies are removed during the downsampling process. We lever-age this fact and propose novel loss functions in Fourier space by calculating the frequency components with the fast Fourier transform (FFT) for direct emphasis on the fre-quency content. We propose a supervision loss in direct reference to the ground truth directly in Fourier domain for reconstruction. Additionally, we propose a discriminator architecture to learn the HF distribution in an adversarial training setup, working directly in Fourier space. To the best of our knowledge we are the ﬁrst to apply a GAN loss directly on Fourier coefﬁcients in SR. Our ablation study shows clear beneﬁts over spatial losses for the task of per-ceptual SR. Also, employing a loss in Fourier space intro-duces global guidance as opposed to pixel-wise evaluation due to the nature of the Fourier transform. In order to lever-age both global and local guidance, we also add the cor-responding spatial supervision and GAN losses. Together with an additional perceptual loss (VGG [30]), this outper-forms all other conﬁgurations in our ablation study. In ad-dition to the advantage of our proposed losses over existing ones, we compare our trained efﬁcient generator with high-performance state-of-the-art methods.
It shows, that our losses can substantially increase the performance of a low-complexity generator to even compete with much larger net-works. 2.