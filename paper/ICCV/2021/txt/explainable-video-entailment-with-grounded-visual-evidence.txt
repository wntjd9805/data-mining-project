Abstract
Video entailment aims at determining if a hypothesis textual statement is entailed or contradicted by a premise video. The main challenge of video entailment is that it requires ﬁne-grained reasoning to understand the complex and long story-based videos. To this end, we propose to incorporate visual grounding to the entailment by explic-itly linking the entities described in the statement to the evidence in the video.
If the entities are grounded in the video, we enhance the entailment judgment by focusing on the frames where the entities occur. Besides, in the en-tailment dataset, the entailed/contradictory (also named as real/fake) statements are formed in pairs with subtle dis-crepancy, which allows an add-on explanation module to predict which words or phrases make the statement contra-dictory to the video and regularize the training of the entail-ment judgment. Experimental results demonstrate that our approach outperforms the state-of-the-art methods. 1.

Introduction
Bridging the gap between computer vision and natural language processing is a rapid growing research area in var-ious tasks including visual captioning [40, 34], VQA [20, 1, 33], and visual-textual retrieval [22, 23]. Liu et al. [25] introduced a new video entailment problem to infer the se-mantic entailment between a premise video and a textual hypothesis. As shown in Fig. 1, video entailment [25] task aims at determining whether a textual statement is entailed or contradicted by a video. In Fig. 1, the label for the ﬁrst statement with the premise is entailment because the state-ment can be concluded from the dialog of the ﬁrst clip in which “the woman wearing jeans” appears. On the con-trary, the second statement is labeled as contradiction, be-cause the premise does not have evidence to conclude the statement. In this paper, we aim to address the video entail-ment with a faithful explanation.
The main challenge of video entailment is that it re-Figure 1. Video entailment aims at judging if a statement is en-tailed or contradicted by a video and its aligned textual dialog. A pair of real and fake statements have the similar structure and sut-ble difference (marked by the red dot line). We incorporate visual grounding into the entailment judgment. The entity grounding, e.g., “A woman wearing jeans” guides the entailment judgment module to focus on the entity-relevant frames and the correspond-ing sentences in the dialog (marked by blue in the temporal axis) to make a correct judgment. Best viewed in color. quires ﬁne-grained reasoning to understand the complex story-based videos and then make a correct judgment. The story-based videos are also accompanied by the textual dia-log (subtitles) (see Fig. 1). In the existing method for video entailment [25], video frames are less exploited than dia-log, because it lacks of a ﬁne-grained understanding of the video and the model does not know which frames in the long video are related to the statement. However, the enti-ties in the textual statement are usually people with their at-tributes, e.g., “A woman wearing jeans” (see Fig. 1), which should be implied in the video frames instead of the dialog.
To this end, we propose to enhance the entailment judg-ment by introducing a visual grounding model that links the entity described in a statement to the evidence in the video.
This is motivated by the fact that the statement is usually only related to a small subset of the long and untrimmed video. Based on this, a visual grounding module for the en-tities described in the statement is developed to localize the clips where the entity appears and guide the judgment to fo-cus on the entity’s occurring clips as well as the aligned sen-tences in the dialog. For example, the statements in Fig. 1 are linked to the ﬁrst and fourth clips and sentences, consid-ering the entity ”The woman wearing jeans”. By highlight-ing the relevant clips and sentences, the details can be better understood compared to [25] that does not have grounding guidance and equally considers all of the frames.
Therefore, we resort
Visual grounding has been attempted in many video+language tasks, such as image captioning [38] and VQA [21]. However, it cannot be directly generalized to the entailment task, because the bounding box anno-tations of grounding are not provided in the entailment dataset. to the existing weakly-supervised object grounding methods [15, 5] to address the training of the grounding module. But these methods are limited to explicit natural objects (e.g., “apple”, “river”).
Our grounding is more demanding, as we target at the described entities with ﬁne-grained attributes, such as hair, clothes and gender, to be grounded to the challenging story-telling videos.
Furthermore, we aim at improving the faithfulness of the entailment model by evaluating if the entailment is judged based on correct evidence. A faithful entailment model should tell not only whether the statement is contradictory to the video but also which words or phrases in the state-ment make it contradictory to the video. A pair of real/fake statements usually have a similar structure and only have very subtle differences, with only a small number of words’ replacement, e.g. “pony lessons in hour” and “school to-morrow” marked by the red dot line in Fig. 1. Thus, we propose to regularize the training of the entailment judg-ment module by encouraging the local explanation on the contribution of the words in the statement to conform to the subtle difference.
Our main contribution is threefold. First, we propose a novel approach to address video entailment with visu-ally grounded evidence. Second, we exploit the pairwise real/fake statements to add the explainability to the entail-ment model, which can tell the speciﬁc words or phrases that make the statement contradictory to the video. Third, extensive results demonstrate that our method outperforms the state-of-the-art video entailment method. 2.