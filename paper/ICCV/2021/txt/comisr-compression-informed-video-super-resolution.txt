Abstract
All
Most video super-resolution methods focus on restor-ing high-resolution video frames from low-resolution videos without taking into account compression. However, most videos on the web or mobile devices are compressed, and the compression can be severe when the bandwidth is limited.
In this paper, we propose a new compression-informed video super-resolution model to restore high-resolution content without introducing artifacts caused by compression. The proposed model consists of three mod-ules for video super-resolution: bi-directional recurrent warping, detail-preserving ﬂow estimation, and Lapla-cian enhancement. these three modules are used to deal with compression properties such as the loca-tion of the intra-frames in the input and smoothness in the output frames. For thorough performance evaluation, we conducted extensive experiments on standard datasets with a wide range of compression rates, covering many real video use cases. We showed that our method not only recovers high-resolution content on uncompressed frames from the widely-used benchmark datasets, but also achieves state-of-the-art performance in super-resolving compressed videos based on numerous quantitative met-rics. We also evaluated the proposed method by simulat-ing streaming from YouTube to demonstrate its effective-ness and robustness. The source codes and trained models are available at https://github.com/google-research/google-research/tree/master/comisr. 1.

Introduction
Super-resolution is a fundamental research problem in computer vision with numerous applications. It aims to re-construct detailed high-resolution (HR) image(s) from low-resolution (LR) input(s). When the input is one single im-age, the reconstruction process usually uses learned image priors to recover high-resolution details of the given image, which is called single-image super-resolution (SISR) [56].
When numerous frames in a video are available, the re-Figure 1. Video super-resolution results (4×, RGB-channels) on compressed Vid4 and REDS datasets. Here we show the results using the most widely adopted compression rate (CRF 23 [10]). construction process uses both image priors and inter-frame information to generate temporally smooth high-resolution results, which is known as video super-resolution (VSR).
Although great progress has been made, existing SISR and VSR methods rarely take compressed images as input.
We note that the uncompressed videos used in prior work in fact are high-quality image sequences with low compres-sion rate. As such, these SR methods tend to generate sig-niﬁcant artifacts when operating on heavily compressed im-ages or videos. However, most videos on the web or mobile devices are stored and streamed with images compressed at different levels. For example, a wide-used compression rate (Constant Rate Factor (CRF)) for H.264 encoding is 23 as a trade-off between visual quality and ﬁle size. We note the state-of-the-art VSR algorithms do not perform well when the input videos are compressed.
To handle compressed videos, one potential solution is to ﬁrst denoise images and remove compression artifacts in images [35, 36, 58] before applying one of the state-of-the-art VSR models. At ﬁrst glance, this is appealing since a
VSR model is fed with high-quality frames, similar to di-rectly using the evaluation data, such as Vid4 [32]. How-ever, our experiments in Section 4.3 show that this approach would not improve SR results and instead negatively affect the visual quality. With pre-processing, it is likely that the denoising model in the ﬁrst step will be signiﬁcantly differ-ent from the degradation kernel used implicitly during the
VSR training process. After the denoising process, the VSR models effectively need to handle more challenging images.
Another possible solution is to train the existing state-of-the-art VSR models on the compressed images. This will enforce the VSR models to account for compression arti-facts during the training process. However, our experiments described in Section 4.5 show that simply using compressed frames in model training brings only modest improvement.
In fact, without speciﬁc changes to the designs of network modules, such training data may even negatively affect the overall performance.
To address the above-mentioned issues, we propose a compression-informed (i.e., compression-aware) super-resolution model that can perform well on real-world videos with different levels of compression. Speciﬁcally, we de-sign three modules to robustly restore the missing informa-tion caused by video compression. First, a bi-directional recurrent module is developed to reduce the accumulated warping errors from the random locations of the intra-frame from compressed video frames [46]. Second, a detail-aware
ﬂow estimation module is introduced to recover HR ﬂow from compressed LR frames. Finally, a Laplacian enhance-ment module is adopted to add high-frequency information to the warped HR frames washed out by video encoding.
We refer to this proposed model as COMpression-Informed video Super-Resolution (COMISR).
With the proposed COMISR model, we demonstrate the effectiveness of these modules with ablation studies. We conduct extensive experiments on several VSR benchmark datasets, including Vid4 [32] and REDS4 [41], using videos compressed with different CRF values. We show that the
COMISR model achieves signiﬁcant performance gain on compressed videos (e.g., CRF23), as shown in Figure 1, and meanwhile maintains competitive performance on un-compressed videos. In addition, we present evaluation re-sults based on different combinations of a state-of-the-art
VSR model and an off-the-shelf video denoiser. Finally, we validate the robustness of the COMISR model on YouTube videos, which are compressed with proprietary encoders.
The contributions of this paper can be summarized as:
• We introduce a compression-informed model for super-resolving real-world compressed videos and achieve state-of-the-art performance.
• We incorporate three modules that are novel to VSR to effectively improve critical components for video super-resolution on compressed frames.
• We conduct extensive experiments of state-of-the-art
VSR models on compressed benchmark datasets. We also present a new setting for evaluating VSR models on YouTube transcoded videos, which is a real-world application scenario that existing evaluation methods do not consider. 2.