Abstract
This paper proposes a novel deep learning approach for single image defocus deblurring based on inverse kernels.
In a defocused image, the blur shapes are similar among pixels although the blur sizes can spatially vary. To utilize the property with inverse kernels, we exploit the observa-tion that when only the size of a defocus blur changes while keeping the shape, the shape of the corresponding inverse kernel remains the same and only the scale changes. Based on the observation, we propose a kernel-sharing parallel atrous convolutional (KPAC) block specifically designed by incorporating the property of inverse kernels for single im-age defocus deblurring. To effectively simulate the invariant shapes of inverse kernels with different scales, KPAC shares the same convolutional weights among multiple atrous con-volution layers. To efficiently simulate the varying scales of inverse kernels, KPAC consists of only a few atrous convolu-tion layers with different dilations and learns per-pixel scale attentions to aggregate the outputs of the layers. KPAC also utilizes the shape attention to combine the outputs of mul-tiple convolution filters in each atrous convolution layer, to deal with defocus blur with a slightly varying shape.
We demonstrate that our approach achieves state-of-the-art performance with a much smaller number of parameters than previous methods. 1.

Introduction
Defocus blur of an image occurs when the light ray from a point in the scene forms a circle of confusion (COC) on the camera sensor. The aperture shape and lens design of the camera determine the blur shape, and the blur size varies upon the depth of a scene point and intrinsic camera pa-rameters. In a defocused image, the spatial variance of the blur size is large, while that of the blur shape is relatively small. Single image defocus deblurring remains a challeng-ing problem as it is hard to accurately estimate and remove defocus blur spatially varying in both size and shape.
The conventional two-step approach [2, 23, 5, 18, 4, 11, 14] reduces the complexity of defocus deblurring by assum-ing an isotropic kernel for the blur shape, such as disc [2, 5] or Gaussian [23, 18, 11, 14]. Based on the assumption, the approach first estimates a defocus map containing the per-pixel blur size of a defocused image, then uses the defo-cus map to perform non-blind deconvolution [8, 15, 12] on the image. However, real-world defocused images may have more complex kernel shapes than disc or Gaussian, and the discrepancy often hinders accurate defocus map estimation and successful defocus deblurring.
Recently, Abuolaim and Brown [1] proposed DPDNet, the first end-to-end defocus deblurring network, that learns to directly deblur a defocused image without relying on a restrictive blur model. They also presented a defocus de-blurring dataset that includes stereo images attainable from a dual-pixel sensor camera. Thanks to the end-to-end learn-ing and the strong supervision provided by the dual-pixel dataset, DPDNet outperforms two-step approaches on de-blurring of real-world defocused images. Still, the deblurred results tend to include ringing artifacts or remaining blur, as the conventional encoder-decoder architecture of DPDNet confines its capability in handling spatially variant blur [34].
In this paper, we propose a novel deep learning approach for single image defocus deblurring based on inverse ker-nels. It was shown that deconvolution of an image with a given blur kernel can be performed by convolving the im-age with an inverse kernel [30], where the inverse kernel could be computed from the given blur kernel using Fourier transform. Xu et al. [29] trained a deep network to learn uni-form deconvolution by introducing the property of pseudo inverse kernel into the network. Similarly, we train our net-work to learn the deconvolution operation by capitalizing the specific characteristics of inverse kernels needed for de-focus deblurring. However, due to the spatially varying na-ture of defocus blur, the inverse kernel required for defocus deblurring also changes per pixel. Training a deep network to learn deconvolution operations of varying inverse kernels would be challenging even with the guidance of defocused
and sharp image pairs.
To reduce the complexity, we use the property of defo-cus blur that the blur shape is similar in a defocused im-age although the blur size can drastically change. However, instead of assuming any specific blur shape as in the two-step approach, we exploit our observation on inverse ker-nels; When only the size of a blur changes while keeping the shape, the shape of the corresponding inverse kernel re-mains the same and the size changes in the same way as the blur (Sec. 3.1). Then, we may constrain our network to sim-ulate inverse kernels with a single shape but with different sizes to cover spatially varying defocus blur. However, it is hard to directly simulate inverse kernels with all possible sizes in practice. Instead, we design our network to carry a few convolutional layers to cover inverse kernels with a discrete set of sizes, and aggregate the outputs of the lay-ers for handling blur with arbitrary size. As a result, com-pared to the conventional two-step approach and the recent deep learning approach [1], our method can perform defo-cus deblurring more accurately by exploiting the properties of defocus blur in the form of inverse kernel.
To implement the network design, we propose a novel kernel-sharing parallel atrous convolutional (KPAC) block.
The KPAC block consists of multiple atrous convolution layers [9, 3] with different dilation rates and additional lay-ers for the scale and shape attentions. The multiple atrous convolution layers share the same convolution kernels rep-resenting the invariant shape of an inverse kernel, and differ-ent dilation rates of the layers correspond to inverse kernels with a discrete set of sizes. To simulate deconvolution us-ing inverse kernels of other sizes, the KPAC block equips a spatial attention mechanism [28], which we call the scale attention, to aggregate the outputs of the atrous convolution layers. By combining the per-pixel scale attention with mul-tiple atrous convolution layers, the KPAC block can han-dle the spatially varying size of defocus blur. In addition, the shape of defocus blur may slightly change in a defo-cused image due to the non-linearity of a camera image pipeline. To handle the variance, we include a channel at-tention mechanism [33], which we call the shape attention, in a KPAC block to support the slight shape change of the inverse kernel.
An important benefit of our KPAC block is its small number of parameters, enabled by kernel sharing of the multiple atrous convolution layers. As a result, our defo-cus deblurring network is lighter-weighted than the previ-ous work [1], showing the better performance (Sec. 5.2).
To summarize, our contributions include:
â€¢ Light-weight single image defocus deblurring net-work, which shows state-of-the-art performance. 2.