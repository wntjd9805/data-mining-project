Abstract
As an attempt towards assessing the robustness of em-bodied navigation agents, we propose ROBUSTNAV, a framework to quantify the performance of embodied nav-igation agents when exposed to a wide variety of visual – affecting RGB inputs – and dynamics – affecting transi-tion dynamics – corruptions. Most recent efforts in visual navigation have typically focused on generalizing to novel target environments with similar appearance and dynam-ics characteristics. With ROBUSTNAV, we find that some standard embodied navigation agents significantly under-perform (or fail) in the presence of visual or dynamics cor-ruptions. We systematically analyze the kind of idiosyn-crasies that emerge in the behavior of such agents when operating under corruptions. Finally, for visual corrup-tions in ROBUSTNAV, we show that while standard tech-niques to improve robustness such as data-augmentation and self-supervised adaptation offer some zero-shot resis-tance and improvements in navigation performance, there is still a long way to go in terms of recovering lost perfor-mance relative to clean “non-corrupt” settings, warranting more research in this direction. Our code is available at https://github.com/allenai/robustnav. 1.

Introduction
A longstanding goal of the artificial intelligence com-munity has been to develop algorithms for embodied agents that are capable of reasoning about rich perceptual infor-mation and thereby accomplishing tasks by navigating in and interacting with their environments. In addition to be-ing able to exhibit these capabilities, it is equally important that such embodied agents are able to do so in a robust and generalizable manner.
A major challenge in Embodied AI is to ensure that agents can generalize to environments with different ap-pearance statistics and motion dynamics than the environ-ment used for training those agents. For instance, an agent
*Part of the work done when PC was a research intern at AI2.
Figure 1. ROBUSTNAV. (a) A navigation agent pretrained in clean environments is asked to navigate to targets in unseen environ-ments in the presence of (b) visual and (c) dynamics based corrup-tions. Visual corruptions (ex. camera crack) affect the agent’s ego-centric RGB observations while Dynamics corruptions (ex. drift in translation) affect transition dynamics in the unseen environment. that is trained to navigate in “sunny” weather should con-tinue to operate in rain despite the drastic changes in the appearance, and an agent that is trained to move on carpet should decidedly navigate when on a hardwood floor de-spite the discrepancy in friction. While a potential solution may be to calibrate the agent for a specific target environ-ment, it is not a scalable one since there can be enormous varieties of unseen environments and situations. A more ro-bust, efficient and scalable solution is to equip agents with the ability to autonomously adapt to new situations by in-teraction without having to train for every possible target scenario. Despite the remarkable progress in Embodied AI, especially in embodied navigation [59, 46, 48, 54, 7], most efforts focus on generalizing trained agents to unseen envi-ronments, but critically assume similar appearance and dy-namics attributes across train and test environments.
As a first step towards assessing general purpose ro-bustness of embodied agents, we propose ROBUSTNAV, a framework to quantify the performance of embodied navi-gation agents when exposed to a wide variety of common visual (vis) and dynamics (dyn) corruptions – artifacts that affect the egocentric RGB observations and transition dy-namics, respectively. We envision ROBUSTNAV as a testbed for adapting agent behavior across different perception and actuation properties. While assessing robustness to changes (stochastic or otherwise) in environments has been inves-tigated in the robotics community [32, 13, 14, 21], the simulated nature of ROBUSTNAV enables practitioners to explore robustness against a rich and very diverse set of changes, while inheriting the advantages of working in sim-ulation – speed, safety, low cost and reproducibility.
ROBUSTNAV consists of two widely studied embodied navigation tasks, Point-Goal Navigation (POINTNAV) [2] and Object-Goal Navigation (OBJECTNAV) [4] – the tasks of navigating to a goal-coordinate in a global reference frame or an instance of a specified object, respectively. Fol-lowing the standard protocol, agents learn using a set of training scenes and are evaluated within a set of held out test scenes, but differently, ROBUSTNAV test scenes are sub-ject to a variety of realistic visual and dynamics corruptions.
These corruptions can emulate real world scenarios such as a malfunctioning camera or drift (see Fig.1).
As zero shot adaptation to test time corruptions may be out of reach for our current algorithms, we provide agents with a fixed “calibration budget” (number of interactions) within the target world for unsupervised adaptation. This mimics a real-world analog where a shipped robot is al-lowed to adapt to changes in the environment by execut-ing a reasonable number of unsupervised interactions. Post calibration, agents are evaluated on the two tasks in the cor-rupted test environments using standard navigation metrics.
Our extensive analysis reveals that both POINTNAV and
OBJECTNAV agents experience significant degradation in performance across the range of corruptions, particularly when multiple corruptions are applied together. We show that this degradation reduces in the presence of a clean depth sensor suggesting the advantages of incorporating multiple sensing modalities, to improve robustness. We find that data augmentation and self-supervised adaptation strategies offer some zero-shot resistance and improvement over de-graded performance, but are unable to fully recover this gap in performance. Interestingly, we also note that visual cor-ruptions affect embodied tasks differently from static tasks like object recognition – suggesting that visual robustness should be explored within an embodied task. Finally, we an-alyze several interesting behaviors our agents exhibit in the presence of corruptions – such as increase in the number of collisions and inability to terminate episodes successfully.
In summary, our contributions include: (1) We present
ROBUSTNAV– a framework for benchmarking and assess-ing the robustness of embodied navigation agents to vi-sual and dynamics corruptions. (2) Our findings show that present day navigation agents trained in simulation under-perform severely when evaluated in corrupt target environ-(3) We systematically analyze the kinds of mis-ments. takes embodied navigation agents make when operating un-der such corruptions. (4) We find that although standard data-augmentation techniques and self-supervised adapta-tion strategies offer some improvement, much remains to be done in terms of fully recovering lost performance.
ROBUSTNAV provides a fast framework to develop and test robust embodied policies, before they can be deployed onto real robots. While ROBUSTNAV currently supports navigation heavy tasks, the supported corruptions can be easily extended to more tasks, as they get popular within the Embodied AI community. 2.