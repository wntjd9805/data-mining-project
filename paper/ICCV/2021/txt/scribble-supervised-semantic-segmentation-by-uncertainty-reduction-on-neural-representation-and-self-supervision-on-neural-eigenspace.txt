Abstract
Scribble-supervised semantic segmentation has gained much attention recently for its promising performance with-out high-quality annotations. Due to the lack of supervi-sion, confident and consistent predictions are usually hard to obtain. Typically, people handle these problems by either adopting an auxiliary task with the well-labeled dataset or incorporating a graphical model with additional require-ments on scribble annotations.
Instead, this work aims to achieve semantic segmentation by scribble annotations directly without extra information and other limitations.
Specifically, we propose holistic operations, including min-imizing entropy and a network embedded random walk on the neural representation to reduce uncertainty. Given the probabilistic transition matrix of a random walk, we fur-ther train the network with self-supervision on its neural eigenspace to impose consistency on predictions between related images. Comprehensive experiments and ablation studies verify the proposed approach, which demonstrates superiority over others; it is even comparable to some full-label supervised ones and works well when scribbles are randomly shrunk or dropped. 1.

Introduction
In recent years, the use of neural networks, especially convolutional neural networks, has dramatically improved semantic classification, detection, and segmentation [16].
As one of the most fine-grained ways to understand the scene, typically, semantic segmentation demands large-scale data with high-quality annotations to feed the net-work. However, the pixel-level annotating process for se-mantic segmentation is costly and tedious, limiting its flex-ibility and usability on some tasks that require rapid de-ployment [18]. As a consequence, the scribble annotations, which are more easily available, have become popular.
The main difficulty for scribble-supervised semantic seg-*Corresponding Author
Figure 1. From left to right: image, scribble annotation, ground truth, our prediction. From top to bottom: sample with regular, shrunk and dropped scribble annotation, respectively. mentation lies in two aspects. (1) the scribble annotation is sparse and cannot provide enough supervision for the net-work to make confident predictions. (2) the scribble annota-tion varies from image to image, which makes it hard for the network to produce consistent results. As a consequence,
[18] adopted the classic graphical model as post-processing to obtain the final dense predictions. Some works [25, 28] turn to an auxiliary task with well-labeled dataset for help, but this does not actually remove the burden of annotation but merely shifts it. To avoid the post-processing and depen-dence on another well-labeled dataset, [24] design a graph-ical model with regularized loss to make predictions con-sistent within the appearance similar neighborhood, but did not consider semantic similarity. Moreover, they require ev-ery object in an image to be labeled, which is too strict for dataset preparation.
We address the task by a more flexible approach with-out introducing auxiliary supervision and constraints in this work. The approach can work properly when scribbles on some objects are randomly dropped or even shrunk to spots.
Several representative results are shown in Fig. 1. We pro-pose two creative solutions for the problems of confidence and consistency mentioned above. To reduce uncertainty when supervision is lacking, we take advantage of two facts related to semantic segmentation. The first one is that each pixel only belongs to one category (deterministic), and there
is only one channel of output neural representation that plays the dominant role. The second one is neural repre-sentations should be uniform within internal object regions.
Accordingly we present here, for the first time, a solution involving neural representations which include two specific operations, minimizing entropy to encourage deterministic predictions and a network embedded random walk module to promote uniform intermediates. The transition matrix of a random walk will also be useful for consistency enhance-ment later. In general, we make up for the lack of supervi-sion with scribble annotations by taking advantage of two priors, determinism and uniformity.
We propose to adopt self-supervision during training as the second solution for inconsistent results caused by vary-ing scribble annotations from image to image, which im-poses consistency on the neural representation before and after certain input transformation [15]. However, consis-tency over the whole neural representation usually is not necessary for semantic segmentation, especially for regions belonging to the background category, which usually are semantically heterogeneous. When these regions are dis-torted and changed heavily after transformation, it is hard for the network to generate consistent output and may con-fuse the network in some scenarios. With that in mind and given the transition matrix of a random walk, we propose to set self-supervision on the main parts of images by impos-ing consistent loss on the eigenspace of transition matrix.
The idea is inspired by spectral methods [26], where it has been observed that the eigenvectors of a Laplacian matrix have the capability to distinguish the main parts in images, and some methods use this property for clustering [20] and saliency detection [12]. Since the eigenspace of a transition matrix has a close relation to the one of a Laplacian matrix, our self-supervision on transition matrixâ€™s eigenspace will also focus on the main image parts.
The proposed approach demonstrates consistent supe-riority over others on a common scribble dataset and is even comparable to some fully supervised ones. More-over, we further conduct experiments when scribbles are gradually shrunk and dropped. The proposed approach can still work reasonably, even when the scribble shrunk to a spot or dropped significantly. Careful ablation stud-ies are made to verify the effectiveness of every op-eration. the code and data are available at https://github.com/panzhiyi/URSS.
Finally, 2.