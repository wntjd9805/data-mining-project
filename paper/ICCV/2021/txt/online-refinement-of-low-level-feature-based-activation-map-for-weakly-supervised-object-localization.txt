Abstract
We present a two-stage learning framework for weakly supervised object localization (WSOL). While most previ-ous efforts rely on high-level feature based CAMs (Class
Activation Maps), this paper proposes to localize objects using the low-level feature based activation maps. In the first stage, an activation map generator produces activa-tion maps based on the low-level feature maps in the classi-fier, such that rich contextual object information is included
In the second stage, we employ an in an online manner. evaluator to evaluate the activation maps predicted by the activation map generator. Based on this, we further pro-pose a weighted entropy loss, an attentive erasing, and an area loss to drive the activation map generator to substan-tially reduce the uncertainty of activations between object and background, and explore less discriminative regions.
Based on the low-level object information preserved in the first stage, the second stage model gradually generates a well-separated, complete, and compact activation map of object in the image, which can be easily thresholded for accurate localization. Extensive experiments on CUB-200-2011 and ImageNet-1K datasets show that our framework surpasses previous methods by a large margin, which sets a new state-of-the-art for WSOL. Code will be available soon. 1.

Introduction
Supervised object localization and detection methods based on deep neural networks [22, 14, 21, 13] have achieved great advances. However, these methods usually rely on massive training data with intensive annotations, es-pecially location-level labels. To alleviate the high annota-tion costs, weakly supervised object localization requiring only image-level annotations has gained lots of attentions.
*Corresponding Author
Figure 1: Comparison between CAM and the proposed method. (a) Overview of the CAM pipeline. (b) Overview of the proposed two-stage learning framework. Red bounding boxes illustrate the localization results.
Instead of exploring the entire extent of the objects, clas-sification networks incline to identify patterns from small and sparse regions. Due to this limitation, class activa-tion maps [44] (CAM), a weighted average of high-level feature maps, usually indicate only the discriminative re-gions of objects. Fig. 1(a) gives the diagram of CAM. As shown in figure, only the head region, which is the most discriminative part to distinguish the bird, is localized. See
Fig. 2 for more examples of CAM based localization. How-ever, discriminative region is insufficient for accurate ob-ject localization. To address this issue, various solutions
[28, 4, 31, 2, 41, 27, 3, 40, 38, 16] have been explored. For example, [11, 40, 3] attempt to erase the most discriminative regions, promoting the network to discover less discrimi-native regions. As high-level features are used as region guidance, these approaches have limited potentials to de-rive complete and compact activation maps. Furthermore, when the following thresholding is used to separate fore-ground and background pixels, the result is very sensitive to the setting of threshold, due to the diverse distribution of
loss, are designed to deal with the second limitation. The two components can explore more alternative contents for classification and penalize the background pixels. Designs in the second stage adversarially encourage the generator to further explore the contextual semantics of objects pre-served in the low-level features. Fig. 2 shows the compar-ison results of our method and two other existing popular object localization methods, i.e., CAM [44] and ADL [3].
From Fig. 3(b) to (c) and from left to right in Fig. 4, it re-veals that, after the entropy-guided refinement, our method can get well-separated, complete and compact object acti-vation map, to achieve the accurate object localization.
Collectively, the main contributions of this paper can be summarized as:
• We propose to employ low-level features as region guidance to generate activation maps in an online man-ner, which provides rich contextual information of ob-jects for the following refinement.
• We design the entropy-guided refinement to adversari-ally drive the network to further explore the low-level features to obtain well-separated, complete, and com-pact activation maps for accurate object localization.
As the activations of objects and background are now well-separated, the localization is not sensitive to the threshold.
• Extensive experiments on CUB-200-2011 [30] and
ImageNet-1K [24] datasets show that the proposed method surpasses the previous methods by a large mar-gin, setting a new state-of-the-art performance. Ex-periments on additional datasets verify the robustness and generalization ability of our method across various scenarios and species. 2.