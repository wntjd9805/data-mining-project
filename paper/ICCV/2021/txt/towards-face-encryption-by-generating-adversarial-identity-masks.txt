Abstract
As billions of personal data being shared through so-cial media and network, the data privacy and security have drawn an increasing attention. Several attempts have been made to alleviate the leakage of identity information from face photos, with the aid of, e.g., image obfuscation tech-niques. However, most of the present results are either per-ceptually unsatisfactory or ineffective against face recogni-tion systems. Our goal in this paper is to develop a tech-nique that can encrypt the personal photos such that they can protect users from unauthorized face recognition sys-tems but remain visually identical to the original version for human beings. To achieve this, we propose a targeted identity-protection iterative method (TIP-IM) to generate adversarial identity masks which can be overlaid on facial images, such that the original identities can be concealed without sacrificing the visual quality. Extensive experiments demonstrate that TIP-IM provides 95%+ protection success rate against various state-of-the-art face recognition mod-els under practical test scenarios. Besides, we also show the practical and effective applicability of our method on a commercial API service. 1.

Introduction
The blooming development of social media and network has brought a huge amount of personal data (e.g., photos) shared publicly. With the growing ubiquity of deep neural networks, these techniques dramatically improve the capa-bilities for the face recognition systems to deal with per-sonal data [6, 26, 37, 46], but as a byproduct, also increase the potential risks for privacy leakage of personal informa-tion. For example, an unauthorized third party may scrabble and identify the shared photos on social media (e.g., Twit-ter, Facebook, LinkedIn, etc.) without the permission of
*Corresponding author
Figure 1. An illustrative example of targeted identity protection.
When users share a photo xr on social media (e.g., Twitter, Face-book, etc.), unauthorized applications could scrabble this identity y0 based on face recognition systems, resulting in the privacy leak-age of personal information. Thus we provide an effective identity mask tool to generate a protected image xp, which can conceal the corresponding identity by misleading the malicious systems to predict it as a wrong target identity yt in an authorized or virtual target set, which can be provided by the service providers. their owners, resulting in cybercasing [23]. Therefore, it is imperative to provide users an effective way to protect their private information from being unconsciously identified and exposed by the excessive unauthorized systems, without af-fecting users’ experience.
The past years have witnessed the progress for face en-cryption in both the security and computer vision commu-nities. Among the existing techniques, obfuscation-based methods are widely studied. Conventional obfuscation tech-niques [48], such as blurring, pixelation, darkening, and oc-clusion, are maybe either perceptually satisfactory or effec-tive against recognition systems [28, 31, 35]. The recent ad-vance in generative adversarial networks (GANs) [15] pro-vides an appealing way to generate more realistic images for obfuscation [14, 43, 44, 49, 25]. However, the resultant ob-fuscated images have significantly different visual appear-ances compared with the original images due to the exag-geration and suppression of some discriminative features, and occasionally generate unnatural output images with un-desirable artifacts [44].
Recent researches have found that adversarial examples can evade the recognition of a FR system [52, 45, 16, 40] by overlaying adversarial perturbations on the original im-ages [1]. It becomes an appealing way to apply an adversar-ial perturbation to conceal one’s identity, even under a more strict constraint of impersonating some authorized or gen-erated face images when available (e.g., given by the social media services). It provides a possible solution to specify the output, which may avoid an invasion of privacy to other persons if the resultant image is recognized as an arbitrary identity 1. It should nevertheless be noted that although the adversarial perturbations generated by the existing methods (e.g., PGD [22] and MIM [8]) have a small intensity change (e.g., 12 or 16 for each pixel in [0, 255]), they may still sac-rifice the visual quality for human perception due to the arti-facts as illustrated in Fig. 2, and similar observation is also elaborately presented in [54, 38] that ℓp-norm adversarial perturbations can not fit human perception well. Moreover, the current adversarial attacks are mainly dependent on ei-ther the white-box control of the target system [40, 32] or the tremendous number of model queries [10], which are impractical in real-world scenarios (e.g., unauthorized face recognition systems on social media) for identity protection.
In this paper, we involve some valuable considerations from a general user’s perspective and propose to alleviate the identity leakage of personal photos in real-world social media. We focus on face identification in particular, a typ-ical sub-task in face recognition, the goal of which is to identify a real face image in an unknown gallery identity set (see Sec. 3), since it can be adopted by unauthorized ap-plications for recognizing the identity information of users.
As stated in Fig. 1, face encryption is to block the ability of automatic inference on malicious applications, making them predict a wrong authorized or virtual target by the ser-vice providers.
In general, little is known about the face recognition system and no direct query access is possible.
Therefore, we need to generate adversarial masks against a surrogate known model with the purpose of deceiving a black-box face recognition system. Moreover, we try to not affect the user experience when users share the protected photos on social media, and simultaneously conceal their identities from unauthorized recognition systems. Thus, the protected images should also be visually natural from the corresponding original ones, otherwise it may introduce un-desirable artifacts as a result.
To address the aforementioned challenges, we propose a targeted identity-protection iterative method (TIP-IM) for face encryption against black-box face recognition sys-tems. The proposed method generates adversarial identity masks that are both transferable and imperceptible. A good 1The practical FR system will obtain the similarity rankings from the transferability implies that a model can effectively deceive other black-box face recognition systems, meanwhile the imperceptibility means that a photo manipulated by an ad-versarial identity mask is visually natural for the human ob-servers. Specifically, to ensure the generated images are not arbitrarily misclassified as other identities, we randomly choose a set of face images from a dataset collected from the internet as the specified targets in our experiments2. Our method obtains superior performance against white-box and black-box face systems with multiple target identities via a novel iterative optimization algorithm.
Extensive experiments under practical and challenging open-set 3 test scenarios [26] demonstrate that our algo-rithm provides 95+% protection success rate against white-box face systems, and outperforms previous methods by a margin even against various state-of-the-art algorithms. Be-sides, we also demonstrate its effectiveness in a real-world experiment by considering a commercial API service. Our main contributions are summarized as
• We involve some valuable considerations to protect privacy against unauthorized identification systems from the user’s perspective, including targeted protec-tion, natural outputs, black-box face systems, and un-known gallery set.
• We propose a targeted identity-protection iterative method (TIP-IM) to generate an adversarial identity mask, in which we consider multi-target sets and in-troduce a novel optimization mechanism to guarantee effectiveness under various scenarios. 2.