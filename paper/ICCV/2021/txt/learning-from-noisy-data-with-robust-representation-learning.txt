Abstract
Learning from noisy data has attracted much attention, where most methods focus on label noise. In this work, we propose a new learning framework which simultaneously addresses three types of noise commonly seen in real-world data: label noise, out-of-distribution input, and input cor-ruption. In contrast to most existing methods, we combat noise by learning robust representation. Specifically, we embed images into a low-dimensional subspace, and regu-larize the geometric structure of the subspace with robust contrastive learning, which includes an unsupervised consis-tency loss and a supervised mixup prototypical loss. We also propose a new noise cleaning method which leverages the learned representation to enforce a smoothness constraint on neighboring samples. Experiments on multiple benchmarks demonstrate state-of-the-art performance of our method and robustness of the learned representation. Code is available at https://github.com/salesforce/RRL/. 1.

Introduction
Data in real life is noisy. However, deep models with remarkable performance are mostly trained on clean datasets with high-quality human annotations. Manual data clean-ing and labeling is an expensive process that is difficult to scale. On the other hand, there exists almost infinite amount of noisy data online. It is crucial that deep neural net-works (DNNs) could harvest noisy training data. However, it has been shown that DNNs are susceptible to overfitting to noise [43].
As shown in Figure 1, a real-world noisy image dataset of-ten consists of multiple types of noise. Label noise refers to samples that are wrongly labeled as another class (e.g. flower labeled as orange). Out-of-distribution input refers to sam-ples that do not belong to any known classes. Input corrup-tion refers to image-level distortion (e.g. low brightness) that causes data shift between training and test.
Most of the methods in literature focus on addressing the more detrimental label noise. Two dominant approaches include: (1) find clean samples as those with smaller loss and
Figure 1. Google search images from WebVision [22] dataset with keyword “orange”. assign larger weights to them [6, 42, 32, 1]; (2) relabel noisy samples using model’s predictions [31, 25, 34, 41, 23, 18].
Previous methods that focus on addressing label noise do not consider out-of-distribution input or input corruption, which limits their performance in real-world scenarios. Fur-thermore, using a model’s own prediction to relabel samples could cause confirmation bias, where the prediction error accumulates and harms performance.
We propose a new direction for effective learning from noisy data. Different from existing methods, our method learns noise-robust low-dimensional representations, and per-forms noise cleaning by enforcing a smoothness constraint on neighboring samples. Specifically, our algorithmic con-tributions include:
• We propose noise-robust contrastive learning, which intro-duces two contrastive losses. The first is an unsupervised consistency contrastive loss. It enforces inputs with per-turbations to have similar normalized embeddings, which helps learn robust and discriminative representation.
• Our second contrastive loss is a weakly-supervised proto-typical contrastive loss. We compute class prototypes as normalized mean embeddings, and enforces each sample’s embedding to be closer to its class prototype. Inspired by
Mixup [44], we construct virtual training samples as lin-ear interpolation of inputs, and encourage the same linear relationship w.r.t the class prototypes.
• We propose a new noise cleaning method which lever-ages the learned representations to enforce a smoothness constraint on neighboring samples. For each sample, we aggregate information from its top-k neighbors to create a pseudo-label. A subset of training samples with confi-dent pseudo-labels are selected to compute the weakly-supervised loss. This process can effectively clean both label noise and out-of-distribution (OOD) noise.
Our experimental contributions include:
• We experimentally show that our method achieves state-of-the-art performance on multiple datasets with con-trolled noise and real-world noise.
• We demonstrate that the proposed noise cleaning method can effectively clean a majority of label noise. It also learns a curriculum that gradually leverages more sam-ples to compute the weakly-supervised loss as the pseudo-labels become more accurate.
• We validate the robustness of the learned low-dimensional representation by showing (1) k-nearest neighbor clas-sification outperforms the softmax classifier. (2) OOD samples can be separated from in-distribution samples. 2.