Abstract
Vehicle tracking is an essential task in the multi-object tracking (MOT) field. A distinct characteristic in vehicle tracking is that the trajectories of vehicles are fairly smooth in both the world coordinate and the image coordinate.
Hence, models that capture motion consistencies are of high necessity. However, tracking with the standalone motion-based trackers is quite challenging because targets could get lost easily due to limited information, detection error and occlusion. Leveraging appearance information to as-sist object re-identification could resolve this challenge to some extent. However, doing so requires extra computa-tion while appearance information is sensitive to occlusion as well. In this paper, we try to explore the significance of motion patterns for vehicle tracking without appearance in-formation. We propose a novel approach that tackles the association issue for long-term tracking with the exclusive fully-exploited motion information. We address the tracklet embedding issue with the proposed reconstruct-to-embed strategy based on deep graph convolutional neural net-works (GCN). Comprehensive experiments on the KITTI-car tracking dataset and UA-Detrac dataset show that the proposed method, though without appearance information, could achieve competitive performance with the state-of-the-art (SOTA) trackers. The source code will be available at https://github.com/GaoangW/LGMTracker. 1.

Introduction
Multi-object tracking (MOT) is an important topic in the computer vision and machine learning field. This tech-nique is highly demanded in many tasks, such as traf-fic flow estimation, human behavior prediction and au-Figure 1. The top part shows tracking with appearance informa-tion, while the bottom shows tracking using detection boxes with-out employing appearance. Obviously, it is more challenging for tracking only based on motion information. tonomous driving assistance [52, 51, 55, 25, 20]. From unsupervised rule-based [6, 7, 5, 22, 52] and optimization-based [66, 11, 62, 56, 32, 38, 37, 1, 24, 12] to deep learning-based trackers [13, 68, 41, 57, 40, 4, 67, 42, 63], significant progress of the MOT techniques has been made in the re-cent ten years. However, some critical challenges still re-main. For example, occlusion is still one of the major is-sues. Without occlusion handling, the targets can easily get lost and identities may get switched. Other challenges, such as crowded scenarios, detection errors and camera motions, also have significant influences on a trackerâ€™s performance.
Appearance information is widely used for MOT and greatly improves performance. Appearance information is employed either in an association manner [52, 67, 14] or with regression-based approaches for joint learning of de-tection and tracking [68, 41, 57, 4]. The assumption, as well as the attribution of its success, is that the same targets from adjacent frames should share similar appearance fea-tures. However, the appearance feature is still sensitive to occlusions and objects may have quite different appearance representations when they are occluded. Additionally, joint learning approaches require an extra computational cost.
Motion consistency is another cue that can be taken ad-vantage of for MOT, especially for vehicle tracking scenar-ios. This is based on the assumption that the motions of ob-jects usually follow fairly smooth patterns in both the world coordinate and the image coordinate. In particular, for ob-jects that cannot change the orientation and speed rapidly, such as vehicles, motion consistency could play a pivot role for tracking. In addition, the motion feature, usually with the four bounding box parameters for each object, is sim-ple and light, saving more computations than complex ap-pearance features. As a result, mere motion trackers are still worth exploring. However, there are two main diffi-culties to establish deep motion-based models. First, mo-tion itself can only provide limited information. As shown in Figure 1, after discarding all appearance information, it is highly challenging to associate the bounding boxes cor-rectly even for humans when false positives and false neg-atives occur in the detection. Second, to alleviate the long-term occlusion issue, tracklet association is needed in deep motion-based models. Accurate association requires ex-pressive tracklet embeddings that could be used to measure the similarity among different tracklets. However, learning such embeddings is very challenging as we need to cap-ture temporal consistency as well. For example, tracklets of the same object might have different temporal lengths or do not share similar locations along time, leading to inferior embeddings in practice. Due to the aforementioned chal-lenges, mere motion trackers usually cannot achieve com-parable performance with models that adopt appearance in-formation.
In this paper, we tackle the vehicle tracking problem only from the motion perspective. Without appearance informa-tion, we aim to explore how well a motion-based model can perform for the vehicle tracking task. A novel motion-based tracking approach, i.e., local-global motion (LGM) tracker, is proposed to exploit the motion consistency without us-ing any appearance information after the detection. More specifically, without appearance information means: 1) NO further bounding box regression or refinement from the de-tector feature maps; 2) NO appearance information used for further association and re-identification. The flowchart of the proposed LGM tracker is shown in Figure 2. We model the MOT problem as a two-stage embedding task where both local and global motion consistencies are uti-lized. At the first stage, we aim at learning the box em-bedding based on deep graph convolutional neural networks (GCN) to associate boxes into tracklets. Since such local as-sociations cannot capture the global track patterns, the oc-clusion issue is yet unaddressed. To break through such limitation, at the second stage, the tracklet embedding with global motion consistency is learned to further associate tracklets into tracks. To better model the tracklet embed-ding, a novel embedding strategy, reconstruct-to-embed, is proposed with the temporal gated convolution mechanism under an attention-based GCN.
Our contributions are summarized as follows: 1) we tackle the vehicle tracking task from the motion perspec-tive without using appearance information; 2) we propose a novel box and tracklet embedding method that can uti-lize both the local and global motion consistencies; 3) we evaluate the proposed LGM tracker on KITTI [18] and UA-Detrac [58] benchmark datasets and achieve competitive performance with the state-of-the-art (SOTA) trackers. 2.