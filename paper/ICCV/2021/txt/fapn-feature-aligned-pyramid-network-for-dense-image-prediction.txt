Abstract
Recent advancements in deep neural networks have made remarkable leap-forwards in dense image prediction.
However, the issue of feature alignment remains as ne-glected by most existing approaches for simplicity. Direct pixel addition between upsampled and local features leads to feature maps with misaligned contexts that, in turn, trans-late to mis-classifications in prediction, especially on ob-ject boundaries. In this paper, we propose a feature align-ment module that learns transformation offsets of pixels to contextually align upsampled higher-level features; and another feature selection module to emphasize the lower-level features with rich spatial details. We then integrate these two modules in a top-down pyramidal architecture and present the Feature-aligned Pyramid Network (FaPN).
Extensive experimental evaluations on four dense predic-tion tasks and four datasets have demonstrated the efficacy of FaPN, yielding an overall improvement of 1.2 - 2.6 points in AP / mIoU over FPN when paired with Faster / Mask R-CNN. In particular, our FaPN achieves the state-of-the-art of 56.7% mIoU on ADE20K when integrated within Mask-Former. The code is available from https://github.com/EMI-Group/FaPN. 1.

Introduction
Dense prediction is a collection of computer vision tasks that aim at labeling every pixel in an image with a pre-defined class.
It plays a fundamental role in scene un-derstanding and is of great importance to real-world ap-plications, such as autonomous driving [7], medical imag-ing [44], augmented reality [1], etc. The modern solutions for these tasks are built upon Convolutional Neural Net-works (CNNs). With the recent advancements in CNN ar-chitectures, a steady stream of promising empirical leap-forwards was reported across a wide range of dense predic-tion tasks, including object detection [26, 39, 40], semantic segmentation [4, 28], instance segmentation [13, 25], and panoptic segmentation [18, 19], to name a few.
*Corresponding author.
†Authors are with Department of Computer Science and Engineering.
Figure 1: Comparisons between FPN and FaPN: (Top row) Qualitatively, FaPN significantly improves the perfor-mance on object boundaries as opposed to its counterpart, i.e. FPN [23]. (Bottom row) Quantitatively, FaPN’s im-provements over FPN are consistent across different tasks, backbones, and object scales. Best view in color.
Dense prediction requires both rich spatial details for ob-ject location and strong semantics for object classification, which most likely reside at different resolution / scale lev-els [28]. How to effectively generate a hierarchy of fea-tures at different scales becomes one of the key barriers to overcome in handling dense prediction tasks [23]. Broadly speaking, there are two common practices to address this issue. The first kind uses atrous convolutions with differ-ent atrous rates to effectively capture long-range informa-tion (i.e. semantic context) without reducing spatial resolu-tion [4]. The other kind builds a top-down feature pyramid based on the default bottom-top pathway of a ConvNet [2].
More specifically, the (higher-level) spatially coarser fea-ture maps are upsampled before merging with the corre-sponding feature maps from the bottom-up path-way. How-ever, there are inaccurate correspondences (i.e. feature mis-alignment) between the bottom-up and upsampled features owing to the non-learnable nature of the commonly-used upsampling operations (e.g. nearest neighbor) and the re-Figure 2: Example pairs of results from FPN [23] and our FaPN. Both methods are implemented in Mask R-CNN [13] with ResNet50 [14] being the backbone and PointRend [20] as the mask head. Qualitatively, FaPN significantly improves the performance on object boundaries. Images are randomly chosen from [24] and [9] for instance (left) and semantic (right) segmentation, respectively. More visualization examples are available in the supplementary materials. peated applications of downsampling and upsampling. The misaligned features, in turn, adversely affects the learning in the subsequent layers, resulting in mis-classifications in the final predictions, especially around the object bound-aries. To address the aforementioned issue, we propose a feature alignment module that learns to align the upsampled feature maps to a set of reference feature maps by adjust-ing each sampling location in a convolutional kernel with a learned offset. We further propose a feature selection mod-ule to adaptively emphasize the bottom-up feature maps containing excessive spatial details for accurate locating.
We then integrate these two modules in a top-down pyrami-dal architecture and propose the Feature-aligned Pyramid
Network (FaPN).
Conceptually, FaPN can be easily incorporated to exist-ing bottom-up ConvNet backbones [14, 29, 31, 33] to gener-ate a pyramid of features at multiple scales [23]. We imple-ment FaPN in modern dense prediction frameworks (Faster
R-CNN [40], Mask R-CNN [13], PointRend [20], Mask-Former [8], PanopticFPN [18], and PanopticFCN [22]), and demonstrate its efficacy on object detection, semantic, in-stance and panoptic segmentation. Extensive evaluations on multiple challenging datasets suggest that FaPN leads to a significant improvement in dense prediction perfor-mance, especially for small objects and on object bound-aries. Moreover, FaPN can also be easily extended to real-time semantic segmentation by pairing it with a lightweight bottom-up backbone [14, 30, 32]. Without bells and whis-tles, FaPN achieves favorable performance against existing dedicated real-time methods. Our key contributions are: – We first develop (i) a feature alignment module that learns transformation offsets of pixels to contextually align up-sampled (higher-level) features; and (ii) another feature se-lection module to emphasize (lower-level) features with rich spatial details. – With the integration of these two contributions, we present, Feature-aligned Pyramid Network (FaPN), an en-hanced drop-in replacement of FPN [23], for generating multi-scale features. – We present a thorough experimental evaluation demon-strating the efficacy and value of each component of FaPN across four dense prediction tasks, including object detec-tion, semantic, instance, and panoptic segmentation on three benchmark datasets, including MS COCO [24], Cityscapes
[9], COCO-Stuff-10K [3]. – Empirically, we demonstrate that our FaPN leads to a sig-nificant improvement of 1.2% - 2.6% in performance (AP / mIoU) over the original FPN [23]. Furthermore, our FaPN achieves the state-of-the-art of 56.7% mIoU on ADE20K when integrated within MaskFormer [8]. 2.