Abstract
This paper presents a neural network built upon Trans-formers, namely PlaneTR, to simultaneously detect and re-construct planes from a single image. Different from pre-vious methods, PlaneTR jointly leverages the context in-formation and the geometric structures in a sequence-to-sequence way to holistically detect plane instances in one
Specifically, we represent the geometric forward pass. structures as line segments and conduct the network with three main components: (i) context and line segments en-coders, (ii) a structure-guided plane decoder, (iii) a pixel-wise plane embedding decoder. Given an image and its detected line segments, PlaneTR generates the context and line segment sequences via two specially designed encoders and then feeds them into a Transformers-based decoder to directly predict a sequence of plane instances by simulta-neously considering the context and global structure cues.
Finally, the pixel-wise embeddings are computed to assign each pixel to one predicted plane instance which is near-est to it in embedding space. Comprehensive experiments demonstrate that PlaneTR achieves state-of-the-art perfor-mance on the ScanNet and NYUv2 datasets. 1.

Introduction
Recovering 3D planar structures from a single RGB im-age is a fundamental problem in 3D vision and is challeng-ing due to its ill-posed nature. The goal of this problem is to detect regions of plane instances and estimate their 3D pla-nar parameters (e.g. surface normal and offset) in an image.
As a fundamental representation of 3D scenes, the recon-structed planes have a wide range of applications in down-stream tasks, such as augmented reality [4], visual SLAM
[30, 44, 20] and indoor scene understanding [31, 16].
Some early methods [6, 2, 21, 15, 25] tend to utilize ge-ometric elements such as line segments, junctions, and van-∗Equal Contribution.
†Correspondence Author.
Figure 1. Illustration of the proposed PlaneTR. Our network holis-tically leverages context features and line segments represented by two tokenized sequences to predict a set of plane instances in an image. ishing points to tackle this problem in a bottom-up manner.
These geometric elements are usually first divided into var-ious groups and then carefully analyzed under a series of strict presuppositions (e.g. Manhattan World) and rules to recover 3D planes. Although these structure-based methods have achieved successes to some extent, they are suffering from the issues of missing or incorrect detection of geo-metric primitives, complex technique processes, and limited scenes which affect their performance and applications.
Recently, Convolutional Neural Networks (CNNs) ad-dressed this problem [19, 43, 18, 45, 11, 24]. Some meth-ods [19, 43, 18] directly predict plane instance masks with corresponding 3D planar parameters from the input im-age in a top-down manner. By contrast, PlaneAE [45] takes a bottom-up manner and achieves plane instances by clustering pixels that are similar in an embedding space.
These methods relax constraints in structure-based meth-ods and have achieved promising performance. However, they mainly leverage the context information from CNNs and ignore structure cues in the image which are useful for 3D plane recovery.
In this paper, we are interested in exploiting geometric structures for the problem of 3D plane recovery of the in-door scene under a learning-based framework. Although there are various low-level geometric primitives, we find that line segments are usually used to construct 3D planes
[16, 25] and contain more holistic 3D information of the scene when comparing with other geometric primitives,
such as feature points, edges, and vanishing points. Be-sides, benefiting from recent state-of-the-art works in line segment detection [42, 40, 41, 47], it is convenient for us to achieve line segments from an image. Thus, in this paper, we use line segments as the geometric structures for plane recovery.
In some recent works [35, 12], geometric structures have already been used for depth and normal estimation. In these methods, structures are represented as dense maps (e.g. line segment map) to meet the representation of CNNs. How-ever, such dense representation of structures is hard for the network to leverage global structure cues with two draw-backs: (i) limited receptive field of CNNs and (ii) sparse distribution of structure pixels in the dense map. Although
CNNs-based attention mechanisms [36, 38] can alleviate the first drawback, the second one is still hard to be well tackled. Therefore, this paper is going toward answering the question:
If it is possible to holistically exploit sparse line segments for the learning of plane recovery?
Most recently, the sequence-to-sequence model of
Transformers [32] has been successfully used in vision tasks
[3, 39]. In these works, the input features and output targets are represented as visual tokens and globally interacted with each other via the attention mechanism of Transformers.
Motivated by the tokenized representation in vision Trans-formers, we address the above question by proposing our
PlaneTR, a Transformer model that leverages the informa-tive context features and meaningful geometric structures for plane recovery.
For a given input image and its detected line segments, our PlaneTR encodes the line segments and context features into two sets of tokenized sequences, respectively. Then, a set of learnable plane queries are used to holistically in-teracted with the context and line segment sequences via a structure-guided plane decoder which outputs a set of tok-enized plane instances. As a final step, we design a simple instance-to-pixel segmentation strategy motivated by the as-sociative embedding [22] and PlaneAE [45], which yields the pixel-wise plane segmentation results by assigning each pixel to its nearest plane instance in the embedding space.
In summary, the main contributions of this paper are as follows:
• We leverage line segments as tokenized sequences in-stead of dense maps to guide the learning of 3D plane recovery with geometric structures.
• We develop a novel Transformer, PlaneTR, to simulta-neously detect and reconstruct plane structures from a single image in a sequence-to-sequence manner.
• Our method obtains state-of-the-art performance on the ScanNet [5] and NYUv2 [28] datasets, verifying the effectiveness of our method. 2.