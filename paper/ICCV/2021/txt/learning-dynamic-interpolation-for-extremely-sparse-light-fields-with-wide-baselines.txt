Abstract
In this paper, we tackle the problem of dense light field (LF) reconstruction from sparsely-sampled ones with wide baselines and propose a learnable model, namely dy-namic interpolation, to replace the commonly-used geome-try warping operation. Specifically, with the estimated ge-ometric relation between input views, we first construct a lightweight neural network to dynamically learn weights for interpolating neighbouring pixels from input views to synthesize each pixel of novel views independently. In con-trast to the fixed and content-independent weights employed in the geometry warping operation, the learned interpo-lation weights implicitly incorporate the correspondences between the source and novel views and adapt to differ-ent image content information. Then, we recover the spa-tial correlation between the independently synthesized pix-els of each novel view by referring to that of input views using a geometry-based spatial refinement module. We also constrain the angular correlation between the novel views through a disparity-oriented LF structure loss. Experimen-tal results on LF datasets with wide baselines show that the reconstructed LFs achieve much higher PSNR/SSIM and preserve the LF parallax structure better than state-of-the-art methods. The source code is publicly available at https://github.com/MantangGuo/DI4SLF. 1.

Introduction
Densely-sampled light field (LF) images record not only appearance but also geometry information of 3D scenes, which enable wide applications, such as 3D reconstruction
[30, 24, 3], image post-refocusing [20], and virtual reality
[7, 38]. However, densely-sampled LFs raise great chal-lenges for the acquisition. For example, camera array [33] or computer-controlled gantry [29] are either bulky and ex-This work was supported by the Hong Kong RGC under grants CityU 21211518 and 11218121. Corresponding author: Junhui Hou
*Equal Contributions
Figure 1. Comparison of the commonly-used warping operation and the proposed dynamic interpolation. In contrast to the fixed and content-independent weights employed in the warping opera-tion (taking bilinear interpolation weights as an example), we pro-pose to dynamically learn geometry-aware and content-adaptive interpolation weights from carefully constructed embeddings. pensive or limited in capturing static scenes, while cost-effective commercial LF cameras [17, 21] suffer from a trade-off between the spatial and angular resolution due to the limited sensor resolution [8, 9].
Although many computational methods have been pro-posed to reconstruct densely-sampled LFs from sparsely-sampled ones, the wide baseline between input views re-mains a great challenge. To be more specific, non-depth-based methods [23, 37, 35, 31, 36, 4, 5] investigate the im-plicit signal distribution of LF data to learn the mapping from sparse to dense LFs. These methods inevitably suffer from the aliasing problem and lead to artifacts when the LF is extremely under-sampled.
In comparison, depth-based methods [32, 12, 34, 11, 10] perform much better by em-ploying the explicit geometry information. These methods follow the general pipeline of warping-based view synthe-sis, and mainly focus on improving the disparity estimation and post-processing refinement. However, the reconstruc-tion quality is still limited.
In this paper, we tackle the challenging problem of LF reconstruction from extremely sparse and wide-baseline in-puts, based on an insight that commonly-used warping operation confronts with natural limitations. Specifically, the warping operation synthesizes pixels of the novel view by performing interpolation using their neighboring pixels from input views. The employed interpolation weights are determined by fitting a simple and smooth curve using a small set of neighbors, which inevitably impacts the re-construction quality as the content information is not con-sidered. To this end, we propose a learnable module, namely dynamic interpolation, to replace the commonly-used warping operation. As shown in Fig. 1, dynamic in-terpolation uses a lightweight neural network to dynami-cally predict geometry-aware and content-adaptive inter-polation weights for novel view synthesis. As the pixels of the novel views are independently synthesized, we sub-sequently recover the spatial correlation between them by referring to that of input views using a geometry-based re-finement module. We also constrain the angular correla-tion between the novel views through a disparity-oriented
LF structure loss. Extensive experimental results demon-strate the significant superiority of the proposed model on
LF datasets with wide baselines over warping-based meth-ods as well as other state-of-the-art ones.
In summary, the main contributions of this paper are as follows:
• we deeply analyze the geometry warping operation for handling the challenge of LF reconstruction from wide-baseline inputs, and figure out the essential limi-tation lies in the weakness of the interpolation weights; and
• we reformulate the LF reconstruction from a new per-spective and propose dynamic interpolation, which is capable of overcoming the limitation of the geometry warping operation. 2.