Abstract
Autonomous driving has attracted much attention over the years but turns out to be harder than expected, proba-bly due to the difficulty of labeled data collection for model training. Self-supervised learning (SSL), which leverages unlabeled data only for representation learning, might be a promising way to improve model performance. Existing
SSL methods, however, usually rely on the single-centric-object guarantee, which may not be applicable for multi-instance datasets such as street scenes. To alleviate this limitation, we raise two issues to solve: (1) how to define positive samples for cross-view consistency and (2) how to measure similarity in multi-instance circumstances. We first adopt an IoU threshold during random cropping to transfer global-inconsistency to local-consistency. Then, we pro-pose two feature alignment methods to enable 2D feature maps for multi-instance similarity measurement. Addition-ally, we adopt intra-image clustering with self-attention for further mining intra-image similarity and translation-invariance. Experiments show that, when pre-trained on
Waymo dataset, our method called Multi-instance Siamese
Network (MultiSiam) remarkably improves generalization ability and achieves state-of-the-art transfer performance on autonomous driving benchmarks, including Cityscapes and BDD100K, while existing SSL counterparts like MoCo,
MoCo-v2, and BYOL show significant performance drop.
By pre-training on SODA10M, a large-scale autonomous driving dataset, MultiSiam exceeds the ImageNet pre-trained MoCo-v2, demonstrating the potential of domain-specific pre-training. Code will be available at https:
//github.com/KaiChen1998/MultiSiam. 1.

Introduction
Autonomous driving has attracted much attention over the years [19, 15, 32]. However, it becomes harder than people have expected in such an age of AI advances. Fully autonomous cars are still out of reach except in special trial programs, mainly due to the limitation of model per-Figure 1. Visualizations of different random crops on
Waymo [20] (left) and ImageNet [9] (right). On ImageNet, im-ages are small and pre-processed to guarantee only one object in the center part of it (i.e., single-centric-object) mostly. However, images from Waymo are of high resolution and contain multiple instances. Different random crops might represent different se-mantic meanings (i.e., global-inconsistency), which will restrict the effectiveness of current self-supervised learning methods. formance. One of the main restrictions is that the annota-tion cost of self-driving datasets is much more expensive than other datasets. Considering that autonomous cars keep collecting unlabeled data when operating, self-supervised learning (SSL) might be a promising way to ease the de-sire for labeled data and improve model performance, which has achieved remarkable transfer results on different down-stream tasks using unlabeled data only.
Existing SSL methods are mainly based on the pretext called instance discrimination and cross-view consistency framework, whose basic assumption is that different views (e.g. data augmentation) of a single image should be con-sistent in the feature space under different metrics, such as cosine distance [10, 7], clustering assignments [4] and dis-criminability from negative samples [27, 21, 5, 12, 6, 18],
This assumption is satisfied well with single-centric-object datasets such as ImageNet. In self-driving, nevertheless, the
data are usually high-resolution images containing multiple instances on a single image (see Figure 1 for an illustration).
Here we define instance as any individual object regardless of its semantic class following Wu et al. [27]. In this case, different crops may correspond to different instances and represent different semantic meanings, which results in the global-inconsistency of multi-instance images. The effec-tiveness of instance discrimination and cross-view consis-tency can no longer be guaranteed.
To adapt current instance discrimination and cross-view consistency framework to multi-instance circumstances, we need to solve two problems: (1) how to define positive samples for cross-view consistency and (2) how to calcu-late the similarity of two randomly generated views within multi-instance images. Considering the locality of images, we first add an IoU threshold during random cropping as a proxy to control the two views not too far from each other
In and transfer global-inconsistency to local-consistency. order to distinguish different instances, we maintain the fi-nal 2D feature maps of the backbone networks and propose the RoI alignment and offset alignment to solve the feature misalignment introduced by it (see Figure 4(a)), which is usually neglected when global pooling layers are adopted.
Moreover, we observe a hierarchy of clusters existing in multi-instance circumstances naturally, so to model the re-lationships between instances, we perform clustering within a single image not for inter-image similarity [2, 4], but for further mining intra-image similarity. To ease the ambigu-ity of cluster assignments, we deploy a self-attention mech-anism with the predictor for more precise cluster prediction.
Translation-invariance is also enhanced in the learned rep-resentation, which is beneficial for downstream pixel-level visual tasks like semantic segmentation.
The main contributions of this work contain three parts: 1. We propose the Multi-instance Siamese Network (MultiSiam) for extending the cross-view consistency framework to multi-instance circumstances by dealing with positive sample definition and similarity measure-ment of 2D feature maps. 2. Experiments on Cityscapes [8] and BDD100K [31] show that MultiSiam pre-trained on Waymo [20] has stronger generalization ability to multi-instance datasets and achieves state-of-the-art transfer perfor-mance on downstream autonomous driving bench-marks compared with MoCo, MoCo-v2 and BYOL.
Moreover, MultiSiam pre-trained on SODA10M [11], a large-scale autonomous driving dataset, exceeds the
ImageNet pre-trained MoCo-v2, revealing the poten-tial of domain-specific pre-training. 3. To the best of our knowledge, our work is the first to perform self-supervised learning on large-scale high-resolution multi-instance street scene datasets (e.g.
Waymo), which will be beneficial for empowering SSL in further autonomous driving research. 2.