Abstract
Weakly Supervised Semantic Segmentation (WSSS) based on image-level labels has been greatly advanced by exploiting the outputs of Class Activation Map (CAM) to generate the pseudo labels for semantic segmentation.
However, CAM merely discovers seeds from a small num-ber of regions, which may be insufficient to serve as pseudo masks for semantic segmentation. In this paper, we formu-late the expansion of object regions in CAM as an increase in information. From the perspective of information the-ory, we propose a novel Complementary Patch (CP) Rep-resentation and prove that the information of the sum of the CAMs by a pair of input images with complementary hidden (patched) parts, namely CP Pair, is greater than or equal to the information of the baseline CAM. Therefore, a CAM with more information related to object seeds can be obtained by narrowing down the gap between the sum of CAMs generated by the CP Pair and the original CAM.
We propose a CP Network (CPN) implemented by a triplet network and three regularization functions. To further im-prove the quality of the CAMs, we propose a Pixel-Region
Correlation Module (PRCM) to augment the contextual in-formation by using object-region relations between the fea-ture maps and the CAMs. Experimental results on the PAS-CAL VOC 2012 datasets show that our proposed method achieves a new state-of-the-art in WSSS, validating the ef-fectiveness of our CP Representation and CPN. 1.

Introduction
Thanks to the booming of deep learning methods, recen-t years have witnessed extraordinary progress in semantic segmentation [28, 43, 7, 8]. However, the prerequisite of a successful neural network for semantic segmentation is pixel-level segmentation ground-truth, which requires mas-sive investments in manual annotation. Numerous efforts have been devoted to developing Weakly Supervised Se-mantic Segmentation (WSSS) to ease the pressure, which
∗Corresponding author
Figure 1. Illustration of our proposed method. The original CAM simply finds object seeds in most discriminative regions. To en-large the seed areas, our Complementary Patch Network (CPN) uses a pair of images with CP regions (CP Pair) to generate two
CAMs, the sum of which are supposed to incorporate more infor-mation of the foreground than the original CAM. aims to train a semantic segmentation network by using weaker supervision, such as image-level classification la-bels [22, 5, 2, 3], bounding boxes [21, 10], scribbles [27] and points [4]. Image-level labels, as the most conveniently-acquired annotation format, have been extensively studied in WSSS. In this work, we particularly focus on WSSS us-ing image-level labels.
Most WSSS approaches generating initial seeds through image-level labels heavily rely on an efficient method—
Class Activation Map (CAM) [45]. Nevertheless, this archi-tecture appears to be barely sensitive to the most discrimina-tive regions, resulting in many incomplete foreground areas.
To address the issue, a promising way is to erase or ignore some high response regions to help CAM ’see’ more seeds in an image [36, 24, 23, 9], i.e., region erasing or mining methods. However, these methods are more or less losing part of the regions of an image in each training epoch due to the randomness of the hiding process. It seems to be effec-tive to intentionally cover the high response areas identified from the CAM in each training epoch, while such iterative operation introduces much computational complexity, and it is difficult to properly determine the number of iterations for each image as well.
In this paper, we show that CAM could explore more high response areas by taking full advantage of the in-formation of an image, specifically including both uncov-ered and hidden parts. Based on the motivation, we treat the task of expanding object seeds in CAM as an in-crease in information, and develop a simple yet efficient concept—Complementary Patch (CP) Representation: the self-information of the CAM of an image is less than or e-qual to the sum of the self-information of the CAMs, which are obtained by CP Pair, namely two images with CP re-gions. Therefore, an improved CAM could be obtained by adding up the CAMs generated by the CP Pair (shown in
Fig. 1). In addition, we show that the equality holds under two extreme cases. One is that if the patch size is too large, one of the CP Pair equals the original image, and the other is that two images in the CP Pair are almost the same for the network if the patch size is too small. Under these extreme conditions, the CP Pair is unable to seek out new seed areas compared to the original image. Thus the degree of the in-crease in information (object seeds) is subject to the patch size for the CP Pair.
Building upon the CP Representation, we propose a CP
Network (CPN) to narrow down the gap between the im-proved CAM mentioned above and the one by the original image. CPN is formed by a triplet network with Triplet CP (TCP) loss and CP Cross Regularization (CPCR) loss, serv-ing as minimizing the above discrepancy. For the generation of the CP Pair, we propose to use grid (Grid Patch) or super-pixel (Super-pixel Patch) as the patch template. Further-more, CPN introduces a Pixel-Region Correlation Module (PRCM), which aims to capture the relationship between the pixels and regions, and incorporates it with Pixel Corre-lation Module (PCM) [35] to further improve the consisten-cy of the predicted CAM.
Extensive experiments conducted on PASCAL VOC 2012 [13] demonstrate the effectiveness of our CPN. As a result, our model yields a new state-of-the-art performance by 67.8% and 68.5% on the val set and test set. Further-more, we notice that the performance of our CPN is influ-enced by the patch size, which is in accordance with our analysis of the CP Representation in extreme cases.
Our main contributions are summarized as three-fold:
• We propose a simple yet effective Complementary
Patch (CP) representation to enlarge the seed regions in CAM, which narrows down the gap between the o-riginal CAM and the CAMs by summing up the CAMs of the CP pair.
• Building upon the CP representation, we present a triplet network (CPN) with Triplet CP (TCP) loss and
CP Cross Regularization (CPCR). Moreover, a Pixel-Region Correlation Module (PRCM) is proposed to further refine the CAM.
• Experimental results on the PASCAL VOC 2012 show that our proposed framework achieves state-of-the-art performance in WSSS. 2.