Abstract
In open set recognition, a classiﬁer has to detect un-known classes that are not known at training time. In or-der to recognize new categories, the classiﬁer has to project the input samples of known classes in very compact and separated regions of the features space for discriminating samples of unknown classes. Recently proposed Capsule
Networks have shown to outperform alternatives in many
ﬁelds, particularly in image recognition, however they have not been fully applied yet to open-set recognition. In cap-sule networks, scalar neurons are replaced by capsule vec-tors or matrices, whose entries represent different proper-ties of objects. In our proposal, during training, capsules features of the same known class are encouraged to match a pre-deﬁned gaussian, one for each class. To this end, we use the variational autoencoder framework, with a set of gaussian priors as the approximation for the posterior dis-tribution. In this way, we are able to control the compact-ness of the features of the same class around the center of the gaussians, thus controlling the ability of the classiﬁer in detecting samples from unknown classes. We conducted several experiments and ablation of our model, obtaining state of the art results on different datasets in the open set recognition and unknown detection tasks. 1.

Introduction
Over the past decade, deep learning has become the dom-inant approach in many computer vision problems, achiev-ing spectacular results on many visual recognition tasks
[13, 27, 7, 29]. However, most of these results have been obtained in a closed set scenario, where a critical assump-tion is that all samples should belong to at least one labeled category. When observing a sample from an unknown cat-egory, closed-set approaches are forced to choose a class label from one of the known classes, thus limiting their ap-plicability in dynamic and ever-changing scenarios.
∗Indicates equal contributions.
Figure 1: CVAECapOSR Model. Input samples are fed into the Capsule Network that produces distributions over the latent space. Each class has its own prior gaussian distribu-tion in the feature space, that in the ﬁgure are represented as spheres. After training, the known samples (represented as small points) are clustered around the class target gaussians.
The samples belonging to unknown classes are represented as black triangles, far from the target distributions.
To overcome such a limitation, open set recognition has been introduced to enable a classiﬁcation system to iden-tify all of known categories, while simultaneously detect-ing unknown test samples [25, 1]. In the open set scenario, samples included/excluded in label space are referred to as knowns/unknowns. Therefore, open set classiﬁers need to use incomplete knowledge learned from a ﬁnite set of acces-sible categories to devise effective representations able to separate knowns from unknowns. Early works have identi-ﬁed this issue, thus proposing methods employing different thresholding strategies for rejection of unknowns [25, 1].
Deep neural networks, despite demonstrating strong capabilities in learning discriminative representations in closed scenarios, show accuracy degradation within open set settings [2]. As a naive strategy, modeling a thresh-1
old for Softmax outputs has been demonstrated to be a sub-optimal solution for deep neural networks to identify unknowns. Thus the Extreme Value Theory was intro-duced to better adapt these discriminative models, fully based on supervised learning, for open-set settings. The underpinning idea is to calibrate Softmax scores so to es-timate the probability of unknowns [32, 2]. In addition to deep discriminative models, deep generative models focus-ing on learning efﬁcient latent feature representations by unsupervised leaning, have been widely utilized in open-set recognition tasks, and have gained successes one after the other [16, 19, 21, 28].
In particular, The Variational
Auto-Encoder (VAE) is a typical probabilistic generative model ideal for detecting unknowns, due to its ability in learning low-dimensional representations in latent space not only supporting input reconstruction but also approximating a speciﬁed prior distribution. On the other hand, the VAE-based models may be not sufﬁciently effective for identi-fying known categories as all feature representations only follow one distribution. To this end, we employ a Condi-tional VAE (CVAE) that uses multiple prior distributions for modeling the known classes, and indirectly the unknown counterpart. Furthermore, we propose to represent the in-put samples with probabilistic capsules, given their already proved representation power capability [22, 24].
Capsule Networks (CapsNet) [24] were proposed as an alternative to Convolutional Neural Networks (CNNs). Un-like CNNs’ scalar neurons, capsules ensemble a group of neurons to accept and output vectors. The vector of an ac-tivated capsule represents the various properties of a partic-ular object, such as position, size, orientation, texture, etc.
In essence, CapsNet can be viewed as an encoder encod-ing objects by distributed representations, which is expo-nentially more efﬁcient than encoding them by activating a single neuron in a high-dimensional space. Besides, Cap-sNet has been successfully used to detect fake images and videos in a task setting similar to open set recognition [18].
This motivated us to design a novel capsule network archi-tecture in combination with CVAE for the open set recog-nition problem, dubbed CVAECapOSR, that is depicted in
Figure 1.
The contributions of this paper are three-fold: i) We present a novel open set recognition framework based on
CapsNet and show its advantages for learning an efﬁcient representation for known classes. ii) We integrate CapsNet and conditional VAEs. In contrast to general VAEs that en-courage the latent representation to approximate a single prior distribution, our model exploits multiple priors (i.e. one for each class), and it forces the latent representation to follow the gaussian prior selected by the class of the input iii) We conduct extensive experiments on all the sample. standard datasets used for open set recognition, obtaining very competitive results, that in several cases outperform previous state of the art methods by a large margin. 2.