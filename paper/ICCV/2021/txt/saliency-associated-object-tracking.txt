Abstract
Most existing trackers based on deep learning perform tracking in a holistic strategy, which aims to learn deep rep-resentations of the whole target for localizing the target. It is arduous for such methods to track targets with various appearance variations. To address this limitation, another type of methods adopts a part-based tracking strategy which divides the target into equal patches and tracks all these patches in parallel. The target state is inferred by summa-rizing the tracking results of these patches. A potential lim-itation of such trackers is that not all patches are equally informative for tracking. Some patches that are not discrim-inative may have adverse effects. In this paper, we propose to track the salient local parts of the target that are discrimi-native for tracking. In particular, we propose a ﬁne-grained saliency mining module to capture the local saliencies. Fur-ther, we design a saliency-association modeling module to associate the captured saliencies together to learn effective correlation representations between the exemplar and the search image for state estimation. Extensive experiments on
ﬁve diverse datasets demonstrate that the proposed method performs favorably against state-of-the-art trackers. 1.

Introduction
Visual object tracking aims to predict the target states in a tracking sequence given the initial state of the tar-get object in the ﬁrst sequence frame. It is a fundamental research topic in Computer Vision and has a wide range of applications including video surveillance, robotics, and motion analysis. Although deep trackers [6, 36, 38, 44], which beneﬁt from excellent feature learning for images by deep neural networks, have achieved great progress in re-cent years, tracking targets with various real-time appear-ance variations, such as deformation, occlusion, and view-point changes, etc., remains an extremely challenging task.
A classical type of deep tracking approaches [2, 7, 25, 49] performs tracking in a holistic strategy, which seeks to
*Corresponding authors.
Figure 1. Given a search image in a tracking sequence, our SAOT
ﬁrst captures local saliencies (yellow dots) of the target that are discriminative for tracking, and then associates the captured saliencies together to learn precise correlations between the target exemplar and the search image for reﬂecting target states. Thus, our model can generate more precise correlation features than
DW-Corr [25] (in the holistic tracking strategy) and PG-Corr [32] (in the part-based strategy), and accordingly predict more precise bounding boxes. The correlation features are visualized by aver-aging all channels (red color indicates higher correlation). Larger-size salient dots indicate higher saliency values. learn a precise deep feature representation for the whole target object and then localize the target in the search im-age. A prominent example is the Siamese-based track-ers [1, 25, 26, 29, 39], which learn deep representations for both the target exemplar and the search image in the same feature space by a Siamese neural network, and then perform target tracking by feature matching between them.
Such methods perform well in ordinary scenarios in which the target keeps stable appearances close to the exemplar, but struggle in the challenging scenarios where the target varies substantially. This is because the global appearance gap between the target exemplar and the target state in the search image results in an inevitable tracking error. The online learning trackers [8, 18, 38], which are another typi-cal type of methods, are designed to adapt to the appearance
variations of the target by learning an online ﬁlter. However, these methods still perform tracking in the holistic strategy and thus can hardly deal with drastic appearance variations.
In contrast to the holistic tracking strategy, another type of existing tracking methods [32, 34, 46, 48] adopts the part-based strategy, which ﬁrst tracks local parts of the target object and then infers the target state by summarizing the tracking results of these parts. A common way of these part-based methods is to partition the target into regular patches equally and then perform tracking on all these patches in parallel. Whilst such a part-based tracking strategy miti-gates the difﬁculties of tracking appearance-varying targets, a potential limitation is that not all the partitioned patches are equally informative for tracking. Some parts which are not discriminative are difﬁcult to be tracked and may have adverse effects on inferring the global target state.
In this paper, we follow the part-based tracking strat-egy and propose the Saliency-Associated Object Tracker (SAOT). The key difference between our SAOT and other part-based tracking methods is that SAOT focuses on cap-turing and tracking the local saliencies of the target that are discriminative for tracking instead of simply tracking all partitioned patches in parallel. Speciﬁcally, we design a ﬁne-grained saliency mining mechanism to capture local saliencies in the target that are discriminative and easily lo-calized in the search image. Subsequently, these captured saliencies are associated together by modeling the interac-tions between them to learn global correlations between the target exemplar and the search image, which can reﬂect the target state in the search image precisely.
The rationales behind such design of our SAOT are: 1) the salient local regions in the target, which are tracked more precisely and easily than other regions, can potentially keep consistent distinctiveness in various appearance vari-ations; 2) different associations between the saliencies cor-respond to different appearances of the same target, so that we model the associations between the captured saliencies to adapt to real-time appearance variations. Consequently, our SAOT is able to cope with various appearance variations of the target during tracking, such as deformation and occlu-sion. Figure 1 presents an example of tracking a gymnast, in which the appearance of the gymnast varies substantially during display. Owing to the captured saliencies robust to appearance variations, the bounding boxes predicted by our model are much more precise than those predicted based on
DW-Corr [25] and PG-Corr [32], which are in the holistic strategy and the part-based strategy, respectively.
The tracking strategy of the proposed SAOT, which ﬁrst deals with local saliencies with high conﬁdence and then as-sociates them together to achieve the global solution, is akin to the divide-and-conquer algorithm. To conclude, we make the following contributions: 1) A ﬁne-grained saliency min-ing module is designed to capture local saliencies in the target which are discriminative for tracking. 2) We pro-pose a saliency-association modeling module to associate the captured saliencies together to learn effective global correlations between the exemplar and the search image. 3) We achieve favorable performance against state-of-the-art methods in both quantitative and qualitative evaluations on ﬁve benchmarks (OTB2015, NFS30, LaSOT, VOT2018, and GOT10k), demonstrating the effectiveness of our SAOT. 2.