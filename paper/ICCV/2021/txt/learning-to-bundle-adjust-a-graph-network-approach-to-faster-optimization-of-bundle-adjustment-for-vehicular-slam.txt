Abstract
Bundle adjustment (BA) occupies a large portion of the execution time of SfM and visual SLAM. Local BA over the latest several keyframes plays a crucial role in visual
SLAM. Its execution time should be sufficiently short for ro-bust tracking; this is especially critical for embedded sys-tems with a limited computational resource. This study pro-poses a learning-based bundle adjuster using a graph net-work. It works faster and can be used instead of conven-tional optimization-based BA. The graph network operates on a graph consisting of the nodes of keyframes and land-marks and the edges representing the landmarks’ visibility.
The graph network receives the parameters’ initial values as inputs and predicts their updates to the optimal values.
It internally uses an intermediate representation of inputs which we design inspired by the normal equation of the
Levenberg-Marquardt method. It is trained using the sum of reprojection errors as a loss function. The experiments show that the proposed method outputs parameter estimates with slightly inferior accuracy in 1/60–1/10 of time com-pared with the conventional BA. 1.

Introduction
Structure-from-Motion (SfM) and visual SLAM (simul-taneous localization and mapping) have been successfully used in many real-world applications of computer vision, robotics, augmented reality, and related areas [25, 29]. To improve the accuracy and robustness of 3D reconstruction, researchers have considered several different approaches, such as feature-point-based methods [27], direct methods
[7], learning-based methods [24, 23], and their hybrids [3].
Among these, the feature-point-based methods are cur-∗These authors contributed equally to this work.
Figure 1. Limiting the computational time budget for local BA results in frequent tracking failures. Left: Without a limit. Right:
With a limit. See the text for details. rently the most widely used. Visual SLAM is often used in embedded systems with limited computational resources, narrowing choices to those using light-weight feature de-scriptors, such as ORB-SLAM [16, 17]. Many SfM systems also use feature-point-based methods; they are used to es-timate camera poses for the subsequent step of multi-view stereo, in which the dense surfaces of objects/scenes are re-constructed.
Although it is comparatively smaller, the feature-point-based methods still have a high computational cost. What dominates in their execution time is the step of bundle ad-justment (BA). It optimizes the unknown parameters, the 3D positions of the landmarks associated with the feature points and camera poses, refining their initial values to get accurate estimates. This step is usually the bottleneck in terms of the speed of visual SLAM and SfM systems. Tak-ing ORB-SLAM, for instance, it frequently performs BA locally over several keyframes and their associated land-marks, maintaining the accuracy of the most recent recon-struction. BA occupies roughly 60–80% of the execution time needed for the mapping operation.
More importantly, the speed of local BA determines
the robustness of SLAM systems. Keyframe-based SLAM systems such as ORB-SLAM can track landmarks more stably when there are spatially denser keyframes. ORB-SLAM employs the strategy of issuing more than sufficient keyframes and culling unnecessary ones later. However, a new keyframe cannot be created while local BA is running due to the causality. Thus, the ability to complete local BA quickly is necessary for issuing keyframes densely, and it is a basis for robust SLAM. This requirement is more criti-cal for embedded systems having low-speed processors. A remedy is to set a limit on the computational budget for lo-cal BA to balance the accuracy of SLAM and the robustness of tracking. For example, we can set the maximum iteration counts for local BA. However, this does not work well in practice, as shown in Figure 1.
In this paper, we consider a learning-based method that can perform BA more quickly. BA is essentially nonlin-ear minimization of the sum of squares, and conventionally the Levenberg-Marquardt method is employed. The method iteratively solves a linear equation to obtain a small param-eter update and updates the parameters until convergence.
When regarding the entire process as a black-box, which receives initial parameter values and outputs their optimal values, we replace it with computation by a graph network
[30, 28]. To be specific, we train the graph network with a set of input-output pairs for some videos, i.e., the initial values fed to BA and their optimized values, aiming at com-puting the optimal parameter values in a shorter time.
We report the results of our experiments focusing on monocular SLAM, in which we used OpenVSLAM [22] as a testbed and evaluate the method on the KITTI dataset
[8].
In the experiments, we trained our graph network on a few sequences from the dataset and tested it on the other sequences. We create training samples by the con-ventional BA’s inputs (i.e., g2o [13]) applied to the train-ing sequences. Using them, we train the graph network us-ing the sum of reprojection errors as a loss. Our method achieved slightly lower accuracy with 1/60–1/10 of compu-tational time compared with the original BA. 2.