Abstract
Shape correspondence from 3D deformation learning has attracted appealing academy interests recently. Nev-ertheless, current deep learning based methods require the supervision of dense annotations to learn per-point trans-lations, which severely over-parameterize the deformation process. Moreover, they fail to capture local geometric de-tails of original shape via global feature embedding. To address these challenges, we develop a new Unsupervised
Dense Deformation Embedding Network (i.e., UD2E-Net), which learns to predict deformations between non-rigid shapes from dense local features. Since it is non-trivial to match deformation-variant local features for deformation prediction, we develop an Extrinsic-Intrinsic Autoencoder to first encode extrinsic geometric features from source into intrinsic coordinates in a shared canonical shape, with which the decoder then synthesizes corresponding target features. Moreover, a bounded maximum mean discrep-ancy loss is developed to mitigate the distribution diver-gence between the synthesized and original features. To learn natural deformation without dense supervision, we introduce a coarse parameterized deformation graph, for which a novel trace and propagation algorithm is proposed to improve both the quality and efficiency of the deforma-tion. Our UD2E-Net outperforms state-of-the-art unsuper-vised methods by 24% on Faust Inter challenge and even supervised methods by 13% on Faust Intra challenge. 1.

Introduction
Alignment of deformable 3D shapes is a ubiquitous chal-lenge in the field of computer vision and graphics with
∗The corresponding author is Prof. Yang Cong.
†This work is supported in part by the National Key Research and De-velopment Program of China under Grant 2019YFB1310300 and the Na-tional Nature Science Foundation of China under Grant 61821005.
Figure 1. Illustration of our UD2E-Net model, which achieves the bidirectional mapping between extrinsic feature space and intrin-sic coordinate space for dense deformation embedding. many applications, including non-rigid reconstruction, de-formation transfer and texture mapping. Traditional meth-ods [33, 23] infer parametric deformation by optimizing correspondences construction and objective minimization iteratively. However, the optimization heavily depends on initialization and is prone to being stuck in local minima, especially for large articulated deformations. With the ad-vent of 3D deep learning techniques [28, 29], deep de-formation learning methods [13, 14, 39, 43, 21] leverag-ing a large amount of data have been applied for large deformation prediction. Generally, these techniques di-rectly regress dense translations or positions for all input 3D points, which neglects the implicit deformation disciplines and severely over-parameterizes the deformation leading to high-frequency artifacts. Unfortunately, these approaches require strong supervision of dense correspondences (e.g., usually more than 5000 per human body shape), which con-sumes huge labor-intensive efforts.
Furthermore, most existing state-of-the-art methods [21, 13, 14, 5, 39, 44, 15] encode the target shape into a global feature for deformation learning, which neglects the low-level geometric details and fails to infer fine-grained defor-mation. To leverage local features for deformation predic-tion, connections between both sides should be established to enable feature communication, which is a challenging correspondence problem for deformable shapes.
To address these challenges, a new Unsupervised Dense
Deformation Embedding Network (i.e., UD2E-Net) en-dowed with the traditional Embedded Deformation (ED) technique [33] is designed to predict deformation between arbitrary source and target shape pairs. With the local rigid-ity regularization provided by ED, UD2E-Net can learn a more natural deformation space, which we expect to miti-gate the strong reliance of deep learning models on abun-dant annotated data. Moreover, our network employs dense local feature embedding and fusion to reason about de-formation parameters for each node within the deforma-tion graph constructed via ED. Specifically, with the fine-grained geometric features extracted via the Siamese mesh encoder, an Extrinsic-Intrinsic Autoencoder (EI-AE) is de-veloped to first encode source features into intrinsic coordi-nates of a shared canonical shape. With the coordinates, corresponding target features are synthesized via the de-coder. To minimize the distribution gap between the syn-thesized and original target features, we design a Bounded
Maximum Mean Discrepancy loss, which further provides the self-supervised guidance for canonical shape construc-tion. To eliminate artifacts caused by wrong adjacent re-lationships between the input shape and its deformation graph via Euclidean measure, a trace and propagation algo-rithm is developed to improve both efficiency and accuracy by leveraging a pre-constructed mesh hierarchy. Extensive experiments demonstrate that UD2E-Net shows stable per-formance under data volume reduction. On Faust bench-mark [1], the proposed UD2E-Net outperforms state-of-the-art unsupervised methods by 24%∼37% on Inter challenge, and shows 13% improvement on Intra challenge over super-vised methods. Furthermore, experiments also demonstrate the potential of our UD2E-Net in several challenging appli-cations, e.g., shape retrieval and human pose transfer.
In conclusion, the main contributions of our work are:
• A new Unsupervised Dense Deformation Embedding
Network (i.e., UD2E-Net) is developed to learn large articulated deformations between arbitrary shape pairs without supervision of ground-truth correspondences.
• We design an Extrinsic-Intrinsic Autoencoder to en-code extrinsic geometric features from source shape into a shared canonical shape, which is utilized to de-code corresponding synthesized target features. Mean-while, a bounded maximum mean discrepancy loss is introduced to mitigate the distribution divergence be-tween the synthesized and original target features.
• A trace and propagation algorithm is developed to avoid artifacts brought by incorrect node-to-vertex as-signment in Embedded Deformation, which improves both quality and efficiency of the deformation process. 2.