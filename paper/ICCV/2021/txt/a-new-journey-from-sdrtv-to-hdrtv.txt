Abstract
Nowadays modern displays are capable to render video content with high dynamic range (HDR) and wide color gamut (WCG). However, most available resources are still in standard dynamic range (SDR). Therefore, there is an urgent demand to transform existing SDR-TV contents into their HDR-TV versions. In this paper, we conduct an analy-sis of SDRTV-to-HDRTV task by modeling the formation of
SDRTV/HDRTV content. Base on the analysis, we propose a three-step solution pipeline including adaptive global color mapping, local enhancement and highlight genera-tion. Moreover, the above analysis inspires us to present a lightweight network that utilizes global statistics as guid-ance to conduct image-adaptive color mapping.
In addi-tion, we construct a dataset using HDR videos in HDR10 standard, named HDRTV1K, and select five metrics to eval-uate the results of SDRTV-to-HDRTV algorithms. Further-more, our final results achieve state-of-the-art performance in quantitative comparisons and visual quality. The code and dataset are available at https://github.com/ chxy95/HDRTVNet. 1.

Introduction
The resolution of television (TV) content has increased from standard definition (SD) to high definition (HD) and most recently to ultra-high definition (UHD). High dynamic range (HDR) is one of the biggest features of the latest TV generation. HDRTV1 content has much wider color space and higher dynamic range than SDR content, and HDRTV standard allows us to create images and videos that are closer to what we see in real life. While HDR display de-vices have become prevalent in daily life, most accessible resources are still in SDR format. Therefore, we need al-*indicates contribute equally. †Corresponding author. 1We add a suffix TV after HDR/SDR to indicate content in HDR-TV/SDR-TV format and standard. gorithms to convert SDRTV content to their HDRTV ver-sion. The task, denoted as SDRTV-to-HDRTV, is of great practical value, but received relatively less attention in the research community. The reason is mainly two-fold. First, existing HDRTV standards (e.g., HDR10 and HLG) have not been well defined until recent years. Second, there is a lack of large-scale datasets for training and testing. This work aims at promoting the development of this emerging area, by presenting the analysis of this problem, basic meth-ods, evaluation metrics and a new dataset.
SDRTV-to-HDRTV is a highly ill-posed problem. In ac-tual production, contents of SDRTV and HDRTV are de-rived from the same Raw file but are processed under dif-ferent standards. Thus, they have different dynamic ranges, color gamuts and bit-depths. To some extent, SDRTV-to-HDRTV is similar to image-to-image translation such as
Pixel2Pixel [11] and CycleGAN [37]. On the contrary, the task of LDR-to-HDR, which is similar in terms of name, has completely different connotations. LDR-to-HDR methods
[21, 26, 10, 24, 5] aim to predict the HDR scene luminance in the linear domain, which is closer to Raw file in essence.
SDRTV-to-HDRTV has recently been touched in Deep SR-ITM [19] and JSI-GAN [20], which try to solve the problem of joint super-resolution and SDRTV-to-HDRTV. Although the above-mentioned works are all related to SDRTV-to-HDRTV, they are not dedicated to this problem. We will detail these comments in Sec. 2 and Sec. 3.
This paper aims to address SDRTV-to-HDRTV based on deep understanding of this problem. We first provide a simplified formation pipeline for SDRTV/HDRTV content, which consists of tone mapping, gamut mapping, transfer function and quantization, as in Fig. 1(a). Based on the for-mation pipeline, we propose a solution pipeline, including adaptive global color mapping (AGCM), local enhancement (LE) and highlight generation (HG). For AGCM, we pro-pose a novel color condition block to extract global image prior and adapt different images. With only 1 × 1 filters, the network achieves the best performance with less parame-ters compared with other photo retouching methods such as
CSRNet [8], HDRNet [6] and Ada-3DLUT [35]. Besides, we adopt a commonly used ResNet-based network and a
GAN-based model for LE and HG, respectively.
To promote the progress of this new research area, we collect a new large-scale dataset, named HDRTV1K. We also select five evaluation metrics – PSNR, SSIM, SR-SIM [36], ∆EIT P [17] and HDR-VDP3 [25], to evaluate the mapping accuracy, structural similarity (SSIM and SR-SIM), color difference and visual quality, respectively.
Our contributions are four-fold: (1) We conduct a de-tailed analysis for SDRTV-to-HDRTV task by modeling the formation of SDRTV/HDRTV content. (2) We propose a three-step SDRTV-to-HDRTV solution pipeline and a cor-responding method, which performs best in quantitative and qualitative comparisons. (3) We present a novel global color mapping network based on color condition blocks. With about only 35K parameters, it can still achieve state-of-the-art performance. (4) We provide a HDRTV dataset and se-lect five metrics to evaluate SDRTV-to-HDRTV algorithms. 2. Preliminary