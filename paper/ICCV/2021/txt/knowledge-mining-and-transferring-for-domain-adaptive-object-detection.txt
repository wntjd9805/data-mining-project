Abstract
With the thriving of deep learning, CNN-based object de-tectors have made great progress in the past decade. How-ever, the domain gap between training and testing data leads to a prominent performance degradation and thus hin-ders their application in the real world. To alleviate this problem, Knowledge Transfer Network (KTNet) is proposed as a new paradigm for domain adaption. Speciﬁcally, KT-Net is constructed on a base detector with intrinsic knowl-edge mining and relational knowledge constraints. First, we design a foreground/background classiﬁer shared by source domain and target domain to extract the common attribute knowledge of objects in different scenarios. Second, we model the relational knowledge graph and explicitly con-strain the consistency of category correlation under source domain, target domain, as well as cross-domain conditions.
As a result, the detector is guided to learn object-related and domain-independent representation. Extensive experi-ments and visualizations conﬁrm that transferring object-speciﬁc knowledge can yield notable performance gains.
The proposed KTNet achieves state-of-the-art results on three cross-domain detection benchmarks. 1.

Introduction
Object detection is the task of identifying where and what the interested targets are in the image.
It is a key component of visual perception and scene understanding, and also the basic module of many advanced visual appli-cations, such as multi object tracking [47, 4, 53], behavior analysis [41, 2] and visual question answering [1, 39, 7].
With the development of deep learning, neural network-based models [32, 30, 31, 24, 5, 43, 42] have gradually re-placed traditional machine vision methods and become the mainstream algorithm in the ﬁeld of object detection. Al-though remarkable progress has been witnessed in modern
Computer Vision systems such as autonomous driving and intelligent surveillance, the deep learning methods suffer from signiﬁcant performance degradation when faced with
Figure 1. Detected objects in source domain (1st row) and target domain (2nd row). The results are collected from a detector only trained on Cityscapes. Green, red, and blue boxes are true posi-tives, false positives and false negatives. We can observe that many targets have been missed in the domain-shifted Foggy Cityscapes. variations of object appearance, weather and illumination.
As illustrated in Figure 1, the detector trained with source domain dataset performs well on testing set with the same distribution. But if there is a severe disparity be-tween the source and target domain, the output results are prone to missing detection (blue boxes) or false alarm (red boxes), which leads to a prominent performance degrada-tion and hinders the deployment in real-world situations. In practice, we can mitigate this impact by establishing a task-speciﬁc dataset that covers various training samples. Un-fortunately, the massive and high-quality annotation could be costly and laborious, thus being not always feasible to acquire adequate training images from new environments.
To deal with this urgent dilemma, many unsupervised domain adaptive algorithms have been proposed to improve detection accuracy in the target domain. Almost all adaptive detectors have added adversarial training modules that are actually some domain classiﬁers. This idea is drawn from the classiﬁcation task [44]. From coarse to ﬁne, the do-main alignment modules can be divided into image-level, instance-level and pixel-level. Although adversarial train-ing can mitigate the domain shift to a certain extent, it still has three defeats leading to deteriorated detection perfor-mance. First, there are no restrictions on image-level fea-ture alignment. In fact, the model should pay more atten-tion to feature consistency of object regions. Other irrele-vant information, such as background noise, does not need to be aligned. Imagine that urban streets and rural wilder-ness are two completely different scenes. Forcing them to have similar distribution in the feature space not only vi-olates human intuition, but also causes the calculated loss difﬁcult to be optimized. Second, instance-level alignment may have noise that is generated by excessive low-quality region proposals. Performing this alignment would be sen-sitive to inaccurate predictions. Third, adversarial training adopts minimax optimization. The gradient used to update the model parameters is alternately reversed, which will af-fect the stability of the training process.
Motivated by these ﬁndings, we ﬁrst raise the question
“Why can humans accurately recognize objects in different weather and scenes?”. There are two factors worth noting.
First, humans have learned the intrinsic properties of target objects. Second, humans can capture relationship knowl-edge between object categories, which is also independent of the domain distribution. Therefore, a new paradigm of domain adaptive detector without adversarial training is proposed. More concretely, two knowledge transfer mod-ules are embed into the detection framework, which dis-cover object-related knowledge from two aspects. First, we train a binary classiﬁer shared by the source and target domain.
If model can make the same classiﬁcation deci-sion for foreground and background representation in dif-ferent domains, it means that the object/non-object features in source and target datasets are aligned to some extent.
Second, we explore relational knowledge of object cate-gories and explicitly constrain the consistency of relation graph between different domains, which tends to further re-ﬁne the adaption process. In short, the similarity between pedestrian and rider will not decrease due to changes in weather, and the irrelevance between car and sky will not be improved due to changes in the scene. Through maintain-ing such object-related and domain-independent knowledge consistent, the generalization performance of detectors can be greatly enhanced.
In order to evaluate the proposed method, cross-domain testing experiments are conducted on three benchmark settings. Cityscapes [9] to Foggy Cityscapes [36] for domain adaption under different weather. Sim10k [21] to Cityscapes for synthetic domain to the real world.
KITTI [14] to Cityscapes is about different scenes and cross cameras. The experimental results indicate that domain-independent knowledge mining and transferring can be used as a new paradigm for domain adaption models, which out-performs existing state-of-the-art approaches. Moreover, we also make ablation study to explore the effectiveness of each knowledge mining strategy. Qualitative visualization analysis intuitively illustrates the motivation and achieve-ments of this paper. To sum up, our major contributions are threefold as follows.
• The proposed domain-invariant classiﬁer can teach the model to extract common attribute knowledge of target objects, which is the basis for detector to distinguish foreground and background regions.
• We design a domain-independent category relation constraint. The generalization performance of detector is improved by explicitly constraining the consistency of category correlation between different domains.
• Comprehensive experiments and visualizations val-idate the effectiveness of knowledge mining and transferring. The designed method further improves the state-of-the-art level on three domain adaptation benchmarks. 2.