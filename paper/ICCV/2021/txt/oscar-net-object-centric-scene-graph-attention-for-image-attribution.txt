Abstract
Images tell powerful stories but cannot always be trusted. Matching images back to trusted sources (attribu-tion) enables users to make a more informed judgment of the images they encounter online. We propose a robust im-age hashing algorithm to perform such matching. Our hash is sensitive to manipulation of subtle, salient visual details that can substantially change the story told by an image.
Yet the hash is invariant to benign transformations (changes in quality, codecs, sizes, shapes, etc.) experienced by im-ages during online redistribution. Our key contribution is
OSCAR-Net1 (Object-centric Scene Graph Attention for Im-age Attribution Network); a robust image hashing model in-spired by recent successes of Transformers in the visual do-main. OSCAR-Net constructs a scene graph representation that attends to ﬁne-grained changes of every object’s visual appearance and their spatial relationships. The network is trained via contrastive learning on a dataset of original and manipulated images yielding a state of the art image hash for content ﬁngerprinting that scales to millions of images. 1.

Introduction
Fake news and misinformation are centuries-old societal problems, exacerbated today by the ease with which digi-tal images are manipulated and shared. Matching (or ‘at-tributing’) an image back to a trusted source, improves user awareness of its origins (or ‘provenance’) and so enables more informed trust decisions to be made [17, 45].
Emerging standards for image attribution embed prove-nance information within metadata [45, 3]. Yet image meta-data is commonly stripped by social platforms, and may be replaced to misattribute an image [12]. One solution is to visually match images to a trusted database via ‘ﬁngerprint-ing’; i.e. visual search or content-aware hashing.
This paper contributes a novel object-centric approach for computing a robust hash from an image, to perform vi-sual matching for image attribution. Images often undergo
‘benign transformations’ during online distribution, such as
*Equal contribution by co-authors 1Code, data and model available at https://exnx.github.io/oscar/ changes in format, resolution, size, padding, etc. that render cryptographic hashes[16] unsuitable as ﬁngerprints. Thus image ﬁngerprints must be made robust to these ‘benign’ transformations.
We propose a representation learning technique that en-courages our hashes to exhibit both invariance to benign transformations and sensitivity to tampering (‘manipula-tion’) where image content is altered — sometimes quite subtly — but sufﬁciently to change meaning. For example, the editorial changes to introduce particular objects/motifs, or alterations to salient visual details such as the face, could substantially change the story told by an image (Fig. 1,2).
Our method generates substantially different hashes in such cases to avoid corroborating a false story with the prove-nance information of the original image. Existing percep-tual hashes [60, 43, 59, 39, 34]) typically exhibit the oppo-site desired characteristics (c.f. Sec. 4.5), that is, they are often invariant to minor changes, and sensitive to benign transformations (such as noise, or padding) during content redistribution.
Our core technical contribution is to encode a scene graph representation of the image via a hybrid network ar-chitecture, combining a fully-connected Graph Neural Net-work (GNN) and Transformer to create a robust binary hash of the image. Our Object-centric Scene Graph Attention for Image Attribution Network (OSCAR-Net) decomposes
a scene into salient objects and aggregates their description into a compact visual hash. This creates an object-centric hash that exhibits improved sensitivity to minor manipula-tion of salient objects, and improved robustness to benign transformations. We leverage contrastive training coupled with benign transformations using data augmentation and manipulations using Adobe PhotoshopTM to learn represen-tations that outperform existing perceptual hashing base-lines. Both object appearance and relative object geometry are learned via OSCAR-Net to yield an object-centric hash with improved tamper-sensitivity and scalability. We com-bine our learned OSCAR-Net representation with geomet-ric veriﬁcation to create a prototype image attribution tool to assist users in determining the provenance of images en-countered online. Such a tool has future potential for ﬁght-ing fake news by helping users gauge the trustworthiness of content. 2.