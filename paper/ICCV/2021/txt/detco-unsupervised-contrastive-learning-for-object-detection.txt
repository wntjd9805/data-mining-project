Abstract
We present DetCo, a simple yet effective self-supervised approach for object detection. Unsupervised pre-training methods have been recently designed for object detection, but they are usually deficient in image classification, or the opposite. Unlike them, DetCo transfers well on downstream instance-level dense prediction tasks, while maintaining competitive image-level classification accuracy. The advan-tages are derived from (1) multi-level supervision to inter-mediate representations, (2) contrastive learning between global image and local patches. These two designs facil-itate discriminative and consistent global and local repre-sentation at each level of feature pyramid, improving detec-tion and classification, simultaneously.
Extensive experiments on VOC, COCO, Cityscapes, and
ImageNet demonstrate that DetCo not only outperforms re-cent methods on a series of 2D and 3D instance-level de-tection tasks, but also competitive on image classification.
For example, on ImageNet classification, DetCo is 6.9% and 5.0% top-1 accuracy better than InsLoc and DenseCL, which are two contemporary works designed for object de-tection. Moreover, on COCO detection, DetCo is 6.9 AP better than SwAV with Mask R-CNN C4. Notably, DetCo largely boosts up Sparse R-CNN, a recent strong detector, from 45.0 AP to 46.5 AP (+1.5 AP), establishing a new
SOTA on COCO. 1.

Introduction
Self-supervised learning of visual representation is an es-sential problem in computer vision, facilitating many down-stream tasks such as image classification, object detection, and semantic segmentation [23, 35, 43]. It aims to provide models pre-trained on large-scale unlabeled data for down-stream tasks. Previous methods focus on designing different pretext tasks. One of the most promising directions among them is contrastive learning [32], which transforms one im-*equal contribution
Figure 1. Transfer accuracy on Classification and Detection.
DetCo achieves the best performance trade-off on both classifi-cation and detection. For example, DetCo outperforms its strong baseline, MoCo v2 [5], by 0.9 AP on COCO detection. Moreover,
DetCo is significant better than recent work e.g. DenseCL [39],
InsLoc [41], PatchReID [8] on ImageNet classification while also has advantages on object detection. Note that these three meth-ods are concurrent work and specially designed for object detec-tion (mark with green). The yellow asterisk indicates that a de-sired method should have both high performance in detection and classification. age into multiple views, minimizes the distance between views from the same image, and maximizes the distance between views from different images in a feature map.
In the past two years, some methods based on contrastive learning and online clustering, e.g. MoCo v1/v2 [19, 5],
BYOL [18], and SwAV [3], have achieved great progress to bridge the performance gap between unsupervised and fully-supervised methods for image classification. How-ever, their transferring ability on object detection is not sat-isfactory. Concurrent to our work, recently DenseCL [39],
InsLoc [41] and PatchReID [8] also adopt contrastive learn-ing to design detection-friendly pretext tasks. Nonetheless, these methods only transfer well on object detection but sac-rifice image classification performance, as shown in Fig-ure 1 and Table 1. So, it is challenging to design a pretext task that can reconcile instance-level detection and image
Method
Place
MoCo v1[19] CVPR’20
MoCo v2[5]
InstLoc[41]
DenseCL[39]
PatchReID[8]
DetCo
Arxiv
CVPR’21
CVPR’21
Arxiv
-ImageNet Cls. COCO Det. Cityscapes Seg. mAP
Top-1 Top-5 38.5 60.6 38.9 67.5 39.8 61.7 39.3 63.6 39.6 63.8 39.8 68.6 mIoU 75.3 75.7
-75.7 76.6 76.5
---85.8 85.6 88.5
Table 1. Classification and Detection trade-off for recent detection-friendly self-supervised methods. Compared with concurrent InstLoc[41], DenseCL[39] and PatchReID[8], DetCo is significantly better by 6.9%, 5.0% and 4.8% on ImageNet clas-sification. Moreover, DetCo is also on par with these methods on dense prediction tasks, achieving best trade-off. classification.
We hypothesize that there is no unbridgeable gap be-tween image-level classification and instance-level detec-tion. Intuitively, image classification recognizes global in-stance from a single high-level feature map, while object detection recognizes local instance from multi-level feature pyramids. From this perspective, it is desirable to build in-stance representation that are (1) discriminative at each level of feature pyramid (2) consistent for both global image and local patch (a.k.a sliding windows). However, existing un-supervised methods overlook these two aspects. Therefore, detection and classification cannot mutually improve.
In this work, we present DetCo, which is a contrastive learning framework beneficial for instance-level detection tasks while maintaining competitive image classification transfer accuracy. DetCo contains (1) multi-level supervi-sion on features from different stages of the backbone net-work. (2) contrastive learning between global image and local patches. Specifically, the multi-level supervision di-rectly optimizes the features from each stage of backbone network, ensuring strong discrimination in each level of pyramid features. This supervision leads to better perfor-mance for dense object detectors by multi-scale prediction.
The global and local contrastive learning guides the network to learn consistent representation on both image-level and patch-level, which can not only keep each local patch highly discriminative but also promote the whole image represen-tation, benefiting both object detection and image classifi-cation.
DetCo achieves state-of-the-art transfer performance on various 2D and 3D instance-level detection tasks e.g. VOC and COCO object detection, semantic segmentation and
DensePose. Moreover, the performance of DetCo on Im-ageNet classification and VOC SVM classification is still very competitive. For example, as shown in Figure 1 and
Table 1, DetCo improves MoCo v2 on both classification and dense prediction tasks. DetCo is significant better than
DenseCL [39], InsLoc [41] and PatchReID [8] on ImageNet classification by 6.9%, 5.0% and 4.8% and slightly bet-ter on object detection and semantic segmentation. Please note DenseCL, InsLoc and PatchReID are three concur-rent works which are designed for object detection but sac-rifice classification. Moreover, DetCo boosts up Sparse
R-CNN [37], which is a recent end-to-end object detec-tor without q, from a very high baseline 45.0 AP to 46.5
AP (+1.5 AP) on COCO dataset with ResNet-50 backbone, establishing a new state-of-the-art detection result. In the 3D task, DetCo outperforms ImageNet supervised methods and MoCo v2 in all metrics on COCO DensePose, espe-cially +1.4 on AP50.
Overall, the main contributions of this work are three-fold:
• We introduce a simple yet effective self-supervised pretext task, named DetCo, which is beneficial for instance-level detection tasks. DetCo can utilize large-scale unlabeled data and provide a strong pre-trained model for various downstream tasks.
• Benefiting from the design of multi-level supervision and contrastive learning between global images and local patches, DetCo successfully improves the trans-ferring ability on object detection without sacrificing image classification, compared to contemporary self-supervised counterparts.
• Extensive experiments on PASCAL VOC [15], COCO
[28] and Cityscapes [6] show that DetCo outperforms previous state-of-the-art methods when transferred to a series of 2D and 3D instance-level detection tasks, e.g. object detection, instance segmentation, human pose estimation, DensePose, as well as semantic segmenta-tion. 2.