Abstract
Removing noise from scanned pages is a vital step before their submission to optical character recognition (OCR) system. Most available image denoising methods are su-pervised where the pairs of noisy/clean pages are required.
However, this assumption is rarely met in real settings. Be-sides, there is no single model that can remove various noise types from documents. Here, we propose a uniﬁed end-to-end unsupervised deep learning model, for the ﬁrst time, that can effectively remove multiple types of noise, includ-ing salt & pepper noise, blurred and/or faded text, as well as watermarks from documents at various levels of inten-sity. We demonstrate that the proposed model signiﬁcantly improves the quality of scanned images and the OCR of the pages on several test datasets. 1.

Introduction
Millions of electronic documents, such as contracts and invoices, are reviewed in the normal course of business in the enterprise. A large percentage of them are scanned doc-uments containing various types of noise, including salt & pepper (S&P) noise, blurred or faded text, watermarks, etc.
Noise in documents highly degrades the performance of the optical character recognition (OCR) and their subsequent digitization and analysis. The ﬁrst step toward automating document analysis is to improve their quality using image processing techniques, such as image denoising and restora-tion. Most of the literature, places attention on removing noise from pictures [25] (e.g., natural scenes) not text doc-uments. However, these techniques may not be directly ap-plicable due to very different nature of text documents.
In the image restoration problem, a degradation function and noise may both affect the quality of images [8]. Exam-ples are deblurring, defading, and inpainting. If in a special case, there is no degradation function, the problem would be a pure image denoising problem (e.g., S&P noise removal).
The current state-of-the-art (SOTA) solutions for im-*equal contribution age restoration problem are discriminative models based on convolutional neural networks (CNNs), auto-encoders and their variants such as REDNet (residual encoder decoder network) [19, 7], DnCNN (denoising convolutional neural networks) [29], and RDN (residual dense network) [30, 31].
These solutions can generally be formulated as follows: arg min
θ (cid:88) (cid:88) (cid:16)
L j i f (xj i ; θ) = ˆyj i , yj i (cid:17) (1) i and ˆyj where xj i refers to a noisy patch extracted from the noisy image xi, yj i are the target and predicted clean patches, respectively, f and θ refer to the CNN and its pa-rameters. The main shortcoming of this approach, how-ever, is the requirement for the availability of clean tar-get images/documents, which is hard to address in real-world documents.
In the literature, the noisy/clean pairs are usually prepared by adding some synthetic noise to clean images/documents. However, the synthetic noise does not completely model noise on real images/documents, and therefore, the performance of the network trained on these synthetic data is sub-optimal and highly degraded on real noisy images/documents [12, 28].
To address the lack of noisy/clean pairs, noise-to-noise (N2N) [15], noise-to-void (N2V) [13], and noise-to-self (N2S) [3, 14] training strategies have been proposed. How-ever, these solutions are based on the assumption that the noise is additive zero-mean, and/or independent between pixels [15, 13, 14]. This only covers a speciﬁc kind of denoising problem and, therefore, not directly applicable to general image restoration problems, including defading and deblurring. Furthermore, in N2N approach, at least two noisy instances of the same document page are needed, which are not readily available in real settings.
There are several challenges in the design of an end-to-end solution for document image clean-up: 1) Noisy/clean pairs are not available, and therefore, the standard SOTA solutions based on discriminative models can not be em-ployed. 2) There are various artifacts at different inten-sity levels (intra-class variation) in documents. 3) We pre-fer to have a single model based on one architecture, and one training strategy, i.e., a uniﬁed solution to address all
noise/degradation problems (blind denoising/restoration) as opposed to individual models trained separately for each noise type. Training multiple models raises the problem of routing a document containing a speciﬁc artifact to the right model for image clean-up.
This paper addresses these challenges by introducing an end-to-end unsupervised image blind denoising algorithm that presents a single uniﬁed model to remove various noise types, without the requirement of paired noisy/clean pages.
The main contributions are listed as follows: 1. We propose a novel uniﬁed architecture by integrating deep mixture of experts with a cycle-consistent GAN as the base network. We formulate a novel loss func-tion for the proposed model. 2. To the best of our knowledge, the designed uniﬁed model is the ﬁrst that removes various artifacts, includ-ing noise (such as S&P noise), and degradation (e.g., faded and blurred text, or watermark) at various inten-sity levels (image blind denoising). 3. We trained the model on actual noisy documents (not documents with synthetically added noise) without the requirement of noisy/clean images, evaluated it across several public and in-house document datasets, and demonstrated its excellent performance on real docu-ments containing various artifacts. 2.