Abstract
Deep learning algorithms have made significant progress in dynamic scene deblurring. However, several challenges are still unsettled: 1) The degree and scale of blur in different regions of a blurred image can have a con-siderable variation in a large range. However, the tradi-tional input pyramid or downscaling-upscaling, is designed to have limited and inflexible perceptual variousness to cope with large blur scale variation. 2) The nonlocal block is proved to be effective in the image enhancement tasks, but it requires high computation and memory cost. In this paper, we are the first to propose a light-weight globally-analyzing module into the image deblurring field, named
Light Global Context Refinement (LGCR) module. With ex-ponentially lower cost, it achieves even better performance than the nonlocal unit. Moreover, we propose the Percep-tual Variousness Block (PVB) and PVB-piling strategy. By placing PVB repeatedly, the whole method possesses abun-dant reception field spectrum to be aware of the blur with various degrees and scales. Comprehensive experimental results from the different benchmarks and assessment met-rics show that our method achieves excellent performance to set a new state-of-the-art in motion deblurring. 1 1.

Introduction
The restoration of the latent sharp image from the blur input in dynamic scene has long been an important task in computer vision and image processing. Deep learning methods for single image deblurring, particularly convolu-tional neural networks (CNNs), have obtained remarkable success [9, 24, 1, 5, 31, 6, 21]. Nah et al. propose the method [20] recovering the blurred image with the input pyramid on 3 scales, in a coarse-to-fine manner. Tao et 1This work is supported by NSFC (Grant No.: U2001209, 61902076, 61772137) and Natural Science Foundation of Shanghai (21ZR1406600).
* Corresponding author: Bo Yan.
Figure 1: The comparison of different methods, in terms of the accuracy and cost. Our approach is better than the other state-of-the-art methods. “720p” indicates that the test image is in the size of 1280× 720. al. deeply investigate the coarse-to-fine strategy and pro-pose a Scale-Recurrent Network [25]. With the adoption of the convLSTM [30], multi-scale, and weight-sharing, SRN achieves high PSNR with fewer parameters. Recently, the state-of-the-art methods [16, 4, 34, 17, 22, 33, 35] have fur-ther revealed the potential of CNNs in deblurring task. that
One of the biggest challenges of deblurring comes the blur pattern’s degree and scale from the fact vary widely. Traditionally, multi-scale input pyramid and downsampling-upsampling layers inside the network are common strategies to release the difficulty brought by the complicated blur pattern [20, 16]. More recent methods fo-cus on other handcrafted strategies to deal with the wide range of blur scale variation. [25] utilizes a recurrent net-work with weight sharing in a coarse-to-fine manner. [34] proposes a multi-patch methodology to exploit multi-scale information. [22] even puts forward a multi-temporal idea that deblurs the image from hard to easy progressively.
Unfortunately, their adopted multi-scale, multi-patch, and multi-temporal strategies augment their models’ per-ceptual scale variousness with only limited times, e.g., there are only two scales or five temporal intervals considered in their designed methods. In other words, the final reception
Figure 2: The architecture of the SimpleNet. Since it grasps the essence of deblurring with the help of the PVB and LGCR, it is designed in an auto-encoder fashion, which is easy to implement and follow. The vanilla ResBlock [8] has three convolution layers. The “Down Sample” is a conv layer, stride=2; the “Up Sample” is deconvolution layer, stride=2. fields obtained in the information flow are only augmented by limited times. However, the blur’s degree has a consid-erable variation in a relatively wide range. Thus, these dis-crete and handcrafted strategies are not satisfactory to equip
CNN with enough ability to percept the complex blur pat-terns whose scale is widely distributed.
Moreover, non-localized neural operation with lower cost is in good demand for deblurring task. The CNN de-sign is based on a localized filtering operation, which pro-cesses one local neighborhood at a time. It is unfavorable for the task that requires a broader reference range or even full-image self-reference, such as image segmentation, pose estimation, and severe motion blur recovery. The nonlocal proposed in [28] is an excellent, classic yet expensive solu-tion for the caption of long-range dependencies. Recently, inspired by tensor canonical-polyadic decomposition the-ory, Chen et al. propose a tensor generation module and a tensor reconstruction module, named ”TGM+TRM” (T+T) in semantic segmentation [2].
It computes the global in-formation while tackling the high-rank difficulty. However,
T+T’s structure is good at high-level semantic reasoning, yet bad at detail recovery, which is essential in deblurring task. Moreover, its non-linearity of the 1-rank tensors is not sufficient; its global context is not well learned and utilized.
In this paper, we work on the deficiencies mentioned above, and propose our deblurring method, SimpleNet. We propose a new light-weight non-localized module, named
Light Global Context Refinement (LGCR). It is the first time that such a light-weight non-localized module is pro-posed in deblurring task to enrich global detail instead of pixel-wise reasoning, with better performance and a much lower cost than the nonlocal module. Moreover, we propose the Perceptual Variousness Block (PVB) and PVB-piling
Figure 3: PVB greatly expands the variety of reception fields that a network can perceive. The architecture of PVB is illustrated in Figure 5. The “Vanilla ResBlock” is an or-dinary three-layered. The braced statistics stands for recep-tion field spectrum. With larger reception field spectrum, network has the better perceptual variousness and ability. strategy. PVB provides abundant adaptive multi-scale re-ception ability with broad reception spectrum. Unlike the traditional “multi” methodology, PVB-piling strategy can greatly broaden the variousness of the network’s reception scales and perceptual ability, as shown in Figure 3, facing the challenge of wide range blur variation. Finally, we ex-amine our method with the state-of-the-art methods, in Go-Pro, RealBlur-J and RWBI benchmarks. Comprehensive experiments show that our method achieves the best per-formance to set a new state-of-the-art.
We name our network “SimpleNet” because its architec-ture is straightforward, easy to implement.
Figure 4: The detailed architecture of the LGCR module (col. #1), in comparison with TGM+TRM (T+T) module (col. #2).
Although both modules adopt the high-rank-to-low-rank decomposition theory[15], their main aims and detailed design are totally different. Experiments demonstrate that LGCR is far more effective than T+T in deblurring task.
In conclusion, our contributions are as follows:
• We are the first to propose a novel light-weight non-localized module into the image deblurring, named
Light Global Context Refinement (LGCR). It outper-forms both nonlocal and T+T methods, in a detail en-hancement manner, instead of pixel-wise reasoning.
• We proposed Perceptual Variousness Block (PVB) and
PVB-piling strategy. PVB provides abundant adaptive multi-scale reception ability. PVB-piling strategy can greatly enrich the variousness of the network’s recep-tion spectrum and perceptual ability, challenging the wide range of blur variations.
• We put forward a robust and effective deblur network,
It has a simple encoder-decoder named SimpleNet. structure, and it is easy to implement and follow.
• Comprehensive experiments are conducted, not only on the prevalent GoPro benchmark, but also on the newly proposed RealBlur-J, RWBI benchmarks, with comprehensive assessment metrics. 2.