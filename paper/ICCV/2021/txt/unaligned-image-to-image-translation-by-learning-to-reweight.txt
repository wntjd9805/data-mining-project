Abstract
Unsupervised image-to-image translation aims at learn-ing the mapping from the source to target domain without using paired images for training. An essential yet restric-tive assumption for unsupervised image translation is that the two domains are aligned, e.g., for the selfie2anime task, the anime (selfie) domain must contain only anime (selfie) face images that can be translated to some images in the other domain. Collecting aligned domains can be laborious and needs lots of attention. In this paper, we consider the task of image translation between two unaligned domains, which may arise for various possible reasons. To solve this problem, we propose to select images based on importance reweighting and develop a method to learn the weights and perform translation simultaneously and automatically. We compare the proposed method with state-of-the-art image translation approaches and present qualitative and quan-titative results on different tasks with unaligned domains.
Extensive empirical evidence demonstrates the usefulness of the proposed problem formulation and the superiority of our method. 1.

Introduction
In recent years, Image-to-Image (I2I) translation has been achieving remarkable success in transferring complex appearance changes across domains [61, 34]. In addition, many related tasks could also be formulated as I2I prob-lems such as image super-resolution [57, 11] and domain adaptation [23, 42].
In supervised image translation, we are given paired data from source and target domains. Pix2pix [28] applies condi-tional Generative Adversarial Network [17, 40] to map the the source images to the target domain while enforcing a L1 distance loss between translated images and target images.
Pix2pix can generate a sharp target image with sufficient paired training data. However, paired data are very difficult to collect or even do not exist (e.g., Van Gogh’s painting to real photos). In the absence of paired data, unsupervised I2I
Figure 1: Example of aligned and unaligned domains. Left: selfie images as domain X and anime face images as do-main Y . Images in two domains are carefully selected and processed. Right: many unwanted anime images may ap-pear in the domain Y for many possible reasons, e.g., lack of human supervision. translation methods have achieved impressive performance by combining GAN with proper constraints, such as cycle consistency [61] and shared latent space assumption [34].
An essential assumption of unsupervised image transla-tion is then that the domains used for training are aligned, which means that each image in one domain can be trans-lated to some image in the other domain in a meaningful manner; in other words, there is some underlying relation-ship between the domains [61]. For example, each of the two domains in the selfie2anime task include only female face images (Figure 1, left) of a similar style.
However, collecting images for two domains which are guaranteed to be aligned needs a lot of attention. For in-stance, to collect the anime domain, Kim et al. [29] first constructed an initial dataset consisting of 69,926 anime character images. Then they applied pre-trained anime face detector to extract 27,073 face images and then manually selected 3500 female face images as the training set. To collect the animal face dataset, Liu et al. [35] manually la-beled bounding boxes of 10,000 carnivorous animal faces in the images and selected images with high detection scores
from Imagenet [13].
To save efforts, one may consider the setting with un-aligned domains since they are much cheaper to obtain.
For example, to obtain the anime face domain, we may also apply the anime face detector as Kim et al. did, and then just treat the detected results as images in the desired domain. Without any human supervision, the constructed domain may contain many unwanted anime images, e.g., anime body or even anime book images as shown in Fig-ure 1 (right). These unaligned images may harm the image translation quality and can even cause the failure of some image translation methods (e.g., see Figure 4).
We therefore seek an algorithm that can learn to trans-late between unaligned domains where some images in ei-ther domain may be unrelated to the main task (Figure 1, right) and thus should not be considered for translation.
For brevity, we denote these images as unaligned images.
We further assume that there are unknown, aligned subsets
Xa ⊆ X and Ya ⊆ Y , and our task is to discover such un-known subsets automatically and simultaneously learn the mapping between them. Inferring the unknown subsets Xa and Ya seems to be challenging since we are given only two unaligned domains X and Y . To address this issue, we pro-pose to reweight (or “select”) each sample with importance
β during the adversarial distribution matching process. Ide-ally, if β is almost 0, then the image is not in the aligned subset and hence not considered for translation.
Thus the problem boils down to learning appropriate im-portance weight for each sample for the purpose of sen-sible translation. To address the importance weight esti-mation problem, we analyze the causal generating process of images and hypothesize that images in Xa and Ya can be translated to the other domain faster than images in unaligned subsets since Xa and Ya share the same con-tent category. Then we propose the reweighted adversar-ial loss which enables us to approximate the density ratios as well as performing image translation between two un-known aligned subsets Xa, Ya. In addition, we also propose an effective sample size loss to avoid importance networks giving trivial solutions. We apply the proposed method to various image-to-image translation problems and the large improvements over strong baselines on unaligned dataset demonstrate the efficacy of our proposed translation method as well as the validity of our hypothesis. Code and data are available at https://github.com/Mid-Push/IrwGAN. 2.