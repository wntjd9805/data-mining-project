Abstract
We introduce Mixture-based Feature Space Learning (MixtFSL) for obtaining a rich and robust feature representa-tion in the context of few-shot image classification. Previous works have proposed to model each base class either with a single point or with a mixture model by relying on offline clustering algorithms. In contrast, we propose to model base classes with mixture models by simultaneously train-ing the feature extractor and learning the mixture model parameters in an online manner. This results in a richer and more discriminative feature space which can be em-ployed to classify novel examples from very few samples.
Two main stages are proposed to train the MixtFSL model.
First, the multimodal mixtures for each base class and the feature extractor parameters are learned using a combina-tion of two loss functions. Second, the resulting network and mixture models are progressively refined through a leader-follower learning procedure, which uses the current estimate as a “target” network. This target network is used to make a consistent assignment of instances to mixture components, which increases performance and stabilizes training. The effectiveness of our end-to-end feature space learning ap-proach is demonstrated with extensive experiments on four standard datasets and four backbones. Notably, we demon-strate that when we combine our robust representation with recent alignment-based approaches, we achieve new state-of-the-art results in the inductive setting, with an absolute accuracy for 5-shot classification of 82.45% on miniIma-geNet, 88.20% with tieredImageNet, and 60.70% in FC100 using the ResNet-12 backbone. 1.

Introduction
The goal of few-shot image classification is to transfer knowledge gained on a set of “base” categories, containing a large number of training examples, to a set of distinct “novel” classes having very few examples [16, 47]. A hallmark of successful approaches [18, 64, 73] is their ability to learn rich and robust feature representations from base training images, which can generalize to novel samples.
A common assumption in few-shot learning is that classes can be represented with unimodal models. For example, Pro-totypical Networks [64] (“ProtoNet” henceforth) assumed each base class can be represented with a single prototype.
Others, favoring standard transfer learning [1, 8, 24], use a classification layer which push each training sample towards a single vector. While this strategy has successfully been employed in “typical” image classification (e.g., ImageNet challenge [58]), it is somewhat counterbalanced because the learner is regularized by using validation examples that be-long to the same training classes. Alas, this solution does not transfer to few-shot classification since the base, validation, and novel classes are disjoint. Indeed, Allen et al. [2] showed that relying on that unimodal assumption limits adaptability in few-shot image classification and is prone to underfitting from a data representation perspective.
To alleviate this limitation, Infinite Mixture Prototypes [2] (IMP) extends ProtoNet by representing each class with mul-tiple centroids. This is accomplished by employing an of-fline clustering (extension of DP-means [36]) where the non-learnable centroids are recomputed at each iteration. This approach however suffers from two main downsides. First, it does not allow capturing the global distribution of base classes since a small subset of the base samples are clustered at any one time—clustering over all base samples at each training iteration would be prohibitively expensive. Second, relying on DP-means in an offline, post hoc manner implies that feature learning and clustering are done independently.
In this paper, we propose “Mixture-based Feature Space
Learning” (MixtFSL) to learn a multimodal representation for the base classes using a mixture of trainable components— learned vectors that are iteratively refined during training.
The key idea is to learn both the representation (feature space) and the mixture model jointly in an online manner, which effectively unites these two tasks by allowing the gra-dient to flow between them. This results in a discriminative representation, which in turn yields superior performance when training on the novel classes from few examples.
We propose a two-stage approach to train our MixtFSL.
In the first stage, the mixture components are initialized by the combination of two losses that ensure that: 1) samples
video classification [6], and 3D shape segmentation [75].
This paper instead focuses on the image classification prob-lem [18, 64, 73], so the remainder of the discussion will focus on relevant works in this area. In addition, unlike transductive inference methods [4, 12, 30, 32, 33, 43, 90, 52] which uses the structural information of the entire novel set, our research focuses on inductive inference research area.
Meta learning
In meta learning [12, 18, 55, 59, 63, 64, 65, 72, 79, 83], approaches imitate the few-shot scenario by repeatedly sampling similar scenarios (episodes) from the base classes during the pre-training phase. Here, distance-based approaches [3, 21, 34, 39, 40, 49, 64, 67, 70, 73, 80, 84, 87] aim at transferring the reduced intra-class variation from base to novel classes, while initialization-based ap-proaches [18, 19, 35] are designed to carry the best starting model configuration for novel class training. Our MixtFSL benefits from the best of both worlds, by reducing the within-class distance with the learnable mixture component and increasing the adaptivity of the network obtained after initial training by representing each class with mixture components.
Standard transfer learning Batch form training makes use of a standard transfer learning modus operandi instead of episodic training. Although batch learning with a naive opti-mization criteria is prone to overfitting, several recent stud-ies [1, 8, 24, 51, 69] have shown a metric-learning (margin-based) criteria can offer good performance. For example,
Bin et al. [41] present a negative margin based feature space learning. Our proposed MixtFSL also uses transfer learn-ing but innovates by simultaneously clustering base class features into multi-modal mixtures in an online manner.
Data augmentation Data augmentation [9, 10, 20, 23, 25, 27, 42, 45, 57, 60, 77, 78, 85, 86, 88] for few-shot image classification aims at training a well-generalized algorithm.
Here, the data can be augmented using a generator function.
For example, [27] proposed Feature Hallucination (FH) us-ing an auxiliary generator. Later, [77] extends FH to generate new data using generative models. In contrast, our MixtFSL does not generate any data and achieves state-of-the-art. [1] makes use of “related base” samples in combination with an alignment technique to improve performance. We demon-strate (in sec. 6) that we can leverage this approach in our framework since our contribution is orthogonal.
Mixture modeling
Similar to classical mixture-based works [17, 22] outside few-shot learning, infinite mixture model [29] explores Bayesian methods [54, 81] to infer the number of mixture components. Recently, IMP [2] relies on the DP-means [36] algorithm which is computed inside the episodic training loop in few-shot learning context. As in [29], our MixtFSL automatically learns the number of mixture components, but differs from [2] by learning the mixture model simultaneously with representation learning in an online manner, without the need for a separate, post (a) without MixtFSL (b) our MixtFSL
Figure 1. t-SNE [44] visualization of a single base class embedding (circles) (a) without, and (b) with our MixtFSL approach. MixtFSL learns a representation for base samples (circles) and associated mixture learned components (diamonds) that clusters a class into several modes (different colors). This more flexible representation helps in training robust classifiers from few samples in the novel do-main compared to the monolithic representation of (a). Embeddings are extracted from a miniImageNet class using a ResNet-18. are assigned to their nearest mixture component; while 2) enforcing components of a same class mixture to be far enough from each other, to prevent them from collapsing to a single point. In the second stage, the learnable mixture model is progressively refined through a leader-follower scheme, which uses the current estimate of the learner as a fixed
“target” network, updated only on a few occasions during that phase, and a progressively declining temperature strategy.
Our experiments demonstrate that this improves performance and stabilizes the training. During training, the number of components in the learned mixture model is automatically adjusted from data. The resulting representation is flexible and better adapts to the multi-modal nature of images (fig. 1), which results in improved performance on the novel classes.
Our contributions are as follows. We introduce the idea of MixtFSL for few-shot image classification, which learns a flexible representation by modeling base classes as a mixture of learnable components. We present a robust two-stage scheme for training such a model. The training is done end-to-end in a fully differentiable fashion, without the need for an offline clustering method. We demonstrate, through an extensive experiments on four standard datasets and using four backbones, that our MixtFSL outperforms the state of the art in most of the cases tested. We show that our approach is flexible and can leverage other improvements in the literature (we experiment with associative alignment [1] and ODE [82]) to further boost performance. Finally, we show that our approach does not suffer from forgetting (the base classes). 2.