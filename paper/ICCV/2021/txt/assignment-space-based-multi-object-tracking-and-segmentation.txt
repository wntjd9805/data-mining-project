Abstract
Multi-object tracking and segmentation (MOTS) is im-portant for understanding dynamic scenes in video data.
Existing methods perform well on multi-object detection and segmentation for independent video frames, but track-ing of objects over time remains a challenge. MOTS meth-ods formulate tracking locally, i.e., frame-by-frame, leading to sub-optimal results. Classical global methods on track-ing operate directly on object detections, which leads to a combinatorial growth in the detection space. In contrast, we formulate a global method for MOTS over the space of assignments rather than detections: First, we ﬁnd all top-k assignments of objects detected and segmented between any two consecutive frames and develop a structured prediction formulation to score assignment sequences across any num-ber of consecutive frames. We use dynamic programming to
ﬁnd the global optimizer of this formulation in polynomial time. Second, we connect objects which reappear after hav-ing been out of view for some time. For this we formulate an assignment problem. On the challenging KITTI-MOTS and
MOTSChallenge datasets, this achieves state-of-the-art re-sults among methods which don’t use depth data. 1.

Introduction
Multi-Object Tracking and Segmentation (MOTS) not only requires to detect and segment objects in a video, but also asks to assign consistent IDs, i.e., each visible instance of the same object is always given the same ID. MOTS is important for understanding scenes in a video and is crucial for autonomous driving, robotics, agricultural and biomedical data analysis, etc. While the MOTS sub-task of multi-object detection and segmentation on individual video frames has received a considerable amount of atten-tion [14, 35, 9, 13, 42, 40, 17, 18, 19, 16], tracking of objects over multiple frames remains a challenge, especially in the presence of occlusions and viewpoint variations.
Tracking of objects over a sequence has been addressed using batch and online-methods. The former assumes an entire sequence is available, while the latter operates frame-by-frame. These methods face two main challenges.
Firstly, current MOTS methods (batch or online) formu-late tracking locally. We note that accurate global track-ing is important to understand complex environments, as it ensures consistency in preserving identities of objects over a long period. Classical global batch methods for multi-object tracking (MOT) have been proposed in the past
[20, 3, 59, 4, 49, 2, 55]. These formulations face the second challenge: Tracking is formulated directly on object detec-tions [20, 3, 59, 4, 49, 2, 55], which leads to a combinatorial growth of options. We note that directly formulating track-ing on detections seems appealing because those are the ob-jects of interest. However, this form of data representation also complicates optimization because one needs to solve for the best path for each object in the video. Note that the number of objects is generally unknown.
To address both challenges, we propose to formulate tracking over the space of assignments rather than object detections. For this, we ﬁrst ﬁnd the top-k assignments of object detections (and segmentations) between any two consecutive frames. This is efﬁciently doable using the
Hungarian-Murty algorithm [34]. We then develop a struc-tured prediction formulation which globally scores an as-signment sequence rather than a detection sequence. By
ﬁnding the global optimizer of the structured formulation in polynomial time using dynamic programming we can ad-dress tracking in MOTS. We jointly learn the tracking pa-rameters and the detection/segmentation network. Further, to establish long term connections, we introduce a post-processing step which associates objects over longer time intervals. This step uses an assignment problem to construct long-term connections between previously unassigned ob-ject detections and detection sequences.
On the challenging KITTI-MOTS and MOTSChallenge datasets [54], the method achieves state of the art results on
MOTS when compared to other 2D methods, i.e., TrackR-CNN [54] and PointTrack [58]. On the KITTI-MOTS test data, we improve upon PointTrack [58] (the next best 2D method) by 14% (car) and 9% (pedestrian) in association (AssA) and 8% (car) and 4% (pedestrian) overall (HOTA).
On the MOTSChallenge test data, we improve upon Point-Track [58] by 5% on sMOTSA. A qualitative comparison with PointTrack [58] is shown in Fig. 1. We also improve upon MOTSFusion [27], a 3D method requiring depth in-formation, on pedestrian tracking on the KITTI-MOTS test data (8% improvement in association (AssA), 5% improve-Figure 1. Use of assignment space better preserves identities of objects when compared to PointTrack [58]. We highlight the identity switches from PointTrack using yellow rectangles. Our method is able to recover those identities (highlighted using cyan rectangles). For example, in the last 2 columns (right-most example), Point track wrongly identiﬁes two different cars to be the same (row 1 and 2). The mismatch is continued forward (row 3). ment overall (HOTA)). Quantitative results are summarized in Tab. 1, Tab. 2 and Tab. 6. To establish generality, we also study our approach on the MOT task and compare with other MOT batch methods (Tab. 7). 2.