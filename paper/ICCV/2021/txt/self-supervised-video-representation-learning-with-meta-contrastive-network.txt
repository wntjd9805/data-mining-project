Abstract
Self-supervised learning has been successfully applied to pre-train video representations, which aims at efﬁcient adaptation from pre-training domain to downstream tasks.
Existing approaches merely leverage contrastive loss to learn instance-level discrimination. However, lack of cat-egory information will lead to hard-positive problem that constrains the generalization ability of this kind of meth-ods. We ﬁnd that the multi-task process of meta learning can provide a solution to this problem. In this paper, we propose a Meta-Contrastive Network (MCN), which com-bines the contrastive learning and meta learning, to en-hance the learning ability of existing self-supervised ap-proaches. Our method contains two training stages based on model-agnostic meta learning (MAML), each of which consists of a contrastive branch and a meta branch. Ex-tensive evaluations demonstrate the effectiveness of our method. For two downstream tasks, i.e., video action recog-nition and video retrieval, MCN outperforms state-of-the-art approaches on UCF101 and HMDB51 datasets. To be more speciﬁc, with R(2+1)D backbone, MCN achieves Top-1 accuracies of 84.8% and 54.5% for video action recogni-tion, as well as 52.5% and 23.7% for video retrieval. 1.

Introduction
Convolutional Neural Networks (CNNs) have brought unprecedented success for supervised video representation learning [4, 7, 8, 48, 29] . However, labeling large-scale video data requires huge human annotations, which is ex-pensive and laborious. How to learn effective video rep-resentations by leveraging unlabeled videos is an impor-tant yet challenging problem. The recent progress of self-supervised learning for image provides an efﬁcient solution to this problem [20, 43, 21, 5], which proposed to use con-trastive loss [14, 15, 49, 51, 22] to discriminate different data samples.
*The work was done when the author was with MSRA as an intern.
Figure 1. Comparison between models trained without and with MCN on UCF101 [39]. The top row shows the activation maps produced by conv5 layer of R(2+1)D backbone using the method of [55]. By using our proposed MCN, the learned repre-sentations can capture motion areas more accurately. The bottom row shows top-1 accuracies of models trained without and with
MCN approach.
This instance-based contrastive learning has also been applied to videos as pre-training, and achieved excellent performance on downstream tasks such as video action recognition and video retrieval [18, 42, 31]. However, it has the inherent limit of lacking the common category in-formation. The instance-based discrimination process takes each video sample as an independent class, so that distance between two video samples will be pushed away by con-trastive loss even if they belong to the same category. This drawback reduces the generalization of the pre-training pa-rameters. Consequently, the efﬁciency of the supervised
ﬁne-tuning for the downstream tasks will also be dam-aged. How to improve the generalization of contrastive self-supervised learning and make the learned parameters easily adapt from pre-training domain to ﬁne-tuning domain for various new tasks is still challenging.
Meta learning has demonstrated the capability of fast 1
adaptation on new tasks with only a few training sam-ples.
The characteristic of meta learning, speciﬁcally model-agnostic meta learning (MAML) [10], might help contrastive self-supervised video learning in two aspects.
Firstly, instance-based discrimination takes each video as a class, so that it is convenient to create numerous sub-tasks for meta learning to improve the model generalization. Sec-ondly, the goal of meta learning is “learn to learn”, which means that it provides good initialization for fast adaptation on a new task. This perfectly meets the requirements of contrastive video representation learning, which is taken as a pre-training method. Therefore, combining meta learning and self-supervised learning might beneﬁt to video repre-sentation learning.
In this paper, we propose a novel Meta-Contrastive
Network (MCN), which leverages meta-learning to improve the generalization and adaptation ability of contrastive self-supervised video learning on downstream tasks. The pro-posed MCN contains two branches, i.e., contrastive branch and meta branch, which establishes a multi-task learning process to enhance the instance discrimination. Meanwhile, we design a two-stage training process based on MAML to improve the learning capability of MCN. Our method out-performs state-of-the-art methods and achieves signiﬁcant performance boost.
The main contributions of this paper are summarized as follows. 1) We propose a novel Meta-Contrastive Network (MCN), which can signiﬁcantly improve the gener-alization of the video representations learned in self-supervised learning manner. 2) We fully investigate the beneﬁts of combining meta learning with self-supervised video representation learning and conduct extensive experiments to make proposed approach better understood. 3) We evaluate our method on mainstream benchmarks tasks, which for action recognition and retrieval demonstrate that our proposed method can achieve state-of-the-art or comparable performance with other self-supervised learning approaches. 2.