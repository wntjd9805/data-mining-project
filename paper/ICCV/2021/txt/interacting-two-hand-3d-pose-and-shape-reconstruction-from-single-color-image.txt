Abstract
In this paper, we propose a novel deep learning frame-work to reconstruct 3D hand poses and shapes of two interacting hands from a single color image. Previous methods designed for single hand cannot be easily ap-plied for the two hand scenario because of the heavy
In or-inter-hand occlusion and larger solution space. der to address the occlusion and similar appearance be-tween hands that may confuse the network, we design a hand pose-aware attention module to extract features asso-ciated to each individual hand respectively. We then lever-age the two hand context presented in interaction to pro-pose a context-aware cascaded reﬁnement that improves the hand pose and shape accuracy of each hand condi-tioned on the context between interacting hands. Exten-sive experiments on the main benchmark datasets demon-strate that our method predicts accurate 3D hand pose and shape from single color image, and achieves the state-of-the-art performance. Code is available in project webpage https://baowenz.github.io/Intershape/. 1.

Introduction 3D hand pose and shape reconstruction plays an im-portant role in many applications, such as AR/VR [8] and robotics [9]. While most of the previous hand pose and shape reconstruction works [3, 41] are proposed for sin-gle hand, we study the problem of hand reconstruction for two interacting hand from single color image, as it is more desirable to express delicate body language [39] and per-form complex tasks [18, 25, 36]. However, the prior art on this topic is barely missing. Existing methods usually rely on depth sensor [19], multi-view camera system [8] or optimization over tracked motion sequence [19, 8], which however are either relative expensive, energy consuming, or sensitive to the tracking quality and initialization. Com-∗indicates corresponding author
Figure 1. Illustration of interacting hand shape reconstruction from single color image. Our method can get high-quality reconstruc-tion under heavy interhand occlusions. paratively, single color camera setup is more cost and com-putation friendly, and it is also widely available. Therefore, we focus on conducting interacting two-hand reconstruction from single color image (See Fig. 1).
Reusing similar hand reconstruction techniques designed for single hand for the two-hand scenario is non-trivial.
First, compared to the case with a single complete hand, two hands are usually heavily occluded and tightly con-tacting with each other due to the interaction, which are much harder to parse. Two hands also share similar tex-tures, which can easily confuse the network to extract fea-ture from correct regions in the image. Second, the ill-pose nature of the problem is exacerbated with the degree of the freedom of the solution space doubled. The model is error-prone and may produce two hands in unreasonable pose and shape that people would rarely or be infeasible to present.
Recently, Moon et al. [18] propose a large-scale inter-acting hand dataset named InterHand2.6M, and present an interacting hand pose estimation method. However, less
special design is conducted to handle the characteristic of two-hand pose estimation problem, and more ﬁne-grained hand shape reconstruction is also not explored in [18].
To address the above mentioned issues, we propose a novel deep learning architecture for interacting hand pose and shape estimation (See Fig. 2). Our network consists of an encoder that extracts multi-scale features, and a decoder to gradually reﬁne the prediction with feature at each level.
In the encoder, a per-hand heatmap is estimated and used to mask the image features, which is particularly effective to extract the features from correct image regions and pro-duce accurate prediction for each individual hand. On the other hand, the decoder is designed to leverage the context between interacting hands. Instead of optimizing each hand separately, we reﬁne each hand conditioned on the current estimation two hands. Our network generates attention map to reduce feature ambiguity between two hands. Different from traditional methods that generate attention map from features in a network, we propose to generate attention map directly from estimated hand shape. In order to jointly re-cover hand skeleton pose and shape, we adopt the popular hand statistical model MANO [27] and predict the MANO parameters of two hands respectively.
Our main contributions are summarized as follows: 1. We propose a novel deep learning architecture, which can estimate 3D hand pose as well as ﬁne-grained hand shapes of the interacting hands from single color im-age. Our work can also inspire several related re-searches such multiple person reconstruction, hand-object interaction reconstruction etc; 2. In order to address the feature ambiguity between two hands, we propose pose-aware attention modules to extract the key features for each hand; 3. We leverage the two-hand context presented in interac-tion and propose a cascaded reﬁnement stage improv-ing the hand pose and shape accuracy of each hand conditioned on context of interacting hands; 4. Extensive experiments shows that our method achieves state-of-the-art performance on the main datasets. 2.