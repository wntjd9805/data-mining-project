Abstract
This paper introduces a powerful channel augmented joint learning strategy for the visible-infrared recognition problem. For data augmentation, most existing methods di-rectly adopt the standard operations designed for single-modality visible images, and thus do not fully consider the imagery properties in visible to infrared matching. Our ba-sic idea is to homogenously generate color-irrelevant im-It can ages by randomly exchanging the color channels. be seamlessly integrated into existing augmentation oper-ations without modifying the network, consistently improv-ing the robustness against color variations. Incorporated with a random erasing strategy, it further greatly enriches the diversity by simulating random occlusions. For cross-modality metric learning, we design an enhanced channel-mixed learning strategy to simultaneously handle the intra-and cross-modality variations with squared difference for stronger discriminability. Besides, a channel-augmented joint learning strategy is further developed to explicitly op-timize the outputs of augmented images. Extensive experi-ments with insightful analysis on two visible-infrared recog-nition tasks show that the proposed strategies consistently improve the accuracy. Without auxiliary information, it im-proves the state-of-the-art Rank-1/mAP by 14.59%/13.00% on the large-scale SYSU-MM01 dataset. 1.

Introduction
Identity recognition (person re-identification [22], face recognition [11, 19]) systems have achieved significant suc-cess recently. However, most research efforts have been paid on the single-modality visible domain. In many night-time surveillance and low-light environments, near(far)-infrared cameras are applied to capture target appearance
*Corresponding Author: Bo Du
Figure 1. Motivation of channel augmentation. Directly recover-ing the three-channel RGB image from a single-channel infrared images is ill-posed. Instead, we propose to directly optimize the relation between the infrared images and the R, G and B channels of the visible images.
[4, 37].
This raises important cross-modality visible-infrared recognition problems, e.g., visible-infrared person re-identification (VI-ReID) [41] and NIR-VIS face recogni-tion [53]. The cross-modality matching is usually formu-lated by learning modality shared or invariant features.
Matching the infrared imagery to visible-spectrum im-ages is a significant challenge due to the large modality gap and unknown environmental factors [32, 54] (e.g., differ-ent viewpoints, occlusions, background clutter, etc.), lead-ing to large intra- and cross-modality variations. To elimi-nate the color discrepancy, cross-modality image generation with Generative Adversarial Networks (GANs) is a popular approach [36, 56] bridging the gap at the image level. How-ever, the image generation process usually needs additional computational cost and suffers from unavoidable noise [21].
Another approach is to directly employ grayscale images to perform the cross-modality matching [9, 42], where the color information is assumed to be irrelevant. While this approach does eliminate the color discrepancy, it also loses discriminative information in color channels.
This paper presents a channel exchangeable augmenta-• We present a novel channel exchangeable augmenta-tion for visible-infrared recognition. It can be seam-lessly integrated into existing augmentations oper-ations without modifying the network structure or changing the learning strategy.
• We design an enhanced channel-mixed learning scheme to simultaneously handle the intra- and cross-modality variations. With a joint learning strategy, it explicitly optimizes the channel augmented images.
• We evaluate on both visible-infrared person re-identification and face recognition, achieving signifi-cant accuracy gains under various settings. 2.