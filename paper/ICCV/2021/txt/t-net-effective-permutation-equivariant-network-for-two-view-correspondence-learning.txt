Abstract
We develop a conceptually simple, flexible, and effec-tive framework (named T-Net) for two-view correspondence learning. Given a set of putative correspondences, we reject outliers and regress the relative pose encoded by the essen-tial matrix, by an end-to-end framework, which is consist-ed of two novel structures: “ − ” structure and “|” struc-ture. “ − ” structure adopts an iterative strategy to learn correspondence features. “|” structure integrates all the features of the iterations and outputs the correspondence weight. In addition, we introduce Permutation-Equivariant
Context Squeeze-and-Excitation module, an adapted ver-sion of SE module, to process sparse correspondences in a permutation-equivariant way and capture both global and channel-wise contextual information. Extensive exper-iments on outdoor and indoor scenes show that the pro-posed T-Net achieves state-of-the-art performance. On out-door scenes (YFCC100M dataset), T-Net achieves an mAP of 52.28%, a 34.22% precision increase from the best-published result (38.95%). On indoor scenes (SUN3D dataset), T-Net (19.71%) obtains a 21.82% precision in-crease from the best-published result (16.18%). Source code: https://github.com/x-gb/T-Net. 1.

Introduction
Two-view feature matching is the core of many funda-mental computer vision problems [15, 12], including Struc-ture from Motion (SfM) [32, 25], visual Simultaneous Lo-calization and Mapping [17, 3] and image retrieval [29, 18].
However, establishing reliable correspondences is not a triv-ial task, due to a large number of false correspondences (i.e. outliers), caused by the large viewpoint and lighting changes, occlusion, blur, and lack of texture.
Recently, learning-based outlier rejection algorithm-s [16, 22, 26, 36] obtain superior matching performance due to the powerful ability in the feature extraction and nonlin-*Corresponding author
Figure 1. The proposed T-Net architecture. ear expression. The most popular networks often adopt an iterative network [22, 36], where the latter iteration inherits the weights and residuals of the previous iteration, since it can extremely boost the performance for outlier rejection.
Nevertheless, we find that a large amount of information in the previous iteration is not fully exploited, and only the last iteration result could be used as the predicted weight, which may lead to sub-optimal performance.
To further improve the performance, we develop a novel network (named T-Net), which integrates the features of all the iterations to comprehensively utilize all the information of iterations. For convenience understanding, we regard all iterations as a whole network and each iteration as the fea-ture learning of the sub-network in that network. As shown in Fig. 1, T-Net consists of two structures: “ − ” structure and “|” structure. “ − ” structure iteratively learns corre-spondence features in each sub-network, and “|” structure integrates all the features of sub-networks and learns the in-tegrated features.
Moreover, previous works [16, 22, 36] often rely on a
PointNet-like architecture with Context Normalization to learn the features. Although that module is an effective module to process unordered and sparse data (e.g., sparse correspondences), that module is not very robust to out-liers [26]. To address this issue, we introduce a novel
Permutation-Equivariant Context Squeeze-and-Excitation
(PCSE) module, which can replace PointCN [16] to cap-ture both global and channel-wise contextual information, thus, it can extremely boost the performance.
The contributions of our work are summarized as fol-lows:
• We propose a simple and effective framework, called
T-Net, which not only learns two-view correspon-dences by an iterative strategy but also synthesizes the different information of each iteration.
• We propose a reformulation of SE module in the con-text of sparse correspondences, to capture contextual information in an equivariant manner.
• We achieve state-of-the-art performance for two-view correspondence learning. On YFCC100M un-known dataset, T-Net achieves an mAP of 52.28%, a 34.22% precision increase from the best-published re-sult (38.95%). On SUN3D dataset, T-Net (19.71%) obtains a 21.82% precision increase from the best-published result (16.18%). 2.