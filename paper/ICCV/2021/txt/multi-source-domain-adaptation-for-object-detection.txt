Abstract
To reduce annotation labor associated with object de-tection, an increasing number of studies focus on transfer-ring the learned knowledge from a labeled source domain to another unlabeled target domain. However, existing meth-ods assume that the labeled data are sampled from a single source domain, which ignores a more generalized scenario, where labeled data are from multiple source domains. For the more challenging task, we propose a unified Faster R-CNN based framework, termed Divide-and-Merge Spindle
Network (DMSN), which can simultaneously enhance do-main invariance and preserve discriminative power. Specif-ically, the framework contains multiple source subnets and a pseudo target subnet. First, we propose a hierarchi-cal feature alignment strategy to conduct strong and weak alignments for low- and high-level features, respectively, considering their different effects for object detection. Sec-ond, we develop a novel pseudo subnet learning algorithm to approximate optimal parameters of pseudo target subset by weighted combination of parameters in different source subnets. Finally, a consistency regularization for region proposal network is proposed to facilitate each subnet to learn more abstract invariances. Extensive experiments on different adaptation scenarios demonstrate the effectiveness of the proposed model. 1.

Introduction
As a fundamental task in computer vision, object de-tection has drawn much attention in the past decade [34, 32, 25]. With the development of convolutional neural networks (CNNs), some modern CNN-based detectors like
Faster R-CNN [35] have emerged and been successfully ap-plied to many tasks, such as autonomous driving [10, 38], face and pedestrian detection [17, 27], etc. However, the high-quality performance of detectors is based on large-scale training images with annotated bounding boxes.
In the real world, variances exist between training and test im-ages in many aspects, including object appearance, back-ground, even taken time. Due to these domain discrepan-Figure 1. An example of domain shift in the multi-source scenario for object detection. The above images are sampled from different subsets of BDD100k [50]. Source domain Sj and Sk are taken in daytime and night, respectively, while the images in target do-main T are taken in dawn/dusk. As shown in the above results, directly combining images from multiple sources and conducting single-source domain adaptation (DA) will cause performance de-cay compared with only using the best single source domain. Note that mAP denotes mean average precision. cies, the performance on the test images may decrease dra-matically. Although annotating more training data of the new domain is able to alleviate the phenomenon, it is not an optimal strategy due to large time and labor costs.
To mitigate the domain gap, unsupervised domain adap-tation (UDA) has been widely used for object detection [6, 20, 22, 19]. Domain adaptive Faster R-CNN [6] is a mile-stone study developed for tackling the domain shift prob-lem in object detection. In the work, image-level features and instance-level features are respectively aligned through an adversarial manner. Following [6], a series of Faster R-CNN based adaptation models [57, 56] have emerged re-cently. Considering that image-level alignment transfers massive unnecessary information background for object de-tection, Zhu et al. [56] and Saito et al. [37] pay more at-tention to align informative local regions. To minimize the
domain distribution disparity on each block, He et al. [14] propose multi-adversarial Faster R-CNN to conduct layer-wise domain feature alignment. However, existing algo-rithms for domain adaptive object detection assume that the source data are sampled from a single domain, which lim-its the generalization of the model. We consider a more practical scenario that the source data are collected from multiple domains with different distributions. As shown in
Figure 1, directly combining two sources and performing single-source domain adaptation (DA) cause performance decay compared with the best result of a single domain, i.e. 29.9% vs. 31.4%. It is mainly resulted from the mu-tual interference between different sources that exist serious domain discrepancy, which is also demonstrated in other tasks [54, 29, 36]. Therefore, we need to design a special-ized framework for domain adaptive object detection from multiple sources.
Though multi-source domain adaptation has been ex-plored for other tasks, such as image classification [54, 48] and segmentation [53], they all belong to the straightfor-ward classification task regardless of image-level or pixel-level. However, detection model like Faster R-CNN is a complex system for both regression and classification, and it contains multiple components including feature extrac-tor, region proposal network (RPN), etc. In this paper, for the new task, we develop a framework termed Divide-and-Merge Spindle Network (DMSN), in which multiple source subnets and a pseudo subnet are included. First, we pro-pose a hierarchical feature alignment strategy. Since low-level features have high resolution that is important to local-ization [30], we perform strong alignment for them of dif-ferent domains. For the high-level features that are impor-tant for object recognition, we weakly align each source and target in corresponding supervised source subnet. Second, to approximate optimal parameters for the target domain, we develop a pseudo subnet learning (PSL) algorithm, in which the pseudo subnet is updated via exponential mov-ing average (EMA) [42] parameters of different source sub-nets. Finally, a new consistency regularization on region proposals are conducted between each source subnet and the pseudo target, which enables the model to capture more robust instance-level invariances for object detection. In the testing phase, the predictions of each subnet are merged into final inference.
In summary, our contributions are threefold.
• We propose to conduct domain adaptation for object detection from multiple sources. To the best of our knowledge, this is the first work on multi-source do-main adaptation for object detection that contains both classification and regression.
• We propose a unified framework termed DMSN to tackle the new problem. The characteristics of each source domain are preserved in each independent su-pervised source subnet. Meanwhile, an optimal pseudo subnet is approximated by aggregating parameters of different source subnets.
• A new consistency regularization is designed to facili-tate each source subnet to propose similar region pro-posals with the pseudo subnet, so that the model is able to learn more abstract invariances. The results of ex-tensive experiments demonstrate the effectiveness of our proposed framework. 2.