Abstract
We address the task of Re-Identification (Re-ID) in multi-target multi-camera (MTMC) tracking where we track mul-tiple pedestrians using multiple overlapping uncalibrated
Since the videos are tempo-(unknown pose) cameras. rally synchronized and spatially overlapping, we can see a person from multiple views and associate their trajectory across cameras.
In order to find the correct association between pedestrians visible from multiple views during the same time window, we extract a visual feature from a track-let (sequence of pedestrian images) that encodes its simi-larity and dissimilarity to all other candidate tracklets. We propose a inter-tracklet (person to person) attention mecha-nism that learns a representation for a target tracklet while taking into account other tracklets across multiple views.
Furthermore, to encode the gait and motion of a person, we introduce second intra-tracklet (person-specific) atten-tion module with position embeddings. This second module employs a transformer encoder to learn a feature from a se-quence of features over one tracklet. Experimental results on WILDTRACK and our new dataset ‘ConstructSite’ con-firm the superiority of our model over state-of-the-art ReID methods (5% and 10% performance gain respectively) in the context of uncalibrated MTMC tracking. While our model is designed for overlapping cameras, we also obtain state-of-the-art results on two other benchmark datasets (MARS and DukeMTMC) with non-overlapping cameras. 1.

Introduction
Multi-Target Multi-Camera (MTMC) tracking [22, 37] relies deeply on the ability to associate people between mul-tiple cameras to determine the position of each person over time. Depending on the situations, the cameras may be syn-chronized, calibrated (known position) or have overlapping views. In this work, we focus on the case where cameras are synchronized with overlapping views, but the calibra-tion information is not available. Our aim is to develop a method that can perform association of pedestrian trajecto-ries across cameras without using any calibration informa-Figure 1: Multi-target multi-camera tracking with over-lapping views. When the target person is seen from multi-ple synchronized cameras (views), identifying the person is feasible by finding the similarities and dissimilarities across multiple views. Note that the geometry information such as the position of each camera may not be known. tion about the cameras (shown in Figure 1).
In order to develop such a method for data associa-tion across uncalibrated cameras, we need to extract a dis-criminative feature for each person over a sequence of im-age patches (tracklet) and perform feature matching across tracklets in different cameras. This process we have de-scribed is a form of the Re-Identification (Re-ID) prob-lem [71].
In the time-synchronized MTMC scenario, the
Re-ID problem is simplified since we only need to match pedestrians appearing in multiple cameras during the same time window. Within this time window, we would like to extract visual features that are both representative and dis-criminative (sufficiently different from other pedestrians in the same view) so that we can match people across camera views.
To learn both a representative and discriminative visual feature for robust person association across views, we pro-pose a novel video-based Re-ID model using Transform-ers [50]. Since attention models [63] has the ability to learn and embed the similarity and dissimilarity between differ-ent synchronized tracklets from overlapping views, it can be used to learn representative and discriminative visual fea-tures. We use attention models in two ways: (1) we intro-duce an inter-tracklet attention model to learn the correla-tion between tracklets across cameras and (2) we introduce an intra-tracklet attention module (before the inter-tracklet attention model) to learn a person-specific motion and ap-pearance feature.
In order to evaluate our Re-ID method for MTMC track-ing, we use a construction site dataset (which we call Con-structSite) provided by a construction company. Videos in the dataset are recorded in a construction site with unknown camera positions. Recorded with four synchronized cam-eras, this dataset has 88 videos (3-minute long) where each synchronized camera has 22 videos. As mentioned above, our Re-ID method is designed intentionally for overlapping, time synchronized, uncalibrated cameras. We also per-form experiments on two other public benchmark datasets (MARS and DukeMTMC) with non-overlapping cameras.
The contributions of this paper are highlighted below: 1. We introduce a transformer-based inter-tracklet attention module that computes a discriminative feature represen-tation by taking into account all other time synchronized tracklets across all camera views. 2. In order to learn a person-specific motion and appear-ance feature, we introduce an transformer-based intra-tracklet attention module to learn a compact representa-tion for each tracklet. 3. We show superior Re-ID performance in the time syn-chronized uncalibrated setting. Furthermore, we apply our method to the case of non-overlapping cameras. We show how our method is able to generalize to harder sce-narios while also advancing the state of the art. 2.