Abstract
We present QueryInst, a new perspective for instance segmentation. QueryInst is a multi-stage end-to-end sys-tem that treats instances of interest as learnable queries, enabling query based object detectors, e.g., Sparse R-CNN, to have strong instance segmentation performance.
The attributes of instances such as categories, bounding boxes, instance masks, and instance association embed-dings are represented by queries in a unified manner.
In
QueryInst, a query is shared by both detection and segmen-tation via dynamic convolutions and driven by parallelly-supervised multi-stage learning. We conduct extensive ex-periments on three challenging benchmarks, i.e., COCO,
CityScapes, and YouTube-VIS to evaluate the effectiveness of QueryInst in object detection, instance segmentation, and video instance segmentation tasks. For the first time, we demonstrate that a simple end-to-end query based frame-work can achieve the state-of-the-art performance in vari-ous instance-level recognition tasks. Code is available at https://github.com/hustvl/QueryInst. 1.

Introduction
Instance segmentation is a fundamental yet challenging computer vision task that requires an algorithm to assign a pixel-level mask with a category label for each instance of interest in image. Prevalent state-of-the-art instance seg-mentation methods are based on high performing object de-tectors and follow a multi-stage paradigm. Among which, the Mask R-CNN family [22, 25, 32, 5, 10, 44] is the most successful one, where the regions-of-interest (RoI) for in-stance segmentation is extracted via a region-wise pooling operation (e.g., RoIPool [23, 20] or RoIAlign [22]) based on the box-level localization information from the region pro-posal network (RPN) [41], or the previous stage bounding-*Equal contributions. This work was done while Shusheng Yang was interning at Applied Research Center (ARC), Tencent PCG.
†Corresponding author, E-mail: xgwang@hust.edu.cn.
Figure 1: AP vs. FPS on COCO test-dev. QueryInst out-performs current state-of-the-art methods in terms of both accuracy and speed. The speed is measured using a single
Titan Xp GPU. box prediction [4, 5]. The final instance mask is obtained via feeding the RoI feature into the mask head, which is a small fully convolutional network (FCN) [35].
Recently, DETR [7] is proposed to reformulate object detection as a query based direct set prediction problem, whose input is mere 100 learned object queries. Follow-up works [63, 44, 45, 19, 60, 16] in object detection improve this query based approach and achieve comparable perfor-mance with state-of-the-art detectors such as Cascade R-CNN [4]. The results show that query based instance-level perception is a very promising research direction. Thus, enabling query based detection framework to perform in-stance segmentation is highly desirable. However, we find that it is inefficient to integrate the previous successful prac-tices in Cascade Mask R-CNN [5] and HTC [10], which are state-of-the-art mask generation solutions in the non-query based paradigm, directly into query based detectors for in-stance mask generation. Therefore, an instance segmenta-tion method tailored for the query based end-to-end frame-work is urgently needed.
To bridge this gap, we propose QueryInst (Instances as
Queries), a query based end-to-end instance segmentation method driven by parallel supervision on dynamic mask heads [26, 46, 44]. The key insight of QueryInst is to leverage the intrinsic one-to-one correspondence in object queries across different stages, and one-to-one correspon-dence between mask RoI features and object queries in the same stage. Specifically, we set up dynamic mask heads in parallel with each other, which transform each mask RoI feature adaptively according to the corresponding query, and are simultaneously trained in all stages. The mask gra-dient not only flows back to the backbone feature extractor, but also to the object query, which is intrinsically one-to-one interlinked in different stages. The queries implicitly carry the multi-stage mask information, which is read by
RoI features in dynamic mask heads for final mask genera-tion. There is no explicit connection between different stage mask heads or mask features. Moreover, the queries are shared between object detection and instance segmentation sub-networks in each stage, enabling cross-task communi-cations that one task can take advantage of the information from the other task. We demonstrate that this shared query design can fully leverage the synergy between object detec-tion and instance segmentation. When the training is com-pleted, we throw away all the dynamic mask heads in the intermediate stages and only use the final stage predictions for inference. Under such a scheme, QueryInst surpasses the state-of-the-art HTC in terms of AP while runs much faster. Concretely, our main contributions are summarized as follows:
• We attempt to solve instance segmentation from a new perspective that uses parallel dynamic mask heads in the query based end-to-end detection framework.
This novel solution enables such a new framework to outperform well-established and highly-optimized non-query based multi-stage schemes such as Cascade
Mask R-CNN and HTC in terms of both accuracy and speed (see Fig. 1). Our best model achieves 56.1 APbox and 49.1 APmask on COCO test-dev.
• We set up a task-joint paradigm for query based ob-ject detection and instance segmentation by leverag-ing the shared query and multi-head self-attention de-sign. This paradigm establishes a kind of communi-cation and synergy between detection and segmenta-tion tasks, which encourages these two tasks to ben-efits from each other. We demonstrate that our archi-tecture design can also significantly improve the object detection performance.
• We extend the QueryInst to video instance seg-mentation task (VIS) [59] task by simply adding a vanilla track head. Experiments on YouTube-VIS dataset [59] indicate that with same tracking approach, our methods outperforms MaskTrack R-CNN [59] and
SipMask-VIS [6] by a large margin. QueryInst-VIS can even outperform well-designed VIS approaches such as STEm-Seg [1] and VisTR [55]. 2.