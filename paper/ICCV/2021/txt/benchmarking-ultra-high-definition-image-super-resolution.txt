Abstract
Increasingly, modern mobile devices allow capturing im-ages at Ultra-High-Deﬁnition (UHD) resolution, which in-cludes 4K and 8K images. However, current single image super-resolution (SISR) methods focus on super-resolving images to ones with resolution up to high deﬁnition (HD) and ignore higher-resolution UHD images. To explore their performance on UHD images, in this paper, we ﬁrst in-troduce two large-scale image datasets, UHDSR4K and
UHDSR8K, to benchmark existing SISR methods. With 70,000 V100 GPU hours of training, we benchmark these methods on 4K and 8K resolution images under seven differ-ent settings to provide a set of baseline models. Moreover, we propose a baseline model, called Mesh Attention Net-work (MANet) for SISR. The MANet applies the attention mechanism in both different depths (horizontal) and differ-ent levels of receptive ﬁeld (vertical). In this way, correla-tions among feature maps are learned, enabling the network to focus on more important features. 1.

Introduction
The task of single image super-resolution (SISR) is to produce an image of high resolution (HR) given a low res-olution (LR) input. In practice, image super-resolution has a wide range of applications, such as medical image anal-ysis [33], image generation [19], and face recognition at large distances [53]. Super-resolving images is inherently ill-posed, i.e., one LR image can correspond to multiple HR images. To tackle this problem, traditional methods use prior cues from HR images or LR exemplar images [14, 12, 46, 13, 6, 22, 47, 11, 18, 37, 31]. Recent deep learn-ing methods remove the need to explicitly design different types of priors. Networks are trained with pairs of corre-sponding HR and LR images in an end-to-end manner. With sufﬁcient training data, deep learning models have achieved impressive results [8, 44, 32, 20, 35, 26, 51, 52, 29, 43].
Most of them are trained based on HD images of up to 2K resolution, with the DIV8K [15] dataset being an excep-tion. Thus, it is not clear how they perform in the case of ultra-high deﬁnition (UHD) images, including 4K and 8K resolution images. Currently, an increasing number of mo-bile devices supports capturing images at these resolutions.
UHD images provide better visual pleasing effects and they are also better to train SISR approaches, applicable to large upscaling factors like 8× or 16×. In this paper, we explore the SR performance of current SISR methods on such UHD images. We collect two large-scale datasets of images with resolutions of 4K and 8K, respectively, from the Internet.
The 4K dataset, UHDSR4K, includes 5, 999 and 2, 100 im-ages for training and testing, respectively. The 8K dataset,
UHDSR8K, contains 2, 029 training and 937 test images, re-spectively. As far as we know, UHDSR4K and UHDSR8K are the largest UHD image datasets for 4K and 8K image super-resolution, respectively. Sample images are shown in
Fig. 1.
We propose seven settings to assess the performance of existing methods. These include different upsampling fac-tors (from 2× to 16×), and two additional settings to eval-uate common image degradations, blur plus downsampling and downsampling plus noise. We evaluate ten recent SISR methods on these datasets, and train the respective models on the new datasets. Training one model on a single dataset takes approximately three weeks, and the total training time for all models was over 70, 000 V100 GPU hours.
By conducting this benchmarking study, we thus ob-tain comprehensive understanding of how the current SISR models work in the speciﬁc 4K and 8K settings, both in terms of standard metrics, such as PSNR and SSIM, and perceptual quality.
Further, we propose a Mesh Attention Network (MANet) to improve the feature representation ability via learning the inter-dependencies between different feature maps. Specif-ically, MANet is a mesh architecture, whose horizontal and vertical layers represent the feature maps from different depths and different receptive ﬁelds, respectively. Within the MANet, a novel mesh attention module is introduced to simultaneously learn the relationship between features from different depths and different levels of receptive ﬁelds. Fi-1
(a) Sample images from the UHDSR4K dataset.
Figure 1. Sample images from the UHDSR4K and UHDSR8K datasets. These two datasets consist of a large number of 4K and 8K
UHD images, respectively. (b) Sample images from the UHDSR8K dataset. nally, the weighted sum of feature maps from horizontal and vertical layers allows the MANet to focus on informative depths and receptive ﬁelds from input LR features to recon-struct SR images.
In summary, the contributions of this paper are three-fold:
• First, we introduce two large-scale UHD image datasets for super resolving. To our knowledge, they are the largest-scale UHD datasets in the ﬁeld of 4K and 8K image super-resolution.
In addition, both datasets provide seven degradation settings to conve-niently evaluate SISR methods.
• Second, we extensively evaluate the state-of-the-art
SISR methods on the two datasets. By doing so, we are able to understand the potential and limitations of these methods.
• Third, we propose a baseline model, called MANet for
SISR with a novel mesh attention module. Experi-ments verify its effectiveness on the UHD SISR task. 2.