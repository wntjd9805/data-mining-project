Abstract
We present SSOD – the ﬁrst end-to-end analysis-by-synthesis framework with controllable GANs for the task of self-supervised object detection. We use collections of real-world images without bounding box annotations to learn to synthesize and detect objects. We leverage controllable
GANs to synthesize images with pre-deﬁned object prop-erties and use them to train object detectors. We propose a tight end-to-end coupling of the synthesis and detection networks to optimally train our system. Finally, we also propose a method to optimally adapt SSOD to an intended target data without requiring labels for it. For the task of car detection, on the challenging KITTI and Cityscapes datasets, we show that SSOD outperforms the prior state-of-the-art purely image-based self-supervised object detec-tion method Wetectron. Even without requiring any 3D
CAD assets, it also surpasses the state-of-the-art rendering-based method Meta-Sim2. Our work advances the ﬁeld of self-supervised object detection by introducing a success-ful new paradigm of using controllable GAN-based image synthesis for it and by signiﬁcantly improving the base-line accuracy of the task. We open-source our code at https://github.com/NVlabs/SSOD. 1.

Introduction
Object detection plays a crucial role in various au-tonomous vision pipelines, e.g., in robotics and self-driving. Convolutional neural networks-based detection methods, such as [40, 32], have achieved impressive per-formance. However, they are fully-supervised and require large amounts of human annotated data, which is time-consuming to acquire for all object types and operating en-vironments. They also do not scale well when target do-mains change, e.g., from one city to another in self-driving.
To reduce annotations, some existing works train detec-tors without requiring bounding box annotations and follow two paradigms. The ﬁrst is of self/weakly supervised ob-ject detection methods [41, 42, 53], which either use image-level object presence labels (a.k.a. self-supervision) or point/scribble annotations (a.k.a weak-supervision). They also rely on high-quality object proposals detected by
*Siva Karthik Mustikovela was an intern at NVIDIA during the project.
Figure 1. Self-Supervised Object Detection. We learn object de-tection purely using natural image collections without bounding box labels. We leverage controllable GANs to synthesize images and to detect objects together in a tightly coupled framework. We learn image synthesis from unlabeled singe-object source images (e.g., Compcars [52]) and optimally adapt our framework to any multi-object unlabeled target dataset (e.g., KITTI [15]). methods requiring human annotations [57]. The second paradigm is of rendering-based methods, including Meta-Sim [26] and Meta-Sim2 [10], which learn object detec-tion from synthetically rendered images. Creating them, however, requires large collections of high-quality 3D CAD models for all the objects in the scene, manual scene setups and expensive rendering engines. Such images also tends to have a large domain gap from real-world ones.
Recently, there has been much progress in making Gen-erative Adversarial Networks (GANs) [16] controllable us-ing input parameters like shape, viewpoint, position and keypoints [36, 37, 38, 45], opening up the possibility of synthesizing images with desired attributes. Controllable
GANs have also been used successfully to learn other vi-sion tasks, e.g., viewpoint [34] and keypoints [50, 56, 22] estimation in a self-supervised manner, but have not been explored previously for self-supervised object detection.
Inspired by these, we propose the ﬁrst end-to-end analysis-by-synthesis framework for self-supervised object detection using controllable GANs, called SSOD (Fig. 1).
We learn to both synthesize images and detect objects purely using unlabeled image collections, i.e., without re-quiring bounding box-labels and without using 3D CAD
assets – a multi-faceted challenge not addressed previ-ously. We learn a generator for object image synthesis using real-world single-object image collections without bound-ing box labels. By leveraging controllable GANs, which provide control over the 3D location and orientation of an object, we also obtain its corresponding bounding box an-notation. To optimally train SSOD, we tightly couple the synthesis and detection networks in an end-to-end fashion and train them jointly. Finally, we learn to optimally adapt
SSOD to a multi-object target dataset, also without requir-ing labels for it and improve accuracy further.
We validate SSOD on the challenging KITTI [15] and
Cityscapes [8] datasets for car object detection. SSOD out-performs the best prior image-based self-supervised object detection method Wetectron [42] with signiﬁcantly better detection accuracy. Furthermore, even without using any 3D CAD assets or scene layout priors it also surpasses the best rendering-based method Meta-Sim2 [10]. To the best of our knowledge, SSOD is the ﬁrst work to explore using controllable GANs for fully self-supervised object detec-tion. Hence, it opens up a new paradigm for advancing fur-ther research in this area. SSOD signiﬁcantly outperforms all competing image-based methods and serves as a strong baseline for future work.
To summarize, our main contributions are:
• We propose a novel self-supervised object detec-tion framework via controllable generative synthesis, which uses only image collections without any kind of bounding box annotations.
• We propose an end-to-end analysis-by-synthesis framework, which can optimally adapt the synthesizer to both the downstream task of object detection and to a target dataset in a purely self-supervised manner.
• Our experiments on two real-world datasets show ∼2x performance improvement over SOTA image-based self-supervised object detection methods. Also, with-out using 3D CAD assets, SSOD outperforms on aver-age, the rendering-based baseline of Meta-Sim2 [10]. 2.