Abstract
Rapid progress in 3D semantic segmentation is insepara-ble from the advances of deep network models, which highly rely on large-scale annotated data for training. To address the high cost and challenges of 3D point-level labeling, we present a method for semi-supervised point cloud semantic segmentation to adopt unlabeled point clouds in training to boost the model performance. Inspired by the recent con-trastive loss in self-supervised tasks, we propose the guided point contrastive loss to enhance the feature representation and model generalization ability in semi-supervised setting.
Semantic predictions on unlabeled point clouds serve as pseudo-label guidance in our loss to avoid negative pairs in the same category. Also, we design the confidence guid-ance to ensure high-quality feature learning. Besides, a category-balanced sampling strategy is proposed to col-lect positive and negative samples to mitigate the class im-balance problem. Extensive experiments on three datasets (ScanNet V2, S3DIS, and SemanticKITTI) show the effec-tiveness of our semi-supervised method to improve the pre-diction quality with unlabeled data. 1.

Introduction 3D point cloud semantic segmentation is a fundamental and essential perception task for many downstream applica-tions [20, 34, 45, 16]. Existing deep-learning-based meth-ods for the task heavily rely on the availability and quantity of labeled point cloud data for the model training. How-ever, 3D point-level labeling is time-consuming and labor-intensive. Compared with point cloud labeling, point cloud collection requires much less effort, mainly by means of 3D scanning followed by some data post-processing. Hence, we are motivated to explore semi-supervised learning (SSL) for improving the data efficiency and performance of deep segmentation models with unlabeled point clouds.
While SSL has been widely explored for tasks on 2D images [9, 21, 39, 27, 48, 29, 17], it is rather underexplored for 3D point clouds. To achieve SSL, a common strategy
Input Point Cloud
Without Pseudo Guidance With Our Pseudo Guidance
Figure 1. Visualizations of feature embeddings for unlabeled data under different loss strategies, separately trained on the indoor
ScanNet V2 [6] (top) and outdoor SemanticKITTI [2] (bottom) with 20% labeled data. Our proposed pseudo guidance enhances the feature learning, with feature embeddings in different cate-gories being better separated (middle vs. right columns). is consistency regularization [21, 39], which aligns features of the same image/pixel under different perturbations for maintaining the prediction consistency when exploiting un-labeled data. Our method shares this common ground in
SSL by encouraging similar and robust features for matched 3D point pairs with different transformations. Yet, inspired by the contrastive loss applied in self-supervised learn-ing [10, 47, 11, 3], we further enhance the feature represen-tation by proposing the guided point contrastive loss to ad-ditionally enlarge the distance between inter-category fea-tures by using the semantic predictions as guidance in the semi-supervised setting.
Contrastive learning starts with works on 2D images, and is recently extended by PointContrast [44] to 3D point clouds as a pre-training pretext task in a self-supervised set-ting. The point contrastive loss encourages the matched positive point pairs to be similar in the embedding space while pushing away the negative pairs. Yet, without any label, negative pairs in the same category may also be sam-pled, especially for large objects (e.g., sofa) and redun-dant background classes (e.g., floor and wall); these nega-tive pairs actually weaken the features’ discriminative abil-ity. Unlike PointContrast, we leverage a few labeled point
clouds to optimize the network model for producing point-level semantic predictions, and meanwhile, utilize the pre-dicted semantic scores and labels for the unlabeled data to guide the contrastive loss computation. Our pseudo-label guidance helps alleviate the side effect of intra-class nega-tive pairs in feature learning, while our confidence guidance utilizes the semantic scores to reduce the chance of feature worsening. Also, we propose a category-balanced sampling strategy to exploit pseudo labels to mitigate the class im-balance issue in point sampling, helping to preserve point samples from rare categories and to improve the feature di-versity in contrastive learning. As revealed in the t-SNE vi-sualizations in Fig. 1, the model equipped with our pseudo guidance learns more discriminative point-wise features.
We follow the conventional practice in SSL to conduct experiments with a small portion of labeled data and a larger portion of unlabeled data and then evaluate how effective an SSL method improves the performance with the unla-beled data. Excellent performance for both indoor (ScanNet
V2 [6] and S3DIS [1]) and outdoor (SemanticKITTI [2]) scenes are obtained, showing the effectiveness of our semi-supervised method, which surpasses the supervised-only models with 5%, 10%, 20%, 30%, and 40% labeled data by a large margin consistently on all three datasets. Also, we experiment with 100% labeled data, in which the la-beled set is also fed into the unsupervised branch with our guided point contrastive loss as an auxiliary feature learning loss. In this case, the accuracy of our method still exceeds the baseline with only supervised cross entropy loss, show-ing that without extra unlabeled data, our guided point con-trastive loss also helps to refine the feature representation and model’s discriminative ability.
Our contributions are threefold:
• We adopt semi-supervised learning to 3D scene se-mantic segmentation, demonstrating that unlabeled point clouds can help to enhance the feature learning in both indoor and outdoor scenes.
• We extend contrastive learning to 3D point cloud semi-supervised semantic segmentation with pseudo-label guidance and confidence guidance.
• We propose a category-balanced sampling strategy to alleviate the point class imbalance issue and to increase the embedding diversity. 2.