Abstract
This paper tackles the problem of table structure pars-ing (TSP) from images in the wild. In contrast to existing studies that mainly focus on parsing well-aligned tabular images with simple layouts from scanned PDF documents, we aim to establish a practical table structure parsing sys-tem for real-world scenarios where tabular input images are taken or scanned with severe deformation, bending or occlusions. For designing such a system, we propose an approach named Cycle-CenterNet on the top of CenterNet with a novel cycle-pairing module to simultaneously detect and group tabular cells into structured tables. In the cycle-pairing module, a new pairing loss function is proposed for the network training. Alongside with our Cycle-CenterNet, we also present a large-scale dataset, named Wired Table in the Wild (WTW), which includes well-annotated structure parsing of multiple style tables in several scenes like photo, scanning files, web pages, etc.. In experiments, we demon-strate that our Cycle-CenterNet consistently achieves the best accuracy of table structure parsing on the new WTW dataset by 24.6% absolute improvement evaluated by the
TEDS metric. A more comprehensive experimental analysis also validates the advantages of our proposed methods for the TSP task. 1.

Introduction
Tables are commonly used in our daily life to record and summarize important data for quick and better visualization of information. With the increasing popularity of smart-phones and portable cameras, it is very common to share in-formation with photo of tables. Accordingly, it is highly de-manded to automatically extract and parse table structures from photos or images in the wild.
*Equal Contribution.
â€ Correspondence Author. t u p n
I
] 9 1
[ t i l p
S b a
T s t l u s e
R r u
O
TSP in Document images
TSP in the wild
Figure 1. Visual comparison for the difference between the prob-lem of table structure parsing (TSP) in document images and the images taken in the wild. We leverage the state-of-the-art approach for document images proposed in [19] and our proposed Cycle-CenterNet for both input images to obtain the parsing results.
Given an image, Table Structure Parsing (TSP) aims at extracting all the tables, locating their cells, and obtain-ing the row-column information in the image. Previously, this problem is studied as table structure recognition fo-cusing on document images.
In such scenario, the tabu-lar images are taken with well imaging conditions and are often horizontally (or vertically) aligned with clean back-ground and clear table structures. Early pioneering works, e.g. [7, 8, 20, 6], tackle the TSP problem in a bottom-up manner by heuristically grouping detected cells based on low-level cues (e.g., lines, boundaries and word regions).
Recently, deep learning-based approaches are presented to avoid the heuristic grouping scheme design and resort to de-1
veloping end-to-end models. However, limited by the train-ing datasets [9, 17, 2, 24, 5] used for table structure parsing, they still addressed this problem under the well-aligned as-sumption of tabular images.
For a more practical requirement of parsing table struc-tures from images taken by hand-held cameras in the wild, the existing state-of-the-art approaches
[13, 14, 11, 16, 9, 23] are prone to fail as the commonly-used assump-tion of tabular images no longer holds. Specifically, the tabular images in the widely-used datasets (e.g., ICDAR-2013 [5], Tablebank [9]) are usually with clean background and clear table structures. Limited by this, existing TSP ap-proaches can only handle table structure parsing in a rel-ative simple scenario by grouping detected cells into ta-bles [11, 16, 9, 23]. Moreover, few research pays attention to the precision of cell boundary, which is important in text recognition.
To tackle the TSP problem in the wild, we present a large-scale dataset in this paper to address the data lacking issue. When we collecting the real-scene tabular images, we found that the wired tables and wireless tables have a very large difference. The wireless tables in natural im-ages are very challenging to be recognized as the lacking of reference for perceptual grouping by human annotators.
Therefore, we mainly focus on the challenging wired tables for annotation. Our proposed dataset, the Wired Tables in the Wild (WTW), contains 14,581 images with the anno-tated information of table id, tabular cells and correspond-ing row/column information. Following the data splitting strategy used in ICDAR 2019 [3], we split our WTW into training/testing subsets with 10,970 and 3611 data samples respectively.
As shown in Fig. 1, the images in the WTW dataset are very different from the document images, which thus poses a new problem to the table structures parsing task. For in-stance, the non-rigid image deformation and complicated image background presented in natural images will chal-lenge existing approaches [14] for document images on de-tecting and grouping the tabular cells.
With our proposed WTW dataset available, we address the problem of table structure parsing in the wild by propos-ing a simple yet effective approach Cycle-CenterNet. It si-multaneously detects the vertices and center points of tab-ular cells, and groups the cells into tables by learning the common vertices. Specifically, we found that the center point and vertices of a cell have a mutual-directed relation-ship that can be used to group the cells into tables by us-ing the common vertex that is located in the intersect of the adjacent cells. Based on this, we propose a loss function named pairing loss to end-to-end group the cells in train-ing phase. Once the structures of tables are obtained, we use a simple post-processing algorithm to retrieve the row
In experi-and column information for the parsed tables. ments, we evaluate the proposed Cycle-CenterNet on WTW dataset. Compared with the strong baseline of vanilla Cen-terNet, our approach largely improves the F1-score of phys-ical coordinate accuracy from 73.1% to 78.3%, while im-proves the F1-score of adjacent relationship estimation from 84.8% to 92.4%. In the metric of TEDS [24], the proposed
Cycle-CenterNet also obtains an absolute improvement by 24.6 points.
Our contributions are summarized as follows:
- We build a large-scale dataset in wild complex scenes, which provides a variety of new challenges for table structure parsing with several real image distortions.
- We present an approach Cycle-CenterNet by exploit-ing the cycle-pairing module optimization with a novel pairing loss proposed, which enables us to precisely group the discrete cells into the structured tables.
- In the experiments, our method improves the perfor-mance of table structure parsing on the WTW dataset by large margins. It also outperforms the state-of-the-art methods on the ICDAR2019 dataset, and achieves competitive results on the ICDAR2013 dataset. 2.