Abstract 1.

Introduction
In this paper, by modeling the point cloud registration task as a Markov decision process, we propose an end-to-end deep model embedded with the cross-entropy method (CEM) for unsupervised 3D registration. Our model con-sists of a sampling network module and a differentiable
CEM module.
In our sampling network module, given a pair of point clouds, the sampling network learns a prior sampling distribution over the transformation space. The learned sampling distribution can be used as a ªgoodº ini-tialization of the differentiable CEM module. In our differ-entiable CEM module, we first propose a maximum consen-sus criterion based alignment metric as the reward function for the point cloud registration task. Based on the reward function, for each state, we then construct a fused score function to evaluate the sampled transformations, where we weight the current and future rewards of the transfor-mations. Particularly, the future rewards of the sampled transforms are obtained by performing the iterative closest point (ICP) algorithm on the transformed state. By select-ing the top-k transformations with the highest scores, we iteratively update the sampling distribution. Furthermore, in order to make the CEM differentiable, we use the sparse-max function to replace the hard top-k selection. Finally, we formulate a Geman-McClure estimator based loss to train our end-to-end registration model. Extensive experimen-tal results demonstrate the good registration performance of our method on benchmark datasets. Code is available at https://github.com/Jiang-HB/CEMNet.
∗Corresponding authors
Haobo Jiang, Yaqi Shen, Jin Xie, Jun Li, Jianjun Qian and Jian Yang are with PCA Lab, Key Lab of Intelligent Perception and Systems for
High-Dimensional Information of Ministry of Education, and Jiangsu Key
Lab of Image and Video Understanding for Social Security, School of
Computer Science and Engineering, Nanjing University of Science and
Technology, China.
Point cloud registration is the problem of finding the op-timal rigid transformation (i.e., a rotation matrix and a trans-lation vector) that can align the source point cloud to the target precisely. It plays important roles in a variety of 3D vision applications such as 3D reconstruction [1, 38, 20],
Lidar SLAM [12, 57], 3D object location [14, 46, 31]. How-ever, various challenges such as outliers and noise interfer-ence still hinder its application in the real world.
Owing to discriminative feature extraction of deep neural networks, deep point cloud registration methods [48, 49, 28] have shown impressive performance. Nevertheless, most of their success mainly depends on large amounts of ground-truth transformations for supervised point cloud registra-tion, which greatly increases their training costs. To avoid it, recent efforts have been devoted to developing an unsu-pervised registration model. For example, cycle consistency is used as the self-supervision signal to train the registration models in [19, 54]. However, the cycle-consistency loss may not be able to deal with the partially-overlapping case well, since the outliers cannot form a closed loop. In addi-tion, unsupervised point cloud registration methods [47, 25] learn the transformation by minimizing the alignment er-ror (e.g., Chamfer metric) between the transformed source point cloud and the target point cloud. Nevertheless, for a pair of point clouds with complex geometry, the optimiza-tion of the alignment error between them may be difficult and prone to sticking into the local minima.
Inspired by the model based reinforcement learning (RL)
[22, 21], in this paper, we propose a novel sampling network guided cross-entropy method for unsupervised point cloud registration. By formulating the 3D registration task as a
Markov decision process (MDP), it is expected to heuris-tically search for the optimal transformation by gradually narrowing its interest transformation region through trial and error. Our deep unsupervised registration model con-sists of two modules, i.e., sampling network module and dif-ferentiable cross-entropy method (CEM) module. Given a
pair of source and target point clouds, the sampling network aims to learn a prior Gaussian distribution over the trans-formation space, which can provide the subsequent CEM module a proper initialization. With the learned sampling distribution, the differentiable CEM further searches for the optimal transformation by iteratively sampling the transfor-mation candidates, evaluating the candidates, and updat-ing the distribution. Specifically, in the sampling network module, we utilize the learned matching map with the local geometric feature for the mean estimation of the sampling distribution and exploit the global feature for variance es-timation, respectively. In the CEM module, a novel fused score function combining the current and the future rewards is designed to evaluate each sampled transformation. Par-ticularly, the future reward is estimated by performing the
ICP algorithm on the transformed source point cloud and the target point cloud. In addition, the differentiability in our CEM module is achieved by softening the sorting based top-k selection with a differentiable sparsemax function. Fi-nally, we formulate a scaled Geman-McClure estimator [58] based loss function to train our model, where the sublinear convergence speed for the outliers can weaken the negative impact on registration precision from the outliers.
To summarize, our main contributions are as follows:
• We propose a novel end-to-end cross-entropy method based deep model for unsupervised point cloud regis-tration, where a prior sampling distribution is predicted by a sampling network to quickly focus on the promis-ing searching region.
• In the cross-entropy method, we design a novel ICP driven fused reward function for accurate transfor-mation candidate evaluation and propose a spasemax function based soft top-k selection mechanism for the differentiability of our model.
• Compared to the unsupervised or even some fully su-pervised deep methods, our method can obtain out-standing performance on extensive benchmarks. 2.