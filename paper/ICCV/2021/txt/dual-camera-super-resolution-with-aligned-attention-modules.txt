Abstract
We present a novel approach to reference-based super-resolution (RefSR) with the focus on dual-camera super-resolution (DCSR), which utilizes reference images for high-quality and high-ﬁdelity results. Our proposed method generalizes the standard patch-based feature matching with spatial alignment operations. We further explore the dual-camera super-resolution that is one promising applica-tion of RefSR, and build a dataset that consists of 146 image pairs from the main and telephoto cameras in a smartphone. To bridge the domain gaps between real-world images and the training images, we propose a self-supervised domain adaptation strategy for real-world im-ages. Extensive experiments on our dataset and a pub-lic benchmark demonstrate clear improvement achieved by our method over state of the art in both quantitative eval-uation and visual comparisons. Our code and data are available at https://tengfei-wang.github.io/
Dual-Camera-SR/index.html. 1.

Introduction
Most smartphone manufacturers adopt an asymmetric-cameras system consisting of multiple ﬁxed-focal lenses instead of a variable-focal one for optical zoom, due to limited assembly space. As shown in Fig. 1, the most common conﬁguration has dual cameras with wide-angle (main camera) and telephoto lenses that have different ﬁeld of views (FoV). The wide-angle and telephoto images of-ten have spatial misalignment and color discrepancy due to viewpoint differences and different image signal processing (ISP) pipelines in the two lenses. As these two images cap-ture the same scene with different focal lengths, can we use the telephoto image as a reference to enhance the resolution of the wide-angle image? To answer this question, we study reference-based super-resolution (RefSR) with the focus on dual-camera super-resolution (DCSR).
The key challenges of RefSR lie in (1) how to effec-tively establish correspondences between low-resolution in-1equal contribution puts (LR) and reference images (Ref) (feature warping), and (2) how to integrate the reference information to im-prove the output image quality (feature fusion). It has been widely observed that similar semantic patches and texture patterns tend to recur in the same or highly-correlated im-ages with variable positions, orientations and sizes [23, 46].
To search and utilize these correlated patterns from ref-erence images, previous learning-based approaches adopt either patch-wise matching (patch-match [44, 43], patch-based attention [34, 35]) or pixel-wise alignment (optical-ﬂow [45], offsets [28]), with different pros and cons. The pixel-wise alignment is able to handle non-rigid transforma-tion, but usually less stable and prone to generate distorted structures due to the difﬁculty of reliable ﬂow or offsets esti-mations [6], especially for largely misaligned reference im-ages. Patch-wise matching can achieve compelling warping performance since it evaluates similarity scores between LR and Ref patches in an explicit fashion. However, the vanilla patch-level matching lacks robustness to spatial misalign-ment, e.g. scaled or rotated patches. As shown in Fig. 1, even though highly-similar patches are available in the ref-erence image, previous approaches are insufﬁcient to make use of these cues, and tend to average the misaligned Ref and LR patches to produce blurry images.
Another limitation of previous RefSR approaches is that they are difﬁcult to be directly applied to high-resolution images captured by smartphones. The reference images in
RefSR datasets [43] are typically smaller than 512 × 512.
Most methods thus globally searches over the entire ref-erence image for super-resolution cues. Nevertheless, the memory consumption of a global searching strategy would be intractable for the high-resolution cases (e.g. 4K). The domain gaps between real-world images and training im-ages can also degrade the zoom performance [13, 40, 5].
To tackle these issues, we propose a deep RefSR method with the focus on dual-camera super-resolution. First, we generalize the vanilla patch-based attention to an aligned attention module, which searches for related patches based on explicit matching, while implicitly learning inter-patch transformations to alleviate spatial misalignment. Second, to prevent the reference patches from idling and contribut-ing less to the super-resolution results, we impose a ﬁdelity
Figure 1. Demonstration of the smartphone dual-camera system. The telephoto and wide-angle images share similar contents within the overlapped FoV (indicated by the white dotted line), while various misalignment exists. We take the telephoto image as the reference to super-resolve the wide-angle image for combining both large FoV and high-quality details. Compared with state-of-the-art SR approaches
RSRGAN [39] and TTSR [35], our results are sharper and more realistic. Zoom-in for details. loss on the reference images. To advance our method to real-world images, we also propose a self-supervised adap-tation strategy. The main contributions of our paper can be summarized as:
• We are the ﬁrst to explore the real-world dual-camera super-resolution (wide-angle and telephoto cameras). We propose a self-supervised domain adap-tation scheme to bridge domain gaps between real-world images and downsampled images.
• We propose the aligned attention module and adaptive fusion module to improve the RefSR architecture. Our method outperforms state-of-the-art approaches quali-tatively and quantitatively.
• We argue the importance of imposing an explicit ﬁ-delity loss on reference images and performing explicit high-frequency fusion in the image space to the super-resolution quality. 2.