Abstract 1.

Introduction
Recovering high-quality 3D human motion in complex scenes from monocular videos is important for many appli-cations, ranging from AR/VR to robotics. However, captur-ing realistic human-scene interactions, while dealing with occlusions and partial views, is challenging; current ap-proaches are still far from achieving compelling results. We address this problem by proposing LEMO: LEarning human
MOtion priors for 4D human body capture. By leverag-ing the large-scale motion capture dataset AMASS [38], we introduce a novel motion smoothness prior, which strongly reduces the jitters exhibited by poses recovered over a se-quence. Furthermore, to handle contacts and occlusions occurring frequently in body-scene interactions, we design a contact friction term and a contact-aware motion inﬁller obtained via per-instance self-supervised training. To prove the effectiveness of the proposed motion priors, we com-bine them into a novel pipeline for 4D human body cap-ture in 3D scenes. With our pipeline, we demonstrate high-quality 4D human body capture, reconstructing smooth mo-tions and physically plausible body-scene interactions. The code and data are available at https://sanweiliti. github.io/LEMO/LEMO.html.
Recovering realistic human motions in everyday 3D scenes is essential for human behaviour understanding, human-scene interaction synthesis, and virtual avatar cre-ation. Marker-based optical motion capture systems (mo-cap) have the proven capability of recovering highly accu-rate human motions. However, such systems require expert knowledge and expensive setup, making it impractical to capture people in their everyday environments, e.g. record-ing people in their living rooms, ofﬁces or kitchens.
Recently, PROX [19] has been proposed as a lightweight pipeline to capture everyday person-scene interactions from monocular sequences given pre-scanned 3D scene geome-tries. With affordable commodity sensors like an RGB or
RGBD camera, it is quite easy to scan a scene and record how humans move in and interact with it. This shows a promising setup for capturing large-scale human motions in everyday environments. However, as shown in this work1, the recovered human motions exhibit severe skating and jitters. The reconstruction quality is far behind that ob-tained with commercial mocap systems. Building a multi-view setup or using additional wearable sensors (e.g. Iner-tial Measurement Unit (IMUs)) can help improve motion reconstruction quality. However, most multi-view settings 1please see videos on the project page
require careful calibration and synchronization in a con-trolled environment and IMUs suffer from heading drift and interference. Furthermore, human motions obtained by
IMUs [60] or multi-view setups [23] still exhibit jitters and are less compelling than the ones from mocap systems.
To improve the naturalness and accuracy of human motions reconstructed from monocular RGBD sequences (e.g. the PROX pipeline [19]) and to close the performance gap between the monocular RGBD setup and marker-based mocap systems, we argue that it is essential to leverage data-driven approaches and learn powerful motion priors from high-quality large-scale mocap data (e.g. AMASS [38]). To this end, we propose LEMO (LEarning human MOtion pri-ors), which has two key innovations: a marker-based mo-tion smoothness prior and a contact-aware motion inﬁller which is ﬁne-tuned per-instance in a self-supervised fash-ion. As shown in the experiments, LEMO can effectively capture the intrinsic properties of human motions and reg-ularize the noisy and partial observations. As a result, the reconstructed human motions are smooth, physically plau-sible and robust to occlusions which are inevitable when capturing human motions in everyday 3D scenes.
Marker-based motion smoothness prior. 3D human bodies reconstructed by PROX [19] have severe jitters over time. Although some heuristic methods like penalizing joint velocity/acceleration can improve temporal smooth-ness, they also degrade the motion naturalness. As shown in our experiments, they can introduce foot-ground skating artifacts, and may result in invalid body conﬁgurations like joint hyperextension. To capture the holistic full-body dy-namics, we use a fully convolutional autoencoder to aggre-gate local motion cues in a bottom-up manner, and derive latent motion patterns that cover a large spatio-temporal receptive ﬁeld. Then, we design a motion smoothness constraint which works in this latent space rather than di-rectly on the body. To incorporate body shape information and model important degrees-of-freedom (DoFs), e.g. ro-tation about limb axes, as in [71] we represent the body in each frame by surface markers instead of body joints.
We learn this convolutional motion smoothness prior on the
AMASS [38] dataset. As shown in our experiments, the proposed prior not only signiﬁcantly increases the recon-struction quality on the PROX dataset, but also improves the motion naturalness on the IMU-based 3DPW dataset [60], suggesting its effectiveness and potential usage for other motion capture and reconstruction settings.
Contact-aware motion inﬁller via per-instance self-supervised learning. When capturing humans moving in and interacting with everyday 3D environments (e.g. liv-ing rooms or ofﬁces), partial body occlusions are almost inevitable. They pose a challenge for reconstruction algo-rithms, causing invalid poses and foot-ground skating arti-facts. By leveraging AMASS [38], we learn a neural mo-tion inﬁller that is able to infer plausible motions of oc-cluded body parts given partial observations. Our network is inspired by [28], but goes beyond the previous work to jointly predict the foot contact status and body motion.
Combined with a contact friction term motivated by intu-itive physics, the inﬁlled motion is natural, realistic and has proper foot-ground interaction, eliminating the foot skat-ing artifacts. Furthermore, inspired by [24], we propose a per-instance network ﬁne-tuning scheme. For a test in-stance which contains partial observations (e.g. only the upper body motion as the lower body parts are occluded by the sofa in a 3D scene), we ﬁne-tune the pre-trained motion inﬁlling network by minimizing a self-supervised loss that is deﬁned on the visible body parts. In this way, we effectively adapt the general motion inﬁlling “prior” to per-test-instance, achieving notable improvements both for
AMASS [38] and PROX [19].
We further carefully combine the learned motion priors and the contact friction term into a novel multi-stage opti-mization pipeline for 4D human body capture in 3D scenes.
In summary, our contributions are 1) a
Contributions. novel marker-based motion smoothness prior that encodes the “whole-body” motion in a learned latent space, which can be easily plugged into an optimization pipeline; 2) a novel contact-aware motion inﬁller that can be adapted to per-test-instance via self-supervised learning; 3) a new op-timization pipeline that explores both learned motion pri-ors and the physics-inspired contact friction term for scene-aware human motion capture. We extensively evaluate the proposed priors and the optimization pipeline. The results show both the wide applicability of the learned motion pri-ors and the efﬁcacy of the optimization pipeline for monoc-ular RGBD human motion capture in 3D scenes. 2.