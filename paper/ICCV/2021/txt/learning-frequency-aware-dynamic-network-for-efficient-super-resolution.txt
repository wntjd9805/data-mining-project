Abstract
Deep learning based methods, especially convolutional neural networks (CNNs) have been successfully applied in the ﬁeld of single image super-resolution (SISR). To obtain better ﬁdelity and visual quality, most of existing networks are of heavy design with massive computation. However, the computation resources of modern mobile devices are limited, which cannot easily support the expensive cost. To this end, this paper explores a novel frequency-aware dy-namic network for dividing the input into multiple parts according to its coefﬁcients in the discrete cosine trans-form (DCT) domain. In practice, the high-frequency part will be processed using expensive operations and the lower-frequency part is assigned with cheap operations to relieve the computation burden. Since pixels or image patches be-long to low-frequency areas contain relatively few textural details, this dynamic network will not affect the quality of resulting super-resolution images. In addition, we embed predictors into the proposed dynamic network to end-to-end
ﬁne-tune the handcrafted frequency-aware masks. Exten-sive experiments conducted on benchmark SISR models and datasets show that the frequency-aware dynamic network can be employed for various SISR neural architectures to obtain the better tradeoff between visual quality and compu-tational complexity. For instance, we can reduce the FLOPs of SR models by approximate 50% while preserving state-of-the-art SISR performance. 1.

Introduction
Single image super resolution (SISR) receives low-resolution images and outputs their high-resolution counter-parts, which is widely used in real-world applications such as mobile phone, surveillance, autonomous driving, etc.
Basically, SISR is an ill-posed reverse problem for recov-ering more information from the low-resolution versions.
Thanks to the great progress of deep learning, a number of approaches have been explored using deep convolutional
∗Equal contribution
Figure 1: The motivation of our frequency-aware dynamic network. We illustrate the performance of SISR networks with various amounts of computation separately processing patches with different frequency signals. The proﬁt brought by heavy computations becomes slighter as the frequency decreases. For conventional SR models, massive computa-tion redundancy exists in processing low and medium fre-quency regions. Wherein, (cid:173), (cid:174) and (cid:175) denote low, medium and high frequency signals/regions, respectively. neural networks (CNNs) for addressing the SISR problem.
Since neural networks can capture more information from a large amount of available images thus yield higher perfor-mance over conventional image recovery algorithms.
Similar to most computer vision tasks, the design of net-work architectures is quite important for the performance of SISR. Dong et al. [8] ﬁrst employed a network on super-resolution with only three convolutional layers, which ob-tained better performance than traditional methods. Sub-sequently, a series of networks with sophisticated archi-tectures and loss functions are developed. For instance,
Lim et al. [21] deepened the SR network with 32 res-blocks. Tai et al. [29] and Zhang et al. [38] investigated the dense concatenation on SR. In addition, channel atten-tion (e.g., RCAN [37] and SAN [7]) and spatial attention (e.g., ABPN [23]) mechanisms were also embedded in SISR models and boosted the performance signiﬁcantly.
Although tremendous efforts have been made to reﬁne quantitative results i.e., PSNR (Peak Signal-to-Noise Ra-tio) and SSIM (Structure Similarity), and visual quality of generated high-resolution images, the computational cost should be carefully restrained for real-world applications.
For instance, 10,194G FLOPs is required for generating a 1280 × 720 (720p) image using RDN [27] model. To im-prove the model efﬁciency for deploying them on mobile devices while retaining the performance, Ahn et al. [2] and
Luo et al. [24] employed cheap operators to construct efﬁ-cient SR models manually. Furthermore, Chu et al. [6] and
Song et al. [27] explored neural architecture search (NAS) to acquire efﬁcient SISR networks automatically.
Nevertheless, most of existing approaches focus on re-ducing computation by processing the whole image with the same way, which are not perfectly efﬁcient. Natural images are composed of distinct frequency signals according to the
Fourier Transform [4]. Recovering high frequency informa-tion requires massive computations due to its severe damage during the downsample procedure, but reconstructing low frequency information does not demand such huge compu-tations. Fig. 1 illustrates this phenomenon and indicates that the proﬁt brought by heavy computations becomes slighter as the frequency decreases. Hence, massive computation redundancy exists in processing low and medium frequency regions.
It motivates us to explore a more efﬁcient SR method according to frequencies of the input instance.
To this end, this paper proposes a novel frequency-aware dynamic convolutional network (FADN). In each block, we introduce a predictor for dividing the input feature into mul-tiple components based on the discrete cosine transform (DCT [1]) domain, e.g., high-frequency, medium-frequency and low-frequency parts. The predictor is learned under the supervision of hand-crafted frequency-domain masks of images in the training set and the reconstruction loss of SISR, simultaneously. Then, features in these multiple parts will be processed using different convolutional lay-ers with various computation burdens. The features with only low-frequency domain information will be assigned with cheaper operations for reducing computations and vice versa. Since features are divided into multiple branches in our paradigm, the overall computational complexity will be signiﬁcantly reduced by the optimized allocation.
Extensive experiments are carefully conducted to verity the effectiveness of the proposed frequency-aware dynamic network on mainstream super-resolution benchmarks. The experimental results demonstrate that our method is able to employ on different neural architectures for achieving com-parable and even better super-resolution performance using fewer computations.
The rest of this paper is structured as follows: we ﬁrstly summarize the related works on super-resolution methods in Section 2. In Section 3, the proposed method is intro-duced in detail. Then, comparison experiments and ablation study are depicted in Section 4. At last, we draw conclu-sions of the paper in Section 5. 2.