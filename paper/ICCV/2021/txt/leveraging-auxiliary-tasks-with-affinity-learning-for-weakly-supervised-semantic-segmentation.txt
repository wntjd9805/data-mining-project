Abstract
Semantic segmentation is a challenging task in the ab-sence of densely labelled data. Only relying on class activa-tion maps (CAM) with image-level labels provides deﬁcient segmentation supervision. Prior works thus consider pre-trained models to produce coarse saliency maps to guide the generation of pseudo segmentation labels. However, the commonly used off-line heuristic generation process cannot fully exploit the beneﬁts of these coarse saliency maps. Mo-tivated by the signiﬁcant inter-task correlation, we propose a novel weakly supervised multi-task framework termed as
AuxSegNet, to leverage saliency detection and multi-label image classiﬁcation as auxiliary tasks to improve the pri-mary task of semantic segmentation using only image-level ground-truth labels. Inspired by their similar structured se-mantics, we also propose to learn a cross-task global pixel-level afﬁnity map from the saliency and segmentation rep-resentations. The learned cross-task afﬁnity can be used to reﬁne saliency predictions and propagate CAM maps to provide improved pseudo labels for both tasks. The mutual boost between pseudo label updating and cross-task afﬁn-ity learning enables iterative improvements on segmenta-tion performance. Extensive experiments demonstrate the effectiveness of the proposed auxiliary learning network structure and the cross-task afﬁnity learning method. The proposed approach achieves state-of-the-art weakly super-vised segmentation performance on the challenging PAS-CAL VOC 2012 and MS COCO benchmarks. 1 1.

Introduction
Semantic segmentation plays a vital role in many appli-cations such as scene understanding and autonomous driv-1https://github.com/xulianuwa/AuxSegNet
Figure 1. An illustration of the proposed approach for weakly su-pervised semantic segmentation. Our approach jointly learns two auxiliary tasks (i.e., multi-label image classiﬁcation and saliency detection) and a primary task (i.e., semantic segmentation) only using image-level ground-truth labels, and performs afﬁnity learn-ing across two dense prediction tasks (i.e., saliency detection and semantic segmentation). The learned afﬁnity is then used to gen-erate updated pseudo ground-truth (PGT) providing supervision to learn saliency detection and semantic segmentation. ing. It describes the process of assigning a semantic label to each pixel of an image. Prior works have achieved great success in the case of fully supervised semantic segmenta-tion using Convolutional Neural Networks (CNNs). How-ever, this has come at a high pixel-wise annotation cost.
There has been an emerging research trend in semantic seg-mentation using less expensive annotations, such as bound-ing boxes [14, 31], scribbles [22, 33], points and image-level labels [28, 18, 42]. Among them, image-level labels only indicate the presence or absence of objects in an image, resulting in an inferior segmentation performance compared to their fully supervised counterparts.
Most existing weakly supervised semantic segmentation (WSSS) approaches follow a two-step pipeline, i.e., gen-erating pseudo segmentation labels and training segmenta-tion models. A key element in generating pseudo segmen-tation labels is the class activation map (CAM) [48], which is extracted from CNNs trained on image-level labels. Al-though CAM maps identify class-speciﬁc discriminative image regions, those regions are quite sparse with very coarse boundaries. In order to generate high-quality pseudo segmentation labels, many approaches [37, 38, 17, 36] have been presented to improve CAM maps from various as-pects. Besides, existing methods [4, 13, 32, 47] typically use off-the-shelf saliency maps, combined with CAM maps, to determine reliable object and background regions. A gen-eral pre-trained saliency model can provide coarse saliency maps, which contain useful object localization informa-tion, on a target dataset. However, in prior works, such coarse off-the-shelf saliency maps are only used as ﬁxed binary cues in an off-line pseudo label generation process via heuristic thresholding, they are neither directly involved in the network training nor updated, which largely restricts their use to further beneﬁt the segmentation performance.
Motivated by the observation that semantic segmenta-tion, saliency detection and image classiﬁcation are highly correlated, we propose a weakly supervised multi-task deep network (see Figure 1), which leverages saliency detec-tion and multi-label image classiﬁcation as auxiliary tasks to help learn the primary task of semantic segmentation.
Through the joint training of these three tasks, an online adaptation can be achieved from pre-trained saliency maps to our target dataset. In addition, the task of saliency detec-tion impels the shared knowledge to emphasize the differ-ence between foreground and background pixels, thus driv-ing the object boundaries of the segmentation outputs to co-incide with those of the saliency outputs. Similarly, the im-age classiﬁcation task highlights the discriminative features which can lead to more accurate segmentation predictions.
Furthermore, we notice that, similar to these two dense prediction tasks, i.e., semantic segmentation and saliency detection, CAM maps also represent pixel-level semantics albeit they are only partially activated. Therefore, we pro-pose to learn global pixel-level pair-wise afﬁnities from the features of segmentation and saliency tasks to guide the propagation of CAM activations. More speciﬁcally, two task-speciﬁc afﬁnity maps are ﬁrst learned for the saliency and segmentation tasks, respectively. To capture the com-plementary information between the two afﬁnity maps, they are then adaptively integrated based on the learned self-attentions to produce a cross-task afﬁnity map. Moreover, as we expect to learn semantic-aware and boundary-aware afﬁnities so as to better update pseudo labels, we impose constraints on learning the cross-task afﬁnities from task-speciﬁc supervision and joint multi-objective optimization.
The learned cross-task afﬁnity map is further utilized to reﬁne saliency predictions and CAM maps to provide im-proved pseudo labels for both saliency detection and seman-tic segmentation respectively, enabling a multi-stage cross-task iterative learning and label updating.
In summary, the main contribution is three-fold:
• We propose an effective multi-task auxiliary deep learning framework (i.e., AuxSegNet) for weakly supervised semantic segmentation. The proposed
AuxSegNet leverages multi-label image classiﬁcation and saliency detection as auxiliary tasks to help learn the primary task (i.e., semantic segmentation) using only image-level ground-truth labels.
• We propose a novel method to learn cross-task afﬁni-ties to reﬁne both task-speciﬁc representations and pre-dictions for semantic segmentation and saliency de-tection. The learned global pixel-level afﬁnities can also be used to simultaneously update semantic and saliency pseudo labels in a joint cross-task iterative learning framework, yielding continuous boosts of the semantic segmentation performance.
• Our proposed method achieves state-of-the-art results on PASCAL VOC 2012 and MS COCO datasets for the task of weakly supervised semantic segmentation. 2.