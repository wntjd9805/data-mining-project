Abstract
Traditional normalization techniques (e.g., Batch Nor-malization and Instance Normalization) generally and sim-plistically assume that training and test data follow the same distribution. As distribution shifts are inevitable in real-world applications, well-trained models with previous normalization methods can perform badly in new environ-ments. Can we develop new normalization methods to im-prove generalization robustness under distribution shifts?
In this paper, we answer the question by proposing Cross-Norm and SelfNorm. CrossNorm exchanges channel-wise mean and variance between feature maps to enlarge train-ing distribution, while SelfNorm uses attention to recal-ibrate the statistics to bridge gaps between training and test distributions. CrossNorm and SelfNorm can comple-ment each other, though exploring different directions in statistics usage. Extensive experiments on different ﬁelds (vision and language), tasks (classiﬁcation and segmenta-tion), settings (supervised and semi-supervised), and dis-tribution shift types (synthetic and natural) show the effec-tiveness. Code is available at https://github.com/ amazon-research/crossnorm-selfnorm 1.

Introduction
Normalization methods, e.g., Batch Normalization [22],
Layer Normalization [1], and Instance Normalization [46], play a pivotal role in training deep neural networks by mak-ing training more stable and convergence faster, assuming that training and test data come from the same distribution.
However, distribution shifts in various real-world scenarios
[15, 38, 16] make traditional normalization techniques im-practical. For instance, a driving scene segmentation model trained on one city usually does not generalize well to an-other city. In this paper, we aim to explore how normal-ization can improve generalization under distribution shifts.
Speciﬁcally, we tackle the distribution shift problem from two respects: enlarging training distribution and reducing test distribution.
First, enlarging the training distribution is not in line with the conventional purpose of normalization which is to sta-bilize and accelerate training. So, can we employ normal-ization for a different goal–augmenting training data? Our inspiration comes from a simple observation that exchang-ing the RGB mean and variance between two images can transfer style between them, as shown in Figure 1 (a). For many tasks such as CIFAR image classiﬁcation [24], style, encoded by channel-wise mean and variance, is usually less critical in recognizing the object than other information, such as object shape. Therefore, augmenting style is safe enough that content labels remain unchanged. To augment style, we propose CrossNorm, which swaps channel-wise mean and variance of feature maps in training so that the model becomes more robust to changes in appearance.
Even with the augmented training data, a model will still encounter data with unforeseen appearances in deployment.
Hence, another question comes: how to make normaliza-tion reduce test data distribution, i.e., bridging distribution gaps between training and test data? Similarly, our method is motivated by an observation illustrated in Figure 1 (b).
Given one image in different styles, we can reduce the style discrepancy when adjusting the RGB means and variances properly. Intuitively, style recalibration can reduce appear-ance variance so that training and test data will share more consistent styles. To this end, we propose SelfNorm by us-ing attention [19] to adjust channel-wise mean and variance.
It is interesting to analyze the distinction and connection between CrossNorm and SelfNorm. At ﬁrst glance, they take opposite actions (style augmentation vs. style reduc-tion). Even so, they use the same tool: channel-wise statis-tics and pursue the same goal: generalization robustness.
Additionally, CrossNorm can increase the capacity of Self-Norm by letting SelfNorm learn from more diverse styles in training. Overall, the key contributions are three-fold:
Figure 1: Examples of exchanging (Left) and adjusting (Right) RGB mean and variance. Swapping the statistics can enrich image styles and thus enlarge training distribution, while recalibrating the statistics properly can encourage style consistency, reducing the train-test distribution gap.
• Unlike previous efforts, we explore a new direction of using feature normalization for generalization under distribution shifts.
• We propose CrossNorm and SelfNorm, two simple yet effective normalization techniques that complement each other to improve generalization robustness.
• CrossNorm and SelfNorm can advance state-of-the-art robustness performance for different ﬁelds (vision or language), tasks (classiﬁcation and segmentation), set-tings (fully or semi-supervised), and distribution shift types (synthetic and natural). 2.