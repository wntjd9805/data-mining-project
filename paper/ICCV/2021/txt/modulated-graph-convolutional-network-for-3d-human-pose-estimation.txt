Abstract
The graph convolutional network (GCN) has recently achieved promising performance of 3D human pose esti-mation (HPE) by modeling the relationship among body parts. However, most prior GCN approaches suffer from two main drawbacks. First, they share a feature transfor-mation for each node within a graph convolution layer. This prevents them from learning different relations between dif-ferent body joints. Second, the graph is usually defined ac-cording to the human skeleton and is suboptimal because human activities often exhibit motion patterns beyond the natural connections of body joints. To address these limita-tions, we introduce a novel Modulated GCN for 3D HPE.
It consists of two main components: weight modulation and affinity modulation. Weight modulation learns different modulation vectors for different nodes so that the feature transformations of different nodes are disentangled while retaining a small model size. Affinity modulation adjusts the graph structure in a GCN so that it can model addi-tional edges beyond the human skeleton. We investigate several affinity modulation methods as well as the impact of regularizations. Rigorous ablation study indicates both types of modulation improve performance with negligible overhead. Compared with state-of-the-art GCNs for 3D
HPE, our approach either significantly reduces the estima-tion errors, e.g., by around 10%, while retaining a small model size or drastically reduces the model size, e.g., from 4.22M to 0.29M (a 14.5× reduction), while achieving com-parable performance. Results on two benchmarks show our Modulated GCN outperforms some recent states of the art. Our code is available at https://github.com/
ZhimingZo/Modulated-GCN . 1.

Introduction 3D human pose estimation (HPE) aims to accurately re-cover the 3D locations of body joints in the camera coordi-nate system from a single image. It plays an important role
*Corresponding author.
Figure 1. Comparison of the performance and model size be-tween the proposed Modulated GCN and state-of-the-art GCNs designed for 3D HPE, i.e., SemGCN [57], Local-to-Global Net
[3], and Weight Unsharing [28]. A lower MPJPE value indicates better performance. All methods are evaluated on Human3.6M
[15] with ground truth 2D joints as input. in several valuable applications such as human-computer interaction, action recognition, and intelligent surveillance.
However, 3D HPE remains a challenging problem due to its ill-posed nature. Multiple valid 3D body configurations can be projected to the same 2D pose in the image space.
State-of-the-art 3D HPE systems are built on deep neu-ral networks [20] due to their strong capability to learn ef-fective feature representations from data. Some approaches
[61, 35, 44, 37, 43, 54, 23, 4] regress 3D joint coordinates or heat maps directly from a monocular image via a con-volutional neural network (CNN) [21, 19]. Recent works decompose the problem into two subtasks, i.e., 2D HPE fol-lowed by 2D-to-3D pose lifting [31, 3, 6, 57, 38, 30, 50, 52, 5, 63, 29, 48]. For example, Martinez et al. [31] construct a simple fully connected network taking only 2D keypoints as input and yield promising 3D HPE performance.
Recently, graph convolutional networks (GCNs) have been applied for 3D HPE [57, 3, 6, 28] to model the cor-relation between body joints. They repeatedly transform and aggregate features of neighboring nodes to obtain more powerful feature representations. Their superior perfor-mance over the fully connected networks proves that rela-tional reasoning is critical to mitigate the depth ambiguity.
However, most previous GCNs suffer from two limita-tions. First, they share a feature transformation for each node within a graph convolution layer. Since it is the fea-ture transformation that captures the relations between each node and their neighboring nodes, this kind of weight shar-ing prevents the GCN from learning diverse relational pat-terns between different body joints. Recently, Liu et al. [28] solve this problem via weight unsharing and apply different feature transformations to different nodes before aggregat-ing their features. However, it significantly increases the model size, i.e., by a factor of the number of body joints (typically 16 or 17). Second, the graph in a GCN defines the pairwise correlations between body joints, and it is usually defined according to the human skeleton. However, human activities often exhibit motion patterns beyond the natural connections of body joints, e.g., the strong correlation be-tween arms and legs for a walking or running person.
It remains unclear what kind of graph structure is optimal for 2D-to-3D pose lifting.
This paper introduces a novel approach, termed the Mod-ulated GCN, to resolve these two difficult issues. It consists of two main components: weight modulation and affinity modulation. Unlike weight unsharing [28] which applies different weight matrices to different nodes, weight mod-ulation uses a shared weight matrix as in the vanilla GCN but learns different modulation vectors for different nodes.
By manipulating the latent weight space, the feature trans-formations of different nodes are disentangled. This enables the graph convolution to learn diverse relationships between different body joints while retaining a small model size.
Affinity modulation means to adjust the graph structure in a GCN so that each graph convolution layer focuses on ad-ditional edges beyond the human skeleton. This is achieved by learning a modulation matrix added to the human skele-ton affinity matrix. However, the unconstrained modulation can be suboptimal as the correlation patterns of body joints exhibit certain properties. This motivates us to study what kind of prior should be enforced on the affinity modulation.
Specifically, we have an in-depth investigation on whether symmetry, sparsity and low-rank constraints help improve the generalization ability.
In sum, the contribution of this paper is threefold.
• We introduce weight modulation to disentangle the feature transformations of different nodes. It enables the GCN to learn diverse relational patterns between different body joints while maintaining a small model size.
• We investigate different affinity modulation methods as well as the impact of different regularizations. Our optimal affinity modulation helps each graph convolu-tion layer focus on additional edges beyond the skele-ton graph.
• Compared with state-of-the-art GCN methods, our
Modulated GCN addresses the dilemma between the accuracy and model complexity, as shown in Fig. 1.
It significantly reduces the model size of the lat-est Weight Unsharing GCN [28], i.e., from 4.22M to 0.29M (a 14.5× reduction), while achieving similar accuracy. It reduces the estimation error of Semantic
GCN [57] by around 10% (9.2% on MPJPE and 10.3% on P-MPJPE) while maintaining a small model size. 2.