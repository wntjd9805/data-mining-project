Abstract
This paper proposes a framework to guide an optical flow network with external cues to achieve superior accu-racy either on known or unseen domains. Given the avail-ability of sparse yet accurate optical flow hints from an ex-ternal source, these are injected to modulate the correlation scores computed by a state-of-the-art optical flow network and guide it towards more accurate predictions. Although no real sensor can provide sparse flow hints, we show how these can be obtained by combining depth measurements from active sensors with geometry and hand-crafted optical flow algorithms, leading to accurate enough hints for our purpose. Experimental results with a state-of-the-art flow network on standard benchmarks support the effectiveness of our framework, both in simulated and real conditions. 1.

Introduction
The task of optical flow computation [21] aims at esti-mating the motion of pixels in a video sequence (e.g., in the most common settings, from two consecutive frames in time). As a result, several higher-level tasks can be faced from it, such as action recognition, tracking and more. Al-though its long history, optical flow remains far from being solved due to many challenges; the lack of texture, occlu-sions or the blurring effect introduced by high-speed mov-ing objects make the problem particularly hard.
Indeed, the adoption of deep learning for dense optical flow estimation has represented a turning point during the years. The possibility of learning more robust pixels simi-larities [2, 73] allowed, at first, to soften the issues above.
Then the research trend in the field rapidly converged to-wards direct inference of the optical flow field in an end-to-end manner [15, 29, 62, 63, 26, 27, 25, 64], achieving both unrivaled accuracy and run time in comparison to previous approaches. The availability of a large amount of training data annotated with ground-truth flow labels, in most cases obtained for free on synthetic images [10, 15, 29], ignited this spread. Common to most end-to-end networks is the use of a correlation layer [15], explicitly computing simi-larity scores between pixels in the two images in order to find matches, and thus flow.
This trend, however, introduced new challenges inher-ently connected to the learning process. Specifically, the use of synthetic images is rarely sufficient to achieve top perfor-mance on real data. As witnessed by many works in the field
[15, 29, 62, 63, 26, 27, 25, 64], a network trained on syn-thetic images already excels on benchmarks such as Sintel
[10], yet struggles at generalizing to real benchmarks such as KITTI [17, 47]. This phenomenon is known as domain-shift and is usually addressed by fine-tuning on few real im-ages with available ground-truth. Nevertheless, achieving generalization without fine-tuning still represents a desir-able property when designing a neural network. The main cause triggering the domain-shift issue is the very different appearance of synthetic versus real images, with the for-mer unable to faithfully model noise, lightning conditions
and other effects usually found in the latter, as extensively supported by the literature [20, 50, 53, 65, 66, 78, 52, 11].
However, it has been shown that a deep neural network can be guided through external hints to reduce the domain-shift effect significantly. In particular, in the case of guided stereo matching [52], a neural network can be conditioned during cost-volume computation with sparse depth measurements, obtained, for instance, employing a LIDAR sensor. This strategy dramatically increases generalization across do-mains, as well as specialization obtained after fine-tuning.
Inspired by these findings, in this paper we formulate the guided optical flow framework. Supposing the availability of a sparse yet accurate set of optical flow values, we use them to modulate the correlation scores usually computed by state-of-the-art networks to guide them towards more accurate results. To this aim, we first extend the guided stereo formulation to take into account 2D cost surfaces.
Then, we empirically study how the effect of the sparse points is affected by the resolution at which the correlation scores are computed and, consequently, revise the state-of-the-art flow network, RAFT [64], to make it better lever-age such a guide. The effectiveness of this approach is evaluated, at first, from a theoretical point of view by sam-pling a low amount of ground-truth flow points (about 3%) – perturbed with increasing intensity of noise – to guide the network, and then using flow hints obtained by a real setup. However, in contrast to stereo/depth estimation [52], sensors capable of measuring optical flow do not exist at all. Consequently, we show how to obtain such a sparse guide out of an active depth sensor combined with a hand-crafted flow method and an instance-segmentation network
[19]. It is worth noting that the setup needed by our pro-posal is already regularly deployed in many practical appli-cations, such as autonomous driving, and nowadays even available in most consumer devices like smartphones and tablets equipped with cameras and active depth sensors.
Figure 1 shows the potential of our method in a challeng-ing environment (a) where the same, state-of-the-art flow network [64] has been run after being trained on synthetic images only.
In its original implementation (b), the net-work miserably fails. Instead, the same network re-trained and guided by our framework (c) with a few hints (e.g., about 3% of the total pixels, sampled from ground-truth and perturbed with random noise for this example) is dramati-cally improved. Experiments carried out on synthetic (Fly-ingChairs, FlyingThings3D, Sintel) and real (Middlebury,
KITTI 2012 and 2015) datasets support our main claims:
• We show, for the first time, that an optical flow network can be conditioned, or guided, by using external cues.
To this aim, we pick RAFT [64], currently the state-of-the-art in dense optical flow estimation, and revise it to benefit from the guide at its best.
• Supposing to have the availability of less than 3% sparse flow hints, guided optical flow allows to largely reduce the domain-shift effect between synthetic and real images, as well as to further improve accuracy on the same domain.
• Although virtually no sensor is capable of providing such accurate flow hints [49], we prove that a LIDAR sensor, combined with a hand-crafted flow algorithm, can provide a meaningful guide. 2.