Abstract
Video compression is a critical component of Internet video delivery. Recent work has shown that deep learning techniques can rival or outperform human-designed algo-rithms, but these methods are signiﬁcantly less compute and power-efﬁcient than existing codecs. This paper presents a new approach that augments existing codecs with a small, content-adaptive super-resolution model that signiﬁcantly boosts video quality. Our method, SRVC, encodes video into two bitstreams: (i) a content stream, produced by com-pressing downsampled low-resolution video with the exist-ing codec, (ii) a model stream, which encodes periodic up-dates to a lightweight super-resolution neural network cus-tomized for short segments of the video. SRVC decodes the video by passing the decompressed low-resolution video frames through the (time-varying) super-resolution model to reconstruct high-resolution video frames. Our results show that to achieve the same PSNR, SRVC requires 20% of the bits-per-pixel of H.265 in slow mode, and 3% of the bits-per-pixel of DVC, a recent deep learning-based video compression scheme. SRVC runs at 90 frames per second on an NVIDIA V100 GPU. 1.

Introduction
Recent years have seen a sharp increase in video traf-ﬁc.
It is predicted that by 2022, video will account for more than 80% of all Internet trafﬁc [6, 1]. Video de-livery is so bandwidth-intensive that during surge periods such as the initial months of the pandemic, Netﬂix and
Youtube were forced to throttle video quality to reduce over-heads [2, 3]. Further, while mobile devices support 1080p resolutions these days, cellular networks are still plagued by low bandwidth and frequent ﬂuctuations in most parts of the world. Hence efﬁcient video compression to reduce bandwidth consumption without compromising on quality is more critical than ever.
While the demand for video content has increased over the years, the techniques used to compress and transmit video have largely remained the same. Ideas such as ap-plying Discrete Cosine Transforms (DCTs) to video blocks and computing motion vectors [46, 18] , which were de-veloped decades ago, are still in use today. Even the latest
H.265 codec improves upon these same ideas by incorpo-rating variable block sizes [7]. Recent efforts [35, 10, 38] to improve video compression have turned to deep learning to capture the complex relationships between the components of a video compression pipeline. These approaches have had moderate success at outperforming current codecs, but they are much less compute- and power-efﬁcient.
We present SRVC, a new approach particularly useful for cellular networks and low bitrate-scenarios, that com-bines existing compression algorithms with a lightweight, content-adaptive super-resolution (SR) neural network that signiﬁcantly boosts performance with low computation cost. SRVC compresses the input video into two bitstreams: a content stream and a model stream, each with a sepa-rate bitrate that can be controlled independently of the other stream. The content stream relies on a standard codec such as H.265 to transmit low-resolution frames at a low bitrate.
The model stream encodes a time-varying SR neural net-work, which the decoder uses to boost the quality of decom-pressed frames derived from the content stream. SRVC uses the model stream to specialize the SR network for short seg-ments of video dynamically (e.g., every few seconds). This makes it possible to use a small SR model, consisting of just a few convolutional and upsampling layers.
Applying SR to improve the quality of low-bitrate com-pressed video isn’t new. AV1 [16], for instance, has a mode (typically used in low-bitrate settings) that encodes frames at low resolution and applies an upsampler at the decoder.
While AV1 relies on standard bicubic [26] or bilinear [52] interpolation for upsampling, recent proposals have shown that learned SR models can signiﬁcantly improve the qual-ity of these techniques [33, 20].
However, these approaches rely on generic SR neural networks [45, 53, 25]) that are designed to generalize across a wide range of input images. These models are large (e.g., 10s of millions of parameters) and can typically reconstruct only a few frames per second even on high-end GPUs [31].
But in many usecases, generalization isn’t necessary. In par-Figure 1: Comparing different video compression schemes at a 200 Kbps bitrate (except for DVC) on the 1560th frame of Sita Sings the
Blues video in Xiph [9] dataset. DVC [34] is encoding at its lowest available bitrate that requires 4.97 Mbps in this example. ticular, we often have access to the video being compressed ahead of time (e.g, for on-demand video). Our goal is to dramatically reduce the complexity of the SR model in such applications by specializing it (in a sense, overﬁtting it) to short segments of video.
To make this idea work, we must ensure that the over-head of the model stream is low. Even with our small SR model (with 2.22M parameters), updating the entire model every few seconds would consume a high bitrate, undoing any compression beneﬁt from lowering the resolution of the content stream. SRVC tackles this challenge by carefully selecting a small fraction (e.g., 1%) of parameters to update for each segment of the video, using a “gradient-guided” coordinate-descent [48] strategy that identiﬁes parameters that have the most impact on model quality. Our primary
ﬁnding is that a SR neural network adapted in this man-ner over the course of a video can provide such a boost to quality, that including a model stream along with the com-pressed video is more efﬁcient than allocating the entire bit-stream to content.
In summary, we make the following contributions:
• We propose a novel dual-stream approach to video streaming that combines a time-varying SR model with compressed low-resolution video produced by a standard codec. We develop a coordinate descent method to update only a fraction of model parameters for each few-second segment of video with low overhead.
• We propose a lightweight model with spatially-adaptive kernels, designed speciﬁcally for content-speciﬁc SR.
Our model runs in real-time, taking only 11 ms (90 fps) to generate a 1080p frame on an NVIDIA V100 GPU. In comparison, DVC [35] takes 100s of milliseconds at the same resolution.
• We show that, in low bitrate regimes, to achieve the same
PSNR, SRVC requires only 20% of the bitrate as H.265 in its slow encoding mode 1, and 3% of DVC’s bits-per-pixel. SRVC’s quality improvement extends across all frames in the video.
Figure 1 shows visual examples comparing the SRVC with these baseline approaches at competitive or higher bi-trates. Our datasets and code are available at https:
//github.com/AdaptiveVC/SRVC.git 2.