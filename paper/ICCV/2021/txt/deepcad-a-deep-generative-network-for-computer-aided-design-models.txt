Abstract
Deep generative models of 3D shapes have received a great deal of research interest. Yet, almost all of them gen-erate discrete shape representations, such as voxels, point clouds, and polygon meshes. We present the ﬁrst 3D genera-tive model for a drastically different shape representation— describing a shape as a sequence of computer-aided de-sign (CAD) operations. Unlike meshes and point clouds,
CAD models encode the user creation process of 3D shapes, widely used in numerous industrial and engineering design tasks. However, the sequential and irregular structure of
CAD operations poses signiﬁcant challenges for existing 3D generative models. Drawing an analogy between CAD operations and natural language, we propose a CAD gener-ative network based on the Transformer. We demonstrate the performance of our model for both shape autoencoding and random shape generation. To train our network, we create a new CAD dataset consisting of 178,238 models and their
CAD construction sequences. We have made this dataset publicly available to promote future research on this topic. 1.

Introduction
It is our human nature to imagine and invent, and to ex-press our invention in 3D shapes. This is what the paper and pencil were used for when Leonardo da Vinci sketched his mechanisms; this is why such drawing tools as the parallel bar, the French curve, and the divider were devised; and this is wherefore, in today’s digital era, the computer aided de-sign (CAD) software have been used for 3D shape creation in a myriad of industrial sectors, ranging from automotive and aerospace to manufacturing and architectural design.
Can the machine also invent 3D shapes? Leveraging the striking advance in generative models of deep learning, lots of recent research efforts have been directed to the generation of 3D models. However, existing 3D generative models merely create computer discretization of 3D shapes: 3D point clouds [6, 52, 53, 8, 30], polygon meshes [17, 42, 31], and levelset ﬁelds [12, 33, 29, 50, 11]. Still missing is the ability to generate the very nature of 3D shape design—the drawing process.
Figure 1. A gallery of generated CAD designs. Our generative network is able to produce a diverse range of CAD designs. Each
CAD model consists of a sequence of CAD operations with spe-ciﬁc parameters. The resulting 3D shapes are clean, have sharp geometric features, and can be readily user-edited.
We propose a deep generative network that outputs a se-quence of operations used in CAD tools (such as SolidWorks and AutoCAD) to construct a 3D shape. Generally referred as a CAD model, such an operational sequence represents the
“drawing” process of shape creation. Today, almost all the in-dustrial 3D designs start with CAD models. Only until later in the production pipeline, if needed, they are discretized into polygon meshes or point clouds.
To our knowledge, this is the ﬁrst work toward a gen-erative model of CAD designs. The challenge lies in the
CAD design’s sequential and parametric nature. A CAD model consists of a series of geometric operations (e.g., curve sketch, extrusion, ﬁllet, boolean, chamfer), each con-trolled by certain parameters. Some of the parameters are discrete options; others have continuous values (more dis-cussion in Sec. 3.1). These irregularities emerge from the user creation process of 3D shapes, and thus contrast starkly to the discrete 3D representations (i.e., voxels, point clouds,
and meshes) used in existing generative models. In con-sequence, previously developed 3D generative models are unsuited for CAD model generation.
Technical contributions. To overcome these challenges, we seek a representation that reconciles the irregularities in
CAD models. We consider the most frequently used CAD operations (or commands), and unify them in a common structure that encodes their command types, parameters, and sequential orders. Next, drawing an analogy between CAD command sequences and natural languages, we propose an autoencoder based on the Transformer network [40]. It em-beds CAD models into a latent space, and later decode a latent vector into a CAD command sequence. To train our autoencoder, we further create a new dataset of CAD com-mand sequences, one that is orders of magnitude larger than the existing dataset of the same type. We have also made this dataset publicly available1 to promote future research on learning-based CAD designs.
Our method is able to generate plausible and diverse CAD designs (see Fig. 1). We carefully evaluate its generation quality through a series of ablation studies. Lastly, we end our presentation with an outlook on useful applications en-abled by our CAD autoencoder. 2.