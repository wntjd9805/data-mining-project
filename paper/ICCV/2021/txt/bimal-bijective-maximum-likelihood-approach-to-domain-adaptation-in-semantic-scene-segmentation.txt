Abstract
Semantic segmentation aims to predict pixel-level labels.
It has become a popular task in various computer vision applications. While fully supervised segmentation methods have achieved high accuracy on large-scale vision datasets, they are unable to generalize on a new test environment or a new domain well. In this work, we first introduce a new Un-aligned Domain Score to measure the efficiency of a learned model on a new target domain in unsupervised manner.
Then, we present the new Bijective Maximum Likelihood1 (BiMaL) loss that is a generalized form of the Adversarial
Entropy Minimization without any assumption about pixel independence. We have evaluated the proposed BiMaL on two domains. The proposed BiMaL approach consistently outperforms the SOTA methods on empirical experiments on “SYNTHIA to Cityscapes”, “GTA5 to Cityscapes”, and
“SYNTHIA to Vistas”. 1.

Introduction
Semantic segmentation is one of the most popular com-puter vision topics, which aims to to assign each pixel in an image to a predefined class. It has various practical applica-tions, especially in autonomous driving where a segmenta-tion model is needed to recognize roads, sidewalks, pedes-trians or vehicles in a large variety of urban conditions. A typical supervised segmentation model is usually trained on datasets with labels. However, annotating images for the semantic segmentation task is costly and time-consuming.
Alternatively, a powerful and cost-effective way to acquire a large-scale training set is to use a simulation, e.g. game en-gines, to create a synthetic dataset [42, 43]. However, fully supervised models [3, 24] trained on the synthetic datasets are often unable to perform well on real images due to the pixel appearance gap between synthetic and real images.
Unsupervised Domain Adaptation (UDA) aims to train 1https://github.com/uark-cviu/BiMaL a machine learning model on an annotated dataset, i.e. the source, and guarantee its high performance on a new unla-the target. The UDA approaches have beled dataset, i.e. been applied to various computer vision tasks such as Se-mantic Segmentation [3, 24, 26, 54, 55, 57], Face Recogni-tion [12, 32, 33, 34, 35]. The recent UDA methods aim to reduce the cross-domain discrepancy, along with the super-vised training on the source domain [5, 16, 29, 40, 52, 54].
In particular, these methods aim to minimize the distribu-tion discrepancy of the deep representations extracted from the source and the target domains. This process can be per-formed at single or multiple levels of deep features using maximum mean discrepancies [16, 29, 52], or adversarial training [5, 6, 20, 21, 22, 50]. The approaches in this group have shown their potential in aligning the predicted out-puts of images from the two domains. However, the bi-nary cross-entropy label predicted by the learned discrim-inator is usually a weak indication of structural learning for the segmentation task. Another approach named self-training utilizes the pseudo-labels or generative networks conditioned on target images [37, 58]. Semi-supervised learning is an approach related to UDA where the training set consists of both labeled and unlabeled samples. Thus, it has motivated several UDA approaches such as Class-balanced self-training (CBST) [60], and entropy minimiza-tion [4, 17, 40, 47, 54]. Although metrics such as entropy can be efficiently computed and adopted for training, they tend to rely on easy predictions, i.e. high confident scores, as references for the label transfer from source to target do-mains. This issue is alleviated in a later approach [4] by preventing learned models from over-focusing on high con-fident areas. However, this type of metrics is formulated in pixel-wised manner, and, therefore, neglects the structural information presented in the image (see Figure 1).
Contributions of this Work. This work presents a new unsupervised domain adaptation approach to tackle the se-mantic segmentation problem. Table 1 summarizes the dif-ference between our proposed approach and the prior ones.
Our contributions can be summarized as follows.
Figure 1. Two images have the same entropy but one has a poor prediction (a top image) and one has an better prediction (a bottom image). Columns 1 and 2 are an input image and a ground truth. Columns 3 and 4 are an entropy map and a prediction of AdvEnt [54].
Column 5 is the results of our proposed method. The two predictions produced by AdvEnt have similar entropy scores (0.13 and 0.14).
Meanwhile, the BiMaL value of the bottom prediction (0.06) is smaller than the top prediction (0.14). Our results in the last column, which have better BiMaL values than AdvEnt, can well model the structure of an image. In particular, our results have sharper results of a barrier and a rider (white dash box), and a clear boundary between road and sidewalk.
Firstly, a new Unaligned Domain Score (UDS) is intro-duced to measure the efficiency of the learned model on a target domain in an unsupervised manner. Secondly, the presented UDS is further extended as a new loss function, named Bijective Maximum Likelihood (BiMaL) loss, that can be used with an unsupervised deep neural network to generalize on target domains. Indeed, we further demon-strate BiMaL loss is a generalized form of the Adversar-ial Entropy Minimization (AdvEnt) [54] without pixel in-dependence assumption. Far apart from AdvEnt that as-sumes pixel independence, BiMaL loss is formed using a
Maximum-likelihood formulation to model the global struc-ture of a segmentation input and a Bijective function to map that segmentation structure to a deep latent space. Fi-nally, the proposed BiMaL method is evaluated on three popular large-scale semantic segmentation benchmarks, in-cluding GTA5 [42] to CityScapes [7], SYNTHIA [43] to
Cityscapes, and SYNTHIA to Vista [38]. The experimen-tal results demonstrate our proposed BiMaL approach con-sistently outperforms the State-of-the-Art (SOTA) methods
[5, 40, 50, 54, 55] in all these benchmark databases. To the best of our knowledge, this is one of the first works that introduces a novel bijective maximum likelihood approach with flow-based metric to unsupervised domain adaptation in semantic segmentation. 2.