Abstract
In recent years, unmanned surface vehicles (USVs) have been experiencing growth in various applications. With the expansion of USVs’ application scenes from the typical ma-rine areas to inland waters, new challenges arise for the ob-ject detection task, which is an essential part of the percep-tion system of USVs. In our work, we focus on a relatively unexplored task for USVs in inland waters: small object detection on water surfaces, which is of vital importance for safe autonomous navigation and USVs’ certain missions such as floating waste cleaning. Considering the limitations of vision-based object detection, we propose a novel radar-vision fusion based method for robust small object detection on water surfaces. By using a novel representation format of millimeter wave radar point clouds and applying a deep-level multi-scale fusion of RGB images and radar data, the proposed method can efficiently utilize the characteristics of radar data and improve the accuracy and robustness for small object detection on water surfaces. We test the method on the real-world floating bottle dataset that we collected and released. The result shows that, our method improves the average detection accuracy significantly compared to the vision-based methods and achieves state-of-the-art per-formance. Besides, the proposed method performs robustly when single sensor degrades. 1.

Introduction
In recent years, unmanned surface vehicles (USVs) have attracted increasing attention and are gradually used for various autonomous activities on water surfaces such as oceanographic research [7], transportation [41], water qual-ity monitoring [19], floating waste removal [32, 36, 1], etc.
Similar to autonomous vehicles on the road, to enable safe navigation and efficient autonomous operation, accu-rate and robust environmental perception is of vital impor-tance for USVs. Small object detection on water surfaces is an important task for USVs environmental perception. It
Figure 1. Overview of the proposed method for small object de-tection for USVs. Our method utilizes the fusion of RGB images and MMW radar data for small object detection of USVs, which can be applied for USVs’ certain missions and safe navigation. can be applied to USVs for avoiding small obstacles like buoys and reefs, and plays an important role in USVs’ cer-tain missions such as autonomous floating waste detection and cleaning. Vision can provide rich semantic information and is widely used for object detection of USVs. However, unlike autonomous vehicles on the road, there are three main challenges for vision-based small objects detection on water surfaces:
- Light reflection on the water surface. As shown in Fig-ure 2(a), the strong light reflection on the water surface can cause high illumination and overexposed image. The small objects like the floating bottles can be shaded by water halos or fused with the background due to overexposure.
- Surrounding scene reflection interference. As shown in
Figure 2(b), in some cases such like the small object detec-tion in inland waters, the reflection of the constructions and vegetation on banks increase the complexity of separating the target from the background.
- A short detection range. A long detection range can significantly improve the safety of navigation and the work-ing efficiency of USVs. However, as the size of the target is small, when the target is far from the camera, the number of occupied pixels of the target in RGB images becomes much less as shown in Figure 2(c).
With the increasing demands towards environmental per-ception for autonomous vehicles, in addition to the vision-based system, object detection based on other sensors like
(a) (b) (c)
Figure 2. Challenges in detecting small objects: Strong light re-flection interference. Surrounding scene reflection interference.
Small size and a short detection range.
Figure 3. The figures show 3 successive frames of radar point clouds projected onto images. The point clouds of the targets and the clutter points are framed by green boxes and yellow boxes re-spectively. As can be seen, the point clouds of the small size float-ing bottles are unstable and hard for humans to identify. Besides, the water clutter can disturb the detection system. millimeter wave (MMW) radar has shown great value in au-tonomous driving [49]. Compared to the vision-based sys-tem, MMW radar is more robust to lighting conditions and provides the possibility of seeing a long distance [24]. De-spite this, for the real-world applications of small object de-tection on water surfaces based on MMW radar, as shown in Figure 3, difficulties remain to be overcome:
- Weak echoes from non-metallic targets. The radar cross-section (RCS) indicates how detectable a target is by radar. Usually, a target of large size and made of metal ma-terial has a larger RCS and are more detectable. The non-metallic small object has a lower RCS and its radar reflec-tion is weak, which significantly increases the difficulties in detection.
- Interference caused by the water surface clutter. To de-tect the floating bottles on the water surface, the radar is usually equipped at a relatively low height. A lower equip-ment height makes the radar more easily affected by the water wave and causes falsely detected targets.
- Lack of semantic information. Compared to RGB images, radar provides very little semantic information.
Therefore, it is challenging to classify the targets using radar data.
It can be seen that, for small object detection on water surfaces, the performance achieved through a single sensor has bottlenecks. Recently, the nuScenes dataset [4] for ob-ject detection and tracking in autonomous driving has been published. The dataset contains images and MMW radar point clouds data, and significantly promotes the researches on deep-level radar-vision fusion based object detection in autonomous driving. However, for small object detection on water surfaces, the characteristics of vision and radar data have changed, which poses new problems. To our knowl-edge, object detection based on deep-level fusion of images and radar in scenes of water surfaces is a relatively unex-plored area. To increase the robustness of object detection on water surfaces and fully utilize the MMW radar point clouds data, in our work, we explore using radar data effec-tively and propose a novel method, which is based on the deep fusion of radar point clouds and RGB images for ro-bust small object detection on water surfaces. Evaluating on the dataset collected in the real-world scene, our model achieves 90.05% average detection accuracy and outper-forms the YOLOv4 [2] baseline (78.46% average accuracy) significantly. In addition, the result of robustness evaluation shows that our model still keeps a good performance when a single sensor degrades.
To summarize, this paper mainly contributes to the fol-lowing aspects: 1. A first-of-its-kind radar-vision fusion based method that can be applied to small object detection for USVs.
Compared to conventional methods, our method can significantly improve the detection performance. 2. A novel approach for the deep-level fusion of MMW radar point clouds and RGB images. By putting forward a novel representation format of radar point clouds and a model that combines different attention mechanisms, the proposed method achieves state-of-the-art accuracy and shows good robustness on detect-ing small object on water surfaces. 3. A real-time object detection system for USVs with ex-tensive evaluations on the real-world dataset of float-ing bottles. Besides, we release our code as well as a radar-vision dataset for small object detection on wa-ter surfaces to benefit the multi-modal fusion object detection research community. 2.