Abstract
Most existing few-shot classification methods only con-sider generalization on one dataset (i.e., single-domain), failing to transfer across various seen and unseen domains.
In this paper, we consider the more realistic multi-domain few-shot classification problem to investigate the cross-domain generalization. Two challenges exist in this new setting: (1) how to efficiently generate multi-domain fea-ture representation, and (2) how to explore domain correla-tions for better cross-domain generalization. We propose a parameter-efficient multi-mode modulator to address both challenges. First, the modulator is designed to maintain multiple modulation parameters (one for each domain) in a single network, thus achieving single-network multi-domain representation. Given a particular domain, domain-aware features can be efficiently generated with the well-devised separative selection module and cooperative query module.
Second, we further divide the modulation parameters into the domain-specific set and the domain-cooperative set to explore the intra-domain information and inter-domain cor-relations, respectively. The intra-domain information de-scribes each domain independently to prevent negative in-terference. The inter-domain correlations guide informa-tion sharing among relevant domains to enrich their own representation. Moreover, unseen domains can utilize the correlations to obtain an adaptive combination of seen do-mains for extrapolation. We demonstrate that the proposed multi-mode modulator achieves state-of-the-art results on the challenging META-DATASET benchmark, especially for unseen test domains. 1.

Introduction
Few-shot classification aims to train a model that can generalize on unseen novel classes with only few labeled
*Part of this work was done when Yanbin Liu was an intern at Baidu
Research. Yi Yang is the corresponding author.
Figure 1. Multi-domain few-shot classification differs from single-domain few-shot classification in two aspects: (1) it contains mul-tiple diverse datasets for training and extra unseen domains for test; (2) there exists potential correlations across multiple domains, e.g., both Omniglot and QuickDraw contain simple shapes. examples in each novel class. Recent progress has been made by the meta-learning paradigm: instead of learning about any training class in particular, few-shot algorithms exploit the training classes to learn to recognize new classes with few examples. Excellent results are achieved on com-mon benchmarks (e.g., Omniglot [21], miniImageNet [33]) by a series of methods [28, 50, 53, 51, 52, 4, 43, 7, 18]. De-spite their success, most of them train and evaluate on only one dataset (i.e., single-domain), failing to learn generalized model across different visual domains (i.e., multi-domain).
In fact, the need for cross-domain generalization is preva-lent in practical applications [44, 13, 24, 23, 14, 11, 26]. For example, we would expect a model trained on ImageNet [6] to be applied on TrafficSigns [17] without collecting extra target training examples (Figure 1).
To break the limitations of existing few-shot classifica-tion methods and benchmarks, [44] have proposed a new
benchmark, META-DATASET, consisting of multiple di-verse datasets and raised the new problem of multi-domain few-shot classification. It differs from conventional single-domain few-shot classification in two aspects (as shown in
Figure 1): (1) It contains multiple diverse datasets for train-ing and extra unseen domains for test; (2) potential corre-lations exist across multiple domains, e.g., both Omniglot and QuickDraw contain simple shapes.
These differences pose two challenges for multi-domain few-shot classification: (1) how to efficiently generate multi-domain representation, and (2) how to explore do-main correlations for better cross-domain generalization.
Current multi-domain methods can not address these chal-lenges well. For example, CNAPs [34] trains a general adaptation network using all training datasets, leading to the single-mode and general-purpose adaptation. For sub-stantially different domains (e.g., ImageNet and Omniglot in Figure 1), this single-mode adaptation network may be insufficient to handle all domains and potential interference may occur.
In contrast, SUR [10] pre-trains multiple in-dependent feature extraction networks to obtain the multi-domain feature representation. However, it is inefficient to maintain multiple replications of the feature extraction net-works and domain-level information sharing is prohibited.
To address the drawbacks of the above methods, we pro-pose a Multi-Mode Modulator (tri-M) to simultaneously model the multi-domain feature representation and cross-domain correlations in a single network. First, the modu-lator is devised to achieve multi-domain representation by incorporating multiple modulation parameters in a single network, where each parameter describes a particular do-main (called a mode). Given a dataset, the domain-aware features are efficiently generated by the well-designed sep-arative selection and cooperative query mechanism.
Second, to explore the domain correlations, the mod-ulation parameters are further divided into two sets: the domain-specific set and the domain-cooperative set, which work complementarily to explore both the intra-domain and inter-domain information. Concretely, the domain-specific set describes each domain independently to prevent neg-ative interference among distant domains, e.g., ImageNet and Omniglot. The domain-cooperative set captures the inter-domain relations to guide beneficial information shar-ing among relevant domains to enrich their own domain-specific representation. Moreover, with the learned domain relations, the unseen domains can be described by an adap-tive combination of the relevant seen domains, showing the extrapolation ability of our model.
Moreover, by design, our modulator is flexible to change the number of modes to deal with varying numbers of datasets and the number of modulation layers to satisfy de-sired model capacity. In experiments, we show the effec-tiveness of each component in our model and visually in-terpret how the selection and query mechanism work on the domain-specific and domain-cooperative sets of parameters.
In summary, our main contributions are three-fold:
• We propose a multi-mode modulator to deal with the multi-domain few-shot classification problem. The domain-aware features can be efficiently generated with our single-network multi-domain model.
• We explicitly model the domain correlations by the domain-specific and domain-cooperative parameter sets. They work complementarily to extract both the intra-domain and inter-domain information.
• We achieve state-of-the-art performance on the chal-lenging META-DATASET benchmark, especially for unseen test domains. 2.