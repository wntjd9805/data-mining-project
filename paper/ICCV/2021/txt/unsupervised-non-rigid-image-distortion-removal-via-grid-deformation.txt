Abstract
Many computer vision problems face difficulties when imaging through turbulent refractive media (e.g., air and water) due to the refraction and scattering of light. These effects cause geometric distortion that requires either hand-crafted physical priors or supervised learning methods to remove.
In this paper, we present a novel unsupervised network to recover the latent distortion-free image. The key idea is to model non-rigid distortions as deformable grids. Our network consists of a grid deformer that esti-mates the distortion field and an image generator that out-puts the distortion-free image. By leveraging the positional encoding operator, we can simplify the network structure while maintaining fine spatial details in the recovered im-ages. Our method doesn’t need to be trained on labeled data and has good transferability across various turbulent image datasets with different types of distortions. Extensive experiments on both simulated and real-captured turbulent images demonstrate that our method can remove both air and water distortions without much customization. 1.

Introduction
Imaging through turbulent refractive medium (e.g., hot air, in-homogeneous gas, fluid flow) is challenging, since the non-linear light transport through the medium (e.g., re-fraction and scattering) causes non-rigid distortions in per-ceived images. However, most computer vision algorithms rely on sharp and distortion-free images to achieve the ex-pected performance. Removal of these non-rigid image dis-tortions is therefore critical and beneficial for many vision applications, from segmentation to recognition.
Air turbulence distortion is caused by the constantly changing refractive index field of the air flow. It typically occurs when imaging through long-range atmospheric tur-bulence or short-range hot air turbulence (e.g., fire flames,
Figure 1. We present a novel unsupervised network to estimate the non-rigid distortion and latent distortion-free image when imaging through turbulent media. Our method works for both air (Row
One) and water (Row Two) distortions. vapor streams). Water turbulence distortion, in contrast, is induced by the refraction of light at the water-air interface.
Although these two types of distortions share certain visual similarities, they are fundamentally different as they are in-duced by different physical mechanisms. Air and water tur-bulent images are usually enhanced in different ways. For air turbulence, physics-based approaches use complex tur-bulence models (e.g., the Kolmogorov model [22, 23]) to simulate the perturbation, and then restore clear images by inverting the models. For water turbulence, classical meth-ods model the distortion as a function of the water surface height or normal by applying Snell’s law [46, 57]. Recently, several learning-based methods are separately proposed to enhance either the air [13, 32] or the water [26] turbulent images. These methods typically require training on a large labeled dataset. Since it is difficult to obtain real turbulent images with ground truth sharp references, these methods use simulated images to augment their datasets and boot-strap the learning.
Motivated by the aforementioned issues, we design an unsupervised network that is able to remove non-rigid dis-Figure 2. The overall architecture of our unsupervised non-rigid image distortion removal network. The network predicts the distortion-free image J, given a sequence of distorted turbulent image {Ik|k = 1, 2, ...K} and uniform grid GU . (cid:101)I and (cid:101)J G are two intermediate results to constrain the optimization procedure. We use the pair-wise differences among I, (cid:101)I, and (cid:101)J G as the optimization losses. tortions from both air and water turbulent images, as shown in Fig. 1. The key idea is to model the non-rigid distor-tions as a deformable grids. For example, we model the distortion-free image as a straight and uniform grid, and tur-bulent images with distorted grids. Inspired by recent works on the Neural Radiance Field (NeRF) [30, 44], we generate the distortion-free image using a grid-based rendering net-work. Our method, therefore, bypasses sophisticated and heterogeneous physical turbulence models and is able to re-store images with different types of distortions.
The overall structure of our network is illustrated in
Fig. 2. Our network consists of two main components: a grid deformer G that estimates the grid deformation and an image generator I that renders a color image that matches the distortion of an input grid. One critical component in our network is the position encoding operator commonly used in NeRF networks [6, 10, 40, 44, 58]. By incorporat-ing this operator into the image generator, we can simplify our network structure while maintaining fine spatial details in the reconstructed output images.
Our network works as an optimizer for generating the distortion-free image by minimizing pairwise differences between the captured input images, the network’s predicted distorted images, and resampled distorted images from the distortion-free image. Our network is fully unsupervised and optimized from scratch on each new example. It does not require any diverse training set to learn from, but run-ning gradient descent on the input data. Specifically, our network is optimized in two steps: we first initialize our network parameters by exploiting the locally-centered prop-erty [35] of pixel displacement caused by turbulent media; we then iteratively update the estimated distortion-free im-age J by minimizing our objective function. Empirically, this two-step optimization converges within 2000 iterations (Adam steps), which takes around 65-499s, depending on the number of input frames. Our initialization provides a reasonable estimation that largely reduces the search space.
We perform extensive experiments on both simulated and real-captured air and water turbulent images. We com-pare our method with the state-of-the-art methods that are specific to either the air or the water turbulence. We show that our method has better performance in correcting the geometric distortions for both types of turbulence. We sum-marize our contributions as follows:
• Our network jointly estimates the non-rigid distortions and recovers the latent distortion-free image. It works for both air and water distortions without much cus-tomization. It is fully unsupervised and does not need to be trained on a labeled dataset.
• Our network leverages the position encoding operator, such that even with fewer numbers of convolutional layers and trainable parameters, it can still generate high-quality images that preserve fine details.
• We propose a two-step optimization framework to guide the training of the unconstrained non-rigid dis-tortion restoration model.
• Extensive experiments demonstrate that state-of-the-art performance can be achieved when applying the proposed grid-based rendering method on two in-herently different tasks: atmospheric turbulence re-moval and imaging through water distortions. Our code is available at: github.com/Nianyi-Li/ unsupervised-NDIR 2.