Abstract
■ r
✌
✍ ✎
✏✑ ✭■
✎✒
✁✁✂
✂
❛♥
❛
✁
✎
✏✑
❢ ■
✍
✏✍ ✭✎
■✒
❛ (cid:0)
♥
✂✁✂ (cid:0)
Typical domain adaptation techniques aim to transfer the knowledge learned from a label-rich source domain to a label-scarce target domain in the same label space. How-ever, it is often hard to get even the unlabeled target do-main data of a task of interest.
In such a case, we can capture the domain shift between the source domain and target domain from an unseen task and transfer it to the task of interest, which is known as zero-shot domain adap-tation (ZSDA). Most of existing state-of-the-art methods for
ZSDA attempted to generate target domain data. However, training such generative models causes signiﬁcant compu-tational overhead and is hardly optimized. In this paper, we propose a novel ZSDA method that learns a task-agnostic domain shift by collaborative training of domain-invariant semantic features and task-invariant domain features via adversarial learning. Meanwhile, the spatial attention map is learned from disentangled feature representations to se-lectively emphasize the domain-speciﬁc salient parts of the domain-invariant features. Experimental results show that our ZSDA method achieves state-of-the-art performance on several benchmarks. 1.

Introduction
Recent deep learning methods achieved success in var-ious computer vision tasks including image classiﬁcation, segmentation, and object detection. However, such deep-learned models often suffer from severe performance degra-dation when the training data and testing data are from dif-ferent domains due to the domain shift [12]. For example, a scene segmentation model trained on synthetic images per-forms worse when applied to real-world images, and vice versa. To tackle this problem, domain adaptation techniques that aim to transfer the knowledge learned from a label-rich source domain to the desired target domain, also known as
*Corresponding author
❙(cid:0)✉✁❝✂ ❞(cid:0)♠❛✄♥
❚☎✆❣✝✞ ✟✠✡☎☛☞
✖ (✗)
✓✔s✕✕✔
Figure 1: An example of zero-shot-domain adaptation. In this scenario, IrT is the digit image analysis and ToI is the fashion image analysis. The source and target domains are grayscale and color image domains, respectively. The ob-jective of zero-shot domain adaptation is to train a model for ToI in the target domain, which is unseen during train-ing time, by learning a task-agnostic domain shift T (·).
”transfer learning”, are actively being studied.
Typical domain adaptation methods assume that the tar-get domain data is available at the training phase. However, in real-world applications, it is often not feasible to get the unlabeled target domain data that shares an identical label space with the source domain data of interest. Such a situ-ation refers to a new transfer learning task, known as zero-shot domain adaptation (ZSDA) [25]. The objective of the zero-shot domain adaptation task is to transfer the domain shift to a task of interest (ToI) from an irrelevant task (IrT) as shown in Fig 1. This domain adaptation technique sug-gests a novel approach for various data scarcity problems.
Suppose that we have a scene text dataset and a synthetic
text dataset to develop a scene text detection model. With
ZSDA, we can also have a model that supports other lan-guages by adding easily producible synthetic datasets.
Prior ZSDA techniques can be categorized into two ap-proaches based on their strategies; 1) generating the target domain samples of ToI and 2) learning domain invariant feature representations over different domains. The meth-ods in the ﬁrst approach typically use generative models such as generative adversarial networks (GAN) [11] or vari-ational autoencoder (VAE) [17] to reconstruct the target do-main distribution and train a model with the generated sam-ples. While this strategy is intuitive, generative models such as GANs and VAEs are prone to problems such as collaps-ing modes and label ﬂipping. These problems can be made worse by samples that are used in domain adaptation.
The other approach for ZSDA is to learn domain invari-ant feature representations. Compared to the sample gen-eration approach, those methods can avoid the aforemen-tioned overhead and undesirable risks of reconstructing tar-get domain data. Learning domain invariant feature repre-sentations have been actively studied for a long time to solve other types of transfer learning problems such as unsuper-vised domain adaptation [10, 27], partial domain adapta-tion [3], and few-shot domain adaptation [24]. However, all the listed techniques are not directly applicable to ZSDA, since they strictly require the unlabeled target domain data to have the same label space with the source domain. When the source and target domains have different labels, the dis-criminative features for IrT are overestimated and the fea-tures for ToI are underestimated while handling target do-main data. Because of this difference among label distribu-tions in domains, this results in a negative transfer effect.
One promising approach for ZSDA is to learn disentan-gled representations of domain-relevant features and task-relevant features. Recent techniques [26, 20] have a fea-ture disentangler to learn a domain-invariant representation from multiple domains via adversarial learning. However, domain-invariant features alone cannot be sufﬁciently dis-criminative to deal with ToI distributions of the target do-main, since the feature extractor never sees it in the training phase.
To address the aforementioned issue, we propose a more effective approach, which collaboratively learns class-agnostic domain feature representations and domain-invariant semantic feature representations. Our training scheme has two phases: disentanglement and reﬁnement.
In the disentanglement stage, we extend the domain adver-sarial adaptation approaches [9, 29] to learn class-agnostic domain features and domain-invariant features simultane-ously. In the reﬁnement stage, a domain feature is trans-formed into a spatial attention map. The spatial atten-tion map selectively emphasizes the domain-speciﬁc salient parts of the domain-invariant semantic feature. This en-hances the discriminative power of the imperfect semantic features.
Our main contribution can be summarized as follows: (1)
We propose an end-to-end framework for zero-shot domain adaptation which does not need any additional information or assumptions in the problem deﬁnition. (2) We propose a novel collaborative feature reﬁnement with disentangled feature representations that can prevent negative transfer ef-fects during zero-shot domain adaptation. (3) Our proposed method achieves state-of-the-art performance in extensive experiments on various benchmarks for zero-shot domain adaptation tasks. 2.