Abstract
Coarse-to-ﬁne strategies have been extensively used for the architecture design of single image deblurring net-works. Conventional methods typically stack sub-networks with multi-scale input images and gradually improve sharp-ness of images from the bottom sub-network to the top sub-network, yielding inevitably high computational costs. To-ward a fast and accurate deblurring network design, we re-visit the coarse-to-ﬁne strategy and present a multi-input multi-output U-net (MIMO-UNet). The MIMO-UNet has three distinct features. First, the single encoder of the
MIMO-UNet takes multi-scale input images to ease the difﬁculty of training. Second, the single decoder of the
MIMO-UNet outputs multiple deblurred images with dif-ferent scales to mimic multi-cascaded U-nets using a sin-gle U-shaped network. Last, asymmetric feature fusion is introduced to merge multi-scale features in an efﬁcient manner. Extensive experiments on the GoPro and Real-Blur datasets demonstrate that the proposed network out-performs the state-of-the-art methods in terms of both ac-curacy and computational complexity. Source code is avail-able for research purposes at https://github.com/ chosj95/MIMO-UNet. 1.

Introduction
Single image deblurring aims to recover a latent sharp image from a blurry image [3]. Even with the rapid devel-opment of camera modules in the last few decades, blur ar-tifact still exists when camera and/or objects move. Blurry images are not only visually unpleasant but signiﬁcantly de-grade the performance of vision systems including surveil-lance [32] and autonomous driving systems [4], necessitat-ing accurate and efﬁcient image deburring techniques.
Owing to the success of deep learning, convolutional neural network (CNN)-based image deblurring methods have been extensively studied and showed promising per-Early CNN-based image deblurring meth-formance.
*equal contribution
†corresponding author
Figure 1. Comparison between the proposed and conventional methods in terms of the PSNR and runtime. The runtime of the methods is reported as the runtime measured using the released test code of each method on our environment (ﬁlled) and the run-time provided in each paper (blank). ods [30, 7, 1, 27] commonly exploit CNN as a blur kernel estimator and construct two-stage image deblurring frame-work, i.e., CNN-based blur kernel estimation stage and kernel-based deconvoltion stage. On the other hand, recent
CNN-based image deblurring methods [20, 22, 23, 31, 5] aim to directly learn the complicated relationship between blurry-sharp image pairs in an end-to-end manner. As a pi-oneering technique, a deep multi-scale CNN for dynamic scene deblurring (DeepDeblur) [20] is introduced to directly regress a sharp image from a blurry image. DeepDeblur consists of multiple stacked sub-networks to handle multi-scale blur, where each sub-network takes a down-scaled im-age and gradually recovers a sharp image in a coarse-to-ﬁne manner. Motivated by the success of DeepDeblur, vari-ous CNN-based image deblurring methods [22, 23, 31, 5] have been introduced with remarkable performance im-provements. Although these methods try to improve the deblurring performance in different aspects, their coarse-to-ﬁne strategies are similar in that multiple sub-networks are stacked.
In other words, a coarse-to-ﬁne network design principle has proven to be effective in image deblurring.
Figure 2. Comparison of coarse-to-ﬁne image deblurring network architectures: (a) DeepDeblur, (b) PSS-NSC, (c) MT-RNN, and (d) pro-posed MIMO-UNet.
However, such efﬁciency comes at the cost of the inevitable increase in the computational complexity and memory us-age, making the conventional methods difﬁcult to be used for cost and time-sensitive environments such as mobile de-vices, vehicles, and robots. Recently, a light-weight CNN is presented for efﬁcient single image deblurring [33]. Specif-ically, by using optical ﬂow and global motion of blurry im-ages as extra supervision for network training, they design a shallower architecture compared to that of conventional deblurring networks. However, such shallow architecture failed in obtaining deblurring accuracy comparable to state-of-the-art methods.
In this paper, we revisit the coarse-to-ﬁne scheme and present a novel deblurring network called multi-input multi-output UNet (MIMO-UNet) that can handle multi-scale blur with low computational complexity. The proposed MIMO-UNet is a single encoder-decoder-based U-shaped network that has three distinct features.
First, the single decoder of the MIMO-UNet outputs multiple deblurred images, and therefore we name our de-coder as multi-output single decoder (MOSD). The MOSD is simple but can mimic conventional network architectures composed of stacked sub-networks and guide the decoder layers to gradually recover latent sharp images in a coarse-to-ﬁne manner. Second, the single encoder of the MIMO-UNet takes multi-scale input images; thus, our encoder is called multi-input single encoder (MISE). Last, asymmet-ric feature fusion (AFF) is introduced to merge multi-scale features in an efﬁcient manner. The AFF takes features from different scales and merges multi-scale information
ﬂow across the encoder and the decoder to improve the de-blurring performance. Extensive experiments demonstrate the superiority of the proposed MIMO-UNet compared to the state-of-the-art methods in terms of the PSNR as well as the computational complexity as shown in Figure 1. 2.