Abstract
Existing Unsupervised Domain Adaptation (UDA) liter-ature adopts the covariate shift and conditional shift as-sumptions, which essentially encourage models to learn common features across domains. However, due to the lack of supervision in the target domain, they suffer from the semantic loss: the feature will inevitably lose non-discriminative semantics in source domain, which is how-ever discriminative in target domain. We use a causal view—transportability theory [40]—to identify that such loss is in fact a confounding effect, which can only be re-moved by causal intervention. However, the theoretical solution provided by transportability is far from practical for UDA, because it requires the stratiﬁcation and repre-sentation of the unobserved confounder that is the cause of the domain gap. To this end, we propose a practi-cal solution: Transporting Causal Mechanisms (TCM), to identify the confounder stratum and representations by us-ing the domain-invariant disentangled causal mechanisms, which are discovered in an unsupervised fashion. Our
TCM is both theoretically and empirically grounded. Ex-tensive experiments show that TCM achieves state-of-the-art performance on three challenging UDA benchmarks:
ImageCLEF-DA, Ofﬁce-Home, and VisDA-2017. Codes are available at https://github.com/yue-zhongqi/ tcm. 1.

Introduction
Machine learning is always challenged when transport-ing training knowledge to testing deployment, which is gen-erally known as Domain Adaptation (DA) [37]. As shown in Figure 1, when the target domain (S = t) is drasti-cally different (e.g., image style) from the source domain (S = s), deploying a classiﬁer trained in S = s results in poor performance due to the large domain gap [5]. To nar-row the gap, conventional supervised DA requires a small set of labeled data in S = t [13, 45], which is expensive and sometimes impractical. Therefore, we are interested in a
Figure 1: A DA example from source “Real World” to target
“Clipart” domain in the Ofﬁce-Home benchmark [53]. more practical setting: Unsupervised DA (UDA), where we can leverage the abundant unlabelled data in S = t [37, 29].
For example, when adapting an autopilot system trained in one country to another, where the street views and road signs are different, one can easily collect unlabelled street images from a camera-equipped vehicle cruise.
Existing UDA literature widely adopts the following two assumptions on the domain gap1: 1) Covariate Shift [50, 4]:
P (X|S = s) (cid:54)= P (X|S = t), where X denotes the sam-ples, e.g., real-world vs. clip-art images; and 2) Conditional
Shift [49, 31]: P (Y |X, S = s) (cid:54)= P (Y |X, S = t), where Y denotes the labels, e.g., in clip-art domain, the “pure back-ground” feature extracted from X is no longer a strong vi-sual cue for Y = “speaker” as in real-world domain. To turn
“(cid:54)=” into “=”, almost all existing UDA solutions rely on learning invariant (or common) features in both source and target domains [50, 20, 29]. Unfortunately, due to the lack of supervision in target domain, it is challenging to capture such domain invariance.
For example, in Figure 1, when S = s, the distribution of
“