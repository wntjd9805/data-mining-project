Abstract
Invariance and equivariance to the rotation group have been widely discussed in the 3D deep learning community for pointclouds. Yet most proposed methods either use com-plex mathematical tools that may limit their accessibility, or are tied to specific input data types and network archi-tectures. In this paper, we introduce a general framework built on top of what we call Vector Neuron representations for creating SO(3)-equivariant neural networks for point-cloud processing. Extending neurons from 1D scalars to 3D vectors, our vector neurons enable a simple mapping of
SO(3) actions to latent spaces thereby providing a frame-work for building equivariance in common neural opera-tions – including linear layers, non-linearities, pooling, and normalizations. Due to their simplicity, vector neurons are versatile and, as we demonstrate, can be incorporated into diverse network architecture backbones, allowing them to process geometry inputs in arbitrary poses. Despite its sim-plicity, our method performs comparably well in accuracy and generalization with other more complex and special-ized state-of-the-art methods on classification and segmen-tation tasks. We also show for the first time a rotation equiv-ariant reconstruction network. Source code is available at https://github.com/FlyingGiraffe/vnn. 1.

Introduction
With the proliferation of lower-cost depth sensors, learn-ing on 3D data has seen rapid progress in recent years. Of particular interest are pointcloud networks, such as Point-Net [27] or ACNe [33] that fully respect the inherent set symmetry – that point sets are not ordered – by incorpo-rating order-invariant and/or order-equivariant layers. Yet, there are other important symmetries that have been less perfectly addressed in the context of pointcloud process-ing, with 3D rotations being a prime example. Consider a scenario where one scans an object using their LIDAR-equipped phone to retrieve similar objects. Clearly, the global object pose should not affect the query result. Point-Net uses spatial transformer layers [16], which only attain
Figure 1: By lifting latent representations from vectors of scalar entries to vectors of 3D points (i.e., matrices) we fa-cilitate the creation of a simple rotation equivariant toolbox allowing the implementation of fully equivariant pointcloud networks. approximate pose invariance while also requiring extensive augmentation at train time.
To avoid an exhaustive data augmentation with all pos-sible rotations, there is a need for network layers that are equivariant to both order and SO(3) symmetries. Recently, two approaches have been introduced to tackle this set-ting: Tensor Field Networks [35] and SE(3)-Transformers
[14]. While guaranteeing equivariance by construction, both frameworks involve an intricate formulation and are hard to incorporate into existing pipelines as they are re-stricted to convolutions and rely on relative positions of ad-jacent points.
In this work, we address these issues by proposing a simple, lightweight framework to build SO(3) equivariant and invariant pointcloud networks. A core ingredient in our framework is a Vector Neuron (VN) representation, extend-ing classical scalar neurons to 3D vectors. Consequently, instead of latent vector representations which can be views as ordered sequences of scalars, we deploy latent matrix representations which can be viewed as (ordered) sequences of 3-vectors. Such a representation supports a direct map-are the first to demonstrate a 3D equivariant network for 3D reconstruction.
• When evaluated on classification and segmentation, our
VN version of popular non-equivariant architectures achieve state-of-the-art performance. 2.