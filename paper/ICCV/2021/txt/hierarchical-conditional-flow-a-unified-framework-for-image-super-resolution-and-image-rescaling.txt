Abstract y
Normalizing flows have recently demonstrated promis-ing results for low-level vision tasks. For image super-resolution (SR), it learns to predict diverse photo-realistic high-resolution (HR) images from the low-resolution (LR) image rather than learning a deterministic mapping. For image rescaling, it achieves high accuracy by jointly mod-elling the downscaling and upscaling processes. While ex-isting approaches employ specialized techniques for these two tasks, we set out to unify them in a single formula-In this paper, we propose the hierarchical condi-tion. tional flow (HCFlow) as a unified framework for image SR and image rescaling. More specifically, HCFlow learns a bijective mapping between HR and LR image pairs by modelling the distribution of the LR image and the rest high-frequency component simultaneously.
In particular, the high-frequency component is conditional on the LR im-age in a hierarchical manner. To further enhance the per-formance, other losses such as perceptual loss and GAN loss are combined with the commonly used negative log-likelihood loss in training. Extensive experiments on gen-eral image SR, face image SR and image rescaling have demonstrated that the proposed HCFlow achieves state-of-the-art performance in terms of both quantitative metrics and visual quality. 1.

Introduction
Normalizing flows [7, 8, 22, 12, 16, 36] are powerful deep generative probabilistic models that allow for efficient and exact likelihood calculation and sampling. They have been used in the generation of image [8, 22], blur ker-nel [28], and audio [20] data. Recently, in the low-level vision community, normalizing flows have attracted much interest and have achieved promising progress for image super-resolution (SR) [32] and image rescaling [47].
*Corresponding author. z y z x x (a) SRFlow (b) IRN y z x (c) HCFlow
Figure 1: The comparison between SRFlow [32], IRN [47] and the proposed HCFlow. x, y and z denote HR image, LR im-age and the latent variable, respectively. Blue boxes are invert-ible neural networks, while green ones are non-invertible mod-els (e.g., CNN). Solid bi-directional arrows denote bijective map-pings, while dashed arrows represent conditional relations.
SRFlow [32] is a seminal flow-based model for image
SR. Unlike previous CNN-based models that learn a deter-ministic mapping from the low-resolution (LR) image to the high-resolution (HR) image, SRFlow learns the distribution of HR images and is able to generate diverse photo-realistic
HR images. However, as shown in Fig. 1(a), it treats the LR image as an external conditional prior and thus is not fully invertible between HR and LR image pairs, making it hard to be used for image rescaling. Another work IRN [47] em-ploys an invertible neural network to learn downscaling and upscaling for image rescaling. Since the model is bijective, it can recover the input HR image with high accuracy af-ter downscaling. Nevertheless, as shown in Fig. 1(b), it as-sumes the high-frequency and low-frequency components of the image are independent of each other and thus lacks the ability to exploit their dependency for image SR.
In this paper, we propose a hierarchical conditional flow (HCFlow) as a unified framework for both image SR and rescaling. As shown in Fig. 1(c), HCFlow is an invertible flow-based model for modelling the HR-LR relationship,
in which the high-frequency component is hierarchically conditional on the low-frequency component of the im-age. More specifically, in the forward propagation, HCFlow learns to decompose the input HR image into the LR im-In the inverse propagation, it age and a latent variable. generates HR images based on the LR input and random samples of the latent variable. The modelling of the latent variable (high-frequency component) is conditional on the generated LR image (low-frequency component) in a hier-archical manner.
When trained for image SR, HCFlow is optimized by minimizing the negative log-likelihood loss on the basis of tractable Jacobian determinant computation. To further im-prove visual quality, we integrate a pixel loss, perceptual loss, and GAN loss in the inverse propagation to constrain the learned HR space. Moreover, HCFlow can be used for the image rescaling task. It can decompose the HR image to a visually-pleasing LR image and a latent variable that fol-lows a simple distribution. In this case, HCFlow is trained as an encoder-decoder framework, in which the forward and inverse processes are jointly optimized. As HCFlow is bi-jective, it can recover the HR image faithfully by sampling from the latent space given the generated LR image.
Our contributions can be summarized as follows: 1) We propose a unified framework for image SR and
It learns to model the LR image image rescaling. and the residual high-frequency component simultane-ously. The high-frequency component is hierarchically conditional on the generated LR image. 2) We propose additional losses to train normalizing flows, including pixel, perceptual, and GAN losses, which effectively enhances the HR image quality. 3) We perform extensive experiments on three tasks: gen-eral image SR, face image SR and image rescaling.
HCFlow achieves state-of-the-art results on all tasks in terms of both quantitative metrics and visual quality. 2.