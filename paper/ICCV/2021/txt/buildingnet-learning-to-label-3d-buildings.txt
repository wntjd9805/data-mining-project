Abstract
We introduce BuildingNet: (a) a large-scale dataset of 3D building models whose exteriors are consistently la-beled, and (b) a graph neural network that labels build-ing meshes by analyzing spatial and structural relations of their geometric primitives. To create our dataset, we used crowdsourcing combined with expert guidance, resulting in 513K annotated mesh primitives, grouped into 292K se-mantic part components across 2K building models. The dataset covers several building categories, such as houses, churches, skyscrapers, town halls, libraries, and castles. We include a benchmark for evaluating mesh and point cloud labeling. Buildings have more challenging structural com-plexity compared to objects in existing benchmarks (e.g.,
ShapeNet, PartNet), thus, we hope that our dataset can nur-ture the development of algorithms that are able to cope with such large-scale geometric data for both vision and graphics tasks e.g., 3D semantic segmentation, part-based generative models, correspondences, texturing, and anal-ysis of point cloud data acquired from real-world build-ings. Finally, we show that our mesh-based graph neu-ral network signiﬁcantly improves performance over sev-eral baselines for labeling 3D meshes. Our project page www.buildingnet.org includes our dataset and code. 1.

Introduction
Architecture is a signiﬁcant application area of 3D vi-sion. There is a rich body of research on autonomous per-ception of buildings, led in large part by digital map devel-opers seeking rich annotations and 3D viewing capabilities for building exteriors [14], as well as roboticists who design
[45]). Recent robots to operate in building interiors (e.g. advances in AR/VR also rely on computer-aided building analysis [6]. Early work on digital techniques for architec-tural design, including freeform design explorations as well as full-ﬂedged constructions [15], led to the current ubiquity of computational design tools in architectural studios. In ad-dition, computers can automate the processing of architec-tural data such as photographs, satellite images and building plans, for archival and analytical purposes (e.g. [62, 32]).
Thus, there is signiﬁcant incentive to apply modern data-driven geometry processing to the analysis of buildings.
However, while buildings are bona ﬁde geometric object-s with well-established design principles and clear ontolo-gies, their structural and stylistic complexity is typically greater than, or at least markedly different from, those of shapes in common 3D datasets like ShapeNet [5] and S-canNet [10]. This makes them challenging for standard shape analysis pipelines, both for discriminative tasks such as classiﬁcation, segmentation and point correspondences, as well as for generative tasks like synthesis and style trans-fer. Further, data-driven methods demand data, and to the best of our knowledge there are no large-scale, consistently-annotated, public datasets of 3D building models.
In this paper, we present BuildingNet, the ﬁrst publicly available large-scale dataset of annotated 3D building mod-els whose exteriors and surroundings are consistently la-beled. The dataset provides 513K annotated mesh prim-itives across 2K building models. We include a bench-mark for mesh and point cloud labeling, and evaluate sever-al mesh and point cloud labeling networks. These methods were developed primarily for smaller single objects or inte-rior scenes and are less successful on architectural data.
In addition, we introduce a graph neural network (GNN) that labels building meshes by analyzing spatial and struc-tural relations of their geometric primitives. Our GNN treat-s each subgroup as a node, and takes advantage of relations, such as adjacency and containment, between pairs of nodes.
Neural message passing in the graph yields the ﬁnal mesh labeling. Our experiments show that this approach yields signiﬁcantly better results for 3D building data than prior methods. To summarize, our contributions are:
• The ﬁrst large-scale, publicly available 3D building dataset with annotated parts covering several common categories, in addition to a benchmark.
• A graph neural network that leverages pre-existing noisy subgroups in mesh ﬁles to achieve state-of-the-art results in labeling building meshes.
• An annotation interface and crowdsourcing pipeline for collecting labeled parts of 3D meshes, which could also extend to other categories of 3D data. 2.