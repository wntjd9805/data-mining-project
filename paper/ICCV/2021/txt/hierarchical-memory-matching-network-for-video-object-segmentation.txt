Abstract
We present Hierarchical Memory Matching Network (HMMN) for semi-supervised video object segmentation.
Based on a recent memory-based method [33], we pro-pose two advanced memory read modules that enable us to perform memory reading in multiple scales while ex-ploiting temporal smoothness. We first propose a kernel guided memory matching module that replaces the non-local dense memory read, commonly adopted in previous memory-based methods. The module imposes the tempo-ral smoothness constraint in the memory read, leading to accurate memory retrieval. More importantly, we intro-duce a hierarchical memory matching scheme and propose a top-k guided memory matching module in which mem-ory read on a fine-scale is guided by that on a coarse-scale. With the module, we perform memory read in mul-tiple scales efficiently and leverage both high-level seman-tic and low-level fine-grained memory features to predict detailed object masks. Our network achieves state-of-the-art performance on the validation sets of DAVIS 2016/2017 (90.8% and 84.7%) and YouTube-VOS 2018/2019 (82.6% and 82.5%), and test-dev set of DAVIS 2017 (78.6%). The source code and model are available online: https:
//github.com/Hongje/HMMN . 1.

Introduction
Semi-supervised video object segmentation (VOS) aims to predict the foreground object mask in every frame of a video given an object mask at the first frame. Recently, memory-based VOS methods [33, 39, 27, 21, 22, 23] have achieved great success. A key idea of the memory-based methods is matching densely between query (i.e., current frame) and memory (i.e., past frames with given or pre-dicted masks) to retrieve the memory at a pixel-level. Since the camera’s field of view or objects in a video may move, spatio-temporal non-local and dense matching was per-formed to compute similarity for all matching possibilities.
There are two limitations of the existing memory-based
*Corresponding author.
Figure 1. Previous memory-based methods densely match image features only at a coarse resolution, as shown in (a). To conduct the memory reading at multiple scales, one can naively apply dense matching at each scale (b), but it needs prohibitive computational cost and is not robust due to noisy low-level features. In our hi-erarchical memory matching architecture, shown in (c), fine-scale matching is guided by coarse-scale matching, resulting in efficient and robust memory matching in multiple scales. temporal smoothness and fine-grained memory methods: information. Temporal smoothness is one of the strong con-straints that we can assume for the VOS task. Previous
VOS methods without memory often applied a local match-ing [43, 50] or local refinement [34, 16, 32, 49, 13, 53] between two adjacent frames for temporal smoothness.
However, in the memory-based method [33], the non-local matching completely ignores the constraint and it raises the risk of false matches (e.g., when multiple similar instances exist, see Fig. 3). Another weakness is the lack of fine-grained memory information. In the memory-based meth-ods, a query encoder only takes the current frame without any target information. Thus the memory matching is the only source to get information of the target object mask.
The previous memory-based methods conduct the memory matching only at the coarsest resolution, (e.g., 1/16 of the input resolution [33]), as shown in Fig. 1 (a). At the low res-olution, while accurate matching is possible with high-level
semantic features, we cannot expect fine-grained informa-tion that is also important to predict fine-detailed masks.
In this paper, we propose Hierarchical Memory Match-ing Network (HMMN) with two novel memory matching modules. To exploit the temporal smoothness, we propose kernel guided memory matching module. We restrict possi-ble correspondences between two adjacent frames to a local window and apply kernel guidance to the non-local memory matching that imposes the temporal smoothness constraint.
For long-range matching between distant frames, we track the most probable correspondence for each memory pixel to a query pixel and apply relaxed kernel guidance accord-ing to the temporal distance, resulting in a smooth tran-sition from local to global memory matching. This mod-ule replaces the non-local memory reading in the previous memory-based networks.
To retrieve fine-grained memory information, we pro-pose top-k guided memory matching module. The computa-tional cost for the dense memory matching grows quadrati-cally with increasing search space. Naively performing the memory reading at fine-scales [51] (Fig. 1 (b)) requires pro-hibitively heavy computation. Also, memory matching with the low-level features at a fine-scale is susceptible to noisy matches. Our top-k guided memory matching solves both the computational cost and the matching robustness issues.
We first sample the top-k candidate memory locations for each query pixel using the matching similarity score at the coarse-scale. Then, we conduct fine-scale memory match-ing between each query pixel and the corresponding can-didate memory locations, as shown in Fig. 1 (c). The top-k guided memory matching reduces the matching com-plexity at high-resolution significantly from O(T H 2W 2) to
O(kHW ), where T , H, and W are the time, height, and width of the feature map, and k is a constant. The coarse-to-fine hierarchical matching scheme makes our fine-scale memory matching robust even with low-level features. We note that some previous works [19, 55] also reduce memory matching complexity by extracting k matching candidates but they select candidates using features at the same scale.
In contrast, we selected k matching candidates from high-level (i.e., coarse-scale) semantic features, thus semanti-cally more accurate matching candidates would be selected.
Our contributions are summarized as follows:
• We propose kernel guided memory matching module, imposing the temporal smoothness constraint to the non-local matching with all memory frames.
• We propose top-k guided memory matching module, resulting in efficient and robust fine-scale memory matching.
• With the two novel memory matching modules, we present Hierarchical Memory Matching Network (HMMN) that performs coarse-to-fine hierarchical memory matching effectively.
• Our network achieves state-of-the-art performance on both DAVIS and YouTube-VOS benchmarks. 2.