Abstract
Generalization on out-of-distribution (OOD) test data is an essential but underexplored topic in visual question an-swering. Current state-of-the-art VQA models often exploit the biased correlation between data and labels, which re-sults in a large performance drop when the test and train-ing data have different distributions. Inspired by the fact that humans can recognize novel concepts by composing ex-isted concepts and capsule network’s ability of representing part-whole hierarchies, we propose to use capsules to repre-sent parts and introduce “Linguistically Routing” to merge parts with human-prior hierarchies. Specifically, we first fuse visual features with a single question word as atomic parts. Then we introduce the “Linguistically Routing” to reweight the capsule connections between two layers such that: 1) the lower layer capsules can transfer their out-puts to the most compatible higher capsules, and 2) two capsules can be merged if their corresponding words are merged in the question parse tree. The routing process max-imizes the above unary and binary potentials across multi-ple layers and finally carves a tree structure inside the cap-sule network. We evaluate our proposed routing method on the CLEVR compositional generation test, the VQA-CP2 dataset and the VQAv2 dataset. The experimental results show that our proposed method can improve current VQA models on OOD split without losing performance on the in-domain test data. 1.

Introduction
The task of visual question answering (VQA) is to cor-rectly answer a question about an image. It is regarded as a core task towards the complete AI [5] as it requires a vast
*Corresponding author is Liang Lin. Qingxing Cao and Xiaodan Liang are with the School of Intelligent Systems Engineering, Shenzhen Campus of Sun Yat-sen University, China. Wentao Wan, Keze Wang and Liang
Lin is with the School of Computer Science and Engineering, Sun Yat-sen
University, China. range of knowledge across multiple domains. However, the complexity of this task also makes it impossible to annotate enough training data that can cover all background knowl-edge and reasoning routes. Thus, a VQA model must capa-ble of generalizing on out-of-distribution (OOD) test data to handle the unconstrained VQA tasks for practical appli-cation.
Current state-of-the-art VQA models [47, 40, 41] focus on increasing models’ capacity, but tend to catch the super-ficial correlation between questions and answers [17, 24].
As such correlation only holds on training distribution, their performance drops on test data that have a different distribu-tion. Other works [42, 49, 21, 26, 23] have explored struc-tured models to represent atomic elements(e.g. object size, color, or relationships) and then integrate elements to infer the final results. These methods have better interpretabil-ity and generalization ability but perform worse than state-of-the-art neural networks on general and unconstrained in-domain test data.
Humans can recognize novel concepts by incorporating learned concepts [30]. This compositional generalization ability allows people to solve a plethora of problems using a limited set of basic skills and is one of the major differ-ences between human intelligence and the current deep neu-ral networks. Meanwhile, the capsule network [38, 20, 19] has the potential to connect the end-to-end neural network with part-based models [14] that represent a sample with part-whole hierarchies. Each capsule can be used to repre-sent a certain part and the routing process can be used to model the hierarchical structure. Although the capsule net-work demonstrates interesting grouping properties in some toy experiments, it still shows unsatisfactory results on the large-scale image datasets since the diverse visual compo-sitions cannot be captured by learning grouping weights in a black-box manner without proper guidance.
Thus, we propose to inject the human-developed struc-ture into the capsule network to improve neural networks’ compositional generalization ability while maintaining their performance on in-domain settings, as shown in Figure 1.
Figure 1: Our proposed Linguistically Routing aims to merge capsules from bottom to top following the linguistic parse tree guidance. Each row or circle represents a capsule and each color represents an encoded word. This compositional process is performed across multiple layers and results in the tree structure inside the capsule network.
Specifically, we propose the “Linguistically Routing” to generate the adaptive reasoning routines inside the capsule network with the guidance of the question parse tree. We first fuse each visual capsule with a single question word to obtain the multimodal representation of the image and question fragment. At each layer, the linguistically rout-ing generates the reweighting vector between [0, 1] for each capsule, such that: 1) only the most compatible higher cap-sules are activated and receive the outputs from each lower capsule, and 2) two capsules should be merged if their cor-responding question fragments are merged in the parse tree.
To meet the above two requirements, the proposed linguisti-cally routing learns to predict the unary potentials that select the most representative capsules for each specific sample; and generates the binary potentials that indicate whether two capsules should be merged or not. The linguistically routing maximizes the unary and binary potential with a conditional random field (CRF). After forwarding all lay-ers, a composing structure isomorphic to the parse tree is carved inside the networks, and the capsules from the bot-tom to the top layer can encode the question words, phrases, clauses, and finally a sentence.
Our contribution can be summarized as follows. 1) We propose an end-to-end trainable routing method that can incorporate external structure information into the capsule network. 2) We propose to utilize the linguistic parse tree to guide the routing and tailor it to the visual question answer-ing task. 3) We perform extensive experiments and show the proposed linguistically routing capsule network can ob-tain good generalization capability while maintaining per-formance on in-domain test data. 2.