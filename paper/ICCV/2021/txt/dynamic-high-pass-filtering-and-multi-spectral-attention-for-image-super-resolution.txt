Abstract
Deep convolutional neural networks (CNNs) have pushed forward the frontier of super-resolution (SR) re-search. However, current CNN models exhibit a major
ﬂaw: they are biased towards learning low-frequency sig-nals. This bias becomes more problematic for the image SR task which targets reconstructing all ﬁne details and image textures. To tackle this challenge, we propose to improve the learning of high-frequency features both locally and glob-ally and introduce two novel architectural units to exist-ing SR models. Speciﬁcally, we propose a dynamic high-pass ﬁltering (HPF) module that locally applies adaptive
ﬁlter weights for each spatial location and channel group to preserve high-frequency signals. We also propose a ma-trix multi-spectral channel attention (MMCA) module that predicts the attention map of features decomposed in the frequency domain. This module operates in a global con-text to adaptively recalibrate feature responses at differ-ent frequencies. Extensive qualitative and quantitative re-sults demonstrate that our proposed modules achieve better accuracy and visual improvements against state-of-the-art methods on several benchmark datasets. 1.

Introduction
Image SR is a modeling task that estimates a high-resolution (HR) image from its low-resolution (LR) coun-terpart. Image SR is a challenging and ill-posed problem since multiple solutions exist for any LR input. Given the recent advances in deep learning, convolutinal neural net-work (CNN) based SR methods have been leveraged in a wide variety of research domains such as biomedicine, ob-ject recognition, and hyper-spectral imaging [9, 21, 32, 43].
The promising results and potential impact of SR in these domains have garnered attention from the vision re-search community. Many CNN-based methods have been proposed [4, 5, 6, 7, 17, 20, 47, 49] and signiﬁcantly out-perform traditional methods. In line with the ‘very deep’
HR
Bicubic
DBPN [11]
Urban100: img 024
CSNLN [29]
RCAN [47]
Ours
Figure 1: Visual comparison (×4) on “image 024” from Ur-ban100. Existing methods suffer from blurring artifacts. paradigm, these methods use over-parameterized networks with hundreds of layers. This approach is usually coupled with a recent architectural breakthrough known as residual learning. Residual learning alleviates the degradation prob-lem due to increased depth, and simpliﬁes the learning task, which improves network convergence.
Although these advancements have enhanced perfor-mance and are now commonplace in SR networks, these methods still suffer from a serious ﬂaw (see Figure 1). It has been demonstrated that neural networks exhibit a bias towards low-frequency signals. Figure 2 illustrates a prime example of this. In the output of a popular and robust SR baseline, RCAN [47], we can see that the high-frequency data are signiﬁcantly reduced, causing the reconstruction to be overly smooth. This is due to many aspects of training, such as the loss function, architecture type, and optimiza-tion method. Ledig et al. [20] already showed that standard pixel-wise metrics ((cid:96)1 or (cid:96)2) tend to pull the reconstruction towards an average of the possible reconstructions equidis-tant in terms of the (cid:96)2 loss on the natural image manifold.
Similarly, higher frequencies struggle to propagate due to the architecture and optimization method of the networks
[2]. They become quickly saturated with low-frequency patterns ﬁrst, thereby halting the learning of additional in-formation. Since there is high information redundancy be-tween channels, many recent works propose using various attention mechanisms to re-weight channels. The classic channel attention mechanism, SENet [13], suffers from one major drawback. Qin et al. [33] theoretically demonstrated that by using global average pooling, SENet discards all other frequencies except the lowest one. Another issue
2.