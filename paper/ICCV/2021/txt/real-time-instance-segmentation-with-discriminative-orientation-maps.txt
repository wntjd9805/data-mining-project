Abstract
Although instance segmentation has made considerable advancement over recent years, it’s still a challenge to de-sign high accuracy algorithms with real-time performance.
In this paper, we propose a real-time instance segmenta-tion framework termed OrienMask. Upon the one-stage object detector YOLOv3, a mask head is added to predict some discriminative orientation maps, which are explicitly defined as spatial offset vectors for both foreground and background pixels. Thanks to the discrimination ability of orientation maps, masks can be recovered without the need for extra foreground segmentation. All instances that match with the same anchor size share a common orienta-tion map. This special sharing strategy reduces the amor-tized memory utilization for mask predictions but without loss of mask granularity. Given the surviving box predic-tions after NMS, instance masks can be concurrently con-structed from the corresponding orientation maps with low complexity. Owing to the concise design for mask rep-resentation and its effective integration with the anchor-based object detector, our method is qualified under real-time conditions while maintaining competitive accuracy.
Experiments on COCO benchmark show that OrienMask achieves 34.8 mask AP at the speed of 42.7 fps evalu-ated with a single RTX 2080 Ti. The code is available at https://github.com/duwt/OrienMask. 1.

Introduction
Instance segmentation aims at pixel-wise predictions for every individual object. It integrates instance-level object detection [28, 26, 19, 16] and pixel-level semantic segmen-tation [21, 6, 7], formulating a more fine-grained visual per-ception task. Currently there are two dominating types of solutions, namely detection-based and segmentation-based methods. The former extends an object detector with addi-tional foreground dense predictions while the latter deploys specific per-pixel attributes or embeddings to separate in-stances of the same category in a bottom-up way.
*Corresponding author. Email: xiangzy@zju.edu.cn
Figure 1. Orientation-based Mask Construction. Those arrowed lines denote densely predicted orientation vectors. Each mask is constructed by gathering all pixels pointing to the central region of the instance in the matched orientation map (white or black).
Both paradigms have apparent drawbacks. Conventional detection-based methods like Mask R-CNN [9] rely on the features pooling operation to project all regions of interest (RoIs) into a fixed size. Since the subsequent mask head should be applied to abundant feature maps of every region proposal, the speed is largely constrained especially when objects densely appear. Moreover, the constant mask reso-lution brings in unnecessary computation for small objects and loses valuable details for large targets. On the contrary, segmentation-based methods [20, 15] retain the fine-grained appearance and geometry in a pixel-to-pixel manner. They can acquire satisfactory results at elementary scenarios but often fall behind detection-based approaches in accuracy.
When the scale of objects varies and the number of cate-gories increases, the generalization of pixel-level clustering adopted in segmentation-based methods is still in doubt.
For the requirement of real-time inference, YOLACT [2] is proposed along with a special mask construction scheme, which linearly combines shared non-local prototypes with instance-wise coefficients. It discards the RoI pooling op-eration that commonly adopted in earlier detection-based methods and directly assemblies masks from fine-grained feature maps. Following this paradigm, an improved ap-It replaces proach named BlendMask [4] is put forward. the 1D instance-specific coefficients with a set of attention maps, which supply additional spatial-adaptive information
to enrich fine-grained details of masks. The success of these solutions shows great potential to incorporate informative global features into detection-based methods. However, one noticeable flaw of these approaches lies in the dependence of RoI cropping operations when generating the assembled masks, which may bring in some mask incompleteness due to inaccurate bounding box predictions.
In this work, we attempt to integrate fine-grained expres-sions with an one-stage detector in another way. To be spe-cific, we focus on compact mask representation and efficient integration with the anchor-based detector YOLOv3 [27] to achieve real-time performance. First, a novel discrimina-tive orientation map is proposed to encode multiple masks independently, where pixels are assigned with centripetal or centrifugal vectors according to their positive or negative labels. This design is totally free from any other semantic segmentation or foreground predictions and is lightweight to decode the complete masks. In addition, considering ob-jects of diverse scales vary the magnitude distributions of orientation vectors, multi-scale design is also taken into ac-count. We assign different orientation maps for instances matching with certain anchor sizes so that the completeness of mask representation is guaranteed. OrienMask merely extends an extra head to the object detector and its func-tion is tightly combined with the box assignment and pre-defined anchor sizes. During inference, for each predicted bounding box, its instance mask can be quickly constructed based on the discriminative vectors in the corresponding orientation map, as shown in Figure 1. This process is sim-ple and direct, consisting of nothing but determining binary labels for all pixels by the spatial destinations that orienta-tion vectors indicate. The main contributions of our work can be summarized as follows:
• We put forward a light and discriminative orientation-based mask representation for real-time instance seg-mentation. By defining opposite orientation vectors for foreground and background pixels, we are able to effectively encode multiple instance masks in a fine-grained two-channel map without the need for explicit foreground segmentation. In inference, given the tar-get regions of instances, their masks can be easily con-structed from orientation maps in parallel.
• To deal with objects with various sizes, we propose an instance grouping mechanism derived from anchor-based detectors. Each group of instances with similar sizes are assigned to share a common class-agnostic orientation map. We also expand the annotated bound-ing boxes to provide sufficient supervision for back-ground. The enlarged valid training area not only bal-ances the number of positive and negative samples but also helps distinguishing them around the boarders.
• We integrate the discriminative orientation maps into a fast anchor-based detector YOLOv3 and implement the resulting model OrienMask end-to-end. Experi-ments show that it is able to achieve 34.8 mask AP at a speed of 42.7 fps on COCO benchmark, which is quite competitive among state-of-the-art real-time methods. 2.