Abstract
In this paper, we propose a novel two-stage context-aware network named CANet for shadow removal, in which the contextual information from non-shadow regions is transferred to shadow regions at the embedded feature spaces. At Stage-I, we propose a contextual patch match-ing (CPM) module to generate a set of potential match-ing pairs of shadow and non-shadow patches. Combined with the potential contextual relationships between shadow and non-shadow regions, our well-designed contextual fea-ture transfer (CFT) mechanism can transfer contextual in-formation from non-shadow to shadow regions at differ-ent scales. With the reconstructed feature maps, we re-move shadows at L and A/B channels separately. At Stage-II, we use an encoder-decoder to reﬁne current results and generate the ﬁnal shadow removal results. We eval-uate our proposed CANet on two benchmark datasets and some real-world shadow images with complex scenes. Ex-tensive experimental results strongly demonstrate the efﬁ-cacy of our proposed CANet and exhibit superior perfor-mance to state-of-the-arts. Our source code is available at https://github.com/Zipei-Chen/CANet. 1.

Introduction
Shadow is a natural phenomenon appearing when the light is partially or completely blocked. As a fundamen-tal challenge in the ﬁeld of computer vision, the exis-tence of shadow in images or videos inevitably degrades the accuracy and effectiveness of general application tasks such as intrinsic image decomposition [21, 10], visual recognition [25, 17, 24, 14], object detection and track-ing [28, 1, 2], trajectory prediction [27, 33], single image super-resolution [40, 39] and image captioning [6]. There-fore, shadow removal is important and necessary to im-*This work was co-supervised by Chengjiang Long and Chunxia Xiao.
†Corresponding author. prove the visual effects and avoid the performance drop on the above-mentioned computer vision tasks. However, due to the complex interactions of geometry and illumination, shadow removal remains a challenging problem.
Current shadow removal methods can be mainly divided into two categories: physical-based methods [8, 7, 12, 19, 29, 38, 43] and learning-based methods [31, 35, 15, 36, 5, 42, 44]. Compared to physical-based methods, which apply a physical model to analyze each pixel’s intensi-ties, learning-based methods analyze the image in feature maps. Recently, learning-based methods with proper model have presented potential advantages [42, 15, 30]. However, these methods mainly focus on increasing the receptive ﬁeld of the model without considering other particular context-sensitive shadow-aware components, which may easily ig-nore the contextual matching information hidden in images.
In this paper, we propose a novel two-stage context-aware network CANet for shadow removal in an end-to-end manner. As shown in Figure 1, our CANet integrates a contextual patch matching (CPM) module and a contex-tual feature transfer (CFT) mechanism at Stage-I and takes
Stage-II as a reﬁnement step for shadow removal. In partic-ular, the CPM module is designed to search for the corre-sponding potential relationships between shadow and non-shadow patches, which demonstrates the contextual map-ping between shadow and non-shadow regions. The CFT mechanism is utilized to transfer the contextual feature at different scales from non-shadow regions to shadow regions based on the output patch matching pairs from the CPM module and the extracted contextual features.
Our CPM module is designed as a dual-head structure network with the shared patch feature extractor to predict the degree of context matching between two patches from the image, as well as determine the type of the patch pair without a shadow mask. We only focus on contextual in-formation transfer from non-shadow regions to shadow re-gions. Therefore we can deﬁne three types of patch pairs, i.e., (1) both from shadow or non-shadow regions, (2) the
ﬁrst one from the shadow region and the second one from
the non-shadow region, and (3) the ﬁrst one from the non-shadow region and the second one from the shadow region.
With these prediction types, we can ﬁlter out most irrele-vant patch pairs. Unlike those traditional patch match meth-ods, our CPM is learning-based to adaptively handle com-plex scenes by data-driven and can effectively avoid match-ing errors caused by shadows the impact of shadows by averaging the lightness. What’s more, our type classiﬁca-tion head can be used to ﬁlter out mostly patch pairs from the same shadow or non-shadow regions and only focus on other pairs with high correlation scores.
We train the CPM module with sizeable self-collected training data and apply the learned CPM module to ob-tain a set of patch matching pairs. Then, inspired by the idea of information transfer [32], we introduce a contex-tual feature transfer (CFT) mechanism to transfer the con-textual feature at different scales from non-shadow patches to shadow patches, resulting in a series of feature maps without shadow information. Different from the exist-ing information transfer strategies used in shadow removal task [38, 43, 41], which search a most relevant non-shadow patch/sub-region for each shadow patch/sub-region, our
CFT mechanism performs feature transfer by applying sev-eral patch matching pairs for one shadow patch according to the similarity between two patches. With the reconstructed shadow-less feature maps, we remove shadows in the L and
A/B channels separately at Stage-I. Finally, to ensure the robustness of our results, with the recovered L and A/B channel images and the shadow image as inputs, we use an encoder-decoder to predict the ﬁnal shadow removal image at Stage-II.
In summary, our main contributions are three-fold as fol-lows:
• We propose a two-stage context-aware network CANet for shadow removal in an end-to-end manner, in which the contextual information from non-shadow regions is transferred to shadow regions at the embedded feature spaces.
• We design and train a context patch matching (CPM) module to acquire the potential contextual relation-ships between shadow and non-shadow regions in the image, which automatically distinguishes shadow patches from non-shadow patches during the matching processing.
• The proposed contextual feature transfer (CFT) mech-anism transfers the extracted contextual features from non-shadow regions to shadow regions in different scales, which remove features associated with shadows and produce superior shadow removal results.
Both quantitative and qualitative experiments demon-strate the effectiveness and efﬁciency of our proposed
CANet, as well as its superior performance in generating realistic shadow-removal images. 2.