Abstract
Though recent years have witnessed remarkable progress in single image super-resolution (SISR) tasks with the prosperous development of deep neural networks (DNNs), the deep learning methods are confronted with the computation and memory consumption issues in prac-tice, especially for resource-limited platforms such as mo-bile devices. To overcome the challenge and facilitate the real-time deployment of SISR tasks on mobile, we combine neural architecture search with pruning search and propose an automatic search framework that derives sparse super-resolution (SR) models with high image quality while sat-isfying the real-time inference requirement. To decrease the search cost, we leverage the weight sharing strat-egy by introducing a supernet and decouple the search problem into three stages, including supernet construc-tion, compiler-aware architecture and pruning search, and compiler-aware pruning ratio search. With the proposed framework, we are the ﬁrst to achieve real-time SR infer-ence (with only tens of milliseconds per frame) for imple-menting 720p resolution with competitive image quality (in terms of PSNR and SSIM) on mobile platforms (Samsung
Galaxy S20). 1.

Introduction
In recent year, people have ever-increasing demands for image processing to achieve higher resolutions, leading to the rapid development of SR. In general, the SR principle is to convert low-resolution images to high-resolution im-ages with clearer details and more information. It has been adopted in various applications such as crime scene analysis to identify unnoticeable evidence or medical image process-ing for more accurate diagnosis.
*Equal contribution.
With the fast growth of live streaming and video record-ing, video contents enjoy high popularity. However, videos often have lower resolution due to the limited communica-tion bandwidth or higher resolution of the display. Besides, live streaming usually has a real-time1 requirement that the latency of each frame should not exceed a threshold. Thus, it is desirable to achieve real-time SR for video locally.
Compared with the classic interpolation algorithms to improve image or video resolution, deep learning-based SR can deliver higher visual qualities by learning the map-pings from the low-resolution to high-resolution images from external datasets. Despite its superior visual perfor-mance, deep learning-based SR is usually more expensive with large amounts of computations and huge power con-sumption (typically hundreds of watts on powerful GPUs)
[19, 17, 53], leading to difﬁculties for the real-time imple-mentations. Moreover, in practice, as SR is often deployed on edge devices such as mobile phones for live streaming or video capturing due to the wide spread of mobile phones, the limited memory and computing resources on edge de-vices make it even harder for achieving real-time SR.
Weight pruning [60, 22, 26] is often adopted to remove the redundancy in DNNs to reduce the resource requirement and accelerate the inference. There are various pruning schemes including unstructured pruning [23, 22, 20, 44], coarse-grained structured pruning [50, 71, 70, 47, 42], and
ﬁne-grained structured pruning [45, 18, 21]. Unstructured pruning removes arbitrary weights, leading to irregular pruned weight matrices and limited hardware parallelism.
Structured pruning maintains a full matrix format of the remaining weights such that the pruned model is compat-ible with GPU acceleration for inference. Recently, ﬁne-grained structured pruning including pattern-based pruning and block-based pruning are proposed to provide a ﬁner pruning granularity for higher accuracy while exhibiting 1We believe targeting sub 100ms can be reasonably called real-time
[49] and we require the real-time implementation to be faster than 50ms.
certain regularities which can be optimized with compilers to improve hardware parallelism. To achieve inference ac-celeration of SR models, we focus on conventional struc-tured pruning and ﬁne-grained structured pruning.
Prior works usually use ﬁxed pruning scheme for the whole model. As different pruning schemes can achieve different SR and acceleration performance, a new optimiza-tion dimension is introduced to ﬁnd the most-suitable prun-ing conﬁguration for each layer instead of for the whole model. Besides, as the performance of pruning depends on the original unpruned model, it is also essential to search an unpruned starting model with high SR performance.
In this paper, to facilitate the real-time SR deployment on edge devices, we propose a framework incorporating ar-chitecture and pruning search to ﬁnd the most suitable cell-wise SR block conﬁgurations and layer-wise pruning con-ﬁgurations. Our implementation can achieve real-time SR inference with competitive SR performance on mobile de-vices. We summarize our contribution as follows.
• We propose an architecture and pruning search frame-work to automatically ﬁnd the best conﬁguration of the
SR block in each cell and pruning scheme for each layer, achieving real-time SR implementation on mo-bile devices with high image quality.
• We train a supernet to provide a well-trained unpruned model for all possible combinations of the SR block in each supernet cell before the architecture and prun-ing search. Thus there is no need to train a separate unpruned model for each combination with multiple epochs, saving tremendous training efforts.
• Different from previous works with ﬁxed pruning scheme for all layers or ﬁxed SR blocks for all cells, we automatically search the best-suited SR block for each cell and pruning scheme for each layer. To reduce the complexity, we decouple the pruning ratio search and employ Bayesian optimization (BO) to accelerate the SR block and pruning scheme search.
• With the proposed method, we are the ﬁrst to achieve real-time SR inference (with only tens of millisec-onds per frame) for implementing 720p resolution with competitive image quality (in terms of PSNR and
SSIM) on mobile platforms (Samsung Galaxy S20).
Our achievements facilitate various practical applica-tions with real-time requirements such as live stream-ing or video communication. 2.