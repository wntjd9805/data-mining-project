Abstract
Human pose forecasting is a complex structured-data sequence-modelling task, which has received increasing at-tention, also due to numerous potential applications. Re-search has mainly addressed the temporal dimension as time series and the interaction of human body joints with a kinematic tree or by a graph. This has decoupled the two aspects and leveraged progress from the relevant ﬁelds, but it has also limited the understanding of the complex struc-tural joint spatio-temporal dynamics of the human pose.
Here we propose a novel Space-Time-Separable Graph
Convolutional Network (STS-GCN) for pose forecasting.
For the ﬁrst time, STS-GCN models the human pose dynam-ics only with a graph convolutional network (GCN), includ-ing the temporal evolution and the spatial joint interaction within a single-graph framework, which allows the cross-talk of motion and spatial correlations. Concurrently, STS-GCN is the ﬁrst space-time-separable GCN: the space-time graph connectivity is factored into space and time afﬁn-ity matrices, which bottlenecks the space-time cross-talk, while enabling full joint-joint and time-time correlations.
Both afﬁnity matrices are learnt end-to-end, which results in connections substantially deviating from the standard kine-matic tree and the linear-time time series.
In experimental evaluation on three complex, recent and large-scale benchmarks, Human3.6M [24], AMASS [34] and 3DPW [48], STS-GCN outperforms the state-of-the-art, surpassing the current best technique [35] by over 32% in average at the most difﬁcult long-term predictions, while only requiring 1.7% of its parameters. We explain the re-sults qualitatively and illustrate the graph interactions by the factored joint-joint and time-time learnt graph connec-tions. Our source code is available at: https://github.com/FraLuca/STSGCN 1.

Introduction
Forecasting future human poses is the task of modelling the complex structured-sequence of joint spatio-temporal
† indicates equal contribution
STS-GCN
Layer1
Layer2 Layer3
Layer4
Input Pose History
R
E
D
O
C
N
E
Future Predicted Pose
TCN x4
R
E
D
O
C
E
D
Figure 1: Overview of the proposed pipeline. Given a se-quence of observed 3D poses, the novel STS-GCN encodes the spatio-temporal body dynamics. The encoded represen-tation serves to predict future poses by means of a Tem-poral Convolutional Network (TCN). STS-GCN allows the spatial and temporal interaction of joints, cf. green-orange linkage on the Vitruvian man and dashed blue lines connect-ing joints in time, which are both learnt. But it bottlenecks their cross-talk by a new GCN design with factored space-time adjacency matrices. (Vector image: please zoom in.) dynamics of the human body. This has received increas-ing attention due to its manifold applications to autonomous driving [38], healthcare [44], teleoperations [39] and collab-orative robots [28, 45], where e.g. anticipating the human motion avoids crashes and helps the robots plan the future.
Research has so far addressed modelling space and time in separate frameworks. Time has generally been mod-elled with convolutions in the temporal dimension [10], with recurrent neural networks (RNN [35, 36, 49, 11],
GRU [53, 1] and LSTM [52]) or with Transformer Net-works [9]. Space and the interaction of joints has instead been recently modelled by Graph Convolutional Networks (GCN) [35], mostly connecting body joints along a kine-matic tree. The separate approach has side-stepped the com-plexity of a joint model across the spatial and temporal di-mensions, which are diverse in nature, and has leveraged progress in the relevant ﬁelds. However this has also limited the understanding of the complex human body dynamics.
Here we propose to forecast human motion with a novel Space-Time-Separable Graph Convolutional Network (STS-GCN). STS-GCN encodes both the spatial joint-joint and the temporal time-time correlations with a joint spatio-temporal GCN [27]. The single-graph framework favors the cross-talk of the body joint interactions and their temporal motion patterns. Further to better performance, using the
GCN-only model results in considerably less parameters.
To the best of our knowledge, STS-GCN is the ﬁrst space-time separable GCN. We realize this by factorizing the graph adjacency matrix Ast into AsAt. Our intuition is that bottleneck’ing the cross-talk of the spatial joints and the temporal frames helps to improve the interplay of spatial joints and temporal patterns. This differs substantially from recent work [29, 5] which separate the graph interactions from the channel convolutions, being therefore depthwise separable. Still both separable designs are advantageous for the reduction of model parameters.
Fig. 1 illustrates the encoder-decoder design of our model. Following the body motion encoding by the STS-GCN, the future pose coordinates are forecast with few sim-ple convolutional layers, generally termed Temporal Convo-lutional Network (TCN) [16, 4, 33], robust and fast to train.
Note from Fig. 1 that the factored AsAt graph adjacency matrices are learnt. This results in better performance and it allows us to interpret the joint-joint and the time-time in-teractions, as we further illustrate in Fig. 3 and in Sec. 4.
In extensive experiments over the modern, challenging and large-scale datasets of Human3.6M [24], AMASS [34] and 3DPW [48], we demonstrate that STS-GCN improves over the state-of-the-art. Notably, STS-GCN outperforms the current best technique [35] by over 32% on all three datasets, in average at the most difﬁcult long-term predic-tions, while only adopting 1.7% of its parameters.
We summarize our main contributions as follows:
• We propose the ﬁrst space-time separable graph con-volutional network, which is ﬁrst to factorize the graph adjacency matrix, rather than depthwise [29, 5];
• Our space-time human body representation is the ﬁrst to exclusively use a GCN and it adopts only 1.7% pa-rameters of the current best competing technique [35];
• We improve on the state-of-the-art by over 32% on Hu-man3.6M [24], AMASS [34] and 3DPW [48], in aver-age at the most challenging long-term predictions;
• The joint-joint and time-time graph edge weights are learnt, which allows to explain their interactions. 2.