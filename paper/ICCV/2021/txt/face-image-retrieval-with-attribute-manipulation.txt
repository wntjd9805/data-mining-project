Abstract
Default result (no attribute manipulation):
Current face image retrieval solutions are limited, since they treat different facial attributes the same and cannot in-corporate user’s preference for a subset of attributes in their search criteria. This paper introduces a new face image re-trieval framework, where the input face query is augmented by both an adjustment vector that specifies the desired mod-ifications to the facial attributes, and a preference vector that assigns different levels of importance to different at-tributes. For example, a user can ask for retrieving images similar to a query image, but with a different hair color, and no preference for absence/presence of eyeglasses in the re-sults. To achieve this, we propose to disentangle the seman-tics, corresponding to various attributes, by learning a set of sparse and orthogonal basis vectors in the latent space of StyleGAN. Such basis vectors are then employed to de-compose the dissimilarity between face images in terms of dissimilarity between their attributes, assign preference to the attributes, and adjust the attributes in the query. Enforc-ing sparsity on the basis vectors helps us to disentangle the latent space and adjust each attribute independently from other attributes, while enforcing orthogonality facilitates preference assignment and the dissimilarity decomposition.
The effectiveness of our approach is illustrated by achieving state-of-the-art results for the face image retrieval task. 1.

Introduction
The problem of image retrieval has been studied in many different applications, such as product search [31, 32] and face recognition [23]. The standard problem formulation for image to image retrieval task is, given a query image, find the most similar images to the query image among all the images in the gallery. However, in many scenarios, it is necessary to improve and/or adjust the retrieval results by incorporating either the user’s feedback or by augmenting
*Work done as part of an internship at Adobe Inc.
Query
Emphasizing Eyeglasses (increased preference):
Emphasizing Eyeglasses (increased preference) and adjusting Beard (no beard):
Figure 1. Example of face image retrieval by considering both the attribute adjustment and attribute preference specified by the user. the query. This is due to the fact, in many cases, a perfect query image may not be readily available. Thus, it is desir-able to give the user more control over the results. For ex-ample, in the context of fashion products, authors in [32, 13] exploit the user’s feedback to refine the search results itera-tively. For instance, the method in [32] asks the user a series of visual multiple-choice questions to refine the search re-sults and to eliminate the semantic gap between the user and the retrieval system. Another parallel approach is to augment the query with additional information, e.g., adjust-ment text, to modify the search results [29]. This is most often done by mapping the multi-modal query onto a joint embedding space [8, 33, 29]. These approaches treat dif-ferent semantics the same and cannot prioritize a subset of attributes. Thus, the user is not able to define a customized distance metric and to assign importance to the attributes.
In this work, we introduce a new formulation for the im-age search task in the context of face image retrieval; and augment the query with both an adjustment vector and a preference vector. The adjustment vector is used to change the presence of certain attributes in the retrieved images, and the preference vector is used to assign the importance of the attribute in the results. To the best of our knowledge,
this is the first work that can simultaneously adjust the at-tributes and assign preference values to them. Employing a preference vector gives the user the ability to customize the similarity criteria. For instance, having eyeglasses might be more important to the user than having the same hair color. This criteria cannot be specified using only the ad-justment vector, which is a limitation of existing retrieval methods. On the other hand, adjustment vector enables the user to use an imperfect query image for the search and ad-just the attributes to achieve the ideal results. Furthermore, employing an adjustment vector, as opposed to an adjust-ment text, provides us with more flexibility, as many facial attributes cannot be easily described in text, for example different shades of brown hair. In the example provided in
Figure 1, the impact of assigning a larger preference value and adjusting attributes are illustrated. In the middle row, the user has emphasized the attribute Eyeglasses, by as-signing a larger preference value to it, which leads to all the top-5 retrieved images containing eyeglasses. The user can further fine-tune the results by adjusting any subset of the attributes. The bottom row shows the retrieved images after both emphasizing the attribute Eyeglasses and adjusting the attribute Beard, as a result the beard has been removed and the eyeglasses are still present.
To achieve this, we employ the recent advancements in generative adversarial networks (GANs). It is shown that different semantic attributes are fairly disentangled in the latent space of StyleGAN [12, 11], even if the generator is trained in an unsupervised manner. This has been studied and experimentally verified in [12, 25]. This property pro-vides us with an array of desirable features for face image retrieval. First, since the generator can be trained in an un-supervised manner, we do not need to have access to a lot of labeled data. A fairly small set of labelled data can be utilized to interpret the latent semantics learned by the gen-erator. Second, the latent space provided by a well-trained
StyleGAN provides us with an opportunity to both adjust the attributes and to assign preference to them. In that con-text, we propose to obtain a set of disentangled attribute vectors in the latent space of StyleGAN. To disentangle the obtained attribute vectors, we enforce both orthogonality and sparsity constraints on them. We argue that, by making the attribute vectors sparse, we can decouple the entangled attributes even further. This is due to the fact that such at-tribute vectors can manipulate their corresponding semantic by affecting only a small subset of entries of the latent vec-tor. This promotes selectivity among both the entries of the latent vector and the layers of the generator of the Style-GAN. On the other hand, by enforcing orthogonality, we can translate the dissimilarity between each image pair into dissimilarity between the attributes, assign preference to at-tributes, and define an attribute-weighted distance metric.
In short, our contributions can be summarized as follows:
• We introduce a new face image retrieval framework that can simultaneously adjust the facial attributes and assign preference to different attributes in the retrieval task, em-ploying the latent space of GANs (Section 3);
• We propose a new method to extract the directions of different attributes in the latent space, by learning all the attribute directions simultaneously and enforcing orthogo-nality and sparsity constraints (Section 3.1);
• We utilize the learned attribute directions to define a weighted distance metric, to manipulate semantic attributes of the query, and to assign preference to different attributes for retrieval (Section 3.2); and
• The proposed method for image retrieval outperforms the recent state-of-the-art methods that use compositional learning or GANs for search (Section 4). 2.