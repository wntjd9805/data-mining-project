Abstract
Arbitrary shape text detection is a challenging task due
In this to the high complexity and variety of scene texts. work, we propose a novel adaptive boundary proposal net-work for arbitrary shape text detection, which can learn to directly produce accurate boundary for arbitrary shape text without any post-processing. Our method mainly con-sists of a boundary proposal model and an innovative adap-tive boundary deformation model. The boundary proposal model constructed by multi-layer dilated convolutions is adopted to produce prior information (including classiﬁ-cation map, distance ﬁeld, and direction ﬁeld) and coarse boundary proposals. The adaptive boundary deformation model is an encoder-decoder network, in which the encoder mainly consists of a Graph Convolutional Network (GCN) and a Recurrent Neural Network (RNN). It aims to per-form boundary deformation in an iterative way for obtain-ing text instance shape guided by prior information from the boundary proposal model. In this way, our method can directly and efﬁciently generate accurate text boundaries without complex post-processing. Extensive experiments on publicly available datasets demonstrate the state-of-the-art performance of our method. Code is available at the web-site: https://github.com/GXYM/TextBPN . 1.

Introduction
Scene text detection has been widely applied in various applications, such as online education, product search, and video scene parsing. Beneﬁting from the rapid development of deep learning, text detection methods [29, 11, 42, 22] have achieved impressive performance on images in which text instances are regular shape or aspect ratio. Recently, arbitrary shape text detection has attracted ever-increasing interests for it can well adapt to real applications.
Although arbitrary shape text detection methods [2, 12,
∗Corresponding author.
Figure 1. Illustration of the boundary proposal deformation pro-cess: (a) Boundary proposal; (b) Sampling on boundaries; (c) Ex-tracting node feature matrix; (d) Learning offsets of sampling ver-texes via adaptive boundary deformation model. 41] have achieved great improvements in recent years, there are still many issues to be addressed due to the challenging characteristic of scene texts, including varied shape, texture, scale, etc. Segmentation-based methods [37, 33, 12] have sparked a new wave of arbitrary shape text detection that locate text regions by a pixel-level prediction for enhancing the robustness to shape variations. However, there are still two main problems that remain to be explored.
One problem is that segmentation-based methods tend to fail in separating adjacent text instances in image. To solve this problem, existing methods [19, 34, 30, 40] usu-ally shrink annotation boundaries as kernels (e.g., text ker-nel [34], text center region [19]) to distinguish different text instances. For rebuilding a complete text, these meth-ods usually need to merge the pixels in text regions to ker-nels by pre-deﬁned expansion rules or auxiliary information (e.g., similarity vector [34]). However, the merging process in [37, 33] are always performed by pixel-to-pixel, which is complex and inefﬁcient. The other problem is that the ﬁnal detected contours of texts in existing segmentation-based methods usually contain a lot of defects and noises. This because the performance of existing segmentation-based methods [4, 12, 33, 34] greatly relies on the accuracy of contour detection, neglecting adaptively adjusting detected contours. Different from generic object instances, text in-stances usually don’t have closed contours and often contain
a lot of background noisy pixels in coarse-grained bound-ary annotations. These will generate unpredictable results of pixels, especially those near boundaries, resulting in a lot of noises and defects in segmentation results.
To tackle the above-mentioned problems, we propose a novel adaptive boundary proposal network for arbitrary shape text detection, which can learn to directly produce accurate boundary for arbitrary shape text without any post-processing. Our adaptive boundary proposal network is mainly composed of a boundary proposal model and an adaptive boundary deformation model. The boundary pro-posal model is composed of multi-layer dilated convolu-tions, which will predict a classiﬁcation map, a distance
ﬁeld, and a direction ﬁeld based on shared convolutions.
Inspired by RPN [25], we adopt the distance ﬁeld and pixel classiﬁcation map to generate coarse boundary proposals as shown in Fig. 1 (a). These coarse boundary propos-als can roughly locate texts, and well separate adjacent texts because they are always slimmer than their bound-ary annotations in our method. To reﬁne the coarse pro-posals, we adopt an innovative adaptive boundary deforma-tion model to perform iterative boundary deformation for generating accurate text instance shape under the guidance of prior information (classiﬁcation map, distance ﬁeld and direction ﬁeld). For fully excavating and exploiting topol-ogy and sequence context in each boundary proposal, the adaptive boundary deformation model adopt an encoder-decoder structure, in which the encoder mainly consists of a GCN and a RNN (B-LSTM). Notably, the proposed method is a uniﬁed end-to-end trainable framework with it-erative optimization. Extensive experiments demonstrate that our method achieves state-of-the-art performance on several publicly available datasets.
In summary, the main contributions of this paper are three-fold:
• We propose a novel uniﬁed end-to-end trainable framework for arbitrary shape text detection, which can directly generate accurate boundaries of arbitrary shape texts without any post-processing.
• We propose an adaptive boundary deformation model which can perform iterative boundary deformation for reﬁning text boundary.
• Extensive experiments on public available datasets demonstrate the state-of-the-art performance of our method. 2.