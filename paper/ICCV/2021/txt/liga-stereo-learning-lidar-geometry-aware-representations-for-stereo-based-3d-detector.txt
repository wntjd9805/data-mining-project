Abstract
Stereo-based 3D detection aims at detecting 3D objects from stereo images, which provides a low-cost solution for 3D perception. However, its performance is still infe-rior compared with LiDAR-based detection algorithms. To detect and localize accurate 3D bounding boxes, LiDAR-based detectors encode high-level representations from Li-DAR point clouds, such as accurate object boundaries and surface normal directions. In contrast, high-level features learned by stereo-based detectors are easily affected by the erroneous depth estimation due to the limitation of stereo matching. To solve the problem, we propose LIGA-Stereo (LiDAR Geometry Aware Stereo Detector) to learn stereo-based 3D detectors under the guidance of high-level geometry-aware representations of LiDAR-based detection models. In addition, we found existing voxel-based stereo detectors failed to learn semantic features effectively from indirect 3D supervisions. We attach an auxiliary 2D de-tection head to provide direct 2D semantic supervisions.
Experiment results show that the above two strategies im-proved the geometric and semantic representation capabil-ities. Compared with the state-of-the-art stereo detector, our method has improved the 3D detection performance of cars, pedestrians, cyclists by 10.44%, 5.69%, 5.97% mAP respectively on the official KITTI benchmark. The gap between stereo-based and LiDAR-based 3D detectors is further narrowed. The code is available at https:
//xy-guo.github.io/liga/. 1.

Introduction
In recent years, LiDAR-based 3D detection [57, 28, 46, 45, 61, 60] has achieved increasing performance and sta-bility in autonomous driving and robotics. However, the high cost of LiDAR sensors has limited its applications in low-cost products. Stereo matching [3, 18, 26, 35] is the most common depth sensing technique using only cameras.
Compared with LiDAR sensors, stereo cameras are at a
Figure 1. Our method utilizes superior geometry-aware features from LiDAR-based 3D detection models to guide the training of stereo-based 3D detectors. much lower cost and higher resolutions, which makes it a suitable alternative solution for 3D perception. 3D detec-tion from stereo images aims at detecting objects using es-timated depth maps [39, 52, 64] or implicit 3D geometry representations [30, 10, 53]. However, the performance of existing stereo-based 3D detection algorithms is still infe-rior compared with LiDAR-based algorithms.
LiDAR-based detection algorithms take raw point cloud as inputs and then encode the 3D geometry information into intermediate and high-level feature representations. To de-tect and localize accurate 3D bounding boxes, the model must learn robust local features about object boundaries and surface normal directions, which are essential for pre-dicting accurate bounding box size and orientation. The features learned by LiDAR-based detectors provide robust high-level summarization of accurate 3D geometry struc-tures. In comparison, due to the limitation of stereo match-ing, the inaccurately estimated depth or implicit 3D repre-sentation have difficulties in encoding accurate 3D geome-try of objects, especially for distant ones. In addition, the target box supervisions only provide object-level supervi-sions (location, size, and orientation).
This inspires us to utilize superior LiDAR detection models to guide the training of stereo detection model via imitating the geometry-aware representations encoded by the LiDAR model. Comparing with traditional knowledge distillation [24] for recognition tasks, we did not take the fi-nal erroneous classification and regression predictions from
the LiDAR model as “soft” targets, which we found bene-fits little for training stereo detection networks. The erro-neous regression targets would constrain the upper-bound accuracy of bounding box regression.
Instead, we force our model to align intermediate features with those of Li-DAR models, which encode high-level geometry repre-sentations of the scene. The features from LiDAR mod-els could provide powerful and discriminative high-level geometry-aware features, such as surface normal directions and boundary locations. On the other hand, the LiDAR fea-tures can provide extra regularization to alleviate the over-fitting problem caused by erroneous stereo predictions.
Besides learning better geometry features, we further ex-plore how to learn better semantic features for boosting the 3D detection performance.
Instead of learning semantic features from indirect 3D supervisions, we propose to at-tach an auxiliary multi-scale 2D detection head on the 2D semantic features, which could directly guide the learning of 2D semantic features. Our baseline model, Deep Stereo
Geometry Network (DSGN) [10], failed to benefit from ex-tra semantic features effectively according to their ablation studies. We argue that the network provides erroneous se-mantic supervisions from indirect 3D supervisions because of depth estimation errors, while our proposed direct guid-ance could greatly benefit 3D detection performance from better learning of 2D semantic features. Experiment results show that the performance is further improved, especially for classes with few samples like cyclist.
The contributions can be summarized as follows. 1) We propose to utilize features from superior LiDAR-based de-tection models to guide the training of stereo-based 3D de-tection model. LiDAR features encode compact 3D geom-etry representations of the scene to guide and regularize the stereo features. 2) By attaching an auxiliary 2D de-tection head to provide direct 2D supervisions, our model significantly improves the learning efficiency for semantic features, which further improves the recall rate especially for rare categories. 4) On the official KITTI 3D detection benchmark, our proposed method surpasses state-of-the-art models by 10.44%, 5.69%, and 5.97% mAP on the car, pedestrian and cyclist classes respectively. 2.