Abstract
Deep learning algorithms mine knowledge from the training data and thus would likely inherit the dataset’s bias information. As a result, the obtained model would generalize poorly and even mislead the decision pro-cess in real-life applications. We propose to remove the bias information misused by the target task with a cross-sample adversarial debiasing (CSAD) method. CSAD explicitly extracts target and bias features disentangled from the latent representation generated by a feature ex-tractor and then learns to discover and remove the cor-relation between the target and bias features. The cor-relation measurement plays a critical role in adversar-ial debiasing and is conducted by a cross-sample neu-ral mutual information estimator. Moreover, we propose joint content and local structural representation learn-ing to boost mutual information estimation for better performance. We conduct thorough experiments on pub-licly available datasets to validate the advantages of the proposed method over state-of-the-art approaches.
Figure 1. A brief illustration of CSAD for a color-biased binary classification task. Our objective is to obtain a color-invariant digit classifier. Given the i-th training sample xi as a red “0”, most existing methods eliminate the correlation between hi and red information from the i-th sample (solid line), where hi is the extracted features. By contrast, CSAD could reduce the correlation between hi and various red colors extracted from other samples. A cross-sample mutual information estimator measures the correlation with joint content and local structural representation. 1.

Introduction
Modern machine learning is built on collected and contributed data. However, real-world data inevitably contains noise and bias and may not be well-distributed.
Such flawed datasets may make the learned model un-reliable and pose threats to the learned model’s general-ization capacity to unseen data. This problem is partic-ularly crucial for medical and healthcare-related appli-cations [10]. For example, Parkinson’s Disease (PD) is
*This work was done when Haofu Liao was at the University of
Rochester. associated with age, and the PD patients are primarily composed of older people in the related datasets [41, 8, 27]. A model learned on these datasets may predict PD by the age of patients instead of the symptoms of the dis-ease. As a result, the age bias renders the learned model hardly useful for real-life disease diagnosis and analysis.
Several methods have been proposed to learn to re-move the dataset bias [22, 1, 36, 51, 30, 5]. Among them, some methods regularize the model to not learn bias with additional regularization terms [30, 5], and others learn to eliminate the learned bias information by adversarial learning [22, 36, 51]. Our work follows the
latter and the bias elimination is often conducted by min-imizing the correlation between the extracted features and the bias label. The correlation measurement plays a critical role in adversarial debiasing and is often ful-filled by recently proposed neural mutual information estimators [17, 6, 21].
In particular, [22] proposes to adversarially discover and remove the bias information by adding a gradient reversal layer between the feature extractor and the bias branch. [36] adversarially learns to mitigate the bias by minimizing the mutual informa-tion between the latent representation and the bias la-bel. To conclude, they essentially learn to remove the bias information from the target classifier by eliminating the dependency between the target and the bias informa-tion from same training sample. And as a result, these methods are limited to model and reduce the correlation within each training sample and totally neglect the rich cross-sample information. However, we note that the cross-sample information is important and necessary to be taken into consideration for debiasing. For example, as shown in Fig. (1), given the i-th sample xi as a red
“0”, it is not enough to only eliminate the correlation between hi and the red representation extracted from xi, as the correlation between hi and the color representa-tion extracted from other red digits will be preserved, where hi is the representation of xi. That is, hi may still be highly biased and is correlated to pink, rose, ruby, etc. The neglect will pose a grave threat to the relia-bility of the learned correlation measurement and even-tually leads to sub-optimal performance for debiasing.
Moreover, although the local structural representation is proven to be helpful for correlation learning [52, 3], it is also hard to be incorporated with existing meth-ods [22, 51, 1].
To address the issues as mentioned above, we propose a cross-sample adversarial debiasing (CSAD) method as shown in Fig. 1. To make it possible to utilize the cross-sample and structural information, inspired by recent progress on domain adaptation [34, 33], CSAD first explicitly disentangles the target and the bias repre-sentation. Then, CSAD relies on a cross-sample neu-ral mutual information estimator for correlation mea-surement, which is conducted on the disentangled bias and target representation. This could also avoid poten-tial problems caused by the domain gap between the latent representation and the bias label used by other methods [22, 36]. With the cross-sample information,
CSAD could comprehensively eliminate correlation be-tween target and bias information from different sam-ples. Additionally, the explicit disentanglement makes it possible to consider the local structural representation for mutual information estimation. Specifically, we en-courage the bias and target representation to have dif-ferent topological structures captured by Random Walk with Restart [44], which could avoid the bias informa-tion of certain sample to be guessed by its neighbors.
We highlight our main contributions as follows: 1. We propose a flexible and general framework for adversarial debiasing that can explicitly disentan-gle target and bias representation. 2. Based on the proposed framework, we pro-pose cross-sample adversarial debiasing (CSAD).
CSAD eliminates the bias information by a cross-that can sample mutual jointly exert cross-sample content and structural features. information estimator 3. We conduct extensive experiments on benchmark datasets, and our method achieves substantial im-provement compared to the current state-of-the-art methods. 2.