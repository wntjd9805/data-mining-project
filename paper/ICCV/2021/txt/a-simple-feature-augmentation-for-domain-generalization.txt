Abstract
The topical domain generalization (DG) problem asks trained models to perform well on an unseen target domain with different data statistics from the source training do-mains. In computer vision, data augmentation has proven one of the most effective ways of better exploiting the source data to improve domain generalization. However, existing approaches primarily rely on image-space data augmenta-tion, which requires careful augmentation design, and pro-vides limited diversity of augmented data. We argue that feature augmentation is a more promising direction for DG.
We find that an extremely simple technique of perturbing the feature embedding with Gaussian noise during train-ing leads to a classifier with domain-generalization perfor-mance comparable to existing state of the art. To model more meaningful statistics reflective of cross-domain vari-ability, we further estimate the full class-conditional feature covariance matrix iteratively during training. Subsequent joint stochastic feature augmentation provides an effective domain randomization method, perturbing features in the directions of intra-class/cross-domain variability. We verify our proposed method on three standard domain generaliza-tion benchmarks, Digit-DG, VLCS and PACS, and show it is outperforming or comparable to the state of the art in all setups, together with experimental analysis to illustrate how our method works towards training a robust generalisable model. 1.

Introduction
Deep learning methods demonstrate exceptional perfor-mance in different fields of computer vision, such as ob-ject recognition, semantic segmentation or object detection.
∗ Equal contributions.
† Corresponding author.
Figure 1: Illustrative schematic of our stochastic feature augmentation method. The trained vanilla model has lim-ited robustness as simple perturbed feature instances, as might be encountered experiencing domain-shift, could in-duce the classifier to make a mistake. During the training, we persistently perturb the feature embedding, which leads to classification mistakes. In order to discriminate these er-roneous perturbed instances, the feature spare must adapt to separate the classes with a more robust decision boundary.
This new boundary is in turn more robust to domain-shift.
However, these machine learning systems’ performance drops dramatically when encountering test data, which is statistically different from the training data [5]. This issue is known as the domain shift problem, which domain gener-alization (DG) research aims to address. Models with good
DG properties are crucial in practical applications since the distribution of testing data in deployment is inevitably dif-ferent from training data collected for model fitting [17], whether due to either the expense or simple impossibility of collecting representative training data.
DG research traces back to a decade ago [3]. Since then a variety of methods were proposed to push the DG bound-ary, including learning domain-invariant features [28, 14], extracting the underlying domain knowledge [15, 20], and
meta-learning inspired methods [21, 2, 6, 22]. Among exist-ing DG strategies, data augmentation based approaches [33, 38, 44] have become popular. Data augmentation is already widely used to reduce overfitting in conventional supervised learning [18], by inserting predefined class-preserving op-erations, such as transformation, cropping, rotation, flip-ping. Intuitively, augmenting the source domain data with diverse samples better representing the breadth of plausible domains also leads to improved generalization to novel do-mains, especially when there are only a few known source domains to start with. However, existing augmentation-based approaches primarily rely on image-space augmen-tations, which are non-trivial to design due to the diffi-culty of specifying- or learning how to synthesize images in new domains. Existing approaches include perturbing in-puts by gradient-descent on the signal from a domain clas-sifier [33], generating adversarial samples [38] and using an image synthesis network to generate novel images that fool a domain classifier [44]. These approaches are all compu-tationally expensive and complex. In contrast, feature-level data augmentation have also proven effective recently in a supervised learning context [37]. We are inspired by these ideas to explore feature-level augmentation solutions to DG, as shown in Fig. 1.
In this paper, we first show that an extremely simple fea-ture augmentation of perturbing latent features using white
Gaussian noise already leads to comparable performance to recent state-of-the-art. This strategy outperforms the above mentioned highly engineered approaches that rely on train-ing image-to-image generation networks, or gradient-based adversarial sample generation; while being extremely sim-ple to implement and much faster to run. Nevertheless, while feature augmentation helps to enhance the breadth of seen domains for training, a limitation is that one can not add too much noise without risking inducing a non-class-preserving augmentation, which then has the counter-productive effect of introducing label-noise. To enable more meaningful and class-preserving augmentations, we aim to estimate the natural directions of correlation that already ex-ist in a given source dataset. Specifically, we estimate the feature covariance online during training using moving av-erage and then use it to simulate a joint (multivariate Nor-mal) noise distribution across the features. Estimating class-conditional covariance further ensures that the learned noise follows the class-preserving but inter-domain directions.
The proposed method potentially applies to any base DG method. We show that it improves the vanilla method to achieving the state of the art performance on three bench-marks, Digit-DG, VLCS and PACS. Furthermore, we show the feature evolution from pretrained Vanilla to our SFA trained features to understand how the proposed method es-sentially improves model generalization. 2.