Abstract
Existing single image high dynamic range (HDR) recon-struction methods attempt to expand the range of illumi-nance. They are not effective in generating plausible tex-tures and colors in the reconstructed results, especially for high-density pixels in ultra-high-deﬁnition (UHD) images.
To address these problems, we propose a new HDR re-construction network for UHD images by collaboratively learning color and texture details. First, we propose a dual-path network to extract the content and chromatic fea-tures at a reduced resolution of the low dynamic range (LDR) input. These two types of features are used to ﬁt bilateral-space afﬁne models for real-time HDR reconstruc-tion. To extract the main data structure of the LDR input, we propose to use 3D Tucker decomposition and reconstruc-tion to prevent pseudo edges and noise ampliﬁcation in the learned bilateral grid. As a result, the high-quality con-tent and chromatic features can be reconstructed capital-ized on guided bilateral upsampling. Finally, we fuse these two full-resolution feature maps into the HDR reconstructed results. Our proposed method can achieve real-time pro-cessing for UHD images (about 160 fps). Experimental results demonstrate that the proposed algorithm performs favorably against the state-of-the-art HDR reconstruction approaches on public benchmarks and real-world UHD im-ages. 1.

Introduction
High dynamic images can display rich appearances, such as brightness, contrast, and texture details. However, most mobile devices can only capture images within a limited dy-namic range due to the physical limitations of the hardware device. Existing methods fuse LDR images of different ex-posures into a single HDR image [9, 14]. However, this technique only works well on static scenes, while ghosting
*Corresponding authors.
Figure 1. Trade-off of speed and accuracy between our proposed enhancement method and state-of-the-art methods on the FiveK dataset [8]. The red line indicates the real-time method for UHD image reconstruction. The right yellow region represents the methods that cannot handle UHD images directly and need to use the downsampling-enhancement-upsampling (DEU) strategy.
For example, the maximum resolution can be handled by Ex-pandNet [26], HDRCNN [15], FMFPL [29] and JSI-GAN [21] is around 2K, while LRCP [25] and UnModNet [42] can only run on images around 512 × 512 resolution. The proposed algorithm generates enhanced images efﬁciently and accurately at UHD res-olution (4K or more). artifacts often occur in dynamic scenes or hand-held cam-eras. Furthermore, it is difﬁcult to get multiple LDR images with different exposure levels in the same scene.
Recently, several methods [10, 16, 21, 25, 29, 36, 39, 42] have been developed to reconstruct an HDR image from an
LDR input using translational invariance models (CNNs).
However, these methods have the following natural limi-tations [41]. First, since the parameters of existing deep models are ﬁxed, these networks need to enhance saturation issues and texture loss with the same weights. Second, ex-isting models usually enhance an LDR image with the help of a learnable model, which inevitably consumes a large
number of computational resources. For example, the re-cent single image HDR reconstruction methods of UnMod-Net [42] and LRCP [25] cannot directly enhance ultra high resolution images (4K) on a GPU with 24G RAM. Although the early light-weight deep models HDRCNN [15] and Ex-pandNet [26] can run on 2K images, the performances of the evaluation metrics are below FMFPL [29] and ours as shown in Figure 1. Therefore, recovering lost edges and colors from LDR images is still a tricky problem.
In summary, designing a deep network with both high accuracy and high efﬁciency for reconstructing the edges and colors of UHD images is still a challenge. To achieve this, we propose a collaborative learning framework to fuse various information with an efﬁcient and interpretable ﬁlter-ing module in bilateral space [11]. We design a dual-path network with edge-aware afﬁne modules for collaborative learning color and texture details. Specially, our algorithm extracts low-resolution content and chromatic features for bilateral grids learning and restores two high-quality fea-ture maps (one is mainly focused on edge and texture, the other is for color). However, we note that the learned bi-lateral grid by the dual-path network tends to result in new edges, a halos, or noises in the restored image. Therefore, we present a 3D Tucker reconstruction scheme to prevent pseudo edges and noises ampliﬁcation based on the low-rank characteristic. Finally, we fuse the two high-resolution features to yield the reconstructed UHD HDR image.
Since the change of the bilateral grid occurs according to the content and color of the local area, our proposed algo-rithm enables the recovery of spatial changes. The proposed dual-path network can also help reﬁne color and texture de-tails in the learned bilateral afﬁne model. In addition, our method processes UHD images in less than 6 ms on a single
Titan RTX GPU.
The contributions of this paper are as summarized as:
• We propose a new dual-path network by collabora-tively learning textural and chromatic features in the bilateral space, which enables the proposed network to process a UHD HDR image in real-time.
• We enforce a smoothness term in the bilateral grid learning process by a 3D Tucker reconstruction block, which prevents pseudo edges and noises ampliﬁcation in the reconstructed results.
• We propose a LeakAdaIN and a self-evolving loss function for training acceleration and visual percep-tion enhancement. Experimental results on synthetic and real-world images demonstrate the proposed al-gorithm performs favorably against the state-of-the-art
HDR reconstruction methods on arbitrary spatial sizes. 2.