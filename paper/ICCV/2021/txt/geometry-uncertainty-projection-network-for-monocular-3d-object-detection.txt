Abstract
Geometry Projection is a powerful depth estimation method in monocular 3D object detection.
It estimates depth dependent on heights, which introduces mathemati-cal priors into the deep model. But projection process also introduces the error amplification problem, in which the er-ror of the estimated height will be amplified and reflected greatly at the output depth. This property leads to uncon-trollable depth inferences and also damages the training ef-ficiency. In this paper, we propose a Geometry Uncertainty
Projection Network (GUP Net) to tackle the error amplifica-tion problem at both inference and training stages. Specif-ically, a GUP module is proposed to obtains the geometry-guided uncertainty of the inferred depth, which not only provides high reliable confidence for each depth but also benefits depth learning. Furthermore, at the training stage, we propose a Hierarchical Task Learning strategy to reduce the instability caused by error amplification. This learning algorithm monitors the learning situation of each task by a proposed indicator and adaptively assigns the proper loss weights for different tasks according to their pre-tasks sit-uation. Based on that, each task starts learning only when its pre-tasks are learned well, which can significantly im-prove the stability and efficiency of the training process.
Extensive experiments demonstrate the effectiveness of the proposed method. The overall model can infer more reli-able object depth than existing methods and outperforms the state-of-the-art image-based monocular 3D detectors by 3.74% and 4.7% AP40 of the car and pedestrian categories on the KITTI benchmark. The code and model will be re-leased at https://github.com/SuperMHP/GUPNet.
†This work was done when Yan Lu was an intern at SenseTime.
*Equal contribution. (cid:0)Corresponding authors.
Figure 1. The main pipeline of our Geometry Uncertainty Projec-tion module. The projection process is modeled in the probability framework. The inference depths can be represented as a distribu-tion so that can provide both accurate values and scores. 1.

Introduction 3D object detection is an important component in au-tonomous driving and has received increasing attention in recent years. Compared with the LiDAR/stereo-based methods [32, 35, 37, 40, 41, 49, 57], monocular 3D object detection is still a challenging task due to the lack of depth cues, which makes monocular object-level depth estimation naturally ill-posed. Therefore, the monocular 3D detector cannot achieve satisfactory performance even some com-plex network structures [39] are applied. Recently, to alle-viate this problem, some works [36, 47] attempt to introduce geometry priors to help depth inference, of which a widely used prior is the perspective projection model.
Existing methods with the projection model usually es-timate the height of 2D and 3D bounding box first and then infer the depth via the projection formula depth = h3d ·f /h2d (f is the camera focal length). Depth inferred by this formula is highly related to the estimated 2D/3D heights so the error of the height estimation will also be reflected at the estimated depth. However, the error of height esti-mation is inevitable especially for the ill-posed 3D height estimation (2D height estimation is relatively more accu-rate because of the well-developed 2d detection), so we are more concerned about the depth inference error caused by the 3D height estimation error. To show the influence of this property, we visualize the depth shifts caused by a fixed 3D height error in Figure 2. We can find that a slight bias (0.1m) of 3D heights could cause a significant shift (even 4m) in the projected depth. This error amplification effect makes out-puts of the projection-based methods hardly controllable, significantly affecting both inference reliability and train-ing efficiency. In this paper, we propose a Geometry Un-certainty Projection Network that includes a Geometry Un-certainty Projection (GUP) module and a Hierarchical Task
Learning (HTL) strategy to treat these problems.
The first problem is inference reliability. A small qual-ity change in the 3D height estimation would cause a large change in the depth estimation quality. This makes the model cannot predict reliable uncertainty or confidence eas-ily, leading to uncontrollable outputs. To tackle this prob-lem, the GUP module is proposed to infer the depth based on the distribution form rather than a discrete value (see Fig-ure 1). The depth distribution is inferred by the estimated 3D height distribution. So, the statistical characteristics of the estimated 3D height estimation would be reflected in the output depth distribution, which leads to more accurate
Uncertainty. At the inference, this well-learned uncertainty would be mapped to a confidence value to indicate the depth inference quality, which makes the total projection process more reliable.
Another problem is the instability of model training. In particular, at the beginning of the training phase, the estima-tion of 2D/3D height tends to be noisy, and the errors will be amplified and cause outrageous depth estimation. Conse-quently, the training process of the network will be misled, which will lead to the degradation of the final performance.
To solve the instability of the training, we propose the Hi-erarchical Task Learning (HTL) strategy, aiming to ensure that each task is trained only when all pre-tasks (e.g. 3D height estimation is one of the pre-tasks of depth estimation) are trained well. To achieve that, the HTL first measures the learning situation of each task by a well-designed learning situation indicator. Then it adjusts weights for each loss term automatically by the learning situation of their pre-tasks, which can significantly improve the training stability, thereby boosting the final performance.
In summary, the key contributions are as follows:
Figure 2. Visualized examples of the depth shift caused by ±0.1m 3D height jitter. We draw some bird’s view examples to show the error amplification effect. In this figure, the unit of the hori-zontal axis and the vertical axis are both meters, and the vertical axis corresponds to the depth direction. The green boxes mean the original projection outputs. The blue and red boxes are shifted boxes caused by +0.1m and -0.1m 3D height bias respectively (best viewed in color).
• We propose a Geometry Uncertainty Projection (GUP) module combining both mathematical priors and un-certainty modeling, which significantly reduces the un-controllable effect caused by the error amplification at the inference.
• For the training instability caused by task dependency in geometry-based methods, we propose a Hierarchical
Task Learning (HTL) strategy, which can significantly improve the training efficiency.
• Evaluation on the challenging KITTI dataset shows the overall proposed GUP Net achieves state-of-the-art performance around 20.11% and 14.72% on the car and the pedestrian 3D detection respectively on the
KITTI testing set. 2.