Abstract
We present an image segmentation algorithm that is de-veloped in an unsupervised deep learning framework. The delineation of object boundaries often fails due to the nui-sance factors such as illumination changes and occlusions.
Thus, we initially propose an unsupervised image decompo-sition algorithm to obtain an intrinsic representation that is robust with respect to undesirable bias ﬁelds based on a multiplicative image model. The obtained intrinsic image is subsequently provided to an unsupervised segmentation pro-cedure that is developed based on a piecewise smooth model.
The segmentation model is further designed to incorporate a geometric constraint imposed in the generative adversarial network framework where the discrepancy between the distri-bution of partitioning functions and the distribution of prior shapes is minimized. We demonstrate the effectiveness and robustness of the proposed algorithm in particular with bias
ﬁelds and occlusions using simple yet illustrative synthetic examples and a benchmark dataset for image segmentation. 1.

Introduction
The image segmentation problem plays a signiﬁcant role in providing both the appearance (such as texture or bright-ness) and geometry of objects by partitioning the domain of image into mutually disjoint regions. It is often consid-ered as a basis for a higher level of visual understanding of image contents. Various classical image segmentation algorithms have been developed based on the variational framework [10, 42, 11, 55, 13, 9, 45, 46] where an objec-tive functional that deﬁnes a discrepancy between model and observation is optimized in a solution space of partition-ing function. The variation of observation from the deﬁned model is typically computed based on a single measure-ment leading to an unsupervised algorithm. Albeit a num-ber of successful unsupervised variational algorithms have been developed using normalized cuts in graph representa-tions [24, 52], markov random ﬁeld models [44, 60], density estimations in a feature space [22, 23], level set embedding functions [43, 13] and hierarchical methods in multi-scale representations [24, 2], their associated limitations that stem from the complexity of statistical properties in character-izing regions of interest naturally lead to the development of supervised algorithms using a large number of training images. The development of supervised image segmenta-tion algorithms based on the resurgent neural networks in particular with locally characteristic convolutional kernels has been making a signiﬁcant improvement over the clas-sical unsupervised approaches [16, 49, 37, 41, 61, 4, 19] where convolutional neural networks predict the probability of indication for region of interest. However, the supervised algorithms generally require extensive manual annotations that are rarely available and often result in coarse-grained. It is also often insufﬁcient to generalize an effective segmen-tation model with respect to both appearance and geometry albeit data-driven supervision due to the inherited complex-ity from the variations in lighting conditions and physical properties of objects. The difﬁculties in coping with high dimensional distributions with huge variations lead to the development of segmentation algorithms by unsupervised learning schemes using abundant training examples with partial or crude labels [33, 26, 6, 20, 7, 1, 58]. In particular, the successful application of generative adversarial networks (GAN) [27, 47, 50, 3] has been extended to an image segmen-tation problem [20, 7, 6] where the distribution of composite images formed by the foreground of the object of interest and its realistic background is desired to be learned. How-ever, the distribution for both appearance and geometry of object turns out difﬁcult to be learned due to its enormous dimensionality and variations despite a relatively large num-ber of coarse-grained labels. Thus, it is desired to improve the learnability [8] of a characteristic distribution for seg-mentation in a generative learning scheme, which motivates to simplify a generative model to learn. In this work, we present an unsupervised segmentation algorithm that learns an embedding function for a bipartitioning model based on the statistical homogeneity of appearance and incorporates
a shape prior that is imposed on the segmentation model in a GAN framework. Our proposed algorithm considers a generative learning model only for the geometric property excluding the appearance (intensity) property of an object so that such simpler distribution is easier to learn and turns to be more effective. It is often feasible to create a three dimensional model for the shape of object and generate a large collection of projected images from arbitrary viewing directions. Thus, we propose to learn an unsupervised seg-mentation model based on the intensity of an object and impose its geometrical constraint using its shape images of the same category in the GAN framework. We also propose to learn an intrinsic image representation that is robust with respect to undesirable bias ﬁelds in an unsupervised way, so that the proposed unsupervised segmentation model can be less sensitive to the inhomogeneity of object appearance.
Our uniﬁed framework combines the intrinsic image repre-sentation model and the segmentation model incorporating a shape constraint that is learned by the GAN algorithm. 2.