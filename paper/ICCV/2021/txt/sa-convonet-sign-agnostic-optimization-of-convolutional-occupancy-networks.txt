Abstract
Surface reconstruction from point clouds is a fundamen-tal problem in the computer vision and graphics commu-nity. Recent state-of-the-arts solve this problem by indi-vidually optimizing each local implicit ﬁeld during infer-ence. Without considering the geometric relationships be-tween local ﬁelds, they typically require accurate normals to avoid the sign conﬂict problem in overlapped regions of local ﬁelds, which severely limits their applicability to raw scans where surface normals could be unavailable. Al-though SAL breaks this limitation via sign-agnostic learn-ing, further works still need to explore how to extend this technique for local shape modeling. To this end, we propose to learn implicit surface reconstruction by sign-agnostic op-timization of convolutional occupancy networks, to simulta-neously achieve advanced scalability to large-scale scenes, generality to novel shapes, and applicability to raw scans in
Correspondence to Dan Xu and Kui Jia. a uniﬁed framework. Concretely, we achieve this goal by a simple yet effective design, which further optimizes the pre-trained occupancy prediction networks with an unsigned cross-entropy loss during inference. The learning of occu-pancy ﬁelds is conditioned on convolutional features from an hourglass network architecture. Extensive experimental comparisons with previous state-of-the-arts on both object-level and scene-level datasets demonstrate the superior ac-curacy of our approach for surface reconstruction from un-orientated point clouds. The code is available at https:
//github.com/tangjiapeng/SA-ConvONet. 1.

Introduction
Surface reconstruction from point clouds is of signiﬁ-cance to perceive and understand surrounding 3D worlds for intelligent systems, which plays a fundamental role in nu-merous practical applications, such as computer-aided de-sign, 3D printing, and robotics grasping. Recently, this
problem has attracted wide attention as inexpensive and portable commodity scanners such as the Microsoft Kinect make it much easier to acquire 3D point clouds. Classical methods [1, 5, 26, 24, 25] tackle this problem by mathemat-ical optimization according to pre-deﬁned geometric priors, while learning-based methods [17, 11, 28, 31] choose to learn geometric priors from large-scale 3D datasets in a data-driven manner. Recently, representing 3D surface as an implicit ﬁeld has gained large popularity [10, 28, 30, 34, 46, 11, 22, 6, 14, 41, 31, 37]. Compared to other shape rep-resentations such as voxel [12, 44], octree [32, 39, 43, 20], point cloud [15] and mesh [17, 42, 23, 36, 29, 37], contin-uous implicit ﬁelds can enable surface reconstruction with inﬁnite resolution and arbitrary topology.
A lot of methods have been proposed to advance the de-velopment of implicit surface reconstruction from various respects in terms of improving scalability, generality, and applicability. However, there is still not an approach in the literature to simultaneously achieve all these objectives with satisfactory performance. Targeting better scalability to large-scale scenes, several approaches [22, 6, 41, 31, 14] learn local implicit ﬁelds and model a global shape as a composition of local surface geometries, rather than con-ducting global shape reasoning from a latent code. Towards better generality to novel shapes, some works [30, 16, 22, 6, 41, 47] attempt to optimize the pre-trained priors at test time to obtain a better solution for each given input, instead of strictly respecting the learned priors. Existing state-of-the-art methods [22, 6, 41] improve both scalability and gener-ality via individual optimization of each local implicit ﬁeld during inference. However, without explicitly considering geometric relationships between local ﬁelds, they heavily rely on accurate normals to avoid the sign conﬂict prob-lems in the overlapped regions of local ﬁelds. Although
SAL [2] breaks this limitation via sign-agnostic learning that improves the applicability to real-world scans where surface normals are unavailable, it can only perform global shape modeling. Further works still need to explore how to extend this technique for local shape modeling.
To this end, we propose to learn implicit surface re-constructions by sign-agnostic optimization of convolu-tional occupancy networks [31], to simultaneously achieve the three important reconstruction objectives, i.e. advanced generality, specialty, and applicability in a uniﬁed frame-work. We achieve this goal by a simple yet effective so-lution that further optimizes the pre-trained occupancy pre-diction networks via sign-agnostic learning. The learning of occupancy ﬁelds is conditioned on convolutional features from an hourglass network (e.g. U-Net [33]). Our solution is motivated by two key characteristics. The ﬁrst character-istic is that, after being pre-trained on the accessible datasets with ground-truth signed ﬁelds, the occupancy decoder can provide a signed ﬁeld as initialization for the test-time opti-mization. Thus we can further apply unsigned objectives to optimize occupancy prediction networks, maximizing the consistency between the desired iso-surface with the ob-served un-oriented point cloud. The second characteristic is that, the U-Net [33] aggregates both local and global in-formation in an hourglass convolutional manner. The use of local shape features not only preserves the ﬁne-grained geometries, but also enables the surface recovery of large-scale indoor scenes. The integrated global shape features can enforce geometric consistency between learned local geometries and guarantee the assembly of local ﬁelds as a globally consistent one, although we do not utilize guid-ance from additional normal information. As shown in Fig-ure 1, we can reconstruct surfaces with ﬁne details directly from un-oriented point clouds without the use of normals, for both complicated objects to large-scale scenes.
Extensive experimental comparisons with state-of-the-arts on both object-level and scene-level datasets, including
ShapeNet [8], synthetic indoor scene dataset [31], and real-world scene datasets (ScanNet [13] and Matterport3D [7]) demonstrate the superior performance of our approach for surface reconstruction from un-oriented point clouds. 2.