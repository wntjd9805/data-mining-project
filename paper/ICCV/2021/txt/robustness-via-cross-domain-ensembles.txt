Abstract
We present a method for making neural network predic-tions robust to shifts from the training data distribution. The proposed method is based on making predictions via a di-verse set of cues (called ‘middle domains’) and ensembling them into one strong prediction. The premise of the idea is that predictions made via different cues respond differ-ently to a distribution shift, hence one should be able to merge them into one robust ﬁnal prediction. We perform the merging in a straightforward but principled manner based on the uncertainty associated with each prediction.
The evaluations are performed using multiple tasks and datasets (Taskonomy, Replica, ImageNet, CIFAR) under a wide range of adversarial and non-adversarial distribution shifts which demonstrate the proposed method is consid-erably more robust than its standard learning counterpart, conventional deep ensembles, and several other baselines. 1.

Introduction
Neural networks deployed in the real world will en-counter data with naturally occurring distortions, e.g. mo-tion blur, or adversarial ones. Such changes make up shifts from the training data distribution. While neural networks are able to learn complex functions in-distribution, their predictions are profoundly unreliable under such shifts [9, 20, 50, 25]. This presents a core challenge that needs to be solved for these models to be useful in the real world.
Suppose we want to learn a mapping from an input do-main, e.g. RGB images, to a target domain, e.g. surface normals (see Fig. 1). A common approach is to learn this mapping with a direct path, i.e. RGB → surface normals.
Since this path directly operates on the input domain, it is prone to being affected by any slight alterations in the
RGB image, e.g. brightness changes. An alternative can be to go through a middle domain1 that is invariant to that 1or equivalently “middle task”, as most vision tasks can be viewed as mapping an input onto some other domain.
* Equal contribution.
Figure 1: An overview of the proposed method for creating a robust and diverse ensemble of predictions. A set of K networks predict a target domain (here surface normals) given an input image that has undergone an unknown distribution shift (here JPEG compression degradation), via
K middle domains (e.g. 2D texture edges, low-pass ﬁltering, greyscale image, emboss ﬁltering, etc). The predictions from the K paths are then merged into one ﬁnal strong prediction using weights that are based on the uncertainty associated with each prediction. This method is shown to be signiﬁcantly robust against adversarial and non-adversarial distribution shifts for several tasks. In the ﬁgure above, solid ( ) and dashed (
) arrows represent learned and analytical functions, respectively. change. For example, the surface normals predicted via the
RGB → 2D edges → surface normals path will be resilient to brightness distortions in the input as the 2D edges domain abstracts that away. However, one does not know which middle-domain to use ahead of time as the distortions that a model may encounter are broad and apriori unknown, and some middle domains can be too lossy for certain down-stream predictions. These issues can be mitigated by em-ploying an ensembling approach where predictions made via a diverse set of middle domains are merged into one strong prediction on-the-ﬂy.
This paper presents a general approach for the aforemen-tioned process. We ﬁrst use a set of K middle domains from which we learn to predict the ﬁnal domain (Fig. 1). Each of the K paths reacts differently to a particular distribution shift due to its inherent biases, so its prediction may or may not degrade severely. Thus, we further estimate the uncer-tainty of each path’s prediction which allows us to employ a principled way of combining these predictions into the one
ﬁnal prediction.
Prior knowledge of the relationship between middle do-mains is not needed as their contribution to the ﬁnal pre-diction is guided by their predicted uncertainties in a fully computational manner independent of the deﬁnition of the middle domain. In other words, no manual modiﬁcation or re-design is needed upon a change in these domains. More-over, the middle domains we adopt can all be programmat-ically extracted. Thus, this framework does not require any additional supervision/labeling than what a dataset already comes with. The proposed method would be equally ap-plicable if the middle domains were also obtained using a learning based approach, e.g. predicting surface normals from the output of another network such as a depth esti-mator. We show in Sec. 4 that the method performs well insensitive to the choice of middle domains and it gener-alizes to completely novel non-adversarial and adversarial corruptions. 2.