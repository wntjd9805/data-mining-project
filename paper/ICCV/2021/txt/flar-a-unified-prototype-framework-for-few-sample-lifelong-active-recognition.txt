Abstract
Intelligent agents with visual sensors are allowed to ac-tively explore their observations for better recognition per-formance. This task is referred to as Active Recognition (AR). Currently, most methods toward AR are implemented under a fixed-category setting, which constrains their ap-plicability in realistic scenarios that need to incrementally learn new classes without retraining from scratch. Further, collecting massive data for novel categories is expensive.
To address this demand, in this paper, we propose a unified framework towards Few-sample Lifelong Active Recogni-tion (FLAR), which aims at performing active recognition on progressively arising novel categories that only have few training samples. Three difficulties emerge with FLAR: the lifelong recognition policy learning, the knowledge preser-vation of old categories, and the lack of training samples.
To this end, our approach integrates prototypes, a robust representation for limited training samples, into a reinforce-ment learning solution, which motivates the agent to move towards views resulting in more discriminative features.
Catastrophic forgetting during lifelong learning is then al-leviated with knowledge distillation. Extensive experiments across two datasets, respectively for object and scene recog-nition, demonstrate that even without large training sam-ples, the proposed approach could learn to actively recog-nize novel categories in a class-incremental behavior. 1.

Introduction
Visual recognition has been widely studied and achieved remarkable success in recent decades. In contrast to pas-sive recognition from a still image, in robot learning sce-narios, an intelligent agent is allowed to explore different viewpoints and is equipped with the capability to make de-cisions about what to observe. This problem is referred to as
Active Recognition (AR), with two specific tasks illustrated in Figure 1(a).
A number of AR methods [4, 18, 12, 6, 23, 13, 7] have been proposed over the years with learning-based models. (a) The schematic illustrations of two AR tasks: active 3D object recogni-tion and panoramic scene recognition. The system could intelligently select actions to acquire better views. (b) A demonstration of lifelong learning during robot exploration. The sys-tem needs to expand its knowledge to novel categories that are discovered continuously. (c) A diagram depicting the relation with other tasks. The terms LAR and
FLAR are abbreviations for Lifelong Active Recognition and Few-sample
Lifelong Active Recognition.
Figure 1. FLAR is one challenging task that requires expanding dy-namically to novel classes with few training samples. Meanwhile, the task setting fits the practical needs of robotic applications that need exploring previously unseen environments.
Despite achieving promising results, these methods are con-fined to a classical learning setting, i.e., the recognition de-cision can only be made for the samples from the trained categories, and massive training data are usually required to facilitate the learning process. When it comes to more practical settings where novel categories are continuously emerging, and more notoriously, only a few samples are available for the emerging category, it is not clear whether these models still remain effectual.
This problem is surprisingly under-explored in the litera-ture but is imperative in realistic autonomous agent applica-tions. In many scenarios, the agent trained in the backend to actively recognize fixed categories will be required to incre-mentally expand its AR ability for novel classes on the fly.
We call this problem Lifelong Active Recognition (LAR), il-lustrated in Figure 1(b). Further, it is often costly to collect many training samples for novel categories, let alone the possibility that the samples of the novel category are scarce per se. This motivates us to study a new problem, Few-shot
Lifelong Active Recognition (FLAR), that is both necessary and challenging. In Figure 1(c), the relationship of FLAR with closed problems is depicted.
Formally, FLAR raises three requirements to the agent. (1) The agent should be capable of making decisions to ex-plore the most informative viewpoints based on the current stage so as to direct senses for a better understanding of sur-roundings. This fits into the realm of AR [32, 6, 4, 20, 41]. (2) The agent should adapt the power of exploration and recognition learned from old classes to new concepts while
It is related to incremen-avoiding training from scratch. tal learning [31, 30, 36]. (3) The agent should learn new concepts from limited training samples.
It is connected with few-shot learning [37, 33, 15]. These requirements compose our FLAR problem, which delivers an intelligent agent that could incrementally learn to explore and recog-nize novel categories with only a few training samples.
Corresponding to these demands, three major challenges are posed by FLAR. (1) The previous AR methods typi-cally learn a recognition policy from categories with mas-sive training data. The constraint of few training samples for incremental categories will certainly impede the suc-cess of the policy training. (2) In the incremental learn-ing setting, the agent is evaluated by the recognition per-formance of not only the categories on the fly but also old categories. Thus the catastrophic forgetting issue [30] needs to be tackled when new categories continuously emerge. (3)
The risk of overfitting always exists for few-sample learn-ing. Generalization from few samples needs to be fulfilled in our setting. In summary, FLAR is highly unconstrained with complex viewing conditions, growing recognition cat-egories, and limited training samples. task that
In this paper, we propose a novel approach towards
FLAR, a challenging but practical is under-explored. Although the challenges of FLAR scatter into dif-ferent research fields, we address them in a unified frame-work. The main idea is that we hypothesize there exists a prototype in the embedding space to represent each cat-egory by averaging the aggregations of the budgeted ex-ploratory observations for each sample. This facilitates flexible policy learning while simplifies knowledge preser-vation during class-incremental learning. Then for novel the agent is only required to take emerging categories, movements for the purpose of distinguishing the newly ob-tained features with prototypes of the trained categories.
Note that the exemplars that best estimate prototypes are delicately selected and stored in the agent memory, which would be instilled during novel category learning.
Specifically, the insights of the proposed method aim-ing at the challenges of FLAR are three-fold: (1) The agent learns the active recognition policy based on a newly de-signed reward that favors a closer distance between aggre-gated features and the correct class prototype in the embed-ding space. (2) To handle the forgetting issue, only limited exemplars are stored in the agent memory in prioritized or-der. By reproducing consistent outputs for the exemplars utilizing the knowledge distillation mechanism, we incorpo-rate the distribution of the old classes during learning novel concepts. (3) The prototype of each category, which serves as robust representations, potentially makes our approach adaptive to the few-training-sample challenge. 2.