Abstract 1.

Introduction
Recent studies show that convolutional neural networks (CNNs) are vulnerable under various settings, including ad-versarial attacks, common corruptions, and backdoor at-tacks. Motivated by the findings that human visual sys-tem pays more attention to global structure (e.g., shapes) for recognition while CNNs are biased towards local tex-ture features in images, in this work we aim to analyze whether “edge features” could improve the recognition ro-bustness in these scenarios, and if so, to what extent? To an-swer these questions and systematically evaluate the global structure features, we focus on shape features and pro-pose two edge-enabled pipelines EdgeNetRob and Edge-GANRob, forcing the CNNs to rely more on edge features.
Specifically, EdgeNetRob and EdgeGANRob first explicitly extract shape structure features from a given image via an edge detection algorithm. Then EdgeNetRob trains down-stream learning tasks directly on the extracted edge fea-tures, while EdgeGANRob reconstructs a new image by re-filling the texture information with a trained generative ad-versarial network (GANs). To reduce the sensitivity of edge detection algorithms to perturbations, we additionally pro-pose a robust edge detection approach Robust Canny based on vanilla Canny. Based on our evaluation, we find that
EdgeNetRob can help boost model robustness under differ-ent attack scenarios at the cost of the clean model accu-racy. EdgeGANRob, on the other hand, is able to improve the clean model accuracy compared to EdgeNetRob while preserving the robustness. This shows that given such edge features, how to leverage them matters for robustness, and it also depends on data properties. Our systematic studies on edge structure features under different settings will shed light on future robust feature exploration and optimization.
∗indicates equal contributions. Our code is available at https:// github.com/Eric-mingjie/Shape-Robustness
Convolutional neural networks (CNNs) have been stud-ied extensively [17], and have achieved state-of-the-art per-formance in many learning tasks [7, 11, 14, 21, 31, 38, 44, 48, 49, 52, 66, 67, 69]. However, different from the hu-man cognition system, recent works have shown that CNNs are vulnerable to adversarial attacks [4, 5, 19, 40, 40– 42, 51, 58–62], where imperceptible perturbation can be added to the test data to tamper the predictions. Different from adversarial examples where test data is manipulated, data poisoning or backdoor attacks, where training data is manipulated to reduce model’s generalization ability, have also been proposed [9, 33]. In addition, recent studies show that CNNs tend to learn spurious statistical features instead of high level abstraction, making it fail to generalize under common corruptions (e.g. fog and snow) [22]. For each of these settings, different robust algorithms have been pro-posed to solve them independently. For instance, adver-sarial training based methods [19, 39, 47] are proposed to improve the robustness against adversarial attacks but are inefficient to backdoor attacks; spectral signature [54] is designed for defending against backdoor attacks while re-mains vulnerable to adversarial attacks and common cor-ruptions. Given existing studies on human visual systems, in this paper we aim to ask: Is it possible to learn seman-tically meaningful structure features to simultaneously im-prove the robustness of DNNs under different settings in-cluding adversarial attacks, backdoors, and common cor-ruptions?
To improve the general robustness of CNNs under dif-ferent attacks, recent studies explore the underlying cause of their vulnerability. Ilyas et al. [25] attributes the exis-tence of adversarial examples to the non-robust but highly-predictive features. They suggest to train a classifier only on
“robust features” which contain the necessary information for recognition and are insensitive to small perturbations.
In addition, Baker et al. [2] and Geirhos et al. [16] have 1
shown that human recognition relies mainly on global ob-ject shapes rather than local patterns (e.g. textures), while
CNNs are more biased towards the latter. Geirhos et al. [16] creates a texture-shape cue conflict, such as a cat shape with elephant texture, and feeds it to a CNN model trained with
IamgeNet and human respectively. While human can still recognize it as a cat, CNN incorrectly predicts it as an ele-phant. Landau et al. [32] have also shown that the shape of objects is the most important cue for human object recogni-tion.
Given the above observation, natural questions emerge:
Can we improve the robustness of CNNs under different at-tacks by making it rely more on global shape structure?
What are the conditions that affect such robustness improve-ment? In this paper, we aim to answer the above questions by quantitatively evaluating whether the shape structure fea-tures could improve model robustness under different at-tacks settings, and how to leverage such features. In par-ticular, we focus on a specific type of shape representation: edges (image points that have sharp changes in brightness).
Edge features come with two benefits: 1) it is an effective way for modelling shape; 2) edges are easy to be captured in images, with many algorithms [3, 36, 65] available.
To evaluate different ways of leveraging such shape fea-tures, in this paper we explore two edge feature enabled pipelines EdgeNetRob and EdgeGANRob. The framework is shown in Figure 1. As illustrated, the pipeline of EdgeN-etRob (grey lines) is a simple yet efficient approach which extracts the structural (edge) information via an edge de-tection algorithm and then trains the classifier on the ex-tracted edge features. As a result, EdgeNetRob forces the
CNNs to make predictions solely based on shape informa-tion rather than texture/color, thus eliminating the texture bias [16]. Comparing with the adversarial training based methods, EdgeNetRob is more general and efficient since it does not need to generate adversarial examples during train-ing. However, one potential problem for EdgeNetRob is that the algorithm may decrease the clean accuracy of CNNs due to the missing texture/color information. Could we refill the texture/color information based on the extracted edge features to improve the robustness? To answer this question, we explore the pipeline EdgeGANRob (blue lines in Fig-ure 1), which embeds a generator to refill the texture/colors based on extracted edge information.
To extract the edge information, we first leverage two standard edge detection algorithms: Canny [3] and a network-based detection algorithm, RCF [36]. However, our results show that by simply applying these edge detec-tion algorithms to EdgeNetRob, the models are still vulner-able to sophisticated adaptive attacks. Thus, we propose a robust edge detection algorithm, s Robust Canny. We show
Robust Canny is able to significantly improve the robustness of EdgeNetRob and EdgeGANRob.
We evaluate EdgeNetRob and EdgeGANRob on four datasets with clear edge information (Fashion MNIST,
CelebA), and unclear or complicated edge information (CIFAR-10, Tiny-ImageNet) among different attack set-tings (e.g., adversarial attacks, common corruptions, and backdoor attacks). Our results show that edge features are able to improve the model robustness under these set-tings. The clean accuracy could be improved by refilling the texture information on the extracted edges via GANs on datasets with clear edge information. However, for datasets with complicated or less clear edge information, the clean accuracy can barely be improved by only refill-ing the texture information and further studies are required.
We believe this work will open new directions for under-standing shape features and designing more robust struc-tural features to improve the model robustness against dif-ferent attacks. Please find more visualization results on the anonymous website: https://sites.google.com/ view/edge-robustness.
The main contributions of this paper are as follows: (i)
We propose two shape feature enable pipelines EdgeN-etRob and EdgeGANRob to evaluate whether the shape-based feature could improve the model robustness under including adversarial at-different adversarial scenarios, tacks, common corruption, and backdoor attacks. (ii) We propose a robust edge detection algorithm Robust Canny to improve the robustness of edge detection against sophis-(iii) We conduct comprehensive ticated adaptive attacks. experiments under various settings with different datasets.
We show that such shape structure features can indeed im-prove model robustness under different adversarial scenar-ios, while sometimes at the cost of sacrificing certain clean accuracy depending on data properties. 2.