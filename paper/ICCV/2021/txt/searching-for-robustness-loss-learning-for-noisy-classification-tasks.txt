Abstract
Meta-Test
Noisy Fashion Data
We present a “learning to learn” approach for discover-ing white-box classiﬁcation loss functions that are robust to label noise in the training data. We parameterise a ﬂexible family of loss functions using Taylor polynomials, and apply evolutionary strategies to search for noise-robust losses in this space. To learn re-usable loss functions that can apply to new tasks, our ﬁtness function scores their performance in aggregate across a range of training datasets and archi-tectures. The resulting white-box loss provides a simple and fast “plug-and-play” module that enables effective label-noise-robust learning in diverse downstream tasks, without requiring a special training procedure or network architec-ture. The efﬁcacy of our loss is demonstrated on a variety of datasets with both synthetic and real label noise, where we compare favourably to prior work. 1.

Introduction
The success of modern deep learning is predicated on large amounts of accurately labelled training data. However, training with large quantities of gold-standard labelled data is often not achievable. This is because professional anno-tation is often too costly to achieve at scale and so machine learning practitioners resort to less reliable crowd-sourcing, web-crawled incidental annotations [6], or imperfect ma-chine annotation [27]; while in other situations the data is hard to classify reliably even by human experts, and thus label-noise is inevitable. These considerations have led to a large body of work focusing on developing noise-robust learning approaches [38, 13]. Diverse solutions have been studied including those that modify the training algorithm through teacher-student [23, 13] learning, or identify and down-weight noisy instances [38]. Much simpler, and there-fore more widely applicable, are attempts to deﬁne noise-robust loss functions that provide drop-in replacements for standard losses such as cross-entropy [45, 54, 10]. These studies hand engineer robust losses, motivated by different considerations including risk minimisation [10] and informa-Meta-Train
Noisy MNIST
+
+
Robust loss "!∗
Deploy
Loss "!
Hoodie
!!∗
Training
CMA-ES Loss
Optimization
Architecture/
Dataset
Randomization
Training
Clean MNIST
Accuracy
!#"
∗
Clean MNIST
Figure 1. Schematic of our robust loss search framework. (1) We train a robust loss function so as to optimise validation performance of a CNN trained with synthetic label noise using this loss. (2)
Thanks to dataset and architecture randomisation, our AutoRobust-Loss (ARL) is reusable and can be deployed to new tasks, including those without clean validation set to drive robust learning. tion theory [51]. In this paper we explore an alternative data-driven AutoML [21] approach to loss design, and search for a simple white-box function that provides a general-purpose noise-robust drop-in loss. While AutoML approaches have been widely [36, 9] and successfully [43] applied to general purpose neural architecture search (NAS), their application to discovery of reusable losses is much less widely studied.
We perform evolutionary search on a space of loss func-tions parameterised as Taylor polynomials. Every function in this space is smooth and differentiable, and thus provides a valid loss that can be easily plugged into existing deep learn-ing frameworks. Meanwhile, this search space provides a good trade-off between the ﬂexibility to represent non-trivial losses, and a low-dimensional white-box parameterisation that is efﬁcient to search and reusable across tasks without overﬁtting. To score a given loss during our search, we use it to train neural networks on noisy data, and then evaluate the 1
Figure 2. Existing hand-designed robust losses and our meta-learned robust loss. Top left: Conventional Cross-Entropy (CE); Top middle:
Generalised Cross Entropy (GCE) [54]; Top right: Mean Absolute Error (MAE) [10]; Bottom left: label-smoothing [34]. Bottom middle:
Symmetric Cross Entropy (SCE) [45]. Bottom right: Our learned ARL. clean validation performance of the trained model. To learn a general purpose loss, rather than one that is speciﬁc to a given architecture or dataset, we explore domain randomisa-tion [44] in the space of architectures and datasets. Scoring losses according to their validation performance in diverse conditions leads to reusable functions that can be applied to new datasets and architectures, as illustrated in Figure 1.
We apply our learned ARL to train various MLP and
CNN architectures on several benchmarks including MNIST,
FashionMNIST, USPS, CIFAR-10, and CIFAR-100 with different types of simulated label noise. We also test our loss on a large real-world noisy label dataset, Clothing1M. The results verify the re-usability of ARL and its efﬁcacy com-pared to state-of-the-art in a variety of settings. This means that, analogously to CNNs discovered by NAS [36, 43], read-ers are free to use our loss on new noisy problems with no further complicated or expensive AutoML required. This is an important distinction and major advantage of our ap-proach compared to previous work that uses AutoML or meta-learning techniques to perform noise-robust learning
[38, 39]. These methods often require (i) expensive meta-learning on a per-problem basis, and (ii) a clean (i.e., noise-less) validation dataset to use as a meta-supervision signal, which may not be available in real applications. In contrast, our ultimate contribution is a general-purpose loss (Figure 2, bottom right) that provides a simple and fast drop-in re-placement for conventional losses (such as cross-entropy) in a standard learning pipeline; and furthermore no clean validation set is required to use it. 2.