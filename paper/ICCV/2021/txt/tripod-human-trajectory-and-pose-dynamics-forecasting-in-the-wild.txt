Abstract
Joint forecasting of human trajectory and pose dynam-ics is a fundamental building block of various applications ranging from robotics and autonomous driving to surveil-lance systems. Predicting body dynamics requires captur-ing subtle information embedded in the humans’ interac-tions with each other and with the objects present in the scene. In this paper, we propose a novel TRajectory and
POse Dynamics (nicknamed TRiPOD) method based on graph attentional networks to model the human-human and human-object interactions both in the input space and the output space (decoded future output). The model is sup-plemented by a message passing interface over the graphs to fuse these different levels of interactions efﬁciently. Fur-thermore, to incorporate a real-world challenge, we pro-pound to learn an indicator representing whether an es-timated body joint is visible/invisible at each frame, e.g. due to occlusion or being outside the sensor ﬁeld of view.
Finally, we introduce a new benchmark for this joint task based on two challenging datasets (PoseTrack and 3DPW) and propose evaluation metrics to measure the effectiveness of predictions in the global space, even when there are invis-ible cases of joints. Our evaluation shows that TRiPOD out-performs all prior work and state-of-the-art speciﬁcally de-signed for each of the trajectory and pose forecasting tasks. 1.

Introduction
The ability to forecast human movements (pose dynam-ics and trajectory) in time is an essential component for many real-world applications, including robotics [38, 48], healthcare [32], detection of perilous behavioral patterns in surveillance systems [37, 53].
While this problem sounds interesting, it is extremely challenging in real-world scenes due to the different factors involved. Humans are intuitively social agents, able to ef-fortlessly conceive a detailed level of semantics from the
Figure 1. An example of a real-world scene containing different levels of interactions (human to human and human to objects). The top-left graph shows the weighted interaction graphs between humans (blue edges) and between humans and objects in the scene (green edges). The top-right graph illustrates the evolved social interactions over time in the future. The red arrows indicate an example of a relation being intensiﬁed over time. scene, which contributes to making swift decisions for their next movements. To accurately forecast their trajectory and pose dynamics, one primary factor is the interactions be-tween people in the scene and the inﬂuences their joints have on each other. For example, consider a tennis-playing scene, when the opponent starts serving and hits a stroke, the other person is probable to take a ready position in the near future (e.g. see the purple agent in Fig. 1). Besides, the objects involved in the scene can provide informative clues for future prediction. For instance, when the person observes the ball in the tennis example, he/she would take a striking pose to return it. However, the movements of all the persons in the scene are not always highly correlated with each other nor the humans to objects. For instance, in Fig. 1, the pose and motion of tennis players will be
barely affected by the skateboarder or his skateboard. This deﬁnes different levels of interactions that need to be dis-covered by the forecasting model. In addition, these differ-ent levels of interactions can change over time, i.e. getting strengthen or weaken. In Fig. 1, lines thickened in future human-human graph (indicated by red arrows), show that the skateboarder’s movements increasingly correlate with the parent and the kid (passengers), while some others lose correlations over time. Finally, a person might move out-side the sensor ﬁeld-of-view or be a partially/fully occluded by an object. In these cases, it is important to have an in-dication of visibility/invisibility for each prediction, which can be interpreted as its reliability score, conducive for the applications such as navigation safety and a collision risk assessment for an autonomous robot/vehicle.
Existing solutions often neglect some of these challeng-ing factors and hence fall short when applied to real-world in-the-wild scenarios. Pose dynamics forecasting methods
[14, 40, 41, 58] mostly forecast the changes in joints with respect to a center position, ignoring the global position changes. They often do not effectively model all the in-formative environmental and social interactions in the scene either. Similarly, the inﬂuence of individual joints is usually overlooked in trajectory forecasting [22, 27]. Moreover, ex-isting frameworks often assume that all tracks and/or body joints are always observable in the past and future, which is an impractical assumption in many real-world scenarios.
To address these challenges, we push the current state of existing solutions for human pose dynamics and trajectory forecasting one step forward toward more practical scenar-ios in-the-wild by considering all these factors together. To this end, similar to other works that use attentional graphs for various purposes [27, 33], we model the input skeleton body joints, the social human-human and human-object in-teractions with different attention graphs. Since, these two types of information are different by nature, we give an ef-fective solution to fuse them and as well make them insensi-tive to their choice of order by applying an iterative message passing. Furthermore, on account of the fact that humans may retain their inﬂuences on each other consistently in fu-ture, we do not content with only representing the history of interactions, but also we preserve their spatio-temporal at-tentional relationships by modeling them also in future pre-diction phase. To overcome the problem of accumulative error in sequential models for long-term sequences and to speed up the convergence, we take a curriculum learning ap-proach to train our model. Finally, since there is no proper benchmark dataset for such real-world problem, we intro-duce a new benchmark by repurposing existing datasets and introducing relevant evaluation metrics.
In summary, the main contributions of our paper are to 1) propose a model that considers all the mentioned chal-lenges together by (i) modeling the human skeleton, so-cial and human-objects interactions through different dense and sparse graph incorporating attention, (ii) introducing a message passing approach to efﬁciently fuse different level of interactions, (iii) dynamically modelling the spatio-temporal attentional human interactions during decoding phase, (iv) addressing the concept of joint invisibility or body disappearance in trajectory and pose dynamics fore-casting problem, (v) suggesting a curriculum learning strat-egy to compensate accumulating error in recurrent models, 2) introduce proper evaluation metrics and a new bench-mark for this real-world problem. 2.