Abstract 1.

Introduction
Fully immersive experiences in AR/VR depend on re-constructing the full body pose of the user without re-stricting their motion.
In this paper we study the use of body-worn electromagnetic (EM) field-based sensing for the task of 3D human pose reconstruction. To this end, we present a method to estimate SMPL parameters from 6-12 EM sensors. We leverage a customized wearable system consisting of wireless EM sensors measuring time-synchronized 6D poses at 120 Hz. To provide accurate poses even with little user instrumentation, we adopt a re-cently proposed hybrid framework, learned gradient de-scent (LGD), to iteratively estimate SMPL pose and shape from our input measurements. This allows us to harness powerful pose priors to cope with the idiosyncrasies of the input data and achieve accurate pose estimates. The pro-posed method uses AMASS to synthesize virtual EM-sensor data and we show that it generalizes well to a newly cap-tured real dataset consisting of a total of 36 minutes of motion from 5 subjects. We achieve reconstruction errors as low as 31.8 mm and 13.3 degrees, outperforming both pure learning- and pure optimization-based methods. Code and data is available under https://ait.ethz.ch/ projects/2021/em-pose.
AR and VR (collectively called XR) is a promising new computing platform for entertainment, communication, medicine, remote presence and more. An important com-ponent of an immersive XR system is a method to accu-rately reconstruct the full body pose of the user. While external camera-based pose estimation has progressed at a rapid pace (e.g., [14, 19, 21, 59]) such approaches inher-ently limit the mobility of the user due to the requirement for external cameras. Body-worn tracking using inertial-measurement units (IMUs) [17, 33, 45, 49, 64, 65] or cam-eras [48, 51, 57, 69] allow for free movement, but suffer from lack of accurate positional measurements in the case of
IMUs, and heavy occlusions for camera-based systems, re-sulting in incorrect pose estimates that may drift over time.
In this paper we propose a new approach to body-worn pose estimation that is based on electromagnetic-field (EM) sensing which can replace or complement vision or IMU-based counterparts. In our method an EM field is emitted from a source that is worn on the body and a small number of sensors measure their position and orientation relative to the emitted magnetic field (c.f . Fig. 1). In our implemen-tation, we leverage a fully wireless magnetic tracking sys-tem consisting of up to 12 sensors. These sensors are small (roughly half the size of a credit card), low-powered, and
have been customized to enable accurate tracking of fast, dynamic motions at update rates up to 120 Hz. Compared to optical tracking, our sensors are typically within 1 cm positional and 2-3 degrees angular error.
However, reconstructing the full articulated pose from these measurements with high accuracy remains difficult du to several challenges. First, for a convenient system, only a small number of body-worn sensors should be used, making the pose estimation problem underconstrained. We show good accuracy with as little as 6 sensors. Second, the accuracy of the position and orientation measurements depend on the distance of the sensor to the source. So, un-der dynamic human motion, the sensor accuracy varies as a function of pose. Third, the skin-to-sensor offsets must be determined. These offsets can vary due to possible slipping of the sensor against the skin. Hence, the resulting method should be robust to changes in these offsets.
Embracing these challenges, we propose a new EM-based pose estimation method that leverages the recently proposed learned gradient descent (LGD) [53] framework to iteratively fit a parametric body model, here SMPL [30], to the EM measurements, where the parameter update rule is predicted by a neural network. The method is based on the key insights that the sensor measurements are perturbed by dynamically varying sources of noise: EM-interference, pose dependent effects, and offsets to the underlying joints.
The parametric body model in combination with a learned parameter update rule allows us to integrate strong priors into the pose estimation pipeline. Furthermore, with LGD the parameter updates stay on the manifold of valid poses thus allowing for larger step sizes leading to fast conver-gence in few steps. SMPL enables us to synthesize virtual positions and orientations on the skin, which we leverage to train LGD on AMASS [32] by simulating many pairs of virtual EM sensors and SMPL references. To close the gap between synthetic and real data, we extract estimates of subject-specific skin-to-sensor offsets from a designated calibration sequence. These offsets are used during train-ing to adjust and augment the synthetic data. Our evalua-tions show that the proposed method generalizes well to a newly recorded dataset without requiring fine-tuning, even for subjects whose offsets were not seen during training.
To foster future research into this direction, we release a new dataset containing pairs of magnetic measurements and SMPL poses. We obtained SMPL reference poses via multi-view tracking from outside-in RGB-D data together with manual annotations. The dataset consists of 45 se-quences of a total length of 36.8 minutes and was recorded with 3 female and 2 male participants. In our evaluations we achieve average reconstruction errors of 31.8 mm and 13.3 ◦ with 12 sensors and 35.4 mm and 14.9 ◦ with 6 sensors. In comparative experiments we show that this outperforms the state-of-the-art in optimization-based approaches to regis-ter SMPL to motion-capture markers [32], a specialized op-timization method for EM data and a hard learning-based baseline, inspired by IMU-based prior work [17].
We see our system as complementary to pure vision-based methods. Because it is light-weight, low-powered, wireless, and accurate, it potentially enables the collection of in-the-wild datasets - currently the biggest challenge for
RGB-based methods because of a lack of data. It can also be used to collect reference poses when image data is affected by occlusions or motion blur, e.g. in egocentric views.
In summary, in this paper we contribute i) a method to estimate SMPL pose and shape parameters from as little as 6 EM sensors leveraging a customized wearable EM sens-ing based system ii) a general framework to estimate SMPL parameters from few on-skin measurements which is agnos-tic to the underlying sensing technology, and iii) a dataset consisting of EM sensor data and SMPL pose pairs. Code and data are available under https://ait.ethz.ch/ projects/2021/em-pose. 2.