Abstract
We tackle the task of diverse 3D human motion predic-tion, that is, forecasting multiple plausible future 3D poses given a sequence of observed 3D poses.
In this context, a popular approach consists of using a Conditional Varia-tional Autoencoder (CVAE). However, existing approaches that do so either fail to capture the diversity in human mo-tion, or generate diverse but semantically implausible con-tinuations of the observed motion.
In this paper, we ad-dress both of these problems by developing a new varia-tional framework that accounts for both diversity and con-text of the generated future motion. To this end, and in con-trast to existing approaches, we condition the sampling of the latent variable that acts as source of diversity on the rep-resentation of the past observation, thus encouraging it to carry relevant information. Our experiments demonstrate that our approach yields motions not only of higher quality while retaining diversity, but also that preserve the contex-tual information contained in the observed motion. 1.

Introduction
Human motion prediction is the task of forecasting plau-sible 3D human motion continuation(s) given a sequence of past 3D human poses. To address this problem, prior work mostly relies on recurrent encoder-decoder architec-tures, where the encoder processes the observed motion, and the decoder generates a single future trajectory given the encoded representation of the past [5, 10, 16, 22, 23, 24, 28, 21]. While this approach yields valid future motion, it tends to ignore the fact that human motion is stochastic in nature; given one single observation, multiple diverse con-tinuations of the motion are likely and plausible. The lack of stochasticity of these encoder-decoder methods ensues from the fact that both the network operations and the se-quences in the training dataset are deterministic1. In this
*Work done while at the Australian National University. 1For complicated tasks such as motion prediction, the training data is typically insufficiently sampled, in that, for any given condition, the dataset contains only a single sample, in effect making the data appear determinis-tic. For instance, in motion prediction, we never observed twice the same
Figure 1. Evaluating the quality, diversity, and context of stochas-tic motion prediction models. We show each model as a circle in a Context vs. Quality plot, further indicating Diversity with the radius of the marker. These three metrics are defined in Section 5.
Our LCP-VAE approach (in black) yields diverse predictions of higher-quality than those of other methods, while better preserv-ing the context of the observations. paper, we introduce an approach to modeling this stochas-ticity by learning multiple modes of human motion. We focus on generating both diverse and contextually and se-mantically plausible motion predictions. By contextually plausible, we mean motions that are natural continuations of an observed sequence of 3D poses, preserving and contin-uing the context depicted by the observation. For instance, when the observed poses depict a person walking, we ex-pect the network to predominantly predict future motions corresponding to different walking modes. This is crucial in certain scenarios, such as pedestrian intention forecasting in autonomous driving, user interaction in AR/VR applica-tions, and automatic animation generation, in which context is as important as diversity.
Recent attempts to account for motion stochasticity mostly rely on combining a random vector with an encoding of the observed pose sequence [4, 5, 7, 16, 19, 28, 29, 31].
In particular, the state-of-the-art approaches to diverse hu-man motion prediction [4, 29, 31] use conditional varia-tional autoencoders (CVAEs). Here, we argue that stan-dard CVAEs are ill-suited to generate motions that are di-past motion with two different future ones.
verse and contextually plausible for the following reasons:
First, standard CVAEs struggle at capturing diversity when the conditioning signal is highly informative.
In the par-ticular case of human motion prediction, the observed 3D motion (i.e., the condition) contains sufficient signal for an expressive motion decoder to generate a natural continua-tion given only this condition [4, 29]. A typical condition-ing scheme, such as concatenating a random latent vector to the condition, then allows the model to learn to ignore the latent variable and only focus on the condition to minimize the reconstruction loss. Second, while ignoring the latent variable can be prevented by replacing the traditional deter-ministic conditioning scheme with a stochastic one [4], cap-turing context in the diverse predictions with CVAEs is im-peded by their use of a general prior on the latent variable.
Since this prior is independent of the conditioning signal, during inference, nothing encourages the latent variable to be drawn from a region of the latent space corresponding to the observed motion. In other words, the latent variable is sampled independently of the condition and thus may not carry contextual information about the observed motion.
In this paper, we address these weaknesses by explicitly conditioning the sampling of the latent variable on the past observation, thus encouraging the latent variable to encode relevant information. We will show that this further allows us to depart from the traditional deterministic conditioning scheme, and thus facilitate generating both diverse and con-textually plausible motions. As demonstrated in Fig. 1, our experiments show that our approach not only yields much higher quality of diverse motions compared to the state-of-the-art stochastic motion prediction methods, but also bet-ter preserves the contextual and semantic information of the condition, such as the type of action performed by the per-son, without explicitly exploiting this information. 2.