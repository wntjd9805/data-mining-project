Abstract
Feature pyramids have been proven powerful in image understanding tasks that require multi-scale features.
State-of-the-art methods for multi-scale feature learning focus on performing feature interactions across space and scales using neural networks with a ﬁxed topology. In this paper, we propose graph feature pyramid networks that are capable of adapting their topological structures to varying intrinsic image structures, and supporting simultaneous feature interactions across all scales. We ﬁrst deﬁne an image speciﬁc superpixel hierarchy for each input image to represent its intrinsic image structures. The graph feature pyramid network inherits its structure from this superpixel hierarchy. Contextual and hierarchical layers are designed to achieve feature interactions within the same scale and across different scales. To make these layers more powerful, we introduce two types of local channel attention for graph neural networks by generalizing global channel attention for convolutional neural networks. The proposed graph feature pyramid network can enhance the multiscale features from a convolutional feature pyramid network.
We evaluate our graph feature pyramid network in the object detection task by integrating it into the Faster R-CNN algorithm. The modiﬁed algorithm outperforms not on-ly previous state-of-the-art feature pyramid based methods with a clear margin but also other popular detection meth-ods on both MS-COCO 2017 validation and test datasets. 1.

Introduction
Deep convolutional neural networks exploit local con-nectivity and weights sharing, and have led to a series of
† This work is done when Gangming Zhao is a visiting student at
Fudan University. *Corresponding authors: wfge@fudan.edu.cn and y-izhouy@acm.org breakthroughs in computer vision tasks, including image recognition [23, 46, 12, 47], object detection [9, 41, 33, 39, 5, 30, 45], and semantic segmentation [32, 54, 28, 17, 52, 48]. Since objects in an image may have varying scales, it is much desired to obtain multiscale feature maps that have fused high-level and low-level features with sufﬁcien-t spatial resolution at every distinct scale. This motivated feature pyramid networks (FPN [29]) and its improved ver-sions, such as path aggregation network (PANet [32]) and feature pyramid transformer (FPT [52]), and other mtehod-s [21, 18, 8, 50, 11].
Every image has multiscale intrinsic structures, includ-ing the grouping of pixels into object parts, the further grouping of parts into objects as well as the spatial layout of objects in the image space. Such multiscale intrinsic struc-tures are different from image to image, and can provide important clues for image understanding and object recog-nition. But FPN and its related methods always use a ﬁxed multiscale network topology (i.e. 2D grids of neurons) in-dependent of the intrinsic image structures. Such a ﬁxed network topology may not be optimal for multiscale feature learning. According to psychological evidence [13], human parse visual scenes into part-whole hierarchies, and mod-el part-whole relationships in different images dynamically.
Motivated by this, researchers have developed a series of
”capsule” models [43, 15, 22], that describe the occurrence of a particular type in a particular region of an image. Hi-erarchical segmentation can recursively group superpixels according to their locations and similarities to generate a superpixel hierarchy [38, 34]. Such a part-whole hierarchy can assist object detection and semantic segmentation by bridging the semantic gap between pixels and objects [34] .
It is known that multiscale features in a feature pyramid can be enhanced through cross-scale interactions [29, 32, 25, 52] in addition to interactions within the same scale.
Another limitation of existing methods related to feature pyramid networks is that only features from adjacent scales interact directly while features from non-adjacent scales in-teract indirectly through other intermediate scales. This is partly because it is most convenient to match the resolu-tions of two adjacent scales, and partly because it is most convenient for existing interaction mechanisms to handle t-wo scales at a time. Interactions between adjacent scales usually follow a top-down or bottom-up sequential order.
In the existing schemes, the highest-level features at the top of the pyramid need to propagate through multiple inter-mediate scales and interact with the features at these scales before reaching the features at the bottom of the pyramid.
During such propagation and interaction, essential feature information may be lost or weakened.
In this paper, we propose graph feature pyramid net-works to overcome the aforementioned limitations because graph networks are capable of adapting their topologi-cal structures to varying intrinsic structures of input im-ages, and they also support simultaneous feature interac-tions across all scales. We ﬁrst deﬁne a superpixel hierarchy for an input image. This superpixel hierarchy has a number of levels, each of which consists of a set of nonoverlapping superpixels deﬁning a segmentation of the input image. The segmentations at all levels of the hierarchy are extracted from the same hierarchical segmentation of the input im-age. Thus the superpixels at two adjacent levels of the hi-erarchy are closely related. Every superpixel on the coars-er level is a union of superpixels on the ﬁner level. Such one-to-many correspondences between superpixels on two levels deﬁne the aforementioned part-whole relationships, which can also be called ancestor-descendant relationships.
The hierarchical segmentation and the superpixel hierarchy derived from it reveal intrinsic image structures. Although superpixels oversegment an image, pixels in the same su-perpixel typically belong to the same semantic object/part, and do not straddle the boundaries of semantic objects/parts.
Thus, superpixls have more homogeneous pixels than cells from a uniform image partition, and more effectively pre-vent feature mixing between background clutters and fore-ground objects.
To effectively exploit intrinsic image structures, the ac-tual structure of our graph feature pyramid network is de-termined on the ﬂy by the above superpixel hierarchy of the
In fact, the graph feature pyramid network input image. inherits its structure from the superpixel hierarchy by map-ping superpixels to graph nodes. Graph edges are set up be-tween neighboring superpixels in the same level as well as corresponding superpixels in ancestor-descendant relation-ships. Correspondences are also set up between the levels in our graph feature pyramid network and a subset of layers in the feature extraction backbone. Initial features at all graph nodes are ﬁrst mapped from the features at their correspond-ing positions in the backbone.Contextual and hierarchical graph neural network layers are designed to promote fea-ture interactions within the same scale and across different scales, respectively. Hierarchical layers make correspond-ing features from all different scales interact directly. Final features at all levels of the graph feature pyramid are fused with the features in a conventional feature pyramid network to produce enhanced multi-scale features.
Our contributions in this paper are summarized below.
• We propose a novel graph feature pyramid network to exploit intrinsic image structures and support simultane-ous feature interactions across all scales. This graph feature pyramid network inherits its structure from a superpixel hi-erarchy of the input image. Contextual and hierarchical lay-ers are designed to promote feature interactions within the same scale and across different scales, respectively.
• We further introduce two types of local channel atten-tion mechanisms for graph neural networks by generalizing existing global channel attention mechanisms for convolu-tional neural networks.
• Extensive experiments on MS-COCO 2017 validation and test datasets [31] demonstrate that our graph feature pyramid network can help achieve clearly better perfor-mance than existing state-of-the-art object detection meth-ods no matter they are feature pyramid based or not. The reported ablation studies further verify the effectiveness of the proposed network components. 2.