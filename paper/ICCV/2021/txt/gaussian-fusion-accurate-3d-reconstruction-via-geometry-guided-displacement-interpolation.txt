Abstract
Reconstructing delicate geometric details with consumer
RGB-D sensors is challenging due to sensor depth and poses uncertainties. To tackle this problem, we propose a unique geometry-guided fusion framework: 1) First, we characterize fusion correspondences with the geodesic curves derived from the mass transport problem, also known as the Monge-Kantorovich problem. Compared with the depth map back-projection methods, the geodesic curves reveal the geometric structures of the local surface. 2) Mov-ing the points along the geodesic curves is the core of our fusion approach, guided by local geometric properties, i.e.,
Gaussian curvature and mean curvature. Compared with the state-of-the-art methods, our novel geometry-guided displacement interpolation fully utilizes the meaningful ge-ometric features of the local surface. It makes the recon-struction accuracy and completeness improved. Finally, a significant number of experimental results on real ob-ject data verify the superior performance of the proposed method. Our technique achieves the most delicate geomet-ric details on thin objects for which the original depth map back-projection fusion scheme suffers from severe artifacts (See Fig.1). 1.

Introduction
With the increasing availability of active optical tech-niques, RGB-D sensors have become more practical and af-fordable. For instance, time of flight (ToF) based RGB-D sensors have been extensively integrated into smartphones and tablets. They are popular due to their high frame rate and excellent portability. Many seminal works leverage these features to reconstruct the indoor scenes in real-time
[26, 15, 17, 35, 42]. However, the resolution and accuracy of depth maps are usually limited by cost and size. The pose estimation heavily relies on visual odometry, constrained by matching accuracy. In all, it is difficult to reconstruct the delicate geometric details through consumer RGB-D sen-Figure 1. The state-of-the-art depth map back-projection fusion methods vs. our geometry-guided displacement interpolation ap-proach on real object data (Ragnaros, see Tab.2 for reconstruction details). Our approach achieves the most delicate geometric de-tails. sors.
The fusion strategy directly decides reconstruction re-sults. Moreover, most state-of-the-art methods employ a depth map back-projection fusion strategy, which differs by data representation. There are two popular represen-tations to reconstruct one 3D model from observed RGB-D data [45]. One is to gather the spatial coordinates in a 3D voxel grid. e.g., InfiniTAM [17], Kinect Fusion[26], and [27] average the truncated signed distance function (TSDF) [5] value if the projection on the depth map is verified. An alternative one to voxel-based representation is surfel/point-based model [30, 19, 42, 31]. Keller et al.
[19, 42, 31] perform a weighted average between measure-ments and their back-projections to eliminate the poses and the measurements uncertainties. However, the depth map back-projection strategy only considers single-surfel/point information and ignores the meaningful geometric struc-ture. Thus, it usually suffers from severe artifacts on recon-structing delicate geometric details. So that, we conclude
three basic obversions: 1) the projective correspondences are typically inaccurate due to sensor depth and poses un-certainties; 2) those uncertainties are difficult to filter out by averaging; 3) point to pixel projection and depth map back-projection fusion can not fully utilize the meaningful geometric structure of the local surface.
In this paper, we propose a unique fusion framework called Gaussian Fusion. In contrast to existing depth map back-projection approaches, the proposed method is based on geometry-guided displacement interpolation. To over-come the shortcomings of depth map back-projection tech-niques, we make the following assumptions: 1) a suffi-ciently small local surface follows Gaussian distribution
[2, 36]; 2) the metrics between distributions can be char-acterized by Wasserstein distance; 3) there are independent transference plans between local surfaces, which are go-ing to be fused; 4) the transference plans between fusion candidates should be optimal due to they are two observa-tions of the same surface interfered by uncertainties. Thus, there are geodesic curves between measurements, as well as geodesic curves between Gaussian measures. In all, we pair measurements with the optimal transference plans by solving the mass transport problem, which is also known as the Monge-Kantorovich problem. We move the points along the geodesic curves and employ a novel advection to tackle the uncertainties.
This paper makes the following contributions:
• We introduce displacement interpolation into the 3D reconstruction area for the first time and propose a unique geometry-guided fusion framework.
• We present a flexible interpolation scheme based on geodesic curves, which reveal the geometric structures of the local surface.
• We propose a novel advection strategy guided by lo-cal geometric properties, i.e., Gaussian curvature and mean curvature. A significant number of experimen-tal results on real data verified the effectiveness of the proposed method. 2.