Abstract
With the recent success of deep neural networks, remark-able progress has been achieved on face recognition. How-ever, collecting large-scale real-world training data for face recognition has turned out to be challenging, especially due to the label noise and privacy issues. Meanwhile, existing face recognition datasets are usually collected from web im-ages, lacking detailed annotations on attributes (e.g., pose and expression), so the inﬂuences of different attributes on face recognition have been poorly investigated. In this pa-per, we address the above-mentioned issues in face recog-nition using synthetic face images, i.e., SynFace. Speciﬁ-cally, we ﬁrst explore the performance gap between recent state-of-the-art face recognition models trained with syn-thetic and real face images. We then analyze the underlying causes behind the performance gap, e.g., the poor intra-class variations and the domain gap between synthetic and real face images. Inspired by this, we devise the SynFace with identity mixup (IM) and domain mixup (DM) to miti-gate the above performance gap, demonstrating the great potentials of synthetic data for face recognition. Further-more, with the controllable face synthesis model, we can easily manage different factors of synthetic face genera-tion, including pose, expression, illumination, the number of identities, and samples per identity. Therefore, we also per-form a systematically empirical analysis on synthetic face images to provide some insights on how to effectively utilize synthetic data for face recognition. 1.

Introduction
In the last few years, face recognition has achieved ex-traordinary progress in a wide range of challenging prob-lems including pose-robust face recognition [5, 24, 62], matching faces across ages [15, 17, 55, 59], across modal-ities [13, 14, 16, 30, 31], and occlusions [40, 48, 70].
*Equal contribution
Figure 1. Examples of real/synthetic face images. The ﬁrst row indicates real face images from CASIA-WebFace, and the sec-ond row shows synthetic face images generated by DiscoFace-GAN [11] with the proposed identity mixup module.
Among these progresses, not only the very deep neural networks [22, 25, 29, 47] and sophisticated design of loss functions [10, 23, 32, 56, 60], but also large-scale training datasets [20, 26, 27] played important roles. However, it has turned out to be very difﬁcult to further boost the per-formance of face recognition with the increasing number of training images collected from the Internet, especially due to the severe label noise and privacy issues [20, 54, 58]. For example, several large-scale face recognition datasets are struggling with the consent of all involved person/identities, or even have to close the access of face data from the web-site [20]. Meanwhile, many face training datasets also suf-fer from the long-tailed problem, i.e., head classes with a large number of samples and tail classes with a few number of samples [34, 37, 71]. To utilize these datasets for face recognition, people need to carefully design the network ar-chitectures and/or loss functions to alleviate the degradation on model generalizability brought by the long-tailed prob-lem. Furthermore, the above-mentioned issues also make it difﬁcult for people to explore the inﬂuences of different attributes (e.g., expression, pose and illumination).
To address the aforementioned issues, we explore the potentials of synthetic images for face recognition in this paper. Recently, face synthesis using GANs [18] and 3DMM [3] have received increasing attention from the computer vision community, and existing methods usually
focus on generating high-quality identity-preserving face images [2, 46, 64]. Some synthetic and real face images are demonstrated in Figure 1. However, the problem of face recognition using synthetic face images has not been well-investigated [28, 52]. Speciﬁcally, Trigueros et al. [52] in-vestigated the feasibility of data augmentation with photo-realistic synthetic images. Kortylewski et al. [28] further explored the pose-varying synthetic images to reduce the negative effects of dataset bias. Lately, disentangled face generation has become popular [11], which can provide the precise control of targeted face properties such as identity, pose, expression, and illumination, thus making it possible for us to systematically explore the impacts of facial prop-erties on face recognition. Speciﬁcally, with a controllable face synthesis model, we are then capable of 1) collecting large-scale face images of non-existing identities without the risk of privacy issues; 2) exploring the impacts of differ-ent face dataset properties, such as the depth (the number of samples per identity) and the width (the number of identi-ties); 3) analyzing the inﬂuences of different facial attributes (e.g., expression, pose, and illumination).
However, there is usually a signiﬁcant performance gap between the models trained on synthetic and real face datasets. Through the empirical analysis, we ﬁnd that 1) the poor intra-class variations in synthetic face images and 2) the domain gap between synthetic and real face datasets are the main reasons of the performance degradation. To address the above issues, we introduce identity mixup (IM) into the disentangled face generator to enlarge the intra-class variations of generated face images. Speciﬁcally, we use a convex combination of the coefﬁcients from two dif-ferent identities to form a new intermediate identity coefﬁ-cient for synthetic face generation. Experimental results in
Sec. 4 show that the identity mixup signiﬁcantly improves the performance of the model trained on synthetic face im-ages. Furthermore, we observe a signiﬁcant domain gap via cross-domain evaluation: 1) training on synthetic face images and testing on real face images; 2) training on real face images and testing on synthetic face images (see more details in Sec. 3.2). Therefore, we further introduce the do-main mixup (DM) to alleviate the domain gap, i.e., by us-ing a convex combination of images from a large-scale syn-thetic dataset and a relatively small number of real face im-ages during training. With the proposed identity mixup and domain mixup, we achieve a signiﬁcant improvement over the vanilla SynFace, further pushing the boundary of face recognition performance using synthetic data. The main contributions of this paper are as follows:
• We observe a performance gap between the models trained on real and synthetic face images, which can be effectively narrowed by 1) enlarging the intra-class variations via identity mixup; 2) leveraging a few real face images for domain adaption via domain mixup.
• We discuss the impacts of synthetic datasets with dif-ferent properties for face recognition, e.g., depth (the number of samples per identity) and width (the number of identities), and reveal that the width plays a more important role.
• We analyze the inﬂuences of different facial attributes on face recognition (e.g., facial pose, expression, and illumination). 2.