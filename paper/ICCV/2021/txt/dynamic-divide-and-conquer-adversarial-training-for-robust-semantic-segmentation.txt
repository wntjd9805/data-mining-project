Abstract
Adversarial training is promising for improving robust-ness of deep neural networks towards adversarial pertur-bations, especially on the classification task. The effect of this type of training on semantic segmentation, contrarily, just commences. We make the initial attempt to explore the defense strategy on semantic segmentation by formulat-ing a general adversarial training procedure that can per-form decently on both adversarial and clean samples. We propose a dynamic divide-and-conquer adversarial training (DDC-AT) strategy to enhance the defense effect, by set-ting additional branches in the target model during train-ing, and dealing with pixels with diverse properties to-wards adversarial perturbation. Our dynamical division mechanism divides pixels into multiple branches automat-ically. Note all these additional branches can be aban-doned during inference and thus leave no extra parame-ter and computation cost. Extensive experiments with var-ious segmentation models are conducted on PASCAL VOC 2012 and Cityscapes datasets, in which DDC-AT yields sat-isfying performance under both white- and black-box at-tack. The code is available at https://github.com/dvlab-research/Robust-Semantic-Segmentation. 1.

Introduction
Recent work has revealed that deep learning models, es-pecially in the classification task, are often vulnerable to adversarial samples [40, 15, 35]. The adversarial attack can deceive the target model by generating crafted adversarial perturbations on original clean samples. Such perturbations are often imperceptible. Meanwhile, such threat also exists in semantic segmentation [46, 31, 1], as shown in Fig. 1.
However, there is seldom work to improve the robustness of semantic segmentation networks. As a universal approach, adversarial training [15, 25, 29] is effective to enhance the target model in classification by training models with adver-(a) Image (c) With Our Defense (b) No Defense
Figure 1. For each image in (a), the left side is the normal data while the right side is perturbed by adversarial noise. (b) shows that the adversarial attack could fail existing segmentation models.
We provide an effective defense strategy shown in (c). The top and bottom rows are results with PSPNet and DeepLabv3, respectively. sarial samples. In this paper, we study the effect of adver-sarial training on the semantic segmentation task. We find that adversarial training impedes convergence on clean sam-ples, which also happens in classification. We aim to make networks perform well on adversarial examples and mean-while maintaining good performance on clean samples.
For the semantic segmentation task, each pixel has one classification output. Thus the property of every pixel in one image toward adversarial perturbations might be differ-ent. Based on this motivation, we design a dynamic divide-and-conquer adversarial training (DDC-AT) strategy. We propose to use multiple branches in the target model during training, each handling pixels with a set of properties. Dur-ing training, a “main branch” is adopted to deal with pix-els from adversarial samples and pixels from clean samples that are not likely to be perturbed; an “auxiliary branch” is utilized to deal with pixels from clean samples that are sensitive to perturbations.
Moreover, such a divide-and-conquer setting is dynamic.
During training, pixels near the decision boundary from clean samples are initially set to the “auxiliary branch”.
They become more insensitive to perturbations in the “aux-iliary branch”, and finally move back to the “main branch” for processing. Such a dynamic procedure is implemented by training a “mask branch”. With this mechanism, our method reduces performance deterioration over clean sam-ples. Experiments manifest that such a mechanism also im-proves robustness towards adversarial samples. Another no-table advantage of our proposed DDC-AT is that branches apart from the main one can be abandoned during inference.
Thus parameters and computation cost remain almost the same. We conduct extensive experiments with various seg-mentation models on both PASCAL VOC 2012 [13] and
Cityscapes [9] datasets. It is validated that our standard ad-versarial training strategy is effective to improve the robust-ness of segmentation networks, and our new DDC-AT strat-egy further boosts the effect of defense. It yields superior performance under both white- and black-box attacks.
In summary, our main contribution is threefold.
• It is the first attempt to have a comprehensive explo-ration on the effect of adversarial training for semantic segmentation. Our standard adversarial training can be treated as a strong baseline to evaluate defense strate-gies for semantic segmentation networks.
• We propose the DDC-AT to notably improve the de-fense performance of segmentation networks on both clean and adversarial samples.
• We conduct experiments with various model structures on different datasets, which manifest the effectiveness and generality of DDC-AT. 2.