Abstract
Detecting pedestrians and their associated faces jointly is a challenging task. On one hand, body or face could be absent because of occlusion or non-frontal human pose. On the other hand, the association becomes difficult or even miss-leading in crowded scenes due to the lack of strong correlational evidence. This paper proposes Body-Face
Joint (BFJ) detector, a novel framework for detecting bod-ies and their faces with accurate correspondance. We fol-low the classical multi-class detector design by detecting body and face in parallel but with two key contributions.
First, we propose an Embedding Matching Loss (EML) to learn an associative embedding for matching body and face of the same person. Second, we introduce a novel con-cept, “head hook”, to bridge the gap of matching body and faces spatially. With the new semantical and geometrical sources of information, BFJ greatly reduces the difficulty of detecting body and face in pairs. Since the problem is un-explored yet, we design a new metric named log-average miss matching rate (mMR−2) to evaluate the association performance and extend the CrowdHuman and CityPer-sons benchmarks by annotating each face box. Experi-ments show that our BFJ detector can maintain state-of-the-art performance in pedestrian detection on both one-stage and two-stage structures while greatly outperform various body-face association strategies. Code will be available at: https://github.com/AibeeDetect/BFJDet. 1.

Introduction
Pedestrian detection has been a long-standing topic in the field of computer vision. Accurate localization of in-dividuals in the scene can effectively facilitate the down-stream process such as recognition, re-identification and tracking. By the development of deep learning, methods based on convolutional neural networks [20] have dramat-ically improved the detecting performance on both general objects like MS-COCO [23] and pedestrians like Crowd-∗Equal contribution.
†Work done during Junfeng’s internship at Aibee.
Figure 1. Challenges of detecting pedestrian with associated faces in the wild. (a) Face of pedestrians in green box (side to the cam-era) and blue box (back to the camera) are invisible. (b) Bodies of the three people are absent despite their faces are clearly visible. (c) Miss-matching between bodies and faces in crowded scenes.
Human [30], leading to the ability of application-level use such as video surveillance and identity authentication. For a pedestrian, the face is the most semantically discriminative part. So finding out body and face jointly becomes mean-ingful. However, for the joint detection, there exist three main obstacles. First, all persons’ bodies and faces are not perfectly visible and not always yielding one-to-one corre-spondance. As shown in Fig. 1a, the man in green box is side to the camera while the man in blue box is back to the camera, both of their faces can not be seen. This phe-nomenon makes the simple method of regressing body and face boxes jointly from one proposal [4] impractical.
In
Fig. 1b, the three people have visually clear faces while their bodies are hardly observed due to the heavy occlusion. This anisotropy limits another intuitive pipeline of first detecting bodies and then finding face from them (we depict it as cas-cade mode) since it would seriously affect the face recall.
The third solution is detecting bodies and faces respectively and then making associations based on their positional re-lationships by solving an assignment problem. However, in crowded scenes, this approach (we depict it as position mode) would cause severe miss-matching since many faces fall into the body region of other people (Fig. 1c).
To overcome these obstacles, we propose a novel frame-work named Body-Face Joint (BFJ) detector.
In our method, body and face are treated as two independent cat-egories and are detected in parallel. From this design, the incorrespondance issue can be inherently avoided and both categories preserve a good performance since they do not depend on each other (such as sharing the same pre-defined box). Then, we make correlations reasonably from the ap-pearance as well as the geometry level. First, an extra branch is attached to the end of the detector, generating embeddings for all objects detected. We propose an Em-bedding Matching Loss (EML) to learn the optimal embed-ding space where the pair of body and face from the same pedestrian are closer to each other. Second, based on the statistical fact that head often appears along with body or face, we introduce a novel conception: “head hook”, which means the center-point of the adjunct head of each body and face. According to the information theory [29] that distinct sources of information often provide complementarity. In the association process, we match bodies and faces under the guidance from both the feature level (embeddings) and spatial level (head hooks) above.
Until now, there is neither metric to evaluate the body-face matching quality nor benchmark that has completed annotations for paired bodies and faces. To verify our method, inspired by the log-average miss rate (MR−2) [8] in pedestrian detection, we design a new metric named log-average miss matching rate (mMR−2) to measure errors in body-face association. Moreover, we carefully annotate face box for each pedestrian in two public datasets: Crowd-Human [30] and CityPersons [38]. Experiments show that
BFJ outperforms the intuitive methods in both cascade mode and position mode with a large margin.
In summary, our contributions are two-fold: 1) We pro-pose a joint body-face detection scheme that output body-face pairs for each pedestrian, showing powerful perfor-mance in both detection and body-face association. 2) To our best knowledge, we are the first one to systematically investigate the performance of body-face joint detection.
Therefore we design a principled metric to evaluate the quality of body-face association. And we annotate faces in
CrowdHuman and CityPersons, constructing two new large-scale benchmarks for joint body-face detection. 2.