Abstract
Benefiting from the excellent performance of Siamese-based trackers, huge progress on 2D visual tracking has been achieved. However, 3D visual tracking is still under-explored. Inspired by the idea of Hough voting in 3D object detection, in this paper, we propose a Multi-level Voting
Siamese Network (MLVSNet) for 3D visual tracking from outdoor point cloud sequences. To deal with sparsity in out-door 3D point clouds, we propose to perform Hough voting on multi-level features to get more vote centers and retain more useful information, instead of voting only on the fi-nal level feature as in previous methods. We also design an efficient and lightweight Target-Guided Attention (TGA) module to transfer the target information and highlight the target points in the search area. Moreover, we propose a
Vote-cluster Feature Enhancement (VFE) module to exploit the relationships between different vote clusters. Extensive experiments on the 3D tracking benchmark of KITTI dataset demonstrate that our MLVSNet outperforms state-of-the-art methods with significant margins. Code will be available at https://github.com/CodeWZT/MLVSNet.
Figure 1. Illustration on how MLVSNet tracks a target on 3D point clouds. MLVSNet tracks the target object in the search area at each frame over a sequence of point clouds. 1.

Introduction
Visual tracking aims to track a given target in every frame of a sequence. As shown in Fig. 1, a tracking algo-rithm takes as input a target and a search area, and outputs the location of the detected target in the search area, which also serves as the target for the next frame. Visual track-ing is an indispensable part in robot vision and autopilot systems [43, 46, 8], and has long been a popular research topic in computer vision [23, 35]. Great progress has been made in 2D visual tracking community, benefiting from the excellent performance of Siamese based trackers [47, 11].
However, direct application of these trackers to 3D tracking is infeasible due to the different data structure. Compared to 2D visual tracking, 3D tracking uses point cloud data. It has the advantages of being more robust to illumination and
*These authors contributed equally to this work.
†Corresponding author: wjun@nuaa.edu.cn. appearance changes, but is also more challenging. Different from RGB images/videos, 3D point cloud data is irregular, noisy, and more sparse especially in outdoor environment.
These impose challenges different from 2D visual tracking and require specific considerations in the algorithm design.
In this paper, we propose a novel Multi-level Voting
Siamese Network (MLVSNet), an end-to-end 3D visual tracking method from point clouds in outdoor scenes. As illustrated in Fig. 1, at each frame, tracking is grounded on target detection. The recently proposed VoteNet [29] has demonstrated its effectiveness in detecting 3D objects from point clouds [42, 5, 33]. VoteNet is based on Hough voting, where the chosen points collect the geometric information from their surrounding points and then vote for the object centers. Inspired by the success of VoteNet, the proposed
MLVSNet also employs the idea of Hough voting to locate targets in the search area. In addition to voting-based detec-tion, the design of MLVSNet also takes into consideration
the following two challenges: 1) how to deal with the irreg-ular, noisy and sparse 3D point cloud data; 2) how to effi-ciently transfer the information of the target to the search area for tracking.
To deal with the irregular data structure and noisy data capture, PointNet++ [30] was proposed recently and has shown great success in 3D object detection [40, 28, 41]. Its hierarchical feature learning effectively distills information and captures useful high-level features from the irregular and noisy point cloud data. However, associated with the high-level features is the reduced number of seed points, which worsens the already sparse points for representing targets in outdoor scene point clouds. We argue that both the number of seed points and the feature descriptive ability of points are important for target detection. To balance the two, in MLVSNet, we propose to make use of seed points and their representations at multiple levels, i.e., a multi-level voting strategy (MLV), to aggregate votes from seed points at multiple levels. We also argue that the multi-level aggregation captures information at different scales and ac-tually improves the detection performance, as we will later show in experiments.
To transfer the target information for tracking, the state-of-the-art method [31] makes use of a series of MLP (Multi-Layer Perceptron) layers to embed target features into the feature map of the search area. However, such operations are both memory and time inefficient especially when com-bined with the multi-level voting strategy. Attention mech-anism [38, 26] has been demonstrated an effective and effi-cient way to model relationship information [40]. We there-fore propose a lightweight module, termed Target-Guided
Attention (TGA) module, to establish the relationship be-tween the search area and the target with much fewer pa-rameters. Attention mechanism is also used in the proposed
Vote-cluster Feature Enhancement (VFE) module to exploit the relationship between different vote clusters, which fur-ther improves the network performance.
All the above modules constitute the proposed Multi-level Voting Siamese Network (MLVSNet) for 3D track-ing from point cloud sequences. Extensive experiments show that our model outperforms the state-of-the-art mod-els [31, 14] by a large margin. In summary, this work makes the following contributions:
• We propose a multi-level voting (MLV) strategy to aggregate data and information at multiple levels for more effective target detection in sparse point clouds.
• We design a lightweight feature fusion module, named
Target-Guided Attention (TGA), for efficient embed-ding of target information for tracking.
• We present the novel Multi-level Voting Siamese Net-work (MLVSNet) for 3D visual tracking on point clouds, which achieves the new state-of-the-art perfor-mance on benchmarks. 2.