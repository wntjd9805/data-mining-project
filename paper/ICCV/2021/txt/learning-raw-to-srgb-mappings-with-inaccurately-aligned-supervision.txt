Abstract
Learning RAW-to-sRGB mapping has drawn increasing attention in recent years, wherein an input raw image is trained to imitate the target sRGB image captured by an-other camera. However, the severe color inconsistency makes it very challenging to generate well-aligned training pairs of input raw and target sRGB images. While learning with inaccurately aligned supervision is prone to causing pixel shift and producing blurry results. In this paper, we circumvent such issue by presenting a joint learning model for image alignment and RAW-to-sRGB mapping. To dimin-ish the effect of color inconsistency in image alignment, we introduce to use a global color mapping (GCM) module to generate an initial sRGB image given the input raw image, which can keep the spatial location of the pixels unchanged, and the target sRGB image is utilized to guide GCM for converting the color towards it. Then a pre-trained opti-cal ﬂow estimation network (e.g., PWC-Net) is deployed to warp the target sRGB image to align with the GCM output.
To alleviate the effect of inaccurately aligned supervision, the warped target sRGB image is leveraged to learn RAW-to-sRGB mapping. When training is done, the GCM module and optical ﬂow network can be detached, thereby bringing no extra computation cost for inference. Experiments show that our method performs favorably against state-of-the-arts on ZRR and SR-RAW datasets. With our joint learning model, a light-weight backbone can achieve better quantita-tive and qualitative performance on ZRR dataset. Codes are available at https://github.com/cszhilu1998/
RAW-to-sRGB. 1.

Introduction
The image signal processing (ISP) pipeline refers to the processing of raw sensor image for producing high qual-ity display-referred sRGB image, and thus is pivotal for a camera system. A representative ISP pipeline usually in-volves a sequence of steps including demosaicking, white balance, color correction, tone mapping, denoising, sharp-ening, gamma correction and so on [40]. While hand-crafted ISP solutions are usually adopted in current cam-era systems, convolutional networks (CNNs) have exhibited great potential in learning deep ISP model in an end-to-end manner [22, 29, 45].
The end-to-end property of deep ISP makes it very com-petitive to learn RAW-to-sRGB mapping to generate high quality image for mobile camera [22]. Albeit mobile cam-era has become the dominant sources of photos, it has a smaller sensor size and limited aperture in comparison to
DSLR camera. By learning RAW-to-sRGB mapping to pro-duce DSLR-like sRGB image from mobile raw image, deep
ISP model can thus offer an encouraging way to close the gap between mobile camera and DSLR camera. Moreover, in contrast to 8-bit sRGB image, raw image usually has higher-bit (e.g., 10-14 bit) and may convey richer details.
Therefore, learning RAW-to-sRGB mapping is beneﬁcial to performance improvement even for other low level vision tasks, e.g., image super-resolution [62], low light image de-noising [8] and high dynamic range imaging (HDR) [6].
However, when preparing training data, input raw im-age and target sRGB image are usually taken using different cameras (e.g., a smartphone and a DSLR) or with different camera conﬁgurations (e.g., focal length). Consequently, color inconsistency and spatial misalignment are usually in-evitable. On the one hand, the color inconsistency makes it very challenging to generate well-aligned training pairs of input raw and target sRGB images. The input raw and target sRGB images usually cannot be perfectly aligned by existing methods [34, 49], resulting in mild alignment. On the other hand, learning with inaccurately aligned super-vision is prone to pixel shift and producing blurry results (see Fig. 1(b)). To alleviate the adverse effect of inaccurate alignment, AWNet [9] adopted global context block [5] at the cost of increasing inference time, while Zhang et al. [62] presented a contextual bilateral (CoBi) loss to search the best matching patch for supervision. However, the patch-based alignment is unable to appropriately handle the spa-tially variant misalignment caused by depth discrepancy be-tween objects. As a result, their method is still prone to producing blurry results as shown in Fig. 1(f).
In order to circumvent inaccurately aligned supervision
(a) Input raw image (visualized) (b) PyNet [22] (c) Ours (d) Target sRGB image (e) Input raw image (visualized) (f) Zhang et al. [62] (g) Ours (h) Target sRGB image
Figure 1: Example of data pairs of ZRR and SR-RAW datasets, where clear spatial misalignment can be observed with the ref-erence line. With such inaccurately aligned training data, PyNet [22] and Zhang et al. [62] are prone to generating blurry re-sults with spatial misalignment, while our results are well aligned with the input. Please zoom in for better observation. problem, this paper presents a joint learning model for im-age alignment and RAW-to-sRGB mapping. We argue that one major reason that explains the inaccurate/mild align-ment is the severe color inconsistency between input raw and target sRGB images. Otherwise, existing optical ﬂow networks [10, 23, 46] can be readily utilized to fulﬁll the task of image alignment. Thus, we suggest to perform im-age alignment by concatenating a delicately designed global color mapping (GCM) module with a pre-trained optical
ﬂow estimation network (e.g., PWC-Net [46]). In particular, the GCM module involves a stack of 1×1 convolutional lay-ers to ensure that the mapping is spatially independent. To overcome the obstacle of color inconsistency, we constrain the GCM output to approximate the aligned target sRGB image. It is worth noting that GCM is deployed to align target sRGB image only during training. Thus, we can also take the target sRGB image and coordinate map to generate conditional guidance for modulating GCM features towards diminishing color inconsistency. Then, a pre-trained optical
ﬂow estimation network (e.g., PWC-Net [46]) can be used to align the target sRGB image with the GCM output, re-sulting in the well aligned sRGB image.
The aligned target sRGB image can serve as a better supervision for training the RAW-to-sRGB mapping.
In particular, we propose a LiteISPNet by reducing the resid-ual channel attention blocks (RCABs) in MW-ISPNet [20].
GCM and LiteISPNet are jointly trained for both the align-ment of target sRGB image (i.e., GCM and PWC-Net) and the RAW-to-sRGB mapping (i.e., LiteISPNet). When train-ing is done, GCM and PWC-Net can be detached and only
LiteISPNet is required for handling test raw images, thereby bringing no extra inference cost. Experiments on Zurich
RAW to RGB (ZRR) dataset [22] show that our solution is effective in learning with inaccurately aligned supervision and producing more ﬁne details. Our proposed method also outperforms the state-of-the-art method in terms of quan-titative metrics, perceptual quality and computational ef-ﬁciency. Furthermore, using SRResNet as the backbone, experiments also show the effectiveness of our method for image super-resolution on the SR-RAW dataset [62].
The main contributions of this work are three-fold:
• An effective approach is presented to circumvent the task of learning RAW-to-sRGB mapping with inaccu-rately aligned supervision.
• A global color mapping (GCM) module is delicately designed to tackle the effect of color inconsistency on image alignment. A spatially preserving network (SPN) is leveraged to avoid spatial shift of pixels, and the target sRGB image is adopted to modulate GCM features towards diminishing color inconsistency.
• Quantitative and qualitative results on ZRR and SR-RAW datasets show that our method outperforms the state-of-the-art methods with no extra inference cost. 2.