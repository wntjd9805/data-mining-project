Abstract
In autonomous driving (AD), accurately predicting changes in the environment can effectively improve safety and comfort. Due to complex interactions among trafﬁc participants, however, it is very hard to achieve accurate prediction for a long horizon. To address this challenge, we propose prediction by anticipation, which views interaction in terms of a latent probabilistic generative process wherein some vehicles move partly in response to the anticipated motion of other vehicles. Under this view, consecutive data frames can be factorized into sequential samples from an action-conditional distribution that effectively generalizes to a wider range of actions and driving situations. Our pro-posed prediction model, variational Bayesian in nature, is trained to maximize the evidence lower bound (ELBO) of the log-likelihood of this conditional distribution. Evaluations of our approach with prominent AD datasets NGSIM I-80 and Argoverse show signiﬁcant improvement over current state-of-the-art in both accuracy and generalization. 1.

Introduction
Predicting the future state of a scene with moving objects is a task that humans handle with ease. This is due to our understanding about the dynamics of the objects in the scene and the way they interact. Despite recent advancements in machine learning and especially deep learning, teaching machines such understanding remains challenging.
In this paper, we are interested in predicting the high-in pixel space, of a scene dimensional observations, e.g. with multiple interacting agents, where the observations are ego-centric, i.e. the scene is observed from the standpoint of one of the agents (ego-agent). Formally, we consider an action-conditional prediction task, which is deﬁned as ﬁnd-ing the next observation from the scene given a sequence of the past and current observations, o1:t, and the ego-agent’s o1:t, at). In action (ego-action) at, i.e. optimizing p(ot+1| particular we consider the prediction task in the challenging framework of autonomous driving (AD), where there is a large number of agents in the scene and they have compli-cated interactions with each other. The common approach in the literature to tackle this problem is to optimize this con-ditional probability directly, e.g. [12]. However, since the observations are heavily affected by the ego-actions, these models often fail to generalize to larger set of actions than the training set or to adapt to broader range of environments.
Nevertheless, in many applications, specially AD, such gen-eralization is of great importance as handling many critical scenarios require taking actions that are rarely seen in the data collected from real-world driving. t t
In order to harness the effect of the action, we propose a novel approach based on splitting the original problem into two subproblems where this effect can be learned much easier. In fact, we break the observation into two sets of features: 1) ego-features, oego
, which contains the features related to the ego agent (e.g. its position). 2) environment-features, oenv
, which contains all other features than the ego-features including other agents. The action has an effect on both of these feature sets. Our approach is based on the idea that sequences of data that include heavy interactions come from a probabilistic generative process wherein some reacting agents move partly in response to the anticipated motion of some acting agents. Therefore, we decompose o1:t, at) p(ot+1| o1:t, oego and then learning p(oenv t+1), i.e. we ﬁrst learn how t+1| the action changes the ego-features and then learn how the environment reacts to this change. However, the effect of the action on the ego-features is much easier to model and often does not need to be learned and can be ﬁxed using the domain knowledge. Then we can learn p(oenv t+1) from data, t+1| which is much easier than learning p(ot+1| o1:t, at) since we only have to learn to predict oenv t+1 based on the effect of action at on the ego-features oego t+1. Conditioning on at or oego t+1 is equivalent from an information theoretic perspec-tive, but conditioning on oego t+1 allows the model to reason about interactions more easily since the ego effect is already learning p(oego t+1| o1:t, at) into two steps: o1:t, oego
anticipated. Moreover, such conditioning is valid in prac-tice as other agents observe the effect of ego-actions not the actions themselves. Hence, the original action-conditional prediction task to a great extent is reduced to learning the interaction of the other agents given the anticipated move-ment of the ego-agent. For such interaction learning we train a conditional deep generative model, where we combine a deterministic mapping that encodes the history of observa-tions and movement of agents with a stochastic mapping that reasons about the future interactions. By thus recovering the latent generative process, our model is capable of achieving a higher capacity for prediction, i.e. handling a wider range of actions and driving situations.
We consider the observations in the form of occupancy grid maps (OGMs), which minimizes the costly and time-consuming preprocessing (e.g. object detection and track-ing). The anticipation step is done through transformations of the original OGM based on motion of the acting vehicle.
Since the observations are ego-centric, these transformations
ﬁx the observation frame from input to target and therefore the interaction learning can be represented by learning the displacement of moving objects conditioned on the next posi-tion of the ego-vehicle. This enables us to extend our model to a difference learning variant, which works very well in dense slow urban trafﬁc. Our contributions include:
• A novel modular model for multi-step action-conditional prediction for AD is proposed, which fac-torizes historical sequence data into samples drawn according to an underlying action-conditional distribu-tion that covers a wider range of actions for predictions better than current state-of-the-art models. The method requires no labeling and is scalable with data.
• An extension of the model for difference learning that outperforms the state-of-the-art in dense trafﬁc.
• Experiment results on two prominent AD datasets (NGSIM I-80 and Argoverse) with different interac-tions among vehicles, i.e. highway and urban area, demonstrating effective coverage of a wide variety of actions and driving situations. An extensive ablative study is conducted to investigate the role of each novel component of our model. 2.