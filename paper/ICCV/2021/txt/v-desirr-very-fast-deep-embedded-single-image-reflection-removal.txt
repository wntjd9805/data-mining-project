Abstract
Real world images often gets corrupted due to unwanted reﬂections and their removal is highly desirable. A major share of such images originate from smart phone cameras capable of very high resolution captures. Most of the exist-ing methods either focus on restoration quality by compro-mising on processing speed and memory requirements or, focus on removing reﬂections at very low resolutions, there by limiting their practical deploy-ability. We propose a light weight deep learning model for reﬂection removal using a novel scale space architecture. Our method processes the corrupted image in two stages, a Low Scale Sub-network (LSSNet) to process the lowest scale and a Progressive In-ference (PI) stage to process all the higher scales. In order to reduce the computational complexity, the sub-networks in PI stage are designed to be much shallower than LSS-Net. Moreover, we employ weight sharing between various scales within the PI stage to limit the model size. This also allows our method to generalize to very high resolutions without explicit retraining. Our method is superior both qualitatively and quantitatively compared to the state of the art methods and at the same time 20× faster with 50× less number of parameters compared to the most recent state-of-the-art algorithm RAGNet. We implemented our method on an android smart phone, where a high resolution 12 MP image is restored in under 5 seconds. 1.

Introduction
Image capture in the vicinity of a reﬂective surface such as glass windows is very challenging due to the formation of undesirable reﬂection artifacts. These artifacts not only affect the perceptual quality of the image, but also impact high-level tasks such as image recognition and object de-tection. Hence removal of reﬂection is very desirable and is an active area of research in image processing and computer vision.
Several methods have been proposed in the past to ad-Input
Input Zoomed
BDN [33]
ERRNet [28]
Zhang.et.al [34]
BeyLin [29]
IBCLN [12]
RAGNet [16]
Ours
Figure 1: High Resolution Performance and Complexity Anal-ysis. (a) Comparison of our method against current state of the art for a high resolution 12MP input image. (b) Complexity evalua-tion on NVIDIA GTX 1080Ti for an image tile of size 540x400. dress the problem of reﬂection, The earliest methods try to solve the problem by imposing additional handcrafted constraints on the problem deﬁnition such as natural scene statistics [10], sparsity priors [11], gradient smoothness [32] and ghosting cues [22]. However it has been observed that solutions based on handcrafted priors do not adapt very well to the complex reﬂection patterns often observed in real life.
In order to model real-life reﬂection patterns, several data-driven approaches using deep neural networks have been proposed in the recent past [12] [16] [28] [34] . Even though these methods achieve state-of-the-art results and is able to model strong and complex reﬂections efﬁciently, they suffer from two major drawbacks: a) High computation requirements: Reﬂection removal needs a large receptive ﬁeld to efﬁciently gather the se-mantic information required for recovering the transmis-sion layer. The conventional methods try to increase the receptive ﬁeld by stacking up a large number of convolu-tion ﬁlters which tremendously increases the computation and memory requirements. For example, a recent method proposed by RAGNet [16] consists of 131 million param-eters, consumes a peak memory of 2.9 GB and takes 20
seconds to process a 12 MP image on a NVIDIA 1080Ti
GPU. This makes it impossible to deploy such methods on a smart phone device with limited computation power and memory making their real-life applicability extremely lim-ited. b) Inability to remove reﬂections from high resolu-tion images: Several contemporary smart phone vendors provide multiple cameras with resolutions varying from 8 megapixels to 108 megapixels. Hence a deploy-able solu-tion should be able to remove reﬂections from a wide range of image resolutions. However, most of the state-of-the-art methods uses ﬁxed network architectures thus making its receptive ﬁeld static. Moreover most of these methods are trained on low resolution data sets which are less than a megapixel in size. Since the semantic content of an im-age in a ﬁxed receptive ﬁeld varies over resolutions, these methods are not ’scale invariant’ and hence cannot remove reﬂections on high resolution images. Hence these methods need to be retrained for each resolution to efﬁciently remove reﬂections which is very cumbersome.
In this paper, we propose a novel method to address the aforementioned challenges while maintaining output im-age quality. Inspired by recent success of scale-space ap-proaches in image deblurring [19] [25], we propose a scale-space reﬂection removal approach for increasing the re-ceptive ﬁeld with minimal increase in computational over-head. The corrupted input image is transformed into its scale space representation, and is processed by identical, weight-shared deep CNNs at each scale except the lowest scale. To make our method more efﬁcient, we use a deeper network at the lowest scale (Low Scale Network - LSSNet) and a much shallower network for higher scales (High Scale
Network - HSSNet). The output at each scale is up sam-[30] and pled using Convolutional Guided Filters (CGF) appended to the input of the immediate higher level to aid the reﬂection removal process at each scale. As observed by [25], the same problem is solved at each scale, and hence weights can be shared between all the HSSNets and
CGF blocks in the scale space resulting in a very low mem-ory footprint. This also enables us to dynamically increase the effective receptive ﬁeld during inference easily by in-creasing the number of scales. Hence the proposed method can remove reﬂections from high resolution images without any explicit retraining making it easily adaptable to smart phones.
A sample output from the proposed method is shown in
Fig. 1. The input image given to the network is of very high resolution (12 MP) and the state of the art methods train on images of much lower resolution with a ﬁxed receptive ﬁeld, hence fails to remove reﬂections from the image. Whereas our method is able to generalize well to high resolution im-ages even without training on such images. Also in Fig. 1, we show three plots to demonstrate how the performance with respect to execution time, memory and network com-plexity compares to the state-of-the-art methods. We show in the later sections that our method is able to achieve better performance than the state of the art methods while being much more computationally efﬁcient. It runs 20× faster with a reduction in peak memory usage of 3× compared
[16] on NVIDIA 1080Ti GPU. Further, our to RAGNet method uses only 2.6 million learnable parameters which is 50× less than RAGNet [16]. We also implemented our method on a mobile android device with 8 GB RAM and
Qualcomm Snapdragon 888 processor. We observed that the proposed method can process a 12 megapixel input data in under 5 seconds and hence can easily be adapted to smart phone devices to process even high resolution images under a reasonable time.
The contributions of our work are as follows: (1) We propose a fast scale space approach for reﬂection removal which can easily be deployed on resource limited devices such as smart phones. (2) To make our method computationally efﬁcient, we use a deeper network only at the lowest scale, while the higher scales are processed using much shallower networks. This makes our method 20× faster than the most recent state-of-the-art method RAGNet. (3) The proposed algorithm is scalable to handle high res-olution input images (tested up to 64 MP) without the need for explicit retraining. (4) The proposed algorithm can process a 12 MP image in under 5 seconds on a smart phone with a Qualcomm Snap-dragon 888 chip set and 8 GB RAM. To the best of our knowledge, this is the fastest deep learning based method for reﬂection removal with state-of-the-art results. (5) We build a high resolution dataset captured using lat-est smartphones with real world reﬂections that can en-able future evaluations. The dataset will be available at https://www.github.com/ee19d005/vdesirr. 2.