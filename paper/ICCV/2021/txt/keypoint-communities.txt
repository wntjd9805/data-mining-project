Abstract
We present a fast bottom-up method that jointly detects over 100 keypoints on humans or objects, also referred to as human/object pose estimation. We model all keypoints belonging to a human or an object –the pose– as a graph and leverage insights from community detection to quantify the independence of keypoints. We use a graph centrality measure to assign training weights to different parts of a pose. Our proposed measure quantifies how tightly a key-point is connected to its neighborhood. Our experiments show that our method outperforms all previous methods for human pose estimation with fine-grained keypoint annota-tions on the face, the hands and the feet with a total of 133 keypoints. We also show that our method generalizes to car poses. 1.

Introduction
Recent large-scale datasets with fine-grained annotations of complex poses present a new challenge for pose estima-tion methods. Beyond detecting a coarse person bounding box and a small set of keypoints for large body joints, we now have large datasets that include over 100 extra fine-grained keypoints in the face, the hands and the feet. Re-solving these fine details will allow us to build robust rep-resentations of humans for downstream tasks like action recognition [24, 2], and intent prediction [25, 31].
Training our current pose estimation algorithms on poses with mixed coarse and fine keypoints presents a challenge as they assume a uniform importance of all keypoints in a pose. We introduce a principled keypoint weighting method to take into account the difference of the importance of coarse and fine-grained keypoints. Figure 1 shows a com-plex person and car poses. For instance, the person pose contains coarse keypoints like the hips and shoulders and fine-grained keypoints like the ones along the eyebrows.
In [12], Jin et al. share a large scale annotation for com-plex human body poses and propose their method, Zoom-Net, that set the state-of-the-art for this type of complex
Figure 1: Our proposed keypoint weighting method for complex poses yields state-of-the-art results for whole body human pose estimation and for complex car poses, whilst running at high frame rates. human body pose. Their method first localizes a person with their major keypoints and then estimates the areas of the hands and face. On the estimated areas, it runs a sepa-rate head that is zoomed-in on that area to determine fine-grained keypoint locations. In contrast, we propose a fast, bottom-up method that directly estimates all keypoints in parallel. Our method does not need predefined areas for fine-grained estimation and, therefore, generalizes to any pose, like a fine-grained car pose. Such a car pose is pro-posed in the ApolloCar3D dataset [35] and we show that our method generalizes to this pose as well.
Complex, coarse and fine-grained poses present a chal-lenge for current pose estimation methods that assume a uniform distribution of keypoints across a person or object.
A cluster of fine-grained keypoints overly emphasizes that region and focuses the neural network optimization on that area reducing the importance of other regions that only have a single keypoint. We propose a method that quantifies how tightly connected these keypoints are and that rebalances the training weights such that all areas of a pose are equally
well connected to the rest of the pose. We introduce the details in Section 3.
Our contributions are (i) a method to weigh the im-portance of keypoints and their connections in complex poses based on graph-based methods for community detec-tion, (ii) an efficient implementation for fine-grained human poses and (iii) generalization from human poses to fine-grained car poses. We show the impact of our contribu-tion with state-of-the-art results on the challenging COCO
WholeBody dataset [12] and the ApolloCar3D dataset [35].
The software is open source and publicly available 1. 2.