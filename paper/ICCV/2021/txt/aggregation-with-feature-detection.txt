Abstract
Aggregating features from different depths of a network is widely adopted to improve the network capability. Lots of modern architectures are equipped with skip connections, which actually makes the feature aggregation happen in all these networks. Since different features tell different seman-tic meanings, there are inconsistencies and incompatibili-ties to be solved. However, existing works na¨ıvely blend deep features via element-wise summation or concatena-tion with a convolution behind. Better feature aggregation method beyond summation or concatenation is rarely ex-plored.
In this paper, given two layers of features to be aggregated together, we first detect and identify where and what needs to be updated in one layer, then replace the fea-ture at the identified location with the information of the other layer. This process, which we call DEtect-rePLAce (DEPLA), enables us to avoid inconsistent patterns while keeping useful information in the merged outputs. Experi-mental results demonstrate our method largely boosts multi-ple baselines e.g. ResNet, FishNet and FPN on three major vision tasks including ImageNet classification, MS COCO object detection and instance segmentation. 1.

Introduction
Representation learning is considered to be the engine for most applications in the field of computer vision. By stacking basic blocks with different connectivities, deep networks can be designed for various tasks, e.g. image clas-sification [15, 18, 46, 34, 35, 16, 48, 25, 7, 45], object de-tection [20, 34] and semantic segmentation [30].
Deep networks [15, 18, 34, 20, 30, 46] that fuses fea-tures from different depths have benefited many applica-tions in computer vision. It is often the case that features from deeper layers are better geared towards the final pre-diction because they contain high-level semantics harvested from large contextual region. However, recent works have found that there may be information loss when forward-propagating data throughout the network [15, 13, 18]. Thus skip connections [15] or dense connections [18] were pro-Figure 1: Brief description of DEPLA. Given an identity feature X and a candidate feature Y, our method could first locate where and what need to be updated in the identity feature X, and then migrate the information from the can-didate feature Y using the learnt locations. posed to consecutively fuse features from previous layers to prevent such loss of information and better leverage the capacity of the network. The above facts indicate that the features at all depths are crucial for building up a network with better performance.
Existing methods [15, 18, 20, 46, 22] however largely focus on features of which layers should be combined, and paid little attention to how to combine them. To the best of our knowledge, state-of-the-art backbones [28, 36] for fea-ture extraction still follow the conventional design in [15].
They use either the element-wise sums to fuse the features together, or a concatenation/convolution [18]. However, as the semantic meaning of different features may vary, net-work activation at the same position but on different feature maps may capture very different information. The afore-mentioned element-wise sum or concatenation cannot dis-cover the inconsistency or the incompatibility between fea-tures during the feature aggregation. A method that can identify which location to aggregate is needed.
In this study, we aim to address this problem by design-ing a pipeline that can learn to detect the most appropriate part of feature for aggregation. As shown in Figure 1, we reformulate the entire feature aggregation process as a two-stage process. Specifically, we first detect where to update, then aggregate the selected locations using the detected fea-1
tures. With our detect-then-aggregate design, the informa-tion retained in the summarized features is only related to the feature within the ROIs, skipping the irrelevant and in-consistent patterns outside the ROIs. The features related to the ROIs of one layer will be finally merged into the features of another layer by Back-Filling Network (BFN). We name the entire module as DEtect-rePLAce (DEPLA) according to the process.
We choose to embed our network into the current preva-lent ResNet [15], SE-ResNet [17], FishNet [34] and the
Feature Pyramid Network [20] to evaluate our method for short-range, long-range and multi-scale feature aggregation.
Experimental results on ImageNet [8] and COCO [21] show that, by simply inserting our module into these baselines, our approach can steadily boost their accuracy on major vision tasks, including image classification, object detec-tion and instance segmentation. Notably, when embedded in ResNet, our method can outperform all other ResNet-based counterparts compared under similar computational complexity. 2.