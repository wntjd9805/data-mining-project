Abstract
Image-to-image translation has been revolutionized with
GAN-based methods. However, existing methods lack the ability to preserve the identity of the source domain. As a result, synthesized images can often over-adapt to the ref-erence domain, losing important structural characteristics and suffering from suboptimal visual quality. To solve these challenges, we propose a novel frequency domain image translation (FDIT) framework, exploiting frequency infor-mation for enhancing the image generation process. Our key idea is to decompose the image into low-frequency and high-frequency components, where the high-frequency fea-ture captures object structure akin to the identity. Our train-ing objective facilitates the preservation of frequency infor-mation in both pixel space and Fourier spectral space. We broadly evaluate FDIT across five large-scale datasets and multiple tasks including image translation and GAN inver-sion. Extensive experiments and ablations show that FDIT effectively preserves the identity of the source image, and produces photo-realistic images. FDIT establishes state-of-the-art performance, reducing the average FID score by 5.6% compared to the previous best method. 1.

Introduction
Image-to-image translation [67, 9, 4, 56, 53] has at-tracted great research attention in computer vision, which is tasked to synthesize new images based on the source and reference images (see Figure 1). This task has been revolutionized since the introduction of GAN-based meth-ods [28, 66]. In particular, a plethora of literature attempts to decompose the image representation into a content space and a style space [11, 45, 37, 26]. To translate a source im-age, its content representation is combined with a different style representation from the reference domain.
Despite exciting progress, existing solutions suffer from
Figure 1:
Image translation results of the Flicker mountains dataset. From left column to right: we show the source images, reference images, the generated images using Swapping Autoen-coder [45] and FDIT (ours), respectively. SwapAE over-adapt to the reference image. FDIT better preserves the composition and identity with respect to the source image. two notable challenges. First, there is no explicit mecha-nism that allows preserving the identity, and as a result, the synthesized image can over-adapt to the reference domain and lose the original identity characteristics. This can be observed in Figure 1, where Swapping Autoencoder [45]
in the frequency domain by applying Fast Fourier Trans-formation (FFT) to each image. This additionally ensures that the original and translated images share a similar high-frequency spectrum.
Extensive experiments demonstrate that FDIT is highly effective, establishing state-of-the-art performance on im-age translation tasks. Below we summarize our key results and contributions:
• We propose a novel frequency-based image translation framework, FDIT, which substantially improves the identity-preserving generation, while enhancing the image hybrids realism. FDIT outperforms competitive baselines by a large margin, across all datasets con-sidered. Compared to the vanilla Swapping Autoen-coder (SwapAE) [45], FDIT decreases the FID score by 5.6%.
• We conduct extensive ablations and user study to eval-uate the (1) identity-preserving capability and (2) im-age quality, where FDIT constantly surpasses previous methods. For example, the user study shows an aver-age preference of 75.40% and 64.39% for FDIT over
Swap AE in the above two aspects. We also conduct the ablation study to understand the efficacy of differ-ent loss terms and frequency supervision modules.
• We broadly evaluate our approach across five large-scale datasets (including two newly collected ones).
Quantitative and qualitative evaluations on image translation and GAN-inversion tasks demonstrate the superiority of our method1. 2.