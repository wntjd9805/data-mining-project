Abstract
Neural painting refers to the procedure of producing a series of strokes for a given image and non-photo-realistically recreating it using neural networks. While reinforcement learning (RL) based agents can generate a stroke sequence step by step for this task, it is not easy to train a stable RL agent. On the other hand, stroke optimization methods search for a set of stroke parame-ters iteratively in a large search space; such low efficiency significantly limits their prevalence and practicality. Dif-ferent from previous methods, in this paper, we formu-late the task as a set prediction problem and propose a novel Transformer-based framework, dubbed Paint Trans-former, to predict the parameters of a stroke set with a feed forward network. This way, our model can generate a set of strokes in parallel and obtain the final painting of size 512 × 512 in near real time. More importantly,
*Equal contribution.
†This work was done when Songhua Liu was an intern at VIS, Baidu. since there is no dataset available for training the Paint
Transformer, we devise a self-training pipeline such that it can be trained without any off-the-shelf dataset while still achieving excellent generalization capability. Experi-ments demonstrate that our method achieves better paint-ing performance than previous ones with cheaper training and inference costs. Codes and models are available on https://github.com/wzmsltw/PaintTransformer. 1.

Introduction
Since ancient times, painting has been a fantastic way for human beings to record what they perceive or even how they imagine about the world. Painting has long been known to require professional knowledge/skills and is not easy for ordinary people. Computer-aided art creation largely fills this gap and enables many of us to create our own artis-tic compositions. Especially with the coming of AI era, natural images can be transformed to be artistic via image style transfer [19, 9, 12, 24, 16] or image-to-image transla-tion [38, 31, 3, 34, 35]. These previous methods typically formulate image creation as an optimization process in the pixel space [5] or a feed-forward pixel-wise image map-ping with neural networks [11, 38]. Nevertheless, different from pixel-wise operations of neural networks, humans cre-ate paintings through a stroke-by-stroke procedure, using brushes from coarse to fine. It is of great potential to make machines imitate such a stroke-by-stroke process to gener-ate more authentic and human-creation-like paintings. Be-sides, it also has the additional benefit of interpreting how a painting can be created step by step, which might be valu-able as a teaching tool. Thus, as an emerging research topic, stroke based neural painting is explored to generate a series of strokes for imitating the way that artistic works are cre-ated by human painters. Hopefully, with such techniques, the generated paintings can look more like real human cre-ated paintings such as oil paint or watercolor.
Generating stroke sequences for painting process is a challenging task even for skilled human painters, especially when the targets have complex compositions and rich tex-tures. To achieve this goal, some previous works tackle this problem by a sequential process of generating strokes one by one, such as recurrent neural networks (RNN) [36, 6], step-wise greedy search [7, 21], and reinforcement learning (RL) [4, 37, 32, 10, 23]. There are also methods [39, 17] tackling this problem via stroke parameter searching using an iterative optimization process. Although attractive paint-ing results are generated by these methods, there still exists large room for improvement on both efficiency and effec-tiveness. Sequence-based methods such as RL are relatively fast in inference but suffer from long training time as well as unstable agents. Meanwhile, optimization-based meth-ods [39, 17] do not need training, but its optimization pro-cess is extremely time consuming. These inconveniences motivate us to explore more efficient and elegant solutions for stroke-based painting generation. Instead of stoke se-quence generation, we re-formulate the neural painting task as a feed-forward stroke set prediction problem. Given an initial canvas and a target natural image, our model predicts a set of strokes and then renders them on the initial canvas to minimize the difference between the rendered image and the target one. This procedure is repeated at K coarse-to-fine scales. At each scale, its initial canvas is the output of the previous scale. As shown in Fig. 1, high-quality final paintings can be generated.
Therefore, the core problem of our method is to train a robust stroke set predictor. Interestingly, object detection is also a typical set prediction problem. We are therefore inspired by recent object detector DETR [2] and propose our novel Paint Transformer to generate painting via pre-dicting parameters of multiple strokes with a feed forward
Transformer. However, different from object detection, no annotated data is available for training a stroke predictor. To overcome such difficulty, we propose a novel self-training pipeline which utilizes synthesized stroke images. Specif-ically, we first synthesize a background canvas image with some randomly sampled strokes; then, we randomly sam-ple a foreground stroke set, and render them on canvas im-age to derive a target image. Thus, the training objective of the stroke predictor is to predict the foreground stroke set and minimize the differences between the synthesized canvas image and the target image, where the optimization is conducted on both stroke level and pixel level. Impres-sively, our self-trained Paint Transformer shows great gen-eralization capability and can work for arbitrary natural im-ages once trained. Extensive experiments demonstrate that our feed-forward method can generate paintings with bet-ter quality at lower cost compared to existing methods. Our contributions can be summarized as:
• We view stroke-based neural painting problem from an innovative perspective of feed-forward stroke set prediction, instead of stroke sequence generation or optimization-based stroke search.
• A novel Paint Transformer tailored for this task is pro-posed with a creative self-training strategy to make it well trained without any off-the-shelf dataset.
• Extensive experiments are conducted to validate our approach and demonstrate that state-of-the-art visual quality is achieved, while maintaining high efficiency. 2.