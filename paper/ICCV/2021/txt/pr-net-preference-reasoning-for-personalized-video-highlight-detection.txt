Abstract
Personalized video highlight detection aims to shorten a long video to interesting moments according to a user’s preference, which has recently raised the community’s at-tention. Current methods regard the user’s history as holis-tic information to predict the user’s preference but negat-ing the inherent diversity of the user’s interests, resulting in vague preference representation. In this paper, we pro-pose a simple yet efficient preference reasoning framework (PR-Net) to explicitly take the diverse interests into account for frame-level highlight prediction. Specifically, distinct user-specific preferences for each input query frame are produced, presented as the similarity weighted sum of his-tory highlights to the corresponding query frame. Next, distinct comprehensive preferences are formed by the user-specific preferences and a learnable generic preference for more overall highlight measurement. Lastly, the degree of highlight and non-highlight for each query frame is calcu-lated as semantic similarity to its comprehensive and non-highlight preferences, respectively. Besides, to alleviate the ambiguity due to the incomplete annotation, a new bi-directional contrastive loss is proposed to ensure a compact and differentiable metric space. In this way, our method sig-nificantly outperforms state-of-the-art methods with a rela-tive improvement of 12% in mean accuracy precision. 1.

Introduction
The short video has become an indispensable medium for people to acquire knowledge and share experiences in their daily lives. However, an unedited video cost minutes or hours for a person to collect meaningful moments by go-ing through the whole video. How to automatically identify the most interesting moments for specific users has recently
*Work done during internship at Tencent Youtu Lab.
†Corresponding author
Figure 1. Considering the diversity of the user’s interests is critical for guiding personalized video highlight detection. For example, if a user is interested in travel, swimming and pets, those query frames that are semantically similar to one of the user’s interests can be marked as the highlight frames. On the other hand, pre-dicting a holistic user’s preference from history will lead to vague preference representation and unsatisfied performance. drawn attention from the research community.
Unlike generic highlight detection methods [41, 13, 40], we focus on personalized video highlight detection, where the user’s previously created historical highlight video seg-ments are used as guidance to detect the interesting mo-ments. To the best of our knowledge, only two methods are proposed to solve this problem. Molino and Gygli [7] directly concatenate the history feature into the input video feature to perform segment level prediction by using a rank-ing model. Rochan et al. [28] introduce a temporal-adaptive instance normalization layer that encodes history for frame-level highlight predictions. Although promising results they achieved, there are still some limitations. Firstly, They re-gard the user’s history as holistic information to predict the user’s preference based on the assumption that there is only one preference in its history. However, it is somehow against common sense in the real world because the user’s interests are inherently diverse. Suppose a user prefers to travel, swimming, pets, et al.
It is not suitable to ex-tract a holistic preference to represent such diverse inter-ests (Fig. 1). Secondly, because there are many repeated or similar shots in a video while only a few positive samples are marked, some unlabeled samples are actually positive.
However, the current methods treat all unlabeled samples as negative ones, leading to the wrong label assignment [5].
In this paper, we propose a preference reasoning frame-work (PR-Net) for frame-level personalized video highlight detection, which overcomes the above limitations.
Intu-itively, if a video frame is semantically similar to one of the user’s history highlights, it could be regarded as an in-teresting moment. Based on this observation, we first at-tend the query frame to history frames to obtain attention weights and then forming the user-specific preference em-bedding by the attention-weighted sum of history frame em-beddings. Considering the generic preference is also an important reference to judge the degree of highlight, espe-cially when the user’s history is missing. We set a learnable generic preference embedding, and it combines the user-specific preference embedding to generate the comprehen-sive preference embedding for more overall highlight detec-tion. In the end, to ensure a more compact and differentiable metric space, a non-highlight preference is used to con-sider the degree of non-highlight for each query frame. We first infer the degree of highlight and non-highlight of each query frame based on the semantic similarity to its com-prehensive preference embedding and non-highlight prefer-ence embedding, respectively. And then constraint the two similarities of all video frames by a new contrastive loss function. Note that we only train those most non-highlight frames as negative samples to alleviate the wrong label as-signment problem.
We conduct the experiments on the PHD-GIF [7] dataset, the only related large-scale dataset for this task. The results show that our method significantly outperforms the state-of-the-art methods, with the relative improvement of 12% in mean accuracy precision.
The contributions of our framework are as follows.
• We propose a novel preference reasoning framework named PR-Net for personalized video highlight detec-tion.
• We propose a novel bi-directional contrastive loss to train a more compact and differentiable metric space for frame-level content understanding.
• Our method significantly outperforms state-of-the-art methods on a large-scale dataset. 2.