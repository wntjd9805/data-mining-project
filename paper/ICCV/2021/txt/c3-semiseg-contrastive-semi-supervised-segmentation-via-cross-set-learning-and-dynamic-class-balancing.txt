Abstract
The semi-supervised semantic segmentation methods uti-lize the unlabeled data to increase the feature discrimina-tive ability to alleviate the burden of the annotated data.
However, the dominant consistency learning diagram is limited by a) the misalignment between features from la-beled and unlabeled data; b) treating each image and re-gion separately without considering crucial semantic de-pendencies among classes.
In this work, we introduce a novel C 3-SemiSeg to improve consistency-based semi-supervised learning by exploiting better feature alignment under perturbations and enhancing the capability of dis-criminative feature cross images. Specifically, we first in-troduce a cross-set region-level data augmentation strat-egy to reduce the feature discrepancy between labeled data and unlabeled data. Cross-set pixel-wise contrastive learn-ing is further integrated into the pipeline to facilitate fea-ture representation ability. To stabilize training from the noisy label, we propose a dynamic confidence region se-lection strategy to focus on the high confidence region for loss calculation. We validate the proposed approach on
Cityscapes and BDD100K dataset, which significantly out-performs other state-of-the-art semi-supervised semantic segmentation methods. 1.

Introduction
Semantic segmentation is a fundamental and challeng-ing problem in the computer vision community and has been studied for the long term. It aims to generate high-resolution pixel-wise categories prediction given an im-age and can be applied to many applications such as au-tonomous driving [39, 51, 9] and medical image analy-*Corresponding Author: xbjxh@live.com sis [36, 53]. Most of the methods enjoy the merit of
Convolutional Neural Networks (CNNs) and improve it by designing specific architectures as well as training strate-gies [26, 36, 5, 43]. However, these data-driven methods depend on the large scale and the high quality of the anno-tated dataset, which becomes a burden to apply in the real world. Regarding limited annotations, the network cannot discern the various appearance within the category and is easily over-fitted to the restricted samples, which results in error prediction in some confusing categories.
Semi-supervised learning aims to utilize datasets that have labels for only a fraction of their samples [18] by learn-ing representation from both labeled and unlabeled data.
The trained network usually has better generalization ability on unseen data than that trained with fully supervised set-ting. Adding consistency regularization is a common way in semi-supervised learning [23, 38, 13]. It encourages the network to generate similar predictions for the same un-labeled image with different augmentation by calculating the difference between outputs as the loss function. Nev-ertheless, previous methods only facilitate the intra-image feature consistency inside the unlabeled dataset. Although both labeled data and unlabeled data are sampled i.i.d. from the same data distribution, it is observed the empirical dis-tribution of labeled data often deviates from the true sam-ples distribution [44], which further leads to the misalign-ment in the feature space [27] and even hurts the perfor-mance [31]. Therefore, reducing the feature misalignment and enhancing feature discriminative ability is crucial for semi-supervised pixel-level recognition.
In this work, we introduce a novel C 3-SemiSeg to allevi-ate those constraints of consistency-based semi-supervised methods by exploiting better feature alignment under per-turbations, and enhancing discriminative of the inter-class features cross images from both labeled and unlabeled set.
Specifically, we adopt the mean teacher networks [38]
into our framework, where each model contains a shared
CNN encoder followed by a segmentation head and a pro-jection head in parallel during training. To fully enjoy the merit of consistency regularisation, we propose the asym-metric data augmentation strategy with the cross-set region-level data mixing that feeds the strong augmented data into the student to match the prediction of weak augmented data from the teacher network. The data mixing method can fur-ther narrow the feature misalignment between labeled and unlabeled data throughout cross-set fusion.
Meanwhile, a pixel-wise contrastive loss is added on both labeled and unlabeled features to simultaneously pro-mote the embedding to be close to that from the same cat-egory while being far away from different categories. The intuition is to enforce the feature compactness within the class and increase the discriminative across classes, simi-lar to [45], but the target scope is different.
[45] only conducts contrastive learning within labeled data, while our method leverages both labeled and unlabeled data. There-fore, our method could not only enhance feature discrimi-native, but also reduce feature misalignment between two sets, and extend the hard negative sampling space. Further-more, to reduce the negative effect brought by noisy predic-tions, we proposed the Dynamic Confident Region Selec-tion (DCRS) to preserve class-balanced samples adaptively with high confidence for network optimization at each step.
We conduct experiments on Cityscapes and BDD100K datasets with different proportions of labeled data to demon-strate the effectiveness of our proposed approach in differ-ent situations. It even closes the performance gap between 1/4 labeled data and fully labeled data by 79%. Our contri-butions can be summarised as follow:
• We propose a novel C 3-SemiSeg framework to improve conventional consistency-based semi-supervised learning by the asymmetric data augmentation with the cross-set region-level data mixing to narrow the feature misalign-ment between labeled and unlabeled data.
• A pixel-wise contrastive learning loss function is pro-posed to enhance inter-class feature discrepancy and inter-class feature compactness across the dataset, with the Dynamic Confident Region Selection module to fur-ther prevent the misleading from noisy predictions.
• Extensive experiments on two autonomous driving dataset, named Cityscapes and BDD100K demonstrates
C 3-SemiSeg outperforms other state-of-the-art methods significantly with all the labeled data ratio. 2.