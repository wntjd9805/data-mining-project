Abstract
Robust face reconstruction from monocular image in general lighting conditions is challenging. Methods com-bining deep neural network encoders with differentiable rendering have opened up the path for very fast monocular reconstruction of geometry, lighting and reflectance. They can also be trained in self-supervised manner for increased robustness and better generalization. However, their dif-ferentiable rasterization-based image formation models, as well as underlying scene parameterization, limit them to
Lambertian face reflectance and to poor shape details.
More recently, ray tracing was introduced for monocu-lar face reconstruction within a classic optimization-based framework and enables state-of-the art results. However, optimization-based approaches are inherently slow and lack robustness. In this paper, we build our work on the afore-mentioned approaches and propose a new method that greatly improves reconstruction quality and robustness in general scenes. We achieve this by combining a CNN en-coder with a differentiable ray tracer, which enables us to base the reconstruction on much more advanced per-*Equal contribution sonalized diffuse and specular albedos, a more sophisti-cated illumination model and a plausible representation of self-shadows. This enables to take a big leap forward in reconstruction quality of shape, appearance and lighting even in scenes with difficult illumination. With consistent face attributes reconstruction, our method leads to prac-tical applications such as relighting and self-shadows re-moval. Compared to state-of-the-art methods, our results show improved accuracy and validity of the approach. 1.

Introduction
Fast and accurate image-based face reconstruction has many applications in several domains including rig based realistic videoconferencing, interactive AR/VR experiences and special effects for professionals like facial attribute manipulation/transfer or relighting. Also, supporting un-constrained pose and in-the-wild capture conditions with-out specific hardware, such as multi-view setup, allows for enhanced flexibility and extended applicability. However, captured images reflect the complex interaction between light and faces including shadows and specularities, which poses a real challenge for face reconstruction. Speed is also
a key factor for interactive scenario and other real-time use cases. Great multi-view approaches exist ([1, 2, 3, 4, 5]), but they may not be easily applied in many applications such as VR or movies / special effects. Significant progress has been made on monocular face reconstruction where most methods resort to some form of parametric prior; high-quality analysis-by-synthesis monocular optimization methods exist ([6, 7, 8]), but besides being rather slow, they would fail for difficult head poses and lighting conditions.
More recently, and to improve this robustness against light-ing conditions, [9] introduced ray tracing for face recon-struction within an optimization-based framework. But the quality of their reconstruction remains sensitive to the land-marks used for initialization.
Real-time analysis-by-synthesis approaches have also been presented, however they often sacrifice reconstruction details. To increase reconstruction efficiency, CNN based approaches ([10, 11, 12, 13]) that directly regress 3D recon-struction parameters from images have been investigated.
To overcome the challenge of creating large amounts of la-beled data, while enabling reconstruction on the basis of meaningful scene parameters, methods combining CNNs with differentiable image formation models trained in a self-supervised way have been presented ([10, 11, 14]). They enable reconstruction performance in the range of millisec-onds, and can be applied to more general scenes and sub-jects ([11, 14]). However, even the best of these highly ef-ficient monocular reconstruction methods fall short of the quality and robustness requirements expected in profes-sional visual effects (VFX) pipelines. They rely on sim-ple parametric diffuse reflectance models based on low-frequency spherical harmonics (SH) illumination model, whereas more detailed models would be needed to recon-struct at the level of quality that is typically required. The inability to model self-shadows is also a prime reason for their instability under challenging scene conditions.
To overcome these limitations, we present a new ap-proach that is the first to jointly provide the following ca-pabilities: it enables monocular reconstruction of detailed face geometry, spatially varying face reflectance and com-plex scene illumination at very high speed on the basis of semantically meaningful scene parameters. To achieve this, our model resorts to a parametric face and scene model that represents geometry using 3DMM statistical model, illumi-nation as high-order spherical harmonics and reflectance model with diffuse and specular components. Our new
CNN-based approach can be trained in a self-supervised way on unlabeled image data. It features a CNN encoder projecting the input image into the parametric scene rep-resentation. We also use an end-to-end differentiable ray tracing image formation model which, in contrast to ear-lier rasterization-based models, provides a more accurate light-geometry interaction and is able to synthesize images with complex illumination accounting for self-shadows. To the best of our knowledge, this is the first time a differen-tiable ray tracer is used for deep-based face reconstruction in an inverse-rendering setup. While ray tracing enables
[9] to improve the state of the art, their method is based on costly and slow iterative optimization and the final re-construction remains sensitive to the quality of the land-marks. Our method overcomes these limitations: it ab-sorbs the complexity of ray tracing at training time, achieves robust and competitive results with near real-time perfor-mance, and, being completely independent of landmarks at test time, is more suitable for in-the-wild conditions.
Finally, with an appropriate training strategy, our method is the first self-supervised method to achieve robust face reconstruction in challenging lighting conditions and cap-tures person-specific shadow-free albedo details (such as facial hair or makeup) not restricted by the 3DMM space.
Our rich and consistent facial attributes reconstruction natu-rally allows various types of applications such as relighting, light/albedo edit and transfer. Our comparison with recent state-of-the-art methods shows improved robustness, accu-racy and versatility of our method. 2.