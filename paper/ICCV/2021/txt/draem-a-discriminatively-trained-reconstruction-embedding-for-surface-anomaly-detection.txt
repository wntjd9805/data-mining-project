Abstract
Visual surface anomaly detection aims to detect local image regions that signiﬁcantly deviate from normal ap-pearance. Recent surface anomaly detection methods rely on generative models to accurately reconstruct the nor-mal areas and to fail on anomalies. These methods are trained only on anomaly-free images, and often require hand-crafted post-processing steps to localize the anoma-lies, which prohibits optimizing the feature extraction for maximal detection capability.
In addition to reconstruc-tive approach, we cast surface anomaly detection primar-ily as a discriminative problem and propose a discrimi-natively trained reconstruction anomaly embedding model (DRÆM). The proposed method learns a joint representa-tion of an anomalous image and its anomaly-free recon-struction, while simultaneously learning a decision bound-ary between normal and anomalous examples. The method enables direct anomaly localization without the need for additional complicated post-processing of the network out-put and can be trained using simple and general anomaly simulations. On the challenging MVTec anomaly detec-tion dataset, DRÆM outperforms the current state-of-the-art unsupervised methods by a large margin and even de-livers detection performance close to the fully-supervised methods on the widely used DAGM surface-defect detection dataset, while substantially outperforming them in localiza-tion accuracy. Code at github.com/VitjanZ/DRAEM. 1.

Introduction
Surface anomaly detection addresses localization of im-age regions that deviate from a normal appearance (Fig-ure 1). A closely related general anomaly detection prob-lem considers anomalies as entire images that signiﬁcantly differ from the non-anomalous training set images. In con-trast, in surface anomaly detection problems, the anomalies occupy only a small fraction of image pixels and are typi-cally close to the training set distribution. This is a particu-Figure 1. DRÆM estimates the decision boundary between the normal an anomalous pixels solely by training on synthetic anoma-lies automatically generated on anomaly-free images (left) and generalizes to a variety of real-world anomalies (right). The re-sult (Mo) closely matches the ground truth (GT). larly challenging task, which is common in quality control and surface defect localization applications.
In practice, anomaly appearances may signiﬁcantly vary, and in applications like quality control, images with anoma-lies present are rare and manual annotation may be overly time consuming. This leads to highly imbalanced training sets, often containing only anomaly-free images. Signiﬁ-cant effort has thus been recently invested in designing ro-bust surface anomaly detection methods that preferably re-quire minimal supervision from manual annotation.
Reconstructive methods, such as Autoencoders [5, 1, 2, 26] and GANs [24, 23], have been extensively explored since they enable learning of a powerful reconstruction sub-space, using only anomaly-free images. Relying on poor re-construction capability of anomalous regions, not observed in training, the anomalies can then be detected by thresh-olding the difference between the input image and its re-synthetic appearance, but rather learns a local-appearance-conditioned distance function between the original and re-constructed anomaly appearance, which generalizes well over a range of real anomalies (see Figure 2, bottom).
To validate our hypothesis, we propose, as our main con-tribution, a new deep surface anomaly detection network, discriminatively trained in an end-to-end manner on syn-thetically generated just-out-of-distribution patterns, which do not have to faithfully represent the target-domain anoma-lies. The network is composed of a reconstructive sub-network, followed by a discriminative sub-network (Fig-ure 3). The reconstructive sub-network is trained to learn anomaly-free reconstruction, while the discriminative sub-network learns a discriminative model over the joint appear-ance of the original and reconstructed images, producing a high-ﬁdelity per-pixel anomaly detection map (Figure 1).
In contrast to related approaches that learn surrogate generative tasks, the proposed model is trained discrimina-tively, yet does not require the synthetic anomaly appear-ances to closely match the anomalies at test time and out-performs the recent, more complex, state-of-the-art meth-ods by a large margin. 2.