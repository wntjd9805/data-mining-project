Abstract
We propose a versatile deep image compression network based on Spatial Feature Transform (SFT) [45], which takes a source image and a corresponding quality map as inputs and produce a compressed image with variable rates. Our model covers a wide range of compression rates using a single model, which is controlled by arbitrary pixel-wise quality maps. In addition, the proposed framework allows us to perform task-aware image compressions for various tasks, e.g., classiﬁcation, by efﬁciently estimating optimized quality maps speciﬁc to target tasks for our encoding net-work. This is even possible with a pretrained network with-out learning separate models for individual tasks. Our al-gorithm achieves outstanding rate-distortion trade-off com-pared to the approaches based on multiple models that are optimized separately for several different target rates. At the same level of compression, the proposed approach suc-cessfully improves performance on image classiﬁcation and text region quality preservation via task-aware quality map estimation without additional model training. The code is available at the project website1. 1.

Introduction
Image compression has been studied actively for decades and has recently become more critical with exploding use of mobile devices for capturing and sharing images. Lossy image compression is a particularly useful technique in this trend since it reduces required space and transmission cost signiﬁcantly at the expense of quality of reconstructed im-ages. The techniques based on deep learning [5, 6, 11, 18, 23–25, 28–31, 43, 46, 47] have started to outperform tra-ditional codecs including JPEG [36], JPEG2000 [42] and
BPG [8]. Many learning-based approaches adopt autoen-coder networks for coding nonlinear transformation and op-timizing rate-distortion trade-off [13]. They have arisen as new candidates for next generation image compression 1https://github.com/micmic123/QmapCompression (a) (b) (c)
Figure 1. The proposed framework. (a) Our compression model takes a quality map as an input along with an image. The com-pression for the image is conditioned on the quality map, which indicates pixel-wise importance. (b) Task-aware compression at test time via non-uniform quality map. One can create a quality map manually or use an output of a pretrained task model (e.g., object detection results). (c) A task-aware quality map from pre-trained models can be estimated at encoding phase by minimizing rate-task loss for the quality map without ﬁne-tuning the models. standards due to their high performance and applicability compared to the traditional hand-engineered codecs.
The rate-distortion optimization in learned lossy image compression methods is realized by minimizing a combined loss function based on compression ratio and distortion be-tween an original and a corresponding output image. For the objective function, most of existing algorithms rely on a uniform compression ratio over image space. However, all pixels in an image are not equally important and a spatially-Figure 2. Compression results with various quality maps using our model. All images are obtained by the same model. Except for uniform quality maps (2nd and 6th column), the quality maps are inferred by optimizing the rate-task loss. The numbers in each quality map denote bits per pixel (bpp)/PSNR (dB)/MS-SSIM/classiﬁcation result of the corresponding reconstructed image. Results by two different uniform maps show that our model adapts well at a wide range of bitrate. The rest of the results show that our model can be adjusted to desired task without additional training of the model. For example, one with classiﬁcation-aware quality map (5th column) only succeeds in classiﬁcation among all reconstructed images with similar bpp, while having the worst PSNR and MS-SSIM. Qualitatively, it maintains the quality of discriminative regions for bird recognition, e.g., an eye, at the expense of the quality in other regions. adaptive image compression by identifying regions of inter-est (ROIs) would be desirable for better performance. On the other hand, existing models are typically optimized for a single target compression rate and their extensions to mul-tiple rates are not straightforward.
This paper introduces a variable-rate image compression network based on an importance map with spatially adap-tive continuous values. Speciﬁcally, we optimize the objec-tive function pertaining to rate-distortion trade-off, where image distortion is constrained by a 2D real-valued qual-ity map that deﬁnes pixel-wise weight for computing mean squared errors (MSEs). The proposed approach employs spatially-adaptive afﬁne transform modules, which perform pixel-wise feature transformations and result in compressed images guided by a quality map. Note that our model en-ables us to compress images with arbitrary compression rates and obtain compressed images with spatially-varying quality given by quality maps. In addition to the ﬂexibility of image compression, we also propose a technique to au-tomatically generate task-aware quality maps by backprop-agation without retraining the models and construct com-pressed images optimized for target tasks.
Compared to the existing adaptive image compression techniques based on variable rates and ROIs [2, 3, 9, 11, 12, 18, 27, 43, 46], the proposed framework is much more ﬂexi-ble and generalizable. The variable-rate models [11, 12, 46] have shown comparable performance with single-rate coun-terparts. However, Yang et al. [46] handle only a few dis-crete levels of compression using an autoencoder. Choi et al. [11] and Cui et al. [12] have proposed continuously variable-rate models, but improper selection of quantiza-tion bin size leads to a degradation of rate-distortion per-formance [11]. More importantly, all of these methods do not consider explicit spatial importance for image compres-sion. A variable-rate approach based on a recurrent neu-ral network (RNN) [18] evaluates the distortion of individ-ual patches in a source image to compute weighted distor-tion. However, it makes the quality of each patch roughly uniform, and realizes spatial adaptiveness by introducing a post-processing for dynamic bit allocation. Minnen et al. [32] allows coarse (per-patch) quality variation, but suf-fers from slow coding speed and low quality compared to recent methods. On the other hand, there exist ROI-based compression methods that reﬂect the given pixel-wise im-portance [2, 3, 9, 27], but they are limited to taking a binary mask and compressing images with predeﬁned discrete lev-els, too.
Figure 1 illustrates the proposed framework for training and inference. The main contributions of our approach are summarized as follows:
• We propose a variable-rate image compression algo-rithm conditioned on a real-valued quality map, which guides an efﬁcient bit allocations across pixels within an input image.
• We design an effective network architecture based on spatially-adaptive feature transform, which takes ad-vantage of spatial information as a prior, for our con-ditioned image compression. Our model even excels the compression performance of ﬁxed-rate models in a practical range of bitrates.
• We introduce a method to estimate task-speciﬁc qual-ity map for image compression at test time. The in-ferred quality maps are efﬁcient to acquire and effec-tive to achieve good performance in the target task.
The rest of the paper is organized as follows. Section 2 reviews related literatures on deep image compression and
Section 3 presents the proposed method in detail. We show experimental results and analysis in Section 4. 2.