Abstract
RGBD (RGB plus depth) object tracking is gaining mo-mentum as RGBD sensors have become popular in many application fields such as robotics. However, the best
RGBD trackers are extensions of the state-of-the-art deep
RGB trackers. They are trained with RGB data and the depth channel is used as a sidekick for subtleties such as occlusion detection. This can be explained by the fact that there are no sufficiently large RGBD datasets to 1) train
“deep depth trackers” and to 2) challenge RGB trackers with sequences for which the depth cue is essential. This work introduces a new RGBD tracking dataset - Depth-Track - that has twice as many sequences (200) and scene types (40) than in the largest existing dataset, and three times more objects (90).
In addition, the average length of the sequences (1473), the number of deformable ob-jects (16) and the number of annotated tracking attributes (15) have been increased. Furthermore, by running the
SotA RGB and RGBD trackers on DepthTrack, we pro-pose a new RGBD tracking baseline, namely DeT, which reveals that deep RGBD tracking indeed benefits from gen-uine training data. The code and dataset is available at https://github.com/xiaozai/DeT. 1.

Introduction
The goal of generic object tracking is to localize an un-known object in a video sequence given its position in the first frame. The most popular tracking modality is color vision in the terms of RGB image frames as the input. Fur-thermore, the problem of visual object tracking (VOT) can be divided into short-term and long-term tracking which are evaluated differently [13, 14]. The short-term evalua-tion protocol focuses on the tracker itself by measuring its accuracy and robustness. If a tracker loses the target, it af-†Equal contribution.
Figure 1: Comparison of the properties of the proposed
DepthTrack and the previous RGBD tracking datasets. fects to the robustness metric, but the tracker is re-initialized and then evaluation continues. In the long-term (LT) proto-col the tracker is not re-initialized and thus the LT track-ers need special procedures for detecting whether the target is present or not and re-detection in the target-not-present operation mode. The two latest VOT challenges [13, 14] include additional tracks for RGBT (RGB plus Thermal in-frared) and RGBD (RGB plus Depth) object tracking. In-terestingly, there are no trackers specialized on thermal fea-tures or depth features, but the top performing RGBT and
RGBD trackers all use RGB features learned by the lead-ing deep tracker architectures, MDNet [22], ATOM [7] and
DiMP [3]. The additional modality T or D is used only as a
“sidekick” to help in various special cases such as occlusion detection. Therefore it remains unclear what are the poten-tial applications of RGBD and RGBT tracking and whether
T and D channels have their own powerful features.
In this work we focus on RGBD tracking. RGBD track-ing has been investigated in a number of recent works (e.g., [11, 12, 17]), but these use conventional RGB and depth features and are inferior to the deep RGB tracker based methods in the VOT 2019 and 2020 RGBD chal-lenges [13, 14]. The top performing trackers in VOT
For example, 2020 RGBD challenge, ATCAIS, DDiMP and CLGS D, are based on the recent deep RGB trackers, ATOM [7],
DiMP [3] and MDNet [22], and use depth only to de-tect occlusion, target disappearance and target re-detection.
There are no “depth trackers” that are trained with depth
The main reason is the lack of suitable sequences. training data. the three existing RGBD datasets, PTB [24], STC [25] and CDTB [18], contain only 100+36+80 sequences. The target and attribute annotations are available only for the STC and CDTB datasets leaving only 116 RGBD tracking sequences for research purposes.
At the same time, the existing RGB tracking datasets, La-SOT [8], TrackingNet [21] and GOT-10k [10], contain 1.55K+30K+10K sequences, i.e. there is more than two or-ders of magnitude difference in the amount of data. To un-veil the power of depth in RGBD tracking, we need larger and more diverse RGBD or depth-only tracking datasets.
In this work, we report a new fully annotated RGBD dataset which is the largest and most diverse of the avail-able datasets in this area. The main contributions are:
• A new annotated dataset - DepthTrack - for RGBD tracking. The dataset is substantially larger than its predecessors and is divided to training and test sets (Fig. 1 and Fig. 2).
• Results and findings from extensive experiments with the SotA RGB and RGBD trackers on DepthTrack.
These findings, including the fusion of RGB and depth features, will facilitate future works on collecting bet-ter RGBD tracking datasets and developing better
RGBD trackers.
• A new RGBD baseline, DeT, that is trained with depth tracking data and obtains better RGBD tracking per-formance than the existing SotA trackers.
DepthTrack RGBD sequences, annotation meta data and evaluation code are made compatible with the VOT 2020
Python Toolkit to make it easy to evaluate existing and new trackers with DepthTrack. 2.