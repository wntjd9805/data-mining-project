Abstract
The performance of computer vision models signiﬁcantly improves with more labeled data. However, the acquisition of labeled data is limited by the high cost. To mitigate the reliance on large labeled datasets, active learning (AL) and semi-supervised learning (SSL) are frequently adopted. Al-though current mainstream methods begin to combine SSL and AL (SSL-AL) to excavate the diverse expressions of un-labeled samples, these methods’ fully supervised task mod-els are still trained only with labeled data. Besides, these method’s SSL-AL frameworks suffer from mismatch prob-lems. Here, we propose a graph-based SSL-AL framework to unleash the SSL task models’ power and make an effec-tive SSL-AL interaction. In the framework, SSL leverages graph-based label propagation to deliver virtual labels to unlabeled samples, rendering AL samples’ structural distri-bution and boosting AL. AL ﬁnds samples near the clusters’ boundary to help SSL perform better label propagation by exploiting adversarial examples. The information exchange in the closed-loop realizes mutual enhancement of SSL and
AL. Experimental results show that our method outperforms the state-of-the-art methods against classiﬁcation and seg-mentation benchmarks. 1.

Introduction
The development of deep learning brings prosperity to the ﬁeld of computer vision [23, 39, 3, 5, 57, 53, 54, 55, 56, 26, 25, 27]. However, these data-hungry models still need to be fed with a large amount of labeled data, the acquisition of which is limited by the expensive cost of annotation [58].
This dilemma between performance and cost brings mas-sive research and practical value to achieve a higher perfor-mance of the task models with limited labeled data.
*Equal contribution.
†Corresponding author. this problem,
With awareness of active learning (AL) [52, 50, 29, 34] is introduced to unleash the poten-tial of labeling procedures for budget-limited annotation.
Despite the progress achieved, most AL algorithms suf-fer from data wasting problems as they ignore that utiliz-ing AL in real-world scenarios means that the majority of data remains unlabeled, which could further empower AL with semi-supervised learning (SSL) in the following three ways: 1) (SSL Task Model) When numerous unlabeled data are used in conjunction with a bunch of labeled data, it is very natural and practical to further improve the per-formance of the task models by SSL without introducing any further annotation cost. 2) (SSL→AL) The success of
SSL [20, 41, 4, 42, 46] proves that it is feasible to improve performance by modeling the relation (intra-class similar-ity and inter-class distinguishability) among samples with
SSL. Thus AL could assess samples’ annotation value more accurately, being guided by the prior knowledge of SSL-modeled relation. 3) (AL→SSL) Since the initial samples’ relations modeled by SSL can hardly be completely cor-rect. AL could conﬁrm precise relations and rectify wrong relations by labeling speciﬁc samples. Finally, the mutual enhancement of AL and SSL is achieved in such a loop.
Although several works combine SSL and AL (SSL-AL) [52, 19, 40], these methods suffer from the two prob-lems: 1) Their fully supervised task models are subjected to data-wasting problems. 2) These works [40, 19, 52] are based on the VAE-GAN structure and conduct AL on the latent representation of samples, which is learned through a mini-max game on samples’ labeling states. As is illustrated in Figure 1, this kind of method suffers from the mismatch problem, which decreases AL’s efﬁciency.
Based on the above insights, we propose a novel gRaph-basEd VIrtual adVersarial Active Learning (REVIVAL) framework for semi-supervised models. The REVIVAL is free of the above two deﬁciencies and realizes the mutual enhancement of AL and SSL. This framework mainly con-with signiﬁcant methods (up to 10% labeling demand reduced). improvement over several SOTA 2.