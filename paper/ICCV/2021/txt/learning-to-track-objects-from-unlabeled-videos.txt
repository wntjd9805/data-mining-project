Abstract
In this paper, we propose to learn an Unsupervised Sin-gle Object Tracker (USOT) from scratch. We identify that three major challenges, i.e., moving object discovery, rich temporal variation exploitation, and online update, are the central causes of the performance bottleneck of existing unsupervised trackers. To narrow the gap between unsu-pervised trackers and supervised counterparts, we propose an effective unsupervised learning approach composed of three stages. First, we sample sequentially moving objects with unsupervised optical flow and dynamic programming, instead of random cropping. Second, we train a naive
Siamese tracker from scratch using single-frame pairs.
Third, we continue training the tracker with a novel cy-cle memory learning scheme, which is conducted in longer temporal spans and also enables our tracker to update on-line. Extensive experiments show that the proposed USOT learned from unlabeled videos performs well over the state-of-the-art unsupervised trackers by large margins, and on par with recent supervised deep trackers. Code is available at https://github.com/VISION-SJTU/USOT. 1.

Introduction
Visual object tracking is one of the most fundamental computer vision tasks with numerous applications, such as autonomous driving, intelligent surveillance, robot, and human-computer interaction. The past few years have witnessed considerable progress in visual object tracking, thanks to the powerful representation of deep learning. In spite of the success, the state-of-the-art deep tracking algo-rithms are data-hungry, requiring a huge number of anno-tated data for supervised training. As manually labeled data are expensive and time-consuming, exploiting ubiquitous unlabeled videos for visual tracking has drawn increasing attention recently. Following the classic pipeline of unsu-pervised learning, existing unsupervised trackers randomly crop template regions on unlabeled videos and employ ei-* Corresponding author.
Figure 1: Comparison on the VOT2017/18 benchmark with recent deep trackers. The proposed trackers, USOT and
USOT*, perform well over the state-of-the-art unsupervised deep trackers, including LUDT [38], LUDT+ [38], and
S2SiamFC [34], and on par with recent supervised trackers.
Notation: SiamFC [2], SiamDW [47], SiamRPN [26], C-RPN [12], DaSiamRPN [50], ATOM [8], SiamRPN++ [25],
DiMP [3], KYS [4]. ther self consistency [34] or cycle consistency [37] as a pre-text task for learning to track. Despite the promising results, there still exists a large performance gap between unsuper-vised and supervised trackers. In view of the great success of unsupervised learning on a number of other vision tasks, such as video object segmentation [23], optical flow [28] and depth estimation [14], it is of great interest to narrow the gap between unsupervised and supervised trackers.
We identify three critical challenges that cause the per-formance bottleneck of unsupervised trackers. 1) Mov-ing object discovery. As ground truth bounding boxes are not available, existing unsupervised trackers randomly sam-ple regions in frames as pseudo templates [37, 34]. Ran-dom samples are far from precisely locating objects, not to mention learning to distinguish between objects and back-ground. Moreover, as random samples do not contain clear edges of objects, they are not suitable for bounding box re-gression learning. The lack of bounding box regression for scale change estimation heavily limits the performance of unsupervised trackers. 2) Rich temporal variation exploita-tion. Due to the lack of labels in the temporal span, exist-ing unsupervised trackers struggle to learn from rich motion clues. For example, UDT [37] performs forward and back-ward tracking within at most 10 frames.
In such a short clip, the foreground objects show highly correlated appear-ances with little variations, causing a failure to exploit rich temporal variations over a long span for training. 3) Online update. Online update helps to exploit the temporal smooth-ness and has demonstrated great success in leading super-vised tracking methods [35, 3, 46, 48]. While supervised trackers usually collect multiple object samples in separated frames for learning online modules [3, 13], it is more chal-lenging to train online branches for unsupervised trackers, due to lack of even coarse object locations in videos.
To address these challenges, we propose to train a robust tracker from unlabeled videos. First, for data preparation, we develop a sequential box sampling algorithm to coarsely discover moving objects from unlabeled videos. Specifi-cally, we use unsupervised optical flow to detect moving ob-jects and apply dynamic programming to sequentially link candidate boxes. Second, we naively train from scratch an unsupervised Siamese tracker using single-frame pairs.
That is, we train with each Siamese pair cropped based on the sampled box in a single frame. Despite its simplicity, we show that this strategy provides a great initialization for the unsupervised tracker, thus beneficial to future training in longer temporal spans. Third, we propose a cycle mem-ory learning scheme to continue training the naive tracker.
Specifically, we divide the whole video into a number of fragments according to the detected moving object trajec-tory. We then conduct forward tracking from a single frame to several other frames in the same fragment, and store all intermediate tracking results in a memory queue. We then track backward to the initial frame to compute the consis-tency loss. Since the length of video fragments is quite long (averaged 64.6 frames on VID [33]) compared with
UDT [37] (<10 frames), our tracker can capture large mo-tion and appearance variations. More importantly, the pro-posed cycle memory scheme allows updating the memory queue online for model update (see Sec. 4.3).
We evaluate the proposed unsupervised tracker on six large-scale benchmarks. Extensive experiments show that our proposed tracker performs well over the state-of-the-art unsupervised trackers by large margins, and on par with the recent supervised trackers (see Fig. 1). The main contribu-tions of this work are summarized as follows:
• We coarsely discover moving objects from unlabeled videos for unsupervised learning.
• We train a naive Siamese tracker with single-frame pairs and gradually extend it to longer temporal spans.
• We propose a cycle memory learning scheme, allowing unsupervised trackers to update online. 2.