Abstract
Bicubic downscaling is a prevalent technique used to re-duce the video storage burden or to accelerate the down-stream processing speed. However, the inverse upscaling step is non-trivial, and the downscaled video may also dete-riorate the performance of downstream tasks. In this paper, we propose a self-conditioned probabilistic framework for video rescaling to learn the paired downscaling and upscal-ing procedures simultaneously. During the training, we de-crease the entropy of the information lost in the downscal-ing by maximizing its probability conditioned on the strong spatial-temporal prior information within the downscaled video. After optimization, the downscaled video by our framework preserves more meaningful information, which is beneﬁcial for both the upscaling step and the downstream tasks, e.g., video action recognition task. We further ex-tend the framework to a lossy video compression system, in which a gradient estimator for non-differential industrial lossy codecs is proposed for the end-to-end training of the whole system. Extensive experimental results demonstrate the superiority of our approach on video rescaling, video compression, and efﬁcient action recognition tasks. 1.

Introduction
High-resolution videos are widely used over various computer vision tasks [44][62][7][35][33][50][64]. How-ever, considering the increased storage burden or the high computational cost, it is usually required to ﬁrst downscale the high-resolution videos. Then we can either compress the output low-resolution videos for saving storage cost or feed them to the downstream tasks to reduce the computa-tional cost. Despite that this paradigm is prevalent, it has the following two disadvantages. First, it is non-trivial to restore the original high-resolution videos from the (com-pressed) low-resolution videos, even we use the latest super-resolution methods [30, 63, 48, 57]. Second, it is also a challenge for the downstream tasks to achieve high perfor-mance based on these low-resolution videos. Therefore,
∗Corresponding author. it raises the question that whether the downscaling opera-tion can facilitate the reconstruction of the high-resolution videos and also preserve the most meaningful information.
Recently, this question has been partially studied as a single image rescaling problem [24, 27, 47, 60], which learns the down/up scaling operators jointly. However, how to adapt these methods from image to video domain and leverage the rich temporal information within videos are still open problems. More importantly, modeling the lost information during downscaling is non-trivial. Curren-t methods either ignore the lost information [24, 27, 47] or assume it as an independent distribution in the latent space [60], while neglecting the internal relationship be-tween the downscaled image and the lost information. Be-sides, all literature above has not explored how to apply the rescaling technique to the lossy image/video compression.
In this paper, we focus on building a video rescal-ing framework and propose a self-conditioned probabilistic learning approach to learn a pair of video downscaling and upscaling operators by exploiting the information depen-dency within the video itself. Speciﬁcally, we ﬁrst design a learnable frequency analyzer to decompose the original high-resolution video into its downscaled version and the corresponding high-frequency component. Then, a Gaus-sian mixture distribution is leveraged to model the high-frequency component by conditioning on the downscaled video. For accurate estimation of the distribution param-eters, we further introduce the local and global temporal aggregation modules to fuse the spatial information from adjacent downscaled video frames. Finally, the original video can be restored by a frequency synthesizer from the downscaled video and the high-frequency component sam-pled from the distribution. We integrate the components above as a novel self-conditioned video rescaling frame-work termed SelfC and optimize it by minimizing the neg-ative log-likelihood for the distribution.
Furthermore, we apply our proposed SelfC in two prac-tical applications, i.e., lossy video compression and video action recognition.
In particular, to integrate our frame-work with the existing non-differential video codecs (e.g.,
H.264 [59] and H.265 [46]), we propose an efﬁcient and ef-fective one-pass optimization strategy based on the control variates method and approximate the gradients of tradition-al codecs in the back-propagation procedure, which formu-lates an end-to-end optimization system.
Experimental results demonstrate that the proposed framework achieves state-of-the-art performance on the video rescaling task. More importantly, we further demon-strate the effectiveness of the framework in practical appli-cations. For the lossy video compression task, compared with directly compressing the high-resolution videos, the video compression system based on our SelfC framework cuts the storage cost signiﬁcantly (up to 50% reduction).
For the video action recognition task, our framework re-duces more than 60% computational complexity with negli-gible performance degradation. In summary, our main con-tributions are:
• We propose a probabilistic learning framework dubbed
SelfC for the video rescaling task, which models the lost information during downscaling as a dynamic dis-tribution conditioned on the downscaled video.
• Our approach exploits rich temporal information in downscaled videos for an accurate estimation of the distribution parameters by introducing the speciﬁed lo-cal and global temporal aggregation modules.
• We propose a gradient estimation method for non-differential lossy codecs based on the control variates method and Monte Carlo sampling technique, extend-ing the framework to a video compression system. 2.