Abstract
In many computer vision problems, it is desired to learn the effective visual data similarity such that the prediction accuracy can be enhanced. Deep Metric Learning (DML) methods have been actively studied to measure the data similarity. Pair-based and proxy-based losses are the two major paradigms in DML. However, pair-wise methods in-volve expensive training costs, while proxy-based methods are less accurate in characterizing the relationships be-tween data points. In this paper, we provide a hybrid grou-plet paradigm, which inherits the accurate pair-wise rela-tionship in pair-based methods and the efficient training in proxy-based methods. Our method also equips a non-Euclidean space to DML, which employs a hierarchical rep-resentation manifold. More specifically, we propose a uni-fied graph perspective — different DML methods learn dif-ferent local connecting patterns between data points. Based on the graph interpretation, we construct a flexible subset of data points, dubbed grouplet. Our grouplet doesn’t re-quire explicit pair-wise relationships, instead, we encode the data relationships in an optimal transport problem re-garding the proxies, and solve this problem via a differen-tiable implicit layer to automatically determine the relation-ships. Extensive experimental results show that our method significantly outperforms state-of-the-art baselines on sev-eral benchmarks. The ablation studies also verify the effec-tiveness of our method. 1.

Introduction for many machine vision tasks,
Learning the semantic similarity between visual data includ-is important ing clustering [49], image retrieval [25, 34], person re-identification [48, 8], and few-shot learning [36, 33]. Con-ventionally, the Mahalanobis distance [24, 46] defined on hand-crafted features are exploited to characterize the data
Figure 1: Top: Bounds of different colors indicate images from different clusters. Our method employs grouplet (yel-low shaded), which can be viewed as randomly split of im-ages in a batch. Bottom: Inside a grouplet, we determine the data-wise relationships dynamically via optimal trans-port. Different colors indicate different clusters. All pairs of data (circles with numbers) and proxy (circles with letters) are evaluated via jointly considering the data-wise relation-ships (e.g. automatically determine that (1, 2) is a positive pair, and (2, 3) is negative). Data embeddings are pulled (inner arrow) or pushed (outer arrow) harder to/away from the proxies if mismatched, e.g. (3, a) is well distributed, and the push is weak (thin line); (4, c) is badly distributed, which leads to a harsh push (thick line). similarity. Boosted by the emerging advance of deep rep-resentation learning, refined distance metrics [17, 39] are proposed in recent works to accurately capture the geomet-ric structure of data embeddings.
*This work was partially supported by NSF IIS 1845666, 1852606, 1838627, 1837956, 1956002, IIA 2040588.
Existing supervised DML methods can be categorized into two paradigms, pair-based methods and proxy-based
methods. Pair-based methods, e.g. contrastive loss [9, 4] and triplet loss [43, 32], consider pairwise relationships between data points.
In detail, a pair of data with the same label is positive, otherwise negative. Pair-based losses then define some rules to select the tuples of pairs and learn the data relationships inside these pairs. To acceler-ate the training, sampling techniques detecting informative tuples are frequently utilized in pair-based methods. Alter-natively, proxy-based methods, e.g. Proxy NCA [25] and soft triplet [31] introduce proxies to summarize subsets of training data and learn the data-wise relationship indirectly, through the data-proxy relationship. Proxy-based methods resolve the complexity issue in pair-based methods.
Though pair-based and proxy-based paradigms each have their own merits, both paradigms, however, have some intrinsic drawbacks. In pair-based methods, the training re-quires explicit pair relationships. An obvious advantage is that the local structures are evaluated more accurately. Nev-ertheless, in pair-based losses, the candidate training sam-ples are composed of all valid combinations of data points (e.g. the number of training samples in contrastive loss [9] is the square of total data numbers), which substantially in-creases the training time. On the other hand, the training of proxy-based methods is based on individual data samples, which enjoys significantly better computational efficiency compared to pair-based methods. However, the data rela-tionships learned in proxy-based methods are estimated and bounded through proxies. This indicates encoding may re-sult in sub-optimal embedding manifolds.
To address the above problems, in this paper we propose a hybrid grouplet paradigm for non-Euclidean deep metric learning, which can be viewed as evaluating enlarged bipar-tite subgraphs consisting of multiple data points (dubbed grouplet) and proxies (Fig. 1). Our grouplet is free of ex-plicit pair construction and doesn’t require exhausting all combinations of data points. The data-wise relationships are dynamically determined via a constrained optimal trans-port layer. To further exploit the hierarchical structure of proxies and data points, we resort to a non-Euclidean em-bedding space and the associated similarity. Our contribu-tions can be summarized as follows,
• We provide a graph perspective for deep metric learning, which generalizes two major DML paradigms, pair-based and proxy-based methods (Fig. 2).
• We formulate a grouplet deep metric learning method, which inherits the accurate estimation for pair-wise rela-tionship from pair-based methods, and the efficient com-putation from proxy-based methods.
• We propose to learn non-Euclidean embeddings and the associated embedding-proxy similarity.
The ablation study demonstrates the effectiveness of our method.
Notations: Throughout the paper, the bold capital and bold lowercase symbols are used to represent matrices and vec-tors, respectively. A ≥ 0 denotes that elements of a matrix
A are greater than or equal to 0. G = {V, E} represents a graph with node set V and edge set E. A n × n-identity matrix is denoted by In, 1n is a n-dimension one vector, and 0 denotes a zero matrix. 2.