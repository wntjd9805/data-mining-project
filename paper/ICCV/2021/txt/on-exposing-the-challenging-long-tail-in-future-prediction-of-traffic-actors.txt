Abstract
Predicting the states of dynamic traffic actors into the fu-ture is important for autonomous systems to operate safely and efficiently. Remarkably, the most critical scenarios are much less frequent and more complex than the uncritical ones. Therefore, uncritical cases dominate the prediction.
In this paper, we address specifically the challenging sce-narios at the long tail of the dataset distribution. Our anal-ysis shows that the common losses tend to place challeng-ing cases sub-optimally in the embedding space. As a con-sequence, we propose to supplement the usual loss with a loss that places challenging cases closer to each other. This triggers sharing information among challenging cases and learning specific predictive features. We show on four pub-lic datasets that this leads to improved performance on the challenging scenarios while the overall performance stays stable. The approach is agnostic w.r.t. the used network architecture, input modality or viewpoint, and can be inte-grated into existing solutions easily. Code is available at github. 1.

Introduction
Future prediction in traffic scenarios aims to foresee the future location of dynamic actors based on their current and previous locations and possibly other information about the environment. For an actor in interaction with others, rea-soning about possible future locations of the other actors is necessary for path planning and to avoid collisions. Given enough data, some recent prediction methods [48, 60, 47] also not just predict a single location of the actor in the fu-ture but a multimodal distribution over possible future loca-tions.
The average prediction errors of such methods look promising, but they hide that the training and test data is dominated by simple scenarios, where the trajectory can be smoothly propagated into the future. Such scenarios can be handled with a simple Kalman filter or other autoregres-sive models. However, the most safety-critical scenarios are those that involve close-by dynamic obstacles and require
Figure 1. Histogram of the ETH-UCY dataset based on the diffi-culty of the sample (based on displacement error of a Kalman fil-ter [31]). An easy scenario (belongs to the head blue class) and a challenging scenario (belongs to the tail red class) are shown along the prediction of the state-of-the-art (Traj++ EWTA) and our ap-proach. Our approach targets those challenging scenarios (from the tail) and improves their performance while maintaining a good performance on the easy scenarios. an evasive maneuver. Such scenarios are rare in both the training and the test data. The more complex and safety-critical they are, the less frequent they are. Fatal cases with a collision are not part of the dataset at all.
As an example, the ETH-UCY dataset is often used to benchmark methods for future trajectory prediction.
It is considered a challenging dataset, as it includes interacting pedestrians in crowded scenes. Figure 1 shows the his-togram of samples in this dataset based on their difficulty approximated by the prediction error of a Kalman filter. The large majority of scenarios can be well modeled by linear extrapolation, whereas scenarios that require more complex modeling are rare. The depicted challenging scenario show-cases a pedestrian (red box), who will turn right in the future to avoid a collision with the stationary pedestrians (black boxes) in front of them.
In this paper, we explicitly address the long-tailed data distribution in future prediction and focus on the rare but important cases rather than the average case. Straightfor-ward ideas to re-distribute the dataset by undersampling the frequent scenarios [20, 27] or by reweighting the loss for these samples [13] are not viable solutions, since it would reduce the (effective) data size dramatically. One can also oversample the challenging scenarios during training
[26, 36], yet this repetition of the same rare samples leads to overfitting and does not perform well, as we show in our experiments. Some works have tried to simulate rare cases
[43, 42]. However, to-date, even the most realistic simu-lations suffer from the domain gap between the simulated and the real world. An interesting direction for dealing with imbalanced data has been presented by Cao et al., who pro-posed a loss that ensures larger margins for the minority [5].
We pick up this general idea and propose to reshape the feature embedding of the predictor. We show in a de-tailed analysis of the feature space that, with the usual loss, the challenging examples get placed next to many normal cases. Consequently, the relevant information of these sam-ples gets smoothed out. As we push the challenging sce-narios to be in proximity in the embedding, more of these samples that share a similar scenario build a small cluster and are no longer ignored. With this approach we can pre-dict the future trajectory of interacting pedestrians better; see blue trajectory in Figure 1.
Our contributions can be briefly summarized as follows. (1) We analyze the problem of long-tailed data distributions in future prediction for the first time. (2) We propose a novel joint optimization of the regular regression loss for predict-ing the future location and a loss that reshapes the feature embedding in favor of the long-tail samples. (3) We show that multi-headed networks outperform cVAEs in address-ing the multimodal nature of the future.
The proposed approach is easy to integrate into existing approaches, since it is agnostic to the network architecture, viewpoint, and input modalities. We demonstrate this by evaluating on four diverse public datasets. On each of them, the method improves the prediction quality of the challeng-ing cases, while maintaining the quality on simple cases. 2.