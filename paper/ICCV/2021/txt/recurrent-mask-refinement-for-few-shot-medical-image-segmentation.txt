Abstract
Although having achieved great success in medical im-age segmentation, deep convolutional neural networks usu-ally require a large dataset with manual annotations for training and are difficult to generalize to unseen classes.
Few-shot learning has the potential to address these chal-lenges by learning new classes from only a few labeled ex-In this work, we propose a new framework for amples. few-shot medical image segmentation based on prototypical networks. Our innovation lies in the design of two key mod-ules: 1) a context relation encoder (CRE) that uses corre-lation to capture local relation features between foreground and background regions; and 2) a recurrent mask refine-ment module that repeatedly uses the CRE and a prototypi-cal network to recapture the change of context relationship and refine the segmentation mask iteratively. Experiments on two abdomen CT datasets and an abdomen MRI dataset show the proposed method obtains substantial improvement over the state-of-the-art methods by an average of 16.32%, 8.45% and 6.24% in terms of DSC, respectively. Code is publicly available 1. 1.

Introduction
Medical image segmentation is a fundamental task in medical image analysis.
It is used in many clinical ap-plications, including disease diagnosis, treatment planning and treatment delivery. Segmentation of anatomical struc-tures or lesions is usually done manually by experienced doctors, which is often tedious and labor-intensive. With the recent use of deep convolutional neural networks, au-tomated segmentation tools using computer programs can achieve near human accuracy on multiple tasks with very short processing time. However, in order to achieve good performance, these systems are usually trained in a fully supervised fashion with large amounts of annotated data.
Acquiring a dataset with abundant manual labels is often 1https://github.com/uci-cbcl/RP-Net very expensive and time-consuming as it requires experts with many yearsâ€™ clinical experience. Moreover, the differ-ences in image acquisition protocols among different med-ical equipment and institutes pose great challenges to the generalization ability of the learning based systems.
Few-shot learning has been proposed as one of the po-tential solutions to addressing these challenges in the low data regime [43, 46, 56, 8, 22]. The main few-shot image segmentation approach forms the problem as meta learn-ing [9, 10, 16] and uses supervised learning to train few-shot learning models. A few-shot learning model is trained to extract class-specific features from the set of support images with annotations, and then perform segmentation on the query images by using distilled knowledge from the support images. During test time, by extracting fea-tures from a set of new support images (unseen classes), the model is able to segment novel classes. Many few-shot learning methods have been proposed and achieved great performance on natural image segmentation tasks
[33, 39, 6, 41, 59, 67, 66, 62, 17]. However, applying few-shot learning models for medical image segmentation is still in early stages [31, 36].
Few-shot segmentation in medical images is different than that in natural images. Many approaches are based on prototypical networks [43], and often apply masked av-erage pooling [6, 59, 67] to extract class prototypes from feature maps within the foreground mask. This step usu-ally assumes the masked region contains sufficient features to distinguish different classes, especially foreground and background. However, this may not always be true in med-ical images. Distinct local appearances and context infor-mation are more critical in determining the boundary for foreground and background. A clear boundary to separate regions of interest from the background is of critical impor-tance in medical image segmentation. Moreover, the back-ground is usually large and spatially inhomogeneous while the foreground is small and homogeneous [30], and there exists the abundance of tissues that share very similar ap-pearance to each other, all of which add ambiguity to define the foreground and background regions. To address this is-sue, we encourage the network to explicitly model the con-text relationship between foreground and background pix-els, especially pixels around the boundary.
In this work, we introduce a new network framework for few shot medical image segmentation using prototypical network (RP-Net: Recurrent Prototypical Networks). First, we propose a context relation encoder (CRE) on top of the extracted features, to explicitly model the relation between foreground and background feature maps. The relationships between foreground and background regions are more im-portant in defining the boundary of the regions of interest in medical image segmentation. To force the model to distill and utilize the local context relation information, CRE uses correlation to capture the differences in the foreground and background regions. Pixel features are augmented with the context relation features. The explicit extraction of the con-text relationship poses a strong constraint to the features the model would learn and forces it to focus on the boundary of the region of interest. A prototypical network is followed to produce predicted masks using these augmented features.
Second, we propose a recurrent mask refinement mod-ule that iteratively refines the segmentation using CRE and prototypical networks. This design draws inspiration from recent works [53, 32, 18] that employ iterative refinement.
More importantly, the prediction mask modifies the mask in the previous step, which results in updated local context relationship. The recurrent module serves the purpose to re-capture the updated context relationship and recompute its context relationship based on new prediction. Starting from the segmentation mask from the previous step, the model uses the refined prediction mask in the previous step to com-pute new context features using CRE, and then feeds it to the same prototypical network. The weights of the module are shared among multiple iterations so it is fully recurrent.
This recurrent module facilitates the learning and forces the model to learn to gradually refine the segmentation.
Our contributions are summarized as:
- A context relation encoder (CRE) that uses correlation between foreground and background to enhance context re-lationship features around the object boundary.
- A new framework for few-shot medical image segmen-tation that iteratively refines the prediction mask through a recurrent module that uses CRE and prototypical networks.
- We conducted experiments on two abdomen CT datasets and one abdomen MRI dataset. Experiments show that the proposed framework outperforms the SOTA few-shot framework for medical image segmentation by an av-erage of 16.32% on ABD-110 dataset [49], 8.45% on MIC-CAI15 Multi-Atlas Abdomen Labeling challenge dataset
[23] and 6.24% on ISBI 2019 Combined Healthy Abdomi-nal Organ Segmentation Challenge [21] in terms of DSC. 2.