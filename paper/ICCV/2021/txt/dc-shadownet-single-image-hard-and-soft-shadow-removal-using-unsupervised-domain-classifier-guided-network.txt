Abstract
Shadow removal from a single image is generally still an open problem. Most existing learning-based methods use supervised learning and require a large number of paired images (shadow and corresponding non-shadow im-ages) for training. A recent unsupervised method, Mask-ShadowGAN [13], addresses this limitation. However, it requires a binary mask to represent shadow regions, mak-ing it inapplicable to soft shadows. To address the problem, in this paper, we propose an unsupervised domain-classifier guided shadow removal network, DC-ShadowNet. Specif-ically, we propose to integrate a shadow/shadow-free do-main classifier into a generator and its discriminator, en-abling them to focus on shadow regions. To train our net-work, we introduce novel losses based on physics-based shadow-free chromaticity, shadow-robust perceptual fea-tures, and boundary smoothness. Moreover, we show that our unsupervised network can be used for test-time train-ing that further improves the results. Our experiments show that all these novel components allow our method to handle soft shadows, and also to perform better on hard shadows both quantitatively and qualitatively than the existing state-of-the-art shadow removal methods. 1.

Introduction
Shadow removal from a single image can benefit many applications, such as image editing, scene relighting, etc.,
[19, 17, 16]. Unfortunately, in general, removing shad-ows from a single image is still an open problem. Exist-ing physics-based methods for shadow removal [7, 6, 10] are based on entropy minimization that can capture the in-variant features of shadow and non-shadow regions belong to the same surfaces in the log-chromaticity space. These methods, however, tend to fail, particularly when the image surfaces are close to achromatic (e.g. gray or white sur-faces), and are not designed to handle soft shadow images.
â€ This work is supported by MOE2019-T2-1-130. (a) Input Image (b) Ground Truth (c) Mask-ShadowGAN [13] (d) Our DC-ShadowNet
Figure 1. Exiting state-of-the-art shadow removal methods like
Mask-ShadowGAN [13] fail to remove soft shadows properly and create artifacts (see regions inside red boxes). Compared to it, our method generates a better shadow-free output.
Unlike physics-based methods, deep-learning methods,
[24, 27, 14, 20, 1, 21], are more robust to different e.g. conditions of image surfaces and lighting. However, most of these methods are based on fully-supervised learning, which means that for training, they require pairs of shadow and their corresponding non-shadow images. To collect these image pairs in a large amount, particularly for images containing diverse scenes and shadows can be considerably expensive.
Recently, Hu et al. propose an unsupervised method,
Mask-ShadowGAN [13], the network architecture of which is based on CycleGAN [34]. To remove shadows, the method mainly relies on adversarial training that employs
a discriminator to check the quality of the generated out-put. Unfortunately, due to the absence of ground truth, the discriminator relies solely on unpaired non-shadow im-ages, which can cause the generator to produce incorrect outputs. Moreover, the method uses a binary mask to rep-resent shadow regions present in the input image, making it inapplicable to soft shadow images. Fig. 1 shows an exam-ple where for the given soft-shadow input image, the output generated by the method [13] is improper.
In this paper, our goal is to remove both hard and soft shadows from a single image. To achieve this, we pro-pose DC-ShadowNet, an unsupervised network guided by the shadow/shadow-free domain classifier. Specifically, we integrate a domain classifier (that classifies the input image to either shadow or shadow-free domain) into our gener-ator and its corresponding discriminator. This allows our generator and discriminator to focus on shadow regions and thus perform better shadow removal. Unlike the ex-isting unsupervised method [13], which only relies on ad-versarial training based on an unpaired discriminator (i.e. using unpaired non-shadow images as reference images), our method uses additional novel unsupervised losses that enable our method to achieve better shadow removal re-sults. Our new losses are based on physics-based shadow-free chromaticity, shadow-robust perceptual features, and boundary smoothness.
Our physics-based shadow-free chromaticity loss em-ploys a shadow-free chromaticity image, which is obtained from the input shadow image by performing entropy min-imization in the log-chromaticity space [7]. Our shadow-robust perceptual features loss uses shadow-robust features obtained from the input shadow image using the pre-trained
VGG-16 network [15]. We also add a boundary smooth-ness loss to ensure that our output shadow-free image has smoother transitions in the regions that contained shadow boundaries. All these ideas enable our method to better deal with hard and soft shadow images compared to exist-ing methods like [13] (see Fig. 1 for an example showing the better performance of our method). Furthermore, we show that our method being unsupervised can be used for test-time training to further improve the performance of our method. As a summary, here are our contributions: 1. We introduce DC-ShadowNet, a new unsupervised single-image shadow removal network guided by a do-main classifier to focus on shadow regions. 2. We propose novel unsupervised losses based on physics-based shadow-free chromaticity, shadow-robust perceptual features, and boundary smoothness losses for robust shadow removal. 3. To our knowledge, our method is the first unsupervised method to perform shadow removal robustly for both hard and soft shadow in a single image. 2.