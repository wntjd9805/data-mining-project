Abstract
Many recent developments in facial landmark detection have been driven by stacking model parameters or aug-menting annotations. However, three subsequent challenges remain, including 1) an increase in computational over-head, 2) the risk of overﬁtting caused by increasing model parameters, and 3) the burden of labor-intensive annota-tion by humans. We argue that exploring the weaknesses of the detector so as to remedy them is a promising method of robust facial landmark detection. To achieve this, we propose a sample-adaptive adversarial training (SAAT) ap-proach to interactively optimize an attacker and a detec-tor, which improves facial landmark detection as a defense against sample-adaptive black-box attacks. By leveraging adversarial attacks, the proposed SAAT exploits adversar-ial perturbations beyond the handcrafted transformations to improve the detector. Speciﬁcally, an attacker gener-ates adversarial perturbations to reﬂect the weakness of the detector. Then, the detector must improve its robust-ness to adversarial perturbations to defend against adver-sarial attacks. Moreover, a sample-adaptive weight is de-signed to balance the risks and beneﬁts of augmenting ad-versarial examples to train the detector. We also intro-duce a masked face alignment dataset, Masked-300W, to evaluate our method. Experiments show that our SAAT performed comparably to existing state-of-the-art methods.
The dataset and model are publicly available at https:
//github.com/zhuccly/SAAT. 1.

Introduction
Recently, facial landmark detection has been signiﬁ-cantly improved by many works [36, 41, 42, 46, 51]. To achieve new breakthroughs, researchers proposed multi-stage stacked networks [3, 12, 25, 10, 24, 28, 40]. Methods such as [12, 25] use the two-stage architecture to regress
In [35, 28], the facial shape in a coarse-to-ﬁne manner.
*Corresponding author.
Insight of the proposed SAAT. The attacker generates
Figure 1. adversarial perturbations to fool the detector, and the detector then learns to defend against attacks. the multi-stage stacked hourglass networks (SHG) are em-ployed to predict the landmark heatmaps. In [19, 24, 40], the additional sub-networks are equipped into the multi-stage stacked hourglass networks to improve the ﬁtting per-formance further. Although the increasing number of model parameters leads to breakthroughs, the redundant parame-ters may raise the risk of these models overﬁtting on the training dataset, especially in small datasets that their data distributions are usually unbalanced [4, 31]. Even the data distribution of existing large-scale datasets may be unbal-anced. For example, 300VW dataset [33] contains 95, 192 training frames. However, these frames are only collected from 50 videos containing 44 different persons under 34 scenes. Because this dataset is large but not diverse, multi-stage stacked models can thoroughly memorize the data dis-tribution of this large-scale dataset, leading to overﬁtting.
Increasing numbers of model parameters may further ex-acerbate this problem. Therefore, the degradation of the generalization performance of facial landmark detectors in unconstrained environments may not be addressed by sim-ply increasing human annotations and model parameters.
In recent years, researchers have proposed various data augmentation methods [8, 10, 12, 30, 49] to achieve robust facial landmark detection. Wingloss [12] balances the data distribution with handcrafted transformations (ﬂipping, ro-tation, scaling etc.). However, these rigid transformations are not adequate for those detectors facing various attacks from the real world ( illumination, make-ups, skin color,
etc.). More recently, unsupervised learning is introduced to improve the generalization of models by automatically annotating large-scale unlabeled data [10, 48, 49] while it requires prior knowledge provided by a pre-trained detec-tor on the existing labeled data. Because the annotated new samples may heavily overlap with ‘easy’ samples in pre-training data, unsupervised methods [10, 48, 49] can hardly maintain accurate detection on ‘hard’ samples. To diversify face data, a few methods [8, 30] introduce face augmenta-tion (e.g., style transfer or face generation). Style aggre-gation [8] augments faces in the aggregated style, which is a test-time augmentation. This method increases computa-tional cost at the testing phase, and its style transfer is lim-ited to three handcrafted styles. AVS [30] augments “new” faces by leveraging generative adversarial networks (GAN).
However, it may also generate unrealistic faces owing to the high uncertainty of the GAN models and the complex-ity of face generation. In addition, the performance gains of unsupervised learning methods [48, 49] and face augmen-tation methods [8, 30] are dependent on their pre-training models, resulting in their generalization performance be-ing limited by pre-training. Unfortunately, Goodfellow et al. [14, 20, 29] proved that deep neural networks trained on even large datasets are vulnerable to human-imperceptive perturbations.
We propose a sample-adaptive adversarial training (SAAT) approach to address the challenges mentioned above, which exploits adversarial attacks to enhance detec-tors, as shown in Figure 1. In this framework, an attacker generates adversarial perturbations instead of “new” faces to fool a facial landmark detector, and the detector learns to defend against these perturbations. Generally, most ex-isting attacks [14, 20, 29] generate category-speciﬁc adver-sarial perturbations that are usually human-imperceptible.
They always have full access to a pre-trained model and use various gradient-based methods to generate adversarial ex-amples. Unlike these attacks, we design a sample-adaptive black-box attacker, which does not require any pre-trained model, but rather crafts adversarial perturbations based on the real-time performance feedback of the detector running on current adversarial examples. In addition, we allow the perturbations to be visible to diversify further adversarial examples, which helps the detector learn to defend against visible attacks from the real world ( illumination, make-up, skin color, etc.). Then the adversarial perturbations must avoid the generation of false cases (e.g. faces with three eyes or twisted mouths) and structural inconsistency of face shapes between the adversarial and corresponding original faces. To achieve this, the attacker induces adversarial per-turbations to adapt to different faces. Speciﬁcally, the at-tacker implicitly learns the face structure of the adversarial examples by leveraging a structure-guided conditional ad-versarial architecture. Moreover, a semantic reconstruction loss is employed to explicitly constrain the semantic con-sistency between adversarial examples and the correspond-ing original faces. Nevertheless, false samples may still be generated during end-to-end training, especially before the convergence of the model, owing to these visible pertur-bations. To avoid irreversible degradation caused by false samples, we introduce a sample-adaptive weight, which au-tomatically adjusts the contribution of different adversarial examples to the detector in each training step by measuring the structural similarity of the adversarial examples and the corresponding original faces. Our main contributions are summarized as follows:
• The proposed approach performs robust facial land-mark detection as a defense against attacks from the real world.
It can improve the robustness of facial landmark detectors without increasing model param-eters and human annotations.
• Based on facial semantic information, the proposed sample-adaptive black-box attacker induces visible perturbations to adapt to different faces by interacting with the detector. It injects these perturbations into the training data, complementing existing data augmenta-tions to reduce the risk of overﬁtting.
• We introduce a sample-adaptive weight to avoid the detector’s performance degradation caused by false samples. This weight allows the attacker and detec-tor to be interactively optimized in end-to-end training without any pre-training. 2.