Abstract
In this paper, we propose a novel normalization method called gradient normalization (GN) to tackle the train-ing instability of Generative Adversarial Networks (GANs) caused by the sharp gradient space. Unlike existing work such as gradient penalty and spectral normalization, the proposed GN only imposes a hard 1-Lipschitz constraint on the discriminator function, which increases the capacity of the discriminator. Moreover, the proposed gradient normal-ization can be applied to different GAN architectures with little modification. Extensive experiments on four datasets show that GANs trained with gradient normalization out-perform existing methods in terms of both Frechet Inception
Distance and Inception Score. 1.

Introduction
Generative Adversarial Networks (GANs) [9] have recently achieved great success for synthesizing new data from a given prior distribution, which facilitates a variety of ap-plications, e.g., super resolution imaging [15], style trans-fer between domains [20, 32].
In the original definition,
GANs consist of two networks: the generator aims to con-struct realistic samples to fool the discriminator while the discriminator learns to discriminate real samples from syn-thetic samples which are produced by the generator.
Although the state-of-the-art GANs generate high fi-delity images that easily fool humans, the unstable training process remains a challenging problem. Therefore, a recent line of study focuses on overcoming the unstable training issue [2, 3, 10, 21, 23]. For example, one of the reasons for the unstable GAN training is caused by the sharp gradi-ent space of the discriminator, which causes the mode col-lapse in the training process of the generator [23]. Although
L2 normalization [14] and weight clipping [3] are simple but effective methods in stabilizing GANs, these additional constraints limit the model capacity of discriminator. As a result, the generator is inclined to fool the discriminator be-fore learning to generate real images. Another kind of pop-ular approaches is to formulate the discriminator as a Lip-schitz continuous function bounded under a fixed Lipschitz constant K by applying regularization or normalization on discriminator [10, 18, 22, 23]. As such, the discriminator gradient space becomes smoother without significantly sac-rificing the performance of the discriminator.
Imposing a Lipschitz constraint on the discriminator can be characterized by three properties. 1) Model- or module-wise constraint. If the constraint objective depends on full model instead of the summation of internal modules, we define such methods to be a model-wise constraint and the converse to be a module-wise constraint. For instance, the
Gradient penalty (1-GP) [10] is a model-wise constraint, while Spectral Normalization (SN) [18] is a module-wise (layer-wise) constraint, i.e.. We argue that model-wise con-straints are better since the module-wise constraints limit the layer capacities and thus reduce the multiplicative power of neural networks. 2) Sampling-based or non-sampling-based constraint.
If the approach requires sampling data from a fixed pool, such method is defined as a sampling-based constraint. For example, 1-GP is a sampling-based constraint due to the regularization, while SN is a non-sampling-based constraint since the normalization only de-pends on the model architecture. The non-sampling-based methods are expected to perform better than sampling-based methods since the sampling-based constraints might not be effective for the data that are not sampled before. 3)
Hard or soft constraint.
If the Lipschitz constant of any function in the function space of the constrained discrimi-nators is not greater than a fixed finite value, such approach is defined as a hard constraint and the converse as a soft constraint. For example, SN is a hard constraint and the fixed finite value is equal to 1, while 1-GP is a soft con-straint since the tightness of the constraint is fluctuated by the regularization and thus the upper bound is not limited.
The hard constraint is expected to perform better since the consistent Lipschitz constant can guarantee the gradient sta-bility of unseen data.
To the best of our knowledge, none of the constraints in previous work is model-wise, non-sampling-based, and hard at the same time.
In this paper, we propose a new normalization method, named gradient normalization (GN),
to enforce the Lipschitz constant to 1 for the discriminator model through dividing the outputs by the gradient norm of the discriminator. Unlike SN, the proposed Lipschitz con-stant does not decay from the multiplicative form of neu-ral networks since we consider the discriminator as a gen-eral function approximator and the calculated normalization term is independent of internal layers. The proposed gradi-ent normalization enjoys the following two favorable prop-erties. 1) The normalization simultaneously satisfies three properties including model-wise, non-sampling-based and hard constraints, and does not introduce additional hyper-parameters. 2) The implementation of GN is simple and compatible with different kinds of network architectures.
The contributions of our paper are summarized as follows.
• In this paper, we propose a novel gradient normaliza-tion for GANs to strike a good balance between sta-bilizing the training process and increasing the abil-ity of generation. To the best of our knowledge, this is the first work simultaneously satisfying the above-mentioned three properties.
• We theoretically prove that the proposed gradient nor-malization is 1-Lipschitz constrained. This property helps the generator to avoid the gradient explosion or vanishing, and thus stabilizes the training process.
• Experimental results show the proposed gradient nor-malization consistently outperforms the state-of-the-art methods with the same GAN architectures in terms of both Inception Score and Frechet Inception Dis-tance. Our implementation is available at: https:
//github.com/basiclab/GNGAN-PyTorch. 2.