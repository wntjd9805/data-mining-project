Abstract
Recently, deep Convolutional Neural Networks (CNNs) can achieve human-level performance in edge detection with the rich and abstract edge representation capacities.
However, the high performance of CNN based edge detec-tion is achieved with a large pretrained CNN backbone, which is memory and energy consuming.
In addition, it is surprising that the previous wisdom from the traditional edge detectors, such as Canny, Sobel, and LBP are rarely investigated in the rapid-developing deep learning era. To address these issues, we propose a simple, lightweight yet effective architecture named Pixel Difference Network (PiDiNet) for efficient edge detection. PiDiNet adopts novel pixel difference convolutions that integrate the traditional edge detection operators into the popular convolutional op-erations in modern CNNs for enhanced performance on the task, which enjoys the best of both worlds. Extensive experiments on BSDS500, NYUD, and Multicue are pro-vided to demonstrate its effectiveness, and its high train-ing and inference efficiency. Surprisingly, when training from scratch with only the BSDS500 and VOC datasets,
PiDiNet can surpass the recorded result of human percep-tion (0.807 vs. 0.803 in ODS F-measure) on the BSDS500 dataset with 100 FPS and less than 1M parameters. A faster version of PiDiNet with less than 0.1M parameters can still achieve comparable performance among state of the arts with 200 FPS. Results on the NYUD and Multicue datasets show similar observations. The codes are avail-able at https://github.com/zhuoinoulu/pidinet. 1.

Introduction
Edge detection has been a longstanding, fundamental low-level problem in computer vision [5]. Edges and object
*Equal contributions. † Corresponding author: http://lilyliliu.com
Figure 1. PDC benefits from both worlds with proper integration of traditional operators and modern CNNs. boundaries play an important role in various higher-level computer vision tasks such as object recognition and de-tection [29, 11], object proposal generation [6, 54], image editing [10], and image segmentation [41, 4]. Therefore, recently, the edge detection problem has also been revis-ited and injected new vitality due to the renaissance of deep learning [2, 23, 47, 60, 55, 31] .
The main goal of edge detection is identifying sharp im-age brightness changes such as discontinuities in intensity, color, or texture [53]. Traditionally, edge detectors based on image gradients or derivatives information are popular choices. Early classical methods use the first or second or-der derivatives (e.g., Sobel [50], Prewitt [46], Laplacian of
Gaussian (LoG), Canny [5], etc.) for basic edge detection.
Later learning based methods [16, 9] further utilize various gradient information [59, 37, 12, 15] to produce more accu-rate boundaries.
Due to the capability of automatically learning rich rep-resentations of data with hierarchical levels of abstraction, deep CNNs have brought tremendous progress for vari-ous computer vision tasks including edge detection and are still rapidly developing. Early deep learning based edge detection models construct CNN architectures as clas-sifiers to predict the edge probability of an input image
Figure 2. PiDiNet configured with pixel difference convolution (PDC) vs. the baseline with vanilla convolution. Both models were trained only using the BSDS500 dataset. Compared with vanilla convolution, PDC can better capture gradient information from the image that facilitates edge detection.
Table 1. Comparison between ours and some leading edge detec-tion models in terms of efficiency and accuracy. The multiply-accumulates (MACs) are calculated based on a 200×200 image,
FPS and ODS F-measure are evaluated on the BSDS500 test set.
Params
MACs
Throughput
Pre-training
ODS F-measure
HED [60] RCF [31] BDCN [18] PiDiNet PiDiNet(tiny) 16.3M 23.2G 47FPS
ImageNet 0.820 14.8M 16.2G 67FPS
ImageNet 0.806 14.7M 22.2G 78FPS
ImageNet 0.788 73K 270M 215FPS
No 0.787 710K 3.43G 92FPS
No 0.807 patch [2, 47, 3]. Building on top of fully convolutional networks [33], HED [60] performs end-to-end edge de-tection by leveraging multilevel image features with rich hierarchical information guided by deep supervision, and achieves state-of-the-art performance. Other similar works include [62, 23, 36, 55, 61, 31, 8, 18].
However, integration of traditional edge detectors with modern CNNs were rarely investigated. The former were merely utilized as auxiliary tools to extract candidate edge points in some prior approaches [3, 2]. Intuitively, edges manifest diverse specific patterns like straight lines, corners, and “X” junctions. On one hand, traditional edge operators like those shown in Fig. 1 are inspired by these intuitions, and based on gradient computing which encodes important gradient information for edge detection by explicitly calcu-lating pixel differences. However, these handcrafted edge operators or learning based edge detection algorithms are usually not powerful enough due to their shallow structures.
On the other hand, modern CNNs can learn rich and hier-archical image representations, where vanilla CNN kernels serve as probing local image patterns. Nevertheless, CNN kernels are optimized by starting from random initializa-tion which has no explicit encoding for gradient informa-tion, making them hard to focus on edge related features.
We believe a new type of convolutional operation can be derived, to satisfy the following needs. Firstly, it can eas-ily capture the image gradient information that facilitates edge detection, and the CNN model can be more focused with the release of burden on dealing with much unrelated image features. Secondly, the powerful learning ability of deep CNNs can still be preserved, to extract semantically meaningful representations, which lead to robust and accu-rate edge detection.
In this paper, we propose pixel dif-ference convolution (PDC), where the pixel differences in the image are firstly computed, and then convolved with the kernel weights to generate output features (see Fig. 3). We show PDC can effectively improve the quality of the output edge maps, as illustrated in Fig. 2.
On the other hand, leading CNN based edge detec-tors suffer from the deficiencies as shown in Table 1: be-ing memory consuming with big model size, being energy hungry with high computational cost, running inefficiency with low throughput and label inefficiency with the need of model pre-training on large scale dataset. This is due to the fact that the annotated data available for training edge detection models is limited, and thus a well pretrained (usu-ally large) backbone is needed. For example, the widely adopted routine is to use the large VGG16 [49] architecture that was trained on the large scale ImageNet dataset [7].
It is important to develop a lightweight structure, to achieve a better trade-off between accuracy and efficiency for edge detection. With pixel difference convolution, in-spired by [19, 20], we build a new end-to-end architecture, namely Pixel Difference Network (PiDiNet) to solve the mentioned issues in one time. Specifically, PiDiNet con-sists of an efficient backbone and an efficient task-specific side structure (see Fig. 5), able to do robust and accurate edge detection with high efficiency.
2.