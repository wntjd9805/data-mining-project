Abstract
Despite the success of deep learning on supervised point cloud semantic segmentation, obtaining large-scale point-by-point manual annotations is still a significant chal-lenge. To reduce the huge annotation burden, we pro-pose a Region-based and Diversity-aware Active Learning (ReDAL), a general framework for many deep learning ap-proaches, aiming to automatically select only informative and diverse sub-scene regions for label acquisition. Ob-serving that only a small portion of annotated regions are sufficient for 3D scene understanding with deep learning, we use softmax entropy, color discontinuity, and structural complexity to measure the information of sub-scene regions.
A diversity-aware selection algorithm is also developed to avoid redundant annotations resulting from selecting infor-mative but similar regions in a querying batch. Extensive experiments show that our method highly outperforms pre-vious active learning strategies, and we achieve the perfor-mance of 90% fully supervised learning, while less than 15% and 5% annotations are required on S3DIS and Se-manticKITTI datasets, respectively. 1.

Introduction
Point cloud semantic segmentation is crucial for vari-ous emerging applications such as indoor robotics and au-tonomous driving. Many supervised approaches [19, 20, 30, 27, 6, 26] along with several large-scale datasets [1, 7, 10, 5] are recently provided and have made huge progress.
Although recent deep learning methods have achieved great success with the aid of massive datasets, obtaining a large-scale point-by-point labeled dataset is still costly and challenging. Specifically, the statistics show that there would be more than 100,000 points in a room-sized point cloud scene [1, 5]. Furthermore, the annotation process of 3D point-wise data is much more complicated than that of
†Co-second authors contribute equally.
Figure 1. Human labeling efforts (colored areas) of different learning strategies. (a) In supervised training or traditional deep active learning, all points in a single point cloud are required to be labeled, which is labor-intensive. (b) Since few regions contribute to the model improvement, our region-based active learning strat-egy selects only a small portion of informative regions for label acquisition. Compared with case (a), our approach greatly reduces the cost of semantic labeling of walls and floors. (c) Moreover, considering the redundant labeling where repeating visually sim-ilar regions in the same querying batch, we develop a diversity-aware selection algorithm to further reduce redundant labeling (e.g., ceiling colored in green in (b) and (c)) effort by penalizing visually similar regions. 2D data. Unlike simply selecting closed polygons to form a semantic annotation in a 2D image [22], in 3D point-by-point labeling, annotators are asked to perform multiple 2D annotations from different viewpoints during the annotation process [10] or to label on 3D space with brushes through multiple zooming in and out and switching the brush size
[5]. Therefore, such numerous points and the complicated annotation process significantly increase the time and cost of manual point-by-point labeling.
To alleviate the huge burden of manual point-by-point labeling in large-scale point cloud datasets, some previous works have tried to reduce the total number of labeled point cloud scans [14] or lower the annotation density within a
Figure 2. Not all annotated regions contribute to the model’s improvement. This toy experiment compares the performance contribu-tion of fully labeled (a) and partially (b, w/o floor) labeled scans on S3DIS [1] dataset. Specifically, the training dataset contains only 4 fully-labeled point cloud scans at the beginning. Another 4 fully or partially labeled scans are then added into the dataset at each following iteration. As shown in (c), compared to using all labels (solid line), removing floor labels (dash line) leads to similar performance on all classes including floor (blue), chairs (red), and bookcases (green). Additionally, (d) demonstrate that 12% of point annotation (21.7M fully labeled points versus 19.1M partially labeled points at 20 scans) is saved by simply removing the floor labels. Therefore, this shows that not all annotated regions contribute to the model’s improvement, and we can save the annotation costs by selecting key regions to annotate while maintaining the original performance. single point cloud scan [34]. However, they neglect that regions in a point cloud scan may not contribute to the per-formance equally. As can be observed from Figure 2, for a deep learning model, only 4 labeled point cloud scans are needed to reach over 0.9 IoU on large uniform objects, such as floors. However, 20 labeled scans are required to achieve 0.5 IoU on small items or objects with complex shapes and colors, like chairs and bookcases. Therefore, we argue that an effective point selection is essential for lowering annota-tion costs while preserving model performance.
In this work, we propose a novel Region-based and
Diversity-aware Active Learning (ReDAL) framework gen-eral for many deep learning network architectures. By ac-tively selecting data from a huge unlabeled dataset for label acquisition, only a small portion of informative and diverse sub-scene regions is required to be labeled.
To find out the most informative regions for label acqui-sition, we utilize the combination of the three terms, soft-max entropy, color discontinuity, and structural complex-ity, to calculate the information score of each region. Soft-max entropy is a widely used approach to measure model uncertainty, and areas with large color differences or com-plex structures in a point cloud provide more information because semantic labels are usually not smooth in these ar-eas. As shown in the comparison of Figure 1 (a, b), the region-based active selection strategy significantly reduces the annotation effort of original full scene labeling.
Furthermore, to avoid redundant annotation resulting from multiple individually informative but duplicated data in a query batch, which is a common problem in deep active learning, we develop a novel diversity-aware selection algo-rithm considering both region information and diversity. In our proposed method, we first extract all regions’ features, then measure the similarity between regions in the feature space, and finally, use a greedy algorithm to penalize mul-tiple similar regions appearing in the same querying batch.
As can be observed from the comparison of Figure 1 (b, c), our region-based and diversity-aware selection strategy can avoid querying labels for similar regions and further reduce the effort of manual labeling.
Experimental results demonstrate that our proposed method significantly outperforms existing deep active learn-ing approaches on both indoor and outdoor datasets with various network architectures. On S3DIS [1] and Se-manticKITTI [5] datasets, our proposed method can achieve the performance of 90% fully supervised learning, while less than 15%, 5% annotations are required. Our ablation studies also verify the effectiveness of each component in our proposed method.
To sum up, our contributions are highlighted as follows,
• We pave a new path for 3D deep active learning that utilizes region segmentation as the basic query unit.
• We design a novel diversity-aware active selection ap-proach to avoid redundant annotations effectively.
• Experimental results show that our method can highly reduce human annotation effort on different state-of-the-art deep learning networks and datasets, and out-performs existing deep active learning methods. 2.