Abstract
Multi-Layer Perceptrons (MLPs) make powerful func-tional representations for sampling and reconstruction prob-lems involving low-dimensional signals like images, shapes and light fields. Recent works have significantly improved their ability to represent high-frequency content by using periodic activations or positional encodings. This often came at the expense of generalization: modern methods are typically optimized for a single signal. We present a new representation that generalizes to multiple instances and achieves state-of-the-art fidelity. We use a dual-MLP archi-tecture to encode the signals. A synthesis network creates a functional mapping from a low-dimensional input (e.g. pixel-position) to the output domain (e.g. RGB color). A modulation network maps a latent code corresponding to the target signal to parameters that modulate the periodic activations of the synthesis network. We also propose a local-functional representation which enables generalization. The signal’s domain is partitioned into a regular grid, with each tile represented by a latent code. At test time, the signal is en-coded with high-fidelity by inferring (or directly optimizing) the latent code-book. Our approach produces generalizable functional representations of images, videos and shapes, and achieves higher reconstruction quality than prior works that are optimized for a single signal. 1.

Introduction
Functional neural representations using Multi-Layer Per-ceptrons (MLPs) have garnered renewed interest for their conceptual simplicity and ability to approximate complex signals like images, videos, audio recordings [38], light-fields [26] and implicitly-defined 3D shapes [8, 32, 2]. They have shown to be more compact and efficient than their dis-crete counterparts [21, 39]. While recent contributions have focused on improving the accuracy of these representations, in particular to model complex signals with high-frequency details [38, 44, 26], it is still challenging to generalize them to unseen signals. Recent approaches typically require train-Discrete Input Signal
Modulator
Encoder (optional)
Tile z x
Cont.
Output f (x; z)
Grid Tiling
Synthesizer 2048 × 2048 SIREN [38]-60m
Ours-10s
GT 24.13dB 34.01dB
Figure 1: (Top) We propose a new method to encode discrete signals as neural-functional representations. Each signal is represented as a structured grid, with each tile defined by a latent code. The tiles are encoded as continuous signals by a synthesis network using periodic activations. The la-tent codes corresponding to the tiles are used to modulate the activations using a modulation network. (Bottom) Our generalizable method is faster and enables higher quality reconstructions than previous methods. ing a separate MLP for each signal [26, 9]. Previous ef-forts sought to improve generalization by imposing priors on the functional space spanned by the MLP parameteri-zation [32, 35], using hypernetworks [14, 38], or via meta-learning [37]. But multi-instance generalization still causes significant degradations in quality.
We introduce a neural functional representation that si-multaneously achieves high-reconstruction quality and gen-eralizes to multiple instances. Our approach can encode functional representations for multiple discrete signals using a single model. Unlike previous works, which train a model for each signal, it can do so in a single feed-forward pass (Fig. 1). We represent each signal using a low-dimensional latent code. These codes serve as conditioning variables in a functional mapping that uses two MLPs: a modulator and a synthesis network. The synthesis network implements a map-1
SIREN [38]
Ours
O v er fit d e z i l a r e n
G e
Figure 2: Obtaining a neural representation of an image using SIREN [38] requires overftting a new MLP to every new image instance. This works well in practice for low-resolution images, but with the same model, we observe a sharp drop in reconstruction accuracy for high-resolution images. Our method can be used to encode multiple images at high-resolution with only feed-forward operations without gradient computation. ping from coordinates (e.g. spatial position) to signal values (e.g. RGB colors). It uses the sine function as activation, which enables accurate reconstructions of high-frequency content [38], but also makes naive conditioning strategies in-effective (§ 3.2). The modulator is the key to generalization.
It consumes latent code and outputs, at each layer, param-eters that modulate the amplitude, phase and frequency of periodic activations in the synthesis network. The modulator uses ReLU activations. Our model can either be used as an autoencoder, where the latent codes are produced by a third network (the encoder); or as an auto-decoder, where the latent codes are optimized jointly with all the network parameters.
As we show in Figure 2, the quality of functional rep-resentations that fit images as-a-whole, degrades as we in-crease the target resolution. High-resolution images typically have a broad power spectrum, thereby requiring more ex-pensive models to represent them functionally. But images are usually much simpler locally: simple edges and textures re-occur commonly across images that are otherwise quite distinct at the global level. This motivates our strategy to exploit locality. We partition the signal domain into a reg-ular tiling, and assign each tile a latent code (Fig. 1). By
“zooming in” on the local structure, computing functional approximations that generalize becomes more tractable [23], because simple parts exhibit fewer variations than complete objects [13]. Some recent work has explored locality, but they focus on relatively simple, low-frequency signals like signed distance fields [4, 13], which can locally be well ap-proximated using a single linear decision boundary—well in the purview of ReLU-based MLPs. For more complex signals like images and videos, even local patterns contain high-frequency components that a standard ReLU-MLP fails to reconstruct (Figure 3). We show that locality, together with our model architecture, makes it possible to obtain func-tional representations of large, complex signals. Compared to previous methods, ours produces qualitatively and quan-titatively better functional representations, with improved generalization capabilities. Concretely, our contributions are as follows:
• A local neural-functional representation that enables generalization and achieves high fidelity. We use a set of local functions defined on a tiling of the input domain that combine to reconstruct the target signal.
• A new network architecture, which uses modulation and synthesis sub-networks for high-fidelity functional neural representations of images, shapes and videos. 2.