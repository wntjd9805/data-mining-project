Abstract
This paper presents a deep relational metric learning (DRML) framework for image clustering and retrieval.
Most existing deep metric learning methods learn an em-bedding space with a general objective of increasing inter-class distances and decreasing intraclass distances. How-ever, the conventional losses of metric learning usually sup-press intraclass variations which might be helpful to iden-tify samples of unseen classes. To address this problem, we propose to adaptively learn an ensemble of features that characterizes an image from different aspects to model both interclass and intraclass distributions. We further employ a relational module to capture the correlations among each feature in the ensemble and construct a graph to repre-sent an image. We then perform relational inference on the graph to integrate the ensemble and obtain a relation-aware embedding to measure the similarities. Extensive experiments on the widely-used CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate that our framework improves existing deep metric learning methods and achieves very competitive results. 1 1.

Introduction
How to effectively measure the similarities among ex-amples has been an important problem for many computer vision tasks. Metric learning aims to learn a distance metric under which samples from one class are close to each other and far away from samples from the other classes. Taking advantage of the deep learning technique [15, 26, 45, 50], deep metric learning (DML) methods utilize the combina-tion of a convolutional neural network (CNN) and fully connected layers (FCs) to construct a mapping from the image space to an embedding space and employ the Eu-clidean distance in this space to measure the similarities between samples. Deep metric learning has outperformed
∗Equal contribution.
†Corresponding author. 1Code: https://github.com/zbr17/DRML.
Figure 1. Comparisons of the proposed DRML framework with conventional deep metric learning methods and ensemble-based deep metric learning methods. Conventional DML employs a deep neural network to obtain an embedding for each image and measures the similarity of two samples by the Euclidean distance between their corresponding embeddings. Ensemble-based DML learns an ensemble of embeddings but simply concatenates them to obtain the ﬁnal embedding, which ignores the structural rela-tions among them. Differently, the proposed DRML framework represents one image using an ensemble of features as well as their interactions and then incorporates the relations to infer the
ﬁnal embedding. (Best viewed in color.) conventional methods by a large margin and demonstrated promising results in a variety of tasks, such as image re-trieval [35, 46, 47, 67], face recognition [16, 30, 43, 53], and person re-identiﬁcation [4, 5, 44, 52, 68].
Most existing metric learning methods utilize a discrim-inative objective to learn the embedding space, which en-courages the metric to discard intraclass variations so that intraclass samples will form a compact cluster with a large margin from the other clusters. The large margin nature of metric learning has been proven useful to improve its ro-bustness and generalization for seen class retrieval or classi-ﬁcation [7, 53, 59]. However, the essence of metric learning is the ability to generalize to unseen classes in the test phase, as is usually evaluated in standard deep metric learning set-tings [35, 46, 47]. Directly learning a discriminative repre-sentation actually harms the performance for unseen class retrieval [41, 62], since the discarded intraclass variations may be useful to differentiate the unseen classes. Moreover, it seems in conﬂict with the general discriminative objective of metric learning to preserve certain characteristics that is unhelpful for distinguishing training data but might be help-ful for unseen test data. A natural question is raised: can we learn a discriminative metric that also generalizes well?
In this paper, we provide a positive answer to this ques-tion. We propose a deep relational metric learning (DRML) framework which learns to comprehensively characterize an instance as well as distinguish different instances. We
ﬁrst learn a set of feature extractors to produce an ensem-ble of features, where each of them describes an image in one aspect. We adopt a bottleneck architecture to determine the dominant characteristics of each image and only use samples with the corresponding dominant characteristics to train each feature. The learned ensemble of features mod-els both interclass differences and intraclass variations, and thus is not discriminative enough to be directly used to com-pute the distance between images. To effectively measure the similarity between two ensembles of features, we further propose a relational model to discover structural patterns in the feature ensemble and exploit them to obtain a relation-aware embedding. The proposed DRML framework can be trained effectively in an end-to-end manner and enjoys the advantage of efﬁcient retrieval similar to existing deep met-ric learning methods. Differently, our framework induces a stronger relational bias than the combination of convolu-tional layers and fully connected layers and thus can gener-alize better to unseen classes. Figure 1 compares our frame-work with existing deep metric learning methods. We con-duct extensive experiments on three widely-used datasets which demonstrate the effectiveness of the proposed frame-work. 2.