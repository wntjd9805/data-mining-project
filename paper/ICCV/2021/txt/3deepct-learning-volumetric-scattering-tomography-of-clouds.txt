Abstract
We present 3DeepCT, a deep neural network for com-puted tomography, which performs 3D reconstruction of scattering volumes from multi-view images. The architec-ture is dictated by the stationary nature of atmospheric cloud fields. The task of volumetric scattering tomography aims at recovering a volume from its 2D projections. This problem has been approached by diverse inverse methods based on signal processing and physics models. However, such techniques are typically iterative, exhibiting a high computational load and a long convergence time. We show that 3DeepCT outperforms physics-based inverse scatter-ing methods, in accuracy, as well as offering orders of magnitude improvement in computational run-time. We further introduce a hybrid model that combines 3DeepCT and physics-based analysis. The resultant hybrid technique enjoys fast inference time and improved recovery perfor-mance. 1.

Introduction
There is increasing effort to develop deep neural net-works (DNNs) for reconstructing three dimensional (3D) shapes or projections of opaque objects. These DNNs use either explicit outer-shell or volumetric representations
[7, 11, 12, 13, 19, 24, 28, 35, 53, 58, 59, 67, 78, 79, 80, 82].
However, there is still a significant gap in advancing re-construction of 3D heterogeneous volumetric translucent fields, such as the atmosphere (Fig. 1). 3D heterogeneous translucent objects are reconstructed, essentially, using to-mographic data. Radiation that propagates through the medium yields a set of multi-view two dimensional (2D) radiometric images. Analysis retrieves from the data the volumetric spatial distribution of material density in 3D.
Figure 1. Shallow cumulus cloud fields [76].
This is computed tomography (CT). It is used extensively in biomedical imaging and earth sciences [3, 5, 23, 37, 57, 66]
DNNs advance medical CT [29, 34, 65, 72, 77]. Nev-ertheless, most CT modalities are based on a linear image formation model. Linear models can be solved well using established signal processing methods, including optimiza-tion of a convex functional, without requiring learning. It may be argued that 3D tomography does not lend itself eas-ily to current DNNs. The reason is that DNNs require big training data, but it is extremely difficult to obtain sufficient ground-truth data of volumetric heterogeneous translucent objects.
Reconstructing such objects poses a serious challenge which is worth tackling by DNNs. We believe this chal-lenge and opportunity occur when these conditions are met. (1) The tomographic model is very complex: nonlinear, not unimodal. Then, methods of linear-CT analysis cannot ap-ply. Moreover, optimization-based estimation is very slow, (2) Scal-unscalable and too dependent on initialization. ability is critically needed to analyze huge 3D fields. (3)
While the imaging model is nonlinear, it is continuous: an infinitesimal change of the medium continuously affects the (4) There is a physics-based image data, and vice versa. way to generate a large and diverse database. Under these
conditions, a DNN can realistically learn to express the rich-ness of large translucent fields, and the physical processes that generate both 3D translucent objects and their images.
Moreover, the inference speed offered by a trained DNN can significantly overtake explicit physics-based optimization.
We pose a problem that should greatly benefit from a
DNN for CT. The problem is imaging of a very large ran-dom 3D spatially heterogeneous scattering medium [2, 10, 25, 46, 55, 68, 69, 74]: the atmosphere. In computer vi-sion, imaging through a scattering medium has usually been related to dehazing [33, 51], defogging [43], underwater descattering [2, 71], or recovering properties of a medium, assuming its spatial uniformity [10]. Here, however the fo-cus is on imaging of clouds [50, 84]. Clouds have interac-tions with the global climate system which are not well un-derstood. This leads to major uncertainties in climate pre-dictions [4, 6, 8]. This is a major motivation to properly sense these volumetric translucent objects internally.
Clouds are usually highly heterogeneous. Furthermore, multi-view images of clouds are governed by 3D radiative transfer (RT) [20, 31, 64]: a nonlinear, recursive forward model, which expresses arbitrary multiple scattering in 3D.
Inverting this model is highly complex. Common methods in remote sensing try to bypass this complexity by imposing a model [60, 61] where clouds are horizontally uniform, in-finitely broad, and RT is roughly vertical (one dimensional).
This is inconsistent with nature, particularly when clouds are small. Recent work in computer vision introduced 3D scattering tomography [1, 16, 25, 26, 32, 40, 45, 46, 47] and proposed it as a viable path to study clouds. However, it is still slow and has not been scaled.
Ref. [22] shows that thick clouds have a veiled core, to which images are insensitive. Relying only on images may lead to major errors in a veiled core: the data term is ill-conditioned in thick clouds. Regularization should be valu-able. A learning-based system may address this: Using ex-amples as it trains, the system implicitly learns a prior of the nature and structure of clouds. 3DeepCT trains on phys-ically realistic clouds, expressing both RT (fidelity) and the nature of clouds (regularization). We thus believe that a neural network (NN) is the way to better condition cloud tomography.
Our proposed learning-based system, 3DeepCT infers 3D scattering-CT. While its results have quality which is comparable to explicit physics-based methods, it appears to run five orders of magnitude faster. Moreover, after train-ing, it can potentially be scalable to broad cloud fields, exploiting GPU parallelism. We show how natural prop-erties of clouds in cloud fields lead to the architecture of 3DeepCT. This includes a convolutional neural network (CNN) based on 2D convolutions, the size of its receptive field and layer-depth, and avoidance of dimensionality re-duction. Furthermore, we provide an approach to train this system using rigorous physics-based generation of simu-lated fields and images. 2. Theoretical