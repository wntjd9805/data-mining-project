Abstract
Recently, deep learning-based image denoising meth-ods have achieved significant improvements over tradi-tional methods. Due to the hardware limitation, most deep learning-based image denoising methods utilize cropped small patches to train a convolutional neural network to infer the clean images. However, the real noisy images in practical are mostly of high resolution rather than the cropped small patches and the vanilla training strategies ignore the cross-patch contextual dependency in the whole image. In this paper, we propose Cross-Patch Net (CPNet), which is the first deep- learning-based real image denois-ing method for HR (high resolution) input. Furthermore, we design a novel loss guided by the noise level map to ob-tain better performance. Compared with the vanilla patch-based training strategies, our approach effectively exploits the cross-patch contextual dependency. Besides, owing to the difficulty in capturing real noisy and noise-free image paired training data, we propose an effective method to gen-erate realistic sRGB noisy images from their corresponding clean sRGB images for denoiser training. Denoising exper-iments on real-world sRGB images show the effectiveness of the proposed method. More importantly, our method achieves state-of-the-art performance on practical sRGB noisy image denoising. 1.

Introduction
Since image denoising can help downstream computer vision tasks [44, 28, 43, 27, 26, 32], it has attracted ex-tensive interest in related fields. The majority of denois-ing methods take the cropped small patches as the train-ing dataset due to the hardware storage limitation like GPU memory. However, these methods trained with the cropped patches may fail when denoising the real noisy images in the practical situation. Nowadays, the images captured by the cameras always have high-resolution and there exists context consistency between the patches in a whole image.
∗Corresponding author.
Figure 1. An example of the patch-wise noise consistency in SIDD
[1]. The four similar patches have almost the same NLFs (βs and
βr for noise level function – see Section 3.1). The NLFs and the
Gaussian noise level are estimated by using the method proposed by [13]and [8], respectively.
A large number of denoising methods can achieve consid-erable performance when they adopt the cropped real noisy image patches as training data set dealing with the Gaussian noise. Nevertheless, there exist virtual differences between the Gaussian noise and the real noise. The noise levels of patches in a Gaussian noisy image are the same which is the fixed variance. Therefore, it is unnecessary to consider the context consistency between Gaussian noisy patches.
It is quite different from the real noise. The real sRGB noise is generated by the raw image noise through the image processing pipeline (ISP). The raw noise can be divided into two categories: shot noise and read noise[13, 29], which obey Poisson distribution and Gaussian distribution respec-tively. Poisson noise is highly relevant to the image pixel values. Besides, the noise on each pixel is affected by the pixels in the adjacent region when the raw image is con-verted to an sRGB image. As a result, similar patches gener-ate similar noise distribution. Figure 1 gives an example of this phenomenon, illustrating that the high-resolution noisy images consist of a series of similar patches, and the noise level functions (NLFs) are almost the same (shot noise σs and read noise σr). All the NLFs are estimated by using the SIDD[1] raw noisy images with the NLFs estimation method [13]. Therefore, It is essential to take the cross-patch consistency into account dealing with the real noise.
To obtain better real image denoising performance, noise level maps are widely used as inputs in nowadays denoising methods[18, 4, 42]. Noise level map consists of not only the original image pixel values information but also the real noise distribution information of each pixel. Both the real noise and the noise level map record these two kinds of in-formation mentioned above. But unlike the noise level map, the real noise is accompanied by uncertainty and random-ness, which makes it difficult to extract the original pixel values and the noise levels. Although the noise level map has superior properties, most existing methods only con-catenate it with the noisy image as the network input and do not leverage it efficiently.
In addition to the cross-patch consistency, the real image denoising performance is limited by the lack of real image training data. Due to the difficulties during image capturing (object movement, camera motion, and lighting changes), all these real noisy image data sets[1, 34, 3, 39, 31] have limited numbers of scenes and images. For example, the largest data set SIDD has only 10 scenes and 160 training image pairs. Each real HR noisy image can be cropped into multiple noisy patch training pairs, but the real noise pa-rameters of each image are fixed which makes a large num-ber of training pairs share the same real noise parameters.
However, there is a wide range of noise parameters in the practical situation so that the lack of real noise parameters in the training images affects the robustness of denoiser to unknown noise parameters. Different from Gaussian noise, the noise of the real image is often complex and difficult to simulate. To tackle this issue, we propose a method to synthesize realistic sRGB noisy images from clean images.
In this paper, we propose CPNet, a novel patch-based deep learning method for real image denoising. Specifi-cally, we crop an input image into patches and a primary patches selection is made according to the semantic rele-vance among them. Then we construct a cross-patch graph and propose Cross-Patch Graph Convolutional Network. we aggregate both the local and non-local information to the decoder to obtain the predicted clean image. Cross-Patch
GCN explicitly captures cross-patch long-range contextual dependency. For each given patch to be estimated (query patch), CPNet aggregates other patches which are highly relevant to the query one. Then CPNet ensembles those cor-related features towards a more faithful predicted clean im-age. To solve the problem of insufficient training data set, we propose an effective method to generate realistic sRGB noisy images from their corresponding clean sRGB images for denoiser training.
In summary, our contributions are as follows:
• We propose a cross-patch strategy to explore the contextual consistency between patches in a high-resolution real noisy image.
• We propose a novel loss to leverage the noise level map. Instead of merely regarding the noise level map as the input in previous work, we further use it to su-pervise the network training.
• We design an effective pipeline to generate realistic sRGB noisy images from their corresponding clean sRGB images for denoiser training.
• We propose a graph convolutional network CPNet to practical HR real image denoising under hardware re-sources constraints. Through extensive experiments on different datasets, we show that the proposed method is able to achieve state-of-the-art performance. 2.