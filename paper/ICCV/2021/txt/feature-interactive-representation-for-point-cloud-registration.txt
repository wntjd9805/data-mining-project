Abstract
Point cloud registration is the process of using the com-mon structures in two point clouds to splice them together.
To ﬁnd out these common structures and make these struc-tures match more accurately, interacting information of the source and target point clouds is essential. However, lim-ited attention has been paid to explicitly model such fea-ture interaction. To this end, we propose a Feature Inter-active Representation learning Network (FIRE-Net), which can explore feature interaction among the source and target point clouds from different levels. Speciﬁcally, we ﬁrst in-troduce a Combined Feature Encoder (CFE) based on fea-ture interaction intra point cloud. The CFE extracts inter-active features intra each point cloud and combines them to enhance the ability of the network to describe the local geometric structure. Then, we propose a feature interaction mechanism inter point clouds which includes a Local In-teraction Unit (LIU) and a Global Interaction Unit (GIU).
The former is used to interact information between point pairs across two point clouds, thus the point features in one point cloud and its similar point features in another point cloud can be aware of each other. The latter is applied to change the per-point features depending on the global cross information of two point clouds, thus one point cloud has the global perception of another. Extensive experiments on partially overlapping point cloud registration show that our method achieves state-of-the-art performance. 1.

Introduction
Geometric registration is a key task in 3D data analy-sis, which aligns one point cloud (source) to another (tar-get) by estimating the transformation between them. It has a variety of applications in many computational ﬁelds, in-cluding medical imaging, robotics, and autonomous driv-ing. Iterative Closest Point (ICP) [3] is the most popular and widely-used registration algorithm, however, it often
*Corresponding author: Jie Ma.
Figure 1: Comparison of prior work and the proposed FIRE-Net. (a) The pipeline without feature interaction [23], which use a feature extractor to extract features for source and target point clouds independently. (b) In our work, the multi-level feature in-teraction mechanism greatly improves the discriminative power of features, which enables a more discriminative similarity matrix and a more accurate registration result. stalls in local minima and is only suitable for small trans-formations. Other methods [12, 30, 49, 55], which can reg-ister two point clouds with large rotation and translation, are typically slower than the original ICP.
The past few years have seen a breakthrough in deep learning, leading to remarkable advancements in most 3D computer vision tasks, such as classiﬁcation [28, 29, 40, 43, 47], segmentation [17, 44, 52, 53], and detection
[5, 18, 22, 35]. Recently, some learning-based methods
[19, 23, 41, 42, 50] for point cloud registration are pro-posed. They solve the registration problem in three steps: (1) extract features for the source and target point clouds using networks such as PointNet [28]; (2) design a module, such as pointer network [41], to ﬁnd the correspondence; (3) apply a differentiable singular value decomposition (SVD) layer to ﬁnd the least-squares rigid transformation. These methods show excellent performance with faster speed than traditional algorithms and have the ability to handle large rotations, but there are still problems. Many methods only focus on the matching stage and neglect the important cor-nerstone of registration–feature extraction. Those methods simply use the existing feature extractors, such as Point-Net [28] and DGCNN [43], which can’t provide the dis-criminative feature for the subsequent matching process to resolve the ambiguity. We argue that by interacting the in-formation between source and target point clouds and mak-ing the features of point clouds depend on each other, the features can be more discriminative and task-relevant. In this work, we formulate a novel feature interaction model, named FIRE-Net, to fully leverage interaction among the source and target point clouds from different levels. Specif-ically, it sequentially explores feature interaction intra each point cloud and feature interaction inter point clouds.
We ﬁrst introduce a Combined Feature Encoder (CFE) to obtain interactive features intra each point cloud by us-ing the graph neural networks (GNN) [15]. For better de-scription of the local geometry structure, the CFE combines features from different propagation layers to capture com-prehensive semantic and geometric information.
In addition to modeling feature interaction intra each point cloud, we observe that GNN can be naturally extended to feature interaction inter point clouds from the local per-spective, namely Local Interaction Unit (LIU). Different from the CFE, we construct a hybrid graph with both source and target features and then update the node feature by ag-gregating information from each other. The key to LIU is making each point feature be adapted with respect to the point features in another point cloud.
Furthermore, we propose a Global Interaction Unit (GIU) to exploit feature interaction inter point clouds from the global perspective. The GIU crosses the information be-tween source and target global features and automatically control the cross information transfer for both point clouds.
With this process, all features of the source and target can complement each other, assisting registration in avoiding matching confusion and improving robustness.
We observe that, through comprehensive information in-teraction from different levels, the similarity matrix is more discriminative than the one obtained without feature inter-action, as shown in Fig. 1. Meanwhile, our experiment re-sults verify that FIRE-Net not only achieves state-of-the-art performance when the overlap rate of point clouds is high but also offers the largest improvements in the case of low overlap rates.
In summary, our main contributions are:
• We present a Combined Feature Encoder to extract inter-active features in the local region and combine the fea-tures of different layers, enhancing the ability of the net-work to extract local geometric and semantic information.
• We design a novel feature interaction mechanism inter point clouds which enables each point cloud to have con-textual awareness of another point cloud, thus providing more discriminative features for subsequent modules.
• Our end-to-end FIRE-Net model achieves state-of-the-art performance on the ModelNet40 benchmark in several settings, thus demonstrating its effectiveness and gener-alization ability. 2.