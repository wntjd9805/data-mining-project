Abstract
In image retrieval, learning local features with deep con-volutional networks has been demonstrated effective to im-prove the performance. To discriminate deep local features, some research efforts turn to attention learning. However, existing attention-based methods only generate a single at-tention map for each image, which limits the exploration of diverse visual patterns. To this end, we propose a novel deep local feature learning architecture to simultaneously focus on multiple discriminative local patterns in an image.
In our framework, we ﬁrst adaptively reorganize the chan-nels of activation maps for multiple heads. For each head, a new dynamic attention module is designed to learn the po-tential attentions. The whole architecture is trained as met-ric learning of weighted-sum-pooled global image features, with only image-level relevance label. After the architec-ture training, for each database image, we select local fea-tures based on their multi-head dynamic attentions, which are further indexed for efﬁcient retrieval. Extensive experi-ments show the proposed method outperforms the state-of-the-art methods on the Revisited Oxford and Paris datasets.
Besides, it typically achieves competitive results even using local features with lower dimensions. Code will be released at https://github.com/CHANWH/MDA. 1.

Introduction
Given a large image corpus, instance image retrieval [32, 27, 17, 38, 18, 9, 10, 19] aims to effectively identify images containing the same object or describing the same scene as the query image. This task is challenging due to the various conditions observed in large-scale datasets, such as lighting variation, occlusion, viewpoint changes, etc. To this end, many research efforts are devoted to image representation with descriptive and discriminative local features.
Given an image, the extraction of local feature usually
*Corresponding Author: Min Wang and Wengang Zhou.
Figure 1. Attention maps of three methods. (a) and (b): attention maps generated by DELF [23] and HOW [37]. (c): attention maps generated by our method. HOW and DELF only generate a sin-gle attention map focusing on limited patterns, while our method focuses on diverse patterns by generating multiple attention maps. involves local region detection and image patch descrip-tion, where the former identiﬁes salient regions of interest in the image which is further described into a vector of pre-deﬁned dimension by the latter. Before the advent of deep learning, local visual features are designed in a hand-crafted way [20, 2], which is also regarded as a kind of shallow fea-ture. With the introduction of deep learning to computer vision, tremendous progress [35, 21, 7, 6, 37, 23] has been made on local feature learning in a data-driven paradigm.
Early works on deep local feature ignores the local re-gion detection. Some works [35, 21, 7] assume the im-age patch is ready from hand-crafted detectors and focus on learning a vector from an image patch with CNNs in a supervised learning way. Some other works [32, 38, 1, 19, 9, 27] directly take the activation map from a convo-lution layer and regard the channel features in each spatial position of the map as a local feature. Such local feature essentially corresponds to a relatively ﬁxed receptive ﬁeld in the input image. Recently, more and more research ef-forts [37, 23, 4, 34] resort to attention learning to discrimi-nate deep local features with only image-level annotation.
In those methods, a single attention map is typically ex-tracted to measure the signiﬁcance of each deep local fea-ture, as illustrated in Fig. 1. Generally, an attention map corresponds to some semantic-aware visual pattern. Con-sidering the diverse content in an image, a single attention map is unlikely to comprehensively capture all potential se-mantic patterns in an image.
To address the above issue, we propose a new framework with multiple dynamic attentions to detect diverse local fea-tures corresponding to different semantic patterns. In our method, we make use of intermediate feature maps from
CNNs to generate attention maps. To decouple different semantic patterns, we introduce a channel mapping layer to adaptively reorganize the channels of input feature maps into multiple groups, each of which is fed to an attention head. In the attention head, we design a new dynamic at-tention module. Specially, we introduce a diversity regular-ization to ensure different heads focus on different patterns within the image. In the training stage, we perform atten-tion pooling with the feature map and the multiple atten-tion maps to generate a set of global representations and the whole network is optimized with image-level label. In the testing stage, we make use of those dynamic attention maps to select deep local features to represent each image. To achieve efﬁcient retrieval on large image database, we quan-tize those deep local features with a codebook and match images with binarized aggregated match kernel [37].
Compared with previous attention-based local feature leaning methods, our approach is able to discover more di-verse and distinctive local patterns, which favorably beneﬁt the semantic content matching between images. We evalu-ate our approach on the Revisited Oxford and Paris datasets, which are further mixed with a million distractors. Abla-tion studies justify the effectiveness of the channel mapping layer, dynamic attention module, and diversity regulariza-tion loss. Our approach achieves superior performance over the existing state-of-the-art methods under similar setting. 2.