Abstract
Advances in deep learning, combined with availability of large datasets, have led to impressive improvements in face presentation attack detection research. However, state-of-the-art face antispoofing systems are still vulnerable to novel types of attacks that are never seen during training.
Moreover, even if such attacks are correctly detected, these systems lack the ability to adapt to newly encountered at-tacks. The post-training ability of continually detecting new types of attacks and self-adaptation to identify these attack types, after the initial detection phase, is highly appealing.
In this paper, we enable a deep neural network to detect anomalies in the observed input data points as potential new types of attacks by suppressing the confidence-level of the network outside the training samples’ distribution. We then use experience replay to update the model to incorporate knowledge about new types of attacks without forgetting the past learned attack types. Experimental results are provided to demonstrate the effectiveness of the proposed method on two benchmark datasets as well as a newly introduced dataset which exhibits a large variety of attack types.1 1.

Introduction
Smartphones with facial authentication features have made biometric systems remarkably common in our every-day lives. This is in addition to less prevalent and more traditional, yet critical, applications of biometric systems, such as automatic passport control and access control to high-security facilities. As services based on biometric recogni-tion technologies gain popularity, presentation attack detec-tion (PAD) is becoming a more crucial requirement for these systems. In parallel, attackers continually attempt to gain unauthorized access by designing new attack types, which makes developing defense mechanisms against presentation attacks more challenging. The goal of a PAD algorithm is to classify whether the presented input to the system is a 1Code is available at github.com/mrostami1366. bona-fide presentation (BF) or a presentation attack (PA), so that access is denied for PAs. While recognition systems for all biometric modalities, such as fingerprint and iris, are vulnerable to presentation attacks, the face modality poses a higher risk and extra challenges due to the easy access to high resolution face images of most people, e.g., through social media, and due to the relatively easier fabrication of face PAs. In this paper we exclusively focus on face PAD.
Similar to most sub-fields in computer vision, advances in deep learning, which is inspired by the nervous system [17], have led to significant face PAD improvements on bench-mark datasets using convolutional neural network-based (CNN) end-to-end representation learning and classifica-tion [1, 7, 12, 20, 39, 42, 36, 4, 41]. Following the standard pipeline of supervised learning for deep learning, a large, labeled training dataset, which consists of known attacks and bona-fide data points, is collected, and then used to train a deep network with a suitable architecture [10, 17, 5].
The vulnerability of using the aforementioned pipeline for PAD is that attackers can continually generate new types of PAs that are unknown to the system, i.e., absent in the training dataset. Since deep networks suffer from overconfi-dence in their predictions [14], the system may not be able to identify novel attack types, generated at inference time after the initial training. Even if the unknown attack types can be identified, the standard deep learning pipeline necessitates collecting a sufficient number of samples of new attack types and augmenting the training dataset. The model then needs to be retrained from scratch (or fine-tuned) on the augmented dataset [26]. However, collecting labeled data is time con-suming, model retraining is computationally inefficient, and both usually involve human intervention [24]. As a result, it is highly desirable to enable biometric recognition systems to identify novel attack types on-the-fly, during deployment, and then to autonomously adapt their classifications models for recognizing these new attack types in the future.
We develop an algorithm for continual detection of emerg-ing novel types of face PAs. Our objective is to enable the system to identify novel PAs. The model then is updated to learn new attack types such that it does not forget the
past learned attack types. Our idea is based on enabling the network to identify new attack types as testing samples that are outside the training distribution samples (OTDS) in an embedding space [11, 29, 40, 19, 4]. The base model is then updated to classify these samples as new attacks types in a continual learning (CL) setting, where catastrophic forget-ting [3] is addressed using experience replay [23]. Despite being effective in continual learning (CL) settings, the idea of detecting OTDS has not been explored for PAD.
The main contributions of our work are as follows:
• A new formulation of face PAD as a continual learning problem to equip a PAD system with defense mecha-nisms that allow learning novel attack types continually.
• An algorithm to identify novel attack types as OTDS anomalies by continually screening the input data rep-resentations and enable the model to correctly classify them as attacks, in the future, via experience replay.
• A new face anti-spoofing dataset with diverse attack types to evaluate our algorithm in CL settings. 2.