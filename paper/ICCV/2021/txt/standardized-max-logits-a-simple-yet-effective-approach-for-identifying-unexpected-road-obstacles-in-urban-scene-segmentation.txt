Abstract
Identifying unexpected objects on roads in semantic seg-mentation (e.g., identifying dogs on roads) is crucial in safety-critical applications. Existing approaches use im-ages of unexpected objects from external datasets or re-quire additional training (e.g., retraining segmentation net-works or training an extra network), which necessitate a non-trivial amount of labor intensity or lengthy inference time. One possible alternative is to use prediction scores of a pre-trained network such as the max logits (i.e., maximum values among classes before the ﬁnal softmax layer) for de-tecting such objects. However, the distribution of max logits of each predicted class is signiﬁcantly different from each other, which degrades the performance of identifying un-expected objects in urban-scene segmentation. To address this issue, we propose a simple yet effective approach that standardizes the max logits in order to align the different distributions and reﬂect the relative meanings of max log-its within each predicted class. Moreover, we consider the local regions from two different perspectives based on the intuition that neighboring pixels share similar semantic in-formation. In contrast to previous approaches, our method does not utilize any external datasets or require additional training, which makes our method widely applicable to ex-isting pre-trained segmentation models. Such a straightfor-ward approach achieves a new state-of-the-art performance on the publicly available Fishyscapes Lost & Found leader-board with a large margin. Our code is publicly available at this link1. 1.

Introduction
Recent studies [7, 8, 18, 34, 36, 37, 11] in semantic segmentation focus on improving the segmentation per-formance on urban-scene images. Despite such recent ad-vances, these approaches cannot identify unexpected ob-jects (i.e., objects not included in the pre-deﬁned classes during training), mainly because they predict all the pixels as one of the pre-deﬁned classes. Addressing such an is-sue is critical especially for safety-critical applications such as autonomous driving. As shown in Fig. 1, wrongly pre-dicting a dog (i.e., an unexpected object) on the road as the road does not stop the autonomous vehicle, which may lead to roadkill. In this safety-critical point of view, the dog should be detected as an unexpected object which works as the starting point of the autonomous vehicle to handle these objects differently (e.g., whether to stop the car or circum-vent the dog).
Several studies [3, 22, 21, 4, 29, 2, 13] tackle the problem of detecting such unexpected objects on roads. Some ap-* indicates equal contribution 1https://github.com/shjung13/Standardized-max-logits
Figure 2: Box plots of MSP, max logit, and standardized max logit in Fishyscapes Static. X-axis denotes the classes which are sorted by the occurrences of pixels in the training phase. Y-axis denotes the values of each method. Red and blue represent the distributions of values in in-distribution pixels and unexpected pixels, respectively. The lower and upper limits of each bar indicate the Q1 and Q3 while the dot represents the mean value of its predicted class. The gray indicates the overlapped regions of the two groups. The opacity of the gray region is proportional to the FPR at TPR 95%. Standardizing the max logits in a class-wise manner clearly reduces the FPR. proaches [2, 4] utilize external datasets [30, 20] as samples of unexpected objects while others [22, 33, 21, 27] leverage image resynthesis models for erasing the regions of such objects. However, such approaches require a considerable amount of labor intensity or necessitate a lengthy inference time. On the other hand, simple approaches which leverage only a pre-trained model [16, 19, 17] are proposed for out-of-distribution (OoD) detection in image classiﬁcation, the task of detecting images from a different distribution com-pared to that of the train set. Based on the intuition that a correctly classiﬁed image generally has a higher maximum softmax probability (MSP) than an OoD image [16], MSP is used as the anomaly score (i.e., the value used for detecting
OoD samples). Alternatively, utilizing the max logit [15] (i.e., maximum values among classes before the ﬁnal soft-max layer) as the anomaly score is proposed, which out-performs using MSP for detecting anomalous objects in se-mantic segmentation. Note that high prediction scores (e.g.,
MSP and max logit) indicate low anomaly scores and vice versa.
However, directly using the MSP [16] or the max logit [15] as the anomaly score has the following limita-tions. Regarding the MSP [16], the softmax function has the fast-growing exponential property which produces highly conﬁdent predictions. Pre-trained networks may be highly conﬁdent with OoD samples which limits the performance of using MSPs for detecting the anomalous samples [19]. In the case of the max logit [15], as shown in Fig. 2, the val-ues of the max logit have their own ranges in each predicted class. Due to this fact, the max logits of the unexpected ob-jects predicted as particular classes (e.g., road) exceed those of other classes (e.g., train) in the in-distribution objects.
This can degrade the performance of detecting unexpected objects on evaluation metrics (e.g., AUROC and AUPRC) that use the same threshold for all classes.
In this work, inspired by this ﬁnding, we propose stan-dardizing the max logits in a class-wise manner, termed standardized max logits (SML). Standardizing the max log-its aligns the distributions of max logits in each predicted class, so it enables to reﬂect the relative meanings of val-ues within a class. This reduces the false positives (i.e., in-distribution objects detected as the unexpected objects, highlighted as gray regions in Fig. 2) when using a single threshold.
Moreover, we further improve the performance of iden-tifying unexpected obstacles using the local semantics from two different perspectives. First, we remove the false pos-itives in boundary regions where predicted class changes from one to another. Due to the class changes, the boundary pixels tend to have low prediction scores (i.e., high anomaly scores) compared to the non-boundary pixels [32, 1]. In this regard, we propose a novel iterative boundary sup-pression to remove such false positives by replacing the high anomaly scores of boundary regions with low anomaly scores of neighboring non-boundary pixels. Second, in or-der to remove the remaining false positives in both bound-ary and non-boundary regions, we smooth them using the neighboring pixels based on the intuition that local consis-tency exists among the pixels in a local region. We term this process as dilated smoothing.
The main contributions of our work are as follows:
• We propose a simple yet effective approach for identi-fying unexpected objects on roads in urban-scene se-mantic segmentation.
• Our proposed approach can easily be applied to vari-ous existing models since our method does not require additional training or external datasets.
• We achieve a new state-of-the-art performance on the publicly available Fishyscapes Lost & Found Leader-board2 among the previous approaches with a large 2https://ﬁshyscapes.com/
Figure 3: Overview of our method. We obtain the max logits from a segmentation network and (a) standardize it using the statistics obtained from the training samples. (b) Then, we iteratively replace the standardized max logits of boundary regions with those of surrounding non-boundary pixels. (c) Finally, we apply dilated smoothing to consider local semantics in broad receptive ﬁelds. margin and negligible computation overhead while not requiring additional training and OoD data. 2.