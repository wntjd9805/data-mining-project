Abstract
We show that relation modeling between visual elements matters in cropping view recommendation. Cropping view recommendation addresses the problem of image recompo-sition conditioned on the composition quality and the rank-ing of views (cropped sub-regions). This task is challeng-ing because the visual difference is subtle when a visual element is reserved or removed. Existing methods repre-sent visual elements by extracting region-based convolu-tional features inside and outside the cropping view bound-aries, without probing a fundamental question: why some visual elements are of interest or of discard? In this work, we observe that the relation between different visual ele-ments significantly affects their relative positions to the de-sired cropping view, and such relation can be characterized by the attraction inside/outside the cropping view bound-aries and the repulsion across the boundaries. By instan-tiating a transformer-based solution that represents visual elements as visual words and that models the dependen-cies between visual words, we report not only state-of-the-art performance on public benchmarks, but also interesting visualizations that depict the attraction and repulsion be-tween visual elements, which may shed light on what makes for effective cropping view recommendation. 1.

Introduction
Image composition is one of key factors in professional photography. The term ‘composition’ can be considered
‘the organization of the elements of art’ [49]. Sad to say, the skills and tricks for organizing visual elements are the main barrier that prevents ordinary people from taking pro-fessional photos. Nonetheless, many amateurs are still ea-ger to compose photos like a photographer, even without ex-pertise and training. The demand for automatic composition has thus come into the eye of computer vision community,
*Corresponding author
Figure 1. Conceptual difference between prior arts and ours. (a) Predecessors recompose images with region-of-interest (RoI) and region-of-discard (RoD) features [51] which depict the pres-ence of visual components rather than the organization. (b) Our insight is to model the organization of visual elements (image patches) using attraction and repulsion dependencies. and much effort has been made to solve image recomposi-tion [8, 18, 27, 38, 48, 51].
One of off-the-shelf and low-end technologies for im-age recomposition [20] is image cropping. It aims to find the most aesthetic view (a sub-region defined by the crop-ping box) in an image. The typical paradigm of image cropping is to rank candidate views and to retrieve appro-priate ones. This task is also given the name of cropping view recommendation. A straightforward idea is to score and rank candidate views by artificially designed evalua-tion criteria. However, such criteria cannot cover the prin-ciples of art and align poorly with the actual preference of users. Recently another promising way is to learn directly from data [31, 48, 51]. In particular, convolutional models are developed as possible solutions to the dilemma above.
These data-driven methods predict scores conditioned on region-aware features that delineate the presence of visual elements (Fig. 1(a)).
In this way, these methods can be viewed as finding connections between the presence of vi-sual elements and the good composition. However, accord-ing to the definition of composition, we argue that what ex-plains why a cropping view is of good composition is not the presence of visual elements, but the harmony in the or-ganization between them. Since the organization is often interpreted as relation between elements [12], composition patterns should be found in the dependencies between vi-sual elements.
Convolutional networks, however, are weak in modeling dependencies. First, long-range dependencies can only be encoded when the receptive field is sufficiently large. Sec-ond, the difficulty in optimization [17, 36] causes multi-hop dependency modeling [46] such that messages are hard to travel between distant positions. This is also why the em-pirical receptive field is limited [29]. In the field of natu-ral language processing [1, 39, 42], this problem has been studied in depth and addressed well with the transformer architecture [42]. Transformer [42] can precisely model all pairwise dependencies in a parallel manner. Since modeling parallel relation is important in cropping view recommenda-tion, we believe transformer can be an effective tool to mine relation-aware composition patterns.
In this work, we propose to explicitly encode the de-pendencies of visual elements inside, outside, and across the cropping view boundaries (Fig. 1(b)). In particular, we borrow the concept of ‘visual words’ in [11] to represent visual elements and model pairwise dependencies between the visual words via repeated attentional operators [1, 22].
We intend to characterize two forms of dependencies: the attraction dependency and the repulsion dependency. The attraction dependency aims to contribute to the global har-mony between expected foreground visual words, e.g., the two persons in Fig. 1(b), or between aesthetically neces-sary background visual words, e.g., the surrounding ice and glacier; the repulsion dependency is used to depict the se-mantically/spatially incompatible relation against the de-sired visual words, e.g., the superfluous ice land that weak-ens the role of the two persons. We believe the two de-pendencies can be used as a criterion to judge a candidate view: a desirable cropping box should not only reserve the main elements clustered by attraction but also discard the elements repulsive to the main subject. To implement the criterion, we propose the TransView model that encodes three types of dependencies: attraction inside the cropping boundaries, attraction outside the boundaries, and repulsion across the boundaries.
Experimental results on the public benchmarks show that TransView outperforms state-of-the-art region-feature-based methods. We also show that TransView does model the attraction and repulsion without supervision via inter-pretable activation maps. Further feature visualizations show that explicit encoding of the attraction and repulsion leads to distinguishable features of similar views. 2.