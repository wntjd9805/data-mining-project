Abstract
Recent research has shown that it is possible to find in-terpretable directions in the latent spaces of pre-trained
Generative Adversarial Networks (GANs). These directions enable controllable image generation and support a wide range of semantic editing operations, such as zoom or ro-tation. The discovery of such directions is often done in a supervised or semi-supervised manner and requires manual annotations which limits their use in practice. In compari-son, unsupervised discovery allows finding subtle directions that are difficult to detect a priori. In this work, we propose a contrastive learning-based approach to discover semantic
†Equal contribution. Author ordering determined by a coin flip. directions in the latent space of pre-trained GANs in a self-supervised manner. Our approach finds semantically mean-ingful dimensions compatible with state-of-the-art methods. 1.

Introduction
Generative Adversarial Networks (GANs) [7] are power-ful image synthesis models that have revolutionized gener-ative modeling in computer vision. Due to their success in synthesizing high-quality images, they are widely used for various visual tasks, including image generation [38], im-age manipulation [35], de-noising [34, 15], upscaling image resolution [30], and domain translation [39].
Until recently, GAN models have generally been inter-preted as black-box models, without the ability to control the generation of images. Some degree of control can be achieved by training conditional models such as [17] and changing conditions in generation-time. Another approach is to design models that generate a more disentangled latent space such as in InfoGAN [4] where each latent dimension controls a particular attribute. However, these approaches require labels and provide only limited control, depending on the granularity of available supervised information.
Albeit some progress has been done, the question of what knowledge GANs learn in the latent representation and how these representations can be used to manipulate images is still an ongoing research question. Early attempts to explicitly control the underlying generation process of
GANs include simple approaches, such as modifying the latent code of images [22] or interpolating latent vectors
[11]. Recently, several approaches have been proposed to explore the structure of latent space in GANs in a more prin-cipled way [10, 26, 9, 33, 21]. Most of these works discover domain-agnostic interpretable directions such as zoom, ro-tation, or translation, while other find domain-specific di-rections such as changing gender, age or expression on fa-cial images. Typically, such methods either identify or op-timize for directions and then shift the latent code in these directions to increase or decrease target semantics in the im-age.
In an optimization-based approach that uses a self-supervised contrastive objective to find interpretable directions in
GANs. In particular, we use the differences caused by an edit operation on the feature activations to optimize the identifiability of each direction. Our contributions are as follows: introduce LatentCLR, paper, we this
• We propose to use contrastive learning on feature di-vergences to discover interpretable directions in the la-tent space of pre-trained GAN models such as Style-GAN2 and BigGAN.
• We show that our method can find distinct and fine-grained directions on a variety of datasets, and that the obtained directions are highly transferable between
ImageNet [24] classes.
• We make our implementation publicly available to encourage further research in this area: https:// github.com/catlab-team/latentclr. 2.