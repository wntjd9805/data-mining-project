Abstract
For successful semantic editing of real images, it is crit-ical for a GAN inversion method to find an in-domain la-tent code that aligns with the domain of a pre-trained GAN model. Unfortunately, such in-domain latent codes can be found only for in-range images that align with the training images of a GAN model. In this paper, we propose BDInvert, a novel GAN inversion approach to semantic editing of out-of-range images that are geometrically unaligned with the training images of a GAN model. To find a latent code that is semantically editable, BDInvert inverts an input out-of-range image into an alternative latent space than the orig-inal latent space. We also propose a regularized inversion method to find a solution that supports semantic editing in the alternative space. Our experiments show that BDInvert effectively supports semantic editing of out-of-range images with geometric transformations. 1.

Introduction
Generative adversarial networks (GANs) are generative models that can synthesize realistic-looking images [7].
Typically, GANs learn a mapping function from a random noise vector sampled from a pre-defined distribution to a realistic-looking image through the adversarial training of a generator and a discriminator. For the past several years, a significant progress has been made to improve the qual-ity and diversity of synthesized images [21, 14, 15, 16, 5].
As a result, recent GAN models such as StyleGAN [15],
StyleGAN2 [16], and BigGAN [5] can produce extremely high-quality images of high resolution.
Recently, it has been shown that rich semantic informa-tion is encoded in the intermediate features and the latent space of GANs, and furthermore, that images can be effec-tively edited in a semantically meaningful way by modify-ing features or latent code [21, 4, 26, 23, 10]. To enable such semantic editing for real images, GAN inversion has attracted much attention lately [3, 1, 31, 33]. GAN inver-sion maps a real image into the latent space of a pre-trained
GAN model. Once an inverted latent code is obtained, the image can be semantically edited by modifying its latent code or intermediate features generated from the code.
For successful semantic editing of real images, it is criti-cal to find an in-domain latent code that aligns with the do-main of a pre-trained GAN model [31]. As shown in [31], there may exist more than one latent codes that can recon-struct a given input image, and some of them may be out of the domain. The semantic knowledge encoded in the latent space does not apply for such out-of-domain codes, thus se-mantic editing of such codes fails to produce proper results.
Unfortunately, such in-domain latent codes can be found only for a small fraction of real images that align with the training images of a pre-trained GAN model. For example, most GAN models use geometrically aligned face images as their training data for ease of training. As a result, images with a small amount of translation or other geometric trans-formations are out of their ranges, and the previous GAN inversion methods cannot find in-domain latent codes for such out-of-range images. This severely limits the applica-bility of semantic editing of real images using GAN inver-sion. Fig. 1 shows real-world examples. The input images in (a) and (d) are random images downloaded from internet.
As they are out-of-range with different rotation, scaling and translation with respect to the training dataset (FFHQ [15]), directly applying a previous GAN inversion method [22] produces unacceptable results as shown in (b) and (e).
One solution would be to align a target image before
GAN inversion, but accurate alignment of an image to the training data can be difficult or even impossible especially
in the case of arbitrary natural images. For example, for the image in Fig. 1(d), a face alignment method [17] completely fails due to severe cropping.
In this paper, we propose a novel GAN inversion ap-proach to semantic editing of out-of-range images, which is dubbed Base-Detail Invert (BDInvert). BDInvert inverts a geometrically unaligned image with the training images for
StyleGAN [15] and StyleGAN2 [16]. Specifically, BDIn-vert is designed to cover geometric transformations such as translation, rotation, and scaling, and supports various types of editing for out-of-range images that are not supported by previous approaches.
Our key idea is as follows. It is impossible to invert an out-of-range image to an in-domain latent code in the orig-inal latent space of a pre-trained GAN model. Instead, we propose to invert an image into another space that we refer to as the F/W +, which consists of two subspaces F and
W +. The base code space F encodes geometric transforma-tions and also supports diverse local variations that enable more faithful reconstruction of an input image. On the other hand, the detail code space W + is independent of geometric transformations and supports semantic manipulations.
To find a latent code in the F/W + space that faith-fully reconstructs an input image, we adopt an optimization-based approach. However, na¨ıve optimization of a recon-struction loss does not guarantee a latent code that supports semantic editing. To enable semantic editing, we also pro-pose a regularization approach based on an encoder net-work. Fig. 1(c) and (f) show our reconstruction and editing results of real-world images. Thanks to our F/W + space and inversion approach, we can successfully reconstruct and edit the out-of-range real-world input images.
Our main contributions can be summarized as follows.
• We propose BDInvert, a novel GAN inversion ap-proach to semantic editing of real images with geomet-ric transformations that are not aligned with the train-ing images of a pre-trained GAN model.
• BDInvert projects an image into an alternative latent space F/W + that supports more faithful reconstruc-tion and semantic editing of out-of-range images with geometric transformations and diverse local variations.
• We propose a novel regularization method to find a proper solution in the F/W + space that supports se-mantic image editing. 2.