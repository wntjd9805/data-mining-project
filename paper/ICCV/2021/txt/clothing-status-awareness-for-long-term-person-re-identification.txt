Abstract
Long-Term person re-identification (LT-reID) exposes extreme challenges because of the longer time gaps be-tween two recording footages where a person is likely to change clothing. There are two types of approaches for
LT-reID: biometrics-based approach and data adaptation based approach. The former one is to seek clothing irrele-vant biometric features. However, seeking high quality bio-metric feature is the main concern. The latter one adopts fine-tuning strategy by using data with significant clothing change. However, the performance is compromised when it is applied to cases without clothing change. This work argues that these approaches in fact are not aware of cloth-ing status (i.e., change or no-change) of a pedestrian. In-stead, they blindly assume all footages of a pedestrian have different clothes. To tackle this issue, a Regularization via
Clothing Status Awareness Network (RCSANet) is proposed to regularize descriptions of a pedestrian by embedding the clothing status awareness. Consequently, the description can be enhanced to maintain the best ID discriminative fea-ture while improving its robustness to real-world LT-reID where both clothing-change case and no-clothing-change case exist. Experiments show that RCSANet performs rea-sonably well on three LT-reID datasets. 1.

Introduction
Person re-Identification (re-ID) is to confirm the identity of a person in visual traces. Based on the scale of time gaps when footages are captured, there are two different scenarios for person re-ID: 1) Short-Term re-ID (ST-reID) and 2) Long-Term re-ID (LT-reID). The first scenario nor-mally addresses the time gap of several minutes.
In this case, we can safely assume that a person does not change clothing. This scenario is investigated first by the research community and produces many state-of-the-art works with encouraging performance [15, 41, 39, 45, 12, 10, 11]. In recent years, more researches have focused on LT-reID. In
LT-reID, the time gap between two footages can be several days or even longer. Therefore, besides significant chal-lenges of non-human factors (i.e., image resolution, illumi-nation, etc.) which can be observed in ST-reID, there are significant challenges caused by human factor (i.e., cloth-ing and dressing accessory) in LT-reID. Clothing change in particular is very common in LT-reID, although it may not necessarily change in some circumstances. Such changes dramatically constrain the performance of methods for ST-reID when they are applied to LT-reID directly.
In order to tackle the challenge shown in LT-reID, var-ious approaches are reported although they are still on a preliminary level. These approaches can be categorized into two types: 1) biometrics-based approach and 2) data adaptation based approach.
Biometrics-based approaches strive to avoid clothing-related information that is deemed not stable in LT-reID.
One type of these methods [36, 32, 37, 26, 21, 34, 17] ex-plore biometric features for LT-reID such as motion, body contour/shape, and face. Theoretically, the biometric fea-ture should be robust. However, it heavily relies on high-quality footages. For example, to obtain people motion features, it needs to successfully extract the human body from cluttered backgrounds and to track the human body throughout the entire video period. Due to limitations of image segmentation, tracking, and body part occlusion, it is implausible to guarantee the reliability of motion feature from footage [36]. Another type of biometrics-based ap-proach introduces additional depth information using RGB-D camera. The depth information does provide another source of helpful information (e.g., 3D biometric informa-tion) for LT-reID [1, 19, 6, 30]. However, it introduces extra complexity to the camera setup. In addition, due to its lim-ited sensing distance, it is still far from real practice.
Instead of using biometric information, data adaptation approaches attempt to use fine-tuning mechanisms [9, 13] by elevating the performance of models pretrained on a ST-reID dataset (e.g., Market-1501 [39]) before training LT-reID data with diverse clothing-change cases. Through
deliberately designed network architectures and loss func-tions, a model is able to tolerate clothing change to a cer-tain extent. This method also has certain limitations.
It expects a pretrained model to be adjusted on parameters by using clothing-change data. However, it does not ex-plicitly consider the actual clothing status (i.e., change or no-change) of each individual during training. That is, the method always tends to learn clothing irrelevant ID features from a certain amount of clothing-change data. Therefore, the core problem in the data adaptation approach is that it simply feeds the input footage into a complex model. How-ever, due to the lack of clothing status awareness, methods may cause sub-optimal performance when they handle the no-clothing-change case. The essence of a LT-reID method should correctly sense the clothing status of each individual in order to dynamically regularize ID features. These regu-larized ID features should be able to tackle clothing-change cases if any without sacrificing their discrimination ability when no-clothing-change cases also exist in LT-reID.
In light of the above discussion, this paper proposes a Regularization via Clothing Status Awareness Network (RCSANet). RCSANet decouples ID discriminative fea-ture learning and clothing status awareness learning into two separate processes in the early part of the network. In the later part of RCSANet, ID features can be regularized through a proposed Feature Regularization Module (FRM) in order to encourage them are more consistent when a per-son wears the same clothes. Such a regularization process is achieved by embedding the ability of clothing status aware-ness into FRM. In this way, RCSANet does not sacrifice performance on no-clothing-change cases while still main-taining its performance on clothing-change cases. It is note-worthy that the proposed RCSANet only requires ID labels throughout the entire training process. It does not require extra clothing type annotations.
Contributions of this paper can be summarized in three-fold: 1) Unlike existing biometrics-based approaches and data adaptation based approaches, this paper proposes a 2) The novel clothing status aware LT-reID solution. proposed RCSANet explicitly builds up a clothing status awareness learning process, which is used to enhance the robustness of ID features for handling both clothing-change case and no-clothing-change case in LT-reID. 3) Extensive experiments are conducted to demonstrate the effectiveness of our RCSANet on three LT-reID benchmarks where both clothing-change case and no-clothing-change case exist. 2.