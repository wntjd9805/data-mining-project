Abstract
Unsupervised domain adaptation (UDA) methods can dramatically improve generalization on unlabeled target domains. However, optimal hyper-parameter selection is critical to achieving high accuracy and avoiding negative transfer. Supervised hyper-parameter validation is not pos-sible without labeled target data, which raises the ques-tion: How can we validate unsupervised adaptation tech-niques in a realistic way? We first empirically analyze ex-isting criteria and demonstrate that they are not very ef-Intuitively, a well-fective for tuning hyper-parameters. trained source classifier should embed target samples of the same class nearby, forming dense neighborhoods in feature space. Based on this assumption, we propose a novel unsupervised validation criterion that measures the density of soft neighborhoods by computing the en-tropy of the similarity distribution between points. Our criterion is simpler than competing validation methods, yet more effective; it can tune hyper-parameters and the number of training iterations in both image classification and semantic segmentation models. The code used for the paper will be available at https://github.com/
VisionLearningGroup/SND. 1.

Introduction
Deep neural networks can learn highly discriminative representations for visual recognition tasks [11, 39, 19, 29, 14], but do not generalize well to out-of-domain data [47].
To improve performance on a new target domain, Unsuper-vised Domain Adaptation (UDA) aims to transfer represen-tations from a label-rich source domain without additional supervision. Recent UDA methods primarily achieve this through unsupervised learning on the target domain, e.g., by minimizing the feature distribution shift between source and target domains [12, 21, 41], classifier confusion [17], clus-tering [34], and pseudo-label based methods [56]. Promis-ing adaptation results have been demonstrated on image classification [22, 55, 8, 52, 43], semantic segmentation [16]
Figure 1:
In unsupervised domain adaptation, validation is a significant and unsolved issue. Performance can be sensitive to hyper-parameters, yet no reliable validation criteria have been pre-sented. In this work, we provide a new criterion, SND, to select proper hyper-parameters for model validation in UDA. The exam-ple shows validation of the ADVENT [50] segmentation model. and object detection [9] tasks.
However, adaptation methods can be highly sensitive to hyper-parameters and the number of training iterations. For example, the adversarial alignment approach is popular in semantic segmentation [16, 44, 50], but can fail badly with-out careful tuning of the loss trade-off weight as shown in Fig. 1. In addition, many methods have other kinds of hyper-parameters, e.g., defining the concentration of clus-ters [34], the confidence threshold on target samples [56], etc. Therefore validation of hyper-parameters is an impor-tant problem in UDA, yet it has been largely overlooked. In
UDA, we assume not to have access to labeled target data, thus, hyper-parameter optimization (HPO) should be done without using target labels. In this paper, we would like to pose a question crucial to making domain adaptation more practical: How can we reliably validate adaptation methods in an unsupervised way?
Unsupervised validation is very challenging in practice, thus many methods do HPO in an ineffective, or even un-fair, way. Evaluating accuracy (risk) in the source domain is popular [12, 41, 5, 40, 22, 5, 17, 51, 53], but this will not
necessarily reflect success in the target domain. Using the risk of the target domain [37, 2, 3, 13, 35, 38, 32] contra-dicts the assumption of UDA. Many works [45, 42, 44, 25, 56, 54, 49, 50] do not clearly describe their HPO method.
To the best of our knowledge, no comprehensive study has compared validation methods across tasks and adapta-tion approaches in a realistic evaluation protocol. Our first contribution is to empirically analyze these existing criteria and demonstrate that they are not very effective for HPO.
This exposes a major barrier to the practical application of state-of-the-art unsupervised domain adaptation methods.
To tackle this problem, we first revisit an unsupervised
If validation criterion based on classifier entropy, C-Ent. the classification model produces confident and low-entropy outputs on target samples, then the target features are dis-criminative and the prediction is likely reliable. Morerio et al. [24] propose to utilize C-Ent to do HPO but only evaluated it on their own adaptation method. We evalu-ate C-Ent extensively, across various adaptation methods, datasets, and vision tasks. We reveal that C-Ent is very ef-fective for HPO for several adaptation methods, but also expose a critical issue in this approach, which is that it can-not detect the collapse of neighborhood structure in target samples (See Fig. 2). By neighborhood structure, we mean the relationship between samples in a feature space. Be-fore any adaptation, target samples embedded nearby are highly likely in the same class (No adaptation in Fig. 2). A good UDA model will keep or even enhance the relation-ships of target samples while aligning them to the source.
However, a UDA model can falsely align target samples with the source and incorrectly change the neighborhood structure ((DANN in Fig. 2). Even in this case, C-Ent can become small and choose a poorly-adapted model.
Natekar et al. [26] measure the consistency of feature embeddings within a class and their discrepancy from other classes to predict the generalization of supervised models by using labeled samples. Accounting for such relation-ships between points is a promising way to overcome the is-sues of C-Ent. But, since computing these metrics requires labeled samples, we cannot directly apply this method.
This leads us to propose a novel unsupervised validation criterion that considers the neighborhood density of the un-labeled target. Our notion of a neighborhood is soft, i.e. we do not form explicit clusters as part of our metric computa-tion. Rather, we define soft neighborhoods of a point using the distribution of its similarity to other points, and measure density as the entropy of this distribution. We assume that a well-trained source model will embed target samples of the same class nearby and thus will form dense implicit neigh-borhoods. The consistency of representations within each neighborhood should be preserved or even enhanced by a well-adapted model. Monitoring the density thus enables us to detect whether a model causes the collapse of implicit
Method
Source Risk
IWV [40, 53]
Entropy [24]
SND (Ours)
✗
✗
✓
✓
Technical Advantages w/ Xt w/o Xs, Ys w/o HP
Test split
+Density Model
✓
✓
Stability across methods
✗
✗
✗
✓
✗
✗
✓
✓
Table 1: Technical comparison with other validation approaches.
Xt denotes unlabeled target, and (Xs, Ys) denote labeled source samples. SND computes a score on unlabeled target samples.
Empirically, we verify that our method is stable across different datasets, methods, and tasks. neighborhood structure as shown in Fig. 2.
Our proposed metric, called Soft Neighborhood Density (SND), is simple yet more effective than competing valida-tion methods. Rather than focusing on the source and target relationship (like IWV [40] or DEV [53]), we measure the discriminability of target features by computing neighbor-hood density and choosing a model that maximizes it.
We demonstrate that target accuracy is consistent with our criterion in many cases. Empirically, we observe that
SND works well for closed and partial domain adaptive im-age classification, as well as for domain adaptive semantic segmentation. SND is even effective in choosing a suitable source domain given an unlabeled target domain.
Our contributions are summarized as follows:
• We re-evaluate existing criteria for UDA and call for more practical validation of DA approaches.
• We propose Soft Neighborhood Density metric which considers target neighborhood structure, improves upon class entropy (C-Ent) and achieves performance close to optimal (supervised) HPO in 80% cases on closed, partial DA, and domain adaptive semantic seg-mentation. 2.