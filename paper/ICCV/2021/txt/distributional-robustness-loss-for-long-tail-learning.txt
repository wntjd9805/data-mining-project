Abstract
Real-world data is often unbalanced and long-tailed, but deep models struggle to recognize rare classes in the pres-ence of frequent classes. To address unbalanced data, most studies try balancing the data, the loss, or the classifier to reduce classification bias towards head classes. Far less at-tention has been given to the latent representations learned with unbalanced data. We show that the feature extractor part of deep networks suffers greatly from this bias. We propose a new loss based on robustness theory, which en-courages the model to learn high-quality representations for both head and tail classes. While the general form of the robustness loss may be hard to compute, we further de-rive an easy-to-compute upper bound that can be minimized efficiently. This procedure reduces representation bias to-wards head classes in the feature space and achieves new
SOTA results on CIFAR100-LT, ImageNet-LT, and iNaturalist long-tail benchmarks. We find that training with robustness increases recognition accuracy of tail classes while largely maintaining the accuracy of head classes. The new robust-ness loss can be combined with various classifier balancing techniques and can be applied to representations at several layers of the deep model. 1.

Introduction
Figure 1: Our distributional robustness loss is designed for learning a representation where samples are kept close to the centroid of their class. Here, the empirical centroid (cid:99)µ2 (framed pink triangle) is estimated based only on few samples (four pink triangles) and as a result it deviates far from the true centroid (µ2). Our loss pulls the same-class samples (green arrow), and pushes away other-class samples (red arrows). The loss takes into account the estimation error by pushing and pulling towards a worst-case possible distribution within an uncertainty area around the estimated centroid (dashed red line). Uncertainty areas are typically larger for tail classes, compared with head classes that have many samples (blue dashed line around (cid:99)µ1).
Real-world data typically has a long-tailed distribution over semantic classes: few classes are highly frequent, while many classes are only rarely encountered. When trained with such unbalanced data, deep models tend to produce predictions that are biased and over-confident towards head classes and fail to recognize tail classes.
Early approaches for handling unbalanced data used re-sampling [12, 17] or loss reweighing [18, 27] aiming to re-balance the training process. Other approaches address unbalanced data by transferring information from head to tail classes [31, 46, 41, 29], or by applying an adaptive loss
[6] or regularization of classifiers [21]. The main focus of these techniques is on balancing the multi-class classifier.
Far less attention has been given to the latent representa-tions learned with unbalanced data. Intuitively, head classes are encountered more often during training and are expected to dominate the latent representation at the top layer of a deep model. Counter to this intuition, [21] compared a series of techniques for rebalancing representations and concluded that ”data imbalance might not be an issue in learning high-quality representations”, and that strong long-tailed recognition can be achieved by only adjusting the classifier.
However, the effect of unbalanced data on the learned rep-resentations is far from being understood, and the extent to which it may hurt classification accuracy is unknown. While existing rebalancing methods do not improve representa-tions, the question remains if better representations could substantially improve recognition with unbalanced data.
The current paper focuses on improving the representa-tion layer of deep models trained with unbalanced data. We show that large gains in accuracy can be achieved simply by balancing the representation at the last layer. The key insight is that the distribution of training samples of tail classes does not represent well the true distribution of the data. This yields representations that hinder the classifier applied to that representation.
To address this problem, we introduce ideas from robust optimization theory. We design a loss that is more robust to the uncertainty and variability of tail representations. Stan-dard training follows Empirical Risk Minimization (ERM), which is designed to learn models that perform well on the training distribution. However, ERM assumes that the test distribution is the same as the training distribution, and this assumption often breaks with tail classes. In comparison,
Distributionally Robust Optimization (DRO) [28, 14, 4] is designed to be robust against likely shifts of the test distri-bution. It learns classifiers that can handle the worst-case distribution within a neighborhood of the training distribu-tion. Figure 1 illustrates this idea.
In the general case, computing a loss based on a worst-case distribution may be computationally hard. Here, we show how the worst-case loss can be bounded from above, with a bound that has an intuitive form and can be easily minimized. The resulting bound allows us to minimize the
DRO loss, which only affects the representation, and to combine it with a standard classification loss, which tunes a classifier on top of the representation.
The main contributions of this paper are: 1. We formulate learning with unbalanced data as a prob-lem of robust optimization and highlight the role of high variance in hindering tail accuracy. 2. We develop a new loss, DRO-LT Loss, based on distri-butional robustness optimization for learning a balanced feature extractor. Training with DRO-LT yields repre-sentations that capture well both head and tail classes. 3. We derive an upper bound of the DRO-LT loss that can be computed and optimized efficiently. We further show how to learn the robustness safety margin for each class, jointly with the task, avoiding additional hyper-parameter tuning. 4. We evaluate our approach on four long-tailed visual recognition benchmarks: CIFAR100-LT, CIFAR10-LT,
ImageNet-LT, and iNaturalist. Our proposed method consistently achieve superior performance over previ-ous models. 2.