Abstract
Model compression aims to deploy deep neural networks (DNN) on mobile devices with limited computing and stor-age resources. However, most of the existing model com-pression methods rely on manually defined rules, which re-quire domain expertise. DNNs are essentially computa-tional graphs, which contain rich structural information.
In this paper, we aim to find a suitable compression policy from DNNs’ structural information. We propose an auto-matic graph encoder-decoder model compression (AGMC) method combined with graph neural networks (GNN) and reinforcement learning (RL). We model the target DNN as a graph and use GNN to learn the DNN’s embeddings auto-matically. We compared our method with rule-based DNN embedding model compression methods to show the effec-tiveness of our method. Results show that our learning-based DNN embedding achieves better performance and a higher compression ratio with fewer search steps. We evalu-ated our method on over-parameterized and mobile-friendly
DNNs and compared our method with handcrafted and learning-based model compression approaches. On over parameterized DNNs, such as ResNet-56, our method out-performed handcrafted and learning-based methods with 4.36% and 2.56% higher accuracy, respectively. Further-more, on MobileNet-v2, we achieved a higher compression ratio than state-of-the-art methods with just 0.93% accu-racy loss. 1.

Introduction
With the increasing demand to deploy deep neural net-works (DNNs) on edge devices (e.g., mobile phones, robots, self-driving cars, etc.), which usually have limited storage and computing power, model compression techniques be-came essential for efficient DNN deployment. Network pruning [10, 11, 32], factorization [46, 38], knowledge dis-tillation [36, 34, 16], and parameter quantization [10, 49, 19] are among the most well-known model compression techniques. However, these methods heavily rely on hand-crafted rules defined by experts, demanding an extensive amount of time and might not necessarily lead to a fully compressed model.
Recently, automatic model compression [14, 49, 27] has gained momentum. For example, Wang et al. [49] proposed a Bayesian automatic model compression method trained in a one-shot manner to find reasonable quantization poli-cies. He et al. [14] proposed an automatic model compres-sion method based on reinforcement learning (RL). How-ever, when representing DNNs, they rely on manually de-fined DNN embedding vector (e.g., using one-hot vectors to characterize DNN’s hidden layers) and ignore the rich structural information between the hidden layers.
DNNs are essentially represented as computational graphs in deep learning frameworks, such as TensorFlow [1] and PyTorch [35]. A computational graph is composed of numerous primitive operations (e.g., add, minus, mul-tiply), where edges are operations and nodes are intermedi-ate calculation results (i.e., feature maps in DNNs). Such a rich structural representation can effectively delineate the state of DNN hidden layers. Additionally, computational graphs often contain repetitive structural patterns due to the same set of primitive operations being used multiple times.
Thus, we aim to benefit from this feature by extracting the structural information readily available within computa-tional graphs to identify the redundancy and pruning policy for DNN hidden layers.
In this paper, we propose a graph-based Auto Graph encoder-decoder Model Compression (AGMC) method that combines graph convolutional networks (GCNs) [21, 53, 52] and reinforcement learning (RL) [25, 45, 43] to learn the compression strategy of DNNs without expert knowl-edge. The graph encoder-decoder aims to learn the DNN’s layer embeddings. The GCN-based graph encoder learns the DNN representation from its structure information, and the decoder decodes the representation to hidden layer em-beddings. The RL agent takes the hidden layer embed-dings as the environment states, looks for the pruning ratio for each hidden layer, and generates a corresponding com-pressed candidate model. Finally, we evaluate the candidate compressed model performance and provide a reward value as feedback to the RL agent. By exploiting DNN’s struc-ture information to suggest compression policies, our ap-proach successfully applied network pruning and achieved outstanding results on various DNNs, such as ResNet [12],
VGG-16 [44], MobileNet [17, 39], and ShuffleNet [54, 29].
In essence, this paper makes the following contributions:
• A novel automatic layer embedding based on compu-tational graph’s structure.
• An efficient method based on GCN and RL to auto-mate the channel pruning.
• State-of-the-art model pruning results on various DNN models. 2.