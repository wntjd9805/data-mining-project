Abstract
This paper investigates the problem of reconstructing hyperspectral (HS) images from single RGB images cap-tured by commercial cameras, without using paired HS and
RGB images during training. To tackle this challenge, we propose a new lightweight and end-to-end learning-based framework. Specifically, on the basis of the intrinsic imag-ing degradation model of RGB images from HS images, we progressively spread the differences between input RGB im-ages and re-projected RGB images from recovered HS im-ages via effective unsupervised camera spectral response function estimation. To enable the learning without paired ground-truth HS images as supervision, we adopt the adver-sarial learning manner and boost it with a simple yet effec-tive L1 gradient clipping scheme. Besides, we embed the se-mantic information of input RGB images to locally regular-ize the unsupervised learning, which is expected to promote pixels with identical semantics to have consistent spectral signatures. In addition to conducting quantitative experi-ments over two widely-used datasets for HS image recon-struction from synthetic RGB images, we also evaluate our method by applying recovered HS images from real RGB images to HS-based visual tracking. Extensive results show that our method significantly outperforms state-of-the-art unsupervised methods and even exceeds the latest super-vised method under some settings. The source code is pub-lic available at https://github.com/zbzhzhy/
Unsupervised-Spectral-Reconstruction. 1.

Introduction
As hyperspectral (HS) images delineate more reliable and accurate spectrum information of scenes than tradi-tional RGB images, they facilitate many vision-based appli-cations, such as visual tracking [44, 39], detection [26, 33],
*Corresponding author. This work was supported by the Hong Kong
Research Grants Council under grant CityU 11219019. and segmentation [34, 6]. However, it is costly to acquire
HS images [50], which severely limits its wide deployment.
Without relying on expensive and specially designed hardware, recovering HS images from single RGB images via computational methods promises a convenient and low-cost manner, and recent deep neural network (DNN)-based methods have demonstrated the impressive abilities in solv-ing such a highly ill-posed recovery problem. However, the majority of them have to be trained with paired RGB and
HS images [25, 49, 45]. Unfortunately, it is non-trivial to collect a large number of such paired data via specially de-signed devices, e.g., well calibrated dual cameras. Although one can inversely synthesize RGB images from available
HS images to form paired data for training, the huge gaps between the synthetic and real images may degrade the per-formance of a model trained with synthetic data when ap-plied to real data.
To tackle the above issues, as illustrated in Fig. 1, we propose a lighweight, unsupervised, and end-to-end learning-based framework, which is capable of recovering
HS images from single RGB images captured by commer-cial cameras without using paired RGB and HS images dur-ing training. Specifically, based on the low-dimensional property of camera spectral response functions (SRFs), we first propose a prior-driven method to estimate the underly-ing camera SRFs of input RGB images by extracting their deep features. Then, we propose an imaging degradation model-aware HS image generation approach, in which an
HS image is generated in a coarse-to-fine manner by pro-gressively spreading the information of the difference be-tween input RGB images and re-projected RGB images ob-tained by integrating recovered HS images via the estimated camera SRFs. Such a generation manner well adapts to this unsupervised scenario. To enable the meaningful learning of our method under the lack of paired ground-truth HS im-ages, we make types of efforts: (1) globally, we employ the popular and powerful adversarial learning to enforce the distribution of generated HS images to be close to that of real HS images, Moreover, we propose L1 gradient clip-ping to stabilize and boost this learning manner; (2) locally, we embed the semantic information of scenes to encourage the pixels of reconstructed HS images with identical (resp. different) semantics to be similar (resp. dissimilar).
The main contributions of this paper are summarized as follows: 1. we propose an unsupervised HS image reconstruction framework from single RGB images in the wild; 2. we propose imaging degradation model-aware HS im-age generation and prior-driven unsupervised estima-tion of camera spectral response functions; 3. we propose to embed scenesâ€™ semantic information ef-ficiently to regularize the unsupervised learning; 4. we propose a simple yet effective L1 gradient clipping strategy to stabilize and boost adversarial learning; and 5. we introduce visual tracking-based quality evaluation of HS images recovered from real RGB images. 2.