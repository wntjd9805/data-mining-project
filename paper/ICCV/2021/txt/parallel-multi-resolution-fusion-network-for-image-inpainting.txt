Abstract
Conventional deep image inpainting methods are based on auto-encoder architecture, in which the spatial details of images will be lost in the down-sampling process, lead-ing to the degradation of generated results. Also, the struc-ture information in deep layers and texture information in shallow layers of the auto-encoder architecture can not be well integrated. Differing from the conventional image in-painting architecture, we design a parallel multi-resolution inpainting network with multi-resolution partial convolu-tion, in which low-resolution branches focus on the global structure while high-resolution branches focus on the local texture details. All these high- and low-resolution streams are in parallel and fused repeatedly with multi-resolution masked representation fusion so that the reconstructed im-ages are semantically robust and textually plausible. Ex-perimental results show that our method can effectively fuse structure and texture information, producing more realistic results than state-of-the-art methods. 1.

Introduction
Image inpainting, which aims at synthesizing meaning-ful and plausible contents in missing regions, is a funda-mental computer vision task. This process not only de-mands meaningful texture content but also expects harmony between the filled regions and the background. Conven-tional image inpainting methods [2, 3, 4, 10] utilize the background information to fill the missing regions. They can inpaint simple low-resolution images with promising results, but fail to inpaint high-resolution images with af-fordable time. Also, these methods perform poorly for im-ages with complex scenes or large missing regions.
In recent years, deep neural network has made a huge breakthrough in the field of image inpainting, such as
*Equal Contributions.
†Corresponding author.
[26, 18, 38, 25, 39, 28, 35, 41].
In general, most of the deep image inpainting networks are based on auto-encoder architecture which is prevalent in image generation tasks.
Some other deep inpainting networks employ the variants of auto-encoder like U-net architecture [34, 23]. Further, a series of methods [40, 15, 37] integrate the idea of multi-resolution into auto-encoder architecture. However, there exist two drawbacks for applying auto-encoder architecture to image inpainting. Firstly, all these methods are composed of series-connected high-to-low resolution sub-networks, following low-to-high resolution sub-networks, with down-sampling and up-sampling. Due to down-sampling, there will be high-resolution information loss and high-resolution inpainting cannot be maintained all the time. Secondly, con-sidering the receptive field size for each layer in a deep neu-ral network, it is generally believed that low-resolution fea-ture maps (representations) from the deeper layers contain high-level information (i.e., global structure information) while high-resolution feature maps (representations) from the shallower layers contain low-level information (i.e., lo-cal texture details) [22, 31]. Hence, texture information and structure information can not be well integrated into a se-rial conventional network like auto-encoder structure. To solve the second problem, a mutual encoder-decoder with feature equalization is proposed to correlate filled structures with textures in [22]. Although the consistency between structures and textures within missing regions is enhanced, this method lacks sufficient information exchange between high-resolution and low-resolution feature maps, which still leads to blur and artifacts.
In order to maintain the high quality of image restoration as well as enhance the coherence between structure and tex-ture, we propose a parallel multi-resolution fusion network for image inpainting. There have been a wide range of com-puter vision tasks benefited from multi-resolution networks, like classification [33, 29, 16, 31], object detection [5, 36], human pose estimate [30], segmentation [7, 45, 27, 13], and face parsing [49]. Similar to [30], our overall network architecture has four parallel branches with four different
resolutions, in which each branch consists of multiple sub-networks with one sub-network belonging to one stage. The information from different branches is exchanged at the end of each stage. Compared with [30], we first make two slight modifications: (1) the main body of our network starts from four resolutions at the beginning to focus on both local and global information; (2) we add two extra stages to guarantee adequate stages for inpainting missing regions. As shown in Figure 1, our network starts from high-resolution branch, followed by the main body containing six stages. In each stage, there are four sub-networks with different resolutions in parallel. Relying on this architecture, our approach can maintain high-resolution inpainting with more detailed tex-ture information instead of recovering images from low-resolution to high-resolution, which effectively avoids the information loss caused by downsampling in auto-encoder architecture.
To further tailor our network for image inpainting, we make two major improvements: mask-aware representation fusion and attention-guided representation fusion. First of all, we replace the convolution layers with partial convolu-tion layers [21] and restore the missing regions with multi-resolution inpainting priorities, which guides the branches to focus on inpainting texture in the high-resolution or struc-ture information in the low-resolution, respectively. After each stage of the first five stages, we conduct mask-aware representation fusion by fusing both masks and representa-tions among all branches to make the reconstructed images structurally robust and textually plausible. Prior to the last stage, we use a fused self-attention map learned from all res-olution feature maps to guide the refinement of each resolu-tion feature map. Experiments conducted on three datasets show that our method is superior to the state-of-the-art ap-proaches. In summary, the main contributions of our work are as follows:
• This is the first work to introduce parallel multi-resolution network architecture into image inpainting, which is able to maintain high-resolution inpainting in the whole process and generate promising texture pat-terns for the inpainted images.
• Built on parallel multi-resolution network architecture, we propose novel mask-aware representation fusion and attention-guided representation fusion, which can fuse the low- and high-resolution representations more effectively.
• Extensive experiments validate that our method can produce more reasonable and fine-detailed results than other state-of-the-art methods. 2.1. Conventional Image Inpainting
Conventional image inpainting methods attempted to re-store the corrupted area with background content, which can be divided into two main categories: diffusion-based methods and exemplar-based methods. Diffusion-based methods [3, 1, 12] diffusely propagated background infor-mation into the missing area while exemplar-based methods
[2, 10, 17] selected similar exemplar patches from back-ground regions to fill in the missing regions. Although these methods are successful in processing image with low-resolution and simple structure, they are incapable of deal-ing with complex scenes due to a lack of broad understand-ing of the image. 2.2. Deep Image Inpainting
Deep learning has brought great performance improve-ment to image inpainting task. Generally, most of the deep image inpainting networks are based on auto-encoder ar-chitecture. In [26, 18, 21], one stage auto-encoder archi-tecture was used for image inpainting. Yu et al. [38, 39] first proposed a two-stage auto-encoder network to refine the inpainting process from coarse to fine. U-net architec-ture was applied by [34, 23] as the variant of auto-encoder to enhance the connection between features in the encoder and decoder. These methods lack thoughtful consideration of the integration of the multi-resolution information. 2.3. Multi-Resolution Image Inpainting Network
There are also some image inpainting methods exploit-ing the idea of multi-resolution more or less when designing their network. Zeng et al. [40] proposed a pyramid-context encoder to progressively learn attention map from a high-level feature map and transfer attention map to the previous low-level feature map. Hong et al. [15] designed a U-Net architecture embedded with multiple fusion blocks to ap-ply multi-scale constraints at image level. Yi et al.
[37] proposed a contextual residual aggregated technique that enables high-quality inpainting of ultra-high-resolution im-age. To solve the inconsistency between structures and tex-tures within hole regions, Liu et al. [22] proposed a mutual encoder-decoder with feature equalization, which still lacks a continuous fusion process for structures and textures. All these methods make use of the multi-resolution information in a serial way. Distinctive from them, we propose a parallel multi-resolution image inpainting architecture that connects the high-to-low resolution branches in parallel and repeat-edly exchanges the information across multi-resolutions. 2.