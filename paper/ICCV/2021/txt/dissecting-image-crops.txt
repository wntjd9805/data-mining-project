Abstract
The elementary operation of cropping underpins nearly every computer vision system, ranging from data augmen-tation and translation invariance to computational photog-raphy and representation learning. This paper investigates the subtle traces introduced by this operation. For exam-ple, despite reﬁnements to camera optics, lenses will leave behind certain clues, notably chromatic aberration and vi-gnetting. Photographers also leave behind other clues re-lating to image aesthetics and scene composition. We study how to detect these traces, and investigate the impact that cropping has on the image distribution. While our aim is to dissect the fundamental impact of spatial crops, there are also a number of practical implications to our work, such as revealing faulty photojournalism and equipping neural network researchers with a better understanding of short-cut learning. Code is available at https://github.com/ basilevh/dissecting-image-crops. 1.

Introduction
The basic operation of cropping an image underpins nearly every computer vision paper that you will be reading this week. Within the ﬁrst few lectures of most introduc-tory computer vision courses, convolutions are motivated as enabling feature invariance to spatial shifts and crop-ping [52, 31, 2]. Neural networks rely on image crops as a form of data augmentation [28, 50, 21]. Computational photography applications will automatically crop photos in order to improve their aesthetics [47, 12, 60]. Predic-tive models extrapolate pixels out from crops [51, 57, 55].
Even the latest self-supervised efforts depend on crops for contrastive learning to induce rich visual representations
[13, 20, 45, 49].
This core visual operation can have a signiﬁcant impact on photographs. As Oliva and Torralba told us twenty years ago, scene context drives perception [44]. Recently, image cropping has been at the heart of media disinformation. Fig-ure 1 shows two popular photographs where the photogra-pher or media organization spatially cropped out part of the context, altering the message of the image. Twitter’s auto-crop feature relied on a saliency prediction network that was
Figure 1: We show two infamous image crops, visualized by the red box. (left) An Ugandan climate activist had been cropped out of the photo before it was posted in an online news article, the discovery of which sparked controversy [16]. (right) A news net-work had cropped out a large stick being held by a demonstrator during a protest [14]. Cropping dramatically alters the message of the photographs. racially biased [10].
The guiding question of this paper is to understand the traces left behind from this fundamental operation. What impact does image cropping have on the visual distribution?
Can we determine when and how a photo has been cropped?
Despite extensive reﬁnements to the manufacturing pro-cess of camera optics and sensors, nearly every modern camera pipeline will leave behind subtle lens artefacts onto the photos that it captures. For example, vignetting is caused by a lens focusing more light at the center of the sensor, creating images that are slightly brighter in the mid-dle than near its borders [36]. Chromatic aberration, also known as purple fringing, is caused by the lens focusing each wave length differently [5]. Since these artefacts are correlated with their spatial position in the image plane, they cause image crops to have trace signatures.
Physical aberrations are not the only traces left behind during the operation. Photographers will prefer to take pho-tos of interesting objects and in canonical poses [53, 4, 22].
Aesthetically pleasing shots will have sensible composi-tions that respect symmetry and certain ratios in the scene.
Violating these principles leaves behind another trace of the cropping operation.
These traces are very subtle, and the human eye often cannot detect them, which makes studying and characteriz-ing them challenging. However, neural networks are excel-lent at identifying these patterns. Indeed, extensive effort goes into preventing neural networks from learning such
shortcuts enabled by image crops [15, 43].
In this paper, we ﬂip this around and declare that these shortcuts are not bugs, but instead an opportunity to dis-sect and understand the subtle clues left behind from image cropping. Capitalizing on a large, high-quality collection of natural images, we train a convolutional neural network to predict the absolute spatial location of a patch within an image. This is only possible if there exist visual features that are not spatially invariant. Our experiments analyze the types of features that this model learns, and we show that it is possible to detect traces of the cropping operation. We can also use the discovered artefacts, along with semantic information, to recover where the crop was positioned in the original sensor plane.
While the aim of this paper is to analyze the fundamental traces of image cropping in order to question conventional assumptions about translational invariance and the crucial role of data augmentation pervading the ﬁeld, we believe our investigation could have a large practical impact as well.
Historically, asking fundamental questions has spurred sig-niﬁcant insight into core computer vision problems, such as invariances to scale [9], asymmetries in time [46], the speediness of videos [6], and visual chirality [34]. For ex-ample, insight into image crops could enable detection of soft tampering operations, or spur developments to mitigate shortcut learning. 2.