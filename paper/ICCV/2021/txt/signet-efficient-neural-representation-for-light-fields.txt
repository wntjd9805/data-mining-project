Abstract
We present a novel neural representation for light ﬁeld content that enables compact storage and easy local recon-struction with high ﬁdelity. We use a fully-connected neural network to learn the mapping function between each light
ﬁeld pixel’s coordinates and its corresponding color val-ues. Since neural networks that simply take in raw coor-dinates are unable to accurately learn data containing ﬁne details, we present an input transformation strategy based on the Gegenbauer polynomials, which previously showed theoretical advantages over the Fourier basis. We conduct experiments that show our Gegenbauer-based design com-bined with sinusoidal activation functions leads to a bet-ter light ﬁeld reconstruction quality than a variety of net-work designs, including those with Fourier-inspired tech-niques introduced by prior works. Moreover, our SInusoidal
Gegenbauer NETwork, or SIGNET, can represent light ﬁeld scenes more compactly than the state-of-the-art compres-sion methods while maintaining a comparable reconstruc-tion quality. SIGNET also innately allows random access to encoded light ﬁeld pixels due to its functional design. We further demonstrate that SIGNET’s super-resolution capa-bility without any additional training. 1.

Introduction
Light ﬁelds offer an information-rich medium for static and dynamic scenes. However, a signiﬁcant barrier to their widespread adoptions is a lack of sufﬁciently compact rep-resentations of such high-dimensional data, making it im-practical for efﬁcient storage, editing, and streaming. For example, a 1080p 60-fps light ﬁeld video captured on a 10 × 10 camera grid easily requires several gigabytes of storage space for every second of content.
A straightforward solution to compressing light ﬁelds is to apply existing, widely used compression methods such as JPEG and MPEG. However, due to the sheer amount of images captured in a light ﬁeld, the compression rate of these single-view-based methods are far from satisfac-tory [48, 49]. Therefore, it is imperative to have a compact
Figure 1: Overview of SIGNET. We train a MLP to approx-imate the mapping function from each pixel’s coordinates to its color values. Our input transformation strategy based on the Gegenbauer polynomials enables the MLP to more accurately learn the high-dimensional mapping function. way to represent light ﬁelds by taking advantage of the over-lapping and repetitive visual patterns in light ﬁelds.
Extensive research has been devoted to designing com-pact light ﬁeld representations based on the patch-based compression strategy manifest in the JPEG standard. These methods represent each image patch as a weighted sum of a small dictionary of basis functions, and the goal is ﬁnd-ing new ways to construct dictionaries of basis functions that achieve better compression results. Yet, previous ef-forts have limited success in enabling easy transmission and manipulation of light ﬁeld content.
Recent advances in deep learning have led to impressive results in representing data like images and volumes [31, 43, 47] with neural networks. A common thread among these methods is incorporating Fourier-inspired modiﬁcations to the classical neural network design called multilayer per-ceptron (MLP). Speciﬁcally, the SIREN network [43] uses
a sinusoidal activation function between the MLP layers, while neural radiance ﬁeld (NeRF) networks [31] designed for volumetric radiance data show the effectiveness of ap-plying cosine and sine transformations on input coordi-nates. The improvement brought by the Fourier basis used in NeRF is further analyzed and formalized by Tancik et al. [47], who also successfully extend the neural represen-tation to data like 2D images and 3D shapes.
The proven capability of MLPs to express visual content with high ﬁdelity implies that we could potentially com-press a gigapixel light ﬁeld within a few megabytes. How-ever, as shown in Section 4, the previous techniques fall short of representing light ﬁelds without visible artifacts.
In this work, we present a new framework that efﬁciently and accurately represents light ﬁeld content using neural networks. Crucially, we introduce a novel input transfor-mation strategy of the multi-dimensional light ﬁeld coor-dinate based on the orthogonal Gegenbauer polynomials, which in our experiments work very well with the sinu-soidal activation functions between the MLP layers. We call this network SIGNET (SInusoidal Gegenbauer NETwork), and we show its superiority for light ﬁeld neural represen-tation over a variety of Fourier-inspired input transforma-tion strategies. SIGNET also achieves outstanding recon-struction quality with a higher compression rate than state-of-the-art dictionary-based light ﬁeld compression methods.
We further demonstrate how our MLP-based approach eas-ily allows for view synthesis and super-resolution on the encoded light ﬁeld scenes.
In summary, our contributions are as follows:
• We present a neural representation of light ﬁelds which achieves high reconstruction quality and compression rate and offers pixel-level random access to the en-coded light ﬁeld.
• We introduce an input transformation strategy for coordinate-input MLPs using Gegenbauer polynomi-als, which outperforms other recently proposed tech-niques on light ﬁeld data.
• We show such a neural representation enables high-quality decoding at novel coordinates without addi-tional training, achieving super-resolution along spa-tial, angular, and temporal dimensions on light ﬁelds. 2.