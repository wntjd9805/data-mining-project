Abstract
Deep neural networks for automatic image colorization often suffer from the color-bleeding artifact, a problematic color spreading near the boundaries between adjacent ob-jects. Such color-bleeding artifacts debase the reality of generated outputs, limiting the applicability of colorization models in practice. Although previous approaches have at-tempted to address this problem in an automatic manner, they tend to work only in limited cases where a high con-trast of gray-scale values are given in an input image. Al-ternatively, leveraging user interactions would be a promis-ing approach for solving this color-breeding artifacts. In this paper, we propose a novel edge-enhancing network for
* indicates equal contribution the regions of interest via simple user scribbles indicating where to enhance. In addition, our method requires a min-imal amount of effort from users for their satisfactory en-hancement. Experimental results demonstrate that our in-teractive edge-enhancing approach effectively improves the color-bleeding artifacts compared to the existing baselines across various datasets. 1.

Introduction
In recent years, deep image colorization methods [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] have achieved a great perfor-mance on the generation of a realistic colorized image given
ment framework that takes a direct user interaction annotat-ing a color-bleeding edge. Unlike the previous approaches, our framework guarantees the reliable edge enhancement in any desired regions by utilizing user interactions. In addi-tion, our interactive approach only requires users the mini-mum efforts for edge enhancement. We first apply a simple add-on edge-enhancing network, which takes both scribbles and an intermediate activation map of the colorization net-work as inputs. This network encodes an edge-corrective representation for its input activation map, particularly in the regions annotated by the scribbles, and adds it into the original activation map by a residual connection. Given this refined representations for the bleeding edges, the following layers of the colorization network can generate the edge-enhanced colorization output.
Experimental results demonstrate that our method has a remarkable performance over the baselines on diverse benchmark datasets, ImageNet [17], COCO-Stuff [19] and
Place205 [20]. Moreover, we introduce a new evaluation metric for measuring how reliably the colorization meth-ods obey the color boundaries. Also, we confirm that our approach takes the reasonable amount of time and efforts through the user-study, representing its potentials in practi-cal applications . Furthermore, we explore the applicability of our approach in the task of sketch colorization as well, by validating our method on Yumiâ€™s Cells [21] and Dan-booru [22] datasets. 2.