Abstract
Remote sensing and automatic earth monitoring are key to solve global-scale challenges such as disaster prevention, land use monitoring, or tackling climate change. Although there exist vast amounts of remote sensing data, most of it remains unlabeled and thus inaccessible for supervised learning algorithms. Transfer learning approaches can re-duce the data requirements of deep learning algorithms.
However, most of these methods are pre-trained on Ima-geNet and their generalization to remote sensing imagery is not guaranteed due to the domain gap. In this work, we propose Seasonal Contrast (SeCo), an effective pipeline to leverage unlabeled data for in-domain pre-training of re-mote sensing representations. The SeCo pipeline is com-posed of
First, a principled procedure to gather large-scale, unlabeled and uncurated remote sensing datasets containing images from multiple Earth locations at different timestamps. Second, a self-supervised algorithm that takes advantage of time and position invariance to learn transferable representations for remote sensing appli-cations. We empirically show that models trained with SeCo achieve better performance than their ImageNet pre-trained counterparts and state-of-the-art self-supervised learning methods on multiple downstream tasks. The datasets and models in SeCo will be made public to facilitate transfer learning and enable rapid progress in remote sensing ap-plications.1 two parts. 1.

Introduction
Remote sensing is becoming increasingly important to many applications, including land use monitoring [12], pre-cision agriculture [29], disaster prevention [37], wildfire detection [11], vector-borne disease surveillance [20], and tackling climate change [33]. Combined with recent ad-vances in deep learning and computer vision, there is enor-1Code, datasets and pre-trained models are available at https:// github.com/ElementAI/seasonal-contrast
Figure 1. Distribution of the Seasonal Contrast (SeCo) dataset.
Each point represents a sampled location.
Images are collected around human settlements to avoid monotonous areas such as oceans and deserts. mous potential for monitoring global issues through the au-tomated analysis of remote sensing and other geospatial data streams.
Remote sensing provides a vast supply of data. The num-ber of Earth-observing satellites is continuously growing, with over 700 satellites currently in orbit generating ter-abytes of imagery data every day [30]. However, many downstream tasks of interest are constrained by a lack of annotations, which are particularly costly to obtain since they often require expert knowledge, or expensive ground sensors. In recent years, a number of techniques have been developed to mitigate the need for labeled data [24, 26, 25], but their application to remote sensing images is largely un-derexplored.
Furthermore, existing remote sensing datasets [38, 19, 42] are highly curated to form well-balanced and diversi-fied classes. Simply discarding the labels does not undo this careful selection of examples, which also requires con-siderable human effort. Our goal is to exploit the massive amount of publicly available remote sensing data for learn-ing good visual representations in a truly unsupervised way.
To enable this, we construct a remote sensing dataset from
Sentinel-2 [10] tiles without any human supervision, neither for curating nor annotating the data.
Another characteristic unique to remote sensing data is satellite revisit, which describes the ability of the system to make repeated image captures of the same point of the
Earth’s surface over time. For publicly funded satellite con-stellations such as Sentinel [10] or Landsat [35], the revisit time is of the order of days. This temporal dimension pro-vides an additional source of natural variation which com-plements the artificial augmentation of images. For in-stance, no amount of artificial augmentation can show how a snowy mountain summit looks like when the snow melts down, or how the different stages of a crop change through the seasons.
Self-supervised learning methods have recently emerged as an effective methodology to learn from vast amounts of unlabeled data. Contrastive methods push together repre-sentations of images that are semantically similar (i.e. pos-itive pairs). Since no labels are available, traditional con-trastive learning methods that work with natural images use different artificial augmentations of the same image (views) as positive pairs. In the case of remote sensing images, we propose to leverage the temporal information to obtain pairs of images from the same location at different points in time, which we call seasonal positive pairs. We argue that sea-sonal changes provide more semantically meaningful con-tent than artificial transformations, and remote sensing im-ages provide this natural augmentation for free.
We propose Seasonal Contrast (SeCo), a novel method-ology for pre-training rich, transferable representations for remote sensing applications. SeCo consists of two parts, an unsupervised data acquisition procedure and a self-supervised model to learn from the acquired data. The self-supervised learning model is designed based on the ob-servation that encouraging the representation to be invari-ant to seasonal changes is a strong inductive bias. This property can be beneficial for certain downstream tasks where the prediction will not change with seasonal vari-ations (e.g., land-cover classification, agricultural pattern segmentation, building detection), but harmful for down-stream tasks where seasonal variations are important (e.g., deforestation tracking, change detection). We want to learn good representations of remote sensing images that are ag-nostic to the downstream tasks where they could be applied.
To leverage temporal information without limiting the visual representations to be always invariant to time, we use the idea of multiple embedding sub-spaces [47]. Instead of mapping an image to a single embedding space which is in-variant to all augmentations, we construct separate embed-ding sub-spaces and optimize them to be variant or invariant to seasonal changes. We use a multi-head architecture with a shared backbone which produces a common representa-tion that encodes the different variances and invariances.
Once the model is trained, this representation can be ap-plied to a wide range of remote sensing downstream tasks, where the model can selectively utilize the different factors of variation captured in the representation.
We evaluate SeCo on several remote sensing datasets and tasks. Our experiments on land-cover classification with
BigEarthNet [38] and EuroSAT [19], and change detection with OSCD [8] demonstrate that SeCo pre-training is more effective for remote sensing tasks than the common Ima-geNet [36] and MoCo [18] pre-training.
In summary, our contributions are:
• We describe a general method for collecting uncurated and unlabeled datasets of remote sensing images. We use this method to construct a remote sensing dataset from Sentinel-2 tiles without any human supervision.
• We combine recent contrastive self-supervised learn-ing methods with the temporal information provided by satellites to learn good visual representations which are simultaneously variant and invariant to seasonal changes.
• We obtain state-of-the-art results on BigEarthNet and
EuroSAT land-cover classification, and on OSCD change detection. 2.