Abstract
Recently, the encoder-decoder and intensity transfor-mation approaches lead to impressive progress in image enhancement. However, the encoder-decoder often loses details in input images during down-sampling and up-sampling processes. Also, the intensity transformation has a limited capacity to cover color transformation between low-quality and high-quality images. In this paper, we pro-pose a novel approach, called representative color trans-form (RCT), to tackle these issues in existing methods. RCT determines different representative colors specialized in in-put images and estimates transformed colors for the repre-sentative colors.
It then determines enhanced colors us-ing these transformed colors based on the similarity be-tween input and representative colors. Extensive exper-iments demonstrate that the proposed algorithm outper-forms recent state-of-the-art algorithms on various image enhancement problems. 1.

Introduction
Nowadays, more and more people take photographs to record and to share their valuable moments. Unfortunately, their photographs often have low dynamic ranges or dis-torted color tones due to inadequate lighting conditions.
Therefore, image enhancement becomes popular to improve the visual aesthetics of these photos. For image enhance-ment, many attempts have been proposed, and considerable progress has been made.
In particular, some studies [6, 50, 52, 22] based on the encoder-decoder architecture [38] in Figure 1a provide promising results by learning a robust non-linear mapping from large amounts of paired data composed of low-quality and high-quality images. In these models, the encoder ex-tracts features from the input image to exploit the high-∗Corresponding author level context information for image enhancement. The de-coder conveys the high-level information to low-level pixel values while recovering the spatial information. Although these methods have led to the performance improvement, they have some limitations. First, details of the input im-age are not preserved in the up-sampling process of the de-coder, even though they employ skip-connections. Second, these approaches train networks with ﬁxed input size, which makes it difﬁcult to enhance images of arbitrary spatial res-olutions in the inference phase.
To overcome these issues, some methods [7, 21, 34, 16, 25, 13] estimate transformation functions to enhance im-ages globally as in Figure 1b. Since these global enhance-ment methods do not require the down-sampling and up-sampling processes for image enhancement, images can be enhanced while preserving details. However, the existing global methods rely on intensity transformation functions on speciﬁc color space e.g. RGB [21, 13] or CIELab [7], pre-deﬁned lookup tables [54], and pre-deﬁned enhance-ment operations [34, 16, 25]. Also, they perform channel-wise color transformation and thus fail to consider all chan-nels simultaneously. These pre-deﬁned models have the limited capacity to cover color transformation between low-quality and high-quality images.
In this paper, we propose a novel enhancement approach, called representative color transform (RCT), which effec-tively achieves a large capacity for color transformation.
First, we encode an input image to extract the high-level context information for image enhancement. Using the high-level context, we determine representative colors for the input image and estimate transformed colors for the rep-resentative colors, as in Figure 1c. Then, we compute the similarity between the input image and the representative colors in an embedding space. Finally, we develop a repre-sentative color transform to obtain the enhanced image by combining the similarity and the representative color trans-formation. Based on the proposed RCT, we propose a rep-resentative color transform network (RCTNet), which con-(a) (b) (c)
Figure 1: Outlines of image enhancement approaches: (a) encoder-decoder, (b) intensity transformation, and (c) representa-tive color transform models. sists of encoder, feature fusion, global RCT, and local RCT modules. The proposed RCTNet predicts different repre-sentative colors specialized in input images as in Figure 1c and enlarges the capacity for color transformation by com-bining several representative color transformations.
Experimental results demonstrate that the proposed
RCTNet outperforms recent state-of-the-art algorithms on the MIT-Adobe 5K dataset [3]. Also, we validate the scala-bility of the proposed RCT on speciﬁc image enhancement problems: low-light image enhancement [49] and underwa-ter image enhancement [28, 19].
The main contributions of this paper are three folds:
• The representative color transformation to enlarge the capacity for color transformation is developed for im-age enhancement.
• Development of RCTNet composed of encoder, fea-ture fusion, global RCT, and local RCT modules.
• We demonstrate excellent scalability of RCTNet for various image enhancement problems. 2.