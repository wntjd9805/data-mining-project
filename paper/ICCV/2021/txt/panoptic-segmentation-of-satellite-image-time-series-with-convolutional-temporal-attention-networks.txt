Abstract
Unprecedented access to multi-temporal satellite im-agery has opened new perspectives for a variety of Earth observation tasks. Among them, pixel-precise panoptic seg-mentation of agricultural parcels has major economic and environmental implications. While researchers have ex-plored this problem for single images, we argue that the complex temporal patterns of crop phenology are better ad-dressed with temporal sequences of images.
In this pa-per, we present the first end-to-end, single-stage method for panoptic segmentation of Satellite Image Time Series (SITS). This module can be combined with our novel image sequence encoding network which relies on temporal self-attention to extract rich and adaptive multi-scale spatio-temporal features. We also introduce PASTIS, the first open-access SITS dataset with panoptic annotations. We demon-strate the superiority of our encoder for semantic segmen-tation against multiple competing architectures, and set up the first state-of-the-art of panoptic segmentation of SITS.
Our implementation and PASTIS are publicly available. 1.

Introduction
The precision and availability of Earth observations have continuously improved thanks to sustained advances in space-based remote sensing, such as the launch of the Planet
[5] and the open-access Sentinel constellations [8]. In par-ticular, satellites with high revisit frequency contribute to a better understanding of phenomena with complex temporal dynamics. Crop mapping—the driving application of this paper—relies on exploiting such temporal patterns [37] and entails major financial and environmental stakes. Indeed, remote monitoring of the surface and nature of agricultural parcels is necessary for a fair allocation of agricultural sub-sidies (50 and 22 billion euros per year in Europe and in the US, respectively) and for ensuring that best crop rota-tion practices are respected. More generally, the automated analysis of SITS represents a significant interest for a wide
Figure 1: Overview. We propose an end-to-end, single-stage model for panoptic segmentation of agricultural parcels from time series of satellite images. Note the diffi-culty of resolving the parcels’ borders from a single image, highlighting the need for modeling temporal dynamics. range of applications, such as surveying urban development and deforestation.
The task of monitoring both the content and extent of agricultural parcels can be framed as the panoptic segmen-tation of an image sequence. Panoptic segmentation con-sists of assigning to each pixel a class and a unique instance label, and has become a standard visual perception task in computer vision [18, 25]. However, panoptic segmentation is a fundamentally different task for SITS versus sequences of natural images or videos. Indeed, understanding videos requires tracking objects through time and space [43]. In yearly SITS, the targets are static in a geo-referenced frame, which removes the need for spatial tracking. Additionally,
SITS share a common temporal frame of reference, which means that the time of acquisition itself contains informa-tion useful for modeling the underlying temporal dynamics.
In contrast, the frame number in videos is often arbitrary.
Finally, while objects on the Earth surface generally do not occlude one another, as is commonly the case for objects in natural images, varying cloud cover can make the analysis of SITS arduous. For the specific problem addressed in this
paper, individualizing agricultural parcels requires learning complex and specific temporal, spatial, and spectral patterns not commonly encountered in video processing, such as dif-ferences in plant phenological profiles, subpixel border in-formation, and swift human interventions such as harvests.
While deep networks have proven efficient for learning such complex patterns for pixel classification [16, 12, 1], there is no dedicated approach for detecting individual ob-jects in SITS. Existing work on instance segmentation has been restricted to analysing a single satellite image [32]. In summary, specialized remote sensing methods are limited to semantic segmentation or single-image instance segmen-tation, while computer vision’s panoptic-ready networks re-quire significant adaptation to be applied to SITS.
In this paper, we introduce U-TAE (U-net with Temporal
Attention Encoder), a novel spatio-temporal encoder com-bining multi-scale spatial convolutions [33] and a tempo-ral self-attention mechanism [37] which learns to focus on the most salient acquisitions. While convolutional-recurrent methods are limited to extracting temporal features at the highest [34] or lowest [36] spatial resolutions, our proposed method can use the predicted temporal masks to extract spe-cialized and adaptive spatio-temporal features at different resolutions simultaneously. We also propose Parcels-as-Points (PaPs), the first end-to-end deep learning method for panoptic segmentation of SITS. Our approach is built upon the efficient CenterMask network [48], which we modify to fit our problem. Lastly, we present Panoptic Agricul-tural Satellite TIme-Series (PASTIS), the first open-access dataset for training and evaluating panoptic segmentation models on SITS, with over 2 billion annotated pixels cover-ing over 4000km2. Evaluated on this dataset, our approach outperforms all reimplemented competing methods for se-mantic segmentation, and defines the first state-of-the-art of
SITS panoptic segmentation. 2.