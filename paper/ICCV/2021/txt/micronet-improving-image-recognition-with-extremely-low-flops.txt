Abstract
This paper aims at addressing the problem of substantial performance degradation at extremely low computational cost (e.g. 5M FLOPs on ImageNet classification). We found that two factors, sparse connectivity and dynamic activa-tion function, are effective to improve the accuracy. The former avoids the significant reduction of network width, while the latter mitigates the detriment of reduction in net-work depth. Technically, we propose micro-factorized con-volution, which factorizes a convolution matrix into low rank matrices, to integrate sparse connectivity into convo-lution. We also present a new dynamic activation function, named Dynamic Shift Max, to improve the non-linearity via maxing out multiple dynamic fusions between an in-put feature map and its circular channel shift. Building upon these two new operators, we arrive at a family of networks, named MicroNet, that achieves significant per-formance gains over the state of the art in the low FLOP regime. For instance, under the constraint of 12M FLOPs,
MicroNet achieves 59.4% top-1 accuracy on ImageNet clas-sification, outperforming MobileNetV3 by 9.6%. Source code is at https://github.com/liyunsheng13/micronet. 1.

Introduction
Recent progress in efficient CNN architectures [16, 13, 31, 12, 47, 28, 34] successfully decreases the computational cost of ImageNet classification from 3.8G FLOPs (ResNet-50 [11]) by two orders of magnitude to about 40M FLOPs (e.g. MobileNet, ShuffleNet), with a reasonable perfor-mance drop. However, they suffer from a significant perfor-mance degradation when reducing computational cost fur-ther. For example, the top-1 accuracy of MobileNetV3 de-grades substantially from 65.4% to 58.0% and 49.8% when the computational cost drops from 44M to 21M and 12M
In this paper, we aim at improving
MAdds, respectively. accuracy at the extremely low FLOP regime from 21M to 4M MAdds, which marks the computational cost decrease
Figure 1. Computational Cost (MAdds) vs. ImageNet Accu-racy. MicroNet significantly outperforms the state-of-the-art effi-cient networks at very low FLOPs (from 4M to 21M MAdds). of another order of magnitude (from 40M).
The problem of dealing with extremely low computa-tional cost (4M–21M FLOPs) is very challenging, consid-ering that 2.7M MAdds are consumed by a thin stem layer that contains a single 3 × 3 convolution with 3 input chan-nels and 8 output channels over a 112 × 112 grid (stride=2).
The remaining resources are too limited to design the con-volution layers and 1,000 class classifier required for effec-tive classification. As shown in Figure 1, a common strat-egy to reduce the width or depth of existing efficient CNNs (e.g. MobileNet [13, 31, 12] and ShuffleNet [47, 28]) re-sults in a severe performance degradation. Note that we fo-cus on new operator design while fixing the input resolution to 224×224 even for the budget of 4M FLOPs.
In this paper, we handle the extremely low FLOPs from two perspectives: node connectivity and non-linearity, which are related to the network width and depth. First, we show that lowering node connectivity to enlarge net-work width provides a good trade-off for a given compu-tational budget. Second, we rely on improved layer non-linearities to compensate for reduced network depth, which determines the non-linearity of the network. These two fac-tors motivate the design of more efficient convolution and
activation functions.
Regarding convolutions, we propose a Micro-Factorized convolution (MF-Conv) to factorize a pointwise convolution into two group convolution layers, where the group number
G adapts to the number of channels C as:
G = (cid:112)C/R, where R is the channel reduction ratio in between. As an-alyzed in Section 3.1, this equation achieves a good trade-off between the number of channels and node connectivity for a given computational cost. Mathematically, the point-wise convolution matrix is approximated by a block matrix (G × G blocks), whose blocks have rank-1. This guarantees minimal path redundancy (with only one path between any input-output pair) and maximum input coverage (per out-put channel), enabling more channels implementable by the network for a given computational budget.
With regards to non-linearities, we propose a new activa-tion function, named Dynamic Shift-Max (DY-Shift-Max), which non-linearly fuses channels with dynamic coeffi-cients. In particular, the new activation forces the network to learn to fuse different circular channel shifts of the in-put feature maps, using coefficients that adapt to the input, and to select the best among these fusions. This is shown to enhance the representation power of the group factorization with little computational cost.
Based upon the two new operators (MF-Conv and DY-Shift-Max), we obtain a family of models, called Mi-croNets. Figure 1 summarizes the ImageNet performance, where MicroNets outperform the state-of-the-art by a large margin.
In particular, our MicroNet models of 12M and 21M FLOPs outperform MobileNetV3 by 9.6% and 4.5% in terms of top-1 accuracy, respectively. For the extremely challenging regime of 6M FLOPs, MicroNet achieves 51.4% top-1 accuracy, outperforming by 1.6% over Mo-bileNetV3, which is twice as complex (12M FLOPs).
Even though MicroNet is manually designed for the-oretical FLOPs, it outperforms MobileNetV3 (which is searched over inference latency) with fast inference on edge devices. Furthermore, our MicroNet surpasses Mo-bileNetV3 on object detection and keypoint detection, but uses substantially less computational cost. 2.