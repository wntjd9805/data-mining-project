Abstract
Manually annotating object segmentation masks is very time-consuming. While interactive segmentation methods offer a more efficient alternative, they become unafford-able at a large scale because the cost grows linearly with the number of annotated masks.
In this paper, we pro-pose a highly efficient annotation scheme for building large datasets with object segmentation masks. At a large scale, images contain many object instances with similar appear-ance. We exploit these similarities by using hierarchi-cal clustering on mask predictions made by a segmenta-tion model. We propose a scheme that efficiently searches through the hierarchy of clusters and selects which clusters to annotate. Humans manually verify only a few masks per cluster, and the labels are propagated to the whole clus-ter. Through a large-scale experiment to populate 1M unla-beled images with object segmentation masks for 80 object classes, we show that (1) we obtain 1M object segmenta-tion masks with an total annotation time of only 290 hours; (2) we reduce annotation time by 76× compared to man-ual annotation; (3) the segmentation quality of our masks is on par with those from manually annotated datasets. Code, data, and models are available online1. 1.

Introduction
The incredible rise in computer vision over the past decade has been propelled by the creation of datasets with multi-million annotated images such as ImageNet [45],
Places [67] and Kinetics [21]. For deep learning models to continue improving with higher capacity, there is a con-tinual need for more training data. It has been shown that the training data must grow exponentially to see linear im-provements in the models [50, 52, 69].
Manual annotation for instance segmentation is expen-sive as it requires humans to draw a detailed outline around every object in an image [8, 13, 33, 46, 68]. For exam-ple, annotating COCO [33] required 80 seconds per mask, 1http://scaling-anno.csail.mit.edu
∗Denotes equal contribution
Figure 1. Scaling up instance annotation. We obtain 76 segmen-tation masks for the cost of manually drawing one. an image in Cityscapes [8] took 1.5 hours, and annotating
ADE20K [68] by a single annotator took several years. At this pace, constructing a dataset with 10M masks would re-quire more than 200k hours and cost over $2M [33].
An alternative is interactive segmentation [1, 4, 7, 30, 34, 39, 43], where the human interaction is much faster (e.g., boxes, scribbles, clicks). Given this interaction, these meth-ods infer the final object mask. They offer substantial gains in annotation time and can lead to larger datasets [4]. How-ever, because annotators intervene on every object, the cost grows linearly with the number of annotations and there-fore, at a larger scale, they become unaffordable.
In this paper, we propose a method for crowd-sourcing object segmentation masks that reduces the annotation time by almost two orders of magnitude (Fig. 1). At large scale, images contain many object instances with similar appear-ance. We exploit this by clustering mask predictions made by an instance segmentation model. Human annotators ver-ify a few masks per cluster and we propagate the verifica-tion labels to the whole cluster. Since annotators interact with few masks per cluster, our cost scales with the number of clusters rather than masks.
Given a small initial image set with manually segmented objects and an annotation budget, our goal is to maximize the number of high-quality obtained annotations in an un-labeled set. We first train an instance segmentation model and obtain mask predictions on the unlabeled set and then hierarchically cluster class-specific masks. Starting from the root of the tree, we search for candidate clusters likely
manually segmenting the initial training set and the time of verifying masks during our human-in-the-loop pipeline.
Interactive object segmentation started in the early 2000’s with the seminal work of graph cut and iterative graph cuts [5, 6, 43]. After that, many approaches were pro-posed to reduce manual annotation effort using bounding boxes [9, 29, 59], point clicks [3, 4, 17, 30, 36, 40, 39, 60], scribbles [2, 3, 31], and editing polygons [1, 7, 34]. These methods offer remarkable gains in time compared to man-ual annotation. However, because they all require human intervention for every object, the annotation cost still grows linearly with the number of object segmentation masks.
Annotation propagation uses pre-segmented images to guide the segmentation of new ones by propagating the annotation signal [12, 18, 22, 27, 42, 44].
[18] selects which images should be annotated or used for propagation, but it focuses on large objects and the task of foreground-[22] uses human verification background segmentation. to propagate 3D shape part annotations on synthetic shape models. Here we present an active framework for instance annotation and propagation of large-scale image collec-tions, where images contain multiple objects per image.
Group-based labeling assigns a single labeled image to a whole group [15, 51, 58]. In [65], human annotators la-bel only a few images, which are used to train binary clas-sifiers and automatically label many images at once with high confidence score. In Sec. 5.2 we modify [65] to work for instance segmentation and compare it with our method.
Active learning has been used in computer vision for the tasks of image classification [19, 20, 26, 35, 48, 62], ob-ject detection [55, 61] and semantic segmentation [18, 47, 53, 54]. The main goal of active learning is to maximize the model’s performance on a test set while minimizing the number of provided human labels. Related to this goal, we aim to maximize the number of obtained annotations while minimizing the human annotation effort. 3. Overview
Given a small set of manually annotated images with segmentation masks and a large set of unlabeled images, our goal is to populate the unlabeled set with high-quality masks using as little human intervention as possible. Our pipeline consists of five steps (Fig. 3): (a) Detection: we deploy an instance segmentation model on an unlabeled set to obtain segmentation masks. (b) Clustering: class-specific masks are hierarchically clustered to obtain a tree. (c) Selecting clusters: we efficiently search the tree and select candidate clusters that are likely to contain high-quality masks. (d)
Human annotation: for each candidate cluster, we sample a few masks and ask annotators to verify whether they are correct or not. We use these labels to estimate the quality of the clusters. (e) Propagation: If the estimated quality is very high or very low (i.e, the cluster almost exclusively contains
Figure 2. Instance segmentation datasets and annotation cost.
The size vs. the total annotation time in hours of our annotations compared to the most popular instance segmentation datasets. to contain high-quality masks. We ask human annotators to verify a few masks per cluster and we propagate the veri-fication labels to the whole cluster. Once the search termi-nates, the new annotations are added to the initial pool.
We first conduct simulated experiments to explore the design space of our method. Then, we conduct a large-scale experiment to populate 1M unlabeled images from the Places dataset [67] with segmentation masks for 80 ob-ject classes. Our results show that we obtain 1M annota-tions with only 290 annotation hours, reducing the anno-tation time by 76× compared to manual annotation [33]. (Note that a higher annotation budget could lead to many more masks.) We also show that the mask quality is on par with those from manually annotated datasets, and our anno-tations leads to a better instance segmentation model than manual annotation given the same annotation time. 2.