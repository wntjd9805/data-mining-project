Abstract Representation for Abstract Sketches
Lan Yang1,2 Kaiyue Pang2 Honggang Zhang1 Yi-Zhe Song2 1 PRIS, School of Artiﬁcial Intelligence, Beijing University of Posts and Telecommunications, China 2 SketchX, CVSSP, University of Surrey, United Kingdom
{ylan, zhhg}@bupt.edu.cn, {kaiyue.pang, y.song}@surrey.ac.uk
Abstract
What makes free-hand sketches appealing for humans lies with its capability as a universal tool to depict the visual world. Such ﬂexibility at human ease, however, introduces abstract renderings that pose unique challenges to com-puter vision models. In this paper, we propose a purpose-made sketch representation for human sketches. The key intuition is that such representation should be abstract at design, so to accommodate the abstract nature of sketches.
This is achieved by interpreting sketch abstraction on two levels: appearance and structure. We abstract sketch struc-ture as a pre-deﬁned coarse-to-ﬁne visual block hierarchy, and average visual features within each block to model ap-pearance abstraction. We then discuss three general strate-gies on how to exploit feature synergy across different lev-els of this abstraction hierarchy. The superiority of explic-itly abstracting sketch representation is empirically vali-dated on a number of sketch analysis tasks, including sketch recognition, ﬁne-grained sketch-based image retrieval, and generative sketch healing. Our simple design not only yields strong results on all said tasks, but also offers intuitive fea-ture granularity control to tailor for various downstream tasks. Code will be made publicly available. 1.

Introduction
Sketches are different to photos. They exhibit a severe lack of visual cues, often made up of just a few coarse strokes other than full of color and texture. The remarkable thing is however despite its abstract nature, humans are still acute to recognizing sketches somewhat equally well to that for a full-blown color photo – one only needs to observe a smiley face to tell the emotion other than seeing a true photo. It is precisely this abstract nature that triggered much of the research on human sketches [13, 42, 56, 19, 16, 58].
With the proliferation of touchscreen devices, this interest has also resulted in a series of practical applications, from sketch-based image retrieval [55, 39, 57, 12, 4], to sketch to photo synthesis [59, 40, 7, 17, 6].
Figure 1: We represent human sketch based on the insight of sketch abstraction as a process happening on two fronts: appearance and structure.
At the very core of all such advancements is learning a feature representation that is most suitable for sketch data.
The early days saw the use of HoG [9] descriptors re-purposed for sketch [14, 13, 37]. Coming to the deep era, sketch representation learning mainly takes two streams: (i)
CNNs that treat sketches as pixel-maps [56, 12, 36], and (ii) RNNs that utilize the temporal stroke-by-stroke nature of sketches [19, 38, 30]. They each have its pros and cons, though what none of them did was accommodating for the abstract nature of sketches at design. This is also evident in that similar to how HoG was re-purposed for sketch, such
CNN and RNN-based approaches were also mainly small deviations from their original photo forms [56, 19].
In this paper, we set out to change that. We aim to de-sign a sketch feature learning scheme that directly tackles the abstract nature of sketches. Our key intuition is there-fore the actual feature learning should resemble that of an abstraction process. We envisage this abstraction process to happen on two fronts – appearance and structure. We take the appearance abstraction process as just feature averaging within a local visual block, and abstract sketch structure as a hierarchy of multi-granularity grid blocks (see Figure 1).
Such representation of sketch data has a nice interpre-tation. By abstracting appearance into a visual mean, fea-ture learning is better regularized beyond individual draw-ing variations. Structural abstraction can then happen by traversing a coarse-to-ﬁne hierarchy of these aggregated features. Figure 1 illustrates the feature embedding of the rabbit category learned by our model. By projecting similar features into their respective visual instances, one can see how our proposed representation groups thematically simi-lar sketches as a clear sign of appearance abstraction taking place (e.g., over rabbit pose), and how different abstraction level focuses on summarizing different visual patterns (e.g., rabbit head vs. ears).
More speciﬁcally, at each level along the abstraction hi-erarchy, we divide a sketch into a pre-deﬁned number of grid blocks. The sketch visual feature for each block is then computed as the mean of a collection of visual patches cen-tered around sampled stroke points (see Figure 2). Naively aggregating appearance features across this hierarchy how-ever does not work – we need to encourage information ex-change across granularity levels to fully beneﬁt from the said abstraction process. For that, we discuss three general aggregation strategies and ﬁnd that hierarchical modeling with graph learning works best. Another intriguing property of our sketch representation is we can now control feature granularity and tailor model behaviors based on the target task. By increasing levels in the hierarchy, ﬁner-grained visual feature representation can be achieved (Section 5).
We show our method, albeit being simple, achieves state-of-the-art results on the task of sketch recognition. It can also be plug-and-play as a competitive sketch-speciﬁc fea-ture extractor for a range of different applications such as sketch-based image retrieval and sketch healing.
The contributions of this work are as follows: (i) we pro-vide a new method for representing human sketch data via explicit appearance and structure abstraction. (ii) a solu-tion is introduced to foster the feature synergy in the multi-granularity modeling of sketch structure. (iii) the efﬁcacy of our sketch-speciﬁc abstract representation has been demon-strated on diverse sketch analysis tasks, including sketch recognition, ﬁne-grained sketch-based image retrieval and generative sketch healing. 2.