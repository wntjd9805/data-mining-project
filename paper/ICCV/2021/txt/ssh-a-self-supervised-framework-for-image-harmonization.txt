Abstract
Image harmonization aims to improve the quality of im-age compositing by matching the “appearance” (e.g., color tone, brightness and contrast) between foreground and background images. However, collecting large-scale anno-tated datasets for this task requires complex professional retouching.
Instead, we propose a novel Self-Supervised
Harmonization framework (SSH) that can be trained us-ing just “free” natural images without being edited. We reformulate the image harmonization problem from a rep-resentation fusion perspective, which separately processes the foreground and background examples, to address the background occlusion issue. This framework design al-lows for a dual data augmentation method, where diverse
[foreground, background, pseudo GT] triplets can be gen-erated by cropping an image with perturbations using 3D color lookup tables (LUTs). In addition, we build a real-world harmonization dataset as carefully created by expert users, for evaluation and benchmarking purposes. Our re-sults show that the proposed self-supervised method outper-forms previous state-of-the-art methods in terms of refer-ence metrics, visual quality, and subject user study. Code and dataset are available at https://github.com/
VITA-Group/SSHarmonization. 1.

Introduction ance—e.g., the color, saturation, brightness and contrast— of a foreground object to better match the background im-age so that the resulting composite is more realistic. For example, a subject captured under sunlight looks different from one on a cloudy day and its appearance needs to be edited when composited into a cloudy scene.
Previous approaches tackle this issue by transferring the statistic information between the foreground and back-ground regions, including color [19, 36] and texture [31].
More recently, [33, 5, 6] train deep neural networks to ad-dress the image harmonization problem, necessitating the large-scale dataset of input-harmonized composite training pairs. However, collecting a large-scale high-quality har-monization dataset, in general, requires tedious professional expert retouching. Instead, existing methods [33, 5, 6] by-pass this by selecting foreground objects in existing images, perturb their color to simulate an unharmonized composite, and train the network to regress the original input image, as manifested in Fig. 2 left. While these approaches [33, 5, 6] are effective to an extent, they have several limitations:
• Limited ground truth paired data. Collecting high-quality paired harmonization data is time-consuming and laborious. Even in the constrained case presented above, it requires an accurate mask of the foreground object in each image, shown as Fig. 2 left.
Image harmonization is a crucial step in image com-positing that aims at adjusting (harmonizing) the appear-•