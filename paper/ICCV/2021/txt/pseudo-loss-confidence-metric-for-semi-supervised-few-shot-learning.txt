Abstract
Semi-supervised few-shot learning is developed to train a classifier that can adapt to new tasks with limited la-beled data and a fixed quantity of unlabeled data. Most semi-supervised few-shot learning methods select pseudo-labeled data of unlabeled set by task-specific confidence estimation. This work presents a task-unified confidence estimation approach for semi-supervised few-shot learn-ing, named pseudo-loss confidence metric (PLCM). It mea-sures the data credibility by the loss distribution of pseudo-labels, which is synthetical considered multi-tasks. Specifi-cally, pseudo-labeled data of different tasks are mapped to a unified metric space by mean of the pseudo-loss model, making it possible to learn the prior pseudo-loss distribu-tion. Then, confidence of pseudo-labeled data is estimated according to the distribution component confidence of its pseudo-loss. Thus highly reliable pseudo-labeled data are selected to strengthen the classifier. Moreover, to overcome the pseudo-loss distribution shift and improve the effective-ness of classifier, we advance the multi-step training strat-egy coordinated with the class balance measures of class-apart selection and class weight. Experimental results on four popular benchmark datasets demonstrate that the pro-posed approach can effectively select pseudo-labeled data and achieve the state-of-the-art performance. 1.

Introduction
Deep learning has made great strides in many visual recognition tasks, and its outstanding performances even exceed human being in some scenarios [7]. However, it always relies on numerous labeled data which may be a heavy burden of data collection and maintenance in reality
[35]. How to get rid of the limitation of labeled samples and learn a novel category only with one or few labeled samples is the core of few-shot learning. Since few-shot learning has great significance for its extensive applications on arti-*Corresponding authors. ficial intelligence, it aroused a growing academic interest in recent years.
As a typical transfer learning method, fine-tuning [5] is the preliminary exploration for transferring accumulated experience to new tasks. However, it is hard to perform the domain adaptation with only few training data, in which limited samples cannot represent the distribution of its class
[26]. Episodes-based training strategy [6][39] clarifies the few-shot learning problem and has been the foundation of majority few-shot learning methods. Particularly, each episode learns a specific classification task, in which only a few samples per class are available for training. Perfor-mances are calculated on a series of episodes data for test-ing the ability of rapidly adapting to new tasks. Meta-based learning methods [6] [31] adopt the meta-learner to improve the capability of acclimatizing themselves to different tasks.
Metric learning methods [11][12] attempt to find more ef-fective distance metrics from numerous episodic tasks. Uti-lizing the unified metrics formula, the class distribution is more distinctive in metrics space.
More recently, there has been extensive research on semi-supervised few-shot learning (SSFSL), aiming to im-prove the model by utilizing a certain amount of unlabeled data. Predicting pseudo-labels of unlabeled samples and se-lecting high-confidence data for iterative training is a di-rect and valid way for SSFSL [20][40]. However, the task-specific confidence inference of pseudo-label suffers from lacking of adequate instances support in single task. To ad-dress this problem, we propose a task-free credibility esti-mation approach to select the credible pseudo-labeled data, by means of building a unitive confidence metric space.
In this paper, we focus on constructing the reliabil-ity estimation of pseudo-labeled samples and proposing a novel semi-supervised few-shot learning approach called pseudo-loss confidence metric (PLCM). The full procedure is showed in Algorithm 1 and illustrated in Figure 1. We first map pseudo-labeled data to pseudo-loss space by uti-lizing the pseudo-loss model, which can reflect the accep-tance of current classifier to the unlabeled data with its
In general, classifier tends to give decep-pseudo-label.
Figure 1. The overview of our proposed framework. On training process, we construct the pseudo-loss space according to the pseudo-loss model for multi-tasks. Then, a selector and a filter are developed to perform confidence metric for unselected and selected pseudo-labeled data respectively. Finally, the self-training strategy is adopted to fit the mixed set on evaluating process. tive prediction results if the sample is hard to understand.
With the undependable prediction, it is extremely possible to generate noisy pseudo-labels which cause heavier loss than correct pseudo-labels do. Based on this, we set up the semi-supervised Gaussian mixture model (ss-GMM) to fit the pseudo-loss distribution and allocate the credibility of pseudo-label according to learned distribution. Different from other samples selection-based SSFSL methods, our pseudo-loss confidence metric is based on the statistics of multi-episodes tasks, concentrating on generality and unity.
Once the fitting is finished on training process, we estimate the credibility of pseudo-labels on evaluation process only through swift reasoning without any extra training.
The main contributions of this work are summarized as: 1) We present a novel pseudo-labeled data reliability es-timation approach for semi-supervised few-shot learning, dubbed as pseudo-loss confidence metric (PLCM). Differ-ent from the previous work, we assess the confidence of pseudo-labeled data in a unified pseudo-loss metric space 2) We devise instead of apart between different tasks. the multi-step training strategy that learns a more flexi-ble pseudo-loss distribution to follow the training of clas-sifier, which offers stabler confidence metric. 3) Experi-mental results on four widely popular benchmark datasets for few-shot learning demonstrate that the proposed method achieves higher performance compared with other state-of-the-art methods. 1.1.