Abstract
Low-latency deep spiking neural networks (SNNs) have become a promising alternative to conventional artificial neural networks (ANNs) because of their potential for in-creased energy efficiency on event-driven neuromorphic hardware.Neural networks, including SNNs, however, are subject to various adversarial attacks and must be trained to remain resilient against such attacks for many appli-cations. Nevertheless, due to prohibitively high training costs associated with SNNs, an analysis and optimization of deep SNNs under various adversarial attacks have been
In this paper, we first present a de-largely overlooked. tailed analysis of the inherent robustness of low-latency
SNNs against popular gradient-based attacks, namely fast gradient sign method (FGSM) and projected gradient de-scent (PGD). Motivated by this analysis, to harness the model’s robustness against these attacks we present an SNN training algorithm that uses crafted input noise and in-curs no additional training time. To evaluate the mer-its of our algorithm, we conducted extensive experiments with variants of VGG and ResNet on both CIFAR-10 and
CIFAR-100 dataset. Compared to standard trained direct-input SNNs, our trained models yield improved classifica-tion accuracy of up to 13.7% and 10.1% on FGSM and
PGD attack generated images, respectively, with negligi-ble loss in clean image accuracy. Our models also out-perform inherently-robust SNNs trained on rate-coded in-puts with improved or similar classification performance on attack-generated images while having up to 25× and
∼4.6× lower latency and computation energy, respectively.
For reproducibility, we have open-sourced the code at github.com/ksouvik52/hiresnn2021. 1.

Introduction
Artificial neural networks (ANNs) have become enor-mously successful in various computer vision applications
[36, 10, 31, 37, 19]. However, as these applications are often part of safety-critical and trusted systems, concerns about their vulnerability to adversarial attacks have grown
Figure 1. (a) Direct and rate-coded input variants of the original image. (b) Layer wise average spikes for VGG11. (c) Performance of direct-input VGG11 SNN and its equivalent ANN under various white-box (WB) and black-box (BB) attacks on CIFAR-100. rapidly. In particular, well crafted adversarial images with small, often unnoticeable perturbations can fool a well trained ANN to make incorrect and possibly dangerous de-cisions [25, 1, 39], despite their otherwise impressive per-formance on clean images. To improve the model perfor-mance of ANNs against attacks, training with various ad-versarially generated images [22, 17] has proven to be very effective. Few other prior art references [40, 33] have ap-plied noisy inputs to train robust models. However, all these training schemes incur non-negligible clean image accuracy drop and require significant additional training time.
Brain-inspired [23] deep spiking neural networks (SNNs) have also gained significant traction due to their potential for lowering the required power consumption of machine learning applications [13, 28]. The underlying
SNN hardware can use binary spike-based sparse process-ing via accumulate (AC) operations over a fixed number of time steps1 T which consume much lower power than the traditional energy-hungry multiply-accumulate (MAC) operations that dominate ANNs [8]. Recent advances in
SNN training by using approximate gradient [2] and hybrid direct-input-coded ANN-SNN training with joint threshold, leak, and weight optimization [29] have improved the SNN 1Here, a time step is the unit of time taken by each input image to be processed through all layers of the model.
accuracy while simultaneously reducing the number of re-quired time steps. This has lowered both their computa-tion cost, which is reflected in their average spike count as shown in Fig. 1(b), and inference latency. However, the trustworthiness of these state-of-the-art (SOTA) SNNs un-der various adversarial attacks is yet to be fully explored.
Some earlier works have claimed that SNNs may have inherent robustness against popular gradient-based adver-sarial attacks [7, 34, 24]. In particular, Sharmin et al. [34] observed that rate-coded input-driven (Fig. 1(a)) SNNs have inherent robustness, which the authors primarily at-tributed to the highly sparse spiking activity of the model.
However, these explorations are mostly limited to small datasets on shallow SNN models, and more importantly, these techniques give rise to high inference latency. This paper extends this analysis, asking two key questions. 1. To what degree does SOTA low-latency deep SNNs retain their inherent robustness under both black-box and white-box adversarial-attack generated images? 2. Can computationally-efficient training algorithms im-prove the robustness of low-latency deep SNNs while retain-ing their high clean-image classification accuracy?
Our contributions are two-fold. We first empirically study and provide detailed observations on inherent robust-ness claims about deep SNN models when the SNN in-puts are directly coded. Interestingly, we observe that de-spite significant reductions in the average spike count, deep direct-input SNNs have lower classification accuracy com-pared to their ANN counterparts on various white-box and black-box attack generated adversarial images, as exempli-fied in Fig. 1(c).
Based on these observations, we present HIRE-SNN, a spike timing dependent backpropagation (STDB) based
SNN training algorithm to better harness SNN’s inherent robustness. In particular, we optimize the model trainable parameters using images whose pixel values are perturbed using crafted noise across the time steps. More precisely, we partition the training time steps T into N equal-length periods of length ⌊T /N ⌋ and train each image-batch over each period, adding input noise after each period. The key feature of our approach is that, instead of showing the same image repeatedly, we efficiently use the time steps of SNN training to input different noisy variants of the same im-age. This avoids extra training time and, because we up-date the weights after each period, requires less memory for the storage of intermediate gradients compared to tradi-tional SNN training methods. To demonstrate the efficacy of our scheme we conduct extensive evaluations with both
VGG [35] and ResNet [10] SNN model variants on both
CIFAR-10 and CIFAR-100 [14] datasets.
The remainder of this paper is arranged as follows.
In Section 2 and 3 we present the necessary background and provide analysis of inherent robustness of direct-input
SNNs, respectively. Section 4 presents our training scheme.
We provide our experimental results and discussion on Sec-Figure 2. SNN fundamental operations. tion 5 and finally conclude in Section 6. 2.