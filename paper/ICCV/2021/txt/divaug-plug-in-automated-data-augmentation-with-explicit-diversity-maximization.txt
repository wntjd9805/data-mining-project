Abstract
Human-designed data augmentation strategies have been replaced by automatically learned augmentation pol-icy in the past two years. Specifically, recent work has em-pirically shown that the superior performance of the au-tomated data augmentation methods stems from increasing the diversity of augmented data [4, 5]. However, two factors regarding the diversity of augmented data are still missing: 1) the explicit definition (and thus measurement) of diver-sity and 2) the quantifiable relationship between diversity and its regularization effects. To bridge this gap, we pro-pose a diversity measure called Variance Diversity and the-oretically show that the regularization effect of data aug-mentation is promised by Variance Diversity. We validate in experiments that the relative gain from automated data aug-mentation in test accuracy is highly correlated to Variance
Diversity. An unsupervised sampling-based framework, Di-vAug, is designed to directly maximize Variance Diver-sity and hence strengthen the regularization effect. With-out requiring a separate search process, the performance gain from DivAug is comparable with the state-of-the-art method with better efficiency. Moreover, under the semi-supervised setting, our framework can further improve the performance of semi-supervised learning algorithms com-pared to RandAugment, making it highly applicable to real-world problems, where labeled data is scarce. The code is available at https://github.com/warai-0toko/
DivAug. 1.

Introduction
Data augmentation is a technique to create synthetic data from existing data with controlled perturbation. For exam-ple, in the context of image recognition, data augmentation refers to applying image operations, e.g., cropping and flip-*The first two authors contributed equally to this paper. ping, to input images to generate augmented images, which
In practice, data have labels the same as their originals. augmentation has been widely used to improve the general-ization in deep learning models and is thought to encourage model insensitivity towards data perturbation [19, 14, 16].
Although data augmentation works well in practice, design-ing data augmentation strategies requires human expertise, and the strategy customized for one dataset often works poorly for another dataset. Recent efforts have been ded-icated to automating the design of augmentation strategies.
It has been shown that training models with a learned data augmentation policy may significantly improve test accu-racy [20, 28, 5, 15, 13].
However, we do not yet have a good theory to ex-plain how data augmentation improves model generaliza-tion. Currently, the most well-known hypothesis is that data augmentation improves generalization by imposing a reg-ularization effect: it regularizes models to give consistent outputs within the vicinity of the original data, where the vicinity of the original data is defined as the space that con-tains all augmented data after applying operations that do not drastically alter image features [27, 6, 23]. Meanwhile, previous automated data augmentation works claim that the performance gain from applying learned augmentation poli-cies arises from the increase in diversity [4, 5, 15]. How-ever, the “diversity” in the claims remains a hand-waving it is evaluated by the number of distinct sub-concept: policies utilized during training or visually evaluated from a human perspective. Without formally defining diversity and its relation to regularization, the augmentation strategies can only be evaluated indirectly by evaluating the models trained on the augmented data, which may cost thousands of
GPU hours [4]. It motivates us to explore the possibility of using an explicit diversity measure to quantify the regular-ization effect of the augmented data may have on the model.
Thus, in this way we can directly maximize the diversity of the augmented data to strengthen the regularization effect to improve the generalization of the model.
Figure 1: The DivAug framework overview. At the expanding stage, each data in the mini-batch is augmented by multiple randomly generated sub-polices. Notice the probability vectors of these augmented data are also obtained. At the selection stage, k-means++ seeding algorithm is used to sub-sample a subset of augmented data whose probability vectors are far apart from each other and thus diversifies the augmented data. Then the sampled data is used to train the model.
To bridge the gap, in this paper we propose a new di-versity measure, called Variance Diversity, to quantify the diversity of augmented data. We show that the regulariza-tion effect of data augmentation is promised by Variance
Diversity. Our measure is motivated by the recent theoret-ical result that after applying augmented data to train the model, the loss implicitly contains a data-driven regular-ization term that is in proportion to the variance of prob-ability vectors, where probability vectors are the outputs from models trained with the augmented data [6]. Specifi-cally, we measure the diversity of a set of augmented data by the variance of their corresponding probability vectors.
Based on the measure, we propose a plug-in automated data augmentation framework named DivAug, which can plug in the standard training process without requiring a sepa-rate search process. As illustrated in Figure 1, the frame-work has two stages: the expanding stage, where we ran-domly generate several augmented data for each original input data, and the selection stage, where we sub-sample a subset of augmented data and feed them to train the model.
Specifically, at the selection stage, for each image, we sub-sample a subset of augmented images with high diversity by applying the k-means++ seeding algorithm [1], where the augmented data accompanied with probability vector which is far away from that of the original data is sampled with high probability. Following the mathematical deriva-tion, the regularization effect increases with the diversity of the augmented data. Consequently, the stronger regulariza-tion effect can lead to better model generalization, which is observed in terms of improved model performance. Our main contributions can be summarized as follows:
• We propose a new measure for quantifying the diver-sity of augmented data. We validate in our experiments that the relative gain in the accuracy of a model after applying data augmentation is highly correlated to our proposed measure.
• Based on the proposed measure, we design a sampling-based framework to explicitly maximize diversity.
Without requiring a separate search process, the per-formance gain from DivAug is comparable to the state-of-the-art method with better efficiency.
• Our method is unsupervised and can plug in the stan-dard training process. We show that our method can further boost the performance of the semi-supervised learning algorithm, making it highly applicable to real-world problems, where labeled data is scarce. 2.