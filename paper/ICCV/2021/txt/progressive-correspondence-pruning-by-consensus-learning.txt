Abstract
Correspondence pruning aims to correctly remove false matches (outliers) from an initial set of putative correspon-dences. The pruning process is challenging since putative matches are typically extremely unbalanced, largely domi-nated by outliers, and the random distribution of such out-liers further complicates the learning process for learning-based methods. To address this issue, we propose to pro-gressively prune the correspondences via a local-to-global consensus learning procedure. We introduce a “pruning” block that lets us identify reliable candidates among the ini-tial matches according to consensus scores estimated us-ing local-to-global dynamic graphs. We then achieve pro-gressive pruning by stacking multiple pruning blocks se-quentially. Our method outperforms state-of-the-arts on ro-bust line ﬁtting, camera pose estimation and retrieval-based image localization benchmarks by signiﬁcant margins and shows promising generalization ability to different datasets and detector/descriptor combinations. 1.

Introduction
Accurate pixel-wise correspondences act as a premise to tackle many important tasks in computer vision and robotics, such as Structure from Motion (SfM) [39], Simul-taneous Location and Mapping (SLAM) [30], image stitch-ing [7], visual localization [31], and virtual reality [41]. Un-fortunately, feature correspondences established by off-the-shelf detector-descriptors [26, 30, 28, 11] tend to be sen-sitive to challenging cross-image variations, such as rota-tions, scale changes, viewpoint changes, and illumination changes. Much recent research has therefore focused on correspondence pruning [4, 27, 29], aiming to identify cor-rect matches (inliers) while rejecting false ones (outliers).
∗Work was done when the author was an intern at SenseTime Research
†Authors contributed equally
Figure 1. Progressive correspondence pruning via local-to-global consensus learning.
Given initial correspondences (bottom-left image) with dominant outliers, correctly identifying inliers remains challenging.
Instead of classifying correspon-dences in a one-shot fashion, we propose to gradually prune the correspondences to obtain a subset of reliable candidates based on correspondence consensus scores estimated from local-to-global graphs, encouraging accurate inlier identiﬁcation.
In this context, deep learning has been utilized as a pow-erful solution [29, 48, 47, 40], typically casting correspon-dence pruning as a per-match classiﬁcation task, and adopt-ing Multi-Layer Perceptrons (MLPs) to classify putative matches into inliers and outliers. However, the resulting learning problem is signiﬁcantly complicated by the fact that the initial matches are general extremely unbalanced, with around 90% of outliers [48](refer to the bottom-left im-age in Fig 1), which are randomly distributed in real-world scenarios [48]. We therefore employ a toy line-ﬁtting exam-ple shown in Fig. 2 to explain this issue, in which 100 in-liers are identically sampled from the same line, while 900 outliers are randomly located. The standard PointCN [29] baseline may fail to detect the same set of inliers depending on the outliers included in the data, because, given a ﬁnite training time, learning a distinctive feature embedding from
Figure 2. Robustness against different distributions of outliers. The inliers are the same in both cases while the outliers are randomly sampled. PointCN fails to ﬁnd the correct line in the second case, showing its lack of robustness to the outlier distribution. By contrast, by gradually pruning the 2D points into reliable candidates for further line ﬁtting, our method mitigates the effects of randomly-sampled outliers and consistently identiﬁes the line. arbitrarily located outliers is non-trivial.
In this paper, motivated by the classical L∞ minimiza-tion method [38], we propose to progressively prune the initial set of correspondences into a subset of candidates in-stead of classifying correspondences in a one-shot fashion.
As the majority of outliers are expected to be ﬁltered out after progressive pruning, this approach lets us identify re-liable inliers among the candidates (bottom-right image in
Fig. 1). This process, however, requires deﬁning a pruning strategy. Leveraging the intuition that one cannot classify an isolated correspondence as inlier or outlier without context information, we therefore introduce a local-to-global con-sensus learning framework, which explicitly captures local and global correspondence context via dynamic graphs to facilitate the correspondence pruning process.
Speciﬁcally, we dynamically construct a local graph for each input correspondence, whose nodes and edges repre-sent the neighbors of the correspondence and their afﬁnities in feature space, respectively. We then introduce an annular convolutional layer to aggregate local features and produce a consensus score for each local graph. Guided by local consensus scores, we further merge multiple local graphs into a global one, from which we obtain a global consen-sus score via a spectral graph convolutional layer [21]. To-gether, the local and global consensus learning layers form a novel “pruning” block, which preserves potential inliers with higher consensus scores while ﬁltering out outliers with lower scores. Correspondence pruning is then progres-sively achieved by stacking multiple pruning blocks. Such an architecture design encourages the reﬁnement of local and global consensus learning at multiple scales. In contrast to previous works [29, 40] that implicitly model contextual information via feature normalization, our network explic-itly exploits context thanks to our local-to-global graphs.
Our contributions can be summarized as follows.
• We propose to progressively prune correspondences for better inlier identiﬁcation, which alleviates the ef-fects of unbalanced initial matches and random outlier distribution.
• We introduce a local-to-global consensus learning net-work for robust correspondence pruning, achieved by establishing dynamic graphs on-the-ﬂy and estimating both local and global consensus scores to prune corre-spondences1.
• Our approach explicitly captures contextual informa-tion to identify inliers from outliers.
We empirically demonstrate the effectiveness of our method on the tasks of robust line ﬁtting, camera pose estima-tion and retrieval-based image localization. Our approach outperforms the state-of-the-art methods by a considerable margin. 2.