Abstract
Deformable templates are essential to large-scale medi-cal image registration, segmentation, and population anal-ysis. Current conventional and deep network-based meth-ods for template construction use only regularized regis-tration objectives and often yield templates with blurry and/or anatomically implausible appearance, confounding downstream biomedical interpretation. We reformulate de-formable registration and conditional template estimation as an adversarial game wherein we encourage realism in the moved templates with a generative adversarial regis-tration framework conditioned on flexible image covariates.
The resulting templates exhibit significant gain in specificity to attributes such as age and disease, better fit underlying group-wise spatiotemporal trends, and achieve improved sharpness and centrality. These improvements enable more accurate population modeling with diverse covariates for standardized downstream analyses and easier anatomical delineation for structures of interest. 1.

Introduction
Deformable image registration enables the quantification of geometric dissimilarity via the pairwise warping of a source image to a target. In the context of population stud-ies, pairwise registration of a subject onto a deformable tem-plate is a central step in standardized analyses, where an ideal template is an unbiased barycentric representation of the (sub-)population of interest [7, 10, 47]. Templates play a key role in diverse large-scale biomedical imaging tasks such as alignment to a common coordinate system [33, 86], brain extraction [38, 43], segmentation [17, 43], and image and shape regression models [31, 67], among others.
While templates can be obtained from a reference database, they are preferably constructed for specific pop-ulations by optimizing for an image which minimizes the average deformation to each individual subject. As the template strongly affects subsequent morphometric analy-sis [82, 89], template construction has received significant attention. Further, as a single template cannot capture the wide structural variability within a population (via age and cohort, for example), we consider conditional template esti-mation with continuous and/or categorical attributes. Con-ditional templates constructed on image sets with diverse covariates enable sub-population modeling accounting for information learned from the overall population and obviate the need for arbitrary thresholding of demographic informa-tion to perform independent analyses [20, 23, 98].
Implicit models for template estimation [2, 7, 10, 47, 58, 96] alternate between registration of each scan to the cur-rent template estimate and updating the template based on averages of the warped subject scans. Due to the averag-ing of aligned image intensities, the resulting templates may blur significantly in regions with high-frequency deforma-tions even alongside shape corrections [10]. Recently, ex-plicit template estimation via unsupervised deep networks was proposed in [23] where each stochastic update of a reg-istration network yields a (potentially conditional) template without averaging aligned images and transformations.
However, both implicit and explicit models typically only minimize an image dissimilarity term between the moved template and fixed image (and/or vice-versa) sub-ject to application-specific regularization ensuring a diffeo-morphic (smooth, differentiable, and invertible) transfor-mation. As inter-brain variability includes complex topo-logical changes not captured by purely diffeomorphic mod-els, estimated templates are often unrealistic and do not re-semble the data that they represent. Sub-optimal appear-ance impacts downstream applications due to ambiguous and/or implausible anatomical boundaries. For example, in order to register one or more expert-annotated templates to target images for atlas-based segmentation [43, 54, 59], the template(s) must have clearly distinguishable anatomi-cal boundaries to enable expert delineation. Unfortunately, structural anatomical boundaries are often obfuscated by current template estimation approaches.
We present a learning framework to estimate sharp (op-tionally conditional) templates with realistic anatomy via
generative adversarial learning. Our core insight is that in addition to possessing high registration accuracy, the distribution of moved template images should be indistin-guishable from the real image distribution. We develop a generator comprising of template generation and regis-tration sub-networks and a discriminator which assesses the realism and condition-specificity of the synthesized and warped templates. As adversarial objectives encour-age high-frequency detail, the templates gain naturalistic boundaries without the need for ad hoc post-processing.
To develop stable and accurate 3D GANs for large medi-cal volumes with highly limited sample and batch sizes, we develop extensive optimization and architectural schemes, augmentation strategies, and conditioning mechanisms.
Our contributions include: (1) a generative adversarial approach to deformable template generation and registra-tion which for the first time uses a realism-based registra-tion regularizer; (2) construction of conditional templates across diverse challenging datasets including neuroimages of pre-term and term-born newborns, adults with and with-out Huntingtonâ€™s disease, and real-world face images; (3) improvements on current template construction methodolo-gies in terms of centrality and interpretability alongside sig-nificantly increased condition-specificity. Code is available at https://github.com/neel-dey/Atlas-GAN. 2.