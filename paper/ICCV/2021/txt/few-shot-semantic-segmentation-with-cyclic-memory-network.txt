Abstract
Few-shot semantic segmentation (FSS) is an important task for novel (unseen) object segmentation under the data-scarcity scenario. However, most FSS methods rely on uni-directional feature aggregation, e.g., from support proto-types to get the query prediction, and from high-resolution features to guide the low-resolution ones. This usually fails to fully capture the cross-resolution feature relationships and thus leads to inaccurate estimates of the query objects.
To resolve the above dilemma, we propose a cyclic memory network (CMN) to directly learn to read abundant support information from all resolution features in a cyclic manner.
Speciﬁcally, we ﬁrst generate N pairs (key and value) of multi-resolution query features guided by the support fea-ture and its mask. Next, we circularly take one pair of these features as the query to be segmented, and the rest N-1 pairs are written into an external memory accordingly, i.e., this leave-one-out process is conducted for N times. In each cy-cle, the query feature is updated by collaboratively match-ing its key and value with the memory, which can elegantly cover all the spatial locations from different resolutions.
Furthermore, we incorporate the query feature re-adding and the query feature recursive updating mechanisms into the memory reading operation. CMN, equipped with these merits, can thus capture cross-resolution relationships and better handle the object appearance and scale variations in
FSS. Experiments on PASCAL-5i and COCO-20i well vali-date the effectiveness of our model for FSS.
Figure 1. Illustrations of existing FSS models and our CMN. (a) Existing FSS methods usually rely on unidirectional feature aggregation, e.g., utilizing the support prototypes to get the query prediction or leveraging the high-resolution features to guide the low-resolution ones. However, some car regions are wrongly pre-dicted as airplane, which is due to the large object variations in the support and query images (the airplanes have different scales and appearance colors). In this case, these unidirectional methods fail to capture and overcome the object variations. (b) CMN predicts the airplane in the query image pretty well, which beneﬁts from our cyclic memory reading on the multi-resolution features. 1.

Introduction
Training high performance semantic segmentation mod-els [1, 3, 18, 24, 42], based on convolutional neural net-works [12, 27, 38, 47], typically requires large amounts of human-annotated training data, e.g., pixel-level annotations are essential for training a desirable segmentation model.
However, data annotating by humans is usually costly and labor-intensive. Moreover, these models, almost always,
*Corresponding authors. fail to segment novel (unseen) objects, when given very few (one) training images (image) with annotations. To this end, as in conventional zero- and few-shot classiﬁcation models [28, 36, 37] that aim to mitigate data annotation and novel object recognition issues in the high-level semantic category space, few-shot semantic segmentation (FSS) [25] has become an active research topic for alleviating these is-sues in the low-level image pixel space, under the object segmentation scenario.
FSS leverages scarce support images with ground-truth
masks – i.e., labeled support set – to segment unseen objects from a query image, where the focused objects share a com-mon class for both the support and query images. Besides the support images, a large-scale training set (base data) having disjoint classes with the support set is provided for learning transferable knowledge from the seen to the un-seen domains. Typically, meta-training [28] is performed on this base data by episode sampling. Here, the constitu-tion of each episode is the same as meta-testing scenario, i.e., a support image set and a query image set. As such, these support images are used as guidance information for the foreground prediction of the query image.
Extensive progresses have been achieved in FSS [7, 21, 26, 32], and most of them utilize a two-branch metric-based network architecture: one for coping with the sup-port images and the other for the query image. For a con-sidered class, the support branch outputs its global and/or local prototypes [9, 17, 39, 46], e.g., by masked average-pooling on the labeled support feature maps. Further, the query branch takes these support prototypes as guidance to segment the query objects by a location-wise match-ing between query feature in each location and these pro-totypes.
In this way, we can achieve the support guided prediction maps for the query, which however, is an uni-directional feature aggregation and thus it is hard to fully capture the object variations based on these limited support guidance (Fig. 1(a)). Recently, some works [31, 41, 44] ex-plore a dense matching scheme – i.e., non-local attention variants [34] – from support to query images, which can al-leviate the object variation issue to some extent, however, these methods are essentially still unidirectional at the pre-diction layer or at most bi-directional for exchanging infor-mation between support-query features at the middle layers.
As in common semantic segmentation task, the ideal uti-lizations of multi-resolution features [4, 16, 30] are the key for achieving accurate segmentation results. To achieve so, some works [30,44] adopt feature pyramid fusion in FSS for enhancing the original features, however, the interactions between these multi-resolution features are unidirectional and/or from high-resolution features to low-resolution ones (Fig. 1(a)), which fails to fully capture the cross-resolution feature relationships.
In this paper, to address the aforementioned issues, we propose a novel cyclic memory network (CMN) [14, 22] (§3.3 and Fig. 2) by directly learning to read abundant sup-port information from all resolution features for tackling
FSS. Speciﬁcally, we generate K pairs (key and value) of multi-resolution query features guided by the support fea-ture and its mask. The intuitions under our framework lie in that (1) Given each pixel in a supposed query feature having a speciﬁc resolution, CMN can explicitly access and read all the other features with different resolutions, which are served as comprehensive guidances to distinguish the considered pixel, i.e., belonging to a foreground or a back-ground. As shown in the second row of the allocation table in Fig. 1(b), when taking the medium resolution as query, the large and small resolutions (memory) are guidances. (2) Contrast to unidirectional feature aggregation of previ-ous methods (Fig. 1(a)), CMN circularly takes each resolu-tion feature as the query one and the rest features are fed into to the memory, which can thus fully exploit the cross-resolution relationships and handle the object appearance and scale changes much better than the previous methods.
As such, a precise prediction of the airplane in the query image is achieved in Fig. 2(b). Since FSS is a pixel-level prediction task, to reserve and transfer more structural con-text for desirable unseen object segmentation, we further in-corporate the query feature re-adding and the query feature recursive updating mechanisms (Fig. 3) into the memory reading operation. To sum up, our contributions are:
• We propose a cyclic memory network (CMN) which circularly takes the cross-resolution features as memory guidance to precisely segment the supposed query feature, for tackling the FSS task. To the best of our knowledge, we are the ﬁrst to model FSS as a memory network framework.
• We introduce the query feature re-adding and the query feature recursive updating mechanisms into the memory reading operation of CMN, which have improved the per-formance of CMN signiﬁcantly.
• We achieve state-of-the-art performances under mean-IoU and competitive results under FB-IoU on two FSS benchmarks. 2.