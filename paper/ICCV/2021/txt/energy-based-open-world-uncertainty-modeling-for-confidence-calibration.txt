Abstract
Confidence calibration is of great importance to the re-liability of decisions made by machine learning systems.
However, discriminative classifiers based on deep neural networks are often criticized for producing overconfident predictions that fail to reflect the true correctness likelihood of classification accuracy. We argue that such an inability to model uncertainty is mainly caused by the closed-world na-ture in softmax: a model trained by the cross-entropy loss will be forced to classify input into one of K pre-defined categories with high probability. To address this problem, we for the first time propose a novel K+1-way softmax for-mulation, which incorporates the modeling of open-world uncertainty as the extra dimension. To unify the learning of the original K-way classification task and the extra di-mension that models uncertainty, we 1) propose a novel energy-based objective function, and moreover, 2) theoret-ically prove that optimizing such an objective essentially forces the extra dimension to capture the marginal data dis-tribution. Extensive experiments show that our approach,
Energy-based Open-World Softmax (EOW-Softmax), is su-perior to existing state-of-the-art methods in improving con-fidence calibration. 1.

Introduction
Given the considerable success achieved so far by deep neural networks (DNNs), one might be wondering if DNN-based systems can be readily deployed to solve real-world problems. On the one hand, DNNs can achieve high ac-curacy if trained with large-scale datasets [15]. But on the other hand, contemporary DNNs are often criticized for producing overconfident predictions [14], which fail to represent the true correctness likelihood of accuracy.
This has raised concerns over safety and reliability for
*Equal contribution. Ordered by dice rolling. Correspondence to yezhen.wang0305@gmail.com. using machine learning systems in real-world scenarios.
Having a confidence-calibrated system is critical. For in-stance, in healthcare applications, the intelligence system should produce low-confidence predictions when it is un-certain about the input—say they differ significantly from the training data—so the decision-making process can be transferred to human doctors for more accurate diagno-sis and safer handling. Research on confidence calibra-tion for DNNs has received increasing attention in recent years [14, 27, 19, 23, 27]. Since most classifiers are based on softmax, a common practice to improve calibration is to insert a temperature scaling parameter to the softmax func-tion and adjust it in a validation set [14]. Besides, methods like Smoothing labels [36, 28], which essentially combines the one-hot ground-truth vector with a uniform distribution, has also been shown effective in improving calibration.
However, most existing confidence calibration methods have overlooked the underlying problem that causes neural network classifiers to generate overconfident predictions, i.e. the inability to model uncertainty in output probabili-ties. We argue that the culprit for causing such a problem is the closed-world nature in softmax [2, 34]. This is easy to understand: during training the model is asked to classify input into one of K pre-defined categories with high proba-bility (due to the cross-entropy loss), and as such, the model has no choice but to assign one of the K categories to any unseen data, likely with high probability as well.
A potential countermeasure is to adopt a K + 1-way formulation where the new category can represent uncer-tainty about the input data. In this way, the K classification scores might be better regularized, and hence better cali-brated. However, learning such a classifier is challenging as we do not have access to those data with the K + 1-th la-bel, thus lacking supervision to teach the network when to give low/high confidence. Furthermore, designing the extra dimension is a non-trivial task as it is directly linked to the formulation of the learning objective. It is also unclear how such a dimension should be constructed, e.g., to design it as another logit produced by the same network or an indepen-Figure 1. Comparison between (a) the conventional softmax and (b) our proposed Energy-based Open-World softmax (EOW-Softmax).
Our new formulation introduces an extra dimension to model uncertainty, which is supposed to produce high scores when the input deviates from the training data distribution. In this way, the original K classification scores can be well calibrated. dent branch that regresses to uncertainty.
In this paper, we propose Energy-based Open-World
Softmax (EOW-Softmax), a novel approach that introduces a K + 1-way softmax based on energy functions [25].
Specifically, the neural network classifier is designed to pro-duce K + 1 logits, where the first K dimensions encode the scores for the original K-way classification task, while the extra dimension aims to model open-world uncertainty. See
Figure 1 for a comparison between a model based on the conventional softmax and that based on our EOW-Softmax.
Besides, we resort to an energy-based K +1-way classifica-tion objective function to unify the learning of the K-way classification task and the uncertainty modeling. Further more, we theoretically justify that optimizing the proposed objective function essentially forces the summation of orig-inal K softmax scores (K + 1 scores in total) to be directly proportional to the marginal density p(x), hence explain-ing why our EOW-Softmax helps calibrate a model’s confi-dence estimates.
The contributions of this paper are summarized as fol-lows. 1) First, we overcome the closed-world softmax prob-lem by transforming the conventional K-way softmax to a novel K + 1-way formulation, where the extra dimension is designed to model open-world uncertainty. 2) Second, a novel energy-based objective function is developed to unify the learning of the original K-way classification task and the uncertainty modeling. 3) A theoretical proof is further provided to explain why our learning objective can help the network capture uncertainty. 4) Finally, we conduct exten-sive experiments on standard benchmark datasets to demon-strate that our method can lead to a better calibrated model compared with other state-of-the-arts. 2.