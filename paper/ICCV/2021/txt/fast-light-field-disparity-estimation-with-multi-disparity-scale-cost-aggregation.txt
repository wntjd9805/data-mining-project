Abstract
Light field images contain both angular and spatial in-formation of captured light rays. The rich information of light fields enables straightforward disparity recovery capa-bility but demands high computational cost as well. In this paper, we design a lightweight disparity estimation model with physical-based multi-disparity-scale cost volume ag-gregation for fast disparity estimation. By introducing a sub-network of edge guidance, we significantly improve the recovery of geometric details near edges and improve the overall performance. We test the proposed model exten-sively on both synthetic and real-captured datasets, which provide both densely and sparsely sampled light fields. Fi-nally, we significantly reduce computation cost and GPU memory consumption, while achieving comparable perfor-mance with state-of-the-art disparity estimation methods for light fields. Our source code is available at https:
//github.com/zcong17huang/FastLFnet. 1.

Introduction
Disparity estimation from light fields has become a promising way to derive disparity information with the arise of consumer-level light field cameras [20, 24]. Many algo-rithms have been proposed to estimate disparity maps from the light field images [25, 12, 9, 29].
With the progress of the artificial neural network, the learning-based algorithms are proposed [14, 3, 33, 28, 29, 26] and greatly improve the performance of disparity es-timation. Considering the high-dimensional essence of this problem, 3D CNN architecture is widely used to han-dle the space-disparity representation for higher accuracy
[14, 3, 29]. However, the extremely high computational cost and huge GPU memory consumption bring lots of difficul-ties to train and deploy the model in practice. Although several fast disparity estimation methods [28, 8, 31] have been proposed, they suffer from the loss of accuracy.
Figure 1. Comparison in performance and efficiency of light field disparity estimation algorithms.
In this work, we propose a fast and lightweight end-to-end deep architecture without using any 3D CNN modules for estimating disparity maps from light field images. Tak-ing into account that different views of light fields have dif-ferent disparity scales, we design a physical-based multi-disparity-scale cost aggregation module for efficient cost regularization. The proposed method can save computation and memory cost while providing pyramidal disparity infor-mation for better accuracy and robustness.
Abandoning the 3D CNN architecture may deteriorate the results in challenging regions with fine structures and detailed textures, thus an edge guidance sub-network is pro-posed to preserve subtle details by integrating edge informa-tion into the main network. The edge maps can highlight the regions where fine structures and detailed textures should be given more attention to, and guide the network handling these regions specially to achieve better results. Based on the edge-guided multi-disparity-scale cost aggregation, the proposed network could achieve competitive performance with the state-of-the-art methods with much faster comput-ing speed and lower GPU memory consumption, as shown
in Fig. 1. In summary, the main contributions are as follows:
• We propose a fast and lightweight end-to-end network for light field disparity estimation.
• We present a physical-based multi-disparity-scale net-work for fast and high-performance cost volume regulariza-tion.
• We design an edge guidance sub-network to guide the disparity estimation with edge cues for better performance on challenging regions.
• We achieve competitive performance on par with state-of-the-art methods for both densely and sparsely sampled light fields while significantly reducing the computation cost and GPU memory consumption. 2.