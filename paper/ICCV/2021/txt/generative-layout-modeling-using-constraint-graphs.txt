Abstract
We propose a new generative model for layout generation.
We generate layouts in three steps. First, we generate the layout elements as nodes in a layout graph. Second, we compute constraints between layout elements as edges in the layout graph. Third, we solve for the ﬁnal layout using constrained optimization. For the ﬁrst two steps, we build on recent transformer architectures. The layout optimiza-tion implements the constraints efﬁciently. We show three practical contributions compared to the state of the art: our work requires no user input, produces higher quality layouts, and enables many novel capabilities for conditional layout generation. 1.

Introduction
We study the problem of topologically and spatially con-sistent layout generation. This problem arises in image lay-out synthesis, ﬂoor plan synthesis, furniture layout genera-tion, street layout planning, and part-based object creation, to name a few. Generated content must meet stringent crite-ria both globally, in terms of its overall topological structure, as well as locally, in terms of its spatial detail. While our work applies to layouts in general, we focus our discussion on two types of layouts: ﬂoorplans and furniture layouts.
When assessing layouts, we must consider the global structure which is largely topological in nature, such as con-nectivity between individual elements or inter-element hop distance. We are also concerned with spatial detail, such as the geometric realization of the elements and their relative positioning, both local and non-local. Realism of such gener-ated content is often assessed by comparing distributions of their properties, both topological and spatial, against those from real-world statistics.
Techniques to generate realistic content have made rapid progress in recent years due to the emergence of generative adversarial networks (GANs) [13, 71, 24, 57], variational autoencoders (VAEs) [27, 53], ﬂow models [48, 63, 53], and autoregressive models [8]. However, satisfying both topolog-ical and spatial properties still remains an open challenge.
Figure 1. We present a method for layout generation. Our approach can generate multiple types of layouts, such as the ﬂoor plans in the top row, where rooms are colored by type, and furniture layouts in the bottom row, where furniture pieces are colored by type. Layouts are represented as graphs, where nodes correspond to layout elements and edges to relationships between elements.
In the top row, nodes represent rooms (illustrated with room-type icons), and edges relate rooms connected by doors (dotted lines).
Unlike previous methods, our method does not require any input guidance and generates higher-quality layouts.
Recently, three papers targeting this challenging problem in the ﬂoor plan setting were published [61, 16, 38]. While these papers often produce good looking ﬂoor plans, they require several simpliﬁcations to tackle this difﬁcult problem: 1) RPLAN [61] and Graph2Plan [16] require the outline of the ﬂoorplan to be given. 2) HouseGAN [38] does not generate the connectivity between rooms that would be given by doors, and RPLAN places doors using a manually deﬁned heuristic that is not learned from data. 3) HouseGAN and
Graph2Plan require the number of rooms, the room types and their topology to be given as input in the form of an adjacency graph. 4) All three methods require a heuristic
post-process that is essential to make the ﬂoorplan look more realistic, but that is not learned from data, such as adding doors and windows (RPLAN), or ﬁxing gaps and overlaps (HouseGAN). In addition, there is still a lot of room to improve the quality and realism of the results.
In this paper, we would like to explore two ideas to im-prove upon this exciting initial work. First, after extensive experiments with many variations of graph-based GANs and
VAEs, we found that these architectures are not well suited to tackle the problem. It is our conjecture that these methods struggle with the discrete nature of graphs and layouts. We therefore propose an auto-regressive model using attention and self-attention layers. Such an architecture inherently handles discrete data and gives superior performance to current state of the art models. While transformer-based auto-regressive models [55] just started to compete with
GANs built on CNNs in image generation [41, 7] on the
ImageNet [10] dataset, we will show that the gap between these two competing approaches for layout generation is signiﬁcant.
Second, we explore the idea of generative modeling using constraint generation. We propose to model layouts with autoregressive models that generate constraint graphs: indi-vidual shapes are nodes and edges between nodes specify constraints. Our auto-regressive model ﬁrst generates initial nodes, that are subsequently optimized to satisfy constraint edges generated by a second auto-regressive model. These models can be conditioned on additional constraints pro-vided by the user. This enables various forms of conditional generation and user interaction, from satisfying constraints provided by the user, to a fully generative model that gener-ates constraints from scratch without user interaction. For example, a user can optionally specify a ﬂoorplan boundary, or a set of rooms.
In summary, we introduce two main contributions: 1) A transformer-based architecture for generative modeling of layouts that produces higher quality layouts than previous work. 2) The idea of a generative model that generates constraint graphs and solves for the spatial shape attributes via optimization, rather than outputting shapes directly.
We demonstrate our approach in the context of ﬂoor plan generation by creating room layouts and furniture layouts for apartments (see Figure 1). Our evaluation shows that our generative model allows layout creation that matches both global and local statistics of real-world data much better than competing work. 2.