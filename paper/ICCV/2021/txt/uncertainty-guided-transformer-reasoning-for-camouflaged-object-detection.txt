Abstract
Spotting objects that are visually adapted to their sur-roundings is challenging for both humans and AI. Con-ventional generic / salient object detection techniques are suboptimal for this task because they tend to only discover easy and clear objects, while overlooking the difﬁcult-to-detect ones with inherent uncertainties derived from indis-tinguishable textures. In this work, we contribute a novel approach using a probabilistic representational model in combination with transformers to explicitly reason under uncertainties, namely uncertainty-guided transformer rea-soning (UGTR), for camouﬂaged object detection. The core idea is to ﬁrst learn a conditional distribution over the backbone’s output to obtain initial estimates and as-sociated uncertainties, and then reason over these uncer-tain regions with attention mechanism to produce ﬁnal predictions. Our approach combines the beneﬁts of both
Bayesian learning and Transformer-based reasoning, al-lowing the model to handle camouﬂaged object detection by leveraging both deterministic and probabilistic informa-tion. We empirically demonstrate that our proposed ap-proach can achieve higher accuracy than existing state-of-the-art models on CHAMELEON, CAMO and COD10K datasets. Code is available at https://github.com/ fanyang587/UGTR. 1.

Introduction
Camouﬂaged object detection (COD), also known as de-camouﬂaging, aims to discover the hidden targets from a given scene.
It is not only an important scientiﬁc topic on understanding the relationship between visual perception and camouﬂage, but also can facilitate many real-life appli-cations, such as image synthesis [4], species discovery [41] and medical image analysis [13]. However, body colours, patterns and other morphological adaptations of camou-ﬂaged object(s) would signiﬁcantly decrease their probabil-ity of being detected, recognized or targeted, making de-*Corresponding author: Xin Li (xinli uestc@hotmail.com)
Figure 1: Our idea is to consider object decamouﬂaging as mixtures of probabilistic-deterministic procedures. The probabilistic representational model is used to capture un-certainty (dashed line), and the Transformer-based model is learned to exploit context for overcoming ambiguity guided by the mined uncertainty (solid line). camouﬂaging difﬁcult for both humans and machines.
Over decades, researchers and scientists have been try-ing to build machine intelligence that is capable of see-ing through camouﬂage [45, 49]. Early attempts on COD used handcrafted features in an unsupervised way, e.g., colour and intensity features [21], 3D convexity [40] and motion boundary [18]. Recently, convolutional neural net-works (CNNs) have been used to address the COD prob-lem. To solve the ambiguities caused by indistinguish-able textures, unlike generic / salient object detection mod-els [9,16,31,32,35,43,59,61], current COD approaches usu-ally distill extra features from the shared context (e.g., fea-tures for identiﬁcation [12], classiﬁcation [29] and bound-ary detection [57]) and incorporate them for joint represen-tation learning via cross-modality fusion techniques. De-spite their progress, none of these approaches has explicitly taken into account the uncertainties caused by camouﬂage strategies, making the representation learning for COD not well-targeted and even easily misguided, not to mention the negative effects of the inherent modality difference of auxiliary- and main-task features. Empirically, we ﬁnd that existing techniques cannot properly identify those true mas-ters of camouﬂage which hide their outlines perfectly.
For better decamouﬂaging performance, we inject
Bayesian learning into Transformer-based reasoning, and
propose the Uncertainty-Guided Transformer Reasoning (dubbed as UGTR) as a new learning paradigm. That is, we ﬁrst obtain initial estimates and quantify the cor-responding uncertainties with the probabilistic representa-tional model [23, 24, 51]. Then, we reason about con-text to infer the difﬁcult-to-detect (uncertain) regions with transformers [7, 50]. Therefore, as illustrated in Figure 1, our UGTR converts the learning of the deterministic map-ping [12, 29, 55, 57] to a more complicated, uncertainty-guided context reasoning procedure. We expect that our carefully designed UGTR will be able to reason with con-text information under conditions of uncertainty, and reli-ably infer the concealed objects by leveraging both deter-ministic and probabilistic information.
More speciﬁcally, our UGTR is composed of three main components: i) uncertainty quantiﬁcation network (UQN), ii) uncertainty-induced transformer (UGT) and iii) auxil-iary prototyping transformer (PT). To obtain uncertainty maps, we draw inspiration from Bayesian probability the-ory [1, 23, 25, 26, 62] and design our UQN as a probabilis-tic representational model, which learns probability distri-butions rather than pixel estimates. We draw K samples from the learned distributions to produce initial estimates and measure the uncertainties. Then, our UGT comprehen-sively exploits richer context to infer the difﬁcult-to-detect (uncertain) regions via attention mechanism. Moreover, to get the transformer focused on uncertain regions, we in-troduce an uncertainty-guided random masking algorithm (UGRM) that automatically assigns higher probability of being masked out to uncertain regions during training. Ac-cordingly, the transformer is trained to be efﬁcient at in-ferring and recovering the content in uncertain regions by exploiting context information. Last but not least, an aux-iliary transformer, called Prototyping Transformer (PT), is plugged to assist UGT in mining higher-level semantics.
We design multiple loss functions for our UGTR, making all components (i.e., UQN, UGT and PT) being learned jointly from the raw data.
Our UGTR achieves state-of-the-art (SOTA) perfor-mance on the CHAMELEON [46], CAMO [29] and
COD10K [12] without requiring any extra information (e.g.,
ﬁxation or boundary). Besides, by explicitly modeling un-certainties, our UGTR also increases the interpretability of
COD models and facilitates further analysis and study of visual camouﬂage. Our contributions are three-fold:
• A new learning paradigm for camouﬂaged object de-tection. To our knowledge, this is the ﬁrst attempt to introduce Bayesian learning into Transformer-based rea-soning for camouﬂaged object detection.
It converts the deterministic mapping process of conventional COD models to an uncertainty-guided context reasoning pro-cedure. By explicitly quantifying uncertainty that carries crucial information, it enables well-directed context rea-soning to overcome all difﬁculties in camouﬂage analysis.
• A novel uncertainty-guided transformer reasoning model for camouﬂaged object detection. We present the uncertainty-guided transformer reasoning model (UGTR) that integrates all novel components, such as uncertainty quantiﬁcation network (UQN), prototyping transformer (PT) and uncertainty-guided transformer (UGT), within a uniﬁed, end-to-end framework for camouﬂaged object detection. It should be noted that our proposed UGRM al-gorithm serves as a hard-example-mining module, which uses uncertainty guidance to enhance UGT’s context rea-soning capability during training.
• State-of-the-art results on widely-used bench-marks. Our fully-equipped UGTR achieves SOTA performance on a variety of benchmarks, including
CHAMELEON [46], CAMO [29] and COD10K [12], and outperforms existing COD models by a large margin. 2.