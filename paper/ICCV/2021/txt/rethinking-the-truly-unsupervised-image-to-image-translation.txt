Abstract
Every recent image-to-image translation model inher-ently requires either image-level (i.e. input-output pairs) or set-level (i.e. domain labels) supervision. However, even set-level supervision can be a severe bottleneck for data col-lection in practice. In this paper, we tackle image-to-image translation in a fully unsupervised setting, i.e., neither paired images nor domain labels. To this end, we propose a truly unsupervised image-to-image translation model (TU-NIT) that simultaneously learns to separate image domains and translates input images into the estimated domains. Ex-perimental results show that our model achieves compara-ble or even better performance than the set-level supervised model trained with full labels, generalizes well on various datasets, and is robust against the choice of hyperparam-eters (e.g. the preset number of pseudo domains). Fur-thermore, TUNIT can be easily extended to semi-supervised learning with a few labeled data. 1.

Introduction
Given an image of one domain, image-to-image transla-tion is a task to generate the plausible images of the other domains. Based on the success of conditional generative models [26, 31], many image translation methods have been proposed either using image-level supervision (e.g. paired data) [14, 12, 39, 33, 28] or using set-level supervision (e.g. domain labels) [38, 18, 21, 13, 22, 20]. Though the latter approach is generally called unsupervised as a counterpart of the former, it actually assumes that the domain labels are given a priori. This assumption can be a serious bot-tleneck in practice as the number of domains and samples increases. For example, labeling individual samples of a
∗Work done during his internship at Clova AI Research.
†Hyunjung Shim is a corresponding author. (a) Image-level (b) Set-level (c) Unsupervised
Figure 1: Levels of supervision. To perform image-to-image translation, existing methods need either (a) a dataset with input-output pairs or, (b) a dataset with domain information. Our method is capable of learning mappings among multiple domains using (c) a dataset without any supervision. large dataset (e.g. FFHQ) is expensive, and the distinction across domains can be vague.
We ﬁrst clarify that unsupervised image-to-image trans-lation should strictly denote the task without any supervi-sion neither paired images nor domain labels. Under this rigorous deﬁnition, our goal is to develop an unsupervised translation model given a mixed set of images of many do-mains (Figure 1). We argue that the unsupervised transla-tion model is valuable in three aspects. First of all, it sig-niﬁcantly reduces the effort of data annotation for model training. As a natural byproduct, the unsupervised model can be robust against the noisy labels produced by the man-ual labeling process. More importantly, it serves as a strong baseline to develop the semi-supervised image translation models. To tackle this problem, we design our model hav-ing three sub-modules: 1) clustering the images by approx-imating the set-level characteristics (i.e. domains), 2) en-coding the individual content and style of an input image, respectively, and 3) learning a mapping function among the estimated domains.
To this end, we introduce a guiding network. The guiding network consists of a shared encoder with two
branches, where one provides pseudo domain labels and the other encodes images into feature vectors (style codes). We employ a differentiable clustering method based on mutual information maximization for estimating the domain labels and contrastive loss for extracting the style codes. The clus-tering helps the guiding network to group similar images into the same category. Meanwhile, the contrastive loss helps the model to understand the dissimilarity among im-ages and learn better representations. We ﬁnd that, by solv-ing two tasks together within the same module, both beneﬁt from each other. Speciﬁcally, the clustering can exploit rich representations learned by the contrastive loss and improve the accuracy of estimated domain labels. By taking advan-tage from the clustering module, the style code can also ac-knowledge the similarity within the same domain, thereby faithfully reﬂecting the domain-speciﬁc nature.
For both more efﬁcient training and effective learning, we jointly train the guiding network and GAN in an end-to-end manner. This allows the guiding network to understand the recipes of domain-separating attributes based on GAN’s feedback, and the generator encourages the style code to contain rich information so as to fool the domain-speciﬁc discriminator. Thanks to these internal and external inter-actions of the guiding network and GAN, our model suc-cessfully separates domains and translates images; a truly unsupervised image-to-image translation.
We quantitatively and qualitatively compare the pro-posed model with the existing set-level supervised models under unsupervised and semi-supervised settings. The ex-periments on various datasets show that the proposed model outperforms the baselines over all different levels of super-vision. Our ablation study shows that the guiding network helps the image translation model to largely improve the performance. Our contributions are summarized as follows:
• We clarify the deﬁnition of unsupervised image-to-image translation and to the best of our knowledge, our model is the ﬁrst to succeed in this task in an end-to-end manner.
• We propose the guiding network to handle the unsuper-vised translation task and show that the interaction be-tween translation and clustering is helpful for the task.
• The quantitative and qualitative comparisons for the un-supervised translation task on four public datasets show the effectiveness of TUNIT, which clearly outperforms the previous arts.
• TUNIT is insensitive to the hyperparameter (i.e. the num-ber of clusters) and serves as a strong baseline for the semi-supervised setting– TUNIT outperforms the current state-of-the-art semi-supervised image translation model. 2.