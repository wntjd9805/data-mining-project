Abstract
Existing GAN inversion methods are stuck in a para-dox that the inverted codes can either achieve high-ﬁdelity reconstruction, or retain the editing capability. Having only one of them clearly cannot realize real image edit-ing. In this paper, we resolve this paradox by introducing consecutive images (e.g., video frames or the same person with different poses) into the inversion process. The ratio-nale behind our solution is that the continuity of consecu-tive images leads to inherent editable directions. This in-born property is used for two unique purposes: 1) regu-larizing the joint inversion process, such that each of the inverted codes is semantically accessible from one of the other and fastened in an editable domain; 2) enforcing inter-image coherence, such that the ﬁdelity of each in-verted code can be maximized with the complement of other images. Extensive experiments demonstrate that our al-ternative signiﬁcantly outperforms state-of-the-art methods in terms of reconstruction ﬁdelity and editability on both the real image dataset and synthesis dataset. Furthermore,
∗Corresponding authors ({xuemx,hesfe}@scut.edu.cn). our method provides the ﬁrst support of video-based GAN inversion and an interesting application of unsupervised semantic transfer from consecutive images. Source code can be found at: https://github.com/cnnlstm/
InvertingGANs_with_ConsecutiveImgs. 1.

Introduction
Generative Adversarial Networks (GANs) [5, 9, 10] has demonstrated versatile image editing capability, es-pecially by discovering the spontaneously learned inter-pretable directions that can manipulate corresponding im-age attributes [17, 8, 19, 4, 22]. Concretely, given a random latent code w, image editing can be achieved by pushing the latent vector along a speciﬁc semantic direction (e.g., age, gender):
I (cid:48) = G(w + α ×
→ n), (1) where I (cid:48) is the edited image, G is the generator, α is a scal-→ n is the interpretable direction. ing factor, and
As a consequence, recent attempts [1, 2, 18, 24] aim to migrate this power to real image editing by inverting an im-age to the latent code w. There are two keys for this task,
i) whether the inverted code can faithfully reconstruct the original input, and, ii) whether the pre-acquired semantic directions can be successfully applied. However, existing methods seem to stuck in a paradox, as achieving one end will inevitably sacriﬁce the other. As shown in Fig. 1, I2S,
I2S++, and pSp [1, 2, 18] concentrate only on obtaining faithful reconstruction, but the inverted codes show lim-ited editability. In contrast, latent codes obtained from In-domain inversion [24] (Fig. 1e) are regularized in the se-mantically meaningful domain at the expense of ﬁdelity. We argue that balancing these two factors solely based on a sin-gle image is extremely challenging, as there is no indicator to shed light on the editable domain in the latent space, pre-venting the optimization from obtaining a perfect balance between two factors.
In this paper, we resolve the above problem by introduc-ing consecutive images, which can be either a video seg-ment or the same person with different poses, to form a joint optimization process. The rational behind our alter-native solution is that the continuity brought by consecutive images can be used as an indicator to constrain the editabil-ity. In particular, to ensure each of the inverted latent codes is editable, we jointly optimize multiple latent codes by en-forcing each of them is semantically accessible from one of the other code with a simple linear combination. In ad-dition, we further explore the sequential continuity for ﬁ-delity, by injecting multi-source supervision that common regions of the reconstructed images should be consistent in all the consecutive images. We establish dense correspon-dences between input images, and then apply the obtained correspondences to warp each of the reconstructions to the neighbors for a consistent and coherence measurement.
To evaluate the proposed method, we construct a real video-based dataset RAVDESS-12, and another consecutive images dataset synthesized by manipulating attributes from the generated images of StyleGAN [10]. Extensive experi-ments demonstrate the superior performance of our solution over existing methods in terms of editability and reconstruc-tion ﬁdelity. Furthermore, our method is capable to perform various applications, e.g., video-based GAN inversion, un-supervised semantic transfer, and image morphing.
In summary, our contributions are three-fold:
• We propose an alternative GAN inversion method for consecutive images, and delve deep into the continuity of consecutive images for GAN inversion.
• We tailor two novel constraints, one is the mutually ac-cessible constraint that formulates consecutive images inversion as a linear combination process in the latent space to ensure editability, and the inversion consis-tency constraint that works in the RGB space to guar-antee reconstruction ﬁdelity, by measuring reconstruc-tion consistency across images.
• We demonstrate optimal performances in terms of ed-itability and reconstruction ﬁdelity, and we support various new applications like video-based GAN inver-sion and unsupervised semantic transfer. 2.