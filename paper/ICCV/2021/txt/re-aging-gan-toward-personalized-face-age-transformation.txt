Abstract 1.

Introduction
Face age transformation aims to synthesize past or fu-ture face images by reflecting the age factor on given faces.
Ideally, this task should synthesize natural-looking faces across various age groups while maintaining identity. How-ever, most of the existing work has focused on only one of these or is difficult to train while unnatural artifacts still ap-pear. In this work, we propose Re-Aging GAN (RAGAN), a novel single framework considering all the critical factors in age transformation. Our framework achieves state-of-the-art personalized face age transformation by compelling the input identity to perform the self-guidance of the gener-ation process. Specifically, RAGAN can learn the personal-ized age features by using high-order interactions between given identity and target age. Learned personalized age fea-tures are identity information that is recalibrated according to the target age. Hence, such features encompass identity and target age information that provides important clues on how an input identity should be at a certain age. Exper-imental result shows the lowest FID and KID scores and the highest age recognition accuracy compared to previous methods. The proposed method also demonstrates the vi-sual superiority with fewer artifacts, identity preservation, and natural transformation across various age groups.
A face age transformation task is dedicated to learn-ing age progression or regression of a given face accord-ing to the target age. Here, target age implies an explicit conditioning factor that guides the transformation to pro-duce facial images with a certain age. That is, we can set any target age for an input face image, and expect to have an output face depicting the target age characteristics,
Ideally, age transformation mod-as shown in Figure 1. els should satisfy the following properties. First, a model should take into account the identity of the person while progressing/regressing the face age and sustain it mostly un-altered, i.e., identity preservation. Second, a model should be able to generate natural-looking faces corresponding to the target age across various age groups.
In this regard, a number of works on face age transfor-mation have been introduced [1, 48, 46, 39, 12, 42, 33, 47, 24, 45]. These methods, on the basis of powerful genera-tive adversarial networks (GANs) [10, 30], train deep neural networks to perform a robust age transformation of the in-put face. Aside from this, several methods [43, 46] adopted additional mechanisms (i.e., networks and constraints) for identity preservation to ensure that face identity is unaltered during the age transformation process. However, even with
improved approaches, existing methods tend to generate im-ages with visible artifacts and/or unnatural-looking faces which surely lowers down the image quality and its percep-tion. Another important aspect that should be considered is a wide-range age transformation, specifically, an age re-gression process for rejuvenating input face. Most existing works scarcely address this process and more focus on pro-gression. Although a few methods can operate on face age regression and provide good performance, their results still suffer from artifacts near and/or on face regions and contain no background due to the tight face cropping. Overall, even with such considerable efforts, few models cover all critical factors such as identity-preserved age transformation across a wide range of age groups.
In this paper, we consider all these important factors for face age transformation and propose a simple yet effective framework called Re-Aging GAN (RAGAN). Unlike recent methods, we endeavor to design RAGAN in a single frame-work for making model training easier and more scalable.
Our generator comprises three sub-networks, namely en-coder, age modulator, and decoder, each of which is de-signed with a specific role for face age transformation. As it is necessary to meet the identity preservation property as well as background for generating accurate and visually plausible transformed images, we make an encoder to de-tach the face region from the background such that it solely focuses on extracting identity features. We are aware that identity might be disrupted in the learning process without explicit guidance. Thus, we consider modulating identity features in agreement with the given target age by means of an age modulator plugged in-between encoder and decoder.
Straightforward incorporation of this network aims to pro-vide personalized age-aware features and so self-guide the decoding process. By leveraging such features, the decoder learns to smoothly add target age characteristics on iden-tity features in an optimal manner. The decoder further im-proves the visual perception of images by mapping back the background. As the whole process focuses on the face re-gion, it allows the generator to pay more attention to trans-forming the facial region and helps to avoid affecting the background (i.e., color change, artifacts). For the discrim-inator part, we follow the advanced approaches [7, 29, 26] consisting of conventional age-related loss.
The main contributions of this work are as follows:
• We introduce a personalized self-guidance scheme that enables transforming the input face across various tar-get age groups while preserving identity.
• We successfully perform face age transformation us-ing only a single generative and discriminative model trained effectively in an unpaired manner.
• We qualitatively and quantitatively demonstrate the superiority of RAGAN over state-of-the-art methods through extensive experiments and evaluations. 2.