Abstract
Recently RGB-D sensors have become very popular in the area of Simultaneous Localisation and Mapping (SLAM).
The RGB-D SLAM approach relies heavily on the accuracy of the input depth map. However, refraction and reﬂection of transparent objects will result in false depth input of
RGB-D cameras, which makes the traditional RGB-D
SLAM algorithm unable to work correctly in the presence of transparent objects. In this paper, we propose a novel
SLAM approach called transfusion that allows transparent object existence and recovery in the video input. Our method is composed of two parts. Transparent Objects
Iterative Closest Points (TC-ICP)is ﬁrst used to
Cut recover camera pose, detecting and removing transparent objects from input to reduce the trajectory errors. Then
Transparent Objects Reconstruction (TO-Reconstruction) is used to reconstruct the transparent objects and opaque objects separately. The opaque objects are reconstructed with the traditional method, and the transparent objects are reconstructed with the visual hull-based method. To evaluate our algorithm, we construct a new RGB-D SLAM database containing 25 video sequences. Each sequence has at least one transparent object. Experiments show that our approach can work adequately in scenes contain transparent objects while the existing approach can not handle them. Our approach signiﬁcantly improves the accuracy of the camera trajectory and the quality of environment reconstruction. 1.

Introduction
Nowadays, the interests in visual SLAM has been sig-niﬁcantly increased due to its variety of usages on many other computer vision applications, such as augmented real-ity, autonomous driving car, and robotics navigation. There are rich types of sensors utilized for SLAM algorithm, such as lidar, monocular camera, RGB-D camera, etc [7, 3, 2].
Among them, the RGB-D camera has been widely consid-†Bo Ren is the corresponding author
Figure 1. Reconstruction result of two scene with our method and Elasticfusion[31]. Due to the transparent object’s charac-teristic, the passed RGB-D slam method can not reconstruct the scene contains transparent objects properly. The ﬁrst column is the reconstruction result of Elasticfusion without transparent objects; in the second column is the reconstruction result of Elasticfusion with transparent objects; in the third column is the reconstruction result of our algorithm with transparent objects. ered for the visual SLAM since it can provide a rich source of 3D information at a relatively low cost.
There is a lot of excellent SLAM methods that take
RGB-D as perception modules [31, 24, 5, 16]. They can get more reﬁned reconstruction results than the monocular methods and can eliminate the scale drifting problem. How-ever, they are all developed in an environment where there are all opaque objects, and as shown in Fig. 1, they cannot properly function when the environment contains transpar-ent objects. But, transparent objects made of glass, such as bottles, windows, are ubiquitous around us, so it is es-sential to study the RGB-D SLAM algorithms that contain transparent objects in the environment model.
RGB-D cameras usually equip infrared light emission and receivers to measure the depth, such as Microsoft’s
Kinect and Intel’s RealSense. Unlike opaque objects, trans-parent materials do not satisfy the classic geometric light path assumptions of stereo vision algorithms. When in-Figure 2. Affect of transparent object to the depth map. (a) When infrared rays are emitted to transparent objects, both reﬂection and refraction occur on their surface.(b) and c) are the RGB image and depth map of the scenes. (d) The 2.5D view by combining the depth map with RGB image. The area in the red circle is where the transparent object locates. The yellow circle is the area affect by the transparent.
The green circle is the opaque object frared rays (IR) are emitted to transparent objects, both re-ﬂection and refraction occur on their surface. As shown in
Fig. 2, some rays reﬂect on the surface of a transparent ob-ject or reﬂect on the surface of the object behind the trans-parent object. Thus when RGB-D cameras are used to ac-quire the environment’s depth, there is a high probability of getting erroneous results due to these objects. The transpar-ent objects often show up as noisy or distorted surfaces in the depth inputs. Meanwhile, the object behind transparent materials will be distorted due to their occlusion, making it challenging for RGB-D cameras to produce accurate depth estimates in the area occluded by transparent objects.
On the other hand, the RGB-D SLAM approach relies heavily on the accuracy of the environmental depth ob-tained, which is in nature of the Iterative Closest Points (ICP) algorithm. The RGB-D SLAM systems often lever-age the ICP algorithm in the tracking stage. ICP algorithm takes the depth map as input then estimates camera pose through 3D points registering. Inaccurate depth will lead the ICP algorithm to get the wrong camera pose.
This leads to another challenge of recovering the con-crete shape of transparent objects in the reconstruction phase because the RGB-D camera cannot get its correct depths. Moreover, the reconstruction of objects behind them will also be affected because transparent objects also distort their depth. As illustrated in Fig. 2, wrong depth destroyed the system’s reconstruction results.
In this paper, we propose a novel RGB-D SLAM ap-proach that can handle scenes include transparent objects.
Our method can simultaneously reduce tracking errors and recover the whole scene’s correct shape.
Firstly, Transparent Objects Cut Iterative Closest Points (TC-ICP) algorithm is used to estimate the camera pose.
TC-ICP can detect transparent objects’ location and remove them from the input, which will reduce the depth error caused by transparent objects. Then Transparent Objects
Reconstruction (TO-Reconstruction) algorithm is used to recover the whole scene’s 3D model. Transparent object re-construction only takes advantage of the RGB image, mask, and camera pose information, which can be readily inte-grated into the traditional RGB-D methods.
Since our main task is making the SLAM algorithm work adequately in scenes containing transparent objects, and there is no existing database dedicated to this task. To eval-uate our algorithm, we construct a new database with 25 video sequences. In every sequence, there is at least one transparent object.
In summary, the main contributions of our paper are:
• We propose a novel RGB-D SLAM approach called
Transfusion, which shows excellent performance in camera pose estimation and scene reconstruction in en-vironments containing transparent objects.
• We construct a new RGB-D database Trans-SLAM for the research of SLAM algorithms in the environment that contains transparent objects. 2.