Abstract
Semi-supervised learning (SSL) algorithms have at-tracted much attentions in medical image segmentation by leveraging unlabeled data, which challenge in acquir-ing massive pixel-wise annotated samples. However, most of the existing SSLs neglected the geometric shape con-straint in object, leading to unsatisfactory boundary and non-smooth of object.
In this paper, we propose a novel boundary-aware semi-supervised medical image segmenta-tion network, named Graph-BAS3Net, which incorporates the boundary information and learns duality constraints between semantics and geometrics in the graph domain.
Speciﬁcally, the proposed method consists of two compo-nents: a multi-task learning framework BAS3Net and a graph-based cross-task module BGCM. The BAS3Net im-proves the existing GAN-based SSL by adding a bound-ary detection task, which encodes richer features of object shape and surface. Moreover, the BGCM further explores the co-occurrence relations between the semantics segmen-tation and boundary detection task, so that the network learns stronger semantic and geometric correspondences from both labeled and unlabeled data. Experimental results on the LiTS dataset and COVID-19 dataset conﬁrm that our proposed Graph-BAS3Net outperforms the state-of-the-art methods in semi-supervised segmentation task. 1.

Introduction
Accurate medical image segmentation is an essential prerequisite for many clinical applications [19]. Recently, a variety of convolutional neural networks (CNNs) have been developed for segmentation tasks. Though these methods achieved satisfactory results, they needed massive pixel-wise annotated samples and to be trained in fully supervi-sion. In the medical ﬁeld, however, sufﬁcient labeled data
*Corresponding Authors: Lanfen Lin (llf@zju.edu.cn), Jianying Zhou (zjyhz@zju.edu.cn), Yen-Wei Chen (chen@is.ritsumei.ac.jp)
Figure 1. (a) shows the boundary results of four methods on LiTS dataset with 10% labeled data, where cyan edges are ground truth boundaries; while red edges are predictions. (b) shows the num-ber of error pixels (horizontal axis) vs. their Euclidean distances (vertical axis) to the boundaries on four methods. We can see that pixels with larger distance tend to be well-classiﬁed, while pixels with smaller distance (boundary pixels) have larger errors. is unavailable as the manual annotation is costly and time-consuming. To address this issue, semi-supervised learning (SSL) has been introduced, which uses both labeled data and arbitrary amounts of unlabeled data in training.
Recent efforts in SSL have been focused on incorpo-rating unlabeled data into training, which can be cate-gorized into following groups: self-training [2, 5], co-training [22,29,35], GAN-based methods [10,14,21,33,34] and self-ensembling (Π model [12, 16] and Mean-Teacher model [7, 25, 31]). For example, Chen et al. [5] proposed a self-training-based SSL that alternately updated the seg-mentation results of unlabeled data; while Ouali et al. [22] achieved co-training by exploiting cross-consistency, which learned the generalized feature from the unlabeled data.
Hung et al. [10] designed a GAN-based SSL that enforced the segmentation of unlabeled data to be similar to the la-beled ones. Tarvainen et al. [25] proposed a Mean-Teacher model to guide the student network learning. However, they often ignored the geometric information and/or the inher-ent semantic and geometric correspondences, which lead to unsatisfactory boundary and non-smooth of object since the ambiguity of structure boundary and heterogeneous tex-ture (see Fig.1(a)). As shown in Fig.1(b), the number of error pixels signiﬁcantly decrease with larger distances to the boundary. In other words, the boundary accuracy is cru-cial to the ﬁnal semantic segmentation, yet its importance is often overlooked in previous methods.
Therefore, in this work, we propose a novel Graph-based boundary-aware semi-supervised segmentation net-work (Graph-BAS3Net) to address the aforementioned lim-itations. Our main idea is to incorporate the boundary rep-resentation in the network, and learn the duality constraints between semantics and boundaries in the graph domain.
The Graph-BAS3Net comprises of two components: (i) a
Boundary-Aware Semi-Supervised Segmentation Network (BAS3Net) that mitigates the blurry boundary problem by incorporating a boundary detection task into the GAN-(ii) a Bilateral Graph based segmentation framework.
Convolution Module (BGCM) that models the duality con-straints between tasks and captures long-range dependen-cies over non-local regions. The design rationale of the above two components is elaborated as below.
Firstly, considering that the boundary surrounded the mask encodes richer features of object shape and surface, our generator of BAS3Net jointly predicts semantic seg-mentation and object boundary with a shared encoder. The shared encoder encourages the network to extract common features for different tasks, thus making the network more compact. To utilize the unlabeled data and learn more de-tailed edge information, we then introduce a discrimina-tor to distinguish the predicted semantic segmentation map and boundary detection results (‘fake’) from ground truth labels (‘real’) for semi-supervised learning. In this multi-task learning way, the semantic segmentation provides the smoothness and continuity constraints; while the boundary detection enforces a global shape and geometric constraints.
Secondly, as there exists duality constraints between two tasks, it is obvious and remarkable that semantic seg-mentation and boundary detection can beneﬁt each other by mutual interaction and promotion to boost the over-all performance of semi-supervised segmentation. Based on this, we design the BGCM to explore co-occurrence relations and diffuse information between the semantics segmentation and boundary detection task. To establish the relationships effectively, we utilize graph convolution
[6, 8, 11, 13, 15, 17, 26, 28, 32] to mine the intra-task and inter-task relations within and between two tasks. Specif-ically, the intra-task reasoning can capture long-range de-pendencies over non-local regions and reﬁne the visual fea-tures in separate tasks; while the inter-task reasoning can model the similar latent representations between tasks and enable information propagation in a bidirectional way. In this way, our Graph-BAS3Net, that consists of the backbone
BAS3Net and the cross-task module BGCM, can be aware of the reciprocal relations between semantics segmentation and boundary detection and exhibits superior performance.
The major contributions of this work are four-fold: (i)
We propose a Graph-BAS3Net to enforce semantic and ge-ometric constraints in semi-supervised medical image seg-mentation.
It combines a multi-task learning framework
BAS3Net and a graph-based cross-task module BGCM rea-soning between tasks. (ii) We devise a BAS3Net that jointly predict the semantic segmentation and object boundary, which improves the segmentation performance of the gen-erator and further introduces boundary information to the discriminator. (iii) We propose a BGCM to enforce dual-ity constraints between semantics and boundaries by using bilateral graph convolution, which globally mines the intra-task and inter-task relations.(iv) We conduct extensive ex-periments on a typical liver datasets and a more challenging
COVID-19 dataset, where the proposed Graph-BAS3Net outperforms the state-of-the-art methods. 2.