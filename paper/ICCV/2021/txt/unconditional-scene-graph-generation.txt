Abstract
Despite recent advancements in single-domain or single-object image generation, it is still challenging to gener-ate complex scenes containing diverse, multiple objects and their interactions. Scene graphs, composed of nodes as ob-jects and directed-edges as relationships among objects, of-fer an alternative representation of a scene that is more se-mantically grounded than images. We hypothesize that a generative model for scene graphs might be able to learn the underlying semantic structure of real-world scenes more effectively than images, and hence, generate realistic novel scenes in the form of scene graphs. In this work, we ex-plore a new task for the unconditional generation of seman-tic scene graphs. We develop a deep auto-regressive model called SceneGraphGen which can directly learn the proba-bility distribution over labelled and directed graphs using a hierarchical recurrent architecture. The model takes a seed object as input and generates a scene graph in a sequence of steps, each step generating an object node, followed by a sequence of relationship edges connecting to the previous nodes. We show that the scene graphs generated by Scene-GraphGen are diverse and follow the semantic patterns of real-world scenes. Additionally, we demonstrate the appli-cation of the generated graphs in image synthesis, anomaly detection and scene graph completion. 1.

Introduction
Scene graphs encompass a representation that describes a scene, where nodes are categorical object instances and the edges describe categorical relationships between them.
This representation allows for an extended high-level un-derstanding of the scenes, which goes beyond object-level reasoning. The computer vision community has explored various approaches for scene graph generation from im-ages [38, 27] as well as tasks in which this representation has proven to be suitable, such as image retrieval [18] and
*The first two authors contributed equally to this work https://SceneGraphGen.github.io/
Figure 1. Method overview. a) SceneGraphGen generates scene graphs unconditionally from a randomly sampled seed object. b)
Applications in Left: translation of a generated scene graph to an image, using an off-the-shelf graph-to-image network Right: de-tection of out-of-distribution samples
VQA [11]. A scene graph allows for modular, specified, and high-level semantic control on the image components, which makes it a good representation for semantic-driven image generation [17] and manipulation [7].
A less explored field has been unconditional generation of scene graphs, i.e. generating a scene graph without any input image, but instead, from a random input. Such scene graph modelling can aid learning patterns from real scenes, such as object co-occurrence, relative placements and inter-actions. In this paper, scene graph generation is explored under the light of generative models, with the aim to gen-erate novel and realistic instances of scene graphs uncon-ditionally. Recent work explored generation of relational graphs [35] or probabilistic grammar [19], designed for a particular domain. To the best of our knowledge, we are the first to investigate the use of a generative model for generating semantic, language-based scene graphs [18, 21].
As scene graphs describe scenes, it is possible to translate the generated graph to another domain, using state-of-the-art models specialized, for instance, in the graph-to-image task [17].
In the context of unconditional image genera-tion, recent works demonstrate impressive results mostly in object-centric images that contain one main subject, or uni-modal distributions, such as datasets of faces or cars.
On the other hand, complex and diverse scenes which con-tain multiple objects are more difficult to capture by these models. We show in our experiments that modelling un-conditional image scene generation through scene graphs instead leads to more distinguishable object instances, as it enables understanding of complex and often abstract se-mantic concepts such as objects, their interactions, and at-tributes. Additionally, such a generative model can detect out-of-distribution scene graphs and complete partial scene graphs.
Recently, deep generative models have been proposed for graph data [41, 12, 9, 30, 3], which aim to synthesize realistic graphs of a certain domain while capturing graph patterns, such as degree distribution and clustering. How-ever, each model comes with caveats making it unsuitable for certain applications. The size of scene graphs often varies significantly, the object and relationship categories are inherently unbalanced, and the edges are directed. For this purpose, we develop a specialized model called Scene-GraphGen (Figure 1). The overall auto-regressive structure is inspired from GraphRNN [41], as it accommodates vary-ing graph sizes, unlike [9, 30, 4]. Specifically, the model is adapted to consume categories for nodes and edges, as well as to support the direction of the edges. In this auto-regressive formulation, the scene graphs are represented as a sequence of sequences. The history of the sequence is car-ried in a hidden state using a Gated Recurrent Unit (GRU)
[5], which is used to generate categorical distribution over the nodes and edges at each step, from which the node and edge categories can be sampled. The nodes are generated using a multi-layer perceptron (MLP) and the edges are gen-erated sequentially using a GRU.
Since unconditional scene graph generation is a new task, metrics to evaluate the quality of the generated graphs have not been proposed yet. Thus, following [41] we lever-age a Maximum Mean Discrepancy (MMD) metric, adapted with a random-walk graph kernel and a node kernel, which are appropriate for the scene graph structure. We verify the validity of these kernels using sets of corrupted datasets.
Our contributions can be summarized as follows:
• We introduce SceneGraphGen to tackle the unexplored task of unconditional semantic scene graph generation.
We adopt a graph auto-regressive model to enable pro-cessing the scene graphs structure.
• We demonstrate the use of the learned scene graph model in three applications, namely image generation, anomaly detection, and scene graph completion.
• We propose and verify an MMD metric to evaluate the generated scene graphs, which operates on the node and graph level.
We evaluate our model on Visual Genome [21] and show that it can generate semantically plausible scene graphs. We show how these scene graphs can transfer to novel images, using state-of-the-art scene graph to image models [17].
Additionally, we show that the model can be used to detect unusual scene graphs and extend incomplete scene graphs. 2.