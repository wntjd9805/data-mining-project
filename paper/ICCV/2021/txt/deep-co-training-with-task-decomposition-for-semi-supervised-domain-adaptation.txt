Abstract
SSDA
Semi-supervised domain adaptation (SSDA) aims to adapt models trained from a labeled source domain to a different but related target domain, from which unlabeled data and a small set of labeled data are provided. Current methods that treat source and target supervision without distinction overlook their inherent discrepancy, resulting in a source-dominated model that has not effectively use the target su-pervision. In this paper, we argue that the labeled target data needs to be distinguished for effective SSDA, and pro-pose to explicitly decompose the SSDA task into two sub-tasks: a semi-supervised learning (SSL) task in the target domain and an unsupervised domain adaptation (UDA) task across domains. By doing so, the two sub-tasks can bet-ter leverage the corresponding supervision and thus yield very different classiﬁers. To integrate the strengths of the two classiﬁers, we apply the well established co-training framework, in which the two classiﬁers exchange their high conﬁdent predictions to iteratively “teach each other” so that both classiﬁers can excel in the target domain. We call our approach Deep Co-training with Task decomposition (DECOTA). DECOTA requires no adversarial training and is easy to implement. Moreover, DECOTA is well founded on the theoretical condition of when co-training would suc-ceed. As a result, DECOTA achieves state-of-the-art results on several SSDA datasets, outperforming the prior art by a notable 4% margin on DomainNet. Code is available at https://github.com/LoyoYang/DeCoTa. 1.

Introduction
Domain adaptation (DA) aims to adapt machine learned models from a source domain to a related but different target domain [4, 14, 53, 13]. DA is particularly important in set-tings where labeled target data is hard to obtain, but labeled source data is plentiful [63, 41, 21], e.g., adaptation from
SSL
UDA
Co-training labeled source labeled target classifier unlabeled target pseudo-labeled target
Figure 1: Deep Co-training with Task decomposition (DECOTA).
We decompose semi-supervised domain adaptation (SSDA) into two sub-tasks: semi-supervised learning (SSL) in the target domain, and unsupervised DA (UDA) across domains. The two sub-tasks offer different pseudo-label conﬁdences to the unlabeled data (light blue & light red circles), which we leverage via co-training: ex-changing their high conﬁdent predictions to teach each other. synthetic to real images [21, 55, 48, 47, 56] and adaptation to a new or rare environment [10, 69, 54, 9]. Most of the existing works focus on the unsupervised domain adaptation (UDA) setting, in which the target domain is completely unlabeled. Several recent works, however, show that adding merely a tiny amount of target labeled data (e.g., just one labeled image per class) can notably boost the performance
[51, 26, 45, 1, 31, 30, 12, 74], suggesting that this setting may be more promising for domain adaptation to succeed.
In this paper, we thus focus on the latter setting, which is referred to as semi-supervised domain adaptation (SSDA).
Despite the seemingly nuanced difference between the two settings, methods that are effective for SSDA and UDA can vary substantially. For instance, [51] showed that di-rectly combining the labeled source and labeled target data and then applying popular UDA algorithms like domain adversarial learning [13] or entropy minimization [16] can hardly improve the performance. In other words, the labeled target data have not been effectively used. Existing meth-ods [51, 45, 26] therefore propose additional objectives to strengthen the inﬂuence of labeled target data in SSDA.
Intrigued by these ﬁndings, we investigate the charac-teristics of SSDA further and emphasize two fundamental challenges. First, the amount of labeled source data is much larger than that of labeled target data. Second, the two data are inherently different in their distributions. A single classi-ﬁer learned together with both sources of supervision is thus easily dominated by the labeled source data and is unable to take advantage of the additional labeled target data.
To resolve this issue, we propose to explicitly decompose the two sources of supervision and learn two distinct clas-siﬁers whose goals are however shared: to classify well on the unlabeled target data. To this end, we pair the labeled source data and the unlabeled target data to learn one classi-ﬁer, which is essentially a UDA task. For the other classiﬁer, we pair the labeled and unlabeled target data, which is es-sentially a semi-supervised learning (SSL) task. That is, we explicitly decompose SSDA into two well-studied tasks.
For each sub-task, one may apply any existing algorithms independently. In this paper, we however investigate the idea of learning the two classiﬁers jointly for two compelling reasons. First, the two tasks share the same goal and same unlabeled data, meaning that they are correlated. Second, learning with distinct labeled data implies that the two classi-ﬁers will converge differently in what types of mistakes they make and on which samples they are conﬁdent and correct, meaning that they are complementary to each other.
We therefore propose to learn the two classiﬁers jointly via co-training [6, 2, 8]1, which is arguably one of the most established algorithm for learning with multi views: in our case, two correlating and complementary tasks. The ap-proach is straightforward: train a separate classiﬁer on each task using its labeled data, and use them to create pseudo-labels for the unlabeled data. As the two classiﬁers are trained with distinct supervision, they will yield different predictions. In particular, there will be samples that only one classiﬁer is conﬁdent about (and more likely to be correct).
By labeling these samples with the conﬁdent classiﬁer’s pre-dictions and adding them to the training set of the other classiﬁer to re-train on, the two classiﬁers are essentially
“teaching each other” to improve. To this end, we employ a simple pseudo-labeling-based algorithm with deep learning, 1We note that, co-training [6] and co-teaching [17] share similar con-cepts but are fundamentally different. See 2 for a discussion. similar to [5], to train each classiﬁer. Pseudo-labeling-based algorithms have been shown powerful for both the UDA and
SSL tasks [70, 27]. In other words, we can apply the same algorithm for both sub-tasks, greatly simplifying our overall framework which we name DECOTA: Deep Co-training with Task Decomposition (Fig. 1 gives an illustration).
We evaluate DECOTA on two benchmark datasets for
SSDA: DomainNet [41] and Ofﬁce-home [66]. While very simple to implement and without any adversarial training
[51, 45], DECOTA signiﬁcantly outperforms the state-of-the-art results [45, 26] on DomainNet by over 4% and is on a par with them on Ofﬁce-home. We attribute this to the empirical evidence that our task decomposition ﬁts the theoretical condition of relaxed ✏-expandability [8, 2], which is sufﬁcient for co-training to succeed. Another strength of
DECOTA is that it requires no extra learning process like feature decomposition to create views from data [8, 44, 7].
To the best of our knowledge, our paper is the ﬁrst to enable deep learning with co-training on SSDA.
The contributions of this work are as follow. (1) We explicitly decompose the two very different sources of su-pervision, labeled source and labeled target data, in SSDA. (2) We present DECOTA, a simple deep learning based co-training approach for SSDA to jointly learn two classiﬁers, one for each supervision. (3) we provide intermediate results and insights that illustrate why DECOTA works. Speciﬁcally, we show that DECOTA satisﬁes the ✏-expandability require-ment [2] of co-training. (4) Lastly, we support this work with strong empirical results that outperform state-of-the-art. 2.