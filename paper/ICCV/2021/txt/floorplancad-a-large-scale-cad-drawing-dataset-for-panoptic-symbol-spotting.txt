Abstract
Access to large and diverse computer-aided design (CAD) drawings is critical for developing symbol spot-ting algorithms.
In this paper, we present FloorPlan-CAD, a large-scale real-world CAD drawing dataset con-taining over 10,000 floor plans, ranging from residential to commercial buildings. CAD drawings in the dataset are all represented as vector graphics, which enable us to provide line-grained annotations of 30 object cate-gories. Equipped by such annotations, we introduce the task of panoptic symbol spotting, which requires to spot not only instances of countable things, but also the se-mantic of uncountable stuff. Aiming to solve this task, we propose a novel method by combining Graph Convo-lutional Networks (GCNs) with Convolutional Neural Net-works (CNNs), which captures both non-Euclidean and Eu-clidean features and can be trained end-to-end. The pro-posed CNN-GCN method achieved state-of-the-art (SOTA) performance on the task of semantic symbol spotting, and help us build a baseline network for the panoptic sym-bol spotting task. Our contributions are three-fold: 1) to the best of our knowledge, the presented CAD draw-ing dataset is the first of its kind; 2) the panoptic sym-bol spotting task considers the spotting of both thing in-stances and stuff semantic as one recognition problem; and 3) we presented a baseline solution to the panoptic symbol spotting task based on a novel CNN-GCN method, which achieved SOTA performance on semantic symbol spotting.
We believe that these contributions will boost research in related areas. The dataset and code is publicly available at https://floorplancad.github.io/. 1.

Introduction
The perception of 2D computer-aided design (CAD) drawings plays a crucial role for creating 3D prototypes, also known as “digital twins”, see Figure 1, in architecture, engineering and construction (AEC) industries. A CAD drawing typically conveys accurate geometric and rich se-(a) Floor plan (b) Facade and 3D model
Figure 1: The rich semantic, accurate location and detailed 3D shape (right top) of windows (light blue), blind windows (blue), railings (orange) and walls (dark red) are faithfully encoded in the CAD drawings of a floor plan (left) and its south facade (right bottom).
Figure 2: Various sink symbols from our FloorPlanCAD dataset. The style and appearance of a symbol depend on the producer of the drawing. mantic information of a cross section of a 3D design. By integrating information from a group of CAD drawings, the according 3D model can be precisely reconstructed. For ex-ample, 3D buildings can be faithfully encoded by a bunch of 2D floor plans, which are detailed CAD drawings com-pose of line segments, arcs, curves, and texts, see Figure 1.
Automatic perception of CAD drawings will lead to effi-cient 3D modeling approaches, saving vast amount of labor work. That is especially true for architectures, which usu-ally contain massive components and might cost months for creating detailed 3D models.
Symbol spotting refers to the recognition of graphic symbols embedded in the context of large digital draw-ings [31]. It is typically carried out as query-by-example
(a) A raw floor plan drawing. (b) The drawing with instance and semantic annotations.
Figure 3: A snapshot of our FloorPlanCAD dataset. (a) Texts are removed to protect privacy and intellectual property. (b)
The line-grained annotations is illustrated by colors. approaches [28, 27, 35], where candidate regions that might contain the given query symbol are obtained. These ap-proaches are impractical in real-world scenarios, because symbols representing the same object might vary fiercely, see Figure 2. To cope with the variability of symbols, a re-cent work [32] attempted learning-based approach on real-world floor plan drawings, but they treat CAD drawings as pixel images, losing the accuracy of vector graphics and leading to possibly inaccurate annotations and predictions.
Traditional symbol spotting approaches focus on in-stance detection, therefore cannot deal with semantic of un-countable stuff. For example, these methods cannot detect the wall in CAD drawings, which is usually represented by a group of parallel lines with large span, see Figure 3. Fol-lowing ideas in [19], we consider the instance spotting of countable things and the semantic detection of uncountable stuff as one visual recognition task, which is called panoptic symbol spotting.
In practice, CAD drawings play the role of universal language among practitioners in AEC industries, includ-ing designers, engineers, constructors, who share a com-mon knowledge set. This observation inspires us to adopt learning methods for recognition tasks on CAD drawings, which demands comprehensive annotated data for training and testing networks.
We build a large-scale dataset of over 10,000 floor plans in the form of vector graphics. Floor plans are collected from real-world architecture projects from various compa-nies and institutions. To overcome the restriction of intel-lectual property, we crop only a small portion from each large floor plan, and remove sensitive texts that might con-vey confidential information. At the end, floor plan blocks in the dataset only contain geometric and structural infor-mation, see Figure 3a. We select 30 object categories of our interest, and provide line-grained annotations, see Fig-ure 3b.
The property of vector graphics enable us to apply graph convolutional networks (GCNs), which is computational ef-ficient due to its sparsity, and is good at extracting non-Euclidean features via topology connections. For each floor plan, we build a graph, whose nodes are graphic entities, e.g. straight segment, arc, and edges are created according to their adjacency.
In our experiments, we found that Euclidean features captures by Convolutional Neural Networks (CNNs) can improve the performance. Therefore we propose a novel network combining GCNs and CNNs, which achieves state-of-the-art performance on the semantic symbol spotting task, and leads us to a baseline network for the panoptic symbol spotting task.
The goal of our research is to push the development of perception on the CAD drawing by providing large-scale annotated dataset and a baseline algorithm. Our main con-tributions are:
• We present a large-scale real-world dataset of over 10,000 CAD drawings with line-grained annotations, residential covering various types of buildings, e.g. towers, schools, hospitals, shopping malls and office buildings. To the best of our knowledge, it is the first of its kind.
• We introduce the task of panoptic symbol spotting, which is a generalization of the traditional symbol spotting problem, considering the instance spotting of countable things and the semantic labeling of uncount-able stuff as one recognition task. A panoptic metric is provided for evaluating the prediction quality of vari-ous methods.
• We propose a CNN-GCN method, which achieved state-of-the-art performance on the semantic symbol spotting task, and help us build a unified baseline net-work for the panoptic symbol spotting task.
2.