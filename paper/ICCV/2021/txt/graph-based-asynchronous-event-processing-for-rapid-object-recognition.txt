Abstract
Different from traditional video cameras, event cam-eras capture asynchronous events stream in which each event encodes pixel location, trigger time, and the polar-ity of the brightness changes. In this paper, we introduce a novel graph-based framework for event cameras, namely
SlideGCN. Unlike some recent graph-based methods that use groups of events as input, our approach can efﬁciently process data event-by-event, unlock the low latency nature of events data while still maintaining the graph’s structure internally. For fast graph construction, we develop a ra-dius search algorithm, which better exploits the partial reg-ular structure of event cloud against k-d tree based generic methods. Experiments show that our method reduces the computational complexity up to 100 times with respect to current graph-based methods while keeping state-of-the-art performance on object recognition. Moreover, we verify the superiority of event-wise processing with our method. When the state becomes stable, we can give a prediction with high conﬁdence, thus making an early recognition. 1.

Introduction
Rapid object recognition is essential for a variety of ap-plications, such as autonomous driving and ﬂying drones.
For instance, when an autonomous vehicle is driving at high speed, the low latency is desirable to identify obstacles or moving objects once they appear. Due to its low frame rate, the standard video camera is not ideal for this task. Fast-speed video cameras can have more than 1000 frames per second, while they are normally very expensive and the in-formation is also highly redundant. As a result, event cam-eras [3, 28, 16] attracts more attention recently due to their high temporal resolution and low latency (both in the or-der of microseconds) as well as high dynamic range with-out motion blur. Compared with video cameras that output
*Corresponding author: Guofeng Zhang.
†Emails: {eugenelyj, hanzhou, ybbbbt, yezhang509, zhpcui, baohujun, zhangguofeng}@zju.edu.cn. The authors except Zhaopeng Cui are also afﬁliated with ZJU-SenseTime Joint Lab of 3D Vision. This work was partially supported by NSF of China (No. 61822310 and 61932003). images with a speciﬁc frame rate, event cameras are event-driven. When a certain brightness change occurs on a pixel,
In this the event camera will trigger an individual event. way, they naturally discard redundant information by only measuring brightness.
However, since the output of an event camera is a sparse asynchronous events stream, existing efﬁcient meth-ods [15, 37] which typically work on frames can not be directly applied for event cameras. As a result, most works [11, 8, 33] transform such events stream to regu-lar 2D event frames or 3D voxel grids before processing.
However, these data representation transformations discard the sparsity of events data and quantify event timestamps, which are likely to obscure the natural invariance of the data Another type of approach is directly tailored to the sparse and asynchronous nature of event-based data. Time-surface-based methods [17, 36] and Spiking Neural Net-works (SNNs) [27, 19, 1] are two dominant classes of meth-ods for event-by-event processing. Despite keeping low latency, both methods have limited accuracy in high-level tasks, mainly due to their sensitivity to tuning and difﬁculty in the training procedure, respectively. To fully utilize the spatial-temporal sparsity of event data, some recent meth-ods [41, 34, 4, 22] introduce a compact graph representa-tion that interprets an event sequence as a graph on event cloud and employs graph convolutional networks. Although these graph-based methods, e.g., [4, 22], reach state-of-the-art performance, they rely on integrating events over a cer-tain number of events or events within a period. They gather the information contained in groups of events at the cost of discarding the low latency nature of events data.
Based on all these observations, in this paper, we pro-pose a novel graph-based recursive algorithm with a sliding window strategy that can process the stream event-by-event efﬁciently while maintaining high accuracy. However, it is non-trivial to apply the sliding window strategy for graph-based and event-wise processing. The naive sliding win-dow strategy is inefﬁcient because it needs to process all the nodes in the graph even with a minor change, although many nodes’ features don’t change. Moreover, graph con-struction is prerequisite for graph neural networks, and the radius search is normally adopted [4, 22] to determine
nodes’ connection, which is very slow. Take the k-d tree based search as an example, frequent insertion and deletion will make it unbalanced and cause query performance to drop while rebuilding the index will bring the extra cost to insertion.
To solve these problems, we ﬁrst propose a novel incre-mental graph convolution, namely slide convolution, that exploits the local spatial connectivity of convolution and reuses previous calculations in order to avoid processing all nodes. For a single layer, it is rather simple to just compute the features around newly added nodes. For multiple-layer
GCN, we need to solve the propagation of modiﬁed features between layers with different graph topologies. Thus we de-rive a series of propagation rules. In this way, we reduce the computational complexity up to 100 times in comparison with the naive sliding window strategy. Moreover, consid-ering that events locate in the image grid (which consists of two limited and discrete dimensions) rather than generic 3D continuous metric spaces, we introduce a novel radius search algorithm for the structure of event cloud, cutting the search cost by half and reducing the cost of insertion and deletion operations to O (1).
A straightforward application of event-wise processing is early object recognition, as when enough information is received, the prediction result becomes stable and it is not necessary to process more events. Previous works either fo-cus on how to process event-by-event efﬁciently or reach a certain level of accuracy with less information, but lack the ability of early recognition. In this paper, we further apply our graph-based recursive method to early object recogni-tion by designing a state-aware module to predict whether it reaches the stable state. In this way, we can enable ac-curate recognition with conﬁdence as early as possible. To the best of our knowledge, we are the ﬁrst ones to verify the superiority of event-wise processing in early object recog-nition.
To summarize, the contributions of this paper are as fol-lows:
• We propose a novel graph-based recursive algorithm that enables efﬁcient event-wise processing for event cameras.
• We introduce a novel incremental graph convolution for event-wise processing.
It reduces the computa-tional complexity up to 100 times compared to the naive sliding-window-based graph convolution.
• We propose an event-speciﬁc radius search algorithm that reduces query and insertion/deletion costs to make graph construction faster.
• Experiments demonstrate that our efﬁcient event-wise algorithm achieves similar performance with batch-wise methods on standard recognition task while en-abling early object recognition with conﬁdence. 2.