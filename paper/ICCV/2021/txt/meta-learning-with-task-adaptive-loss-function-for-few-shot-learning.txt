Abstract
In few-shot learning scenarios, the challenge is to gen-eralize and perform well on new unseen examples when only very few labeled examples are available for each task. Model-agnostic meta-learning (MAML) has gained the popularity as one of the representative few-shot learn-ing methods for its flexibility and applicability to diverse problems. However, MAML and its variants often resort to a simple loss function without any auxiliary loss function or regularization terms that can help achieve better gen-eralization. The problem lies in that each application and task may require different auxiliary loss function, especially when tasks are diverse and distinct. Instead of attempting to hand-design an auxiliary loss function for each applica-tion and task, we introduce a new meta-learning framework with a loss function that adapts to each task. Our proposed framework, named Meta-Learning with Task-Adaptive Loss
Function (MeTAL), demonstrates the effectiveness and the flexibility across various domains, such as few-shot classifi-cation and few-shot regression. 1.

Introduction
Training deep neural networks entails a tremendous amount of labeled data and the corresponding efforts, which hinder the prompt application to new domains. As such, there has been growing interests in few-shot learning, in which the goal is to imbue the artificial intelligence systems with the capability of learning new concepts, given only few labeled examples (e.g. support examples). The core chal-lenge in few-shot learning is to alleviate the susceptibility of deep neural networks to overfitting under few-data regime and achieve generalization on new examples (e.g. query ex-amples).
Recently, meta-learning [34, 40], a.k.a. learning-to-learn, has emerged as one of the prominent methods for few-shot learning. Meta-learning is used in the field of few-shot learning to learn a learning framework that can adapt to novel tasks and generalize under few-data regime.
Figure 1. Overview of inner-loop optimization in optimization-based meta-learning frameworks. (a) Conventional approaches, such as MAML [10], utilize a fixed given classical loss func-tion (e.g. cross entropy for classification) during adaptation to a task. (b) Our proposed scheme, MeTAL, instead meta-learns a loss function whose parameters ϕ are made adaptive to the current task state τ at the j-th step of adaptation to the i-th task.
Among the meta-learning algorithms, optimization-based meta-learning has enjoyed the attention from different do-mains for its flexibility that enables application across di-verse domains. Optimization-based meta-learning algo-rithms are often formulated as bi-level optimization [10, 25, 29].
In such formulation, an outer-loop optimization trains a learning algorithm to achieve generalization while an inner-loop optimization uses the learning algorithm to adapt a base learner to a new task with few examples.
Model-agnostic meta-learning (MAML) [10], one of the seminal optimization-based meta-learning methods, learns an initial set of values of network weights to achieve gen-eralization. The learned initialization serves as a good starting point for adapting to new tasks with few exam-ples and few updates. Although the learned initialization is
trained to be a good starting point, MAML often faces the difficulty to achieve generalization, especially when tasks are diverse or significantly different between training and test phases [9]. Several works attempted to overcome the difficulty either by attempting to find a better initializa-tion [5, 13, 11, 15, 43, 47] or a better fast adaptation process (inner-loop update rule) [2, 7, 19, 20, 32]. However, these methods resort to a simple loss function (e.g. cross-entropy in classification) in the inner-loop optimization even though other auxiliary loss functions, such as ℓ2 regularization terms, can help achieve better generalization [4].
The experimental
On the other hand, we focus on designing a better loss function for the inner-loop optimization in MAML frame-work. As outlined in Figure 1, we propose a new framework called Meta-Learning with Task-Adaptive LLoss Function (MeTAL) to learn an adaptive loss function that leads to better generalization for each task. Specifically, MeTAL learns a task-adaptive loss function via two meta-learners: one meta-learner for learning a loss function and one meta-learner for generating parameters that transform a learned loss function. Our task-adaptive loss function is designed to be flexible in that both labeled (e.g. support) and unla-beled (e.g. query) examples can be used together to adapt a base learner to each task during the inner-loop optimization. results demonstrate that MeTAL greatly improves the generalization of MAML. Owing to the simplicity and flexibility of MeTAL, we further demon-strate its effectiveness not only across different domains but also other MAML-based algorithms. When applied to other
MAML-based algorithms, MeTAL consistently brings a substantial boost in generalization performance, introduc-ing a new state-of-the-art performance among MAML-based algorithms. This alludes to the significance of a task-adaptive loss function, which has drawn less attention in contrast to initialization schemes and inner-loop update rules. Overall experimental results underline that learning a better loss function for the inner loop optimization is impor-tant complementary component to learning a better inner-loop update or a better initialization. 2.