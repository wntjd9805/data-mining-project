Abstract
In recent years, neural image compression emerges as a rapidly developing topic in computer vision, where the state-of-the-art approaches now exhibit superior compres-sion performance than their conventional counterparts.
Despite the great progress, current methods still have limitations in preserving ﬁne spatial details for optimal reconstruction, especially at low compression rates. We make three contributions in tackling this issue. First, we develop a novel back projection method with attentional and multi-scale feature fusion for augmented representation power. Our back projection method recalibrates the current estimation by establishing feedback connections between high-level and low-level attributes in an attentional and dis-criminative manner. Second, we propose to decompose the input image and separately process the distinct frequency components, whose derived latents are recombined using a novel dual attention module, so that details inside regions of interest could be explicitly manipulated. Third, we propose a novel training scheme for reducing the latent rounding residual. Experimental results show that, when measured in PSNR, our model reduces BD-rate by 9.88% and 10.32% over the state-of-the-art method, and 4.12% and 4.32% over the latest coding standard Versatile Video Coding (VVC) on the Kodak and CLIC2020 Professional Validation dataset, respectively. Our approach also produces more visually pleasant images when optimized for MS-SSIM. The signiﬁcant improvement upon existing methods shows the effectiveness of our method in preserving and remedying spatial information for enhanced compression quality. 1.

Introduction
Lately, the demand for image compression has increased dramatically to cope with the enormous amount of high-resolution images produced by modern devices. Based on deep neural networks (DNNs), neural image compression has reinvigorated this domain with its superb capacity to
Figure 1. Comparison of kodim05.png reconstructed by different methods. The image is cropped for convenient visualization.
Notice that the tilted, shadowy artifacts in the yellow tube region have been largely suppressed by our method. learn in a data- and metric-driven manner, as opposed to their conventional, handcrafted counterparts [17].
Neural image compression typically employs autoen-coders to model the compression and reconstruction process as a uniﬁed task and optimize the rate-distortion trade-off jointly. image into
Such methods map the input a more compact latent intermediate via an encoder and inversely transform the quantized latent back to generate the reconstructed image on the decoder side. Many researches concentrate on optimizing the network architecture, e.g.,
GDN [6], residual blocks [34, 23], RNNs [35, 22, 36], to reduce bit-rates with alleviated quality degradation. Mean-while, some other works focus on reducing the entropy of the latent representations to attain fewer encoding bits.
Earlier works [8, 34] in this respect incorporate elementwise entropy models to encode each element independently.
Later advancements introduce hierarchical hyperprior net-works [7] and autoregressive components [20, 25] into the VAE framework to explicitly estimate the entropy of the latent representation by utilizing prior information.
Currently, the rate-distortion performance of the state-of-the-art methods has surpassed that of reigning compression
codecs, such as BPG [9] and VVC [33], in both PSNR and
MS-SSIM.
Nonetheless, existing schemes remain limited in faith-fully restoring the original image from its compact repre-sentation. The reconstructions at low compression rates tend to be over-smoothed and contain undesirable artifacts.
One major issue of the autoencoder is that, while it excels at extracting contextualized, non-linear information for it stumbles in preserving spatial effective decorrelation, image details that are crucial to faithful reconstruction, since down-sampling via convolution layers is inherently non-injective due to the loss of high-frequency details.
Another limitation of current implementations is that the input image is usually compressed in its RGB format, in which the easily-lost high-frequency details are mingled with large-scale variations. The inability to distinguish distinct frequency characteristics makes it even harder for the network to preserve or infer ﬁne-grained details for optimal reconstruction.
In this paper, to enable mutual facilitation between low-and high-level image properties, we replace the standard feedforward up- and down-sampling layers with a novel
Attentional Multi-scale Back Projection (AMBP) module.
Our AMBP module efﬁciently aggregates intermediate fea-tures from higher to lower layers of the network, allowing it to attain semantically rich features, on the one hand, and extrapolate ﬁne spatial details, on the other. Retaining the desired properties of both gives the network greater
ﬂexibility to decide which information should be preserved for better rate-distortion trade-offs. To extract richer visual representations, we leverage channel attention and a soft attention mechanism that consolidates the input feature maps in a weighted average fashion.
Moreover, we propose to extract and process the distinc-tive frequency components of the input image via frequency decomposition. In this way, the network could yield further efﬁciencies in representation by exploiting various pieces of information that carry different frequency characteristics.
Our method deploys a dual-branch encoder to compress the separate layer components in parallel and later recombines their derived latents using a novel dual attention module.
Besides, to reduce the quantization residual of the latent, we modify the mixed training scheme [26] by adding a rounding loss of the latent, which enforces the network to focus on reducing the quantization error whilst optimizing for the ﬁnal reconstruction. The main contributions of this work are:
• A novel back projection approach capable of produc-ing contextualized outputs with enriched details via multi-scale context aggregation across stages.
• An effective scheme that decomposes the image into distinct frequency components, processes them sepa-rately, and recombines the results via a dual attention module to yield the latent representation.
• A ﬁnetuning strategy for reducing the error caused by rounding the latent to facilitate reconstruction. 2.