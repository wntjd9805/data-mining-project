Abstract
Recent research efforts in lifelong learning propose to grow a mixture of models to adapt to an increasing num-ber of tasks. The proposed methodology shows promising results in overcoming catastrophic forgetting. However, the theory behind these successful models is still not well un-derstood. In this paper, we perform the theoretical analy-sis for lifelong learning models by deriving the risk bounds based on the discrepancy distance between the probabilis-tic representation of data generated by the model and that corresponding to the target dataset.
Inspired by the the-oretical analysis, we introduce a new lifelong learning ap-proach, namely the Lifelong Infinite Mixture (LIMix) model, which can automatically expand its network architectures or choose an appropriate component to adapt its param-eters for learning a new task, while preserving its previ-ously learnt information. We propose to incorporate the knowledge by means of Dirichlet processes by using a gat-ing mechanism which computes the dependence between the knowledge learnt previously and stored in each com-ponent, and a new set of data. Besides, we train a compact
Student model which can accumulate cross-domain repre-sentations over time and make quick inferences. The code is available at https://github.com/dtuzi123/
Lifelong-infinite-mixture-model. 1.

Introduction
Lifelong learning (LLL) aims to learn successively a series of tasks from their corresponding probabilistic rep-resentations of specific databases. The objective of the lifelong learning model is to implement all learnt tasks at any given time. Modern deep learning approaches have been successful in a variety of applications including image translation [24], image synthesis [29] and object detection
[37], but all these models face a major challenge in the per-formance, when applied on prior tasks, while learning mul-tiple tasks, one after the other. This challenge is caused by catastrophic forgetting which happens when a model adapts its parameters in order to learn a new task [31].
Figure 1. The process of forgetting the information from a certain dataset after learning two additional tasks. The source distribution generated by the Generative Replay Mechanims (GRM) is degen-erated when learning a new task.
The Generative Replay Mechanism (GRM) [41] is a pop-ular lifelong learning approach showing promising results overcoming catastrophic forgetting [1, 33, 39, 48, 56]. A generative replay model Gθ : Z → X , aims to transform a low dimensional random variable Z into a high dimensional variable X . Gθ can be an implicit generative model such as a Generative Adversarial Network (GAN) [11] or an ex-plicit latent model such as a Variational Autoencoder (VAE)
[16]. Once a task is learnt, Gθ generates data which then can be combined with data sampled from a given database, corresponding to a new task, to form a joint dataset used for training. Some methods [1, 41] reduce the memory size by only generating a batch of samples for each train-ing step, by using only a copy Gθ′ of the GRM. However, a major challenge for GRM based methods is that of grad-ually losing knowledge across tasks since a GRM model is trained on its own generations repeatedly. Another draw-back, when GANs are used as GRMs, is that of facing mode collapse [44]. Two solutions have been proposed to address this problem. Rao et al. [34] enable GRMs with a network expansion mechanism in which the model’s capacity is in-creased when shifting data distributions. The other solu-tion is to use the expansion mechanism [20] or an ensemble
structure [10, 14, 47] in which each expert is built on the top of a shared module and only a single expert is updated dur-ing the training. These approaches usually preserve the best performance of previous tasks, but the theoretical analyse behind these methods is not well understood.
In this paper, we provide the theoretical analysis for life-long learning models, inspired by the idea illustrated in
Fig. 1. The forgetting behaviour of the model, when learn-ing a certain task, is affected by an ever increasing upper bound (solid line in Fig. 1) to the target-risk, during the life-long leaning. This is mainly caused by the increased accu-mulated errors when learning additional tasks while the dis-crepancy between the target and source distribution is also gradually increased. However, the optimal source-risk can not guarantee a low target-risk since the source distribution of the trained model is gradually degenerated. Inspired by these results, the main idea of the proposed Lifelong In-finite Mixture (LIMix) model is to automatically grow its network architecture if the given task is sufficiently novel when compared to the previously learned knowledge or up-date an appropriate component that has a small discrepancy to the given task. The Dirichlet process, which is usu-ally computational expensive when using the expectation-maximization algorithm to estimate component parameters
[8], can be used for these mechanisms. In order to reduce the computational costs and make an accurate inference for the selection and expansion of the model architecture, we infer an indicator variable for each data sample by using a gating mechanism based on the Dirichlet process that com-putes the corrections between the knowledge stored in each component and the new data. Furthermore, by accumulat-ing knowledge, while enabling fast inference across data domains, using a lightweight model is an attractive feature in LLL, which does not appear in existing lifelong mixtures or ensemble models [20, 47]. Our main contributions are :
• We analyse the forgetting behaviour during LLL by evaluating the accumulated risk and find that the dis-crepancy distance between the source and target distri-bution is key to overcome forgetting.
• This is the first study to provide theory insights when using mixture models for LLL. We also extend the the-oretical analysis to explain the performance change for a model when shifting the order of tasks.
• We propose a new lifelong mixture model with theo-retical guarantees for LLL. We also explore training a compact Student model from the mixture under LLL. 2.