Abstract
Today’s state-of-the-art methods for 3D object detec-tion are based on lidar, stereo, or monocular cameras.
Lidar-based methods achieve the best accuracy, but have a large footprint, high cost, and mechanically-limited an-gular sampling rates, resulting in low spatial resolution at long ranges. Recent approaches using low-cost monocu-lar or stereo cameras promise to overcome these limita-tions but struggle in low-light or low-contrast regions as they rely on passive CMOS sensors. We propose a novel 3D object detection modality that exploits temporal illumina-tion cues from a low-cost monocular gated imager. We in-troduce a novel deep detection architecture, Gated3D, that is tailored to temporal illumination cues in gated images.
This modality allows us to exploit mature 2D object feature extractors that guide the 3D predictions through a frustum segment estimation. We assess the proposed method ex-perimentally on a 3D detection dataset that includes gated images captured over 10,000 km of driving data. We val-idate that our method outperforms state-of-the-art monoc-ular and stereo methods, opening up a new sensor modal-ity as an avenue to replace lidar in autonomous driving. https://light.princeton.edu/gated3d 1.

Introduction 3D object detection is a fundamental vision task in robotics and autonomous driving. Accurate 3D detections are critical for safe trajectory planning, with applications emerging across disciplines such as autonomous drones, as-sistive and health robotics, as well as warehouse and de-livery robots. RGB-D cameras using correlation time-of-ﬂight [22, 29, 34], such as Microsoft’s Kinect One, enable robust 3D detection indoors [55, 56] for small ranges. In the past, autonomous driving, which requires long ranges and high depth accuracy, has relied on scanning lidar for 3D de-tection [50, 60, 15, 64, 35, 11, 68, 30, 33]. However, while lidar provides accurate depth, existing systems are funda-mentally limited by point-by-point acquisition, resulting in
*indicates equal contribution. spatial resolution that falls off quadratically with distance
In contrast to conventional and linearly with frame rate. cameras, lidar systems are three orders of magnitude more expensive, suffer from low resolution at long distances, and fail in the presence of strong back-scatter, e.g. in snow or fog [3].
Promising to overcome these challenges, a recent line of work proposed pseudo-lidar sensing [61], which relies on low-cost sensors, such as stereo [10, 7, 27] or monoc-ular [9, 20, 14] to recover dense depth maps from conven-tional intensity imagers. Point-clouds are sampled from the depth maps and ingested by 3D detection methods that op-erate on point-cloud representations [33, 68]. More recent methods predict 3D boxes directly from the passive input images [36, 4, 54]. Although all of these methods promise low-cost 3D detection with the potential to replace lidar, they rely on passive camera-only sensing. Passive stereo approaches degrade at long ranges, where disparities are small, and in low-light scenarios, e.g. at night, when stereo or monocular depth cues are less visible.
In this work, we introduce the ﬁrst 3D object detection method using gated imaging and evaluate this as a low-cost detection method, outperforming recent monocular and stereo detection methods. Similar to passive approaches, we use CMOS sensors but add active temporal illumina-tion. The proposed gated imager captures illumination dis-tributed in three wide gates (> 30 m) for all sensor pixels.
Gated imaging [25, 5, 2, 63, 49, 1, 21] allows us to capture several dense high-resolution images distributed continu-ously across the distances in their respective temporal bin.
Additionally, back-scatter can be removed by the distribu-tion of early gates. Whereas scanning lidar trades off tem-poral resolution with spatial resolution and signal-to-noise ratio (SNR), the sequential acquisition of gated cameras trades off dense spatial resolution and SNR (i.e. wide gates) with coarse temporal resolution. We demonstrate that the temporal illumination variations in gated images are a depth cue naturally suited for 3D object detection. Operating on 2D gated slices allows us to leverage existing 2D object de-tection architectures to guide the 3D object detection task with a novel frustum segmentation. The proposed archi-tecture further exploits gated images by disentangling the 1
Figure 1: We propose a novel 3D object detection method, “Gated3D”, which uses a ﬂood-illuminated gated camera. The high resolution of gated images enables semantic understanding at long ranges. In the ﬁgure, our gated slices are color-coded with red for slice 1, green for slice 2 and blue for slice 3. We evaluate Gated3D on real data collected with a Velodyne
HDL64-S3D scanning lidar as reference, as seen in the overlay on the right. semantic contextual features from depth cues in the gates through a two stream feature extraction. Relying on the re-sulting high-resolution 2D feature stacks, the method out-performs existing methods especially at long ranges. Al-though the proposed architecture is trained using only gated images as input, it naturally supports fusion with other ex-isting depth modalities, e.g. from RGB stereo or lidar depth maps. The method runs at real-time frame rates and outper-forms existing passive imaging methods, independent of the ambient illumination – promising low-cost CMOS sensors for 3D object detection in diverse automotive scenarios.
Speciﬁcally, we make the following contributions:
• We formulate the 3D object detection problem as a re-gression from a frustum segment, computed using 2D detection priors and the object dimension statistics.
• We propose a novel end-to-end deep neural network architecture that solves this regression with depth cues and semantic features from gated images.
• We validate the proposed method on real-world driv-ing data acquired in challenging automotive scenarios.
The proposed approach detects objects with high ac-curacy up to 80 m, outperforming existing monocular, stereo and pseudo-lidar low-cost methods.
• We provide 3D annotations for gated data captured in northern Europe, along with code and models.
As an example, Figure 1 shows experimental results of the proposed method. The gated image contains dense in-formation on objects further away in the scene. The advan-tage of gated sensors for nighttime scenes is also demon-strated in this example, where the pedestrians are not clearly visible in the RGB image. 2.