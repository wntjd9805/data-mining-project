Abstract
This paper presents an end-to-end semi-supervised ob-ject detection approach, in contrast to previous more com-plex multi-stage methods. The end-to-end training grad-ually improves pseudo label qualities during the curricu-lum, and the more and more accurate pseudo labels in turn benefit object detection training. We also propose two sim-ple yet effective techniques within this framework: a soft teacher mechanism where the classification loss of each un-labeled bounding box is weighed by the classification score produced by the teacher network; a box jittering approach to select reliable pseudo boxes for the learning of box re-gression. On the COCO benchmark, the proposed approach outperforms previous methods by a large margin under var-ious labeling ratios, i.e. 1%, 5% and 10%. Moreover, our approach proves to perform also well when the amount of labeled data is relatively large. For example, it can improve a 40.9 mAP baseline detector trained using the full COCO training set by +3.6 mAP, reaching 44.5 mAP, by leverag-ing the 123K unlabeled images of COCO. On the state-of-the-art Swin Transformer based object detector (58.9 mAP on test-dev), it can still significantly improve the detection accuracy by +1.5 mAP, reaching 60.4 mAP, and improve the instance segmentation accuracy by +1.2 mAP, reaching 52.4 mAP. Further incorporating with the Object365 pre-trained model, the detection accuracy reaches 61.3 mAP and the instance segmentation accuracy reaches 53.0 mAP, pushing the new state-of-the-art. The code and models will be made publicly available at https://github.com/ microsoft/SoftTeacher. 1.

Introduction
Data matters. In fact, large data such as ImageNet has largely triggered the boom of deep learning in computer vi-*Equal contribution. †This work is done when Mengde Xu was intern in MSRA. ‡Contact person.
Figure 1. The proposed end-to-end pseudo-label based semi-supervised object detection method outperforms the STAC [27] by a large margin on MS-COCO benchmark. sion. However, obtaining labels can be a bottleneck, due to the time-consuming and expensive annotation process.
This has encouraged learning methods to leverage unla-beled data in training deep neural models, such as self-supervised learning and semi-supervised learning. This pa-per studies the problem of semi-supervised learning, in par-ticular for object detection.
For semi-supervised object detection, we are concerned with the pseudo-label based approaches, which are the cur-rent state-of-the-art. These approaches [27, 36] conduct a multi-stage training schema, with the first stage train-ing an initial detector using labeled data, followed by a pseudo-labeling process for unlabeled data and a re-training step based on the pseudo labeled unannotated data. These multi-stage approaches achieve reasonably good accuracy, however, the final performance is limited by the quality of pseudo labels generated by an initial and probably inaccu-rate detector trained using a small amount of labeled data.
detector
HTC++(Swin-L) w/ single-scale
HTC++(Swin-L) w/ multi-scale method supervised ours ours∗ supervised ours ours∗ val2017 test-dev2017 mAPdet mAPmask mAPdet mAPmask 57.1 59.1 60.1 58.2 59.9 60.7 49.6 51.0 51.9 50.5 51.9 52.5
---58.9 60.4 61.3
---51.2 52.4 53.0
Table 1. On the state-of-the-art detector HTC++(Swin-L), our method surpasses the supervised learning on both val2017 and test-dev2017. * indicates that models are pre-trained with Object365 [24] dataset.
To address this issue, we present an end-to-end pseudo-label based semi-supervised object detection framework, which simultaneously performs pseudo-labeling for unla-beled images and trains a detector using these pseudo labels along with a few labeled ones at each iteration. Specifically, labeled and unlabeled images are randomly sampled with a preset ratio to form one data batch. Two models are applied on these images, with one conducting detection training and the other in charge of annotating pseudo labels for unla-beled images. The former is also referred to as a student, and the latter is a teacher, which is an exponential moving average (EMA) of the student model. This end-to-end ap-proach avoids the complicated multi-stage training scheme.
Moreover, it also enables a “flywheel effect” that the pseudo labeling and the detection training processes can mutually reinforce each other, so that both get better and better as the training goes on.
Another important benefit of this end-to-end framework is that it allows for greater leverage of the teacher model to guide the training of the student model, rather than just providing “some generated pseudo boxes with hard cate-gory labels” as in previous approaches [27, 36]. A soft teacher approach is proposed to implement this insight. In this approach, the teacher model is used to directly assess all the box candidates that are generated by the student model, rather than providing “pseudo boxes” to assign category la-bels and regression vectors to these student-generated box candidates. The direct assessment on these box candidates enables more extensive supervision information to be used in the student model training. Specifically, we first catego-rize the box candidates as foreground/background by their detection scores with a high foreground threshold to ensure a high precision of the positive pseudo labels, as in [27].
This high foreground threshold, however, results in many positive box candidates mistakenly assigned as background.
To address this issue, we propose using a reliability measure to weight the loss of each “background” box candidate. We empirically find that a simple detection score produced by the teacher model can well serve as the reliability measure, and is used in our approach. We find that this approach mea-sure performs significantly better than previous hard fore-ground/background assignment methods (see Table 2 and
Table 3), and we name it “soft teacher”.
Another approach instantiates this insight is to select re-liable bounding boxes for the training of the student’s lo-calization branch, by a box jittering approach. This ap-proach first jitters a pseudo-foreground box candidate sev-eral times. Then these jittered boxes are regressed accord-ing the teacher model’s location branch, and the variance of these regressed boxes is used as a reliability measure. The box candidate with adequately high reliability will be used for the training of the student’s localization branch.
On MS-COCO object detection benchmark [16], our ap-proach achieves 20.5 mAP, 30.7 mAP and 34.0 mAP on val2017 with 1%, 5% and 10% labeled data using the
Faster R-CNN [22] framework with ResNet-50 [8] and
FPN [14], surpassing previous best method STAC [27] by
+6.5, +6.4 and +5.4 mAP, respectively.
In addition, we also perform evaluation on a more chal-lenge setting where the labelled data has been adequately large to train a reasonably accurate object detector. Specifi-cally, we adopt the complete COCO train2017 set as la-beled data and the unlabeled2017 set as the unlabeled data. Under this setting, we improve the supervised baseline of a Faster R-CNN approach with ResNet-50 and ResNet-101 backbones by +3.6 mAP and +3.0 mAP, respectively.
Moreover, on a state-of-the-art Swin-Transformer [18] based detector which achieves 58.9 mAP for object detec-tion and 51.2 mAP for instance segmentation on COCO test-dev2017, the proposed approach can still improve the accuracy by +1.5 mAP and +1.2 mAP, respectively, reaching 60.4 mAP and 52.4 mAP. Further incorporating with the Object365 [24] pre-trained model, the detection ac-curacy reaches 61.3 mAP and the instance segmentation ac-curacy reaches 53.0 mAP, which is the new state-of-the-art on this benchmark. 2.