Abstract
Despite the recent success of 3D human reconstruction methods, recovering the accurate and smooth 3D human motion from video is still challenging. Designing a temporal model in the encoding stage is not sufficient enough to set-tle the trade-off problem between the per-frame accuracy and the motion smoothness. To address this problem, we approach some of the fundamental problems of 3D recon-struction tasks, simultaneously predicting 3D pose and 3D motion dynamics. First, we utilize the power of uncertainty to address the problem of multiple 3D configurations result-ing in the same 2D projections. Second, we confirmed that dividing the body into local regions shows outstanding re-sults for estimating 3D motion dynamics. In this paper, we propose (i) an encoder that makes two different estimations: a static feature that presents 2D pose feature as distribution and a dynamic feature that includes optical flow informa-tion and (ii) a decoder that divides the body into five dif-ferent local regions to estimate the 3D motion dynamics of each region. We demonstrate how our method recovers the accurate and smooth motion and achieves the state-of-the-art results for both constrained and in-the-wild videos. 1.

Introduction
Reconstructing a 3D human mesh can be used for many applications, including motion analysis, virtual and aug-mented reality, gaming, and biometrics. However, estimat-ing 3D human pose and shape from a single image or video is a challenging problem because of the limited 3D scan data and the ambiguity that multiple 3D configurations can result in the same 2D projection. To address the above diffi-culties, Loper et al. [27] introduced a parametric 3D human mesh model, SMPL, that was learned from thousands of 3D body scans. Recently, many studies have been proposed to directly regress the model parameters from the input image by utilizing the power of the DCNN, which have shown im-pressive results [3, 12, 28, 32, 11, 36]. However, these single image-based methods tend to produce temporally inconsis-tent and unsmooth 3D motion when applied to a video.
Several methods [2, 5, 37, 29, 38, 18] have been pro-posed to effectively extend single image-based methods to video cases. They have introduced the concept of temporal network to SMPL. This network makes a model learn di-rectly from a video to better capture temporal information.
However, these methods are still not capable of recover-ing the accurate and smooth 3D human motion. Among the above studies, contrary to other methods that showed limita-tions in recovering smooth 3D motion, the model proposed in [2] succeeded in reducing the temporal inconsistency by learning 3D motion dynamics but showed a low per-frame accuracy. To address this problem, we approach some of the fundamental problems of 3D reconstruction tasks, simulta-neously learning 3D pose and 3D motion dynamics.
The main reason that the 3D reconstruction task is chal-lenging derives from the existence of ambiguity in that var-ious 3D poses can be projected into the same or similar 2D poses. The estimated 3D meshes can be completely wrong even though they are closely matched with input images when projected into 2D space. However, existing studies have not addressed this problem directly. We found that we could improve robustness of the model on such ambigu-ity by utilizing the power of uncertainty in the embedding step [15]. As 2D poses have an inherent ambiguity, it is diffi-cult to represent 2D poses through a deterministic mapping, which previous 3D human reconstruction methods use in the latent feature space. Unlike previous methods, we pro-pose employing a view-invariant probabilistic encoder for a static feature that presents 2D pose features as distribu-tion to inform the decoder of the uncertainty information in 2D space. As an ideal model reconstructs a view-invariant 3D human mesh, the uncertainty concept plays an impor-tant role in 3D human reconstruction task. Furthermore, we introduce a novel method to optimize the decoding process using uncertainty-aware pose loss, which further helps the model to reconstruct an accurate 3D pose. Apart from the static feature taking into account the uncertainty of the 2D pose, we also estimate the dynamic feature including opti-cal flow information from the video. This dynamic feature is effective for estimating 3D motion changes in a short pe-riod of time. The encoding method we suggested makes two different estimations; a static feature and a dynamic feature from the video show a significant effect on the decoder to recover the accurate and smooth 3D motion.
Additionally, we confirmed that dividing the body into local regions shows outstanding results for estimating 3D motion dynamics. Estimating 3D motion dynamics for all joints together is difficult, as the deformations of the local body regions are different. The nearby joints have strong dependency, while the dependency of the distant joints is weak. We propose to estimate 3D dynamics by dividing the entire body into five local body regions: torso, left arm, right arm, left leg, and right leg. Unlike existing methods that ig-nore spatial relationships between features by using a fully connected layer (FCN) to estimate 3D pose and 3D motion dynamics, we model the spatial relationships between lo-cal regions in the decoding process. This allows the model to consider the independent characteristics of different local body regions while making the joints in the same local body region more dependent. This decoding method also enables our network to better infer about uncommon global poses by learning the distribution of local body poses instead of the distribution of global body poses.
In this paper, we propose a 3D human reconstruction method that can estimate the accurate and smooth motion from video. Qualitative and quantitative results show that our method outperforms previous state-of-the-art methods for both constrained and in-the-wild videos. The contribu-tions of the paper can be summarized as follows:
• We propose to estimate two different features from video: a static feature and a dynamic feature for simul-taneously predicting 3D pose and motion dynamics.
• We propose employing a view-invariant probabilistic encoder that presents 2D pose features as distribution for considering uncertainty in 2D space. Furthermore, we introduce an uncertainty loss in the decoding pro-cess.
• We present a decoder that divides the body into five different local regions to estimate the 3D motion dy-namics of each region. 2.