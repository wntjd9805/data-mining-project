Abstract
Motion prediction of vehicles is critical but challenging due to the uncertainties in complex environments and the limited visibility caused by occlusions and limited sensor ranges. In this paper, we study a new task, safety-aware mo-tion prediction with unseen vehicles for autonomous driv-ing. Unlike the existing trajectory prediction task for seen vehicles, we aim at predicting an occupancy map that indi-cates the earliest time when each location can be occupied by either seen and unseen vehicles. The ability to predict unseen vehicles is critical for safety in autonomous driv-ing. To tackle this challenging task, we propose a safety-aware deep learning model with three new loss functions to predict the earliest occupancy map. Experiments on the large-scale autonomous driving nuScenes dataset show that our proposed model significantly outperforms the state-of-the-art baselines on the safety-aware motion prediction task. To the best of our knowledge, our approach is the first one that can predict the existence of unseen vehicles in most cases. Project page at https://github.com/ xrenaa/Safety-Aware-Motion-Prediction. 1.

Introduction
Every year, there are more than 1 million deaths related to car accidents, and up to 94% of accidents are resulted from human errors [42]. Autonomous driving systems can potentially save hundreds of thousands of lives [4]. Critical to autonomous driving is motion prediction, which predicts surrounding traffic participants [55].
Prior work on motion prediction can be broadly classi-fied into two approaches. The first approach predicts the future trajectories of agents. Both discriminative models
[17, 49, 30, 34, 52] and generative models [57, 14, 33, 35, 11, 46] are proposed. The second approach formu-lates this problem as an occupancy map prediction prob-lem [18, 23, 37, 31, 39]. These prior work rarely model safety explicitly and have difficulty predicting unseen vehi-cles.
*Equal contribution
Figure 1. Our goal is to predict how early a vehicle or even unseen vehicles will occupy the space, referred to as safety-aware motion prediction. An unseen vehicle due to the occlusion or limited sen-sor ranges is the one that can not be observed by the ego vehicle in the past. Ignoring the future motion of unseen vehicles can lead to collisions. In this figure, the possible prediction (in gray) can help the planner to filter out the risky planned trajectories that may lead to collisions. Safe planning should leave a larger margin for the ego vehicle to respond.
In real-world driving scenarios, unseen vehicles are very common due to occlusions and the limited range of sensors.
An unseen vehicle refers to a vehicle that has not appeared at present or in history but will come into view and influence planning decisions. An example of an unseen vehicle is illustrated in Figure 1. Missing the prediction of unseen vehicles threatens the safety of planning decisions and even causes collisions.
To achieve safety-first autonomous driving, we analyze the possible consequences of later/earlier prediction, i.e., predicting vehicles’ arrival (occupancy) time at a certain lo-cation later/earlier than the ground truth, in a specific driv-ing scenario. As shown in Figure 1, the ground truth (GT) for the surrounding vehicle (blue car) is plotted in a blue dotted line. Due to uncertainty, it is hard to make a perfect prediction. In this case, it is safer to make a prediction ear-lier than the GT, i.e., the predicted arrival/occupancy time at any location is earlier than GT. When we make an ear-lier prediction (gray line) than GT, there is a collision with
a candidate trajectory. Though the GT trajectory actually does not have a collision with this candidate trajectory, it is safe for the planner to filter out this trajectory. Instead, if the prediction is later than GT, the planner may select a risky candidate trajectory. With the above observations, we propose the task of safety-aware motion prediction that in-cludes the following two aspects: 1. For the sake of safety, the predicted occupancy time of each location should be earlier than the ground truth but as accurate as possible. 2. The prediction for unseen vehicles should be included.
To solve the proposed safety-aware motion prediction task, we propose a new representation called earliest occu-pancy map to characterize vehicles’ future motion (usually in 3 to 5 seconds). The earliest occupancy map contains a value at each location indicating when this location was first occupied. To estimate the earliest occupancy map, we can formulate a regression problem with three novel loss functions. Two of the loss functions encourage accurate prediction with a preference for earlier than later predic-tions. The third one optimizes for unseen vehicle predic-tion. Moreover, with the raster image [12] as input and the earliest occupancy map as the output, we propose a new net-work architecture that uses a customized U-Net [38] with a dilated bottleneck and an unseen-aware self-attention unit.
Our architecture takes advantage of image-to-image transla-tion networks to model the complex motion prediction task.
Our main contributions are summarized as:
• We propose a safety-aware motion prediction task for autonomous driving. The task predicts the earliest oc-cupancy map from surrounding vehicles, including both seen and unseen vehicles.
• We present a customized U-Net [38] architecture with a dilated bottleneck and an unseen-aware self-attention unit to obtain the earliest occupancy map. Conse-quently, we introduce three specific loss functions to train our model effectively.
• We introduce new evaluation metrics such as Missing
Rate, Aggressiveness, and Unseen Recall to evaluate our models and baselines. The experimental results on the large-scale nuScene dataset show that our model outperforms the state-of-the-art methods for safety-aware motion prediction.
For the input representations, researchers propose to use either graph-based representations [19, 7, 15, 32, 41, 27, 43, 53] or rasterization-based representations [10, 2, 6, 20, 1].
Homayounfar et al. [19] propose to model the lane graph with a Directed Acyclic Graph (DAG), and Chu et al. [7] use an undirected graph to model the road layout. Djuric et al. [12] rasterize map elements (e.g., roads, crosswalks) as layers and encode the lanes and vehicles with different colors. Compared with graph representation, raster maps provide richer geometric and semantic information for mo-tion prediction [32].
For the output representation, prior work has focused on trajectories [10, 41, 6] or occupancy maps [18, 23, 37, 31, 39]. Notably, P3 [39] recently propose a semantic occu-pancy map to enrich the traditional occupancy map [13].
Prior work leverages either discriminative models [17, 49, 30, 34, 52] or generative models [22, 56, 16, 40, 26, 28].
Discriminative models predict either a single most-likely trajectory per agent, usually via supervised regression [6] or multiple possible trajectories using multi-modal loss func-tion such as mixture-of-experts loss [10]. Generative mod-els [41, 45, 29] explicitly handle multimodality by lever-aging latent variable generative models, which incorporate random sampling during training and inference to capture future uncertainty. However, prior work on motion predic-tion does not explicitly consider safety and unseen vehicles.
In this paper, we propose the earliest occupancy map as an output representation to assist autonomous driving systems for safety-aware motion prediction with unseen vehicles.
Safety and uncertainty awareness. Prior work on safety and uncertainty-aware autonomous driving systems has focused on uncertainty estimation [51, 3, 44, 8] and planning with collision avoidance guarantee [57, 14, 33, 35, 11, 46]. However, it is not straightforward to extend these methods to be unseen vehicles-aware. To the best of our knowledge, there are few works considering unseen vehi-cles for the autonomous driving system. The only excep-tion is Tas and Stiller [46], which proposes a method to re-main collision-free while considering unseen vehicles dur-ing planning. However, their method is based on hand-craft rules for each scenario considered (e.g. intersection cross-ing, give-way maneuvers) and can not generalize well to complex urban environments. 3. Safety-aware Motion Prediction 3.1. Problem Definition 2.