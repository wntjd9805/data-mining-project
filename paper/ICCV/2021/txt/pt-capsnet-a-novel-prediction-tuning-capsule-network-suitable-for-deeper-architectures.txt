Abstract
Capsule Networks (CapsNets) create internal represen-tations by parsing inputs into various instances at differ-ent resolution levels via a two-phase process – part-whole transformation and hierarchical component routing. Since both of these internal phases are computationally expen-sive, CapsNet have not found wider use. Existing varia-tions of CapsNets mainly focus on performance compari-son with the original CapsNet, and have not outperformed
CNN-based models on complex tasks. To address the limita-tions of the existing CapsNet structures, we propose a novel
Prediction-Tuning Capsule Network (PT-CapsNet), and also introduce fully connected PT-Capsules (FC-PT-Caps) and locally connected PT-Capsules (LC-PT-Caps). Differ-ent from existing CapsNet structures, our proposed model (i) allows the use of capsules for more difficult vision tasks and provides wider applicability; and (ii) provides better than or comparable performance to CNN-based baselines on these complex tasks. In our experiments, we show ro-bustness to affine transformations, as well as the lightweight and scalability of PT-CapsNet via constructing larger and deeper networks and performing comparisons on classifica-tion, semantic segmentation and object detection tasks. The results show consistent performance improvement and sig-nificant parameter reduction compared to various baseline models. Code is available at https://github.com/
Christinepan881/PT-CapsNet.git. 1.

Introduction
Convolutional Neural Networks (CNNs) [4][12][27] can capture features of objects similar to human visual system by assembling a set of small kernels looking for different patterns. Their ability to learn rich feature representations
*The information, data, or work presented herein was funded in part by
National Science Foundation (NSF) under Grants 1739748 and 18167325 and by the Advanced Research Projects Agency-Energy (ARPA-E), U.S.
Department of Energy, under Award Number DE-AR0000940. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof. from data have allowed them to find a wide range of appli-cations for various vision tasks.
When looking at an object, humans deconstruct it into hierarchical sub parts, and tend to develop a relationship between object parts [10]. This parsing process aligns well with the capsule networks (CapsNets) [26]. Capsules rep-resent distinct types of parts/instances, and each capsule is a collection of neurons, encapsulating different attributes of a part/instance, e.g. scale, orientation etc. A capsule layer consists of multiple capsules. A special agreement/routing mechanism between subsequent capsule layers is used for parsing different levels of capsules. Encapsulation of dif-ferent attributes and the agreement mechanism encourage each capsule to be responsible for capturing how an entity is represented, instead of only indicating its presence as in traditional neuron activations.
However, existing CapsNet variants have several limi-tations preventing them from being as widely adopted as
CNNs. Firstly, the fully pairwise connection between cap-sules focuses more on global information, but is not that conducive to capturing diverse local relationships. Sec-ondly, while stacking capsule layers, the fully pairwise con-nection between every capsule tends to increase the number of parameters exponentially, thereby decreasing the gener-alization ability and causing the overfitting problem dur-ing training. Thirdly, the routing-by-agreement mecha-nism [26] is computationally expensive and time consum-ing. Due to these limitations, current CapsNets cannot be generalized to a wider range of more complicated computer vision tasks and datasets involving deeper networks.
In order to utilize all the benefits of CapsNets and realize their full potential, we propose a novel Prediction-Tuning
Capsule Network (PT-CapsNet) to overcome the limitations of previous CapsNets. We show that PT-CapsNet is a scal-able and equivariant model for capsule networks, and has more sparse projections from the input capsule to output capsule space, providing better robustness and generaliza-tion ability. Different from the existing CapsNets vari-ants, our contributions include the following: We (i) pro-pose a novel PT-CapsNet, which is lightweight and effi-cient; (ii) introduce two instance layers–fully connected PT
capsule layer (FC-PT-Caps) and locally connected PT cap-sule layer (LC-PT-Caps)– to make the PT-CapsNet appli-cable to various deep learning architectures; (iii) conduct ablation studies to investigate the best combination to build the PT-CapsNets; (iv) design a PT-CapsNet architecture for classification, which is composed of multiple FC-PT-Caps and LC-PT-Caps; (v) conduct experiments to validate the robustness of PT-CapsNet to affine transformations, and achieve much better results by using 29 times less number of parameters compared to previous CapsNets; (vi) scale our model to larger deep learning architectures for classifi-cation, semantic segmentation, and object detection tasks, and achieve better or comparable performance to CNN-based baselines using much less number of parameters. 2.