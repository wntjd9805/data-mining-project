Abstract 1.

Introduction
Although different approaches have been proposed for 3D point cloud-related tasks, few-shot learning (FSL) of 3D point clouds still remains under-explored. In FSL, un-like traditional supervised learning, the classes of training and test data do not overlap, and a model needs to rec-ognize unseen classes from only a few samples. Existing
FSL methods for 3D point clouds employ point-based mod-els as their backbone. Yet, based on our extensive experi-ments and analysis, we first show that using a point-based backbone is not the most suitable FSL approach, since (i) a large number of points’ features are discarded by the max pooling operation used in 3D point-based backbones, decreasing the ability of representing shape information; (ii) point-based backbones are sensitive to occlusion. To address these issues, we propose employing a projection-and 2D Convolutional Neural Network-based backbone, re-ferred to as the ViewNet, for FSL from 3D point clouds.
Our approach first projects a 3D point cloud onto six dif-ferent views to alleviate the issue of missing points. Also, to generate more descriptive and distinguishing features, we propose View Pooling, which combines different projected plane combinations into five groups and performs max-pooling on each of them. The experiments performed on the
ModelNet40, ScanObjectNN and ModelNet40-C datasets, with cross validation, show that our method consistently outperforms the state-of-the-art baselines. Moreover, com-pared to traditional image classification backbones, such as
ResNet, the proposed ViewNet can extract more distinguish-ing features from multiple views of a point cloud. We also show that ViewNet can be used as a backbone with different
FSL heads and provides improved performance compared to traditionally used backbones.
*The information, data, or work presented herein was funded in part by
National Science Foundation under Grant 1816732 and Federal Highway
Administration Exploratory Advanced Research Program under Agree-ment No. 693JJ31950022. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Govern-ment or any agency thereof. 3D point cloud data has a wide range of applications including robotics, self driving cars and simultaneous lo-calization and mapping (SLAM). In recent years, different approaches have been proposed for traditional point cloud-related tasks, such as point cloud classification, segmenta-tion and object detection. Yet, few-shot learning of 3D point clouds remains relatively under-explored.
In contrast to structured 2D images, a 3D point cloud is a set of unordered points. Thus, traditional Convolution Neural Networks (CNNs) cannot be directly used with 3D point clouds. To address this, PointNet [14] was proposed, which employs a max pooling operation to obtain permutation invariant fea-tures. This has been shown to be effective in capturing 3D objects’ shape, and could be used for downstream tasks, such as point cloud classification and segmentation. How-ever, in PointNet, each point’s features are learned inde-pendently, and features from neighboring points are not ag-gregated. Thus, later works presented different approaches, wherein a better representation can be learned by incorpo-rating features from neighboring points [15, 22, 24, 25]. De-spite having different network structures, these point-based methods all employ a max pooling module to obtain permu-tation invariant features for the downstream tasks.
Traditional supervised learning needs a large number of labeled samples for training, and performs testing on the same classes used in training.
In contrast, with few-shot learning (FSL), a model performs prediction on classes, which have not been seen during training, with only a few labeled samples provided in a support set. Let (x, y) denote a point cloud sample and its label. In N -way-K-shot FSL, a support set S = {(xi, yi)}N ×K contains N classes with K samples for each class. A query set Q = {xj}N ×q j=1 contains the same classes, with q samples for each class. The model matches each sample in Q with a sample in S to predict the labels of query samples. Support and query sets are used both in training and testing. The model gains the ability to learn the similarities between samples from the same class, and dissimilarities between different classes. i=1
Existing approaches for FSL from point clouds [26, 27]
use DGCNN [22], a well-known point-based method, as their backbone due to its simplicity and effectiveness in rep-resenting 3D object shapes. In DGCNN, non-local features are learned for each point by aggregating features from dif-ferent neighbors in each Edge Convolution Layer. At the end of the network, max pooling is performed to obtain per-mutation invariant features, which are then used for the FSL tasks. In this paper, we first show that point-based methods are not the most suitable backbones for FSL for the follow-ing reasons: (i) The representation ability of a point-based method is correlated with the number of points kept after max-pooling [3]. Our extensive experiments show that, in
FSL, a point-based backbone utilizes only a small portion of points after max pooling. Considering that classification with FSL is already more challenging than traditional su-pervised classification, it is even more important to make effective use of the available data points. Discarding 3D points during max-pooling decreases the shape representa-tion ability of a point-based approach; (ii) Real-world point cloud data is affected by occlusions and has missing points, and point-based methods are very sensitive to these issues.
For instance, almost all point-based methods [14, 15, 22] perform well on the ModelNet40 [23] dataset, which was generated from CAD models, and thus is not affected by missing point issues. On the other hand, the performances of these methods drop on the ScanObjectNN dataset [21], which was collected by scanning real-world objects.
To address the aforementioned issues, instead of a point-based backbone, we propose a 2D projection-based back-bone, referred to as the ViewNet, for FSL of point clouds.
The proposed ViewNet is inspired by GaitSet [2], which was proposed for gait recognition from videos. ViewNet is designed by incorporating our proposed novel View Pool-ing, which extracts more descriptive and distinguishing fea-tures from 2D projection images of point clouds, which are then fed into a few-shot head for downstream FSL tasks.
More specifically, we project a point cloud into six orthogo-nal planes (front, back, left, right, top and bottom) to gener-ate six depth images by using the SimpleView [7] projection method. Some example depth images are shown in Fig. 2.
In addition, we propose View Pooling, which combines dif-ferent projected plane combinations into five groups and performs max-pooling on each of them to generate more descriptive features. The experiments performed on the
ModelNet40 [23], ScanObjectNN [21] and ModelNet40-C [18] datasets, with cross validation, show that our pro-posed method consistently outperforms the state-of-the-art (SOTA) on the few-shot point cloud classification task. The main contributions of this work include the following:
• We first provide an analysis of the commonly used point-based backbones in terms of point utilization, and argue that they are not well-suited for the FSL task especially with real-word point clouds obtained via scanning.
• By visualizing projected depth images of point clouds, we have observed that some projections are robust to missing points and deformations. Motivated by this, we propose the ViewNet, a 2D projection-based backbone, for few-shot point cloud classification.
• We propose View Pooling to generate more descriptive and distinguishing features.
• Our approach achieves SOTA performance on ScanOb-jectNN, ModelNet40-C and ModelNet40 datasets, and outperforms four different baselines [10, 17, 19, 26] on few-shot point cloud classification task.
• Ablation studies show that the proposed ViewNet back-bone can generalize and be employed together with dif-ferent few-shot prediction heads, providing better perfor-mance than a point-based backbone. 2.