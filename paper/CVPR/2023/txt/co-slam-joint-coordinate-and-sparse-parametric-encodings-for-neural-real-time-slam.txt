Abstract 1.

Introduction
We present Co-SLAM, a neural RGB-D SLAM system based on a hybrid representation, that performs robust cam-era tracking and high-fidelity surface reconstruction in real time. Co-SLAM represents the scene as a multi-resolution hash-grid to exploit its high convergence speed and abil-ity to represent high-frequency local features.
In addi-tion, Co-SLAM incorporates one-blob encoding, to encour-age surface coherence and completion in unobserved ar-eas. This joint parametric-coordinate encoding enables real-time and robust performance by bringing the best of both worlds: fast convergence and surface hole filling.
Moreover, our ray sampling strategy allows Co-SLAM to perform global bundle adjustment over all keyframes in-stead of requiring keyframe selection to maintain a small number of active keyframes as competing neural SLAM ap-proaches do. Experimental results show that Co-SLAM runs at 10−17Hz and achieves state-of-the-art scene reconstruc-tion results, and competitive tracking performance in vari-ous datasets and benchmarks (ScanNet, TUM, Replica, Syn-thetic RGBD). Project page: https://hengyiwang. github.io/projects/CoSLAM
⋆ Indicates equal contribution.
Real-time joint camera tracking and dense surface re-construction from RGB-D sensors has been a core problem in computer vision and robotics for decades. Traditional
SLAM solutions exist that can robustly track the position of the camera while fusing depth and/or color measurements into a single high-fidelity map. However, they rely on hand-crafted loss terms and do not exploit data-driven priors.
Recent attention has turned to learning-based models that can exploit the ability of neural network architectures to learn smoothness and coherence priors directly from data.
Coordinate-based networks have probably become the most popular representation, since they can be trained to predict the geometric and appearance properties of any point in the scene in a self-supervised way, directly from images. The most notable example, Neural Radiance Fields (NeRF) [14], encodes scene density and color in the weights of a neural network. In combination with volume rendering, NeRF is trained to re-synthesize the input images and has a remark-able ability to generalize to nearby unseen views.
Coordinate-based networks embed input point coordi-nates into a high dimensional space, using sinusoidal or other frequency embeddings, allowing them to capture high-frequency details that are essential for high-fidelity geometry reconstruction [1]. Combined with the smooth-COORDINATE
PARAMETRIC
JOINT
REFERENCE
Frequency
DenseGrid
DenseGrid+OneBlob
NICE-SLAM [42]
OneBlob
HashGrid
HashGrid+OneBlob (Ours)
GT
Figure 2. Illustration of the effect of different encodings on completion. COORDINATE based encodings achieve hole filling but require long training times. PARAMETRIC encodings allow fast training, but fail to complete unobserved regions. JOINT coordinate and para-metric encoding (Ours) allows smooth scene completion and fast training. NICE-SLAM [42] uses a dense parametric encoding. ness and coherence priors inherently encoded in the MLP weights, they constitute a good choice for sequential track-ing and mapping [26]. However, the weakness of MLP-based approaches is the long training times required (some-times hours) to learn a single scene. For that reason, re-cent real-time capable SLAM systems built on coordinate networks with frequency embeddings such as iMAP [26] need to resort to strategies to sparsify ray sampling and re-duce tracking iterations to maintain interactive operation.
This comes at the cost of loss of detail in the reconstruc-tions which are oversmoothed (Fig. 5) and potential errors in camera tracking.
Optimizable feature grids, also known as parametric embeddings, have recently become a powerful alternative scene representation to monolithic MLPs, given their ability to represent high-fidelity local features and their extremely fast convergence (orders of magnitude faster) [7, 10, 15, 32, 40]. Recent efforts focus on sparse alternatives to these parametric embeddings such as octrees [28], tri-plane [2], hash-grid [15] or sparse voxel grid [12, 13] to improve the memory efficiency of dense grids. While these represen-tations can be fast to train and are therefore well suited to real-time operation, they fundamentally lack the smooth-ness, and coherence priors inherent to MLPs and strug-gle with hole-filling in areas without observation. NICE-SLAM [42] is a recent example of a multi-resolution fea-ture grid-based SLAM method. Although it does not suffer from over-smoothness and captures local detail (as shown in Fig. 2) it cannot perform hole-filling which might in turn lead to drift in camera pose estimation.
Our first contribution is to design a joint coordinate and sparse grid encoding for input points that brings together the benefits of both worlds to the real-time SLAM frame-work. On the one hand, the smoothness and coherence pri-ors provided by coordinate encodings (we use one-blob [16] encoding), and on the other hand the optimization speed and local details of sparse feature encodings (we use hash grid [15]), resulting in more robust camera tracking and high-fidelity maps with better completion and hole filling.
Our second contribution relates to the bundle adjustment (BA) step in the joint optimization of the map and cam-era poses. So far, all neural SLAM systems [26, 42] per-form BA using rays sampled from a very small subset of selected keyframes. Restricting the optimization to a very small number of viewpoints results in decreased robustness in camera tracking and increased computation due to the need for a keyframe-selection strategy. Instead, Co-SLAM performs global BA, sampling rays from all past keyframes, which results in an important boost in robustness and per-formance in pose estimation.
In addition, we show that our BA optimization requires a fraction of the iterations of
NICE-SLAM [42] to achieve similar errors. In practice, Co-SLAM achieves SOTA performance in camera tracking and 3D reconstruction while maintaining real time performance.
Co-SLAM runs at 15-17Hz on Replica and Syn-thetic RGB-D datasets [1], and 12-13Hz on ScanNet [5] and TUM [25] scenes — faster than NICE-SLAM (0.1-1Hz)
[42] and iMAP [26]. We perform extensive evaluations on various datasets (Replica [24], Synthetic
RGBD [1], ScanNet [6], TUM [25]) where we outperform
NICE-SLAM [42] and iMAP [26] in reconstruction and achieve better or at least on-par tracking accuracy. 2.