Abstract
We present ObjectMatch1, a semantic and object-centric camera pose estimator for RGB-D SLAM pipelines. Mod-ern camera pose estimators rely on direct correspondences of overlapping regions between frames; however, they can-not align camera frames with little or no overlap. In this work, we propose to leverage indirect correspondences ob-tained via semantic object identification. For instance, when an object is seen from the front in one frame and from the back in another frame, we can provide additional pose constraints through canonical object correspondences. We first propose a neural network to predict such correspon-dences on a per-pixel level, which we then combine in our energy formulation with state-of-the-art keypoint matching solved with a joint Gauss-Newton optimization. In a pair-wise setting, our method improves registration recall of state-of-the-art feature matching, including from 24% to 45% in pairs with 10% or less inter-frame overlap. In regis-tering RGB-D sequences, our method outperforms cutting-edge SLAM baselines in challenging, low-frame-rate sce-narios, achieving more than 35% reduction in trajectory er-ror in multiple scenes. 1https://cangumeli.github.io/ObjectMatch/ 1.

Introduction
RGB-D registration and 3D SLAM has been a funda-mental task in computer vision, with significant study and enabling many applications in mixed reality, robotics, and content creation. Central to both state-of-the-art traditional and learning-based camera pose estimation is establishing correspondences between points in input frames. However, correspondence estimation remains quite challenging when there is little or no overlap between frames.
In contrast, humans can easily localize across these chal-lenging scenarios by leveraging additional semantic knowl-edge – in particular, by further localizing at the level of ob-jects and identifying matching objects between views. For instance, when observing a chair from the back and the side (e.g., in Figure 1), view overlap is minimal (or even no view overlap), resulting in failed registration from keypoint matching. However, the semantic knowledge of the chair and its object pose nonetheless enables humans to estimate the poses from which the front and side views were taken.
Thus, we propose to take a new perspective on camera pose estimation and imbue camera registration with awareness of such semantic correspondences between objects for robust performance in these challenging scenarios.
To this end, we propose ObjectMatch, a new paradigm for camera pose estimation leveraging canonical object cor-respondences in tandem with local keypoint correspon-dences between views. This enables significantly more robust registration under a variety of challenging scenar-ios, including low view overlap. For a sequence of in-put frames, ObjectMatch learns to semantically identify ob-jects across frames, enabling a compact, global parame-terization of 9-DoF object poses. Object correspondences are established through predicting normalized object coor-dinates [43], dense correspondences from object pixels to a canonically oriented space for each object. We then for-mulate a joint camera and object pose optimization that constrains object correspondences indirectly, operating ir-respective of the shared visibility of image regions. Our approach is complementary to state-of-the-art SLAM meth-ods, and we leverage our energy formulation to comple-ment state-of-the-art keypoint matching [10, 11, 36] in a joint Gauss-Newton optimization.
Our method outperforms strong baselines in both pair-wise registration and registration of RGB-D frame se-quences.
In pairwise registration of challenging Scan-Net [9] image pairs, we improve pose recall from 24% to 45% when the overlap is below 10%. On sequence registra-tion of room-scale RGB-D scenes, our method outperforms various strong baselines in difficult, low-frame-rate settings in several TUM-RGBD [39] and ScanNet [9] scenes, re-ducing the trajectory error by more than 35% in multiple challenging scenes.
To sum up, our main contributions include:
• An object-centric camera pose estimator that can han-dle low-overlap frame sets via indirect, canonical ob-ject correspondences established with predicted dense, per-pixel normalized object coordinates.
• A joint energy formulation that leverages semantic ob-ject identification and dense, normalized object coor-dinates corresponding to canonical object geometries.
• Our semantic grounding of object correspondences enables significantly more robust registration in low-overlap and low-frame-rate cases. ObjectMatch im-proves over state of the art from 24% to 45% registra-tion recall of ≤ 10% overlap frame pairs and achieves over 35% trajectory error reduction in several chal-lenging sequences. 2.