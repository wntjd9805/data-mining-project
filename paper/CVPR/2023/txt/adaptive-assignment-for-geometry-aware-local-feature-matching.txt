Abstract
The detector-free feature matching approaches are cur-rently attracting great attention thanks to their excellent performance. However, these methods still struggle at large-scale and viewpoint variations, due to the geomet-the ric inconsistency resulting from the application of mutual nearest neighbour criterion (i.e., one-to-one as-signment) in patch-level matching. Accordingly, we in-troduce AdaMatcher, which first accomplishes the fea-ture correlation and co-visible area estimation through an elaborate feature interaction module, then performs adaptive assignment on patch-level matching while es-timating the scales between images, and finally refines the co-visible matches through scale alignment and sub-pixel regression module.
Extensive experiments show that AdaMatcher outperforms solid baselines and achieves state-of-the-art results on many downstream tasks. Ad-ditionally, the adaptive assignment and sub-pixel refine-ment module can be used as a refinement network for other matching methods, such as SuperGlue, to boost their per-formance further. The code will be publicly available at https://github.com/AbyssGaze/AdaMatcher. 1.

Introduction
Establishing accurate correspondences for local features between image pairs is an essential basis for a broad range of computer vision tasks, including visual localization, structure from motion (SfM), simultaneous localization and mapping (SLAM), etc. However, achieving reliable and ac-curate feature matching is still challenging due to various factors such as scale changes, viewpoint diversification, il-lumination variations, repetitive patterns, and poor texture.
Existing image matching pipelines are mainly divided
*These authors contributed equally.
†Corresponding author.
Figure 1. An illustration of one-to-one assignment and adap-tive assignment. Under viewpoint changes or scale variations, one-to-one assignment leads to geometric inconsistency in patch-level feature matching, while adaptive assignment does not. For example, with one-to-one assignment, patch pair (pA, pC 2 ) is treated as a negative example, even though both pC 1 and pC 2 are projected into pA of I A. Such a matching rule is inconsistent with two-view and multi-view projective geometry. into two types: detector-based and detector-free. The for-mer is to build matches on detected and described sparse keypoints [8, 19, 20, 23, 26, 32]. However, as the detector-based matching pipeline relies on the reliability of key-point detectors and features description, it tends to per-form poorly under large viewpoint changes or scale vari-ations. For the latter, the detector-free matching pipeline can take full advantage of the rich context to establish corre-spondence between images end-to-end [6,13,24,25,29–31], without independent keypoint detection and feature descrip-tion steps. To achieve efficiency and accurate matching, the
SOTA detector-free matching pipelines [6,11,13,29,30] use a coarse-to-fine structure, in which the patch-level matches are first obtained using the mutual nearest neighbor crite-rion, and then are refined to a sub-pixel level. 1 and pC
Although these methods have improved considerably in performance, they still perform unsatisfactorily in extreme cases (e.g., large viewpoint changes and scale changes).
This is due to the fact that applying the mutual nearest neighbor criterion (ie, one-to-one correspondence) in patch-level matching leads to geometric inconsistencies and dif-ficulties in obtaining sufficient high-quality matches under large-scale or viewpoint variations. As shown in Fig.1, where I A, I B, I C are from the same scene, pC 2 of
I C are both projected into pA of I A. However, when the mutual nearest neighbour criterion is applied in the train-ing process, the patch pair (pA, pC 1 ) is treated as a positive sample, while the patch pair (pA, pC 2 ) is treated as a neg-ative sample. The incorrect assignment leads to two-view geometric inconsistency. Deeply, from a multi-view per-spective, (pA, pB) and (pB, pC 2 ) are positive samples while (pA, pC 2 ) is a negative sample, which leads to multi-view geometric inconsistency between multiple image pairs. For inference, when there are large viewpoint changes or scale variations, one-to-one matching is difficult to obtain enough inliers to ensure accurate camera pose estimation. Further-more, when applied to multi-view-based downstream tasks (e.g., SfM and 3D reconstruction), one-to-one patch-level correspondences do not guarantee the consistency of multi-view matching, which is likely to make the mapping fail or the bundle adjustment difficult to converge.
Inspired by the above consideration, we present
AdaMatcher, a geometry aware local feature matching ap-proach, targeting at mitigating potential geometry mismatch between image pairs without scale-alignment preprocess-ing or viewpoint warping. Different from dual-softmax or optimal transport in [28, 29] which guarantees one-to-one correspondence, we allow adaptive assignment (including many-to-one and one-to-one) at patch-level matching dur-ing training and inference. When the scale or viewpoint changes significantly, the adaptive assignment can guaran-tee matching accuracy. The smooth scale transition from many-to-one matches between image pairs can be adopted to resolve scale inconsistencies. Furthermore, the structure of our delicately designed feature interaction module cou-ples co-visible feature decoding with cross-feature interac-tion, allowing the probability map of the co-visible region to be obtained later by a simple module to filter out matches outside co-visible areas. To summarize, we aim to provide several critical insights of matching local features across scales and viewpoints:
• We propose a detector-free matching approach
AdaMatcher that allows a patch-level adaptive assign-ment followed by a sub-pixel refinement to guaran-tee the establishment of geometry aware feature cor-respondences.
• We introduce a novel feature interaction structure, which couples the co-visible feature decoding and cross-feature interaction. The probability map of the co-visible area can be obtained later by an additional module.
• Extensive experiments and analysis demonstrate that
AdaMatcher outperforms various strong baselines and achieves SOTA results for many downstream vision tasks. 2.