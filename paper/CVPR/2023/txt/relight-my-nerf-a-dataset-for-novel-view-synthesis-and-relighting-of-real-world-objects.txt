Abstract 1.

Introduction
In this paper, we focus on the problem of rendering novel views from a Neural Radiance Field (NeRF) under unob-served light conditions. To this end, we introduce a novel dataset, dubbed ReNe (Relighting NeRF), framing real world objects under one-light-at-time (OLAT) conditions, annotated with accurate ground-truth camera and light poses. Our acquisition pipeline leverages two robotic arms holding, respectively, a camera and an omni-directional point-wise light source. We release a total of 20 scenes depicting a variety of objects with complex geometry and challenging materials. Each scene includes 2000 images, acquired from 50 different points of views under 40 different
OLAT conditions. By leveraging the dataset, we perform an ablation study on the relighting capability of variants of the vanilla NeRF architecture and identify a lightweight archi-tecture that can render novel views of an object under novel light conditions, which we use to establish a non-trivial baseline for the dataset. Dataset and benchmark are avail-able at https://eyecan-ai.github.io/rene.
Inverse rendering [29, 47, 52, 73] addresses the problem of estimating the physical attributes of an object, such as its geometry, material properties and lighting conditions, from a set of images or even just a single one. This task is a longstanding problem for the vision and graphics commu-nities, since it unlocks the creation of novel renderings of an object from arbitrary viewpoints and under unobserved lighting conditions. An effective and robust solution to this problem would have significant value for a wide range of applications in gaming, robotics and augmented reality.
Recently, Neural Radiance Fields (NeRF) [36] has con-tributed tremendously to the novel view synthesis sub-task of inverse rendering pipelines. By mapping an input 5D vector (3D position and 2D viewing direction) to a 4D con-tinuous field of volume density and color by means of a neu-ral network, NeRF learns the geometry and appearance of a single scene from a set of posed images. The appealing re-sults in novel view synthesis have attracted a lot of attention from the research community and triggered many follow-up
∗ Joint first authorship. ⋄ Work done while at Eyecan.ai
Dataset
Multiple categories
Real-World