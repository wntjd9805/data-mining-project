Abstract
Estimating depth from four large ﬁeld of view (FoV) cam-eras has been a difﬁcult and understudied problem. In this paper, we proposed a novel and simple system that can con-vert this difﬁcult problem into easier binocular depth esti-mation. We name this system OmniVidar, as its results are similar to LiDAR, but rely only on vision. OmniVidar con-tains three components: (1) a new camera model to address the shortcomings of existing models, (2) a new multi-ﬁsheye camera based epipolar rectiﬁcation method for solving the image distortion and simplifying the depth estimation prob-lem, (3) an improved binocular depth estimation network, which achieves a better balance between accuracy and efﬁ-ciency. Unlike other omnidirectional stereo vision methods,
OmniVidar does not contain any 3D convolution, so it can achieve higher resolution depth estimation at fast speed.
Results demonstrate that OmniVidar outperforms all other methods in terms of accuracy and performance. 1.

Introduction
Depth estimation from images is an important research
ﬁeld in computer vision, as it enables the acquisition of depth information with low-cost cameras for a wide range of applications. Traditional stereo cameras with pinhole lenses are limited in their FoV. However, many scenarios require an omnidirectional depth map, such as autonomous driving [42] and robot navigation [13, 43]. Although there are active sensors available that can provide omnidirectional depth information, such as LiDAR [25], their high cost makes them less accessible than stereo vision. Passive sen-sors, such as RGB cameras, are a common choice for depth estimation due to their low cost, lightweight, and low power consumption. To increase the FoV, ﬁsheye lenses are often introduced into stereo vision setups.
Over the past few decades, various methods have been proposed for depth estimation using ﬁsheye cameras. These
*Corresponding author.
Figure 1. Our prototype that built with four 250◦ ﬁsheye cameras and its results of dense inverse distance map and cloud points. It can get great depth estimation results in real scenes and achieve real-time performance on modern GPU. include the binocular ﬁsheye system [31], up-down ﬁsheye system [13], and catadioptric cameras [17, 23, 32]. How-ever, all of these approaches have limitations. The binoc-ular ﬁsheye system cannot provide an omnidirectional per-ception. The up-down ﬁsheye system and catadioptric cam-eras can offer horizontal 360◦ depth perception, but their vertical FoV is limited. Furthermore, catadioptric cameras tend to be bulky, challenging to calibrate, and prone to er-rors. It turns out that the best choice for omnidirectional depth estimation is a system consisting of four cameras with extremely wide FoV (> 180◦). This system enables
360◦ depth estimation both horizontally and vertically, and is light-weight, convenient to calibrate and maintain. Sev-eral studies [21,29,39,41] have shown excellent results with this approach. However, these methods often use many 3D convolutions, resulting in low efﬁciency. To adapt to lim-ited memory, the images must be down-sampled, leading to a lower resolution of the output depth map. Furthermore, many of these approaches perform depth estimation using the original ﬁsheye image without explicitly processing im-age distortion, which leads to the construction of a tedious and complicated cost volume and can result in reduced ac-curacy.
Moreover, due to the complex imaging process of large
FoV ﬁsheye lenses, handling ﬁsheye image distortion using mathematical formulas can be a challenging task. While several excellent large FoV ﬁsheye camera models have been proposed [2, 18, 19, 27, 30, 36], our experiments have shown that none of these models can accurately approxi-mate the imaging process, and we get less satisfactory depth estimation results when using them.
Inspired by the above observations, we propose Om-niVidar, a novel and simple multi-ﬁsheye omnidirectional depth estimation system, as shown in Figure 2. OmniVi-dar contains three components. Firstly, we improve the
DSCM [36] and propose a new camera model, named Triple
Sphere Camera Model (TSCM), which can better approx-imate the imaging process and achieve the best accuracy.
Then we propose an epipolar rectiﬁcation algorithm de-signed for multi-ﬁsheye camera system. We leverage a cubic-like projection approach to transform the four ﬁsh-eye camera systems into four binocular camera systems and then conduct epipolar rectiﬁcation on each binocular sys-tem. This method solves the distortion issue and reduces the complex multi-ﬁsheye omnidirectional depth estimation problem to a much simpler binocular depth estimation prob-lem. Finally, we design a lightweight binocular depth esti-mation network based on RAFT [35]. We add Transformer encoder [37] into feature extraction in RAFT to combine the advantages of Transformer and GRU, and it’s easy to balance the accuracy and efﬁciency.
We compare OmniVidar with existing methods on sev-eral datasets. The results demonstrate that our method out-performs all the others in terms of speed and accuracy, achieving State-of-The-Art performance. 2.