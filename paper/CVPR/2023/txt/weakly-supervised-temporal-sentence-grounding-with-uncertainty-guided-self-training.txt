Abstract
The task of weakly supervised temporal sentence ground-ing aims at finding the corresponding temporal moments of a language description in the video, given video-language correspondence only at video-level. Most existing works se-lect mismatched video-language pairs as negative samples and train the model to generate better positive proposals that are distinct from the negative ones. However, due to the complex temporal structure of videos, proposals distinct from the negative ones may correspond to several video seg-ments but not necessarily the correct ground truth. To alle-viate this problem, we propose an uncertainty-guided self-training technique to provide extra self-supervision signal to guide the weakly-supervised learning. The self-training process is based on teacher-student mutual learning with weak-strong augmentation, which enables the teacher net-work to generate relatively more reliable outputs compared to the student network, so that the student network can learn from the teacher’s output. Since directly applying existing self-training methods in this task easily causes error accu-mulation, we specifically design two techniques in our self-training method: (1) we construct a Bayesian teacher net-work, leveraging its uncertainty as a weight to suppress the noisy teacher supervisory signals; (2) we leverage the cy-cle consistency brought by temporal data augmentation to perform mutual learning between the two networks. Exper-iments demonstrate our method’s superiority on Charades-STA and ActivityNet Captions datasets. We also show in the experiment that our self-training method can be applied to improve the performance of multiple backbone methods. 1.

Introduction
One of the most important directions in video under-standing is to temporally localize the start and end times-tamp of a given sentence description. Also known as tempo-ral sentence grounding, this task has a wide range of poten-* equal contribution. Author order is determined by a coin toss.
Figure 1. (a) Existing methods [70, 71] find it hard to distinguish the two cases since they learn positive proposals purely based on negative proposals. (b) Our method provides extra supervision sig-nals for learning positive proposals. (c) Performance of the back-bone network [71], backbone network trained with existing self-training methods pseudo labeling [29], Mean Teacher (MT) [50], and backbone network trained with our method. Directly apply-ing self-training methods for semi-supervised learning negatively influences the performance, while our self-training method can im-prove the backbone performance. tial applications ranging from video summarization [45,66], video action segmentation [23, 28, 59], to Human-computer interaction systems [8, 22, 30, 52, 63]. While most existing works deal with this task in a supervised manner, manually annotating temporal labels of the starting and ending times-tamps of each sentence is extremely laborious, which harms the scalability and viability of this task in real-world appli-cations. To escalate practicability, recent research attention has been drawn towards weakly supervised temporal sen-tence grounding, where video-language correspondence is given as annotation only at video-level for model training.
Previous weakly supervised temporal sentence ground-ing works [16,21,36,38] mainly adopt the multiple instance learning (MIL) method. They generate mismatched video-language pairs as negative samples and train the model to distinguish the positive/negative samples, in order to learn a cross-modal latent space for a language feature to highlight a certain time period of the video. Some methods find neg-ative samples by selecting sentences that describe another
video [38, 62], but these negative samples are often easy to distinguish and thus cannot provide strong supervision sig-nals. Recent works [68, 70, 71] select negative samples by sampling video segments within the same video, allowing the model to distinguish more confusing video segments.
One major limitation of these methods is that they learn the models completely depending on negative samples, since the objectives of these methods are to generate posi-tive proposals that are distinct from the negative ones, where the distance is usually measured by a certain metric such as the ability to reconstruct the query using only the video seg-ment inside the proposal [32, 60, 70, 71]. However, due to the complex temporal structure of videos that often contain multiple events, being distinct from the negative proposals does not always guarantee the quality of the positive pro-posals. For example in Figure 1(a), it is hard for existing methods like [70, 71] to distinguish the two cases since in both cases the positive proposals can better reconstruct the query sentence than the negative proposals.
However, in the absence of strong supervision, it is not straightforward to positively guide the process of temporal sentence grounding. Our solution is to leverage self-training to produce extra supervision signals (Figure 1(b)). As for self-training, one may consider to directly apply existing techniques originally designed for semi-supervised learn-ing such as pseudo label [29] or Mean Teacher with weak-strong augmentation [50]. However, as shown in Figure 1(c), our preliminary experiment suggests that the teacher’s supervision tends to be noisy and would degrade perfor-mance due to error accumulation. This is mainly because unlike semi-supervised learning [72], no strong supervision is used for initializing the teacher network.
Following previous works [12, 31, 34, 50], our method also apply the weak-strong augmentation technique, where the student network takes data with strong augmentation as input, while the teacher network gets as input weakly aug-mented data. Thus, compared to the student network, the teacher network can generate output less affected by heavy augmentation, providing supervisory guidance to the stu-dent network. To realize self-training in the weakly super-vised temporal sentence grounding task, we specifically de-sign the following two techniques: (1) As the teacher net-work itself is initially trained with only weak supervision and may generate erroneous supervision signals, we apply a Bayesian teacher network, enabling an uncertainty esti-mation of its output. The estimated uncertainty is used to weigh the teacher supervision signal thus reducing the chance of error accumulation. (2) To efficiently update both networks, we develop cyclic mutual learning, where the for-ward cycle forces the student network to output temporally consistent representations with the teacher, and the back-ward cycle encourages the teacher’s output to be consistent with the average of multiple student outputs generated by inputs with different augmentations. This mutual-learning method allows the teacher to update more carefully than the student, preventing over-fitting to the low-quality supervi-sion. On the other hand, a better teacher will provide reli-able uncertainty measures for learning the student network.
Our self-training technique can be applied to most exist-ing methods and we observe performance improvement on multiple public datasets.
Our contributions can be summarized as follows: (1) We propose a novel method for temporal sentence grounding based on self-training. To the best of our knowledge, this is the first attempt to apply self-training to the weakly su-pervised temporal sentence grounding task. (2) To realize self-training for this task, we design a Bayesian teacher net-work to alleviate the negative effect of low-quality teacher supervision, and we use a mutual-learning strategy based on the consistency of the data augmentation to better update the teacher and student networks. (3) Our experiments on two standard datasets Charades-STA and ActivityNet Cap-tions demonstrate that our method can effectively improve the performance of existing weakly supervised methods. 2.