Abstract
Arbitrary-scale image super-resolution (SR) is often tackled using the implicit neural representation (INR) ap-proach, which relies on a position encoding scheme to im-prove its representation ability. In this paper, we introduce orthogonal position encoding (OPE), an extension of po-sition encoding, and an OPE-Upscale module to replace the INR-based upsampling module for arbitrary-scale im-age super-resolution. Our OPE-Upscale module takes 2D coordinates and latent code as inputs, just like INR, but does not require any training parameters. This parameter-free feature allows the OPE-Upscale module to directly perform linear combination operations, resulting in con-tinuous image reconstruction and achieving arbitrary-scale image reconstruction. As a concise SR framework, our method is computationally efficient and consumes less mem-ory than state-of-the-art methods, as confirmed by exten-sive experiments and evaluations. In addition, our method achieves comparable results with state-of-the-art methods in arbitrary-scale image super-resolution. Lastly, we show that OPE corresponds to a set of orthogonal basis, validat-ing our design principle. 1 1.

Introduction
Photographs are composed of discrete pixels of vary-ing precision due to the limitations of sampling frequency, which breaks the continuous visual world into discrete parts. The single image super-resolution (SISR) task aims to restore the original continuous world in the image as
In an arbitrary-scale SR task, one of-much as possible. ten reconstructs the continuous representation of a low-resolution image and then adjusts the resolution of the target image as needed. The recent rise of implicit neural repre-sentation (INR) in 3D vision has enabled the representation
*Corresponding author. 1Project page: https://github.com/gaochao-s/ope-sr of complex 3D objects and scenes in a continuous man-ner [14,19,41,42,44,45,47,49,57,58], which also opens up possibilities for continuous image and arbitrary-scale image super-resolution [5, 18, 32, 72].
Existing methods for arbitrary-scale SR typically use a post-upsampling framework [70].
In this approach, low-resolution (LR) images first pass through a deep CNN network (encoder) without improving the resolution, and then pass through an INR-based upsampling module (de-coder) with a specified target resolution to reconstruct high-resolution (HR) images. The decoder establishes a mapping from feature maps (the output of encoder) to target image pixels using a pre-assigned grid partitioning and achieves arbitrary-scale with the density of the grid in Cartesian co-ordinate system. However, the INR approach has a defect of learning low-frequency information, also known as spectral bias [50]. To address this issue, sinusoidal positional en-coding is introduced to embed input coordinates to higher dimensions and enable the network to learn high-frequency details. This inspired recent works on arbitrary-scale SR to further improve the representation ability [32, 72].
Despite its effectiveness in arbitrary-scale SR, the INR-based upsampling module increases the complexity of the entire SR framework as two different networks are jointly trained. Additionally, as a black-box model, it represents a continuous image with a strong dependency on both the feature map and the decoder (e.g., MLP). However, its rep-resentation ability decreases after flipping the feature map, a phenomenon known as flipping consistency decline. As shown in Fig. 1, flipping the feature map horizontally be-fore the upsampling module of LIIF results in a blurred tar-get image that does not have the expected flip transforma-tion. This decline could be due to limitations of the MLP in learning the symmetry feature of the image.
MLP is a universal function approximator [17], which tries to fit a mapping function from feature map to the con-tinuous image, therefore, it is reasonable to assume that such process could be solved by an analytical solution. In this paper, we re-examine position encoding from the per-spective of orthogonal basis and propose orthogonal posi-tion encoding (OPE) for continuous image representation.
The linear combination of 1D latent code and OPE can directly reconstruct continuous image patch without using implicit neural function [5]. To prove OPE’s rationality, we analyse it both from functional analysis and 2D-Fourier transform. We further embed it into a parameter-free up-sampling module, called OPE-Upscale Module, to replace
INR-based upsampling module in deep SR framework, then currently deep SR framework can be greatly simplified.
Unlike the state-of-the-art method by Lee et al. [32], which enhances MLP with position encoding, we explore the possibility of extending position encoding without MLP.
By providing a more concise SR framework, our method achieves high computing efficiency and consumes less memory than the state-of-the-art, while also achieving com-parable image performance in arbitrary-scale SR tasks.
Our contributions are as follows:
• We propose a novel position encoding, called orthogo-nal position encoding (OPE), which takes the form of a 2D-Fourier series and corresponds to a set of orthog-onal basis. Building on OPE, we introduce the OPE-Upscale Module, a parameter-free upsampling module for arbitrary-scale image super-resolution.
• Our method significantly reduces the consumption of computing resources, resulting in high computing effi-ciency for arbitrary-scale SR tasks.
• The OPE-Upscale Module is interpretable, parameter-free and does not require training, resulting in a con-cise SR framework that elegantly solves the flipping consistency problem.
• Extensive experiments demonstrate that our method achieves comparable results with the state-of-the-art.
Furthermore, our method enables super-resolution up to a large scale of ×30. 2.