Abstract
Videos stored on mobile devices or delivered on the In-ternet are usually in compressed format and are of various unknown compression parameters, but most video super-resolution (VSR) methods often assume ideal inputs result-ing in large performance gap between experimental set-tings and real-world applications.
In spite of a few pio-neering works being proposed recently to super-resolve the compressed videos, they are not specially designed to deal with videos of various levels of compression.
In this pa-per, we propose a novel and practical compression-aware video super-resolution model, which could adapt its video enhancement process to the estimated compression level.
A compression encoder is designed to model compression levels of input frames, and a base VSR model is then condi-tioned on the implicitly computed representation by insert-ing compression-aware modules. In addition, we propose to further strengthen the VSR model by taking full advan-tage of meta data that is embedded naturally in compressed video streams in the procedure of information fusion. Ex-tensive experiments are conducted to demonstrate the ef-fectiveness and efficiency of the proposed method on com-pressed VSR benchmarks. The codes will be available at https://github.com/aprBlue/CAVSR 1.

Introduction
Video super-resolution aims at restoring a sequence of high-resolution (HR) frames by utilizing the comple-mentary temporal information within low-resolution (LR) frames. There have been many efforts [1–3, 7, 13, 15–18, 20, 24, 35, 38, 47] made on this task, especially after the rise of deep learning. Most of these methods, however,
*T. ISOBE and Y. WANG contributed equally to this work.
†Corresponding author. (a) Application scenario of
Figure 1. Motivation of this work. the VSR task this work focuses on, (b) performance of existing
VSR methods on compressed VSR task, and (c) performance of previous VSR models trained on videos of different compression. assume an ideal input such as directly taking either bicu-bicly downsampled frames or Gaussian smoothed and dec-imated ones as the degraded inputs. In real world, videos stored on mobile devices or delivered on the Internet are all in a compressed format with different compression lev-els [10, 11, 14, 25, 30, 33, 41, 45]. Unless the compression is very lightweight, directly applying an existing VSR model would give unsatisfactory results with magnified compres-sion artifacts, as shown in Fig. 1(a). One straightforward so-lution is to first apply a multi-frame decompression method
[5, 9, 41, 45] to remove blocking artifacts and then feed the enhanced frames to an uncompressed VSR model. How-ever, as shown in Fig. 1(b), the performance is still not good with artifacts remained. In addition, the decompression net-work usually cannot handle video frames of different com-pression levels adaptively, which will cause over-smoothing
and accumulate errors in super-resolution stage.
Recently a few pioneering works have been proposed to investigate the video super-resolution task on compressed videos. In [46], Yang et al. took into consideration com-plex degradations in real video scenarios and built a real-world VSR dataset using iPhone 11 Pro Max. A special training strategy is proposed to handle misalignment and il-lumination/color difference. In RealBasicVSR [3], Chan et al. synthesized real-world-like low-quality videos based on a combination of several degradations and proposed a two-stage method with an image pre-cleaning module followed by an existing VSR model. COMISR [22] and FTVSR [27] are proposed to address streamed videos compressed in dif-ferent levels rather than degradations like noise and blur.
Although COMISR and FTVSR have improved perfor-mance on compressed videos, they are not specially de-signed to deal with videos of various levels of compres-sion. Being aware of compression with input videos would allow a model to exert its power on those videos adap-tively. Otherwise, video frames with less compression would be oversmoothed while the ones with heavy com-pression would still remain magnified artifacts, as shown in
Fig. 1(c). These methods feed themselves with only com-pressed video frames as input, however, meta data such as frame type, motion vectors and residual maps that are nat-urally encoded with a compressed video are ignored. Mak-ing full use of such meta data and the decoded video frames could help further improve super-resolution performance on compressed videos.
Based on the above observations, we propose a compression-aware video super-resolution model, a com-pression encoder module is designed to implicitly model compression level with the help of meta data of a com-pressed video. It would also take into account both frames and their frame types in computing compression represen-tation. A base bidirectional recurrent-based VSR model is then conditioned on that representation by inserting compression-aware modules such that it could adaptively deal with videos of different compression levels. To fur-ther strengthen the power of the base VSR model, we take advantage of meta data in a further step. Motion vectors and residual maps are employed to achieve fast and accu-rate alignment between different time steps and frame types are leveraged again to update hidden state in bidirectional recurrent network. Extensive experiments demonstrate that the specially designed VSR model for compressed videos performs favorably against state-of-the-art methods.
Our contributions are summarized as follows:
• A compression encoder to perceive compression levels of frames is proposed. It is supervised with a ranking-based loss and the computed compression representa-tion is used to modulate a base VSR model.
• Meta data that comes naturally with compressed videos are fully explored in fusion process of spatial and temporal information to strengthen the power of a bidirectional RNN-based VSR model.
• Extensive experiments demonstrate the effectiveness and efficiency of the proposed method on compressed
VSR benchmarks. 2.