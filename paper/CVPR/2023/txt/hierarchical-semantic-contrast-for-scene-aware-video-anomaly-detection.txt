Abstract
Increasing scene-awareness is a key challenge in video anomaly detection (VAD). In this work, we propose a hier-archical semantic contrast (HSC) method to learn a scene-aware VAD model from normal videos. We first incorporate foreground object and background scene features with high-level semantics by taking advantage of pre-trained video parsing models. Then, building upon the autoencoder-based reconstruction framework, we introduce both scene-level and object-level contrastive learning to enforce the en-coded latent features to be compact within the same seman-tic classes while being separable across different classes.
This hierarchical semantic contrast strategy helps to deal with the diversity of normal patterns and also increases their discrimination ability. Moreover, for the sake of tack-ling rare normal activities, we design a skeleton-based mo-tion augmentation to increase samples and refine the model further. Extensive experiments on three public datasets and scene-dependent mixture datasets validate the effectiveness of our proposed method. 1.

Introduction
With the prevalence of surveillance cameras deployed in public places, video anomaly detection (VAD) has at-tracted considerable attention from both academia and in-dustry.
It aims to automatically detect abnormal events so that the workload of human monitors can be greatly reduced. By now, numerous VAD methods have been developed under different supervision settings, including weakly supervised [13, 50, 55, 58, 64, 76], purely unsu-pervised [69, 72], and ones learning from normal videos only [20, 24, 33, 44, 45]. However, it is extremely diffi-cult or even impossible to collect sufficient and comprehen-sive abnormal data due to the rare occurrence of anomalies, whereas collecting abundant normal data is relatively easy.
Therefore, the setting of learning from normal data is more
*Corresponding author.
Figure 1. An illustration of hierarchical semantic contrast. The encoded scene-appearance/motion features are gathered together with respect to their semantic classes. Best viewed in color. practical and plays the dominant role in past studies.
Although a majority of previous techniques learn their
VAD models from normal data, this task has still not been well addressed due to the following reasons. First, implying some anomalies are scene-dependent [46, 51], that an appearance or motion may be anomalous in one scene but normal in other scenes. How to detect scene-dependent anomalies while preventing background bias (i.e. learning the background noise rather than the essence of anomaly [31]) is a challenging problem. Second, normal patterns are diverse. How to enable a deep VAD model to represent the diverse normality well but not generalize to anomalous data is also a challenge [18, 44]. Last but not least, samples collected from different normal patterns are imbalanced because some normal activities may appear very sparsely [46]. How to deal with rare but normal activ-ities is challenging as well.
Previous VAD methods mainly perform learning at frame-level [20, 47, 75] or in an object-centric [17, 24, 78] way. The former is prone to suffer from the background bias [31] while most of the latter methods are background-agnostic. There are some attempts to address the above-mentioned challenges in one or another aspect. For in-stance, a spatio-temporal context graph [51] and a hierar-chical scene normality-binding model [1] are constructed to discover scene-dependent anomalies. Memory-augmented autoencoders (AE) [18,44] are designed to represent diverse normal patterns while lessening the powerful capacity of
AEs. An over-sampling strategy [32] is adopted but to solve the imbalance between normal and abnormal data. Con-trastively, in this work we address all of these challenges simultaneously and in distinct ways.
The primary objective of our work is to handle scene-dependent anomalies. An intuition behind scene-dependent anomalies is that, if a type of object or activity is never observed in one scene in normal videos, then it should be viewed as an anomaly. It implies that we can first determine the scene type and then check if an object or activity has oc-curred in normal patterns of this scene. Based on this obser-vation, we propose a hierarchical semantic contrast method to learn a scene-aware VAD model. Taking advantage of pre-trained video parsing networks, we group the appear-ance and activity of objects and background scenes into se-mantic categories. Then, building upon the autoencoder-based reconstruction framework, we design both scene-level and object-level contrastive learning to enforce the en-coded latent features to gather together with respect to their semantic categories, as shown in Fig. 1. When a test video is input, we retrieve weighted normal features for reconstruc-tion and the clips of high errors are detected as anomalies.
The contributions of this work are as follows:
• We build a scene-aware reconstruction framework composed of scene-aware feature encoders and object-centric feature decoders for anomaly detection. The scene-aware encoders take background scenes into ac-count while the object-centric decoders are to reduce the background noise.
• We propose hierarchical semantic contrastive learn-ing to regularize the encoded features in the latent spaces, making normal features more compact within the same semantic classes and separable between dif-ferent classes. Consequently, it helps to discriminate anomalies from normal patterns.
• We design a skeleton-based augmentation method to generate both normal and abnormal samples based on our scene-aware VAD framework. The augmented samples enable us to additionally train a binary clas-sifier that helps to boost the performance further.
• Experiments on three public datasets demonstrate promising results on scene-independent VAD. More-over, our method also shows a strong ability in detect-ing scene-dependent anomalies on self-built datasets. 2.