Abstract
Recently, a surge of high-quality 3D-aware GANs have been proposed, which leverage the generative power of neu-ral rendering. It is natural to associate 3D GANs with GAN inversion methods to project a real image into the gener-ator’s latent space, allowing free-view consistent synthesis and editing, referred as 3D GAN inversion. Although with the facial prior preserved in pre-trained 3D GANs, recon-structing a 3D portrait with only one monocular image is still an ill-pose problem. The straightforward application of 2D GAN inversion methods focuses on texture similarity only while ignoring the correctness of 3D geometry shapes.
It may raise geometry collapse effects, especially when re-constructing a side face under an extreme pose. Besides, the synthetic results in novel views are prone to be blurry.
In this work, we propose a novel method to promote 3D
GAN inversion by introducing facial symmetry prior. We design a pipeline and constraints to make full use of the pseudo auxiliary view obtained via image flipping, which helps obtain a view-consistent and well-structured geome-try shape during the inversion process. To enhance texture fidelity in unobserved viewpoints, pseudo labels from depth-guided 3D warping can provide extra supervision. We de-sign constraints to filter out conflict areas for optimization in asymmetric situations. Comprehensive quantitative and qualitative evaluations on image reconstruction and editing demonstrate the superiority of our method. 1.

Introduction
Recent 3D-aware generative adversarial networks (3D
GANs) have seen immense progress. By incorporating a neural rendering engine into the generator network ar-chitecture, 3D GANs can synthesize view-consistent im-ages. To increase the generation resolution, existing meth-ods [5, 12, 25, 30, 31, 36±38, 41] boost the 3D inductive bias
Work done during an internship at Tencent AI Lab.
²Corresponding Author.
Figure 1. Visual examples of our inversion method. Direct apply-ing 2D GAN inversion methods (PTI [28]) to the 3D GAN suffers from inaccurate geometry in novel views. Our method excels in synthesizing consistent geometry and high-fidelity texture in dif-ferent views, even reconstructing a face under an extreme pose. with an additional 2D CNN-based upsampler or an efficient 3D representation modeling method. With tremendous ef-fort, 3D GANs can produce photorealistic images while en-forcing strong 3D consistency across different views.
We are interested in the task of reconstructing a human face with 3D geometry and texture given only one monocu-lar image. It is an ill-posed problem and close to the harsh condition of real scenarios. With the power of 3D GANs, it seems achievable via projecting a target image onto the manifold of a pre-trained generator. The process is referred as 3D GAN inversion. A straightforward path is to follow the 2D GAN inversion method [28], i.e., optimizing the la-tent code and the network parameters of the generator to overfit the specific portrait.
However, since the ground truth 3D geometry is absent given one monocular image, the inversion result is far from satisfactory. The process of fitting a 3D GAN to one im-age would sacrifice geometric correctness in order to make the synthetic texture as close as possible to the input, even destroying the original semantic-rich latent space. As the optimization process goes, the face geometry tends to de-generate into a flattened shape, due to the absence of geom-etry supervision, e.g., images from other views. Besides, there exist quality issues in texture synthesis under novel views. The rendered images of unseen views tend to be blurry and inconsistent with the original image, especially when reconstructing a side face under an extreme pose. Be-cause there is no texture supervision for unseen views given only one monocular image. The failure cases of directly applying [28] are illustrated in Fig. 1.
In this work, to alleviate the issue caused by missing ge-ometry and texture supervision under multiple views, we propose a novel 3D GAN inversion approach by taking full advantage of facial symmetry prior to construct pseudo su-pervision of different views. Intuitively, we note that human faces are almost symmetric. Assuming the given portrait is symmetric, we can obtain an additional perspective of the portrait by simply mirroring the image. The images of two distinct views can provide geometric relations between the 3D points and their 2D projections based on epipolar geom-etry. Motivated by this, we seek to leverage facial symmetry as the geometric prior constraining the inversion. The sym-metry prior is also employed in a traditional 3D reconstruc-tion work [35]. We leverage the mirrored image as extra supervision of another view when performing the inversion, which prevents the geometry collapse. A rough geometry can be obtained by the inversion with the original and mir-ror images.
To further enhance texture quality and geometry in novel views, we employ depth-guided 3D warping to generate the pseudo images of the views surrounding the input and sym-metric camera pose. The depth is inferred from the rough 3D volume. The original image along with the pseudo im-ages are used to fine-tune the generator’s parameters for the joint promotion of texture and geometry. To prevent the op-timized geometry from deviating too much from the rough geometry, we design a geometry regularization term as a constraint. However, human faces are never fully symmet-ric in practice, neither in shape nor appearance. Therefore, we design several constraints to extract meaningful infor-mation adaptively from the mirror image without compro-mising the original reconstruction quality.
Our main contributions are as follows:
• We propose a novel 3D GAN inversion method by in-corporating facial symmetry prior. It enables a high-quality reconstruction while preserving the multi-view consistency in geometry and texture.
• We conduct comprehensive experiments to demon-strate the effectiveness of our method and compare it with many state-of-the-art inversion methods. We also apply our method to various downstream applications. 2.