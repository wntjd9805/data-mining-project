Abstract
Foggy Clean
Foggy Patched
Deep learning models have shown extreme vulnerabil-ity to distribution shifts such as synthetic perturbations and spatial transformations. In this work, we explore whether we can adopt the characteristics of adversarial attack meth-ods to help improve robustness of object detection to dis-tribution shifts such as synthetic perturbations and spa-tial transformations. We study a class of realistic object detection settings wherein the target objects have control over their appearance. To this end, we propose a reversed
Fast Gradient Sign Method (FGSM) to obtain these angelic patches that significantly increase the detection probabil-ity, even without pre-knowledge of the perturbations. In de-tail, we apply the patch to each object instance simultane-ously, strengthening not only classification, but also bound-ing box accuracy. Experiments demonstrate the efficacy of the partial-covering patch in solving the complex bounding box problem. More importantly, the performance is also transferable to different detection models even under severe affine transformations and deformable shapes. To the best of our knowledge, we are the first object detection patch that achieves both cross-model efficacy and multiple patches.
We observed average accuracy improvements of 30% in the real-world experiments. Our code is available at: https:
//github.com/averysi224/angelic_patches. 1.

Introduction
Deep learning models have been heavily deployed in many safety-critical settings such as autonomous vehicles.
However, these models have been notoriously fragile to mild perturbations. For example, natural corruptions like weather conditions and simple lightning effects can signif-icantly degrade the performance of state-of-the-art mod-els [11, 14]. Similarly, the performance under small spa-tial transformations exhibits a large gap compared to clean benchmarks [2, 7, 15]. On the other hand, a set of carefully designed adversarial examples [10] are able to manipulate the prediction behavior arbitrarily without notice of human eyes. The untrustworthiness of deep learning systems leads
Angelic Patch
Figure 1. In this paper, we demonstrate that optimizing a partial-cover patch for pre-trained object detectors can improve robust-ness and significantly boost performance for both the classification and bounding box regression accuracy. In the left picture, one of the three people is mis-detected after applying the fog corruption.
However, in the right image with our angelic patch, the detector was able to detect all three people with even more accurate bound-ing boxes. Consider all three people wearing an angelic raincoat, we could save lives from the foggy-blinded autonomous car! to high stake failures and devastating consequences.
Two main streams of algorithms investigate solving these problems. One is to improve out-of-distribution behav-ior by adding more robustness interventions and diverse data during training. However, they do not fully close the gap between standard model performance and perturbed re-sults [8]. Others applied domain adaptation over covari-ate shift achieving reasonable performance [23], yet this method does not generalize on unseen domains. Whereas the misspecified test time distribution occurs dominantly in practice.
Motivated and inspired by the efficacy of these perturba-tion/adversarial methods above, we ask the question: Can we adopt the characteristics of adversarial attack methods to help improve perturbation-robustness? We propose to reconsider the problem setup itself and study in a scenario where the target objects are in control of their appearance.
To simplify, we build the objects instead of the models to improve detection reliability. As a concrete example, con-sider a pedestrian interacting with autonomous cars that use deep learning models for detection. Our approach is to pro-vide a wearable patch designed to improve the visibility of these people to these models (Figure 1). Such practices
Step 1: Apply patch.
Step 2: Apply corruption.
Step 1: Apply patch. (a) An example of corruption-aware angelic patch training procedure. (b) An example of corruption-agnostic angelic patch training.
Figure 2. Examples of the two considered methods for constructing angelic patches. In the corruption-aware setting, we compute loss by the predictions of the corrupted patched images. At test time, we test on the same type of corruption; In the corruption-agnostic setting, we compute loss by the predictions of the corrupted clean images. At test time, we test on arbitrary corruption. are already common for dealing with human driversâ€”e.g., wearing bright or reflective clothing at night.
Furthermore, though the adversarial attacks and robust-ness of classifiers are well-studied, we focus on the less studied yet practically broadly used object detection setting.
In detail, the detectors learn not only the object class infor-mation but also learn about the localization and the size of an object, e.g. bounding boxes. Besides, the object detec-tion problem is essentially multiple instances, causing im-plicit interaction between objects with even occlusions. To our knowledge, we are the first to systematically investigate this setting. We validated our method on both the single-stage detector and the two-stage detector that are with the proposal network as well as cross model experiments.
Our contribution is three-fold: First, we propose the novel angelic patches with a Reversed Fast Signed Gra-dient Method to improve the performance of both single-stage and two-stage third-party object detectors. Second, we demonstrate the efficacy of our framework on a wide va-riety of detection settings including dozens of synthetic cor-ruptions and affine transformations without additional aug-mentation during training. Third, we are the first defense physical patch that achieves cross-model validation on sev-eral state-of-the-art unseen models. We extensively evalu-ated our approach with both programmatic patches as well as real-world experiments. We believe our approach identi-fies a highly practical valuable strategy that can be used in a broad range of applications.
In the following sections, we start with a review of re-lated work, then give the proposed angelic patch framework and experiment results. After that, we conclude the paper. 2.