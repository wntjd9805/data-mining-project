Abstract
← Perceptual Quality
Fidelity →
Behavior of neural networks is irremediably determined by the specific loss and data used during training. How-ever it is often desirable to tune the model at inference time based on external factors such as preferences of the user or dynamic characteristics of the data. This is espe-cially important to balance the perception-distortion trade-off of ill-posed image-to-image translation tasks.
In this work, we propose to optimize a parametric tunable con-volutional layer, which includes a number of different ker-nels, using a parametric multi-loss, which includes an equal number of objectives. Our key insight is to use a shared set of parameters to dynamically interpolate both the ob-jectives and the kernels. During training, these parame-ters are sampled at random to explicitly optimize all possi-ble combinations of objectives and consequently disentan-gle their effect into the corresponding kernels. During in-ference, these parameters become interactive inputs of the model hence enabling reliable and consistent control over the model behavior. Extensive experimental results demon-strate that our tunable convolutions effectively work as a drop-in replacement for traditional convolutions in existing neural networks at virtually no extra computational cost, outperforming state-of-the-art control strategies in a wide range of applications; including image denoising, deblur-ring, super-resolution, and style transfer. 1.

Introduction
Neural networks are commonly trained by optimizing a set of learnable weights against a pre-defined loss function, often composed of multiple competing objectives which are delicately balanced together to capture complex behaviors from the data. Specifically, in vision, and in image restora-tion in particular, many problems are ill-posed, i.e. admit a potentially infinite number of valid solutions [15]. Thus, se-lecting an appropriate loss function is necessary to constrain neural networks to a specific inference behavior [39, 64].
However, any individual and fixed loss defined empirically before training is inherently incapable of generating opti-Figure 1. We propose a framework to build a single neural net-work that can be tuned at inference without retraining by interact-ing with controllable parameters, e.g. to balance the perception-distortion tradeoff in image restoration tasks. mal results for any possible input [43]. A classic example is the difficulty in finding a good balance for the perception-distortion trade-off [5, 64], as shown in the illustrative ex-ample of Fig. 1. The solution to this problem is to design a mechanism to reliably control (i.e. tune) neural networks at inference time. This comes with several advantages, namely providing a flexible behavior without the need to retrain the model, correcting failure cases on the fly, and balancing competing objectives according to user preference.
Existing approaches to control neural networks, com-monly based on weights [54, 55] or feature [53, 63] mod-ulation, are fundamentally limited to consider only two ob-jectives, and furthermore require the addition of a new set of layers or parameters for every additional loss consid-ered. Different approaches, specific to image restoration tasks, first train a network conditioned on the true degra-dation parameter of the image, e.g. noise standard deviation or blur size, and then, at inference time, propose to interact with these parameters to modulate the effects of the restora-tion [17, 24, 50]. However this leads the network to an un-defined state when asked to operate in regimes correspond-ing to combinations of input and parameters unseen during training [27].
In this work, we introduce a novel framework to reliably and consistently tune model behavior at inference time. We propose a parametric dynamic layer, called tunable convo-lution, consisting in p individual kernels (and biases) which we optimize using a parametric dynamic multi-loss, con-sisting in p individual objectives. Different parameters can be used to obtain different combinations of kernels and ob-jectives by linear interpolation. The key insight of our work is to establish an explicit link between the p kernels and objectives using a shared set of p parameters. Specifically, during training, these parameters are randomly sampled to explicitly optimize the complete loss landscape identified by all combinations of the p objectives. As a result, dur-ing inference, each individual objective is disentangled into a different kernel, and thus its influence can be controlled by interacting with the corresponding parameter of the tun-able convolution. In contrast to previous approaches, our strategy is capable of handling an arbitrary number of ob-jectives, and by explicitly optimizing all their intermediate combinations, it allows to tune the overall network behavior in a predictable and intuitive fashion. Furthermore, our tun-able layer can be used as a drop-in replacement for standard layers in existing neural networks with negligible difference in computational cost.
In summary the main contributions of our work are:
• A novel plug-and-play tunable convolution capable to reliably control neural networks through the use of in-teractive parameters;
• A unique parametric multi-loss optimization strategy dictating how tunable convolution should be optimized to disentangle the different objectives into the different tunable kernels;
• Extensive experimental validation across several image-to-image translation tasks demonstrating state-of-the-art performance for tunable inference. 2.