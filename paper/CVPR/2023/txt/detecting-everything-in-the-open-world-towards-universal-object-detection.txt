Abstract
In this paper, we formally address universal object de-tection, which aims to detect every scene and predict ev-ery category. The dependence on human annotations, the limited visual information, and the novel categories in the open world severely restrict the universality of traditional detectors. We propose UniDetector, a universal object de-tector that has the ability to recognize enormous categories in the open world. The critical points for the universal-ity of UniDetector are: 1) it leverages images of multi-ple sources and heterogeneous label spaces for training through the alignment of image and text spaces, which guar-antees sufficient information for universal representations. 2) it generalizes to the open world easily while keeping the balance between seen and unseen classes, thanks to abun-dant information from both vision and language modali-ties. 3) it further promotes the generalization ability to novel categories through our proposed decoupling train-ing manner and probability calibration. These contribu-tions allow UniDetector to detect over 7k categories, the largest measurable category size so far, with only about 500 classes participating in training. Our UniDetector be-haves the strong zero-shot generalization ability on large-vocabulary datasets - it surpasses the traditional supervised baselines by more than 4% on average without seeing any corresponding images. On 13 public detection datasets with various scenes, UniDetector also achieves state-of-the-art performance with only a 3% amount of training data. 1 1.

Introduction
Universal object detection aims to detect everything in every scene. Although existing object detectors [18, 31, 42,
*corresponding author 1Codes are available at https://github.com/zhenyuw16/UniDetector.
Figure 1. Illustration for the universal object detector. It aims to detect every category in every scene and should have the ability to utilize images of multiple sources with heterogeneous label spaces for training and generalize to the open world for inference. 43] have made remarkable progress, they heavily rely on large-scale benchmark datasets [12, 32]. However, object detection varies in categories and scenes (i.e., domains).
In the open world, where significant difference exists com-pared to existing images and unseen classes appear, one has to reconstruct the dataset again to guarantee the success of object detectors, which severely restricts their open-world generalization ability. In comparison, even a child can gen-eralize well rapidly in new environments. As a result, uni-versality becomes the main gap between AI and humans.
Once trained, a universal object detector can directly work in unknown situations without any further re-training, thus significantly approaching the goal of making object detec-tion systems as intelligent as humans.
A universal object detector should have the following two abilities. First, it should utilize images of multiple
sources and heterogeneous label spaces for training. Large-scale collaborative training in classification and localization is required to guarantee that the detector can gain sufficient information for generalization.
Ideal large-scale learning needs to contain diversified types of images as many as pos-sible with high-quality bounding box annotations and large category vocabularies. However, restricted by human anno-tators, this cannot be achieved. In practice, unlike small vo-cabulary datasets [12,32], large vocabulary datasets [17,23] tend to be noisily annotated, sometimes even with the incon-sistency problem. In contrast, specialized datasets [8,55,70] only focus on some particular categories. To cover ade-quate categories and scenes, the detector needs to learn from all the above images, from multiple sources with heteroge-neous label spaces, so that it can learn comprehensive and complete knowledge for universality. Second, it should gen-eralize to the open world well. Especially for novel classes that are not annotated during training, the detector can still predict the category tags without performance degradation.
However, pure visual information cannot achieve the pur-pose since complete visual learning demands human anno-tations for fully-supervised learning.
In this paper, we formally address the task of univer-sal object detection. To realize the above two abilities of the universal object detector, two corresponding challenges should be solved. The first one is about training with multi-source images. Images collected from different sources are associated with heterogeneous label spaces. Existing detec-tors are only able to predict classes from one label space, and the dataset-specific taxonomy and annotation inconsis-tency among datasets make it hard to unify multiple het-erogeneous label spaces. The second one is about novel category discrimination. Motivated by the recent success of image-text pre-training [20, 39, 58], we leverage their pre-trained models with language embeddings for recogniz-ing unseen categories. However, fully-supervised training makes the detector focus on categories that appear during training. At the inference time, the model will be biased to-wards base classes and produce under-confident predictions for novel classes. Although language embeddings make it possible to predict novel classes, the performance of them is still far less than that of base categories.
We propose UniDetector, a universal object detection framework, to address the above two problems. With the help of the language space, we first investigate possible structures to train the detector with heterogeneous label spaces and discover that the partitioned structure promotes feature sharing and avoids label conflict simultaneously.
Next, to exploit the generalization ability to novel classes of the region proposal stage, we decouple the proposal gen-eration stage and RoI classification stage instead of training them jointly. Such a training paradigm well leverages their characteristics and thus benefits the universality of the de-tector. Under the decoupling manner, we further present a class-agnostic localization network (CLN) for producing generalized region proposals. Finally, we propose probabil-ity calibration to de-bias the predictions. We estimate the prior probability of all categories, then adjust the predicted category distribution according to the prior probability. The calibration well improves the performance of novel classes.
Our main contributions can be summarized as follows:
• We propose UniDetector, a universal detection frame-work that empowers us to utilize images of heteroge-neous label spaces and generalize to the open world.
To the best of our knowledge, this is the first work to formally address universal object detection.
• Considering the difference of generalization ability in recognizing novel classes, we propose to decouple the training of proposal generation and RoI classification to fully explore the category-sensitive characteristics.
• We propose to calibrate the produced probability, which balances the predicted category distribution and raises the self-confidence of novel categories.
Extensive experiments demonstrate the strong universal-ity of UniDetector. It recognizes the most measurable cat-egories. Without seeing any image from the training set, our UniDetector achieves a 4% higher AP on existing large-vocabulary datasets than fully-supervised methods. Besides the open-world task, our UniDetector achieves state-of-the-art results in the closed world - 49.3% AP on COCO with a pure CNN model, ResNet50, and the 1× schedule. 2.