Abstract
To defend the inference attacks and mitigate the sensitive information leakages in Federated Learning (FL), client-level Differentially Private FL (DPFL) is the de-facto stan-dard for privacy protection by clipping local updates and adding random noise. However, existing DPFL methods tend to make a sharper loss landscape and have poorer weight perturbation robustness, resulting in severe per-formance degradation. To alleviate these issues, we pro-pose a novel DPFL algorithm named DP-FedSAM, which leverages gradient perturbation to mitigate the negative im-pact of DP. Specifically, DP-FedSAM integrates Sharpness
Aware Minimization (SAM) optimizer to generate local flat-ness models with better stability and weight perturbation robustness, which results in the small norm of local up-dates and robustness to DP noise, thereby improving the performance. From the theoretical perspective, we ana-lyze in detail how DP-FedSAM mitigates the performance degradation induced by DP. Meanwhile, we give rigorous privacy guarantees with R´enyi DP and present the sensitiv-ity analysis of local updates. At last, we empirically confirm that our algorithm achieves state-of-the-art (SOTA) perfor-mance compared with existing SOTA baselines in DPFL. 1.

Introduction
Federated Learning (FL) [31] allows distributed clients to collaboratively train a shared model without sharing data. However, FL faces severe dilemma of privacy leak-age [27]. Recent works show that a curious server can also infer clients’ privacy information such as membership and data features, by well-designed generative models and/or shadow models [14, 37, 40, 44, 55]. To address this is-sue, differential privacy (DP) [12] has been introduced in
FL, which can protect every instance in any client’s data (instance-level DP [3,20,47,48]) or the information between
*Corresponding authors: Li Shen and Xueqian Wang clients (client-level DP [8, 15, 21, 25, 35, 52]). In general, client-level DP are more suitable to apply in the real-world setting due to a better model performance. For instance, a language prediction model with client-level DP [16, 35] has been applied on mobile devices by Google.
In gen-eral, the Gaussian noise perturbation-based method is com-monly adopted for ensuring the strong client-level DP. How-ever, this method includes two operations in terms of clip-ping the l2 norm of local updates to a sensitivity thresh-old C and adding random noise proportional to the model size, whose standard deviation (STD) is also decided by
C. These steps may cause severe performance degradation dilemma [9, 22], especially on large-scale complex model
[45], such as ResNet-18 [18], or with heterogeneous data.
The reasons behind this issue may be two-fold: (i) The useful information is dropped due to the clipping operation especially on small C, which is contained in the local up-dates; (ii) The model inconsistency among local models is exacerbated as the addition of random noise severely dam-ages local updates and leads to large variances between lo-cal models especially on large C [9]. To overcome these issues, existing works improve the performance via restrict-ing the norm of local update [9] and leveraging local up-date sparsification technique [9, 22] to reduce the adverse impacts of clipping and adding amount of random noise.
However, the model performance degradation remains sig-nificantly severe compared with FL methods without con-sidering the privacy, e.g., FedAvg [33].
Motivation. To further explore the reasons behind this phenomenon, we compare the structure of loss landscapes and surface contours [30] for FedAvg [33] and DP-FedAvg
[15,35] on partitioned CIFAR-10 dataset [28] with Dirichlet distribution (α = 0.6) and ResNet-18 backbone [18] in Fig-ure 1 (a) and (b), respectively. Note that the convergence of
DP-FedAvg is worse than FedAvg as its loss value is higher after a long communication round. Furthermore, FedAvg has a flatter landscape, whereas DP-FedAvg has a sharper one, resulting in poorer generalization ability (sharper min-ima, see Figure 1 (a)) and weight perturbation robustness
(a) Loss landscapes. (b) Loss surface contours.
Figure 1. Loss landscapes and surface contours comparison between DP-FedAvg (left) and FedAvg (right), respectively. (see Figure 1 (b)), which is caused by the clipped local up-date information and exacerbated model inconsistency, re-spectively. Based on these observations, an interesting re-search question is: can we further overcome the severe per-formance degradation via making landscape flatter?
√
+ L2
To answer this question, we propose DP-FedSAM via gradient perturbation to improve model performance.
Specifically, a local flat model is generated by using SAM optimizer [13] in each client, which leads to better sta-bility. After that, a potentially global flat model can be generated by aggregating several flat local models, which results in higher generalization ability and better robust-ness to DP noise, thereby significantly improving the per-formance and achieving a better trade-off between perfor-mance and privacy. Theoretically, we present a tighter g+ ˜αtL2) (cid:80)T t=1(αtσ2
T 2 1√
T σ2C2d
K
√ m2
+
KT (cid:80)T (cid:80)T t=1 αt and 1
T
) for DP-bound O(
FedSAM in the stochastic non-convex setting, where both 1 t=1 ˜αt are bounded constant, K and T
T is local iteration steps and communication rounds, respec-tively. Meanwhile, we present how SAM mitigates the im-pact of DP. For the clipping operation, DP-FedSAM reduces the l2 norm and the negative impact of the inconsistency among local updates on convergence. For adding noise op-eration, we obtain better weight perturbation robustness for reducing the performance damage caused by random noise, thereby having better robustness to DP noise. Empirically, we conduct extensive experiments on EMNIST, CIFAR-10, and CIFAR-100 datasets in both the independently and identically distributed (IID) and Non-IID settings. Further-more, we observe the loss landscape, surface contour, and the norm distribution of local updates for exploring the in-trinsic effects of SAM with DP, which together with the the-oretical analysis confirms the effect of DP-FedSAM.
Contribution. The main contributions of our work are sum-marized as four-fold: (i) We propose a novel scheme DP-FedSAM in DPFL to alleviate performance degradation is-sue from the optimizer perspective. (ii) We establish an im-proved convergence rate, which is tighter than the conven-tional bounds [9, 22] in the stochastic non-convex setting.
Moreover, we provide rigorous privacy guarantees and sen-sitivity analysis. (iii) We are the first to in-depth analyze the roles of the on-average norm of local updates αt and local update consistency among clients ˜αt on convergence. (iv)
We conduct extensive experiments to verify the effect of
DP-FedSAM, which could achieve state-of-the-art (SOTA) performance compared with several strong DPFL baselines. 2.