Abstract
Reconstructing 3D shapes from planar cross-sections is a challenge inspired by downstream applications like med-ical imaging and geographic informatics. The input is an in/out indicator function fully defined on a sparse collection of planes in space, and the output is an interpolation of the indicator function to the entire volume. Previous works ad-dressing this sparse and ill-posed problem either produce low quality results, or rely on additional priors such as target topology, appearance information, or input normal direc-tions. In this paper, we present OReX, a method for 3D shape reconstruction from slices alone, featuring a Neural Field as the interpolation prior. A modest neural network is trained on the input planes to return an inside/outside estimate for a given 3D coordinate, yielding a powerful prior that induces smoothness and self-similarities. The main challenge for this approach is high-frequency details, as the neural prior is overly smoothing. To alleviate this, we offer an iterative estimation architecture and a hierarchical input sampling scheme that encourage coarse-to-fine training, allowing the training process to focus on high frequencies at later stages.
In addition, we identify and analyze a ripple-like effect stem-ming from the mesh extraction step. We mitigate it by regular-izing the spatial gradients of the indicator function around input in/out boundaries during network training, tackling the problem at the root. Through extensive qualitative and quantitative experimentation, we demonstrate our method is robust, accurate, and scales well with the size of the in-put. We report state-of-the-art results compared to previous approaches and recent potential solutions, and demonstrate the benefit of our individual contributions through analysis and ablation studies. 1 1.

Introduction
Reconstructing a 3D object from its cross-sections is a long-standing task. It persists in fields including medical imaging, topography mapping, and manufacturing. The typi-cal setting is where a sparse set of arbitrary planes is given, upon which the “inside” and “outside” regions of the de-1Code and data available at https://github.com/haimsaw/
OReX
picted domain are labeled, and the entire shape in 3D is to be estimated (see Fig. 1). This is a challenging and ill-posed problem, especially due to the sparse and irregular nature of the data. Classical approaches first localize the problem by constructing an arrangement of the input planes, and then introduce a local regularizer that governs the interpo-lation of the input to within each cell. While sound, these approaches typically involve simplistic regularization func-tions, that only interpolate the volume within a cell bounded by the relevant cross-sections; as a consequence, they intro-duce over-smoothed solutions that do not respect features.
In addition, finding a cellular arrangement of planes is a computationally-heavy procedure, adding considerable com-plexity to the problem and rendering it quickly infeasible for large inputs (see Sec. 4). As we demonstrate (Sec. 4), recent approaches that reconstruct a mesh from an input point cloud are not well suited to our setting, as they assume a rather dense sampling of the entire shape. In addition, these methods do not consider the information of an entire cross-sectional plane, but rather only on the shape boundary.
In this paper, we introduce OReX—a reconstruction ap-proach based on neural networks that estimates an entire shape from its cross-sectional slices. Similar to recent ap-proaches, the neural network constitutes the prior that ex-trapolates the input to the entire volume. Neural networks in general have already been shown to inherently induce smoothness [17], and self-similarities [12], allowing natural recurrence of patterns. Specifically, we argue that Neural
Fields [25] are a promising choice for the task at hand. Neu-ral Fields represent a 3D scene by estimating its density and other local geometric properties for every given 3D coordi-nate. They are typically trained on 2D planar images, and are required to complete the entire 3D scene according to multi-view renderings or photographs. This neural representation is differentiable by construction, and hence allows native geometric optimization of the scene, realized via training.
We pose the reconstruction problem as a classification of space into “in” and “out” regions, which are known for the entire slice planes, and thus generate the indicator function which its decision boundary is the output shape.
The main challenge with applying neural fields to this problem is high-frequency details. Directly applying es-tablished training schemes [19] shows strong spectral bias, yielding overly smoothed results and other artifacts (Fig. 12).
Spectral bias is a well-known effect, indicating that higher frequency is effectively learned slower [22]. To facilitate effective high-frequency learning, avoiding the shadow cast by the low frequency, we introduce two alterations. First, we sample the planar data mostly around the inside/outside tran-sition regions, where the frequencies are higher. This sam-pling is further ordered from low to high-frequency regions (according to the distance from the inside/outside boundary), to encourage a low-to-high-frequency training progression.
In addition, we follow recent literature and allow the net-work to iteratively infer the result, where later iterations are responsible for finer, higher-frequency corrections [1, 23].
Finally, we consider another high-frequency artifact, also found in other neural-field-based works [9]. The desired density (or indicator) function dictates a sharp drop in value at the shape boundary. This is contradictory to the induced neural prior, causing sampling-related artifacts in the down-stream task of mesh extraction (Sec. 3.4). To alleviate this, we penalize strong spatial gradients around the boundary contours. This enforces a smoother transition between the in and out regions, allowing higher-quality mesh extraction.
As we demonstrate (see Fig. 1), our method yields state-of-the-art reconstructions from planar data, both for woman-made and organic shapes. The careful loss and training schemes are validated and analyzed through quantitative and qualitative experimentation. Our method is arrangement-free, and thus both interpolates all data globally, avoiding local artifacts, and scales well to a large number of slices (see Sec. 4). 2.