Abstract
A hard challenge in developing practical face recogni-tion (FR) attacks is due to the black-box nature of the target
FR model, i.e., inaccessible gradient and parameter infor-mation to attackers. While recent research took an impor-tant step towards attacking black-box FR models through leveraging transferability, their performance is still limited, especially against online commercial FR systems that can be pessimistic (e.g., a less than 50% ASR–attack success rate on average). Motivated by this, we present Sibling-Attack, a new FR attack technique for the first time explores a novel multi-task perspective (i.e., leveraging extra infor-mation from multi-correlated tasks to boost attacking trans-ferability). Intuitively, Sibling-Attack selects a set of tasks correlated with FR and picks the Attribute Recognition (AR) task as the task used in Sibling-Attack based on theoret-ical and quantitative analysis. Sibling-Attack then devel-ops an optimization framework that fuses adversarial gra-dient information through (1) constraining the cross-task features to be under the same space, (2) a joint-task meta optimization framework that enhances the gradient com-patibility among tasks, and (3) a cross-task gradient stabi-lization method which mitigates the oscillation effect during attacking. Extensive experiments demonstrate that Sibling-Attack outperforms state-of-the-art FR attack techniques by a non-trivial margin, boosting ASR by 12.61% and 55.77% on average on state-of-the-art pre-trained FR models and two well-known, widely used commercial FR systems. 1.

Introduction
Deep Neural Networks (DNNs) have demonstrated sig-nificant success in various applications, especially for face
*indicates equal contributions.
†indicates corresponding author.
Figure 1. Under the single task, previous attacks (a) boost trans-ferability by attacking multiple models or using various sampling or augmentation strategies. Nevertheless, in the proposed Sibling-Attack (b), we adopt the Attribute Recognition (AR) as the auxil-iary task to improve the transferability. And we utilize the hard-parameter sharing architecture from [3] as the attacking backbone. recognition [14, 53]. Despite these achievements, recent re-search has revealed that DNN-based face recognition (FR) models may be susceptible to adversarial attacks [2, 23, 59].
In practical attacking scenarios, the victim FR model’s pa-rameters are inaccessible to the attackers [4, 19, 43, 52, 61], i.e., the attacker has to perform attacks under black-box settings. One feasible black-box attacking strategy is to craft transferable adversarial examples by attacking a white-box surrogate model. On the face recognition task, re-cent research (e.g., optimization-based methods [17,41,62], model-ensemble training [17, 43] and input data transfor-mations [18, 65, 67]) has shown efficacy on boosting the at-tacking transferability. Essentially, those methods prevent the adversarial examples from over-fitting to a single mod-el/image by fusing auxiliary gradient information from en-semble models or various sampling/augmenting strategies.
However, their performance against online commercial FR
systems can be rather pessimistic (e.g., a less than 50% at-tack success rate on average as shown in our evaluation).
Motivated by this, we obtain an important insight by un-derstanding such pessimism is that existing methods col-lect adversarial gradients only from the single task and thus overlook the potential possibilities to further improve transferability, as illustrated in Fig. 1(a). Recent multi-task learning (MTL) methods [3, 42, 58, 74] have indicated that the multi-task or joint-task training among the corre-lated tasks can learn more robust and general features and thus improve the overall generalizability. Inspired by this, we seek to improve the FR task’s attacking transferability within the cross-task scope. To explore the FR attacking transferability under a multi-task setting, there are two chal-lenges: 1) identifying an appropriate auxiliary task as a suit-able candidate for FR task when performing multi-task at-tacks, and 2) how to fully utilize the adversarial information from two tasks thus boosting transferability.
We assume that a face-related task, which can provide relevant but diverse adversarial gradients information to complement the inherently absent adversarial knowledge for the target FR task, could be deemed as a good auxiliary task candidate, named sibling task. The empirical observa-tions of previous works [15, 60] have proved that the AR model can learn robust identity features, which can be used to enhance the FR’s recognition robustness. Also, in turn,
FR features implicitly encode latent facial attribute features.
In addition, we conduct quantitative results to show the ef-fectiveness of the AR task. To this end, we leverage a cor-related AR task as the sibling task to improve the attacking transferability, i.e., Sibling-Attack.
Since big variance exists in the feature and gradient spaces of different tasks [16, 46, 55], direct optimization over FR and AR models will lead to a limited attacking transferability without considering the better gradients fu-sion and stabilized training strategies. To address the issues, in Sibling-Attack, we first adopt the hard-parameter shar-ing architecture derived from [3] as our backbone attack-ing framework to constrain them within the same feature space, as shown in Fig. 1(b). Next, we design an alternat-ing joint-task meta optimization (JTMO) algorithm based on the high-level spirit of meta-learning [20, 51, 56] to fur-ther improve the gradient compatibility between two tasks.
Finally, to mitigate the training oscillation effect, we pro-pose a cross-task gradient stabilization (CTGS) strategy for stabilizing the adversarial example optimization.
Extensive experiments demonstrate that Sibling-Attack outperforms state-of-the-art FR attack techniques by a non-trivial margin, boosting the attack success rate by 12.61% and 55.77% on average on state-of-the-art pre-trained FR models and two well-known, widely used commercial FR systems, Face++ face recognition [48] and Microsoft face
API [50]. Notably, Sibling-Attack yields 86.50% and 96.10% ASR on attacking the widely used Face++ com-mercial face API on two common datasets, while the state-of-the-art only reaches 58.10% and 64.30%, respectively.
We summarize our contributions as: 1) We propose to generate highly transferable adversarial examples against face recognition by utilizing the adversarial information from the related AR task. 2) We propose a novel Sibling-Attack method which jointly learns the adversarial infor-mation from multiple tasks in a more effective manner. 3)
Evidenced by extensive experiments, the ASR of Sibling-Attack significantly outperforms current SOTA single-task attacks on the widely-adopted and large-scale FR bench-marks, particularly, several online commercial FR systems, which is aligned with our assumptions and analyses. 2.