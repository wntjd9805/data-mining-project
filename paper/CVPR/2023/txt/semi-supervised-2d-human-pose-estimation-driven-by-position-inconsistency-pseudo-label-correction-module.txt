Abstract
In this paper, we delve into semi-supervised 2D human pose estimation. The previous method ignored two prob-lems: (i) When conducting interactive training between large model and lightweight model, the pseudo label of lightweight model will be used to guide large models. (ii)
The negative impact of noise pseudo labels on training.
Moreover, the labels used for 2D human pose estimation are relatively complex: keypoint category and keypoint po-sition. To solve the problems mentioned above, we pro-pose a semi-supervised 2D human pose estimation frame-work driven by a position inconsistency pseudo label cor-rection module (SSPCM). We introduce an additional auxil-iary teacher and use the pseudo labels generated by the two teacher model in different periods to calculate the inconsis-tency score and remove outliers. Then, the two teacher mod-els are updated through interactive training, and the student model is updated using the pseudo labels generated by two teachers. To further improve the performance of the student model, we use the semi-supervised Cut-Occlude based on pseudo keypoint perception to generate more hard and ef-fective samples. In addition, we also proposed a new indoor overhead fisheye human keypoint dataset WEPDTOF-Pose.
Extensive experiments demonstrate that our method outper-forms the previous best semi-supervised 2D human pose es-timation method. We will release the code and dataset at https://github.com/hlz0606/SSPCM.
*This work was done when the authors were visiting Beike as interns.
†Corresponding author.
Figure 1. Performance comparison between our method SSPCM and SOTA method (DataDistill [33], DUAL [46]) on COCO [28] dataset. On the COCO dataset, using 1000, 5000, and 10000 labeled person instances, our method has increased 2.3mAP, 1.9mAP, and 1.1mAP compared with the previous method. 1.

Introduction 2D human pose estimation (HPE) [4, 6, 24, 27, 30, 52] is a task to estimate all 2D keypoints of the human body from images. It is a fundamental task of action recognition
[5,10,47], 3D human pose estimation [16,25,29,32,55], etc.
In recent years, thanks to the development of deep learn-ing [14, 20, 36, 39], 2D human pose estimation has made significant progress. However, the training of such a task is known to be data-hungry, where the labelling process is par-ticularly costly and time-consuming. To solve this problem, semi-supervised 2D human pose estimation has become an important research direction. This direction focuses on how to use a small amount of labeled data and a large amount of unlabeled data to improve the performance of the model.
Figure 2. Illustration of motivation. (i): (a) Previous interactive training methods [46]. (b) Our architecture. The arrow indicates the transmission direction of the pseudo label. (ii) and (iii) are the statistics of teacher model predictions (pseudo labels) on COCO dataset.
Ppred represents the keypoint coordinates predicted by the model (based on the heatmap). S represents student model. T A and T B represent 2 teacher models. Pgt represents the ground truth keypoint coordinates (based on the heatmap). LHM represents the diagonal length of the heatmap. (ii): The relationship between the quality of the pseudo labels and confidence. (iii): The relationship between the quality of the pseudo labels and position inconsistency. (iv): Results of the DUAL [46] at different confidence thresholds. (v): One specific example to demonstrate that the confidence does not represent the localization quality. (a) and (b) are the output results of teacher model
A in different epochs (heatmap of the right ankle). (c) and (d) are the output results of the additional auxiliary teacher model B.
The current state-of-the-art semi-supervised 2D HPE model [46] is based on consistency learning. Xie et al. [46] find that by maximizing the similarity between different in-crements of the image directly, there would be a collaps-ing problem. The reason is that the decision boundary passes the high-density areas of the minor class, so more and more pixels are gradually wrongly classified as back-grounds. They proposed a simple way to solve this prob-lem. For each unlabeled image, an easy augmentation Ie and a hard augmentation Ih are generated, and they are fed to the network to obtain two heatmap predictions. They use the accurate predictions on the easy augmentation to teach the network to learn about the corresponding hard augmen-tation. In addition, they also proposed a method that can replace EMA [12] to update the parameters of the teacher model, called Dual Network. The two models will take turns to act as teachers’ identities to generate pseudo labels, and take turns to act as students’ identities.
The previous methods [33, 46] can improve the accuracy of student models. However, the previous method has the following problems: 1) In the practical application of semi-supervised learning, large model are often used as teacher and lightweight model as student. Due to the inconsis-tent model structure, it is hard to use EMA to update the teacher model. When conducting interactive training be-tween large model and lightweight model, the pseudo label of lightweight model will be used to guide large models, as shown in the (a) of Fig. 2 (i). Although this method can also improve the performance of the teacher model, it is subop-timal. 2) The noise labels will harm the model training, and the student model will overfit the noise labels (caus-ing confirmation bias [2]). Some previous semi-supervised classification tasks [22, 37] use the confidence of classifi-cation to filter pseudo labels. There are a large number of high-quality pseudo labels in the low confidence region, as shown in Fig. 2 (ii). When the confidence threshold ex-ceeds a certain value, the higher the confidence threshold, the lower the model performance, as shown in the Fig. 2 (iv). By observing (a) and (b) in Fig. 2 (v), we can find that (b) has a higher confidence, but it is a noise label deviat-ing from the ground truth (outliers). Therefore, we choose to filter with a lower threshold. In addition, in recent stud-ies [17, 23, 34, 42, 48], it has been found that the more in-consistent the prediction results of different models for the same object, the more likely the prediction results will be wrong. To solve above problems, we introduce an addi-tional auxiliary teacher and use it to generate pseudo labels.
Their parameters are updated through interactive training, which ensures the difference between the two models, as shown in the (b) of Fig. 2 (i). The structure of these two teacher models can be consistent with the student model, or they can be larger models. Two teacher models may out-put different results for the same image. Even in different training periods, the output results of the same model for the same image will be different. We post-process the N pseudo labels output by the two teacher models in differ-ent periods to obtain N prediction results (2D coordinates) of each keypoint. Then, we calculate the pixel distance be-tween N prediction results of each keypoint. We use pixel distance to characterize the degree of position inconsistency (inconsistency score). We visual the relationship between the quality of the pseudo labels and position inconsistency, as shown in Fig. 2 (iii). We select a group of pseudo labels (2 pseudo labels) with the smallest position inconsistency for ensemble to obtain the final corrected pseudo labels. In short, on the basis of filtering based on confidence, PCM
module selects a set of pseudo labels with the least incon-sistency to remove outliers. The correction of pseudo labels of PCM module is similar to ensemble learning, which can make pseudo labels smoother. It is worth mentioning that we only use student model when testing.
In addition, we also use the semi-supervised Cut-Occlude based on pseudo keypoint perception to generate more hard samples, as shown in Fig. 5. Specifically, we use the pseudo label of the teacher model to locate the center of each keypoint in the image. Then, based on this central po-sition, we cut out the local limb image. We randomly paste the local limb image to the center of a keypoint in another image to simulate local occlusion.
Our contributions are as follows:
• We propose a semi-supervised 2D human pose esti-mation framework driven by a position inconsistency pseudo label correction module (SSPCM). Especially when the structure of teacher model and student model is inconsistent, it is a better solution.
• To further improve the performance of the student model, we propose the semi-supervised Cut-Occlude based on pseudo keypoint perception (SSCO) to gen-erate more hard and effective samples.
• Extensive experiments on MPII [1], COCO [28], and
AI-Challenger [43] have proved that our method out-performs the previous best semi-supervised 2D human pose estimation method , as shown in Fig. 1.
• We release a new 2D HPE dataset collected by indoor overhead fisheye camera based on the WEPDTOF [41] dataset, which is called WEPDTOF-Pose. We have conducted lots of experiments on WEPDTOF-Pose,
CEPDOF [11] and BKFisheye datasets (after remov-ing sensitive information). 2.