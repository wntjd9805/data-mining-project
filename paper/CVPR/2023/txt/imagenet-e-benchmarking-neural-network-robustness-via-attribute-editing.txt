Abstract
Recent studies have shown that higher accuracy on Im-ageNet usually leads to better robustness against differ-ent corruptions. Therefore, in this paper, instead of fol-lowing the traditional research paradigm that investigates new out-of-distribution corruptions or perturbations deep models may encounter, we conduct model debugging in in-distribution data to explore which object attributes a model may be sensitive to. To achieve this goal, we create a toolkit for object editing with controls of backgrounds, sizes, po-sitions, and directions, and create a rigorous benchmark named ImageNet-E(diting) for evaluating the image clas-siﬁer robustness in terms of object attributes. With our
ImageNet-E, we evaluate the performance of current deep learning models, including both convolutional neural net-works and vision transformers. We ﬁnd that most models are quite sensitive to attribute changes. A small change in the background can lead to an average of 9.23% drop
Corresponding author.
⇤
This research is supported in part by the National Key Research and
Development Progrem of China under Grant No.2020AAA0140000. on top-1 accuracy. We also evaluate some robust models including both adversarially trained models and other ro-bust trained models and ﬁnd that some models show worse robustness against attribute changes than vanilla models.
Based on these ﬁndings, we discover ways to enhance at-tribute robustness with preprocessing, architecture designs, and training strategies. We hope this work can provide some insights to the community and open up a new av-enue for research in robust computer vision. The code and dataset are available at https : / / github . com / alibaba/easyrobust. 1.

Introduction
Deep learning has triggered the rise of artiﬁcial intel-ligence and has become the workhorse of machine intel-ligence. Deep models have been widely applied in vari-ous ﬁelds such as autonomous driving [28], medical sci-ence [33], and ﬁnance [38]. With the spread of these tech-niques, the robustness and safety issues begin to be essen-tial, especially after the ﬁnding that deep models can be easily fooled by negligible noises [16]. As a result, more researchers contribute to building datasets for benchmark-ing model robustness to spot vulnerabilities in advance.
Most of the existing work builds datasets for evaluat-ing the model robustness and generalization ability on out-of-distribution data [7, 22, 30] using adversarial examples and common corruptions. For example, the ImageNet-C(orruption) dataset conducts visual corruptions such as
Gaussian noise to input images to simulate the possible pro-cessors in real scenarios [22]. ImageNet-R(enditions) con-tains various renditions (e.g., paintings, embroidery) of Im-ageNet object classes [21]. As both studies have found that higher accuracy on ImageNet usually leads to better robust-ness against different domains [22,50]. However, most pre-vious studies try to achieve this in a top-down way, such as architecture design, exploring a better training strategy, etc. We advocate that it is also essential to manage it in a bottom-up way, that is, conducting model debugging with the in-distribution dataset to provide clues for model repair-ing and accuracy improvement. For example, it is interest-ing to explore whether a bird with a water background can be recognized correctly even if most birds appear with trees or grasses in the training data. Though this topic has been investigated in studies such as causal and effect analysis [9], the experiments and analysis are undertaken on domain gen-eralization datasets. How a deep model generalizes to dif-ferent backgrounds is still unknown due to the vacancy of a qualiﬁed benchmark. Therefore, in this paper, we provide a detached object editing tool to conduct the model debug-ging from the perspective of object attribute and construct a dataset named ImageNet-E(diting).
The ImageNet-E dataset is a compact but challenging test set for object recognition that contains controllable ob-ject attributes including backgrounds, sizes, positions and directions, as shown in Fig. 1. In contrast to ObjectNet [5] whose images are collected by their workers via posing ob-jects according to speciﬁc instructions and differ from the target data distribution. This makes it hard to tell whether the degradation comes from the changes of attribute or dis-tribution. Our ImageNet-E is automatically generated with our object attribute editing tool based on the original Im-ageNet. Speciﬁcally, to change the object background, we provide an object background editing method that can make the background simpler or more complex based on diffusion models [25, 46]. In this way, one can easily evaluate how much the background complexity can inﬂuence the model performance. To control the object size, position, and di-rection to simulate pictures taken from different distances and angles, an object editing method is also provided. With the editing toolkit, we apply it to the large-scale ImageNet dataset [42] to construct our ImageNet-E(diting) dataset. It can serve as a general dataset for benchmarking robustness evaluation on different object attributes.
With the ImageNet-E dataset, we evaluate the perfor-mance of current deep learning models, including both con-volutional neural networks (CNNs), vision transformers as well as the large-scale pretrained CLIP [40]. We ﬁnd that deep models are quite sensitive to object attributes. For ex-ample, when editing the background towards high complex-ity (see Fig. 1, the 3rd row in the background part), the drop in top-1 accuracy reaches 9.23% on average. We also ﬁnd that though some robust models share similar top-1 accu-racy on ImageNet, the robustness against different attributes may differ a lot. Meanwhile, some models, being robust un-der certain settings, even show worse results than the vanilla ones on our dataset. This suggests that improving robust-ness is still a challenging problem and the object attributes should be taken into account. Afterward, we discover ways to enhance robustness against object attribute changes. The main contributions are summarized as follows:
• We provide an object editing toolkit that can change the object attributes for manipulated image generation.
• We provide a new dataset called ImageNet-E that can be used for benchmarking robustness to different ob-ject attributes. It opens up new avenues for research in robust computer vision against object attributes.
• We conduct extensive experiments on ImageNet-E and
ﬁnd that models that have good robustness on adversar-ial examples and common corruptions may show poor performance on our dataset. 2.