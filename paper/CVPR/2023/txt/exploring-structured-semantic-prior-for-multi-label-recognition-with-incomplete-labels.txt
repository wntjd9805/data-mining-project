Abstract
Multi-label recognition (MLR) with incomplete labels is very challenging. Recent works strive to explore the image-to-label correspondence in the vision-language model, i.e.,
CLIP [22], to compensate for insufficient annotations. In spite of promising performance, they generally overlook the valuable prior about the label-to-label correspondence. In this paper, we advocate remedying the deficiency of label supervision for the MLR with incomplete labels by deriving a structured semantic prior about the label-to-label corre-spondence via a semantic prior prompter. We then present a novel Semantic Correspondence Prompt Network (SCP-Net), which can thoroughly explore the structured semantic prior. A Prior-Enhanced Self-Supervised Learning method is further introduced to enhance the use of the prior. Com-prehensive experiments and analyses on several widely used benchmark datasets show that our method significantly out-performs existing methods on all datasets, well demonstrat-ing the effectiveness and the superiority of our method.
Our code will be available at https://github.com/ jameslahm/SCPNet. 1.

Introduction
Multi-label recognition (MLR) aims to describe the im-age content with various semantic labels [5, 26, 29, 30]. It encodes the visual information into structured labels, which can benefit the index and fast retrieval of images in broad practical applications, such as the search engine [24,27] and the recommendation system [2, 33].
Benefited from the development of deep learning, MLR
*Equal contributions. † Corresponding author.
Figure 1. Overview of CNN-based, DualCoOp [26] and our SCP-Net. Like DualCoOp, our SCPNet adopts CLIP as the base model.
Differently, our SCPNet aims to enhance the MLR with the prior about the label-to-label correspondence. MC means multi-class.
CL denotes contrastive learning. has achieved remarkable progress in recent years. How-ever, collecting high-quality full annotations becomes very challenging when the label set scales up, which greatly hin-ders the wide usage of MLR in real scenarios. Recently, researchers explore more feasible solutions for MLR. For example, the full label setting is relaxed with a partial label setting in [3, 21], which merely annotates a few labels for each training image. One more extreme setting with solely one single positive label is tackled in [8, 16]. These settings can be unified into a common issue of incomplete labels, which relieves the burden of the full annotation and con-siderably reduces the annotation cost. Therefore, it draws increasing attention from both academia and industry.
Compared with the full label setting, the incomplete la-bel setting encounters a dilemma of poor supervision, re-sulting in severe performance drops for MLR. Existing methods strive to regain supervision from missing labels by exhaustively exploring the image-to-label correspondence via semantic-aware modules [4,21] or loss calibration meth-ods [8, 16, 32]. A convolutional neural network (CNN) pre-trained on the ImageNet is usually leveraged to construct the MLR model. Its multi-class softmax layer is often re-placed by a multi-label sigmoid layer (Fig. 1 (a)). Such a re-placement wipes out prior knowledge about the correspon-dence between images and labels although it is necessary and inevitable.
Recently, vision-language pretrained models have ob-tained remarkable success in various vision tasks [26, 34, 35]. Thanks to their large-scale pretraining, the vision-language model, e.g., CLIP [22], which is trained with 400 million image-text pairs, can well bridge the visual-textual gap [26], providing rich prior knowledge for the down-stream tasks. For the MLR task, Sun et al. [26] propose a DualCoOp method, which is the first work to employ the
CLIP as the MLR base model. Through dual prompts, Du-alCoOp directly adopts the text encoder in the CLIP as the multi-label classification head (Fig. 1 (b)), without aban-doning the visual-textual prior in the pretrained CLIP.
Despite its effectiveness, DualCoOp is still limited in remedying the deficiency of label supervision, which is de-sired for the MLR with incomplete labels. Intuitively, it is convenient to reason unknown labels from annotated labels by leveraging the correspondence among labels, e.g., tables are likely to appear with chairs, and cars are usually ac-companied by roads. Therefore, such a label-to-label cor-respondence can help survive more label supervision and thus benefit MLR with incomplete labels. Besides, although most vision-language models do not encourage the con-trastive learning among texts, they are still abundant in the knowledge about the label-to-label correspondence because of the large-scale cross-modality training. However, such a valuable prior is rarely explored in the existing state-of-the-art method, i.e., DualCoOp [26].
In this paper, we aim to mitigate such deficiency of label supervision for MLR with incomplete labels by leveraging the abundant prior about the label-to-label correspondence in the CLIP [22]. We present a structured prior prompter to conveniently derive a structured semantic prior from the
CLIP. Then we propose a novel Semantic Correspondence
Prompt network (SCPNet) (Fig. 1 (c)), which can prompt the structured label-to-label correspondence with a cross-modality prompter. Our SCPNet also equips a semantic as-sociation module to explore high-order relationships among labels with the guidance of the derived structured semantic prior. A prior-enhanced self-supervised learning method is further introduced to comprehensively investigate the valu-able prior. As a result, our method can neatly calibrate its predicted semantic distribution while maintaining the self-consistency.
To verify the effectiveness of the proposed method for
MLR with incomplete labels, we conduct extensive exper-iments and analyses on a series of widely used benchmark datasets, i.e., MS COCO [19], PASCAL VOC [11], NUS
Wide [7], CUB [28] and OpenImages [17]. Experimental results show that our method can significantly outperform state-of-the-art methods on all datasets with a maximal im-provement of 6.8%/3.4% mAP for the single positive la-bel setting and the partial label setting, respectively, well demonstrating its effectiveness and superiority.
Overall, our contributions are four folds.
• We advocate leveraging a structured semantic prior to deal with the deficiency of label supervision for MLR with incomplete labels. To this end, we extract such a prior via a structured prior prompter.
• We present a semantic correspondence prompt Net-work (SCPNet) based on a cross-modality prompter and a semantic association module. The SCPNet can adequately explore the structured prior knowledge, thus boosting MLR with incomplete labels.
• We design a prior-enhanced self-supervised learning method to further investigate such a structured seman-tic prior, which can enjoy both distribution refinement and self-consistency.
• Experimental results show that our method can con-sistently achieve state-of-the-art performance on all benchmark datasets, revealing the significant effective-ness. Thorough analyses also demonstrate the superi-ority of our method. 2.