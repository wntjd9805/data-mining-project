Abstract
Few-Shot Learning (FSL) has been rapidly developed in recent years, potentially eliminating the requirement for signiﬁcant data acquisition. Few-shot ﬁne-tuning has been demonstrated to be practically efﬁcient and helpful, espe-cially for out-of-distribution datum [7, 13, 17, 29]. In this work, we ﬁrst observe that the few-shot ﬁne-tuned meth-ods are learned with the imbalanced class marginal distri-bution, leading to imbalanced per-class testing accuracy.
This observation further motivates us to propose the Trans-ductive Fine-tuning with Margin-based uncertainty weight-ing and Probability regularization (TF-MP), which learns a more balanced class marginal distribution as shown in
Fig. 1. We ﬁrst conduct sample weighting on unlabeled testing data with margin-based uncertainty scores and fur-ther regularize each test sample’s categorical probability.
TF-MP achieves state-of-the-art performance on in- / out-of-distribution evaluations of Meta-Dataset [31] and sur-passes previous transductive methods by a large margin. 1.

Introduction
Deep learning has gained vital progress in various ar-chitecture designs, optimization techniques, data augmenta-tion, and learning strategies, demonstrating its great poten-tial to be applied to real-world scenarios. However, applica-tions with deep learning generally require a large amount of labeled data, which is time-consuming to collect and costly on manual labeling force. Few-Shot Learning (FSL), learn-ing with only a few training samples, becomes increasingly essential [5, 9, 10, 27, 31, 33] to alleviate the dependence on data acquisition signiﬁcantly.
The recent attention on FSL over out-of-distribution da-tum [31] poses a challenge in obtaining efﬁcient algorithms that can perform well on cross-domain situations. Fine-tuning a pre-trained feature extractor with a few samples
[5, 7, 13, 17, 29] recently demonstrates its prominent poten-tial to solve this challenge. However, as illustrated in [29],
DCMSS
TF
URL
TSA
TF-MP 20 15 10 5
. d e r
P s s a l c
-r e
P n e e w t e b
. i
ﬀ
D t s e g r a
L 73 74
Per-class Accuracy 75 76
Figure 1. We observe that ﬁne-tuned models with current state-of-the-art methods [7,17,18,29] learned an imbalanced class marginal distribution. In the empirical experiments, a uniform testing set is utilized, and the Largest Difference LD between per-class predic-tions is used to quantify whether the learned class marginal proba-bility is balanced. Data are from sub-datasets in Meta-Dataset [31] with 100 episodes for each dataset and 10 per-class testing sam-ples. With current methods, LD is over 10. TF-MP successfully reduces LD by around 5 points and achieves the best per-class ac-curacy. a few training samples would lead to a biased estimation of the true data distribution. The biased learning during few-shot ﬁne-tuning could further mislead the model to learn an imbalanced class marginal distribution. To verify this, we quantify the largest difference (LD) between the num-ber of per-class predictions with a uniform testing set. If the ﬁne-tuned model learns a balanced class marginal dis-tribution, with a uniform testing set LD should approach zero. However, the empirical results show the opposite an-swer. As shown in Fig. 1, even with state-of-the-art meth-ods [7, 17, 18, 29], LD could be largely over 10 in practice.
(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7) (cid:2)(cid:8)(cid:3)(cid:9)(cid:10)(cid:11) (cid:17)(cid:6)(cid:3)(cid:13)(cid:7)(cid:16)(cid:18)(cid:5)(cid:6)(cid:19)(cid:12)(cid:20) (cid:21)(cid:16)(cid:22)(cid:12)(cid:3)(cid:9)(cid:6)(cid:7)(cid:16)(cid:9)(cid:10)(cid:10) (cid:17)(cid:6)(cid:3)(cid:13)(cid:7)(cid:16)(cid:18)(cid:5)(cid:6)(cid:19)(cid:12)(cid:20) (cid:21)(cid:16)(cid:22)(cid:12)(cid:3)(cid:9)(cid:6)(cid:7)(cid:16)(cid:9)(cid:10) (cid:23)(cid:12)(cid:7)(cid:13)(cid:24)(cid:9)(cid:7)(cid:16)(cid:13) (cid:23)(cid:12)(cid:7)(cid:13)(cid:24)(cid:9)(cid:7)(cid:16)(cid:13) (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:4)(cid:8)(cid:5) (cid:9)(cid:8)(cid:10)(cid:23)(cid:11)(cid:3)(cid:10)(cid:3)(cid:12) (cid:7)(cid:3)(cid:13)(cid:7)(cid:4)(cid:8)(cid:5) (cid:12)(cid:23)(cid:7)(cid:23) (cid:2)(cid:12)(cid:3) (cid:5)(cid:11)(cid:9)(cid:6)(cid:9)(cid:10)(cid:7)(cid:11)(cid:9)(cid:19)(cid:15) (cid:19)(cid:21) (cid:24)(cid:8)(cid:19)(cid:15)(cid:4) (cid:18)(cid:8)(cid:3)(cid:17)(cid:9)(cid:16)(cid:11)(cid:9)(cid:19)(cid:15)(cid:22) (cid:9)(cid:22) (cid:6)(cid:7)(cid:8)(cid:4)(cid:3)(cid:6)(cid:20) (cid:16)(cid:19)(cid:13)(cid:18)(cid:8)(cid:3)(cid:22)(cid:22)(cid:3)(cid:17) (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7) (cid:2)(cid:8)(cid:3)(cid:9)(cid:10)(cid:11) (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:5)(cid:7)(cid:8)(cid:7)(cid:9)(cid:10) (cid:11)(cid:12)(cid:13)(cid:14)(cid:8)(cid:6)(cid:3)(cid:7)(cid:15)(cid:6)(cid:9)(cid:7)(cid:4)(cid:16) (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:5)(cid:7)(cid:8)(cid:7)(cid:9)(cid:10) (cid:11)(cid:12)(cid:13)(cid:14)(cid:8)(cid:6)(cid:3)(cid:7)(cid:15)(cid:6)(cid:9)(cid:7)(cid:4)(cid:16) (cid:2)(cid:3)(cid:4)(cid:5)(cid:10)(cid:12)(cid:4) (cid:6)(cid:7)(cid:3)(cid:8)(cid:9) (cid:2)(cid:3)(cid:4)(cid:5) (cid:6)(cid:7)(cid:3)(cid:8)(cid:9) (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:3) (cid:11)(cid:12)(cid:3) (cid:9)(cid:13)(cid:14)(cid:7)(cid:6)(cid:7)(cid:15)(cid:16)(cid:3)(cid:17) (cid:18)(cid:8)(cid:19)(cid:14)(cid:7)(cid:14)(cid:9)(cid:6)(cid:9)(cid:11)(cid:20) (cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:3) (cid:11)(cid:12)(cid:3) (cid:9)(cid:13)(cid:14)(cid:7)(cid:6)(cid:7)(cid:15)(cid:16)(cid:3)(cid:17) (cid:18)(cid:8)(cid:19)(cid:14)(cid:7)(cid:14)(cid:9)(cid:6)(cid:9)(cid:11)(cid:20) (cid:19)(cid:21) (cid:11)(cid:3)(cid:22)(cid:11)(cid:9)(cid:15)(cid:4) (cid:17)(cid:7)(cid:11)(cid:7) (cid:11)(cid:3)(cid:22)(cid:11)(cid:9)(cid:15)(cid:4) (cid:17)(cid:7)(cid:11)(cid:7)(cid:17) (cid:19)(cid:21)(cid:19)(cid:21) (cid:11)(cid:3)(cid:22)(cid:11)(cid:9)(cid:15)(cid:4) (cid:3)
Illustration of TF-MP. We empirically evaluate a 1-shot 10-way classiﬁcation on the correct/predicted number of per-class
Figure 2. predictions. The model without TF-MP presents a severely imbalanced categorical performance even with the same number of per-class training samples. This motivates our methodology: (1) By proposing Margin-based uncertainty, the loss of each unlabeled testing data is weighted during ﬁnetuning, compressing the utilization of wrongly predicted testing data. (2) We explicitly regularize the categorical probability for each testing data to pursue balanced class-wise learning during ﬁnetuning. Using TF-MP, the difference between per-class predictions reduces from 21.3% to 14.4% with per-class accuracy improved from 4.5% to 4.9%. Results are averaged over 100 episodes in Meta-Dataset [31].
The observation in Fig. 1 demonstrates that the ﬁne-tuned models in FSL suffer from severely imbalanced cat-egorical performance.
In other words, the learned class marginal distribution of few-shot ﬁne-tuned models is largely imbalanced and biased. We argue that solving this issue is critical to maintaining the algorithm’s robustness to different testing scenarios. Classes with fewer predictions would carry low accuracy, and this issue of ﬁne-tuned mod-els could yield a fatal failure for testing scenarios in favor of these classes.
In this work, we revisit Transductive Fine-tuning [7] by effectively using unlabelled testing data. Based on the aforementioned analysis, the imbalanced categorical perfor-mance in FSL motivates us to propose two solutions: (1) the per-sample loss weighting through Margin-based un-certainty and (2) the probability regularization. For (1), as shown in Fig. 2, using the same number of per-class training data achieves extremely imbalanced prediction re-sults.
It indicates that each sample contributes to the ﬁ-nal performance differently, which inspires us to weigh the unlabeled testing samples according to their uncertainty scores. Speciﬁcally, we address the importance of utiliz-ing margin [26] in entropy computation and demonstrate its supreme ability to compress the utilization of wrong predictions. For (2), as the ideal performance should be categorically balanced, we propose to explicitly regularize the probability for each testing data. Precisely, each test-ing sample’s categorical probability is adjusted by a scale vector, which quantiﬁes the difference between the class marginal distribution and the uniform. The class marginal distribution is estimated by combining each query sample with the complete support set. Our proposed Transductive
Fine-tuning with Margin-based uncertainty and Probability regularization (TF-MP) effectively reduces the largest dif-ference between per-class predictions by around 5 samples and further improves per-class accuracy with 2.1%, shown in Fig. 1. Meanwhile, TF-MP shows robust cross-domain performance boosts on Meta-Dataset, demonstrating its po-tential in real applications. Our contributions can be sum-marized as follows:
• We present the observation that: with current state-of-the-art methods [7, 17, 18, 29], the few-shot ﬁne-tuned models are learned with the imbalanced class marginal distribution, which in other words presents imbalanced per-class accuracy. We highlight the importance of solving it to improve the model’s robustness under dif-ferent testing scenarios.
• Inspired by the observation, we revisit Transductive
Fine-tuning and propose TF-MP: (1) Utilizing Margin-based uncertainty to weigh each unlabeled testing data in the loss objective in order to compress the utiliza-tion of possibly wrong predictions. (2) Regularizing the categorical probability for each testing sample to pursue a more balanced class marginal during ﬁnetun-ing.
• We empirically verify that models with TF-MP learn a more balanced class marginal distribution as shown in
Fig. 1. Furthermore, we conduct comprehensive exper-iments to show that TF-MP obtains consistent perfor-mance boosts on Meta-Dataset [31], demonstrating its efﬁciency and effectiveness for practical applications.
2.