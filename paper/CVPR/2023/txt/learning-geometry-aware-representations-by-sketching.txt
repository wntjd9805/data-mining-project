Abstract
Understanding geometric concepts, such as distance and shape, is essential for understanding the real world and also for many vision tasks. To incorporate such information into a visual representation of a scene, we propose learning to represent the scene by sketching, inspired by human be-havior. Our method, coined Learning by Sketching (LBS), learns to convert an image into a set of colored strokes that explicitly incorporate the geometric information of the scene in a single inference step without requiring a sketch dataset. A sketch is then generated from the strokes where
CLIP-based perceptual loss maintains a semantic similar-ity between the sketch and the image. We show theoreti-cally that sketching is equivariant with respect to arbitrary affine transformations and thus provably preserves geomet-ric information. Experimental results show that LBS sub-stantially improves the performance of object attribute clas-sification on the unlabeled CLEVR dataset, domain trans-fer between CLEVR and STL-10 datasets, and for diverse downstream tasks, confirming that LBS provides rich geo-metric information. 1.

Introduction
Since geometric principles form the bedrock of our phys-ical world, many real-world scenarios involve geometric concepts such as position, shape, distance, and orienta-tion. For example, grabbing an object requires estimating its shape and relative distance. Understanding geometric concepts is also essential for numerous vision tasks such as image segmentation, visual reasoning, and pose estima-tion [27]. Thus, it is crucial to learn a visual representation of the image that can preserve such information [76], which we call geometry-aware representation.
However, there is still a challenge in learning geometry-aware representations in a compact way that can be useful for various downstream tasks. Previous approaches have focused on capturing geometric features of an image in a 2D grid structure, using methods such as handcrafted fea-ture extraction [2, 4, 14, 31], segmentation maps [21, 57], or
Figure 1. Overview of LBS, which aims to generate sketches that accurately reflect the geometric information of an image. A sketch consists of a set of strokes represented by a parameterized vec-tor that specifies curve, color, and thickness. We leverage it as a geometry-aware representation for various downstream tasks. convolution features [36, 55]. Although these methods are widely applicable to various domains, they often lack com-pactness based on a high-level understanding of the scene and tend to prioritize nuisance features such as the back-ground. Another line of work proposes architectures that guarantee to preserve geometric structure [12,13,23,58,73] or disentangle prominent factors in the data [8, 28, 39, 51].
Although these methods can represent geometric concepts in a compact latent space, they are typically designed to learn features that are specific to a particular domain and often face challenges in generalizing to other domains [64].
In this study, we present a novel approach to learning geometry-aware representations via sketching. Sketching, which is the process of converting the salient features of an image into a set of color-coded strokes, as illustrated in
Figure 1, is the primary means by which humans represent images while preserving their geometry. Our key idea is that sketches can be a compact, high-level representation of an image that accurately reflects geometric information.
Sketching requires a high-level understanding of the scene, as it aims to capture the most salient features of the image and abstract them into a limited number of strokes. In ad-dition, a sketch can be represented as a set of parameters by replacing each stroke with parametric curves. Sketch-Figure 2. Examples of how sketches capture essential geometric concepts such as shape, size, orientation, curvature, and local distortion.
The control points of each stroke compactly represent the local geometric information of the corresponding region in the sketch. The strokes as a whole maintain the geometric structure of the entire image under various transformations in the image domain. ing has also been linked to how people learn geometric concepts [66]. Based on these properties, we directly use strokes as a geometry-aware representation and utilize them for downstream tasks. Under the theoretical framework of geometric deep learning [3], we conduct theoretical analy-sis to validate the effectiveness of strokes as a representation and prove their ability to preserve affine transformations.
To validate our hypothesis, we introduce Learning by
Sketching (LBS), a method that generates abstract sketches coherent with the geometry of an input image. Our model is distinct from existing sketch generation methods as it does not require a sketch dataset for training, which often has limited abstraction or fails to accurately reflect geometric information. Instead, LBS learns to convert an image into a set of colored BÃ©zier curves that explicitly represent the geometric concepts of the input image. To teach the style of sketching, we use perceptual loss based on the CLIP model [59, 68], which measures both semantic and geo-metric similarities between images and generated sketches.
We propose a progressive optimization process that predicts how strokes will be optimized from their initial positions through CLIP-based perceptual loss to generate abstract sketches in a single inference step. As a result, LBS gen-erates a representation that reflects visual understanding in a single inference step, without requiring a sketch dataset.
This produces highly explainable representations through sketches, as illustrated in Figure 2.
We conduct experimental analyses to evaluate the ef-fectiveness of our approach, learning by sketching, by ad-dressing multiple research questions in various downstream tasks, including: (i) describing the relationships between geometric primitives, (ii) demonstrating simple spatial rea-soning ability by conveying global and local geometric in-formation, (iii) containing general geometric information shared across different domains, and (iv) improving perfor-mance on FG-SBIR, a traditional sketch task. 2.