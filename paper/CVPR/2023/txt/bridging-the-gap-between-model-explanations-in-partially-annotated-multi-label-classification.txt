Abstract
Due to the expensive costs of collecting labels in multi-label classification datasets, partially annotated multi-label classification has become an emerging field in computer vi-sion. One baseline approach to this task is to assume unob-served labels as negative labels, but this assumption induces label noise as a form of false negative. To understand the negative impact caused by false negative labels, we study how these labels affect the model’s explanation. We observe that the explanation of two models, trained with full and partial labels each, highlights similar regions but with dif-ferent scaling, where the latter tends to have lower attribu-tion scores. Based on these findings, we propose to boost the attribution scores of the model trained with partial labels to make its explanation resemble that of the model trained with full labels. Even with the conceptually simple approach, the multi-label classification performance improves by a large margin in three different datasets on a single pos-itive label setting and one on a large-scale partial label setting. Code is available at https://github.com/ youngwk/BridgeGapExplanationPAMC. 1.

Introduction
Multi-label image classification is the task of predict-ing all labels corresponding to a given image. Since web-crawled images often contain multiple objects/concepts
[3, 32, 35, 44], the importance of this task is rising. How-ever, it faces a significant issue of huge annotation costs. We need C binary labels for each training image to provide ex-haustive annotation for a model that classifies images into C categories. It acts as a severe obstacle to scaling multi-label classification datasets.
For this reason, partially annotated multi-label classifi-cation [2, 11, 13, 17, 21, 24] has recently become an actively
*Corresponding author.
Figure 1. CAM Observation. We compare the class activation map (CAM) output from two multi-label classification models: one trained with full labels (CAMfull) and the other trained with partial labels and AN assumption (CAMpartial). We observe that the overall structure of CAMpartial is not much affected by the noisy false negative labels during training. This observation motivates us to make CAMpartial similar to CAMfull by boosting its relatively large attribution scores. Best viewed in color. studied topic. In this setting, instead of exhaustive annota-tion, only a few categories are labeled for each training im-age. We can effectively reduce the burden of annotation by adopting partial annotation strategies.
One baseline approach for solving a partially annotated multi-label classification task is assuming unobserved la-bels as negative labels (Assume Negative, AN) [4,6,36,40].
It is a reasonable assumption since most labels are nega-tive labels in the multi-label scenario [33]. However, this assumption causes label noise in a form of false negatives since the actually positive but unannotated labels are incor-rectly assumed to be negative. Since this label noise per-turbs the learning process of the model [1, 7, 18, 45], recent studies on a partially annotated multi-label classification fo-cus on suppressing the influence of label noise by ignoring or correcting the loss of samples that are likely to be false negatives [2, 21].
Aside from recent research directions, we delve into
“how” false negative labels influence a multi-label classi-fication model. We conduct control experiments with two models. One is the model trained with partial labels and
AN assumption where false negative labels exist. The other is the model trained with full annotations and thus trained without false negatives. We compare the class activation map (CAM) [49] output between the two models to see the difference in how each model understands the input image and makes a prediction result.
Figure 1 shows that a model trained with false negatives still highlights similar regions to one trained with full an-notation. However, the attribution scores in the highlighted areas are much small. This observation leads us to think that if we scale up the damaged score of the highlighted region in the model trained with false negatives, the explanation of this model will become similar to that of the model trained with full annotation.
To this end, we introduce a simple piece-wise linear function, named BoostLU, that bridges the gap between the explanation of two models trained with false negatives and with full annotation each. Concretely, we use the mod-ified CNN model to get CAM during the forward pass di-rectly [47], and the logit in the modified CNN model is the mean of attribution scores of CAM. The BoostLU function is applied element-wisely to the CAM output of the mod-ified CNN to boost the scores of the highlighted regions, thereby compensating for the decrease of attribution scores in CAM caused by false negatives. It increases the logit value for positive labels and thus makes a better prediction.
Furthermore, when we combine BoostLU with the recently proposed methods [21] that explicitly detect and modify false negatives during training, it helps to detect false neg-atives better, thus leading to better performance. As a re-sult, we achieve state-of-the-art performance on PASCAL
VOC [14], MS COCO [28], NUSWIDE [10], and Openim-ages V3 [23] datasets in a partial label setting.
We summarize the contributions of this paper as follows. 1. We analyze how the false negative labels affect the ex-planation of the model in a partially annotated multi-label classification scenario. 2. We propose a simple but effective function, named
BoostLU, that compensates for the damage of false negatives in a multi-label classification model with lit-tle extra computational cost. 3. When applied during inference, BoostLU boosts the baseline method (AN)’s test performance without ad-ditional training. 4. Combined with recent methods of detecting and mod-ifying false negatives during training, BoostLU boosts the state-of-the-art performance on single positive and large-scale partial label settings. 2.