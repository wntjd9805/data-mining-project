Abstract
Realistic face rendering from multi-view images is bene-ficial to various computer vision and graphics applications.
Due to complex spatially-varying reflectance properties and geometry characteristics of faces, however, it remains chal-lenging to recover 3D facial representations both faithfully and efficiently in the current studies. This paper presents a novel 3D face rendering model, namely NeuFace, to learn accurate and physically-meaningful underlying 3D repre-sentations by neural rendering techniques. It naturally in-corporates the neural BRDFs into physically based render-ing, capturing sophisticated facial geometry and appear-ance clues in a collaborative manner. Specifically, we intro-duce an approximated BRDF integration and a simple yet new low-rank prior, which effectively lower the ambiguities and boost the performance of the facial BRDFs. Extensive experiments are performed to demonstrate the superiority of NeuFace in human face rendering, along with a decent generalization ability to common objects. Code is released at NeuFace. 1.

Introduction
Rendering realistic human faces with controllable view-points and lighting is now becoming ever increasingly im-portant with its applications ranging from game production, movie industry, to immersive experiences in the Metaverse.
Various factors, including the sophisticated geometrical dif-ferences among individuals, the person-specific appearance idiosyncrasies, along with the spatially-varying reflectance properties of skins, collectively make faithful face rendering a rather difficult problem.
According to photogrammetry, the pioneering studies on this issue generally leverage complex active lighting setups, e.g., LightStage [8], to build 3D face models from multiple
*Corresponding author.
Figure 1. Demonstration of the face rendering results and recov-ered underlying 3D representations. photos of an individual, where accurate shape attributes and high-quality diffuse and specular reflectance properties are commonly acknowledged as the premises of its success. An elaborately designed workflow is required, typically involv-ing a series of stages such as camera calibration, dynamic data acquisition, multi-view stereo, material estimation, and texture parameterization [42]. While a compelling and con-vincing 3D face model can be finally obtained, this output highly depends on the expertise of the engineers and artists with significant manual efforts, as the multi-step process in-evitably brings diverse optimization goals.
Recently, 3D neural rendering, which offers an end-to-end alternative, has demonstrated promising performance in recovering scene properties from real-world imageries, such as view-dependent radiance [26, 28, 36, 38, 47] and geome-try [33, 48, 49, 54, 55]. Itâ€™s mainly credited to the disentan-glement of the learnable 3D representations and the differ-entiable image formation process, free of the tedious pho-togrammetry pipeline. However, like classical function fit-ting, inverse rendering is fundamentally under-constrained, which may incur badly-conditioned fits of the underly-ing 3D representations, especially for intricate cases, e.g., non-Lambertian surfaces with view-dependent highlights.
With the trend in the combination of computer graphics and learning techniques, several attempts take advantage of physically motivated inductive biases and present Phys-ically Based Rendering (PBR) [14, 31, 47, 56], where Bidi-rectional Reflectance Distribution Functions (BRDFs) are widely adopted. By explicitly mimicking the interaction of the environment light with the scene, they facilitate net-work optimization and deliver substantial gains. Unfortu-nately, the exploited physical priors are either heuristic or analytic [7, 20, 44], limited to a small set of real-world ma-terials, e.g., metal, incapable of describing human faces.
For realistic face rendering, the most fundamental issue lies in accurately modeling the optical properties of multi-layered facial skin [21].
In particular, the unevenly dis-tributed fine-scale oily layers and epidermis reflect the inci-dent lights irregularly, leading to complex view-dependent and spatially-varying highlights. This characteristic and the low-textured nature of facial surfaces strongly amplify the shape-appearance ambiguity. Moreover, subsurface scatter-ing between the underlying dermis and other skin layers fur-ther complicates this problem.
In this paper, we follow the PBR paradigm for its poten-tial in learning 3D representations and make the first step towards realistic 3D neural face rendering, mainly target-ing complex skin reflection modeling. Our method, namely
NeuFace, is able to recover faithful facial reflectance and geometry from only multi-view images. Concretely, we es-tablish a PBR framework to learn neural BRDFs to describe facial skin, which simulates physically-correct light trans-port with a much higher representation capability. By using a differentiable Signed Distance Function (SDF) based rep-resentation, i.e., ImFace [61], as the shape prior, the facial appearance and geometry field can be synchronously opti-mized in inverse rendering.
Compared to the analytic BRDFs, the neural ones allow richer representations for sophisticated material like facial skin. In spite of this superiority, such representations pose challenges to computational cost and data demand during training. To tackle these difficulties, the techniques in real-time rendering [1] are adapted to separate the hemisphere integral of neural BRDFs, where the material and light in-tegrals are individually learned instead, bypassing the mas-sive Monte-Carlo sampling phase [34] required by numer-ical solutions. Furthermore, a low-rank prior is introduced into the spatially-varying facial BRDFs, which greatly re-stricts the solution space thereby diminishing the need for large-scale training observations. These model designs in-deed enable NeuFace to accurately and stably describe how the light interacts with the facial surface as in the real 3D space. Fig. 1 displays an example.
The main contributions of this study include: 1) A novel framework with naturally-bonded PBR as well as neural
BRDF representations, which collaboratively captures fa-cial geometry and appearance properties in complicated fa-cial skin. 2) A new and simple low-rank prior, which sig-nificantly facilitates the learning of neural BRDFs and im-proves the appearance recovering performance. 3) Impres-sive face rendering results from only multi-view images, applicable to various applications such as relighting, along with a decent generalization ability to common objects. 2.