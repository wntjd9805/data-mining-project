Abstract
Perceiving potential “action possibilities” (i.e., affor-dance) regions of images and learning interactive func-tionalities of objects from human demonstration is a chal-lenging task due to the diversity of human-object inter-actions. Prevailing affordance learning algorithms often adopt the label assignment paradigm and presume that there is a unique relationship between functional region and affordance label, yielding poor performance when adapt-ing to unseen environments with large appearance varia-tions. In this paper, we propose to leverage interactive affin-ity for affordance learning, i.e.extracting interactive affinity from human-object interaction and transferring it to non-interactive objects. Interactive affinity, which represents the contacts between different parts of the human body and lo-cal regions of the target object, can provide inherent cues of interconnectivity between humans and objects, thereby re-ducing the ambiguity of the perceived action possibilities.
Specifically, we propose a pose-aided interactive affinity learning framework that exploits human pose to guide the network to learn the interactive affinity from human-object interactions. Particularly, a keypoint heuristic perception (KHP) scheme is devised to exploit the keypoint association of human pose to alleviate the uncertainties due to interac-tion diversities and contact occlusions. Besides, a contact-driven affordance learning (CAL) dataset is constructed by collecting and labeling over 5, 000 images. Experimental results demonstrate that our method outperforms the rep-resentative models regarding objective metrics and visual quality. Code and dataset: github.com/lhc1224/PIAL-Net. 1.

Introduction
The objective of affordance learning is to locate the “ac-tion possibilities” regions of an object [15, 18]. For an in-*Corresponding author. ‡ Equal contributions.
Figure 1. (a) Interaction affinity refers to the contact between dif-ferent parts of the human body and the local regions of a target object. (b) The interactive affinity provides rich cues to guide the model to acquire invariant features of the object’s local regions in-teracting with the body part, thus counteracting the multiple pos-sibilities caused by diverse interactions. telligent agent, it is vital to perceive not only the object se-mantics but also how to interact with various objects’ local regions. Perceiving and reasoning about the object’s inter-actable regions is a critical capability for embodied intelli-gent systems to interact with the environment actively, dis-tinct from passive perception systems [3, 38, 39, 44]. More-over, affordance learning has a wide range of applications in fields such as action recognition [13, 24, 43], scene un-derstanding [9, 69], human-robot interaction [51, 63], au-tonomous driving [7] and VR/AR [50, 53].
Affordance is a dynamic property closely related to hu-mans and the environment [18]. Previous works [11, 37, 40, 46] focus on establishing mapping relationships between appearances and labels for affordance learning. However, they neglect the multiple possibilities of affordance brought about by changes in the environment and actors, leading to an incorrect perception. Recent studies [39, 48] uti-lize reinforcement learning to allow intelligent agents to perceive the environment through numerous interactions in simulated/actual scenarios. Such approaches are mainly limited by their high cost and struggle to generalize to
Figure 2. Motivation. (a) This paper explores the associations of interactable regions between diverse images by considering the context of contact regions with different body parts. (b) This paper considers leveraging the connection of human pose keypoints to alleviate the uncertainties due to interaction diversities and contact occlusions. unseen scenarios [58]. To this end, researchers consider learning from human demonstration in an action-free man-ner [14, 29, 30, 38]. Nonetheless, they only roughly seg-ment the whole object/interaction regions in a general way, which is still challenging to understand how the object is used. The multiple possibilities due to different local re-gions interacting with humans in various ways are not fully resolved.
In this paper, we propose to leverage interac-tive affinity for affordance learning, i.e.extracting interac-tive affinity from human-object interaction and transferring it to non-interactive objects. The interactive affinity (Fig. 1 (a)) denotes the contacts between different human body parts and objects’ local regions, which can provide inher-ent cues of interconnectivity between humans and objects, thereby reducing the ambiguity of the perceived action pos-sibilities (Fig. 1 (b)).
However, it faces the challenges of interaction diversi-ties and contact occlusions, leading to difficulties in acquir-ing a good interactive affinity representation. The human pose is independent of background, and the same interac-tion corresponds to approximately similar poses. Thus, it makes sense to use the association between pose keypoints to overcome the difficulty of obtaining interactive affinity representations. Moreover, it is challenging to transfer the interactive affinity to non-interactive object images due to variations in views, scales, and appearances. The context between the different body part contact regions (Fig. 2 (a)) provides the model with the possibility to explore the as-sociations between the interactable regions of the various images to counteract transfer difficulties.
In this paper, we present a pose-aided interactive affin-First, an Interactive Feature ity learning framework.
Enhancement (IFE) module is introduced to explore the connections between different interactable regions of the images. Then, a Keypoint Heuristic Perception (KHP) scheme is devised to mine the interactive affinity repre-sentation from interaction and transfer it to non-interactive objects. Specifically, the IFE module leverages the trans-former to fully extract global contextual cues by exploiting the common relationships between their local interactable regions (Fig. 2 (a)). Then, they are used to establish asso-ciations between the object interactable regions in different images. Subsequently, the KHP scheme exploits the corre-lation between the human body keypoints and the contact region to guide the network to mine the object’s local in-variant features interacting with the body parts (Fig. 2 (b)).
Although the numerous related datasets [9, 10, 19, 30, 36, 57, 67] that emerged during the development of affor-dance learning, there is still a lack of relevant datasets suited for leveraging interactive affinity. To carry out a thorough study, this paper constructs an Contact-driven Affordance
Learning (CAL) dataset, consisting of 5, 258 images from 23 affordance and 47 object categories. We conduct con-trastive studies on the CAL dataset against six representa-tive models in several related fields. Experimental results validate the effectiveness of our method in solving the mul-tiple possibilities of affordance.
Contributions: 1) We propose leveraging interactive affinity for affordance learning and establishing a CAL benchmark to facilitate the study of obtaining interactive affinity to counteract the multiple possibilities of affor-dance. 2) We propose a pose-aided interactive affinity learn-ing framework that exploits pose data to guide the network to mine the interactive affinity of body parts and object re-gions from human-object interaction. 3) Experiments on the CAL dataset demonstrate that our model outperforms state-of-the-art methods and can serve as a strong baseline for future affordance learning research. 2.