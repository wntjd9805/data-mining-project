Abstract
Early action prediction deals with inferring the ongoing action from partially-observed videos, typically at the out-set of the video. We propose a bottleneck-based attention model that captures the evolution of the action, through pro-gressive sampling over fine-to-coarse scales. Our proposed
Temporal Progressive (TemPr) model is composed of mul-tiple attention towers, one for each scale. The predicted action label is based on the collective agreement consider-ing confidences of these towers. Extensive experiments over four video datasets showcase state-of-the-art performance on the task of Early Action Prediction across a range of en-coder architectures. We demonstrate the effectiveness and consistency of TemPr through detailed ablations.† 1.

Introduction
Early action prediction (EAP) is the task of inferring the action label corresponding to a given video, from only partially observing the start of that video. Interest in EAP has increased in recent years due to both the ever-growing number of videos recorded and the requirement of pro-cessing them with minimal latency. Motivated by the ad-vances in action recognition [6, 57], where the entire video is used to recognize the action label, recent EAP meth-ods [3,15,34,45,60] distill the knowledge from these recog-nition models to learn from the observed segments. Despite promising results, the information that can be extracted from partial and full videos is inevitably different. We in-stead focus on modeling the observed partial video better.
Several neurophysiological studies [11, 29] have sug-gested that humans understand actions in a predictive and not reactive manner. This has resulted in the direct match-ing hypothesis [18, 46] where, actions are believed to be perceived through common patterns. Encountering any of these patterns prompts the expectation of specific action(s), even before the action is completed. Although the early pre-*Work carried out while A. Stergiou was at University of Bristol
†Code is available at: https://tinyurl.com/temprog
Figure 1. Early action prediction with TemPr involves the use of multiple scales for extracting features over partially observed videos. Encoded spatio-temporal features are attended by distinct transformer towers (T ) at each scale. We visualize two scales, where the fine scale Ti predicts ‘hold plate’, and the coarse scale
Ti+1 predicts ‘hold sponge’. Informative cues from both scales are combined for early prediction of the action ‘wash plate’. diction of actions is an inherent part of human cognition, the task remains challenging for computational modeling.
Motivated by the direct matching hypothesis, we propose a Temporally Progressive (TemPr) approach to modeling
Inspired by multi-scale repre-partially observed videos. sentations in images [7, 69] and video [27, 62], we repre-sent the observed video by a set of sub-sequences of tem-porally increasing lengths as in Figure 1, which we refer to as scales. TemPr uses distinct transformer towers over each video scale. These utilize a shared latent-bottleneck for cross-attention [28, 37], followed by a stack of self-attention blocks to concurrently encode and aggregate the input. From tower outputs, a shared classifier produces la-bel predictions for each scale. Labels are aggregated based on their collective similarity and individual confidences.
In summary, our contributions are as follows: (i) We
propose a progressive fine-to-coarse temporal sampling ap-proach for EAP. (ii) We use transformer towers over sam-pled scales to capture discriminative representations and adaptively aggregate tower predictions, based on their con-(iii) We evaluate the fidence and collective agreement. effectiveness of our approach over four video datasets:
UCF-101 [53], EPIC-KITCHENS [8], NTU-RGB [51] and
Something-Something (sub-21 & v2) [21], consistently out-performing prior work. 2.