Abstract
Recent state-of-the-art methods for HOI detection typ-ically build on transformer architectures with two decoder branches, one for human-object pair detection and the other for interaction classification. Such disentangled transform-ers, however, may suffer from insufficient context exchange between the branches and lead to a lack of context informa-tion for relational reasoning, which is critical in discover-ing HOI instances. In this work, we propose the multiplex relation network (MUREN) that performs rich context ex-change between three decoder branches using unary, pair-wise, and ternary relations of human, object, and interac-tion tokens. The proposed method learns comprehensive re-lational contexts for discovering HOI instances, achieving state-of-the-art performance on two standard benchmarks for HOI detection, HICO-DET and V-COCO. 1.

Introduction
The task of Human-Object Interaction (HOI) detection is to discover the instances of ⟨human, object, interaction⟩ from a given image, which reveal semantic structures of hu-man activities in the image. The results can be useful for a wide range of computer vision problems such as human action recognition [1,25,42], image retrieval [9,33,37], and image captioning [12, 34, 36] where a comprehensive visual understanding of the relationships between humans and ob-jects is required for high-level reasoning.
With the recent success of transformer networks [31] in object detection [2, 45], transformer-based HOI detection methods [4, 15, 16, 29, 38, 44, 46] have been actively devel-oped to become a dominant base architecture for the task.
Existing transformer-based methods for HOI detection can be roughly divided into two types: single-branch and two-branch. The single-branch methods [16, 29, 46] update a token set through a single transformer decoder and detect
HOI instances using the subsequent FFNs directly. As a sin-gle transformer decoder is responsible for all sub-tasks (i.e.,
Figure 1. The illustration of relation context information in an HOI instance. We define three types of relation context information in an HOI instance: unary, pairwise, and ternary relation contexts.
Each relation context provides useful information for detecting an
HOI instance. For example, in our method, the unary context about an interaction (green) helps to infer that a human (yellow) and an object (red) are associated with the interaction, and vice versa.
Our method utilizes the multiplex relation context consisting of the three relation contexts to perform context exchange for relational reasoning. human detection, object detection, and interaction classifi-cation), they are limited in adapting to the different sub-tasks with multi-task learning, simultaneously [38]. To re-solve the issue, the two-branch methods [4, 15, 38, 40, 44] adopt two separated transformer decoder branches where one detects human-object pairs from a human-object to-ken set while the other classifies interaction classes between human-object pairs from an interaction token set. However, the insufficient context exchange between the branches pre-vents the two-branch methods [15, 38, 40] from learning re-lational contexts, which plays a crucial role in identifying
HOI instances. Although some methods [4, 44] tackle this issue with additional context exchange, they are limited to propagating human-object context to interaction context.
To address the problem, we introduce the MUtiplex
RElation Network (MUREN) that performs rich context ex-change using unary, pairwise, and ternary relations of hu-man, object, and interaction tokens for relational reasoning.
As illustrated in Figure 1, we define three types of relation context information in an HOI instance: unary, pairwise, and ternary, each of which provides useful information to discover HOI instances. The ternary relation context gives holistic information about the HOI instance while the unary and pairwise relation contexts provide more fine-grained in-formation about the HOI instance. For example, as shown in
Figure 1, the unary context about an interaction (e.g., ‘rid-ing’) helps to infer which pair of a human and an object is associated with the interaction in a given image, and the pairwise context between a human and an interaction (e.g.,
‘human’ and ‘riding’) helps to detect an object (e.g., ‘bicy-cle’). Motivated by this, our multiplex relation embedding module constructs the context information that consists of the three relation contexts, thus effectively exploiting their benefits for relational reasoning. Since each sub-task re-quires different context information for relational reason-ing, our attentive fusion module selects requisite context in-formation for each sub-task from multiplex relation context and propagates the selected context information for con-text exchange between the branches. Unlike previous meth-ods [4, 15, 38, 44], we adopt three decoder branches which are responsible for human detection, object detection, and interaction classification, respectively. Therefore, the pro-posed method learns discriminative representation for each sub-task.
We evaluate MUREN on two public benchmarks, HICO-DET [3] and V-COCO [10], showing that MUREN achieves state-of-the-art performance on two benchmarks. The abla-tion study demonstrates the effectiveness of the multiplex relation embedding module and the attentive fusion mod-ule. Our contribution can be summarized as follows:
• We propose multiplex relation embedding module for
HOI detection, which generates context information using unary, pairwise, and ternary relations in an HOI instance.
• We propose the attentive fusion module that effectively propagates requisite context information for context exchange.
• We design a three-branch architecture to learn more discriminative features for sub-tasks, i.e., human de-tection, object detection, and interaction classification.
• Our proposed method, dubbed MUREN, outperforms state-of-the-art methods on HICO-DET and V-COCO benchmarks. 2.