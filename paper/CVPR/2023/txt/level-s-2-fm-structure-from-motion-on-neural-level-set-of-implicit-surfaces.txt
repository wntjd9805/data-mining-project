Abstract
This paper presents a neural incremental Structure-from-Motion (SfM) approach, Level-S2fM, which estimates the camera poses and scene geometry from a set of uncali-brated images by learning coordinate MLPs for the implicit surfaces and the radiance fields from the established key-point correspondences. Our novel formulation poses some new challenges due to inevitable two-view and few-view configurations in the incremental SfM pipeline, which com-plicates the optimization of coordinate MLPs for volumetric neural rendering with unknown camera poses. Neverthe-less, we demonstrate that the strong inductive basis convey-ing in the 2D correspondences is promising to tackle those challenges by exploiting the relationship between the ray sampling schemes. Based on this, we revisit the pipeline of incremental SfM and renew the key components, includ-ing two-view geometry initialization, the camera poses reg-istration, the 3D points triangulation, and Bundle Adjust-ment, with a fresh perspective based on neural implicit sur-faces. By unifying the scene geometry in small MLP net-works through coordinate MLPs, our Level-S2fM treats the zero-level set of the implicit surface as an informative top-down regularization to manage the reconstructed 3D points, reject the outliers in correspondences via querying SDF, and refine the estimated geometries by NBA (Neural BA).
Not only does our Level-S2fM lead to promising results on camera pose estimation and scene geometry reconstruction, but it also shows a promising way for neural implicit ren-dering without knowing camera extrinsic beforehand. 1.

Introduction
Structure-from-Motion (SfM) is a fundamental 3D vi-sion problem that aims at reconstructing 3D scenes and estimating the camera motions from a set of uncalibrated images. As a long-standing problem, there have been a tremendous of studies that are mostly established on the keypoint correspondences across viewpoints and the theo-retical findings of Multi-View Geometry (MVG) [11], and
*Corresponding author
Figure 1. SfM calculations on neural level sets. We learn to do geometric calculations including Triangulation, PnP, and Bun-dle Adjustment above neural level sets, which easily help to re-ject the outliers in the matches especially in the texture repeated scenes. Also, due to the continuous surface priors of neural level sets, we achieve better pose estimation accuracy and our recon-structed points are sticking on the surface which are painted with color in the figure. While, there are a lot of outlier 3d points re-constructed by COLMAP [32] which are painted by black. have formed three representative pipelines of Incremental
SfM [32], Global SfM [4, 43], and Hybrid SfM [5].
In this paper, we focus on the incremental pipeline of
SfM and we will use SfM to refer to the incremental SfM.
Given an unordered image set, an SfM system initializes the computation by a pair of images that are with well-conditioned keypoint correspondences to yield an initial set of feature tracks, then incrementally adds new views one by one to estimate the camera pose from the 2D-3D point correspondences and update the feature tracks with new matches. Because the feature tracks are generated by group-ing the putative 2D correspondences across viewpoints in bottom-up manners, they would be ineffective or inaccurate to represent holistic information of scenes. Accordingly, 1
Bundle Adjustment (BA) is necessary to jointly optimize the camera poses and 3D points in a top-down manner. The success of BA indicates that a global perspective is vital for accurate 3D reconstruction, however, their input feature tracks are the bottom-up cues without enough holistic con-straints for the 3D scenes. To this end, we study to integrate the top-down information into the SfM system by propos-ing a novel Level-S2fM. Fig. 1 illustrates a representative case for the classic SfM systems that generate more flying 3D scene points, which can be addressed by our method.
Our Level-S2fM is inspired by the recently-emerged neural implicit surface that could manage all 3D scene points as the zero-level set of the signed distance function (SDF). Because the neural implicit surfaces can be param-eterized by Multi-Layer Perceptrons (MLPs), it could be viewed as a kind of top-down information of 3D scenes and is of great potential for accurate 3D reconstruction. How-ever, because both the 3D scene and camera poses are to be determined, it poses a challenging problem:
How can we optimize a neural SDF (or other neu-ral fields such as NeRF) from only a set of uncal-ibrated images without any 3D information?
Most recently, the above problem was partially answered in BARF [18] and NeRF- - [42] that relaxed the requirement of optimizing Neural Radiance Fields [24] without know-ing accurate camera poses, but they can only handle the un-known pose configurations in small-scale face-forwarding scenes. Moreover, when we confine the problem in the in-cremental SfM pipelines, it would be more challenging as we need to optimize the neural fields with only two over-lapped images at the initialization stage. To this end, we found that the optimization of neural SDF can be accom-plished by the 2D matches at the initialization stage, and facilitate the management of feature tracks by querying the 3D points and tracing the 2D keypoints in a holistic way.
As shown in Fig. 1, we define a neural network that pa-rameterizes an SDF as the unified representation for the underdetermined 3D scene and accomplishes the computa-tions of PnP for camera pose intersection, the 3D points tri-angulation as well as the geometry refinement on the param-eterized SDF. In the initialization stage with a pair of over-lapped images, Level-S2fM uses the differentiable sphere tracing algorithm [19] to attain the corresponding 3d points of the keypoints and calculate the reprojection error to drive the joint optimization. For the traced 3d points with small
SDF values and 2D reprojection errors for its feature track, they are added into a dynamic point set and take the point set with feature tracks as the Lagrangian representation for the level sets. Because the pose estimation and the scene points reconstruction are sequentially estimated, the estima-tion errors will be accumulated. To this end, we present an
NBA (i.e., Neural Bundle Adjustment) that plays a similar role as in Bundle Adjustment, but it optimizes the implicit surface and camera poses from the explicit flow of points by the energy function of the reprojection errors, which can be viewed as an evolutionary step between Lagrangian and
Eulerian representations as discussed in [23].
In the experiments, we evaluate our Level-S2fM on a va-riety of scenes from the BlendedMVS [45], DTU [14], and
ETH3D [34] datasets. On the BlendedMVS dataset, our proposed Level-S2fM clearly outperforms the state-of-the-art COLMAP [32] by significant margins. On the DTU and
ETH3D datasets [14, 34], our method also obtains on-par performance with COLMAP for both camera pose estima-tion and dense surface reconstruction, which are all com-puted in one stage.
The contributions of this paper are in two folds:
• We present a novel neural SfM approach Level-S2fM, which formulates to optimize the coordinate MLP net-works for implicit surface and radiance field and esti-mate the camera poses and scene geometry. To the best of our knowledge, our Level-S2fM is the first implicit neural SfM solution on the zero-level set of surfaces.
• From the perspective of neural implicit fields learning, we show that the challenging problems of two-view and few-view optimization of neural implicit fields can be addressed by exploiting the inductive biases con-veyed in the 2D correspondences. Besides, our method presents a promising way for neural implicit rendering without knowing camera extrinsics beforehand. 2.