Abstract weights: (# weights: ($
Recent research in robust optimization has shown an overﬁtting-like phenomenon in which models trained against adversarial attacks exhibit higher robustness on the training set compared to the test set. Although pre-vious work provided theoretical explanations for this phe-nomenon using a robust PAC-Bayesian bound over the ad-versarial test error, related algorithmic derivations are at best only loosely connected to this bound, which implies that there is still a gap between their empirical success and our understanding of adversarial robustness theory.
To close this gap, in this paper we consider a different form of the robust PAC-Bayesian bound and directly min-imize it with respect to the model posterior. The derivation of the optimal solution connects PAC-Bayesian learning to the geometry of the robust loss surface through a Trace of
Hessian (TrH) regularizer that measures the surface ﬂat-ness. In practice, we restrict the TrH regularizer to the top layer only, which results in an analytical solution to the bound whose computational cost does not depend on the network depth. Finally, we evaluate our TrH regulariza-tion approach over CIFAR-10/100 and ImageNet using Vi-sion Transformers (ViT) and compare against baseline ad-versarial robustness algorithms. Experimental results show that TrH regularization leads to improved ViT robustness that either matches or surpasses previous state-of-the-art approaches while at the same time requires less memory and computational cost. 1.

Introduction
Despite their success in a wide range of ﬁelds and tasks, deep learning models still remain susceptible to manipu-lating their outputs by even tiny perturbations to the input
[6, 7, 10, 19, 30, 32, 43, 47]. Several lines of work have fo-cused on developing robust training techniques against such
*Work done in Google.
†Corresponding author clean adversarial
L a y e r 1
L a y e r
N
-1
T o p
L a y e r
" !")
Trace of Hessian 
#$(∇!!
+
Robustness Loss 
!"
+
| "" |#
#
# + | "$ |#
Figure 1. We propose Trace of Hessian (TrH) regularization for training adversarially robust models. In addition to an ordinary robust loss (e.g., TRADES [54]), we regularize the TrH of the loss with respect to the weights of the top layer to encourage ﬂatness.
The training objective is the result of direct PAC-Bayesian bound minimization in Theorem 3. adversarial attacks [8, 20, 31, 32, 36, 41, 46, 48, 54].
Im-portantly, Rice et al. [38] observe a robust overﬁtting phe-nomenon, referred to as the robust generalization gap, in which a robustly-trained classiﬁer shows much higher ac-curacy on adversarial examples from the training set, com-pared to lower accuracy on the test set. Indeed, several tech-nical approaches have been developed that could alleviate this overﬁtting phenomenon, including `2 weight regular-ization, early stopping [38], label smoothing, data augmen-tation [51, 53], using synthetic data [21] and etc.
According to learning theory, the phenomenon of overﬁt-ting can be characterized by a PAC-Bayesian bound [4,9,18, 34, 42] which upper-bounds the expected performance of a random classiﬁer over the underlying data distribution by its performance on a ﬁnite set of training points plus some ad-ditional terms. Although several prior works [21, 24, 26, 49] have built upon insights from the PAC-Bayesian bound, none attempted to directly minimize the upper bound, likely due to the fact that the minimization of their forms of the
PAC-Bayesian bound do not have an analytical solution.
In this paper, we rely on a different form of the PAC-       
Bayesian bound [18], which can be readily optimized using a Gibbs distribution [16] with which we derive a second-order upper bound over the robust test loss. Interestingly, the resulting bound consists of a regularization term that in-volves Trace of Hessian (TrH) [12] of the network weights, a well-known measure of the loss-surface ﬂatness.
For practical reasons, we limit TrH regularization to the top layer of the network only because computing a Hessian matrix and its trace for the entire network is too costly. We further derive the analytical expression of the top-layer TrH and show both theoretically and empirically that top-layer
TrH regularization has a similar effect as regularizing the entire network. The resulting TrH regularization (illustrated in Figure 1) is less expensive and more memory efﬁcient compared to other competitive methods [21, 24, 26, 49].
In summary, our contributions are as follows: (1) We provide a PAC-Bayesian upper-bound over the robust test loss and show how to directly minimize it (Theorem 3). To the best of our knowledge, this has not been done by prior work. Our bound includes a TrH term which encourages the model parameters to converge at a ﬂat area of the loss func-tion; (2) Taking efﬁciency into consideration, we restrict the TrH regularization to the top layer only (Algorithm 1) and show that it is an implicit but empirically effective reg-ularization on the TrH of each internal layer (Theorem 4 and Example 1); and (3) Finally, we conduct experiments with our new TrH regularization and compare the results to several baselines using Vision Transformers [14]. On
CIFAR-10/100, our method consistently matches or beats the best baseline. On ImageNet, we report a signiﬁcant gain (+2.7%) in robust accuracy compared to the best baseline and establish a new state-of-the-art result of 48.9%. 2.