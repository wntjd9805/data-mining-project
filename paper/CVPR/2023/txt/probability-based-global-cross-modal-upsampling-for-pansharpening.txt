Abstract
Pansharpening is an essential preprocessing step for re-mote sensing image processing. Although deep learning (DL) approaches performed well on this task, current up-sampling methods used in these approaches only utilize the local information of each pixel in the low-resolution multi-spectral (LRMS) image while neglecting to exploit its global information as well as the cross-modal information of the guiding panchromatic (PAN) image, which limits their per-formance improvement. To address this issue, this paper develops a novel probability-based global cross-modal up-sampling (PGCU) method for pan-sharpening. Precisely, we first formulate the PGCU method from a probabilis-tic perspective and then design an efficient network mod-ule to implement it by fully utilizing the information men-tioned above while simultaneously considering the chan-nel specificity. The PGCU module consists of three blocks, i.e., information extraction (IE), distribution and expecta-tion estimation (DEE), and fine adjustment (FA). Exten-sive experiments verify the superiority of the PGCU method compared with other popular upsampling methods. Addi-tionally, experiments also show that the PGCU module can help improve the performance of existing SOTA deep learn-ing pansharpening methods. The codes are available at https://github.com/Zeyu-Zhu/PGCU .
Figure 1. Comparison between local upsampling methods and our proposed PGCU method. The local method has limited receptive field and thus only utilizes the local information of LRMS for up-sampling, while our proposed PGCU method can fully exploit the rich global information of LRMS and the cross-modal global in-formation of PAN. 1.

Introduction
Pansharpening aims to reconstruct a high-resolution multispectral image (HRMS) from a low-resolution multi-spectral image (LRMS) under the guidance of a panchro-matic image (PAN). It’s an indispensable pre-processing step for many subsequent remote sensing tasks, such as
*Corresponding author object detection [11, 26], change detection [1, 19], unmix-ing [3] and classification [7, 8].
The last decades have witnessed the great development of pansharpening methods. The typical approaches include component substitution (CS) approaches [10, 18, 23, 24], multi-resolution analysis (MRA) methods [21, 25, 31], and variational optimization (VO) methods [12, 13, 15, 16, 38].
Recently, with the rapid development of deep learning,
plenty of deep learning-based methods [4,5,14,43,45] have been proposed to tackle this task due to its powerful non-linear fitting and feature extraction ability. Among these methods, almost all the approaches have a pipeline that up-samples the LRMS image first and then carries out other super-resolution operations. These approaches treat upsam-pling as an essential and indispensable component for this task. For instance, as for residual networks (e.g., PanNet), the upsampled image is directly added to the network’s out-put, which makes the quality of the upsampled image an essential factor for model performance.
However, hardly any approaches explored to design a reasonable upsampling method for pansharpening but just simply utilized bicubic interpolation [9] and transposed convolution [17] as their upsampling module. At the same time, upsampling methods proposed for other tasks aren’t suitable for pansharpening either, such as attention-based image upsampling (ABIU) [22] and ESPCNN [32]. Almost all the aforementioned upsampling methods are in the form of local interpolation and thus suffer from a limited recep-tive field issue. Therefore, these local interpolation-based upsampling methods fail to exploit similar patterns globally, while there are usually many non-local similar patches in remote sensing images, as shown in Figure 1(b). Addition-ally, almost all these upsampling methods are not capable of utilizing useful structure information from the PAN image.
Also, some existing upsampling methods, e.g., ABIU [22] ignore channel specificity, which utilizes the same weight for the same position of all channels, which is unsuitable for pansharpening due to the significant difference among spectral image channels.
In summary, these existing up-sampling methods suffer from either insufficient utilization of information (i.e., global information of LRMS, structure information of PAN) or incomplete modeling of the prob-lem (i.e., channel specificity issue).
To address the aforementioned problems, we propose a novel probability-based global cross-modal upsampling method (PGCU) to exploit cross-modal and global infor-mation while considering channel specificity. The reason why we utilize probabilistic modeling is that pansharpening is essentially an ill-posed image inverse problem. Proba-bilistic modeling can be used to better adapt to the char-acteristics of the problem itself. Specifically, an approxi-mate global discrete distribution value is sampled from the pixel value space for each channel which can thus charac-terize the common property of each channel and the dis-tinctive property of different channels. Then, we establish a cross-modal feature vector for each pixel in the upsampled
HRMS image and discrete distribution value, using not only the LRMS image but also the PAN image. Inspired by the main idea of Transformer [36], we utilize vector similarity to calculate the probability value for each pixel on its chan-nel distribution. Finally, PGCU calculates the pixel values of the upsampled image by taking the expectation.
To implement the PGCU method, we design a network module containing three blocks, i.e., information extraction (IE) module block, distribution and expectation estimation (DEE) block, and fine adjustment (FA) block. Firstly, IE ex-tracts spectral and spatial information from LRMS and PAN images to generate channel distribution value and cross-modal information. Next, DEE utilizes this information to construct cross-modal feature vectors for each pixel in the upsampled image and generate the distribution value, re-spectively. Then, they are used to estimate the distribution probability for each pixel in the upsampled image. Finally,
FA further compensates for using the local information and channel correlation of the upsampled image.
To further explore the results obtained by PGCU, we uti-lize information theory to analyze pixel distribution. Specif-ically, by clustering pixels of the obtained upsampled image using JS divergence as the distance measurement, the spa-tial non-local correlation property of the image can be eas-ily observed. Besides, by visualizing the information en-tropy image of each channel in the upsampled image, chan-nel specificity can be easily observed as well, which also verifies that the PGCU method indeed learns the difference among channels.
To sum up, the contributions of this work are as follows:
• We propose a novel probability-based upsampling model for pan-sharpening. This model assumes each pixel of the upsampled image to obey a probability dis-tribution given the LRMS image and PAN image.
• We design a new upsampling network module to im-plement the probability-based upsampling model. The module can fully exploit the global information of
LRMS and the cross-modal information of PAN. As far as we know, PGCU is the first upsampling module specifically designed for pan-sharpening.
• Extensive experiments verify that the PGCU module can be embedded into the existing SOTA pansharpen-ing networks to improve their performance in a plug-and-play manner. Also, the PGCU method is a univer-sal upsampling method and has potential application in other guided image super-resolution tasks. 2.