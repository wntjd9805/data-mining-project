Abstract
Deep learning based methods for super-resolution have become state-of-the-art and outperform traditional ap-proaches by a signiﬁcant margin. From the initial mod-els designed for ﬁxed integer scaling factors (e.g. ×2 or
×4), efforts were made to explore different directions such as modeling blur kernels or addressing non-integer scaling factors. However, existing works do not provide a sound framework to handle them jointly.
In this paper we pro-pose a framework for generic image resampling that not only addresses all the above mentioned issues but extends the sets of possible transforms from upscaling to generic transforms. A key aspect to unlock these capabilities is the faithful modeling of image warping and changes of the sam-pling rate during the training data preparation. This allows a localized representation of the implicit image degradation that takes into account the reconstruction kernel, the lo-cal geometric distortion and the anti-aliasing kernel. Using this spatially variant degradation map as conditioning for our resampling model, we can address with the same model both global transformations, such as upscaling or rotation, and locally varying transformations such lens distortion or undistortion. Another important contribution is the auto-matic estimation of the degradation map in this more com-plex resampling setting (i.e. blind image resampling). Fi-nally, we show that state-of-the-art results can be achieved by predicting kernels to apply on the input image instead of direct color prediction. This renders our model applicable for different types of data not seen during the training such as normals. 1.

Introduction
Thanks to recent advances in deep learning based super-resolution which allow to infer impressive high frequency details from low resolution inputs, it has become possible to bridge the gap between content and display resolution with-out noticeable degradation in quality. This is beneﬁcial in different contexts and, among other things, has enabled new visual effects production workﬂows to operate in 2K while still ultimately delivering at 4K resolution by performing a 2x upscale just before ﬁnal delivery.
However, super-resolution is not the only image transfor-mation that can occur in typical visual effects pipelines, and it is very common to perform additional tasks such as im-age rectiﬁcation, retargeting, lens (un)distortion or image
warping. All these transformations require more complex image resampling solutions. Even the simple case of lens undistortion corresponds to a more complex type of resam-pling — which might locally upscale or downscale — that existing super-resolution methods do not support. As a re-sult, one has to fall back to traditional interpolation based resampling approaches which can result in a noticeable and unnecessary loss in quality.
To the best of our knowledge, there is only one learn-ing based method that considers more complex resam-plings [15]. However, this approach has two drawbacks:
On the one hand it is not optimally suited for real world content that might suffer from different kinds of implicit degradations from different blur kernels. On the other hand the solution seems more complex than needed due to the multi-scale warping and blending strategy.
In this paper we propose a framework for generic neural image resampling that is lean and better applicable to real world scenarios through handling implicit degradations. To achieve this, we build upon fundamental concepts of signal processing and decompose the resampling process into dif-ferent stages, namely reconstruction, geometric distortion, and anti-aliasing. With this, we are able to create proper training examples to better handle and interactively control spatially variant degradation maps that are expected in im-age resampling. In addition to this, we design our approach to be able to predict kernels instead of directly outputting color values which makes the model more robust and en-ables consistent resampling of other channels, such as nor-mals. Figure 1 illustrates this with a complex example: the transformation consists of image rectiﬁcation and an in-crease in image resolution. This is an image that was not downscaled and the blur kernel is unknown. Our method automatically estimates the degradation map and produces sharper results than existing methods. Additionally it’s pos-sible to directly create outputs at different sharpness levels.
This is the ﬁrst time such applications are possible in image resampling.
Finally, we are able to show that our approach is able to beat the state-of-the-art despite its lean design allow-ing higher quality processing in parts of the visual effects pipeline that until now could not beneﬁt from advances in deep learning. 2.