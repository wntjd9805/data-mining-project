Abstract
We propose a Unified Pose Sequence Modeling ap-proach to unify heterogeneous human behavior understand-ing tasks based on pose data, e.g., action recognition, 3D pose estimation and 3D early action prediction. A major obstacle is that different pose-based tasks require different output data formats. Specifically, the action recognition and prediction tasks require class predictions as outputs, while 3D pose estimation requires a human pose output, which limits existing methods to leverage task-specific network ar-chitectures for each task. Hence, in this paper, we propose a novel Unified Pose Sequence (UPS) model to unify het-erogeneous output formats for the aforementioned tasks by considering text-based action labels and coordinate-based human poses as language sequences. Then, by optimiz-ing a single auto-regressive transformer, we can obtain a unified output sequence that can handle all the aforemen-tioned tasks. Moreover, to avoid the interference brought by the heterogeneity between different tasks, a dynamic rout-ing mechanism is also proposed to empower our UPS with the ability to learn which subsets of parameters should be shared among different tasks. To evaluate the efficacy of the proposed UPS, extensive experiments are conducted on four different tasks with four popular behavior understand-ing benchmarks. 1.

Introduction
Pose sequences, which capture the movements of the hu-man body via human joint coordinates, are well-known to be an efficient and effective representation of human mo-tion and behaviour [58,80]. This is mainly because pose se-quences often provide enough information to characterize complex motion patterns [31], while being robust against superficial visual variations such as the background, cloth-ing texture and illumination conditions [43,44]. At the same
*equal contribution
†corresponding author time, by using depth sensors such as the Kinect, pose data can also be conveniently obtained in real-time to facilitate downstream applications. Therefore, the potential of pose sequences to tackle behaviour understanding has attracted a lot of attention in recent years.
Notably, the usage of pose sequences has been widely explored across many practical applications, including human-robot interaction [1, 59], augmented reality [4, 51] and security surveillance [18, 71]. Specifically, pose se-quences, as informative inputs, can facilitate certain aspects in these applications, such as action recognition [12, 44, 48, 66, 67, 86–88], 3D pose estimation [41, 45, 84, 92, 95, 96] and early action prediction [23,35, 39, 77,78], making these tasks popular and important areas of research.
However, existing methods for each task still often re-quire task-specific architectures, e.g., hourglass networks for pose estimation [84] and specialized GCN architectures for action recognition [11,69], while the performing of mul-tiple pose-based tasks with a single model is not well ex-plored. Therefore, in order to perform multiple tasks, users will often need to design and train multiple separate models, which can be inconvenient and inefficient.
Hence, in this work, we seek to simplify and unify the modeling for several popular and important pose-based tasks: 3D action recognition, 2D action recognition, 3D pose estimation and 3D early action prediction. This is a challenging goal that has not been achieved before, requir-ing a single model to cover a large scope involving 2D tasks, 3D tasks, as well as 2D to 3D lifting. By unifying these pose-based tasks and removing the need to design and train separate task-specific models to tackle different pose-based tasks, we can greatly reduce the difficulty and complexity involved in tackling these tasks. Moreover, a unified model is also an elegant way of handling multiple tasks that brings us one step closer in our pursuit of general purpose vision systems [25], i.e., an efficient multi-purpose AI model akin to the human brain.
To this end, we propose a Unified Pose Sequence (UPS) model to unify the architecture and output format for mul-tiple popular pose-based tasks. Our UPS is a single uni-fied model that simultaneously tackles multiple tasks with-out task-specific designs or branches, i.e., with a unified decoder. In order to unify the output formats of different tasks (which can be very different) to be produced by a sin-gle decoder, our UPS predicts a sequence of output tokens, similar to language modeling tasks. Specifically, our UPS’s decoder auto-regressively produces a sequence of output to-kens, such that the output sequence can potentially be of different lengths to meet the requirements of multiple tasks.
Additionally, these output tokens can be interpreted as text embeddings, which are a powerful and general represen-tation that can be mapped into various predictions as re-quired. Moreover, to mitigate the potential destructive inter-ference [60, 90] brought by the heterogeneity between dif-ferent tasks, we propose a dynamic routing mechanism for our UPS that facilitates parameter sharing between tasks.
In summary, our contributions are as follows:
• We propose a Unified Pose Sequence (UPS) model that can tackle several popular pose-based tasks through a single unified framework. UPS simultaneously tack-task-specific designs or les multiple tasks without branches by modeling the output as a sequence of to-kens, enabling it to handle different output formats.
• On four popular pose-based tasks (3D action recog-nition, 2D action recognition, 3D pose estimation and 3D early action prediction), UPS achieves good perfor-mance that is comparable to state-of-the-art methods. 2.