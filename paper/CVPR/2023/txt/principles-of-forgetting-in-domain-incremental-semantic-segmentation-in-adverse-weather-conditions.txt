Abstract
Deep neural networks for scene perception in automated vehicles achieve excellent results for the domains they were trained on. However, in real-world conditions, the do-main of operation and its underlying data distribution are subject to change. Adverse weather conditions, in partic-ular, can significantly decrease model performance when such data are not available during training. Addition-ally, when a model is incrementally adapted to a new do-main, it suffers from catastrophic forgetting, causing a sig-nificant drop in performance on previously observed do-mains. Despite recent progress in reducing catastrophic forgetting, its causes and effects remain obscure. Therefore, we study how the representations of semantic segmenta-tion models are affected during domain-incremental learn-ing in adverse weather conditions. Our experiments and representational analyses indicate that catastrophic forget-ting is primarily caused by changes to low-level features in domain-incremental learning and that learning more gen-eral features on the source domain using pre-training and image augmentations leads to efficient feature reuse in sub-sequent tasks, which drastically reduces catastrophic for-getting. These findings highlight the importance of meth-ods that facilitate generalized features for effective contin-ual learning algorithms. 1.

Introduction
Semantic segmentation is widely used for environment perception in automated driving, where it aims at recogniz-ing and comprehending images at the pixel level. One fun-damental constraint of the traditional deep learning-based semantic segmentation models is that they are often only trained and evaluated on data collected mostly in clear weather conditions and that they assume that the domain of the training data matches the domain they operate in. How-ever, in the real world, those autonomous driving systems
Figure 1. Activation drift between models f1 to f0 measured by relative mIoU on the first task of the models stitched together at specific layers (horizontal axis). The layers of the encoder are marked in the gray area, the decoder layers in the white area.
Layer-stitching reveals that during domain-incremental learning, changes in low-level features are a major cause of forgetting. With an improved training scheme, combining simple augmentations, exchanging normalization layers and using pre-training, the model is optimized to reuse low-level features during incremental learn-ing, leading to significant reduction of catastrophic forgetting. are faced with constantly changing driving environments and variable input data distributions. Specifically, changing weather conditions can have adverse effects on the perfor-mance of segmentation models.
Therefore, a semantic segmentation model needs to be adapted to these conditions. A naive solution to this prob-lem would be to incrementally fine-tune the model to new domains with labeled data. However, fine-tuning a neural network to a novel domain will, in most cases, lead to a severe performance drop in previously observed domains.
This phenomenon is usually referred to as catastrophic for-getting and is a fundamental challenge when training a neu-ral network on a continuous stream of data. Recently pro-posed methods mostly mitigate this challenge by replaying data from previous domains, re-estimating statistics or even in an unsupervised manner by transferring training images in the style of the novel domain [32, 48, 52]. The focus of our work is to study how the internal representations of se-mantic segmentation models are affected during domain-incremental learning and how efficient feature reuse can mitigate forgetting without explicit replay of the previous domain. Our main contributions are: 1. We analyze the activation drift that a model’s layers are subjected to when adapting from good to adverse weather conditions by stitching them with the previous task’s network. We reveal that the major cause of for-getting is a shift of low-level representations in the first convolution layer that adversely affects the population statistics of the following BatchNorm Layer. 2. Using different augmentation strategies to match the target domains in color statistics or in the frequency domain, we reveal that learning color-invariant fea-tures stabilizes the representations in early layers, as they don’t change when the model is adapted to a new domain. 3. With a combination of pre-training, augmentations and exchanged normalization layers, we achieve an over-all reduction of forgetting of ∼20% mIoU compared to fine-tuning without using any form of replay and prove the effectiveness of pre-training and augmenta-tions which are often overlooked in continual learning. 2.