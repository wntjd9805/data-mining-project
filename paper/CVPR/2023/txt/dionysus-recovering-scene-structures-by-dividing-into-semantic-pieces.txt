Abstract mess.
Most existing 3D reconstruction methods result in either detail loss or unsatisfying efficiency. However, effective-ness and efficiency are equally crucial in real-world ap-plications, e.g., autonomous driving and augmented reality.
We argue that this dilemma comes from wasted resources on valueless depth samples. This paper tackles the prob-lem by proposing a novel learning-based 3D reconstruc-tion framework named Dionysus. Our main contribution is to find out the most promising depth candidates from es-timated semantic maps. This strategy simultaneously en-ables high effectiveness and efficiency by attending to the most reliable nominators. Specifically, we distinguish unre-liable depth candidates by checking the cross-view semantic consistency and allow adaptive sampling by redistributing depth nominators among pixels. Experiments on the most popular datasets confirm our proposed framework’s effec-tiveness. 1.

Introduction
Recovering 3D structures from 2D images is one of the most fundamental computer vision tasks [7, 25, 26, 68] and has wide applications in various scenarios (e.g., autonomous driving, metaverse, and augmented reality).
Thanks to the popularity of smartphones, high-quality RGB videos are always obtainable. Since each image describes only a tiny piece of the whole scenario [31, 33], reconstruc-tion from multiple frames [44, 50] is more attractive than from a single image [13, 14]. Although model quality and real-time response are equally essential, the existing 3D reconstruction methods have difficulty performing well in both aspects. For example, multi-view stereo (MVS) mod-els [63,73] consume seconds on each image, while real-time approaches [9, 57, 64] lead to missing details or large-area
The mainstream reconstruction methods [15,63,72] gen-erally sample a set of candidate depths or voxels, then use neural networks (e.g., CNNs [21] and transformers [58]) to evaluate each candidate’s reliability. The candidate num-ber is generally small because of the evaluation networks’ high computational demand. Consequently, the reconstruc-tion quality becomes unsatisfying because the ground truth is less likely to be sampled.
Pursuing a higher candidate sampling density, CasMVS-Net [15] shrinks the depth range in a coarse-to-fine fashion;
IS-MVSNet [63] searches for new candidates according to the estimated error distribution; NeuralRecon [57] prunes the voxels thought to be unreliable in the previous predic-tions. All these methods select candidates according to the initial depth estimations. Notably, small objects and del-icate structures are hard to recover in the beginning low-resolution phase because they require a high resolution to distinguish. As a result, the final reconstruction often suf-fers from missing objects and crude details because the ac-tual depth can be outside the final search range when the initial estimation is unreliable. However, decent reconstruc-tion quality on delicate objects is crucial to many real-world applications. Specifically, traffic accidents may occur if any pedestrian or warning post fails to recover; frequent collisions and even fire disasters might happen if cleaning robots cannot well reconstruct table legs and electric ca-bles. Besides the defects in meticulous structures, coarse-to-fine models also have room to improve efficiency. As mentioned, the mainstream coarse-to-fine methods sample and then evaluate initial candidates multiple times to locate the most valuable candidate depths. Notably, examining the preliminary candidates may be more expensive (usually two times more [15, 78]) than assessing the final nominators.
In addition to the costly evaluation networks widely adopted in coarse-to-fine architectures, another natural so-Figure 1. The overall architecture of our framework. We first estimate a semantic map for the current frame and then retrieve the former semantic estimations. After that, we locate the most valuable depth candidates through the semantic maps. Finally, we predict the depth map for the current frame by examining each depth candidate. lution is to measure each depth candidate’s reliability ac-cording to the photometric consistency among RGB images or feature maps from different views. The basic logic be-hind these methods is that pixels from distinct perspectives should own the same color if they are the correct projec-tions from the same 3D point. However, a 3D point may look distinct in different views due to illumination, trans-parency, and reflection. Moreover, candidates close to but not precisely coinciding with the ground truth may have dif-ferent colors for delicate objects, thus leading to low photo-metric consistency. Consequently, the found candidate may correspond to a pixel distant from the ground truth but of a similar color.
To get rid of detail defects and keep efficiency, it be-comes crucial to accurately and efficiently find the most promising candidate depths. This paper proposes a novel high-quality real-time 3D reconstruction framework named
Dionysus, which looks for depth hypotheses based on se-mantic estimations. Precisely, we distinguish each depth candidate’s reliability according to its semantic consistency among warped views. Fig. 1 illustrates the overall archi-tecture of our framework. Our intuition is that two pixels should share the same semantic label if they are projections of the same 3D point. We argue that selecting depth candi-dates according to the semantic tags results in various ben-efits: 1. Consistent: A 3D point may have distinct colors when observing from different perspectives, but its semantic label never changes. 2. Efficient: Semantic estimation requires a meager cost.
A semantic segmentation model may spend only mil-liseconds on each frame [11, 47] while evaluating each cost volume in coarse layers generally takes ten times more cost.
In addition, most hierarchical methods shrink the depth range only by half in each stage, while our method may significantly reduce the depth range on delicate objects (e.g., desk legs). 3. Dense: Tiny objects always get missing in hierarchical frameworks because the initial samples are too sparse.
However, the semantic maps are highly dense, thus re-taining fine details. 4. Adaptive: Semantics indicate various properties of the pixel. For example, an electric cable may demand highly dense samples to recover, but a wall may not. In other words, we can assign each pixel the most suitable sampling density according to its semantic estimation.
Depth Reassignment: A bed pixel may have much more valid depth candidates than a pen pixel after the semantic-based pruning because there are likely many bed pixels in other views. Consequently, we cannot form a regular cost volume based on the pruned depth candidates because pix-els may have different numbers of valid depth candidates.
However, most GPUs are not designed for irregular inputs
and are inefficient in such cases. Thus, we further propose reallocating depth samples from pixels with excess valid candidates to those in the opposite.
In this way, all pix-els finally have the same number of candidates and thus can be conveniently computed by GPUs. Moreover, we sam-ple more densely for delicate structures, otherwise more sparsely, because tiny objects have a narrower depth range after semantic pruning, and all pixels have the same depth number.
To summarize, this paper has two significant contribu-tions: 1. Instead of densely evaluating all depths or sparsely evaluating limited depths, we efficiently select the most promising depth candidates based on the cross-view semantic consistency. 2. We reallocate depth samples among pixels to make our model adaptive to objects and efficient on GPUs.
The mentioned contributions significantly benefit the ef-fectiveness while retaining efficiency. Our extensive exper-iments on the most popular 3D reconstruction datasets [5] further verify our proposed method’s validity. 2.