Abstract
We propose a method that trains a neural radiance field (NeRF) to encode not only the appearance of the scene but also semantic correlations between scene points, regions, or entities – aiming to capture their mutual co-variation pat-terns.
In contrast to the traditional first-order photomet-ric reconstruction objective, our method explicitly regular-izes the learning dynamics to align the Jacobians of highly-correlated entities, which proves to maximize the mutual information between them under random scene perturba-tions. By paying attention to this second-order information, we can shape a NeRF to express semantically meaningful synergies when the network weights are changed by a delta along the gradient of a single entity, region, or even a point.
To demonstrate the merit of this mutual information model-ing, we leverage the coordinated behavior of scene entities
*Equal Contributions
†Corresponding Author <yanchaoy@hku.hk>. The author is also af-filiated with the HKU Musketeers Foundation Institute of Data Science. that emerges from our shaping to perform label propagation for semantic and instance segmentation. Our experiments show that a JacobiNeRF is more efficient in propagating annotations among 2D pixels and 3D points compared to
NeRFs without mutual information shaping, especially in extremely sparse label regimes – thus reducing annotation burden. The same machinery can further be used for entity selection or scene modifications. Our code is available at https://github.com/xxm19/jacobinerf. 1.

Introduction
When a real-world scene is perturbed, the response is generally local and semantically meaningful, e.g., a slight knock on a chair will result in a small displacement of just that chair. Such coherence in the perturbation of a scene evidences high mutual information between certain scene points or entities that can be leveraged to discover instances or semantic groups [37, 38]. A NeRF scene representation, however, solely supervised with 2D photometric loss may not converge to a configuration that reflects the actual scene
structure [41]; even if the density is correctly estimated, the network in general will not be aware of the underlying se-mantic structure. As shown in Fig. 1, a perturbation on a specific entity of the scene through the network weights ac-tivates almost all other entities.
This lack of semantic awareness may not be a problem for view synthesis and browsing, but it clearly is of con-cern when such neural scene representations are employed for interactive tasks that require understanding the underly-ing scene structure, e.g., entity selection, annotation prop-agation, scene editing, and so on. All these tasks can be greatly aided by a representation that better reflects the cor-relations present in the underlying reality. We take a step towards endowing neural representations with such aware-ness of the mutual scene inter-dependencies by asking how it is possible to train a NeRF, so that it not only reproduces the appearance and geometry of the scene, but also gener-ates coordinated responses between correlated entities when perturbed in the network parameter space.
Current approaches that encode semantics largely treat semantic labels (e.g., instance segmentation) [17, 42] as a separate channel, in addition to density or RGB radiance.
However, in the semantics case, the value of the channel (e.g., instance ID) is typically an artifact of the implemen-tation. What really matters is the decomposition of the 2D pixels (or of the scene 3D points) the NeRF encodes into groups – this is because semantics is more about rela-tionships than values. Thus, we introduce an information-theoretic technique whose goal is to “shape” an implicit
NeRF representation of a scene to better reflect the underly-ing regularities (“semantics”) of the world; so as to enforce consistent variation among correlated scene pixels, points, regions, or entities, enabling efficient information propaga-tion within and across views.
The key to the proposed “shaping” technique is an equiv-alence between mutual information and the normalized in-ner product (cosine similarity) of the Jacobians at two pixels or 3D points. More explicitly, if we apply random delta per-turbations to the NeRF weights, the induced random values of two pixels share mutual information up to the absolute cosine similarity of their gradients or Jacobians with respect to the weights computed at the unperturbed NeRF. This the-oretical finding ensures a large correlation between scene entities with high mutual information – and thus coherent perturbation-induced behaviors – if their tangent spaces are aligned. Based on this insight, we apply contrastive learn-ing to align the NeRF gradients with general-purpose self-supervised features (e.g., DINO), which is why we term our
NeRF “JacobiNeRF”. While several prior works [16, 30] distill 1st-order semantic information from 2D views to get a consensus 1st-order feature in 3D, we instead regularize the NeRF using 2nd-order, mutual information based con-trastive shaping on the NeRF gradients to achieve semantic consensus – now encoded in the NeRF tangent space.
The proposed NeRF shaping sets up resonances between correlated pixels or points and makes the propagation of all kinds of semantic information possible from sparse annota-tions – because pixels that co-vary with the annotated one are probably of the same semantics indicated by the mutual information equivalence. For example, we can use such res-onances to propagate semantic or instance information as shown in Sec. 3.4, where we also show that our contrastive shaping can be applied to gradients of 2D pixels, or of 3D points. The same machinery also enables many other func-tions, including the ability to select an entity by clicking at one of its points or the propagation of appearance edits, as illustrated in Fig. 9. Additionally, our approach suggests the possibility that a NeRF shaped with rich 2nd-order re-lational information in the way described may be capable of propagating many additional kinds of semantics without further re-shaping – because the NeRF coefficients have al-ready captured the essential “DNA” of points in the scene, of which different semantic aspects are just different expres-sions. In summary, our key contributions are:
• We propose the novel problem of shaping NeRFs to re-flect mutual information correlations between scene enti-ties under random scene perturbations.
• We show that the mutual information between any two scene entities is equivalent to the cosine similarity of their gradients with respect to the perturbed weights.
• We develop JacobiNeRF, a shaping technique that ef-fectively encodes 2nd-order relational information into a
NeRF tangent space via contrastive learning.
• We demonstrate the effectiveness of JacobiNeRF with state-of-the-art performance on sparse label propagation for both semantic and instance segmentation tasks. 2.