Abstract
Coordinate-based implicit neural networks, or neural fields, have emerged as useful representations of shape and appearance in 3D computer vision. Despite advances, however, it remains challenging to build neural fields for categories of objects without datasets like ShapeNet that provide “canonicalized” object instances that are consis-tently aligned for their 3D position and orientation (pose).
We present Canonical Field Network (CaFi-Net), a self-supervised method to canonicalize the 3D pose of instances from an object category represented as neural fields, specif-ically neural radiance fields (NeRFs). CaFi-Net directly learns from continuous and noisy radiance fields using a
Siamese network architecture that is designed to extract equivariant field features for category-level canonicaliza-tion. During inference, our method takes pre-trained neu-ral radiance fields of novel object instances at arbitrary 3D pose and estimates a canonical field with consistent 3D pose across the entire category. Extensive experiments on a new dataset of 1300 NeRF models across 13 object categories show that our method matches or exceeds the performance of 3D point cloud-based methods. 1.

Introduction
Neural fields [59]—coordinate-based neural networks that implicitly parameterize signals—have recently gained significant attention as representations of 3D shape [6, 22, 28], view-dependent appearance [24, 42], and motion [25].
In particular, neural radiance fields (NeRFs) [24], have been successfully used in problems such as novel view synthe-sis [3, 4, 66], scene geometry extraction [55, 61], capturing dynamic scenes [19, 29, 30, 33, 52], 3D semantic segmenta-tion [53, 68], and robotics [1, 13, 21].
Despite the progress, it remains challenging to build neu-ral fields that represent an entire category of objects. Pre-vious methods sidestep the problem by overfitting on a sin-gle instance [24], or learning [22, 28, 63] on datasets like
ShapeNet [5] that contain objects that are manually canon-icalized – oriented consistently for 3D position and orien-tation (3D pose) across a category. This strong supervision makes it easier to learn over categories, but limits their ap-plication to data that contain these labels. Recent work has proposed methods for self-supervised learning of 3D pose canonicalization [40, 43, 47], however, these operate on 3D point clouds, meshes, or voxels – but not neural fields.
In this paper, we present Canonical Field Network (CaFi-Net), a self-supervised method for category-level canonicalization of the 3D position and orientation of ob-jects represented as neural fields, specifically neural radi-ance fields. Canonicalizing neural fields is challenging be-cause, unlike 3D point clouds or meshes, neural fields are continuous, noisy, and hard to manipulate since they are pa-rameterized as the weights of a neural network [60]. To ad-dress these challenges, we first extend the notion of equiv-ariance to continuous vector fields and show how networks for processing 3D point clouds [50] can be extended to op-erate directly on neural radiance fields. We design CaFi-Net as a Siamese network that contains layers to extract equivariant features directly on vector fields. These field features are used to learn a canonical frame that is consis-tent across instances in the category. During inference, our method takes as input neural radiance fields of object in-stances from a category at arbitrary pose and estimates a canonical field that is consistent across the category. To handle noise in radiance fields from NeRF, our method in-corporates density-based feature weighting and foreground-background clustering.
Our approach learns canonicalization without any super-vision labels on a new dataset of 1300 pre-trained NeRF models of 13 common ShapeNet categories in arbitrary 3D pose (see Figure 1). We introduce several self-supervision loss functions that encourage the estimation of a consistent canonical pose. In addition, we present extensive quantita-tive comparisons with baselines and other methods on stan-dardized canonicalization metrics [37] over 13 object cat-egories. In particular, we show that our approach matches or exceeds the performance of 3D point cloud-based meth-ods. This enables the new capability of directly operating on neural fields rather than converting them to point clouds for canonicalization. To sum up, we contribute:
• Canonical Field Network (CaFi-Net), the first method for self-supervised canonicalization of the 3D position and orientation (pose) of objects represented as neural radiance fields.
• A Siamese neural network architecture with equivari-ant feature extraction layers that are designed to di-rectly operate on continuous and noisy radiance fields from NeRF.
• A public dataset of 1300 NeRF models from 13
ShapeNet categories including posed images, and weights for evaluating canonicalization performance. 2.