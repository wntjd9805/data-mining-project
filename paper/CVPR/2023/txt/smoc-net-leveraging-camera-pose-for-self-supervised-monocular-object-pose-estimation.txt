Abstract
Recently, self-supervised 6D object pose estimation, where synthetic images with object poses (sometimes jointly with un-annotated real images) are used for training, has attracted much attention in computer vision. Some typical works in literature employ a time-consuming differentiable renderer for object pose prediction at the training stage, so that (i) their performances on real images are generally lim-ited due to the gap between their rendered images and real images and (ii) their training process is computationally ex-pensive. To address the two problems, we propose a novel
Network for Self-supervised Monocular Object pose esti-mation by utilizing the predicted Camera poses from un-annotated real images, called SMOC-Net. The proposed network is explored under a knowledge distillation frame-work, consisting of a teacher model and a student model.
The teacher model contains a backbone estimation module for initial object pose estimation, and an object pose refiner for refining the initial object poses using a geometric con-straint (called relative-pose constraint) derived from rela-tive camera poses. The student model gains knowledge for object pose estimation from the teacher model by impos-ing the relative-pose constraint. Thanks to the relative-pose constraint, SMOC-Net could not only narrow the domain gap between synthetic and real data but also reduce the training cost. Experimental results on two public datasets demonstrate that SMOC-Net outperforms several state-of-the-art methods by a large margin while requiring much less training time than the differentiable-renderer-based meth-ods. 1.

Introduction
Monocular 6D object pose estimation is a challenging task in the computer vision field, which aims to estimate object poses from single images. According to whether real images with ground-truth object poses are given for model training, the existing works for monocular object pose es-timation in literature could be divided into two categories: fully-supervised methods [17, 35] which are trained by uti-lizing annotated real images with ground-truth object poses, and self-supervised methods [16, 34] which are trained by utilizing synthetic images with object poses (sometimes jointly with un-annotated real images). Since it is very time-consuming to obtain high-quality object poses as ground truth, self-supervised monocular object pose estimation has attracted increasing attention recently [16, 33, 39].
Some existing methods for self-supervised monocular object pose estimation [16, 31] use only synthetic images with object poses (which are generated via Blender [22] or some other rendering tools [24, 29]) for training. How-ever, due to the domain gap between real and synthetic data, the performances of these self-supervised methods are significantly lower compared to the fully-supervised meth-ods [22, 35]. Addressing this domain gap problem, a few recent self-supervised methods [33, 34, 39] jointly use syn-thetic images with object pose and un-annotated real images at their training stage, where a differentiable renderer [19] is introduced to provide a constraint on the difference between real and rendered images. Although these methods could al-leviate the domain gap problem by utilizing the introduced differentiable renderer, they still have to be confronted with the following two problems: (i) There still exists a notice-able gap between real images and rendered images by the differentiable renderer, so that their performances on object pose estimation are still limited; (ii) Much time has to be spent on differentiable rendering during training, so that the training costs of these methods are quite heavy.
To address the above problems, this paper proposes a novel Network for Self-supervised Monocular Object pose estimation by utilizing the predicted Camera poses from un-annotated real images, called SMOC-Net. The SMOC-Net is designed via the knowledge distillation technique, con-sisting of a teacher model and a student model. Under the teacher model, a backbone pose estimation module is in-troduced to provide an initial estimation on the pose of the image object. Then, a geometric constraint (called relative-pose constraint) on object poses is mathematically derived from relative camera poses which are calculated by a typ-ical structure from motion method (here, we straightfor-wardly use COLMAP [25, 26]), and a camera-pose-guided refiner is further explored to refine the initial object pose based on this constraint. The student model simply employs the same architecture as the backbone estimation module of the teacher model, and it learns knowledge from the teacher model by imposing the relative-pose constraint, so that it could estimate object poses as accurately and fast as possi-ble. Once the proposed SMOC-Net has been trained, only its student model is used to predict the object pose from an arbitrary testing image.
In sum, the main contributions in this paper include: 1. We design the relative-pose constraint on object poses under the knowledge distillation framework for self-supervised object pose estimation. And it could narrow the domain gap between synthetic and real data to some extent. 2. According to the designed relative-pose constraint, we explore the camera-pose-guided refiner, which is able to refine low-accuracy object poses effectively. 3. By jointly utilizing the camera-pose-guided refiner and the above object pose constraint, we propose the
SMOC-Net for monocular 6D object pose estimation. Ex-perimental results in Sec. 4 demonstrate that the proposed
SMOC-Net does not only outperform several state-of-the-art methods when only synthetic images with object poses and un-annotated real images are used for training, but also perform better than three state-of-the-art fully-supervised methods on the public dataset LineMOD [8]. 2.