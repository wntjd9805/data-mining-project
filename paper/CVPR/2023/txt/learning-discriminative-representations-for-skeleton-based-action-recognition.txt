Abstract
Human action recognition aims at classifying the cate-gory of human action from a segment of a video. Recently, people have dived into designing GCN-based models to ex-tract features from skeletons for performing this task, be-cause skeleton representations are much more efﬁcient and robust than other modalities such as RGB frames. However, when employing the skeleton data, some important clues like related items are also discarded.
It results in some ambiguous actions that are hard to be distinguished and tend to be misclassiﬁed. To alleviate this problem, we pro-pose an auxiliary feature reﬁnement head (FR Head), which consists of spatial-temporal decoupling and contrastive fea-ture reﬁnement, to obtain discriminative representations of skeletons. Ambiguous samples are dynamically discovered and calibrated in the feature space. Furthermore, FR Head could be imposed on different stages of GCNs to build a multi-level reﬁnement for stronger supervision. Extensive experiments are conducted on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets. Our proposed models obtain competitive results from state-of-the-art methods and can help to discriminate those ambiguous samples. Codes are available at https://github.com/zhysora/FR-Head.
Figure 1. There are some actions that are hard to recognize be-cause the skeleton representations lack important interactive ob-jects and contexts, which make them easily confused with each other. 1.

Introduction
In human-to-human communication, action plays a par-ticularly important role. The behaviors convey intrinsic in-formation like emotions and potential intentions and thus help to understand the person. Empowering intelligent ma-chines with the same ability to understand human behaviors is critical for natural human-computer interaction and many other practical applications, and has been attracting much attention recently.
Nowadays, obtaining 2D/3D skeletons of humans has become much easier thanks to the advanced sensor tech-nology and human pose estimation algorithms. Skeletons
∗Corresponding author are compact and robust representations that are immune to viewpoint changes and cluttered backgrounds, making them attractive for action recognition. A typical way to use skele-tons for action recognition is to build Graph Convolutional
Networks (GCNs) [38]. The joints and bones in the human body naturally form graphs, which make GCNs a perfect tool to extract topological features of skeletons. GCN-based methods have become more and more popular, with another merit that the models can be built lightweight and have high computational efﬁciency compared with models processing video frames.
However, using skeletons to recognize actions has some limitations. A major problem is that skeleton representation lacks important interactive objects and contextual informa-tion for distinguishing similar actions. As shown in Fig. 1, it is hard to distinguish “Writing”, “Reading” and “Typing on a keyboard” based on the skeleton view alone. In contrast, a model can recognize them from RGB frames by focusing on the related items. These actions are easily confused with each other and should be given more attention.
To alleviate this drawback, we propose a feature re-ﬁnement module using contrastive learning to lift the dis-criminative ability of features between ambiguous actions.
We ﬁrst decouple hidden features into spatial and temporal components so that the network can better focus on discrim-inative parts among ambiguous actions along the topologi-cal and temporal dimensions. Then we identify the con-ﬁdent and ambiguous samples based on the model predic-tion during training. Conﬁdent samples are used to main-tain a prototype for each class, which is achieved by a con-trastive learning loss to constrain intra-class and inter-class distances. Meanwhile, ambiguous samples are calibrated by being closer to or far away from conﬁdent samples in the feature space. Furthermore, the aforementioned feature reﬁnement module can be embedded into multiple types of
GCNs to improve hierarchical feature learning. It will pro-duce a multi-level contrastive loss, which is jointly trained with the classiﬁcation loss to improve the performance of ambiguous actions. Our main contributions are summarized as follows:
• We propose a discriminative feature reﬁnement mod-ule to improve the performance of ambiguous actions in skeleton based action recognition.
It uses con-trastive learning to constrain the distance between con-ﬁdent samples and ambiguous samples.
It also de-couples the raw feature map into spatial and temporal components in a lightweight way for efﬁcient feature enhancement.
• The feature reﬁnement module is plug-and-play and compatible with most GCN-based models. It can be jointly trained with other losses but discarded in the inference stage.
• We conduct extensive experiments on NTU RGB+D,
NTU RGB+D 120, and NW-UCLA datasets to com-pare our proposed methods with the state-of-the-art models. Experimental results demonstrate the signif-icant improvement of our methods. 2.