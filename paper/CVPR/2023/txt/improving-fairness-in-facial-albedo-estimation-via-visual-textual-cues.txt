Abstract
Recent 3D face reconstruction methods have made sig-nificant advances in geometry prediction, yet further cos-metic improvements are limited by lagged albedo because inferring albedo from appearance is an ill-posed problem.
Although some existing methods consider prior knowledge from illumination to improve albedo estimation, they still produce a light-skin bias due to racially biased albedo mod-els and limited light constraints.
In this paper, we recon-sider the relationship between albedo and face attributes and propose a ID2Albedo to directly estimate albedo with-out constraining illumination. Our key insight is that in-trinsic semantic attributes such as race, skin color, and age can be used to constrain the albedo map. We first introduce visual-textual cues and design a semantic loss to supervise facial albedo estimation. Specifically, we pre-define text la-bels such as race, skin color, age, and wrinkles. Then, we employ the text-image model (CLIP) to compute the simi-larity between the text and the input image, and assign a
* Corresponding authors. pseudo-label to each facial image. We constrain generated albedos in the training phase to have the same attributes
In addition, we train a high-quality, unbi-as the inputs. ased facial albedo generator and utilize the semantic loss to learn the mapping from illumination-robust identity fea-tures to the albedo latent codes. Finally, our ID2Albedo is trained in a self-supervised way and outperforms state-of-the-art albedo estimation methods in terms of accuracy and fidelity. It is worth mentioning that our approach has excel-lent generalizability and fairness, especially on in-the-wild data. 1.

Introduction 3D face reconstruction is one of the fundamental prob-lems in computer vision and graphics. It aims to estimate realistic 3D face shapes and appearances from 2D images, given only multi-view or single-view images. 3D face re-construction plays a vital role in numerous vision appli-cations, such as face manipulation [52], speech-driven fa-cial animation [51], and video conferencing [56]. Since the pioneering work of 3D Morphable Model (3DMM) [54], monocular face reconstruction methods have made remark-able progress due to their high speed and geometric accu-racy. To enable more realistic applications such as avatar creation, interactive AR/VR, etc., fine-grained albedo re-construction attracts a lot of attention [16].
Inferring albedo from pixels is an ill-posed problem, and existing methods attempt to achieve approximate re-sults. The primary approaches are 1) creating a texture model to restrict the albedo space [24, 41, 49], and 2) in-troducing additional lighting constraints to reduce ambigu-ity [1,12,17]. Despite these constraints, most current albedo reconstruction methods continue to bias light-colored albe-dos, unfair to people of different ages and races. The main reasons behind the biased albedo estimation include 1) bi-ased albedo models and 2) limited lighting constraints. To address the above issues, TRUST [16] rebuilt a balanced albedo model, estimated the environment light from the scene and used this prior to decrease the ambiguity between light and albedo. Given the difficulty of the illumination estimation for both face and scene, the albedo estimation method proposed in TRUST [16] is still vulnerable under complex scenarios and complicated facial appearance vari-ations.
Since the facial albedo is a property of individual faces that should be consistent even when the lighting changes, could we design an illumination-robust albedo estimation method like the face recognition model [10] and the face attribute analysis model [28]? In this work, we provide an affirmative answer by proposing a novel ID2Albedo method. We first train a high-resolution albedo generator as the current PCA-based albedo model [49] fails in re-constructing high-frequency facial details. Given hundred-level training data, high-resolution Generative Adversar-ial Networks (GANs) [31] are not easy to train. To this end, we replace the single large discriminator with four smaller discriminators, which are applied to the feature pyramids [36] produced by a fixed ImageNet model. Based on our high-resolution albedo generator, we further utilize the illumination-robust identity features [10] to predict the latent codes to reconstruct albedo maps, ensuring the gen-eralization ability on in-the-wild data.
Given the fact that facial albedo is related to facial at-tributes (e.g. ethnicity, age, and skin color), we consider ex-ploring attribute constraints during albedo estimation. For example, African albedos are primarily dark, while Cau-casian albedos are mostly light. However, race alone is in-sufficient because the albedo of different individuals within a race varies due to age, skin color, and other factors. There-fore, we attempt to use diverse facial attribute priors to constrain the albedo estimation. Considering that few face datasets contain diverse semantic labels and manual anno-tation is time-consuming, we utilize a recent state-of-the-art visual-textual model, CLIP [42], to provide semantic cues for individual faces. Specifically, we predefine diverse texts from various perspectives, including race, skin tones, age, wrinkles, etc., and then compute the corresponding seman-tic attribute labels by embedded image features. Based on the pseudo attribute labels, we propose a novel semantic loss to compare the attribute differences between the recon-structed face and the original input face. The entire pipeline is self-supervised by a differentiable rendering framework.
To verify the effectiveness of the proposed albedo recon-struction approach, we conduct exhaustive evaluations on the FAIR benchmark and real-world images. The results show that our method consistently achieves competitive per-formance compared to state-of-the-art methods, especially under various lighting conditions.
In summary, our contributions are summarized as fol-lows:
• We first train a high-resolution, expressive, and nonlin-ear face albedo generator. Then, we construct a power-ful face albedo predictor, named ID2Albedo, by utiliz-ing the face identification features from a pre-trained face recognition network.
• We employ visual-textual cues in the face reconstruc-tion framework to overcome the illumination/albedo ambiguity problem by constraining facial semantic at-tributes.
• The proposed method improves the accuracy and fair-ness of facial albedo estimation, achieving state-of-the-art performance on the FAIR benchmark. 2.