Abstract
Multi-class cell detection and counting is an essential task for many pathological diagnoses. Manual counting is tedious and often leads to inter-observer variations among pathologists. While there exist multiple, general-purpose, deep learning-based object detection and counting meth-ods, they may not readily transfer to detecting and counting cells in medical images, due to the limited data, presence of tiny overlapping objects, multiple cell types, severe class-imbalance, minute differences in size/shape of cells, etc.
In response, we propose guided posterior regularization (DEGPR), which assists an object detector by guiding it to exploit discriminative features among cells. The features may be pathologist-provided or inferred directly from vi-sual data. We validate our model on two publicly avail-able datasets (CoNSeP and MoNuSAC), and on MuCeD, a novel dataset that we contribute. MuCeD consists of 55 biopsy images of the human duodenum for predicting celiac disease. We perform extensive experimentation with three object detection baselines on three datasets to show that
DEGPR is model-agnostic, and consistently improves base-lines obtaining up to 9% (absolute) mAP gains. 1.

Introduction
Multi-class multi-cell detection and counting (MC2DC) is the problem of identifying and localizing bounding boxes for different cells, followed by counting of each cell class.
MC2DC aids diagnosis of many clinical conditions. For ex-ample, CBC blood test counts red blood cells, white blood cells, and platelets, for diagnosing anemia, blood cancer, and infections [13, 31]. MC2DC over malignant tumor im-ages helps assess the resistance and sensitivity of cancer treatments [9]. MC2DC over duodenum biopsies is needed to compute the ratio of counts of two cell types for diagnos-ing celiac disease [6]. Cell counting is a tedious process and
*Equal contribution often leads to significant inter-observer and intra-observer variations [4, 8]. This motivates the need for an AI system that can provide robust and reproducible predictions.
Standard object detection models such as Yolo [21],
Faster-RCNN [35] and EfficientDet [44] have achieved state-of-the-art performance on various object detection set-tings. However, extending these to detecting cells in med-ical images poses several challenges. These include lim-ited availability of annotated datasets, tiny objects of inter-est (cells) that may be overlapping, similarity in the appear-ance of different cell types, and skewed cell class distribu-tion. Due to the non-trivial nature of the problem, MC2DC models may benefit from insights from trained pathologists, e.g., via discriminative attributes. For instance, in duode-num biopsies, intraepithelial lymphocytes (IELs) are struc-turally smaller, circular, and darker stained, whereas epithe-lial nuclei (ENs) are bigger, elongated, and lighter. A key challenge lies in incorporating these expert-insights within a detection model. A secondary issue is that such insights may not always be available or may be insufficient â€“ this motivates additional data-driven features.
We propose a novel deep guided posterior regularization (DEGPR) framework. Posterior regularization (PR) is an auxiliary loss [12], which enforces that the posterior distri-bution of a predictor should mimic the data distribution for the given features. We call our method deep guided PR, since we apply it to deep neural models, and it is meant to formalize the clinical guidance given by pathologists.
DEGPR incorporates PR over two types of features, which we term explicit and implicit features. Explicit features are introduced through direct guidance by expert pathologists.
Implicit features are learned feature embeddings for each class, trained through a supervised contrastive loss [22].
Subsequently, both features are feed into a Gaussian Mix-ture Model (GMM). DEGPR constrains the distributions over the predicted features to follow that of the ground truth features, via a KL divergence loss between them.
We test the benefits of DEGPR over three base object detection models (Yolov5, Faster-RCNN, EfficientDet) on
Figure 1. Visual dissimilarities between IELs and ENs. ENs (first row) are lighter stained, bigger and elongated in structure. IELs (second row) are darker stained, smaller, and circular in shape. three MC2DC datasets. Of these, two are publicly avail-able: CoNSeP [15] and MoNuSAC [47]. We additionally contribute a novel MuCeD dataset for the detection of celiac disease. MuCeD consists of 55 annotated biopsy images of the human duodenum, which have a total of 8,600 cell anno-tations of IELs and ENs. We find that DEGPR consistently improves detection and counting performance over all base models on all datasets. For example, on MuCeD, DEGPR obtains a 3-9% mAP gain for detection and a 10-35% re-duction in mean absolute error for counting two cell types.
In summary, (a) we propose DEGPR to guide object de-tection models by exploiting the discriminative visual fea-tures between different classes of cells; (b) we use super-vised contrastive learning to learn robust embeddings for different cell classes, which are then used as implicit fea-tures for DEGPR; (c) we introduce MuCeD, a dataset of human duodenum biopsies, which has 8,600 annotated cells of two types; and (d) we experiment on three datasets, in-cluding MuCeD, and find that DEGPR strongly improves detection and counting performance over three baselines.
We release our dataset and code for further research.* 2.