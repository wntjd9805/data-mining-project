Abstract
LiDAR panoptic segmentation facilitates an autonomous vehicle to comprehensively understand the surrounding ob-jects and scenes and is required to run in real time. The recent proposal-free methods accelerate the algorithm, but their effectiveness and efficiency are still limited owing to the difficulty of modeling non-existent instance centers and the costly center-based clustering modules. To achieve ac-curate and real-time LiDAR panoptic segmentation, a novel center focusing network (CFNet) is introduced. Specifically, the center focusing feature encoding (CFFE) is proposed to explicitly understand the relationships between the origi-nal LiDAR points and virtual instance centers by shifting the LiDAR points and filling in the center points. More-over, to leverage the redundantly detected centers, a fast center deduplication module (CDM) is proposed to select only one center for each instance. Experiments on the Se-manticKITTI and nuScenes panoptic segmentation bench-marks demonstrate that our CFNet outperforms all existing methods by a large margin and is 1.6 times faster than the most efficient method. 1.

Introduction
Panoptic segmentation [18] combines both semantic seg-mentation and instance segmentation in a single framework.
It predicts semantic labels for the uncountable stuff classes (e.g. road, sidewalk), while it simultaneously provides se-mantic labels and instance IDs for the countable things classes (e.g. car, pedestrian). The LiDAR panoptic segmen-tation is one of the bases for the safety of autonomous driv-ing, which employs the point clouds collected by the Light
Detection and Ranging (LiDAR) sensors to effectively de-pict the surroundings. Existing LiDAR panoptic segmenta-tion methods first conduct semantic segmentation, and then achieve instance segmentation for the things categories in
Figure 1. PQ vs. runtime on the SemanticKITTI test set. Runtime measurements are taken on a single NVIDIA RTX 3090 GPU. The panoptic quality (PQ) is introduced in section 4.1. two ways, the proposal-based and proposal-free methods.
The proposal-based methods [17, 31, 37] adopt a two-stage process similar to the well-known Mask R-CNN [14] in the image domain. It first generates object proposals for the things points by using 3D detection networks [19, 30] and then refines the instance segmentation results within each proposal. As shown in Fig. 1, these methods are usu-ally complicated and hardly achieve real-time processing, owing to their sequential multi-stage pipelines.
The proposal-free frameworks [13, 15, 21, 22, 29, 35, 39] are more compact. To associate the things points with in-stance IDs, these methods usually leverage the instance cen-ters. Specifically, they regress the offsets from the points to their corresponding centers, and then adopt the class-agnostic center-based clustering modules [13, 15, 29] or the bird’s-eye view (BEV) center heatmap [22, 35, 39]. How-ever, two problems exist in these methods. First, for center feature extracting and center modeling, the non-existent in-• The proposed CFNet is evaluated on the nuScenes and
SemanticKITTI LiDAR panoptic segmentation bench-marks. Our CFNet achieves the state-of-the-art perfor-mance with a real-time inference speed. 2.