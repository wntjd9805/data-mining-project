Abstract
Camera pose estimation is a key step in standard 3D re-construction pipelines that operate on a dense set of im-ages of a single object or scene. However, methods for pose estimation often fail when only a few images are avail-able because they rely on the ability to robustly identify and match visual features between image pairs. While these methods can work robustly with dense camera views, cap-turing a large set of images can be time-consuming or im-practical. We propose SparsePose for recovering accu-rate camera poses given a sparse set of wide-baseline im-ages (fewer than 10). The method learns to regress initial camera poses and then iteratively refine them after train-ing on a large-scale dataset of objects (Co3D: Common
Objects in 3D). SparsePose significantly outperforms con-ventional and learning-based baselines in recovering ac-curate camera rotations and translations. We also demon-strate our pipeline for high-fidelity 3D reconstruction using only 5-9 images of an object. Project webpage: https:
//sparsepose.github.io/ 1.

Introduction
Computer vision has recently seen significant advances in photorealistic new-view synthesis of individual ob-jects [24, 41, 52, 60] or entire scenes [5, 62, 81]. Some of these multiview methods take tens to hundreds of images as input [5, 35, 36, 41], while others estimate geometry and appearance from a few sparse camera views [43, 52, 76].
To produce high-quality reconstructions, these methods cur-rently require accurate estimates of the camera position and orientation for each captured image.
Recovering accurate camera poses, especially from a limited number of images is an important problem for prac-tically deploying 3D reconstruction algorithms, since it can be challenging and expensive to capture a dense set of im-ages of a given object or scene. While some recent meth-ods for appearance and geometry reconstruction jointly tackle the problem of camera pose estimation, they typi-cally require dense input imagery and approximate initial-Figure 1. SparsePose – Given sparse input views, our method predicts initial camera poses and then refines the poses based on learned image features aggregated using projective geometry.
SparsePose outperforms conventional methods for camera pose estimation based on feature matching within a single scene and enables high-fidelity novel view synthesis (shown for each itera-tion of pose refinement) from as few as five input views. ization [34, 67] or specialized capture setups such as imag-ing rigs [27, 78]. Most conventional pose estimation algo-rithms learn the 3D structure of the scene by matching im-age features between pairs of images [46, 58], but they typ-ically fail when only a few wide-baseline images are avail-able. The main reason for this is that features cannot be matched robustly resulting in failure of the entire recon-struction process.
In such settings, it may be outright impossible to find correspondences between image features. Thus, reliable camera pose estimation requires learning a prior over the geometry of objects. Based on this insight, the recent Rel-Pose method [79] proposed a probabilistic energy-based model that learns a prior over a large-scale object-centric dataset [52]. RelPose is limited to predicting camera rota-tions (i.e., translations are not predicted). Moreover, it op-erates directly on image features without leveraging explicit 3D reasoning.
To alleviate these limitations, we propose SparsePose, a method that predicts camera rotation and translation param-eters from a few sparse input views based on 3D consistency between projected image features (see Figure 1). We train the model to learn a prior over the geometry of common objects [52], such that after training, we can estimate the camera poses for sparse images and generalize to unseen object categories. More specifically, our method performs a two-step coarse-to-fine image registration: (1) we predict coarse approximate camera locations for each view of the scene, and (2) these initial camera poses are used in a pose refinement procedure that is both iterative and autoregres-sive, which allows learning fine-grained camera poses. We evaluate the utility of the proposed method by demonstrat-ing its impact on sparse-view 3D reconstruction.
Our method outperforms other methods for camera pose estimation in sparse view settings. This includes conven-tional image registration pipelines, such as COLMAP [58], as well as recent learning-based methods, such as Rel-Pose [79]. Overall, SparsePose enables real-life, sparse-view reconstruction with as few as five images of common household objects, and is able to predict accurate camera poses, with only 3 source images of previously unseen ob-jects.
In summary, we make the following contributions.
• We propose SparsePose, a method that predicts camera poses from a sparse set of input images.
• We demonstrate that the method outperforms other tech-niques for camera pose estimation in sparse settings.
• We evaluate our approach on 3D reconstruction from sparse input images via an off-the-shelf method, where our camera estimation enables much higher-fidelity re-constructions than competing methods. 2.