Abstract 3D object detection is an important task in autonomous driving to perceive the surroundings. Despite the excellent performance, the existing 3D detectors lack the robustness to real-world corruptions caused by adverse weathers, sen-sor noises, etc., provoking concerns about the safety and reliability of autonomous driving systems. To comprehen-sively and rigorously benchmark the corruption robustness of 3D detectors, in this paper we design 27 types of common corruptions for both LiDAR and camera inputs considering real-world driving scenarios. By synthesizing these corrup-tions on public datasets, we establish three corruption ro-bustness benchmarks—KITTI-C, nuScenes-C, and Waymo-C. Then, we conduct large-scale experiments on 24 diverse 3D object detection models to evaluate their corruption ro-bustness. Based on the evaluation results, we draw several important findings, including: 1) motion-level corruptions are the most threatening ones that lead to significant perfor-mance drop of all models; 2) LiDAR-camera fusion models demonstrate better robustness; 3) camera-only models are extremely vulnerable to image corruptions, showing the in-dispensability of LiDAR point clouds. We release the bench-marks and codes at https://github.com/thu-ml/ 3D_Corruptions_AD to be helpful for future studies. 1.

Introduction
As a fundamental task in autonomous driving, 3D object detection aims to identify objects of interest (e.g., vehicles, pedestrians, or cyclists) in the surrounding environment by predicting their categories and the corresponding 3D bound-ing boxes. LiDAR and camera are two important types of sensors for 3D object detection, where the former provides
*Corresponding authors. the depth information of road objects as sparse point clouds, while the latter captures abundant semantic information of the scene as color images. Based on the complementary na-ture of the two modalities, 3D object detection models can be categorized into LiDAR-only [29,47,48,60,69], camera-only [39, 56–58], and LiDAR-camera fusion [11, 28, 34, 53] models. Since autonomous driving is safety-critical, it is of paramount importance to assess the robustness of 3D object detectors under diverse circumstances before deployed.
Although the recent progress of 3D object detection has led to significant improvements in typical benchmarks (e.g.,
KITTI [17], nuScenes [6], and Waymo [51]), the existing models based on data-driven deep learning approaches of-ten generalize poorly to the corrupted data caused by, e.g., adverse weathers [21, 22, 27], sensor noises [7, 25, 44], and uncommon objects [9, 31], posing a formidable obstacle to safe and reliable autonomous driving [1]. To perform ro-bustness evaluation, recent works construct new datasets of road anomalies [9,23,31,40] or under extreme weather con-ditions [4, 15, 41]. Nevertheless, they are usually of small sizes due to the high data collection costs and the rareness of corner cases or adverse weathers. Other works synthesize common corruptions on clean datasets to benchmark robust-ness on image classification [25] and point cloud recogni-tion [44, 50], but they only consider several simple corrup-tions, which could be insufficient and unrealistic for 3D ob-ject detection. Therefore, it remains challenging to com-prehensively characterize different corruptions considering diverse driving scenarios and fairly evaluate corruption ro-bustness of existing models within a unified framework.
In this paper, we systematically design 27 types of com-mon corruptions in 3D object detection for both LiDAR and camera sensors to comprehensively and rigorously evalu-ate the corruption robustness of current 3D object detectors.
Figure 1. An overview of 27 corruptions for 3D object detection, which are categorized into weather, sensor, motion, object, and alignment levels. As shown, some corruptions are effective for one modality, while the others are applied to both (e.g., Snow, Moving Object, Shear).
The corruptions are grouped into weather, sensor, motion, object, and alignment levels, covering the majority of real-world corruption cases, as demonstrated in Fig. 1. Most of them are specifically designed for autonomous driving (e.g., motion-level ones), which have not been explored before.
Following [25], every corruption has five severities, leading to a total number of 135 distinct corruptions. By applying them to typical autonomous driving datasets—KITTI [17], nuScenes [6], and Waymo [51], we establish three corrup-tion robustness benchmarks—KITTI-C, nuScenes-C, and
Waymo-C. We hope that they can serve as general datasets for comprehensively benchmarking corruption robustness of 3D object detectors and facilitating future research.
We conduct large-scale experiments to compare the cor-ruption robustness of existing 3D object detection models.
Specifically, we evaluate 11 models on KITTI-C, 10 models on nuScenes-C, and 3 models on Waymo-C. The models are of great variety with different input modalities, representa-tion methods, and detection heads. Based on the evaluation results, we find that: 1) the corruption robustness of 3D ob-ject detectors is highly correlated with their clean accuracy; 2) motion-level corruptions impair the model performance most, while being rarely explored before; 3) LiDAR-camera fusion models are more resistant to corruptions, but there is a trade-off between robustness under image corruptions and point cloud corruptions of fusion models. More discussions are provided in Sec. 6. Moreover, we study data augmenta-tion strategies [14, 64, 67] as potential solutions to improve corruption robustness, but find that they provide a little ro-bustness gain, leaving robustness enhancement of 3D object detection an open problem for future research. 2.