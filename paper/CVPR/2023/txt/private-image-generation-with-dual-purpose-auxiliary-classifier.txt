Abstract
Privacy-preserving image generation has been impor-tant for segments such as medical domains that have sen-sitive and limited data. The benefits of guaranteed privacy come at the costs of generated images’ quality and utility due to the privacy budget constraints. The utility is cur-rently measured by the gen2real accuracy (g2r%), i.e., the accuracy on real data of a downstream classifier trained using generated data. However, apart from this standard utility, we identify the “reversed utility” as another cru-cial aspect, which computes the accuracy on generated data of a classifier trained using real data, dubbed as real2gen accuracy (r2g%). Jointly considering these two views of utility, the standard and the reversed, could help the gen-eration model better improve transferability between fake and real data. Therefore, we propose a novel private image generation method that incorporates a dual-purpose auxil-iary classifier, which alternates between learning from real data and fake data, into the training of differentially private
GANs. Additionally, our deliberate training strategies such as sequential training contributes to accelerating the gen-erator’s convergence and further boosting the performance upon exhausting the privacy budget. Our results achieve new state-of-the-arts over all metrics on three benchmarks:
MNIST, Fashion-MNIST, and CelebA. 1.

Introduction
By combining game theory with the powerful deep neu-ral networks, Generative Adversarial Network (GAN) [19] and its variants [2, 21, 24, 27] have shown impressive capa-bility to learn the data distribution and synthesise data of high fidelity and diversity that are challenging to be differ-entiated from the real ones. Therefore, they are appealing data augmentation methods in domains where real data is too rare or contains sensitive information, such as the med-ical domain. For example, GANs can be used to generate synthetic liver lesions [16], MRIs [5], and CT scans [34]
Figure 1. In each training loop, the proposed dual-purpose aux-iliary classifier is trained sequentially to improve on both two as-pects of transferability and provide feedback to the generator. that could then be fed into machine learning models to un-leash their power for building high-quality medical analyt-ics systems. Ideally, this could also protect the privacy of real patient data and encourage data sharing between insti-tutions by only releasing the synthetic ones generated by
GANs. This seems to solve the two problems mentioned, the scarcity and sensitivity of data.
Unfortunately, recent works have shown that GANs are not safe from leaking sensitive information about training sample [3, 29, 40] as GANs are subject to model inversion attacks and membership inference attacks in both white-box and black-box settings [15, 23, 35, 42]. To preserve privacy, recent works have made progress by adopting Dif-ferential Privacy (DP) [12], a rigorously privacy-guaranteed mechanism, in GAN training [8, 14, 25, 30, 37]. Along this line, GS-WGAN [8] is a current state-of-the-art method, which demonstrated that DP can be achieved by only se-lectively sanitising the generator, while leaving the discrim-inator non-private.
Despite the success of recent works, there are still two main gaps to be filled for this task. Firstly, the current util-ity in the literature only focuses on the transferability from fake data to real data. It computes the gen2real accuracy (g2r%), i.e. the classification accuracy on real data of a clas-sifier trained using fake data. Such utility is surely impor-tant by definition since it reflects how useful the generated data will be in downstream applications. Nonetheless, the gen2real accuracy only covers one direction of data trans-ferability, while neglecting the other way around, namely from real to fake data. It was previously less investigated that whether blending both these two aspects of transfer-ability in model design could lead to better private GANs.
Secondly, the gained privacy largely sacrifices the gener-ated outputs’ quality and utility. This is because the pri-vacy budget constraints the maximum number of generator updates, which makes the generator difficult to converge.
Prior works [6, 8, 30, 37] have hardly synthesised images of both high quality and utility within standard privacy bud-get under DP framework, especially for RGB image gener-ation such as on CelebA dataset. Private GANs still need to accelerate the generator convergence within the budget to achieve a better privacy-quality/utility trade-off.
In this paper, the following attempts are made to close the two aforementioned gaps. Firstly, we recognize the “re-versed utility” as another critical aspect for transferability, which is defined as the real2gen accuracy (r2g%) computed as the classification accuracy of the classifier trained with real data and tested on the generated data. The intuition is that for an output to generalise well, it should be difficult to tell from the real ones in its corresponding class. There-upon, a novel method for private image generation with the standard and reversed utility unified in the training pro-cess is proposed. This is based on a dual-purpose auxiliary classifier as illustrated in Fig. 1, which switches between training on real data and fake data, and then provide feed-back for the generator to enhance the transferability in both two direction. Concretely, we build the proposed method on GS-WGAN [8], since its sanitisation mechanism could keep the generator differentially private when integrating an auxiliary classifier that is exposed to real data. Secondly, different from the conventional training scheme of GANs where the discriminator learns from real and fake data si-multaneously, we devise our training procedure of the clas-sifier in a sequential manner. This could assist the classifier in learning from different domains separately and reducing noisy gradients during updates, which enables the classifier to provide more valuable feedback to the generator and ac-celerate its convergence within a given privacy budget.
Experiments on standard datasets for private image gen-eration: MNIST, FashionMNIST and CelebA, demonstrate that the proposed method could achieve outstanding per-formance over state-of-the-art approaches on all evaluation metrics including quality and utility. In summary, our con-tributions are three-fold: 1) The “reversed utility” is identi-fied as an beneficial part of an improved design of private
GANs. 2) A dual-purpose auxiliary classifier is developed in alignment with both the standard and reversed utility. 3)
The classifier is trained with strategies like sequentialisation to accelerate the convergence of generator. 2.