Abstract
In recent years, we have witnessed the great advance-ment of Deep neural networks (DNNs) in image restoration.
However, a critical limitation is that they cannot general-ize well to real-world degradations with different degrees or types. In this paper, we are the first to propose a novel training strategy for image restoration from the causality perspective, to improve the generalization ability of DNNs for unknown degradations. Our method, termed Distortion
Invariant representation Learning (DIL), treats each distor-tion type and degree as one specific confounder, and learns the distortion-invariant representation by eliminating the harmful confounding effect of each degradation. We de-rive our DIL with the back-door criterion in causality by modeling the interventions of different distortions from the optimization perspective. Particularly, we introduce coun-terfactual distortion augmentation to simulate the virtual distortion types and degrees as the confounders. Then, we instantiate the intervention of each distortion with a virtual model updating based on corresponding distorted images, and eliminate them from the meta-learning perspective. Ex-tensive experiments demonstrate the generalization capa-bility of our DIL on unseen distortion types and degrees.
Our code will be available at https://github.com/ lixinustc/Causal-IR-DIL. 1.

Introduction
Image restoration (IR) tasks [7, 8, 32, 51], including image super-resolution [11, 24, 43, 46, 56, 57], deblur-ring [41, 75], denoising [3, 23, 40], compression artifacts removal [28, 53], etc, have achieved amazing/uplifting per-formances, powered by deep learning. A series of back-bones are elaborately and carefully designed to boost the
†Corresponding Author
Figure 1. A comparison between ERM and our DIL with RRDB as backbone. The results are tested on Set5 with Gaussian noise. restoration performances for specific degradation. Convolu-tion neural networks (CNNs) [20] and transformers [12, 34] are two commonly-used designed choices for the backbones of image restoration. However, these works inevitably suf-fer from severe performance drops when they encounter un-seen degradations as shown in Fig. 1, where the restora-tion degree in training corresponds to the noise of standard deviation 20 and the degrees in testing are different. The commonly-used training paradigm in image restoration, i.e., empirical risk minimization (ERM), does not work well for out-of-distribution degradations. Particularly, the restora-tion networks trained with ERM merely mine the correla-tion between distorted image Id and its ideal reconstructed image Io by minimizing the distance between Io and the corresponding clean image Ic. However, a spurious corre-lation [44] is also captured which introduces the bad con-founding effects of specific degradation d.
It means the conditional probability P (Io|Id) is also conditioned on the distortion types or degrees d (i.e., d ̸⊥⊥ Io|Id).
A robust/generalizable restoration network should be distortion-invariant (i.e., d ⊥⊥ Io|Id). For instance, given two distorted images with the same content Ic but differ-ent degradations d1 and d2, the robust restoration network is expected to recover the same reconstructed image Io
from these two distorted images (i.e., P (Io|Id, d = d1) =
P (Io|Id, d = d2)), respectively. Previous works for the ro-bustness of the restoration network can be roughly divided into two categories, distortion adaptation-based schemes, and domain adaptation/translation-based schemes. Distor-tion adaptation-based schemes [60] aim to estimate the dis-tortion types or representations, and then, handle the differ-ent distortions by adaptively modulating the restoration net-work. Domain adaptation/translation-based schemes [13, 35,48] regard different distortions as different domains, and introduce the domain adaptation/translation strategies to the image restoration field. Notwithstanding, the above works ignore the exploration of the intrinsic reasons for the poor generalization capability of the restoration network. In this paper, we take the first step to the causality-inspired im-age restoration, where novel distortion invariant represen-tation learning from the causality perspective is proposed, to improve the generalization capability of the restoration network.
As depicted in [17, 44], correlation is not equivalent to causation. Learning distortion invariant representation for image restoration requires obtaining the causal effects be-tween the distorted and ideal reconstructed images instead of only their correlation. There are two typical adjust-ment criteria for causal effects estimation [17], the back-door criterion, and the front-door criterion, respectively. In particular, the back-door criterion aims to remove the bad confounding effects by traversing over known confounders, while the front-door criterion is to solve the challenge that confounders cannot be identified. To improve the gener-alization capability of the restoration network, we build a structural causal graph in Fig. 2 for the image restora-tion process and propose the Distortion-Invariant represen-tation Learning (DIL) for image restoration by implement-ing the back-door criterion from the optimization perspec-tive. There are two challenges for achieving this. The first challenge is how to construct the confounder sets (i.e., dis-tortion sets). From the causality perspective [17, 44], it is better to keep other factors in the distorted image invari-ant except for distortion types. However, in the real world, collecting distorted/clean image pairs, especially with dif-ferent real distortions but the same content is impractical.
Inspired by counterfactual [44] in causality and the distor-tion simulation [55, 71], we propose counterfactual distor-tion augmentation, which selects amounts of high-quality images from the commonly-used dataset [2, 49], and simu-late the different distortion degrees or types on these images as the confounders.
Another challenge of implementing DIL stems from finding a stable and proper instantiating scheme for the back-door criterion. Previous works [36,37,54,64,65] have incorporated causal inference in high-level tasks by instan-tiating the back-door criterion [17] with attention interven-tion [64], feature interventions [66], etc, which are arduous to be exploited in the low-level task of image restoration. In this work, we theoretically derive our distortion-invariant representation learning DIL by instantiating the back-door criterion from the optimization perspective. Particularly, we model the intervention of simulated distortions for the restoration process by virtually updating the restoration net-work with the samples from the corresponding distortions.
Then, we eliminate the confounding effects of distortions by introducing the optimization strategy from Meta-Learning to our proposed DIL. In this way, we can instantiate the causal learning in image restoration and enable the DIL based on the back-door criterion.
The contributions of this paper are listed as follows:
• We revisit the image restoration task from a causality view and pinpoint that the reason for the poor gener-alization of the restoration network, is that the restora-tion network is not independent to the distortions in the training dataset.
• Based on the back-door criterion in causality, we pro-pose a novel training paradigm, Distortion Invariant representation Learning (DIL) for image restoration, where the intervention is instantiated by a virtually model updating under the counterfactual distortion augmentation and is eliminated with the optimization based on meta-learning.
• Extensive experiments on different image restoration tasks have demonstrated the effectiveness of our DIL for improving the generalization ability on unseen dis-tortion types and degrees. 2.