Abstract
Video-based 3D human pose and shape estimations are evaluated by intra-frame accuracy and inter-frame smooth-ness. Although these two metrics are responsible for dif-ferent ranges of temporal consistency, existing state-of-the-art methods treat them as a unified problem and use monotonous modeling structures (e.g., RNN or attention-based block) to design their networks. However, using a single kind of modeling structure is difficult to balance the learning of short-term and long-term temporal corre-lations, and may bias the network to one of them, lead-ing to undesirable predictions like global location shift, temporal inconsistency, and insufficient local details. To solve these problems, we propose to structurally decou-ple the modeling of long-term and short-term correlations in an end-to-end framework, Global-to-Local Transformer (GLoT). First, a global transformer is introduced with a
Masked Pose and Shape Estimation strategy for long-term modeling. The strategy stimulates the global transformer to learn more inter-frame correlations by randomly mask-ing the features of several frames. Second, a local trans-former is responsible for exploiting local details on the hu-man mesh and interacting with the global transformer by leveraging cross-attention. Moreover, a Hierarchical Spa-tial Correlation Regressor is further introduced to refine intra-frame estimations by decoupled global-local repre-sentation and implicit kinematic constraints. Our GLoT surpasses previous state-of-the-art methods with the low-est model parameters on popular benchmarks, i.e., 3DPW,
MPI-INF-3DHP, and Human3.6M. Codes are available at https://github.com/sxl142/GLoT. 1.

Introduction
Automatically recovering a sequence of human meshes from a monocular video plays a pivotal role in various appli-cations, e.g., AR/VR, robotics, and computer graphics. This technology can potentially reduce the need for motion cap-*This work was done during an internship at Alibaba. (a) TCMR [4] results. Global location shift, shifting to the left. (b) MPS-Net [41] results. Insufficient local details. (c) Our results.
Figure 1. Our motivation. With the help of global-local coop-erative modeling, our results avoid the global location shift and complement local details on intra-frame human meshes. ture devices and manual 3D annotations, providing human motion templates for downstream tasks, e.g., the anima-tion of 3D avatars. By utilizing parametric human models (i.e., SMPL [26]) with well-defined artificial joint and shape structures, the popular procedure for video-based human mesh recovery involves indirectly regressing the SMPL pa-rameters. However, effectively integrating deep neural net-works with parametric artificial models to leverage multi-knowledge representations [42] for better estimation accu-racy still remains an open problem.
In video-based human mesh recovery, temporal under-standing poses a crucial challenge that necessitates main-taining both intra-frame accuracy and inter-frame smooth-ness. Previous methods [4, 16, 41] mainly design deep networks to model long-term and short-term correlations simultaneously. For instance, VIBE [16] utilizes Recur-rent Neural Network (RNN) [3] to model correlations.
TCMR [4] and MPS-Net [41] consist of a temporal en-global transformer mine the coherent consistency of hu-man motion and guides it to seize the inter-frame correla-tion from a global view. Under the local view, we intro-duce a local transformer and a Hierarchical Spatial Cor-relation Regressor (HSCR) for exploiting the short-term inter-frame detail and learning the intra-frame human mesh structure. To achieve this, we introduce nearby frames of the mid-frame and process them through the local en-coder, which utilizes the mid-frame as a query to match the global transformer encoder’s memory, generating a disen-tangled global-local representation of the mid-frame. Fi-nally, HSCR employs human kinematic structures to con-strain the refinement of decoupled global-local representa-tion and improve global estimation.
With the help of global-local cooperative modeling, our model obtains the best intra-frame accuracy and inter-frame smoothness. For example, compared with the previous state-of-the-art method [41], our model significantly re-duces the PA-MPJPE, MPJPE, and MPVPE by 1.5 mm, 3.6 mm, and 3.4 mm, respectively, on the widely used dataset 3DPW [38], while preserving the lowest Accel metric rep-resenting the inter-frame smoothness. Moreover, our model remarkably decreases the model parameters, as shown in
Figure 2. Our contributions can be summarized as follows:
• To our best knowledge, we make the first attempt to de-couple the modeling of long-term and short-term cor-relations in video-based 3D human pose and shape es-timation. The proposed Global-to-Local Transformer (GLoT) merges the knowledge from deep networks and human prior structures, improving our method’s accuracy and efficiency.
• In GLoT, we carefully design two components, i.e.,
Global Motion Modeling and Local Parameter Correc-tion, for learning inter-frame global-local contexts and intra-frame human mesh structure, respectively.
• We conduct extensive experiments on three widely-used datasets. Our results show that GLoT outper-forms the previous state-of-the-art method [41], while achieving the lowest model parameters. 2.