Abstract
Semi-Supervised Object Detection (SSOD), aiming to ex-plore unlabeled data for boosting object detectors, has be-come an active task in recent years. However, existing
SSOD approaches mainly focus on horizontal objects, leav-ing multi-oriented objects that are common in aerial images unexplored. This paper proposes a novel Semi-supervised
Oriented Object Detection model, termed SOOD, built upon the mainstream pseudo-labeling framework. Towards ori-ented objects in aerial scenes, we design two loss func-tions to provide better supervision. Focusing on the orien-tations of objects, the first loss regularizes the consistency between each pseudo-label-prediction pair (includes a pre-diction and its corresponding pseudo label) with adaptive weights based on their orientation gap. Focusing on the layout of an image, the second loss regularizes the similar-ity and explicitly builds the many-to-many relation between the sets of pseudo-labels and predictions. Such a global consistency constraint can further boost semi-supervised learning. Our experiments show that when trained with the two proposed losses, SOOD surpasses the state-of-the-art SSOD methods under various settings on the DOTA-v1.5 benchmark. The code will be available at https:
//github.com/HamPerdredes/SOOD. 1.

Introduction
Sufficient labeled data is essential for fully-supervised object detection. However, the data labeling process is time-consuming and expensive. Recently, Semi-Supervised Ob-ject Detection (SSOD), where object detectors are learned from labeled data as well as easy-to-obtain unlabeled data, has attracted increasing attention. Existing SSOD meth-ods [16, 24, 44, 50] mainly focus on detecting objects with horizontal bounding boxes in general scenes. Nevertheless, in more complex scenes, such as aerial scenes, objects usu-*Equal contribution. †Corresponding author.
Work done when Dingkang Liang was an intern at Baidu.
Figure 1. Arbitrary rotating (a), small and dense (b) objects are common in aerial scenes, which are often regularly arranged on the image. From a global perspective, this pattern indicates that an aerial can be regarded as a layout. ally need to be annotated with oriented bounding boxes.
Considering the higher annotation cost of oriented boxes*, semi-supervised oriented object detection is worth studying.
Compared with general scenes, the main characteristics of objects in aerial scenes (or aerial objects for short) are three-fold: arbitrary orientations, small scales, and agglom-eration, as shown in Fig. 1. The mainstream SSOD meth-ods are based on the pseudo-labeling framework [3, 35, 36] consisting of a teacher model and a student model. The teacher model, an Exponential Moving Average (EMA) of the student model at historical training iterations, gener-ates pseudo-labels for unlabeled images. Thus, the student model can learn from both labeled and unlabeled data. To extend the framework to oriented object detection, we think the following two aspects need to be addressed: 1) As orien-tation is an essential property of multi-oriented objects, how to use the orientation information when guiding the student with pseudo-labels is critical. 2) As aerial objects are often dense and regularly distributed in an image, we can utilize the layout to facilitate the learning of each pair instead of treating them individually.
This paper proposes the first Semi-supervised Oriented
*Annotation cost of an oriented box is about 36.5% (86$ vs. 63$ per 1k at 2022.11) more than a horizontal box according to https://cloud. google.com/ai-platform/data-labeling/pricing.
Object Detection method, termed SOOD. Following [50],
SOOD is built upon the dense pseudo-labeling framework, where the pseudo labels are filtered from the raw pixel-wise predictions (including box coordinates and confidence scores). The key design is two simple yet effective losses that enforce the instance-level and set-level consistency be-tween the student’s and the teacher’s predictions.
To be specific, considering that the pseudo-label-prediction pairs are not equally informative, we propose the
Rotation-aware Adaptive Weighting (RAW) loss. It utilizes the orientation gap of each pair, which reflects the difficulty of this sample in a way, to weight the corresponding loss dynamically. In this manner, we can softly pick those more useful supervision signals to guide the learning of the stu-dent. In addition, considering that the layout of an aerial im-age can potentially reflect components’ overall status (e.g., objects’ density and location distribution) and help the de-tection process, we propose the Global Consistency (GC) loss.
It measures the similarity of the pseudo-labels and the predictions from a global perspective, which can allevi-ate the disturbance of noise in pseudo-labels and implicitly regularizes the mutual relations between different objects.
We extensively evaluate SOOD under various settings on
DOTA-v1.5, a popular aerial object detection benchmark.
Our SOOD achieves consistent performance improvement when using 10%, 20%, 30%, and full of labeled data, com-pared with the state-of-the-art SSOD methods (using the same oriented object detector). The ablation study also ver-ifies the effectiveness of the two losses.
In summary, this paper makes an early exploration of semi-supervised learning for oriented object detection. By analyzing the distinct characteristics of oriented objects from general objects, we propose two novel loss functions to adapt the pseudo-label framework to this task. We hope that this work can provide a good starting point for semi-supervised oriented object detection and serve as a simple yet strong baseline for future research. 2.