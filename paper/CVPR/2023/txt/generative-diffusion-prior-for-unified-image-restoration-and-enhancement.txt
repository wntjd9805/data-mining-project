Abstract
Existing image restoration methods mostly leverage the posterior distribution of natural images. However, they often assume known degradation and also require super-vised training, which restricts their adaptation to complex real applications. In this work, we propose the Generative
Diffusion Prior (GDP) to effectively model the posterior distributions in an unsupervised sampling manner. GDP utilizes a pre-train denoising diffusion generative model (DDPM) for solving linear inverse, non-linear, or blind problems. Specifically, GDP systematically explores a pro-tocol of conditional guidance, which is verified more prac-tical than the commonly used guidance way. Furthermore,
GDP is strength at optimizing the parameters of degrada-tion model during the denoising process, achieving blind image restoration. Besides, we devise hierarchical guid-ance and patch-based methods, enabling the GDP to gen-erate images of arbitrary resolutions. Experimentally, we demonstrate GDP ’s versatility on several image datasets for linear problems, such as super-resolution, deblurring, inpainting, and colorization, as well as non-linear and blind issues, such as low-light enhancement and HDR image re-∗Equal contribution, †Corresponding author. covery. GDP outperforms the current leading unsupervised methods on the diverse benchmarks in reconstruction qual-ity and perceptual quality. Moreover, GDP also general-izes well for natural images or synthesized images with ar-bitrary sizes from various tasks out of the distribution of the ImageNet training set. The project page is available at https://generativediffusionprior.github.io/ 1.

Introduction
Image quality often degrades during capture, storage, transmission, and rendering.
Image restoration and en-hancement [42] aim to inverse the degradation and im-prove the image quality. Typically, restoration and enhance-ment tasks can be divided into two main categories: 1)
Linear inverse problems, such as image super-resolution (SR) [24, 38], deblurring [36, 75], inpainting [88], coloriza-tion [37, 94], where the degradation model is usually linear and known; 2) Non-linear or blind problems [1], such as image low-light enhancement [39] and HDR image recov-ery [10, 79], where the degradation model is non-linear and unknown. For a specific linear degradation model, image restoration can be tackled through end-to-end supervised training of neural networks [16,94]. Nonetheless, corrupted images in the real world often have multiple complex degra-dations [57], where fully supervised approaches suffer to
generalize.
There is a surge of interest to seek for more general im-age priors through generative models [1, 21, 69], and tackle image restoration in an unsupervised setting [8, 19], where multiple restoration tasks of different degradation models can be addressed during inference without re-training. For instance, Generative Adversarial Networks (GANs) [20] that are trained on a large dataset of clean images learn rich knowledge of the real-world scenes have succeeded in various linear inverse problems through GAN inver-sion [21, 51, 58].
In parallel, Denoising Diffusion Proba-bilistic Models (DDPMs) [2, 7, 35, 67, 72, 77] have demon-strated impressive generative capabilities, level of details, and diversity on top of GAN [26, 61, 62, 71, 73, 76]. As an early attempt, Kawar et al. [31] explore pre-trained DDPMs with variational inference, and achieve satisfactory results on multiple restoration tasks, but their Denoising Diffusion
Restoration Model (DDRM) leverages the singular value decomposition (SVD) on a known linear degradation ma-trix, making it still limited to linear inverse problems.
In this study, we take a step further and propose an effi-cient approach named Generative Diffusion Prior (GDP).
It exploits a well-trained DDPM as effective prior for general-purpose image restoration and enhancement, using degraded image as guidance. As a unified framework, GDP not only works on various linear inverse problems, but also generalizes to non-linear, and blind image restoration and enhancement tasks for the first time. However, solving the blind inverse problem is not trivial, as one would need to concurrently estimate the degradation model and recover the clean image with high fidelity. Thanks to the generative prior in a pre-trained DDPM, denoising within the DDPM manifold naturally regularizes the realness and fidelity of the recovered image. Therefore, we adopt a blind degrada-tion estimation strategy, where the degradation model pa-rameters of GDP are randomly initialized and optimized during the denoising process. Moreover, to further improve the photorealism and image quality, we systematically in-vestigate an effective way to guide the diffusion models.
Specifically, in the sampling process, the pre-trained DDPM first predicts a clean image ˜x0 from the noisy image xt by estimating the noise in xt. We can add guidance on this in-termediate variable ˜x0 to control the generation process of the DDPMs. In addition, with the help of the proposed hier-archical guidance and patch-based generation strategy, GDP is able to recover images of arbitrary resolutions, where low-resolution images and degradation models are first pre-dicted to guide the generation of high-resolution images.
We demonstrate the empirical effectiveness of GDP by comparing it with various competitive unsupervised meth-ods under the linear or multi-linear inverse problem on
ImageNet [14], LSUN [89], and CelebA [30] datasets in terms of consistency and FID. Over the low-light [39] and
NTIRE [59] datasets, we further show GDP results on non-linear and blind issues, including low-light enhancement and HDR recovery, superior to other zero-shot baselines both qualitatively and quantitively, manifesting that GDP trained on ImageNet also works on images out of its train-ing set distribution.
Our contributions are fourfold: (1) To our best knowl-edge, GDP is the first unified problem solver that can ef-fectively use a single unconditional DDPM pre-trained on ImageNet provide by [15] to produce diverse and high-fidelity outputs for unified image restoration and enhance-ment in an unsupervised manner. (2) GDP is capable of op-timizing randomly initiated parameters of degradation that are unknown, resulting in a powerful framework that can tackle any blind image restoration. (3) Further, to achieve arbitrary size image generation, we propose hierarchical guidance and patch-based methods, greatly promoting GDP on natural image enhancement. (4) Moreover, the compre-hensive experiments are carried out, different from the con-ventional guidance way, where GDP directly predicts the temporary output given the noisy image in every step, which will be leveraged to guide the generation of images in the next step. 2.