Abstract
Image segmentation is a fundamental task in the field of imaging and vision. Supervised deep learning for segmen-tation has achieved unparalleled success when sufficient training data with annotated labels are available. However, annotation is known to be expensive to obtain, especially for histopathology images where the target regions are usu-ally with high morphology variations and irregular shapes.
Thus, weakly supervised learning with sparse annotations of points is promising to reduce the annotation workload. In this work, we propose a contrast-based variational model to generate segmentation results, which serve as reliable complementary supervision to train a deep segmentation model for histopathology images. The proposed method considers the common characteristics of target regions in histopathology images and can be trained in an end-to-end manner.
It can generate more regionally consistent and smoother boundary segmentation, and is more robust to un-labeled ‘novel’ regions. Experiments on two different his-tology datasets demonstrate its effectiveness and efficiency in comparison to previous models. Code is available at: https://github.com/hrzhang1123/CVM_WS_
Segmentation. 1.

Introduction
Histopathology images are of great importance for clini-cal diagnosis and prognosis of diseases. With the thriving of artificial intelligence (AI) techniques over the past decade, especially deep learning, automatic analysis of histopathol-ogy images in some tasks has achieved comparable or even
†: Equal contribution; ∗: Corresponding author
Figure 1. Two examples of histopathology images with target re-gions (e.g. tumor (top row) and stroma (bottom row)) annotated by contours (b) or in-target and out-of-target points (c). surpassing performance in comparison with human pathol-ogists’ reviewing [2, 13, 28, 50]. However, most competent methods are based on supervised learning, and their perfor-mances critically rely on a large number of training samples with detailed annotations. Yet such annotations usually re-quire experienced pathologists and are expensive (in terms of cost and time consumption) to obtain, and also subject to human errors. The annotation problem for histopathol-ogy images is particularly demanding, not only due to the large size of such an image but also resulting from irregular shapes of target tissues to be annotated (See Figure.1).
Weakly supervised learning is a promising solution to alleviate the issues of obtaining annotations. The anno-tations for the “weakly supervised” can specifically re-fer to image-level labelling (multiple instance learning)
[23, 25, 27, 41, 48, 51], partial annotations within an image (point or scribble annotation) [26], or full annotation in par-tial images (semi-supervised learning) [31]. Amongst these three categories, learning by partial annotations has excel-lent target localization capability, yet requires comparably less cost to annotate.
Interactive segmentation with scribbles or points has been widely studied for a few decades [4]. Conventional methods relied on user interactive input for object segmen-tation, such as grab-cut [39], Graph-cut [4], active contour-based selective segmentation [37], random walker [17]. In recent years it has been a hot topic to develop segmentation models that can be trained by utilizing only the scribble or point annotations, formulated as partially-supervised learn-ing problem [8, 12, 22, 24, 26, 34, 36, 46, 49, 52]. Yet, exist-ing partially-supervised methods were designed mainly for natural images or medical images with relatively regular-shaped objects and consistent textures, and very few are di-rectly applicable to histopathology images given the above challenges.
In this work, we focus on partially-supervised learning for histopathology image segmentation based on in-target and out-of-target point annotations, where in-target points refer to those labelled inside the target regions and out-of-target points refer to the outside ones. Histopathology images are significantly distinguished from other types of images. In many histopathology images, the target objects present distinct regional characteristics. Specifically, as the example shown in Figure.1, the tumors usually cluster in-side large regions, in which morphological features or tex-tures are similar and visually different to the outside re-gions, and there exist comparably clear boundaries. Ex-isting works on partially-supervised learning do not well utilize this characteristic. Moreover, a histopathology im-age scanned from a tissue section often contains some non-target regions that are visually or morphologically unique to those in other images. If such regions are not labelled, they will be ‘novel’ to a trained machine learning model, and the predicted categories of them will depend on their similarity to the neutral tissue and to the target tissue. If such novel re-gions are more similar to target tissues, they will be wrongly predicted as the target category, leading to false detections.
Existing methods are limited in tackling this situation, es-pecially for those methods based on consistency training on data augmentation [15, 30], as consistency supervision may amplify such errors.
Based on the above observations and insights, we pro-pose to adopt a variational segmentation model to provide complementary supervision information to assist the train-ing of a deep segmentation model. This variational seg-mentation model itself will be guided by annotated in-target and out-of-target points for the segmentation of target re-gions in the images. Variational methods are powerful tools for segmenting structures in an image. Often posed as an optimisation problem, energy functionals can be carefully constructed to satisfy certain desired properties, for exam-ple, maintaining consistency inside the evolving contour, or constraining the length of the boundary to ensure a smooth boundary [11, 40].
The uniqueness of variational methods highly fits the characteristic of target regions in histopathology images, as mentioned above. However, existing variational methods cannot be directly applied to high-dimensional deep fea-tures, which contain higher-level semantic information. To tackle this problem, we introduce the concept of contrast maps derived from deep feature correlation maps and for-mulate a variational model applied to the obtained contrast maps. Specifically, a set of correlation maps are generated based on the annotated points on an image. The correspond-ing contrast maps can then be obtained by the pairs of corre-lation maps of in-target and out-of-target points through the subtraction operation. A variational formulation is used to aggregate the obtained contrast maps for the final segmen-tation result. Finally, the variational segmentation provides complementary supervision to the deep segmentation model through the uncertainty-aware Kullback–Leibler (KL) di-vergence. Besides, the proposed model can alleviate the aforementioned issue of unlabeled novel tissue regions, re-sulting from the subtraction operation in obtaining the con-trast maps.
In summary, the main contribution of this work is the for-mulated contrast-based variational model, used as reliable complementary supervision for training a deep segmenta-tion model from weak point annotations for histopathology images. The variational model is based on the proposed new contrast maps, which incorporate the correlations between each location in an image and the annotated in-target and out-of-target points. The proposed model is well suited for the segmentation of histopathology images and is robust to unlabeled novel regions. The effectiveness and efficiency of the proposed method are empirically proven by the experi-mental results on two different histology datasets. 2.