Abstract
Non-blind deblurring methods achieve decent perfor-mance under the accurate blur kernel assumption. Since the kernel uncertainty (i.e. kernel error) is inevitable in practice, semi-blind deblurring is suggested to handle it by introducing the prior of the kernel (or induced) error. How-ever, how to design a suitable prior for the kernel (or in-duced) error remains challenging. Hand-crafted prior, in-corporating domain knowledge, generally performs well but may lead to poor performance when kernel (or induced) er-ror is complex. Data-driven prior, which excessively de-pends on the diversity and abundance of training data, is vulnerable to out-of-distribution blurs and images. To ad-dress this challenge, we suggest a dataset-free deep resid-ual prior for the kernel induced error (termed as residual) expressed by a customized untrained deep neural network, which allows us to ﬂexibly adapt to different blurs and im-ages in real scenarios. By organically integrating the re-spective strengths of deep priors and hand-crafted priors, we propose an unsupervised semi-blind deblurring model which recovers the clear image from the blurry image and inaccurate blur kernel. To tackle the formulated model, an efﬁcient alternating minimization algorithm is developed.
Extensive experiments demonstrate the favorable perfor-mance of the proposed method as compared to model-driven and data-driven methods in terms of image quality and the robustness to different types of kernel error. 1.

Introduction
Image blurring is mainly caused by camera shake [28], object motion [9], and defocus [42]. By assuming the blur kernel is shift-invariant, the image blurring can be formu-lated as the following convolution process: y = k ⊗ x + n, (1)
*Corresponding author
Blurry
[8]
[34]
Ours
PSNR 19.56 PSNR 20.83 PSNR 22.75 PSNR 25.66
True Res.
MSE 0
Res. in [8]
Res. in [34]
Our Res.
MSE 0.075 MSE 0.067 MSE 0.027
Figure 1. Visual comparison of the restored results and esti-mated residuals by three semi-blind methods based on different priors for the residual induced by the kernel error, including hand-crafted prior [8], data-driven prior [34], and the proposed deep residual prior (DRP). The true residual is the convolution result of the kernel error and the clear image (r = ∆k ⊗ x). The closer estimated residual is to the true residual, the better it is. where y and x denote the blurry image and the clear im-age respectively, k represents the blur kernel, n represents the additive Gaussian noise, and ⊗ is the convolution oper-ator. To acquire the clear image from the blurry one, image deblurring has received considerable research attention and related methods have been developed.
In terms of the availability of kernel, current image de-blurring methods can be mainly classiﬁed into two cate-gories, i.e., blind deblurring methods in which the blur ker-nel is assumed to be unknown, and non-blind deblurring methods in which the blur kernel is assumed to be known or computed elsewhere. Typical blind deblurring methods
[13, 15, 17, 18, 21, 27, 31, 32, 38, 43] involve two steps: 1) estimating the blur kernel from the blurry images, and 2) recovering the clear image with the estimated blur kernel.
Recently there also emerge transformer-based [36, 39] and unfolding networks [19] that learn direct mappings from blurry image to the deblurred one without using the kernel.
Non-blind deblurring methods [1, 4, 5, 6, 11, 22, 35, 40], based on various priors for the clear image, estimate the clear image solely from the blurry image with known blur kernel. Notably, existing non-blind deblurring methods can perform well under the error-free kernel assumption. How-ever, in the real application, uncertainty exists in the kernel acquisition process. As a result, these methods without han-dling kernel uncertainty often introduce artifacts and cause unpleasant performances.
Recently, semi-blind methods are suggested to handle kernel uncertainty by introducing the prior for the kernel (or induced) error. In the literature, there are two groups of priors of kernel (or induced) error, i.e., hand-crafted priors and data-driven priors. Hand-crafted priors [8, 41], incorpo-rating domain knowledge, generally perform well but may lead to poor performance when the distribution of kernel (or induced) error is complex. For example, hand-crafted priors (e.g., sparse prior [8]) are relatively impotent to characterize the complex intrinsic structure of the kernel induced error; see Figure 1. Data-driven priors [20, 26, 34], which ex-cessively depend on the diversity and abundance of training data, are vulnerable to out-of-distribution blurs and images.
Speciﬁcally, the data-driven prior in [34] that is expressed by a trained network introduces artifacts around the sharp edges; see Figure 1. Therefore, how to design a suitable prior for the kernel (or induced) error remains challenging.
To address this problem, we suggest a dataset-free deep prior called deep residual prior (DRP) for the kernel induced error (termed as residual), which leverages the strong rep-resentation ability of deep neural networks. Speciﬁcally,
DRP is expressed by an untrained customized deep neu-ral network. Moreover, by leveraging the general domain knowledge, we use the sparse prior to guide DRP to form a semi-blind deblurring model. This model organically in-tegrates the respective strengths of deep priors and hand-crafted priors to achieve favorable performance. To the best of our knowledge, we are the ﬁrst to introduce the untrained network to capture the kernel induced error in semi-blind problems, which is a featured contribution of our work.
In summary, our contributions are mainly three-fold:
• For the residual induced by the kernel uncertainty, we elaborately design a dataset-free DRP, which allows us to faithfully capture the complex residual in real-world appli-cations as compared to hand-crafted priors and data-driven priors.
• Empowered by the deep residual prior, we suggest an unsupervised semi-blind deblurring model by synergizing the respective strengths of dataset-free deep prior and hand-crafted prior, which work togerther to deliver promising re-sults.
• Extensive experiments on different blurs and images sus-tain the favorable performance of our method, especially for the robustness to kernel error. 2.