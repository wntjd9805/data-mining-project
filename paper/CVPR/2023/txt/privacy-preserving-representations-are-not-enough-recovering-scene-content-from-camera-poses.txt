Abstract
Visual localization is the task of estimating the camera pose from which a given image was taken and is central to several 3D computer vision applications. With the rapid growth in the popularity of AR/VR/MR devices and cloud-based applications, privacy issues are becoming a very im-portant aspect of the localization process. Existing work on privacy-preserving localization aims to defend against an attacker who has access to a cloud-based service. In this paper, we show that an attacker can learn about details of a scene without any access by simply querying a localization service. The attack is based on the observation that modern visual localization algorithms are robust to variations in ap-pearance and geometry. While this is in general a desired property, it also leads to algorithms localizing objects that are similar enough to those present in a scene. An attacker can thus query a server with a large enough set of images of objects, e.g., obtained from the Internet, and some of them will be localized. The attacker can thus learn about object placements from the camera poses returned by the service (which is the minimal information returned by such a ser-vice). In this paper, we develop a proof-of-concept version of this attack and demonstrate its practical feasibility. The attack does not place any requirements on the localization algorithm used, and thus also applies to privacy-preserving representations. Current work on privacy-preserving repre-sentations alone is thus insufficient. 1.

Introduction
Visual localisation refers to the problem of estimating the camera pose of a given image in a known scene. It is a core problem in several 3D computer vision applications, including self-driving cars [17, 18] and other autonomous robots [50], and Augmented Reality [5, 23, 25].
A popular approach for Augmented/Mixed/Virtual Re-ality (XR) applications is to use a client-server mechanism for localization: the user device (client) sends image data to a cloud-based system (server) that computes and returns the camera pose [23, 25, 46]. Examples of such services in-clude Google’s Visual Positioning System [29], Microsoft’s
Azure Spatial Anchors [24], and Niantic’s Lightship [39].
Cloud-based localization services are popular for multiple reasons - first, performing localization on the server reduces storage requirements and the computational load, and thus energy consumption, which is important for client devices such as mobile phones and headsets; second, it enables us-ing robust mapping and localization algorithms that are too expensive for mobile devices; third, in the context of col-laborative mapping, e.g., for the AR cloud or autonomous driving, maintaining a single scene representation in a cen-tralized place is far easier than keeping multiple copies on various mobile devices up-to-date.
Naturally, sending user data to a server, e.g., in the form of images to be localized or 3D maps recorded by users that will be used for localization, raises privacy con-cerns [9, 41, 42]. Work on privacy-preserving localization aims to resolve these concerns by ensuring that private de-tails cannot be recovered from the data sent [14, 26, 42] to or stored on the server [11, 11, 15, 28, 36, 41, 52].
Existing work focuses on scenarios where an attacker gains access to the localization service or can eavesdrop on the communication between client and server. In this work, we demonstrate that it is possible for an attacker to learn about the content of a scene stored on a localization server without direct access to the server. We show that a localiza-tion service will reveal scene-related information through estimated camera poses, i.e., through its normal operation process. The attack is based on two recent developments: (1) modern visual localization algorithms are designed to be robust against changes such as illumination and seasonal variations [44]. This is an essential property for cloud-based localization services in order to operate robustly and reli-Figure 1. In the context of privacy-preserving localization, we show that it is possible to learn about the content of a scene using camera poses returned by a localization service, without any direct access to the scene representation. (1st column) Examples of images from the scene, used to build the scene representation. The images are shown for illustrative purposes and are not available to an attacker trying to learn about the scene. (2nd column) The attacker queries the service with images of objects, e.g., downloaded from the Internet. (3rd & 4th column) Using the camera poses for the query image returned by the localization service, the attacker is able to identify the types of objects present in the scene and to accurately place them in the scene. We show the estimated object poses overlaid over the ground truth structure of the scene (which is not accessible to the attacker). The attacker is able to faithfully recover the placement of objects. Overall, our results demonstrate that simple feedback such as camera poses is already sufficient to potentially reveal private details. ably. However, since these algorithms are robust to (slight) variations in appearance and geometry, they will also local-ize images showing objects that are similar (but not neces-sarily identical) to those objects present in the scene. (2) massive amounts of images depicting objects in different variations are readily available on the Internet. Taken to-gether, both developments allow an attacker to repeatedly query the server with images and to recover the positions of the objects in the scene based on the camera poses returned by the server (cf . Fig. 1). In this paper, we demonstrate the feasibility of this attack by developing a proof-of-concept implementation of the attack.
In summary, we make the following contributions: (1) we identify a new line of attack in the context of privacy-preserving visual localization based on the camera poses returned by a cloud-based server. (2) we show the feasibil-ity of the attack through a proof-of-concept implementation of the attack. Through experiments, we explore the per-formance of our implementation as well as the trade-off be-tween localization robustness and potential defenses against the attack. (3) the attack is agnostic to the underlying local-ization algorithm and thus applicable even if the localiza-tion system is otherwise perfectly privacy-preserving. This paper thus proposes a new research direction for privacy-preserving localization, where the aim for the localization service is to correctly identify whether a query image was taken in the concerned scene or not, in order to prevent leak-ing information through camera poses. 2.