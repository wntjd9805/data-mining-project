Abstract
The recently proposed open-world object and open-set detection have achieved a breakthrough in finding never-seen-before objects and distinguishing them from known ones. However, their studies on knowledge transfer from known classes to unknown ones are not deep enough, result-ing in the scanty capability for detecting unknowns hidden in the background. In this paper, we propose the unknown sniffer (UnSniffer) to find both unknown and known objects.
Firstly, the generalized object confidence (GOC) score is introduced, which only uses known samples for supervision and avoids improper suppression of unknowns in the back-ground. Significantly, such confidence score learned from known objects can be generalized to unknown ones. Addi-tionally, we propose a negative energy suppression loss to further suppress the non-object samples in the background.
Next, the best box of each unknown is hard to obtain during inference due to lacking their semantic information in train-ing. To solve this issue, we introduce a graph-based deter-mination scheme to replace hand-designed non-maximum suppression (NMS) post-processing. Finally, we present the Unknown Object Detection Benchmark, the first pub-licly benchmark that encompasses precision evaluation for unknown detection to our knowledge. Experiments show that our method is far better than the existing state-of-the-art methods. Code is available at: https://github. com/Went-Liang/UnSniffer. 1.

Introduction
Detecting objects with a limited number of classes in the closed-world setting [2, 3, 14, 20, 21, 23, 31–33, 46] has been the norm for years. Recently, the popularity of autonomous
†Equal Contribution
*Corresponding Author
This work was supported by the national key R & D program inter-governmental international science and technology innovation cooperation project 2021YFE0101600.
Figure 1. (a)-(c) the predicted unknown (blue), known (yellow), and missed (red) objects of VOS [9], ORE [18], and our model. (e) (d) t-SNE visualization of various classes’ hidden vectors. score for objects and non-object (generalized object confidence). (f) score for unknown, known, and non-object (negative energy). driving [4, 7, 17, 25, 29, 30, 38, 39, 43–45] has raised the bar for object detection. That is, the detector should detect both known and unknown objects. ‘Known Objects’ are those that belong to pre-defined categories, while ‘Unknown Ob-jects’ are those that the detector has never seen during train-ing. Detecting unknown objects is crucial in coping with more challenging environments, such as autonomous driv-ing scenes with potential hazards.
Since unknown objects do not have labels in the train-ing set, how to learn knowledge that can be generalized to unknown classes from finite pre-defined categories is the key issue in detecting unknown objects.
In recent years, a series of groundbreaking works have been impressive on open-set detection (OSD) [8, 9, 11, 28] and open-world ob-ject detection (OWOD) [12, 18, 37, 40]. Several OSD meth-ods have used uncertainty measures to distinguish unknown
objects from known ones. However, they primarily focus on improving the discriminatory power of uncertainty and tend to suppress non-objects along with many potential un-knowns in the training phase. As a result, these meth-ods miss many unknown objects. Fig. 1 (a) shows that
VOS [9] misses many unknown objects, such as bags, stalls and surfboards. Furthermore, OWOD requires generating high-quality boxes for both known and unknown objects.
ORE [18] and OW-DETR [12] collect the pseudo-unknown samples by an auto-labelling step for supervision and per-form knowledge transfer from the known to the unknown by contrastive learning or foreground objectness. But the pseudo-unknown samples are unrepresentative of the un-known objects, thus limiting the model’s ability to describe unknowns. Fig. 1 (b) shows that ORE [18] mis-detects many unknown objects, even though some are apparent.
In philosophy, there is a concept called ‘Analogy’ [34], which describes unfamiliar things with familiar ones. We argue that despite being ever-changing in appearance, the unknown objects are often visually similar to the objects of pre-defined classes, as observed in Fig. 1 (d). The t-SNE visualization shows that the unknown objects tend to be among several pre-defined classes, while the non-objects are far away from them. This inspires us to express a unified concept of ‘object’ by the proposed generalized object con-fidence (GOC) score learned from the known objects only.
To this end, we first discard the background bounding boxes and only collect the object-intersected boxes for training to prevent potential unknown objects from being classified as backgrounds. Then, a combined loss function is designed to enforce the detector to assign relatively higher scores to boxes tightly enclosing objects. Unlike ‘objectness’, non-object boxes are not used as the negative samples for su-pervision. Fig. 1 (e) shows that the GOC score distinctly separates non-objects and ‘objects’. In addition, we design a negative energy suppression loss on top of VOS’s energy calculation [9] to further widen the gap between the non-object and the ‘object’. Fig. 1 (f) shows three distinct peaks for the knowns, unknowns and non-objects. Next, due to the absence of the unknown’s semantic information in training, the detector hardly determines the best bounding box by a constant threshold when the number of objects cannot be predicted ahead of time. In our model, the best box determi-nation is modelled as a graph partitioning problem, which adaptively clusters high-score proposals into several groups and selects one from each group as the best box.
As far as we know, the existing methods are evaluated on the COCO [22] and Pascal VOC benchmarks [10] that do not thoroughly label unknown objects. Therefore, the accu-racy of unknown object detection cannot be evaluated. Mo-tivated by this practical need, we propose the Unknown Ob-ject Detection Benchmark (UOD-Benchmark), which takes the VOC’s training set as the training data and contains two test sets. (1) COCO-OOD containing objects with the un-known class only; (2) COCO-Mix with both unknown and known objects. They are collected from the original COCO dataset [22] and annotated according to the COCO’s in-stance labeling standard. In addition, the Pascal VOC test-ing set is employed for evaluating known object detection.
Our key contributions can be summarized as follows:
• To better separate non-object and ‘object’, we propose the GOC score learned from known objects to express unknown objects and design the negative energy sup-pression to further limit non-object.
• The graph-based box determination is designed to adaptively select the best bounding box for each object during inference for higher unknown detection preci-sion.
• We propose the UOD-Benchmark containing annota-tion of both known and unknown objects, enabling us to evaluate the precision of unknown detection. We comprehensively evaluate our method on this bench-mark which facilitates future use of unknown detection in real-world settings. 2.