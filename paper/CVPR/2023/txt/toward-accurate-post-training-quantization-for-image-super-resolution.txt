Abstract
Model quantization is a crucial step for deploying super resolution (SR) networks on mobile devices. However, exist-ing works focus on quantization-aware training, which re-quires complete dataset and expensive computational over-head.
In this paper, we study post-training quantization (PTQ) for image super resolution using only a few unla-beled calibration images. As the SR model aims to maintain the texture and color information of input images, the distri-bution of activations are long-tailed, asymmetric and highly dynamic compared with classiﬁcation models. To this end, we introduce the density-based dual clipping to cut off the outliers based on analyzing the asymmetric bounds of acti-vations. Moreover, we present a novel pixel aware calibra-tion method with the supervision of the full-precision model to accommodate the highly dynamic range of different sam-ples. Extensive experiments demonstrate that the proposed method signiﬁcantly outperforms existing PTQ algorithms on various models and datasets. For instance, we get a 2.091 dB increase on Urban100 benchmark when quantiz-ing EDSR×4 to 4-bit with 100 unlabeled images. Our code is available at both PyTorch and MindSpore. 1.

Introduction
Image super resolution (SR) is a classical image pro-cessing task in computer vision, which reconstructs high-resolution (HR) images from the corresponding low-resolution (LR) images. SR has been widely applied in the real-world scenarios, such as medical imaging [12, 35], surveillance [1, 49], satellite imagery [31, 36] and smart-phone display [8, 19]. With the rapid development of deep learning in recent years, SR models with deep neural net-work (DNN) structure have continued to achieve state-of-the-art performance on various datasets. However, these
SR models require signiﬁcant storage and computational re-sources, which makes their deployment on mobile devices extremely difﬁcult. To improve the inference efﬁciency, various techniques have been proposed to compress the models, such as network pruning [16, 50], model quantiza-Table 1. Computational overhead of different quantization meth-ods on EDSR model. The FP denotes full-precision training, the
Gt denotes the ground-truth, and the Bs denotes batch size.
Type Data Gt Bs
Method 800 (cid:51) 16
FP
EDSR [28]
QAT 800 (cid:51) 16
PAMS [25]
QAT 800 (cid:51) 16
FQSR [40]
CADyQ [14] QAT 800 (cid:51) 8
QAT 800 (cid:51) 4
DAQ [15]
DDTB [52] QAT 800 (cid:51) 16
PTQ 100 (cid:53) 2
Ours
Iters Run time 240× 24× 120× 240× 1200× 48× 1× 15,000 1,500 15,000 30,000 300,000 3,000 500 tion [13, 38], compact architecture design [8, 9] and knowl-edge distillation [29, 41, 45, 46]. Among these approaches, model quantization is much beneﬁt to existing artiﬁcial in-telligent (AI) accelerators [3, 42], which generally focus on low-precision arithmetic, resulting in lower latency, smaller memory footprint and less energy consumption.
Although the previous SR quantization methods make great effort on improving the performance with given bit-width, their main drawback is that they require quantiza-tion aware training (QAT) with complete datasets and ex-pensive computational overhead. As shown in Table 1, the full-precision EDSR model needs to train 15,000 iters with the batch size of 16, takes 8 days on NVIDIA Titan X
GPUs [28]. To recover the performance drop of the quan-tized models, most methods also need to train with the same iterative steps on the complete training dataset, in which one training step in QAT actually takes more GPU memory and longer running time than those of the regular ﬂoating-point.
On the contrast, post-training quantization (PTQ) only requires a few unlabeled calibration images without train-ing, which enables fast deployment on various devices within minutes. Nevertheless, different from the image clas-siﬁcation, super resolution requires accurate prediction for each pixel of the output images, which is much sensitive to low-bit compression for feature maps. Figure 2 shows the original ﬂoating-point activations of different layers and samples, we observe three properties of their distributions that are much unfriendly to quantization: (1) Long-tailed:
Figure 1. The overview of the proposed post-training quantization framework for image super resolution. the distribution shows to be dense in the middle yet sparse in the tails, which means most of values lie in a small range, while only a few outliers have larger amplitude; (2) Asym-metric: the density on the two tails of the distribution is asymmetric, the skewness differ for different layers; (3)
Highly-dynamic: the activation range varies, or even by twice, for different input samples. Therefore, the existing
PTQ methods which are designed for image classiﬁcation can not be transferred to the SR task directly.
In this paper, we propose a coarse-to-ﬁne method to get the accurate quantized SR model with post-training quan-tization. We ﬁrst introduce the density-based dual clipping (DBDC) to cut off most of the outliers for narrowing the distribution to a valid range. Different from previous meth-ods [25, 40], the amplitudes of lower and upper clip are not same and the clipping position is depend on the den-sity of two tails. The clipping scheme is employed itera-tively to eliminate the long-tail distribution. The asymmet-ric quantizer with adjustable lower and upper clip values is adopted to solve the asymmetric distribution in SR models.
And then we further propose a novel pixel-aware calibration (PaC) to help the quantized network ﬁt the highly dynamic activations for different samples. The PaC leverages fea-ture maps of the full-precision model to supervise those of the quantized model. To stabilize the ﬁnetune process, we only update the quantization parameters instead of the orig-inal weights. The whole quantization process of our method can be ﬁnished within minutes with a few unlabeled images.
The contributions of this paper are summarized as follow: (1) We present a detailed analysis to demonstrate the challenge of post-training quantization on image super reso-lution, indicating that the performance degradation of quan-tized SR model suffers from the long-tailed, asymmetric and highly-dynamic distribution of feature maps. (2) We introduce a coarse-to-ﬁne quantization method to accommodate above problems. With the density-based dual clipping and the pixel-aware calibration, the proposed method is able to conduct accurate quantization with only a few unlabeled calibration images. To the best of our knowl-edge, we are the ﬁrst to optimize the post-training quantiza-tion for image super resolution task. (3) Extensive experiments on various benchmark models and datasets demonstrate that our method signiﬁcantly out-performs the existing PTQ methods, and is able to achieve comparable performance with the QAT in some setting.
Further, our method can speed up the convergence and bring up the performance when combined with QAT methods. 2.