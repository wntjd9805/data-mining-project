Abstract
Existing dehazing approaches struggle to process real-world hazy images owing to the lack of paired real data and robust priors. In this work, we present a new paradigm for real image dehazing from the perspectives of synthe-sizing more realistic hazy data and introducing more ro-bust priors into the network. Specifically, (1) instead of adopting the de facto physical scattering model, we re-think the degradation of real hazy images and propose a phenomenological pipeline considering diverse degrada-(2) We propose a Real Image Dehazing net-tion types. work via high-quality Codebook Priors (RIDCP). Firstly, a
VQGAN is pre-trained on a large-scale high-quality dataset to obtain the discrete codebook, encapsulating high-quality priors (HQPs). After replacing the negative effects brought by haze with HQPs, the decoder equipped with a novel normalized feature alignment module can effectively utilize high-quality features and produce clean results. However, although our degradation pipeline drastically mitigates the domain gap between synthetic and real data, it is still in-tractable to avoid it, which challenges HQPs matching in the wild. Thus, we re-calculate the distance when match-ing the features to the HQPs by a controllable matching operation, which facilitates finding better counterparts. We provide a recommendation to control the matching based on an explainable solution. Users can also flexibly adjust the enhancement degree as per their preference. Extensive experiments verify the effectiveness of our data synthesis pipeline and the superior performance of RIDCP in real image dehazing. Code and data are released at https://rq-wu.github.io/projects/RIDCP. 1.

Introduction
Image dehazing aims to recover clean images from their hazy counterparts, which is essential for computational pho-tography and high-level tasks [20, 32]. The hazy image for-mulation is commonly described by a physical scattering
*Corresponding author (a) Hazy input (b) DAD [33] (c) PSD [7] (d) Ours
Figure 1. Visual comparisons on a typical hazy image. The pro-posed method generates cleaner results than other two state-of-the-art real image dehazing approaches. The enhancement degree of our result can be flexibly adjusted by adopting different parame-ters in the real-domain adaptation phase. The image with a golden border is the result obtained under our recommended parameter. model:
I(x) = J(x)t(x) + A(1 − t(x)), (1) where I(x) denotes the hazy image and J(x) is its corre-sponding clean image. The variables A and t(x) are the global atmosphere light and transmission map, respectively.
The transmission map t(x) = eβd(x) depends on scene depth d(x) and haze density coefficient β.
Given a hazy image, restoring its clean version is highly ill-posed. To mitigate the ill-posedness of this problem, var-ious priors, e.g., dark channel prior [16], color attenuation prior [44], and color lines [12] have been proposed in exist-ing traditional methods. Nevertheless, the statistical priors cannot cover diverse cases in real-world scenes, leading to suboptimal dehazing performance.
With the advent of deep learning, image dehazing has achieved remarkable progress. Existing methods either adopt deep networks to estimate physical parameters [5, 21, 31] or directly restore haze-free images [10, 15, 27, 30, 40].
However, image dehazing neural networks perform lim-ited generalization to real scenes, owing to the difficulty in 1
collecting large-scale yet perfectly aligned paired training data and solving the uncertainty of the ill-posed problem without robust priors . Concretely, 1) collecting large-scale and perfectly aligned hazy images with the clean counter-part is incredibly difficult, if not impossible. Thus, most of the existing deep models use synthetic data for training, in which the hazy images are generated using Eq. (1), lead-ing to the neglect of multiple degradation factors. There are some real hazy image datasets [2, 3] with paired data, but the size and diversity are insufficient. Moreover, these datasets deviate from the hazy images captured in the wild.
These shortcomings inevitably decrease the capability of deep models in real scenes. 2) Real image dehazing is a highly ill-posed issue. Generally, addressing an uncertain mapping problem often needs the support of priors. How-ever, it is difficult to obtain robust priors that can cover the diverse scenes of real hazy images, which also limits the performance of dehazing algorithms. Recently, many stud-ies for real image dehazing try to solve these two issues by domain adaptation from the perspective of data genera-tion [33,39] or priors guidance [7,23], but still cannot obtain desirable results.
In this work, we present a new paradigm for real image dehazing motivated by addressing the above two problems.
To obtain large-scale and perfectly aligned paired training data, we rethink the degradation of hazy images by observ-ing amounts of real hazy images and propose a novel data generation pipeline considering multiple degradation fac-tors. In order to solve the uncertainty of the ill-posed issue, we attempt to train a VQGAN [11] on high-quality images to extract more robust high-quality priors (HQPs). The VQ-GAN only learns high-quality image reconstruction, so it naturally contains the robust HQPs that can help hazy fea-tures jump to the clean domain. The observation in Sec. 4.1 further verifies our motivation. Thus, we propose the Real
Image Dehazing network via high-quality Codebook Priors (RIDCP). The codebook and decoder of VQGAN are fixed to provide HQPs. Then, RIDCP is equipped with an en-coder that helps find the correct HQPs, and a new decoder that utilizes the features from the fixed decoder and pro-duces the final result. Moreover, we propose a novel Nor-malized Feature Alignment (NFA) that can mitigate the dis-tortion and balance the features for better fusion.
In comparison to previous methods [6, 14, 43] that intro-duce codebook for image restoration, we further design a unique real domain adaptation strategy based on the char-acteristics of VQGAN and the statistical results. Intuitively, we propose Controllable HQPs Matching (CHM) operation that replaces the nearest-neighbour matching by imposing elaborate-designed weights on the distances between fea-tures and HQPs during the inference phase. The weights are determined by a controllable parameter α and the statistical distribution gap of HQPs activation in Sec. 4.3. By adjust-ing α, the distribution of HQPs activation can be shifted.
Moreover, we present a theoretically feasible solution to obtain the optimal α by minimizing the Kullback-Leibler
Divergence of two probability distributions. More signifi-cantly, the value of α can be visually reflected as the en-hancement degree as shown in Figure 1(d), and users are al-lowed to adjust the dehazing results as per their preference.
Our CHM is effective, flexible, and explainable.
Compared with the state-of-the-art real image dehazing methods, e.g., DAD [33] and PSD [7], only the proposed
RIDCP can effectively process the hazy images captured in the wild while generating adjustable results, which are shown in Figure 1. The contributions of our work can be summarized as follows.
• We present a new paradigm to push the frontier of deep learning-based image dehazing towards real scenes.
• We are the first to leverage the high-quality codebook prior in the real image dehazing task. The controllable
HQPs matching operation is proposed to overcome the gap between synthetic and real domains and produce adjustable results.
• We re-formulate the degradation model of real hazy images and propose a phenomenological degradation pipeline to simulate the hazy images captured in the wild. 2.