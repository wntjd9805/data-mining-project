Abstract
Although DETR-based 3D detectors simplify the detec-tion pipeline and achieve direct sparse predictions, their performance still lags behind dense detectors with post-processing for 3D object detection from point clouds. DE-TRs usually adopt a larger number of queries than GTs (e.g., 300 queries v.s. ∼40 objects in Waymo) in a scene, which inevitably incur many false positives during infer-ence. In this paper, we propose a simple yet effective sparse 3D detector, named Query Contrast Voxel-DETR (Con-QueR), to eliminate the challenging false positives, and achieve more accurate and sparser predictions. We observe that most false positives are highly overlapping in local re-gions, caused by the lack of explicit supervision to discrimi-nate locally similar queries. We thus propose a Query Con-trast mechanism to explicitly enhance queries towards their best-matched GTs over all unmatched query predictions.
This is achieved by the construction of positive and negative
GT-query pairs for each GT, and a contrastive loss to en-hance positive GT-query pairs against negative ones based on feature similarities. ConQueR closes the gap of sparse and dense 3D detectors, and reduces ∼60% false positives.
Our single-frame ConQueR achieves 71.6 mAPH/L2 on the challenging Waymo Open Dataset validation set, outper-forming previous sota methods by over 2.0 mAPH/L2. Code 1.

Introduction 3D object detection from point clouds has received much attention in recent years [7, 32, 34, 47, 52] as its wide ap-plications in autonomous driving, robots navigation, etc.
State-of-the-art 3D detectors [7, 31, 33, 53] still adopt dense predictions with post-processing (e.g., NMS [2]) to obtain final sparse detections. This indirect pipeline usually in-volves many hand-crafted components (e.g., anchors, center masks) based on human experience, which involves much effort for tuning, and prevents dense detectors from being
Figure 1. Comparison of our baseline Voxel-DETR and ConQueR.
GTs (green) and predictions (blue) of an example scene in the
WOD is visualized. Sparse predictions of Voxel-DETR still con-tain many highly overlapped false positives (in the red dashed cir-cle), while ConQueR can generate much sparser predictions. optimized end-to-end to achieve optimal performance. Re-cently, DETR-based 2D detectors [3, 39, 49, 57] show that transformers with direct sparse predictions can greatly sim-plify the detection pipeline, and lead to better performance.
However, although many efforts [1, 26, 27] have been made towards direct sparse predictions for 3D object detection, because of the different characteristics of images and point clouds (i.e., dense and ordered images v.s. sparse and irreg-ular points clouds), performance of sparse 3D object detec-tors still largely lags behind state-of-the-art dense detectors.
To achieve direct sparse predictions, DETRs usually adopt a set of object queries [1, 3, 27, 39, 49, 57], and re-sort to the one-to-one Hungarian Matching [17] to assign ground-truths (GTs) to object queries. However, to guaran-tee a high recall rate, those detectors need to impose much more queries than the actual number of objects in a scene.
For example, recent works [1, 27] select top-300 scored query predictions to cover only ∼40 objects in each scene of Waymo Open Dataset (WOD) [36], while 2D DETR de-tectors [3, 39, 49, 57] use 10× more predictions than the av-erage GT number of MS COCO [22]. As shown in Fig. 1(a), we visualize an example scene by a baseline DETR-based
3D detector, named Voxel-DETR, which shows its top-300 scored predictions. Objects are generally small and densely populated in autonomous driving scenes, while 3D DETRs adopt the same fixed top-N scored predictions as 2D DE-TRs, and lack a mechanism to handle such small and dense objects. Consequently, they tend to generate densely over-lapped false positives (in the red-dashed circle), harming both the accuracy and sparsity [29, 39] of final predictions.
We argue the key reason is that the Hungarian Match-ing in existing 3D DETRs only assigns each GT to its best matched query, while all other unmatched queries near this
GT are not effectively suppressed. For each GT, the one-to-one matching loss solely forces all unmatched queries to predict the same “no-object” label, and the best matched query are supervised without considering its relative rank-ing to its surrounding unmatched queries. This design causes the detectors to be insufficiently supervised in dis-criminating similar query predictions for each GT, leading to duplicated false positives for scenes with densely popu-lated objects.
To overcome the limitations of current supervision, we introduce a simple yet novel Query Contrast strategy to ex-plicitly suppress predictions of all unmatched queries for each GT, and simultaneously enhance the best matched query to generate more accurate predictions in a contrastive manner. The Query Contrast strategy is integrated into our baseline Voxel-DETR, which consists of a sparse 3D con-volution backbone to extract features from voxel grids, and a transformer encoder-decoder architecture with a bipar-tite matching loss to directly generate sparse predictions.
Our Query Contrast mechanism involves the construction of positive and negative GT-query pairs, and the contrastive learning on all GT-query pairs to supervise both matched and unmatched queries with knowledge of the states of their surrounding queries. Such GT-query pairs are directly cre-ated by reusing the Hungarian Matching results: each GT and its best matched query form the positive pair, and all other unmatched queries of the same GT then form nega-tive pairs. To quantitively measure the similarities of the
GT-query pairs, we formulate the object queries to be the same as GT boxes (i.e., using only box categories, loca-tions, sizes and orientations), such that GTs and object queries can be processed by the same transformer decoder, and embedded into a unified feature space to properly cal-culate their similarities. Given the GT-query similarities, we adopt the contrastive learning loss [5, 12, 54] to effec-tively enhance the positive (matched) query’s prediction for each GT, and suppress those of all its negative queries at the same time. Moreover, to further improve the contrastive supervision, we construct multiple positive GT-query pairs for each GT by adding small random noises to the original
GTs, which greatly boost the training efficiency and effec-tiveness. The resulting sparse 3D detector Query Contrast
Voxel-DETR (ConQueR) significantly improves the detec-tion performance and sparsity of predictions, as shown in
Fig. 1(b). Besides, ConQueR abandons the fixed top-N pre-diction scheme and achieves dynamic prediction numbers across scenes. ConQueR reduces∼60% false positives and sets new records on the challenging Waymo Open Dataset (WOD) [36]. Contributions are summarized as bellow: 1. We introduce a novel Query Contrast strategy into
DETR-based 3D detectors to effectively eliminate densely overlapped false positives and achieve more accurate predictions. 2. We propose to construct multi-positive contrastive training, which greatly improve the effectiveness and efficiency of our Query Contrast mechanism. 3. Our proposed sparse 3D detector ConQueR closes the gap between sparse and dense 3D detectors, and sets new records on the challenging WOD benchmark. 2.