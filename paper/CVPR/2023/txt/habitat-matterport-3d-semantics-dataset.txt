Abstract
We present the Habitat-Matterport 3D Semantics (HM3DSEM) dataset. HM3DSEM is the largest dataset of 3D real-world spaces with densely annotated seman-tics that is currently available to the academic commu-nity.
It consists of 142,646 object instance annotations across 216 3D spaces and 3,100 rooms within those spaces.
The scale, quality, and diversity of object annotations far exceed those of prior datasets. A key difference setting apart HM3DSEM from other datasets is the use of tex-ture information to annotate pixel-accurate object bound-aries. We demonstrate the effectiveness of HM3DSEM dataset for the Object Goal Navigation task using differ-ent methods. Policies trained using HM3DSEM perform outperform those trained on prior datasets.

Introduction of HM3DSEM in the Habitat ObjectNav Challenge lead to an increase in participation from 400 submissions in 2021 to 1022 submissions in 2022. Project page: https:
//aihabitat.org/datasets/hm3d-semantics/ 1. Introduction
Over the recent past, work on acquiring and semantically annotating datasets of real-world spaces has significantly accelerated research into embodied AI agents that can per-ceive, navigate and interact with realistic indoor scenes [1–5].
However, the acquisition of such datasets at scale is a labori-ous process. HM3D [5] which is one of the largest available datasets with 1000 high-quality and complete indoor space reconstructions, reportedly required 800+ hours of human effort to carry out mainly data curation and verification of 3D reconstructions. Moreover, dense semantic annotation of such acquired spaces remains incredibly challenging.
We present the Habitat-Matterport 3D Dataset Seman-tics (HM3DSEM). This dataset provides a dense semantic annotation ‘layer’ augmenting the spaces from the original
*Equal Contribution, Correspondence: karmeshyadav@meta.com
†Equal Contribution
HM3D dataset. This semantic ‘layer’ is implemented as a set of textures that encode object instance semantics and cluster objects into distinct rooms. The semantics include architectural elements (walls, floors, ceilings), large objects (furniture, appliances etc.), as well as ‘stuff’ categories (ag-gregations of smaller items such as books on bookcases).
This semantic instance information is specified in the seman-tic texture layer, providing pixel-accurate correspondences to the original acquired RGB surface texture and underlying geometry of the objects.
The HM3DSEM dataset currently contains annotations for 142,646 object instances distributed across 216 spaces and 3,100 rooms within those spaces. Figure 1 shows some examples of the semantic annotations from the HM3DSEM dataset. The achieved scale is larger than prior work (2.8x rel-ative to Matterport3D [6] (MP3D) and 2.1x relative to ARK-itScenes [7] in terms of total number of object instances).
We demonstrate the usefulness of HM3DSEM on the Ob-jectGoal navigation task. Training on HM3DSEM results in higher cross-dataset generalization performance. Surpris-ingly, the policies trained on HM3DSEM perform better on average across scene datasets compared to training on the datasets themselves. We also show that increasing the size of training datasets improve the navigation performance. These results highlight the importance of improving the quality and scale of 3D datasets with dense semantic annotations for improving downstream embodied AI task performance. 2.