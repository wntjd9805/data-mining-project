Abstract
Learning continuous image representations is recently gaining popularity for image super-resolution (SR) because of its ability to reconstruct high-resolution images with ar-bitrary scales from low-resolution inputs. Existing methods mostly ensemble nearby features to predict the new pixel at any queried coordinate in the SR image. Such a local ensemble suffers from some limitations: i) it has no learn-able parameters and it neglects the similarity of the visual features; ii) it has a limited receptive field and cannot en-semble relevant features in a large field which are important in an image. To address these issues, this paper proposes a continuous implicit attention-in-attention network, called
CiaoSR. We explicitly design an implicit attention network to learn the ensemble weights for the nearby local features.
Furthermore, we embed a scale-aware attention in this im-plicit attention network to exploit additional non-local in-formation. Extensive experiments on benchmark datasets demonstrate CiaoSR significantly outperforms the existing single image SR methods with the same backbone. In addi-tion, CiaoSR also achieves the state-of-the-art performance on the arbitrary-scale SR task. The effectiveness of the method is also demonstrated on the real-world SR setting.
More importantly, CiaoSR can be flexibly integrated into any backbone to improve the SR performance. 1.

Introduction
Single image super-resolution (SISR), which aims to reconstruct a high-resolution (HR) image from a low-resolution (LR) one, has been widely employed in many practical applications [24, 61, 91]. However, deep neural networks (DNN)-based SISR methods are facing some lim-itations in some real-world scenarios with arbitrary scales.
For example, camera users may want to enhance the digi-tal zoom quality by super-resolving a photo or a video to
*Currently with Google. This work was done at ETH Z¨urich.
†Corresponding Authors: Kai Zhang, cskaizhang@gmail.com; Yulun
Zhang, yulun100@gmail.com
Figure 1. Comparison of different backbones and implicit models.
Our proposed implicit neural network on RDN [88] has better performance than SwinIR [40]. Check Section 5 for details. continuous arbitrary scales. Most existing DNN-based SISR methods [40, 44, 86] need to train a series of models for all different scales separately. However, it can be impractical to store all these models on the device due to limited storage and computing power. Alternatively, arbitrary-scale image
SR methods [13, 28, 39] aim to train a single network for all scales in a continuous manner.
Most existing SISR methods [40,44,86] consist of a DNN and an upsampling module (e.g., pixel shuffling [60]) at a discrete scale. While substantial progresses have been made in the DNN backbones for SR, there is little attempt to study the upsampling module. A natural question to ask is: Does the pixel shuffling hinder the potential of SR models? One limitation of the pixel shuffling module is that it cannot syn-thesize SR images at large unseen and continuous scales.
To tackle this, one can treat synthesizing different-scale SR images as a multi-task learning problem, and train a specific upsampling module for each scale [44]. However, these tasks are dependent and highly inter-related. Neglecting the correlation of different-scale SR tasks may lead to discrete representations and limited performance. Under a certain capacity of a network, training a model on multi-tasks may sacrifice the performance or have the comparable perfor-mance on each task. These above disadvantages limit its applicability and flexibility in the real-world scenarios.
To address these, most existing arbitrary-scale SR meth-ods [13, 28, 39] replace the upsampling method with an implicit neural function and boost the performance. These methods predict an RGB value at the query point in an image
Figure 2. Comparisons of different attention mechanisms. (a) Self-attention can predict pixel features on the grid, but it cannot be directly used in arbitrary-scale SR without considering coordinates. (b) Most existing methods can be treated as coordinate-based implicit attention since they calculate the distance between a key and query coordinate, and then use a function g to aggregate with the value features. However, these methods ignore the distance between the features. (c) Our implicit attention not only considers the coordinate distance, but also the distance among features with visual information. by ensembling features within a local region. However, the local ensemble methods have limitations in the ensemble weights and insufficient information (e.g., non-local informa-tion). The ensemble weights are often calculated by the area of the rectangle between the query point and each nearest point, which is equivalent to the bilinear interpolation. Thus, those methods cannot adaptively ensemble local features since there is no trainable parameter. These weights are only related to the coordinates of the local features, but indepen-dent of the local features. Ignoring both the coordinates and the local features lose visual information and result in blurry artifacts. It is important and necessary to design a new implicit network to predict the weights and exploit more information in the local ensemble.
In this paper, we propose a novel implicit attention model to enhance arbitrary-scale SR performance. Specifically, we use our attention to predict the ensemble weights by con-sidering both the similarity and coordinate distance of local features, as shown in Figure 2. Based on such learnable weights, the implicit model can adaptively aggregate local features according to different inputs. To enrich more infor-mation, we introduce an attention in our implicit attention, which helps discover more features in a larger receptive field.
Our contributions are summarized as follows:
• We propose a novel continuous implicit attention-in-attention network for arbitrary-scale image SR, called
CiaoSR. Different from most existing local ensemble meth-ods, our method explicitly learns the ensemble weights and exploits scale-aware non-local information.
• Our CiaoSR can be flexibly integrated into any backbone, allowing the network to super-resolve an image at arbitrary scales and improve the SR performance in Figure 1.
• Extensive experiments demonstrate CiaoSR achieves the state-of-the-art performance in both SISR and arbitrary-scale SR tasks. Besides, our CiaoSR has good generaliza-tion on both in-scale and out-of-scale distributions. Last, we extend our method to real-world SR settings to synthe-size arbitrary-scale images. 2.