Abstract
Unsupervised completion of real scene objects is of vi-tal importance but still remains extremely challenging in preserving input shapes, predicting accurate results, and adapting to multi-category data.
To solve these prob-lems, we propose in this paper an Unsupervised Symmetric
Shape-Preserving Autoencoding Network, termed USSPA, to predict complete point clouds of objects from real scenes.
One of our main observations is that many natural and man-made objects exhibit significant symmetries. To ac-commodate this, we devise a symmetry learning module to learn from those objects and to preserve structural sym-metries. Starting from an initial coarse predictor, our au-toencoder refines the complete shape with a carefully de-signed upsampling refinement module. Besides the discrim-inative process on the latent space, the discriminators of our USSPA also take predicted point clouds as direct guid-ance, enabling more detailed shape prediction. Clearly different from previous methods which train each category separately, our USSPA can be adapted to the training of multi-category data in one pass through a classifier-guided discriminator, with consistent performance on single cate-gory. For more accurate evaluation, we contribute to the community a real scene dataset with paired CAD models as ground truth. Extensive experiments and comparisons demonstrate our superiority and generalization and show that our method achieves state-of-the-art performance on unsupervised completion of real scene objects. 1.

Introduction
As the standard outputs of 3D scanners [12, 32], point clouds are becoming more and more popular [9] which are also the basic data structure in 3D geometry process-ing [4, 5, 13]. Complete point clouds are hard to obtain due to the nature of the scanning process and object oc-clusion [35]. Due to the defects of incomplete point clouds on downstream applications such as reconstruction [10], re-cent works [17, 19, 22, 23, 26, 30, 33, 35] pay more attention
*Corresponding author.
Figure 1. Visual comparison of predicted results on real scene data by our USSPA and other works (top) and our complete result on a whole real scene (bottom). (a) shows an example of a real scene partial point cloud of a chair and the complete predictions by Disp3D [23], ShapeInv [36], Unpaired [32] and our method. As shown, our prediction result is more accurate and uniform accord-ing to the input, which contains complete arms and legs. (b) and (c) show the original point cloud of a real scene and the complete results of all the objects in this scene. to point cloud completion which relies on paired artificial complete point clouds for supervised training to complete partial point clouds. However, these supervised works are difficult to apply in practice because of the great gap be-tween artificial data and real scene data and the inaccessi-bility to the ground truth of real scene data. Therefore, it is important to complete partial point clouds from real scene in an unsupervised way.
Recent unsupervised works [24, 32, 36] only require real
scene partial point clouds and artificial CAD models for un-paired completion utilizing GANs [8] as their fundamental frameworks, most of which need pre-training on artificial data. The main ideas are to transform latent codes from the space of real scene partial data to the space of artificial complete data and then employ the decoder trained on arti-ficial data to predict the complete point cloud. Essentially, these methods make the predictions whose distributions are consistent with the artificial models. Most of them, how-ever, just extract a global feature from the partial input with-out fully exploiting its geometry information, leading to the prediction severely deviated from the input. And such in-formation actually provides vital clues and constraints for completion. Furthermore, prediction results by these meth-ods usually lack enough geometric details due to the ab-sence of an explicit discriminative process on point clouds.
These domain transforming methods are also hard to adapt to multi-category data or other datasets.
In this paper, we present an unsupervised symmetric shape-preserving autoencoding network, termed USSPA, for the completion of real scene objects, as shown in Figure 2, which is a GAN-based end-to-end network without the requirement of pre-trained weights. Different from previ-ous domain transforming methods which cannot fully lever-age existing incomplete models, we argue that the exist-ing partial scanning, which also provides vital clues and constraints for the prediction of the missing part, should be preserved to some extent. To this end, we exploit the symmetries shown in many natural or man-made objects and devise a novel symmetry learning module to generate symmetrical point clouds of existing parts by predicting the symmetric planes. This enables our network to preserve the shapes of input symmetrically, intrinsically facilitating structure completion, as shown in Figure 1. For those parts that can not be directly inferred from inputs, we employ an initial coarse module for an initial prediction first. Start-ing from the initial guess, we specifically design a refine-ment autoencoder with an upsampling refinement module for detailed refinement and the local feature grouping for extracting local information, to learn detailed structures of artificial data through the autoencoding process. Benefit-ing from this, our final prediction is accurate, uniform, and symmetric shape-preserving. Besides the indirect guidance of the feature discriminator on latent space, our point dis-criminator takes predicted point clouds as direct guidance for generating more accurate shapes. Compared with pre-vious methods which train each category separately, our method can classify the partial point clouds simultaneously through a classifier-guided discriminator when adapted to multi-category data, with consistent performance on the sin-gle category.
To measure the performance of unsupervised comple-tion quantitatively, we build a dataset from ScanNet [5] and
ShapeNet [2] utilizing the annotations of Scan2CAD [1].
Our dataset contains real scene partial point clouds and paired ground truths that are only used for evaluation in our experiments. Extensive comparisons against previous works on this dataset and the public PCN Dataset [35] show the superiority and generalization of our method which achieves state-of-the-art performance on unsupervised com-pletion of real scene objects.
Our main contributions are as follows.
• We propose a novel USSPA for unsupervised real scene point cloud completion whose prediction is accurate, uniform and symmetric shape-preserving.
Clearly different from previous works training each category separately, our USSPA can be adapted to the training of multi-category data in one pass by classify-ing the input simultaneously.
• We propose a novel symmetry learning module and a novel refinement autoencoder. The symmetry learn-ing module preserves input shapes by generating sym-metrical point clouds, and the refinement autoencoder learns the detailed information from artificial data to refine the initial guess by an autoencoding process.
• We propose a new evaluation method for obtaining paired ground truths and partial data from artificial and real scene datasets using alignment information, which can be used to more accurately evaluate unsupervised completion of real scene objects. 2.