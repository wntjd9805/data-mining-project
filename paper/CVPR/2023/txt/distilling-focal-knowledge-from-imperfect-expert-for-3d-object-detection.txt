Abstract
Foreground region
Multi-camera 3D object detection blossoms in recent years and most of state-of-the-art methods are built up on the bird’s-eye-view (BEV) representations. Albeit remark-able performance, these works suffer from low efﬁciency.
Typically, knowledge distillation can be used for model compression. However, due to unclear 3D geometry reason-ing, expert features usually contain some noisy and confus-ing areas. In this work, we investigate on how to distill the knowledge from an imperfect expert. We propose FD3D, a
Focal Distiller for 3D object detection. Speciﬁcally, a set of queries are leveraged to locate the instance-level areas for masked feature generation, to intensify feature representa-tion ability in these areas. Moreover, these queries search out the representative ﬁne-grained positions for reﬁned dis-tillation. We verify the effectiveness of our method by ap-plying it to two popular detection models, BEVFormer and
DETR3D. The results demonstrate that our method achieves improvements of 4.07 and 3.17 points respectively in terms of NDS metric on nuScenes benchmark. Code is hosted at https : / / github . com / OpenPerceptionX /
BEVPerception-Survey-Recipe. 1.

Introduction
Accurate 3D object detection is a vital component in au-tonomous driving. To achieve this, most methods [14, 37] resort to LiDAR sensors and dominate the public bench-marks [1, 27]. Despite the performance gap, pure vision approaches are still worthy of in-depth inquiry, since cam-eras can provide rich semantic information and are low-cost and easy-to-deploy. Among these, bird’s-eye-view (BEV) detection has drawn extensive attention from both industry and academia, and shown great potential to narrow down the performance gap [15, 21]. However, such models tend to be computationally consuming.
Expert 
Abstraction (a) Global distillation (b) Attentive distillation
Random mask
Query mask
Apprentice 
Representation
Generator
Generator (c) Generative distillation  with random mask
Query offset (d) Generative and  focal  distillation (ours)
Figure 1. Illustration of the proposed generative and focal distilla-tion method. Compared with others, the proposed manner in 1 (d) leverages queries to generate instance masks for masked genera-tive distillation, rather than random masks in 1 (c). Moreover, the queries meanwhile search for the representative position to per-form reﬁned distillation, where the distillation region selection is more ﬁne-grained and ﬂexible than 1 (b).
In common practice, knowledge distillation can com-press the model and is usually applied to alleviate com-putation overhead. One possible solution is to utilize the
LiDAR-based model as the expert [4, 17], but this requires complex spatial-temporal calibrations and also needs to handle heterogeneous problems from different modalities.
An intuitive question is, can we distill these models solely based on camera sensors? In this work, we intend to ad-dress this problem and focus on the camera-only distillation setting. To the best of our knowledge, our work is the ﬁrst solution tailored for this setting.
*Corresponding author at lihongyang@pjlab.org.cn
Distillation methods in 2D object detection have derived
1. To the best of our knowledge, this is the ﬁrst work to explore knowledge distillation on the camera-only 3D object detection. We reveal the challenge relies on how to distill focal knowledge from an imperfect 3D object detector expert. 2. We propose FD3D, which utilizes a set of queries to distill focal knowledge. With these queries, coarse-grained focal regions are selected for masked gener-ation, and ﬁne-grained focal regions are searched out for instance-oriented reﬁnement distillation. 3. FD3D serves as a plug-and-play module. It can be eas-ily extended to various detectors. The improvements with 4.07 and 3.17 NDS can be obtained with FD3D assembled in BEVFormer and DETR3D, respectively. 2.