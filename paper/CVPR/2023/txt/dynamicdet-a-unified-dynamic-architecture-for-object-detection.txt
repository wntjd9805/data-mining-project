Abstract
Dynamic neural network is an emerging research topic in deep learning. With adaptive inference, dynamic mod-els can achieve remarkable accuracy and computational efficiency. However, it is challenging to design a power-ful dynamic detector, because of no suitable dynamic ar-chitecture and exiting criterion for object detection. To tackle these difficulties, we propose a dynamic framework for object detection, named DynamicDet. Firstly, we care-fully design a dynamic architecture based on the nature of the object detection task. Then, we propose an adaptive router to analyze the multi-scale information and to de-cide the inference route automatically. We also present a novel optimization strategy with an exiting criterion based on the detection losses for our dynamic detectors. Last, we present a variable-speed inference strategy, which helps to realize a wide range of accuracy-speed trade-offs with only one dynamic detector. Extensive experiments conducted on the COCO benchmark demonstrate that the proposed
DynamicDet achieves new state-of-the-art accuracy-speed trade-offs. For instance, with comparable accuracy, the inference speed of our dynamic detector Dy-YOLOv7-W6 surpasses YOLOv7-E6 by 12%, YOLOv7-D6 by 17%, and
YOLOv7-E6E by 39%. The code is available at https:
//github.com/VDIGPKU/DynamicDet. 1.

Introduction
Object detection is an essential topic in computer vision, as it is a fundamental component for other vision tasks, e.g., autonomous driving [26, 40, 56], multi-object track-ing [52,57], intelligent transportation [36,55], etc. In recent years, tremendous progress has been made toward more ac-curate and faster detectors, such as Network Architecture
Search (NAS)-based detectors [10,25,48] and YOLO series models [2, 9, 11, 21, 44, 45]. However, these methods need to design and train multiple models to achieve a few good trade-offs between accuracy and speed, which is not flexible enough for various application scenarios. To alleviate this
†Corresponding author.
Figure 1. Comparison of the proposed dynamic detectors and other efficient object detectors. Our method can achieve a wide range of state-of-the-art trade-offs between accuracy and speed with a single model.
Figure 2. Examples of “easy” and “hard” images for the object detection task. problem, we focus on dynamic inference for the object de-tection task, and attempt to use only one dynamic detector to achieve a wide range of good accuracy-speed trade-offs, as shown in Fig. 1.
The human brain inspires many fields of deep learning, and the dynamic neural network [12] is a typical one. As two examples shown in Fig. 2, we can quickly identify all objects on the left “easy” image, while we need more time to achieve the same effect for the right one. In other words, the processing speeds of images are different in our brains [18, 34], which depend on the difficulties of the im-ages. This property motivates the image-wise dynamic neu-ral network, and many exciting works have been proposed
(e.g., Branchynet [43], MSDNet [17], DVT [50]). Although these approaches have achieved remarkable performance, they are all designed specifically for the image classifica-tion task and are not suitable for other vision tasks, espe-cially for the object detection [12]. The main difficulties in designing an image-wise dynamic detector are as follows.
Dynamic detectors cannot utilize the existing dy-namic architectures. Most existing dynamic architectures are cascaded with multiple stages (i.e., a stack of multiple layers) [17, 20, 33, 54], and predict whether to stop the in-ference at each exiting point. Such a paradigm is feasible in image classification but is ineffective in object detection, since an image has multiple objects and each object usu-ally has different categories and scales, as shown in Fig. 2.
Hence, almost all detectors depend heavily on multi-scale information, utilizing the features on different scales to de-tect objects of different sizes (which are obtained by fusing the multi-scale features of the backbone with a detection neck, i.e., FPN [27]).
In this case, the exiting points for detectors can only be placed behind the last stage. Con-sequently, the entire backbone module has to be run com-pletely [58], and it is impossible to achieve dynamic infer-ence on multiple cascaded stages.
Dynamic detectors cannot exploit the existing exiting criteria for image classification. For the image classi-fication task, the threshold of top-1 accuracy is a widely used criterion for decision-making [17, 50]. Notably, it only needs one fully connected layer to predict the top-1 accuracy at intermediate layer, which is easy and costless.
However, object detection task requires the neck and the head to predict the categories and locations of the object in-stances [3, 14, 27, 39]. Hence, the existing exiting criteria for image classification is not suitable for object detection.
To deal with the above difficulties, we propose a dynamic framework to achieve dynamic inference for object detec-tion, named DynamicDet. Firstly, We design a dynamic ar-chitecture for the object detection task, which can exit with multi-scale information during the inference. Then, we pro-pose an adaptive router to choose the best route for each image automatically. Besides, we present the correspond-ing optimization and inference strategies for the proposed
DynamicDet.
Our main contributions are as follows:
• We propose a dynamic architecture for object detec-tion, named DynamicDet, which consists of two cas-caded detectors and a router. This dynamic architec-ture can be easily adapted to mainstream detectors, e.g., Faster R-CNN and YOLO.
• We propose an adaptive router to predict the difficulty scores of the images based on the multi-scale features, and achieve automatic decision-making. In addition, we propose a hyperparameter-free optimization strat-egy and a variable-speed inference strategy for our dy-namic architecture.
• Extensive experiments show that DynamicDet can ob-tain a wide range of accuracy-speed trade-offs with only one dynamic detector. We also achieve new state-of-the-art trade-offs for real-time object detection (i.e., 56.8% AP at 46 FPS). 2.