Abstract
Physical world adversarial attack is a highly practical and threatening attack, which fools real world deep learn-ing systems by generating conspicuous and maliciously crafted real world artifacts. In physical world attacks, eval-uating naturalness is highly emphasized since human can easily detect and remove unnatural attacks. However, cur-rent studies evaluate naturalness in a case-by-case fash-ion, which suffers from errors, bias and inconsistencies.
In this paper, we take the ﬁrst step to benchmark and as-sess visual naturalness of physical world attacks, taking autonomous driving scenario as the ﬁrst attempt. First, to benchmark attack naturalness, we contribute the ﬁrst
Physical Attack Naturalness (PAN) dataset with human rat-ing and gaze. PAN veriﬁes several insights for the ﬁrst time: naturalness is (disparately) affected by contextual features (i.e., environmental and semantic variations) and correlates with behavioral feature (i.e., gaze signal). Sec-ond, to automatically assess attack naturalness that aligns with human ratings, we further introduce Dual Prior Align-ment (DPA) network, which aims to embed human knowl-edge into model reasoning process. Speciﬁcally, DPA imi-tates human reasoning in naturalness assessment by rating prior alignment and mimics human gaze behavior by atten-tive prior alignment. We hope our work fosters researches to improve and automatically assess naturalness of physi-cal world attacks. Our code and dataset can be found at https://github.com/zhangsn-19/PAN. 1.

Introduction
Extensive evidences have revealed the vulnerability of deep neural networks (DNNs) towards adversarial attacks
[5, 17, 27, 37, 53, 72–74] in digital and physical worlds.
Different from digital world attacks which make pixelwise perturbations, physical world adversarial attacks are es-pecially dangerous, which fail DNNs by crafting specif-† Corresponding author
Figure 1. Overview of our work. To solve the problem in physical world attack naturalness evaluation, we provide PAN dataset to support this research. Based on PAN, we provide insights and naturalness assessment methods of visual naturalness. ically designed daily artifacts with adversarial capability
[2,13,31,48,51,59,70]. However, physical world attacks are often conspicuous, allowing human to easily identify and remove such attacks in real-world scenarios. To sidestep such defense, in 48 physical world attacks we surveyed(cid:192), 20 papers (42%) emphasize their attack is natural and stealthy to human [9, 11, 22, 31, 49, 55].
Despite the extensive attention on visual naturalness, studies on natural attacks follow an inconsistent and case-In 20 surveyed papers claimed to be by-case evaluation. natural or stealthy(cid:193), (1) 11 papers perform no experiment to validate their claim. (2) 11 papers claim their attack closely imitates natural image, but it was unclear if arbitrary natural image indicates naturalness. (3) 5 papers validate natural-ness by human experiments, yet follow very different eval-uation schemes and oftentimes neglect the gap between ex-isting attacks and natural images. These problems raise our question: how natural indeed are physical world attacks? (cid:192)See this survey in supplementary materials. (cid:193)A work can have multiple limitations.
In this paper, we take the ﬁrst attempt to evaluate vi-sual naturalness of physical world attacks in autonomous driving [24], a ﬁeld of attack with increasing attention
[11, 22, 55, 58, 70]. Since the factors and methods stud-ied in our work are common in physical world attacks and not limited to autonomous driving, our methods and ﬁnd-ings also have the potential to be applied to other scenarios.
The overview of our work is summarized in Fig. 1. To benchmark attack naturalness, we contribute Physical At-tack Naturalness (PAN) dataset, the ﬁrst dataset to study this problem. Speciﬁcally, PAN contains 2,688 images in autonomous driving, with 5 widely used attacks, 2 benign patterns (i.e., no attacks) for comparison, 5 types of envi-ronmental variations and 2 types of diversity enhancement (semantic and model diversity). Data was collected from 126 participants, containing their subjective ratings as an indicator of naturalness, and their gaze signal for all images as an indicator of the selective attention area of human when they make naturalness ratings [66].
PAN provides a plethora of insights for the ﬁrst time.
First, we ﬁnd contextual features have signiﬁcant effect on naturalness, including semantic variations (using natu-ral image to constrain attack) and environmental variations (illumination, pitch/yaw angles, etc). Properly selecting en-vironmental and semantic factors can improve naturalness up to 34.73% and 8.09%, respectively. Second, we ﬁnd contextual features have disparate impact on naturalness of different attacks, some attacks might look more natural un-der certain variations, which can lead to biased subjective evaluation even under identical settings. Third, we ﬁnd nat-uralness is related to behavioral feature (i.e., human gaze).
Speciﬁcally, we ﬁnd attacks are considered less natural if human gaze are more centralized and focus more on vehi-cle (with statistical signiﬁcance at p < .001). This correla-tion suggests modelling and guiding human gaze can be a feasible direction to improve attack naturalness.
Finally, since manually collecting naturalness ratings re-quires human participation and can be laborious as well as costly, based on PAN dataset, we propose Dual Prior Align-ment (DPA), an objective naturalness assessment algorithm that gives a cheap and fast naturalness estimate of physical world attacks. DPA aims to improve attack result by em-bedding human knowledge into the model. Speciﬁcally, to align with human reasoning process, rating prior alignment mimics the uncertainty and hidden desiderata when human rates naturalness. To align with human attention, attentive prior alignment corrects spurious correlations in models by aligning model attention with human gaze. Extensive ex-periments on PAN dataset and DPA method shows training
DPA on PAN dataset outperforms the best method trained on other dataset by 64.03%; based on PAN dataset, DPA improves 3.42% in standard assessment and 11.02% in gen-eralization compared with the best baseline. We also make early attempts to improve naturalness by DPA.
Our contributions can be summarized as follows:
• We take the ﬁrst step to evaluate naturalness of physi-cal world attacks, taking autonomous driving as a ﬁrst attempt. Our methods and ﬁndings have the potential to be applied to other scenarios.
• We contribute PAN dataset, the ﬁrst dataset that sup-ports studying the naturalness of physical world at-tacks via human rating and human gaze. PAN encour-age subsequent research on enhancing and assessing naturalness of physical world attacks.
• Based on PAN, we unveil insights of how contextual and behavioral features affect attack naturalness.
• To automatically assess image naturalness, we propose
DPA method that embeds human behavior into model reasoning, resulting in better result and generalization. 2.