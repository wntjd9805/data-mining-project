Abstract
To be successful, Vision-and-Language Navigation (VLN) agents must be able to ground instructions to ac-tions based on their surroundings. In this work, we develop a methodology to study agent behavior on a skill-specific basis – examining how well existing agents ground instruc-tions about stopping, turning, and moving towards speci-fied objects or rooms. Our approach is based on gener-ating skill-specific interventions and measuring changes in agent predictions. We present a detailed case study analyz-ing the behavior of a recent agent and then compare multi-ple agents in terms of skill-specific competency scores. This analysis suggests that biases from training have lasting ef-fects on agent behavior and that existing models are able to ground simple referring expressions. Our comparisons be-tween models show that skill-specific scores correlate with improvements in overall VLN task performance. 1.

Introduction
Following navigation instructions requires coordinating observations and actions in accordance with the natural lan-guage. Stopping when told to stop. Turning when told to turn. And appropriately grounding referring expressions when an action is conditioned on some aspect of the envi-ronment. All three of these example are required when fol-lowing the instruction “Turn left then go down the hallway until you see a desk. Walk towards the desk and then stop.”
In this work, we examine how well current instruction-following agents can execute different types of these sub-behaviors which we will refer to as skills.
We situate our study in the popular Vision-and-Language
Navigation (VLN) paradigm [2].
In a VLN episode, an agent is spawned in a never-before-seen environment and must navigate to a goal location specified by a natural language navigation instruction. An agent’s instruction-following capabilities are typically measured at the episode level – examining whether an agent reaches near the goal (success rate [2]), how efficiently it does so (SPL [1]), or how well its trajectory matches the ground truth path which the human-generated instruction was based on (nDTW
[15]). These metrics are useful for comparing agents in ag-gregate, but take a perspective that has little to say about an agent’s fine grained competencies or what sub-instructions it is able to ground appropriately.
In this work, we design an experimental paradigm based on controlled interventions to analyze fine-grained agent be-haviors. We focus our study on an agent’s ability to ex-ecute unconditional instructions like stopping or turning, as well as, conditional instructions that require more vi-sual grounding like moving towards specified objects and rooms. Our approach leverages annotations from RxR [13] to produce truncated trajectory-instruction pairs that can then be augmented with an additional skill-specific sub-instruction. We carefully filter these trajectories and gen-erate template-based sub-instructions to build non-trivial intervention episodes that evaluate an agent’s ability to ground skill-specific language to the appropriate actions.
To demonstrate the value of this approach, we present a case study analyzing the behavior of a contemporary VLN model [6]. While we find evidence that the model can reli-ably ground some skill-specific language, our analysis also reveals that its errors are not random. But rather, they re-flect a systematic bias towards forward actions learned dur-ing training. For object- or room-seeking skills, we find only modest relationships between instructions and agent actions. Finally, we derive aggregate skill-specific scores and compare across VLN models with different overall task performance. We find that higher skill-specific scores cor-relate with higher task performance; however, not all skills share the same scale of improvement between weaker and stronger VLN models – suggesting that improvements in
VLN may be fueled by some skills more than others.
Contributions. To summarize this work, we:
- Develop an intervention-based behavioral analysis paradigm for evaluating the behavior of VLN agents,1
- Provide a case study on a contemporary VLN agent [6], evaluating fine-grained competencies and biases, and
- Examine the relationships between skill-specific metrics 1https://github.com/Yoark/vln-behave
and overall VLN task performance. 2.