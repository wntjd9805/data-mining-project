Abstract
The mechanism of existing style transfer algorithms is by minimizing a hybrid loss function to push the generated image toward high similarities in both content and style.
However, this type of approach cannot guarantee visual fi-delity, i.e., the generated artworks should be indistinguish-able from real ones. In this paper, we devise a new style transfer framework called QuantArt for high visual-fidelity stylization. QuantArt pushes the latent representation of the generated artwork toward the centroids of the real artwork distribution with vector quantization. By fusing the quan-tized and continuous latent representations, QuantArt al-lows flexible control over the generated artworks in terms of content preservation, style similarity, and visual fidelity.
Experiments on various style transfer settings show that our
QuantArt framework achieves significantly higher visual fi-delity compared with the existing style transfer methods. 1.

Introduction
Image style transfer aims at transferring the artistic style of a reference image to a content image, where the output image should have the style (e.g., colors, textures, strokes, and tones) of the reference and the content information of the content image. Great advances [4, 5, 13, 14, 39, 40, 63] have been made in the area of image style transfer, where the arbitrary style transfer (AST) has become one of the main research focuses. Given a trained model, AST algo-rithms [8, 26, 33] can perform style transfer on arbitrary un-seen content-style pairs in a zero-shot manner, such that it enables more practical applications1.
Existing AST algorithms, including the statistics-based methods [1, 26, 35, 60] and the patch-based methods [6, 47], deliver remarkable style transfer results by matching the artistic style information of the stylized image and the style reference. However, taking the high-fidelity artwork gener-ation as the ultimate goal of image style transfer, all existing methods can still be improved since there are few mech-anisms to guarantee a high artistic fidelity of the stylized image. A few existing work [3,59] accommodate the adver-sarial loss [15] into the style transfer framework to enhance the image quality. However, the performance improvement is hindered by the heterogeneous optimization objectives of high image quality and faithful image stylization.
In this work, we introduce visual fidelity as a new eval-1The codes of this paper are available at https://github.com/ siyuhuang/QuantArt
uation dimension of style transfer. It is formulated as the similarity between the stylized image and the real artwork dataset, and it is orthogonal to the two widely studied eval-uation dimensions including style similarity and content preservation. Motivated by the vector-quantized image rep-resentation [11, 45, 52], if the latent feature of generation is closer to one of the cluster centers in the real distribution, it is harder for humans to distinguish it from the real images, i.e., having better visual fidelity. We propose to learn an art-work codebook, i.e., a global dictionary, to save the discrete cluster centers of all artworks. The continuous representa-tions of images are converted to the discrete encodings in the artwork codebook via vector quantization, ensuring that it is not only close to the given style reference but also close to one of the learned cluster centers in the real distribution.
We further propose a framework called Quantizing Artis-tic Style Transfer (QuantArt) to achieve flexible control of the three evaluation dimensions mentioned above. Quan-tArt first extracts both content and style features using sep-arate encoders, respectively. Next, it applies vector quan-tization to both content and style features to fetch discrete codes in the learned codebooks. Then, the content and style codes are transferred to the stylized feature with a specially designed feature style transfer module called Style-Guided
Attention. Before feeding into the decoder, the stylized fea-ture is quantized again with the artwork codebook, ensuring a high visual-fidelity stylization by approaching the cluster centers of the real artwork distribution. By fusing the con-tinuous and quantized stylized features with the content fea-tures before the decoder, QuantArt allows users to arbitrar-ily trade off between the style similarity, visual fidelity, and content reservation of the style transfer results. In the ex-periments, the proposed method significantly increases the visual fidelity of generations in various image style transfer settings including photo-to-art, art-to-art, photo-to-photo, and art-to-photo (see Fig. 1). The contribution of the pro-posed method can be summarized as follows:
• We define visual fidelity as a new evaluation dimension of style transfer and propose a high visual-fidelity style transfer algorithm based on vector quantization.
• We design a framework based on both discrete and continuous style transfer architectures, which allow users to flexibly control style similarity, content preser-vation, and visual fidelity of the stylization result.
• The extensive experiments demonstrate that our method achieves higher visual fidelity and compara-ble style similarity with respect to the state-of-the-art style transfer methods. 2.