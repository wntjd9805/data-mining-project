Abstract
Scene flow estimation is a long-standing problem in com-puter vision, where the goal is to find the 3D motion of a scene from its consecutive observations. Recently, there have been efforts to compute the scene flow from 3D point clouds. A common approach is to train a regression model that consumes source and target point clouds and outputs the per-point translation vector. An alternative is to learn point matches between the point clouds concurrently with regressing a refinement of the initial correspondence flow.
In both cases, the learning task is very challenging since the flow regression is done in the free 3D space, and a typical solution is to resort to a large annotated synthetic dataset.
We introduce SCOOP, a new method for scene flow esti-mation that can be learned on a small amount of data with-out employing ground-truth flow supervision. In contrast to previous work, we train a pure correspondence model fo-cused on learning point feature representation and initial-ize the flow as the difference between a source point and its softly corresponding target point. Then, in the run-time phase, we directly optimize a flow refinement component with a self-supervised objective, which leads to a coherent and accurate flow field between the point clouds. Experi-ments on widespread datasets demonstrate the performance gains achieved by our method compared to existing leading techniques while using a fraction of the training data. Our code is publicly available1. 1.

Introduction
Scene flow estimation [27] is a fundamental problem in computer vision with various use-cases, such as au-tonomous driving, scene parsing, pose estimation, and ob-ject tracking, to name a few. Given two consecutive obser-vations of a 3D scene, the aim is to compute the dynamics of the scene between the observations. Scene flow predic-tion based on 2D images has been thoroughly investigated in the literature [17, 19, 28, 32, 33]. However, in light of the 1https://github.com/itailang/SCOOP
*The work was done during an internship at Google Research.
Figure 1. Flow accuracy on the KITTI benchmark vs. the train set size. Our method is trained on one or two orders of magnitude less data while surpassing the performance of the competing tech-niques [4, 13, 14, 16, 21, 24, 30, 31] by a large margin. Please see
Table 1 for the complete details of the evaluation settings. recent proliferation of 3D sensors, such as LiDAR, there is a surge of interest in scene flow methods that operate directly on the 3D data [10, 13, 16, 21, 34].
Liu et al. [16] were among the first to pursue this
They proposed FlowNet3D, a fully-research avenue. supervised neural network that learned to regress the flow between 3D point clouds and showed remarkable perfor-mance improvement over image-based techniques [1, 19, 29]. Since their method required ground-truth flow anno-tations, which are scarce for real-world data, they turned to training on a large synthetic dataset that compromised the generalization capability to real-world LiDAR data.
Follow-up works devised self-supervised learning schemes [13, 21] and narrowed the domain gap by training on unannotated LiDAR point cloud pairs. However, similar to Liu et al. [16], they used a regression approach in which the model should learn to compute the flow in the free 3D space. This task is extremely challenging, given the irreg-ular nature of point clouds, and requires a large amount of training data for the network to converge.
In another line of work [8, 11, 24], researchers leveraged
In point cloud correspondence for scene flow prediction. this approach, the flow is computed as the translation of a point in the first point cloud (source) to its softly corre-aaaaaaaFlowNet3D [16] aaaaaaaaaaFLOT [24] aaaaaaaaaaaNeural Prior [15] aSCOOP (ours)
Figure 2. Comparison of scene flow approaches. Given a pair of point clouds, FlowNet3D [16] learns to regress the flow in the free 3D space, and the trained model is frozen for testing. FLOT [24] concurrently trains two network components: one that computes point correspondence and another that regresses a correction to the resulting correspondence flow. Neural Prior [15] optimizes the flow between the point clouds from scratch without learning. In contrast to previous work, we take a hybrid approach. We train a pure correspondence model without flow regression, which serves for flow initialization. Then, we directly optimize only the flow refinement at the test-time. sponding point in the second one (target). The softly cor-responding point is a weighted sum of target points based on point similarity in a learned latent space. Thus, rather than the challenging regression problem in the 3D ambi-ent space, the flow estimation task boils down to point feature learning and is reduced to the convex combination space [26] of existing target points. However, to relax this constraint, another network component is trained to regress flow corrections. The joint training of point representation and flow refinement burdens the learning process and re-tains the reliance on large datasets with flow supervision.
Another emerging approach is an optimization-only flow computation [15, 23]. In this case, no training data is in-volved, and the flow is optimized at run-time for each scene separately. Despite the high accuracy such a dedicated op-timization achieves, it requires a long processing time.
We present SCOOP, a hybrid flow estimation method that can be learned from a small amount of training data.
SCOOP consists of two parts: a self-supervised neural net-work for point cloud correspondence and a direct flow re-finement optimization module. During the training phase, the network learns to extract point features for soft point matches, which initialize the flow between the point clouds.
In contrast to previous work, our network is focused on learning just the point embeddings, allowing its training on a very small dataset, as shown in Figure 1. Additionally, we consider the confidence of the network in the computed correspondences to guide the learning process better.
Then, instead of training another network for regress-ing flow updates, we define an optimization problem and directly optimize residual flow refinement vectors at run-time. The optimization objective encourages a coherent flow field while retaining the translated source points close to the target point cloud. Our design choices improve the accuracy compared to learning-based methods and reduce the processing time with respect to the optimization-only approach [15, 23]. For both correspondence learning and refinement optimization, we use a self-supervised distance objective and a smoothness prior instead of ground-truth flow labels. Figure 2 presents the difference between our approach and leading previous ones.
In summary, we propose a hybrid flow prediction ap-proach for point clouds based on self-supervised correspon-dence learning and direct run-time residual flow optimiza-tion. Using well-established datasets in the scene flow liter-ature, we show that our approach yields clear performance improvement over existing state-of-the-art methods while using a fraction of the training data and without employing any ground-truth flow supervision. 2.