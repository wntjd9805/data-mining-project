Abstract
The combination of deep learning, artist-curated scans, and Implicit Functions (IF), is enabling the creation of de-tailed, clothed, 3D humans from images. However, existing methods are far from perfect. IF-based methods recover free-form geometry, but produce disembodied limbs or de-generate shapes for novel poses or clothes. To increase robustness for these cases, existing work uses an explicit parametric body model to constrain surface reconstruction, but this limits the recovery of free-form surfaces such as loose clothing that deviates from the body. What we want is a method that combines the best properties of implicit repre-sentation and explicit body regularization. To this end, we make two key observations: (1) current networks are better at inferring detailed 2D maps than full-3D surfaces, and (2) a parametric model can be seen as a “canvas” for stitch-ing together detailed surface patches. Based on these, our method, ECON, has three main steps: (1) It infers detailed 2D normal maps for the front and back side of a clothed per-son. (2) From these, it recovers 2.5D front and back surfaces, called d-BiNI, that are equally detailed, yet incomplete, and registers these w.r.t. each other with the help of a SMPL-X body mesh recovered from the image. (3) It “inpaints” the missing geometry between d-BiNI surfaces. If the face and hands are noisy, they can optionally be replaced with the ones of SMPL-X. As a result, ECON infers high-fidelity 3D humans even in loose clothes and challenging poses. This goes beyond previous methods, according to the quantitative evaluation on the CAPE and Renderpeople datasets. Per-ceptual studies also show that ECON’s perceived realism is better by a large margin. Code and models are available for research purposes at econ.is.tue.mpg.de 1.

Introduction
Human avatars will be key for future games and movies, mixed-reality, tele-presence and the “metaverse”. To build re-alistic and personalized avatars at scale, we need to faithfully reconstruct detailed 3D humans from color photos taken in the wild. This is still an open problem, due to its challenges; people wear all kinds of different clothing and accessories, and they pose their bodies in many, often imaginative, ways.
A good reconstruction method must accurately capture these, while also being robust to novel clothing and poses.
Initial, promising, results have been made possible by using artist-curated scans as training data, and implicit func-tions (IF) [56,59] as the 3D representation. Seminal work on
PIFu(HD) [70, 71] uses “pixel-aligned” IF and reconstructs clothed 3D humans with unconstrained topology. However, these methods tend to overfit to the poses seen in the training data, and have no explicit knowledge about the human body’s structure. Consequently, they produce disembodied limbs or degenerate shapes for images with novel poses; see the 2nd row of Fig. 2. Follow-up work [26, 82, 96] accounts for such artifacts by regularizing the IF using a shape prior provided by an explicit body model [52, 61], but regularization intro-duces a topological constraint, restricting generalization to novel clothing while attenuating shape details; see the 3rd and 4th rows of Fig. 2. In a nutshell, there are trade-offs between robustness, generalization and detail.
What we want is the best of both worlds; that is, the robustness of explicit anthropomorphic body models, and the flexibility of IF to capture arbitrary clothing topology. To that end, we make two key observations: (1) While inferring detailed 2D normal maps from color images is relatively easy [31, 71, 82], inferring 3D geometry with equally fine details is still challenging [9]. Thus, we exploit networks to infer detailed “geometry-aware” 2D maps that we then lift to 3D. (2) A body model can be seen as a low-frequency
“canvas” that “guides” the stitching of detailed surface parts.
With these in mind, we develop ECON, which stands for “Explicit Clothed humans Optimized via Normal inte-gration”. It takes, as input, an RGB image and a SMPL-X body inferred from the image. Then, it outputs a 3D human in free-form clothing with a level of detail and robustness that goes beyond the state of the art (SOTA); see the bottom of Fig. 2. Specifically, ECON has three steps.
Step 1: Front & back normal reconstruction. We predict front- and back-side clothed-human normal maps from the input RGB image, conditioned on the body estimate, with a standard image-to-image translation network.
Step 2: Front & back surface reconstruction. We take the previously predicted normal maps, and the correspond-ing depth maps that are rendered from the SMPL-X mesh, to produce detailed and coherent front-/back-side 3D sur-faces, {MF, MB}. To this end, we extend the recent BiNI method [7], and develop a novel optimization scheme that is aimed at satisfying three goals for the resulting surfaces: (1) their high-frequency components agree with clothed-human normals, (2) their low-frequency components and the dis-continuities agree with the SMPL-X ones, and (3) the depth values on their silhouettes are coherent with each other and consistent with the SMPL-X-based depth maps. The two out-put surfaces, {MF, MB}, are detailed yet incomplete, i.e., there is missing geometry in occluded and “profile” regions.
Step 3: Full 3D shape completion. This module takes two inputs: (1) the SMPL-X mesh, and (2) the two d-BiNI
Figure 2. Summary of SOTA. PIFuHD [71] recovers clothing details, but struggles with novel poses. ICON [82] and PaMIR [96] regularize shape to a body shape, but over-constrain the skirts, or over-smooth the wrinkles. ECON combines their best aspects. surfaces, {MF, MB}. The goal is to “inpaint” the missing geometry. Existing methods struggle with this problem. On one hand, Poisson reconstruction [38] produces “blobby” shapes and naively “infills” holes without exploiting a shape distribution prior. On the other hand, data-driven approaches, such as IF-Nets [10], struggle with missing parts caused by (self-)occlusions, and fail to keep the fine details present on two d-BiNI surfaces, producing degenerate geometries.
We address above the limitations in two steps: (1) We ex-tend and re-train IF-Nets to be conditioned on the SMPL-X body, so that SMPL-X regularizes shape “infilling”. We dis-card the triangles that lie close to {MF, MB}, and keep the remaining ones as “infilling patches”. (2) We stitch together the front- and back-side surfaces and infilling patches via
Poisson reconstruction; note that holes between these are small enough for a general purpose method. The result is a full 3D shape of a clothed human; see Fig. 2, bottom.
We evaluate ECON both on established benchmarks (CAPE [55] and Renderpeople [66]) and in-the-wild images.
Quantitative analysis reveals ECON’s superiority. A percep-tual study echos this, showing that ECON is significantly preferred over competitors on challenging poses and loose clothing, and competitive with PIFuHD on fashion images.
Qualitative results show that ECON generalizes better than the SOTA to a wide variety of poses and clothing, even with extreme looseness or complex topology; see Fig. 9.
With both pose-robustness and topological flexibility,
ECON recovers 3D clothed humans with a good level of detail and realistic pose. Code and models are available for research purposes at econ.is.tue.mpg.de
2.