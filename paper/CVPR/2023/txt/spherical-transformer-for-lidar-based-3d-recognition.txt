Abstract
LiDAR-based 3D point cloud recognition has benefited various applications. Without specially considering the Li-DAR point distribution, most current methods suffer from information disconnection and limited receptive field, es-In this work, we pecially for the sparse distant points. study the varying-sparsity distribution of LiDAR points and present SphereFormer to directly aggregate information from dense close points to the sparse distant ones. We de-sign radial window self-attention that partitions the space into multiple non-overlapping narrow and long windows.
It overcomes the disconnection issue and enlarges the re-ceptive field smoothly and dramatically, which significantly boosts the performance of sparse distant points. Moreover, to fit the narrow and long windows, we propose exponen-tial splitting to yield fine-grained position encoding and dynamic feature selection to increase model representation ability. Notably, our method ranks 1st on both nuScenes and
SemanticKITTI semantic segmentation benchmarks with 81.9% and 74.8% mIoU, respectively. Also, we achieve the 3rd place on nuScenes object detection benchmark with 72.8% NDS and 68.5% mAP. Code is available at https:
// github.com/ dvlab-research/ SphereFormer.git. 1.

Introduction
Nowadays, point clouds can be easily collected by Li-DAR sensors. They are extensively used in various indus-trial applications, such as autonomous driving and robotics.
In contrast to 2D images where pixels are arranged densely and regularly, LiDAR point clouds possess the varying-sparsity property — points near the LiDAR are quite dense, while points far away from the sensor are much sparser, as shown in Fig. 2 (a).
However, most existing work [12, 13, 24, 25, 55, 70–72] does not specially consider the the varying-sparsity point distribution of outdoor LiDAR point clouds. They inherit from 2D CNNs or 3D indoor scenarios, and conduct local operators (e.g., SparseConv [24, 25]) uniformly for all lo-cations. This causes inferior results for the sparse distant points. As shown in Fig. 1, although decent performance
Figure 1. Semantic segmentation performance on nuScenes val set for points at different distances. is yielded for the dense close points, it is difficult for these methods to deal with the sparse distant points optimally.
We note that the root cause lies in limited receptive field.
For sparse distant points, there are few surrounding neigh-bors. This not only results in inconclusive features, but also hinders enlarging receptive field due to information discon-nection. To verify this finding, we visualize the Effective
Receptive Field (ERF) [40] of the given feature (shown with the yellow star) in Fig. 2 (d). The ERF cannot be expanded due to disconnection, which is caused by the extreme spar-sity of the distant car.
Although window self-attention [22, 30], dilated self-attention [42], and large-kernel CNN [10] have been pro-posed to conquer the limited receptive field, these methods do not specially deal with LiDAR point distribution, and re-main to enlarge receptive field by stacking local operators as before, leaving the information disconnection issue still unsolved. As shown in Fig. 1, the method of cubic self-attention brings a limited improvement.
In this paper, we take a new direction to aggregate long-range information directly in a single operator to suit the varying-sparsity point distribution. We propose the module of SphereFormer to perceive useful information from points
Figure 2. Effective Receptive Field (ERF) of SparseConv and ours. (a) LiDAR point cloud. (b) Radial window partition. Only a single radial window is shown. Points inside the window are marked in red. (c) Zoom-in sparse distant points. A sparse car is circled in yellow. (d) ERF of SparseConv, given the point of interest (with yellow star). White and red denote high contribution. (e) ERF of ours. 50+ meters away and yield large receptive field for feature extraction. Specifically, we represent the 3D space using spherical coordinates (r, θ, ϕ) with the sensor being the ori-gin, and partition the scene into multiple non-overlapping windows. Unlike the cubic window shape, we design radial windows that are long and narrow. They are obtained by partitioning only along the θ and ϕ axis, as shown in Fig. 2 (b). It is noteworthy that we make it a plugin module to conveniently insert into existing mainstream backbones.
The proposed module does not rely on stacking local op-erators to expand receptive field, thus avoiding the discon-nection issue, as shown in Fig. 2 (e). Also, it facilitates the sparse distant points to aggregate information from the dense-point region, which is often semantically rich. So, the performance of the distant points can be improved sig-nificantly (i.e., +17.1% mIoU) as illustrated in Fig. 1.
Moreover, to fit the long and narrow radial windows, we propose exponential splitting to obtain fine-grained relative position encoding. The radius r of a radial window can be over 50 meters, which causes large splitting intervals.
It thus results in coarse position encoding when converting relative positions into integer indices. Besides, to let points at varying locations treat local and global information dif-ferently, we propose dynamic feature selection to make fur-ther improvements.
In total, our contribution is three-fold.
• We propose SphereFormer to directly aggregate long-range information from dense-point region.
It in-creases the receptive field smoothly and helps improve the performance of sparse distant points.
• To accommodate the radial windows, we develop ex-ponential splitting for relative position encoding. Our dynamic feature selection further boosts performance.
• Our method achieves new state-of-the-art results on multiple benchmarks of both semantic segmentation and object detection tasks. 2.