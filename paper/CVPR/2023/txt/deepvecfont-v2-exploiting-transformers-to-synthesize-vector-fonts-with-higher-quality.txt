Abstract
Vector font synthesis is a challenging and ongoing prob-lem in the fields of Computer Vision and Computer Graph-ics. The recently-proposed DeepVecFont [27] achieved state-of-the-art performance by exploiting information of both the image and sequence modalities of vector fonts.
However, it has limited capability for handling long se-quence data and heavily relies on an image-guided outline refinement post-processing. Thus, vector glyphs synthesized by DeepVecFont still often contain some distortions and ar-tifacts and cannot rival human-designed results. To address the above problems, this paper proposes an enhanced ver-sion of DeepVecFont mainly by making the following three novel technical contributions. First, we adopt Transform-ers instead of RNNs to process sequential data and design a relaxation representation for vector outlines, markedly im-proving the model’s capability and stability of synthesizing long and complex outlines. Second, we propose to sample auxiliary points in addition to control points to precisely align the generated and target B´ezier curves or lines. Fi-nally, to alleviate error accumulation in the sequential gen-eration process, we develop a context-based self-refinement module based on another Transformer-based decoder to re-move artifacts in the initially synthesized glyphs. Both qual-itative and quantitative results demonstrate that the pro-posed method effectively resolves those intrinsic problems of the original DeepVecFont and outperforms existing ap-proaches in generating English and Chinese vector fonts with complicated structures and diverse styles.
*Zhouhui Lian is the corresponding author.
This work was supported by National Language Committee of China (Grant No.: ZDI135-130), Project 2020BD020 supported by PKU-Baidu
Fund, Center For Chinese Font Design and Research, and Key Laboratory of Science, Technology and Standard in Press Industry (Key Laboratory of
Intelligent Press Media Technology).
Figure 1. Visualization of the vector glyphs synthesized by Deep-VecFont and Ours, where different colors denote different drawing commands. (a) DeepVecFont w/o refinement suffers from location shift. (b) DeepVecFont w/ refinement has both over-smoothness (see green circles) and under-smoothness (see blue circles). (c)
Our method can directly synthesize visually-pleasing results with compact and coordinated outlines. Zoom in for better inspection. 1.

Introduction
Vector fonts, in the format of Scalable Vector Graph-ics (SVGs), are widely used in displaying documents, arts, and media contents. However, designing high-quality vec-tor fonts is time-consuming and costly, requiring extensive experience and professional skills from designers. Auto-matic font generation aims to simplify and facilitate the font designing process: learning font styles from a small set of user-provided glyphs and then generating the complete font library. until now, there still exist enormous challenges due to the variety of topology structures, sequential lengths, and styles, especially for some writing systems such as Chinese.
Recent years have witnessed significant progress [5, 17] made by deep learning-based methods for vector font gen-eration. Nevertheless, vector fonts synthesized by these existing approaches often contain severe distortions and are typically far from satisfactory. More recently, Wang
and Lian [27] proposed DeepVecFont that utilizes a dual-modality learning architecture by exploiting the features of both raster images and vector outlines to synthesize visually-pleasing vector glyphs and achieve state-of-the-art performance. However, DeepVecFont tends to bring lo-cation shift to the raw vector outputs (Fig. 1(a)), which are then further refined according to the synthesized im-ages. Specifically, DeepVecFont adopts a differentiable ras-terizer [14] to fine-tune the coordinates of the raw vector glyphs by aligning their rasterized results and the synthe-sized images. However, after the above process, the refined vector outputs tend to be over-fitted to the inherent noise in the synthesized images. Thus, there often exist suboptimal outlines (Fig. 1(b)) with over-smoothed corners (green cir-cles) or under-smoothed adjacent connections (blue circles) in the final synthesized vector fonts, making them unsuited to be directly used in real applications.
To address the above-mentioned issues, we propose a new Transformer-based [25] encoder-decoder architecture, named DeepVecFont-v2, to generate high-fidelity vector glyphs with compact and coordinated outlines. Firstly, we observed that the commonly used SVG representation, which shares the same starting and ending points between adjacent drawing commands, is more suitable for the learn-ing process of RNNs [9] than Transformers [25]. RNNs simulate a recurrent drawing process, where the next move-ment is determined according to the current hidden state fed with the current drawing command. Therefore, the start-ing point of the following drawing command can be omit-ted (replaced by the ending point of the current drawing command). On the contrary, Transformers make drawing prediction based on the self-attention operations performed on any two drawing commands, whether adjacent or not.
Therefore, to make the attention operator receive the com-plete information of their positions, the starting point of each drawing command cannot be replaced by the ending point of the previous command. Based on the above ob-servation, we propose a relaxation representation that mod-els these two points separately and merges them via an ex-tra constraint. Secondly, although the control points of a
B´ezier curve contain all the primitives, we found that the neural networks still need more sampling points from the curve to perform a better data alignment. Therefore, we sample auxiliary points distributed along the B´ezier curves when computing the proposed B´ezier curve alignment loss.
Thirdly, to alleviate the error accumulation in the sequential generation process, we design a self-refinement module that utilizes the context information to further remove artifacts in the initially synthesized results. Experiments conducted on both English and Chinese font datasets demonstrate the superiority of our method in generating complicated and di-verse vector fonts and its capacity for synthesizing longer sequences compared to existing approaches. To summarize, the major contributions of this paper are as follows:
- We develop a Transformer-based generative model, accompanied by a relaxation representation of vector outlines, to synthesize high-quality vector fonts with compact and coordinated outlines.
- We propose to sample auxiliary points in addition to control points to precisely align the generated and target outlines, and design a context-based self-refinement module to fully utilize the context informa-tion to further remove artifacts.
- Extensive experiments have been conducted to verify that state-of-the-art performance can be achieved by our method in both English and Chinese vector font generation. 2.