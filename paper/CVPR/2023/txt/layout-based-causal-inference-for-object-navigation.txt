Abstract
Previous works for ObjectNav task attempt to learn the association (e.g. relation graph) between the visual inputs and the goal during training. Such association contains the prior knowledge of navigating in training environments, which is denoted as the experience. The experience per-forms a positive effect on helping the agent infer the likely location of the goal when the layout gap between the un-seen environments of the test and the prior knowledge ob-tained in training is minor. However, when the layout gap is significant, the experience exerts a negative effect on nav-igation. Motivated by keeping the positive effect and re-moving the negative effect of the experience, we propose the layout-based soft Total Direct Effect (L-sTDE) frame-work based on the causal inference to adjust the predic-tion of the navigation policy. In particular, we propose to calculate the layout gap which is defined as the KL diver-gence between the posterior and the prior distribution of the object layout. Then the sTDE is proposed to appropri-ately control the effect of the experience based on the lay-out gap. Experimental results on AI2THOR, RoboTHOR, and Habitat demonstrate the effectiveness of our method.
The code is available at https://github.com/sx-zhang/Layout-based-sTDE.git. 1.

Introduction
The visual object-oriented navigation task (i.e. Object-Nav) [3] requires the agent to navigate to a user-specified goal (e.g. laptop) based on the egocentric visual observa-tions. A typical challenge is navigating in unseen environ-ments, where the goal is invisible most of the time, i.e. the partial observable problem, which typically results in the agent’s meaningless actions (e.g. back-tracking or getting lost at dead-ends). Although encouraging the exploration in the unseen environment (until the goal is visible) is an in-tuitive solution, the lack of environment layout information still limits the efficiency of goal-oriented navigation. the original prediction of the trained model.
Figure 1. The proposed causal graph. (a) represents the fact pre-diction a, i.e. (b) refers to the counter-fact prediction ¯a, i.e. the prediction is only affected by the experience Z. (b) is realized by applying the inter-vention and counterfactual operations to the original model.
Recently, the learning-based methods attempt to model the prior knowledge of the spatial relationships among the objects, so the agent could infer the likely locations of the goal based on the current observation (which objects are observed currently) and the prior knowledge (the spatial relationships between the goal and the observed objects) learned in the training stage. Some works utilize additional modules to construct the objects graph [15, 59, 60], the re-gion graph [63] and the attention mechanism [32], while others [16, 56] employ a network that implicitly learns the spatial relationships end-to-end. All these methods attempt to establish prior knowledge in training environments, so that the agent would utilize the prior knowledge to associate the real-time observations with the goal, and infer the likely locations of the goal during the inference. The underlying assumption of these methods is that all of the object lay-outs in unseen environments should be exactly consistent with those in training environments. However, the layout consistency assumption is only partially correct due to the limited training data. Thus, those methods typically suffer from poor generalization [31] in unseen environments.
To reveal the causes of poor generalization, we propose to use the casual graph (i.e. Structural Causal Model, SCM
[38]) to analyze these navigation works. As illustrated in
Fig. 1 (a), the navigation model takes the observation S and the goal G as the input, and predicts the action A at each timestamp. The causal links S → Z and G → Z represent that the observation and the goal are embedded by the pre-constructed modules [15, 32, 59, 60, 63] or the pre-trained network [16, 56]. The embedding vector is defined as the experience Z in the causal graph, which introduces the prior knowledge to influence action prediction (Z → A). Mean-while, the real-time observation and the goal also indepen-dently affect the prediction without being encoded by the prior knowledge module, which is represented as S → A and G → A, respectively. The causal links S → A and
G → A represent the exploration-based effect (only related to the current episode) on the action prediction, which is dif-ferent from the experience-based effect Z → A. Consider two cases of the layout gap between the current environment and the prior knowledge: 1) the layout gap is minor and 2) the layout gap is significant. In the former case, the object layout is consistent in the current environment and the prior knowledge. Thus, the experience Z exerts a positive effect on the prediction of action A. However, the effect of experi-ence Z in the latter case could be negative. If the agent still relies on the “negative” experience to predict actions, it will suffer from poor generalization. Therefore, wisely utilizing the experience is essential to the ObjectNav task.
Motivated by wisely utilizing the learned experience, we propose the soft Total Direct Effect (sTDE) framework based on the Total Direct Effect analysis in causal inference.
Our sTDE improves the generalization of the trained model in inference by eliminating the prediction bias brought by the experience. To decouple the effect of experience, we construct the counter-fact prediction ¯a: the prediction is only affected by the experience Z while ignoring the S and
G, as shown in Fig. 1 (b). Then we propose the object layout estimator that calculates whether the effect of the ex-perience is positive, by measuring the layout gap between the current environment and the prior knowledge. Further-more, our sTDE will remove the counter-fact prediction ¯a from the fact prediction a when the layout gap is large.
In this paper, we propose the layout-based soft TDE framework for the ObjectNav task. Specifically, we adopt the Dirichlet-Multinomial distribution [22] to formulate the contextual relationship between objects, which represents the object layout of the environment. Before training, the agent learns prior layout distribution (i.e. the prior parame-ters of Dirichlet-Multinomial distribution) by randomly ex-ploring the training environments.
In the training stage, based on the Bayesian inference, the agent estimates the posterior layout distribution with the prior distribution and newly obtained observations. Then the constantly updated posterior layout is encoded into the navigation model and utilized to learn the environment-adaptive experience. The entire model is trained with RL by maximizing the reward of reaching the goal. In the test stage, our agent will not di-rectly use the trained policy as most previous works do. The agent first calculates the layout gap and the counter-fact pre-diction. The layout gap is determined by calculating the KL divergence between the posterior and prior distribution of object layouts and serves as a weight to determine whether to remove the counter-fact prediction (i.e. experience ef-fect) from the original prediction. The experimental results on AI2THOR [27], RoboTHOR [12] and Habitat [48] in-dicate that our layout-based sTDE (L-sTDE) can be a plug-and-play method to boost existing methods to achieve better navigation performances. 2.