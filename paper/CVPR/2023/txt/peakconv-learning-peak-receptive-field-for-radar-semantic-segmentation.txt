Abstract
The modern machine learning-based technologies have shown considerable potential in automatic radar scene un-derstanding. Among these efforts, radar semantic segmen-tation (RSS) can provide more refined and detailed infor-mation including the moving objects and background clut-ters within the effective receptive field of the radar. Moti-vated by the success of convolutional networks in various visual computing tasks, these networks have also been in-troduced to solve RSS task. However, neither the regular convolution operation nor the modified ones are specific to interpret radar signals. The receptive fields of existing convolutions are defined by the object presentation in opti-cal signals, but these two signals have different perception mechanisms. In classic radar signal processing, the object signature is detected according to a local peak response, i.e., CFAR detection. Inspired by this idea, we redefine the receptive field of the convolution operation as the peak re-ceptive field (PRF) and propose the peak convolution oper-ation (PeakConv) to learn the object signatures in an end-to-end network. By incorporating the proposed PeakConv layers into the encoders, our RSS network can achieve bet-ter segmentation results compared with other SoTA meth-ods on a multi-view real-measured dataset collected from an FMCW radar. Our code for PeakConv is available at https://github.com/zlw9161/PKC. 1.

Introduction
Radar is a remote sensor, which usually uses modu-lated electromagnetic signals to detect the objects of interest through directional transmitting antennas in a specific effec-tive working field [22]. As an active detection device, radar is more robust to extreme weather (e.g., haze, rain or snow) than other active detection device such as LiDARs [2], and it is also not susceptible to dim light condition and sun glare,
*Equal contribution. †Corresponding author. This research is sup-ported by Young Science Foundation of National Natural Science Foun-dation of China (No.62206258). as the passive optical sensors are [19]. In addition to the real-world location information, it can also tell the velocity of the moving objects thanks to the Doppler effects. Due to these advantages, radar sensors have played an irreplaceable role for many automotive security and defense applications, e.g., autonomous safety driving or UAV early warning.
Conventional radar detection mostly relies on the peak detection algorithm following constant false alarm rate (CFAR) [22, 23] principle. Taking frequency modulated continuous wave (FMCW) radar as example, the raw radar echos are first converted as multi-domain united frequency representations, e.g., range-Doppler (RD) and range-angle (RA) maps, through a series of cascading fast Fourier trans-formations (FFTs). Then for each cell under test (CUT) in the input RD/RA map, the CFAR detector will determine whether it contains moving object information according to an estimated detection threshold, which fully considers the characteristics of the radar signal itself. However, to ob-tain good effect in practical application, it is necessary to manually fine-tune various hyper-parameters including the thresholding factor, sizes and shapes of the local scope (i.e., the bandwidths of reference and guard units). Beyond that, conventional radar detection cannot give category informa-tion of the object. These two inconveniences hinder the con-ventional detection method from automatic semantic radar scene understanding.
Encouraged by the success of modern deep learning techniques in computational perception, especially the ob-ject detection [8, 15, 20, 21, 29] and semantic segmenta-tion [5, 11, 16, 24, 28] in computer vision, some efforts had been made recently for better automatic radar scene inter-pretation. These efforts evolve the target-clutter binary hy-pothesis of conventional radar testing into target semantic characterization of modern machine learning, i.e., radar ob-ject detection (ROD) [10, 17, 27] and radar semantic seg-mentation (RSS) [3, 13, 18]. Most of these methods used convolution networks as backbone models, which take radar frequency representations as input, and then make predic-tions on RA or RD view or both two views. For example, a multi-view RSS (MVRSS) network [18] was proposed
nism for radar data. (cid:80)N r }N i=1 x(i)
To achieve our goal, we take a look inside of the con-ventional radar detection method and the convolution op-eration in deep learning. As aforementioned, the conven-tional detection method is a kind of CFAR-based peak de-tection, e.g., commonly used cell averaging-CFAR (CA-CFAR) [22]. For a CUT, xc, of the input RD representation,
CA-CFAR detection can be divided into three steps: (i) av-eraging aggregation from reference cells {x(i) i=1 around
CUT, excluding the guard cells; (ii) threshold computing,
Θ = ξ · 1 r ; (iii) decision-making by comparing
N xc and Θ. It can be seen that, the decision-making basis is the difference between CUT and its threshold, i.e., the weighted summation of {x(i) i=1 with a shared weight, ξ r }N
N .
In another word, the key to determine whether the CUT has object for CA-CFAR is the denoised peak frequency response from an RF consisted of the CUT and its refer-ence cells. Yet none of the convolution operators mentioned above can explicitly possess such property, i.e., each output unit is actually a weighted summation of the units in a local dense/dilated rectangular or deformable RF, which does not strictly follow the guard-reference policy.
Therefore, in this work we redefine the RF of the con-volution operator as the guard-reference style, and call such new type RF the peak receptive field (PRF), which consists of the center unit and its reference neighbors. Then with some simple computational designs, we present two novel convolution operations to explicitly learn the peak response from PRF, i.e., PeakConvs. Compared with other convolu-tion operations, PeakConvs explicitly possess the advantage of the conventional radar detection methods. In comparison with the conventional CA-CFAR, adaptive peak response with learnable weights and high-level semantic representa-tion via task-driven learning paradigm can be achieved since
PeakConvs maintain the computational compatibility of the regular convolution operation. The main contributions are:
• A novel convolution computing paradigm for radar data processing. Instead of extracting radar signature directly from RF, we propose learning peak response from redefined PRF, which is more suitable for learn-ing tasks related to radar data.
• Two implementations of the proposed PeakConv.
According to the participation of center unit dur-ing interference (e.g., device noises and background there are two approaches of clutters) estimation,
PeakConv, including vanilla-PeakConv (PKC), and response difference aware PeakConv (ReDA-PKC).
• Well-performed multi-view RSS frameworks based on PeakConvs: by introducing PeakConvs into encoders of the convolutional automatic-encoder-decoder (CAED) framework, two RSS networks with
Figure 1. An examplar illustration of moving object signa-tures/presentations in (a) the 2D RD map and the corresponding (b) RD-amplitude 3D representation of radar signals, and their (c) synchronized camera image. to take better advantage of radar localization capability by making “unit-wise” predictions on both RD and RA fre-quency domains. To support the sufficient training of these deep models, a few large-scale radar datasets were also col-lected and created, e.g., OxfordRobotCar [9], nuScenes [4],
CRUW [26] and CARRADA [19].
However, the electromagnetic object signatures received by radar are not as intuitively understood as the optical ones captured by the cameras as shown in Fig. 1. With rich tex-ture and color information in the image, the convolution op-eration can learn useful semantic information from a rectan-gular local spatial receptive field (RF). And by introducing some intuitive priors of human vision, more efficient learn-ing mechanisms for convolution had been proposed, e.g., multi-scale fusion [12, 15, 25], dilation [5, 28] and deforma-tion [8, 29]. So far, these mechanisms are also introduced into radar data processing, such as the inception or pyramid pooling for multi-scale information, atrous convolution for larger dilated RF and deformable convolution for irregular object signature in ROD-Net [27] and MVRSS [18]. De-spite the multi-scale mechanism, which is more of a modu-lar idea, i.e., the computation is decoupled from the convo-lution itself, other variants are actually changing the RF it-self. One conclusion might be summed up that, the RF sam-pling/selection manner plays a very important role in convo-lution. While none of these RF selection manners including the regular one is proposed specifically for the radar data, thus they might not fully exploit the potential of convolu-tional networks in radar scene understanding. This concern motivates us to rethink the internal relation between convo-lution and the conventional radar detection mechanism, and try to find a more efficient and specific convolution mecha-multi-input and multi-output (MIMO) style are pre-sented. Our networks can achieve SoTA performance on both RD and RA views. 2.