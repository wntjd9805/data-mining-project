Abstract
Weakly-Supervised Semantic Segmentation (WSSS) us-ing image-level labels typically utilizes Class Activation
Map (CAM) to generate the pseudo labels. Limited by the local structure perception of CNN, CAM usually cannot identify the integral object regions. Though the recent Vi-sion Transformer (ViT) can remedy this flaw, we observe it also brings the over-smoothing issue, i.e., the final patch to-kens incline to be uniform. In this work, we propose Token
Contrast (ToCo) to address this issue and further explore the virtue of ViT for WSSS. Firstly, motivated by the obser-vation that intermediate layers in ViT can still retain se-mantic diversity, we designed a Patch Token Contrast mod-ule (PTC). PTC supervises the final patch tokens with the pseudo token relations derived from intermediate layers, al-lowing them to align the semantic regions and thus yield more accurate CAM. Secondly, to further differentiate the low-confidence regions in CAM, we devised a Class Token
Contrast module (CTC) inspired by the fact that class tokens in ViT can capture high-level semantics. CTC facilitates the representation consistency between uncertain local regions and global objects by contrasting their class tokens. Exper-iments on the PASCAL VOC and MS COCO datasets show the proposed ToCo can remarkably surpass other single-stage competitors and achieve comparable performance with state-of-the-art multi-stage methods. Code is available at https://github.com/rulixiang/ToCo. 1.

Introduction
To reduce the expensive annotation costs of deep seman-tic segmentation models, weakly-supervised semantic seg-mentation (WSSS) is proposed to predict pixel-level predic-tions with only weak and cheap annotations, such as image-level labels [2], points [4], scribbles [51] and bounding
*Corresponding author. This work was done when Lixiang Ru was a research intern at JD Explore Academy.
Figure 1. The generated CAM and the pairwise cosine simi-larity of patch tokens (sim. map). Our method can address the over-smoothing issue well and produce accurate CAM. Here we use ViT-Base. boxes [23]. Among all these annotation forms, the image-level label is the cheapest and contains the least informa-tion. This work also falls in the field of WSSS using only image-level labels.
Prevalent works of WSSS using image-level labels typ-ically derive Class Activation Map (CAM) [53] or its vari-ants [35] as pseudo labels. The pseudo labels are then pro-cessed with alternative refinement methods [1, 2] and used to train regular semantic segmentation models. However,
CAM is usually flawed since it typically only identifies the most discriminative semantic regions, severely weakening the final performance of semantic segmentation [1, 19, 43].
The recent works [15, 34, 47] show one reason is that pre-vious methods usually generate CAM with CNN, in which convolution only perceives local features and fails to acti-vate the integral object regions. To ameliorate this problem and generate more accurate pseudo labels for WSSS, these works propose solutions based on the recent Vision Trans-former (ViT) architecture [12], which inherently models the global feature interactions with self-attention blocks.
However, as demonstrated in [29, 42], self-attention in
ViT is essentially a low-pass filter, which inclines to re-duce the variance of input signals. Therefore, stacking self-attention blocks is equivalent to repeatedly performing spa-tial smoothing operations, which encourages the patch to-kens in ViT to be uniform [16, 36], i.e., over-smoothing.
We observe that the over-smoothing issue particularly im-pairs the WSSS task, since CAM used to derive pseudo labels relies on the output features (i.e. patch tokens). As shown in Figure 1, due to over-smoothing, the pairwise co-sine similarities of the patch tokens are close to 1, suggest-ing the learned representations of different patch tokens are almost uniform. The generated CAM thus tends to assign different image regions with the monotonous semantic la-bel. Though several recent works have explored the ViT architecture for WSSS [34, 39, 47], they typically overlook the over-smoothing issue of patch tokens, leaving this prob-lem unresolved.
In this work, we empirically observe that ViT smooths the patch tokens progressively, i.e. the learned representa-tions in intermediate layers can still preserve the seman-tic diversity. Therefore, we propose a Patch Token Con-trast (PTC) module to address the over-smoothing issue by supervising the final patch tokens with intermediate layer knowledge. Specifically, in the PTC module, we simply add an additional classifier in an intermediate layer to extract the auxiliary CAM and the corresponding pseudo pairwise token relations. By supervising the pairwise cosine simi-larities of final patch tokens with the pseudo relations, PTC can finely counter the over-smoothing issue and thus pro-duce high-fidelity CAM. As shown in Figure 1, our method can generate CAM that aligns well with the semantic object regions. The pairwise cosine similarities also coincide with the corresponding semantics. In addition, to further differ-entiate the uncertain regions in generated CAM, inspired by the property that the class token in ViT can inherently ag-gregate high-level semantics [6,15], we also propose a Class
Token Contrast (CTC) module. In CTC, we first randomly crop local images from uncertain regions (background re-gions), and minimize (maximize) the representation differ-ence between the class tokens of local and global images.
As a result, CTC can facilitate the local-to-global represen-tation consistency of semantic objects and the discrepancy between foreground and background, benefiting the integral and accurate object activation in CAM. Finally, based on the proposed PTC and CTC, we build Token Contrast (ToCo) for WSSS and extend it to the single-stage WSSS frame-work [34].
Overall, our contributions in this work include the fol-lowing aspects.
• We propose Patch Token Contrast (PTC) to address the over-smoothing issue in ViT. By supervising the final to-kens with intermediate knowledge, PTC can counter the patch uniformity and significantly promote the quality of pseudo labels for WSSS.
• We propose Class Token Contrast (CTC), which contrasts the representation of global foregrounds and local uncer-tain regions (background) and facilitates the object acti-vation completeness in CAM.
• The experiments on the PASCAL VOC [14] and MS
COCO dataset [26] show that the proposed ToCo can sig-nificantly outperform SOTA single-stage WSSS methods and achieve comparable performance with multi-stage competitors. 2.