Abstract
Building animatable and editable models of clothed hu-mans from raw 3D scans and poses is a challenging prob-lem. Existing reposing methods suffer from the limited ex-pressiveness of Linear Blend Skinning (LBS), require costly mesh extraction to generate each new pose, and typically do not preserve surface correspondences across different poses. In this work, we introduce Invertible Neural Skinning (INS) to address these shortcomings. To maintain corre-spondences, we propose a Pose-conditioned Invertible Net-work (PIN) architecture, which extends the LBS process by learning additional pose-varying deformations. Next, we combine PIN with a differentiable LBS module to build an expressive and end-to-end Invertible Neural Skinning (INS) pipeline. We demonstrate the strong performance of our method by outperforming the state-of-the-art reposing tech-niques on clothed humans and preserving surface corre-spondences, while being an order of magnitude faster. We also perform an ablation study, which shows the usefulness of our pose-conditioning formulation, and our qualitative results display that INS can rectify artefacts introduced by
LBS well. 1.

Introduction
Being able to create animatable representations of clothed humans beyond skinned meshes is essential for building realistic augmented or virtual reality experiences and improving simulators. Towards this goal, we consider the task of building animatable human representations from raw 3D scans and corresponding poses. Prior work in this area has seen a shift from building parametric models of humans [6, 21, 29], to more recent works learning implicit 3D neural representations [1,12,13,47,48,52,53] from data in canonical space. These canonical representations are an-imated to a new pose by a learning skinning weight field around them [11, 14, 35, 49, 54] and applying Linear Blend
Skinning (LBS) to warp the surface, where the pose is de-fined by a bone skeleton underlying the 3D surface.
Figure 1. Fast and Invertible Posing. We propose an end-to-end learnable reposing pipeline that allows animating implicit surfaces with intricate pose-varying effects, without requiring mesh extrac-tion [34] for each pose, while also maintaining correspondences across poses.
These prior works generally suffer from the limited ex-pressivity of LBS when handling complex pose-varying deformations, such as those of loose clothes and body tissue (i.e. muscle bulges, skin wrinkles).
In paramet-ric models like SMPL [29], such deformations are repre-sented by adding simple linear pose correctives (aka blend shapes), but these are restrictive and only work for un-clothed humans.
Implicit methods, to relieve this issue, learn their canonical representations conditioned on the de-formed pose [11, 14]. However, this conditioning comes with two major drawbacks during reposing. Given the se-quence of poses, a new mesh has to be extracted from scratch for each pose, which becomes a bottleneck when animating subjects at a high frame-rate or resolution. Also, as a consequence of this step, correspondences (topology preservation) between the surfaces of the same subject across different poses are lost.
Invertible Neural Networks (INN) [15, 16, 24] are bijec-tive functions that can preserve exact correspondences be-tween their input and output spaces, while learning com-plex non-linear transforms between them. This ability of
INNs makes them a suitable candidate for reposing, and in this work, we leverage INNs to build an Invertible Neu-ral Skinning (INS) pipeline. For this, we first build a
Pose-conditioned Invertible Network, abbreviated as PIN1, to learn pose-conditioned deformations. Next, to create an end-to-end Invertible Neural Skinning (INS) pipeline, we place two PINs around a differentiable LBS module, and use a pose-free canonical representation. These PINs help capture the non-linear surface deformations of clothes across poses and alleviate the volume loss suffered from the
LBS operation. Since our canonical representation remains pose-free, we perform the expensive mesh extraction ex-actly once, and repose the mesh by simply warping it with the learned LBS and an inverse pass through PINs.
We demonstrate the strong performance of INS by out-performing the previous state-of-the-art reposing method
SNARF [11]. On clothed humans data, we find INS pro-vides an absolute gain of roughly 1% when compared to
SNARF with pose-conditioning, and roughly 6% compared to SNARF without pose-conditioning. We conduct experi-ments on much simpler minimally clothed human data and obtain competitive results. We also find INS to be an or-der of magnitude faster at reposing long sequences. We ab-late our INS and demonstrate the effectiveness of our pose-conditioning formulation. Our results clearly show that the proposed INS can correct the LBS artefacts well. 2.