Abstract
Existing methods of multi-person video 3D human Pose and Shape Estimation (PSE) typically adopt a two-stage strategy, which ﬁrst detects human instances in each frame and then performs single-person PSE with temporal model.
However, the global spatio-temporal context among spa-tial instances can not be captured. In this paper, we pro-pose a new end-to-end multi-person 3D Pose and Shape estimation framework with progressive Video Transformer, termed PSVT. In PSVT, a spatio-temporal encoder (STE) captures the global feature dependencies among spatial ob-jects. Then, spatio-temporal pose decoder (STPD) and shape decoder (STSD) capture the global dependencies be-tween pose queries and feature tokens, shape queries and feature tokens, respectively. To handle the variances of ob-jects as time proceeds, a novel scheme of progressive de-coding is used to update pose and shape queries at each frame. Besides, we propose a novel pose-guided attention (PGA) for shape decoder to better predict shape parame-ters. The two components strengthen the decoder of PSVT to improve performance. Extensive experiments on the four datasets show that PSVT achieves stage-of-the-art results.
Figure 1. Comparison of multi-stage and end-to-end framework. (a) Existing video-based methods [4, 16, 49, 50] perform single-person pose and shape estimation (SPSE) on the cropped areas by temporal modeling, such as Gated Recurrent Units (GRUs). (b)
PSVT achieves end-to-end multi-person pose and shape estimation in video with spatial-temporal encoder (STE) and decoder (STD). 1.

Introduction
Multi-person 3D human Pose and Shape Estimation (PSE) from monocular video requires localizing the 3D joint coordinates of all persons and reconstructing their human meshes (e.g. SMPL [29] model). As an essen-tial task in computer vision, it has many applications in-cluding human-robot interaction detection [22], virtual re-ality [33], and human behavior understanding [8], etc. Al-though remarkable progress has been achieved in PSE from videos [4, 41, 50, 51] or images [5, 44, 45], capturing multi-person spatio-temporal relations of pose and shape simulta-neously is still challenging since the difﬁculty in modeling long-range global interactions.
To tackle this challenge, as shown in Figure 1 (a), exist-ing methods [4,16,50,51] employ a detection-based strategy of ﬁrstly detecting each human instance, then cropping the instance area in each frame and feeding it into the tempo-ral model, such as the recurrent neural network [4, 6, 16].
However, this framework can not capture the spatial re-lationship among human instances in an image and has the limitation of extracting long-range global context. Be-sides, the computational cost is expensive since it is pro-portional to the number of instances in image and it needs extra tracker [50] to identify each instance. Other temporal smoothing methods [15, 47] adopt a post-processing mod-ule to align the shape estimated by image-based PSE ap-proaches [5, 15, 23, 44, 45]. However, they can not capture temporal information directly from visual image features and lack the ability of long-range global interactions. These multi-stage methods split space and time dimensions and can not be end-to-end optimized.
To strengthen the long-range modeling ability, recently developed Transformer models [7,46] have been introduced in PSE. The Transformer-based mesh reconstruction ap-proaches [24, 25, 36, 54] take each human joint as a to-ken and capture the relationship of human joints by atten-tion mechanism. However, the global context among dif-ferent persons in spatio-temporal dimensions has not been explored. Other Transformer-based human pose estimation approaches [27, 57] explore the spatio-temporal context of human joints for single-person, but not on the multi-person mesh. Besides, these methods focus on capturing the rela-tions among human joints, while ignoring the relations be-tween human poses and shapes.
To tackle the above problems, we propose an end-to-end multi-person 3D Pose and Shape estimation framework with Video Transformer, termed PSVT, to capture long-range spatio-temporal global interactions in the video. As shown in Figure 1 (b), PSVT formulates the human in-stance localization and ﬁne-grained pose and mesh estima-tion as a set prediction problem as [3, 42]. First, PSVT extracts a set of spatio-temporal tokens from the deep vi-sual features and applies a spatio-temporal encoder (STE) on these visual tokens to learn the relations of feature to-kens. Second, given a set of pose queries, a progressive spatio-temporal pose decoder (STPD) learns to capture the relations of human joints in both spatial and temporal di-mensions. Third, with the guidance of pose tokens from
STPD, a progressive spatio-temporal shape decoder (STSD) learns to reason the relations of human mesh and pose in both spatial and temporal dimensions and further estimates the sequence 3D human mesh based on the spatio-temporal global context. Compared with previous shape estimation works [4,5,44,45,50,51], PSVT achieves end-to-end multi-person 3D pose and shape estimation in video.
In PSVT, different from previous methods, we propose a novel progressive decoding mechanism (PDM) for se-quence decoding and pose-guided attention (PGA) for de-coder. PDM takes the output tokens from the last frame as the initialized queries for next frame, which enables bet-ter sequence decoding for STPD and STSD. PGA aligns the pose tokens and shape queries and further computes the cross-attention with feature tokens from encoder. With the guidance of pose tokens, shape estimation can be more ac-curate. Our contributions can be summarized as follows:
• We propose a novel video Transformer framework, termed PSVT, which is the ﬁrst end-to-end multi-person 3D human pose and shape estimation frame-work with video Transformer.
• We propose a novel progressive decoding mechanism (PDM) for the decoder of video Transformer, which updates the queries at each frame in the attention block to improve the pose and shape decoding.
• We propose a novel pose-guided attention (PGA), which can capture the spatio-temporal relations among pose tokens, shape tokens, and feature tokens to im-prove the performance of shape estimation.
• Extensive experiments on four benchmarks show that
PSVT achieves new state-of-the-art results. 2.