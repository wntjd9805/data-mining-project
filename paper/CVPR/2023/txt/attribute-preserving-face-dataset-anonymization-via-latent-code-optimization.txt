Abstract
This work addresses the problem of anonymizing the identity of faces in a dataset of images, such that the pri-vacy of those depicted is not violated, while at the same time the dataset is useful for downstream task such as for training machine learning models. To the best of our knowl-edge, we are the first to explicitly address this issue and deal with two major drawbacks of the existing state-of-the-art approaches, namely that they (i) require the costly training of additional, purpose-trained neural networks, and/or (ii) fail to retain the facial attributes of the original images in the anonymized counterparts, the preservation of which is of paramount importance for their use in downstream tasks.
We accordingly present a task-agnostic anonymization pro-cedure that directly optimizes the images’ latent representa-tion in the latent space of a pre-trained GAN. By optimizing the latent codes directly, we ensure both that the identity is of a desired distance away from the original (with an iden-tity obfuscation loss), whilst preserving the facial attributes (using a novel feature-matching loss in FaRL’s [48] deep feature space). We demonstrate through a series of both qualitative and quantitative experiments that our method is capable of anonymizing the identity of the images whilst– crucially–better-preserving the facial attributes. We make the code and the pre-trained models publicly available at: https://github.com/chi0tzp/FALCO. 1.

Introduction
The ubiquitous use of mobile devices equipped with high-resolution cameras and the ability to effortlessly share personal photographs and videos on social media poses a
*These authors contributed equally. This work has been conducted dur-ing a research exchange visit of S. Barattin in QMUL in the framework of the EU H2020 project AI4Media.
Figure 1. Comparison of the proposed method to CIAGAN [27] and DeepPrivacy [16] in terms of identity anonymization and at-tribute preservation. significant threat to data privacy. Considering that mod-ern machine learning algorithms learn from vast amounts of data often crawled from the Web [18, 38], it has become increasingly important to consider the impact this has on the privacy of those individuals depicted. Motivated by pri-vacy concerns, many societies have recently enacted strict legislation, such as the General Data Protection Regulation (GDPR) [7], which requires the consent of every person that might be depicted in an image dataset. Whilst such laws have obvious benefits to the privacy of those featured in im-age datasets, this is not without costly side effects to the research community. In particular, research fields such as computer vision and machine learning rely on the creation and sharing of high-quality datasets of images of humans for a number of important tasks including security [24], healthcare [1], and creative applications [18, 35].
A recent line of research focuses on overcoming this is-sue by anonymizing the identity of the individuals in image datasets. Through this approach, the machine learning com-munity can still benefit from the wealth of large datasets of high-resolution images, but without cost to privacy.
This research field has seen several developments throughout the last few years. Early methods proposed by the computer vision community attempt to solve this prob-lem with simple solutions based on blurring [10] or other masking techniques, such as pixelation [12]. The result of this masking process succeeds in anonymizing the im-ages by completely hiding the identity-related components, but as a consequence renders the facial attribute informa-tion such as a person’s pose, expression, or skin tone (from which many computer vision tasks learn) indecipherable.
Another problem with these methods is that, whilst the re-sulting images may not be re-identifiable by humans, they can often be reversed by deep learning models [28, 32].
Another line of work leverages the power of Generative
Adversarial Networks (GANs) [13], which have recently been used for discovering controllable generation paths in their latent or feature spaces [2,33,34,42,43]. Towards face anonymization, GANs have been incorporated in order to synthesize new images in order to obtain photos that main-tain most of the image while changing the face of the subject of interest. In particular, these approaches use techniques like image inpainting [16], conditional generation [27], at-tribute manipulation [21], or adversarial perturbation [39].
These works are able to obtain anonymized images that can still be used for computer vision tasks such as tracking and detection, with very good results in terms of privacy preser-vation. However, many of these works lack the ability to generate natural-looking faces and often fail to preserve the original facial attributes in the anonymized images (or, on the occasions in which such methods do preserve the facial attributes, they fail to demonstrate this quantitatively). This is critical for many applications which rely on the attributes of the inner face, such as expression recognition [20], or mental health affect analysis [11]. To further complicate the picture, a fundamental problem often found with existing works is the way in which the anonymized images copy not just the original image’s background, but also more identi-fiable features [16, 27], such as the clothes of an individual, or their hair (see examples of this in Fig. 1). We argue that leaving such structure of the images unchanged constitutes a glaring privacy vulnerability, as one can re-identify the original image from the anonymized counterpart by com-paring the image background or person’s clothes.
Motivated by these concerns, in this work we propose to de-identify individuals in datasets of facial images whilst preserving the facial attributes of the original images. To achieve this, in contrast to existing work [16, 21, 27, 44, 45] that train custom neural networks from scratch, we propose to work directly in the latent space of a powerful pre-trained
GAN, optimizing the latent codes directly with losses that explicitly aim to retain the attributes and obfuscate the iden-tities. More concretely, we use a deep feature-matching loss [48] to match the high-level semantic features between the original and the fake image generated by the latent code, and a margin-based identity loss to control the similarity be-tween the original and the fake image in the ArcFace [9] space. The initialisation of the latent codes is obtained by randomly sampling the latent space of GAN, using them to generate the corresponding synthetic images and finding the nearest neighbors in a semantic space (FARL [48]). In or-der to preserve texture and pose information of the original image, we perform inversion of the original image and re-tain the parts that correspond to the properties we want to preserve in the final code. This results in a latent code that yields a high-resolution image that contains a new identity but retains the same facial attributes as the original image.
The main contributions of this paper can be summarized as follows:
• To the best of our knowledge, we are the first to address the problem of identity anonymization whilst also ex-plicitly retaining facial attributes.
• We propose a novel methodology and loss functions working with pre-trained GANs capable of generating high-resolution anonymized datasets.
• We show through a series of thorough experiments on both Celeba-HQ [25] and LFW [15] that our method competes with the state-of-the-art in obfuscating the identity, whilst better-retaining the facial attributes un-der popular quantitative metrics. 2.