Abstract
Despite the tremendous progress on data-free knowledge distillation (DFKD) based on synthetic data generation, there are still limitations in diverse and efficient data syn-thesis. It is naive to expect that a simple combination of generative network-based data synthesis and data augmen-tation will solve these issues. Therefore, this paper proposes a novel data-free knowledge distillation method (Spaceship-Net) based on channel-wise feature exchange (CFE) and multi-scale spatial activation region consistency (mSARC) constraint. Specifically, CFE allows our generative net-work to better sample from the feature space and efficiently synthesize diverse images for learning the student network.
However, using CFE alone can severely amplify the un-wanted noises in the synthesized images, which may result in failure to improve distillation learning and even have negative effects. Therefore, we propose mSARC to assure the student network can imitate not only the logit output but also the spatial activation region of the teacher network in order to alleviate the influence of unwanted noises in di-verse synthetic images on distillation learning. Extensive experiments on CIFAR-10, CIFAR-100, Tiny-ImageNet, Im-agenette, and ImageNet100 show that our method can work well with different backbone networks, and outperform the state-of-the-art DFKD methods. Code will be available at: https://github.com/skgyu/SpaceshipNet.
*Equal contribution
This research was supported in part by the National Key R&D Pro-gram of China (grant 2018AAA0102500), and the National Natural Sci-ence Foundation of China (grant 62176249). 1.

Introduction
Knowledge distillation (KD) aims to train a lightweight student model that can imitate the capability of a pre-trained complicated teacher model. In the past decade, KD has been studied in a wide range of fields such as image recogni-tion, speech recognition, and natural language processing.
Traditional KD methods usually assume that the whole or part of the training set used by the teacher network is ac-cessible by the student network [17, 24, 34]. But in practi-cal applications, there can be various kinds of constraints in accessing the original training data, e.g., due to pri-vacy issues in medical data [1, 2, 5, 20, 28, 35] and portrait data [3], and copyright and privateness of large data vol-ume such as JFT-300M [40] and text-image data [37]. The traditional KD methods no longer work under these sce-narios. Recently, data-free knowledge distillation (DFKD)
[4,7,10,13,14,22,25,27,29,43,46] seeks to perform KD by generating synthetic data instead of accessing the original training data used by the teacher network to train the student network. Thus, the general framework of DFKD consists of two parts: synthetic data generation that replicates the orig-inal data distribution and constraint design between student and teacher network during distillation learning. Synthetic data generation methods in DFKD mainly consist of noise image optimization-based methods [4, 26, 31, 44] and gen-erative network-based methods [8, 9, 12, 13, 27, 29, 45]. The former approaches optimize randomly initialized noise im-ages to make them have the similar distribution to the orig-inal training data. These methods can theoretically gener-ate an infinite number of independent and identically dis-tributed images for student network learning, but they are usually extremely time-consuming, and thus are difficult in generating sufficient synthetic data with high diversity.
The later approaches learn a generator to synthesize im-ages that approximate the distribution of the original train-ing data. These methods can be much faster than the image
optimization-based approach, but the diversity of the syn-thesized data is usually limited because the generation of different images are not completely independent with each other. we verify the effectiveness of the key components (CFE and mSARC), we find that mSARC plays a particularly impor-tant role when strong data augmentation is applied to the synthetic images.
Despite the encouraging results achieved, DFKD re-mains a challenging task, because the synthetic data may have a different distribution from the original data, which could potentially result in bias in student network learn-ing. The possible reason is that the noises in the synthe-sized images can easily lead to the bias of the network’s region of interest. In addition, the widely used KL diver-gence constraint between student and teacher networks in existing DFKD methods may not work well with synthetic data [4].
This paper proposes a novel DFKD method that utilizes channel-wise feature exchange (CFE) and multi-scale spa-tial activation region consistency (mSARC) constraint to improve knowledge transfer from the teacher network to the student network. The proposed method enhances the diversity of synthetic training data and the robustness to un-wanted noises in synthetic images during distillation. Un-like previous generative network-based methods that em-ployed multiple generators to synthesize images [27] or reinitialization and retraining of generator [13] to enhance the synthetic training data diversity, our method improves the synthetic training data diversity by using the features of early synthetic images to perform CFE. When our gen-erative network and those of other methods have learned to generate the same number of synthetic images, the pro-posed method can produce more diverse training data for distillation. However, CFE also amplifies unwanted noise in synthetic images, which may hinder distillation learning (traditional data augmentation methods also suffer from this problem, e.g., CutMix [47] and Mixup [50]). To address this issue, we propose the mSARC constraint, which en-ables the student network to learn discriminative cues from similar regions to those used by the teacher network, effec-tively overcoming the limitations of the traditional KL di-vergence loss when applied to synthetic images during dis-tillation learning. Moreover, combining our mSARC with traditional data augmentation methods [47, 50] can still sig-nificantly improve distillation learning with synthetic data.
We evaluate our method on a number of datasets, includ-ing CIFAR-10 [19], CIFAR-100 [19], and Tiny-ImageNet
[21]. Our approach demonstrates superior performance compared to the state-of-the-art DFKD methods. More-over, we observe that the student networks trained using our
DFKD method achieve comparable performance to those trained using original training data. Additionally, we eval-uate our method on subsets of ImageNet [11] with 10 and 100 classes and a resolution of 224 × 224, validating the efficacy of our method on generating high-resolution syn-thetic images for distillation learning. In our ablation study, 2.