Abstract
Inspired by DETR variants, query-based end-to-end in-stance segmentation (QEIS) methods have recently outper-formed CNN-based models on large-scale datasets. Yet they would lose efficacy when only a small amount of training data is available since it’s hard for the crucial queries/kernels to learn localization and shape priors. To this end, this work offers a novel unsupervised pre-training solution for low-data regimes.
Inspired by the recent success of the Prompting technique, we introduce a new pre-training method that boosts QEIS models by giving
Saliency Prompt for queries/kernels. Our method contains three parts: 1) Saliency Masks Proposal is responsible for generating pseudo masks from unlabeled images based on the saliency mechanism. 2) Prompt-Kernel Matching transfers pseudo masks into prompts and injects the corre-sponding localization and shape priors to the best-matched kernels. 3) Kernel Supervision is applied to supply super-vision at the kernel level for robust learning. From a practi-cal perspective, our pre-training method helps QEIS models achieve a similar convergence speed and comparable per-formance with CNN-based models in low-data regimes. Ex-perimental results show that our method significantly boosts several QEIS models on three datasets.1 1.

Introduction
Modern CNN models address the instance segmentation task in an indirect way, by defining the localization prob-lem on a large set of proposals [16], window centers [6,10], or location-based masks [30, 33, 35]. A typical example is Mask-RCNN [16], which generates candidate bound-ing boxes using a well-designed region proposal network.
Although this paradigm makes localization learning eas-*Corresponding author. 1Code: https://github.com/lifuguan/saliency prompt
Figure 1. Performance comparison between K-Net and Mask-RCNN. K-Net can outperform Mask-RCNN on large-scale datasets (COCO-full). However, on small datasets (the right three), it can not perform as well as Mask-RCNN since it’s hard to learn localization and shape priors. Our proposed unsupervised pre-training method based on saliency prompt not only boosts the vanilla K-Net significantly, but also helps to achieve comparable performance compared with Mask-RCNN. ily optimized, it still relies on the manually-designed non-maximum suppression (NMS) as post-processing to remove duplicated predictions.
Based on a state-of-the-art object detection model,
DETR [27], a few Query-based End-to-end Instance Seg-mentation (QEIS) models [7, 8, 15, 18, 32, 41] have been proposed to perform instance segmentation in a new way.
Unlike CNN-based methods which usually require a large set of proposals, QEIS models use dynamic queries/kernels to automatically encode object localization knowledge with different locations and object shapes. This design effec-tively eliminates hand-crafted anchors and post-processing like NMS. However, due to the intrinsic dynamic attribute, the kernels are forced to learn general object spatial dis-tribution and shape priors in a data-driven manner so that they can fit any input image. This makes QEIS models re-quire a much larger amount of training data and a much longer training time to achieve competitive performance with CNN-based methods. Once in low-data regimes [1],
QEIS models will encounter much more significant perfor-mance drops than CNN-based methods, as shown in Fig-ure 1. Here we take K-Net [41] as the typical example of
QEIS models and compare it with Mask-RCNN.
That being said, the potential of QEIS models is still enormous since once good localization and shape priors can be learned, they can perform on par with or even outperform
CNN-based methods with a much more concise pipeline.
This makes us think about how we can help QEIS models learn localization and shape priors quickly, especially for low-data regimes.
A promising solution is to adopt unsupervised pre-training, which requires no extra data and any modifica-tion to existing model architectures. However, most exist-ing unsupervised pre-training methods [1, 3, 5, 11, 36] are only used for the backbone and can not benefit instance seg-mentation prediction heads, where localization and shape priors are exactly encoded.
In the object detection field, some works [1, 11] do pre-train a full detection architec-ture. However, they use pseudo bounding boxes for train-ing, many of which do not contain any object inside hence can not generate pseudo instance masks for instance seg-mentation. FreeSOLO [34] is the first method specifically designed for instance segmentation. Yet it mainly focuses on generating pseudo masks and directly using them to su-pervise the model training. Such a way still learns the object localization and shape priors in a data-driven man-ner, hence requiring tedious steps to generate high-quality pseudo masks. To address these problems, we present a novel unsupervised pre-training method for QEIS models.
Inspired by the recent advances in Prompting in NLP and vision tasks [12, 19, 28, 43, 44], we propose to directly in-ject localization and shape priors into the kernels using our proposed Saliency Prompt (SP). The prompts are gener-ated by saliency masks which indicate potential objects, and then are used to decorate the kernels for injecting location and shape knowledge.
In detail, our saliency prompt involves two essential saliency and prompt: First, a Saliency Mask parts:
Proposal generation method is responsible for generating saliency-level pseudo masks from unlabeled images.
In-stead of directly learning from noisy pseudo masks, we use them to generate corresponding region features and then achieve prompts from them. Next, a Prompt-Kernel
Matching module matches the saliency prompts to the ker-nels and then injects the prior knowledge encoded in the prompts into the best-matched kernels. Furthermore, we also propose a Kernel Supervision scheme to supervise the model learning at the kernel level to gain kernel robustness.
See Figure 2 for overview.
In our experiments, our method surpasses all the existing unsupervised pre-training algorithms on low-data regimes
It can be used as a plug-and-play pre-on four datasets. training step for most QEIS methods and enables faster convergence speed and better performance without any in-crease in parameters or memory. Most importantly, our method achieves two desiderata on downstream tasks a) it leads to the same convergence speed as CNN-based meth-ods. (b) it gains comparable or even better performance than CNN-based methods on most downstream datasets.
In ablations, we find that our method shows big tolerance to the quality of pseudo masks. As such, we can easily achieve performance improvement without a sophisticated and time-consuming pseudo mask generation method as in
FreeSOLO [34].
Meanwhile, it is essential that our approach has the following significant differences from the currently pop-ular semi-supervised methods [37]: (1) Our model is a self-supervised method that works in ”pre-training+down-stream task finetuning” fashion, where the domains of the down-stream tasks are not constrained, which, in most cases, differ from the pre-training domain. However, the semi-supervised setting constrains all training data resid-ing in a single domain. Otherwise, the semi-supervised model cannot converge based on our experiments. (2) Semi-supervised methods usually use auxiliary loss (like pseudo-label supervision) which we don’t use. Based on the above two-fold reasons, the semi-supervised works are incompa-rable to ours. 2.