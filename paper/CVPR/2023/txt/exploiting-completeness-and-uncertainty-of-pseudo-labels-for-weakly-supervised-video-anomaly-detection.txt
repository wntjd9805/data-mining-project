Abstract
Weakly supervised video anomaly detection aims to iden-tify abnormal events in videos using only video-level labels.
Recently, two-stage self-training methods have achieved significant improvements by self-generating pseudo labels and self-refining anomaly scores with these labels. As the pseudo labels play a crucial role, we propose an enhance-ment framework by exploiting completeness and uncertainty properties for effective self-training. Specifically, we first design a multi-head classification module (each head serves as a classifier) with a diversity loss to maximize the distri-bution differences of predicted pseudo labels across heads.
This encourages the generated pseudo labels to cover as many abnormal events as possible. We then devise an it-erative uncertainty pseudo label refinement strategy, which improves not only the initial pseudo labels but also the up-dated ones obtained by the desired classifier in the sec-ond stage. Extensive experimental results demonstrate the proposed method performs favorably against state-of-the-art approaches on the UCF-Crime, TAD, and XD-Violence benchmark datasets.
Figure 1. Illustration of the completeness: (a) represents a video that contains multiple abnormal clips (ground truth anomalies are in the orange area). Existing methods tend to focus on the most anomalous clip as shown in (b). We propose to use the multi-head classification module together with a diversity loss to encourage pseudo labels to cover the complete abnormal events as depicted in (c). 1.

Introduction
Automatically detecting abnormal events in videos has attracted increasing attention for its broad applications in intelligent surveillance systems. Since abnormal events are sparse in videos, recent studies are mainly developed within the weakly supervised learning framework [5, 12, 19, 25, 27,
*Corresponding author. 29, 32, 34, 37–41], where only video-level annotations are available. However, the goal of anomaly detection is to pre-dict frame-level anomaly scores during test. This results in great challenges for weakly supervised video anomaly de-tection.
Existing methods broadly fall into two categories: one-stage methods based on Multiple Instance Learning (MIL) and two-stage self-training methods. One-stage MIL-based
methods [19, 27, 29, 39, 41] treat each normal and abnor-mal video as a negative and positive bag respectively, and clips of a video are the instances of a bag. Formulating anomaly detection as a regression problem, these methods adopt ranking loss to encourage the highest anomaly score in a positive bag to be higher than that in a negative bag.
Due to the lack of clip-level annotations, the anomaly scores generated by MIL-based methods are usually less accurate.
To alleviate this problem, two-stage self-training methods
In the first stage, pseudo labels for are proposed [5, 12]. clips are generated by MIL-based methods. In the second stage, MIST [5] utilizes these pseudo labels to refine dis-criminative representations. In contrast, MSL [12] refines the pseudo labels via a transformer-based network. Despite progress, existing methods still suffer two limitations. First, the ranking loss used in the pseudo label generator ignores the completeness of abnormal events. The reason is that a positive bag may contain multiple abnormal clips as shown in Figure 1, but MIL is designed to detect only the most likely one. The second limitation is that the uncertainty of generated pseudo labels is not taken into account in the sec-ond stage. As the pseudo labels are usually noisy, directly using them to train the final classifier may hamper its per-formance.
To address these problems, we propose to enhance pseudo labels via exploiting completeness and uncertainty properties. Specifically, to encourage the complete detec-tion of abnormal events, we propose a multi-head module to generate pseudo labels (each head serves as a classifier) and introduce a diversity loss to ensure the distribution dif-ference of pseudo labels generated by the multiple classi-fication heads. In this way, each head tends to discover a different abnormal event, and thus the pseudo label genera-tor covers as many abnormal events as possible. Then, in-stead of directly training a final classifier with all pseudo la-bels, we design an iterative uncertainty-based training strat-egy. We measure the uncertainty using Monte Carlo (MC)
Dropout [6] and only clips with lower uncertainty are used to train the final classifier. At the first iteration, we use such uncertainty to refine pseudo labels obtained in the first stage, and in the remaining iterations, we use it to refine the output of the desired final classifier.
The main contributions of this paper are as follows:
• We design a multi-head classifier scheme together with a diversity loss to encourage the pseudo labels to cover as many abnormal clips as possible.
• We design an iterative uncertainty aware self-training strategy to gradually improve the quality of pseudo la-bels.
• Experiments on UCF-Crime, TAD, and XD-Violence datasets demonstrate the favorable performance com-pared to several state-of-the-art methods. 2.