Abstract 1.

Introduction
Multi-person pose forecasting remains a challenging problem, especially in modeling fine-grained human body interaction in complex crowd scenarios. Existing methods typically represent the whole pose sequence as a tempo-ral series, yet overlook interactive influences among peo-ple based on skeletal body parts. In this paper, we propose a novel Trajectory-Aware Body Interaction Transformer (TBIFormer) for multi-person pose forecasting via effec-tively modeling body part interactions. Specifically, we con-struct a Temporal Body Partition Module that transforms all the pose sequences into a Multi-Person Body-Part se-quence to retain spatial and temporal information based on body semantics. Then, we devise a Social Body Interaction
Self-Attention (SBI-MSA) module, utilizing the transformed sequence to learn body part dynamics for inter- and intra-individual interactions. Furthermore, different from prior
Euclidean distance-based spatial encodings, we present a novel and efficient Trajectory-Aware Relative Position En-coding for SBI-MSA to offer discriminative spatial infor-mation and additional interactive clues. On both short-and long-term horizons, we empirically evaluate our frame-work on CMU-Mocap, MuPoTS-3D as well as synthesized datasets (6 ∼ 10 persons), and demonstrate that our method greatly outperforms the state-of-the-art methods.
†Corresponding author.
Recent years have seen a proliferation of work on the topic of human motion prediction [4, 6, 7, 13, 24, 25, 28, 34], which aims to forecast future poses based on past obser-vations. Similarly, understanding and forecasting human motion plays a critical role in the field of artificial intelli-gence and computer vision, especially for robot planning, autonomous driving, and video surveillance [8, 14, 21, 44].
Although encouraging progress has been achieved, the cur-rent methods are mostly based on local pose dynamics fore-casting without considering global position changes of body joints (global body trajectory) and often tackle the prob-lem of single humans in isolation while overlooking human-human interaction. Actually, in real-world scenarios, each person may interact with one or more people, ranging from low to high levels of interactivity with instantaneous and deferred mutual influences [2, 31]. As illustrated in Fig. 1 (a), two individuals are pushing and shoving with high in-teraction, whilst a third individual is strolling with no or low interaction. Thus, accurately forecasting pose dynamics and trajectory and comprehensively considering complex social interactive factors are imperative for understanding human behavior in multi-person motion prediction. However, ex-isting solutions do not efficiently address these challenging factors. For example, Guo et al. [15] propose a collabo-rative prediction task and perform future motion prediction for only two interacted dancers, which inevitably ignores low interaction influence on one’s future behavior. Wang et al. [39] use local and global Transformers to learn indi-vidual motion and social interactions separately in a crowd scene. The aforementioned methods ignore the interactive influences of body parts and only learn temporal and social relationships without modeling fine-grained body interac-tion, which makes it difficult to capture complex interaction dependencies.
To solve this issue, we propose a novel Transformer-based framework, termed TBIFormer, which consists of multiple stacked TBIFormer blocks and a Transformer de-coder.
In particular, each TBIFormer block contains a
Social Body Interaction Multi-Head Self-Attention (SBI-MSA) module, which aims at learning body part dynam-ics across inter- and intra-individuals and capturing fine-grained skeletal body interaction dependencies in complex crowd scenarios as shown in Fig. 1 (b). More specifically,
SBI-MSA learns body parts dynamics across temporal and social dimensions by measuring motion similarity of body parts rather than pose similarity of the entire body. In addi-tion, a Trajectory-Aware Relative Position Encoding is in-troduced for SBI-MSA as a contextual bias to provide addi-tional interactive clues and discriminative spatial informa-tion, which is more robust and accurate than the Euclidean distance-based spatial encodings.
In order to feed the TBIFormer a pose sequence contain-ing both temporal and spatial information, an intuitive way is to retain body joints in time series. However, this strat-egy will suffer from noisy joints caused by noisy sensor in-puts or inaccurate estimations. In this work, we propose a
Temporal Body Partition Module (TBPM) that, based on human body semantics, transforms the original pose se-quence into a new one, enhancing the network’s capacity for modeling interactive body parts. Then, we concatenate the transformed sequences for all people one by one to gen-erate a Multi-Person Body Part (MPBP) sequence for input of TBIFormer blocks, which enables the model to capture dependencies of interacting body parts between individu-als. TBIFormer makes MPBP sequence suitable for motion prediction by utilizing positional and learnable encodings to indicate to whom each body part and timestamp belongs.
Finally, a Transformer decoder is used to further con-sider the relations between the current and historical context across individuals’ body parts toward predicting smooth and accurate multi-person poses and trajectories. For multi-person motion prediction (with 2 ∼ 3 persons), we evaluate our method on multiple datasets, including CMU-Mocap
[9] with UMPM [35] augmented and MuPoTS-3D [30].
Besides, we extend our experiment by mixing the above datasets with the 3DPW [38] dataset to perform prediction in a more complex scene (with 6 ∼ 10 persons). Our method outperforms the state-of-the-art approaches for both short-and long-term predictions by a large margin, with 14.4%
∼ 16.5% accuracy improvement for the short-term (≤ 1.0s) and 6.5% ∼ 18.2% accuracy improvement for the long-term (1.0s ∼ 3.0s).
To summarize, our key contributions are as follows: 1)
We propose a novel Transformer-based framework for ef-fective multi-person pose forecasting and devise a Tempo-ral Body Partition Module that transforms the original pose sequence into a Multi-Person Body-Part sequence to retain both temporal and spatial information. 2) We present a novel Social Body Interaction Multi-Head Self-Attention (SBI-MSA) that learns body part dynamics across inter-and intra-individuals and captures complex interaction de-pendencies. 3) A novel Trajectory-Aware Relative Posi-tion Encoding is introduced for SBI-MSA to provide dis-criminative spatial information and additional interactive clues. 4) On multiple multi-person motion datasets, the proposed TBIFormer significantly outperforms the state-of-the-art methods. 2.