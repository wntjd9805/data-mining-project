Abstract
Open-vocabulary object detection aims to provide ob-ject detectors trained on a fixed set of object categories with the generalizability to detect objects described by arbi-trary text queries. Previous methods adopt knowledge dis-tillation to extract knowledge from Pretrained Vision-and-Language Models (PVLMs) and transfer it to detectors.
However, due to the non-adaptive proposal cropping and single-level feature mimicking processes, they suffer from information destruction during knowledge extraction and inefficient knowledge transfer. To remedy these limitations, we propose an Object-Aware Distillation Pyramid (OADP) framework, including an Object-Aware Knowledge Extrac-tion (OAKE) module and a Distillation Pyramid (DP) mech-anism. When extracting object knowledge from PVLMs, the former adaptively transforms object proposals and adopts object-aware mask attention to obtain precise and com-plete knowledge of objects. The latter introduces global and block distillation for more comprehensive knowledge transfer to compensate for the missing relation information in object distillation. Extensive experiments show that our method achieves significant improvement compared to cur-rent methods. Especially on the MS-COCO dataset, our
OADP framework reaches 35.6 mAPN 50, surpassing the cur-rent state-of-the-art method by 3.3 mAPN 50. Code is released at https://github.com/LutingWang/OADP. 1.

Introduction
Open-vocabulary object detection (OVD) [49] aims to endow object detectors with the generalizability to detect open categories including both base and novel categories where only the former are annotated in the training phase.
Pretrained Vision-and-Language Models (PVLMs, e.g.,
CLIP [32] and ALIGN [19]) have witnessed great progress in recent years, and Knowledge Distillation (KD) [17] has led to a wave of unprecedented advances transferring the zero-shot visual recognition ability from PVLMs to detec-*Corresponding author (liaoyue.ai@gmail.com) (a) Knowledge Extraction (b) Knowledge Transfer
Figure 1. An overview of our OADP framework. (a) Directly applying center crop on proposals may throw informative object parts away, resulting in ambiguous image regions. In contrast, our
OAKE module extracts complete objects and reduces the influence of surrounding distractors. (b) Our DP mechanism includes global, block, and object KD to achieve effective knowledge transfer. tors [12, 25, 28, 29, 48, 53]. KD typically comprises two es-sential steps, i.e., knowledge extraction and then knowledge transfer. A common practice in OVD is to crop objects with class-agnostic proposals and use the teacher (e.g., CLIP vi-sual encoder) to extract knowledge of the proposals. The knowledge is then transferred to the detector (e.g., Mask R-CNN [15]) via feature mimicking.
Despite significant development, we argue that con-ventional approaches still have two main limitations: 1)
Dilemma between comprehensiveness and purity during knowledge extraction. As proposals have diverse aspect ra-tios, the fixed center crop strategy to square them may cut out object parts (fig. 1a). Enlarging those proposals via re-sizing function may alleviate this problem, but additional surrounding distractors may confuse the teacher to extract 2) Missing global scene accurate proposal knowledge. understanding during knowledge transfer. Conventional approaches merely concentrate on object-level knowledge transfer by directly mimicking the teacher’s features of indi-vidual proposals. As a result, the student cannot fully grasp the contextual characteristics describing the interweaving of different objects. In light of the above discussions, we pro-pose an Object-Aware Distillation Pyramid (OADP) frame-work to excavate the teacher’s knowledge accurately and effectively transfer the knowledge to the student.
To preserve the complete information of proposals while extracting their CLIP image embeddings, we propose an Object-Aware Knowledge Extraction (OAKE) module.
Concretely, given a proposal, we square it with an adaptive resizing function to avoid destroying the object structure and involve object information as much as possible. How-ever, the resizing process inevitably introduces environmen-tal context, which may contain some distractors that confuse the teacher. Therefore, we propose to utilize an object to-ken [OBJ] whose interaction manner during the forward process is almost the same as the class token [CLS] except that it only attends to patch tokens covered by the origi-nal proposal. In this way, the extracted embeddings contain precise and complete knowledge of the proposal object.
To facilitate complete and effective knowledge trans-fer, we propose a Distillation Pyramid (DP) mechanism (fig. 1b). As previous works only adopt object distillation to align the feature space of detectors and PVLMs, the re-lation between different objects is neglected. Therefore, we propose global and block distillation to compensate for the missing relation information in object distillation. For global distillation, we optimize the L1 distance between the detector backbone and the CLIP visual encoder so that the detector learns to encode rich semantics implied in the im-age scene. However, the CLIP visual encoder is prone to ignore background information, which may also be valu-able for detection. Therefore, we take a finer step to divide the input image into several blocks and optimize the L1 dis-tance between the block embeddings of the detector and the
CLIP image encoder. Overall, the above three distillation modules constitute a hierarchical distillation pyramid, al-lowing for the transfer of more diversified knowledge from
CLIP to the detectors.
We demonstrate the superiority of our OADP framework on MS-COCO [27] and LVIS [14] datasets. On MS-COCO, it improves the state-of-the-art results of mAPN 50 from 32.3 to 35.6. On the LVIS dataset, our OADP framework reaches 21.9 APr on the object detection task and 21.7 APr on the instance segmentation task, leading the former methods by more than 1.1 APr and 1.9 APr respectively. 2.