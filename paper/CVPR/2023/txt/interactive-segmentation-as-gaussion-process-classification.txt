Abstract
Click-based interactive segmentation (IS) aims to extract the target objects under user interaction. For this task, most of the current deep learning (DL)-based methods mainly follow the general pipelines of semantic segmentation. Al-beit achieving promising performance, they do not fully and explicitly utilize and propagate the click information, in-evitably leading to unsatisfactory segmentation results, even at clicked points. Against this issue, in this paper, we propose to formulate the IS task as a Gaussian process (GP)-based pixel-wise binary classification model on each image. To solve this model, we utilize amortized variational inference to approximate the intractable GP posterior in a data-driven manner and then decouple the approximated GP posterior into double space forms for efficient sampling with linear complexity. Then, we correspondingly construct a GP classi-fication framework, named GPCIS, which is integrated with the deep kernel learning mechanism for more flexibility. The main specificities of the proposed GPCIS lie in: 1) Under the explicit guidance of the derived GP posterior, the informa-tion contained in clicks can be finely propagated to the entire image and then boost the segmentation; 2) The accuracy of predictions at clicks has good theoretical support. These merits of GPCIS as well as its good generality and high efficiency are substantiated by comprehensive experiments on several benchmarks, as compared with representative methods both quantitatively and qualitatively. Codes will be released at https://github.com/zmhhmz/GPCIS CVPR2023. 1.

Introduction
Driven by the huge potential in reducing the pixel-wise annotation cost, interactive segmentation (IS) has sparked much research interest [14], which aims to seg-ment the target objects under user interaction with less interaction cost. Among various types of user interac-*Corresponding author
Figure 1. Classification procedure for an exemplar unclicked pixel (blue box) in the IS task. (a) Most current deep learning-based IS methods individually perform pixel-wise classification on the deep feature x; (b) We formulate the IS task as a Gaussian process (GP) classification model on each image, where red (green) clicks are viewed as training data with foreground (background) labels, and the unclicked pixel as the to-be-classified testing data. Based on the derived GP posterior inference framework, the relations between the deep feature x of the testing pixel (blue solid line) and that of other pixels (dashed lines) can be finely modeled and then the information at clicks can be propagated to the entire image for improved prediction. tion [1â€“3, 27, 30, 49, 52, 54], in this paper, we focus on the popular click-based mode, where positive annotations are clicked on the target object while negative ones are clicked in the background regions [7, 18, 25, 40, 41].
Recent years have witnessed the promising success of deep learning (DL)-based methods in the IS task. The most commonly adopted research line is that the user interaction is encoded as click maps and fed into a deep neural network (DNN) together with input images to extract deep features for the subsequent segmentation [41, 51]. However, these methods generally suffer from two limitations: 1) As shown in Fig. 1 (a), after extracting the deep features, they generally perform pixel-wise classification without specific designs for the IS task. As a result, during the last-layer classification, the deep features of different pixels are not fully interactive and the information contained in clicked pixels cannot be
finely propagated to other pixels under explicit regularization. 2) There is no explicit theoretical support that the clicked regions can be properly activated and correctly classified. Al-though some researchers have proposed different strategies, e.g., non-local-based modules [6] and the backpropagating refinement scheme [18, 40], they usually incur extra compu-tational cost and are not capable enough to deal with the two problems simultaneously. Besides, the relations between deep features of different pixels are generally characterized and captured based on off-the-shelf network modules. Such implicit design makes it hard to clearly understand the work-ing mechanism underlying these methods.
To alleviate these aforementioned issues, inspired by the intrinsic capabilities of Gaussian process (GP) models, e.g., explicitly measuring the relations between data points by a kernel function, and promoting accurate predictions at training data via interpolation, we rethink the IS task and attempt to construct a GP-based inference framework for the specific IS task. Concretely, as shown in Fig. 1 (b), we pro-pose to treat the IS task from an alternative perspective and reformulate it as a pixel-level binary classification problem on each image, where clicks are viewed as training pixels with classification labels, i.e., foreground or background, and the unclicked points as the to-be-classified testing pixels.
With such understanding, we construct the corresponding
GP classification model. To solve it, we propose to utilize the amortized variational inference to efficiently approxi-mate the intractable GP posterior in a data-driven manner, and then adopt the decoupling techniques [47, 48] to achieve the GP posterior sampling with linear complexity. To im-prove the learning flexibility, we further embed the deep kernel learning strategy into the decoupled GP posterior in-ference procedure. Finally, by correspondingly integrating the derived GP posterior sampling mechanism with DNN backbones, we construct a GP Classification-based Interac-tive Segmentation framework, called GPCIS. In summary, our contributions are mainly three-fold: 1) We propose to carefully formulate the IS task as a Gaus-sian process classification model on each image. To adapt the GP model to the IS task, we propose specific designs and accomplish the approximation and efficient sampling of the
GP posterior, which are then effectively integrated with the deep kernel learning mechanism for more flexibility. 2) We build a concise and clear interactive segmentation network under a theoretically sound framework. As shown in Fig. 1 (b), the correlation between the deep features of dif-ferent pixels is modeled by GP posterior. With such explicit regularization, the information contained in clicks can be finely propagated to the entire image and boost the prediction of unclicked pixels. Besides, our method can provide ratio-nal theoretical support for accurate predictions at clicked points. These merits are finely validated in Sec. 5.2. 3) Extensive experimental comparisons as well as model ver-ification comprehensively substantiate the superiority of our proposed GPCIS in segmentation quality and interaction effi-ciency. It is worth mentioning that the proposed GPCIS can consistently achieve superior performance under different backbone segmentors, showing its fine generality. 2.