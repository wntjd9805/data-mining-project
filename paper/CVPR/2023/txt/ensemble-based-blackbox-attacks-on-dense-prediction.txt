Abstract
We propose an approach for adversarial attacks on dense prediction models (such as object detectors and segmenta-tion). It is well known that the attacks generated by a single surrogate model do not transfer to arbitrary (blackbox) vic-tim models. Furthermore, targeted attacks are often more challenging than the untargeted attacks. In this paper, we show that a carefully designed ensemble can create effec-tive attacks for a number of victim models. In particular, we show that normalization of the weights for individual mod-els plays a critical role in the success of the attacks. We then demonstrate that by adjusting the weights of the ensemble according to the victim model can further improve the per-formance of the attacks. We performed a number of experi-ments for object detectors and segmentation to highlight the significance of the our proposed methods. Our proposed ensemble-based method outperforms existing blackbox at-tack methods for object detection and segmentation. Finally we show that our proposed method can also generate a sin-gle perturbation that can fool multiple blackbox detection and segmentation models simultaneously. Code is available at https://github.com/CSIPlab/EBAD. 1.

Introduction
Computer vision models (e.g., classification, object de-tection, segmentation, and depth estimation) are known to be vulnerable to carefully crafted adversarial exam-ples [4, 11, 16, 17, 46]. Creating such adversarial attacks is easy for whitebox models, where the victim model is com-pletely known [14,16,24,37,55]. In contrast, creating adver-sarial attacks for blackbox models, where the victim model is unknown, remains a challenging task [1, 33, 54]. Most of the existing blackbox attack methods have been devel-oped for classification models [10, 21, 35, 47]. Blackbox attacks for dense prediction models such as object detec-tion and segmentation are relatively less studied [4, 17, 27], and most of the existing ones mainly focus on untargeted
*Equal contribution
Figure 1.
Illustration of the targeted ensemble-based blackbox attack. (Top) Attack generated by a single surrogate model does not transfer on the victim blackbox model (person does not map to car). (Bottom) Attack generated by weight balancing and optimization can transfer on a variety of victim models (person is mapped to car). attacks [17]. Furthermore, a vast majority of these methods are based on transfer attacks, in which a surrogate (white-box) model is used to generate the adversarial example that is tested on the victim model. However, the success rate of such transfer-based attacks is often low, especially for tar-geted attacks [10, 21, 47].
In this paper, we propose and evaluate an ensemble-based blackbox attack method for objection detection and segmentation. Our method is inspired by three key obser-vations: 1) targeted attacks generated by a single surrogate model are rarely successful; 2) attacks generated by an en-semble of surrogate models are highly successful if the con-tribution from all the models is properly normalized; and 3) attacks generated by an ensemble for a specific victim model can be further improved by adjusting the contribu-tions of different surrogate models. The overall idea of the proposed work is illustrated in Fig. 1. Our proposed method can be viewed as a combination of transfer- and query-based attacks, where we can adjust the contribution based on the feedback from the victim model using a small number of queries (5–20 in our experiments). In contrast, conventional query-based attacks require hundreds or thou-sands of queries from the victim model [9, 19, 22, 49].
We conduct comprehensive experiments to validate our proposed method and achieve state-of-the-art performance for both targeted and untargeted blackbox attacks on ob-1
ject detection. Specifically, our proposed method attains 29–53% success rate using only 5 queries for targeted at-tacks on object detectors, whereas the current state-of-the-art method [4] achieves 20–39% success rate with the same number of queries. Furthermore, we extend our evalua-tion to untargeted and targeted attacks on blackbox seman-tic segmentation models. Our method achieves 0.9–1.55% mIoU for untargeted and 69–95% pixel-wise success for tar-geted attacks. By comparison, the current state-of-the-art method [17] obtains 0.6–7.97% mIoU for untargeted attacks and does not report results for targeted attacks. To the best of our knowledge, our work is the first approach for targeted and query-based attacks for semantic segmentation.
Below we summarize main contributions of this work.
• We design a novel framework that can effectively attack blackbox dense prediction models based on an ensemble of surrogate models.
• We propose two simple yet highly effective ideas, namely weight balancing and weight optimization, with which we can achieve significantly better attack performance compared to existing methods.
• We extensively evaluate our method for targeted and un-targeted attacks on object detection and semantic seg-mentation models and achieve state-of-the-art results.
• We demonstrate that our proposed method can generate a single perturbation that can fool multiple blackbox de-tection and segmentation models simultaneously. 2.