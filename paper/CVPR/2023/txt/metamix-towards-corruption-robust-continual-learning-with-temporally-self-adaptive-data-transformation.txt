Abstract
Continual Learning (CL) has achieved rapid progress in recent years. However, it is still largely unknown how to determine whether a CL model is trustworthy and how to foster its trustworthiness. This work focuses on evaluating and improving the robustness to corruptions of existing CL models. Our empirical evaluation results show that existing state-of-the-art (SOTA) CL models are particularly vulnera-ble to various data corruptions during testing. To make them trustworthy and robust to corruptions deployed in safety-critical scenarios, we propose a meta-learning framework of self-adaptive data augmentation to tackle the corruption ro-bustness in CL. The proposed framework, MetaMix, learns to augment and mix data, automatically transforming the new task data or memory data. It directly optimizes the general-ization performance against data corruptions during train-ing. To evaluate the corruption robustness of our proposed approach, we construct several CL corruption datasets with different levels of severity. We perform comprehensive exper-iments on both task- and class-continual learning. Extensive experiments demonstrate the effectiveness of our proposed method compared to SOTA baselines. 1.

Introduction
Humans constantly acquire new information throughout their lifespan and easily recognize information shifts such as structure and style variations in images. Continual learn-ing (CL) aims at imitating human’s ability to learn from non-stationary data distributions without forgetting the previ-ously learned knowledge. The past few years have witnessed rapid progress in CL research [1, 30, 31, 36, 45]. Despite the success, existing CL systems overlook the robustness
*Corresponding author against unforeseen data shifts during testing. They assume that training and test images for each task follow the same distribution. However, as data distributions evolve and new scenarios occur, test images often encounter various cor-ruptions such as snow, blur, pixelation, and combinations, resulting in a shifted distribution from the training set. For example, Figure 1 shows various corruptions applied on one image from Split-miniImageNet.
Data corruption can drastically impair the performance of existing image recognition systems. A recent study [21] shows that classification accuracy of various architectures has dropped significantly on the ImageNet test set with some simple and natural corruptions. Our empirical evaluation results show that state-of-the-art CL models are even more vulnerable to these corruptions during testing. For example, the accuracy of DER++ [5] for task-continual learning de-creases from 93.9% to 50.5% on split-CIFAR10; accuracy drops to 10.6 % from 75.6 % on split-CIFAR100; accuracy decreases to 9.8% from 61.3% on split-miniImageNet by applying those common corruptions on test data of each CL task. This severe issue makes existing CL models highly unreliable in safety-critical applications. Thus, improving the robustness of CL models to foster their trustworthiness when deployed in real-world scenarios is essential.
Training a CL model robust to various corruptions is diffi-cult due to the following challenges. 1) Unseen corruptions could perturb the test set far beyond those encountered dur-ing training. A model that naively augments training images with seen corruptions cannot generalize to the new ones during testing. Also, it is unrealistic to enumerate all possi-ble corruptions during training since there are infinite types of corruptions and their combinations. 2) With the ever-evolving data distributions in CL, an effective augmentation strategy learned on previous tasks may gradually become less effective because the optimal augmentation strategies are task-dependent and dynamically change over tasks [11].
(a) Original data (b) Brightness (c) Contrast (d) Defocus Blur (e) Elastic (f) Fog
Figure 1. Visualization of five types of different corruption operations on the testing images of Split-miniImageNet.
Although we can adopt a memory buffer to store data from previous tasks, augmenting and replaying them at later train-ing iterations, the augmented memory may gradually be-come less effective as the model could memorize the stored information after replay runs. Recent approaches, such as
Augmix [22] composes and combines multiple pre-defined augmentation operations with different depths and widths, show efficacy in improving robustness under traditional su-pervised classification tasks. However, these approaches are not directly applicable to corruption-robust CL since they only use a fixed random augmentation strategy that is often not optimal for non-stationary data distributions in CL.
To address these unique challenges of corruption-robustness in CL, we propose a temporally self-adaptive
Augmix within a meta-learning framework, named MetaMix.
It adaptively augments the memory buffer data and the cur-rently received new data by learning to mix the augmentation operations tailored to the evolving data distributions. In par-ticular, our automatic self-adaptive MetaMix is a bi-level optimization, simulating the evaluation process on unseen corruptions. We randomly divide the training augmentation operations into pseudo-seen and pseudo-unseen operations at each CL step. The lower-level optimization is to optimize the model performance on the pseudo-seen operations; the upper-level optimization is to optimize the generalization of the pseudo-unseen operations. The augmentation strategy is governed by an LSTM, which inputs context information and outputs the corresponding mixing parameters for the augmentations. The proposed MetaMix ensures the augmen-tation strategy automatically adapts to non-stationary data distribution. Furthermore, the objective is to optimize the performance of the pseudo-unseen corruption operations, which aligns with our goal during testing and encourages the generalization to unseen corruptions.
To evaluate the corruption robustness of existing and the proposed methods, we propose a new challenging benchmark where various corruptions perturb the testing data of each CL task. To facilitate future research, we construct several new datasets, including split-CIFAR-10-C, split-CIFAR-100-C, and split-miniImageNet-C. Extensive experiments on the constructed benchmarks demonstrate the effectiveness of our proposed MetaMix approach compared with several
SOTA data-augmentation approaches adapted for CL. We summarize our contributions as follows:
• To our best knowledge, we are the first to study the corruption-robustness of CL methods. Accordingly, we propose the first set of novel benchmarks for evaluating the corruption-robustness of existing CL methods and moving towards trustworthy CL.
• We propose a self-adaptive augmentation method,
MetaMix, by learning to mix and augment the training data of each CL task to achieve corruption-robustness on unseen corruptions for each CL task.
• Our method is versatile and can be seamlessly inte-grated with existing CL methods. Extensive experi-ments with both task/class continual learning demon-strate the effectiveness of MetaMix. 2.