Abstract 1.

Introduction
We propose a novel framework to reconstruct accu-rate appearance and geometry with neural radiance fields (NeRF) for interacting hands, enabling the rendering of photo-realistic images and videos for gesture animation from arbitrary views. Given multi-view images of a single hand or interacting hands, an off-the-shelf skeleton estima-tor is first employed to parameterize the hand poses. Then we design a pose-driven deformation field to establish cor-respondence from those different poses to a shared canon-ical space, where a pose-disentangled NeRF for one hand is optimized. Such unified modeling efficiently complements the geometry and texture cues in rarely-observed areas for both hands. Meanwhile, we further leverage the pose priors to generate pseudo depth maps as guidance for occlusion-aware density learning. Moreover, a neural feature distilla-tion method is proposed to achieve cross-domain alignment for color optimization. We conduct extensive experiments to verify the merits of our proposed HandNeRF and report a series of state-of-the-art results both qualitatively and quantitatively on the large-scale InterHand2.6M dataset.
*Corresponding Authors.
As a dexterous tool to interact with the physical world and convey rich semantic information, the modeling and re-construction of human hands have attracted substantial at-tention from the research community. Typically, the synthe-sis of realistic hand images or videos with different postures in motion has a wide range of applications, e.g., human-computer interaction, sign language production, virtual and augmented reality technologies such as telepresence, etc.
Classic hand-modeling works are mainly built upon pa-rameterized mesh models such as MANO [31]. They fit the geometry of hands to polygon meshes manipulated by shape and pose parameters, and then complete coloring via texture mapping. Despite being widely adopted, those models have the following limitations. On the one hand, high-frequency details are hard to present on low-resolution meshes, hinder-ing the production of photo-realistic images. On the other hand, no special design is developed for interacting hands, which is a non-trivial scenario involving complex postures with self-occlusion.
To address the above issues and push the boundary of re-alistic human hand modeling, motivated by the recent suc-cess of NeRF [17] in modeling human body [11, 25, 26], we propose HandNeRF, a novel framework that unifiedly models the geometry and texture of animatable interacting
hands with neural radiance fields (NeRF). Specifically, a pose-conditioned deformation field is introduced to warp the sampled observing ray into a canonical space, guided by the prior-based blend skinning transformation and a learn-able error-correction network dealing with non-rigid defor-mations. The different input postures are thereby mapped to a common mean pose, where a canonical NeRF is com-petent at modeling. Thanks to the continuous implicit rep-resentation of NeRF and the multi-view-consistent volume rendering, we are able to produce high-fidelity images of posed hands from arbitrary viewing directions. This can not only be applied in the synthesis of free-viewpoint videos, but also help to perform data augmentation for multi-view detection and recognition tasks in computer vision, e.g., sign language recognition.
Meanwhile, modeling one single hand is nowhere near enough from an application perspective. The semantics ex-pressed by single-hand movements is quite limited. Many practical scenarios such as sign language conversations re-quire complex interacting postures of both hands. However, handling interaction scenarios is far from trivial and still
Interacting hands exhibit fine-grained lacks exploration. texture in small areas, while incompleteness of visible tex-ture permeates the image samples due to self-occlusion and limited viewpoints. To this end, we extend the aforemen-tioned model into a unified framework for both hands. By introducing the hand mapping and ray composition strategy into the pose-deformable NeRF, we make it possible to nat-urally handle interaction contacts and complement the ge-ometry and texture in rarely-observed areas for both hands.
Note that with such a design, HandNeRF is compatible with both single hand and two interacting hands.
Moreover, to ensure a correct depth relationship when rendering the hand interactions, we re-exploit the hu-man priors and propose a low-cost depth supervision for occlusion-robust density optimization. Such strong con-straint guides the model to extract accurate geometry from sparse-view training samples. Additionally, a neural feature distillation branch is designed to achieve feature alignment between a pre-trained 2D teacher and the 3D color field. By implicitly leveraging spatial contextual cues for color learn-ing, this cross-domain distillation effectively alleviates the artifacts on the target shape and further improves the quality of the learned texture.
Our main contributions are summarized as follows:
• To the best of our knowledge, we are the first to de-velop a unified framework to model photo-realistic in-teracting hands with deformable neural radiance fields.
• We propose several elaborate strategies, including the depth-guided density optimization and the neural fea-ture distillation, in order to effectively address practi-cal challenges in interacting hands training and ensure high-fidelity results for novel view/pose synthesis.
• Extensive experiments on the large-scale dataset Inter-Hand2.6M [18] show that our HandNeRF outperforms the baselines both qualitatively and quantitatively. 2.