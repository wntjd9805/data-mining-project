Abstract
This paper proposes an anchor-based deformation model, namely AnchorDEF, to predict 3D garment anima-tion from a body motion sequence. It deforms a garment mesh template by a mixture of rigid transformations with extra nonlinear displacements. A set of anchors around the mesh surface is introduced to guide the learning of rigid transformation matrices. Once the anchor transfor-mations are found, per-vertex nonlinear displacements of the garment template can be regressed in a canonical space, which reduces the complexity of deformation space learn-ing. By explicitly constraining the transformed anchors to satisfy the consistencies of position, normal and direction, the physical meaning of learned anchor transformations in space is guaranteed for better generalization. Furthermore, an adaptive anchor updating is proposed to optimize the anchor position by being aware of local mesh topology for learning representative anchor transformations. Qualita-tive and quantitative experiments on different types of gar-ments demonstrate that AnchorDEF achieves the state-of-the-art performance on 3D garment deformation prediction in motion, especially for loose-ﬁtting garments. 1.

Introduction
Animating 3D garments has a wide range of applications in 3D content generation, digital humans, virtual try-on, video games, and so on. Existing pipelines of 3D garment animation usually rely on physics based simulation (PBS), which requires a large amount of computational resources and time costs, particularly for high-quality PBS methods.
Some data-driven or learning-based methods have been proposed to quickly produce 3D garment deformation from static poses or motion sequences with low computational complexity [4,5,9,11,12,16,25–28,31,40]. However, many of them attach garment templates to the skeleton of hu-man body for modeling the articulation of garments, which
*Corresponding author.
Figure 1. 3D garment deformation predicted by the proposed An-chorDEF with body motions. Leveraging the anchor transforma-tions, AnchorDEF is able to realistically deform the garment mesh, especially for loose-ﬁtting garments, e.g., dresses. only work with tight garments, e.g., T-shirts and pants, and poorly address loose-ﬁtting ones, e.g., dresses and skirts.
In this case, the topology of garments is different from the human body. Therefore, using the skinning blend weights of body yields discontinuities on deformed garment mesh.
Several methods [26, 34] smooth out the blend weights to alleviate the discontinuities but may lose the shape details for large deformations of loose-ﬁtting garments, which do not closely follow body movements.
To this end, we propose an anchor-based deformation model, namely AnchorDEF, for predicting 3D garment de-It leverages a formation from a body motion sequence. mixture of rigid anchor transformations to represent prin-ciple rotations and translations of garments to detach the
garment articulation from the body skeleton while preserv-ing the body movement prior, then nonlinear displacements can be regressed relatively easily in a canonical space. As shown in Fig. 1, our method can exploit anchor transforma-tions to realistically deform the garment mesh, especially for loose-ﬁtting garments, e.g., dresses.
Speciﬁcally, given a sequence of body motions includ-ing poses and translations, we ﬁrst estimate rigid transfor-mations of a set of anchors around the garment mesh. Us-ing the linear blending skinning (LBS), the garment mesh template is deformed by a weighted combination of the an-chor transformations meanwhile per-vertex displacements of the mesh template are regressed to correct artifacts of the blended rigid transformations. To learn physically mean-ingful anchor transformations for better generalization, we enforce the transformed anchors to maintain consistency with the target’s position and normal. In addition, a relative direction constraint is employed to reduce garment-body in-terpenetrations, which is efﬁcient due to the sparseness of anchors. To make the learned anchor transformations effec-tively represent the garment deformation, an adaptive an-chor updating is further introduced to utilize mesh simpliﬁ-cation as supervision to optimize the anchor position. It pa-rameterizes the position with a local attention mask on ad-jacent mesh vertices and pushes the anchors towards folds and boundaries of garment mesh which usually determine the way of deformation.
The main contributions of our work can be summarized as follows: 1) We propose an anchor-based deformation model which learns a set of anchor transformations and blend weights in a uniﬁed framework to represent the de-formation of 3D garments, especially for loose-ﬁtting ones. 2) We propose to learn anchor transformations by position and normal consistencies as well as relative direction con-straint for better generalization and fewer garment-body in-terpenetrations. 3) We introduce an adaptive anchor updat-ing with the mesh simpliﬁcation as supervision to optimize the anchor position for learning representative anchor trans-formations. 2.