Abstract
Gait is one of the most promising biometrics that aims to identify pedestrians from their walking patterns. However, prevailing methods are susceptible to confounders, result-ing in the networks hardly focusing on the regions that re-flect effective walking patterns. To address this fundamen-tal problem in gait recognition, we propose a Generative
Counterfactual Intervention framework, dubbed GaitGCI, consisting of Counterfactual Intervention Learning (CIL) and Diversity-Constrained Dynamic Convolution (DCDC).
CIL eliminates the impacts of confounders by maximiz-ing the likelihood difference between factual/counterfactual attention while DCDC adaptively generates sample-wise factual/counterfactual attention to efficiently perceive the sample-wise properties. With matrix decomposition and di-versity constraint, DCDC guarantees the model to be effi-cient and effective. Extensive experiments indicate that pro-posed GaitGCI: 1) could effectively focus on the discrimi-native and interpretable regions that reflect gait pattern; 2) is model-agnostic and could be plugged into existing mod-els to improve performance with nearly no extra cost; 3) ef-ficiently achieves state-of-the-art performance on arbitrary scenarios (in-the-lab and in-the-wild). 1.

Introduction
Gait recognition aims to utilize walking patterns to iden-tify pedestrians without explicit cooperation, thus drawing rising attention. Current gait recognition research focuses on in-the-lab [53, 69] and in-the-wild scenarios [73, 76] for theoretical analysis and practical application, respectively.
The key to addressing gait recognition is to fully cap-ture the effective visual cues of the gait patterns, i.e., the regions close to the body boundary [39, 60] for both in-the-lab scenarios and in-the-wild scenarios. However, the at-tention analysis [4, 59, 68] on prevailing methods in Fig. 1
*Corresponding author.
Figure 1. Network attention comparison. From top to down: sil-houette, existing method, and proposed GaitGCI. The confounders make the existing model collapse into suboptimal attention re-gions. By contrast, GaitGCI could effectively focus on the dis-criminative and interpretable regions (i.e., close to the bound-ary [39, 60]) that could represent walking patterns. indicates that the existing methods hardly capture the effec-tive gait patterns and tend to collapse into the suboptimal attention regions, which would deteriorate the gait repre-sentation. We argue that this phenomenon is caused by the network’s susceptibility to the confounders [21, 32], which may provide shortcuts [21, 32] for the models rather than the valid gait-related patterns. For example, the attention regions of prevailing methods are related to viewpoints [64] or walking conditions [30]. As shown in Fig. 1, the prevail-ing network tends to focus on the head under the front view and the head/feet under the side view. However, the major-ity of the gait-related information close to the boundary is neglected. Therefore, how to alleviate the impact of con-founders is a fundamental problem to model discriminative and interpretable gait representation.
Motivated by this, we propose a generative counterfac-tual intervention framework, named GaitGCI, consisting of
Counterfactual Intervention Learning (CIL) and Diversity-Constrained Dynamic Convolution (DCDC). The core idea of CIL is to leverage the counterfactual-based causal infer-ence to alleviate the impact of confounders and mine the
state-of-the-art performance under arbitrary scenarios (in-the-lab and in-the-wild) as shown in Fig. 2.
The main contributions are summarized as follows:
• We present counterfactual intervention learning (CIL) to alleviate the impact of confounders. CIL could ef-fectively force the model to focus on the regions that reflect gait patterns by maximizing the likelihood dif-ference between factual/counterfactual attention.
• We present diversity-constrained dynamic convolution (DCDC) to generate factual/counterfactual attention in a sample adaptive manner. Matrix decomposition and diversity constraint guarantee efficiency and represen-tation power, respectively.
• Extensive experiments demonstrate that the proposed framework efficiently achieves state-of-the-art perfor-mance in arbitrary scenarios. Besides, the proposed methods could serve as a plug-and-play module to boost the performance of prevailing models. 2.