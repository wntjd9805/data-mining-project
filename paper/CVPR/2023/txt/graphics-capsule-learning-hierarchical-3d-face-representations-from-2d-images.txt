Abstract 1.

Introduction
The function of constructing the hierarchy of objects is important to the visual process of the human brain. Previ-ous studies have successfully adopted capsule networks to decompose the digits and faces into parts in an unsuper-vised manner to investigate the similar perception mecha-nism of neural networks. However, their descriptions are restricted to the 2D space, limiting their capacities to imi-tate the intrinsic 3D perception ability of humans. In this paper, we propose an Inverse Graphics Capsule Network (IGC-Net) to learn the hierarchical 3D face representations from large-scale unlabeled images. The core of IGC-Net is a new type of capsule, named graphics capsule, which rep-resents 3D primitives with interpretable parameters in com-puter graphics (CG), including depth, albedo, and 3D pose.
Speciﬁcally, IGC-Net ﬁrst decomposes the objects into a set of semantic-consistent part-level descriptions and then as-sembles them into object-level descriptions to build the hier-archy. The learned graphics capsules reveal how the neural networks, oriented at visual perception, understand faces as a hierarchy of 3D models. Besides, the discovered parts can be deployed to the unsupervised face segmentation task to evaluate the semantic consistency of our method. Moreover, the part-level descriptions with explicit physical meanings provide insight into the face analysis that originally runs in a black box, such as the importance of shape and texture for face recognition. Experiments on CelebA, BP4D, and
Multi-PIE demonstrate the characteristics of our IGC-Net.
∗Corresponding author.
A path toward autonomous machine intelligence is to en-able machines to have human-like perception and learning abilities [19]. As humans, by only observing the objects, we can easily decompose them into a set of part-level com-ponents and construct their hierarchy even though we have never seen these objects before. This phenomenon is sup-ported by the psychological studies that the visual process of the human brain is related to the construction of the hi-erarchical structural descriptions [11,22,23,29]. To investi-gate the similar perception mechanism of neural networks, previous studies [18, 35] incorporate the capsule networks, which are designed to present the hierarchy of objects and describe each entity with interpretable parameters. After observing a large-scale of unlabeled images, these meth-ods successfully decompose the digits or faces into a set of parts, which provide insight into how the neural networks understand the objects. However, their representations are limited in the 2D space. Speciﬁcally, these methods follow the analysis-by-synthesis strategy in model training and try to reconstruct the image by the decomposed parts. Since the parts are represented by 2D templates, the reconstruction becomes estimating the afﬁne transformations to warp the templates and put them in the right places, which is just like painting with stickers. This strategy performs well when the objects are intrinsically 2D, like handwritten digits and frontal faces, but has difﬁculty in interpreting 3D objects in the real world, especially when we want a view-independent representation like humans [2].
How to represent the perceived objects is the core re-search topic in computer vision [3, 25]. One of the most popular theories is the Marr’s theory [22, 23]. He believed that the purpose of the vision is to build the descriptions
of shapes and positions of things from the images and con-struct hierarchical 3D representations of objects for recog-nition.
In this paper, we try to materialize Marr’s the-ory on human faces and propose an Inverse Graphics Cap-sule Network (IGC-Net), whose primitive is a new type of capsule (i.e., graphics capsule) that is deﬁned by com-puter graphics (CG), to learn the hierarchical 3D represen-tations from large-scale unlabeled images. Figure 1 shows an overview of the proposed method. Speciﬁcally, the hi-erarchy of the objects is described with the part capsules and the object capsules, where each capsule contains a set of interpretable parameters with explicit physical meanings, including depth, albedo, and pose. During training, the in-put image is ﬁrst encoded to a global shape and albedo em-beddings, which are sent to a decomposition module to get the spatially-decoupled part-level graphics capsules. Then, these capsules are decoded by a shared capsule decoder to get explicit 3D descriptions of parts. Afterward, the parts are assembled by their depth to generate the object capsules as the object-centered representations, naturally construct-ing the part-object hierarchy. Finally, the 3D objects em-bedded in the object capsules are illuminated, posed, and rendered to ﬁt the input image, following the analysis-by-synthesis manner. When an IGC-Net is well trained, the learned graphics capsules naturally build hierarchical 3D representations.
We apply IGC-Net to human faces, which have been widely used to investigate human vision system [31] due to the similar topology structures and complicated appear-ances. Thanks to the capacity of the 3D descriptions, IGC-Net successfully builds the hierarchy of in-the-wild faces that are captured under various illuminations and poses. We evaluate the IGC-Net performance on the unsupervised face segmentation task, where the silhouettes of the discovered parts are regarded as segment maps. We also incorporate the IGC-Net into interpretable face analysis to uncover the mechanism of neural networks when recognizing faces.
The main contributions of this paper are summarized as:
• This paper proposes an Inverse Graphics Capsule Net-work (IGC-Net) to learn the hierarchical 3D face repre-sentations from unlabeled images. The learned graph-ics capsules in the network provide insight into how the neural networks, oriented at visual perception, un-derstand faces as a hierarchy of 3D models.
• A Graphics Decomposition Module (GDM) is pro-posed for part-level decomposition, which incorpo-rates shape and albedo information as cues to ensure that each part capsule represents a semantically con-sistent part of objects.
• We execute the interpretable face analysis based on the part-level 3D descriptions of graphics capsules. Be-sides, the silhouettes of 3D parts are deployed to the unsupervised face segmentation task. Experiments on
CelebA, BP4D, and Multi-PIE show the effectiveness of our method. 2.