Abstract
We explore long-term temporal visual correspondence-based optimization for 3D video object detection in this work. Visual correspondence refers to one-to-one map-pings for pixels across multiple images. Correspondence-based optimization is the cornerstone for 3D scene recon-struction but is less studied in 3D video object detection, because moving objects violate multi-view geometry con-straints and are treated as outliers during scene recon-struction. We address this issue by treating objects as first-class citizens during correspondence-based optimiza-tion. In this work, we propose BA-Det, an end-to-end op-timizable object detector with object-centric temporal cor-respondence learning and featuremetric object bundle ad-justment. Empirically, we verify the effectiveness and ef-ficiency of BA-Det for multiple baseline 3D detectors un-der various setups. Our BA-Det achieves SOTA perfor-mance on the large-scale Waymo Open Dataset (WOD) with only marginal computation cost. Our code is available at https://github.com/jiaweihe1996/BA-Det. 1.

Introduction 3D object detection is an important perception task, es-pecially for indoor robots and autonomous-driving vehi-cles. Recently, image-only 3D object detection [23, 52] has
In real-been proven practical and made great progress. world applications, cameras capture video streams instead of unrelated frames, which suggests abundant temporal in-formation is readily available for 3D object detection. In single-frame methods, despite simply relying on the predic-tion power of deep learning, finding correspondences play an important role in estimating per-pixel depth and the ob-ject pose in the camera frame. Popular correspondences include Perspective-n-Point (PnP) between pre-defined 3D keypoints [22, 52] and their 2D projections in monocular 3D object detection, and Epipolar Geometry [6,12] in multi-view 3D object detection. However, unlike the single-frame case, temporal visual correspondence has not been explored much in 3D video object detection.
As summarized in Fig. 1, existing methods in 3D video object detection can be divided into three categories while each has its own limitations. Fig. 1a shows methods with object tracking [3], especially using a 3D Kalman Filter to smooth the trajectory of each detected object. This ap-proach is detector-agnostic and thus widely adopted, but it is just an output-level smoothing process without any fea-ture learning. As a result, the potential of video is under-exploited. Fig. 1b illustrates the temporal BEV (Bird’s-[14, 23, 26] for 3D video object
Eye View) approaches detection. They introduce the multi-frame temporal cross-attention or concatenation for BEV features in an end-to-end fusion manner. As for utilizing temporal information, temporal BEV methods rely solely on feature fusion while ignoring explicit temporal correspondence. Fig. 1c depicts stereo-from-video methods [46, 47]. These methods explic-itly construct a pseudo-stereo view using ego-motion and then utilize the correspondence on the epipolar line of two frames for depth estimation. However, the use of explicit correspondence in these methods is restricted to only two frames, thereby limiting its potential to utilize more tem-poral information. Moreover, another inevitable defect of these methods is that moving objects break the epipolar con-straints, which cannot be well handled, so monocular depth estimation has to be reused.
Considering the aforementioned shortcomings, we seek a new method that can handle both static and moving objects, and utilize long-term temporal correspondences.
Firstly, in order to handle both static and moving objects, we draw experience from the object-centric global optimization with reprojection constraints in Simultaneous Localization and Mapping (SLAM) [21, 48]. Instead of directly estimat-ing the depth for each pixel from temporal cues, we utilize them to construct useful temporal constraints to refine the object pose prediction from network prediction. Specifi-cally, we construct a non-linear least-square optimization problem with the temporal correspondence constraint in an
(a) Temporal Filtering (b) Temporal BEV (c) Stereo from Video (d) BA-Det (Ours)
Figure 1. Illustration of how to leverage temporal information in different 3D video object detection paradigms. object-centric manner to optimize the pose of objects no matter whether they are moving or not. Secondly, for long-term temporal correspondence learning, hand-crafted de-scriptors like SIFT [27] or ORB [35] are no longer suit-able for our end-to-end object detector. Besides, the long-term temporal correspondence needs to be robust to view-point changes and severe occlusions, where these traditional sparse descriptors are incompetent. So, we expect to learn a dense temporal correspondence for all available frames.
In this paper, as shown in Fig. 1d, we propose a 3D video object detection paradigm with learnable long-term tempo-ral visual correspondence, called BA-Det. Specifically, the detector has two stages.
In the first stage, a CenterNet-style monocular 3D object detector is applied for single-frame object detection. After associating the same objects in the video, the second stage detector extracts RoI features for the objects in the tracklet and matches dense local fea-tures on the object among multi-frames, called the object-centric temporal correspondence learning (OTCL) module.
To make traditional object bundle adjustment (OBA) learn-able, we formulate featuremetric OBA. In the training time, with featuremetric OBA loss, the object detection and tem-poral feature correspondence are learned jointly. During in-ference, we use the 3D object estimation from the first stage as the initial pose and associate the objects with 3D Kalman
Filter. The object-centric bundle adjustment refines the pose and 3D box size of the object in each frame at the track-let level, taking the initial object pose and temporal feature correspondence from OTCL as the input. Experiment re-sults on the large-scale Waymo Open Dataset (WOD) show that our BA-Det could achieve state-of-the-art performance compared with other single-frame and multi-frame object detectors. We also conduct extensive ablation studies to demonstrate the effectiveness and efficiency of each com-ponent in our method.
In summary, our work has the following contributions:
• We present a novel object-centric 3D video object detec-tion approach BA-Det by learning object detection and temporal correspondence jointly.
• We design the second-stage object-centric temporal cor-respondence learning module and the featuremetric object bundle adjustment loss.
• We achieve state-of-the-art performance on the large-scale WOD. The ablation study and comparisons show the effectiveness and efficiency of our BA-Det. 2.