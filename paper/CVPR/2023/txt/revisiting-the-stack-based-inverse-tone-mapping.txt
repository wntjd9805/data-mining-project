Abstract
Current stack-based inverse tone mapping (ITM) meth-ods can recover high dynamic range (HDR) radiance by predicting a set of multi-exposure images from a single low dynamic range image. However, there are still some limitations. On the one hand, these methods estimate a fixed number of images (e.g., three exposure-up and three exposure-down), which may introduce unnecessary com-putational cost or reconstruct incorrect results. On the other hand, they neglect the connections between the up-exposure and down-exposure models and thus fail to fully
In this paper, we revisit the excavate effective features. stack-based ITM approaches and propose a novel method to reconstruct HDR radiance from a single image, which only needs to estimate two exposure images. At first, we de-sign the exposure adaptive block that can adaptively adjust the exposure based on the luminance distribution of the in-put image. Secondly, we devise the cross-model attention block to connect the exposure adjustment models. Thirdly, we propose an end-to-end ITM pipeline by incorporating the multi-exposure fusion model. Furthermore, we propose and open a multi-exposure dataset that indicates the opti-mal exposure-up/down levels. Experimental results show that the proposed method outperforms some state-of-the-art methods. 1.

Introduction
The luminance distribution in nature spans a wide range, from the starlight (10âˆ’5cd/m2) to the direct sunlight (108cd/m2). The low dynamic range (LDR) devices can not cover the full range of luminance of the real scene, and thus fail to reproduce the realistic visual experience. High dynamic range imaging (HDRI) technology [1] [26] can solve this problem, which takes multiple LDR images of the same scene with different shutter time, and then gener-ates the high dynamic range (HDR) image via the multi-exposure fusion (MEF) method [4] [19] [32]. However,
HDRI cannot handle the images that have already been cap-Figure 1. (a) The influences of different stack lengths demonstrate that the stack length is important to the quality of reconstructed
HDR image. However, the previous ITM methods [7] [11] [12]
[10] simply set a fixed length, which cannot be the optimal choice for every scene. (b) The comparison between the MES predicted by the state-of-the-art stack-based method [10] and the proposed method. Our method only needs to estimate two exposure im-ages to recover more realistic details in highlights and shadows and achieves a higher HDR-VDP-2.2 Q-score. The HDR images are tone mapped by [15] for LDR display. tured, such as a large number of LDR images and videos on the Internet. The inverse tone mapping (ITM) technique is thus designed to recover the HDR radiance from a single
LDR image, which is an ill-posed problem because the de-tails in the highlights and shadows are almost lost and dif-ficult to be restored. Fortunately, the development of deep learning [6] [7] provides a solution by learning and predict-ing the distribution of the lost information from the huge amount of training examples.
There are two main deep-learning-based ITM ap-proaches, i.e., direct mapping methods [6] [17] [22] [28]
[34] and stack-based methods [7] [10] [11] [12] [13]. The direct mapping methods learn an end-to-end model to re-cover the HDR radiance from the LDR input straightfor-wardly. By contrast, the stack-based methods simulate the
HDRI technology by increasing and decreasing the expo-sure value (EV) of the input image to obtain the multi-exposure stack (MES). Compared to the direct mapping methods, the stack-based methods simulate the generation process of HDR images in the real world and perform the learning stage in the same LDR space, which avoids the sophisticated changes between the LDR and HDR domain
[10] [11] [13].
The process of the previous stack-based based ITM methods can be roughly summarized in the following three main steps: (1) Training an up-exposure model and a down-(2) Gen-exposure model separately and independently. erating a fixed number of exposure adjusted images (e.g., three up-exposure and three down-exposure images) with the trained models. (3) Merging these images by a clas-sic multi-exposure fusion (MEF) approach [4]. However, each of these three steps has limitations that may cause in-accurate results. Specifically, (1) the process of increasing and decreasing the exposure should not be independent. For instance, when decreasing the exposure, some useful infor-mation of the under-exposed regions may become subtle, while the features in the opposite increasing process can compensate for it. (2) The times of exposure adjustment are important to the quality of reconstructed HDR images and a fixed length of MES will cause incomplete information recovery or introduce an unnecessary computational cost, as shown in Fig. 1 (a). (3) The classic MEF approaches cannot be integrated into the entire end-to-end training pro-cess. Although Kim et al. [10] proposed a differentiable
HDR synthesis layer, it is time-consuming and highly de-pends on the shutter time and therefore cannot be applied to general scenes.
In this paper, we propose a novel HDR reconstruction method with adaptive exposure adjustment, which provides an effective solution to the existing limitations in the field of stack-based ITM. At first, we design an efficient encoder equipped with the luminance-guided convolution (LGC) and cross-model attention block (CMAB) to extract useful information from local and cross-model features. With the help of CMAB, valid information on the entire up-exposure and down-exposure process can be fully explored to help their reconstruction. Secondly, the proposed up-exposure and down-exposure models can adjust the input LDR im-age only once to obtain the corresponding optimal expo-sure adjusted result. In this way, we can avoid the difficulty of determining the length of the MES and get the desired exposure adjustment directly. For this purpose, appropri-ate ground truth is needed to indicate the optimal exposure level. Therefore, we improve the SICE [2] dataset to form a new MES dataset with optimal exposure labels. On the other hand, since the exposure levels of the labels are dif-ferent, the models need to be able to generate different re-sults adaptively based on different inputs. Consequently, we devise the exposure adaptive block (EAB) to extract the global information and remap the features of the decoder.
The features extracted from EAB are used to normalize the features in the decoder, which results in the image-adaptive capability. Thirdly, we propose a lightweight and fast multi-exposure fusion model (MEFM), which can merge the ex-posure adjusted results with the input image into the de-sired HDR image and thus make the whole pipeline end-to-end. Furthermore, we propose progressive reconstruction loss and mask-aware generative adversarial loss to avoid the artifacts in the restored textures of over/under-exposed re-gions. As Fig. 1 (b) shows, the proposed method only needs to estimate two exposure values to recover the lost infor-mation in the shadows and highlights respectively, which is more concise and effective. Experiments show that our ITM algorithm outperforms the state-of-the-art ITM methods in both quantitative and qualitative evaluations.
This paper has the following main contributions: (1). We propose a novel stack-based ITM framework, which only needs to estimate two exposure images to form the MES. In this way, the lost information can be recov-ered more efficiently and precisely. Moreover, the exposure adaptive block is designed to adaptively adjust the exposure based on LDR inputs with different luminance distributions. (2). We connect the up-exposure and down-exposure models with the designed cross-model attention block, which can fully extract the effective features of the image regions with different luminance. (3). A lightweight and fast multi-exposure fusion net-work is proposed that can merge the generated results and makes the entire training pipeline end-to-end. (4). A more concise MES dataset is proposed and opened based on the SICE dataset [2], which contains the optimal exposure-up/down labels to train the adaptive exposure ad-justment networks. 2.