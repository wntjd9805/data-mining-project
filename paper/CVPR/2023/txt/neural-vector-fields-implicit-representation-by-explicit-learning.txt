Abstract
Deep neural networks (DNNs) are widely applied for nowadays 3D surface reconstruction tasks and such meth-ods can be further divided into two categories, which re-spectively warp templates explicitly by moving vertices or represent 3D surfaces implicitly as signed or unsigned dis-tance functions. Taking advantage of both advanced ex-plicit learning process and powerful representation abil-ity of implicit functions, we propose a novel 3D repre-sentation method, Neural Vector Fields (NVF). It not only adopts the explicit learning process to manipulate meshes directly, but also leverages the implicit representation of unsigned distance functions (UDFs) to break the barri-ers in resolution and topology. Specifically, our method first predicts the displacements from queries towards the surface and models the shapes as Vector Fields. Rather than relying on network differentiation to obtain direction fields as most existing UDF-based methods, the produced vector fields encode the distance and direction fields both and mitigate the ambiguity at “ridge” points, such that the calculation of direction fields is straightforward and differentiation-free. The differentiation-free characteristic enables us to further learn a shape codebook via Vector
Quantization, which encodes the cross-object priors, accel-erates the training procedure, and boosts model generaliza-tion on cross-category reconstruction. The extensive exper-iments on surface reconstruction benchmarks indicate that our method outperforms those state-of-the-art methods in different evaluation scenarios including watertight vs non-watertight shapes, category-specific vs category-agnostic reconstruction, category-unseen reconstruction, and cross-domain reconstruction. Our code is released at https:
//github.com/Wi-sc/NVF. 1.

Introduction
Reconstructing continuous surfaces from unstructured, discrete and sparse point clouds is an emergent but non-trivial task in nowadays robotics, vision and graphics appli-cations, since the point clouds are hard to be deployed into
Figure 1. Common 3D representations. Explicit representations: (a) point clouds, (b) meshes, (c) voxels.
Implicit representa-tions: (c) occupancy, (d) reconstruction from the signed distance functions, and (e) reconstruction from unsigned distance func-tions. Our method represents continuous surfaces through (f) vec-tor fields. (g) Vector fields can deform meshes (red) as explicit representation methods. the downstream applications without recovering to high-resolution surfaces [5, 7, 38, 42].
With the tremendous success of Deep Neural Networks (DNNs), a few DNN-based surface reconstruction meth-ods have already achieved promising reconstruction perfor-mance. These methods can be roughly divided into two cat-egories according to whether their output representations are explicit or implicit. As shown in Fig. 1, explicit rep-resentation methods including mesh and voxel based ones denote the exact location of a surface, which learn to warp templates [3, 4, 19, 26, 29, 68] or predict voxel grids [10, 30, 59]. Explicit representations are friendly to downstream ap-plications, but they are usually limited by resolution and topology. On the other hand, implicit representations such
as Occupancy and Signed Distance Functions (SDFs) repre-sent the surface as an isocontour of a scalar function, which receives increasing attention due to their capacity to repre-sent surfaces with more complicated topology and at arbi-trary resolution [12, 14, 22, 35, 44, 48]. However, most im-plicit representation methods usually require specific pre-processing to close non-watertight meshes and remove in-ner structures. To free from the above pre-processing re-quirements for implicit representation, Chibane et al. [15] introduced Neural Unsigned Distance Fields (NDF), which employs the Unsigned Distance Functions (UDFs) for neu-ral implicit functions (NIFs) and models continuous sur-faces by predicting positive scalar between query locations and the target surface. Despite certain advantages, UDFs require a more complicated surface extraction process than other implicit representation methods (e.g., SDFs). Such a process using Ball-Pivoting Algorithm [5] or gradient-based
Marching Cube [28, 83] relies on model differentiation dur-ing inference (i.e., differentiation-dependent). Moreover,
UDFs leave gradient ambiguities at “ridge” points, where the gradients1 used for surface extraction cannot accurately point at target points as illustrated by Fig. 2a.
In this work, we propose a novel 3D representation method, Neural Vector Fields (NVF), which leverages the explicit learning process of direct manipulation on meshes and the implicit representation of UDFs to enjoy the ad-vantages of both approaches. That is, NVF can directly manipulate meshes as those explicit representation meth-ods as Fig. 1g, while representing the shapes with arbi-trary resolution and topology as those implicit represen-tation methods. Specifically, NVF models the 3D shapes as vector fields and computes the displacement between a point q ∈ R3 and its nearest-neighbor point on the surface
ˆq ∈ R3 by using a learned function f (q) = ∆q = ˆq − q :
R3 ⇒ R3. Therefore, NVF could serve both as an implicit function and an explicit deformation function, since the dis-placement output of the function could be directly used to deform source meshes (i.e., Fig. 1g). In general, it encodes both distance and direction fields within vector fields, which can be straightforwardly obtained from the vector fields.
Different from existing UDF-based methods, our NVF representation avoids the comprehensive inference process by skipping the gradient calculation during the surface ex-traction procedure1, and mitigates ambiguities by directly learning displacements as illustrated by Fig. 2b. Such one-pass forward-propagation nature frees NVF from dif-ferentiation dependency, significantly reduces the infer-ence time and memory cost, and allows our model to learn a shape codebook consisting of un-differentiable dis-crete shape codes in the embedded feature space. The 1Learning-based methods calculate the gradients of distance fields via model differentiation. The opposite direction of gradients should point to the nearest-neighbor point on the target surface. (a) NDF [15]. (b) NVF.
Figure 2. Gradient ambiguities. (a) NDF [15] cannot guarantee to pull points onto surfaces (i.e., ambiguity of gradient), while (b) our NVF address this issue by direct displacement learning. learned shape codebook further provides cross-object priors to consequently improve the model generalization on cross-category reconstruction, and accelerates the training proce-dure as a regularization term during training. We use VQ as an example to demonstrate that the differentiation-free property of NVF provides more flexibility in model design in this paper.
We conduct extensive experiments on two surface reconstruction benchmark datasets: a synthetic dataset
ShapeNet [8] and a real scanned dataset MGN [6]. Besides category-specific reconstruction [15, 76] as demonstrated in most reconstruction methods, we also evaluate our frame-work by category-agnostic reconstruction, category-unseen reconstruction, and cross-domain reconstruction tasks to exploit the model generalization. Our experimental results indicate that our NVF can significantly reduce the inference time compared with other UDF-based methods as we avoid the comprehensive surface extraction step and circumvent the requirement of gradient calculation at query locations.
Also, using the shape codebook, we observe a significant performance improvement and a better model generaliza-tion across categories.
Our contributions are summarized as follows.
• We propose a 3D representation NVF for better 3D field representation, which bridges the explicit learn-ing and implicit representations, and benefits from both of their advantages. Our method can obtain the displacement of a query location in a differentiation-free way, and thus it significantly reduces the infer-ence complexity and provides more flexibility in de-signing network structures which may include non-differentiable components.
• Thanks to our differentiation-free design, we further propose a learned shape codebook in the feature space, which uses VQ strategy to provide cross-object priors.
In this way, each query location is encoded as a com-position of discrete codes in feature space and further used to learn the NVF.
• We conduct the extensive experiments to evaluate the effectiveness of our proposed method. It consistently shows promising performance on two benchmarks
across different evaluation scenarios: water-tight vs non-water-tight shapes, category-specific vs category-agnostic reconstruction, category-unseen reconstruc-tion, and cross-domain reconstruction. 2.