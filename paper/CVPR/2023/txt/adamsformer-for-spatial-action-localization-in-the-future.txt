Abstract
Predicting future action locations is vital for applica-tions like human-robot collaboration. While some computer vision tasks have made progress in predicting human ac-tions, accurately localizing these actions in future frames remains an area with room for improvement. We intro-duce a new task called spatial action localization in the future (SALF), which aims to predict action locations in both observed and future frames. SALF is challenging be-cause it requires understanding the underlying physics of video observations to predict future action locations accu-rately. To address SALF, we use the concept of NeuralODE, which models the latent dynamics of sequential data by solving ordinary differential equations (ODE) with neural networks. We propose a novel architecture, AdamsFormer, which extends observed frame features to future time hori-zons by modeling continuous temporal dynamics through
ODE solving. Specifically, we employ the Adams method, a multi-step approach that efficiently uses information from previous steps without discarding it. Our extensive experi-ments on UCF101-24 and JHMDB-21 datasets demonstrate that our proposed model outperforms existing long-range temporal modeling methods by a significant margin in terms of frame-mAP. 1.

Introduction
Human action understanding is essential in computer vision, especially for applications like VR/AR [61, 64], robotics [57, 60], and autonomous vehicles [28, 38]. These applications help users by interpreting intentions or per-ceiving others’ actions in the environment. Considerable progress has been made in human action perception, in-cluding action recognition [7, 10, 11], temporal action lo-calization [3, 36], and spatio-temporal action localization
[2, 30, 42, 52].
Lately, predicting and anticipating human actions, such as early action prediction [13, 23, 62], action anticipa-tion [15, 16], and hand or pedestrian trajectory prediction
Figure 1. Future Spatial Action Localization (SALF) aims to iden-tify diverse action patterns in both observed and future frames.
Green and red boxes represent observed and future frames, while blue bounding boxes indicate predicted action locations.
[40,45,47], have gained attention due to the increasing need to prepare for future events. While progress has been made in predicting human actions, further exploration is needed in localizing future actions, which is critical for various ap-plications. For example, anticipatory behavior is essential for effective collaboration in human-robot interaction [57].
Accurately predicting future activity locations enables robot agents to support humans more efficiently.
In this work, we introduce Spatial Action Localization in the Future (SALF), a novel task that expands upon tra-ditional spatio-temporal action localization. SALF aims to predict spatial locations and categorize actions in both long-term future and past observations, as illustrated in Fig. 1.
By enabling models to recognize and classify present ac-tions while anticipating and localizing future actions, SALF significantly enhances real-time decision-making and adap-tive responses in complex environments. As demonstrated in Table 1, SALF uniquely focuses on diverse, highly non-linear motion patterns across various action categories, set-ting it apart from related tasks like pedestrian or hand tra-jectory prediction. Additionally, SALF differs in input and target, utilizing only video input and predicting multiple bounding boxes and action categories for both future and observed frames.
In contrast, trajectory predictions gen-erally estimate the future path of specific objects, such as hands or pedestrians, without requiring bounding boxes.
† Work done while at Honda Research Institute USA.
To address the challenges of SALF, we leverage the con-Task
Input
Video BBox
Pedestrian prediction [47] ✓
Pedestrian prediction [45]
Hand prediction [40]
SALF (ours)
✓
✓
✓
✓
✓
Target
Trajectory
Bbox (F)
Bbox (F)
Center (F)
Bbox (O & F)
Classification
Intention (Binary)
--Actions
Table 1. Comparison between SALF and trajectory predictions.
‘Bbox’ signifies the bounding box, while ‘O’ and ‘F’ represent observation and future, respectively cept of NeuralODE [6]. Recent works on Neural ODE
[6,49,67] and its applications [26,27,35,43,65] demonstrate that Neural ODE successfully models continuous sequen-tial data by solving ordinary differential equations (ODE) with neural networks. Neural ODE has an advantage over other temporal modeling methods like transformers [58] or
RNNs [21] in that it can model the underlying physics of sequential data. We adapt the concept of Neural ODE to predict information for future frames from observations to address the proposed SALF.
From this motivation, We propose AdamsFormer, a net-work designed to detect spatial locations of the action for both the observed previous frames and unobserved future frames. The proposed model predicts future action loca-tions by extrapolating observed frames’ latent features to the future time horizon we want to predict. With the ex-trapolated latent features of future frames, we can predict the locations of the action and their corresponding cate-gories. When solving ODE, we adopt the multi-step method (Adams method), which is more robust to noisy conditions than single-step methods such as Euler or Runge-Kutta. A single-step method that uses information from only the pre-vious step can be easily affected by noise.
In contrast, a multi-step way attends several previous steps to predict the future; thus, it gains efficiency and robustness by using the information from previous frames rather than discarding it.
Using a toy example, we compare multi-step and single-step methods in Fig. 2.
We conduct extensive experiments on action video datasets UCF101-24 [54] and JHMDB-21 [32] to demon-strate the advantage of the proposed architecture and bench-mark the existing long-range temporal dependency mod-eling algorithms on SALF. We observe that AdamsFormer outperform other state-of-the-art models, thus demonstrat-ing its efficacy. We also provide a deeper analysis to pro-vide intuition to researchers on how to improve the model performance on SALF.
In summary, our contributions are as follows,
• We present a novel task called Spatial Action Local-ization in the Future (SALF), which aims to identify the spatial boundaries of actions in both observed and future frames.
• To address the SALF task, we introduce Adams-Former, an innovative architecture that predicts action locations in future frames by extrapolating the latent state using the Adams method to solve ODEs.
• Our extensive experimental results demonstrate that
AdamsFormer significantly outperforms existing state-of-the-art methods for long-range feature modeling in the SALF task. 2.