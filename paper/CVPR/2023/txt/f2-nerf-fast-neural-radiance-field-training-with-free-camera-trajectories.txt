Abstract
This paper presents a novel grid-based NeRF called F2-NeRF (Fast-Free-NeRF) for novel view synthesis, which enables arbitrary input camera trajectories and only costs a few minutes for training. Existing fast grid-based NeRF training frameworks, like Instant-NGP, Plenoxels, DVGO, or TensoRF, are mainly designed for bounded scenes and rely on space warping to handle unbounded scenes. Existing two widely-used space-warping methods are only designed for the forward-facing trajectory or the 360◦ object-centric trajectory but cannot process arbitrary trajectories. In this paper, we delve deep into the mechanism of space warping to handle unbounded scenes. Based on our analysis, we further propose a novel space-warping method called perspective warping, which allows us to handle arbitrary trajectories in the grid-based NeRF framework. Extensive experiments demonstrate that F2-NeRF is able to use the same perspec-tive warping to render high-quality images on two standard datasets and a new free trajectory dataset collected by us.
Project page: totoro97.github.io/ projects/ f2-nerf . 1.

Introduction
The research progress of novel view synthesis has ad-vanced drastically in recent years since the emergence of the
Neural Radiance Field (NeRF) [24, 42]. Once the training is done, NeRF is able to render high-quality images from novel camera poses. The key idea of NeRF is to represent the scene as a density field and a radiance field encoded by Multi-layer Perceptron (MLP) networks, and optimize the MLP networks with the differentiable volume rendering technique. Though NeRF is able to achieve photo-realistic rendering results, training a NeRF takes hours or days due to the slow optimization of deep neural networks, which limits its application scopes.
Recent works demonstrate that grid-based methods, such as Plenoxels [57], DVGO [38], TensoRF [6], and Instant-*Equal contribution.
Figure 1. Top: (a) Forward-facing camera trajectory. (b) 360◦ object-centric camera trajectory. (c) Free camera trajectory. In (c), the camera trajectory is long and contains multiple foreground objects, which is extremely challenging. Bottom: Rendered images of the state-of-the-art fast NeRF training methods and F2-NeRF on a scene with a free trajectory.
NGP [25], enable fast training a NeRF within a few minutes.
However, the memory consumption of such grid-based rep-resentations grows in cubic order with the size of the scene.
Though various techniques, such as voxel pruning [38, 57], tensor decomposition [6] or hash indexing [25], are proposed to reduce the memory consumption, these methods still can only process bounded scenes when grids are built in the original Euclidean space.
To represent unbounded scenes, a commonly-adopted strategy is to use a space-warping method that maps an un-bounded space to a bounded space [3, 24, 61]. There are typically two kinds of warping functions. (1) For forward-facing scenes (Fig. 1 (a)), the Normalized Device Coordinate (NDC) warping is used to map an infinitely-far view frus-tum to a bounded box by squashing the space along the z-axis [24]; (2) For 360◦ object-centric unbounded scenes (Fig. 1 (b)), the inverse-sphere warping can be used to map an infinitely large space to a bounded sphere by the sphere inversion transformation [3, 61]. Nevertheless, these two warping methods assume special camera trajectory patterns and cannot handle arbitrary ones.
In particular, when a trajectory is long and contains multiple objects of interest, called free trajectories, as shown in Fig. 1 (c), the quality of rendered images degrades severely.
The performance degradation on free trajectories is caused by the imbalanced allocation of spatial representation capacity. Specifically, when the trajectory is narrow and long, many regions in the scenes are empty and invisible to any input views. However, the grids of existing methods are regularly tiled in the whole scene, no matter whether the space is empty or not. Thus, much representation capacity is wasted on empty space. Although such wasting can be allevi-ated by using the progressive empty-voxel-pruning [38, 57], tensor decomposition [6] or hash indexing [25], it still causes blurred images due to limited GPU memory. Furthermore, in the visible spaces, multiple foreground objects in Fig. 1 (c) are observed with dense and near input views while back-ground spaces are only covered by sparse and far input views.
In this case, for the optimal use of the spatial representation of the grid, dense grids should be allocated for the fore-ground objects to preserve shape details and coarse grids should be put in background space. However, current grid-based methods allocate grids evenly in the space, causing the inefficient use of the representation capacity.
To address the above problems, we propose F2-NeRF (Fast-Free-NeRF), the first fast NeRF training method that accommodates free camera trajectories for large, unbounded scenes. Built upon the framework of Instant-NGP [25], F2-NeRF can efficiently be trained on unbounded scenes with diverse camera trajectories and maintains the fast conver-gence speed of the hash-grid representation.
In F2-NeRF , we give the criterion on a proper warping function under an arbitrary camera configuration. Based on this criterion, we develop a general space-warping scheme called the perspective warping that is applicable to arbitrary camera trajectories. The key idea of perspective warping is to first represent the location of a 3D point p by the concate-nation of the 2D coordinates of the projections of p in the input images and then map these 2D coordinates into a com-pact 3D subspace space using Principle Component Analysis (PCA) [51]. We empirically show that the proposed perspec-tive warping is a generalization of the existing NDC warp-ing [24] and the inverse sphere warping [3, 61] to arbitrary trajectories in a sense that the perspective warping is able to handle arbitrary trajectories while could automatically degenerate to these two warping functions in forward-facing scenes or 360◦ object-centric scenes. In order to implement the perspective warping in a grid-based NeRF framework, we further propose a space subdivision algorithm to adap-tively use coarse grids for background regions and fine grids for foreground regions.
We conduct extensive experiments on the unbounded forward-facing dataset, the unbounded 360◦ object-centric dataset, and a new unbounded free trajectory dataset. The experiments show that F2-NeRF uses the same perspective warping to render high-quality images on the three datasets with different trajectory patterns. On the new Free dataset with free camera trajectories, our method outperforms base-line grid-based NeRF methods,while only using ∼12 min-utes on training on a 2080Ti GPU. 2.