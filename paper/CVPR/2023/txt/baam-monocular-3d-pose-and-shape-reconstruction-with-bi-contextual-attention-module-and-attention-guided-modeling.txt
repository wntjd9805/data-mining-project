Abstract 3D trafﬁc scene comprises various 3D information about car objects, including their pose and shape. However, most recent studies pay relatively less attention to recon-structing detailed shapes. Furthermore, most of them treat each 3D object as an independent one, resulting in losses of relative context inter-objects and scene context reﬂect-ing road circumstances. A novel monocular 3D pose and shape reconstruction algorithm, based on bi-contextual at-tention and attention-guided modeling (BAAM), is proposed in this work. First, given 2D primitives, we reconstruct 3D object shape based on attention-guided modeling that considers the relevance between detected objects and ve-hicle shape priors. Next, we estimate 3D object pose through bi-contextual attention, which leverages relation-context inter objects and scene-context between an object and road environment. Finally, we propose a 3D non-maximum suppression algorithm to eliminate spurious ob-jects based on their Bird-Eye-View distance. Extensive experiments demonstrate that the proposed BAAM yields state-of-the-art performance on ApolloCar3D. Also, they show that the proposed BAAM can be plugged into any mature monocular 3D object detector on KITTI and sig-niﬁcantly boost their performance. Code is available at https://github.com/gywns6287/BAAM. 1.

Introduction 3D trafﬁc scene understanding provides enriched de-scriptions of the dynamic objects, e.g., 3D shape, pose, and location, compared to representing objects as bounding boxes. 3D visual perception is crucial for the autonomous driving system to develop downstream tasks such as mo-tion prediction and planning, and aids to faithfully recon-∗Corresponding author
†These authors contributed equally to this work.
Figure 1. Reconstructed 3D scene with rough bounding box (right up) and with detailed shape (right down). For better 3D recon-struction, detailed 3D shapes are needed rather than the simple 3D bounding boxes. struct the trafﬁc scene from recorded data. To acquire pre-cise 3D information, some prior arts have relied on speciﬁc devices such as LiDAR [3,10,42] and stereo vision [26,44].
However, as the system becomes complex and costly, it quickly reaches the limit to scalability. To contrary, areas of study about 3D perception using monocular vision have been receiving attention due to its simplicity and cost efﬁ-ciency [4, 7, 19, 29, 33, 50, 51].
Monocular 3D perception is an ill-posed problem in that projective geometry inherently loses depth information. In particular, trafﬁc scene contains partially observable ob-jects, and shows ﬁne-grained classes which are visually confusing. Pseudo-LiDAR [49] presents a feasible solution of the image based 3D object detection. To reconstruct 3D poses of the objects, many studies [25, 27, 30, 33, 40, 41, 50, 51] focus on using geometry constraints between 2D and 3D. Yet, it is less studied in the line of research that leverage relative context among the objects and global scene context depending on road environment.
Figure 1 compares the reconstructed 3D scene with 3D bounding boxes and detailed 3D shapes. With a detailed 3D shape, we render the trafﬁc scene in realistic and provide intuitive representations of the objects. Despite scale ambi-guity of the monocular 3D perception, 3D mesh provides a
strong clue to align instances’ scales and orientations. Con-currently, there have been many attempts [8, 20, 22, 31, 45, 46] to reconstruct the 3D shape of human objects. These methods mainly focus on learning PCA-basis to represent
Inspired by human shape reconstruction, human shapes. recent methods [21, 24] also design PCA-basis for vehicle shape reconstruction. However, as pointed out in [1, 34],
PCA-basis often loses object details and thus leads to un-satisfactory reconstruction.
In this work, we propose a novel 3D pose and shape estimation algorithm, utilizing bi-contextual attention and attention-guided modeling (BAAM). Given a monocular
RGB image, the proposed BAAM ﬁrst extracts various 2D primitive features such as appearance, position, and size.
And it constructs object features to embed internal object structures by aggregating primitive features. For detailed object shapes, we introduce shape priors consisting of the mean shape and various template offsets to represent de-tails of vehicle shapes. Then, BAAM reconstructs objects’ 3D shapes as mesh structures with attention-guided mod-eling, which combines shape prior and individual object features based on their relevance. For accurate pose es-timation, we present the notion of bi-contextual attention consisting of relation-context and scene-context, which de-scribe the relationship inter objects and between object and road environment, respectively. Based on this rich infor-mation, BAAM integrates object features to predict ob-jects’ 3D poses through a carefully designed bi-contextual attention module. Finally, we proposed a novel 3D non-maximum suppression (NMS) algorithm that effectually re-moves spurious objects based on Bird-Eye-view (BEV) ge-ometry. Extensive experiments on Apollocar3D [43] and
KITTI [12] datasets demonstrate the effectiveness of the proposed BAAM algorithm. Also, experiments show that the proposed method signiﬁcantly outperforms state-of-the arts [21, 43] in both pose and shape estimation. The main contributions of our work are four folds:
• We propose the attention-guided modeling that recon-structs objects’ shapes based on the relevance between objects and vehicle shape priors.
• We proposed the bi-contextual attention module that estimates objects’ pose by exploiting relation-context inter objects and scene-context between an object and road environment.
• We also develop the novel 3D non-maximum suppres-sion algorithm to remove spurious objects based on their Bird-Eye-view distance.
• The proposed BAAM algorithm achieves the state-of the art performance on ApolloCar3D [43]. Also, ex-periments on KITTI [12] show that the proposed al-gorithm can signiﬁcantly improve the performance of existing monocular 3D detectors. 2.