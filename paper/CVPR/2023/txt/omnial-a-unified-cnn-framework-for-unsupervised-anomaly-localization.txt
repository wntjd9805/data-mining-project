Abstract
Unsupervised anomaly localization and detection is cru-cial for industrial manufacturing processes due to the lack of anomalous samples. Recent unsupervised advances on industrial anomaly detection achieve high performance by training separate models for many different categories. The model storage and training time cost of this paradigm is high. Moreover, the setting of one-model-N-classes leads to fearful degradation of existing methods.
In this pa-per, we propose a uniﬁed CNN framework for unsuper-vised anomaly localization, named OmniAL. This method conquers aforementioned problems by improving anomaly synthesis, reconstruction and localization. To prevent the model learning identical reconstruction, it trains the model with proposed panel-guided synthetic anomaly data rather than directly using normal data. It increases anomaly re-construction error for multi-class distribution by using a network that is equipped with proposed Dilated Channel and Spatial Attention (DCSA) blocks. To better localize the anomaly regions, it employs proposed DiffNeck between reconstruction and localization sub-networks to explore multi-level differences. Experiments on 15-class MVTecAD and 12-class VisA datasets verify the advantage of proposed
OmniAL that surpasses the state-of-the-art of uniﬁed mod-els. On 15-class-MVTecAD/12-class-VisA, its single uniﬁed model achieves 97.2/87.8 image-AUROC, 98.3/96.6 pixel-AUROC and 73.4/41.7 pixel-AP for anomaly detection and localization respectively. Besides that, we make the ﬁrst at-tempt to conduct a comprehensive study on the robustness of unsupervised anomaly localization and detection meth-ods against different level adversarial attacks. Experiential results show OmniAL has good application prospects for its superior performance. 1.

Introduction
In real industrial scenarios, the location of anomaly
[22, 26] reveals important information, such as defective types and degrees. It is essential not only to inspect whether a sample is defective but also to know where the speciﬁc anomaly regions are. Since anomaly appearance is inex-haustible, it is almost impossible and infeasible to collect and manually annotate all kinds of abnormal data. Thus, only normal samples are available for training a detector that is robust enough to ﬁnd out unseen anomalies during in-ference phase. Considering the diversity of classes and var-ious types of one class, the conventional training paradigm of N models for N classes, as shown in Fig.1a, may not be the best solution. The model storage and training time cost increase with the number of classes. As shown in
Fig.1b, existing method severely degrades anomaly local-Figure 2. Problem analysis. The ﬁnal failure may caused by reconstruction and localization. ization performance if the training paradigm changes to one model for N classes. Therefore, a robust uniﬁed framework for unsupervised anomaly localization is highly demanded for intelligent industrial.
With the limitation of available training data, many ap-pealing unsupervised approaches [14, 18, 35, 38] using syn-thesized anomaly data are proposed. These approaches gen-erate anomalous instances to inspire the anomaly detector to learn discriminative features. Their experiments show that the realisticness of generated anomalous instances had a strong impact on the quality of anomaly localization. How-ever, none of these methods consider the training paradigm of one model for N classes. When switching to the uniﬁed training paradigm, they are more prone to learn an identical short-cut and fail to discriminate the anomaly.
With the normal and synthesized anomalous sam-ples, recent unsupervised learning methods train a deep anomaly detector by either a distance-based [6, 14, 19–21, 27] or reconstruction-based [2, 9, 35, 36, 38] way. The reconstruction-based architectures [35, 38] are supposed to reconstruct normal images more accurately than the un-seen anomalous. The anomaly localization is then cal-culated from the reconstruction error between the original and reconstructed versions of the input image, as shown in
Fig.2a. The prediction of anomaly location is not only based on the reconstruction quality but also the ability of spot-ting the reconstruction error. The typical reconstruction-based method JNLD [38] learns a joint representation of an anomalous image and its anomaly-free reconstruction, while simultaneously learning a decision boundary between normal and simulated anomalous examples. As shown in
Fig.2b and Fig.2c, under the uniﬁed setting, JNLD [38] fails to produce correct results either because of the reconstruc-tion failure or the localization failure.
To conquer aforementioned problems, we propose a novel uniﬁed framework OmniAL for effectively localiz-ing anomaly pixels of different classes only by using a sin-gle model. OmniAL uses a panel-guided anomaly synthe-sis method that controls the portion of normal and anomaly regions for each training sample. By doing this, OmniAL blocks the chance of learning identical shortcut from the source. To increase the anomaly reconstruction error for multi-class distribution, OmniAL constructs a reconstruc-tion and a localization sub-networks that are equipped with proposed Dilated Channel and Spatial Attention (DCSA) blocks. To better localize the anomaly regions, OmniAL employs a DiffNeck module between the reconstruction and localization sub-networks to explore multi-level reconstruc-tion errors. As shown in Fig.1 and Fig.2, OmniAL learns a single uniﬁed model for multiple classes that produces high quality reconstruction and precise anomaly localiza-tion. Furthermore, we conduct an exhaustive evaluation of reconstruction and localization performance against to multi-level adversarial attacks.
In summary, we make following main contributions:
• We construct a uniﬁed CNN framework OmniAL for unsupervised anomaly localization that is equipped with proposed panel-guided anomaly synthesis, DCSA block, and DiffNeck module. OmniAL achieves supe-rior performance for anomaly localization on challeng-ing MVTecAD [1] and VisA [39] datasets compared to the state-of-the-art.
• By preventing model from learning identical re-construction, our proposed panel-guided anomaly improve-synthesis method also brings substantial ment for existing methods under the uniﬁed setting.
It boosts the image-AUROC/pixel-AUROC/pixel-AP from 88.7/87.1/49.4 to 92.5/94.5/57.4 for Draem [35].
• We make a comprehensive study on the robustness of separate/uniﬁed anomaly localization methods against different level adversarial attacks. Our synthesized
Figure 3. Framework of OmniAL. It consists of panel-guided anomaly synthesis, reconstruction and localization. Anomaly synthesis is based on anomaly panel and three variants of the Just Noticeable Distortion (JND) map. The synthetic anomaly is reconstructed into normal image and corresponding JND map by the Dilated Channel Spatial Attention (DCSA) modules equipped reconstruction sub-network. The localization sub-network with a DiffNeck module localizes the anomaly regions by exploring the difference between reconstructed and original data. adversarial datasets exhibit strong attack capability against anomaly detection, reconstruction and local-ization, also helping to analyse the risks of existing methods. 2.