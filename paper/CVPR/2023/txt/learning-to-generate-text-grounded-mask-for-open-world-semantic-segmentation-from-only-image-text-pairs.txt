Abstract
We tackle open-world semantic segmentation, which aims at learning to segment arbitrary visual concepts in images, by using only image-text pairs without dense an-notations. Existing open-world segmentation methods have shown impressive advances by employing contrastive learn-ing (CL) to learn diverse visual concepts and transferring the learned image-level understanding to the segmenta-tion task. However, these CL-based methods suffer from a train-test discrepancy, since it only considers image-text alignment during training, whereas segmentation requires region-text alignment during testing. In this paper, we pro-posed a novel Text-grounded Contrastive Learning (TCL) framework that enables a model to directly learn region-text alignment. Our method generates a segmentation mask for a given text, extracts text-grounded image embedding from the masked region, and aligns it with text embedding via
TCL. By learning region-text alignment directly, our frame-work encourages a model to directly improve the quality of generated segmentation masks. In addition, for a rigorous and fair comparison, we present a unified evaluation pro-tocol with widely used 8 semantic segmentation datasets.
TCL achieves state-of-the-art zero-shot segmentation per-formances with large margins in all datasets. Code is avail-able at https://github.com/kakaobrain/tcl. 1.

Introduction
Open-world semantic segmentation aims to identify the arbitrary semantic concepts in the open world1. Conven-tional semantic segmentation aims to learn segmentation capability for the small number of pre-defined target cat-egories, whereas open-world semantic segmentation ad-dresses unrestricted arbitrary categories or free-form texts.
Such segmentation capability over unlimited targets drasti-1This setting is often called both open-world and open-vocabulary. In this paper, we mainly refer to this setting as open-world for clarity.
Figure 1. Open-world segmentation performance comparison.
The proposed method remarkably outperforms existing methods in all 8 segmentation benchmark datasets. cally extends the application scope of the open-world seg-mentation models.
The first challenge for open-world segmentation is how to learn arbitrary concepts, beyond pre-defined cate-gories. Inspired by the success of CLIP [23], previous ap-proaches [11, 17–19, 28, 30, 33] tackle this challenge by ex-ploiting massive web-crawled image-text paired data; since the texts in web-crawled data contain a global semantic de-scription for the paired images, the large-scale image-text pairs can provide rich knowledge for arbitrary semantic cat-egories. However, there still remains another challenge in how to achieve precise localization of arbitrary concepts without dense annotations. There are several approaches that simply address this issue using dense annotation (seg-mentation masks) in addition to image-text pairs [11,17,18].
The dense annotation helps to improve segmentation perfor-using the mask, and applies contrastive learning between text and grounded region. By re-formulating the contrastive loss to be directly affected by the segmentation quality, TCL enables end-to-end training of the grounder and directly im-proves the quality of region-text level alignment. We also present a unified evaluation protocol using widely used 8 semantic segmentation datasets and compare existing meth-ods in the same setting. As a result, TCL achieves state-of-the-art zero-shot segmentation performance with large mar-gins in all datasets, as shown in Fig. 1.
Our main contributions are summarized as follows:
• We introduce a novel framework for open-world seg-mentation, named Text-grounded Contrastive Learn-ing (TCL), which enables learning region-text align-ment directly without thus learning to generate more precise segmentation masks through only image-text pairs. train-test discrepancy,
• We present a unified evaluation protocol and re-evaluate recent open-world segmentation models for a fair and direct comparison.
• We achieve the new state-of-the-art zero-shot segmen-tation performance on 8 segmentation datasets with large margins compared to existing methods. 2.