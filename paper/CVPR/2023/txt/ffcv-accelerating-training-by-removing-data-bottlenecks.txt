Abstract
We present FFCV, a library for easy and fast machine learning model training. FFCV speeds up model training by eliminating (often subtle) data bottlenecks from the training process. In particular, we combine techniques such as an ef-ﬁcient ﬁle storage format, caching, data pre-loading, asyn-chronous data transfer, and just-in-time compilation to (a) make data loading and transfer signiﬁcantly more efﬁcient, ensuring that GPUs can reach full utilization; and (b) of-ﬂoad as much data processing as possible to the CPU asyn-chronously, freeing GPU cycles for training. Using FFCV, we train ResNet-18 and ResNet-50 on the ImageNet dataset with a state-of-the-art tradeoff between accuracy and train-ing time. For example, across the range of ResNet-50 mod-els we test, we obtain the same accuracy as the best base-lines in half the time. We demonstrate FFCV’s performance, ease-of-use, extensibility, and ability to adapt to resource constraints through several case studies. Detailed installa-tion instructions, documentation, and Slack support chan-nel are available at https://ffcv.io/. 1.

Introduction
What’s the limiting factor in faster model training? Hint: it isn’t always the GPUs. When training a machine learning model, the life cycle of an individual example spans three stages: reading the example into memory, processing the example in memory, and ﬁnally updating model parameters with the example on GPU (e.g. by calculating and then fol-lowing the gradient). The stage with the lowest throughput determines the overall learning system’s throughput.
Our investigations (and others’ [Mohan et al.(2021)]) show that in practice the limiting factor is often not com-puting model updates but rather the data reading and data processing stages. Indeed, in standard training setups, the
GPUs can spend a majority of cycles just waiting for inputs to process!
*Equal contribution.
Figure 1. Accuracy vs. training time when training a ResNet-50 on 8 A100s. The FFCV accuracy/training time tradeoff outperforms all baselines. As an example, we can train ImageNet to 75% accu-racy in less than 20 minutes on a single machine.
To better saturate GPUs and thereby increase training throughput, we present FFCV, a system designed to reduce data loading and processing bottlenecks while remaining simple to use. FFCV operates in two successive stages: pre-processing and train-time loading.
In the ﬁrst stage, FFCV preprocesses the dataset into a format more amenable to high throughput loading. Then, in the train-time loading stage, FFCV’s data loader replaces the original learning system’s data loader without requiring any other implementation changes.
Together, FFCV data preprocessing and the FFCV data loader can drastically increase training speeds without any learning algorithm modiﬁcations. To demonstrate, we train machine learning models for a number of tasks much faster than previous general purpose data loaders can support, in-cluding single-node ResNet-50 [He et al.(2015)] training (2x faster than the previous state-of-the-art to reach the same accuracies) and parallel ResNet-18 training (we can train 14 models per minute on an 8 GPU machine). While
FFCV improves performance on most GPUs, its effect is most pronounced on faster GPUs, which require higher throughput data loading to saturate available compute ca-pacity. We expect FFCV will only increase in utility as new
GPUs become faster.
Contributions. We introduce FFCV, a drop-in, general purpose training system for high throughput data loading.
Using FFCV requires no algorithmic changes, and involves
a nearly identical API to standard data loading systems (e.g., the default PyTorch data loader). FFCV automatically handles the necessary data transfer, memory management, and data conversion work that users usually manually opti-mize (or leave to suboptimal defaults). FFCV also replaces the default data preprocessing and augmentation pipeline with one that is more efﬁcient due to (a) just-in-time com-pilation to machine code and (b) highly optimized mem-ory management. Comparing with strong baselines, we ﬁnd that FFCV drastically speeds up a number of standard appli-cations:
• Faster ImageNet Training. We greatly improve Ima-geNet single node training throughput, achieving state-of-the-art speed-accuracy tradeoffs. We reach the same accuracy as the best public baselines in less than half the time.
• Faster bootstrapping and grid search. We enable faster large-scale grid search by supporting same-machine, different-GPU training without any through-put penalty.
Figure 2. Time taken per set of stages in ImageNet training (me-dian over three runs). ImageFolder refers to the default PyTorch data loader used to load ImageNet. We ﬁnd that data loading, in particular data processing, is the major bottleneck of standard training. The idealized training time, or the training time we would obtain with perfect data loading, is almost 30 times smaller than the time required to just process all the training images. In the top column, FFCV reduces the overall training time to almost the idealized time by removing the data reading and processing bot-tlenecks. ing setup, and, furthermore, by ﬁxing data loading we could achieve 30 times faster model training. Below we explore this data loading bottleneck in further detail.
• Faster network ﬁlesystem-based training. Espe-cially in cloud computing environments where net-work ﬁle systems are commonplace, data reading can greatly bottleneck learning systems. FFCV enables faster data loading in a realistic read-constrained en-vironment.
Data reading throughput. We begin by only benchmark-ing data read throughput, measuring how long the data loader takes to read the entire dataset without performing any processing. As the machine we test on can cache the entire ImageNet dataset into memory, the data reading step is not a bottleneck (cf. Figure 2): it takes only 75 seconds.
• Accelerating tasks beyond computer vision. We demonstrate FFCV’s ability to speed up almost any data loading task by using it as a drop-in replacement to the default PyTorch data loader in a GPU-enabled sparse regression solver. 2. Identifying Bottlenecks in Training
What makes a machine learning training system “slow” or “fast”? The answer varies by task, algorithm, implemen-tation, and computing equipment available at train time.
Model training is best thought of as a pipeline of discrete steps: data reading, data processing, and GPU computing that executes the learning algorithm.
To understand which of these steps bottlenecks training in practice, we study a standard task commonly used to benchmark training speeds [Coleman et al.(2017), Mattson et al.(2020)], namely ImageNet [Deng et al.(2009)] train-ing. As a speciﬁc setup, we investigate the PyTorch Im-ageNet training example with the standard PyTorch Ima-geNet data loader, running on a standard AWS instance for
GPU-based learning: p4d.24xlarge machines, which have 8 A100 GPUs, 96 vCPUs, and enough RAM to ﬁt the Ima-geNet training set into memory. We benchmark each part of the system’s throughput; Figure 2 shows our results. Over-all, we ﬁnd that data loading bottlenecks this standard train-Data processing throughput. To check whether data processing is a bottleneck, we measure how long the data loader takes to read the entire dataset while also perform-ing processing: JPEG decoding, random cropping/resizing, random ﬂipping, and normalization. We ﬁnd that process-ing is a major bottleneck: adding processing to reading greatly increases loading time to 1200 seconds from the 70 seconds that loading alone took (see Figure 2).
Full training throughput. Finally, we measure the entire system’s throughput, including the learning stage. We ﬁnd that adding the learning stage does not greatly change the time taken to iterate through the whole dataset (cf. Fig-ure 2). The fact that our throughput does not decrease despite adding learning on the GPUs indicates that the data loading/processing subsystem cannot supply data fast enough to saturate the GPUs. Indeed, as further corrobo-ration, we simulate how fast model throughput could be by benchmarking our training process on a ﬁxed data vector (here, we require no data loading). Our throughput in this idealized setting, shown in the same ﬁgure above, is much higher, and shows that we could obtain around 30x faster training with optimal data loading.
3. Eliminating Data Bottlenecks
Now, our focus turns to: how can we design a better data loading system? To maximize performance, FFCV manages the entire data management pipeline, from the ﬁle format used to store the training data all the way to data augmenta-tions used at training time. Focusing on one step of the data loading pipeline at a time, we show how FFCV’s implemen-tation circumvents issues in existing solutions to efﬁciently load data. 3.1. Challenge #1: Storing a Machine Learning
Dataset
To eliminate data bottlenecks in the machine learning pipeline we start with the data format. There are already multiple existing ﬁle formats designed to store machine learning datasets: the most common of these formats (and indeed, the default one in PyTorch) is the ﬁle-based format, where one stores each example as an individual ﬁle. In the context of image recognition, for example, one saves each example as its own (typically JPEG-compressed) image ﬁle, and uses the enclosing folder to encode the label. The ﬁle-based approach has some advantages—most notably, users can intuitively interact with the examples on an individual level (e.g., they can open any training image in a standard image viewer). However, this format is not at all optimized for performance, and comes with several fundamental draw-backs.
FFCV introduces its own new ﬁle format: the .beton
ﬁle.
In the following, we discuss the different consid-erations involved in designing this ﬁle format, and show that FFCV’s new ﬁle format circumvents issues both with
ﬁle-based formats as well as existing specialized solutions (namely, WebDataset, TFRecord, and MXNet RecordIO).
Reducing ﬁlesystem strain. To reduce ﬁlesystem strain, existing specialized ﬁle formats either group data examples in shards (WebDataset) or concatenate all the data into a single ﬁle (TFRecord, RecordIO). FFCV adopts the latter option, but goes even further—by organizing the dataset into pages (at the cost of some wasted space), it eliminates random read penalties by making it easy to read data in large chunks. FFCV (along with TFRecord and RecordIO) datasets are also easier to share than sharded data formats (e.g., WebDataset), since one only needs to transport a sin-gle ﬁle. maximal ﬂexibility, and use an abstract “Field” class that enables users to store arbitrary data modalities (with built in support for vision, text, tabular, and more), and even eas-ily extend FFCV’s capabilities by writing data-speciﬁc cus-tomized encoders and decoders.
Searchability/Indexability. A good data format should also natively support fast access to only a particular subset of the dataset, whether for the purpose of inspecting a given example, or training on a particular subset of the training set. Specialized data formats that only support sequential reads, however (e.g., TFRecord, WebDataset) are inherently unable to support such a feature. FFCV datasets contain a data table that hold metadata (including indices) as well as pointers to any given sample, allowing one to easily ﬁlter and retrieve samples based on any predicate.
File structure. FFCV datasets are optimized for machine learning training and offer great performance regardless of the underlying storage method (RAM, HDDs, SSDs or net-work). Each ﬁle consists of four sections. The Header con-tains general information about the dataset like the num-ber of samples and the ﬁelds. The Data Table is a small
DataFrame-like data structure containing metadata (small
ﬁxed-width information) about a given sample, such as e.g. the image resolution in the image domain, or audio sample duration in the audio domain. The Heap Storage section contains pages (of default size 8MB) that store either vari-able size information or data that is too large for the Data
Table, such as binary representations of images/audio ex-amples. Finally, the Allocation Table at the end of the ﬁle contains book-keeping data about allocated regions in Heap
Storage.
We show what a .beton ﬁle would look like for a basic image classiﬁcation task in Figure 3. 3.2. Challenge #2: Efﬁcient Data Reading
We now describe how FFCV achieves high read perfor-mance across a variety of compute environments with the
FFCV ﬁle format, ranging from those featuring local SSDs (with high IOPS and low latency) to large spinning disks (which suffer under random, nonsequential accesses, such as when reading many discrete image ﬁles) to networked
ﬁlesystems. FFCV offers built-in read strategies optimized for high throughput across all these different scenarios.
Flexibility. A data format should to be ﬂexible enough to accommodate a wide variety of data formats and modal-ities. Many existing specialized solutions are hyper-specialized and support only speciﬁc modalities (e.g.,
RecordIO datasets can only store images with associated
ﬂoating-point labels), while others are slightly more ﬂexi-ble (e.g., TFRecord and WebDataset). In FFCV, we opt for
Operating system caching. For systems that can ﬁt the dataset in random-access memory (RAM), FFCV can take advantage of OS-level caching. This ensures that every data read after the ﬁrst one will be from RAM rather than disk, resulting in high throughput. Beyond just simplicity,
OS-level caching also allows for multiple models training in parallel on the same dataset (i.e., when hyperparameter
Figure 3. Structure of a .beton ﬁle used to store a simple image classiﬁcation dataset. searching) to share the same cache without any additional memory overhead. the number of workers. For further comparison, see Ap-pendix A.
Process cache. On the other hand, if the dataset is larger than the main memory, an effective caching scheme will have to optimally cache, discard, and reload data at each epoch.
In OS-level caching—which other data loading schemes use by default—the random access patterns in-duced by SGD in machine learning cause suboptimal caching behavior. FFCV circumvents this issue through op-timized, process-level caching. By leveraging our knowl-edge of the sample order in data loading (since we can gen-erate this order at the beginning of the epoch), FFCV can preload data much earlier than the OS can.
Quasi-random sampling. For cases where disk reads are particularly expensive (e.g., when reading from a network drive and having insufﬁcient RAM to cache the dataset),
FFCV offers a quasi-random loading strategy that can com-bine with the process cache strategy above to minimize the stress on the underlying storage. Rather than reading exam-ples in a uniformly random order, the quasi-random strat-egy (a) allocates a buffer large enough to ﬁt batch_size pages of the dataset; (b) samples a permutation of all the pages of the dataset; then (c) generates a batch only from samples in the buffer.
WebDataset’s shufﬂing procedure is similar to FFCV’s quasi-random loading strategy with two crucial differences: (1) pages in FFCV are much smaller than WebDataset shards, leading to signiﬁcantly better randomness 1; (2) quasi-random loading in FFCV has a constant memory footprint, while WebDataset’s footprint scales linearly in 3.3. Challenge #3: Fast Data Processing
So far, we’ve outlined how FFCV improves both data storage and reading—we now turn to the data processing stage of the ML pipeline. In ML research, the data augmen-tation/processing pipeline requires both efﬁciency (in order to avoid bottlenecking the entire training process) and the
ﬂexibility to accommodate, e.g., researchers devising their own augmentations of pre-processing techniques.
FFCV tries to strike a balance between these two ob-jectives via just-in-time (JIT) compiled data processing pipeline. Speciﬁcally, for a small cost paid at the start of training, FFCV analyzes the user-provided (Python) data processing pipeline, and automatically compiles it to op-timized machine code via the following steps:
Categorization. Our main tool for compiling Python to machine code is the Numba library [Lam et al.(2015)], which is by default able to compile a large (but not com-plete) subset of the Python language into machine code2.
We thus ﬁrst categorize each element of the data pipeline based on whether it can be automatically compiled by (Note that all the pipeline elements that ship
Numba. with FFCV are Numba-compilable, so this step is primarily to enable users to write their own FFCV compatible non-compilable transformations, as in cases where it is too difﬁ-cult to write a compilable verfsion of a transformation).
Grouping. After categorizing each transformation in the data pipeline, we group together all consecutive transforms of each category into groups called “stages” (see Figure 4). 1While one can manually make WebDataset shards smaller, this incurs 2We motivate this choice and compare with other compilation systems a signiﬁcant ﬁlesystem load. in Appendix C.
Illustration of the procedure followed by FFCV to generate the code of a complex image processing pipeline. Transforms are
Figure 4. categorized together based on whether they can be JIT-ed (dashed, FFCV native or numpy based user-deﬁned augmentations) or not (solid,
Pytorch ones and others). Groups (stages) are formed based on these categories (1-4) by gluing each operation using meta-programming.
Finally, the stages are compiled to machine code using Numba/LLVM.
This will allow us to compile several separate pipeline ele-ments into a single executable block of machine code.
Code generation. Finally, using meta-programming, we generate the code necessary to fuse each stage into a single function. Some of the stages will be then passed to Numba to be converted to machine code, the others remain unmod-iﬁed and run natively in Python (albeit at much lower speed than their compiled counterparts).
Memory pre-allocation. A core tenet of FFCV is to avoid unnecessary memory allocation. Thus, every operation in the pipeline declares memory requirements in advance, and memory allocation is performed once at the start of an epoch. To let workers prepare the data while training hap-pens, and to absorb potential slow downs in data prepara-tion, FFCV relies on a circular buffer (illustrated in Figure 8 in Appendix F). 3.4. Challenge #4: Circumventing Data Transfer
Costs
Since compiled machine code isn’t under the supervision of the Python interpreter, FFCV can escape the constraints of Python’s global interpreter lock (GIL) and can rely on threads instead of sub-processes like most libraries (the GIL typically only allows a single thread to use the Python in-terpreter at once, generally making multi-threading infeasi-ble).
Threads yields two important advantages for FFCV.
First, threads can collaborate directly by reading/writing memory instead of using (expensive) communication prim-itives. FFCV workers can therefore work together on same batch instead of having to work on their own, improving on latency and saving large quantities of memory (i.e., FFCV’s memory usage is typically constant instead of scaling with the number of workers). Second, since they share the same
CUDA context, all data preparation operations running on
GPUs (e.g., data copying, augmentations) can be run asyn-chronously and—critically—in parallel with respect to the training loop, reducing the length of the critical path. See
Appendix B for more details. 4. Case Studies
In this section, we showcase FFCV’s versatility by il-lustrating how it can dramatically accelerate model train-ing in three common practical settings. While one can use FFCV with any task or modality, we center our ﬁrst three use cases around the ImageNet ILSVRC-2012 im-age classiﬁcation task, which comprises 1.3 million la-beled training images corresponding to 1,000 different classes.
ImageNet is a standard dataset in both image classiﬁcation [Russakovsky et al.(2015), He et al.(2015),
Krizhevsky et al.(2012)] and model training speed bench-marks [Mattson et al.(2020), Coleman et al.(2017), Cole-man et al.(2019)]; indeed, searching “ImageNet PyTorch” on GitHub returns hundreds of thousands of repositories.
We show, through the following use cases, that FFCV enables dramatic speedups over typical setups and more modest speedups over specialized performant training se-tups requiring specialized hardware (namely, NVIDIA
DALI [NVIDIA(2018)]):
• Single-model training: We ﬁrst use FFCV to train a
ResNet-50 on ImageNet to 75% accuracy in 20 min-utes on a single node, (Pareto) dominating all previous recorded benchmarks we are aware of (in fact, beating the next-best baseline by a factor of two). To evaluate
FFCV directly with other data loaders in this scenario, we also measure the effect of using different data load-ing baselines in a ﬁxed a model training setup;
• Multi-model training: We then consider the setting where a researcher wants to train several small mod-els in parallel (e.g., to obtain conﬁdence intervals or perform hyperparameter search). We show that FFCV can train 8 ResNet-18s at the same time (one per GPU) without incurring any additional overhead over single-GPU training. This demonstrates that FFCV enables both (a) efﬁcient training of high throughput models and (b) low-overhead concurrent training.
• Low-memory training: Finally, we consider the (practically common) setting in which the dataset does not ﬁt into machine memory (RAM). Via process-level caching and a quasi-random sampling scheme (ex-posed to users via just two lines of code), FFCV accel-erates training even when reading data from slow disks (and even from networked ﬁle systems) with minimal performance overhead.
We then demonstrate FFCV’s drop-in applicability beyond computer vision tasks:
• GPU-enabled sparse regression: In just a few lines of code, FFCV can considerably speed up an itera-tive SAGA [Defazio et al.(2014)] solver (similar to that of [Wong et al.(2021)]) by simply replacing a default
PyTorch data loader (loading from a memory-mapped
ﬁle) with an FFCV loader. 4.1. Training a single model
We ﬁrst study the simplest use case of FFCV: training a single model on ImageNet as fast as possible. By combin-ing the data loading speed of FFCV with known ImageNet training optimizations, we are able to establish a new state-of-the-art speed/accuracy tradeoff for the benchmark task of training a ResNet-50 on ImageNet (Figure 1).
Fast training. We begin with an overview of the train-ing algorithm itself—a long line of work has explored vari-ous modiﬁcations to standard training that have been shown to improve speed and/or accuracy, of which we use Blur-pool [Zhang(2019)]; NoWD-BN [Jia et al.(2018)]; linear learning rate annealing [Li et al.(2020)]; test-time augmen-tation and resizing [Touvron et al.(2019)]; and progressive resizing (i.e., we start training at 160px resolution and then increase to 192px 75% of the way through training).
Fast data loading. With FFCV we JPEG-compress 50% of the dataset, compromising between compute (i.e. faster image processing, as 50% of the images come pre-decoded) and available memory. Doing so allows our system to: (a) reap the full beneﬁts of progressive resizing. Even at smaller resolutions like 160px in which the GPU has much higher throughput, we can still fully saturate the GPU as we are neither data reading nor processing bottlenecked; (b) outsource augmentations to the CPU. Since the dataset is cached (largely decoded) in memory, we can use
CPU cycles for augmentations that would otherwise go to decoding.
Evaluation. We compare our FFCV-enabled optimized
ImageNet example to these baselines:
• PyTorch ImageNet example: As a naive baseline, we take the PyTorch ImageNet example code, which is both unoptimized and slow to load data—we use the reported accuracy from torchvision and multiply the per-epoch time (from Figure 5a by 90 to ob-tain an optimistic estimate of total training time. We modify the code to use half precision. This loader is far and away the most popular loader seen in open source/research implementations, and is used by the most popular open-source ImageNet training li-braries [Wightman(2019), Falcon et al.(2019), Devel-opers(2016)].
• NVIDIA ImageNet example: As a second baseline, we use the NVIDIA DALI-based ImageNet example
This work uses a ﬁxed 90 epoch schedule. Note that, some benchmarks for DALI leverage hardware JPEG decoder only available on some GPUs, which is why they were not enabled here. While nothing in the design of FFCV is incompatible with their usage we made the decision to not include them in the public re-lease as the beneﬁt didn’t seem to outweight the draw-backs (namely compatibility and ease of installation).
• MosaicML: Finally, we consider the MosaicML explorer baseline. The MosaicML Explorer plots the tradeoff between accuracy and training speed for models trained with MosaicML’s training sys-tem; MosaicML explores a far larger set of algo-rithmic training changes than our work, including
MixUp [Zhang et al.(2017)], specialized optimizers outside of SGD [Foret et al.(2021)], squeeze-excitation blocks [Hu et al.(2018)], and more.
We run all implementations on an AWS EC2 p4d.24xlarge machine. We report our results above in Figure 1, ﬁnding that our system obtains the best accuracy vs. speed tradeoff across all baselines. In particular, to obtain 75% accuracy we require only 20 minutes, much faster than any of the
(a) Single-model (1x RN-50 on 8xA100) (b) Multi-model (8x RN-18 on 1xA100 each) (c) Low-memory (1x ResNet-18 via Network File
System)
Figure 5. A comparison between the time to train one epoch on ImageNet using FFCV, NVIDIA DALI, and PyTorch’s ImageFolder. We further compare with WebDataset in Appendix D: FFCV performance dominates that of WebDataset. tested baselines and, to our knowledge, the fastest single-node system to obtain this accuracy. (Pessimistic) comparison with DALI loading. Swap-ping out FFCV for DALI and the PyTorch ImageNet train loader, we measure the training times obtained for each data loader when the implementation is held constant in Fig-ure 5a, and ﬁnd that FFCV still dominates.
MLPerf baselines. We do not compare with MLPerf baselines for two reasons: the scenarios are unfair to the
MLPerf baselines (which do not allow data preprocessing), and the best MLPerf baselines have very strict hardware re-quirements (for example, the best NVIDIA submission re-quires a DGX POD3 and is not reproducible on cloud-based machines). 4.2. Training multiple models
Another common paradigm in machine learning is train-ing multiple models simultaneously. For example, we may want to perform a grid search for optimal parameters, or rerun a model with the same training parameters to obtain conﬁdence intervals on results. In what follows, we show that FFCV allows for much faster parallel training than ex-isting methods: FFCV has automatic support for OS-level caching and is high throughput enough to support even 8
ResNet-18s training at once (ResNet-18 models have nearly three times the throughput of ResNet-50 models since they are smaller).
Evaluation. Using the same AWS EC2 p4d.24xlarge ma-chine as above, we run eight concurrent training routines for the following baselines (each originally described in
Section 4.1): (a) PyTorch ImageNet example: ResNet-18 with code from the PyTorch ImageNet example; (b) Scaled
DALI: ResNet-18 with code from the FFCV ImageNet ex-ample, code, swapping out FFCV for a DALI loader.
Each training routine has access to one eighth of the available vCPUs (12) and one A100. For DALI and FFCV 3See: https://www.nvidia.com/en- sg/data- center/ dgx-basepod/ we use image datasets that have been originally scaled to 350px. FFCV performs no JPEG compression, storing only image pixel values. Our throughput results can be found in
Figure 5b; we ﬁnd that FFCV has greater throughput than either DALI or ImageFolder-based methods, despite not re-quiring any specialized hardware for decoding. 4.3. Low-memory training
In the previous two examples, we operated in a set-ting where the machine being used for training has sufﬁ-cient memory (RAM) to cache the entire ImageNet dataset (in particular, our 50% compressed version of ImageNet is 339GB). In many scenarios, however, we do not have sufﬁ-cient RAM to cache even a fully JPEG-compressed dataset, and are thus forced to load images directly from the ﬁlesys-tem. Normally, this process incurs additional signiﬁcant training cost, especially in settings where the ﬁlesystem is mounted on a networked drive (or any other slow disk).
Here, we show that with minimal changes to existing code, FFCV enables fast training even in such resource-constrained setups. By changing only two lines of code, we can enable process-level caching and quasi-random loading. These optimizations together ensure that read-constrained, memory-constrained systems operate at as high a throughput as possible; see Section 3 for details.
Just as in the last section, we compare to
Evaluation.
NVIDIA DALI and the default PyTorch Image Dataset. The results, shown in Figure 5c, illustrate that FFCV indeed en-ables faster training in memory-limited settings. 4.4. Beyond computer vision
Finally, we show the applicability of FFCV beyond just computer vision workloads.
Speciﬁcally, we con-sider a large-scale sparse linear regression problem with n = 100, 000 training points and dimensionality d = 50, 000. We use an optimized iterative SAGA-based opti-mizer [Wong et al.(2021)] for solving sparse linear regres-sion problems.
In Figure 6, we compare the unmodiﬁed code (which loads data using the standard PyTorch data
Fast training on ImageNet. Our evaluation focuses on fast train-training on ImageNet, a standard in model ing speed benchmarks [Mattson et al.(2020), Coleman et al.(2017), Coleman et al.(2019)]. Many prior works
[Goyal et al.(2017), Jia et al.(2018), You et al.(2018), Sun et al.(2019), You et al.(2017), Akiba et al.(2017)] use dis-tributed training with extremely large batch sizes to reduce training time. Beyond the increase in engineering complex-ity arising from distributed training, training models with large batch sizes comes with its own challenges, for in-stance, proper tuning of the learning rate [Dettmers and
Zettlemoyer(2019), You et al.(2017)]. Moreover, extreme resource usage, including large communication overheads necessitated by distributed training [Coleman et al.(2019)], reduce their usability. 6. Conclusion
In this work, we present FFCV, an optimized framework for eliminating data bottlenecks in machine learning model training routines. We use FFCV to establish a state-of-the-art speed/accuracy tradeoff for the ImageNet dataset, and demonstrate (through a series of case studies) the potential for FFCV to speed up almost any ML workload. The main limitation of our work is that it does not address non-data related bottlenecks in training, and might thus yield less sig-niﬁcant (but still non-zero) improvements in settings where data is fast to load and process (e.g., NLP) or where models are very large and dominate training time (e.g., NLP).
References
[Aizman et al.(2019)] Alex Aizman, Gavin Maltby, and Thomas
Breuel. High performance i/o for large scale deep learning.
In 2019 IEEE International Conference on Big Data (Big
Data), pages 5965–5967. IEEE, 2019. 8
[Akiba et al.(2017)] Takuya Akiba, Shuji Suzuki, and Keisuke
Training arXiv preprint
Extremely large minibatch sgd: in 15 minutes.
Fukuda. resnet-50 on imagenet arXiv:1711.04325, 2017. 8
[Coleman et al.(2019)] Cody Coleman, Daniel Kang, Deepak
Narayanan, Luigi Nardi, Tian Zhao, Jian Zhang, Peter Bailis,
Kunle Olukotun, Chris Ré, and Matei Zaharia. Analysis of dawnbench, a time-to-accuracy machine learning perfor-mance benchmark. Operating Systems Review, 2019. 5, 8
[Coleman et al.(2017)] Cody Coleman, Deepak Narayanan,
Daniel Kang, Tian Zhao, Jian Zhang, Luigi Nardi, Peter
Bailis, Kunle Olukotun, Chris Ré, and Matei Zaharia.
Dawnbench: An end-to-end deep learning benchmark and competition. In NeurIPS ML Systems Workshop, 2017. 2, 5, 8
[Defazio et al.(2014)] Aaron Defazio, Francis Bach, and Simon
Lacoste-Julien. Saga: A fast incremental gradient method with support for non-strongly convex composite objec-tives. In Advances in neural information processing systems (NeurIPS), 2014. 6
Figure 6. FFCV provides signiﬁcant speedups over the default Py-Torch data loader for non-vision modalities: here, e.g., a drop-in replacement of FFCV makes a sparse regression solver 1.6x faster. loader, reading from a memory-mapped ﬁle) with a drop-in FFCV replacement. The results indicate that even outside typical computer vision setups, FFCV is an effective drop-in replacement for default data loaders.
Video: Beyond image classiﬁcation. We also evaluate on
UCF101, a standard video dataset, ﬁnding that FFCV can greatly outperform standard loaders. Our setup and results are in Appendix E. 5.