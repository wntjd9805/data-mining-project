Abstract
Aerial robots are now able to fly in complex environ-ments, and drone-captured data gains lots of attention in object tracking. However, current research on aerial per-ception has mainly focused on limited categories, such as pedestrian or vehicle, and most scenes are captured in ur-ban environments from a birds-eye view. Recently, UAVs equipped with depth cameras have been also deployed for more complex applications, while RGBD aerial tracking is still unexplored. Compared with traditional RGB ob-ject tracking, adding depth information can more effec-tively deal with more challenging scenes such as target and background interference. To this end, in this paper, we explore RGBD aerial tracking in an overhead space, which can greatly enlarge the development of drone-based visual perception. To boost the research, we first propose a large-scale benchmark for RGBD aerial tracking, contain-ing 1,000 drone-captured RGBD videos with dense annota-tions. Then, as drone-based applications require for real-time processing with limited computational resources, we also propose an efficient RGBD tracker named EMT. Our tracker runs at over 100 fps on GPU, and 25 fps on the edge platform of NVidia Jetson NX Xavier, benefiting from its ef-ficient multimodal fusion and feature matching. Extensive experiments show that our EMT achieves promising track-ing performance. All resources are available at https:// github.com/yjybuaa/RGBDAerialTracking. 1.

Introduction
Aerial robots have been widely used in complex mis-sions. For example, Unmanned Aerial Vehicles (UAVs) equipped with cameras are able to perceive and understand unknown environments and have wide applications on agri-culture and surveillance [11, 43]. Specifically, color-based visual tracking with drones has been rapidly developed, thanks to large-scale datasets [27, 43] and dedicated algo-† Equal contribution. ∗ Corresponding author. rithms [2–4, 9, 10, 12, 17, 24, 35]. However, these UAVs merely equipped with color-based sensors generally fail to deal with the challenges in complex environments, such as background clutters and dark scenes, which break the visi-bility and illumination limitations in color-only domain. For example, current drones have difficulties on tracking a per-son in dark scenes. While, RGBD tracking is effective to tackle such kinds of tracking failures.
However, for a long time, depth sensors are only incor-porated with UAVs to enable aerial autonomy and collision avoidance [14]. Visual perception like RGBD tracking with drones is unexplored due to the multiple limitations. For example, commercial RGBD sensors are strictly limited by application scenarios and depth measurement range. On the other hand, we notice that current UAV tracking datasets record video sequences in the manner of aerial photogra-phy [8, 43]. The captured objects mainly focus on pedes-trians and vehicles, and the captured scenes are in urban environments from a birds-eye view.
In this work, we explore RGBD aerial tracking from a more practical viewpoint. Different from existing UAV tracking works, we focus on the unexplored overhead space (2 - 5 meters above the ground), aiming to save the ground space greatly with drone-based visual perception. Instead of mainly focusing on people and vehicles, our research can include more generic objects of different categories, such as hands, cups, or balls. Thus, multimodal aerial platforms in this space are very important, as flying robots with short-range perception capabilities can potentially be used in a wider range of scenarios, such as human-robot interaction.
Notably, the new task brings challenges in drone-based visual perception, which can be concluded as follows:
Complex real-world circumstances. The real-world flight comes with complicated and changeable natural en-vironments. On the one hand, the high mobility of drones brings intense pose changes, resulting in huge variations of target scale and considerable motion blurs. Except for the common challenges in visible situations, drone vision also suffers from other problems like low illumination, similar objects and background clutter.
Limited onboard computational resources. In practi-cal applications, flying platforms generally require higher efficiency on edge platforms with limited resources, while state-of-the-art trackers can only run on powerful GPUs.
Especially for multimodal trackers, the model efficiency is always the least valued in model design.
Real-time practical applications. Real time is a basic requirement in aerial tracking. Moving platforms require real-time responses and real-world applications also require trackers to function in real-time speed. However, most of current state-of-the-art trackers even cannot achieve real-time speed on powerful GPUs, not to mention their real-world applications.
Therefore, to achieve UAV visual tracking with depth, we first build a novel RGBD aerial platform to collect videos. The platform is particularly designed to simulate the environments in real-world applicaitions. The captured videos can comprehensively reflect those challenges to be tackled. Using this aerial platform, a large-scale dataset for Drone-based RGBD aerial tracking, named D2Cube, is built. Some examples in our dataset are given in Fig. 1.
In total, 1,000 sequences are provided with dense bound-ing box annotations. The settings of captured videos cover diverse scenarios in daily life.
Furthermore, we propose an efficient tracker named
EMT to facilitate the development of on-board RGBD tracking. The proposed EMT can be treated as a strong baseline for on-board multimodal tracking to simultane-ously tackle above three issues. Thanks to the efficient mul-timodal fusion and feature matching, our proposed tracker can successfully balance the tight computational budget and tracking accuracy. We perform extensive experiments in di-verse scenarios and various platforms to validate the effec-tiveness of our EMT. Competitive tracking performance is observed in comparison with state-of-the-art RGB-only and multimodal trackers, in which EMT runs at a high frame rate of over 100 FPS. Practical application tests are given on NVIDIA Jetson NX Xavier, where our EMT can run at a frame rate of over 25 FPS. To conclude, our dataset covers complex aerial tracking scenarios and our method shows a promising balance of accuracy, resources and speed.
The contributions are summarised below:
• New Problem: We propose a new task of RGBD air tracking for newly defined overhead space (2m - 5m).
Unlike previous aerial tracking, this task is more rele-vant to human life and has wider applications.
• New Benchmark: We construct a large-scale high-diversity benchmark for RGBD aerial tracking. The advantage is that much more categories (34 classes) tracking can be considered than existing aerial datasets. As far as we know, this is the first dataset that can test multimodal aerial tracking models.
• New Baseline: An efficient tracking baseline is pro-posed for RGBD aerial tracking, which is the first real-time tracker for efficient on-board multimodal track-ing. It performs better than classical UAV trackers and maintains comparable efficiency. 2.