Abstract
Based on the Manhattan World assumption, most exist-ing indoor layout estimation schemes focus on recovering layouts from vertically compressed 1D sequences. However, the compression procedure confuses the semantics of differ-ent planes, yielding inferior performance with ambiguous interpretability.
To address this issue, we propose to disentangle this 1D representation by pre-segmenting orthogonal (vertical and horizontal) planes from a complex scene, explicitly captur-ing the geometric cues for indoor layout estimation. Con-sidering the symmetry between the floor boundary and ceil-ing boundary, we also design a soft-flipping fusion strategy to assist the pre-segmentation. Besides, we present a fea-ture assembling mechanism to effectively integrate shallow and deep features with distortion distribution awareness.
To compensate for the potential errors in pre-segmentation, we further leverage triple attention to reconstruct the dis-entangled sequences for better performance. Experiments on four popular benchmarks demonstrate our superiority over existing SoTA solutions, especially on the 3DIoU met-ric. The code is available at https://github.com/ zhijieshen-bjtu/DOPNet. 1.

Introduction
Indoor panoramic layout estimation refers to recon-structing 3D room layouts from omnidirectional images.
Since the panoramic vision system captures the whole-room contextual information, we can estimate the complete room layout with a single panoramic image. However, inferring the 3D information from a 2D image is an ill-posed prob-lem. Besides, the 360° field-of-view (FoV) of panoramas brings severe distortions that increase along the latitude.
Both issues are challenging for indoor layout estimation.
†Corresponding author
Figure 1. (a) The commonly used architecture. (b) The proposed one. Compared with the traditional pipeline, ours has two advan-tages: (1) Disentangling the 1D representation into two separate sequences with different plane semantics. (2) Adaptively integrat-ing shallow and deep features with distortion awareness via a fea-ture assembling mechanism rather than simple concatenation.
Different from outdoor scenarios, the indoor room has the following properties: (1) The indoor scenes conform to the Manhattan World assumption (The floors and ceilings are all flat planes, and the walls are perpendicular to them). (2) The room layout is always described as the corners or the floor boundary and ceiling boundary. These characteris-tics could be used as potential priors to guide the design of a reasonable layout estimation method.
Based on the Manhattan World assumption, previous approaches [19, 20, 8, 14, 21] prefer to estimate the lay-out from a 1D sequence. They advocate compressing the extracted 2D feature maps in height dimension to obtain a 1D sequence, of which every element in this sequence share the same distortion magnitude (Fig. 1a). We argue that this compressed representation does not eliminate the panoramic distortions because there is no explicit distortion processing when extracting 2D feature maps before com-pression. Moreover, this strategy roughly mixes the vertical and horizontal planes together, confusing the semantics of different planes that are crucial for layout estimation.
On the other hand, some researchers devoted themselves 1
to adopting different projection formats to boost the perfor-mance, e.g., the bird’s view of the room [29] and cubemap projection [27]. These projection-based schemes weaken the negative effect of the distortions. Nevertheless, frequent projection operations between different formats raise com-putational complexity. In addition, there exists an inevitable domain gap between the feature maps from different for-mats.
To address the above problems, we propose a novel ar-chitecture (Fig.1b) that disentangles the orthogonal planes in advance to capture an explicit geometric cue. Follow-ing [21], our room layout can be recovered from the pre-dicted horizon-depth map and the room height. Therefore, the “clean” depth-relevant features and height-relevant fea-tures can both help with the layout estimation. To obtain such “clean” features free from the disturbance of decora-tions and furniture, we disentangle the widely used 1D rep-resentation into two separate sequences — the horizontal and vertical ones. Specifically, we pre-segment the vertical plane (i.e., walls) and horizontal planes (i.e., floors and ceil-ings) from the whole-room contextual information. Then these orthogonal planes are compressed into two 1D repre-sentations. Especially, based on the symmetry property be-tween the floor boundary and ceiling boundary, we design a soft-flipping fusion strategy to assist this process.
Moreover, we propose an assembling mechanism to fuse multi-scale features with distortion awareness effectively.
To eliminate the negative effect of distortion, we com-pute the attention among distortion-relevant positions fol-lowing distortion distribution patterns. Meanwhile, cross-scale interaction is carried out to integrate shallow geo-metric structures and deep semantic features. Considering the error of pre-segmentation, we further leverage triple at-tention to reconstruct the two 1D sequences. Particularly, we adopt graph-based attention to generate discriminative channels, self-attention to rebuild long-range dependencies, and cross-attention to provide the missing information for different sequences.
To demonstrate our effectiveness, we conduct extensive experiments on four popular datasets — MatterportLayout
[29], Zind [6], Stanford 2D-3D [1], and PanoContext [26].
The qualitative and quantitative results show that the pro-posed solution outperforms other SoTA methods. Our con-tributions can be summarized as follows:
• We propose to disentangle orthogonal planes to cap-ture an explicit geometric cue for indoor 360° room layout estimation, with a soft-flipping fusion strategy to assist this procedure.
• We design a cross-scale distortion-aware assembling mechanism to perceive distortion distribution as well as integrate shallow geometric structures and deep se-mantic features.
• On popular benchmarks, our solution outperforms other SoTA schemes, especially on the metric of in-tersection over the union of 3D room layouts. 2.