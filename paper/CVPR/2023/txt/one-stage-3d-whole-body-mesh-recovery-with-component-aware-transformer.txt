Abstract
Whole-body mesh recovery aims to estimate the 3D hu-man body, face, and hands parameters from a single im-age.
It is challenging to perform this task with a single network due to resolution issues, i.e., the face and hands are usually located in extremely small regions. Existing works usually detect hands and faces, enlarge their reso-lution to feed in a specific network to predict the parameter, and finally fuse the results. While this copy-paste pipeline can capture the fine-grained details of the face and hands, the connections between different parts cannot be easily re-covered in late fusion, leading to implausible 3D rotation and unnatural pose. In this work, we propose a one-stage pipeline for expressive whole-body mesh recovery, named
OSX, without separate networks for each part. Specifically, we design a Component Aware Transformer (CAT) com-posed of a global body encoder and a local face/hand de-coder. The encoder predicts the body parameters and pro-vides a high-quality feature map for the decoder, which per-forms a feature-level upsample-crop scheme to extract high-resolution part-specific features and adopt keypoint-guided deformable attention to estimate hand and face precisely.
The whole pipeline is simple yet effective without any man-ual post-processing and naturally avoids implausible pre-diction. Comprehensive experiments demonstrate the effec-tiveness of OSX. Lastly, we build a large-scale Upper-Body dataset (UBody) with high-quality 2D and 3D whole-body annotations. It contains persons with partially visible bod-ies in diverse real-life scenarios to bridge the gap between the basic task and downstream applications. 1.

Introduction
Expressive whole-body mesh recovery aims to jointly es-timate the 3D human body poses, hand gestures, and fa-cial expressions from monocular images. It is gaining in-creasing attention due to recent advancements in whole-body parametric models (e.g., SMPL-X [37]). This task is a key step in modeling human behaviors and has many appli-cations, e.g., motion capture, human-computer interaction.
Previous research focus on individual tasks of reconstruct-ing human body [9, 21, 25, 44, 48, 49], face [2, 10, 12, 43],
§ Work done during an internship at IDEA; ¶ Corresponding author.
or hand [4, 8, 16]. However, whole body mesh recovery is particularly challenging as it requires accurate estimation of each part and natural connections between them.
Existing learning-based works [13, 29, 36, 41, 51] use multi-stage pipelines for body, hand, and face estimation to achieve the goal of this task. As depicted in Figure 1(a), these methods typically detect different body parts, crop and resize each region, and feed them into separate expert mod-els to estimate the parameters of each part. The multi-stage pipeline with different estimators for body, hand, and face results in a complicated system with a large computational complexity. Moreover, the blocked communications among different components inevitably cause incompatible config-urations, unnatural articulation of the mesh, and implau-sible 3D wrist rotations as they cannot obtain informative and consistent clues from other components. Some meth-ods [13,29,51] attempt to alleviate these issues by designing additional complicated integration schemes or elbow-twist compensation fusion among individual body parts. How-ever, these approaches can be regarded as a late fusion strat-egy and thus have limited ability to enhance each other and correct implausible predictions.
In this work, we propose a one-stage framework named
OSX for 3D whole-body mesh recovery, as shown in Fig-ure 1(b), which does not require separate networks for each part. Inspired by recent advancements in Vision Transform-ers [11, 47], which are effective in capturing spatial infor-mation in a plain architecture, we design our pipeline as a component-aware Transformer (CAT) composed of a global body encoder and a local component-specific decoder. The encoder equipped with body tokens as inputs captures the global correlation, predicts the body parameters, and si-multaneously provides high-quality feature map for the de-coder. The decoder utilizes a differentiable upsample-crop scheme to extract part-specific high-resolution features and adopt the keypoint-guided deformable attention to precisely locate and estimate hand and face parameters. The proposed pipeline is simple yet effective without any manual post-processing. To the best of our knowledge, this is the first one-stage pipeline for 3D whole-body estimation. We con-duct comprehensive experiments to investigate the effects of the above designs and compare our method, with existing works on three benchmarks. Results show that OSX outper-forms the state-of-the-art (SOTA) [29] by 9.5% on AGORA, 7.8% on EHF, and 13.4% on the body-only 3DPW dataset.
In addition, existing popular benchmarks, as illustrated in the first row of Figure 2, are either indoor single-person scenes with limited images (e.g., EHF [37]) or outdoor syn-thetic scenes (e.g., AGORA [35]), where the people are of-ten too far from the camera and the hands and faces are fre-quently obscured. In fact, human pose estimation and mesh recovery is a fundamental task that benefits many down-stream applications, such as sign language recognition, ges-ture generation, and human-computer interaction. Many scenarios, such as talk shows and online classes, are of vital importance to our daily life yet under-explored. In such sce-narios, the upper body is a major focus, whereas the hand and face are essential for analysis. To address this issue, we build a large-scale upper-body dataset with fifteen human-centric real-life scenes, as shown in Figure 2(f) to (t). This dataset contains many unseen poses, diverse appearances, heavy truncation, interaction, and abrupt shot changes, which are quite different from previous datasets. Accord-ingly, we design a systematical annotation pipeline and pro-vide precise 2D whole-body keypoint and 3D whole-body mesh annotations. With this dataset, we perform a compre-hensive benchmarking of existing whole-body estimators.
Our contributions can be summarized as follows.
• We propose a one-stage pipeline, OSX, for 3D whole-body mesh recovery, which can regress the SMPL-X parameters in a simple yet effective manner.
• Despite the conceptual simplicity of our one-stage framework, it achieves the new state of the art on three popular benchmarks.
• We build a large-scale upper-body dataset, UBody, to bridge the gap between the basic task and downstream applications and provide precise annotations, with which we conduct benchmarking of existing methods.
We hope UBody can inspire new research topics. 2.