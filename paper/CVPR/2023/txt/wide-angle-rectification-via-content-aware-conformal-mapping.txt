Abstract 1.

Introduction
Despite the proliferation of ultra wide-angle lenses on smartphone cameras, such lenses often come with severe image distortion (e.g. curved linear structure, unnaturally skewed faces). Most existing rectification methods adopt a global warping transformation to undistort the input wide-angle image, yet their performances are not entirely satis-factory, leaving many unwanted residue distortions uncor-rected or at the sacrifice of the intended wide FoV (field-of-view). This paper proposes a new method to tackle these challenges. Specifically, we derive a locally-adaptive polar-domain conformal mapping to rectify a wide-angle image.
Parameters of the mapping are found automatically by an-alyzing image contents via deep neural networks. Experi-ments on a large number of photos have confirmed the su-perior performance of the proposed method compared with all available previous methods.
It has become trendy to equip modern smartphone cam-eras with ultra wide-angle lenses, to allow the user to shoot photographs of natural landscapes or buildings with a wide field-of-view (FoV), or capture a group-selfie in a tight space. This trend can be easily seen on high-end phones for example iPhone 13 which features a rear camera with 120◦ FoV, or Samsung S21 that is 123◦.
While such lenses provide the user with an immersive vi-sual experience, they also induce apparent and unavoidable image distortions, resulting in e.g. curved straight lines or sheared human faces. Traditional methods for lens distor-tion removal solve this problem by finding a global para-metric geometric transformation to warp the input image.
Their performances are however far from satisfactory, with either obvious residual distortions on linear structure or lo-cal shapes, or missing image contents at the image bound-aries due to a much compromised field of view.
In contrast, human eyes, while enjoying a wide field of
view (about 120◦ in monocular case [24]), are capable of perceiving a wide environment without obvious distortions.
In our mind’s eye, lines appear to be straight, and objects preserve their natural shapes. Our brain seems to be able to intelligently “undistort” different parts of the view-field by applying different content-aware transformations. More-over, it is also recognized that human vision is most sensi-tive to global linear structures as well as perceptually salient regions in a scene. Given that distortions are unavoidable when one projects a view-sphere onto a flat image plane, our goal of this paper is not to eliminate all distortions (which is impossible), but to minimize those most visually salient distortions such that they become unnoticeable or tolerable.
To this end, this paper develops a content-aware image projection method which focuses on correcting the most salient distortions (e.g. visual features), while preserving local shapes in the scene as much as possible. Specifically, our method searches for an optimal content-aware confor-mal mapping which warps a wide-angle input image to a rectified one, in a locally adaptive manner by respecting lo-cal image contents. This way, it not only eliminates most noticeable distortions in the scene, but also retains the wide
FoV, offering the user the intended immersive experience endowed by the wide-angle lens.
Specifically, key contributions of the paper are:
• An automatic content-aware wide-angle image rec-tification method which preserves both local shapes and global structures by analyzing image contents via deep-learning.
• A new formulation for Least-Squares Conformal Map-ping (LSCM) in the polar domain to achieve locally adaptive shape-preserving transformation.
• A new optimization procedure which incorporates multiple energy terms, each encodes a different prior on local shapes, linear structures, smoothness and im-age boundaries, respectively.
Our method strikes an excellent balance between local-shape-preserving (e.g., “circles remain circular”) and global linear-structure-preserving (e.g., “straight lines must be straight”), making the rectified images look both real, natu-ral, and visually pleasing, while at the same time enjoying the immersive wide-angle visual experience by retaining the original wide field of view. Our method evidently out-performs all previous methods for wide-angle rectification, including both global warp based methods (e.g. perspec-tive correction, Mercator projection), and local optimization method [4] that alters the orientation of local shapes, and method that is restricted to portrait photo only [22]. Our method is fully automatic, without the need of human in-tervention. It also runs fast, taking about 1-2 seconds per image, and can be easily optimized on a mobile-GPU to reach sub-second processing time, sufficient for real-world photography applications. 2.