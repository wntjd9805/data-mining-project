Abstract
Detecting arbitrarily oriented tiny objects poses intense challenges to existing detectors, especially for label assign-ment. Despite the exploration of adaptive label assignment in recent oriented object detectors, the extreme geometry shape and limited feature of oriented tiny objects still in-duce severe mismatch and imbalance issues. Specifically, the position prior, positive sample feature, and instance are mismatched, and the learning of extreme-shaped objects is biased and unbalanced due to little proper feature supervi-sion. To tackle these issues, we propose a dynamic prior along with the coarse-to-fine assigner, dubbed DCFL. For one thing, we model the prior, label assignment, and ob-ject representation all in a dynamic manner to alleviate the mismatch issue. For another, we leverage the coarse prior matching and finer posterior constraint to dynamically as-sign labels, providing appropriate and relatively balanced supervision for diverse instances. Extensive experiments on six datasets show substantial improvements to the baseline.
Notably, we obtain the state-of-the-art performance for one-stage detectors on the DOTA-v1.5, DOTA-v2.0, and DIOR-R datasets under single-scale training and testing. Codes are available at https://github.com/Chasel-Tsui/mmrotate-dcfl. 1.

Introduction
The oriented bounding box is a finer representation for object detection since the object’s background region is greatly eradicated by introducing the rotation angle [55].
This advantage is pronounced in aerial images, where ob-jects are in arbitrary orientations, resulting in the prosper-ity of corresponding object detection datasets [7, 11, 35, 55] and customized oriented object detectors [10,17,18,60,62].
Nevertheless, one unignorable fact is that there exist numer-ous tiny objects in aerial images. When oriented objects are tiny-sized, the challenges posed to existing object detec-*Corresponding Authors
Figure 1. Comparisons of different learning paradigms for ori-ented object detection. M* means the matching function. Each box in the 2nd row denotes a prior location. The 3rd row are predic-tions of the RetinaNet and DCFL, where green, blue, and red boxes denote true positive, false positive, and false negative predictions. (a) RetinaNet, FCOS, and Rotated RPN statically assign labels be-tween fixed priors and fixed gts. (b) Our proposed DCFL dynami-cally updates priors and gts, and dynamically assigns labels. tors are quite remarkable. Especially, the extreme geometry characteristics of oriented tiny objects hamper the accurate label assignment.
Label assignment is a fundamental and crucial process in object detection [68], in which priors (box for anchor-based [30] and point for anchor-free detectors [50]) need to be assigned with appropriate labels to supervise the net-work training. In fact, there have been some works that lay a foundation for the effective label assignment of oriented objects, as shown in Fig. 1. Early works additionally preset anchors of different angles (e.g. Rotated RPN [36]) or re-fine high-quality anchors (e.g. S2A-Net [17]) based on the generic object detector, then a static rule (e.g. MaxIoU strat-egy [44]) is used to separate positive and negative (pos/neg) training samples. The derived prior boxes can thus cover more ground truth (gt) boxes and a considerable accuracy improvement can be expected. However, the static assign-ment cannot adaptively divide pos/neg samples according to the gt’s shape and filter out low-quality samples, usually
the Deep Neural Network (DNN). Simultaneously, we dy-namically and progressively assign labels in a coarse-to-fine manner to seek balanced supervision for various instances.
Specifically, we introduce a dynamic Prior Capturing
Block (PCB) to learn the prior, which adaptively adjusts the prior location while retaining the physical meaning of prior [54]. The PCB is inspired by the paradigm of learnable proposals in the DETR [4] and Sparse R-CNN [48] which naturally avoids the mismatch issue between the predefined prior and feature. Compared to this paradigm, we intro-duce its flexibility for prior updates while keeping the fast-convergence ability of dense detectors [32, 54]. Based on the dynamic prior, we then select Cross-FPN-layer Coarse
Positive Sample (CPS) candidates for further label assign-ment, and the CPS is realized by the Generalized Jensen-Shannon Divergence [39] (GJSD) between the gt and the dynamic prior. The GJSD is able to enlarge the CPS to the object’s nearby spatial locations and adjacent FPN lay-ers, ensuring more candidates for extreme-shaped objects.
After obtaining the CPS, we re-rank these candidates with predictions (posterior) and represent the gt with a finer Dy-namic Gaussian Mixture Model (DGMM), filtering out low-quality samples. All designs are incorporated into an end-to-end one-stage detector without additional branches.
In short, our contributions are listed as follows: (1) We identify that there exist severe mismatch and imbalance is-sues in the current learning pipeline for oriented tiny ob-ject detection. (2) We design a Dynamic Coarse-to-Fine
Learning (DCFL) scheme for oriented tiny object detection, which is the first to model the prior, label assignment, and gt representation all in a dynamic manner. In the DCFL, we propose to use the GJSD to construct Coarse Positive
Samples (CPS) and represent objects with a finer Dynamic
Gaussian Mixture Model (DGMM), obtaining coarse-to-fine label assignment. (3) Extensive experiments on six datasets show promising results. 2.