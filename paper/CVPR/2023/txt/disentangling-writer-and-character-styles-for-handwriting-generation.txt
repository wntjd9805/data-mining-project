Abstract
Training machines to synthesize diverse handwritings is an intriguing task. Recently, RNN-based methods have been proposed to generate stylized online Chinese charac-ters. However, these methods mainly focus on capturing a person’s overall writing style, neglecting subtle style in-consistencies between characters written by the same per-son. For example, while a person’s handwriting typically exhibits general uniformity (e.g., glyph slant and aspect ratios), there are still small style variations in finer de-In tails (e.g., stroke length and curvature) of characters. light of this, we propose to disentangle the style repre-sentations at both writer and character levels from indi-vidual handwritings to synthesize realistic stylized online handwritten characters. Specifically, we present the style-disentangled Transformer (SDT), which employs two com-plementary contrastive objectives to extract the style com-monalities of reference samples and capture the detailed style patterns of each sample, respectively. Extensive exper-iments on various language scripts demonstrate the effec-tiveness of SDT. Notably, our empirical findings reveal that the two learned style representations provide information at different frequency magnitudes, underscoring the impor-tance of separate style extraction. Our source code is public at: https://github.com/dailenson/SDT. 1.

Introduction
As the oldest writing system, Chinese characters are widely used across Asian countries. When compared with Latin scripts, Chinese characters encompass an excep-tionally vast lexicon (87,887 characters in GB18030-2022 charset) and have intricate structures composed of multiple strokes. Recently, the intriguing task of generating Chinese characters has garnered significant attention [10, 23, 32]. A promising approach to synthesising realistic handwritings is
*Authors contributed equally.
†Corresponding author
Figure 1. Illustration of two online handwritten Chinese charac-ters, with each color representing a stroke. The increasing num-bers indicate the writing order from the start to the end. to progressively generate online characters (i.e., the hand-writing trajectory in a sequential format) [40]. As shown in
Figure 1, online characters convey richer information (e.g., the order of writing) and thus pave the way for various ap-plications, including writing robots [39].
Our goal is to automatically generate online Chinese handwritings that not only correspond to specific textual content, but also emulate the calligraphic style of a given exemplar writer (e.g., glyph slant, shape, stroke length, and curvature). This task thus holds potential for a wide range of applications, such as font design and calligraphy education.
A popular solution [18] is to extract style information from the provided stylized samples and merge it with the content reference. DeepImitator [44] concatenates the style vector obtained from a CNN encoder with a character embedding, which is then fed into the RNN decoder to generate styl-ized online characters. WriteLikeYou [30] adopts the large-margin softmax loss [36] to promote discriminative learning of style features. However, these methods mainly focus on the overall writing style, thus overlooking the detailed style inconsistencies (e.g., the highlighted regions in Figure 2) between characters produced by the same writer.
The observations mentioned above inspire us to disen-tangle style representations at the writer and character levels from the stylized handwritings. However, accurately cap-Figure 2. Handwritten character samples from three unique writ-ers, with each row containing characters by the same person. De-spite sharing similar overall handwriting styles (e.g., glyph slant), subtle style differences (e.g., stroke length, location, and curva-ture) can still be observed among them.
Figure 3. In this two-character example, we independently sample the positive pair, i.e., o and o+, within the first character, while the negative o− is sampled from another character. Our sampling strategy randomly selects a small subset of patches, following a uniform distribution. turing these two styles is a challenging task. To address this, we propose a style-disentangled Transformer (SDT) equipped with a dual-head style encoder. Specifically, we employ the contrastive learning framework [13] to guide each head in concentrating on writer-wise and character-wise styles, respectively. For the overall writer-wise style, we treat characters from the same writer as positive in-stances, and characters from different writers as negatives.
This enables the encoder to learn the style commonalities among characters written by the same writer. Regarding the detailed character-wise style, we independently sample pos-itive pairs within a character, and sample negative samples from other characters, as illustrated in Figure 3. Aggregat-ing positive views of a character encourages the encoder to focus on the intricate character style patterns.
In addition, we introduce a content encoder for SDT to learn a textual feature with a global context. The two style representations, along with the textual feature, are then fed into a decoder that progressively generates online charac-ters. Given that the output characters are in sequential form, we employ Transformer [35], a powerful sequence model-ing architecture, as our backbone.
To extend SDT for generating offline Chinese handwrit-tings (i.e., character images with stroke-width, e.g., Fig-ures 3-7 in Appendix), we further propose an offline-to-offline generation framework. We first use SDT to generate online characters with significant shape changes, and then decorate them with stroke width, ink-blot effects, etc. This enables us to generate authentic offline handwritings. For more details, please refer to Appendix A.4.
We summarize our contributions in three key aspects:
• We are the first to disentangle two style representations (i.e., writer-wise and character-wise) for enhancing
Chinese handwriting generation. Our findings show that the former focuses more on low-frequency infor-mation, while the latter captures higher frequencies.
• We introduce a novel online character generation method, i.e., SDT. Extensive experiments on handwrit-ing datasets in Chinese, English, Japanese, and Indic scripts demonstrate its effectiveness and superiority.
• Building on the SDT, we further develop an offline-to-offline framework that can produce more plausible offline handwritten Chinese characters, as evidenced in
Appendix A.4. 2.