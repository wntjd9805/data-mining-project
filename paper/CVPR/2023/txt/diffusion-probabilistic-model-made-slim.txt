Abstract
Despite the recent visually-pleasing results achieved, the massive computational cost has been a long-standing flaw for diffusion probabilistic models (DPMs), which, in turn, greatly limits their applications on resource-limited plat-forms. Prior methods towards efficient DPM, however, have largely focused on accelerating the testing yet overlooked their huge complexity and sizes.
In this paper, we make a dedicated attempt to lighten DPM while striving to pre-serve its favourable performance. We start by training a small-sized latent diffusion model (LDM) from scratch, but observe a significant fidelity drop in the synthetic images.
Through a thorough assessment, we find that DPM is in-trinsically biased against high-frequency generation, and learns to recover different frequency components at differ-ent time-steps. These properties make compact networks unable to represent frequency dynamics with accurate high-frequency estimation. Towards this end, we introduce a customized design for slim DPM, which we term as Spec-tral Diffusion (SD), for light-weight image synthesis. SD incorporates wavelet gating in its architecture to enable frequency dynamic feature extraction at every reverse step, and conducts spectrum-aware distillation to promote high-frequency recovery by inverse weighting the objective based on spectrum magnitude. Experimental results demonstrate that, SD achieves 8-18× computational complexity reduc-tion as compared to the latent diffusion models on a series of conditional and unconditional image generation tasks while retaining competitive image fidelity. 1.

Introduction
Diffusion Probabilistic Models (DPMs) [18, 57, 59] have recently emerged as a powerful tool for generative mod-eling, and have demonstrated impressive results in image synthesis [8, 45, 48], video generation [17, 20, 77] and 3D editing [43]. Nevertheless, the gratifying results come with a price: DPMs suffer from massive model sizes. In fact,
*Corresponding author
Figure 1. (1) Visualization of the frequency gap among generated images with the DPM [48], Lite DPM and our SD on FFHQ [27] dataset. Lite-DPM is unable to recover fine-grained textures, while
SD can produce realistic patterns. (2) Model size, Multiply-Add cumulation (MACs) and FID score on ImageNet [7]. Our model achieves compelling visual quality with minimal computational cost. ∗ indicates our re-implemented version. state-of-the-art DPMs requires billions of parameters, with hundreds or even thousands of inference steps per image.
For example, DALL· E 2 [45], which is composed of 4 sep-arate diffusion models, requires 5.5B parameters and 356 sampling steps in total. such an enormous model size, in turn, makes DPMs extremely cumbersome to be employed in resource-limited platforms.
However, existing efforts towards efficient DPMs have focused on model acceleration, but largely overlooked light-ening of the model. For example, the approaches of [1, 32, 37, 38, 40, 52, 56] strive for faster sampling, while those of [13, 19, 48, 62] rely on reducing the input size. Admit-tedly, all of these methods give rise to shortened training or inference time, yet still, the large sizes prevent them from many real-world application scenarios.
In this paper, we make a dedicated efforts towards build-ing compact DPMs. To start with, we train a lite version of the popular latent diffusion model (LDM) [48] by re-ducing the channel size. We show the image generated by the original and and lite DPM in Figure 1. While the lite
LDM sketches the overall structure of the faces, the high-frequency components, such as the skin and hair textures, are unfortunately poorly recovered. This phenomenon can be in fact revealed by the Discrete Fourier Transform (DFT) coefficient shown on the right column, indicating that the conventional design for DPMs leads to high-frequency de-ficiency when the model is made slim.
We then take an in-depth analysis on the DPMs through the lens of frequency, which results in two key obser-(1) Frequency Evolution. Under mild assump-vations. tions, we mathematically prove that DPMs learn different functionalities at different stages of the denoising process.
Specifically, we show that the optimal denoiser in fact boils down to a cascade of wiener filters [66] with growing band-widths. After recovering the low-frequency components, high-frequency features are added gradually in the later de-noising stages. This evolution property, as a consequence, small DPMs fails to learn dynamic bandwidths with limited (2) Frequency Bias. DPM is biased towards parameters. dominant frequency components of the data distribution. It is most obvious when the noise amplitude is small, lead-ing to inaccurate noise prediction at the end of the reverse process. As such, small DPMs struggle to recover the high-frequency band and image details.
Motivated by these observations, we propose a novel
Spectral Diffusion (SD) model, tailored for light-weight im-age synthesis. Our core idea is to introduce the frequency dynamics and priors into the architecture design and train-ing objective of the small DPM, so as to explicitly preserve the high-frequency details. The proposed solution consists of two parts, each accounting for one aforementioned obser-vations. For the frequency evolution, we propose a wavelet gating operation, which enables the network to dynamically adapt to the spectrum response at different time-steps. In the upsample and downsample stage, the input feature is first decomposed through wavelet transforms and the coef-ficients are re-weighted through a learnable gating function.
It significantly lowers the parameter requirements to repre-sent the frequency evolution in the reverse process.
To compensate for the frequency bias for small DPMs, we distill high-frequency knowledge from a teacher DPM to a compact network. This is achieved by inversely weight-ing the distillation loss based on the magnitudes of the fre-quency spectrum. In particular, we give more weight to the frequency bands with small magnitudes, which strength-ens the recovery of high-frequency details for the student model. By integrating both designs seamlessly, we build a slim latent diffusion model, called SD, which largely pre-serves the performance of LDM. Notably, SD inherits the advantages of DPMs, including superior sample diversity, training stability, and tractable parameterization. As shown in Figure 1, our model is 8 ∼ 18× times smaller and runs 2 ∼ 5× times faster than the original LDM, while achieving competitive image fidelity.
The contributions of this study are threefold: 1. This study investigates the task of diffusion model slimming, which remains largely unexplored before. 2. We identify that the key challenge lies in its unrealistic recovery for the high-frequency components. By prob-ing DPMs from a frequency perspective, we show that there exists a spectrum evolution over different denois-ing steps, and the rare frequencies cannot be accurately estimated by small models. 3. We propose SD, a slim DPM that effectively restores imagery textures by enhancing high-frequency genera-tion performance. SD achieves gratifying performance on image generation tasks at a low cost. 2.