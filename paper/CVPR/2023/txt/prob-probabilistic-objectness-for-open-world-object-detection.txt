Abstract
Open World Object Detection (OWOD) is a new and challenging computer vision task that bridges the gap be-tween classic object detection (OD) benchmarks and ob-In addition to detecting ject detection in the real world. and classifying seen/labeled objects, OWOD algorithms are expected to detect novel/unknown objects - which can be classiﬁed and incrementally learned. In standard OD, ob-ject proposals not overlapping with a labeled object are automatically classiﬁed as background. Therefore, simply applying OD methods to OWOD fails as unknown objects would be predicted as background. The challenge of detect-ing unknown objects stems from the lack of supervision in distinguishing unknown objects and background object pro-posals. Previous OWOD methods have attempted to over-come this issue by generating supervision using pseudo-labeling - however, unknown object detection has remained low. Probabilistic/generative models may provide a solu-tion for this challenge. Herein, we introduce a novel prob-abilistic framework for objectness estimation, where we al-ternate between probability distribution estimation and ob-jectness likelihood maximization of known objects in the embedded feature space - ultimately allowing us to estimate the objectness probability of different proposals. The result-ing Probabilistic Objectness transformer-based open-world detector, PROB, integrates our framework into traditional object detection models, adapting them for the open-world setting. Comprehensive experiments on OWOD benchmarks show that PROB outperforms all existing OWOD methods in both unknown object detection (∼ 2× unknown recall) and known object detection (∼ 10% mAP). Our code is available at https://github.com/orrzohar/PROB.
Figure 1. Comparison of PROB with other open world object de-tectors. (a) Query embeddings are extracted from an image via the deformable DETR model. (b) other open-world detectors at-tempt to directly distinguish between unlabeled ‘hidden’ objects and background without supervision (red). (c) PROB’s scheme of probabilistic objectness training and revised inference, which per-forms alternating optimization of (i) Embeddings distribution es-timation and (ii) likelihood maximization of embeddings that rep-resent known objects. (d) Qualitative examples of the improved unknown object detection of PROB on the MS-COCO test set. 1.

Introduction
Object detection (OD) is a fundamental computer vi-sion task that has a myriad of real-world applications, from autonomous driving [18, 25], robotics [4, 32] to health-care [6, 12]. However, like many other machine learning systems, generalization beyond the training distribution re-mains challenging [5] and limits the applicability of exist-ing OD systems. To facilitate the development of machine learning methods that maintain their robustness in the real world, a new paradigm of learning was developed – Open
World Learning (OWL) [8–10, 16, 17, 21, 27, 29–31, 34]. In
OWL, a machine learning system is tasked with reason-ing about both known and unknown concepts, while slowly learning over time from a non-stationary data stream.
In
Open World Object Detection (OWOD), a model is ex-pected to detect all previously learned objects while simul-taneously being capable of detecting novel unknown ob-jects. These ﬂagged unknown objects can be sent to an oracle (human annotator), which labels the objects of in-terest. The model is then expected to update itself without catastrophically forgetting previous object classes [10].
While unknown object detection is pivotal to the OWOD objective, existing OWOD methods have very low unknown object recall (∼10%) [8, 10, 30, 34]. As such, it is clear that the ﬁeld has much to improve to meet its actual goal. The difﬁculty of unknown object detection stems from a lack of supervision as, unlike known objects, unknown objects are not labeled. Hence, while training OD models, object pro-posals that include an unknown object would be incorrectly penalized as background. Thus far, most OWOD methods have attempted to overcome this challenge by using differ-ent heuristics to differentiate between unknown objects and background during training. For example, OW-DETR [8] uses a pseudo-labeling scheme where image patches with high backbone feature activation are determined to be un-known objects, and these pseudo-labels are used to super-vise the OD model. In contrast, instead of reasoning about known and unknown objects separately using labels and pseudo-labels, we take a more direct approach. We aim to learn a probabilistic model for general “objectness” (see
Fig. 1). Any object – both known and unknown – should have general features that distinguish them from the back-ground, and the learned objectness can help improve both unknown and known object detection.
Herein, we introduce the Probabilistic Objectness Open
World Detection Transformer, PROB. PROB incorporates a novel probabilistic objectness head into the standard de-formable DETR (D-DETR) model. During training, we al-ternate between estimating the objectness probability dis-tribution and maximizing the likelihood of known objects.
Unlike a classiﬁcation head, this approach does not re-quire negative examples and therefore does not suffer from the confusion of background and unknown objects. Dur-ing inference, we use the estimated objectness distribution to estimate the likelihood that each object proposal is in-deed an object (see Fig. 1). The resulting model is simple and achieves state-of-the-art open-world performance. We summarize our contributions as follows:
• We introduce PROB - a novel OWOD method. PROB incorporates a probabilistic objectness prediction head that is jointly optimized as a density model of the im-age features along with the rest of the transformer net-work. We utilize the objectness head to improve both critical components of OWOD: unknown object detec-tion and incremental learning.
• We show extensive experiments on all OWOD bench-marks demonstrating the PROB’s capabilities, which outperform all existing OWOD models. On MS-COCO, PROB achieves relative gains of 100-300% in terms of unknown recall over all existing OWOD methods while improving known object detection per-formance ∼ 10% across all tasks.
• We show separate experiments for incremental learn-ing tasks where PROB outperformed both OWOD baselines and baseline incremental learning methods. 2.