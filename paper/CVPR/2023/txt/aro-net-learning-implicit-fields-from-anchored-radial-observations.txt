Abstract
We introduce anchored radial observations (ARO), a novel shape encoding for learning implicit field representation of 3D shapes that is category-agnostic and generalizable amid significant shape variations. The main idea behind our work is to reason about shapes through partial observations from a set of viewpoints, called anchors. We develop a general and unified shape representation by employing a fixed set of an-chors, via Fibonacci sampling, and designing a coordinate-based deep neural network to predict the occupancy value of a query point in space. Differently from prior neural implicit models that use global shape feature, our shape encoder operates on contextual, query-specific features. To predict point occupancy, locally observed shape information from the perspective of the anchors surrounding the input query point are encoded and aggregated through an attention mod-ule, before implicit decoding is performed. We demonstrate the quality and generality of our network, coined ARO-Net, on surface reconstruction from sparse point clouds, with tests on novel and unseen object categories, “one-shape” training, and comparisons to state-of-the-art neural and classical methods for reconstruction and tessellation.
Figure 1. Neural 3D reconstruction using ARO-Net from sparse point clouds (1,024 or 2,048 points). Top: reconstruction results on airplanes, riffles, and animals when the network was trained only on chairs. Bottom: reconstruction of a variety of shapes when the network was train on numerous versions of one model - the
Fertility. See comparison to other methods in Section 4. 1.

Introduction
Despite the substantial progress made in deep learning in recent years, transferability and generalizability issues still persist due to domain shifts and the need to handle diverse, out-of-distribution test cases. For 3D shape representation learning, a reoccurring challenge has been the inability of trained neural models to generalize to unseen object cate-gories and diverse shape structures, as these models often overfit to or “memorize" the training data.
In this paper, we introduce a novel shape encoding for learning an implicit field [34] representation of 3D shapes that is category-agnostic and generalizable amid significant shape variations. In Figure 1 (top), we show 3D reconstruc-tions from sparse point clouds obtained by our approach that is trained on chairs but tested on airplanes, riffles, and
*Equal contribution
†Corresponding author. E-mail: ruizhen.hu@gmail.com animals. Our model can even reconstruct a variety of shapes when the training data consists of only one shape, augmented with rotation and scaling; see Figure 1 (bottom).
The main idea behind our work is to reason about shapes from partial observations at a set of viewpoints, called an-chors, and apply this reasoning to learn implicit fields. We develop a general and unified shape representation by des-ignating a fixed set of anchors and designing a coordinate-based neural network to predict the occupancy at a query point. In contrast to classical neural implicit models such as
IM-Net [8], OccNet [23], and DeepSDF [24], which learn global shape features for occupancy/distance prediction, our novel encoding scheme operates on local shape features obtained by viewing the query point from the anchors.
Specifically, for a given query point x, we collect locally observable shape information surrounding x, as well as direc-tional and distance information toward x, from the perspec-tive of the set of anchors, and encode such information using
Figure 2. 2D illustration of ARO and ARO-Net architecture: (a) Input point cloud (in grey) and a set of m fixed anchors (coloured dots). (b) Radial observation Oi from each anchor ai toward the query point x consists of closed points inside the cone apexed at ai, with axis ri = x − ai. (c) Each radial observation Oi is passed to a PointNet encoder to obtain an embedding feature fi, which is concatenated with ri and its norm to form the query-specific ARO encoding of x with respect to ai. Finally, all the ARO features are decoded into the occupancy value occ(x) though an attention module and several MLPs. For 3D reconstruction, the ARO features are computed for each query point, while the PointNet, attention module, and implicit decoder are fixed during inference – their weights were determined during training.
Figure 3. A somewhat extreme toy example comparing ARO-Net to prior occupancy prediction networks on 3D reconstruction from a sparse point cloud of a cube (a), with training on a single sphere.
The results from OccNet [23] and ConvONet) [25] show more signs of overfitting to the training sphere than ARO-Net (d).
PointNet [27]; see Figure 2(b). The PointNet features are then aggregated through an attention module, whose output is fed to an implicit decoder to produce the occupancy value for x. We call our query-specific shape encoding Anchored
Radial Observations, or ARO. The prediction network is coined ARO-Net, as illustrated in Figure 2.
The advantages of ARO for learning implicit fields are three-fold. First, shape inference from partial and local observations is not bound by barriers set by object categories or structural variations. Indeed, local shape features are more prevalent, and hence more generalizable, across categories than global ones [8, 23, 24]. Second, ARO is query-specific and the directional and distance information it includes is intimately tied to the occupancy prediction at the query point, as explained in Section 3.1. Last but not least, by aggregating observations from all the anchors, the resulting encoding is not purely local, like the voxel-level encoding or latent codes designed to better capture geometric details across large-scale scenes [3,15,25]. ARO effectively captures more global and contextual query-specific shape features.
In Figure 3, we demonstrate using a toy example the difference between ARO-Net and representative neural im-plicit models based on global (OccNet [23]) and local grid shape encodings (convolutional occupancy network or Con-vONet [25]), for the 3D reconstruction task. All three net-works were trained on a single sphere shape, with a single anchor for ARO inside the sphere. When tested on recon-structing a cube, the results show that both OccNet and
ConvONet exhibit more memorization of the training sphere either globally or locally, while the ARO-Net reconstruction is more faithful to the input without special fine-tuning.
In our current implementation of ARO-Net, we adopt Fi-bonacci sampling [19] to obtain the fixed set of anchors. We demonstrate the quality and generalizability of our method on surface reconstruction from sparse point clouds, with testing on novel and unseen object categories, as well as
“one-shape” training (see bottom of Figure 1). We report extensive quantitative and qualitative comparison results to state-of-the-art methods including both neural models for re-construction [8, 11, 23, 25, 26] and tessellation [7], as well as classical schemes such as screen Poisson reconstruction [18].
Finally, we conduct ablation studies to evaluate our choices for the number of anchors, the selection strategies, and the decoder architecture: MLP vs. attention modules. 2.