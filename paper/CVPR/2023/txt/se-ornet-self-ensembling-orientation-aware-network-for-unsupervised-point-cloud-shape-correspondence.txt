Abstract
Unsupervised point cloud shape correspondence aims to obtain dense point-to-point correspondences between point clouds without manually annotated pairs. However, hu-mans and some animals have bilateral symmetry and var-ious orientations, which lead to severe mispredictions of symmetrical parts. Besides, point cloud noise disrupts con-sistent representations for point cloud and thus degrades the shape correspondence accuracy. To address the above issues, we propose a Self-Ensembling ORientation-aware
Network termed SE-ORNet. The key of our approach is to exploit an orientation estimation module with a domain adaptive discriminator to align the orientations of point cloud pairs, which signiﬁcantly alleviates the mispredic-tions of symmetrical parts. Additionally, we design a self-ensembling framework for unsupervised point cloud shape correspondence.
In this framework, the disturbances of point cloud noise are overcome by perturbing the inputs of the student and teacher networks with different data aug-mentations and constraining the consistency of predictions.
Extensive experiments on both human and animal datasets show that our SE-ORNet can surpass state-of-the-art unsu-pervised point cloud shape correspondence methods. 1.

Introduction
With the cost of LiDAR and depth cameras falling, it is more accessible to obtain 3D point cloud data. For real-world applications, such as articulated motion trans-fer [5, 26] and non-rigid human body alignment [3], the correspondence between two point clouds is indispensable.
However, we are hard to directly obtain the correspondence between two raw point clouds due to various object orienta-tions and ununiﬁed coordinate systems.
To accurately ﬁnd the point-to-point correspondence be-∗Equal Contribution
†Corresponding Author
Figure 1. The visualization of dense point matching results.
Three point cloud pairs have different relative rotation angles. GT denotes ground truth. The correspondence is visualized by trans-ferring colors from source to target according to matching results.
The baseline predicts many false matches, especially for symmet-rical, similar parts of the object. Our method achieves accurate matches for these parts with our orientation estimation module. tween two point clouds, spectral-based methods [1, 9, 15, 19, 28] have been proven as practical shape correspondence methods by computing functional mapping between the projected features and learning a transformation for the cor-respondence. Nevertheless, the spectral-based methods suf-fer from complicated pre-processing steps and the neces-sity for connectivity information between points. With the rapid development of deep learning, many fully supervised point cloud shape correspondence methods [4, 8, 16] have been proposed to lead to remarkable progress. However, these methods rely on a large amount of carefully annotated point cloud pairs, which are expensive and time-consuming to collect. To relieve the annotation cost of fully super-vised methods, unsupervised methods [12, 32] that utilize unlabeled data for model training have attracted more and more attention. CorrNet3D [32] proposes the ﬁrst unsu-pervised deep learning framework for building dense corre-spondence between point clouds in an end-to-end manner.
DPC [12] models the local point cloud structure by explor-ing the proximity of points using DGCNN [29] and designs reconstruction losses to extract continuous point cloud rep-resentations. However, in the scanning process of 3D scan-ner, due to light, vibration and other factors, point cloud noise will be inevitably generated. Meanwhile, the pre-processing of point cloud (such as random subsampling) will also introduce noise. Unfortunately, the previous meth-ods fail to adequately consider the point cloud noise, which negatively impacts the point cloud representations. Besides the noise, existing methods lack attention to symmetrical parts of the body. The mismatching issue of symmetrical parts is challenging in this task, which was also spotted by the previous method [32] but has yet to be solved.
By studying the previous point-based shape correspon-dence methods [4, 8, 12, 16, 32], we summarize two key issues that need consideration to achieve a more accurate shape correspondence: 1) How to overcome the disturbance of point cloud noise to get robust and consistent point cloud representations? Point cloud noise perturbs the spatial co-ordinates of point cloud and interferes with local structure modeling. Therefore, it is necessary to overcome noise dis-turbances. 2) How to solve the mismatching issue of sym-metrical parts in point clouds with different body orienta-tions? As shown in Figure 1, for the pair of bilaterally sym-metrical human point clouds facing the opposite directions, existing methods predict the completely reverse and seri-ously wrong point cloud correspondence due to the similar structure and position. The speciﬁc relative rotation angles lead to severe mispredictions of symmetrical parts.
To achieve the above goals, we propose a Self-Ensembling Orientation-aware Network (SE-ORNet) for unsupervised point cloud shape correspondence. We inte-grate orientation modeling and consistent point cloud rep-resentations under a uniﬁed self-ensembling framework, which consists of a pair of teacher and student models, an orientation estimation module, and an adaptive domain dis-criminator. Firstly, we design a new augmentation scheme to produce augmented samples with rotation and Gaussian noise, and record the rotation angles as rotation angle labels.
Then, we formulate soft labels and consistency losses to encourage consensus among ensemble predictions of aug-mented and raw samples, aiming to perceive the difference in body orientation and overcome the point cloud noise dis-turbance to obtain consistent point cloud representations.
In addition, we design a plug-and-play lightweight Orien-tation Estimation Module, which aligns the orientations of two point clouds to solve the mismatching issue of symmet-rical parts in point clouds. Without the real label of rela-tive rotation angle between the source and target, we super-vise the training with the rotation angle labels and calculate angle losses. However, there is a noticeable domain gap between the rotation-augmented samples and the real sam-ples. Therefore, we design a discriminator to achieve do-main adaptation and calculate the domain losses. Further-more, the discriminator facilitates the Orientation Estima-tion Module to mine the valuable knowledge in the rotation-augmented samples to compensate for the information loss of the real relative rotation angles.
In summary, the main contributions of this work are as follows: (i) We design a plug-and-play lightweight Orien-tation Estimation Module that accurately aligns the orienta-tions of point cloud pairs to achieve correct matching re-sults of symmetrical parts. (ii) We integrate point cloud orientation modeling and consistent point cloud representa-tion learning with the disturbance of point cloud noise into a uniﬁed self-ensembling framework. (iii) Our method at-tains state-of-the-art performance on both human and ani-mal benchmarks, and extensive experimental results verify the superiority of our designs. 2.