Abstract
In recent years, several efforts have been aimed at im-proving the robustness of vision models to domains and environments unseen during training. An important practi-cal problem pertains to models deployed in a new geography that is under-represented in the training dataset, posing a direct challenge to fair and inclusive computer vision.
In this paper, we study the problem of geographic robust-ness and make three main contributions. First, we intro-duce a large-scale dataset GeoNet for geographic adapta-tion containing benchmarks across diverse tasks like scene recognition (GeoPlaces), image classification (GeoImNet) and universal adaptation (GeoUniDA). Second, we inves-tigate the nature of distribution shifts typical to the prob-lem of geographic adaptation and hypothesize that the ma-jor source of domain shifts arise from significant varia-tions in scene context (context shift), object design (de-sign shift) and label distribution (prior shift) across ge-ographies. Third, we conduct an extensive evaluation of several state-of-the-art unsupervised domain adaptation al-gorithms and architectures on GeoNet, showing that they do not suffice for geographical adaptation, and that large-scale pre-training using large vision models also does not lead to geographic robustness. Our dataset is publicly available at https://tarun005.github.io/GeoNet. 1.

Introduction
In recent years, domain adaptation has emerged as an effective technique to alleviate dataset bias [80] during train-ing and improve transferability of vision models to sparsely labeled target domains [27, 36, 40, 42, 49–51, 68, 69, 86, 89].
While being greatly instrumental in driving research forward, methods and benchmark datasets developed for domain adap-tation [56, 57, 64, 83] have been restricted to a narrow set of divergences between domains. However, the geographic ori-gin of data remains a significant source of bias, attributable to several factors of variation between train and test data. Train-ing on geographically biased datasets may cause a model to learn the idiosyncrasies of their geographies, preventing (a) Geographic bias manifested in proposed GeoNet dataset (b) Unsupervised domain adaptation does not suffice on GeoNet (c) Large vision models exhibit cross-domain drops on GeoNet
Figure 1. Summary of our contributions. (a): Training computer vision models on geographically biased datasets suffers from poor generaliza-tion to new geographies. We propose a new dataset called GeoNet to study this problem and take a closer look at the various types of domain shifts induced by geographic variations. (b) Prior unsupervised adapta-tion methods that efficiently handle other variations do not suffice for improving geographic transfer. (c) We highlight the limitations of mod-ern convolutional and transformer architectures in addressing geographic bias, exemplified here by USA→Asia transfer on GeoImNet. generalization to novel domains with significantly different geographic and demographic composition. Besides robust-ness, this may have deep impact towards fair and inclusive
computer vision, as most modern benchmark datasets like
ImageNet [63] and COCO [47] suffer from a significant US or UK-centric bias in data [24, 73], with poor representation of images from various other geographies like Asia.
In this paper, we study the problem of geographic adaptation by introducing a new large-scale dataset called
GeoNet, which constitutes three benchmarks – GeoPlaces for scene classification, GeoImNet for object recognition and
GeoUniDA for universal domain adaptation. These bench-marks contain images from USA and Asia, which are two distinct geographical domains separated by various cultural, economic, demographic and climatic factors. We addition-ally provide rich metadata associated with each image, such as GPS location, captions and hashtags, to facilitate algo-rithms that leverage multimodal supervision.
GeoNet captures the multitude of novel challenges posed by varying image and label distributions across geographies.
We analyze GeoNet through new sources of domain shift caused by geographic disparity, namely (i) context shift, where the appearance and composition of the background in images changes significantly across geographies, (ii) design shift, where the design and make of various objects changes across geographies, and (iii) prior shift, caused by different per-category distributions of images in both domains. We illustrate examples of performance drop caused by these fac-tors in Fig. 1a, where models trained on images from USA fail to classify common categories such as running track and mailbox due to context and design shifts, respectively.
GeoNet is an order of magnitude larger than previous datasets for geographic adaptation [58, 61], allowing the training of modern deep domain adaptation methods. Im-portantly, it allows comparative analysis of new challenges posed by geographic shifts for algorithms developed on other popular adaptation benchmarks [56, 57, 64, 83]. Specifically, we evaluate the performance of several state-of-the-art un-supervised domain adaptation algorithms on GeoNet, and show their limitations in bridging domain gaps caused by geographic disparities. As illustrated in Fig. 1b for the case of DomainNet [56] vs. GeoNet, state-of-the-art models on
DomainNet often lead to accuracies even worse than a source only baseline on GeoNet, resulting in negative relative gain in accuracy (defined as the gain obtained by an adaptation method over a source-only model as a percentage of gap be-tween a source-only model and the target-supervised upper bound). Furthermore, we also conduct a study of modern ar-chitectures like vision transformers and various pre-training strategies, to conclude that larger models with supervised and self-supervised pre-training offer improvements in accu-racy, which however are not sufficient to address the domain gap (Fig. 1c). This highlights that the new challenges intro-duced by geographic bias such as context and design shift are relatively under-explored, where our dataset may motivate further research towards this important problem.
In summary, our contribution towards geographic domain adaptation is four-fold:
• A new large-scale dataset, GeoNet, with benchmarks for diverse tasks like scene classification and object recogni-tion, with labeled images collected from geographically distant locations across hundreds of categories (Sec. 3).
• Analysis of domain shifts in geographic adaptation, which may be more complex and subtle than style or appearance variations (Sec. 3.4).
• Extensive benchmarking of unsupervised adaptation al-gorithms, highlighting their limitations in addressing geographic shifts (Sec. 4.2).
• Demonstration that large-scale pretraining and recent advances like vision transformers do not alleviate these geographic disparities (Sec. 4.3). 2.