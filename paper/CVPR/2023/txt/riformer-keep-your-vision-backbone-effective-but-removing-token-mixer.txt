Abstract
This paper studies how to keep a vision backbone ef-fective while removing token mixers in its basic building blocks. Token mixers, as self-attention for vision transform-ers (ViTs), are intended to perform information communica-tion between different spatial tokens but suffer from consid-erable computational cost and latency. However, directly removing them will lead to an incomplete model structure prior, and thus brings a significant accuracy drop. To this end, we first develop an RepIdentityFormer base on the re-parameterizing idea, to study the token mixer free model architecture. And we then explore the improved learn-ing paradigm to break the limitation of simple token mixer free backbone, and summarize the empirical practice into 5 guidelines. Equipped with the proposed optimization strat-egy, we are able to build an extremely simple vision back-bone with encouraging performance, while enjoying the high efficiency during inference. Extensive experiments and ablative analysis also demonstrate that the inductive bias of network architecture, can be incorporated into simple net-work structure with appropriate optimization strategy. We hope this work can serve as a starting point for the explo-ration of optimization-driven efficient network design. 1.

Introduction
The monumental advance in computer vision in the past few years was partly brought by the revolution of vision backbones, including convolutional neural networks (Con-vNets) [13, 17, 25, 30] and vision transformers (ViTs) [14, 38]. Both of them have particular modules in their basic building blocks that aggregate information between differ-ent spatial locations, which are called token mixer [46], such as self-attention for ViTs. Although the effective-∗ Corresponding author.
Figure 1. Latency analysis of different components in ViT-Base [14]. (a) For token mixer (self-attention), the latency oc-cupies about 46.3% of the backbone. (b) Our motivation was to remove the token mixer while striving to keep the performance. ness of token mixer has been demonstrated on many vision tasks [5, 6, 24, 45], its computational complexity typically takes up a significant portion of the network. In practice, heavy token mixers make the vision backbone limited espe-cially on the edge-side devices due to the issue of speed and computation cost.
There have been several attempts in the literature to in-vestigate efficient token mixers for slimming vision back-bones [29, 31, 46]. Although those works have already achieve competitive performance with light-weight design, they do retain the token mixers, which brings non-negligible increase in latency, as illustrated in Fig. 1. The recent work [47] finds that removing the token mixer is possible but leads to performance degeneration. Those explorations in efficient token mixers inspire us to think that can we keep the vision backbone effective but removing the token mixer?
The resulting token mixer free vision backbone is expected to be efficient and effective for the realistic application.
In this work, we first review the current model architec-tures and learning paradigms. Most of the previous works concentrate on the improvement of the architecture while adopting the conventional supervised learning to optimize the model from scratch. Differently, we propose to adopt the simplified model architecture, and explore the learning paradigm design to fully exploit the potential of the simple model. We aim to simultaneously maintain the efficiency and efficacy of token mixer free vision backbone (namely
IdentityFormer, in Fig. 1-(b)). To this end, we investigate the simple and yet effective learning strategy, knowledge distillation (KD) [18] thoroughly in the following sections.
Our main idea is distilling the knowledge from powerful teacher model (with token mixer) to the student model (to-ken mixer free). We instantiate the re-parameterizing idea to enlarge the modeling capacity of student network but retain its efficiency, as shown in Fig. 2. Specifically, the simple affine transformation is introduced into student model, to re-place the token mixer for training. The parameters of affine transformation can be merged into LayerNorm [2] during inference, which makes the student token mixer free finally.
We empirically summarize the our learning strategy as the following guidelines, hope to shed light on how to learn the extremely simple model. Concretely, 1) soft distillation without using ground-truth labels is more effective; 2) using affine transformation without distillation is difficult to tailor the performance degeneration; 3) the proposed block-wise knowledge distillation, called module imitation, helps lever-aging the modeling capacity of affine operator; 4) teacher with large receptive field is beneficial to improve receptive field limited student; 5) loading the pre-trained weight of teacher model (except the token mixer) into student improve the convergence and performance.
Based on the above guidelines, we finally obtain a to-ken mixer free vision model with competitive performance enjoying the high efficiency, dubbed as RepIdentityFormer (RIFormer). RIFormer shares nearly the same macro and micro design as MetaFormer [46], but safely removing all token mixers. The quantitative results show that our net-works outperform many prevailing backbones with faster inference speed on ImageNet-1K [8]. And the ablative analyses on the feature distribution and Effective Recep-tive Fields (ERFs) also demonstrate that the inductive bias brought by an explicit token mixer, can be implicitly incor-porated into the simple network structure with appropriate optimization strategies. In summary, the main contributions of our work are as the following:
• We propose to explore the vision backbone by develop-ing advanced learning paradigm for simple model archi-tecture, to satisfy the demand of realistic application.
• We instantiate the re-parameterizing idea to build a to-ken mixer free vision model, RIFormer, which owns the improved modeling capacity for the inductive bias while enjoying the efficiency during inference.
• Our proposed practical guidelines of distillation strategy has been demonstrated effective in keeping the vision backbone competitive but removing the token mixer. 2.