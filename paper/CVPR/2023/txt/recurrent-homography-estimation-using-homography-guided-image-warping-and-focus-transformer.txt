Abstract
We propose the Recurrent homography estimation framework using Homography-guided image Warping and
Focus transformer (FocusFormer), named RHWF. Both be-ing appropriately absorbed into the recurrent framework, the homography-guided image warping progressively en-hances the feature consistency and the attention-focusing mechanism in FocusFormer aggregates the intra-inter cor-respondence in a global→nonlocal→local manner. Thanks to the above strategies, RHWF ranks top in accuracy on a variety of datasets, including the challenging cross-resolution and cross-modal ones. Meanwhile, benefiting from the recurrent framework, RHWF achieves parame-ter efficiency despite the transformer architecture. Com-pared to previous state-of-the-art approaches LocalTrans and IHN, RHWF reduces the mean average corner error (MACE) by about 70% and 38.1% on the MSCOCO dataset, while saving the parameter costs by 86.5% and 24.6%. Sim-ilar to the previous works, RHWF can also be arranged in 1-scale for efficiency and 2-scale for accuracy, with the 1-scale RHWF already outperforming most of the previous methods. Source code is available at https://github. com/imdumpl78/RHWF. 1.

Introduction
Homography is defined as a global projective mapping between two images captured from different perspectives.
It has been widely applied in computer vision tasks rang-ing from the monocular camera system to the multi-camera system, such as image/video stitching [4, 17, 19], multi-scale gigapixel photography [3,34], multispectral image fu-sion [41,49], planar object tracking [44,45], SLAM [14,31], and GPS-denied UAV localization [18, 48].
Deep homography estimation was introduced in the pi-oneer [12] that uses a VGG-style network to predict the homography. Many following works have been presented to further improve the estimation accuracy, including cas-*Corresponding author.
Figure 1. Illustration of the difference of warping and attention strategies in RHWF and previous approaches. Our RHWF deploys (c) and (f). Please see text for details. cading multiple similar networks [15, 21, 22, 34] or design-ing iterable architectures such as the IC-LK iterator [7, 48] and the trainable CNN iterator [6]. The cascading strategy has improved the accuracy to some extent but is limited by the fixed number of networks. Worse still, stacking more networks cannot guarantee better accuracy [22]. The IC-LK (inverse compositional Lucas-Kanade [1]) based deep methods use deep feature extractor combined with the un-trainable iterator to improve the estimation performance, but is limited by the theoretical drawback of the untrainable iterator [6, 32]. IHN [6] avoids this limitation by designing an iterable and trainable network architecture, which fur-ther improves the estimation accuracy. However, the fea-ture inconsistency caused by the homography deformation has long been neglected in most current works.
It has been well investigated in [9] that standard convo-lution is unable to keep the equivariance under the spatial transformation except translation. However, besides trans-lation, homography is composed of rotation, scaling, shear-ing, aspect ratio, and perspective transformations [37, 43], which leads to the inconsistency of the features from cor-responding points [25]. The inconsistency will hinder the homography estimation performance. Many efforts have been made to acquire the transformation-equivariance by either applying group convolutions in the network [9] or pre-warping [16, 20, 25, 43] the input image. But the above strategies need to exhaustively explore the possible trans-formation dimensions and degrees, as is illustrated in Fig. 1a, which is redundant in computation when coping with
the homography transformation with a DOF of 6.
To cope with the above problem, homography-guided image warping, as shown in Fig. 1c, is adopted in our pro-posed recurrent homography estimation framework, dubbed
RHWF. We note that homography-guided image warping has already been unconsciously employed in some of the previous cascading-based works [15, 22, 34]. However, the reason, effect, and technique of using homography-guided image warping, especially absorbing it properly in the recurrent framework, hasn’t ever been investigated.
Different from the previous works, our RHWF combines the homography-guided image warping with the recurrent trainable network, which significantly improves the ac-curacy without the cost of network parameters. Com-pared to the previous cascading-based SOTA method Lo-calTrans [34], RHWF reduces the mean average corner er-ror (MACE) by about 70% on the MSCOCO dataset, while reducing the parameter cost of 86.5%.
On the other side, transformer architecture [8, 13] has demonstrated its superior ability in computer vision and image processing tasks. The transformer architecture has also been introduced in the homography estimation task as in [21,34]. Following their pioneer exploration, we propose a transformer structure, named FocusFormer, that is pretty compatible with the homography-guided image warping and the recurrent framework. As illustrated in Fig. 1d, Fig. 1e, and Fig. 1f, unlike the attention mechanism in previous works that is pure global or local, FocusFormer employs the attention focusing mechanism. The scope of the attention mechanism shrinks along with the recurrence procedure, which captures the intra/inter correspondence information in a global→nonlocal→local1 manner. We note that com-pared to the most widely adopted global attention mecha-nism, the attention-focusing mechanism can save computa-tion costs while improving the homography estimation per-formance simultaneously.
We introduce the homography-guided image warping and FocusFormer into the recurrent homography estima-tion framework, named RHWF. The three parts, i.e., recur-rent estimation, homography-guided image warping, and the FocusFormer cooperate well, with each part facilitat-ing the others. We evaluate RHWF on a variety of datasets including common RGB image data [24], cross-resolution data [34] and cross-modal data [6, 48], on which it outper-forms all other competitors by a large gap. We show that though adopting the transformer, our RHWF reduces the pa-rameter cost of 24.6% while achieving the accuracy gain of 38.1% (MSCOCO) and 34.1% (GoogleMap), compared to the previous SOTA method IHN [6]. In summary, our con-tributions are as follows: (1) We propose a novel Recurrent homography estimation framework using Homography-1As in most of the works that refer to “nonlocal” [5], it denotes a rela-tively large neighborhood around a pixel. guided image Warping and FocusFormer, dubbed RHWF.
RHWF ranks top on a variety of datasets, including the chal-lenge scenes such as the cross-resolution and cross-modal ones. The recurrent estimation, homography-guided im-age warping, and FocusFormer facilitate the functionality of each other. (2) The reason, effect, and technique of using homography-guided image warping properly in the recur-rent framework is first fully investigated. With the assis-tance of homography-guided image warping, the extracted features gradually converge into consistency, and hence boosting the homography estimation accuracy. (3) The Fo-cusFormer is proposed to be the fundamental block of the recurrent homography estimation. The attention mecha-nism in FocusFormer works in a global→nonlocal→local manner, which significantly saves the computational costs while achieving a better performance. 2.