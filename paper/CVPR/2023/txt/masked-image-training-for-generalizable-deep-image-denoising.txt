Abstract
When capturing and storing images, devices inevitably introduce noise. Reducing this noise is a critical task called image denoising. Deep learning has become the de facto method for image denoising, especially with the emergence of Transformer-based models that have achieved notable state-of-the-art results on various image tasks. However, deep learning-based methods often suffer from a lack of generalization ability. For example, deep models trained on
Gaussian noise may perform poorly when tested on other noise distributions. To address this issue, we present a novel approach to enhance the generalization performance of denoising networks, known as masked training. Our method involves masking random pixels of the input image and reconstructing the missing information during training.
We also mask out the features in the self-attention layers to avoid the impact of training-testing inconsistency. Our approach exhibits better generalization ability than other deep learning models and is directly applicable to real-world scenarios. Additionally, our interpretability analysis demonstrates the superiority of our method. 1.

Introduction
Image denoising is a crucial research area that aims to recover clean images from noisy observations. Due to the rapid advancements in deep learning, many promising im-age denoising networks have been developed. These net-works are typically trained using images synthesized from a pre-defined noise distribution and can achieve remarkable performance in removing the corresponding noise. How-ever, a significant challenge in applying these deep models to real-world scenarios is their generalization ability. Since
*Haoyu Chen and Jinjin Gu contribute equally to this work.
†Lei Zhu (leizhu@ust.hk) is the corresponding author.
Figure 1. We illustrate the generalization problem of denois-ing networks. We train a SwinIR model on Gaussian noise with
σ = 15. When tested on the same noise, SwinIR demon-strates outstanding performance. However, when applied to out-of-distribution noise, e.g., the mixture of various noise. SwinIR suffers from a huge performance drop. The model trained by the proposed masked training method maintains a reasonable denois-ing effect, despite aldo being trained on Gaussian noise. the real-world noise distribution can differ from that ob-served during training, these models often struggle to gen-eralize to such scenarios.
More specifically, most existing denoising works train and evaluate models on images corrupted with Gaussian noise, limiting their performance to a single noise distri-bution. When these models are applied to remove noise drawn from other distributions, their performance drasti-cally drops. Figure 1 shows an example. The research community has become increasingly aware of this gener-alization issue of deep models in recent years. As a coun-termeasure, some methods [80] assume that the noise level of a particular noise type is unknown, while others [5, 68] attempt to improve the performance in real-world scenarios by synthesizing or collecting training data closer to the tar-get noise or directly performing unsupervised training on the target noise [11, 71]. However, none of these meth-ods substantially improve the generalization performance of denoising networks, and they still struggle when the noise distribution is mismatched [1]. The generalization issue of
deep denoising still poses challenges to making these meth-ods broadly applicable.
In this work, we focus on improving the generalization ability of deep denoising models. We define generalization ability as the model’s performance on noise different from what it observed during training. We argue that the gener-alization issue of deep denoising is due to the overfitting of training noise. The existing training strategy directly op-timizes the similarity between the denoised image and the ground truth. The intention behind this is that the network should learn to reconstruct the texture and semantics of nat-ural images correctly. However, what is often overlooked is that the network can also reduce the loss simply by overfit-ting the noise pattern, which is easier than learning the im-age content. This is at the heart of the generalization prob-lem. Even many popular deep learning methods exacerbate this overfitting problem. When it comes to noise different from that observed during training, the network exhibits this same behavior, resulting in poor performance.
In light of the preceding discussion, our study seeks to improve the generalization performance of deep de-noising networks by directing them to learn image con-tent reconstruction instead of overfitting to training noise.
Drawing inspiration from recent masked modeling methods
[4, 20, 34, 69], we employ a masked training strategy to ex-plicitly learn representations for image content reconstruc-tion, as opposed to training noise. Leveraging the properties of image processing Transformers [15,45,78], we introduce two masking mechanisms: the input mask and the attention mask. During training, the input mask removes input image pixels randomly, and the network reconstructs the removed pixels. The attention mask is implemented in each self-attention layer of the Transformer, enabling it to learn the completion of masked features dynamically and mitigate the distribution shift between training and testing in masked learning. Although we use Gaussian noise for training – similar to previous works – our method demonstrates sig-nificant performance improvements on various noise types, such as speckle noise, Poisson noise, salt and pepper noise, spatially correlated Gaussian noise, Monte Carlo-rendered image noise, ISP noise, and complex mixtures of multiple noise sources. Existing methods and models have yet to ef-fectively and accurately remove all these diverse noise pat-terns. 2.