Abstract
Virtually every object in the modern world was created, modified, analyzed and optimized using computer aided de-sign (CAD) tools. An active CAD research area is the use of data-driven machine learning methods to learn from the massive repositories of geometric and program represen-tations. However, the lack of labeled data in CAD’s na-tive format, i.e., the parametric boundary representation (B-Rep), poses an obstacle at present difficult to overcome.
Several datasets of mechanical parts in B-Rep format have recently been released for machine learning research. How-ever, large-scale databases are mostly unlabeled, and la-beled datasets are small. Additionally, task-specific label sets are rare and costly to annotate. This work proposes to leverage unlabeled CAD geometry on supervised learn-ing tasks. We learn a novel, hybrid implicit/explicit surface representation for B-Rep geometry. Further, we show that this pre-training both significantly improves few-shot learn-ing performance and achieves state-of-the-art performance on several current B-Rep benchmarks. 1.

Introduction
Almost every human-made object that exists today started its life as a model in a CAD system. As the preva-lent method of creating 3D shapes, repositories of CAD models are extensive. Further, CAD models have a robust structure, including geometric and program representations that have the potential to expose design and manufactur-ing intent. Learning from CAD data can therefore enable a variety of applications in design automation and design-and fabrication-aware shape reconstruction and reverse en-gineering.
An important challenge in learning from CAD is that most of this data does not have labels that can be lever-aged for inference tasks. Manually labeling B-Rep data is time consuming and expensive, and its specialized format requires CAD expertise, making it impractical for large col-lections.
In this work we ask: how can we leverage large databases of unlabeled CAD geometry for analysis and modeling tasks that typically require labels for learning?
Our work is driven by a simple, yet fundamental observa-tion: the CAD data format was not developed to enable easy visualizing or straightforward geometric interpretation: it is a format designed to be compact, have infinite resolu-tion, and allow easy editing. Indeed, CAD interfaces con-sistently run sophisticated algorithms to convert the CAD representation into geometric formats for rendering. Driven by this observation, our key insight is to leverage large col-lections of unlabeled CAD data to learn to geometrically interpret the CAD data format. We then leverage the net-works trained over the geometric interpretation task in su-pervised learning tasks where only small labeled collections are available. In other words, we use geometry as a model of self-supervision and apply it to few-shot-learning.
Specifically, we learn to rasterize local CAD geometry using an encoder-decoder structure. The standard CAD format encodes geometry as parametric boundary repre-sentations (B-Reps). B-Reps are graphs where the nodes are parametric geometry (surfaces, curves, and points) and edges denote the topological adjacency relationships be-tween the geometry.
Importantly, the parametric geome-try associated with each node is unbounded, and bounds are computed from the topological relationships: curves bound-ing surfaces and points bounding curves. As shown in Fig-ure 2, the geometry of a B-Rep face is computed by clipping the surface primitive to construct a surface patch, where the clipping mask is constructed from adjacent edges.
Figure 2. A B-Rep face (a) is a surface patch cut from a geometric primitive surface (b). The adjacent edges define a clipping mask (c), which we learn an SDF (d).
Thus, B-reps are constructed piecewise by explicitly de-fined surfaces with implicitly defined boundaries. This ob-servation drives our proposed learning architecture, which reconstructs faces by jointly decoding the explicit surface parameterization as well as the implicit surface boundary.
Our proposed encoder uses message passing on the topo-logical graph to capture the boundary information to encode
B-Rep faces. To handle graph heterogeneity (nodes com-prised of faces, edges, and, vertices), we use a hierarchical message passing architecture inspired by the Structured B-Rep GCN [16]. Our decoder uses the learned embeddings as latent codes for two per-face neural function evaluators: one mapping from R2 → R3 that encodes the face’s para-metric surface (Figure 2 (b)), and one mapping R2 → R that encodes the face’s boundary as a signed distance field (SDF) within the parametric surface (Figure 2 (c,d)).
We apply our proposed model of B-Rep self-supervision to learn specialized B-Rep tasks from very small sets of la-beled data—10s to 100s of examples vs 10k to 100k. To do this, we use the embeddings learned on self-supervision as input features to supervised tasks. We evaluate our ap-proach on three tasks and datasets from prior work [3,6,21] and validate our findings across varying training set sizes.
We show that our model consistently outperforms prior su-pervised approaches, significantly improving performance on smaller training sets. By using less data, our approach also proves substantially faster to train, making possible ap-plications that depend on training speed. We believe that our differentiable CAD rasterizer paves the way to many exciting future applications, and show one possibility by prototyping a reverse engineering example. 2.