Abstract
Lane graph estimation is an essential and highly challeng-ing task in automated driving and HD map learning. Exist-ing methods using either onboard or aerial imagery struggle with complex lane topologies, out-of-distribution scenar-ios, or significant occlusions in the image space. Moreover, merging overlapping lane graphs to obtain consistent large-scale graphs remains difficult. To overcome these challenges, we propose a novel bottom-up approach to lane graph esti-mation from aerial imagery that aggregates multiple over-lapping graphs into a single consistent graph. Due to its modular design, our method allows us to address two com-plementary tasks: predicting ego-respective successor lane graphs from arbitrary vehicle positions using a graph neural network and aggregating these predictions into a consistent global lane graph. Extensive experiments on a large-scale lane graph dataset demonstrate that our approach yields highly accurate lane graphs, even in regions with severe occlusions. The presented approach to graph aggregation proves to eliminate inconsistent predictions while increas-ing the overall graph quality. We make our large-scale urban lane graph dataset and code publicly available at http://urbanlanegraph.cs.uni-freiburg.de. 1.

Introduction
Most automated driving vehicles rely on the knowledge of their immediate surroundings to safely navigate urban environments. Onboard sensors including LiDARs and cam-eras provide perception inputs that are utilized in multiple tasks such as localization [7, 21, 27], tracking [4], or scene understanding [20, 24, 26, 37] to aggregate representations of the environment. However, robust planning and control typically require vastly more detailed and less noisy world models in the form of HD map data [12]. In particular, infor-mation on lane parametrization and connectivity is essential for both planning future driving maneuvers as well as high-level navigation tasks. Creating and maintaining HD maps in the form of lane graphs is a time-consuming and arduous
*Equal contribution
Figure 1. Our approach predicts accurate lane graphs from aerial images of complex urban environments. We visualize the estimated lane graph in magenta and indicate model initialization points with yellow circles. task due to the large amount of detail required in the anno-tation and the data curation process including map updates based on local environment changes such as construction sites.
Previous approaches to lane graph estimation have shown shortcomings in predicting lane graphs due to multiple defi-ciencies: On the one hand, methods using onboard imagery typically degrade at complex real-world intersections and under significant occlusions, e.g., when following another vehicle [5, 6]. On the other hand, methods based on aerial imagery show reduced performance when confronted with occlusions in the bird’s-eye-view (BEV) due to, e.g., vege-tation or shadows, and suffer from catastrophic drift when unconstrained in out-of-distribution scenarios [30]. Previous works treat intersections and non-intersections inherently differently [15] and thus require elaborated heuristics and post-processing to merge single predictions into a consistent lane graph. Moreover, prior works do not focus on use cases where multiple predicted graphs must be merged into a sin-gle consistent solution, which is essential for enabling the automatic generation of highly detailed lane graphs of large contiguous regions.
Related to the aforementioned challenges, we propose a novel two-stage graph neural network (GNN) approach termed LaneGNN that operates on single aerial color images for lane graph prediction. Inspired by methods in the field of trajectory prediction [8], we formulate a bottom-up ap-proach according to which we place a virtual agent into a local crop of the aerial image and predict reachable successor lane graphs from its positions. To transform multiple disjoint local solutions into a single global solution, we aggregate a global representation by iteratively inferring the lane graph from consecutive poses, ultimately imitating real-world driv-ing behavior. This iterative approach not only increases the predicted area covered but also improves graph accuracy based on data association and rejection. Note that we do not require any human in the loop to perform the graph aggre-gation. We visualize the output of our graph aggregation procedure in Fig. 1, in which we superimpose the predicted graph on the aerial image input. Using this framework, we envision two applications: ego-centered successor path pre-diction and full lane graph estimation by aggregation.
To summarize, the main contributions of this work are:
• An innovative bottom-up approach to lane graph estima-tion in challenging environments that explicitly encodes graph-level lane topology from input aerial images in a scenario-agnostic manner.
• A novel graph aggregation scheme enabling robust and method-agnostic merging of graph-level predictions.
• The large-scale lane graph dataset UrbanLaneGraph comprising high-resolution aerial images aligned with dense lane graph annotations aggregated from the Ar-goverse2 dataset that we make publicly available.
• Extensive experiments and ablation studies demonstrat-ing the significance of our findings. 2.