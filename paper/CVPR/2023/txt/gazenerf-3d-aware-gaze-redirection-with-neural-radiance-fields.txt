Abstract
We propose GazeNeRF, a 3D-aware method for the task of gaze redirection. Existing gaze redirection meth-ods operate on 2D images and struggle to generate 3D consistent results. Instead, we build on the intu-ition that the face region and eyeballs are separate 3D structures that move in a coordinated yet independent fashion. Our method leverages recent advancements in conditional image-based neural radiance fields and pro-poses a two-stream architecture that predicts volumetric features for the face and eye regions separately. Rigidly transforming the eye features via a 3D rotation matrix provides fine-grained control over the desired gaze an-gle. The final, redirected image is then attained via dif-ferentiable volume compositing. Our experiments show that this architecture outperforms na¨ıvely conditioned
NeRF baselines as well as previous state-of-the-art 2D gaze redirection methods in terms of redirection accu-racy and identity preservation. Code and models will be released for research purposes. 1.

Introduction
Gaze redirection is the task of manipulating an in-put image of a face such that the face in the output image appears to look at a given target direction, with-out changing the identity or other latent parameters of the subject. Gaze redirection finds applications in video conferencing [31], image and movie editing [3], human-computer interaction [23], and holds the poten-tial to enhance life-likeness of avatars for the metaverse (e.g., [2,42]). It has furthermore been shown that gaze-redirected images can be used to synthesize training data for downstream tasks such as person-specific gaze estimation [7, 41].
Existing gaze redirection methods formulate this task as a 2D image manipulation problem. Either by
∗These two authors contributed equally to this work.
Figure 1. GazeNeRF consists of a NeRF-based two-stream-MLP structure conditioned on a target gaze label to gen-erate the photo-realistic face images. A 3D rotation trans-formation R is applied on eyes stream of GazeNeRF. warping select pixels of the input image [3,35,36,38], or by synthesizing new images via deep generative mod-els such as Generative Adversarial Networks (GANs)
[7, 10], encoder-decoder networks [22], or Variational
Autoencoders (VAEs) [41].
Image warping methods can not model large changes due to the inability to gen-erate new pixels. While 2D generative models can pro-duce high-quality images and allow for large gaze direc-tion changes, they do not take the 3D nature of the task into consideration. This can lead to spatio-temporal or identity inconsistencies where other latent variables are entangled with the gaze direction. Some 2D methods attempt to simulate the eyeball rotation by applying a 3D rotation matrix in latent space [22, 41]. However, these injected implicit priors are weak and do not ex-plicitly model the 3D nature of the task.
In this paper, we address these issues by reformulat-ing gaze redirection as a 3D task and propose a novel 3D-aware gaze redirection method GazeNeRF. Our ap-proach leverages recent advances in image-based con-ditional neural radiance fields [8] to inherit the ability to generate images of excellent quality. The physical face and eyes are not a monolithic 3D structure but
are composed of two 3D structures – the face without eyes that deforms and the eyes only that rotates when we move our eyes. Hence, we model the two structures as separate feature volumes with neural radiance field (NeRF) models. To this end, our work shares similari-ties to EyeNeRF [16], but their focus is on high-fidelity rendering and relighting quality, whereas we are con-cerned with gaze redirection accuracy.
To endow NeRF architectures with 3D-aware gaze redirection capabilities, we propose a novel two-stream multilayer-perceptron (MLP) structure that predicts feature maps for the eye-balls (eyes) and the rest of the face region (face only) separately (see Fig. 1). The fea-tures of the eyes region are transformed via the desired 3D rotation matrix, before compositing the regions via differentiable volume rendering. With the explicit sep-aration of the eyeballs, GazeNeRF rigidly rotates the 3D features which we show to be beneficial for gaze redirection accuracy. To be able to train the model, we propose the feature composition at end of the two-stream MLPs and additional training losses to enhance the functionality of gaze redirection.
We find that GazeNeRF outperforms previous state-of-the-art methods [8,41] for gaze redirection on multi-ple datasets in terms of gaze and head pose redirection accuracy and identity preservation, evidencing the ad-vantage of formulating the task as a 3D-aware problem.
In summary, our contributions are as follows:
• We re-formulate the task of gaze redirection as 3D-aware neural volume rendering.
• GazeNeRF learns to disentangle the features of the face and eye regions, which allows for the rigid transformation of the eyeballs to the desired gaze direction.
• State-of-the-art performance in gaze redirection accuracy under identity preservation across differ-ent datasets. 2.