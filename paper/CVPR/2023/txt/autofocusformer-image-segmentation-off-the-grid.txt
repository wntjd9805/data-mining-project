Abstract
Real world images often have highly imbalanced content density. Some areas are very uniform, e.g., large patches of blue sky, while other areas are scattered with many small objects. Yet, the commonly used successive grid downsam-pling strategy in convolutional deep networks treats all ar-eas equally. Hence, small objects are represented in very few spatial locations, leading to worse results in tasks such as segmentation.
Intuitively, retaining more pixels repre-senting small objects during downsampling helps to pre-serve important information. To achieve this, we propose
AutoFocusFormer (AFF), a local-attention transformer im-age recognition backbone, which performs adaptive down-sampling by learning to retain the most important pixels for the task. Since adaptive downsampling generates a set of pixels irregularly distributed on the image plane, we aban-don the classic grid structure. Instead, we develop a novel point-based local attention block, facilitated by a balanced clustering module and a learnable neighborhood merging module, which yields representations for our point-based versions of state-of-the-art segmentation heads. Experi-ments show that our AutoFocusFormer (AFF) improves sig-nificantly over baseline models of similar sizes. 1.

Introduction
Typical real-world images distribute content unevenly.
Consider the photo of a typical outdoor scene in Fig. 1:
Large swaths of the image contain textureless regions like the ground, while a few regions contain many small ob-jects. Despite this, most computer vision neural networks distribute computation evenly across the image; every pixel, regardless of texture or importance, is processed with the same computational cost. Popular convolutional neural net-works operate on regularly-arranged square patches. Al-*Work done while Chen Ziwen was an intern at Apple Inc.
Figure 1. Comparison between on-grid model Swin [16] and off-grid model AFF. The red pixels indicate the locations of the re-maining tokens. AFF downsamples non-uniformly, automatically focusing on more textured, important image regions, which lead to better performance on small objects in the scene. though recent transformer architectures do not strictly de-pend on a grid structure, many transformer-based meth-ods adopt grid-based techniques such as stride-16 convolu-tions [5] and 7 × 7 square windows for local attention [16].
Despite its popularity, uniform downsampling is less effective for tasks that require pixel-level details such as segmentation. Here, uniform downsampling unfortunately makes tiny objects even tinier – possibly dropping needed, pixel-level information. To combat this, many techniques increase the input resolution [6,31] to obtain better segmen-tation performance. This intuitively helps, as larger input will lead to higher resolution after downsampling. How-ever, increasing input resolution is costly in memory and computation, as this brute-force bandaid neglects the under-Figure 2. The network architecture of AutoFocusFormer. The model consists of four stages, each stage processing a successively down-sampled set of tokens. Within each stage, tokens first go through balanced clustering, then attend to the tokens in their local neighborhoods defined by the nearby clusters in the following local-attention blocks, and finally adaptively merge into the set of downsampled output tokens with weights modulated by the learnable importance scores. lying issue – namely, uniform downsampling. Some prior works amend this by irregularly sampling points in the seg-mentation decoder [13], but by still relying on a uniformly-downsampled convolutional encoder, these techniques re-main susceptible to the pitfalls of uniform downsampling.
To address this concern, we need solutions that en-able computer vision models to allocate computation non-In particular, we need a uniformly across each image. downsampling strategy that retains important details, while more aggressively summarizing texture-less regions such as sky or road. However, non-uniform downsampling breaks from the grid structure that existing architectures rely on.
Prior work on adaptive downsampling [8, 14, 27] addresses this by simply using global attention, but global attention does not scale to resolutions much higher than that of Ima-geNet, such as those required for segmentation tasks.
To satisfy this need for adaptive, scalable downsampling strategies, we propose AutoFocusFormer (AFF). To our knowledge, AFF is the first end-to-end segmentation net-work with successive adaptive downsampling stages. To scale to higher resolutions required in segmentation tasks,
AFF employs local attention blocks.
In order to define local attention neighborhoods among irregularly sampled tokens, we develop a novel balanced clustering algorithm which employs space-filling curves to group irregular loca-tions into neighborhoods. We also propose a novel adaptive downsampling module that learns the importance of differ-ent image locations through a differentiable neighborhood merging process (Fig. 4). Finally, we modify state-of-the-art segmentation heads so that they can be applied on the irregular-spaced representations our backbone generates.
Our AutoFocusFormer attains state-of-the-art perfor-mance with less computational cost across major segmenta-tion tasks, with especially strong results when using smaller models. Furthermore, by moving away from the grid struc-ture, our downsampling strategy can support a larger range of computational budget by retaining any number of tokens, rather than operating only at rates of 1/4, 1/16 etc.
To summarize, our contributions are:
• To our knowledge, we introduce the first end-to-end segmentation network with successive adaptive down-sampling stages and with flexible downsampling rates.
• To facilitate a local attention transformer on irregularly spaced tokens, we propose a novel balanced clustering algorithm to group tokens into neighborhoods. We also propose a neighborhood merging module that enables end-to-end learning of adaptive downsampling.
• We adapt state-of-the-art decoders such as deformable
DETR [49], Mask2Former [2] and HCFormer [34] to operate on irregularly spaced sets of tokens.
• Results show that our approach achieves state-of-the-art for both image classification and segmentation with fewer FLOPs, and improves significantly on the recog-nition of small objects in instance segmentation tasks.
2.