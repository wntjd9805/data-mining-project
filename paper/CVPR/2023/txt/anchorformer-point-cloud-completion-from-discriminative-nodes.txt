Abstract
Point cloud completion aims to recover the completed 3D shape of an object from its partial observation. A common strategy is to encode the observed points to a global fea-ture vector and then predict the complete points through a generative process on this vector. Nevertheless, the results may suffer from the high-quality shape generation problem due to the fact that a global feature vector cannot sufficient-ly characterize diverse patterns in one object. In this pa-per, we present a new shape completion architecture, name-ly AnchorFormer, that innovatively leverages pattern-aware discriminative nodes, i.e., anchors, to dynamically capture regional information of objects. Technically, AnchorFormer models the regional discrimination by learning a set of an-chors based on the point features of the input partial ob-servation. Such anchors are scattered to both observed and unobserved locations through estimating particular offset-s, and form sparse points together with the down-sampled points of the input observation. To reconstruct the fine-grained object patterns, AnchorFormer further employs a modulation scheme to morph a canonical 2D grid at in-dividual locations of the sparse points into a detailed 3D structure. Extensive experiments on the PCN, ShapeNet-55/34 and KITTI datasets quantitatively and qualitatively demonstrate the efficacy of AnchorFormer over the state-of-the-art point cloud completion approaches. Source code is available at https://github.com/chenzhik/AnchorFormer. 1.

Introduction
As a 3D data description, point cloud can characterize various attributes of real-world objects. Although the point cloud data is readily acquired via laser scanners or depth cameras, factors like occlusion, transparency of surface, or the limit of sensor resolution, often cause geometric infor-mation loss and result in incomplete point cloud. As a re-sult, it is an essential task of point cloud completion to im-prove the data quality for the downstream tasks, e.g., point
Figure 1. An illustration of point cloud completion by leveraging (a) a global feature vector and (b) anchors in our AnchorFormer.
We highlight the reconstruction results of two local patterns in the bounding boxes and visualize the details in the zoomed-in view.
The L1 Chamfer Distance are also given. cloud classification [21â€“23] and 3D object detection [20].
Recent works [1, 34, 41, 46, 47] on point cloud comple-tion usually formulate the task as a generation problem and mainly capitalize on an encoder-decoder architecture. The input partial points are encoded as a global feature vec-tor which is further decoded to reconstruct the point cloud.
Figure 1(a) conceptually depicts a typical process of point cloud completion through leveraging a global feature vec-tor, which is generally measured by the pooling operation in the encoding phase to encapsulate the holistic shape in-formation. The pooling operation inevitably leads to the loss of the fine-grained details and limits the capability of the global feature. It is thus difficult to decode from such degenerated global feature vector to reconstruct the diverse patterns of a 3D object, especially for completing some ge-ometric details, e.g., the airplane tail in the green box in
Figure 1(a). In contrast, we propose to rebuild object shape from a set of discriminative nodes, i.e., anchors, which in-dicate the local geometry of different patterns in an object, as shown in Figure 1(b). We derive the anchors from the input partial observation via self-attention. As such, the
anchors could adequately infer the key patterns of the ob-served points. Moreover, some anchors can even be scat-tered into the unobserved locations to represent the missing parts and potentially capable of holistically reconstructing all patterns in the object. Taking the anchors and the down-sampled points of the input observation as the sparse points, we reform the fine-grained shape structure at the location of each sparse point to complete the point cloud of the object.
By exploiting the idea of shape reconstruction from pattern-aware discriminative nodes, we present a novel
Anchor-based Transformer architecture namely Anchor-Former for point cloud completion. Given the input par-tial observation of a 3D object, AnchorFormer first down-samples the points and extracts the point features via an
EdgeConv-based head [32]. Next, a transformer encoder takes the point features of down-sampled points as the in-puts and is learnt to predict a set of coordinates, i.e., an-chors, in each basic block of the encoder. Meanwhile, the point features of down-sampled points and anchors are also refined through the encoder. The anchors are further scat-tered into different 3D locations by learning specific off-sets. Finally, AnchorFormer combines the down-sampled points and anchors as sparse points, and deliberately devis-es a morphing scheme to deform a canonical 2D grid at the location of each sparse point into a 3D structure. The whole architecture of AnchorFormer is optimized with respect to two objectives: the Chamfer Distance between the predict-ed points and the ground-truth points, and the compactness constraint of the generated points in each pattern.
The main contribution of this paper is the proposed An-chorFormer for reconstructing shape in point cloud com-pletion. This issue also leads to the elegant views of how to characterize the geometric patterns in an object and how to convert the patterns into the fine-grained 3D structures.
Extensive experiments over four datasets demonstrate the effectiveness of AnchorFormer from both quantitative and qualitative perspectives. 2.