Abstract
Monocular 3D human pose and shape estimation is an ill-posed problem since multiple 3D solutions can explain a 2D image of a subject. Recent approaches predict a probability distribution over plausible 3D pose and shape parameters conditioned on the image. We show that these approaches exhibit a trade-off between three key properties: (i) accuracy
- the likelihood of the ground-truth 3D solution under the pre-dicted distribution, (ii) sample-input consistency - the extent to which 3D samples from the predicted distribution match the visible 2D image evidence, and (iii) sample diversity - the range of plausible 3D solutions modelled by the predicted distribution. Our method, HuManiFlow, predicts simultane-ously accurate, consistent and diverse distributions. We use the human kinematic tree to factorise full body pose into ancestor-conditioned per-body-part pose distributions in an autoregressive manner. Per-body-part distributions are im-plemented using normalising flows that respect the manifold structure of SO(3), the Lie group of per-body-part poses.
We show that ill-posed, but ubiquitous, 3D point estimate losses reduce sample diversity, and employ only probabilistic training losses. HuManiFlow outperforms state-of-the-art probabilistic approaches on the 3DPW and SSP-3D datasets. 1.

Introduction
Estimating 3D human pose and shape from a single RGB image is an inherently ill-posed [25, 47] computer vision task. Many 3D solutions can correspond to an input 2D ob-servation, due to depth ambiguity, occlusion and truncation.
Thus, several recent approaches [1, 2, 23, 42, 43] use deep neural networks to predict a probability distribution over 3D pose and shape, conditioned on the 2D input. In theory, this has a few advantages over deterministic single-solution predictors [18, 20, 21, 27, 55] - such as the quantification of prediction uncertainty, sampling of multiple plausible 3D solutions, and usage in downstream tasks such as multi-input fusion [43, 44] or as a prior in parametric model fitting [23].
To fully realise the advantages of probabilistic 3D pose
Figure 1. Comparison between pose and shape distributions from
HuManiFlow and ProHMR [23]. 3D samples from HuManiFlow are consistent with the visible 2D evidence, while being more di-verse than samples from ProHMR. Per-vertex sample variances along the x/y/z-axes highlight interpretable uncertainty due to oc-clusion/truncation (all axes), and depth ambiguity (z-axis-specific). and shape estimation in practice, we suggest that pre-dicted distributions should exhibit three properties: accuracy, sample-input consistency and sample diversity. Accuracy de-notes the likelihood of the ground-truth (GT) 3D pose and shape under the distribution. Sample-input consistency mea-sures the extent to which 3D samples from the distribution match the 2D input. In particular, after projection to the im-age plane, samples should agree with any pose and shape information visible in the image. Sample diversity refers to the range of 3D poses and shapes modelled by the distribu-tion. The GT pose and shape is but one 3D solution - the predicted distribution should model several plausible solu-tions when ill-posedness arises due to occlusion, truncation and depth ambiguity in the 2D input. More diverse samples enable better estimates of prediction uncertainty.
We show that recent probabilistic approaches suffer from a trade-off between accuracy, consistency and diversity.
Several methods [23, 42–44] predict uni-modal pose and shape distributions with limited expressiveness, and use non-probabilistic loss functions such as L1/L2 losses between
GT 3D keypoints and a 3D point estimate (usually the mode of the predicted distribution). These choices favour accuracy and consistency but harm diversity, as shown in Figure 1.
Approaches that generate diverse samples [2], through the use of more expressive probability distributions, often yield samples that are not consistent with the 2D input image.
We aim to balance accuracy, consistency and diversity with our approach, HuManiFlow, which outputs a distri-bution over SMPL [29] pose and shape parameters condi-tioned on an input image. We use normalising flows [37] to construct expressive full body pose distributions, which are factorised into per-body-part distributions autoregressively conditioned on ancestors along the human kinematic tree.
We account for the manifold structure of the Lie Group of per-body-part poses (or 3D rotations) SO(3) by predicting distributions on the corresponding Lie algebra so(3), and
“pushing forward” the algebra distributions onto the group via the exponential map [12]. We follow [42, 43] in pre-dicting a Gaussian distribution over SMPL’s shape-space
PCA coefficients. Notably, our method is trained without commonly-used point estimate losses on 3D keypoints. We demonstrate that such non-probabilistic losses reduce sample diversity while providing negligible accuracy improvements when expressive distribution estimation models are used.
In summary, our main contributions are as follows:
• We demonstrate that current probabilistic approaches to monocular 3D human pose and shape estimation suffer from a trade-off between distribution accuracy, sample-input consistency and sample diversity.
• We propose HuManiFlow, a normalising-flow-based method to predict distributions over SMPL pose and shape parameters that (i) considers the manifold struc-ture of the 3D body-part rotation group SO(3), (ii) exploits the human kinematic tree via autoregressive factorisation of full body pose into per-body-part rota-tion distributions, and (iii) is trained without any non-probabilistic point estimate losses on 3D keypoints (such as vertices or body joints).
• We show that HuManiFlow provides more accurate, input-consistent and diverse pose and shape distribu-tions than current approaches, using the 3DPW [51] and SSP-3D [41] datasets (see Figure 1). Our method interpretably and intuitively models uncertainty due to occlusion, truncation and depth ambiguities. 2.