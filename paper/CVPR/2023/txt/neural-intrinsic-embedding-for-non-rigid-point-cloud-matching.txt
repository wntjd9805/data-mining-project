Abstract
As a primitive 3D data representation, point clouds are prevailing in 3D sensing, yet short of intrinsic struc-tural information of the underlying objects. Such discrep-ancy poses great challenges in directly establishing corre-spondences between point clouds sampled from deformable shapes. In light of this, we propose Neural Intrinsic Embed-ding (NIE) to embed each vertex into a high-dimensional space in a way that respects the intrinsic structure. Based upon NIE, we further present a weakly-supervised learn-ing framework for non-rigid point cloud registration. Un-like the prior works, we do not require expansive and sen-sitive off-line basis construction (e.g., eigen-decomposition of Laplacians), nor do we require ground-truth correspon-dence labels for supervision. We empirically show that our framework performs on par with or even better than the state-of-the-art baselines, which generally require more su-pervision and/or more structural geometric input. 1.

Introduction
Estimating non-rigidly aligned point clouds serves as a critical building block in correspondences between many computer vision and graphics applications, including animation [21, 34], robotics [15, 44], autonomous driv-ing [10, 54], to name a few. In contrast to the well-known rigid case, more sophisticated deformation models are in demand to characterize the non-rigid motions, for instance, articulation movements of human shapes.
To address this challenge, extrinsic methods in princi-ple approximate a complex global non-rigid deformation with a set of local rigid and/or affine transformations, e.g., point-wise affine transformation [24, 50, 53], deformation graph [6, 7, 25], and patch-based deformation [23, 52]. Be-ing intuitive and straightforward, the extrinsic deformation models are in general redundant and lack global structures.
On the other hand, intrinsic methods [2, 8, 19, 29, 30, 33] first transform extrinsic coordinates into an alternative rep-resentation, in which shape alignment is performed. For in-stance, the seminal functional maps framework [32] utilizes eigenbasis of the Laplace-Beltrami operator as spectral em-beddings and turns non-rigid 3D shapes matching into rigid alignment of high-dimensional spectral embeddings, under the isometric deformation assumption. However, spectral embeddings are generally obtained by an inefficient, non-differentiable off-line eigen-decomposition of the Laplacian operator defined on shapes, either represented as polygonal meshes [36] or point clouds [42]. Moreover, spectral em-beddings are sensitive to various practical artifacts such as noise, partiality, and disconnectedness, to name a few.
To this end, we follow the isometric assumption and first propose a learning-based framework, Neural Intrin-sic Embedding (NIE), to embed point clouds into a high-dimensional space. In particular, we expect our embedding to satisfy the following desiderata: (1) It is aware of the in-trinsic geometry of the underlying surface; (2) It is compu-tationally efficient; (3) It is robust to typical artifacts man-ifested in point clouds. Our key insight is that geodesics on a deformable surface, which are inherently related to the
Riemannian metric, contain rich information of the intrinsic geometry. Therefore NIE is trained such that the Euclidean distance between embeddings approximates the geodesic distance between the corresponding points on the under-lying surface.
In particular, considering the local tracing manner of geodesic computation, we choose DGCNN [49] as our backbone, which efficiently gathers local features at different abstraction levels. We also carefully formulate a set of losses and design network modifications to overcome practical learning issues including rank deficiency, and sen-sitivity to point sampling density. As a consequence, NIE manages to learn an intrinsic-aware embedding from merely unstructured point clouds. Fig. 1 demonstrates that we ob-tain the segmentation result closest to the ground truth based on geodesic distances.
Furthermore, based on NIE, we propose a Neural Intrin-sic Mapping (NIM) network, a weakly supervised learn-ing framework for non-rigid point cloud matching. Though closely related to the Deep Functional Maps (DFM) frame-works, our method replaces the spectral embedding with the trained NIE and further learns to extract the optimal fea-tures based on a self-supervised loss borrowed from [14]. In the end, we establish a pipeline for weakly supervised non-rigid point cloud matching, which only requires all the point clouds to be rigidly aligned and, for training point clouds, access to the geodesic distance matrices of them.
Our overall pipeline is simple and geometrically infor-mative. We conduct a set of experiments to demonstrate the effectiveness of our pipeline.
In particular, we high-light that (1) our method performs on par with or even better than the competing baselines which generally require more supervision and/or more structural geometric input on near-isometric point cloud matching; (2) our method achieves sensible generalization performance, thanks to our tailored design to reduce the bias of point sampling density; (3) our method is robust regarding several artifacts, including noise and various partiality. 2.