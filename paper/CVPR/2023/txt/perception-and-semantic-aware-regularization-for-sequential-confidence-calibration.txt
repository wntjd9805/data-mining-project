Abstract
Deep sequence recognition (DSR) models receive in-creasing attention due to their superior application to var-ious applications. Most DSR models use merely the tar-get sequences as supervision without considering other re-lated sequences, leading to over-confidence in their pre-dictions. The DSR models trained with label smoothing regularize labels by equally and independently smoothing each token, reallocating a small value to other tokens for mitigating overconfidence. However, they do not consider tokens/sequences correlations that may provide more ef-fective information to regularize training and thus lead to sub-optimal performance.
In this work, we find to-kens/sequences with high perception and semantic correla-tions with the target ones contain more correlated and effec-tive information and thus facilitate more effective regular-ization. To this end, we propose a Perception and Semantic aware Sequence Regularization framework, which explore perceptively and semantically correlated tokens/sequences as regularization. Specifically, we introduce a semantic context-free recognition and a language model to acquire similar sequences with high perceptive similarities and se-mantic correlation, respectively. Moreover, over-confidence degree varies across samples according to their difficul-ties. Thus, we further design an adaptive calibration in-tensity module to compute a difficulty score for each sam-ples to obtain finer-grained regularization. Extensive ex-periments on canonical sequence recognition tasks, includ-ing scene text and speech recognition, demonstrate that our method sets novel state-of-the-art results. Code is available at https://github.com/husterpzh/PSSR. 1.

Introduction
Deep neural networks (DNNs) have shown remarkable performance in sequence recognition tasks, such as scene
*Corresponding author. (a) Perception overconfidence (b) Semantic overconfidence
Figure 1. Text strings placed along the right side of images are target, prediction, and sequence confidence respectively from top to bottom. Fig. 1 (a): the model assigns higher confidence to the character that extremely resembles to the ground-truth character in visual perception (e.g., texture and topological shape); Fig. 1 (b): the word that are semantically correlated to the ground-truth label will be predicted with a high confidence. text recognition (STR) [11, 40, 47] and speech recognition (SR) [3, 25]. Despite impressive accuracy, recent studies have indicated that DNNs [7, 8, 19], including deep se-quence recognition (DSR) models, are usually poorly cali-brated and tend to be overconfident [15,27,28]. In the sense that the confidence values associated with the predicted la-bels are higher than the true likelihood of the correctness of these labels, even for the wrong predictions, the over-confident DSR models may assign high confidences. This property may lead to potentially disastrous consequences for many safety-critical applications, such as autonomous driving [12] and medical diagnosis [26, 35].
Current DSR models use merely the target sequence as supervision and consider little information about any other sequences. Thus, they may tend to blindly give an over-confident score for their predictions, leading to the over-confidence dilemma. Presently, some works [13, 58] in-troduce label smoothing, which smooth each token by re-allocating a small value to all non-target token class from the target class, to prevent the DSR models from assign-ing the full probability mass to target sequences. However, these algorithms do not consider token/sequences correla-tions, and are difficult to provide effective and sufficient in-formation. In this work, we find that tokens/sequences with high perception or semantic correlations, which refer to to-kens/sequences with high visual/auditory similarities and with high co-occurrence similarities respectively, may be mistakenly given a highly-confident score. Taking STR for example, the Figure 1 shows that token “l” shares highly visual similarity with “i”, and thus the models may easily predict it to “i” with high confidence. On the other hand, word “universiti” is semantically similar to word “univer-sity” and thus it is also predicted to “university”. These tokens/sequences are easily ambiguous with the target ones and thus may provide more effective information to regular-ize training.
In this paper, we propose a calibration method for
DSR models: Perception and Semantic aware Sequence
Regularization (PSSR). The PSSR enables the DSR mod-els with stronger vital perception discrimination ability and richer semantic contextual correlation knowledge by incor-porating additional perception similarity and semantic cor-relation information into training. Specifically, we con-struct a similar sequence set that comprises sequences ei-ther perception similar to the instantiated sequence input or semantic correlated with the target text sequence. Dur-ing the training stage, these similar sequences are used as weighted additional supervision signals to offer more per-ception similarity of different token classes and semantic correlation in the same context. Furthermore, we discover that the degree of overconfidence of the model on its pre-dictions varies across samples and is related to the hard-ness of recognizing samples. Hence, we further introduce a modulating factor function to adjust the calibration among different samples adaptively. To evaluate the effectiveness of the proposed method, we conduct experiments on two canonical sequence recognition tasks, including scene text recognition and speech recognition. Experimental results demonstrate that our method is superior to the state-of-the-art calibration methods across different benchmarks.
The major contributions of this paper are fourfold. First, we discovered the overconfidence of DSR models com-prises perception overconfidence and semantic overconfi-dence. Second, following our observations, we propose a calibration method for DSR models that enables the DSR models with more vital perception discrimination ability and richer semantic contextual correlation knowledge, so as to obtain more calibrated predictions. Third, we introduce a modulating factor function to achieve adaptive calibration.
Fourth, we provide comprehensive experiments over mul-tiple sequence recognition tasks with various network ar-chitectures, datasets, and in/out-domain settings. We also verify its effectiveness on the downstream application ac-tive learning. The results suggest that our method yields substantial improvements in DSR models calibration. 2.