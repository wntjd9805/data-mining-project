Abstract
We propose TensoIR, a novel inverse rendering approach based on tensor factorization and neural fields. Unlike previous works that use purely MLP-based neural fields, thus suffering from low capacity and high computation costs, we extend TensoRF, a state-of-the-art approach for radiance field modeling, to estimate scene geometry, sur-face reflectance, and environment illumination from multi-view images captured under unknown lighting conditions.
Our approach jointly achieves radiance field reconstruction and physically-based model estimation, leading to photo-realistic novel view synthesis and relighting results. Bene-fiting from the efficiency and extensibility of the TensoRF-based representation, our method can accurately model secondary shading effects (like shadows and indirect light-ing) and generally support input images captured under sin-gle or multiple unknown lighting conditions. The low-rank tensor representation allows us to not only achieve fast and compact reconstruction but also better exploit shared in-formation under an arbitrary number of capturing lighting conditions. We demonstrate the superiority of our method to baseline methods qualitatively and quantitatively on var-ious challenging synthetic and real-world scenes. 1.

Introduction
Inverse rendering is a long-standing problem in com-puter vision and graphics, aiming to reconstruct physical attributes (like shape and materials) of a 3D scene from captured images and thereby supporting many downstream applications such as novel view synthesis, relighting and material editing. This problem is inherently challenging and ill-posed, especially when the input images are cap-tured in the wild under unknown illumination. Recent works [6, 7, 28, 41] address this problem by learning neural field representations in the form of multi-layer perceptrons
* Equal contribution. † Equal advisory.
Figure 1. Given multi-view captured images of a real scene (a), our approach – TensoIR – is able to achieve high-quality shape and material reconstruction with high-frequency details (b). This allows us to render the scene under novel lighting and viewpoints (c), and also change its material properties (d). (MLP) similar to NeRF [22]. However, pure MLP-based methods usually suffer from low capacity and high compu-tational costs, greatly limiting the accuracy and efficiency of inverse rendering.
In this work, we propose a novel inverse rendering framework that is efficient and accurate. Instead of purely using MLPs, we build upon the recent TensoRF [11] scene representation, which achieves fast, compact, and state-of-the-art quality on radiance field reconstruction for novel view synthesis. Our tensor factorization-based inverse ren-dering framework can simultaneously estimate scene ge-ometry, materials, and illumination from multi-view im-ages captured under unknown lighting conditions. Bene-fiting from the efficiency and extensibility of the TensoRF representation, our method can accurately model secondary shading effects (like shadows and indirect lighting) and gen-erally support input images captured under a single or mul-tiple unknown lighting conditions.
Similar to TensoRF, our approach models a scene as a neural voxel feature grid, factorized as multiple low-rank
tensor components. We apply multiple small MLPs on the same feature grid and regress volume density, view-dependent color, normal, and material properties, to model the scene geometry and appearance. This allows us to si-multaneously achieve both radiance field rendering – using density and view-dependent color, as done in NeRF [22] – and physically-based rendering – using density, normal and material properties, as done in inverse rendering meth-ods [3, 20]. We supervise both renderings with the cap-tured images to jointly reconstruct all scene components. In essence, we reconstruct a scene using both a radiance field and a physically-based model to reproduce the scene’s ap-pearance. While inverse rendering is our focus and primar-ily enabled by the physically-based model, modeling the ra-diance field is crucial for the success of the reconstruction (see Fig. 3), in significantly facilitating the volume density reconstruction and effectively regularizing the same tensor features shared by the physically-based model. Despite that previous works [41] similarly reconstruct NeRFs in inverse rendering, their radiance field is pre-computed and fixed in the subsequent inverse rendering stage; in contrast, our ra-diance field is jointly reconstructed and also benefits the physically-based rendering model estimation during opti-mization, leading to much higher quality. Besides, our ra-diance field rendering can also be directly used to provide accurate indirect illumination for the physically-based ren-dering, further benefiting the inverse rendering process.
Accounting for indirect illumination and shadowing is a critical challenge in inverse rendering. This is especially challenging for volume rendering, since it requires sam-pling a lot of secondary rays and computing the integrals along the rays by performing ray marching. Limited by the high-cost MLP evaluation, previous NeRF-based meth-ods and SDF-based methods either simply ignore secondary effects [6, 7, 39], or avoid online computation by approx-imating these effects in extra distilled MLPs [41, 42], re-quiring expensive pre-computation and leading to degrada-tion in accuracy. In contrast, owing to our efficient tensor-factorized representation, we are able to explicitly compute the ray integrals online for accurate visibility and indirect lighting with the radiance field rendering using low-cost second-bounce ray marching. Consequently, our approach enables higher accuracy in modeling these secondary ef-fects, which is crucial in achieving high-quality scene re-construction (see Tab. 2).
In addition, the flexibility and efficiency of our tensor-factorized representation allows us to perform inverse ren-dering from multiple unknown lighting conditions with lim-ited GPU memory. Multi-light capture is known to be ben-eficial for inverse rendering tasks by providing useful pho-tometric cues and reducing ambiguities in material estima-tion, thus being commonly used [13,15,18]. However, since each lighting condition corresponds to a separate radiance field, this can lead to extremely high computational costs if reconstructing multiple purely MLP-based NeRFs like pre-vious works [28, 41, 42]. Instead, we propose to reconstruct radiance fields under multi-light in a joint manner as a fac-torized tensor. Extending from the original TensoRF repre-sentation that is a 4D tensor, we add an additional dimen-sion corresponding to different lighting conditions, yielding a 5D tensor. Specifically, we add an additional vector factor (whose length equals the number of lights) per tensor com-ponent to explain the appearance variations under different lighting conditions, and we store this 5D tensor by a small number of bases whose outer-product reconstructs the 5D tensor. When multi-light capture is available, our frame-work can effectively utilize the additional photometric cues in the data, leading to better reconstruction quality than a single-light setting (see Tab. 1).
As shown in Fig. 1, our approach can reconstruct high-fidelity geometry and reflectance of a complex real scene captured under unknown natural illumination, enabling photo-realistic rendering under novel lighting conditions and additional applications like material editing. We eval-uate our framework extensively on both synthetic and real data. Our approach outperforms previous inverse rendering methods [41,42] by a large margin qualitatively and quanti-tatively on challenging synthetic scenes, achieving state-of-the-art quality in scene reconstruction – for both geometry and material properties – and rendering – for both novel view synthesis and relighting. Owing to our efficient tenso-rial representation and joint reconstruction scheme, our ap-proach also leads to a much faster reconstruction speed than previous neural field-based reconstruction methods while achieving superior quality. In summary,
• We propose a novel tensor factorization-based inverse rendering approach that jointly achieves physically-based rendering model estimation and radiance field reconstruction, leading to state-of-the-art scene recon-struction results;
• Our framework includes an efficient online visibility and indirect lighting computation technique, providing accurate second-bounce shading effects;
• We enable efficient multi-light reconstruction by mod-eling an additional lighting dimension in the factorized tensorial representation. 2.