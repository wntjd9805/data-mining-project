Abstract 1.

Introduction
We propose a 3D shape generation framework (SDF-Diffusion in short) that uses denoising dif-fusion models with continuous 3D representation via signed distance fields (SDF). Unlike most existing meth-ods that depend on discontinuous forms, such as point clouds, SDF-Diffusion generates high-resolution 3D shapes while alleviating memory issues by separating the generative process into two-stage: generation and super-resolution. In the first stage, a diffusion-based generative model generates a low-resolution SDF of 3D shapes.
Using the estimated low-resolution SDF as a condition, the second stage diffusion model performs super-resolution to generate high-resolution SDF. Our framework can generate a high-fidelity 3D shape despite the extreme spatial complexity. On the ShapeNet dataset, our model shows competitive performance to the state-of-the-art methods and shows applicability on the shape completion task without modification.
*Corresponding author.
The need for generative modeling of 3D shapes has rapidly increased due to high demand in various fields, such as computer vision, graphics, robotics, and content gener-ation. To synthesize a high-quality 3D shape, numerous generative approaches have been actively studied, includ-ing generative adversarial networks (GAN) [1, 7, 8, 18, 20, 40, 51, 62, 71, 85], variational auto-encoders (VAE) [13, 27, 35,45,67], normalizing flows [26,30,60,77], auto-regressive models [19, 31, 45, 46, 76], and others [61, 74, 75, 80, 84].
Recently, denoising diffusion models (DDM) have emerged as a promising generative framework in image generation [10, 16, 22, 39, 47, 63] and speech synthesis [5, 32, 54]. DDM achieves a generative process by gradually corrupting data through a diffusion process and denoising through a learned neural network. This network can gen-erate new realistic data by repeating the denoising process from the given pure noise. Based on the success of DDM-based generative models in various domains, several at-tempts are being made to apply them to the task of 3D shape generation [41,83,87]. They have applied DDM to generate new point cloud and have outperformed previous methods.
However, even though DDM-based 3D generative mod-els have demonstrated their impressive performance, they still have limitations to being adopted for real-world prob-lems. Most previous DDM-based 3D generative models use point clouds to represent 3D shapes, which limits their ability to express continuous surfaces of 3D shapes, unlike mesh representation commonly used in real-world applica-tions. To resolve this issue, intricate post-processing [2, 24, 25, 52] is required to reconstruct continuous meshes from point clouds. They require various parameter tun-ing or additional information (e.g., surface normal at each point [52]), and a densely sampled point cloud is required to reconstruct high-quality mesh. However, existing DDM-based methods for 3D shape generation are based on sparse point clouds.
In this work, we introduce a new DDM-based generation framework that generates high-quality 3D shapes through signed distance fields (SDF) (see Fig. 1). We can view SDF as a function that takes an arbitrary location as input and returns a signed distance value from the input location to the nearest surface of the mesh, and the sign of the value means whether inside or outside of the shape. We sample
SDF values uniformly from a 3D shape to form a voxel-shaped SDF. This form has several advantages over point clouds. It can directly reconstruct mesh through the march-ing cube algorithm [38] and can utilize convolutional neural network (CNN) because of its dense and fixed structure.
Based on this voxel-shaped SDF representation, we pro-pose a novel DDM-based generative model in two-stage (see Fig. 2). In the first stage, a diffusion-based SDF gener-ation produces low-resolution SDF for coarse 3D shapes. In the second stage, we propose a diffusion-based SDF super-resolution, given the low-resolution SDF of the first stage as a condition. In particular, since the increasing resolution of the voxel comes as a significant burden in terms of computa-tional resources (i.e., due to the curse of the dimension), we approach this problem by super-resolution in patch-based learning. Under this scheme, we can iteratively perform the second stage multiple times with the same structure and generate further higher resolution of SDF, which is a more detailed 3D shape. With various experiments, we achieve state-of-the-art in single-/multi-category 3D shape genera-tive quality, and our method can be directly converted into 3D meshes, unlike other point cloud-based methods that re-quire intricate post-processing.
In summary, our contributions are as follows:
• We propose a novel DDM-based generation method that utilizes a voxel-shaped SDF representation to generate high-quality and continuous 3D shapes.
• We represent a memory-efficient two-stage framework composed of low-resolution SDF generation and SDF super-resolution conditioned on the low-resolution SDF.
In particular, we can iteratively perform super-resolution to generate higher-resolution SDF.
• SDF-diffusion can be seamlessly extended into multi-category 3D shape generation and completion, which shows the flexibility of the proposed method. 2.