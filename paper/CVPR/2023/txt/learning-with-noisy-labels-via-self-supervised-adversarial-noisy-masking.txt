Abstract
Collecting large-scale datasets is crucial for training deep models, annotating the data, however, inevitably yields noisy labels, which poses challenges to deep learning algo-rithms. Previous efforts tend to mitigate this problem via identifying and removing noisy samples or correcting their labels according to the statistical properties (e.g., loss val-ues) among training samples. In this paper, we aim to tackle this problem from a new perspective, delving into the deep feature maps, we empirically find that models trained with clean and mislabeled samples manifest distinguishable acti-vation feature distributions. From this observation, a novel robust training approach termed adversarial noisy mask-ing is proposed. The idea is to regularize deep features with a label quality guided masking scheme, which adap-tively modulates the input data and label simultaneously, preventing the model to overfit noisy samples. Further, an auxiliary task is designed to reconstruct input data, it nat-urally provides noise-free self-supervised signals to rein-force the generalization ability of models. The proposed method is simple yet effective, it is tested on synthetic and real-world noisy datasets, where significant improvements are obtained over previous methods. Code is available at https://github.com/yuanpengtu/SANM . 1.

Introduction
Deep learning has achieved remarkable success, relying on large-scale datasets with human-annotated accurate la-bels. However, collecting such high-quality labels is time-consuming and expensive. As an alternative, inexpensive strategies are usually used for generating labels for large-scale samples, such as web crawling, leveraging search en-gines, or using machine-generated annotations. All these
* Equal contribution.
† Corresponding author.
Figure 1. Activation maps of mis-predicted (a-b) and correctly-predicted (c) samples when training PreAct ResNet-18 with clean (i.e., clean-trained) and noisy (i.e., noisy-trained) data on CIFAR-10 (1st and 2nd row) and Clothing1M [38] (3rd row). alternative methods inevitably yield numerous noisy sam-ples. However, previous research [2] has revealed that deep networks can easily overfit to noisy labels and suffer from dramatic degradation in the generalization performance.
Towards this problem, numerous Learning with Noisy labels (LNL) approaches have been proposed. Sample se-lection methods [3, 8, 34, 41] are the most straightforward methods, which attempt to select clean samples based on certain criterion (e.g., loss value) and then reweight or dis-card the noisy instances to reduce the interference of mis-labeled training samples. However, these methods fail to leverage the potential information of the discarded samples.
Similarly, label correction based methods [32, 40, 48] try to correct labels, which often impose assumptions on the existence of a small correctly-labeled validation subset or directly utilize predictions of deep models. However, such assumptions can not be always full-filled in real-world noisy datasets [27], leading to limited application scenarios. Be-sides, the predictions of deep model tend to fluctuate when training with mislabeled samples, making the label correc-tion process unstable and sub-optimal [36]. On the contrary, regularization based methods [2, 6, 15, 20, 26, 29, 43, 47, 50] aim to alleviate the side effect of label noise by prevent-ing the deep models from overfitting to all training sam-ples, which is flexible and can work collaboratively with other LNL methods. Both explicit and implicit regulariza-tion techniques were proposed, the former generally cali-brates the parameter update of networks by modifying the expected training loss, i,e., dropout. The latter focuses on improving the generalization by utilizing the stochasticity, i,e., data augmentation strategy and stochastic gradient de-scent [29]. However, most of these methods are designed for general fully-supervised learning tasks with correctly-labeled samples, and poor generalization ability could be obtained when the label noise is severe [29].
In this paper, we present a novel regularization based method specialized for LNL problem. Our method is in-spired by an observation that some differences exist in activation maps between the predictions of deep models trained with clean and noisy labels. As shown in Fig. 1 (a), activation maps of mis-predicted samples by the model trained with clean labels are always focused on their fore-ground areas. By contrast, when the model is trained with noisy labels, it tends to generates results focused on the meaningless background area for the mis-predicted sam-ples (Fig. 1 (b)). And even for cases that the prediction is correct, i.e., Fig. 1 (c), the high-activated region drifts to irrelevant (i.e., edge) areas of the object, rather than the main regions of the object. This indicates that model trained with mislabeled samples is likely to overfit to some corner parts of the object from noisy data or remember the less-informative regions (i.e., background). Therefore, from this observation, we propose a novel Self-supervised Adversar-ial Noisy Masking (SANM) method for LNL. The idea is to explicitly regularize the model to generate more diverse activation maps through masking the certain region (e.g., max-activated) of the input image and thus alleviates the confirmation bias [8].
Moreover, to investigate how the masking strategies af-fect the performance of training deep models with noisy labels, we conduct a simple experiment, where differ-ent adversarial masking strategies (i.e., masking the max-activated region of input images with fixed, random, and noise-aware mask ratio) were applied to the popular LNL framework DivideMix [15]. As shown in Fig. 2, we find that the performance gain is much more sensitive to the masking strategy. A fixed or random mask ratio obtain only marginal gain, but when dealing with the correctly-labeled and misla-beled samples with different mask ratios, a significant per-formance gain is achieved. This indicates that how to design an effective adversarial masking method in the case of LNL is non-trivial and not well addressed.
Towards the problem above, a label quality guided adap-tive masking strategy is proposed, which modulates the im-age label and the mask ratio of image masking simultane-ously. The label is updated via first leveraging the soft-distributed model prediction and then reducing the proba-bility of max-activated class with the noise-aware masking ratio, while at the same time lifting the probability of other classes. Intuitively, a sample with a high probability of be-ing mislabeled will possess a larger masking ratio, leading to a more strictly regularized input image and modulated label. Therefore, the negative impact of noisy labels can be greatly reduced. As for the correctly-labeled samples, the masking ratio is relatively small, which plays the role of general regularization strategy and improves the model gen-eralization ability by preventing the model from overfitting training samples. Further, we specially customized an aux-iliary decode branch to reconstruct the original input image, which provides noise-free self-supervised information for learning a robust deep model. The proposed SANM is flex-ible and can further boost existing LNL methods. It is tested on synthetic and real-world large-scale noisy datasets, and elaborately ablative experiments were conducted to verify each design component of the proposed method. In a nut-shell, the key contributions of this work are:
• We propose a novel self-supervised adversarial noisy masking method named SANM to explicitly impose reg-ularization for LNL problem, preventing the model from overfitting to some corner parts of the object or less-informative regions from noisy data;
• A label quality guided masking strategy is proposed to differently adjust the process for clean and noisy sam-ples according to the label quality estimation. This strategy modulates the image label and the ratio of image masking simultaneously;
• A self-supervised mask reconstruction auxiliary task is designed to reconstruct the original images based on the features of masked ones, which aims at enhancing general-ization by providing noise-free supervision signals. 2.