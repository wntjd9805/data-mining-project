Abstract in module with extensive comparison against state-of-the-art methods on several real and synthetic datasets.
Accurate facial landmark detection on wild images plays an essential role in human-computer interaction, enter-tainment, and medical applications. Existing approaches have limitations in enforcing 3D consistency while detect-ing 3D/2D facial landmarks due to the lack of multi-view in-the-wild training data. Fortunately, with the recent ad-vances in generative visual models and neural rendering, we have witnessed rapid progress towards high quality 3D image synthesis. In this work, we leverage such approaches to construct a synthetic dataset and propose a novel multi-view consistent learning strategy to improve 3D facial land-mark detection accuracy on in-the-wild images. The pro-posed 3D-aware module can be plugged into any learning-based landmark detection algorithm to enhance its accu-racy. We demonstrate the superiority of the proposed plug-*This work was done when Libing Zeng and Wentao Bao were interns at OPPO US Research Center, InnoPeak Technology, Inc. 1.

Introduction
Accurate and precise facial landmark plays a signif-icant role in computer vision and graphics applications, such as face morphing [54], facial reenactment [58], 3D face reconstruction [17, 18, 30], head pose estimation [38], face recognition [1, 10, 13, 19, 32, 41, 71], and face genera-tion [11, 21, 60, 69]. In these applications, facial landmark detection provides great sparse representation to ease the burden of network convergence in different training stages and is often used as performance evaluation metric. For in-stance, as a facial prior, it provides good initialization for subsequent training [66, 67, 69, 76], good intermediate rep-resentation to bridge the gap between different modalities for content generation [11,27,51,79], loss terms which reg-ularize the facial expression [11, 52], or evaluation metrics to measure the facial motion quality [53, 73, 78].
The aforementioned applications require the estimated facial landmarks to be accurate even with significantly var-ied facial appearance under different identities, facial ex-pressions, and extreme head poses. Tremendous efforts have been devoted to address this problem [15, 22–24, 29, 34,40,56,63,74,75,77,82,84]. These approaches often rely on manually annotated large-scale lab-controlled or in-the-wild image datasets [4,34] to handle various factors such as arbitrary facial expressions, head poses, illumination, facial occlusions, etc.
However, even with the high cost of human labeling, consistent and accurate manual annotation of landmarks re-mains challenging [22, 23, 34]. It is very difficult, if not im-possible, to force a person to annotate the facial landmark keypoints at the same pixel locations for faces of different poses, let alone different annotators under different labeling environments. Such annotation inconsistency and inaccu-racy in training images are often the killing factor to learn an accurate landmark localization model. This is particu-larly a major problem in non-frontal faces where annotation becomes extremely challenging. As shown in Fig. 1(a) a small annotation variation in view #1, results in a signifi-cant inaccuracy in view #2. This multi-view inconsistency and inaccuracy can ultimately lead to poor landmark de-tection accuracy, especially for facial images with extreme head pose.
To mitigate this annotation inconsistency and inaccuracy issue, we propose to learn facial landmark detection by en-forcing multi-view consistency during training. Given the images of the same facial identity captured with different head poses, instead of detecting facial landmark at each sep-arate facial image, we propose a multi-view consistency su-pervision to locate facial landmark in a holistic 3D-aware manner. To enforce multi-view consistency, we introduce self-projection consistency loss and multi-view landmark loss in training. We also propose an annotation genera-tion procedure to exploit the merits of lab-controlled data (e.g., multi-view images, consistent annotations) and in-the-wild data (e.g., wide range of facial expressions, identities).
Thanks to this synthetic data, our method does not rely on human annotation to obtain the accurate facial landmark locations. Therefore, it alleviates the problem of learning from inaccurate and inconsistent annotations.
We formulate our solution as a plug-in 3D aware module, which can be incorporated into any facial landmark detec-tor and can boost a pre-trained model with higher accuracy and multi-view consistency. We demonstrate the effective-ness of our approach through extensive experiments on both synthetic and real datasets. The main contributions of our work are as follows:
• We show, for the first time, how to combine the merits of lab captured face image data (e.g., multi-view) and the in-the-wild face image datasets (e.g., appearance diversity). Using our proposed approach we produce a large-scale synthetic, but realistic, multi-view face dataset, titled DAD-3DHeads-Syn.
• We propose a novel 3D-aware optimization module, which can be plugged into any learning-based facial landmark detection methods. By refining an existing landmark detection algorithm using our optimization module, we are able to improve its accuracy and multi-view consistency.
• We demonstrate the performance improvements of our module built on top multiple baseline methods on sim-ulated dataset, lab-captured datasets, and in-the-wild datasets. 2.