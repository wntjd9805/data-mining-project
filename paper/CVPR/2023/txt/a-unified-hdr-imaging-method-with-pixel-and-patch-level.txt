Abstract
Mapping Low Dynamic Range (LDR) images with differ-ent exposures to High Dynamic Range (HDR) remains non-trivial and challenging on dynamic scenes due to ghosting caused by object motion or camera jitting. With the success of Deep Neural Networks (DNNs), several DNNs-based methods have been proposed to alleviate ghosting, they can-not generate approving results when motion and saturation occur. To generate visually pleasing HDR images in various cases, we propose a hybrid HDR deghosting network, called
HyHDRNet, to learn the complicated relationship between reference and non-reference images. The proposed HyH-DRNet consists of a content alignment subnetwork and a
Transformer-based fusion subnetwork. Specifically, to ef-fectively avoid ghosting from the source, the content align-ment subnetwork uses patch aggregation and ghost atten-tion to integrate similar content from other non-reference images with patch level and suppress undesired compo-nents with pixel level. To achieve mutual guidance between patch-level and pixel-level, we leverage a gating module to sufficiently swap useful information both in ghosted and saturated regions. Furthermore, to obtain a high-quality
HDR image, the Transformer-based fusion subnetwork uses a Residual Deformable Transformer Block (RDTB) to adap-tively merge information for different exposed regions. We examined the proposed method on four widely used public
HDR image deghosting datasets. Experiments demonstrate that HyHDRNet outperforms state-of-the-art methods both quantitatively and qualitatively, achieving appealing HDR visualization with unified textures and colors. 1.

Introduction
Natural scenes cover a very broad range of illumina-tion, but standard digital camera sensors can only measure
*† The first three authors contributed equally to this work. This work was partially supported by NSFC (U19B2037, 61901384), Natu-ral Science Basic Research Program of Shaanxi (2021JCW-03, 2023-JC-QN-0685), the Fundamental Research Funds for the Central Universi-ties (D5000220444), and National Engineering Laboratory for Integrated
Aero-Space-Ground-Ocean Big Data Application Technology. Corre-sponding author: Jinqiu Sun.
Figure 1. Our approach produces high-quality HDR images, lever-aging both patch-wise aggregation and pixel-wise ghost atten-tion. The two modules provide complementary visual information: patch aggregation recovers patch-level content of the complex dis-torted regions and ghost attention provides pixel-level alignment. a limited dynamic range. Images captured by cameras of-ten have saturated or under-exposed regions, which lead to terrible visual effects due to severely missing details. High
Dynamic Range (HDR) imaging has been developed to ad-dress these limitations, and it can display richer details. A common way of HDR imaging is to fuse a series of differ-ently exposed Low Dynamic Range (LDR) images. It can recover a high-quality HDR image when both the scene and the camera are static, however, it suffers from ghosting arti-facts on dynamic objects or hand-held camera scenarios.
Several methods have been proposed to alleviate these problems, including alignment-based methods [1, 7, 20], rejection-based methods [3, 8, 16, 18, 33] and patch-based methods [5, 13, 19]. The alignment-based methods employ global (e.g., homographies) or non-rigid alignment (e.g., optical flow) to rectify the content of motion regions, but they are error-prone and cause ghosts due to saturation and occlusion. The rejection-based methods attempt to remove the motion components from the exposed images and re-place them with the content of the reference image. Al-though these methods achieve good quality for static scenes, they discard the misalignment regions, which causes insuf-ficient content in moving regions. The patch-based meth-ods utilize patch-level alignment to transfer and fuse simi-lar content. While these patch-based methods achieve better performance, they suffer from high computational costs.
With the rise of Deep Neural Networks (DNNs), many works directly learn the complicated mapping between
LDR and HDR using a CNN. In general, these models fol-low the paradigm of alignment before fusion. The non-end-to-end DNN-based methods [6, 22] first align LDR images with optical flow or homographies, and then fuse aligned images to generate HDR images. The alignment approaches are error-prone and inevitably cause ghosting artifacts when complex foreground motions occur. Based on the attention-based end-to-end method AHDRNet [25, 26] which per-forms spatial attention to suppress motion and saturation, several methods [2, 12, 27, 30, 31] have been proposed to re-move ghosting artifacts. The spatial attention module pro-duces attention maps and element-wise multiplies with non-reference features, thus the model removes motion or satu-rated regions and highlights more informative regions.
However, the success of these methods relies on no-ticeable variations between reference and non-reference frames. These methods perform well in the marginal areas, even if there is a misalignment in the input images. Unluck-ily, spatial attention produces unsatisfactory results when motion and saturation are present simultaneously (see Fig-ure 1). The reason can be attributed to that spatial attention uses element-wise multiplication, which only considers the features in the same positions. For example, in the reference frame of Figure 1 (i.e., LDR with EV=0), the information in the over-exposed regions is unavailable, spatial attention can only rely on the non-saturated information of the same position (i.e., moving regions) in the non-reference frame due to element-wise multiplication. Therefore, recovering the content of the moving and saturated regions is challeng-ing. Finally, this limitation of spatial attention causes obvi-ous ghosting artifacts in these complex cases.
To generate high-quality HDR images in various cases, we propose a Hybrid HDR deghosting Network, named Hy-HDRNet, to establish the complicated alignment and fusion relationship between reference and non-reference images.
The proposed HyHDRNet comprises a content alignment subnetwork and a Transformer-based fusion subnetwork.
For the content alignment subnetwork, inspired by patch-based HDR imaging methods [5, 19], we propose a novel
Patch Aggregation (PA) module, which calculates the sim-ilarity map between different patches and selectively ag-gregates useful information from non-reference LDR im-ages, to remove ghosts and generate content of saturation and misalignment. While the traditional patch-based HDR imaging methods have excellent performance but have the following drawbacks: 1) low patch utilization ratio caused by reusing the same patches, which leads to insufficient content during fusion, 2) structural destruction of images when transfering patches, 3) high computational complex-ity in full resolution. To this end, our Patch Aggregation mechanism 1) aggregates multiple patches which improves the patch utilization ratio 2) aggregates patches instead of exchanging them to maintain structural information, 3) cal-culates a similarity map within a window to reduce compu-tational complexity. These advantages promote the network to remedy the content of saturated and motion regions(See
Figure 9), other patch-based HDR imaging methods cannot achieve this goal. In a word, our PA module (patch level) discovers and aggregates similar patches within a large re-ceptive field according to the similarity map, thus it can re-cover the content inside the distorted regions. To further avoid ghosting, we also employ a ghost attention module (pixel level) as a complementary branch for the PA module, and propose a gating module to achieve mutual guidance of these two modules in the content alignment subnetwork. In addition, unlike previous methods using DNN structure in the feature fusion stage which has static weights and only merges the local information, we propose a Transformer-based fusion subnetwork that uses Residual Deformable
Transformer Block (RDTB) to model long-range dependen-cies of different regions. The RDTB can dynamically ad-just weights and adaptively merge information in different exposure regions. The experiments demonstrate that our proposed method achieves state-of-the-art performance on public datasets. The main contributions of our work can be summarized as follows:
• We propose a hybrid HDR deghosting network to ef-fectively integrate the advantage of patch aggregation and ghost attention using a gating strategy.
• We first introduce the patch aggregation module which selectively aggregates useful information from non-reference LDR images to remove ghosts and generate content for saturation.
• A novel residual deformable Transformer block is pro-posed, which can adaptively fuse a large range of in-formation to generate high-quality HDR images.
• We carry out both qualitative and quantitative experi-ments, which show that our method achieves state-of-the-art results over four public benchmarks. 2.