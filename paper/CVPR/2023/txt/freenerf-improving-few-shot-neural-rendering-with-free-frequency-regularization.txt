Abstract
Novel view synthesis with sparse inputs is a challeng-ing problem for neural radiance ﬁelds (NeRF). Recent ef-forts alleviate this challenge by introducing external super-vision, such as pre-trained models and extra depth signals, or by using non-trivial patch-based rendering. In this pa-per, we present Frequency regularized NeRF (FreeNeRF), a surprisingly simple baseline that outperforms previous methods with minimal modiﬁcations to plain NeRF. We an-alyze the key challenges in few-shot neural rendering and
ﬁnd that frequency plays an important role in NeRF’s train-ing. Based on this analysis, we propose two regularization terms: one to regularize the frequency range of NeRF’s inputs, and the other to penalize the near-camera density
ﬁelds. Both techniques are “free lunches” that come at no additional computational cost. We demonstrate that even with just one line of code change, the original NeRF can achieve similar performance to other complicated methods in the few-shot setting. FreeNeRF achieves state-of-the-art performance across diverse datasets, including Blender,
DTU, and LLFF. We hope that this simple baseline will mo-tivate a rethinking of the fundamental role of frequency in
NeRF’s training, under both the low-data regime and be-yond. This project is released at FreeNeRF. 1.

Introduction
Neural Radiance Field (NeRF) [21] has gained tremen-dous attention in 3D computer vision and computer graph-ics due to its ability to render high-ﬁdelity novel views.
However, NeRF is prone to overﬁtting to training views and struggles with novel view synthesis when only a few inputs are available. We term this view synthesis from sparse in-puts problem as a few-shot neural rendering problem.
Existing methods address this challenge using different strategies. Transfer learning methods, e.g., PixelNerf [37] and MVSNeRF [4], pre-train on large-scale curated multi-view datasets and further incorporate per-scene optimiza-tion at test time. Depth-supervised methods [6, 29] in-troduce estimated depth as an external supervisory signal, leading to a complex training pipeline. Patch-based reg-ularization methods impose regularization from different sources on rendered patches, e.g., semantic consistency reg-ularization [11], geometry regularization [8, 22], and ap-pearance regularization [22], all at the cost of computation overhead since an additional, non-trivial number of patches must be rendered during training [8, 11, 22].
In this work, we ﬁnd that a plain NeRF can work sur-prisingly well with none of the above strategies in the few-shot setting by adding (approximately) as few as one line of code (see Fig. 1). Concretely, we analyze the common failure modes in training NeRF under a low-data regime.
Drawing on this analysis, we propose two regularization terms. One is frequency regularization, which directly reg-ularizes the visible frequency bands of NeRF’s inputs to stabilize the learning process and avoid catastrophic over-ﬁtting at the start of training. The other is occlusion reg-ularization, which penalizes the near-camera density ﬁelds that cause “ﬂoaters,” another failure mode in the few-shot neural rendering problem. Combined, we call our method
Frequency regularized NeRF (FreeNeRF), which is “free” in two ways. First, it is dependency-free because it requires neither costly pre-training [4, 11, 22, 37] nor extra supervi-sory signals [6,29]. Second, it is overhead-free as it requires no additional training-time rendering for patch-based regu-larization [8, 11, 22].
We consider FreeNeRF a simple baseline (with mini-mal modiﬁcations to a plain NeRF) in the few-shot neural rendering problem, although it already outperforms exist-ing state-of-the-art methods on multiple datasets, including
Blender, DTU, and LLFF, at almost no additional computa-tion cost. Our contributions can be summarized as follows:
• We reveal the link between the failure of few-shot neu-ral rendering and the frequency of positional encoding, which is further veriﬁed by an empirical study and ad-dressed by our proposed method. To our knowledge, our method is the ﬁrst attempt to address few-shot neural ren-dering from a frequency perspective.
• We identify another common failure pattern in learning
NeRF from sparse inputs and alleviate it with a new oc-clusion regularizer. This regularizer effectively improves performance and generalizes across datasets.
• Combined, we introduce a simple baseline, FreeNeRF, that can be implemented with a few lines of code mod-iﬁcation while outperforming previous state-of-the-art methods. Our method is dependency-free and overhead-free, making it a practical and efﬁcient solution to this problem.
We hope the observations and discussions in this paper will motivate people to rethink the fundamental role of fre-quency in NeRF’s positional encoding. 2.