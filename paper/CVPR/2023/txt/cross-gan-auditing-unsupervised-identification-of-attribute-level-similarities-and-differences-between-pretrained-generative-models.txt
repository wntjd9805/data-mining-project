Abstract
Generative Adversarial Networks (GANs) are notori-ously difficult to train especially for complex distributions and with limited data. This has driven the need for tools to audit trained networks in human intelligible format, for example, to identify biases or ensure fairness. Existing
GAN audit tools are restricted to coarse-grained, model-data comparisons based on summary statistics such as FID
In this paper, we propose an alternative ap-or recall. proach that compares a newly developed GAN against a prior baseline. To this end, we introduce Cross-GAN Audit-ing (xGA) that, given an established “reference” GAN and a newly proposed “client” GAN, jointly identifies intelligi-ble attributes that are either common across both GANs, novel to the client GAN, or missing from the client GAN.
This provides both users and model developers an intuitive assessment of similarity and differences between GANs. We introduce novel metrics to evaluate attribute-based GAN auditing approaches and use these metrics to demonstrate quantitatively that xGA outperforms baseline approaches.
We also include qualitative results that illustrate the com-mon, novel and missing attributes identified by xGA from
GANs trained on a variety of image datasets1. 1.

Introduction
Generative Adversarial Networks (GANs) [12, 19–21] have become ubiquitous in a range of high impact commer-cial and scientific applications [5, 7–9, 13]. With this pro-1Source is mattolson93/cross_gan_auditing available code at https : / / github . com /
lific use comes a growing need for investigative tools that are able to evaluate, characterize and differentiate one GAN model from another, especially since such differences can arise from a wide range of factors – biases in training data, model architectures and hyper parameters used in training etc. In practice, this has been mostly restricted to compar-ing two or more GAN models against the dataset they were trained on using summary metrics such as Fr´echet Inception
Distance (FID) [16] and precision/recall [20] scores.
However, in many real world scenarios, different models may not even be trained on the same dataset, thereby mak-ing such summary metrics incomparable. More formally, if we define the model comparison problem as one being be-tween a known – and presumably well vetted – reference
GAN and a newly developed client GAN. For example, the reference GANs can correspond to models purchased from public market places such as AWS [2], Azure [3], or
GCP [11], or to community-wide standards. Furthermore, there is a critical need for more fine-grained, interpretable, investigative tools in the context of fairness and account-ability. Broadly, these class of methods can be studied un-der the umbrella of AI model auditing [1, 6, 32]. Here, the interpretability is used in the context to indicate that the proposed auditing result will involves of human intelligi-ble attributes, rather than summary statistic that do not have explicit association with meaningful semantics.
While auditing classifiers has received much attention in the past [32], GAN auditing is still a relatively new research problem with existing efforts focusing on model-data com-parisons, such as identifying how faithfully a GAN recovers the original data distribution [1]. In contrast, we are inter-ested in developing a more general framework that enables a user to visually audit a “client” GAN model with respect the “reference”. This framework is expected to support different kinds of auditing tasks: (i) comparing different
GAN models trained on the same dataset (e.g. StyleGAN3-Rotation and StyleGAN3-Translate on FFHQ); (ii) compar-ing models trained on datasets with different biases (e.g.,
StyleGAN with race imbalance vs StyleGAN with age im-balance); and finally (iii) comparing models trained using datasets that contain challenging distribution shifts (e.g.,
CelebA vs Toons). Since these tools are primarily intended for human experts and auditors, interpretability is critical.
Hence, it is natural to perform auditing in terms of human intelligible attributes. Though there has been encouraging progress in automatically discovering such attributes from a single GAN in the recent years [14, 28, 39, 40, 43] they are not applicable to our setting with multiple GANs.
Proposed work We introduce cross-GAN auditing (xGA), an unsupervised approach for identifying attribute similar-ities and differences between client GANs and reference models (which could be pre-trained and potentially unre-lated). Since the GANs are trained independently, their la-tent spaces are disparate and encode different attributes, and thus they are not directly comparable. Consequently, dis-covering attributes is only one part of the solution; we also need to ‘align’ humanly meaningful and commonly occur-ring attributes across the individual latent spaces.
Our audit identifies three distinct sets of attributes: (a) common: attributes that exist in both client and refer-ence models; (b) novel: attributes encoded only in the client model; (c) missing: attributes present only in the reference.
In order to identify common attributes, xGA exploits the fact that shared attributes should induce similar changes in the resulting images across both the models. On the other hand, to discover novel/missing attributes, xGA leverages the key insight that attribute manipulations unique to one
GAN can be viewed as out of distribution (OOD) to the other GAN. Using empirical studies with a variety of Style-GAN models and benchmark datasets, we demonstrate that xGA is effective in providing a fine-grained characterization of generative models.
Contributions (i) We present the first cross-GAN audit-ing framework that uses an unified, attribute-centric method to automatically discover common, novel, and missing at-tributes from two or more GANs; (ii) Using an external, robust feature space for optimization, xGA produces high-quality attributes and achieves effective alignment even across challenging distribution shifts; (iii) We introduce novel metrics to evaluate attribute-based GAN auditing ap-proaches; and (iv) We evaluate xGA using StyleGANs trained on CelebA, AFHQ, FFHQ, Toons, Disney and Met-Faces, and also provide a suite of controlled experiments to evaluate cross-GAN auditing methods. 2.