Abstract
A signed distance function (SDF) parametrized by an
MLP is a common ingredient of neural surface reconstruc-tion. We build on the successful recent method NeuS to ex-tend it by three new components. The first component is to borrow the tri-plane representation from EG3D and rep-resent signed distance fields as a mixture of tri-planes and
MLPs instead of representing it with MLPs only. Using tri-planes leads to a more expressive data structure but will also introduce noise in the reconstructed surface. The sec-ond component is to use a new type of positional encoding with learnable weights to combat noise in the reconstruc-tion process. We divide the features in the tri-plane into multiple frequency scales and modulate them with sin and cos functions of different frequencies. The third component is to use learnable convolution operations on the tri-plane features using self-attention convolution to produce features with different frequency bands. The experiments show that
PET-NeuS achieves high-fidelity surface reconstruction on standard datasets. Following previous work and using the
Chamfer metric as the most important way to measure sur-face reconstruction quality, we are able to improve upon the
NeuS baseline by 57% on Nerf-synthetic (0.84 compared to 1.97) and by 15.5% on DTU (0.71 compared to 0.84). The qualitative evaluation reveals how our method can better control the interference of high-frequency noise. 1.

Introduction
Implicit neural functions, or neural fields, have received a lot of attention in recent research. The seminal paper
NeRF [25] combines neural fields with volume rendering, enabling high-quality novel view synthesis.
Inspired by
NeRF, NeuS [41] and VolSDF [44] introduce a signed dis-tance function (SDF) into the volume rendering equation and regularize the SDF, so that smooth surface models can be reconstructed. However, these methods use pure MLP networks to encode SDFs. Although these two methods can reconstruct smooth surfaces, they both leave room for im-provement when it comes to reconstructing surface details.
One research direction ( [5, 6, 26, 33, 46]) explores data structures such as tri-planes or voxel grids that are suitable to improve the NeRF framework, in terms of speed or recon-struction quality. However, data structures that are success-ful for novel view synthesis may not bring immediate suc-cess when employed for surface reconstruction as shown in the third column of Fig. 1. While a greater expressiveness to encode local details is useful to better fit the input data, there is also less inductive bias towards a smooth surface. There-fore, noise during image acquisition, high-frequency shad-ing, or high-frequency texture variations are more likely to result in a noisy reconstructed surface.
In our work, we explore how to increase expressiveness to encode local features while at the same time reducing the impact of noise interference. We choose to build on the tri-plane data structure since it consumes less memory and can be easier scaled to higher resolutions.
In our work, we build on EG3D and NeuS to propose a novel framework, called PET-NeuS. First, we propose a method to integrate the tri-plane data structure into a sur-face reconstruction framework in order to be able to model an SDF with more local details. Second, since the features between tri-plane pixels do not share learnable parameters, we use positional encoding to modulate the tri-plane fea-tures, thereby enhancing the smoothness of the learnable features. Third, the positional encoding involves functions of different frequencies.
In order to better match differ-ent frequencies, we propose to use multi-scale self-attention convolution kernels with different window sizes to perform convolution in the spatial domain to generate features of dif-ferent frequency bands. This further increases the fidelity of the surface reconstruction while suppressing noise.
We experiment on two datasets to verify the effectiveness of our method, the DTU dataset and the NeRF-Synthetic dataset. Since the DTU dataset contains non-Lambertian surfaces, the ability of the network to resist noise interfer-ence can be verified. The NeRF-Synthetic dataset has many sharp features, which can verify that our framework can ef-fectively utilize its improved local expressiveness to better reconstruct local details. We show superior performance compared to state-of-the-art methods on both datasets.
In summary, our contributions are as follows:
• We propose to train neural implicit surfaces with a tri-Figure 1. The challenge of using the tri-plane representation directly. First column: reference image. Second to the fifth column: NeuS,
Learning SDF using tri-planes, OURS without self-attention convolution, and OURS. plane architecture to enable the reconstructed surfaces to better preserve fine-grained local features. or rendering quality.
• We derive a novel positional encoding strategy to be used in conjunction with tri-plane features in order to reduce noise interference.
• We utilize self-attention convolution to produce tri-plane features with different frequency bands to match the positional encoding of different frequencies, fur-ther improving the fidelity of surface reconstruction. 2.