Abstract
Input
Output
We present a efficient multi-view inverse rendering method for large-scale real-world indoor scenes that re-constructs global illumination and physically-reasonable
SVBRDFs. Unlike previous representations, where the global illumination of large scenes is simplified as multiple environment maps, we propose a compact representation called Texture-based Lighting (TBL). It consists of 3D mesh and HDR textures, and efficiently models direct and infinite-bounce indirect lighting of the entire large scene. Based on
TBL, we further propose a hybrid lighting representation with precomputed irradiance, which significantly improves the efficiency and alleviates the rendering noise in the ma-terial optimization. To physically disentangle the ambiguity between materials, we propose a three-stage material opti-mization strategy based on the priors of semantic segmen-tation and room segmentation. Extensive experiments show that the proposed method outperforms the state-of-the-art quantitatively and qualitatively, and enables physically-reasonable mixed-reality applications such as material editing, editable novel view synthesis and relighting. The project page is at https://lzleejean.github.io/TexIR. 1.

Introduction
Inverse rendering aims to reconstruct geometry, material and illumination of an object or a scene from images. These properties are essential to downstream applications such as scene editing, editable novel view synthesis and relighting.
However, decomposing such properties from the images is extremely ill-posed, because different configurations of such properties often lead to similar appearance. With re-cent advances in differentiable rendering and implicit neural representation, several approaches have achieved significant success on small-scale object-centric scenes with explicit or implicit priors [7, 32, 34, 43, 50, 51, 55, 57, 58]. However, in-verse rendering of large-scale indoor scenes has not been well solved.
*Co-corresponding authors. s e g a m i w e i v
-e s r a p s d e s o
P
• • • g n i t h g i
L o d e b l
A s s e n h g u o
R
Applications
Material Editing
Editable Novel View
Relighting
Figure 1. Given a set of posed sparse-view images for a large-scale scene, we reconstruct global illumination and SVBRDFs.
The recovered properties are able to produce convincing results for several mixed-reality applications such as material editing, ed-itable novel view synthesis and relighting. Note that we change roughness of all walls, and albedo of all floors. The detailed spec-ular reflectance shows that our method successfully decomposes physically-reasonable SVBRDFs and lighting. Please refer to sup-plementary videos for more animations.
There are two main challenges for large-scale indoor scenes. 1) Modelling the physically-correct global illu-mination. There are far more complex lighting effects, e.g., inter-reflection and cast shadows, in large-scale in-door scenes than object-centric scenes due to complex oc-clusions, materials and local light sources. Although the widely-used image-based lighting (IBL) is able to effi-ciently model direct and indirect illumination, it only rep-resents the lighting of a certain position [13, 17, 18, 42].
The spatial consistency of per-pixel or per-voxel IBL rep-resentations [26, 29, 47, 59] is difficult to ensure. Moreover, such incompact representations require large memory. Pa-rameterized lights [16, 27] such as point light, area light and directional light are naturally globally-consistent, but modeling the expensive global light transport will be in-evitable [1,37,58]. Thus, simple lighting representations ap-plied in previous works are unsuitable in large-scale scenes. 2) Disentangling the ambiguity between materials. Differ-ent configurations of materials often lead to similar appear-ance, and to add insult to injury, there are an abundance of objects with complex and diverse materials in large-scale scenes. In object-centric scenes, dense views distributed on the hemisphere are helpful for alleviating the ambigu-ity [14, 22, 32, 35, 55, 56]. However, only sparse views are available in large-scale scenes, which more easily lead to ambiguous predictions [37, 51].
In this work, we present TexIR, an efficient inverse ren-dering method for large-scale indoor scenes. Aforemen-tioned challenges are tackled individually in the following. 1) We model the infinite-bounce global illumination of the entire scene with a novel compact lighting representation, called TBL. The TBL is able to efficiently represent the infinite-bounce global illumination of any position within the large scene. Such a compact and explicit representation provides more physically-accurate and spatially-varying il-lumination to guide the material estimation. Directly op-timizing materials with TBL leads to expensive compu-tation costs caused by high samples of the monte carlo sampling. Therefore, we precompute the irradiance based on our TBL, which significantly accelerates the expensive computation in the material optimization process. 2) To ameliorate the ambiguity between materials, we introduce a segmentation-based three-stage material optimization strat-egy. Specifically, we optimize a coarse albedo based on
Lambertian-assumption in the first stage. In the second stage, we integrate semantics priors to guide the propaga-tion of physically-correct roughness in regions with same semantics. In the last stage, we fine-tune both albedo and roughness based on the priors of semantic segmentation and room segmentation. By leveraging such priors, physically-reasonable albedo and roughness are disentangled globally.
To summarize, the main contributions of our method are as follows: 1. A compact large-scale lighting representation for scenes, where the infinite-bounce global illumination of the entire large scene can be handled efficiently. 2. A segmentation-based material optimization strategy to globally and physically disentangle the ambiguity between albedo and roughness of the entire scene. 3. A hybrid lighting representation based on the proposed
TBL and precomputed irradiance to improve the effi-ciency in the material optimization process. 2.