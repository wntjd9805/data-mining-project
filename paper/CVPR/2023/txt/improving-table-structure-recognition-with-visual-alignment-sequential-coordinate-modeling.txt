Abstract
Table structure recognition aims to extract the logical and physical structure of unstructured table images into a machine-readable format. The latest end-to-end image-to-text approaches simultaneously predict the two struc-tures by two decoders, where the prediction of the physi-cal structure (the bounding boxes of the cells) is based on the representation of the logical structure. However, the previous methods struggle with imprecise bounding boxes as the logical representation lacks local visual informa-tion. To address this issue, we propose an end-to-end se-quential modeling framework for table structure recogni-tion called VAST. It contains a novel coordinate sequence decoder triggered by the representation of the non-empty cell from the logical structure decoder. In the coordinate se-quence decoder, we model the bounding box coordinates as a language sequence, where the left, top, right and bottom coordinates are decoded sequentially to leverage the inter-coordinate dependency. Furthermore, we propose an auxil-iary visual-alignment loss to enforce the logical representa-tion of the non-empty cells to contain more local visual de-tails, which helps produce better cell bounding boxes. Ex-tensive experiments demonstrate that our proposed method can achieve state-of-the-art results in both logical and phys-ical structure recognition. The ablation study also vali-dates that the proposed coordinate sequence decoder and the visual-alignment loss are the keys to the success of our method. 1.

Introduction
Tables are an essential medium for expressing structural or semi-structural information. Table structure recognition, including recognizing a table’s logical and physical struc-ture, is crucial for understanding and further editing a vi-*Equal contribution. (a) TableFormer (Baseline) (b) VAST (Ours)
Figure 1. Visualization comparison of the bounding box predicted by TableFormer and VAST. Our results are more accurate, which is vital for downstream content extraction or table understanding tasks. The image is cropped from the table with id 7285, which comes from FinTabNet. sual table. The logical structure represents the row-column relation of cells and the spanning information of a cell. The physical structure contains not only the logical structure but also the bounding box or content of the cells, focusing on the exact locations in the image.
Table recognition can be implemented by an end-to-end encoder-decoder paradigm. Such methods excel at predict-ing the logical structure but usually produce less accurate physical structures, i.e., bounding boxes of cells or cell con-tents. However, the bounding box accuracy is essential to downstream tasks, such as text information extraction or ta-ble QA. This work designs the sequential coordinate decod-ing and enforces more visual information to produce more accurate bounding boxes.
In the coordinate sequence decoder, the start embedding of the non-empty cell is the representation from the HTML sequence decoder. The representation usually contains a more global context of the table and has fewer local visual details. Because the local visual appearance is vital for pre-dicting accurate coordinates, we align the representation of non-empty cells from the HTML sequence decoder with the visual features from the CNN image encoder. In particular, a visual-alignment loss is designed to maximize the cosine similarity of the paired visual-HTML representation in the image. In summary, our contributions are threefold.
• We propose a coordinate sequence decoder to signifi-cantly improve the table’s physical structure accuracy upon an end-to-end table recognition system.
• We introduce a visual-alignment loss between the
HTML decoder and coordinate sequence decoder. It enforces the representation from the HTML decod-ing module contains more detailed visual information, which can produce better bounding boxes for the non-empty cells.
• We develop an end-to-end sequential modeling frame-work for table structure recognition, the comparison experiments prove that our method can achieve state-of-the-art performance and the ablation experiments show the effectiveness of our method. 2.