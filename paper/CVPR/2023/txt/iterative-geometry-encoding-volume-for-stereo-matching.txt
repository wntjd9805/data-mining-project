Abstract
Recurrent All-Pairs Field Transforms (RAFT) has shown great potentials in matching tasks. However, all-pairs cor-relations lack non-local geometry knowledge and have dif-ficulties tackling local ambiguities in ill-posed regions. In this paper, we propose Iterative Geometry Encoding Volume (IGEV-Stereo), a new deep network architecture for stereo matching. The proposed IGEV-Stereo builds a combined geometry encoding volume that encodes geometry and con-text information as well as local matching details, and itera-tively indexes it to update the disparity map. To speed up the convergence, we exploit GEV to regress an accurate starting point for ConvGRUs iterations. Our IGEV-Stereo ranks 1st on KITTI 2015 and 2012 (Reflective) among all published methods and is the fastest among the top 10 methods. In addition, IGEV-Stereo has strong cross-dataset generaliza-tion as well as high inference efficiency. We also extend our
IGEV to multi-view stereo (MVS), i.e. IGEV-MVS, which achieves competitive accuracy on DTU benchmark. Code is available at https://github.com/gangweiX/IGEV. 1.

Introduction
Inferring 3D scene geometry from captured images is a fundamental task in computer vision and graphics with applications ranging from 3D reconstruction, robotics and autonomous driving. Stereo matching which aims to re-construct dense 3D representations from two images with calibrated cameras is a key technique for reconstructing 3D scene geometry.
Many learning-based stereo methods [5, 17, 24, 47, 48] have been proposed in the literature. The popular repre-sentative is PSMNet [5] which apply a 3D convolutional encoder-decoder to aggregate and regularize a 4D cost vol-ume and then use sof t argmin to regress the disparity map from the regularized cost volume. Such 4D cost volume filtering-based methods can effectively explore stereo ge-ometry information and achieve impressive performance on
â€ Corresponding author.
Figure 1. (a) Comparison with state-of-the-art stereo methods
[9, 21, 25, 43, 47, 59] on KITTI 2012 and 2015 leaderboards. (b)
Performance comparison with RAFT-Stereo [24] on Scene Flow test set as the number of iterations changes. several benchmarks. However, it usually demands a large amount of 3D convolutions for cost aggregation and regu-larization, and in turn yield high computational and memory costs. As a result, it can hardly be applied to high-resolution images and/or large-scale scenes.
Recently, iterative optimization-based methods [21, 24, 30, 39, 43] have exhibited attractive performance on both high resolution images and standard benchmarks. Different from existing methods, iterative methods bypass the com-putationally expensive cost aggregation operations and pro-gressively update the disparity map by repeatedly fetching information from a high-resolution 4D cost volume. Such solution enables the direct usage of high-resolution cost vol-ume and hence is applicable to high-resolution images. For instance, RAFT-Stereo [24] exploits a multi-level Convo-lutional Gated Recurrent Units (ConvGRUs) [10] to recur-rently update the disparity field using local cost values re-trieved from all-pairs correlations (APC).
However, without cost aggregation the original cost vol-ume lacks non-local geometry and context information (see
Fig. 2 (b)). As a result, existing iterative methods have difficulties tackling local ambiguities in ill-posed regions, such as occlusions, texture-less regions and repetitive struc-tures. Even though, the ConvGRU-based updater can im-prove the predicted disparities by incorporating context and geometry information from context features and hidden lay-Figure 2. (a) Input images from KITTI 2015. Illustration of (b) disparity regressed from All-pairs Correlations (APC) in RAFT-Stereo [24], (c) disparity regressed from our Geometry Encoding Volume (GEV), (d) our final disparity. The APC lacks non-local geometry knowledge and thus has difficulties tackling local ambiguities in ill-posed region. We take full advantage of cost filtering and iterative optimization: 1) exploiting 3D CNN to filter cost volume and obtain the strong scene representation and the initial disparity with smooth edges, 2) exploiting
ConvGRUs to optimize the initial disparity to recover object edges and details. ers, such limitation in the original cost volume greatly lim-its the effectiveness of each iteration and in turn yields a large amount of ConvGRUs iterations for satisfactory per-formance.
We claim that cost filtering-based methods and itera-tive optimization-based methods have complementary ad-vantages and limitations. The former can encode sufficient non-local geometry and context information in the cost vol-ume which is essential for disparity prediction in particu-lar in challenging regions. The latter can avoid high com-putational and memory costs for 3D cost aggregation, yet are less capable in ill-posed regions based only on all-pairs correlations. To combine complementary advantages of the two methods, we propose Iterative Geometry Encoding Vol-ume (IGEV-Stereo), a new paradigm for stereo matching (see Fig. 3). To address ambiguities caused by ill-posed regions, we compute a Geometry Encoding Volume (GEV) by aggregating and regularizing a cost volume using an ex-tremely lightweight 3D regularization network. Compared to all-pairs correlations of RAFT-Stereo [24], our GEV en-codes more geometry and context of the scene after aggre-gation, shown in Fig. 2 (c). A potential problem of GEV is that it could suffer from over-smoothing at boundaries and tiny details due to the 3D regularization network. To com-plement local correlations, we combine the GEV and all-pairs correlations to form a Combined Geometry Encoding
Volume (CGEV) and input the CGEV into the ConvGRU-based update operator for iterative disparity optimization.
Our IGEV-Stereo outperforms RAFT-Stereo in terms of both accuracy and efficiency. The performance gains come from two aspects. First, our CGEV provides more compre-hensive yet concise information for ConvGRUs to update, yielding more effective optimization in each iteration and in turn could significantly reduce the amount of ConvGRUs iterations. As shown in Fig. 1, our method achieves even smaller EPE (i.e., 0.58) using only 3 ConvGRUs iterations (i.e.,100ms totally for inference) than RAFT-Stereo using 32 ConvGRUs iterations (i.e., EPE of 0.61 and 440ms for inference). Second, our method regresses an initial disparity map from the GEV via sof t argmin which could provide an accurate starting point for the ConvGRU-based update operator, and in turn yield a fast convergence. In compari-son, RAFT-Stereo starts disparity prediction from an initial starting point d0=0, which demands a large number Con-vGRUs iterations to achieve an optimized result.
We demonstrate the efficiency and effectiveness of our method on several stereo benchmarks. Our IGEV-Stereo achieves the state-of-the-art EPE of 0.47 on Scene Flow
[31] and ranks 1st on KITTI 2015 [32] and 2012 (Re-flective) [15] leaderboards among all the published meth-ods. Regarding the inference speed, our IGEV-Stereo is the fastest among the top 10 methods on KITTI leader-boards. IGEV-Stereo also exhibits better cross-dataset gen-eralization ability than most existing stereo networks. When trained only on synthetic data Scene Flow, our IGEV-Stereo performs very well on real datasets Middlebury [34] and
ETH3D [35]. We also extend our IGEV to MVS, i.e. IGEV-MVS, which achieves competitive accuracy on DTU [1]. 2.