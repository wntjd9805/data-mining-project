Abstract
The task of key-points detection and description is to es-timate the stable location and discriminative representa-tion of local features, which is a fundamental task in vi-sual applications. However, either the rough hard positive or negative labels generated from one-to-one correspon-dences among images may bring indistinguishable samples, like false positives or negatives, which acts as inconsis-tent supervision. Such resultant false samples mixed with hard samples prevent neural networks from learning de-scriptions for more accurate matching. To tackle this chal-lenge, we propose to learn the transformation-predictive representations with self-supervised contrastive learning.
We maximize the similarity between corresponding views of the same 3D point (landmark) by using none of the neg-ative sample pairs and avoiding collapsing solutions. Fur-thermore, we adopt self-supervised generation learning and curriculum learning to soften the hard positive labels into soft continuous targets. The aggressively updated soft la-bels contribute to overcoming the training bottleneck (de-rived from the label noise of false positives) and facili-tating the model training under a stronger transformation paradigm. Our self-supervised training pipeline greatly de-creases the computation load and memory usage, and out-performs the sota on the standard image matching bench-marks by noticeable margins, demonstrating excellent gen-eralization capability on multiple downstream tasks. 1.

Introduction
Local visual descriptors are fundamental to various com-puter vision applications such as camera calibration [37], 3D reconstruction[19], visual simultaneous localization and mapping (VSLAM) [33], and image retrieval [38]. The descriptors indicate the representation vector of the patch around the key-points and can be used to generate dense
*Corresponding author correspondences between images.
The discriptors are highly dependent on the effective rep-resentation, which has been always trained with the Siamese architecture and contrastive learning loss [12, 29, 39]. The core idea of contrastive learning is “learn to compare”: given an anchor key-point, distinguish a similar (or pos-itive) sample from a set of dissimilar (or negative) sam-ples, in a projected embedding space. The induced repre-sentations present two key properties: 1) alignment of fea-tures from positive pairs, 2) and uniformity of representation on the hypersphere [51]. Negative samples are thus intro-duced to keep the uniformity property and avoid model col-lapse, i.e., preventing the convergence to one constant solu-tion [13]. Therefore, various methods have been proposed to mine hard negatives [6, 21, 55]. However, these methods raise the computational load and memory resources usage heavily [17]. More Importantly, within the hard negatives, some samples are labeled as negatives, but actually have the identical semantics of the anchor (i.e., false negatives).
These false negatives act as inconsistent supervision and prevent the learning-based models from achieving higher accuracy[4]. More concretely, the false negatives represent the instance located on the repetitive texture in the structural dataset, as shown in Figure 1. It is challenging to recognize such false negatives from true negatives[39].
The recent active self-supervised learning methods [5, 8, 9, 15] motivate us to rethink the effectiveness of negatives in descriptors learning. We propose to learn the transfor-mation predictive representations (TPR) for visual descrip-tors only with the positives and avoids collapsing solutions.
Furthermore, using none of negatives greatly improves the training efficiency by reducing the scale of the similarity matrix from O(n2) to O(n), and reduces the computation load and memory usage.
To further improve the generalization performance of descriptors, hard positives (i.e., corresponding pairs with large-scale transformation) are encouraged as training data to expose novel patterns. However, recent experiments have shown that directly contrastive learning on stronger
Figure 1. Illustrative schematic of different negative samples. Easy negatives (green) are easy to distinguish from the query (blue) and not sufficient for good performance. Hard negatives (orange) are important for better performance and are still semantically dissimilar from the query. False negatives (red) are practically impossible to distinguish and semantically identical with the query, which is harmful to the performance. The right figure visualizes the embedding of different samples in latent space. transformed images can not learn representations effec-tively [52]. In addition, current contrastive learning meth-ods label all positives with different transformation strength as coarse “1”, which prevent learning refined representa-tion. We propose to learn transformation predictive repre-sentation with soft positive labels from (0,1] instead of “1” to supervise the learning of local descriptors. Furthermore, we propose a self-supervised curriculum learning module to generate controllable stronger positives with gradually re-fined soft supervision as the network iterative training.
Finally, our TPR with soft labels is trained on natural images in a fully self-supervised paradigm. Different from previous methods trained on datasets with SfM or cam-era pose information [20, 29, 39, 49], our training datasets are generally easy to collect and scale up since there is no extra annotation requirement to capture dense correspon-dences. Experiments show that our self-supervised method outperforms the state-of-the-art on standard image match-ing benchmarks by noticeable margins and shows excel-lent generalization capability on multiple downstream tasks (e.g., visual odometry, and localization).
Our contributions to this work are as follows: i) we pro-pose to learn transformation-predictive representations for joint local feature learning, using none of the negative sam-ple pairs and avoiding collapsing solutions. ii) We adopt self-supervised generation learning and curriculum learn-ing to soften the hard positives into continuous soft labels, which can alleviate the false positives and train the model with stronger transformation. iii) The overall pipeline is trained with the self-supervised paradigm, and the training data are computed from random affine transformation and augmentation on natural images. 2.