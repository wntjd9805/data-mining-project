Abstract
User-generated content (UGC) live videos are often bothered by various distortions during capture procedures and thus exhibit diverse visual qualities. Such source videos are further compressed and transcoded by media server providers before being distributed to end-users. Because of the flourishing of UGC live videos, effective video qual-ity assessment (VQA) tools are needed to monitor and per-ceptually optimize live streaming videos in the distributing process. In this paper, we address UGC Live VQA prob-lems by constructing a first-of-a-kind subjective UGC Live
VQA database and developing an effective evaluation tool.
Concretely, 418 source UGC videos are collected in real live streaming scenarios and 3,762 compressed ones at dif-ferent bit rates are generated for the subsequent subjective
VQA experiments. Based on the built database, we de-velop a Multi-Dimensional VQA (MD-VQA) evaluator to measure the visual quality of UGC live videos from seman-tic, distortion, and motion aspects respectively. Extensive experimental results show that MD-VQA achieves state-of-the-art performance on both our UGC Live VQA database and existing compressed UGC VQA databases. 1.

Introduction
With the rapid development of social media applications and the advancement of video shooting and processing tech-nologies, more and more ordinary people are willing to tell their stories, share their experiences, and have their voice heard on social media or streaming media platforms such as Twitch, Tiktok, Taobao, etc. However, due to the lack of photography skills and professional equipment, the vi-*These authors contributed equally to this work. The database is avail-able at https://tianchi.aliyun.com/dataset/148818?t=1679581936815.
†Corresponding author.
Figure 1. The distributing process of UGC live videos, where the users upload the videos degraded by the UGC distortions to the live platforms and the distorted videos are further compressed be-fore being distributed to the viewers. The VQA models can mon-itor the quality changes of the compressed UGC live videos and adaptively optimize the transcoding setting. sual quality of user-generated content (UGC) videos may be degraded by in-the-wild distortions [51]. What’s more, in common live platforms, live videos are encoded and dis-tributed to end-users with very low delay, where compres-sion algorithms have a significant influence on the visual quality of live videos because they can greatly reduce trans-mission bandwidth. As illustrated in Fig. 1, video quality assessment (VQA) tools play an important role in monitor-ing, optimizing, and further improving the Quality of Expe-rience (QoE) of end-users in UGC live streaming systems.
In the literature, many UGC VQA databases have been carried out [14, 21, 36, 45, 51] to address the impact of gen-eral in-the-wild distortions on video quality, while some compression VQA databases [22, 34, 40] are proposed to study the influence of compression artifacts. Then some compressed UGC VQA databases [1, 21, 46] are further constructed to solve the problem of assessing the quality of UGC videos with compression distortions. However, they are either small in scale or employ high-quality UGC videos as the sources, and all of the mentioned databases lack videos in live streaming scenes. Therefore, there is a lack of a proper UGC Live VQA database to develop and validate the video quality measurement tools for live streaming systems.
Table 1. Review of common VQA databases, where ’UGC+Compression’ refers to manually encoding the UGC videos with different compression settings.
Database
Year Duration/s Ref. Num.
Scale
Scope
Subjective Evaluating Format
CVD2014 [31]
LIVE-Qualcomm [12]
KoNViD-1k [14]
LIVE-VQC [36]
YouTube-UGC [45]
LSVQ [51]
UGC-VIDEO [21]
LIVE-WC [53] 2014 2016 2017 2018 2019 2021 2019 2020
YT-UGC+(Subset) [46] 2021 2021 2022
ICME2021 [1]
TaoLive(proposed) 10-25 15 8 10 20 5-12
>10 10 20
-8
------50 55 189 1,000 418
In-capture 234
In-capture 208
In-the-wild 1,200
In-the-wild 585
In-the-wild 1,500
In-the-wild 39,075
UGC + Compression 550
UGC + Compression 275 567
UGC + Compression 8,000 UGC + Compression 3,762 UGC + Compression
In-lab
In-lab
Crowdsourced
Crowdsourced
Crowdsourced
Crowdsourced
In-lab
In-lab
In-lab
In-lab
In-lab
To address UGC Live VQA problems, we first con-struct a large-scale database named TaoLive, consisting 418 source UGC videos from the TaoBao [2] live streaming platform and the corresponding 3,762 compressed videos at various bit rates. Then we perform a subjective experiment in a well-controlled environment. Afterward, we propose a no-reference (NR) Multi-Dimensional VQA (MD-VQA) model to measure the visual quality of UGC live videos in terms of semantic, distortion, and motion aspects. The semantic features are extracted by pretrained convolutional neural network (CNN) model; the distortion features are ex-tracted by specific handcrafted image distortion descriptors (i.e. blur, noise, block effect, exposure, and colorfulness); and the motion features are extracted from video clips by pretrained 3D-CNN models. Compared with existing UGC
VQA algorithms, MD-VQA measures visual quality from multiple dimensions, and these dimensions correspond to key factors affecting live video quality, which thereby has better interpretability and performance. The contributions of this paper are summarized as below:
• We build a large-scale UGC Live VQA database targeted at the compression artifacts on the UGC live videos. We collect 418 raw UGC live videos that are diverse in content, distortion, and quality. Then 8 encoding settings are used, which provides 3,762 com-pressed UGC live videos in total.
• We carry out a well-controlled in-lab subjective ex-periment. 44 participants are invited to participate in the subjective experiment and a total of 165,528 sub-jective annotations are gathered.
• A multi-dimensional NR-VQA model is proposed, using pretrained 2D-CNN, handcrafted distortion de-scriptors, and pretrained 3D-CNN for the semantic, distortion, and motion features extraction respectively.
The extracted features are then spatio-temporally fused to obtain the video-level quality score. The extensive experimental results validate the effectiveness of the proposed method. (a) (b)
Figure 2. Comparison of the quality distribution of reference videos between the TaoLive and ICME2021 [1] databases. The source UGC videos in the ICME2021 database are centered on high-quality levels while the quality levels of the source UGC videos in the TaoLive database are more diverse. 2.