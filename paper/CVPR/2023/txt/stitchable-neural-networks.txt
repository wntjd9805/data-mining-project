Abstract
The public model zoo containing enormous powerful pretrained model families (e.g., ResNet/DeiT) has reached an unprecedented scope than ever, which significantly con-tributes to the success of deep learning. As each model fam-ily consists of pretrained models with diverse scales (e.g.,
DeiT-Ti/S/B), it naturally arises a fundamental question of how to efficiently assemble these readily available models in a family for dynamic accuracy-efficiency trade-offs at runtime. To this end, we present Stitchable Neural Net-works (SN-Net), a novel scalable and efficient framework for model deployment. It cheaply produces numerous net-works with different complexity and performance trade-offs given a family of pretrained neural networks, which we call anchors. Specifically, SN-Net splits the anchors across the blocks/layers and then stitches them together with simple stitching layers to map the activations from one anchor to another. With only a few epochs of training, SN-Net effec-tively interpolates between the performance of anchors with varying scales. At runtime, SN-Net can instantly adapt to dynamic resource constraints by switching the stitching po-sitions. Extensive experiments on ImageNet classification demonstrate that SN-Net can obtain on-par or even bet-ter performance than many individually trained networks
†Corresponding author. E-mail: bohan.zhuang@gmail.com while supporting diverse deployment scenarios. For exam-ple, by stitching Swin Transformers, we challenge hundreds of models in Timm model zoo with a single network. We be-lieve this new elastic model framework can serve as a strong baseline for further research in wider communities. 1.

Introduction
The vast computational resources available and large amount of data have driven researchers to build tens of thou-sands of powerful deep neural networks with strong per-formance, which have largely underpinned the most recent breakthroughs in machine learning and much broader arti-ficial intelligence. Up to now, there are ∼81k models on
HuggingFace [53] and ∼800 models on Timm [52] that are ready to be downloaded and executed without the over-head of reproducing. Despite the large model zoo, a model family (e.g., DeiT-Ti/S/B [48]) that contains pretrained models with functionally similar architectures but different scales only covers a coarse-grained level of model complex-ity/performance, where each model only targets a specific resource budget (e.g., FLOPs). Moreover, the model fam-ily is not flexible to adapt to dynamic resource constraints since each individual model is not re-configurable due to the fixed computational graph. In reality, we usually need to deploy models to diverse platforms with different resource
require complicated training strategies to guarantee a good model performance.
In this work, we present Stitchable Neural Network (SN-Net), a novel scalable deep learning framework for efficient model design and deployment which quickly stitches an off-the-shelf pretrained model family with much less train-ing effort to cover a fine-grained level of model complex-ity/performance for a wide range of deployment scenarios (see Figure 1 (c)). Specifically, SN-Net is motivated by the previous observations [2, 10, 21] that the typical min-ima reached by SGD can be stitched to each other with low loss penalty, which implies architectures of the same model family pretrained on the same task can be stitched. Based on this insight, SN-Net directly selects the well-performed pretrained models in a model family as “anchors”, and then inserts a few simple stitching layers at different positions to transform the activations from one anchor to its nearest
In this way, SN-Net nat-anchor in terms of complexity. urally interpolates a path between neighbouring anchors of different accuracy-efficiency trade-offs, and thus can handle dynamic resource constraints with a single neural network at runtime. An example is shown in Figure 2, where a single
Swin-based SN-Net is able to do what hundreds of models can do with only 50 epochs training on ImageNet-1K.
We systematically study the design principles for SN-Net, including the choice of anchors, the design of stitching layers, the stitching direction and strategy, along with a suf-ficiently simple but effective training strategy. With com-prehensive experiments, we show that SN-Net demonstrates promising advantages: 1) Compared to the existing preva-lent scalable deep learning frameworks (Figure 1), SN-Net is a new universal paradigm which breaks the limit of a sin-gle pretrained model or supernet design by extending the design space into a large number of model families in the model zoo, forming a “many-to-many” pipeline. 2) Differ-ent from NAS training that requires complex optimization techniques [4, 61], training SN-Net is as easy as training in-dividual models while getting rid of the huge computational cost of training from scratch. 3) The final performance of stitches is almost predictable due to the interpolation-like performance curve between anchors, which implies that we can selectively train a number of stitches prior to training based on different deployment scenarios.
In a nutshell, we summarize our contributions as follows:
• We introduce Stitchable Neural Networks, a new uni-versal framework for elastic deep learning by directly utilising the pretrained model families in model zoo via model stitching.
• We provide practical principles to design and train SN-Net, laying down the foundations for future research.
• Extensive experiments demonstrate that compared to training individual networks from scratch, e.g., a single
Figure 2. One Stitchable Neural Network vs. 200 models in Timm model zoo [52].
It shows an example of SN-Net by stitching
ImageNet-22K pretrained Swin-Ti/S/B. Compared to each indi-vidual network, SN-Net is able to instantly switch network topol-ogy at runtime and covers a wide range of computing resource budgets. Larger and darker dots indicate a larger model with more parameters and higher complexity. constraints (e.g., energy, latency, on-chip memory). For in-stance, a mobile app in Google Play has to support tens of thousands of unique Android devices, from a high-end Sam-sung Galaxy S22 to a low-end Nokia X5. Therefore, given a family of pretrained models in the model zoo, a funda-mental research question naturally arises: how to effectively utilise these off-the-shelf pretrained models to handle di-verse deployment scenarios for Green AI [45]?
To answer this question, a naive solution is to train indi-vidual models with different accuracy-efficiency trade-offs from scratch. However, such method has a linearly in-creased training and time cost with the number of possi-ble cases. Therefore, one may consider the existing scal-able deep learning frameworks, such as model compres-sion and neural architecture search (NAS), to obtain mod-els at different scales for diverse deployment requirements.
Specifically, network compression approaches such as prun-ing [20,22,25], quantization [32,42,62] and knowledge dis-tillation [7, 43, 47] aim to obtain a small model from a large and well-trained network, which however only target one specific resource budget (see Figure 1 (a)), thus not flexible to meet the requirements of real-world deployment scenar-ios. On the other hand, one-shot NAS [28, 37], a typical
NAS framework that decouples training and specialization stages, seeks to train an over-parameterized supernet that supports many sub-networks for run-time dynamics (see
Figure 1 (b)), but training the supernet is extremely time-consuming and computationally expensive (e.g., 1,200 GPU hours on 32 V100 GPUs in OFA [4]). To summarize, the existing scalable deep learning frameworks are still limited within a single model design space, which cannot inherit the rich knowledge from pretrained model families in a model zoo for better flexibility and accuracy. Besides, they also
DeiT-based [48] SN-Net can achieve flexible accuracy-efficiency trade-offs at runtime while reducing 22× training cost and local disk storage. 2.