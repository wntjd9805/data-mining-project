Abstract
How to ensure fairness is an important topic in feder-ated learning (FL). Recent studies have investigated how to reward clients based on their contribution (collaboration fairness), and how to achieve uniformity of performance across clients (performance fairness). Despite achieving progress on either one, we argue that it is critical to con-sider them together, in order to engage and motivate more diverse clients joining FL to derive a high-quality global model. In this work, we propose a novel method to opti-mize both types of fairness simultaneously. Speciﬁcally, we propose to estimate client contribution in gradient and data space. In gradient space, we monitor the gradient direc-tion differences of each client with respect to others. And in data space, we measure the prediction error on client data using an auxiliary model. Based on this contribu-tion estimation, we propose a FL method, federated train-ing via contribution estimation (FedCE), i.e., using estima-tion as global model aggregation weights. We have theo-retically analyzed our method and empirically evaluated it on two real-world medical datasets. The effectiveness of our approach has been validated with signiﬁcant perfor-mance improvements, better collaboration fairness, better performance fairness, and comprehensive analytical stud-ies. Code is available at https://nvidia.github. io/NVFlare/research/fed-ce 1.

Introduction
Recent development of federated learning (FL) facil-itates collaboration for medical applications, given that multiple medical institutions can jointly train a consensus model without sharing raw data [1–6]. FL provides an op-portunity to leverage larger and more diverse datasets to derive a robust and generalizable model [7, 8]. However, it is usually difﬁcult to pool different institutions together
*Corresponding authors: Qi Dou (qidou@cuhk.edu.hk) and Ziyue Xu (ziyuex@nvidia.com) to train a FL model in practice. The challenges mainly lie in two aspects. First, it takes effort to set up and partici-pate in federated training, medical institutions may not be sufﬁciently motivated to contribute to a FL study without a fair credit assignment and a fair reward allocation, i.e., collaboration fairness [9]. Second, medical data are het-erogeneous in amounts and data-collection process [10–13], which may lead to inferior performance for clients with ei-ther less data or a data distribution deviating from others, harming performance fairness [14, 15]. It is critical to in-volve diverse datasets and improve individual prediction ac-curacy for building robust medical applications with low er-ror tolerance [16]. Therefore, we argue that these two types of fairness need to be considered together.
Despite recent investigations on fairness-related topics, existing literature mostly addresses collaboration fairness and performance fairness separately. For example, meth-ods for collaboration fairness aim to estimate client reward, by using the computation and communication cost of each client [17], evaluating local validation performance [18], and using cosine similarity between local and global up-dates [19]. Meanwhile, methods for performance fairness aim to mitigate performance disparities, by using mini-max optimization to improve worst-performing clients [15, 20], re-weighting clients to adjust fairness/accuracy trade-off [14], or learning personalized models [21]. To ade-quately address concerns on these two fairness, we postulate that it is desirable to consider both simultaneously, because reward estimation and model performance could essentially be coupled during training. Solutions on how to tackle col-laboration fairness and performance fairness together are still under-investigated, especially in medical domain.
To tackle this problem, our insight is to estimate the contribution of each client, and further use the contribu-tion to promote training performance. The idea is inspired by Shapley Value (SV) [22], a classic approach to quan-tify the contribution of participants in cooperative game the-ory. SV proposes to permute all possible subsets of partici-pants to calculate the contribution of a certain client. Some existing works have adopted SV for estimating client re-ward [19, 23–25]. However, these methods mostly approxi-mate SV by comparing local model updates or local model validations, which can be highly correlated with local sam-ple numbers. A client with more samples can dominate the training, resulting in inaccurate estimation results. There-fore, ﬁnding a more accurate and robust estimation is im-perative to break through this bottleneck.
In this work, we propose a novel client contribution es-timation method to approximate SV by comparing a certain client with respect to all other clients. We further present a new FL algorithm, federated training via contribution es-timation (FedCE), which uses client contributions as new weighting factors for global model aggregation. Speciﬁ-cally, since the fundamental setting of SV is to validate if a new client contributes to all possible combinations of ex-isting clients, to effectively and efﬁciently approximate it, we propose to directly measure how a certain client con-tributes to all remaining clients, rather than computing all possible permutations. Our contribution measurement con-siders both gradient and data space to quantify the contribu-tion of each client. In gradient space, we calculate the gradi-ent direction differences between one client and all the other clients; and in data space, we measure the prediction error on client data by using an auxiliary model, which is calcu-lated by excluding a client’s own parameters. By combin-ing these two measurements, we are able to quantify each client’s contribution for collaboration fairness, and further use this estimation to promote training for performance fair-ness. Our main contributions are summarized as follows:
• We propose a novel method for client contribution esti-mation to facilitate collaboration fairness. We empir-ically and theoretically analyze the robustness of this estimation method under various FL data distributions.
• We propose a novel federated learning method, FedCE, based on the proposed client contribution estimation to help promote performance fairness, and we theoreti-cally analyze the model’s convergence.
• We conduct extensive experiments on two medical im-age segmentation tasks. The proposed FedCE method signiﬁcantly outperforms several latest state-of-the-art FL methods, and comprehensive analytical studies demonstrate the effectiveness of our method. 2.