Abstract
We present 3D Highlighter, a technique for localizing se-mantic regions on a mesh using text as input. A key feature of our system is the ability to interpret “out-of-domain” localizations. Our system demonstrates the ability to rea-son about where to place non-obviously related concepts on an input 3D shape, such as adding clothing to a bare 3D animal model. Our method contextualizes the text de-scription using a neural ﬁeld and colors the correspond-ing region of the shape using a probability-weighted blend.
Our neural optimization is guided by a pre-trained CLIP en-coder, which bypasses the need for any 3D datasets or 3D annotations. Thus, 3D Highlighter is highly ﬂexible, gen-eral, and capable of producing localizations on a myriad of input shapes. Our code is publicly available at https:
//github.com/threedle/3DHighlighter. 1.

Introduction
Semantic localization of regions on 3D meshes is an im-portant problem in computer graphics and vision with broad applications. One such application is the incorporation of semantic information into the 3D modeling process. A par-ticularly challenging aspect of this task emerges when 3D geometric signals are insufﬁcient for performing segmenta-tion, e.g. where to add a shirt to a bare 3D human model.
We propose 3D Highlighter, a method for automatically localizing ﬁne-grained semantic regions on a shape based on only a text description. Our system contextualizes the text prompt and highlights the corresponding shape region using the network-predicted probabilities. Using only text, users are able to semantically identify regions on a shape.
Our system takes meshes as input, making it compatible with 3D modeling workﬂows and tools.
This highlighting task requires both object-level and part-level understanding. 3D Highlighter demonstrates the ability to reason about where to place seemingly unrelated concepts on the 3D shape, such as a hat on a candle (Fig. 1).
Our system localizes attributes that are geometrically ab-sent from a shape, which we refer to as hallucinated high-lighting. Understanding a part’s global shape context is challenging even when relying on salient geometric fea-tures [17, 27], let alone without them.
We optimize the weights of a neural network to produce probabilities that are used to color a given 3D shape in ac-cordance with the speciﬁed text. We leverage a pre-trained vision-language model (CLIP [31]) to guide the neural opti-mization towards the text-speciﬁed region. This neural opti-mization formulation is ﬂexible, bypassing the need for any 3D datasets, 3D annotations, or 3D pre-training. Our sys-tem is not bound to a speciﬁc set of classes, and, as shown in Fig. 2, is not limited to object parts deﬁned by salient geometric features.
We encode the part selection as a neural ﬁeld [44] over the mesh surface. Our network learns to map each point on the surface to a probability of belonging to the text-speciﬁed region. We translate the inferred probabilities to a visual at-Shoes
Wheels
Bow Tie
Hair
Necklace
Shoes
Shoes
Heart
Belt
Hat
Belt
Hat
Hat
Gloves
Necklace
Mask
Necklace
Snout
Shoes
Arm
Shoes
Mouth
Floor
Scarf
Roof
Wings
Car Headlights Shoes
Glasses
Belt
Collar
Braids
Figure 2. Hallucinated part highlighting. Our system is able to reason about where to highlight a geometrically-absent region on shapes.
The resulting localizations demonstrate global understanding and localized part-awareness. tribute on the mesh surface, which can be rendered and visu-ally understood. The network-predicted probabilities act as a soft-selection operator which blends the highlighter color onto the mesh. The network weights are updated by en-couraging the CLIP [31] embedding of the 2D renders of the highlighted mesh to adhere to the speciﬁed text. As a result, the network implicitly learns to segment the object to adhere to the text prompt.
We make several design choices that are key to the suc-cess of 3D Highlighter. Our network does not directly color the mesh. Rather, we predict a probability of being inside the text-speciﬁed highlight, which is used to blend colors on the mesh. The network is initialized such that points have roughly a 50% probability of being highlighted, resulting in a mesh with albedo halfway between the highlight and background color. During optimization, the relative blend weight of the highlight color directly corresponds to the highlight probability. This blending enables the network to naturally and smoothly increase or decrease the segmenta-tion probability in accordance with the text speciﬁcation of the target region.
In summary, we present a method for localizing seman-tic regions on 3D shapes. The localization is speciﬁed by a textual description, which is intuitive, ﬂexible, and not limited to a speciﬁc training dataset. We demonstrate appli-cations of our method to shape editing and stylization. Fur-thermore, our ﬁeld formulation enables the 3D Highlighter to work with different mesh resolutions and triangulations.
A key feature of our system is the ability to interpret out-of-domain localizations. For example, 3D Highlighter is able to ﬁgure out where to place a ‘hat’ on a candle as seen in
Fig. 1, demonstrating the ability to reason about where to place seemingly unrelated concepts on the 3D shape. 2.