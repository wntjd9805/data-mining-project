Abstract
We propose a novel method called SHS-Net for oriented normal estimation of point clouds by learning signed hyper surfaces, which can accurately predict normals with global consistent orientation from various point clouds. Almost all existing methods estimate oriented normals through a two-stage pipeline, i.e., unoriented normal estimation and normal orientation, and each step is implemented by a sep-arate algorithm. However, previous methods are sensitive to parameter settings, resulting in poor results from point clouds with noise, density variations and complex geome-tries.
In this work, we introduce signed hyper surfaces (SHS), which are parameterized by multi-layer perceptron (MLP) layers, to learn to estimate oriented normals from point clouds in an end-to-end manner. The signed hyper surfaces are implicitly learned in a high-dimensional fea-ture space where the local and global information is aggre-gated. Specifically, we introduce a patch encoding mod-ule and a shape encoding module to encode a 3D point cloud into a local latent code and a global latent code, respectively. Then, an attention-weighted normal predic-tion module is proposed as a decoder, which takes the local and global latent codes as input to predict oriented nor-mals. Experimental results show that our SHS-Net out-performs the state-of-the-art methods in both unoriented and oriented normal estimation on the widely used bench-marks. The code, data and pretrained models are available at https://github.com/LeoQLi/SHS-Net.
*The corresponding author is Yu-Shen Liu. This work was supported by National Key R&D Program of China (2022YFC3800600), the Na-tional Natural Science Foundation of China (62272263, 62072268), and in part by Tsinghua-Kuaishou Institute of Future Media Data.
Figure 1. We propose SHS-Net to estimate oriented normals di-rectly from point clouds.
In contrast, previous studies usually achieve this process through a two-stage paradigm using different algorithms, i.e., (1) unoriented normal estimation (e.g., PCA [19],
AdaFit [59] and HSurf-Net [32]) and (2) normal orientation (e.g.,
MST [19], QPBO [45] and ODP [38]). 1.

Introduction
In computer vision and graphics, estimating normals for point clouds is a prerequisite for many techniques. As an important geometric property of point clouds, normals with consistent orientation, i.e., oriented normals, clearly reveal the geometric structures and make significant contributions in downstream applications, such as rendering and surface reconstruction [24–26]. Generally, the estimation of ori-ented normals requires a two-stage paradigm (see Fig. 1): (1) the unoriented normal estimation from the local neigh-bors of the query point, (2) the normal orientation to make the normal directions to be globally consistent, e.g., facing outward of the surface. While unoriented normals can be estimated by plane or surface fitting of the local neighbor-hood, determining whether the normals are facing outward
In recent years, many excellent or inward is ambiguous. algorithms [5, 29, 31, 32, 59] have been proposed for unori-ented normal estimation, while there are few methods that
have reliable performance for normal orientation or directly estimating oriented normals. Estimating oriented normals from point clouds with noise, density variations, and com-plex geometries in an end-to-end manner is still a challenge.
The classic normal orientation methods rely on simple greedy propagation, which selects a seed point as the start and diffuses its normal orientation to the adjacent points via a minimum spanning tree (MST) [19, 27]. These methods are limited by error accumulation, where an incorrect ori-entation may degenerate all subsequent steps during the it-erative propagation. Furthermore, they heavily rely on a smooth and clean assumption, which makes them easily fail in the presence of sharp edges or corners, density variations and noise. Meanwhile, their accuracy is sensitive to the neighborhood size of propagation. For example, a large size is usually used to smooth out outliers and noise, but can also erroneously include nearby surfaces. Considering that local information is usually not sufficient to guarantee robust ori-entation, some improved methods [22, 38, 45, 46, 49, 53] try to formulate the propagation process as a global energy op-timization by introducing various constraints. Since their constraints are mainly derived from local consistency, the defects are inevitably inherited, and they also suffer from cumulative errors. Moreover, their data-specific parameters are difficult to generalize to new input types and topologies.
Different from the propagation-based methods, which only consider the adjacent orientation, the volume-based approaches exploit volumetric representation, such as signed distance functions [35, 40] and variational formula-tions [2, 21, 48]. They aim to divide the space into inte-rior/exterior and determine whether point normals are fac-ing inward or outward. Despite improvements in accu-racy and robustness, these methods cannot scale to large point clouds due to their computational complexity. In gen-eral, propagation-based methods have difficulty with sharp features, while volume-based methods have difficulty with open surfaces. Furthermore, the above-mentioned meth-ods are usually complex and require a two-stage operation, their performance heavily depends on the parameter tuning in each separated stage. Recently, several learning-based methods [17, 18, 50] have been proposed to deliver oriented normals from point clouds and have exhibited promising performance. Since they focus on learning an accurate local feature descriptor and do not fully explore the relationship between the surface normal orientation and the underlying surface, their performance cannot be guaranteed across dif-ferent noise levels and geometric structures.
In this work, we propose to estimate oriented normals from point clouds by implicitly learning signed hyper sur-faces, which are represented by MLP layers to interpret the geometric property in a high-dimensional feature space. We learn this new geometry representation from both local and global shape properties to directly estimate normals with consistent orientation in an end-to-end manner. The insight of our method is that determining a globally consistent nor-mal orientation should require global context to eliminate the ambiguity from local since orientation is not a local property. We evaluate our method by conducting a series of qualitative and quantitative experiments on a range of point clouds with different sampling densities, noise levels, thin and sharp structures.
Our main contributions can be summarized as follows.
• We introduce a new technique to represent point cloud geometric properties as signed hyper surfaces in a high-dimensional feature space.
• We show that the signed hyper surfaces can be used to es-timate normals with consistent orientations directly from point clouds, rather than through a two-stage paradigm.
• We experimentally demonstrate that our method is able to estimate normals with high accuracy and achieves the state-of-the-art results in both unoriented and oriented normal estimation. 2.