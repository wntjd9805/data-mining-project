Abstract
Towards stable human pose estimation from monocular images, there remain two main dilemmas. On the one hand, the different perspectives, i.e., front view, side view, and top view, appear the inconsistent performances due to the depth ambiguity. On the other hand, foot posture plays a significant role in complicated human pose estimation, i.e., dance and sports, and foot-ground interaction, but un-fortunately, it is omitted in most general approaches and datasets. In this paper, we first propose the Cross-View Fu-sion (CVF) module to catch up with better 3D intermediate representation and alleviate the view inconsistency based on the vision transformer encoder. Then the optimization-based method is introduced to reconstruct the foot pose and foot-ground contact for the general multi-view datasets in-cluding AIST++ and Human3.6M. Besides, the reversible kinematic topology strategy is innovated to utilize the con-tact information into the full-body with foot pose regressor.
Extensive experiments on the popular benchmarks demon-strate that our method outperforms the state-of-the-art ap-proaches by achieving 40.1mm PA-MPJPE on the 3DPW test set and 43.8mm on the AIST++ test set. 1.

Introduction
Estimating 3D poses from a monocular RGB camera is significant in computer vision and artificial intelligence, as it is fundamental in many applications, e.g. robotics, action recognition, animation, human-object interaction, etc. Ben-efiting from the dense representation of SMPL models [18],
SMPL-based methods [9–12] have recently dominated the 3D pose estimation and achieved state-of-the-art results.
Although these methods have considerably decreased the reconstruction error, they still suffer from two main chal-lenges in pose stability. Thus, in this paper, we focus on
SMPL-based 3D pose estimation and present a method for reducing the instability in estimation.
* indicates the equal contributions.
Inconsistent (a) from different perspectives. performance (b) Inaccurate foot posture and foot-ground interaction.
Figure 1. Two main challenges towards stable human pose estima-tion.
The first challenge is the inconsistency performance of poses from different perspectives. An example is shown in Figure 1a that the front view projection of the 3D poses predicted by the model can be well aligned with the picture, but from its side view, the human poses are oblique. The difficulty mainly stems from the fact that estimating 3D hu-man poses requires a model to extract good 3D intermedi-ate representation from monocular images, which is diffi-cult due to the lack of depth input. The second challenge is the stability of the foot posture. As shown in Figure 1b, the estimated foot posture is inaccurate and does not match the foot-ground contact. The main reason is that the con-tact between the foot and the ground and the posture of foot joints i.e. heels, foot toes, ankles, etc. are omitted in most work.
In the literature, most SMPL-based methods directly ex-tract the holistic features from the image and then feed them to the subsequent regression networks to calculate the
SMPL parameters [9–12]. These holistic methods do not explicitly model the pose-related 3D features. In addition, it is also challenging to directly predict the SMPL param-Figure 2. The top-down framework for 3D human pose and shape estimation, which consists of three parts, including the vision transformer encoder, the cross-view attention representation, and the reversible kinematic topology decoder. eters from the holistic features due to the highly nonlinear mapping [22]. Our first contribution is that we propose an intermediate representation architecture called the Cross-View Fusion module (CVF). It learns a fused 3D interme-diate representation by supervision over three views: the front, the side, and the top. Specifically, our method con-sists of three branches. Each branch learns 2D poses and features in its corresponding view. Predicting the 2D poses in side-view and top-view from input images is challenging, so we design an attention-based architecture that leverages prior information from the front-view branch to facilitate the training of side-view and bird-view branches. Thanks to the better 3D intermediate representation, our method alle-viates the view inconsistency and outperforms other SMPL-based methods on 3D pose estimation.
Understanding the foot-ground contact and learning the inherent dynamic dependencies among joints is the key to solving the challenge of foot stability. However, most datasets lack the annotation information of foot-ground
For this reason, we propose a method based contact. on multi-view optimization to add foot-ground annota-tions to some public datasets, i.e., Human3.6M [7] and
AIST++ [16]. Different from the previous optimization-based methods ( e.g., SMPLify [1]), our method utilizes multi-view images, which can deal with the severe joints occlusion, and thus obtain better foot joint annotations and foot-ground contact annotations. To the best of our knowl-edge, our work is the first to perform unified foot-ground contact annotations on multiple existing large-scale 3D pose datasets. We believe these additional annotations will fur-ther improve the human pose estimation task in the future.
Inspired by [32], we further propose a Reversible Kinematic
Topology Decoder (RKTD) that can dynamically adjust the predicted order of individual lower limb joints according to the state of foot-ground contact.
Our method achieves state-of-the-art performance on multiple 3D human pose estimation benchmarks. On the 3DPW [31] dataset, it achieves 2.7mm improvement com-pared to the best art D&D [14]. Although our method is trained on single-frame images, it does achieve bet-ter results than existing video-based methods, such as
MAED [33] and D&D [14]. We annotated foot joint and foot-ground contact on Human3.6M and AIST++ and then trained our method on them. Our method reduced MPJPE by 2mm and 3mm on Human3.6m and AIST++, respec-tively.
In summary, we make the following four contributions:
• We design a 3D intermediate feature representation module called Cross-View Fusion to extract the fea-tures of the key points in the front, side, and bird’s eye views. By doing this, our method achieves more consistent performances in different perspectives than other state-of-the-art methods.
• We design an optimization-based scheme to recon-struct the foot poses and annotate foot-ground con-tacts for the commonly-used multi-view datasets, in-cluding AIST++ and Human3.6M. These new annota-tions can be used to improve pose stability during the foot-ground interaction in future work.
• We propose a Reversible Kinematic Topology De-coder(RKTD) that utilizes the foot-ground contact in-formation to dynamically adapt the prediction order of the joints on the leg limb chain. This strategy improves the accuracy of pose estimation when there is a foot touchdown.
• We conduct extensive experiments on the commonly-used benchmarks, including 3DPW, Human3.6M, and
AIST++. Compared to other existing methods, our method achieves state-of-the-art performance quanti-tatively. The qualitative comparison shows that our method estimates more stable poses, i.e., the perfor-mances are more consistent under different views with more accurate foot-ground contacts. 2.