Abstract
With the rapid development of virtual reality, 360◦ im-ages have gained increasing popularity. Their wide field of view necessitates high resolution to ensure image qual-ity. This, however, makes it harder to acquire, store and even process such 360◦ images. To alleviate this issue, we propose the first attempt at 360◦ image rescaling, which refers to downscaling a 360◦ image to a visually valid low-resolution (LR) counterpart and then upscaling to a high-resolution (HR) 360◦ image given the LR variant. Specifi-cally, we first analyze two 360◦ image datasets and observe several findings that characterize how 360◦ images typi-cally change along their latitudes. Inspired by these find-ings, we propose a novel deformable invertible neural net-work (INN), named DINN360, for latitude-aware 360◦ im-age rescaling. In DINN360, a deformable INN is designed to downscale the LR image, and project the high-frequency (HF) component to the latent space by adaptively handling various deformations occurring at different latitude regions.
Given the downscaled LR image, the high-quality HR image is then reconstructed in a conditional latitude-aware man-ner by recovering the structure-related HF component from the latent space. Extensive experiments over four public datasets show that our DINN360 method performs consid-erably better than other state-of-the-art methods for 2×, 4× and 8× 360◦ image rescaling. 1.

Introduction
With the rapid development of virtual reality, 360◦ im-ages have gained increasing popularity. Different from 2D images, 360◦ images cover a scene with a wide range of 360◦ × 180◦ views, requiring high resolution for ensuring the image quality. However, this also makes it considerably more costly to acquire, store and even process such high-resolution (HR) 360◦ images. To address these issues, it is necessary to conduct 360◦ image rescaling, which consists of image downscaling for generating low-resolution (LR)
*Corresponding authors: Mai Xu (MaiXu@buaa.edu.cn), Lai Jiang (jianglai.china@buaa.edu.cn)
Figure 1. Motivation and pipeline of our DINN360 method. The non-uniform sampling density causes various deformations at dif-ferent latitude regions, and this guides the design of our DINN360 model. Finally, the HR 360◦ image can be rescaled from the cor-responding LR image and latent space. images with visually valid information and image upscaling for reconstructing HR 360◦ images. Different from image super-resolution (SR) that only upscales from LR images, image rescaling can directly utilize the texture information from the input HR 360◦ images, and therefore achieves bet-ter reconstruction results.
Recently, 2-dimensional (2D) image rescaling has re-ceived increasing research interests [17, 21, 23, 36, 43, 44], due to its promising application potential. Specifically, Kim et al. [17] proposed a task-aware auto-encoder-based frame-work including a task-aware downscaling (TAD) model and a task-aware upscaling (TAU) model. In this work, the pro-cedures of downscaling and upscaling are implemented by two individual deep neural networks (DNNs), and then they are jointly optimized. Xiao et al. [44] proposed an im-age rescaling framework based on invertible neural network (INN), in which downscaling and upscaling are regarded as invertible procedures. Different from 2D images, as shown in Fig. 1, 360◦ images contain various types of deformation at different latitude regions, due to the non-uniform sam-pling density of the sphere-to-plain projection. Therefore, it is inappropriate to directly apply the existing 2D rescal-ing methods on 360◦ images (see analysis in Section 3).
Hence, it is necessary to develop a specialized framework
for rescaling of the 360◦ image, by fully considering its spherical characteristics.
This paper is the first attempt at 360◦ image rescaling.
First, we conduct data analysis to find how the spherical characteristics of 360◦ images, such as texture complexity and high-frequency (HF) components, change along with the latitude.
Inspired by our findings, we propose a de-formable invertible neural network (DINN360) for latitude-aware 360◦ image rescaling. Specifically, as shown in
Fig. 1, deformable downscaling with a set of invertible deformable blocks is developed in DINN360 to learn the adaptive receptive fields. As such, the 360◦ image can be downscaled in a deformation-adaptive manner. Subse-quently, the bijective projection is conducted with the devel-oped INN structure for the HF component extracted from the downscaling procedure, such that the texture details can be better recovered for the following upscaling. More importantly, a novel latitude-aware conditional mechanism is developed for the projection, in order to preserve the
HF component of 360◦ images in a latitude-aware manner.
Given the invertible structures of downscaling and HF pro-jection, the 360◦ image can be reversely upscaled. More-over, a new backflow training protocol is developed to re-duce the information gap between the forward and reverse flows of the INN structure. The extensive experimental re-sults show that our DINN360 outperforms state-of-the-art image rescaling and 360◦ SR methods for 2×, 4× and 8× rescaling over 4 public datasets. The codes are available at https://github.com/gyc9709/DINN360. The main contributions of this paper are three-fold.
• We find how the low-level characteristics of 360◦ im-ages change along with its latitude, benefiting the de-signs of our DINN360 method.
• We propose a novel INN framework for 360◦ image rescaling, with the developed invertible deformable blocks to handle various 360◦ deformations.
• We develop a latitude-aware conditional mechanism in our framework, to better preserve the HF component of 360◦ images in a latitude-aware manner. 2.