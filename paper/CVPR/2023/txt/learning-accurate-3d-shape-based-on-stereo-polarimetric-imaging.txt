Abstract
Shape from Polarization (SfP) aims to recover surface normal using the polarization cues of light. The accuracy of existing SfP methods is affected by two main problems.
First, the ambiguity of polarization cues partially results in false normal estimation. Second, the widely-used assump-tion about orthographic projection is too ideal. To solve these problems, we propose the first approach that com-bines deep learning and stereo polarization information to recover not only normal but also disparity. Specifically, for the ambiguity problem, we design a Shape Consistency-based Mask Prediction (SCMP) module. It exploits the in-herent consistency between normal and disparity to iden-tify the areas with false normal estimation. We replace the unreliable features enclosed by these areas with new fea-tures extracted by global attention mechanism. As to the orthographic projection problem, we propose a novel View-ing Direction-aided Positional Encoding (VDPE) strategy.
This strategy is based on the unique pixel-viewing direction encoding, and thus enables our neural network to handle the non-orthographic projection. In addition, we establish a real-world stereo SfP dataset that contains various ob-ject categories and illumination conditions. Experiments showed that compared with existing SfP methods, our ap-proach is more accurate. Moreover, our approach shows higher robustness to light variation. 1.

Introduction 3D shape recovery is a fundamental problem in com-puter vision and has been extensively studied [15, 26, 31].
However, existing shape recovery methods have some lim-itations. For example, the geometry-based methods, e.g., structure from motion [33, 37] have difficulty in dealing with texture-less regions and can only recover sparse point cloud. While the photometric stereo methods [15, 18] can recover dense surface, they need cumbersome photo-metric calibration. By contrast, shape from polarization
*Tianyu Huang and Haoang Li contributed equally to this work.
†Yun-Hui Liu is the corresponding author. (SfP) [11, 20, 40] can avoid the above problems by using the polarization cues of light. Specifically, polarization cues can detect rich geometric details even for white wall [11].
Moreover, such cues can be easily obtained in a single shot with the quad-Bayer polarization camera [46].
Despite the above advantages of SfP, there remain two main problems that affect the recovery accuracy. First, the ambiguous polarization cues are inevitable due to unidirec-tional measurement [10]. These cues partially result in false normal estimation. To solve this problem, early SfP meth-ods rely on specific assumptions about shape prior [2, 40] and lead to unsatisfactory recovery accuracy. Recently, some approaches use stereo [16] or multi-view [49] polar-ization information for disambiguation. However, the ac-curacy of these methods is limited by the low quality of stereo matching for polarization cues. Second, most ex-isting SfP approaches assume orthographic projection for modelling simplification [35, 40]. Such assumption ignores the influence of viewing directions, which affects the accu-racy of polarimetric measurements. A representative work for this problem is based on a perspective phase angle con-straint [8], but this constraint is still insufficient.
In addition to the above attempts to solve the ambigu-ity and orthographic projection problems, some methods are proposed based on deep learning [3, 12, 23, 25]. They improve the shape recovery accuracy to some extent. How-ever, they still partly suffer from the ambiguity problem due to monocular imaging. By contrast, our method is based on stereo polarimetric imaging. To the best of our knowledge, our approach is the first one that combines stereo polariza-tion information and deep learning to estimate both normal and disparity.
As shown in Fig. 1, we integrate convolutional neural network (CNN) with Vision Transformer [13, 14] to design the feature extraction module. This module considers both local and global contexts [34] to extract stereo feature maps.
For one thing, we use the feature map of the left view to es-timate the normal map. For another thing, we exploit the stereo feature maps to generate a polarimetric cost volume.
This cost volume aligns stereo features to estimate the dis-parity map. Our joint estimation of normal and disparity
Figure 1. Overview of the proposed approach. Given a pair of stereo polarization images, our method can simultaneously recover normal map and disparity map with high quality. contributes to solving the above-mentioned problems in SfP, which is introduced in the following.
For the ambiguity problem, we design a Shape
Consistency-based Mask Prediction (SCMP) module. This module predicts a mask to identify the areas with inac-curate normal estimation caused by unreliable features in the feature map. We use these areas to achieve a coarse-to-fine refinement for the feature map. At each step, we replace the features enclosed by such areas with new fea-tures extracted by the global attention mechanism in Trans-former. As to the orthographic projection problem, we in-troduce a novel Viewing Direction-aided Positional Encod-ing (VDPE) strategy to Transformer. Based on the pixel-viewing direction encoding, this strategy enables our neural network to handle non-orthographic projection. Moreover, we establish a large real-world stereo SfP dataset.
To summarize, we propose the first approach 1 that com-bines stereo polarimetric imaging and deep learning to re-cover accurate normal and disparity maps simultaneously.
Our main contributions are as follows:
• We design a mask prediction module to reduce the ef-fect of ambiguous polarization cues based on the con-sistency between normal and disparity.
• We propose a novel positional encoding design that en-ables our network to handle the non-orthographic pro-jection in polarimetric measurement.
• We establish a large real-world dataset for stereo SfP problem. Our dataset contains various object cate-gories and illumination conditions.
Extensive experiments showed that compared with existing methods, our approach is more accurate. Moreover, our ap-proach shows higher robustness to light variation. 2.