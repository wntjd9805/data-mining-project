Abstract
High-fidelity kinship face synthesis has many potential applications, such as kinship verification, missing child identification, and social media analysis. However, it is challenging to synthesize high-quality descendant faces with genetic relations due to the lack of large-scale, high-quality annotated kinship data. This paper proposes RFG (Region-level Facial Gene) extraction framework to address this issue. We propose to use IGE (Image-based Gene En-coder), LGE (Latent-based Gene Encoder) and Gene De-coder to learn the RFGs of a given face image, and the relationships between RFGs and the latent space of Style-GAN2. As cycle-like losses are designed to measure the L2 distances between the output of Gene Decoder and image encoder, and that between the output of LGE and IGE, only
*Corresponding Author face images are required to train our framework, i.e. no paired kinship face data is required. Based upon the pro-posed RFGs, a crossover and mutation module is further designed to inherit the facial parts of parents. A Gene Pool has also been used to introduce the variations into the mu-tation of RFGs. The diversity of the faces of descendants can thus be significantly increased. Qualitative, quantita-tive, and subjective experiments on FIW, TSKinFace, and
FF-Databases clearly show that the quality and diversity of kinship faces generated by our approach are much better than the existing state-of-the-art methods. 1.

Introduction
Humans can identify kinship through photographs based on the resemblance between parents and children. Many works have investigated this intrinsic relation in the fields
of kinship verification [9, 32, 42] and genetics [4, 5, 8, 19].
With the popularity of face synthesis and editing technol-ogy in recent years, high-fidelity kinship face synthesis has also attracted much attention. This task, aiming to synthe-size the faces of descendants based on the appearance of the parents, has many potential applications, such as find-ing long-lost children, crime investigations, kinship verifi-cation, and multimedia social applications.
In recent years, many efforts have been made to make use of generative models [7, 12, 15, 16, 27, 29, 38, 43, 45, 48] for kinship face synthesis. These works can be catego-rized into two paradigms: one-stage and two-stage. The one-stage paradigm [12, 29, 38, 45] treats this problem as an image-to-image translation task and trains a one-to-one kinship face generator with paired data. However, these ap-proaches can only produce low-resolution images and the resultant images can be blurry and lack diversity. Further, it would be quite difficult to obtain annotated kinship data.
By contrast, the two-stage paradigm [7, 15, 16, 27, 43, 48] first extracts the genetic representation and assembles them into children’s representation based on the parents’ faces.
To obtain genetic representation, existing methods try to learn the inheritance and variation of facial appearances by training deep neural networks [14, 27, 48] or via a knowl-edge rule [7]. However, the learned genetic representation is prone to overfitting due to the lack of high-quality kin-ship annotated training data, resulting in a lack of diversity in the generated children. In addition, these methods cannot provide fine-grained attributes representation, and thus the generated facial attributes lack interpretability.
In this paper, the facial genetic process is abstracted as the exchange and mutation of the parents’ facial parts. We propose an Image-based Gene Encoder (IGE) to construct an independent representation for each facial part, called a Region-level Facial Gene (RFG), which is used to con-trol the synthesis of facial regions. We further simulate the crossover and mutation process to assemble the RFGs of de-scendants by using those of the parents, and our proposed
Gene Pool used in the mutation process can significantly increase the diversity of the generated descendants. We use the pre-trained StyleGAN2 [24] as the generator to synthe-size high-fidelity faces. To achieve this, we use a Gene De-coder to map RFGs to the W + space of StyleGAN2. Since
IGE requires a facial parsing mask to generate the RFG, we additionally train a Latent-based Gene Encoder (LGE) to directly map the latent code of StyleGAN2 to RFGs. Thus, facial parsing mask is not required for the RFG extraction in the inference stage. The main contributions of this paper are summarized as follows:
• We propose StyleGene to synthesize high-fidelity kin-ship faces with controllable facial genetic regions, via modeling the facial genetic relations based on the pro-posed region-level facial genes.
• A novel genetic strategy is further introduced by sim-ulating the crossover and mutation process to generate the RFGs of descendants. We introduce a Gene Pool into the mutation process to significantly increase the diversity of the kinship face.
• We validate the effectiveness of our approach on sev-eral benchmarks, demonstrating the superiority of our
StyleGene framework over other state-of-the-art meth-ods, in terms of the quality and diversity of the gener-ated kinship faces. 2.