Abstract
Sensitivity to severe occlusion and large view angles lim-its the usage scenarios of the existing monocular 3D dense face alignment methods. The state-of-the-art 3DMM-based method, directly regresses the model’s coefficients, under-utilizing the low-level 2D spatial and semantic information, which can actually offer cues for face shape and orienta-tion. In this work, we demonstrate how modeling 3D facial geometry in image and model space jointly can solve the oc-clusion and view angle problems. Instead of predicting the whole face directly, we regress image space features in the visible facial region by dense prediction first. Subsequently, we predict our model’s coefficients based on the regressed feature of the visible regions, leveraging the prior knowl-edge of whole face geometry from the morphable models to complete the invisible regions. We further propose a fusion network that combines the advantages of both the image and model space predictions to achieve high robustness and accuracy in unconstrained scenarios. Thanks to the pro-posed fusion module, our method is robust not only to occlu-sion and large pitch and roll view angles, which is the bene-fit of our image space approach, but also to noise and large yaw angles, which is the benefit of our model space method.
Comprehensive evaluations demonstrate the superior per-formance of our method compared with the state-of-the-art methods. On the 3D dense face alignment task, we achieve 3.80% NME on the AFLW2000-3D dataset, which outper-forms the state-of-the-art method by 5.5%. Code is avail-able at https://github.com/lhyfst/DSFNet. 1.

Introduction is an important prob-3D dense face alignment lem with many applications, e.g. video conferencing,
AR/VR/metaverse, games, facial analysis, etc. Many meth-ods have been proposed [8–12, 16, 21, 26, 27, 29, 33, 39, 41, 47, 49]. However, these methods are sensitive to severe oc-clusion and large view angles [19, 26, 31, 32], limiting their applicability of 3D dense face alignment on wild images where occlusion and view angles often occur. 3D dense face alignment from a single image is an ill-posed problem, mainly because of the depth ambiguity. The
module, our DSFNet effectively combines the advantages of both spaces. In summary, the main contributions of this paper are:
• We propose a novel 3D facial geometry’s 2D im-age space representation, followed by a novel post-processing algorithm. It achieves robust 3D dense face alignment to occlusion and large view angles.
• We introduce a fusion network, which combines the advantages of both the image and model space predic-tions to achieve high robustness and accuracy in un-constrained scenarios.
• On the 3D dense face alignment task, we achieve 3.80% NME on AFLW2000-3D dataset, which out-performs the state-of-the-art method by 5.5%. 2.