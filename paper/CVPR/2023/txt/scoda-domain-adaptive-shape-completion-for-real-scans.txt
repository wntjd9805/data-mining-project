Abstract 3D shape completion from point clouds is a challeng-ing task, especially from scans of real-world objects. Con-sidering the paucity of 3D shape ground truths for real scans, existing works mainly focus on benchmarking this task on synthetic data, e.g. 3D computer-aided design mod-els. However, the domain gap between synthetic and real data limits the generalizability of these methods. Thus, we propose a new task, SCoDA, for the domain adaptation of real scan shape completion from synthetic data. A new dataset, ScanSalon, is contributed with a bunch of elaborate 3D models created by skillful artists according to scans. To address this new task, we propose a novel cross-domain feature fusion method for knowledge transfer and a novel volume-consistent self-training framework for robust learn-ing from real data. Extensive experiments prove our method is effective to bring an improvement of 6%∼7% mIoU. 1.

Introduction
Shape completion and reconstruction from scans is a practical 3D digitization task that is of great significance in applications of virtual and augmented reality. It takes a scanned point cloud as input and aims to recover the 3D shape of the target object. The completion of real scans is challenging for the poor quality of point clouds and the deficiency of 3D shape ground truths. Existing methods ex-ploit synthetic data, e.g. 3D computer-aided design (CAD) models to alleviate the demand for real object shapes. For example, authors of [18, 26, 35] simulate the scanning pro-cess to obtain point clouds from CAD models with paired ground truth shapes to train learning-based reconstruction models. However, there still exist distinctions between the simulated and real scan because the latter is scanned from a real object with complex scanning noise and occlusion, which limits the generalization quality.
Considering the underexploration in this field, we propose a new task, SCoDA, Domain Adaptive Shape
Completion, that aims to transfer the knowledge from the synthetic domain with rich clean shapes (source domain) into the shape completion of real scans (target domain), as illustrated in Fig. 1. To this end, we, for the first time, build an object-centric dataset, ScanSalon, which consists of real
Scans with Shape manual annotations. Our ScanSalon con-tains a bunch of 3D models that are paired with real scans of objects in six categories: chair, desk/table, sofa, bed, lamp,
and car. The 3D models are manually created of high qual-ity by skillful artists for around 10% of real scans, which can serve as the evaluation ground truths of shape comple-tion or as the few labels for semi-supervised domain adapta-tion. See Fig. 1 for some examples, and details of ScanSa-lon are exposed in Sec. 4.
The main challenge of the proposed SCoDA task lies in the domain gap between synthetic and real point clouds.
Due to the intrinsic complexity of the scanning process, e.g., the scanner parameters and object materials, it is difficult to simulate the scans in terms of sparsity, noisy extent, etc.
More importantly, real scans are usually incomplete result-ing from the scene layout and object occlusion during scan-ning, which can hardly be simulated. Thus, we propose a novel domain adaptive shape completion approach to trans-fer the rich knowledge from the synthetic domain to the real one. At first, the reconstruction module in our approach is based on an implicit function for continuous shape com-pletion [18, 54, 58]. For an effective transfer, we observe that although the local patterns of real scans (e.g., noise, sparsity, and incompleteness) are distinct from the simu-lated synthetic ones, the global topology or structure in a same category is usually similar between the synthetic and real data, for example, a chair from either the synthetic or real domain usually consists of a seat, a backrest, legs, etc. (see Fig. 1). In other words, the global topology is more likely to be domain invariant, while the local patterns are more likely to be domain specific. Accordingly, we propose a cross-domain feature fusion (CDFF) module to combine the global features and local features learned in the syn-thetic and real domain, respectively, which helps recover both fine details and global structures in the implicit recon-struction stage. Moreover, a novel volume-consistent self-training (VCST) framework is developed to encourage self-supervised learning from the target data. Specifically, we create two views of real scans by dropping different clus-ters of points to produce incompleteness of different extent, and the model is forced to make consistent implicit predic-tions at each spatial volume, which encourages the model’s robustness to the incompleteness of real scans.
To construct a benchmark on the proposed new task, we implement some existing solutions to related tasks as base-lines, and develop extensive experiments for the baselines and our method on ScanSalon. These experiments also demonstrate the effectiveness of the proposed method.
In summary, our key contributions are four-fold:
• We propose a new task, SCoDA, namely domain adaptive shape completion for real scans; A dataset
ScanSalon that contains 800 elaborate 3D models paired with real scans in 6 categories is contributed.
• A novel cross-domain feature fusion module is de-signed to combine the knowledge of global shapes and local patterns learned in the synthetic and real domain, respectively. Such a feature fusion manner may also inspire the works in the 2D domain adaption field.
• A volume-consistent self-training framework is pro-posed to improve the robustness of shape completion to the complex incompleteness of real scans.
• A benchmark with multiple methods evaluated is con-structed for the task of SCoDA based on ScanSalon;
Extensive experiments also demonstrate the superior-ity of the proposed method. 2.