Abstract
Timestamp supervised temporal action segmentation (TSTAS) is more cost-effective than fully supervised coun-terparts. However, previous approaches suffer from severe label bias due to over-reliance on sparse timestamp an-notations, resulting in unsatisfactory performance. In this paper, we propose the Debiasing-TSTAS (D-TSTAS) frame-work by exploiting unannotated frames to alleviate this bias from two phases: 1) Initialization. To reduce the depen-dencies on annotated frames, we propose masked times-tamp predictions (MTP) to ensure that initialized model captures more contextual information. 2) Refinement. To overcome the limitation of the expressiveness from sparsely annotated timestamps, we propose a center-oriented times-tamp expansion (CTE) approach to progressively expand pseudo-timestamp groups which contain semantic-rich mo-tion representation of action segments. Then, these pseudo-timestamp groups and the model output are used to iter-atively generate pseudo-labels for refining the model in a fully supervised setup. We further introduce segmental con-fidence loss to enable the model to have high confidence predictions within the pseudo-timestamp groups and more accurate action boundaries. Our D-TSTAS outperforms the state-of-the-art TSTAS method as well as achieves compet-itive results compared with fully supervised approaches on three benchmark datasets. 1.

Introduction
Analyzing and understanding human actions in videos is very important for many applications, such as human-robot interaction [14] and healthcare [33]. Recently, sev-eral approaches have been very successful in locating and analyzing activities in videos, including action localization
[12,29,37,50], action segmentation [7,11,20,23], and action recognition [9, 27, 39, 41, 47].
*These authors contributed equally to this work.
†Corresponding author.
Figure 1. (a) The TSTAS task aims to segment actions in videos by timestamp annotations. (b) An example of focus bias: exist-ing initialization methods prefer to predict frames similar to the annotated timestamp, leading to incorrectly identifying dissimilar frames within the segment and similar frames outside the segment. the frames of complex (c) An example of representation bias: action share large semantic variance, e.g. the process of cutting cheese includes both taking out and cutting, resulting in the mod-els that rely on sparse timestamps to produce biased pseudo-labels.
Despite the success of previous approaches, they rely on fully temporal supervision, where the start and end frames of each action are annotated. As a lightweight alternative, many researchers have started exploring timestamp super-vised temporal action segmentation (TSTAS), where each action segment is annotated with only one frame in the untrimmed video, as shown in Fig. 1 (a).
Most previous approaches follow a two-step pipeline by initializing and then iteratively refining the model with gen-erated pseudo-labels. However, relying only on supervised signals of sparse single-timestamp annotations, these meth-ods fail to learn the semantics of entire action segments, which is referred to as label bias in this paper, including fo-cus bias and representation bias. Specifically, to initialize the segmentation model, the previous methods [17, 28, 32] adopt the Naive approach proposed in [28] (referred to as
Naive), which computes the loss at the annotated frames for training. However, utilizing only the annotated frames leads to focus bias, where the initialized model tends to fo-cus on frames distributed over segments of various action categories similar to the annotated frames [51] (shown in
Fig. 1 (b)). ecuted several times alternately to improve the model pre-diction in a lazy manner instead of generating pseudo-labels per epoch in previous methods [28, 51].
During refining the segmentation model, to utilize the unlabeled frames, typical methods generate hard [17,28,51] or soft weighted [32] pseudo-labels that are used to re-fine the model like fully supervised methods. To gener-ate pseudo-labels, the above methods depend on the times-tamps that contain semantic or relative position informa-tion. Despite the success of such refined models, these ap-proaches suffer from representation bias that single-frame fails to represent the entire action segment for complex ac-tions with the large semantic variance of various frames (il-lustrated in Fig. 1 (c)). Moreover, when refining the seg-mentation model by these biased pseudo-labels, represen-tation bias can be accumulated and expanded, resulting in unsatisfactory performance that is still a gap compared to fully supervised approaches.
In this paper, we propose a novel framework called
Debiasing-TSTAS (D-TSTAS) to reduce label bias, con-taining masked timestamp predictions and center-oriented timestamp expansion approaches. During the initialization phase, we aim to alleviate the focus bias problem by prop-agating timestamp supervision information to the contex-tual frames of the timestamps. In contrast to previous ap-proaches, we propose the Masked Timestamp Predictions (MTP) approach that masks the input features of times-tamps to remove the dependencies of the model on anno-tated frames.
In this way, the initialized model is forced to reconstruct the annotated frames in corresponding out-put features and then predict their action categories by con-textual information of timestamps. Furthermore, to capture the semantics of both timestamps and contextual frames, we adopt the Naive after our MTP.
While our initialized model can reduce focus bias by capturing more contextual information, it does not guar-the generated pseudo-labels avoid represen-antee that
Inspired by query expan-tation bias during refining. sion, we propose a Center-oriented Timestamp Expansion (CTE) approach for obtaining potential trustworthy unla-beled frames, which we refer to as pseudo-timestamps, to progressively expand the pseudo-timestamp groups that contain more semantics than single annotated timestamps.
More specifically, it consists of three steps: 1) In the gen-erating step, we generate pseudo-labels by current pseudo-timestamp groups and the model output. 2) In the updating step, we choose the semantically dissimilar center frames of each segment in the pseudo-labels as pseudo-timestamps to expand the pseudo-timestamp groups. 3) In the segmenting step, the model is refined by pseudo-labels and our segmen-tal confidence loss, which smooths the predicted probabil-ities in each action segment and maintains high confidence within pseudo-timestamp groups. The above steps are ex-Our contributions can be summarised as follows:
• We study the label bias in the TSTAS task and propose a novel D-TSTAS framework to reduce both focus and representation bias.
• Our masked timestamp predictions approach is the first attempt to alleviate the dependencies on timestamps, promoting the model to capture contextual informa-tion. Coupling MTP and Naive as a general solution is used to initialize the model in the TSTAS.
• Compared to sparsely annotated timestamps, our center-oriented timestamp expansion approach pro-gressively expands pseudo-timestamp groups to con-tain semantic-rich motion representations of action segments.
• The proposed D-TSTAS not only outperforms state-of-the-art TSTAS approaches but also achieves competi-tive results compared with fully supervised approaches on three benchmark datasets. 2.