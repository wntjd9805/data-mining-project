Abstract
In many real-world settings, the critical class is rare and a missed detection carries a disproportionately high cost.
For example, tumors are rare and a false negative diagno-sis could have severe consequences on treatment outcomes; fraudulent banking transactions are rare and an undetected occurrence could result in significant losses or legal penal-ties. In such contexts, systems are often operated at a high true positive rate, which may require tolerating high false positives. In this paper, we present a novel approach to ad-dress the challenge of minimizing false positives for systems that need to operate at a high true positive rate. We propose a ranking-based regularization (RankReg) approach that is easy to implement, and show empirically that it not only ef-fectively reduces false positives, but also complements con-ventional imbalanced learning losses. With this novel tech-nique in hand, we conduct a series of experiments on three broadly explored datasets (CIFAR-10&100 and Melanoma) and show that our approach lifts the previous state-of-the-art performance by notable margins. 1.

Introduction
The cost of error is often asymmetric in real-world sys-tems that involve rare classes or events. For example, in medical imaging, incorrectly diagnosing a tumor as benign (a false negative) could lead to cancer being detected later at a more advanced stage, when survival rates are much worse. This would be a higher cost of error than incor-rectly diagnosing a benign tumour as potentially cancerous (a false positive). In banking, misclassifying a fraudulent transaction as legitimate may be more costly in terms of financial losses or legal penalties than misclassifying a le-gitimate transaction as fraudulent (a false positive). In both of these examples, the critical class is rare, and a missed de-tection carries a disproportionately high cost. In such situa-tions, systems are often operated at high true positive rates,
*Work done during an internship at Borealis AI
Figure 1. Which optimization option is preferred in operational contexts with critical positives? We propose a novel regularizer for systems that need to operate at a high true positive rate (TPR). Our approach prioritizes reducing false positives at a high TPR when presented with different options that equally improve the base ob-jective, e.g. area under the ROC curve (AUC). In this toy example, option 2 is preferred because, with a suitable threshold depicted by the dashed line, all positives can be detected (100% TPR) with only one false positive (i.e., 25% FPR at 100% TPR), better than option 1 where two false positives need be tolerated. Our regular-izer is consistent with this preference: ℓreg is lower for option 2 than option 1 (i.e., 13 vs. 17). even though this may require tolerating high false positive rates. Unfortunately, false positives can undermine user confidence in the system and responding to them could in-cur other costs (e.g. additional medical imaging tests).
In this paper, we present a novel approach to address the challenge of minimizing false positives for systems that need to operate at a high true positive rate. Surprisingly, this
high-stakes operational setting has rarely been studied by the research community. In contrast to conventional imbal-anced classification methods, we propose a general method for inducing a deep neural network to prioritize the reduc-tion of false positives at a high true positive rate. To re-main as broadly applicable as possible, we make minimal assumptions on the architecture and optimization details of the deep neural network. Our key insight is that the false positive rate at a high true positive rate is determined by how the least confident positives are ranked by the network. Our plug-and-play solution adds a simple yet effective ranking-based regularization term to the usual neural network train-ing objective. The regularization term places an increasing penalty on positive samples the lower they are ranked in a sorted list of the network’s classification scores, which works to push up the scores of the hardest positives.
Contributions. The main contributions of this paper are as follows:
• We present a novel plug-and-play regularization term that induces a deep neural network to prioritize the re-duction of false positives in operational contexts where a high true positive rate is required.
• Our regularizer is generic and can be easily combined with other methods for imbalanced learning.
• We conduct extensive experiments on three public benchmarks to show how the proposed regularization term is complementary to conventional imbalanced learning losses, and achieves state-of-the-art perfor-mance in the high true positive rate operational setting. 2.