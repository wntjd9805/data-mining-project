Abstract
We present a novel approach to perform instance seg-mentation and counting for densely packed self-similar trees using a top-view RGB image sequence. We propose a solution that leverages pixel content, shape, and self-occlusion. First, we perform an initial over-segmentation of the image sequence and aggregate structural character-istics into a contour graph with temporal information incor-porated. Second, using a graph convolutional network and its inherent local messaging passing abilities, we merge ad-jacent tree crown patches into a final set of tree crowns. Per various studies and comparisons, our method is superior to all prior methods and results in high-accuracy instance segmentation and counting despite the trees being tightly packed. Finally, we provide various forest image sequence datasets suitable for subsequent benchmarking and evalua-tion captured at different altitudes and leaf conditions. 1.

Introduction
Trees in forests are tightly spaced, partially overlap-ping 3D objects with complex boundaries. Tree instance segmentation is critical in several domains. For exam-ple, ecosystem services and agriculture need to segment and count trees in large areas in order to obtain informa-tion about the ecological balance, environmental health, and timber inventory. Counting trees from the ground per-spective is inefficient, does not scale, and is challenging to automate because of many occlusions with branches and low accesibility.
In this paper, we address tree instance segmentation and counting using overhead RGB image se-quences captured by unmanned aerial vehicles (UAVs), es-pecially during the green-leaf season when trees are most self-similar; see Fig. 1 for an illustration.
There is significant prior work in segmentation and counting, particularly in the field of instance segmentation.
While some approaches make use of LiDAR or RGB-D im-ages (see the survey paper [5]), we focus on using easier-to-obtain uncalibrated RGB image sequences. Prior works based on uncalibrated RGB images can be largely organized into three groups. The first group seeks to count individ-ual objects. These approaches often use density estima-tion and do not focus on segmentation [35, 36]. The sec-ond group of methods relies on convolutional neural net-works (CNNs) applied directly to image pixels, such as
Mask R-CNN [26]. However, in the case of abutting and self-similar objects, e.g., trees, distinguishing individual in-stances is hard. The third group of techniques (e.g., Ke et al. [28], Newell and Deng [43]) model object contour as a graph, where each pixel corresponds to a node, and makes use of graph convolutional networks to complete individual contours; nevertheless, abutting and self-similar instances also hinder these methods. Yet other methods, such as those in digital forestry research, exploit domain-specific features such as assumed differences between tree species or fall leaf coloring (i.e., during one brief time period of the year, the
Figure 2. Pipeline: The input image sequence is analyzed. Initial contours and features are detected and organized into a contour graph that is refined by merging edges and nodes, resulting in the final output mask. leaf color of adjacent crowns is often different).
Our main contributions include:
Our approach is motivated by a key observation that two tree crown leaf patterns tightly packed together are highly similar, and additional features beyond leaf patterns are nec-essary to perform segmentation. Hence, we consider fea-tures based on the tree crown shape because it is unlikely to observe a rectangular tree crown. Beyond shape features, we also use the changing self-occlusion patterns captured in the different frames to aid segmentation.
At a high level, our proposed approach simultaneously exploits pixel content, shape, and self-occlusion, which collectively define a graph-based structure that we call a contour graph. Each node corresponds to an initial over-segmentation of a tree crown fragment; i.e., each node cor-responds to a region enclosed by a closed contour. We then learn features on this contour graph via graph convolu-tional network (GCN) to determine which nodes should be merged. Our method decides whether two nearby regions correspond to the same tree crown. Notably, a tree crown fragment is subject to various simultaneous features that we can exploit to discern one tree crown from another, even if one tree crown is of the same species and has a very similar leaf pattern and color to an adjacent tree crown. Altogether this leads to an instance segmentation method that can pro-cess overhead RGB image sequences of dense forests even when all leaves are mostly similar in color during summer.
See Fig. 2 for an overview of our approach.
When creating and evaluating model performance, we are not aware of suitable databases on dense forests with subsequent frames. To address this: (a) We leveraged devel-opmental tree models [33, 57] to produce a synthetic dataset with annotated tree crowns (5,157 trees in total); (b) We manually labeled real-world image sequences captured by
UAV over three large forests (6,527 trees in total), collec-tively spanning approximately 3,680,000 m2. We will make our self-collected datasets publicly available.
On these datasets, we show that the proposed method achieves a segmentation accuracy of 73.6 and a count accu-racy of 89.8% on average, which is compared to multiple recent instance segmentation approaches.
• an instance segmentation method to robustly process densely packed trees where the instances are abutting, partially overlapping, and self-similar,
• tree crown counting, which is beneficial to ecosystem services and digital forestry, and
• a curated dataset of multiple labeled and unlabeled temporally continuous dense forests suitable for future research. 2.