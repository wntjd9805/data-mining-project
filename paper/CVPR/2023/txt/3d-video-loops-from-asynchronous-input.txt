Abstract 1.

Introduction
Looping videos are short video clips that can be looped endlessly without visible seams or artifacts. They provide a very attractive way to capture the dynamism of natu-ral scenes. Existing methods have been mostly limited to 2D representations. In this paper, we take a step forward and propose a practical solution that enables an immer-sive experience on dynamic 3D looping scenes. The key challenge is to consider the per-view looping conditions from asynchronous input while maintaining view consis-tency for the 3D representation. We propose a novel sparse 3D video representation, namely Multi-Tile Video (MTV), which not only provides a view-consistent prior, but also greatly reduces memory usage, making the optimization of a 4D volume tractable. Then, we introduce a two-stage pipeline to construct the 3D looping MTV from completely asynchronous multi-view videos with no time overlap. A novel looping loss based on video temporal retargeting al-gorithms is adopted during the optimization to loop the 3D scene. Experiments of our framework have shown promise in successfully generating and rendering photorealistic 3D looping videos in real time even on mobile devices. The code, dataset, and live demos are available in https:
//limacv.github.io/VideoLoop3D_web/.
Endless looping videos are fascinating ways to record special moments. These video loops are compact in terms of storage and provide a much richer experience for scenes that exhibit looping behavior. One successful commercial use of this technique is the live photo [19] feature in the
Apple iPhone, which tries to find an optimal looping period and fade in/out short video clips to create looping videos.
There have been several works on automatically construct-ing 2D looping videos from non-looping short video clips.
Liao et al. [24] first propose to create 2D video loops from videos captured with static cameras. They solve for the optimal starting frame and looping period for each pixel in the input video to composite the final video. Later on, several methods are proposed to improve the computation speed [23], or extend to panoramas [1, 36], and gigapixel videos [16]. However, few attempts have been made to ex-tend video loops to a 3D representation. One existing work that shares a similar setting as ours is VBR [46], which generates plausible video loops in novel views. However, it comes with some limitations: It builds on top of ULR
[5], which can produce ghosting artifacts due to inaccurate mesh reconstruction, as shown in [30]. Besides, VBR gen-erates looping videos and reduces the inconsistency from asynchronous input by adaptively blending in different fre-quency domains, which tends to blur away details. 1
To allow free-view observation of the looping videos, a proper 3D representation needs to be employed. Recently, tremendous progress has been made in novel view syn-thesis based on 3D scene representations such as triangle meshes [37, 38, 45], Multi-plane Image (MPI) [9, 56], and
Neural Radiance Field (NeRF) [7, 31, 32], which could be reconstructed given only sparse observations of real scenes and render photo-realistic images in novel views. Much effort has been made to adapt these methods to dynamic scenes, which allows for both viewing space and time con-trols [2,6,27,28,34,35,52,57]. Therefore, a straightforward solution to generate a 3D looping video is to employ the 2D looping algorithms for each view and lift the results to 3D using these methods. However, we find it hard to get satis-factory results since the 2D looping algorithms do not con-sider view consistency, which is even more challenging for the asynchronous multi-view videos that we use as input.
In this work, we develop a practical solution for these problems by using the captured video input of the dynamic 3D scene with only one commodity camera. We automat-ically construct a 3D looping video representation from completely asynchronous multi-view input videos with no time overlap. To get promising 3D video loop results, two main issues need to be addressed. First, we need to solve for a view-consistent looping pattern from inconsis-tent multi-view videos, from which we need to identify spatio-temporal 3D patches that are as consistent as pos-sible. Second, the 3D video potentially requires a memory-intensive 4D volume for storage. Therefore, we need to develop a 3D video representation that is both efficient in rendering and compact in memory usage to make the opti-mization of the 4D volume tractable.
To this end, we develop an analysis-by-synthesis ap-proach that trains for a view-consistent 3D video represen-tation by optimizing multi-view looping targets. We pro-pose an efficient 3D video representation based on Multi-plane Images (MPIs), namely Multi-tile Videos (MTVs), by exploiting the spatial and temporal sparsity of the 3D scene. As shown in Fig. 2, instead of densely storing large planes, MTVs store static or dynamic texture tiles that are sparsely scattered in the view frustum. This greatly reduces the memory requirement for rendering compared with other 3D video representations, making the optimization of the 3D looping video feasible in a single GPU. The sparsity of
MTVs also serves as a view-consistent prior when optimiz-ing the 3D looping video. To optimize the representation for looping, we formulate the looping generation for each view as a temporal video retargeting problem and develop a novel looping loss based on this formulation. We propose a two-stage pipeline to generate a looping MTV, and the ex-periments show that our method can produce photorealistic 3D video loops that maintain similar dynamism from the in-put, and enable real-time rendering even in mobile devices.
Our contributions can be summarized as follows:
• We propose Multi-tile Videos (MTVs), a novel dy-namic 3D scene representation that is efficient in ren-dering and compact in memory usage.
• We propose a novel looping loss by formulating the 3D video looping construction as a temporal retargeting problem.
• We propose a two-stage pipeline that constructs MTVs from completely asynchronous multi-view videos. 2.