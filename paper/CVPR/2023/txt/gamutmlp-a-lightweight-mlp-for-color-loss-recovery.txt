Abstract
Cameras and image-editing software often process im-ages in the wide-gamut ProPhoto color space, encompass-ing 90% of all visible colors. However, when images are encoded for sharing, this color-rich representation is trans-formed and clipped to ﬁt within the small-gamut standard
RGB (sRGB) color space, representing only 30% of visi-ble colors. Recovering the lost color information is chal-Inspired by neu-lenging due to the clipping procedure. ral implicit representations for 2D images, we propose a method that optimizes a lightweight multi-layer-perceptron (MLP) model during the gamut reduction step to predict the clipped values. GamutMLP takes approximately 2 sec-onds to optimize and requires only 23 KB of storage. The small memory footprint allows our GamutMLP model to be saved as metadata in the sRGB image—the model can be extracted when needed to restore wide-gamut color values.
We demonstrate the effectiveness of our approach for color recovery and compare it with alternative strategies, includ-ing pre-trained DNN-based gamut expansion networks and other implicit neural representation methods. As part of this effort, we introduce a new color gamut dataset of 2200 wide-gamut/small-gamut images for training and testing. 1.

Introduction
The RGB values of our color images do not represent the entire range of visible colors. The span of visible colors that can be reproduced by a particular color space’s RGB primaries is called a gamut. Currently, the vast majority of color images are encoded using the standard RGB (sRGB) color space [7]. The sRGB gamut is capable of reproducing approximately 30% of the visible colors and was optimized for the display hardware of the 1990s. Close to 30 years later, this small-gamut color space still dominates how im-ages are saved, even though modern display hardware is ca-pable of much wider gamuts.
Interestingly, most modern DSLR and smartphone cam-eras internally encode images using the ProPhoto color space [12]. ProPhoto RGB primaries deﬁne a wide gamut capable of representing 90% of all visible colors [33].
Figure 1. (A) shows a wide-gamut (ProPhoto) image that has been converted and saved as a small-gamut (sRGB) image; color clipping is required to ﬁt the smaller sRGB gamut (as shown in the chromaticity diagrams). (B) Standard color conversion back to the wide-gamut color space is not able to recover the clipped colors. (C) Conversion back to the wide-gamut RGB using our lightweight GamutMLP (23 KB) can recover the clipped color val-ues back to their original values.
Image-processing software, such as Adobe Photoshop, also uses this color-rich space to manipulate images, especially when processing camera RAW-DNG ﬁles. By process-ing images in the wide-gamut ProPhoto space, cameras and editing software allow users the option to save an image in other color spaces—such as AdobeRGB, UHD, and Display-P3—that have much wider color gamuts than sRGB. However, these color spaces are still rare, and most images are ultimately saved in sRGB. To convert color val-ues between ProPhoto and sRGB, a gamut reduction step is applied that clips the wide-gamut color values to ﬁt the smaller sRGB color gamut. Once gamut reduction is ap-plied, it is challenging to recover the original wide-gamut values. As a result, when images are converted back to a wide-gamut color space for editing or display, much of the color ﬁdelity is lost, as shown in Figure 1.
Figure 2. An overview of the gamut reduction stage in our framework. This phase shows the gamut reduction step, where the wide-gamut
ProPhoto is converted to the small-gamut sRGB. While saving the sRGB image, an MLP is optimized based on the original and clipped
ProPhoto color values. The MLP is embedded in the sRGB image as metadata.
Contribution We address the problem of recovering the
RGB colors in sRGB images back to their original wide-gamut RGB representation. Our work is inspired by coordinate-based implicit neural image representations that use multilayer perceptrons (MLPs) as a differentiable im-age representation. We propose to optimize a lightweight (23 KB) MLP model that takes the gamut-reduced RGB values and their spatial coordinates as input and predicts the original wide-gamut RGB values. The idea is to opti-mize the MLP model when the ProPhoto image is saved to sRGB and embed the MLP model parameters in the sRGB image as a comment ﬁeld. The lightweight MLP model is extracted and used to recover the wide-gamut color values when needed. We describe an optimization process for the
MLP that requires ∼2 seconds per full-sized image. We demonstrate the effectiveness of our method against several different approaches, including other neural image repre-sentations and pre-trained deep-learning-based models. As part of this work, we have created a dataset of 2200 wide-gamut/small-gamut image pairs for training and testing. 2.