Abstract
Domain adaptive semantic segmentation methods com-monly utilize stage-wise training, consisting of a warm-up and a self-training stage. However, this popular approach still faces several challenges in each stage: for warm-up, the widely adopted adversarial training often results in lim-ited performance gain, due to blind feature alignment; for self-training, finding proper categorical thresholds is very tricky. To alleviate these issues, we first propose to re-place the adversarial training in the warm-up stage by a novel symmetric knowledge distillation module that only ac-cesses the source domain data and makes the model do-main generalizable. Surprisingly, this domain generaliz-able warm-up model brings substantial performance im-provement, which can be further amplified via our pro-posed cross-domain mixture data augmentation technique.
Then, for the self-training stage, we propose a threshold-free dynamic pseudo-label selection mechanism to ease the aforementioned threshold problem and make the model bet-ter adapted to the target domain. Extensive experiments demonstrate that our framework achieves remarkable and consistent improvements compared to the prior arts on popular benchmarks. Codes and models are available at https://github.com/fy-vision/DiGA 1.

Introduction
Semantic segmentation [7,42,45,82] is an essential com-ponent in autonomous driving [20], image editing [54, 79], medical imaging [60], etc. However, for images in a spe-cific domain, training deep neural networks [35, 37, 38, 62] for semantic segmentation often requires a vast amount of pixel-wisely annotated data, which is expensive and la-borious. Therefore, domain adaptive semantic segmen-tation, learning semantic segmentation from a la-belled source domain (either virtual data or an existing dataset) and then performing unsupervised domain adapta-i.e.
*corresponding author tion (UDA) [3, 15, 21, 46, 63] to the target domain, becomes an important research topic. Yet the remaining challenge is the severe model performance degradation caused by the vi-sual domain gap between source and target domain data. In this work, we tackle this domain adaptive semantic segmen-tation problem, with the goal of aligning correct categorical information pixel-wisely from the labelled source domain onto the unlabelled target domain.
Currently, stage-wise training, composed of a warm-up and a self-training stage, has been widely adopted in do-main adaptive semantic segmentation [1,41,50,80,81,84] as it stabilizes the domain adaptive learning [81] and thus re-duces the performance drop across domains. However, the gap is far from being closed and, in this work, we identify that there is still a large space to improve in both warm-up and self-training.
Regarding warm-up, recent works in this field [41, 50, 80, 81, 84] mostly adopt adversarial training [21, 67, 68] as their basic strategy, which usually contributes to limited adaptation improvements. Without knowing the target do-main labels, this adversarial learning proposes to align the overall feature distributions across domains. Note that this alignment is class-unaware and fails to guarantee the fea-tures from the same semantic category are well aligned be-tween the source and target domain, thus being sub-optimal as a warm-up strategy.
In contrast, we take an alternative perspective to improve the warm-up: simply enhancing the model’s domain gener-alizability without considering target data. To be specific, we introduce a pixel-wise symmetric knowledge distillation technique. The benefits are threefold: i. knowledge distil-lation is performed on the source domain where ground-truths are available, the learning thus becomes class-aware, which avoids the blind alignment as observed in adversarial training; ii. the soft labels created in the process of distilla-tion can effectively avoid the model overfitting to domain-specific bias [71] and help to learn more generalized fea-tures across domains; iii. our symmetric proposal ensures the bidirectional consistency between the original source view and its augmented view, leading to more generaliz-In this work, we present DiGA, a novel framework for domain adaptive semantic segmentation (see Fig.1). Our contributions can be summarized as follows:
• We introduce pixel-wise symmetric knowledge distil-lation sorely on source domain, which results in a stronger warm-up model and turns out to be a better option than its adversarial counterpart.
• We introduce cross-domain mixture (CrDoMix), a novel data augmentation technique that brings further improvement to our warm-up model performance;
• We propose bilateral-consensus pseudo-supervision, empowering efficient self-training while abandoning categorical thresholds;
• Our method achieves remarkable and consistent per-formance gain over prior arts on popular benchmarks, e.g., GTA5- and Synthia-to-Cityscapes adaptation. 2.