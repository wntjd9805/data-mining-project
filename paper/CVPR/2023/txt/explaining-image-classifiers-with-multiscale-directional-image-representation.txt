Abstract
Image classiﬁers are known to be difﬁcult to interpret and therefore require explanation methods to understand their decisions. We present ShearletX, a novel mask ex-planation method for image classiﬁers based on the shear-let transform – a multiscale directional image representa-tion. Current mask explanation methods are regularized by smoothness constraints that protect against undesirable
ﬁne-grained explanation artifacts. However, the smooth-ness of a mask limits its ability to separate ﬁne-detail pat-terns, that are relevant for the classiﬁer, from nearby nui-sance patterns, that do not affect the classiﬁer. ShearletX solves this problem by avoiding smoothness regularization all together, replacing it by shearlet sparsity constraints.
The resulting explanations consist of a few edges, textures, and smooth parts of the original image, that are the most relevant for the decision of the classiﬁer. To support our method, we propose a mathematical deﬁnition for explana-tion artifacts and an information theoretic score to evaluate the quality of mask explanations. We demonstrate the supe-riority of ShearletX over previous mask based explanation methods using these new metrics, and present exemplary situations where separating ﬁne-detail patterns allows ex-plaining phenomena that were not explainable before. 1.

Introduction
Modern image classiﬁers are known to be difﬁcult to explain. Saliency maps comprise a well-established ex-plainability tool that highlights important image regions for the classiﬁer and helps interpret classiﬁcation deci-sions. An important saliency approach frames saliency map computation as an optimization problem over masks
[8, 10, 13, 14, 18, 24, 29]. The explanation mask is opti-mized to keep only parts of the image that sufﬁce to retain the classiﬁcation decision. However, Fong and Vedaldi [14] showed that an unregularized explanation mask is very sus-ceptible to explanation artifacts and is hence unreliable.
Figure 1. Left column: ImageNet samples with prediction. Mid-dle column: Smooth pixel mask explanation from Fong et al. [13].
Right column: ShearletX (ours). Retained probability is computed as class probability after masking divided by class probability be-fore masking. ShearletX is the ﬁrst mask explanation method that can separate ﬁne-detail patterns, that are relevant for the classiﬁer, from nearby patterns that are irrelevant, without producing arti-facts.
Therefore, current practice [8,13,14] heavily regularizes the explanation masks to be smooth. The smooth explanation masks can communicate useful explanatory information by roughly localizing the relevant image region. However, the pattern that is relevant for the classiﬁer is often overlaid on
In such a situa-patterns that do not affect the classiﬁer. tion the mask cannot effectively separate the relevant pat-tern from the nuisance pattern, due to the smoothness con-1
straints. As a result, many details that are irrelevant to the classiﬁer, such as background elements, textures, and other spatially localized patterns, appear in the explanation.
An ideal mask explanation method should be resistant to explanation artifacts and capable of highlighting only rele-vant patterns. We present such a method, called ShearletX, that is able to separate different patterns that occupy nearby spatial locations by optimizing a mask in the shearlet rep-resentation of an image [25]. Due to the ability of shear-lets to efﬁciently encode directional features in images, we can separate relevant ﬁne-grained image parts, like edges, smooth areas, and textures, extremely well. We show both theoretically and experimentally that deﬁning the mask in the shearlet domain circumvents explanation artifacts. The masked image is optimized so that the classiﬁer retains its prediction as much as possible and to have small spatial sup-port (but not high spatial smoothness), while regularizing the mask to be sparse in the shearlet domain. This regular-ization assures that ShearletX retains only relevant parts, a fact that we support by a new information theoretic score for the quality of mask explanations. Figure 1 gives examples demonstrating that ShearletX can separate relevant details from nuisance patterns, which smooth pixel masks cannot.
Our contributions are summarized as follows: 1. ShearletX: The ﬁrst mask explanation method that can effectively separate ﬁne-detail patterns, that are rele-vant for the classiﬁer, from nearby nuisance patterns, that do not affect the classiﬁer. 2. Artifact Analysis: Our explanation method is based on low-level vision for maximal interpretability and belongs to the family of methods that produce out-of-distribution explanations. To validate that the re-sulting out-of-distribution explanations are meaning-ful, we develop a theory to analyze and quantify expla-nation artifacts, and prove that ShearletX is resilient to such artifacts. 3. Hallucination Score: a new metric for mask explana-tions that quantiﬁes explanation artifacts by measuring the amount of edges in the explanation that do not ap-pear in the original image. 4. Concisesness-Preciseness Score: A new information theoretic metric for mask explanations that gives a high score for explanations that extract the least amount of information from the image to retain the classiﬁcation decision as accurately as possible. 5. Experimental Results: We demonstrate that ShearletX performs better than previous mask explanations using our new metrics and give examples where ShearletX allows to explain phenomena that were not explainable with previous saliency methods.
The source code for the experiments is publicly available 1. 1https://github.com/skmda37/ShearletX 2 2.