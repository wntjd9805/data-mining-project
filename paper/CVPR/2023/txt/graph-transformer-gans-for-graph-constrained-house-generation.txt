Abstract
We present a novel graph Transformer generative adver-sarial network (GTGAN) to learn effective graph node re-lations in an end-to-end fashion for the challenging graph-constrained house generation task. The proposed graph-Transformer-based generator includes a novel graph Trans-former encoder that combines graph convolutions and self-attentions in a Transformer to model both local and global interactions across connected and non-connected graph nodes. Specifically, the proposed connected node atten-tion (CNA) and non-connected node attention (NNA) aim to capture the global relations across connected nodes and non-connected nodes in the input graph, respectively. The proposed graph modeling block (GMB) aims to exploit local vertex interactions based on a house layout topology. More-over, we propose a new node classification-based discrim-inator to preserve the high-level semantic and discrimina-tive node features for different house components. Finally, we propose a novel graph-based cycle-consistency loss that aims at maintaining the relative spatial relationships be-tween ground truth and predicted graphs. Experiments on two challenging graph-constrained house generation tasks (i.e., house layout and roof generation) with two public datasets demonstrate the effectiveness of GTGAN in terms of objective quantitative scores and subjective visual real-ism. New state-of-the-art results are established by large margins on both tasks. 1.

Introduction
This paper focuses on converting an input graph to a re-alistic house footprint, as depicted in Figure 1. Existing house generation methods such as [2, 16, 20, 28, 32, 45, 47], typically rely on building convolutional layers. However, convolutional architectures lack an understanding of long-range dependencies in the input graph since inherent in-Several Transformer architectures ductive biases exist.
[3, 6, 11, 17, 18, 24, 43, 44, 46, 54, 55] based on the self-attention mechanism have recently been proposed to encode long-range or global relations, thus learn highly expressive feature representations. On the other hand, graph convolu-tion networks are good at exploiting local and neighborhood vertex correlations based on a graph topology. Therefore, it stands to reason to combine graph convolution networks and Transformers to model local as well as global interac-tions for solving graph-constrained house generation.
To this end, we propose a novel graph Transformer gen-erative adversarial network (GTGAN), which consists of two main novel components, i.e., a graph Transformer-based generator and a node classification-based discrimi-nator (see Figure 1). The proposed generator aims to gen-erate a realistic house from the input graph, which consists of three components, i.e., a convolutional message passing neural network (Conv-MPN), a graph Transformer encoder (GTE), and a generation head. Specifically, Conv-MPN first receives graph nodes as inputs and aims to extract discrim-inative node features. Next, the embedded nodes are fed to
GTE, in which the long-range and global relation reasoning is performed by the connected node attention (CNA) and non-connected node attention (NNA) modules. Then, the output from both attention modules is fed to the proposed graph modeling block (GMB) to capture local and neigh-borhood relationships based on a house layout topology. Fi-nally, the output of GTE is fed to the generative head to pro-duce the corresponding house layout or roof. To the best of our knowledge, we are the first to use a graph Transformer to model local and global relations across graph nodes for solving graph-constrained house generation.
In addition, the proposed discriminator aims to distin-guish real and fake house layouts, which ensures that our generated house layouts or roofs look realistic. At the same time, the discriminator classifies the generated rooms to their corresponding real labels, preserving the discrimina-tive and semantic features (e.g., size and position) for differ-ent house components. To maintain the graph-level layout, we also propose a novel graph-based cycle-consistency loss to preserve the relative spatial relationships between ground truth and predicted graphs.
Overall, our contributions are summarized as follows:
Figure 1. Overview of the proposed GTGAN on house layout generation. It consists of a novel graph Transformer-based generator G and a novel node classification-based discriminator D. The generator takes graph nodes as input and aims to capture local and global relations across connected and non-connected nodes using the proposed graph modeling block and multi-head node attention, respectively. Note that we do not use position embeddings since our goal is to predict positional node information in the generated house layout. The discriminator
D aims to distinguish real and generated layouts and simultaneously classify the generated house layouts to their corresponding room types. The graph-based cycle-consistency loss aligns the relative spatial relationships between ground truth and predicted nodes. The whole framework is trained in an end-to-end fashion so that all components benefit from each other.
• We propose a novel Transformer-based network (i.e., GT-GAN) for the challenging graph-constrained house gener-ation task. To the best of our knowledge, GTGAN is the first Transformer-based framework, enabling more effec-tive relation reasoning for composing house layouts and validating adjacency constraints.
• We propose a novel graph Transformer generator that combines both graph convolutional networks and Trans-formers to explicitly model global and local correlations across both connected and non-connected nodes simul-taneously. We also propose a new node classification-based discriminator to preserve high-level semantic and discriminative features for different types of rooms.
• We propose a novel graph-based cycle-consistency loss to guide the learning process toward accurate relative spatial distance of graph nodes.
• Qualitative and quantitative experiments on two challeng-ing graph-constrained house generation tasks (i.e., house layout generation and house roof generation) with two datasets demonstrate that GTGAN can generate better house structures than state-of-the-art methods, such as
HouseGAN [28] and RoofGAN [32]. 2.