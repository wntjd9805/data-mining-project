Abstract
We present RAFTformer, a real-time action forecasting transformer for latency-aware real-world action forecast-ing. RAFTformer is a two-stage fully transformer based architecture comprising of a video transformer backbone that operates on high resolution, short-range clips, and a head transformer encoder that temporally aggregates infor-mation from multiple short-range clips to span a long-term horizon. Additionally, we propose a novel self-supervised shuffled causal masking scheme as a model level augmen-tation to improve forecasting fidelity. Finally, we also pro-pose a novel real-time evaluation setting for action fore-casting that directly couples model inference latency to overall forecasting performance and brings forth a hith-erto overlooked trade-off between latency and action fore-casting performance. Our parsimonious network design fa-cilitates RAFTformer inference latency to be 9× smaller than prior works at the same forecasting accuracy. Ow-ing to its two-staged design, RAFTformer uses 94% less training compute and 90% lesser training parameters to outperform prior state-of-the-art baselines by 4.9 points on EGTEA Gaze+ and by 1.4 points on EPIC-Kitchens-100 validation set, as measured by Top-5 recall (T5R) in the offline setting.
In the real-time setting, RAFTformer outperforms prior works by an even greater margin of upto 4.4 T5R points on the EPIC-Kitchens-100 dataset.
Project Webpage: https://karttikeya.github. io/publication/RAFTformer/. 1.

Introduction
Latency matters.
It is a crucial system design consid-eration for countless applications that operate in real-time from hardware design [65], network engineering [63], and satellite communications [30] to capital trading [32], human vision [59] and COVID transmission patterns [54]. How-ever, it has not been a center stage design consideration in modern computer vision systems of the past decade [11,45].
Modern vision system design has largely focused on the
* Work done during Harshayu’s internship at HRI with Chiho Choi’s supervision who is now at Samsung Seminconductor US
Karttikeya Mangalam is the corresponding author
Figure 1. Action Forecasting is the task of predicting actions that will happen after a pre-determined time span, say tf seconds, into the future. Prior works consider an offline evaluation setting that ignores the model inference latency. We propose a latency-aware real-time evaluation setting where the model is required to finish forecasting tf seconds before the target time. We present
RAFTformer, a fast action anticipation transformer that outper-forms prior works both in offline & real-time setting while fore-casting actions in real-time (≥ 25 FPS). correctness of systems rather than the latency of the pre-dictions. While vision-based forecasting systems are often meant for embodied real-time deployment on autonomous agents like self-driving cars and robots, they are evaluated in an offline setting where inference latency is neglected (Figure 1).
Interestingly, recent neural network architec-tures have adopted FLOPs as a proxy for latency as a sec-ond axis for model design. While a sufficient fidelity met-ric for offline after-the-fact applications like automatic con-tent recognition, latency often comes second to correctness, even for real-time systems such as forecasting models.
Forecasting empowers reactive planning [17]. An au-tonomous system present in rich human environments in-evitably needs to understand human actions around it for smooth task planning and execution. Autonomous agent planning critically depends on anticipating the future of the scene in various forms such as trajectory prediction [22, 23, 57, 58], action forecasting [19, 25, 80] or future scene
segmentation [8] and anticipating the future is an activity humans subconsciously do for day-to-day tasks [60]. And while vision-based forecasting systems are often meant for embodied real-time deployment on autonomous agents like autonomous cars and robots, they are evaluated in an offline setting where inference latency is neglected (Figure 1).
In this work, we propose a real-time evaluation setting (Figure 1) that closely mimics the real-world deployment for a forecasting system. Suppose that in a real-time sys-tem, the design specifications require the forecasting system outputs tf seconds in advance of the event to be able to plan and use the forecasts effectively. In current offline settings, the forecasting system begins the inference tf seconds in advance of the event (‘Present’ in Figure 1) and the model latency is ignored (or assumed to be 0) such that the pre-dictions are available instantly. However, in our proposed real-time setting, the model is required to start inference in advance of ‘Present’ so that the outputs are available with a horizon of tf seconds, meeting the design specification.
We observe that in the real-time setting, the prior works fare quite poorly because of their slow model inference la-tency (Table 3). A large latency implies that the model has to start inference further in the past and has to rely on older video data to make forecasts with the benefit of more ex-pressiveness (Figure 2). A smaller latency means the model can enjoy more recent video data but has limited capacity.
Simply said, models that are only evaluated in the offline setting may fare poorly in the real-time deployment setting due to their latency agnostic design (Figure 2).
We present, RAFTformer, a real-time action forecast-ing transformer that uses a two-stage transformer encoder-based network for lightning fast forecasts in inference.
RAFTformer uses a shuffled casual masking scheme based feature prediction loss for learning strong temporal cues that transfer to feature prediction. Further, RAFTformer uses specialized anticipation tokens for learning to predict action at multiple temporal horizons that improve model reasoning capabilities of short-term action forecasting as well. Finally, the model is explicitly designed for real-time embodied de-ployments that allows inference up to an order of magnitude faster than prior state-of-the-art methods. In summary, our contributions are three-fold,
First, we propose Real-time Action Forecasting
Transformer a real-time action fore-(RAFTformer), casting transformer with latency at least 9× smaller than prior state-of-the-art action forecasting methods. RAFT-former uses specialized anticipation tokens and a novel shuffled casual masking-based self-supervision loss that allows it to outperform prior work while maintaining low latency with a reduction of 94% in GPU training time and 90% in the number of trainable parameters compares to prior works. To the best of our knowledge, our work is the first to achieve action anticipation in real-time (i.e. 25 fps).
Figure 2. Evaluation Performance vs. Latency. Bigger models perform better in latency agnostic offline settings. In the real-time evaluation setting, we observe that, beyond a limit, bigger models with higher latency cause a drop in forecasting performance. In practical deployment, there exists a trade-off between latency and high-fidelity forecasts. See §4.3.1 for details.
Second, we propose a latency-aware real-time evaluation setting (Figure 1) that better mimics practical deployment settings for embodied forecasting systems. Real-time eval-uation demonstrates a clear trade-off between inference la-tency and model forecasting fidelity, paving the path for the development of latency-aware forecasting models in the fu-ture (also see [20]).
Third, Through extensive experiments, we show that
RAFTformer outperforms prior state-of-the-art methods by 4.9 points on the EGTEA Gaze+ dataset, by 1.4 points on the EPIC-Kitchens-100 dataset according to the Top-5 Re-call metric and by a relative margin of 5.3% on the top-1 accuracy metric on EPIC-Kitchens-55 dataset. 2.