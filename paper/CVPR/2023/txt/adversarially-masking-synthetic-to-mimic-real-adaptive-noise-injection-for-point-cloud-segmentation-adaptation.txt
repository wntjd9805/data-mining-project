Abstract
This paper considers the synthetic-to-real adaptation of point cloud semantic segmentation, which aims to segment the real-world point clouds with only synthetic labels avail-able. Contrary to synthetic data which is integral and clean, point clouds collected by real-world sensors typi-cally contain unexpected and irregular noise because the sensors may be impacted by various environmental condi-tions. Consequently, the model trained on ideal synthetic data may fail to achieve satisfactory segmentation results on real data. Influenced by such noise, previous adversar-ial training methods, which are conventional for 2D adap-tation tasks, become less effective. In this paper, we aim to mitigate the domain gap caused by target noise via learn-ing to mask the source points during the adaptation pro-cedure. To this end, we design a novel learnable masking module, which takes source features and 3D coordinates as inputs. We incorporate Gumbel-Softmax operation into the masking module so that it can generate binary masks and be trained end-to-end via gradient back-propagation. With the help of adversarial training, the masking module can learn to generate source masks to mimic the pattern of irregular target noise, thereby narrowing the domain gap. We name our method “Adversarial Masking” as adversarial training and learnable masking module depend on each other and cooperate with each other to mitigate the domain gap. Ex-periments on two synthetic-to-real adaptation benchmarks verify the effectiveness of the proposed method. 1.

Introduction
Recently, point cloud semantic segmentation task at-tracts increasing attention because of its important role in various real-world applications, e.g., autonomous driving, augmented reality, etc. Despite remarkable progress [5,
*Work done during an internship at Baidu.
†Corresponding author: Guoliang Kang
Figure 1. Comparison between a synthetic LiDAR scan (upper) and a real scan (lower). Both original point clouds and projected
LiDAR images are given. Black points denote noise and other col-ors denote points from different classes. Compared with synthetic data which is integral and clean, point clouds collected from the real world typically contain unexpected and irregular noise which may impede the adaptation. 19, 30, 33, 39, 40, 62, 63], most algorithms are designed for the fully-supervised setting, where massive annotated data is available. In the real world, it is costly and time-consuming to annotate large amounts of data, especially for labeling each point in the segmentation task. Syn-thetic data is easy to obtain and its label can be automat-ically generated, which largely reduces the human effort of annotating data. However, it is usually infeasible to di-rectly apply networks trained on synthetic data to real-world
In data due to the apparent domain gap between them. this paper, we consider the synthetic-to-real domain adap-tation [7, 10, 29, 38, 42, 45, 56, 68] for point cloud segmen-tation. Specifically, we aim to utilize the fully-annotated synthetic point clouds (source domain) and unlabeled point clouds collected from imperfect real-world sensors (target domain) to train a network to support the segmentation of real-world point clouds (target domain).
Domain adaptation solutions [8, 9, 20, 21] aim to dis-cover and mitigate the domain shift from source to target domain. Through comparing the synthetic and real-world point clouds, we observe that the domain shift can be largely attributed to the unexpected and irregular noise existing in the target domain data. As with [53], we consider “noise” to be the missing points of certain instances/objects, where all pixel channels are zero. Such noise may be caused by various factors such as non-reflective surfaces (e.g., glass).
As shown in Fig. 1, the synthetic point cloud is integral and clean, but the real one contains large amounts of noisy points. A model trained on clean source data may find it hard to understand the scene context under the distraction of noises and thus cannot achieve satisfactory segmentation results on target point clouds.
Previous domain adaptation methods [4, 13, 14, 18, 28, 31, 32, 38, 61] (e.g., adversarial training), which have been proven effective in the 2D visual tasks, can be applied to this 3D segmentation setting. For example, Squeeze-SegV2 [54] employs geodesic correlation alignment [37] to align the point-wise feature distributions of two domains.
However, without explicitly modeling and dealing with the noise, these methods bring quite weak benefits to the adap-tation performance. Recently, several works attempt to deal with the target noise to mitigate the domain gap. Rochan et al. [43] randomly select target noise masks and apply the selected mask to source samples. Wu et al. [53] compute one dataset-level mask and apply it to all source samples.
Zhao et al. [67] use CycleGAN [69] to perform noise in-painting which is then used to learn synthetic noise gen-eration module. The issues of these previous works are two-fold: 1) they cannot adaptively determine the injected noises according to the context of source samples; 2) the generated mask cannot be guaranteed to reduce the domain shift. Thus, these methods may achieve sub-optimal results.
In this paper, we aim to mitigate the domain shift caused by the target noise by learning to adaptively mask the source points during the adaptation procedure. To reach this goal, we need to deal with two problems: 1) how to learn a spa-tial mask that can be adaptively determined according to the specific context of a source sample, and 2) how to guaran-tee the learned masks help narrow the domain gap. To solve the first problem, we design a learnable masking module named “Adaptive Spatial Masking (ASM)” module, which takes source Cartesian coordinates and features as input, to generate point-wise source masks. We incorporate Gumbel-Softmax operation into the masking module so that it can generate binary masks and be trained end-to-end via gra-dient back-propagation. To solve the second problem, we incorporate adversarial training into the masking module learning process. Specifically, during training, we add an additional domain discriminator on top of the feature ex-tractor. By encouraging features from two domains (fea-tures of masked source samples and those of normal tar-get samples) to be indistinguishable, the masking module is able to learn to generate masks mimicking the pattern of tar-get noise and narrow the domain gap. Note that these two designs cooperate with each other to better align features across domains and improve the adaptation performance.
In a nutshell, our contributions can be summarized as:
• We notice that the pattern of target noise is unexpected and irregular. Thus, we propose to model the target noise in a learnable way. Previous works, which don’t explicitly model the target noise or ignore such char-acteristics, are less effective.
• We propose to adversarially mask source samples to mimic the target noise patterns. In detail, we design a novel learnable masking module and incorporate ad-versarial training. Both components cooperate with each other to promote the adaptation.
• Experiments on two synthetic-to-real adaptation benchmarks, i.e. SynLiDAR → SemKITTI and Syn-LiDAR → nuScenes, demonstrate that our method can effectively improve the adaptation performance. 2.