Abstract
In Weakly Supervised Semantic Segmentation (WSSS),
Class Activation Maps (CAMs) usually 1) do not cover the whole object and 2) be activated on irrelevant regions.
To address the issues, we propose a novel WSSS frame-work via adversarial learning of a classifier and an im-age reconstructor. When an image is perfectly decomposed into class-wise segments, information (i.e., color or tex-ture) of a single segment could not be inferred from the other segments. Therefore, inferability between the seg-ments can represent the preciseness of segmentation. We quantify the inferability as a reconstruction quality of one segment from the other segments.
If one segment could be reconstructed from the others, then the segment would be imprecise. To bring this idea into WSSS, we simulta-neously train two models: a classifier generating CAMs that decompose an image into segments and a reconstruc-tor that measures the inferability between the segments.
As in GANs, while being alternatively trained in an ad-versarial manner, two networks provide positive feedback to each other. We verify the superiority of the proposed framework with extensive ablation studies. Our method achieves new state-of-the-art performances on both PAS-CAL VOC 2012 and MS COCO 2014. The code is available at https://github.com/sangrockEG/ACR. 1.

Introduction
Over the past decade, learning-based semantic segmen-tation has made significant advancements. However, the high labeling cost remains a major challenge when applying existing methods to real cases. In response to this challenge, without relying on pixel-wise supervision, Weakly Super-vised Semantic Segmentation (WSSS) has been proposed to learn semantic segmentation with weak labels only.
The field of WSSS has studied several types of weak la-bels such as scribbles [29, 36], bounding boxes [16, 23, 31], and image-level classification labels [1–3, 7, 12, 19, 21, 28,
*The first two authors contributed equally. In alphabetical order.
Figure 1. Demonstration of our method. We are motivated by the relation between semantic segmentation and inferability. We realize it as adversarial learning of a classifier and a reconstructor. 37, 42, 46, 47, 49, 52], which are relatively inexpensive to acquire. Among them, using image-level labels is the most widely studied setting due to its high accessibility and effi-ciency. Different from the other supervisions that roughly notify the locations of the things in the image, image-level labels only contain categorical information. Therefore, the main challenge in WSSS using image-level labels is local-izing the regions of each class.
To dispel this challenge, most of the existing literature employs Class Activation Maps (CAMs) [51] that highlight the regions highly contributing to the prediction of a classi-fier. Intuitively, the classifier learns shared patterns among the images including the same class, and thereby the CAM of each class is activated on the image regions correspond-ing to the class. However, the CAMs usually show a ten-dency to focus on the most discriminative regions of each class (e.g. face for the cat class), which leads to incomplete segmentation. Also, due to the absence of pixel-wise su-pervision, the CAMs are rather imprecise at the boundary, which is a critical issue from the perspective of segmenta-tion. Technically, the goal of WSSS can be summarized as obtaining better CAMs, which can serve as precise pseudo-labels for learning semantic segmentation.
In this paper, we propose a novel method inspired by simple but meaningful intuition as in Fig. 1.
If semantic segmentation is perfectly accomplished, each of the objects in the image is perfectly segmented into mutually indepen-dent segments in terms of color and texture. In this case, each of the segments does not include any clue about the rest of the image. Therefore, if segmentation of the image is perfectly performed, no single segment can “infer” colors or textures about the other segments. As a contra-positive statement, if any information such as color or textures about a segment could be inferred from the other segments, the semantic segmentation could be regarded as imperfect. Ac-cordingly, it might be possible to measure the quality of se-mantic segmentation based on the inferability between the segments. However, how could we quantify the degree of
“inferability”? To this end, we propose to employ the image reconstruction task, which reconstructs one image segment from the other segments. Then, the quality of reconstruc-tion could be regarded as a measure of inferability. Here, note that the image reconstruction task does not introduce any additional supervision.
We formulate the aforementioned intuition as an adver-sarial learning of a classifier and a reconstructor. In spe-cific, according to the CAMs obtained by the classifier, we decompose an image into two segments: a segment of the target class and a segment of the non-target class (the other classes). The reconstructor is trained to reconstruct one seg-ment by using the other segment as the only input. On the other hand, we promote the CAMs to decompose an im-age into segments that reduce the inferability of the recon-structor. In other words, the classifier is trained to not only classify the image but also generate CAMs correctly seg-menting the image, while competing with the reconstructor.
Ultimately, we improve the quality of the CAMs by jointly training the two competitors (i.e., the classifier and the re-constructor) in an adversarial manner.
The adversarial learning strategy of our framework is similar to Generative Adversarial Networks (GANs) [14].
Like the discriminator in GANs is specialized to discrimi-nate the real/fake samples, the reconstructor in our frame-work is trained to fully exploit the remnant contained in the given segment for reconstructing the other segment. Simi-larly, the classifier in our framework learns to generate pre-cise CAMs, using the reconstructor as a measure of the in-ferability between the segments, like the generator getting feedback from the discriminator in GANs. Consequently, our adversarial learning framework can achieve WSSS us-ing only the supervision that comes from the image-level classification labels and the input images themselves.
The proposed method has methodological similarity to the existing Adversarial Erasing (AE) methods of WSSS in that it erases (or spatially decomposes) the image according to CAMs. However, the insights behind our method and the
AE methods are far different. AE methods mask the highly activated regions of the CAMs from the image and impose classification loss on the remained image. Therefore, due to the lack of regularization for the erasing process, the CAMs usually suffer from undesirable expansion. On the other hand, the proposed method is inspired by the relation be-tween segmentation and reconstruction. And we formulate it as adversarial learning between two networks performing each task. This realization not only provides reliable guid-ance for CAMs from the perspective of segmentation, but also enables each network to improve while training pro-ceeds, based on the positive feedback from its counterpart.
To verify the superiority of our method, we conduct extensive ablation studies and comparisons with the other state-of-the-art (SoTA) WSSS methods. Further, on both
PASCAL VOC 2012 [11] and MS COCO [30] datasets, the proposed framework achieves a new SoTA.
The contribution of this paper is threefold:
• We formulate the problem of WSSS as minimizing infer-ability between the segments decomposed by the CAMs.
• We propose a novel WSSS framework based on adversar-ial learning of the classifier and reconstructor.
• We achieve state-of-the-art performance on both the
PASCAL VOC 2012 val/test set and MS COCO val set. 2.