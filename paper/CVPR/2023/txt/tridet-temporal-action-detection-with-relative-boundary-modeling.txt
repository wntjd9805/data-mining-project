Abstract
In this paper, we present a one-stage framework TriDet for temporal action detection. Existing methods often suf-fer from imprecise boundary predictions due to the ambigu-ous action boundaries in videos. To alleviate this prob-lem, we propose a novel Trident-head to model the action boundary via an estimated relative probability distribution around the boundary. In the feature pyramid of TriDet, we propose an efficient Scalable-Granularity Perception (SGP) layer to mitigate the rank loss problem of self-attention that takes place in the video features and aggregate information across different temporal granularities. Benefiting from the
Trident-head and the SGP-based feature pyramid, TriDet achieves state-of-the-art performance on three challeng-ing benchmarks: THUMOS14, HACS and EPIC-KITCHEN 100, with lower computational costs, compared to previ-ous methods. For example, TriDet hits an average mAP of 69.3% on THUMOS14, outperforming the previous best by 2.5%, but with only 74.6% of its latency. The code is re-leased to https://github.com/dingfengshi/TriDet. 1.

Introduction
Temporal action detection (TAD) aims to detect all start and end instants and corresponding action categories from an untrimmed video, which has received widespread atten-tion. TAD has been significantly improved with the help of the deep learning. However, TAD remains to be a very challenging task due to some unresolved problems.
A critical problem in TAD is that action boundaries are usually not obvious. Unlike the situation in object detec-tion where there are usually clear boundaries between the
*: This work is done during an internship at JD Explore Academy.
â€ : Corresponding authors.
Figure 1. Illustration of different boundary modeling. Segment-level: these methods locate the boundaries based on the global fea-ture of a predicted temporal segment. Instant-level: they directly regress the boundaries based on a single instant, potentially with some other features. Ours: the action boundaries are modeled via an estimated relative probability distribution of the boundary. objects and the background, the action boundaries in videos can be fuzzy. A concrete manifestation of this is that the in-stants (i.e. temporal locations in the video feature sequence) around the boundary have relatively higher predicted re-sponse value from the classifier.
Some previous works attempt to locate the boundaries based on the global feature of a predicted temporal seg-ment [21,22,29,46,51], which may ignore detailed informa-tion at each instant. As another line of work, they directly regress the boundaries based on a single instant [32,47], po-tentially with some other features [20, 33, 49], which do not consider the relation between adjacent instants (e.g. the rel-across three challenging benchmarks: THUMOS14, HACS and EPIC-KITCHEN 100. 2.