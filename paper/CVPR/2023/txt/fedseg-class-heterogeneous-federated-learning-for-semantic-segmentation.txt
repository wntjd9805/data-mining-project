Abstract
Federated Learning (FL) is a distributed learning paradigm that collaboratively learns a global model by multiple clients with data privacy-preserving. Although many FL algorithms have been proposed for classification tasks, few works focus on more challenging semantic seg-mentation tasks, especially in the class-heterogeneous FL situation. Compared with classification, the issues from het-erogeneous FL for semantic segmentation are more severe: (1) Due to the non-IID distribution, different clients may contain inconsistent foreground-background classes, result-ing in divergent local updates. (2) Class-heterogeneity for complex dense prediction tasks makes the local optimum of clients farther from the global optimum.
In this work, we propose FedSeg, a basic federated learning approach for class-heterogeneous semantic segmentation. We first propose a simple but strong modified cross-entropy loss to correct the local optimization and address the foreground-background inconsistency problem. Based on it, we intro-duce pixel-level contrastive learning to enforce local pixel embeddings belonging to the global semantic space. Ex-tensive experiments on four semantic segmentation bench-marks (Cityscapes, CamVID, PascalVOC and ADE20k) demonstrate the effectiveness of our FedSeg. We hope this work will attract more attention from the FL community to the challenging semantic segmentation federated learning. 1.

Introduction
Semantic segmentation is the task of assigning a unique semantic label to every pixel in a given image, which is a fundamental research topic in computer vision and has many potential applications, such as autonomous driving, image editing and robotics [30]. Training a semantic seg-mentation model usually needs vast of data with pixel-level annotations, which is extremely hard to acquire. Collabo-rative training on multiple clients is a feasible way to solve
†Corresponding author.
Figure 1. (a) The foreground-background inconsistency for class-heterogeneous semantic segmentation. (b) Local optimization di-vergence problem for the heterogeneous dense prediction task. the problem. However, collaborative training has the risk of leaking sensitive information. For example, for the au-tonomous driving task, the training images may include pri-vate information such as where the user arrived, where the user lives and what the user’s house looks like. Thus, a privacy-preserving collaborative training method is requi-site for semantic segmentation.
Federated Learning (FL) [31] is an emerging distributed machine learning paradigm that jointly trains a shared global model by multiple clients without exchanging their raw data. FedAvg [31] is a basic FL algorithm that learns local models with raw data on clients separately while ag-gregating weights to a global model on a server. One key problem of FL is the statistical heterogeneity of data dis-tribution among different clients. Many recent FL algo-rithms [1, 21, 22, 26, 32] are proposed to tackle the prob-lem. However, most of them evaluate their methods on classification, while few works focus on more challeng-ing semantic segmentation. Although some federated learn-ing approaches [17, 29, 46, 52] for medical image segmen-tation have been proposed, they mainly address the sim-ple foreground-background segmentation and cannot solve the class-heterogeneous problem for semantic segmentation with a variety of object classes. A recent FL approach, Fed-Drive [14], evaluates FL methods on an autonomous driv-ing semantic segmentation dataset, Cityscapes [9]. How-ever, FedDrive [14] focuses on domain heterogeneity (im-ages from different cities) while ignoring the more challeng-ing class-heterogeneous problem.
In this paper, we focus on class-heterogeneous feder-ated learning for semantic segmentation, which has spe-cific and more severe issues compared with classifica-tion. First, images for semantic segmentation are more complex, and pixel-level annotation is extremely time-consuming. Clients usually annotate the objects of fre-quent classes and ignore the rare ones. Due to the non-IID (non-Independent Identically Distribution) data distri-bution of different clients, classes ignored by one client may be foreground classes in another client. For exam-ple, in Fig. 1 (a), the ignored class “person” in Client 1 is annotated in Client 2. The foreground-background incon-sistency across clients leads to divisive optimization direc-tions and degrades the capability of the aggregated global model. Second, as shown in Fig. 1 (b), even if there is no foreground-background inconsistency, for non-IID dis-tribution, complex dense prediction makes the local opti-mization direction diverging farther to the global optimum compared with classification tasks, resulting in poor conver-gence. From the perspective of the pixel embedding space, the local update in each client cannot learn the relative posi-tions of different semantic classes in the pixel embedding space, leading to the confounded embedding space after global aggregation.
In this paper, we propose a new federated learning method for semantic segmentation, FedSeg, to address the above issues. A standard objective function for semantic segmentation is the cross-entropy (CE) loss which takes effect on foreground pixels and ignores the background pixels. For FL with non-IID data distribution, it makes the learned local optimum away from the global optimum.
Thus, we propose a simple but strong baseline, a modified cross-entropy loss, by aggregating the probabilities of back-ground classes. The modified loss corrects “client drift” in local updates and alleviates the foreground-background in-consistency problem. Then we further introduce a local-to-global pixel-level contrastive learning loss to enforce the local pixel embedding space close to the global semantic space, improving the convergence of the global model.
Extensive experiments on four semantic segmentation datasets (Cityscapes [9], CamVID [3], PascalVOC [13] and
ADE20k [63]) are conducted to evaluate the effectiveness of our FedSeg. Experimental results show that the sim-ple modified cross-entropy loss significantly improves the segmentation quality. Based on it, our proposed local-to-global pixel contrastive learning consistently improves the segmentation performance compared with previous FL al-gorithms [1, 22, 26, 31].
To summarize, the contributions of this paper are as fol-lows:
• We systematically investigate federated learning for the semantic segmentation task with a variety of classes, particularly the class-heterogeneous problem.
• We propose a strong baseline with a simple modified
CE loss and a local-to-global metrics learning method to alleviate the class distribution drift problem across clients.
• We provide benchmarks on four semantic segmenta-tion datasets to evaluate our FedSeg for the semantic seg-mentation FL problem. We hope this work will motivate the FL community to further study the federated learning problem for challenging semantic segmentation tasks. 2.