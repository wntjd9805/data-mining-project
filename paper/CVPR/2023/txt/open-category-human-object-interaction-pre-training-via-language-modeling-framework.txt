Abstract
Human-object interaction (HOI) has long been plagued by the conflict between limited supervised data and a vast number of possible interaction combinations in real life.
Current methods trained from closed-set data predict HOIs as fixed-dimension logits, which restricts their scalability to open-set categories. To address this issue, we introduce
OpenCat, a language modeling framework that reformu-lates HOI prediction as sequence generation. By convert-ing HOI triplets into a token sequence through a serial-ization scheme, our model is able to exploit the open-set vocabulary of the language modeling framework to pre-dict novel interaction classes with a high degree of free-dom. In addition, inspired by the great success of vision-language pre-training, we collect a large amount of weakly-supervised data related to HOI from image-caption pairs, and devise several auxiliary proxy tasks, including soft re-lational matching and human-object relation prediction, to pre-train our model. Extensive experiments show that our
OpenCat significantly boosts HOI performance, particu-larly on a broad range of rare and unseen categories. 1.

Introduction
Human-object interaction (HOI) task [5, 6], whose out-put is usually in the format of a triplet: <human, relation, object>, has drawn increasing attention due to its crucial role in scene understanding. As humans, we have a rich vo-cabulary to describe one human-object relation in various ways (e.g., near, next to, close to). We can also recognize different combinations of HOI triplets in our real-life sce-narios. However, current HOI methods have struggled to achieve such ºopen-categoryº capability for a long time.
We argue that this is primarily due to two deficiencies: in-flexible prediction manner and insufficient supervised data.
Previous works treat HOI learning as a classification problem where the class vocabulary must be pre-defined.
*Qin Jin is the corresponding author.
Figure 1. OpenCat reformulates HOI learning as a sequence gener-ation task, rather than a closed-set classification task. Through the aid of task-specific pre-training with weak supervision, our model achieves open-category prediction on a large number of tail and unseen HOI classes.
This approach involves projecting the input image into fixed-dimension logits through a classifier, which restricts the ability to identify new HOI triplets.
In contrast, lan-guage models [51] are more suited to predict free-form texts, thanks to their extensive token vocabulary. Recently, other works [9, 62] explore to generate visual outputs using a single language modeling objective. Inspired by this line of research, we reformulate HOI learning as a language se-quence generation problem as illustrated in Figure 1, which enables our model to leverage an open-set vocabulary, gen-erating HOI triplets with a high degree of freedom.
Moreover, HOI learning requires abundant labels for ex-haustive HOI categories. However, due to the high cost of labeling grounded HOIs and the natural long-tailed distribu-tion of HOI categories, it is unrealistic to ensure sufficient instances in each category. In fact, the two most popular benchmarks so far, HICO-DET [5] and V-COCO [21], con-tain 117 and 50 relation classes respectively, covering just a small portion of the HOI categories in reality. Models trained on such closed-set data fail to handle the large num-ber of possible combinations of human, relation and object.
Recently, researchers have explored weakly supervised or even self-supervised vision-language (VL) pre-training to address data scarcity. These endeavors have achieved great success, demonstrating their generalization to novel visual
Inspired by these works, or textual concepts [3, 12, 44]. one intuitive idea is to leverage pre-training to overcome the problem of insufficient labeled HOI data. However, lever-aging weakly-supervised or unsupervised data for HOI pre-training is not trivial. An HOI model must accurately local-ize the interaction regions in the image and recognize fine-grained differences among massive human activities (e.g., stand on motorcycle vs. sit on motorcycle), which is quite challenging to learn from merely weak supervision (e.g., image-caption pairs). Therefore, the pre-training frame-work as well as the proxy tasks must be well designed.
In this work, to address the issues of inflexible prediction manner and insufficient supervised data in human-object interaction tasks, we propose a novel Open-Category pre-training framework named OpenCat
. Our framework utilizes a serialization scheme to convert HOI triplets into a sequence of discrete tokens and incorporates several auxil-iary proxy tasks to enhance visual representation, including masked language prediction (MLP), human-object relation prediction (HRP) and human-object patch jigsaw (HPJ), all formulated as sequence generation tasks. To enable learn-ing interaction alignment between human and object with-out the need for grounded HOI annotations, we further de-vise an additional proxy task named soft relational matching (SRM). The SRM task borrows knowledge from a VL pre-training model [34,50] to create pseudo alignment labels be-tween detected object regions and HOI triplets parsed from the caption. With these proxy tasks, our model improves its generalization to a wide range of novel HOIs.
Our contributions can be outlined as follows:
• We introduce OpenCat, a language modeling frame-work to effectively model open-category HOIs.
• We collect a large amount of weakly-supervised HOI pre-training data based sorely on textual supervision and devise several proxy tasks to train our model.
• By adapting our model to downstream HOI tasks, we achieve state-of-the-art performance with larger gains observed under zero-shot and few-shot setups. 2.