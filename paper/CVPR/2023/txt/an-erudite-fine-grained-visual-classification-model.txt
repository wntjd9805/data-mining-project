Abstract
Current fine-grained visual classification (FGVC) mod-els are isolated. In practice, we first need to identify the coarse-grained label of an object, then select the corre-sponding FGVC model for recognition. This hinders the ap-plication of FGVC algorithms in real-life scenarios. In this paper, we propose an erudite FGVC model jointly trained by several different datasets1, which can efficiently and ac-curately predict an object’s fine-grained label across the combined label space. We found through a pilot study that positive and negative transfers co-occur when differ-ent datasets are mixed for training, i.e., the knowledge from other datasets is not always useful. Therefore, we first propose a feature disentanglement module and a fea-ture re-fusion module to reduce negative transfer and boost positive transfer between different datasets. In detail, we reduce negative transfer by decoupling the deep features through many dataset-specific feature extractors. Subse-quently, these are channel-wise re-fused to facilitate pos-itive transfer. Finally, we propose a meta-learning based dataset-agnostic spatial attention layer to take full advan-tage of the multi-dataset training data, given that localisa-tion is dataset-agnostic between different datasets. Exper-imental results across 11 different mixed-datasets built on four different FGVC datasets demonstrate the effectiveness of the proposed method. Furthermore, the proposed method can be easily combined with existing FGVC methods to obtain state-of-the-art results. Our code is available at https://github.com/PRIS-CV/An- Erudite-FGVC-Model. 1.

Introduction
In daily life, most people can quickly identify the coarse-grained label of an object (e.g., car, bird, or aircraft). Then if we want to go further and identify its fine-grained la-*indicates the corresponding author. 1In this paper, different datasets mean different fine-grained visual clas-sification datasets.
Figure 1. How to identify the fine-grained labels of an object? Cur-rent paradigms require two stages: coarse-grained visual classifi-cation and fine-grained visual classification. This paper transforms the two stages of recognition into an erudite fine-grained visual classification model, which can directly recognise the fine-grained labels of objects across different coarse-grained label spaces. bels (e.g., “Ferrari FF Coupe” [20], “Sayornis” [36], “Boe-ing 727-200” [25]), we must learn and master the relevant knowledge [7]. However, it is impossible to master the knowledge and the classification topology of all objects in the world. A critical way to address this problem is to de-velop FGVC algorithms which can assist humans to recog-nise the fine-grained labels of different objects. Moreover, with the rapid development of deep learning, current FGVC algorithms have already abandoned the reliance on addi-tional information [2, 5] (e.g., attributes, bounding boxes) and have achieved recognition performance of over 90% on a wide range of fine-grained datasets [38], with the ability to be applied in practice.
However, current FGVC algorithms are all based on a single source of training data, e.g., a model trained on the
CUB-200-2011 [36] dataset can only be used to recognise the species of a bird. If we want to identify a model for a car, we have to use another FGVC model. Specifically, as shown in Figure 1, if we want to recognise the fine-grained label of an object, we first need to know its coarse-grained label (e.g., birds vs. cars) through a coarse-grained vi-sual classification model, then select its corresponding fine-grained model from the FGVC model zoo and recognise
its fine-grained label. This two-stage approach faces four challenges: Firstly, the inference time becomes longer (first coarse-grained image recognition, then fine-grained image recognition); Secondly, more storage space is required (dif-ferent FGVC datasets require different fine-grained models to be stored); Thirdly, the accumulation of errors occurs (the accuracy of coarse-grained image recognition directly af-fects the accuracy of fine-grained recognition); Fourthly, the positive and negative transfers between different datasets is ignored. The above challenges greatly hinder the applica-tion of FGVC algorithms in practice.
A key solution to solve the challenges is to jointly train an erudite FGVC model with all training data from dif-ferent datasets, as shown in Figure 1. However, our pilot study found that a vanilla erudite model fails to make accu-rate predictions because both positive and negative transfer occurs between different datasets. Specifically, after joint training, although each dataset’s overall distribution of fea-tures almost always becomes better (i.e., larger inter-class variance and intra-class similarity) than training alone, it becomes clear that only some categories get a better feature representation, and others get a worse feature representa-tion. At the same time, the boundaries between different datasets sometimes become more blurred, confounding the model’s predictions between them. Unfortunately, negative transfer dominates in practice, resulting in a significant drop in the test accuracy of the model on each dataset compared to training alone.
To make the erudite model more accurate, in this paper, we propose a feature disentanglement module and a fea-ture re-fusion module to balance the positive and negative transfer between different datasets. In detail, we decouple the deep features through many dataset-specific feature ex-tractors to obtain dataset-specific features, thus reducing the negative transfer. However, after decoupling the features, we need to know which dataset-specific classifier to use at the inference stage (but we cannot access the coarse-grained label of an object), and lost the positive transfer between datasets. Therefore, inspired by the mixture of experts (MoE) [26], we propose a gating-based feature re-fusion module to channel-wise re-fuse the dataset-specific features to facilitate positive transfer between different datasets. Fi-nally, we obtain features with higher inter-class variance and intra-class similarity while maintaining positive trans-fer and suppressing negative transfer between datasets.
Meanwhile, an advantage of joint training with many different datasets is that we have more training data.
Although the feature representations should be dataset-specific, salient feature localisation should be dataset-agnostic. Therefore, we can take full advantage of the in-creased training data to train the model to locate many dif-ferent discriminative regions. Naturally, we can use a tradi-tional spatial attention layer to locate regions that are useful for FGVC. However, directly applying a traditional spatial attention layer fails to work well due to domain-shift when training on different datasets [21, 28, 48]. To address this issue, we propose a meta-learning based spatial attention layer that drives the model to acquire a dataset-agnostic spa-tial attention that enhances the models’ localisation ability to further increase performance.
We demonstrate our resulting framework on 11 different mixed-datasets built on four different FGVC datasets, and show that it can easily be combined with existing FGVC methods to obtain state-of-the-art results. 2.