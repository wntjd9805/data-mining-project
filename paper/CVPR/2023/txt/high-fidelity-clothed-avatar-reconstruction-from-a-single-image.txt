Abstract
This paper presents a framework for efficient 3D clothed avatar reconstruction. By combining the advantages of the high accuracy of optimization-based methods and the ef-ficiency of learning-based methods, we propose a coarse-to-fine way to realize a high-fidelity clothed avatar recon-struction (CAR) from a single image. At the first stage, we use an implicit model to learn the general shape in the canonical space of a person in a learning-based way, and at the second stage, we refine the surface detail by esti-mating the non-rigid deformation in the posed space in an optimization way. A hyper-network is utilized to generate a good initialization so that the convergence o f the opti-mization process is greatly accelerated. Extensive exper-iments on various datasets show that the proposed CAR successfully produces high-fidelity avatars for arbitrarily clothed humans in real scenes. The codes will be released in https://github.com/TingtingLiao/CAR. 1.

Introduction
Clothed avatar reconstruction is critical to a variety of applications for 3D content creations such as video gaming, online meeting [54,55], virtual try-on and movie industry [10, 21, 39]. Early attempts are based on expensive scanning devices such as 3D and 4D scanners, or complicated multi-camera studios with carefully capturing processes. While highly accurate reconstruction results can be obtained from these recording equipment, they are inflexible and even not
*Equal contribution.
†Corresponding author. feasible in many applications. An alternative is to collect data using depth sensors [31, 42], which is however still less ubiquitous than RGB cameras. A more practical and low-cost way is to create an avatar from an image by RGB cameras or mobile phones.
Monocular RGB reconstruction [19, 37, 51, 59] has been extensively investigated and shows promising results.
ARCH [22] is the first method that reconstructs a clothed avatar from a monocular image. Due to the disadvantage of depth ambiguity, a number of methods that create an avatar from a video are proposed to resolve the problem. Most exist-ing monocular video-based methods [2, 3, 7, 9, 10, 14, 15, 46] are typically restricted to parametric human body prediction, which lacks geometry details like cloth surface. How to cre-ate a high-fidelity avatar from an in-the-wild image, with consistent surface details is still a great challenge.
In this work, we focus on the shape recovery and pro-pose an efficient high-fidelity clothed human avatar creation method from a single image in a coarse-to-fine way. The method consists of a learning-based canonical implicit model and an optimization-based normal refinement process. The canonical implicit model uses the canonical normal inverse transformed from original space as geometric feature to help grasp clothing detail of the general shape in canonical space.
Unlike occupancy-based methods [22, 36, 37], we adopt a
Signed Distance Function (SDF) to approximate the canoni-cal human body surface, which gains advantages in learning the human body in the surface level instead of the point level, so that the reconstruction accuracy is improved. In the normal refinement process, a SDF is learned to approxi-mates the target surface in the posed space by enforcing its surface normal closed to the predicted normal image. Com-pared with mesh-based refinement, our method can obtain
(a) Input (b) Posed Reconstruction (c) Canonical Reconstruction (d) Reposed
Figure 1. Images to avatars. Given an image of a person in an unconstrained pose (a), our method reconstructs 3D clothed avatars in both original posed space (b) and canonical space (c) and can repose the human body from the canonical mesh (d). more realistic results without artifacts due to the flexibility of implicit representation. Moreover, to learn the SDF of the normal refinement process efficiently, we propose a meta-learning-based hyper network for parameter initialization to accelerate the convergence of the normal refinement process.
Extensive experiments have been conducted on MVP-Human [60] and RenderPeople [1] datasets. Both qualita-tive and quantitative results demonstrate that our proposed method outperforms related avatar reconstruction methods.
The main contributions are summarized as follows:
• We propose a coarse-to-fine framework for efficient clothed avatar reconstruction from a single image.
Thanks to the integration of image and geometry fea-tures, as well as the meta-learning, it achieves high-fidelity clothed avatar reconstruction efficiently.
• We design the canonical implicit regression model and the normal refinement process. The former fuses all observations to the canonical space where the general shape of a person is depicted, and the latter learns pose dependent deformation.
• Results validate that our method could reconstruct high-quality 3D humans in both posed and canonical space from a single in-the-wild image. 2.