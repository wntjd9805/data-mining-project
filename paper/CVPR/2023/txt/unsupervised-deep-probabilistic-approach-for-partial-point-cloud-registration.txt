Abstract
Deep point cloud registration methods face challenges to partial overlaps and rely on labeled data. To address these issues, we propose UDPReg, an unsupervised deep probabilistic registration framework for point clouds with partial overlaps. Specifically, we first adopt a network to learn posterior probability distributions of Gaussian mix-ture models (GMMs) from point clouds. To handle partial point cloud registration, we apply the Sinkhorn algorithm to predict the distribution-level correspondences under the constraint of the mixing weights of GMMs. To enable unsu-pervised learning, we design three distribution consistency-based losses: self-consistency, cross-consistency, and local contrastive. The self-consistency loss is formulated by en-couraging GMMs in Euclidean and feature spaces to share identical posterior distributions. The cross-consistency loss derives from the fact that the points of two partially over-lapping point clouds belonging to the same clusters share the cluster centroids. The cross-consistency loss allows the network to flexibly learn a transformation-invariant pos-terior distribution of two aligned point clouds. The lo-cal contrastive loss facilitates the network to extract dis-criminative local features. Our UDPReg achieves competi-tive performance on the 3DMatch/3DLoMatch and Model-Net/ModelLoNet benchmarks. 1.

Introduction
Rigid point cloud registration aims at determining the optimal transformation to align two partially overlapping point clouds into one coherent coordinate system [21, 30– 32]. This task dominates the performance of systems in many areas, such as robotics [57], augmented reality [6], autonomous driving [35, 42], radiotherapy [27], etc. Re-cent advances have been monopolized by learning-based approaches due to the development of 3D point cloud rep-resentation learning and differentiable optimization [37].
Existing deep learning-based point cloud registration methods can be broadly categorized as correspondence-free [2, 21, 30, 32, 47] and correspondence-based [4, 9, 19, 50]. The former minimizes the difference between global features extracted from two input point clouds. These global features are typically computed based on all the points of a point cloud, making correspondence-free ap-proaches inadequate to handle real scenes with partial over-lap [9, 55]. Correspondence-based methods first extract lo-cal features used for the establishment of point-level [9, 17, 19,21] or distribution-level [15,29,39,52] correspondences, and finally, estimate the pose from those correspondences.
However, point-level registration does not work well un-der conditions involving varying point densities or repeti-tive patterns [31]. This issue is especially prominent in in-door environments, where low-texture regions or repetitive patterns sometimes dominate the field of view. Distribution-level registration, which compensates for the shortcomings of point-level methods, aligns two point clouds without es-tablishing explicit point correspondences. Unfortunately, to the best of our knowledge, the existing methods are inflex-ible and cannot handle point clouds with partial overlaps in real scenes [28, 31]. Moreover, the success of learning-based methods mainly depends on large amounts of ground truth transformations or correspondences as the supervision signal for model training. Needless to say, the required ground truth is typically difficult or costly to acquire, thus hampering their application in the real world [38].
We thus propose an unsupervised deep probabilistic reg-istration framework to alleviate these limitations. Specif-ically, we extend the distribution-to-distribution (D2D) method to solve partial point cloud registration by adopt-ing the Sinkhorn algorithm [11] to predict correspondences of distribution.
In order to make the network learn ge-ometrically and semantically consistent features, we de-sign distribution-consistency losses, i.e., self-consistency and cross-consistency losses, to train the networks without using any ground-truth pose or correspondences. Besides, we also introduce a local contrastive loss to learn more dis-criminative features by pushing features of points belong-ing to the same clusters together while pulling dissimilar features of points coming from different clusters apart.
Our UDPReg is motivated by OGMM [33] and
UGMM [20] but differs from them in several ways. Firstly, unlike OGMM, which is a supervised method, our approach is unsupervised. Secondly, while UGMM [20] treats all clusters equally in the matching process, our method aligns different clusters with varying levels of importance. This enables our approach to handle partial point cloud regis-tration successfully. To enable unsupervised learning, the designed self-consistency loss encourages the extracted fea-tures to be geometrically consistent by compelling the fea-tures and coordinates to share the posterior probability. The cross-consistency loss prompts the extracted features to be geometrically consistent by forcing the partially overlap-ping point clouds to share the same clusters. We evaluate our UDPReg on 3DMatch [53], 3DLoMatch [19], Model-Net [45] and ModelLoNet [19], comparing our approach against traditional and deep learning-based point cloud reg-istration approaches. UDPReg achieves state-of-the-art re-sults and significantly outperforms unsupervised methods on all the benchmarks.
In summary, the main contributions of this work are:
• We propose an unsupervised learning-based probabilistic framework to register point clouds with partial overlaps.
• We provide a deep probabilistic framework to solve par-tial point cloud registration by adopting the Sinkhorn al-gorithm to predict distribution-level correspondences.
• We formulate self-consistency, cross-consistency, and local-contrastive losses, to make the posterior probabil-ity in coordinate and feature spaces consistent so that the feature extractor can be trained in an unsupervised way.
• We achieve state-of-the-art performance on a compre-hensive set of experiments, including synthetic and real-world datasets1. 2.