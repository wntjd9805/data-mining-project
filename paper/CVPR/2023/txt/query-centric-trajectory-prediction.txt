Abstract
Predicting the future trajectories of surrounding agents is essential for autonomous vehicles to operate safely. This paper presents QCNet, a modeling framework toward push-ing the boundaries of trajectory prediction. First, we iden-tify that the agent-centric modeling scheme used by existing approaches requires re-normalizing and re-encoding the in-put whenever the observation window slides forward, lead-ing to redundant computations during online prediction.
To overcome this limitation and achieve faster inference, we introduce a query-centric paradigm for scene encoding, which enables the reuse of past computations by learning representations independent of the global spacetime coordi-nate system. Sharing the invariant scene features among all target agents further allows the parallelism of multi-agent trajectory decoding. Second, even given rich encodings of the scene, existing decoding strategies struggle to capture the multimodality inherent in agents’ future behavior, espe-cially when the prediction horizon is long. To tackle this challenge, we first employ anchor-free queries to generate trajectory proposals in a recurrent fashion, which allows the model to utilize different scene contexts when decod-ing waypoints at different horizons. A refinement module then takes the trajectory proposals as anchors and leverages anchor-based queries to refine the trajectories further. By supplying adaptive and high-quality anchors to the refine-ment module, our query-based decoder can better deal with the multimodality in the output of trajectory prediction. Our approach ranks 1st on Argoverse 1 and Argoverse 2 motion forecasting benchmarks, outperforming all methods on all main metrics by a large margin. Meanwhile, our model can achieve streaming scene encoding and parallel multi-agent decoding thanks to the query-centric design ethos. 1.

Introduction
Making safe decisions for autonomous vehicles requires accurate predictions of surrounding agents’ future trajec-tories. In recent years, learning-based methods have been
Illustration of our query-centric reference frame,
Figure 1. where we build a local coordinate system for each spatial-temporal element, including map polygons and agent states at all time steps.
In the attention-based encoder, all scene elements’ queries are de-rived and updated in their local reference frames. widely used for trajectory prediction [14, 31, 37, 38, 46, 56].
Despite the considerable efforts made to enhance models’ forecasting ability, there is still a long way to go before fully addressing the problem of trajectory prediction. Why is this task so challenging, and what inability lies in existing ap-proaches? We attempt to answer these questions from the following two perspectives: (i) While the flourishing forecasting models have achieved impressive performance on trajectory prediction benchmarks [7,13,49], today’s most advanced architectures specialized for this task [37, 38, 46, 56] fail to process the heterogeneous traffic scenes efficiently. In an autonomous driving system, data frames arrive at the prediction module sequentially as a stream of sparse scene context, including the high-definition vector map and the surrounding agents’ kinematic states. A model must learn expressive representa-tions of these scene elements to achieve accurate forecasts.
With the continuing development of modeling techniques for sparse context encoding [14, 31, 50], the research com-munity has witnessed rapid progress toward more powerful trajectory predictors. Notably, factorized attention-based
Transformers [37,38,56] have recently raised prediction ac-curacy to an unprecedented level. However, they require learning attention-based representations for each spatial-temporal scene element and suffer from prohibitively high costs when processing dense traffic scenes. As every mini-mal delay may lead to catastrophic accidents in autonomous driving, the unmet need for real-time predictions has limited the applicability of state-of-the-art approaches. (ii) The immense uncertainty in the output of trajectory prediction, which grows explosively as the prediction hori-zon lengthens, has troubled the research community con-stantly. For example, a vehicle at an intersection may turn or go straight depending on the driver’s long-term goal. To avoid missing any potential behavior, a model must learn to capture the underlying multimodal distribution rather than simply predicting the most frequent mode. This learning task is challenging since only one possibility is logged in each training sample. To ease the learning difficulty, a body of works utilizes handcrafted anchors as guidance for mul-timodal prediction [6, 12, 39, 53, 55]. Their effectiveness, however, is subject to the quality of the anchors. Typically, these methods fail to work well when few anchors can pre-cisely cover the ground truth. This problem is exacerbated in long-term prediction, where the search space for anchors is much larger. Some other works [10, 31, 38, 46, 56] cir-cumvent this issue by directly predicting multiple trajecto-ries, albeit at the risk of mode collapse and training instabil-ity [33, 41]. Due to the lack of spatial priors, these methods also fail to produce accurate long-term forecasts.
The analysis above drives us to propose a trajectory pre-diction framework, termed as QCNet, to overcome the lim-itations of previous solutions. First, we note that it is possi-ble to achieve faster online inference while also benefiting from the power of factorized attention, but the agent-centric encoding scheme [25, 27, 46, 56] used by existing methods serves as an impediment. Each time a new data frame ar-rives, the observation window slides one step forward and overlaps with its predecessor substantially, which provides opportunities for models to reuse the previously computed encodings. However, agent-centric approaches require nor-malizing the input based on the latest agent states’ positions, necessitating the re-encoding of scene elements whenever the observation window slides forward. To address this is-sue, we introduce a query-centric paradigm for scene en-coding (see Fig. 1). The crux of our design ethos lies in processing all scene elements in their local spacetime ref-erence frames and learning representations independent of the global coordinates. This strategy enables us to cache and reuse the previously computed encodings, spreading the computation across all observation windows and thereby re-ducing inference latency. The invariant scene features can also be shared among all target agents in the scene to en-able the parallelism of multi-agent decoding. Second, to better utilize the scene encodings for multimodal and long-term prediction, we use anchor-free queries to retrieve the scene context recurrently and let them decode a short seg-ment of future waypoints at each recurrence. This recurrent mechanism eases the modeling burden on the queries by al-lowing them to focus on different scene contexts when pre-dicting waypoints at different horizons. The high-quality trajectories predicted by the recurrent decoder serve as dy-namic anchors in the subsequent refinement module, where we use anchor-based queries to refine the trajectory propos-als based on the scene context. As a result, our query-based decoding pipeline incorporates the flexibility of anchor-free methods into anchor-based solutions, taking the best of both worlds to facilitate multimodal and long-term prediction.
Our proposed query-centric encoding paradigm is the first that can exploit the sequential nature of trajectory pre-diction to achieve fast online inference. Besides, our query-based decoder exhibits superior performance for multi-modal and long-term prediction. Experiments show that our approach achieves state-of-the-art results, ranking 1st on two large-scale motion forecasting benchmarks [7, 49]. 2.