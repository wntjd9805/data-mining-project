Abstract
Domain shift degrades the performance of object de-tection models in practical applications. To alleviate the influence of domain shift, plenty of previous work try to decouple and learn the domain-invariant (common) fea-tures from source domains via domain adversarial learn-ing (DAL). However, inspired by causal mechanisms, we find that previous methods ignore the implicit insignificant non-causal factors hidden in the common features. This is mainly due to the single-view nature of DAL. In this work, we present an idea to remove non-causal factors from com-mon features by multi-view adversarial training on source domains, because we observe that such insignificant non-causal factors may still be significant in other latent spaces (views) due to the multi-mode structure of data. To sum-marize, we propose a Multi-view Adversarial Discriminator (MAD) based domain generalization model, consisting of a
Spurious Correlations Generator (SCG) that increases the diversity of source domain by random augmentation and a
Multi-View Domain Classifier (MVDC) that maps features to multiple latent spaces, such that the non-causal factors are removed and the domain-invariant features are purified.
Extensive experiments on six benchmarks show our MAD obtains state-of-the-art performance. 1.

Introduction
The problem of how to adapt object detectors to un-known target domains in real world has drawn increasing attention. Traditional object detection methods [11, 12, 25, 29, 30] are based on independent and identically distributed (i.i.d.) hypothesis, which assume that the training and test-ing datasets have the same distribution. However, the target distribution can hardly be estimated in real world and dif-fers from the source domains, which is coined as domain
*Corresponding author (Lei Zhang)
Figure 1. Illustration of the biased learning of conventional DAL.
The domain classifier easily encounters early stop and fails. shift [38]. And the performance of object detection models will sharply drop when facing the domain shift problem.
Domain adaptation (DA) [3, 6, 17, 34, 40, 44, 52] is pro-posed to deal with the domain shift problem, which enables the model to be adapted to the target distribution by aligning features extracted from the source and unlabeled target do-mains. However, the requirement of target domain datasets still limits the applicability of DA methods in reality. Do-main generalization (DG) [49] goes one step further, aiming to train a model from single or multiple source domains that can generalize to unknown target domains.
Although lots of DG methods have been proposed in the image classification field, there are still some unresolved problems. In our opinion, the common features extracted by previous DG methods are still not pure enough. The main reason is that through a single-view domain discriminator in
DAL, only the significant domain style information can be removed, while some implicit and insignificant non-causal factors in source domains may be absorbed by the feature extractor as a part of common features. This has never been noticed. This implies the multi-mode structure of data and single-view domain discriminator cannot fully interpret the data. There is a piece of evidence to support our claim.
To confirm our suspicions on the domain discriminator, we designed a validation experiment. As is shown in Fig. 1,
Figure 2. Relationships among causal factors, noncausal factors, domain specific feature and domain common feature.
Figure 3. An illustration of the multi-view idea and effect of MAD.
Left: a toy example. Right: attention heatmaps of different views. we use DANN model [9] with DAL strategy to train a com-mon feature extractor. When domain classifier converges, we freeze feature extractor and re-train domain classifier with a newly added residual block [14]. We observe an interesting phenomenon: when re-trained with the newly added residual block, the domain classifier loss continues to decline. That is, some domain-specific information still exists. This phenomenon confirms our claim that in existing
DG, DAL cannot explore and remove all domain specific features. This is because domain classifier only observes significant domain-specific feature in a single-view, while insignificant domain specific features in one view (space) can be significant in other views (latent spaces).
Based on the former experiment, we propose that min-ing common features through DAL in single-view on a lim-ited number of domains is insufficient. By using traditional
DAL, only the primary style information w.r.t. domain la-bels can be removed. Here we analyse this problem from the perspective of causality. As shown in Fig. 2, in a lim-ited number of domains, the common features still contain non-causal factors such as light color, illumination, back-ground, etc., which is expressed as the orange arrows in the figure. And such insignificant non-causal factors observed from one view may still be significant uninformative fea-tures in other latent spaces (views). So a natural idea is to explore and remove the implicit non-causal information from multiple views and purify the common features for generalizing to unseen domains.
In order to remove the potential non-causal information, we rethink the domain discriminator in DAL and propose a multi-view adversarial domain discriminator (MAD) that can observe the implicit insignificant non-causal factors. In our life, in order to get the whole architecture of an object, we often need to observe it from multiple views/profiles. A toy example is shown in Fig. 3 (left part). When we observe the Penrose triangle from one specific view, we might mis-classify it as a triangle, ignoring that it might also appear to be L from another perspective. Following this intuition, we construct a Multi-View Domain Classifier (MVDC) that can discriminate features in multiple views. Specifically, we simulate multi-view observations by mapping the fea-tures to different latent spaces with auto-encoders [16], and discriminate these transformed features via multi-view do-main classifiers. By mining and removing as many non-causal factors as possible, MVDC encourages the feature extractor to learn more domain-invariant but causal factors.
We conduct an experiment based on MVDC and show the heatmaps from different views in Fig. 3 (right part), which verifies our idea that different noncausal factors can be un-veiled in different views.
Although the Multi-View Domain Classifier can remove the implicit non-causal features in principle, it still implies a sufficient diversity of source domains during training. So we further design a Spurious Correlation Generator (SCG) to increase the diversity of source domains. Our SCG gen-erates non-causal spurious connections by randomly trans-forming the low-frequency and extremely high-frequency components, as [19] points out that in the spectrum of im-ages, the extremely high and low frequency parts contain the majority of domain-specific components.
Combining MVDC and SCG, the Multi-view Adversar-ial Discriminator (MAD) is formalized. Cross-domain ex-periments on six standard datasets show our MAD achieves the SOTA performance compared to other mainstream
DGOD methods. The contributions are three-fold: 1. We point out that existing DGOD work focuses on ex-tracting common features but fails to mine and remove the potential spurious correlations from a causal perspective. 2. We propose a Multi-view Adversarial Discriminator (MAD) to eliminate implicit non-causal factors by discrim-inating non-causal factors from multiple views and extract-ing domain-invariant but causal features. 3. We test and analyze our method on standard datasets, verifying the effectiveness and superiority of our method. 2.