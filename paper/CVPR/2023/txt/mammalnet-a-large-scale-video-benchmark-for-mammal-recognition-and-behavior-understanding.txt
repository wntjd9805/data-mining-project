Abstract
Monitoring animal behavior can facilitate conservation efforts by providing key insights into wildlife health, popula-tion status, and ecosystem function. Automatic recognition of animals and their behaviors is critical for capitalizing on the large unlabeled datasets generated by modern video devices and for accelerating monitoring efforts at scale. However, the development of automated recognition systems is cur-rently hindered by a lack of appropriately labeled datasets.
Existing video datasets 1) do not classify animals according to established biological taxonomies; 2) are too small to fa-cilitate large-scale behavioral studies and are often limited to a single species; and 3) do not feature temporally local-∗Equal contribution. ized annotations and therefore do not facilitate localization of targeted behaviors within longer video sequences. Thus, we propose MammalNet, a new large-scale animal behav-ior dataset with taxonomy-guided annotations of mammals and their common behaviors. MammalNet contains over 18K videos totaling 539 hours, which is ∼10 times larger than the largest existing animal behavior dataset [36]. It covers 17 orders, 69 families, and 173 mammal categories for animal categorization and captures 12 high-level animal behaviors that received focus in previous animal behavior studies. We establish three benchmarks on MammalNet: standard animal and behavior recognition, compositional low-shot animal and behavior recognition, and behavior detection. Our dataset and code have been made available at: https://mammal-net.github.io.
1.

Introduction
Animal species are a core component of the world’s ecosystems. Through their behavior, animals drive diverse ecological processes, including seed dispersal, nutrient cy-cling, population dynamics, speciation, and extinction. Thus, understanding and monitoring the behaviors of animals and their interactions with their physical and social environ-ments is key to understanding the complexities of the world’s ecosystems, an objective that is especially critical now given the ongoing biodiversity crisis [12].
Modern sensors, including camera traps, drones, and smartphones, allow wildlife researchers, managers, and cit-izen scientists to collect video data of animal behavior on an unprecedented scale [43]. However, processing this data to generate actionable, timely insights remains a major chal-lenge. Manual human review and annotation of footage to identify and locate species and behavioral sequences of in-terest is time-intensive and does not scale to large datasets.
Thus, methods for automated animal and behavioral recogni-tion could open the door to large-scale behavioral monitoring and speed up the time to produce usable data, thereby reduc-ing the time to implement management directives.
The first essential step to creating such an AI system for animal and behavior recognition is curating a diverse, repre-sentative dataset that allows us to formalize these challenges as computer vision tasks and benchmark potential solutions.
Most previous datasets either only cover a limited number of animal and behavior types [4, 38], or do not implement animal labeling [36], or include a small number of videos with insufficient environmental diversity [4,38,48]. Recently, a dataset named “Animal Kingdom” [36] was proposed to study animal actions and is currently the largest existing behavioral dataset, to the best of our knowledge. However, it only contains 4,310 videos totaling 50 hours, which might be insufficient for large-scale animal behavior studies consider-ing its diversity. Furthermore, the authors only focus on the recognition of atomic actions such as yawning, swimming, and flying. These basic actions cannot be easily matched to the higher-order behavioral states that are of primary interest to end users in animal management and conservation [6].
For example, a cheetah that is running may either be hunting, escaping, or playing. Finally, and most importantly, they do not support some important tasks such as animal recogni-tion and behavior detection which are essential for animal behavior understanding.
To overcome the limitations of previous datasets, we pro-pose a new dataset called MammalNet. We specifically focus on mammals since they, unlike other animal classes such as birds or insects, usually have more diverse and distin-guishable behavior statuses. MammalNet is comprised of 539 hours of annotated videos, which is ∼10 times longer than that of the largest available animal behavior dataset. It contains 18,346 videos depicting 12 fundamental high-level behaviors from hundreds of mammal species. Importantly, it focuses on 12 higher-order animal behaviors that are the fo-cus of previous animal behavior literature [3,8,17,33], rather than atomic actions. MammalNet also categorizes animals according to the scientific taxonomy available in Wikipedia, as we show in Fig. 1; hence the dataset can be flexibly ex-panded in the future by following the same protocols. It includes videos of approximately 800 mammal species in 173 mammal categories. We establish three benchmarks inspired by ecological research needs - standard animal & behavior classification, compositional low-shot animal & behavior recognition, and behavior detection – to promote future study in animal behavior understanding.
Through our experiments, we find that: (1) Correctly rec-ognizing the animals and behaviors is a challenging task even for the state-of-the-art models, especially for less-frequent animals. The top-1 per-class accuracy is 32.5 for animal recognition, 37.8 for behavior recognition, and 17.8 for their joint recognition in our best-performing model. (2) Behavior recognition for unseen animals can be transferred from ob-servations of other seen animals due to their similar features such as appearance and movement style, which can help in studies of animals with less available data. However, to achieve more accurate behavior recognition, having access to videos of the target animals and behaviors is still crucial. 2.