Abstract
Domain generalization (DG) tends to alleviate the poor generalization capability of deep neural networks by learn-ing model with multiple source domains. A classical solution to DG is domain augmentation, the common belief of which is that diversifying source domains will be conducive to the out-of-distribution generalization. However, these claims are understood intuitively, rather than mathematically. Our explorations empirically reveal that the correlation between model generalization and the diversity of domains may be not strictly positive, which limits the effectiveness of domain aug-mentation. This work therefore aim to guarantee and further enhance the validity of this strand. To this end, we propose a new perspective on DG that recasts it as a convex game be-tween domains. We ﬁrst encourage each diversiﬁed domain to enhance model generalization by elaborately designing a regularization term based on supermodularity. Meanwhile, a sample ﬁlter is constructed to eliminate low-quality samples, thereby avoiding the impact of potentially harmful informa-tion. Our framework presents a new avenue for the formal analysis of DG, heuristic analysis and extensive experiments demonstrate the rationality and effectiveness. 1 1.

Introduction
Owning extraordinary representation learning ability, deep neural networks (DNNs) have achieved remarkable success on a variety of tasks when the training and test data are drawn from the same distribution [9, 11, 16]. Whereas for out-of-distribution data, DNNs have demonstrated poor generalization capability since the i.i.d. assumption is vio-lated, which is common in real-world conditions [27, 28, 42].
To tackle this issue, domain generalization (DG) has become a propulsion technology, aiming to learn a robust model from multiple source domains so that can generalize well to any unseen target domains with different statistics [2, 19, 22, 30].
Among extensive solutions to improve generalization, do-main augmentation [39, 46, 48, 56] has been a classical and
∗ Corresponding author. 1 Code is available at "https://github.com/BIT-DA/DCG". (a) Cartoon. (b) Sketch.
Figure 1. The relation between model generalization and domain diversity with Cartoon and Sketch on PACS dataset as the un-seen target domain, respectively. N is the maximum number of augmented domains. Note that the solid lines denote the actual re-sults of a BASELINE method that combines DeepAll with Fourier augmentation strategy and a SOTA domain augmentation method
FACT, while the dash lines represent the ideal relation in this work. prevalent strategy, which focuses on exposing the model with more diverse domains via some augmentation techniques.
A common belief is that generalizable models would be-come easier to learn when the training distributions become more diverse, which has been also emphasized by a recent work [47]. Notwithstanding the promising results shown by this strand of approaches, the claims above are vague and lack of theoretical justiﬁcation, formal analyses of the relation between domain diversity and model generalization are sparse. Further, the transfer of knowledge may even hurt the performance on target domains in some cases, which is referred to as negative transfer [33, 41]. Thus the relation of domain diversity and model generalization remains unclear.
In light of these points, we begin by considering the question:
The stronger the domain diversity, will it certainly help to improve the model generalization capability?
To explore this issue, we ﬁrst quantify domain diversity as the number of augmented domains. Then we conduct a brief experiment using Fourier augmentation strategy [48] as a classical and representative instance. The results presented in Fig 1 show that with the increase of domain diversity, the model generalization (measured by the accuracy on unseen target domain) may not necessarily increase, but sometimes decreases instead, as the solid lines show. On the one hand,
this may be because the model does not best utilize the rich information of diversiﬁed domains; on the other hand, it may be due to the existence of low-quality samples which contain redundant or noisy information that is unproﬁtable to generalization [18]. This discovery indicates that there is still room for improvement of the effectiveness of do-main augmentation if we enable each domain to be certainly conducive to model generalization as the dash lines in Fig 1.
In this work, we therefore aim to ensure the strictly posi-tive correlation between model generalization and domain diversity to guarantee and further enhance the effectiveness of domain augmentation. To do this, we take inspiration from the literature of convex game that requires each player to bring proﬁt to the coalition [4, 13, 40], which is consistent to our key insight, i.e, make each domain bring beneﬁt to model generalization. Thus, we propose to formalize DG as a convex game between domains. First, we design a novel regularization term based on the supermodularity of convex game. This regularization encourages each diversiﬁed do-main to contribute to improving model generalization, thus enables the model to better exploit the diverse information.
In the meawhile, considering that there may exist samples with unproﬁtable or even harmful information to general-ization, we further construct a sample ﬁlter based on the proposed regularization to get rid of the low-quality samples such as noisy or redundant ones, so that their deterioration to model generalization can be avoided. We provide some heuristic analyses and intuitive explanations about the mech-anisms behind to demonstrate the rationality in Section 4.
Nevertheless, it is well known that the supermodularity also indicates increasing marginal contribution, which may not hold intuitively in DG, where the marginal contribution of domains is generally decreasing. To mitigate the gap be-tween theory and practice, we impose a constraint on the naive supermodularity when construct our regularization term. We constrain the regularization to work only in case that the supermodularity is violated, i.e., when the marginal contribution of domains decreases. Thus, the limit of our regularization optimization is actually to achieve a constant marginal contribution, rather than an impracticable increas-ing marginal contribution. Hence, our regularization can additionally regularize the decreasing speed of the marginal contribution as slow as possible by optimizing towards the constant marginal contribution, just like changing the line
Ideal (a) in Fig 1 into line Ideal (b). Generally, the role of our proposed supermodularity regularization is to encour-age the contribution of each domain, and further relieve the decreasing marginal contribution of domains to a certain extent, so as to better utilize the diversiﬁed information.
Contributions. Our contributions in this work include: (i) Exploring the relation of model generalization and source domain diversity, which reveals the limit of previous domain augmentation strand; (ii) Introducing convex game into DG to guarantee and further enhance the validity of domain augmentation. The proposed framework encourages each domain to conducive to generalization while avoiding the negative impact of low-quality samples, enabling the model to better utilize the information within diversiﬁed domains; (iii) Providing heuristic analysis and intuitive explanations about the rationality. The effectiveness and superiority are veriﬁed empirically across extensive real-world datasets. 2.