Abstract
We propose a method for in-hand 3D scanning of an un-known object with a monocular camera. Our method re-lies on a neural implicit surface representation that cap-tures both the geometry and the appearance of the object, however, by contrast with most NeRF-based methods, we do not assume that the camera-object relative poses are known.
Instead, we simultaneously optimize both the object shape and the pose trajectory. As direct optimization over all shape and pose parameters is prone to fail without coarse-level initialization, we propose an incremental approach that starts by splitting the sequence into carefully selected overlapping segments within which the optimization is likely to succeed. We reconstruct the object shape and track its poses independently within each segment, then merge all the segments before performing a global optimization. We show that our method is able to reconstruct the shape and color of both textured and challenging texture-less objects, outperforms classical methods that rely only on appearance features, and that its performance is close to recent methods that assume known camera poses. 1.

Introduction
Reconstructing 3D models of unknown objects from multi-view images is a computer vision problem which has received considerable attention [8]. With a single camera, a user can capture multiple views of an object by manually moving the camera around a static object [22, 26, 43] or by turning the object in front of the camera [27, 31, 35, 36].
The latter approach is often referred to as in-hand object scanning and is convenient for reconstructing objects from cameras mounted on an AR/VR headset such as Microsoft
HoloLens or Meta Quest. Moreover, this approach can re-construct the full object surface, including the bottom part
*Work done as part of Shreyas’s PhD thesis at TU Graz, Austria.
Figure 1. Given an RGB sequence of a hand manipulating an un-known object, our method reconstructs the 3D shape and color of the object, even if the object surface is non-Lambertian or poorly textured. We first split the input sequence into multiple overlap-ping segments (two in this figure) in which the object can be re-liably reconstructed and tracked. We then use the tracked object-camera relative poses to initialize a global optimization that pro-duces the final object model and refined pose trajectory. which cannot be scanned in the static-object setup.
Recent 3D reconstruction methods rely on neural rep-resentations [19, 21–23, 42, 43]. By contrast with earlier re-construction methods [9], the recent methods can provide an accurate dense 3D reconstruction even in non-Lambertian conditions and without any prior knowledge of the object shape. However, most of these methods assume that the camera poses are provided, typically by Structure-from-Motion (SfM) methods such as COLMAP [29]. Apply-ing SfM methods to in-hand object scanning is problem-atic as these methods require a sufficient number of distinct visual features and can thus handle well only textured ob-jects. NeRF-based methods such as [13, 15, 16, 34], which simultaneously estimate the radiance field of the object and the camera poses without requiring initialization from
COLMAP, are restricted to forward-facing camera captures.
As we experimentally demonstrate, these methods fail to converge if the images cover a larger range of viewpoints, which is typical for in-hand scanning.
We propose a method for in-hand object scanning from an RGB image sequence with unknown camera-object rel-ative poses. We rely on a neural representation that cap-tures both the geometry and the appearance of the object and therefore enables reconstructing even poorly textured objects, as shown in Fig. 1. By contrast with most NeRF-based methods, we do not assume that the camera poses are available and instead simultaneously optimize both the ob-ject model and the camera trajectory. As global optimiza-tion over all input frames is prone to fail, we propose an incremental optimization approach. We start by splitting the sequence into carefully selected overlapping segments within which the optimization is likely to succeed. We then optimize our objective for incremental object reconstruction and pose tracking within each segment independently. The segments are then combined by aligning poses estimated at the overlapping frames, and we finally optimize the objec-tive globally over all frames of the input sequence to achieve complete object reconstruction.
Note that we do not make any assumptions on the type of hand-object grasps and also consider scenarios where the grasping is dynamic, i.e., contact points continuously change, which corresponds to natural hand-object interac-tions. This is in contrast with the recent work [11] that con-siders only static grasps. In fact, we refrain from consid-ering hand poses in our method as they cannot be reliably estimated under occlusion in case of dynamic grasps, which could lead to incorrect object reconstruction.
We experimentally demonstrate that the proposed method is able to reconstruct the shape and color of both textured and challenging texture-less objects. We evaluate the method on datasets HO-3D [7], RGBD-Obj [32] and on the newly captured sequences with challenging texture-less objects. We show that the proposed method achieves higher-quality reconstruction than COLMAP [29], which fails to estimate the object poses in the case of poorly tex-tured objects and is in par with a strong baseline method which uses ground-truth object poses. Our method also outperforms a very recent single-image based object recon-struction method [44], even though this method is trained on sequences of the same object. We also demonstrate the real-world applicability of our method by in-hand scanning an object with ARIA glasses [18] (see supplement). 2.