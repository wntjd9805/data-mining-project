Abstract 3D object detectors usually rely on hand-crafted prox-ies, e.g., anchors or centers, and translate well-studied 2D frameworks to 3D. Thus, sparse voxel features need to be densified and processed by dense prediction heads, which
In this paper, we in-inevitably costs extra computation. stead propose VoxelNext for fully sparse 3D object detec-tion. Our core insight is to predict objects directly based on sparse voxel features, without relying on hand-crafted proxies. Our strong sparse convolutional network Vox-elNeXt detects and tracks 3D objects through voxel fea-tures entirely.
It is an elegant and efficient framework, with no need for sparse-to-dense conversion or NMS post-processing. Our method achieves a better speed-accuracy trade-off than other mainframe detectors on the nuScenes dataset. For the first time, we show that a fully sparse voxel-based representation works decently for LIDAR 3D object detection and tracking. Extensive experiments on nuScenes,
Waymo, and Argoverse2 benchmarks validate the effective-ness of our approach. Without bells and whistles, our model outperforms all existing LIDAR methods on the nuScenes tracking test benchmark. Code and models are available at github.com/dvlab-research/VoxelNeXt. 1.

Introduction 3D perception is a fundamental component in au-tonomous driving systems. 3D detection networks take sparse point clouds or voxels as input, and localize and cat-egorize 3D objects. Recent 3D object detectors [40, 49, 57] usually apply sparse convolutional networks (Sparse
CNNs) [53] for feature extraction owing to its efficiency.
Inspired by 2D object detection frameworks [14, 38], an-chors [12, 53] or centers [57], i.e., dense point anchors in CenterPoint [57], are commonly utilized for prediction.
Both of them are hand-crafted and taken as intermediate proxies for 3D objects.
Anchors and centers are designed for regular and grid-structured image data in the first place, and do not consider sparsity and irregularity of 3D data. To employ these proxy representations, the main stream of detectors [12, 40, 57]
Figure 1. Visualization of input and heatmaps of CenterPoint in
BEV for Car. Most values in the heatmaps are nearly zero, while the dense head computes over all BEV features, which is wasteful. convert 3D sparse features to 2D dense features, so as to build a dense detection head for the ordered anchors or centers. Albeit useful, this dense head tradition leads to other limitations, including inefficiency and complicated pipelines, as explained below.
In Fig. 1, we visualize the heatmap in CenterPoint [57].
It is clear that a large portion of space has nearly zero pre-diction scores. Due to inherent sparsity and many back-ground points, only a small number of points have re-sponses, i.e., less than 1% for Car class on average of nuScenes validation set. However, the dense prediction head computes over all positions in the feature map, as re-quired by the dense convolution computation. They not only waste much computation, but also complicate detec-tion pipelines with redundant predictions. It requires to use non-maximum suppression (NMS) like post-processing to remove duplicate detections, preventing the detector from being elegant. These limitations motivate us to seek alter-native sparse detection solutions.
In this paper, we instead propose VoxelNeXt.
It is a simple, efficient, and post-processing-free 3D object detec-tor. The core of our design is a voxel-to-object scheme, which directly predicts 3D objects from voxel features, with a strong fully sparse convolutional network. The key ad-vantage is that our approach can get rid of anchor proxies, sparse-to-dense conversion, region proposal networks, and
Figure 2. Pipelines of mainstream 3D object detectors and VoxelNeXt. These 3D detectors [12, 40, 57] rely on sparse-to-dense conversion, anchors/centers, and dense heads with NMS. RoI pooling is an option for two-stage detectors [12, 40]. In contrast, VoxelNeXt is a fully sparse convolutional network, which predicts results directly upon voxel features, with either fully connected layers or sparse convolutions. other complicate components. We illustrates the pipelines of mainstream 3D detectors and ours in Fig. 2.
High inference efficiency is due to our voxel-to-object scheme avoiding dense feature maps. It predicts only upon sparse and necessary locations, as listed in Tab. 1 with com-parison to CenterPoint [57]. This representation also makes
VoxelNeXt easily extended to 3D tracking with an offline tracker. Previous work [57] only tracks for the predicted object centers, which might involve prediction bias to its positions. In VoxelNeXt, the query voxels, i.e., the voxels for box prediction, can also be tracked for association.
Recently, FSD [16] exploits the fully sparse framework.
Motivated by VoteNet [36], it votes for object centers and resorts to iterative refinement. Since 3D sparse data is gen-erally scattered on object surfaces, this voting process in-evitably introduces bias or error. Consequently, refinement, such as iterative group correction, is needed to ensure final accuracy. The system is complicated by its heavy belief in object centers. FSD [16] is promising at the large-range Ar-goverse2, while its efficiency is inferior to ours, as in Fig. 3.
To demonstrate the effectiveness of VoxelNeXt, we evaluate our models on three large-scale benchmarks of nuScenes [3], Waymo [44], Argoverse2 [52] datasets. Vox-elNeXt achieves leading performance with high efficiency on 3D object detection on both these benchmarks. It also yields state-of-the-art performance on 3D tracking. With-out bells and whistles, it ranks 1st among all LIDAR-only entries on the nuScenes tracking test split [3]. 2.