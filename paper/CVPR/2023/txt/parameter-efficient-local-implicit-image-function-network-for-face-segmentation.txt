Abstract
Face parsing is defined as the per-pixel labeling of im-ages containing human faces. The labels are defined to identify key facial regions like eyes, lips, nose, hair, etc.
In this work, we make use of the structural consistency of the human face to propose a lightweight face-parsing method using a Local Implicit Function network, FP-LIIF.
We propose a simple architecture having a convolutional encoder and a pixel MLP decoder that uses 1/26th num-ber of parameters compared to the state-of-the-art models and yet matches or outperforms state-of-the-art models on multiple datasets, like CelebAMask-HQ and LaPa. We do not use any pretraining, and compared to other works, our network can also generate segmentation at different reso-lutions without any changes in the input resolution. This work enables the use of facial segmentation on low-compute or low-bandwidth devices because of its higher FPS and smaller model size. 1.

Introduction
Face parsing is the task of assigning pixel-wise labels to a face image to distinguish various parts of a face, like eyes, nose, lips, ears, etc. This segregation of a face image enables many use cases, such as face image editing [20, 46, 57], face e-beautification [37], face swapping [16, 35, 36], face completion [23].
Since the advent of semantic segmentation through the use of deep convolutional networks [31], a multitude of research has investigated face parsing as a segmentation problem through the use of fully convolutional networks
[13, 14, 25, 26, 28, 29].
In order to achieve better results, some methods [14, 28] make use of conditional random fields (CRFs), in addition to CNNs. Other methods [25,27],
*Work done during internship at Adobe
Figure 1. The simple architecture of Local Implicit Image repre-sentation base FP-LIIF: A light convolutional encoder of modified resblocks followed by a pixel only MLP decoder focus on a two-step approach that predicts bounding boxes of facial regions (nose, eyes, hair. followed by segmentation within the extracted regions. Later works like AGRNET [48] and EAGR [49] claim that earlier ap-proaches do not model the relationship between facial com-ponents and that a graph-based system can model these statistics, leading to more accurate segmentation. etc.)
In more recent research, works such as FaRL [59] in-vestigate pretraining on a human face captioning dataset.
They pre-train a Vision Transformer (ViT) [8] and finetune on face parsing datasets and show improvement in com-parison to pre-training with classification based pre-training like ImageNet [44], etc., or no pre-training at all. The cur-rent state-of-the-art model, DML CSR [58], tackles the face parsing task using multiple concurrent strategies including multi-task learning, graph convolutional network (GCN), and cyclic learning. The Multi-task approach handles edge discovery in addition to face segmentation. The proposed
GCN is used to provide global context instead of an aver-age pooling layer. Additionally, cyclic learning is carried out to arrive at an ensemble model and subsequently per-form self-distillation using the ensemble model in order to learn in the presence of noisy labels.
In this work, we perform face segmentation by taking advantage of the consistency seen in human facial struc-tures. We take our inspiration from various face modeling works [1, 12, 61] that can reconstruct a 3D model of a face from 2D face images. These works show it is possible to create a low-dimensional parametric model of the human face in 3D. This led us to conclude that 2D modeling of the human face should also be possible with low dimen-sion parametric model. Recent approaches, like NeRF [34] and Siren [47] demonstrated that it is possible to reconstruct complex 3D and 2D scenes with implicit neural represen-tation. Many other works [2, 11, 43, 56] demonstrate that implicit neural representation can also model faces both in 3D and 2D. However, to map 3D and 2D coordinates to the RGB space, the Nerf [34] and Siren [47] variants of the models require training a separate network for every scene.
This is different from our needs, one of which is that we must map an RGB image into label space and require a sin-gle network for the whole domain. That brings us to another method known as LIIF [3], which is an acronym for a Lo-cal Implicit Image Function and is used to perform image super-resolution. They learn an approximation of a contin-uous function that can take in any RGB image with low res-olution and output RGB values at the sub-pixel level. This allows them to produce an enlarged version of the input im-age. Thus, given the current success of learning implicit representations and the fact that the human face could be modeled using a low-dimension parametric model, we came to the conclusion that a low parameter count LIIF-inspired model should learn a mapping from a face image to its la-bel space or segmentation domain. In order to test this hy-pothesis, we modify a low-parameter version of EDSR [24] encoder such that it can preserve details during encoding.
We also modify the MLP decoder to reduce the comput-ing cost of our decoder. Finally, we generate a probability distribution in the label space instead of RGB values. We use the traditional cross-entropy-based losses without any complicated training mechanisms or loss adaptations. An overview of the architecture is depicted in Figure 1, and more details are in Section 3. Even with a parameter count that is 1/26th compared to DML CSR [58], our model at-tains state-of-the-art F1 and IoU results for CelebAMask-HQ [21] and LaPa [29] datasets. Some visualizations of our outputs are shared in Figure 3 and Figure 4.
To summarise, our key contributions are as follows:
• We propose an implicit representation-based simple and lightweight neural architecture for human face se-mantic segmentation.
• We establish new state-of-the-art mean F1 and mean
IoU scores on CelebAMask-HQ [21] and LaPa [29].
• Our proposed model has a parameter count of 1/26th or lesser compared to the previous state-of-the-art model. Our model’s SOTA configuration achieves an
FPS of 110 compared to DML CSR’s FPS of 76. 2.