Abstract
For a long time, the most common paradigm in Multi-Object Tracking was tracking-by-detection (TbD), where objects are first detected and then associated over video frames. For association, most models resourced to motion and appearance cues, e.g., re-identification networks.
Recent approaches based on attention propose to learn the cues in a data-driven manner, showing impressive
In this paper, we ask ourselves whether simple results. good old TbD methods are also capable of achieving the performance of end-to-end models.
To this end, we propose two key ingredients that allow a standard re-identification network to excel at appearance-based tracking. We extensively analyse its failure cases, and show that a combination of our appearance features with a simple motion model leads to strong tracking results. Our tracker generalizes to four public datasets, namely MOT17,
MOT20, BDD100k, and DanceTrack, achieving state-of-the-art performance. https://github.com/dvl-tum/GHOST. 1.

Introduction
Multi-Object Tracking (MOT) aims at finding the trajectories of all moving objects in a video. The dominant paradigm in the field has long been tracking-by-detection, which divides tracking into two steps: (i) frame-wise object detection, (ii) data association to link the detections and form trajectories. One of the simplest forms of data association for online trackers is frame-by-frame matching using the Hungarian algorithm [26]. Matching is often driven by cues such as appearance, e.g., re-identification (reID) features [11, 20, 35, 45, 57, 59, 75], or motion cues
[4, 42, 47, 65, 74]. Even recent trackers propose data-driven motion priors [4, 54, 64, 79] or appearance cues, which may include external reID models [4, 64].
Most recent trackers based on Transformers [36, 56, 71] learn all necessary cues from data through self- and cross-attention between frames and tracked objects. While this implicitly gets rid of any heuristic typically embedded in
*Correspondance to j.seidenschwarz@tum.de.
†Currently at NVIDIA.
IDF1/Rank-1 of different state-of-the-art
Figure 1. re-ID approaches. R50-TR [78], BOT [35], BDB [14], ABD [10]. Basic is our baseline, Ours is our appearance model. the handcrafted appearance and motion cues, and could be the path to more general trackers, the training strategies are highly complex and the amount of data needed to train such models is very large, to the point where MOT datasets
[15] are not enough and methods rely on pre-training on detection datasets such as CrowdHuman [52].
While interesting and challenging from a research point of view, it is questionable whether we should also follow the path of learning everything in multi-object tracking, when there are strong priors that we know how to define and leverage, such as the good old appearance and motion cues. As we show in this paper, there are key observations that need to be made in order to properly leverage such cues.
These observations might seem simple and obvious but have been largely overlooked by the community.
If we spend as much time in properly understanding and implementing such cues as we do in training Transformers, we will be rewarded with a simple Hungarian tracker with appearance and motion cues that still dominates state-of-the-art on multiple benchmarks, and does not even need to be trained on any tracking data.
Our first observation is that simply using state-of-the-art re-identification (reID) networks for appearance matching is not enough for the real scenarios of MOT.
In Figure 1, we visualize the performance of several state-of-the-art reID approaches on Market-1501 dataset
[77] (x-axis), as well as the model’s performance when used in a simple matching-based tracker (y-axis).
It the reID performance does not necessarily shows that translate to MOT performance. We identify two problems causing the weak performance of reID models on MOT: (i) 1
reID models need to account for the different challenges expected at different time horizons, i.e., while in nearby frames appearance of objects will vary minimally, in longer time gaps more severe changes are expected, e.g., caused by (partial-) occlusions and (ii) reID performance tends to be inconsistent across MOT sequences because of their varying image statistics, which in turn differs from the relatively stable conditions of the corresponding reID training dataset. We propose two simple but key design choices to overcome the aforementioned problems, i.e., on-the-fly domain adaptation, and different policies for active and inactive tracks. Moreover, we conduct an extensive analysis under different conditions of visibility, occlusion time, and camera movement, to determine in which situations reID is not enough and we are in need of a motion model. We combine our reID with a simple linear motion model using a weighted sum so that each cue can be given more weight when needed for different datasets.
Our findings culminate in our proposed Good Old
Hungarian Simple Tracker or GHOST (the order of the letters of the acronym does not change the product) remarkably that generalizes to four different datasets, outperforming the state-of-the-art while, most notably, never being trained on any tracking dataset.
In summary, we make the following contributions:
• We provide key design choices that significantly boost the performance of reID models for the MOT task.
• We extensively analyze in which underlying situations appearance is not sufficient and when it can be backed up by motion.
• We generalize to four datasets achieving state-of-the-art performance by combining appearance and motion in our simple and general TbD online tracker GHOST. the importance of domain adaptation,
With this paper, we hope to show the importance of domain-specific knowledge and the impact it can have, even on the simple good old models. Our observations, i.e., the different handling of short- and long-term associations as well as the interplay between motion and appearance are straightforward, almost embedded into the subconscious of the tracking community, and yet they have largely been overlooked by recent methods.
Introducing our simple but strong tracker, we hope our observations will inspire future work to integrate such observations into sophisticated models further improving the state of the art, in a solution where data and priors will gladly meet. 2.