Abstract
Domain generalization (DG) is a principal task to eval-uate the robustness of computer vision models. Many previ-ous studies have used normalization for DG. In normaliza-tion, statistics and normalized features are regarded as style and content, respectively. However, it has a content vari-ation problem when removing style because the boundary between content and style is unclear. This study addresses this problem from the frequency domain perspective, where amplitude and phase are considered as style and content, respectively. First, we verify the quantitative phase varia-tion of normalization through the mathematical derivation of the Fourier transform formula. Then, based on this, we propose a novel normalization method, P CN orm, which eliminates style only as the preserving content through spec-tral decomposition. Furthermore, we propose advanced
P CN orm variants, CCN orm and SCN orm, which ad-just the degrees of variations in content and style, respec-tively. Thus, they can learn domain-agnostic representa-tions for DG. With the normalization methods, we propose
ResNet-variant models, DAC-P and DAC-SC, which are ro-bust to the domain gap. The proposed models outperform other recent DG methods. The DAC-SC achieves an aver-age state-of-the-art performance of 65.6% on five datasets:
PACS, VLCS, Office-Home, DomainNet, and TerraIncog-nita. 1.

Introduction
Deep learning has performed remarkably well in various computer vision tasks. However, the performance decreases when distribution-shifted test data are given [39]. As train-ing and testing datasets are assumed to be identically and independently distributed, common vision models are not
*Equal contribution
†Corresponding author
Figure 1. Concepts of (a) the existing normalization and (b) the proposed methods. Our methods prevent or adjust the content change caused by existing normalization using spectral decom-position. The solid line marks the feedforward process and the dashed line conceptually represents the content and style of the feature. Red-colored star and doughnut in (b) indicate the content and style adjusting terms, respectively. as robust as the human vision system, which is not confused by affordable changes in the image style [14]. Domain gen-eralization (DG) aims to learn models that are robust to the gap between source domain and unseen target domain to address this problem [49]. Moreover, DG is challenging be-cause models should learn domain-irrelevant representation in an unsupervised manner.
The style-based approach is widely studied for DG, which defines the domain gap as the difference in style
[19, 31, 51, 56, 57]. Typically, normalization methods, such as batch normalization (BN) [18], layer normalization (LN)
[18], and instance normalization (IN) [45], which are well-known in style transfer, are used in this approach. Normal-ization statistics contain style information, and normaliza-tion can successfully extract the style from a feature. How-ever, the content is also changed when the style is elimi-nated [15, 19, 34].
Moreover, another method for style-based DG [7, 48, 50, 51] is the frequency domain-based method. Input images are decomposed into amplitude and phase using the Fourier transform (FT) [4]. The amplitude and phase are each re-garded as the style and content of the input image, respec-tively [7, 33, 37, 51, 53]. Each component is manipulated independently to generate the style-transformed image. In this context, this method has an advantage of the separation between style and content [56]. Nevertheless, most previous studies have applied it to just the input-level data augmen-tation [7, 51, 53] for DG.
Thus, the normalization is expected to be complemented by the frequency domain-based method if the method is also applicable at the feature level. To identify the feasibility of this, we conduct a style transfer experiment. We replace IN in AdaIN [15], a milestone work that uses normalization in style transfer, with spectral decomposition. The qualitative results in Fig. 2 indicate that the frequency domain-based method can work as a feature-level style-content separator instead of normalization.
Motivated by this, we aim to overcome the content change problem in normalization by combining the normal-ization with spectral decomposition. The overall concept of our proposed method is visualized in Fig. 1. For this, we investigate the effect of the existing normalization in DG from the standpoint of the frequency domain. We verify how normalization transforms the content of a feature by mathematically deriving the FT formula. This is the first to present such an analysis.
Then, based upon the analysis, we introduce a novel normalization method, phase-consistent normaliza-tion (P CN orm), which preserves the content of a pre-normalized feature. The P CN orm synthesizes a content-invariant normalized feature by composing the phase of pre-normalized feature and the amplitude of post-normalized feature. The experimental results reveal the effectiveness of P CN orm in DG compared to existing normalization.
Along with the success of P CN orm, we take a step further and propose two advanced P CN orm variants: content-controlling normalization (CCN orm) and style-controlling normalization (SCN orm). The main idea of both methods is not to preserve the content or style but to adjust the change in it. CCN orm and SCN orm regulate the changes in content and style, respectively, so they can synthesize more robust representations of the domain gap.
With the proposed normalization methods, we propose
ResNet [13] variant models, DAC-P and DAC-SC. DAC-P is the initial model with P CN orm, and DAC-SC is the primary model using CCN orm and SCN orm. In DAC-P, the existing BN in the downsample layer is replaced with
P CN orm. In contrast, DAC-SC applies CCN orm instead of P CN orm, and SCN orm is inserted at the end of each stage. We evaluate DAC-P and DAC-SC on five DG bench-Figure 2. Examples of style transfer with spectral decomposition.
Only the amplitude of the target images are transferred instead of their normalization statistics in AdaIN. marks: PACS, VLCS, Office-Home, DomainNet and Ter-raIncognita, and DAC-P outperforms other recent DG meth-ods with average performance of 65.1%. Furthermore, the primary model, DAC-SC, achieves state-of-the-art (SOTA) performance of 65.6% on average, and displays the high-est performance at 87.5%, 70.3% and 44.9% on the PACS,
Office-Home, and DomainNet benchmarks.
The contributions of this paper are as follows:
• For the first time, we analyze the quantitative shift in the phase caused by normalization using mathematical derivation.
• We introduce a new normalization, P CN orm, which can remove style only through spectral decomposition. the
• We propose advanced P CN orm variants,
CCN orm and SCN orm, which can learn domain-agnostic features for DG by adjusting the degrees of the changes in content and style, respectively.
• We propose ResNet-variant models, DAC-P and DAC-SC, which applies our proposed normalization meth-ods. We experimentally show that our methods are effective for DG and achieve SOTA average perfor-mances on five benchmark datasets. 2.