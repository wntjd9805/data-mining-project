Abstract
Few-shot segmentation (FSS) aims to segment novel ob-jects in a given query image with only a few annotated support images. However, most previous best-performing methods, whether prototypical learning methods or affinity learning methods, neglect to alleviate false matches caused by their own pixel-level correlation. In this work, we rethink how to mitigate the false matches from the perspective of representative reference features (referred to as buoys), and propose a novel adaptive buoys correlation (ABC) network to rectify direct pairwise pixel-level correlation, including a buoys mining module and an adaptive correlation module.
The proposed ABC enjoys several merits. First, to learn the buoys well without any correspondence supervision, we customize the buoys mining module according to the three characteristics of representativeness, task awareness and re-silience. Second, the proposed adaptive correlation module is responsible for further endowing buoy-correlation-based pixel matching with an adaptive ability. Extensive experimen-tal results with two different backbones on two challenging benchmarks demonstrate that our ABC, as a general plu-gin, achieves consistent improvements over several leading methods on both 1-shot and 5-shot settings. 1.

Introduction
Semantic segmentation has achieved conspicuous achievements attributed to the recent advances in deep neural network [20]. However, its data-driven nature makes it heav-ily dependent on massive pixel-level training data, which is labor-intensive and time-consuming to collect. To imitate the human learning habits which can recognize new classes with only a glance, few-shot segmentation [25] (FSS) has attracted increasing interest in recent years, which aims at segmenting novel objects in the given query image with a few annotated support images.
In previous literature, superior prototypical learning meth-ods [15, 28, 37] and affinity learning methods [11, 26, 30, 40]
*Equal contribution
â€ Corresponding author
Figure 1. The motivation of our proposed method. False matches tend to occur in the pixel-level correlation due to large intra-class variations. We introduce a series of representative features (buoys) as references and calculate the buoys-level correlation to suppress false matches. are almost all equipped with pixel-level correlation. In spe-cific, for prototypical learning methods, pixel-level correla-tion is implicitly endowed with the expectation to generate the foreground prior mask [28] for guiding the query pixel classification. For affinity learning methods, pixel-level cor-relation directly serves to aggregate support information and convey it to the query image [40].
Despite their promising results, these methods neglect the fact that there may exist cluttered background and inher-ent large intra-class variations between support and query images. In this case, directly employing pairwise pixel cor-relation may lead to considerable false matches. To make matters worse, the negative impact is inevitably amplified by inbuilt low-data regimes of FSS, leading to sub-optimal results. As shown in Fig. 1 (a), due to the significant pose difference of the object plane in the support-query image pair, p2 in the query image located in the plane hatch is erro-neously closer to p3 situated on the ground than counterpart p1 in the support image. Therefore, it is highly desirable to rectify these false matches caused by the direct pairwise pixel-level correlation.
In this paper, we aim to mitigate the false matches in previous FSS methods from the perspective of representative reference features (referred to as buoys). Specifically, we design a novel Adaptive Buoys Correlation (ABC) network that can be applied as a generic plugin, including a buoy mining module and an adaptive correlation module to rec-tify direct pairwise pixel-level correlation for robust FSS.
The main idea is, for each pixel from the support or query image, we can obtain the buoy-level correlation (i.e., a like-lihood vector) by comparing this pixel with a set of buoys.
In essence, the buoy-level correlation reflects the consensus among representative buoys with a broader receptive field, thus it encodes the relative semantic comparability of the buoys that can be relied upon. Intuitively, each pair of true pixel correlation (e.g., the p1-p2 pair in Fig. 1 (b)) derived from the query and support images should be not only vi-sually similar to each other (i.e., high pairwise pixel-level correlation), but also similar to any other buoys (i.e., simi-lar buoy-level correlation pair). Based on this correlation consistency in ABC, false matches caused by similar vision but dissimilar buoy correlations will be suppressed (e.g., the point p3-p2 pair in Fig. 1 (b)), ensuring that true pixel correlations enjoy higher weights to safely extract support information.
However, it is non-trivial to learn the buoys well without any correspondence supervision for training. In the buoys mining module (BMM), we carefully design this module customized for the following three characteristics. (1) Rep-resentativeness. Intuitively, the buoys should have the ability to represent the diverse semantic clues from both support and query pixels with a broader semantic contrast descriptive.
In other words, the matching between support-query pixels based on buoy-level correlation should preserve as much critical information as possible in the correspondence based on pixel-level correlation. In specific, we take advantage of Singular Value Decomposition (SVD) in pursuit of con-trollable information decay. Besides, a representation decay loss is devised to prevent the degradation of buoys. (2) Task awareness. Since tasks are randomly sampled during FSS training, each individual task consists of unique categories with large distribution differences. Therefore, to enable the buoys to perceive the current task and generalize to novel classes well, we employ the cross-aggregation mechanism to flexibly adjust buoys to meet the expectations of any tasks, even the tasks with unseen classes. (3) Resilience. Consider-ing the large gap between support and query images caused by large intra-class variations and cluttered background, it is necessary for buoys to bridge this gap and become more referable. In specific, we prepend the self-aggregation mech-anism to amend buoys by reconciling the intrinsic resilience between support and query images.
Moreover, we observe that not all buoys are profitable when calculating pixel pair matching based on buoy-level correlation, and comprehensive consideration of the relation-ships between helpful buoys with potential intersections can assist in the final matching score. In the adaptive corre-lation module (ACM), we endow buoy-correlation-based pixel matching with an adaptive ability, which can flexibly assign less weight to irrelevant buoys conditioned to dif-ferent pixel pairs and focus on the structural similarity of related buoys. In specific, given the corresponding buoy pair for each pixel pair as the initial marginal distribution of the optimal transport(OT) algorithm, we can attain the opti-mal transport plan which can be regarded as the structural buoy contribution adaptive to the current pixel pair, and the corresponding OT distance is adopted for scoring matches.
In this work, our contributions can be concluded as fol-lows: (1) We propose an Adaptive Buoys Correlation (ABC) network to rectify the widely used pairwise pixel correla-tion in FSS. To the best of our knowledge, this is the first work to mitigate the false matches in FSS methods, from the perspective of representative reference features (buoys). (2) We introduce two novel modules, namely Buoys Mining
Module (BMM) and Adaptive Correlation Module (ACM), for representative buoys construction and adaptive matching respectively. They can cooperate well to achieve effective false match suppression. (3) Extensive experimental results with two different backbones on two challenging bench-marks demonstrate that our ABC, as a general plugin mod-ule, achieves consistent improvements over several leading methods on both 1-shot and 5-shot settings. 2.