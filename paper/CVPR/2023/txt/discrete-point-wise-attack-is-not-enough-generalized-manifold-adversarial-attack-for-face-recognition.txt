Abstract
Classical adversarial attacks for Face Recognition (FR) models typically generate discrete examples for target iden-tity with a single state image. However, such paradigm of point-wise attack exhibits poor generalization against nu-merous unknown states of identity and can be easily de-fended. In this paper, by rethinking the inherent relationship between the face of target identity and its variants, we in-troduce a new pipeline of Generalized Manifold Adversarial
Attack (GMAA)1 to achieve a better attack performance by expanding the attack range. Specifically, this expansion lies on two aspects – GMAA not only expands the target to be attacked from one to many to encourage a good general-ization ability for the generated adversarial examples, but it also expands the latter from discrete points to manifold by leveraging the domain knowledge that face expression change can be continuous, which enhances the attack ef-fect as a data augmentation mechanism did. Moreover, we further design a dual supervision with local and global con-straints as a minor contribution to improve the visual qual-ity of the generated adversarial examples. We demonstrate the effectiveness of our method based on extensive experi-ments, and reveal that GMAA promises a semantic contin-uous adversarial space with a higher generalization ability and visual quality. 1.

Introduction
Thanks to the rapid development of deep neural net-works (DNNs), the face recognition (FR) networks [5, 27] has been applied to identity security identification systems in a variety of crucial applications, such as face unlocking and face payment on smart devices. However, it has been observed that DNNs are easily fooled by adversarial exam-ples and offer incorrect assessments [9, 23], which has risks
*Co-first author
†Corresponding author 1https://github.com/tokaka22/GMAA of unauthorized access to FR systems and stealing personal privacy through poisoned data. These ‘well-designed’ ad-versarial examples reveal the aspects of FR models that are vulnerable to be attacked, which makes the adversarial at-tack a meaningful work to provide reference for improving model robustness.
Following the point-wise paradigm, previous methods typically tend to attack a single target identity sample with discrete adversarial examples illustrated in Fig. 1. However, these methods are not strong enough both in target domain and adversarial domain. Concretely, for the target domain, attacking a single identity image has a poor generalization on those unseen faces (even if they belong to the same per-son) in realistic scenarios. For example, Fig. 2 shows these adversarial examples which were used to attack the target (a girl) have a disappointingly lower success rate of attack-ing the identity with other unseen states. We analyze that’s because attacking a single image of target identity overfits the generation of adversarial examples to some fixed factors
In addition to the such as expression, makeup style, etc. target domain, we naturally consider the weakness of ad-versarial domain in the existing methods. Most adversarial attack methods optimize a Lp bounded perturbation [24,34] based on the gradient, which limits the problem to search-ing for discrete adversarial examples in a hypersphere of the clean sample and ignores the continuity of the generated ad-versarial domain. For example, the recently proposed meth-ods based on makeup style transformation [16,35,37] focus on generating finite adversarial examples that correspond to discrete makeup references. Such methods all overem-phasize on mining discrete adversarial examples within a limited scope and ignore the importance of the continuity in adversarial space. The weakness of current adversarial attack tasks motivates us, on the one hand, to explore how to generate adversarial examples that are more general to various target identity’s states and, on the other hand, to up-grade adversarial domain from discrete points to continuous manifold for a stronger attack.
In this paper, we introduce a new paradigm dubbed Gen-Figure 1. The core idea comparison. Discrete point-wise attack methods leverage a single state of the target identity during training and provide discrete adversarial examples. By attacking the target identity’s state set and employing domain knowledge, our core idea aims to Generalized Manifold Adversarial Attack (GMAA), which promises a semantic continuous adversarial manifold with a higher generalization ability on the target identity with unknown state. boundaries of target identity. More specifically, we employ the Facial Action Coding System (FACS) [10] as prior do-main knowledge (a kind of instantiation) to expand adver-sarial domain from discrete points to manifold. Through using FACS, the expressions can be encoded into a vec-tor space, and by which the adversarial example generator could produce an manifold that is homogeneous with the expression vector space and possesses semantic continuity.
In addition, in order to build an adversarial space with high visual quality, we employ four expression editors in GMAA pipeline to supervise the adversarial example generation in terms of global structure and local texture details. A trans-ferability enhancement module is also introduced to drive the model to mine robust and transferable adversarial fea-tures. Extensive experiments have shown that these compo-nents work well on a wide range of baselines and black-box attack models.
Our contributions are summarized as follows.
• We first pinpoint that the popular adversarial at-tack methods generally face generalization difficulty caused by the limited point-wise attack mechanism.
• To enhance the performance of adversarial attack, a new paradigm of Generalized Manifold Adversarial
Attack (GMAA) is proposed with an improved attack success rate and better generalization ability.
• GMAA considers the enhancement in terms of both target domain and adversarial domain. For the target domain, it expands the target to be attacked from one to many to encourage a good generalization. For the adversarial domain, the domain knowledge is embed-ded to strengthen the attack effect from discrete points to continuous manifold.
Figure 2. The black-box attack success rate on the Mobileface of attacking target * 1, 2 and 3 during the testing. The three methods are exclusively trained on target *. eralized Manifold Adversarial Attack (GMAA) depicted in
Fig. 1, which achieves a higher attack success rate by pro-viding semantic continuous adversarial domains while ex-panding the target to be attacked from an instance to a group set. Specifically, we train adversarial examples to attack a target identity set rather than a single image, which in-creases the attack success rate on the target identity with different states. The expansion of target domain naturally prompts us to consider enhancing the adversarial domain.
Inspired by the success of some recent data and knowl-edge dual driven methods [2, 18, 36], we explore a low-dimensional manifold near the sample according to the do-main knowledge, which is a simple yet highly-efficient con-tinuous embedding scheme and can be used to augment the data. For such manifold, the data in it share the visual iden-tity same as the original sample and also lie in the decision
• We instantiate GMAA in the face expression state space for a semantic continuous adversarial manifold and use it to attack a state set of the target identity. As a minor contribution, GMAA supervises the adversarial example generator w.r.t global structure and local de-tails with the pre-trained expression editors for a high visual quality. 2.