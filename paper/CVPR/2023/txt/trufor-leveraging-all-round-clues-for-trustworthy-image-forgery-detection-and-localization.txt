Abstract
In this paper we present TruFor, a forensic framework that can be applied to a large variety of image manipula-tion methods, from classic cheapfakes to more recent ma-nipulations based on deep learning. We rely on the ex-traction of both high-level and low-level traces through a transformer-based fusion architecture that combines the
RGB image and a learned noise-sensitive fingerprint. The latter learns to embed the artifacts related to the cam-era internal and external processing by training only on real data in a self-supervised manner. Forgeries are de-tected as deviations from the expected regular pattern that characterizes each pristine image. Looking for anomalies makes the approach able to robustly detect a variety of lo-cal manipulations, ensuring generalization. In addition to a pixel-level localization map and a whole-image integrity score, our approach outputs a reliability map that high-lights areas where localization predictions may be error-prone. This is particularly important in forensic applica-tions in order to reduce false alarms and allow for a large scale analysis. Extensive experiments on several datasets show that our method is able to reliably detect and local-ize both cheapfakes and deepfakes manipulations outper-forming state-of-the-art works. Code is publicly available at https://grip-unina.github.io/TruFor/. 1.

Introduction
Manipulating images has never been easier, with new powerful editing tools appearing by the day. These new opportunities stimulate the creativity of benign and mali-cious users alike. Previously, crafting a multimedia disin-formation campaign required sophisticated skills, and at-tackers could do little more than copy, replicate or remove objects in an image, classic forms of image manipulations also known as “cheapfakes”. With the explosive growth of deep learning, image manipulation tools have become both easier to use and more powerful, allowing users to generate on-the-fly images of persons that do not exist or to realize
Figure 1. TruFor detects and localizes image forgeries (in yellow).
It is based on the extraction of a learned noise-sensitive fingerprint,
Noiseprint++, which is combined with the RGB image to output an anomaly localization map. Noiseprint++ is also used jointly with the image to compute the confidence map, which estimates the less reliable regions of the anomaly heatmap (black areas), e.g. the false positive region in lower right. The confidence and anomaly maps are then used together to produce a global integrity score. credible deepfakes. Diffusion models enable the creation of realistic image edits using natural language prompts, photo-realistically adapting the inserted manipulation to the style and lighting of the context [1, 33].
The risks posed by such tools in the wrong hands are obvious.
Indeed, in recent years there has been a grow-ing interest on the part of governments and funding agen-cies in developing forensic tools capable of countering such attacks. A major focus is on local image edits, particu-larly partial modifications that change the image seman-tics (for example the partially manipulated image in Fig. 1, where the two real faces have been replaced with GAN-generated ones [26]). Multimedia forensics and related sci-entific fields have seen a rapid increase in activity in re-sponse to such challenges, with a large number of methods and tools proposed for image forgery detection and localiza-tion [38]. Despite considerable advances in the area, current
SOTA detectors are not yet performant enough for in-the-wild deployment, due mainly to deficiencies in several ar-eas subject to intense research: i) limited generalization; ii) limited robustness; iii) insufficient detection performance.
Limited generalization is the inability of detectors to cope with out-of-distribution manipulations. Some detec-tors are built to exploit well-defined low-level features, e.g., traces of JPEG compression, demosaicking or interpola-tion [2, 6, 34], while others are typically developed to work well only on specific types of manipulations, like splicing
[25, 37]. In addition, in a realistic scenario images also un-dergo numerous forms of non-malicious degradation, (e.g. recompression, resizing, etc) - also called laundering. For example, social networks compress and resize uploaded im-ages, both of which can easily remove forensic traces. Fi-nally, most SOTA methods perform image forgery localiza-tion, leaving detection as an afterthought [11], which is typ-ically derived as a global integrity score from the localiza-tion heatmap itself [22, 36, 42]. Few methods address the detection task directly [8, 31, 39, 46]. As a result, detection accuracy is poor, with a high false alarm rate. In a realis-tic setting where manipulated images are rare, such perfor-mance could cause more problems than it solves, with false positives drastically outnumbering true positives.
This work addresses such shortcomings, with a focus on robust detection under varied manipulations. Our aim is to first establish whether the image under analysis has been manipulated or not, and subsequently consider forgery lo-calization only for images where a forgery has been de-tected. To perform in a real-world scenario where im-ages undergo many post-processing steps that may atten-uate forensic traces, our design was guided by the need to leverage information at multiple scales (both low and high-level features) even in complex scenarios. Our framework estimates a confidence map that associates localization re-sults with region-specific uncertainty, allowing many poten-tial false alarms to be rejected. The block diagram of our method is presented in Fig. 1. Overall, in this work we make the following key contributions:
• we propose a new framework, TruFor, which outputs a global integrity score, an anomaly-based localization map and an associated confidence map;
• we propose a new noise-sensitive fingerprint,
Noiseprint++, with enhanced robustness to image laundering;
• we combine low-level and high-level evidence to per-form anomaly analysis, which together with the confi-dence analysis provide more reliable decisions;
• we carry out extensive experiments on several bench-marks, considering new and challenging scenarios, and demonstrate that our method achieves state-of-the-art performance in both detection and localization tasks. 2.