Abstract
In the field of binocular stereo matching, remarkable progress has been made by iterative methods like RAFT-Stereo and CREStereo. However, most of these methods lose information during the iterative process, making it difficult to generate more detailed difference maps that take full advantage of high-frequency information. We propose the Decouple module to alleviate the problem of data coupling and allow features containing subtle details to transfer across the iterations which proves to alleviate the problem significantly in the ablations. To further capture high-frequency details, we propose a Normalization Refine-ment module that unifies the disparities as a proportion of the disparities over the width of the image, which address the problem of module failure in cross-domain scenarios.
Further, with the above improvements, the ResNet-like feature extractor that has not been changed for years becomes a bottleneck. Towards this end, we proposed a multi-scale and multi-stage feature extractor that intro-duces the channel-wise self-attention mechanism which greatly addresses this bottleneck. Our method (DLNR) ranks 1st on the Middlebury leaderboard, significantly outperforming the next best method by 13.04%. Our method also achieves SOTA performance on the KITTI-2015 benchmark for D1-fg. Code and demos are available at: https://github.com/David- Zhao- 1997/
High- frequency- Stereo- Matching- Network.
† These authors contributed equally.
⋆ Corresponding author.
Email: zyj6667@126.com.
⋆⋆ Second Corresponding author.
Email: zhaoyong@pkusz.edu.cn 1.

Introduction
Figure 1. Motivation. We aim to address the problem of blurry edges, thin object missing, and textureless region mismatch.
Stereo depth estimation is becoming the infrastructure for 3D applications. Accurate depth perception is vital for autonomous driving, drones navigation, robotics and other related fields. The main point of the task is to estimate a pixel-wise displacement map also known as disparity that can be used to determine the depth of the pixels in the scene.
Traditional stereo matching algorithms [7,11,12] are mainly divided into two types: global methods [6, 16, 17, 26] and local methods [1, 13]. Both methods solve the optimiza-tion problem by minimizing the objective function contain-ing the data and smoothing terms, while the former takes into account the global information, the latter simply takes into account the local information, hence both have their own benefits in terms of accuracy and speed when solv-ing the optimization problem. Traditional methods have ex-cellent generalization performance and robustness in differ-ent scenarios, but perform poorly on details such as weak
textures and repetitive texture regions. With the develop-ment of convolutional neural networks, learning-based ap-proaches [20, 28, 37] have lately demonstrated promising result in tackling the matching problem of challenging re-gions. Take advantages of the strong regularization perfor-mance of the 3D convolution and 4D cost volume, meth-ods [2, 10, 15, 45] using 3D convolution performs well.
While their practical applicability is limited by the high computational cost. Subsequent methods [37,43] attempt to use multiple adaptive aggregated and guided aggregated 2D convolutions instead of 3D convolution, reducing computa-tional cost and achieving better performance. The recent ap-pearance of RAFT-Stereo [20] has given rise to a fresh con-cept for the research of stereo matching. Derived from the optical estimation method RAFT [29], RAFT-Stereo uses the iterative refinement method for a coarse-to-fine pipeline.
It first calculates the correlation between all pixel pairs to construct a 3D correlation pyramid. Then an update oper-ator with a convolutional GRU as the core unit is used to retrieves features from the correlation pyramid and updates the disparity map [20].
Despite great progress has been made in learning-based approaches, two major problems remain. (1) Most current approaches fall short when it comes to the finer features of the estimated disparity map. Especially for the edge perfor-mance of the objects. In bokeh and rendering applications, the edge performance of the disparity map is critical to the final result. For example, technologies that require pixel-level rendering, such as VR and AR, have high requirements for fitting between the scene model and the image mapping, which means we need a tight fit between the edges in the disparity map and the original RGB image. (2) The mis-match of textureless regions and the missing of thin objects are also important factors that significantly deteriorate the disparity map. For example, the mismatch of weak texture walls and the missing of thin electrical wires are fatal flaws for obstacle avoidance applications.
To alleviate these problems, we propose DLNR (Stereo
Matching Network with Decouple LSTM and Normaliza-tion Refinement), a new end-to-end data-driven method for stereo matching.
We introduced several improvements based on the itera-tive model:
Most of the current iterative methods usually apply the original GRU structure as their iterative cell. While the problem is that in the original GRU structure, the informa-tion used to generate the update matrix of the disparity map is coupled with the value of the hidden state transfer be-tween iterations, making it hard to keep subtle details in the hidden state. Therefore, we designed the Decouple LSTM module to decouple the hidden state from the update ma-trix of the disparity map. Experiments and visualizations proved that the module retains more subtle details in the hidden states.
Decouple LSTM keeps more high-frequency informa-tion in the iterative stage through data decoupling, how-ever, in order to balance performance and computational speed, the resolution of the iterative stage is only 1/4 of the original resolution at most. To produce disparity maps with sharp edges and subtle details, a subsequent refine-ment module is still needed. In our refinement module, we aim to sufficiently exploit the information from the upsam-pled disparity maps, the original left and right images con-taining high-frequency information to enhance edges and details. However, due to the large differences in disparity ranges between different images and different datasets, the
Refinement module often has poor generalization perfor-mance when encountering images with different disparity ranges. In particular, when performing finetune, the mod-ule may even fail when encountering disparity ranges that differ greatly. To address this problem, we propose the Dis-parity Normalization strategy. Experiments and visualiza-tions proved that the module improves performance as well as alleviates the problem of domain difference.
After the above two improvements, we found that the feature extractor became the bottleneck of the performance.
In the field of stereo matching, feature extraction has not been improved significantly for years, most learning-based methods still use ResNet-like feature extractors which fall short when providing information for well-designed post-stage structures. To alleviate the problem, we propose the
Channel-Attention Transformer feature extractor aims to capture long-range pixel dependencies and preserve high-frequency information. 2.