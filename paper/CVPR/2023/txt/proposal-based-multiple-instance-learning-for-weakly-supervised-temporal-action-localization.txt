Abstract
Weakly-supervised temporal action localization aims to localize and recognize actions in untrimmed videos with only video-level category labels during training. Without instance-level annotations, most existing methods follow the
Segment-based Multiple Instance Learning (S-MIL) frame-work, where the predictions of segments are supervised by the labels of videos. However, the objective for acquiring segment-level scores during training is not consistent with the target for acquiring proposal-level scores during test-ing, leading to suboptimal results. To deal with this prob-lem, we propose a novel Proposal-based Multiple Instance
Learning (P-MIL) framework that directly classiﬁes the candidate proposals in both the training and testing stages, which includes three key designs: 1) a surrounding con-trastive feature extraction module to suppress the discrimi-native short proposals by considering the surrounding con-trastive information, 2) a proposal completeness evaluation module to inhibit the low-quality proposals with the guid-ance of the completeness pseudo labels, and 3) an instance-level rank consistency loss to achieve robust detection by leveraging the complementarity of RGB and FLOW modal-ities. Extensive experimental results on two challenging benchmarks including THUMOS14 and ActivityNet demon-strate the superior performance of our method. Our code is available at github.com/RenHuan1999/CVPR2023 P-MIL. 1.

Introduction
Temporal Action Localization (TAL) is one of the es-sential tasks in video understanding, which aims to simul-taneously discover action instances and identify their cat-egories in untrimmed videos [9, 18]. TAL has recently received increasing attention from the research commu-nity due to its broad application potentials, such as intel-ligent surveillance [44], video summarization [22], high-light detection [49], and visual question answering [23].
Most existing methods handle this task in a fully-supervised
*Corresponding Author
Figure 1. Drawbacks of the Segment-based Multiple Instance
Learning framework. (a) The objectives of the training and testing stages are inconsistent. (b) By watching a single running segment in the red box, it is difﬁcult to tell which category it belongs to. setting [7, 25, 42, 51, 63], which requires instance-level annotations. Despite their success, the requirements for such massive instance-level annotations limit their applica-tion in real-world scenarios. To overcome this limitation,
Weakly-supervised Temporal Action Localization (WTAL) has been widely studied because it only requires video-level labels [13, 26, 36, 45, 55], which are much easier to collect.
Most existing WTAL methods follow the Segment-based
Multiple Instance Learning (S-MIL) framework [16,32,45], where the predictions of segments are supervised by the
In particular, a class-agnostic attention labels of videos. branch is used to calculate the attention sequence, which in-dicates the foreground probability of each segment. Mean-while, a classiﬁcation branch is used to calculate the Class
Activation Sequence (CAS), which indicates the category probability of each segment. In the training stage, the video-level classiﬁcation scores can be derived by aggregating
CAS with the attention sequence, which are then supervised by the video-level category labels. In the testing stage, the candidate proposals are generated by thresholding the atten-tion sequence, and the segment-level CAS corresponding to each proposal is aggregated to score each proposal.
Despite the considerable progress achieved by these methods, the S-MIL framework has two drawbacks. Firstly, the objectives of the training and testing stages are inconsis-tent. As shown in Figure 1 (a), the target is to score the ac-tion proposals as a whole in the testing stage, but the classi-ﬁer is trained to score the segments in the training stage. The inconsistent scoring approach can lead to suboptimal results as shown in other weakly-supervised tasks [1,34,43,52,56].
Secondly, it is difﬁcult to classify each segment alone in many cases. As shown in Figure 1 (b), by watching a single running segment, it is difﬁcult to tell whether it belongs to high jump, long jump, or triple jump. Only by watching the entire action instance and using of the contextual informa-tion, we can determine which category it belongs to.
Inspired by the above discussions, we propose a novel
Proposal-based Multiple Instance Learning (P-MIL) frame-work, which employs a two-stage training pipeline. In the
ﬁrst stage, an S-MIL model is trained and the candidate pro-posals are generated by thresholding the attention sequence.
In the second stage, the candidate proposals are classiﬁed and aggregated into video-level classiﬁcation scores, which are supervised by video-level category labels. Since the candidate proposals are directly classiﬁed in both the train-ing and testing stages, the proposed method can effectively handle the drawbacks of the S-MIL framework. However, there are three issues that need to be considered within the P-MIL framework. First, the model tends to focus on discriminative short proposals. Since the training stage is mainly guided by the video-level classiﬁcation, the classi-ﬁer tends to focus on the most discriminative proposals to minimize the classiﬁcation loss. To solve this problem, we propose a Surrounding Contrastive Feature Extraction mod-ule. Speciﬁcally, we extend the boundaries of the candidate proposals and then calculate the outer-inner contrastive fea-tures of the proposals. By taking surrounding contrastive information into consideration, those discriminative short proposals can be effectively suppressed. Second, the candi-date proposals generated by the S-MIL approach may be over-complete, which include irrelevant background seg-ments. In this regard, we present a Proposal Completeness
Evaluation module. Concretely speaking, we treat the high-conﬁdence proposals as pseudo instances, and then acquire the completeness pseudo label of each proposal by com-puting the Intersection over Union (IoU) with these pseudo instances. Under the guidance of the completeness pseudo labels, the activation of low-quality proposals can be inhib-ited. Third, due to the Non-Maximum Suppression (NMS) process in the testing stage, the relative scores of propos-als belonging to the same action instance have substantial inﬂuences on the detection results. To learn robust rela-tive scores, we design an Instance-level Rank Consistency loss by leveraging the complementarity of RGB and FLOW modalities [55, 60]. Those proposals that overlap with a given candidate proposal are considered as a cluster. By constraining the normalized relative scores within the clus-ter between RGB and FLOW modalities to be consistent, we can achieve reliable detection by discarding proposals with low relative scores in the NMS process.
To sum up, the main contributions of this paper are as follows: (1) We propose a novel Proposal-based Mul-tiple Instance Learning (P-MIL) framework for weakly-supervised temporal action localization, which can handle the drawbacks of the S-MIL framework by directly classi-fying the candidate proposals in both the training and test-ing stages. (2) We propose three key designs (Surrounding
Contrastive Feature Extraction module, Proposal Complete-ness Evaluation module, Instance-level Rank Consistency loss), which can deal with the challenges in different stages of the P-MIL framework. (3) Extensive experimental re-sults on THUMOS14 and ActivityNet datasets demonstrate the superior performance of the proposed framework over state-of-the-art methods. 2.