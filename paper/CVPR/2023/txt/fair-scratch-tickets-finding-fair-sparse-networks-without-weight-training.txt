Abstract
Recent studies suggest that computer vision models come at the risk of compromising fairness. There are exten-sive works to alleviate unfairness in computer vision using pre-processing, in-processing, and post-processing meth-ods. In this paper, we lead a novel fairness-aware learning paradigm for in-processing methods through the lens of the lottery ticket hypothesis (LTH) in the context of computer vision fairness. We randomly initialize a dense neural net-work and ﬁnd appropriate binary masks for the weights to obtain fair sparse subnetworks without any weight training.
Interestingly, to the best of our knowledge, we are the ﬁrst to discover that such sparse subnetworks with inborn fair-ness exist in randomly initialized networks, achieving an accuracy-fairness trade-off comparable to that of dense neural networks trained with existing fairness-aware in-processing approaches. We term these fair subnetworks as Fair Scratch Tickets (FSTs). We also theoretically pro-vide fairness and accuracy guarantees for them.
In our experiments, we investigate the existence of FSTs on var-ious datasets, target attributes, random initialization meth-ods, sparsity patterns, and fairness surrogates. We also ﬁnd that FSTs can transfer across datasets and investigate other properties of FSTs. 1.

Introduction
In recent years, deep neural networks (DNN) has become one of the core technologies in computer vision (CV). How-ever, it has been observed that CV models learn spurious age, gender, and race correlations when trained for seem-ingly unrelated tasks [7, 67]. There are growing appeals for fairness-aware learning [58]. A model should not dis-criminate against any demographic group with sensitive at-tributes [3, 15, 60, 63, 76].
Extensive work has been done to alleviate unfairness in CV using pre-processing [37, 54, 64, 66], in-processing
[5, 6, 12, 57], and post-processing methods [39, 74]. Only in-processing approaches can optimize notions of fairness during model training. Such methods have direct con-trol over the optimization function of the model [8] and have attracted great attention in the research community.
Popular in-processing ideas include fairness regularization
[5, 12, 13, 33, 49, 52, 57, 69] and fairness-aware adversarial training [6, 19, 44, 72]. Fairness regularization is to intro-duce regularization terms to penalize unfairness. Fairness-aware adversarial training uses an adversary to predict the sensitive attribute and enforces the main classiﬁer to pre-vent the adversary from predicting successfully. However, most in-processing methods leverage deep and dense neural networks so that they are computationally intensive during the inference phase [28]. But model compression methods which scale down overparameterized models will introduce or exacerbate unfairness [34, 35, 63].
In this paper, to ﬁll the research gap, we raise an intrigu-ing and challenging question: Is there a learning paradigm without weight training that is plug-and-play for bias mit-igation approaches in computer vision? Intuitively, the re-cently proposed Lottery Ticket Hypothesis (LTH) [20] is a natural ﬁt for our needs. LTH focuses on ﬁnding sparse trainable subnetworks (winning tickets) that reach test accu-racy comparable to the original dense neural network. The primal training method in [20] is iteratively pruning and re-training the neural network. Interestingly, some researchers empirically discover that winning tickets can be found with-out weight training [53,75], which is theoretically validated in [14, 45, 48, 50]. Both empirical observations and theoret-ical results have veriﬁed the feasibility of ﬁnding winning tickets without training the weights of the neural networks.
Motivated by the above, we break down the original ques-tion into three sub-questions instead:
• Q1: Is there a fair winning ticket?
†Equal Contribution. ∗Corresponding author.
• Q2: How can we ﬁnd it without weight training?
• Q3: Is it easy to generalize on various datasets, tar-get attributes, random initialization methods, sparsity patterns and fairness surrogates?
For the ﬁrst question, Proposition 1 states that a suf-ﬁciently over-parameterized neural network with random weights contains a subnetwork that can approximate any target neural network with high probability under some con-ditions. Furthermore, our Theorem 1 shows that if we suc-cessfully ﬁnd a sparse neural network that approximates a fair and accurate neural network well, then the sparse neu-ral network is also fair and accurate. Combining the results of Proposition 1 and Theorem 1, they answer our ﬁrst ques-tion by clarifying the possibility of ﬁnding fair and accurate winning tickets without any weight training. To our best knowledge, LTH remains poorly understood in the context of fairness. For the second question, note that the proof of Theorem 2.1 in [45] follows a constructive routine for masking. Therefore, it sheds light on the feasibility of ﬁnd-ing fair winning tickets without any weight training by de-signing an appropriate masking scheme, and that is exactly what we do. We randomly initialize a DNN and search for masks to iteratively ﬁnd Fair Scratch Tickets (FSTs).
In particular, following [53], we search for the best bi-nary masks by optimizing a continuously updated learnable score for each weight. For the third question, to verify the generality of FST, we demonstrate its effectiveness in two famous types of in-processing approaches in CV fair-ness: fairness regularization [5] and fairness-aware adver-sarial training [72]. Extensive experiments verify the exis-tence of FSTs on various datasets, target attributes, random initialization methods, sparsity patterns and fairness surro-gates. We further show the properties of ﬁne-tuning and transferability of FSTs.
Overall, our contributions are threefold:
• We theoretically and empirically conﬁrm the existence of winning tickets with inborn fairness. And we extend the application scenario of LTH to CV fairness.
• We propose a brand new plug-and-play learning paradigm that does not require weight training for the
CV fairness community.
• Extensive experiments verify the existence of FSTs on various datasets, target attributes, random initial-ization methods, sparsity patterns and fairness surro-gates. Furthermore, we show the properties of ﬁne-tuning and transferability of FSTs. 2.