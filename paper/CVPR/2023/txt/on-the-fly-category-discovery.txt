Abstract
Although machines have surpassed humans on visual recognition problems, they are still limited to providing closed-set answers. Unlike machines, humans can cog-nize novel categories at the first observation. Novel cate-gory discovery (NCD) techniques, transferring knowledge from seen categories to distinguish unseen categories, aim to bridge the gap. However, current NCD methods assume a transductive learning and offline inference paradigm, which restricts them to a pre-defined query set and renders them unable to deliver instant feedback. In this paper, we study on-the-fly category discovery (OCD) aimed at making the model instantaneously aware of novel category samples (i.e., enabling inductive learning and streaming inference).
We first design a hash coding-based expandable recogni-tion model as a practical baseline. Afterwards, noticing the sensitivity of hash codes to intra-category variance, we further propose a novel Sign-Magnitude dIsentangLEment (SMILE) architecture to alleviate the disturbance it brings.
Our experimental results demonstrate the superiority of
SMILE against our baseline model and prior art. Our code is available at https://github.com/PRIS-CV/On-the-fly-Category-Discovery. 1.

Introduction
Deep models are well known for beating humans in vi-sual recognition [13]. However, this is just a victory of specialist models over generalist humans – existing vision recognition models are mostly closed-set experts. Given a defined category set, huge datasets are gathered and an-notated, and then, deep models trained with the annotated data can easily handle such an in-category recognition due to their great fitting ability. However, these models are ar-guably only learning to memorize in that they are restricted to the defined category set and are incapable of modeling novel categories. Although paradigms like open set recog-*Corresponding Author
Figure 1. Comparison of the conventional NCD setting and the proposed OCD setting. (a) NCD adopts transductive learning and offline inference. (b) OCD removes the pre-defined query set as-sumption and conducts inductive learning and instant inference. nition [9] aim to filter out the out-of-category samples, sim-ply rejecting them is not satisfactory. For humans, visual recognition is far beyond a closed-set problem – instead of learning to memorize, we learn to cognize. In particular, given samples containing novel categories, we can not only tell which are novel but we can also tell which may share the same novel category. E.g., even you have never seen
“hedgehogs”, you can easily realize that they differ from other creatures you have seen before and realise that multi-ple hedgehog images belong to the same category, even if you don’t know the name.
To bridge the gap, a rising field named novel category discovery (NCD) [11] attaching increasing attention. With a labelled support set of seen categories and an unlabeled query set containing unseen ones, NCD aims at cogniz-ing unseen categories by splitting the query set into several groups with the same latent category. As shown in Figure 1, existing NCD works [7, 10, 15, 37] mostly fall into a trans-ductive learning and offline inference procedure. Specifi-cally, a visual feature encoder is first trained with the sup-port set via supervised learning and the query set via unsu-pervised or semi-supervised learning. After that, clustering
techniques are applied to the encoded visual features to ob-tain category clusters.
Although convincing performance has been obtained, two restrictive assumptions still hinder the real-world ap-plication of NCD approaches under the current setting. (i)
Firstly, the query set is visible and required during train-ing, which makes the model specialized to the pre-defined query set and less capable of dealing with truly novel sam-ples. (ii) Secondly, the query set is batch processed offline during inference. Therefore these models are not practical in online scenarios where new data occurs in a stream and instant feedback on each instance is required.
To approach a more realistic scenario, we put forward the problem of on-the-fly category discovery (OCD) that re-moves the assumption of a pre-defined query set (Figure 1).
In particular, we keep the seen/unseen split of datasets, and make samples of the unseen query set unavailable during training and only individually visible during test. The goal of OCD is learning to recognise seen categories and to cog-nize unseen categories – both in an inductive manner that can be applied online. We follow the setting of generalized category discovery (GCN) [30] where both seen and unseen categories appear in the query set.
Next, we introduce a new recognition paradigm for OCD along with a baseline model.
Instead of adopting cross-entropy loss during training for fully supervised learning, we choose supervised contrastive learning [16] that works in embedding space. Thus, we directly optimize and ob-tain discriminative visual features rather than probability outputs within a fixed prediction space. To meet the need for instant feedback, cluster-based techniques are no longer practical during inference. To this end, we take the bina-rized feature embeddings as hash-like category descriptors, and samples with the same descriptor can be regarded as sharing the same latent category. In this way, the model can individually recognize each novel sample, like us humans.
Afterward, we observe a challenge of OCD – the hash-like descriptor is extremely sensitive to intra-category vari-ance, especially for fine-grained categories. E.g., for the
CUB-2011-200 dataset [31], ∼1500 different 12-dimension hash codes are generated for ∼4000 birds from only 200 categories. To address this, we contribute a novel Sign-Magnitude dIsentangLEment (SMILE) architecture to al-leviate the negative influence of intra-category variance.
Specifically, we infer the signs and the magnitudes of fea-ture embeddings with two separate branches and only the sign branch is used during inference. The intuition be-hind this is that, since deep neural features respond to ab-stract semantics (e.g., colors, textures, shapes), the sign branch should encode whether a semantic feature corre-sponds to this category, and the magnitude branch indicates the expression level of the semantic feature on the current sample. In summary, the magnitude branch should model intra-category variance, and the sign branch inter-category variance. Experiments on three widely used classifica-tion datasets and three fine-grained classification datasets demonstrate the superiority of SMILE over our baseline and prior art. 2.