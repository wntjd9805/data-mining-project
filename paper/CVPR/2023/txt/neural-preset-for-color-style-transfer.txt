Abstract 1.

Introduction
In this paper, we present a Neural Preset technique to address the limitations of existing color style transfer meth-ods, including visual artifacts, vast memory requirement, and slow style switching speed. Our method is based on two core designs. First, we propose Deterministic Neural Color
Mapping (DNCM) to consistently operate on each pixel via an image-adaptive color mapping matrix, avoiding artifacts and supporting high-resolution inputs with a small memory footprint. Second, we develop a two-stage pipeline by divid-ing the task into color normalization and stylization, which allows efficient style switching by extracting color styles as presets and reusing them on normalized input images. Due to the unavailability of pairwise datasets, we describe how to train Neural Preset via a self-supervised strategy. Vari-ous advantages of Neural Preset over existing methods are demonstrated through comprehensive evaluations. Besides, we show that our trained model can naturally support mul-tiple applications without fine-tuning, including low-light image enhancement, underwater image correction, image dehazing, and image harmonization. The project page is: https://ZHKKKe.github.io/NeuralPreset.
With the popularity of social media (e.g., Instagram and
Facebook), people are increasingly willing to share pho-tos in public. Before sharing, color retouching becomes an indispensable operation to help express the story cap-tured in images more vividly and leave a good first impres-sion. Photo editing tools usually provide color style presets, such as image filters or Look-Up Tables (LUTs), to help users explore efficiently. However, these filters/LUTs are handcrafted with pre-defined parameters, and are not able to generate consistent color styles for images with diverse appearances. Therefore, careful adjustments by the users is still necessary. To address this problem, color style trans-fer techniques have been introduced to automatically map the color style from a well-retouched image (i.e., the style image) to another (i.e., the input image).
Earlier color style transfer methods [41–43, 49] focus on retouching the input image according to low-level fea-ture statistics of the style image. They disregard high-level information, resulting in unexpected changes in image in-† Corresponding author. This project is in part supported by a General
Research Fund from RGC of Hong Kong (RGC Ref.: 11205620).
herent colors. Although recent deep learning based mod-els [1,6,19,34,36,54] give promising results, they typically suffer from three obvious limitations in practice (Fig. 1 (a)).
First, they produce unrealistic artifacts (e.g., distorted tex-tures or inharmonious colors) in the stylized image since they perform color mapping based on convolutional mod-els, which operate on image patches and may have incon-sistent outputs for pixels with the same value. Although some auxiliary constraints [36] or post-processing strate-gies [34] have been proposed, they still fail to prevent ar-tifacts robustly. Second, they cannot handle high-resolution (e.g., 8K) images due to their huge runtime memory foot-print. Even using a GPU with 24GB of memory, most recent models suffer from the out-of-memory problem when pro-cessing 4K images. Third, they are inefficient in switching styles because they carry out color style transfer as a single-stage process, requiring to run the whole model every time.
In this work, we present a Neural Preset technique with two core designs to overcome the above limitations: (1) Neural Preset leverages Deterministic Neural Color
Mapping (DNCM) as an alternative to the color mapping process based on convolutional models. By multiplying an image-adaptive color mapping matrix, DNCM converts pixels of the same color to a specific color, avoiding un-realistic artifacts effectively. Besides, DNCM operates on each pixel independently with a small memory footprint, supporting very high-resolution inputs. Unlike adaptive 3D
LUTs [7, 55] that need to regress tens of thousands of pa-rameters or automatic filters [23, 27] that perform particu-lar color mappings, DNCM can model arbitrary color map-pings with only a few hundred learnable parameters. (2) Neural Preset carries out color style transfer in two stages to enable fast style switching. Specifically, the first stage builds a nDNCM from the input image for color nor-malization, which maps the input image to a normalized color style space representing the “image content”; the sec-ond stage builds a sDNCM from the style image for color stylization, which transfers the normalized image to the tar-get color style. Such a design has two advantages in terms of efficiency: the parameters of sDNCM can be stored as color style presets and reused by different input images, while the input image can be stylized by diverse color style presets after normalized once with nDNCM.
In addition, since there are no pairwise datasets avail-able, we propose a new self-supervised strategy for Neu-ral Preset to be trainable. Our comprehensive evaluations demonstrate that Neural Preset outperforms state-of-the-art methods significantly in various aspects. Notably, Neural
Preset can produce faithful results for 8K images (Fig. 1 (b)) and can provide consistent color style transfer results across video frames without post-processing. Compared to re-cent deep learning based models, Neural Preset achieves
∼28× speedup on a Nvidia RTX3090 GPU, supporting real-time performances at 4K resolution. Finally, we show that our trained model can be applied to other color map-ping tasks without fine-tuning, including low-light image enhancement [30], underwater image correction [52], im-age dehazing [16], and image harmonization [37]. 2.