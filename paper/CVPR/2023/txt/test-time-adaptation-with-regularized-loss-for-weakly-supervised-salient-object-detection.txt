Abstract
It is well known that CNNs tend to overfit to the training data. Test-time adaptation is an extreme approach to deal with overfitting: given a test image, the aim is to adapt the trained model to that image. Indeed nothing can be closer to the test data than the test image itself. The main difficulty of test-time adaptation is that the ground truth is not available.
Thus test-time adaptation, while intriguing, applies to only a few scenarios where one can design an effective loss func-tion that does not require ground truth. We propose the first approach for test-time Salient Object Detection (SOD) in the context of weak supervision. Our approach is based on a so called regularized loss function, which can be used for training CNN when pixel precise ground truth is unavail-able. Regularized loss tends to have lower values for the more likely object segments, and thus it can be used to fine-tune an already trained CNN to a given test image, adapting to images unseen during training. We develop a regularized loss function particularly suitable for test-time adaptation and show that our approach significantly outperforms prior work for weakly supervised SOD. 1.

Introduction
A well known problem with CNNs is that they tend to overfit to the training data. One approach to deal with over-fitting is test-time adaptation [30]. A model is trained on the training data, and then fine-tuned for a few epochs dur-ing test time on a given test image. The main difficulty of test-time adaptation is that there is no ground truth for the test image. Thus test-time adaptation has been previously used for only a few applications [11, 16, 22, 30, 45] where a suitable loss function can be designed without ground truth.
We propose the first approach for test-time Salient Ob-ject Detection (SOD). The goal of SOD is to find image regions that attract human attention. Convolutional Neu-ral Networks (CNNs) [14, 15] brought a significant break-through for SOD [18, 28, 46, 47]. Traditional training of
CNNs for SOD requires pixel precise ground truth, but ob-taining such annotations is a substantial effort. Therefore, there is an increased interest in semi-supervised [20,23] and weakly supervised SOD [17, 25, 33, 40, 41, 44]. Weak su-pervision requires less annotation effort, compared to semi-supervision. In this paper, we assume image level supervi-sion, the weakest supervision type, where one provides only images containing salient objects, with no other annotation. level weakly supervised SOD ap-proaches [17, 25, 40, 41, 44] are based on noisy pseudo labels, constructed from unsupervised SOD methods.
These approaches are hard to modify for test-time adapta-tion, as at test time, one has only one image to create noisy pseudo-ground truth samples, but combating noise requires diverse samples. image
Most
Our test-time adaptation is based on the approach in [33].
Different from the other image level supervised SOD meth-ods, the approach in [33] does not require pseudo labels.
They design a regularized loss1 to use for CNN training without pixel precise annotations. Regularized loss models class-independent properties of object shapes and is likely to have lower values for segmentations that separate the ob-ject from the background. This makes regularized loss ap-proach particularly suitable for test time adaptation.
We design a regularized loss function tailored for test time adaptation. The main problem with regularized loss in [33] is that it may result in a trivial empty solution if hy-perparameters of the loss function are not chosen correctly.
When training on a large dataset, an occasional empty result is not a big problem, but when training on a single test im-age, an empty result is disastrous, catastrophically worsen-ing the performance. Thus we must develop a hyperparame-ter setting method that avoids empty solutions. However, in the absence of ground truth, setting hyperparameter weights is not trivial. We propose a method for setting hyperparame-ters specific for each test image such that an empty solution is avoided. This method is crucial for obtaining good results 1In the context of CNNs, regularization is a term often used to refer to the norm regularization on the network weights [8]. Here, regularized loss refers to the loss function on the output of CNN. 1
Figure 1. Overview of our approach. Top: test image, ground truth, output of base CNN on the test image, and the result of dense CRF [13] post-processing of the base CNN result. Bottom: test-time dataset, CNN output on the test image during several test time epochs, and the final result of the adapted CNN. during test-time adaptation.
Fig. 1 is an overview of our approach. First we train
CNN for SOD in weakly supervised setting with image level labels using [33]. The result is called the base CNN.
The top row of Fig. 1 shows a test image, ground truth, and the result of the base CNN. Given a test image, we create a small training dataset by augmentation, see Fig. 1, bottom, left. Then we fine tune the base CNN on the small dataset, using our version of regularized loss, Fig. 1, bottom, mid-dle. The resulting CNN is called the adapted CNN.
The result of base CNN (Fig. 1, top, third image) has many erroneous regions. Sometimes dense CRF [13] is used for post processing to improve performance. We apply dense CRF to the output of base CNN (Fig. 1, top, right).
Dense CRF removes small spurious regions but is unable to remove the large erroneous regions as these are salient with high confidence according to the base CNN.
In contrast, our approach is able to produce much better results, Fig. 1, bottom, right. This is because the base CNN has a high value of regularized loss for this test image. As the fine tuning proceeds, CNN is forced to find alternative segmentations with better loss values, resulting in increas-ingly better segmentations. Unlike CRF post processing, our adapted CNN is able to remove the large erroneous re-gions, as their high confidence values according to the base
CNN are ignored, and these regions give higher values of regularized loss. Both dense CRF and our approach use
CRF models. However, as opposed to post-processing, we use CRF for CNN supervision, enabling CNN to learn a better segmentation.
Our experiments on the standard benchmarks show that test time adaptation significantly improves performance, achieving the new state-of-art in image level weakly super-vised SOD.
This paper is organized as follows: Sec. 2 is related work, Sec. 3 explains the approach in [33], Sec. 4 describes our approach, and Sec. 5 presents experiments. 2.