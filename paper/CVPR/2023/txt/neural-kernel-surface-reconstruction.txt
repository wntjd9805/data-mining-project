Abstract
We present a novel method for reconstructing a 3D im-plicit surface from a large-scale, sparse, and noisy point cloud. Our approach builds upon the recently introduced
Neural Kernel Fields (NKF) [58] representation. It enjoys similar generalization capabilities to NKF, while simulta-neously addressing its main limitations: (a) We can scale to large scenes through compactly supported kernel func-tions, which enable the use of memory-efﬁcient sparse lin-ear solvers. (b) We are robust to noise, through a gradi-ent ﬁtting solve. (c) We minimize training requirements, enabling us to learn from any dataset of dense oriented points, and even mix training data consisting of objects and scenes at different scales. Our method is capable of recon-structing millions of points in a few seconds, and handling very large scenes in an out-of-core fashion. We achieve state-of-the-art results on reconstruction benchmarks con-sisting of single objects (ShapeNet [5], ABC [33]), indoor scenes (ScanNet [11], Matterport3D [4]), and outdoor scenes (CARLA [16], Waymo [49]). 1.

Introduction
The goal of 3D reconstruction is to recover geometry from partial measurements of a shape. In this work, we aim to map a sparse set of oriented points sampled from the sur-face of a shape to a 3D implicit ﬁeld. This is a challenging inverse problem since point clouds acquired from real-world sensors are often very large (millions or billions of points), vary in sampling density, and are corrupted with sensor noise.
Furthermore, since surfaces are continuous but points are discrete, there are many valid solutions which can explain a given input. To address these issues, past approaches aim to recover surfaces that agree with the input points while satisfying some prior everywhere else in space. Classical methods use an explicit prior (e.g. smoothness), while more recent learning-based approaches promote a likely recon-struction under a data-driven prior.
There are, however, key limitations to both types of tech-niques that inhibit their application in practical situations.
Since classical methods are fast, scalable, and able to han-dle diverse inputs, they have become an industry standard (e.g. [32, 61]). Yet, they suffer from quality issues in the presence of high noise or sparse inputs, often failing to re-construct even simple geometry such as a ground plane (see the ground in Fig. 1). On the other hand, learning-based ap-proaches were shown to handle large noise [42], and sparse inputs [39, 3], yet they often struggle to generalize to out-of-distribution shapes and sampling densities as was highlighted in [58]. These generalization issues can be attributed to the
fact that current learning-based methods struggle to exploit large and diverse amounts of data for training. One cause of this is that a single forward pass can take minutes for even moderately sized inputs (e.g. [3]), limiting training to collections consisting of small point clouds. Furthermore, many existing methods rely on a preprocessing step to ex-tract supervision in the form of occupancy or signed distance function [43, 38, 40, 3, 58]. In practice, this preprocessing step hinders the ability to easily use diverse datasets for training since most shape datasets (including synthetic ones such as the popular ShapeNet [5]) consist of non-watertight shapes, open surfaces, or contain ghost geometry from which extracting supervision is hard.
Recently, [58] proposed Neural Kernel Fields (NKF), a new paradigm to address the problem of generalization in 3D reconstruction. NKF learns a data-dependent kernel, and pre-dicts a continuous occupancy ﬁeld as a linear combination of this kernel supported on the input points. The key insights of
NKF are that a kernel explicitly encodes inductive bias, and that solving a kernel linear interpolation problem at test time always produces solutions that adhere to the inputs. Thus, by training on diverse shapes, NKF can learn a good inductive bias for the general 3D reconstruction problem rather than for a speciﬁc dataset. While NKF achieves impressive gen-eralization results, it suffers from two major limitations that restrict its practical application. First, since it uses a globally supported kernel, it requires solving a dense linear system and cannot reconstruct inputs with more than ten thousand input points. Second, it degrades poorly in the presence of noise due to its interpolation of exact positional occupancy constraints.
In this work, we build upon the excellent generalization capability of NKF and tackle its main limitations to achieve a practical learning-based reconstruction method that is scal-able, fast, and robust to noise. Like NKF, our work leverages the idea of a learned kernel for generalization, but we (1) develop a novel, gradient-based kernel formulation which is robust to noise, and (2) use an explicit voxel hierarchy struc-ture and compactly supported kernels to make our interpo-lation problem sparse, multi-scale, and capable of handling large inputs while still producing high ﬁdelity outputs. The result is a learning-based yet out-of-the-box reconstruction method that can be applied to point clouds in the wild. In particular, it enjoys all of the following properties:
• It can generalize to out-of-distribution inputs, produc-ing high-ﬁdelity reconstructions, even in the presence of sparsity and noise.
• It can be trained on the union of diverse datasets while only requiring dense oriented points as supervision, unlocking a new level of training data scale.
• It can reconstruct point clouds consisting of millions of points in seconds, and scale to extremely large inputs in an out-of-core fashion.
General Applicability
[2]
[5]
[1]
[3, 9]
D a t a
-P r i o r
Ours
[6, 8]
[4, 7]
Scalability
[1]: SPSR [32]
[2]: N-Splines [61]
[3]: OccNet [38]
[4]: NGLOD [51]
[5]: NKF [58]
[6]: ConvONet [43]
[7]: TSDF-Fusion [10]
[8]: POCO [3]
[9]: DMTet [47]
Figure 2: Comparison to related works.
We illustrate other methods in the context of these points visually in Fig. 2. 2.