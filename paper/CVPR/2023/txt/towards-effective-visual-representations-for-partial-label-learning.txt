Abstract
Under partial-label learning (PLL) where, for each training instance, only a set of ambiguous candidate labels containing the unknown true label is accessible, contrastive learning has recently boosted the performance of PLL on vi-sion tasks, attributed to representations learned by contrast-ing the same/different classes of entities. Without access to true labels, positive points are predicted using pseudo-labels that are inherently noisy, and negative points often require large batches or momentum encoders, resulting in unreliable similarity information and a high computational overhead. In this paper, we rethink a state-of-the-art con-trastive PLL method PiCO [24], inspiring the design of a simple framework termed PaPi (Partial-label learning with a guided Prototypical classifier), which demonstrates sig-nificant scope for improvement in representation learning, thus contributing to label disambiguation. PaPi guides the optimization of a prototypical classifier by a linear classi-fier with which they share the same feature encoder, thus ex-plicitly encouraging the representation to reflect visual sim-ilarity between categories. It is also technically appealing, as PaPi requires only a few components in PiCO with the opposite direction of guidance, and directly eliminates the contrastive learning module that would introduce noise and consume computational resources. We empirically demon-strate that PaPi significantly outperforms other PLL meth-ods on various image classification tasks. 1.

Introduction
The excellent performance of modern deep neural net-works (DNNs) is attributed to the large-scale fully super-vised training data, but the requirement for high-quality data poses a challenge for the practical application. As a result, non-expert but cheap labelers are often resorted as an ap-pealing substitute, which inevitably leads to low-quality la-beled data due to their expertise limitation. A typical sit-* Equal contributions. † Corresponding author.
Figure 1. An image of “Eagle” in PLL is equipped with a candidate label set. PLL learns from such ambiguous supervision, in contrast to its supervised counterpart where only the true label is chosen. uation is that the labelers have difficulty in making an ac-curate judgement about an instance from multiple ambigu-ous labels, and therefore choose multiple likely ones. For example, in Fig. 1, it can be difficult for labelers without specialist knowledge to identify an Eagle from a Hawk, so both “Eagle” and “Hawk” are labeled as possible candi-dates for the true label. Learning from such training in-stances with a set of possible candidate labels, where only one fixed but unknown is true, is known as partial-label learning (PLL) [3, 4, 15, 22–24, 32, 38, 40]. This problem naturally arises in various important applications in the real world such as web mining [13] and image annotation [1].
Research into PLL dates back some twenty years and a number of practical approaches have been proposed, which can be divided into identification-based strategies [9, 20, 32, 38, 41] and average-based strategies [3, 8], depending on how they treat candidate labels. Recently, DNNs bring the research of PLL into a new era [4, 15, 26–28, 36, 37], among which PiCO [24] has achieved state-of-the-art per-It introduces a con-formance on multiple benchmarks. trastive learning module into PLL that uses predictions of one linear classifier to select pseudo positive samples for each anchor point and maintains a queue of negative sam-ples. Meanwhile, a momentum encoder is used to improve consistency. In addition, PiCO adds a prototypical classifier module (called prototype-based in the original) to guide the update of the linear classifier, which is based on the idea that there exists an embedding space where points from the same class cluster around its prototype [19]. PiCO claims credit for its success to the mutual benefit of contrastive learning and prototype-based label disambiguation.
(a) CIFAR-10 (q = 0.7) (b) CIFAR-100 (q = 0.2) (c) CIFAR-10 (q = 0.7) (d) CIFAR-100 (q = 0.2)
Figure 2. Visualizations of impacts of the unreliability of pseudo positives and the improper direction of disambiguation guidance in PiCO.
In (a)-(b), PiCO-v2 means positives are selected based on fully supervised information, i.e., true labels are known by the contrastive learning module. Further, PiCO-v3 removes the guidance of prototypical classifier to linear classifier, such that the linear classifier performs self-teaching. The red lines in (c)-(d) indicate the number of samples that were correctly classified by linear classifier and incorrectly classified by prototypical classifier per mini-batch, and the green lines are the opposite. The first 100 epochs shown in (d) are in a warm-up period. q means the flipping probability of each incorrect label, which will be introduced in Sec. 3.1.
In this paper, we rethink the two modules in PiCO and empirically point out that they do not work as well in practice as one might think due to the unreliability of the pseudo positives and the improper direction of disambigua-tion guidance. Fig. 2a and Fig. 2b show accuracy of three versions of PiCO. Fig. 2c and Fig. 2d show the performance differences between the linear and prototypical classifier during training. Fig. 2 delivers two important messages: (1) noisy pseudo-labels do lead to significant performance degradation, and (2) the phenomenon “poor teacher teaches good student” possibly happens. Specifically, the good stu-dent, the linear classifier, always made more correct pre-dictions than its teacher, the prototypical classifier, at the
In some cases, due to the forced direction of beginning. guidance, the teacher performed better than the student for a while, but soon the teacher had nothing new to teach the student, shown in Fig. 2c. And sometimes the student’s ad-vantage was even maintained until convergence as shown in Fig. 2d. These also explain the significant improvement compared to PiCO-v2 after PiCO-v3 made the clever stu-dent perform self-teaching.
Inspired by the above observations, we propose a sim-ple PLL framework termed PaPi, i.e., Partial-label learn-ing with a guided Prototypical classifier. PaPi directly eliminates the contrastive learning module which introduces noisy positives, and adopts the opposite direction of disam-biguation guidance compared to PiCO. Specifically, PaPi produces a similarity distribution over classes for each sam-ple based on a softmax function over distances to class-specific prototypes in a projected low-dimensional space.
Afterwards, PaPi aligns the distribution with the disam-biguated probability post-processed from one linear clas-sifier prediction. Meanwhile, the linear classifier performs self-teaching wherein each stage of learning is guided by the current and previous stages. We conduct extensive ex-periments on multiple image classification tasks. PaPi sur-passes the state-of-the-art PLL methods by a large margin, with a 4.57% improvement on CIFAR-100 in very difficult scenarios. Moreover, PaPi learns effective representations efficiently without using neither large batches nor a momen-tum encoder, where training instances from the same class are grouped into tighter clusters. Our main contributions are summarized as follows:
• We propose a simple PLL framework termed PaPi which explicitly encourages the representation to re-flect visual similarity between categories, such that
PaPi is remarkable for improving the class-level dis-crimination of learned representation.
• Extensive experiments on various image classification datasets with different generation processes of candi-date labels demonstrate PaPi significantly outperforms state-of-the-art PLL methods. 2.