Abstract
Existing continual learning (CL) research regards catas-trophic forgetting (CF) as almost the only challenge. This paper argues for another challenge in class-incremental learning (CIL), which we call cross-task class discrimi-nation (CTCD), i.e., how to establish decision boundaries between the classes of the new task and old tasks with no (or limited) access to the old task data. CTCD is implicitly and partially dealt with by replay-based methods. A replay method saves a small amount of data (replay data) from previous tasks. When a batch of current task data arrives, the system jointly trains the new data and some sampled re-play data. The replay data enables the system to partially learn the decision boundaries between the new classes and the old classes as the amount of the saved data is small.
However, this paper argues that the replay approach also has a dynamic training bias issue which reduces the effec-tiveness of the replay data in solving the CTCD problem. A novel optimization objective with a gradient-based adaptive method is proposed to dynamically deal with the problem in the online CL process. Experimental results show that the new method achieves much better results in online CL. 1.

Introduction
Continual learning (CL) learns a sequence of tasks in-crementally. This work focuses on the class incremental learning (CIL) setting [32] in online CL. In CIL, each task consists of a set of unique classes, the sets of classes of any two different tasks are disjoint and the system has no access to the task information in testing. In online CL, the data comes gradually from a data stream. Whenever the small batch of data arrives, it is trained in one iteration. Thus, the data for each task is effectively trained in one epoch.
Existing CL papers almost regard catastrophic forgetting (CF) as the only issue for CL. In fact, CIL also has another major challenge. When the system learns a new task, if no data from previous tasks is available, it has no way to es-tablish decision boundaries between new classes and old classes in previous tasks. Even if there is no CF, the classifi-cation results will still be poor. We call this problem, cross-task class discrimination (CTCD). Those approaches that do not save any previous data, e.g., regularization-based or orthogonal projection-based, do not deal with CTCD.
Replay-based methods implicitly deal with CTCD to some extent because such a method uses a memory buffer M to save a small amount of data (replay data) from old tasks.
When a small batch of current task data X new arrives, the system jointly trains X new and some sampled replay data
X buf from M. X buf enables the system to partially learn the decision boundaries between the new classes and the old classes because the amount of the saved data is very small.
Due to the limited replay data, the training is biased, which reduces its ability to solve the CTCD problem. To make matters worse, the training bias also changes as more tasks are learned. This paper first shows that the problem is reflected as gradient imbalance (GI) on logits, i.e., higher positive gradients than negative gradients on the logits and vice versa. It further shows that GI is caused by two main is-sues. The first is data imbalance. Since the memory buffer size, the batch size of the new data X new, and the sampled data X buf from the memory buffer are all fixed, if the system has learned many tasks, the average number of samples in each previous class in X buf will be much smaller than that of each class in X new. This results in higher positive gradients than negative gradients on the logits of the previous classes leading to training bias and poor decision boundaries (or weak CTCD capability) between the classes of the new and old tasks. The second is CL imbalance, i.e., CL training fo-cuses more on the new samples (which are harder to train as they are new) than the replayed samples (which have been seen and trained many times before). This causes further
GI. This imbalance is involved (see Sec. 4.2 for details).
Some existing works [2, 42] have tried to deal with data imbalance in offline CL. For example, SSIL [2] separately calculates the cross-entropy loss of the new data and the replay data to mitigate data imbalance. But they are not from the gradient angle. The second issue of GI is more complex and has not been attempted before.
This paper proposes a novel method, called GSA (Gradient Self-Adaptation), to deal with GI (and CTCD) in online CL. GSA includes a new training objective and a gradient-based self-adaptive loss to compensate for the GI.
The loss is dynamically controlled by two gradient rates which automatically measure and adapt to the dynamic GI situation. The main contributions of this paper are: (1) It deals with the CTCD problem in online CL and proposes a new optimization framework that decomposes the problem into cross-task classification and within-task classification (see Section 5). In [22], CTCD is called inter-task class separation, but it uses an out-of-distribution based approach to dealing with the problem in offline CL.
The paper uses a replay-based approach for online CL. (2) It analyzes the CTCD problem from the gradient im-balance (GI) angle and finds two kinds of gradient imbal-ance (data imbalance and CL imbalance) (see Section 4).
Based on the analysis, it proposes a gradient-based self-adaptive loss to compensate for the GI. (3) Experiments in both the disjoint and long-tail online
CL settings show that GSA outperforms strong baselines by a large margin (see Section 6). 2.