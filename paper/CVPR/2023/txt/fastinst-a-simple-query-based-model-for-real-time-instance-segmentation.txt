Abstract
Recent attention in instance segmentation has focused on query-based models. Despite being non-maximum suppres-sion (NMS)-free and end-to-end, the superiority of these models on high-accuracy real-time benchmarks has not been well demonstrated. In this paper, we show the strong potential of query-based models on efficient instance seg-mentation algorithm designs. We present FastInst, a sim-ple, effective query-based framework for real-time instance segmentation. FastInst can execute at a real-time speed (i.e., 32.5 FPS) while yielding an AP of more than 40 (i.e., 40.5 AP) on COCO test-dev without bells and whis-tles. Specifically, FastInst follows the meta-architecture of recently introduced Mask2Former.
Its key designs in-clude instance activation-guided queries, dual-path update strategy, and ground truth mask-guided learning, which en-able us to use lighter pixel decoders, fewer Transformer decoder layers, while achieving better performance. The experiments show that FastInst outperforms most state-of-the-art real-time counterparts, including strong fully con-volutional baselines, in both speed and accuracy. Code can be found at https://github.com/junjiehe96/
FastInst. 1.

Introduction
Instance segmentation aims to segment all objects of in-terest in an image. The mainstream methods like Mask
R-CNN [5, 15, 19, 28] follow the design of detection-then-segmentation. Despite being simple and intuitive, those methods generate a lot of duplicate region proposals that introduce redundant computations. To improve efficiency, many single-stage methods [2, 8, 23, 42] built upon Fully
Convolutional Networks (FCNs) [29] appear. They segment objects end-to-end without region proposals. The inference speed of such methods is appealing, especially in real-time scenes. However, due to the dense predictions, the classical single-stage methods still rely on manually-designed post-processing steps like non-maximum suppression (NMS).
Figure 1. Speed-performance trade-off on COCO test-dev.
All models employ ResNet-50 [16] as the backbone except Orien-Mask with DarkNet-53 [33]. Our FastInst surpasses most state-of-the-art real-time instance segmentation algorithms in both speed and accuracy. To keep the speed and accuracy in a similar order,
Mask2Former here takes the pyramid pooling module-based [48]
FPN as the pixel decoder, the same as FastInst and SparseInst.
Recently, with the success of DETR [4] in object detec-tion, query-based single-stage instance segmentation meth-ods [9, 10, 25, 43] have emerged.
Instead of convolution, they exploit the versatile and powerful attention mecha-nism [39] combined with a sequence of learnable queries to infer the object class and segmentation mask. For exam-ple, Mask2Former [9] simplifies the workflow of instance segmentation by adding a pixel decoder and a masked-attention Transformer decoder on top of a backbone. Un-like previous methods [15, 42], Mask2Former does not re-quire additional handcrafted components, such as training target assignment and NMS post-processing. While being simple, Mask2Former has its own issues: (1) it requires a large number of decoder layers to decode the object queries since its queries are learned static and need a lengthy pro-cess to refine; (2) It relies upon a heavy pixel decoder, e.g., multi-scale deformable attention Transformer (MSDefor-mAttn) [50], because its object segmentation mask straight-forwardly depends on the output of the pixel decoder, which
is used as a per-pixel embedding feature for distinguishing different objects; (3) masked attention restricts the recep-tive field of each query, which may cause the Transformer decoder to fall into a suboptimal query update process. Al-though Mask2Former achieves outstanding performance, its superiority on fast, efficient instance segmentation has not been well demonstrated, which yet is critical for many real-world applications such as self-driving cars and robotics. In fact, due to the lack of prior knowledge and the high com-putational complexity of the attention mechanism, the ef-ficiency of query-based models is generally unsatisfactory
[9, 18, 25]. The efficient real-time instance segmentation benchmarks are still dominated by classical convolution-based models [11, 42].
In this paper, we fill this gap by proposing FastInst, a concise and effective query-based framework for real-time instance segmentation. We demonstrate that the query-based model can achieve outstanding performance on the instance segmentation task while maintaining a fast speed, showing great potential in efficient instance segmentation algorithm design. As an example, our designed fastest query-based model with ResNet-50 [16] backbone achieves 35.6 AP at 53.8 FPS (frames-per-second) on the COCO [27] test-dev, evaluated on a single V100 GPU (see Fig-ure 1); moreover, our best trade-off model can execute at a real-time speed, i.e., 32.5 FPS, while yielding an AP of more than 40, i.e., 40.5 AP, which to the best of our knowl-edge, has not yet been achieved in previous methods.
Specifically, our model follows the meta-architecture of Mask2Former [9]. To achieve efficient real-time in-stance segmentation, we have proposed three key tech-niques. First, we use instance activation-guided queries, which dynamically pick the pixel embeddings with high semantics from the underlying feature map as the initial queries for the Transformer decoder. Compared with static zero [4] or learnable [9, 10] queries, these picked queries contain rich embedding information about potential objects and reduce the iteration update burden of the Transformer decoder. Second, we adopt a dual-path architecture in the
Transformer decoder where the query features and the pixel features are updated alternately. Such a design enhances the representational ability of pixel features and saves us from the heavy pixel decoder design. Moreover, it makes a direct communication between query features and pixel features, which speeds up the iterative update convergence and effectively reduces the dependence on the number of decoder layers. Third, to prevent the masked attention from falling into a suboptimal query update process, we intro-duce ground truth mask-guided learning. We replace the mask used in the standard masked attention with the last-layer bipartite matched ground truth mask to forward the
Transformer decoder again and use a fixed matching assign-ment to supervise the outputs. This guidance allows each query to see the whole region of its target predicted object during training and helps masked attention attend within a more appropriate foreground region.
We evaluate FastInst on the challenging MS COCO dataset [27]. As shown in Figure 1, FastInst obtains strong performance on the COCO benchmark while staying fast, surpassing most of the previous state-of-the-art methods.
We hope FastInst can serve as a new baseline for real-time instance segmentation and advance the development of query-based instance segmentation models. 2.