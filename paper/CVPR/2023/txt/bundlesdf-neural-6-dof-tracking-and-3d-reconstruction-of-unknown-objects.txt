Abstract
We present a near real-time (10Hz) method for 6-DoF tracking of an unknown object from a monocular RGBD video sequence, while simultaneously performing neural 3D reconstruction of the object. Our method works for arbi-trary rigid objects, even when visual texture is largely ab-sent. The object is assumed to be segmented in the first frame only. No additional information is required, and no assumption is made about the interaction agent. Key to our method is a Neural Object Field that is learned concur-rently with a pose graph optimization process in order to robustly accumulate information into a consistent 3D rep-resentation capturing both geometry and appearance. A dy-namic pool of posed memory frames is automatically main-tained to facilitate communication between these threads.
Our approach handles challenging sequences with large pose changes, partial and full occlusion, untextured sur-faces, and specular highlights. We show results on HO3D,
YCBInEOAT, and BEHAVE datasets, demonstrating that our method significantly outperforms existing approaches.
Project page: https://bundlesdf.github.io/ 1.

Introduction
Two fundamental (and closely related) problems in com-puter vision are 6-DoF (“degree of freedom”) pose tracking and 3D reconstruction of an unknown object from a monoc-ular RGBD video. Solving these problems will unlock a wide range of applications in areas such as augmented reality [34], robotic manipulation [22, 70], learning-from-demonstration [71], and sim-to-real transfer [1, 15].
Prior efforts often consider these two problems sepa-rately. For example, neural scene representations have achieved great success in creating high quality 3D object models from real data [3, 40, 44, 59, 68, 81]. These ap-proaches, however, assume known camera poses and/or ground-truth object masks. Furthermore, capturing a static object by a dynamically moving camera prevents full 3D reconstruction (e.g., the bottom of the object is never seen if resting on a table). On the other hand, instance-level 6-DoF object pose estimation and tracking methods of-ten require a textured 3D model of the test object before-hand [24, 28, 66, 72, 73] for pre-training and/or online tem-plate matching. While category-level methods enable gen-eralization to new object instances within the same cate-gory [7,27,62,67,74], they struggle with out-of-distribution object instances and unseen object categories.
To overcome these limitations, in this paper we pro-pose to solve these two problems jointly. Our method as-sumes that the object is rigid, and it requires a 2D object mask in the first frame of the video. Apart from these two requirements, the object can be moved freely through-out the video, even undergoing severe occlusion. Our ap-proach is similar in spirit to prior work in object-level
SLAM [35, 36, 50–52, 64, 85], but we relax many common assumptions, allowing us to handle occlusion, specularity, lack of visual texture and geometric cues, and abrupt object motion. Key to our method is an online pose graph opti-mization process, a concurrent Neural Object Field to re-construct the 3D shape and appearance, and a memory pool to facilitate communication between the two processes. The
robustness of our method is highlighted in Fig. 1.
Our contributions can be summarized as follows:
• A novel method for causal 6-DoF pose tracking and 3D reconstruction of a novel unknown dynamic object. This method leverages a novel co-design of concurrent track-ing and neural reconstruction processes that run online in near real-time while largely reducing tracking drift.
• We introduce a hybrid SDF representation to deal with uncertain free space caused by the unique challenges in a dynamic object-centric setting, such as noisy segmenta-tion and external occlusions from interaction.
• Experiments on three public benchmarks demonstrate state-of-the-art performance against leading methods. 2.