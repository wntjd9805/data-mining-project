Abstract
Many deep learning-based solutions to blind image de-blurring estimate the blur representation and reconstruct the target image from its blurry observation. However, these methods suffer from severe performance degradation in real-world scenarios because they ignore important prior information about motion blur (e.g., real-world motion blur is diverse and spatially varying). Some methods have at-tempted to explicitly estimate non-uniform blur kernels by
CNNs, but accurate estimation is still challenging due to the lack of ground truth about spatially varying blur ker-nels in real-world images. To address these issues, we pro-pose to represent the field of motion blur kernels in a latent space by normalizing flows, and design CNNs to predict the latent codes instead of motion kernels. To further improve the accuracy and robustness of non-uniform kernel estima-tion, we introduce uncertainty learning into the process of estimating latent codes and propose a multi-scale kernel at-tention module to better integrate image features with es-timated kernels. Extensive experimental results, especially on real-world blur datasets, demonstrate that our method achieves state-of-the-art results in terms of both subjec-tive and objective quality as well as excellent generaliza-tion performance for non-uniform image deblurring. The code is available at https://see.xidian.edu.cn/ faculty/wsdong/Projects/UFPNet.htm. 1.

Introduction
Blind single image deblurring is a classic low-level vi-sion problem that aims to recover the unknown sharp im-age from its observed blurry image without knowing the blur kernel. The uniform degradation model assumes that a blurry image is generated by a spatially invariant convo-lution process, which can be mathematically formulated as y = B(x, k) + n, (1)
*Corresponding author
Figure 1. The non-uniform kernel estimation and deblurring re-sults of the proposed UFPNet on the RealBlur-J dataset. where x and y are sharp image and blurry image, respec-tively, B(·, k) represents the blurring operator with the blur kernel k and n denotes the additive Gaussian noise. The simple case assumes the blur operation in Eq. (1) is uniform and the corresponding blur kernel is shift-invariant [11, 43].
Several methods have been proposed to estimate the blur kernel and sharp image simultaneously [6,34,42]. However, in the real world, there are several factors that can cause blur degradation, such as camera shake and object movement.
Although camera shake usually causes uniform and global background blurring, fast-moving objects often produce lo-cal blurring in the situation of a stationary background [50].
Therefore, the uniform blur in Eq. (1) is inappropriate for characterizing local blurring in the real world.
Traditional approaches to blind image deblurring first estimate the underlying blur kernels and then reconstruct the sharp image by iterative optimization [12, 28, 40, 44].
To constrain the solution space, both the image- and blur-related priors are exploited. In [29], the dark channel prior is used to estimate the blur kernel and reconstruct the sharp image. In [45], a novel extreme channel prior is proposed to facilitate the process of simultaneous image and kernel estimation. More recently, deep learning-based solutions have been proposed for blind image deblurring. Existing methods can be categorized into two classes. One class is to explicitly estimate the non-uniform blur kernel using convolutional neural networks (CNNs) [1, 2, 33, 37]. The other class of approaches is to use CNNs to directly recon-struct the original sharp image end-to-end without estimat-ing the blur kernel [7, 19, 23, 26, 31, 46–48, 51]. DeepDe-blur method [27] designs a multi-scale CNN to mimic con-ventional coarse-to-fine optimization and directly restores sharp images without assuming any restricted blur kernel model. SRN [38] proposes a scale-recurrent network and an encoder-decoder ResBlocks structure in each scale. Kupyn et al. propose DeblurGAN [19] and DeblurGAN-v2 [20] to reconstruct sharp images by adversarial training.
Unfortunately, both types of methods mentioned above have their fundamental limitations. First, since the charac-teristics of blur in real scenarios are complex, accurate es-timation of non-uniform (i.e., spatially varying) blur kernel is challenging. For example, there exists an inevitable un-certainty in kernel estimation because a blurry image may have multiple kernel candidates due to its ill-posed nature.
Therefore, incorrect blur kernels will lead to severe perfor-mance degradation in real-world image deblurring. Second, end-to-end methods ignore the information of motion prior, because the formation of image blur is usually associated with the motion trajectory of the camera and objects, which can be exploited for image deblurring effectively. The above observations inspire us to tackle the problem of blind image deblurring from a different perspective. The motiva-tion for our work is threefold. On the one hand, since there is no ground truth of the blur kernel of real blur datasets, we attempt to simulate the non-uniform motion kernels to facil-itate the kernel estimation in a self-supervised manner. On the other hand, we advocate a latent space approach to non-uniform blur kernel estimation, which is inspired by recent work on normalizing flows [13, 14, 16, 25]. Third, we intro-duce uncertainty learning to the process of estimating latent code, aiming to improve both the accuracy and robustness of non-uniform kernel estimation.
In this paper, we propose to model spatially varying mo-tion blur prior by introducing normalizing flow and uncer-tainty learning in the latent space to kernel estimation. To address the issue of non-uniform blur that varies from pixel to pixel, we propose to represent the motion blur kernels in a latent space by normalizing flow and designing CNNs to predict spatially varying latent codes instead of motion kernels. This latent space approach can be interpreted as the generalization of the existing flow-based kernel prior (FKP) [24] from uniform to non-uniform by incorporating kernel generation from simulated random trajectories (e.g.,
DeblurGAN [19]). To further improve the accuracy and robustness of kernel estimation, we introduce uncertainty learning into the process of estimating latent codes and pro-pose a multi-scale kernel attention module to better inte-grate image features with estimated kernels. The technical contributions of this paper are listed below.
• We propose to represent the non-uniform motion blur kernels in a latent space by normalizing flow. Our la-tent space approach allows CNNs to predict spatially varying latent codes rather than motion kernels. For the first time, we show how to estimate spatially vary-ing motion blur on a pixel-by-pixel basis.
• To further improve performance and robustness, we in-troduce uncertainty learning to the latent code estima-tion process. The network learns the variance of the latent code to quantify the corresponding uncertainty, which leads to a more accurate prediction than the de-terministic model.
• We propose a novel multi-scale kernel attention mod-ule to integrate image features and kernel information, which can be plugged into encoder-decoder architec-tures to incorporate the estimated kernels with the de-blurring network.
• In view of the lack of ground truth about the non-uniform motion kernel in real-world images, we tackle the training set generation in a self-supervised manner.
Extensive experimental results on benchmark datasets show that the proposed method significantly outper-forms existing state-of-the-art methods and demon-strated excellent generalization performance from Go-Pro to other real-world blur datasets. 2.