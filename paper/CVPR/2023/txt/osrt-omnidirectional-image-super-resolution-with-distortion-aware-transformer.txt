Abstract
Omnidirectional images (ODIs) have obtained lots of re-search interest for immersive experiences. Although ODIs require extremely high resolution to capture details of the entire scene, the resolutions of most ODIs are insufﬁcient.
Previous methods attempt to solve this issue by image super-resolution (SR) on equirectangular projection (ERP) images. However, they omit geometric properties of ERP in the degradation process, and their models can hardly gener-alize to real ERP images. In this paper, we propose Fisheye downsampling, which mimics the real-world imaging pro-cess and synthesizes more realistic low-resolution samples.
Then we design a distortion-aware Transformer (OSRT) to modulate ERP distortions continuously and self-adaptively.
Without a cumbersome process, OSRT outperforms previ-ous methods by about 0.2dB on PSNR. Moreover, we pro-pose a convenient data augmentation strategy, which syn-thesizes pseudo ERP images from plain images. This simple strategy can alleviate the over-ﬁtting problem of large net-works and signiﬁcantly boost the performance of ODISR.
Extensive experiments have demonstrated the state-of-the-art performance of our OSRT. 1.

Introduction
In pursuit of the realistic visual experience, omnidi-rectional images (ODIs), also known as 360◦ images or panoramic images, have obtained lots of research interest in the computer vision community. In reality, we usually view
ODIs with a narrow ﬁeld-of-view (FOV), e.g., viewing in a headset. To capture details of the entire scene, ODIs require extremely high resolution, e.g., 4K × 8K [1]. However, due to the high industrial cost of camera sensors with high pre-cision, the resolutions of most ODIs are insufﬁcient.
Recently, some attempts have been made to solve this problem by image super-resolution (SR) [12, 15, 28, 39, 40].
Unseen LR
LAU-Net [12] w/o Fisheye
OSRT w/o Fisheye
OSRT w/ Fisheye
Figure 1. Visual comparisons of ×8 SR results on LR images1with unknown degradations. Fisheye denotes that the downsampling process in training stages is under Fisheye images.
As most of the ODIs are stored and transmitted in the equirectangular projection (ERP) type, the SR process is usually performed on the ERP images. To generate high-/low-resolution training pairs, existing ODISR methods
[12, 15, 28, 39, 40] directly apply uniform bicubic down-sampling on the original ERP images (called ERP down-sampling), which is identical to general image SR settings
[24, 43]. While omitting geometric properties of ERP in the degradation process, their models can hardly general-ize to real ERP images. We can observe missing struc-tures and blur textures in Fig. 1. Therefore, we need a more appropriate degradation model before studying SR al-gorithms.
In practice, ODIs are acquired by the ﬁsheye lens and stored in ERP. Given that the low-resolution is-sue in real-world scenarios is caused by insufﬁcient sensor precision and density, the downsampling process should be applied to original-formatted images before converting into other storage types. Thus, to be conformed with real-world imaging processes, we propose to apply uniform bicubic
*Equal contribution
†Corresponding author (e-mail: chao.dong@siat.ac.cn) 1Photoed by Peter Leth on Flickr, with CC license.
downsampling on Fisheye images, which are the original format of ODIs. The new downsampling process (called
Fisheye downsampling) applies uniform bicubic downsam-pling on Fisheye images before converting them to ERP im-ages. Our Fisheye downsampling is more conducive to ex-ploring the geometric property of ODIs.
The key issue of ODISR algorithm design is to utilize the geometric properties of ERP images, which is also the focus of previous methods. For example, Nishiyama et al.
[28] add a distortion-related condition as an additional in-put. LAU-Net [12] splits the whole ERP image into patches by latitude band and learns upscaling processes separately.
However, the separated learning process will lead to infor-mation disconnection between adjacent patches. SphereSR
[40] learns different upscaling functions on various projec-tion types, but will inevitably introduce multiple-time com-putation costs. To push the performance upper bound, we propose the ﬁrst Transformer for Omnidirectional image
Super-Resolution (OSRT), and incorporate geometric prop-erties in a distortion-aware manner. Speciﬁcally, to mod-ulate distorted feature maps, we implement feature-level warping, in which offsets are learned from latitude condi-tions. In OSRT, we introduce two dedicated blocks to adapt latitude-related distortion: distortion-aware attention block (DAAB), and distortion-aware convolution block (DACB).
DAAB and DACB are designed to perform distortion mod-ulation in arbitrary Transformers and ConvNets. These two blocks can directly replace the multi-head self-attention block and convolution layer, respectively. The beneﬁt of
DAAB and DACB can be further improved when being in-serted into the same backbone network. OSRT outperforms previous methods by about 0.2dB on PSNR (Tab. 2).
However, the increase of network capacity will also en-large the overﬁtting problem of ODISR, which is rarely mentioned before. The largest ODIs dataset [12] contains only 1K images, which cannot provide enough diversity for training Transformers. Given that acquiring ODIs requires expensive equipment and tedious work, we propose to gen-erate distorted ERP samples from plain images for data aug-mentation. In practice, we regard a plain image as a sampled perspective, and project it back to the ERP format. Then we can introduce 146K additional training patches, 6 times of the previous dataset. This simple strategy can signiﬁcantly boost the performance of ODISR (Tab. 4) and alleviate the over-ﬁtting problem of large networks (Fig. 9). A similar data augmentation method is also applied in Nishiyama et al. [28], but shows marginal improvement on small models under ERP downsampling settings.
Our contributions are threefold. 1) For problem formula-tion: To generate more realistic ERP low-resolution images, we propose Fisheye downsampling, which mimics the real-world imaging process. 2) For method: Combined with the geometric properties of ERP, we design a distortion-aware
Transformer, which modulates distortions continuously and self-adaptively without cumbersome process. 3) For data:
To reduce overﬁtting, we propose a convenient data aug-mentation strategy, which synthesizes pseudo ERP images from plain images. Extensive experiments have demon-strated the state-of-the-art performance of our OSRT2. 2.