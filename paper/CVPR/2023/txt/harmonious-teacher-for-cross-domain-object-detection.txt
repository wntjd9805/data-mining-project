Abstract
Self-training approaches recently achieved promising re-sults in cross-domain object detection, where people it-eratively generate pseudo labels for unlabeled target do-main samples with a model, and select high-confidence samples to refine the model. In this work, we reveal that the consistency of classification and localization predic-tions are crucial to measure the quality of pseudo labels, and propose a new Harmonious Teacher approach to im-prove the self-training for cross-domain object detection.
In particular, we first propose to enhance the quality of pseudo labels by regularizing the consistency of the clas-sification and localization scores when training the detec-tion model. The consistency losses are defined for both labeled source samples and the unlabeled target samples.
Then, we further remold the traditional sample selection method by a sample reweighing strategy based on the con-sistency of classification and localization scores to improve the ranking of predictions. This allows us to fully ex-ploit all instance predictions from the target domain with-out abandoning valuable hard examples. Without bells and whistles, our method shows superior performance in various cross-domain scenarios compared with the state-of-the-art baselines, which validates the effectiveness of our Harmonious Teacher. Our codes will be available at https://github.com/kinredon/Harmonious-Teacher. 1.

Introduction
Object detection aims to recognize and localize objects in images simultaneously. As one of the fundamental tasks in computer vision, it plays an important role in many downstream vision tasks, including face recognition [33], person re-identification [42], instance segmentation [11], action recognition [8] and so on. With the development of deep convolution neural network (DCNN) [12,32], we have witnessed a performance breakthrough of object detection
*The corresponding author
Figure 1. Comparison of pseudo labels selection using classifi-cation score and our proposed harmony measure. Object detec-tion models often produce inconsistent predictions, e.g., bound-ing boxes with low classification score but high localization IoU (blue box) or with high classification score but low localization
IoU (red box) with ground truth box (green box). Existing self-training methods [6, 13, 22] usually adopt classification scores to rank the predictions and are easily biased to low-quality predic-tion.
In contrast, we use the harmony measure to consider the consistency of the classification and localization scores and prefer the accurate bounding box. in recent years [1, 11, 27, 28, 36]. One important driving force for such an advance is the availability of large-scale annotated training data. However, collecting and annotating those data are often extremely expensive in both time and fund, which even has been a major challenge for many real-world applications, for example, face authentication [39], autonomous driving [4], etc.
Cross-domain Object Detection (CDOD) [4, 6, 7, 13, 17– 19,22,30] has been proposed to address this problem, where the goal is to adapt an object detector from a labeled source domain to a novel unlabeled target domain.
In this way, great efforts can be saved from annotating training data in the target domain. Recently, researchers have reported that the self-training strategy achieves promising results in the
CDOD task. Generally, in the self-training framework, peo-ple use an existing object detection model to predict the ob-ject category labels and bounding boxes for the target do-main images, and select confident predictions as pseudo la-bels to continuously train the object detection model. These two steps are repeated alternatively for a certain times, and the final model is found to perform quite well in the target domain in many scenarios [6, 13, 22, 26, 43], as the infor-mation of the target domain is effectively exploited through training model with pseudo labels.
Nevertheless, existing methods are mainly motivated by self-training classification works, which may have draw-backs for the object detection task. One major issue is that existing methods usually adopt the classification score to select pseudo labels. However, since the classification and localization branches are separately trained, inconsis-tency between classification and localization scores may happen when predicting the target domain images. For ex-ample, the bounding boxes with high classification scores could considerably deviate from the ground-truth position (see example in Fig. 1). Such noise in pseudo labels in-evitably introduces bias in the learnt object detection model, leading to degradation in performance. Another issue is the hard thresholding for selecting confident pseudo-labeled instances. Despite how sophisticated it is for determin-ing such a threshold, simply abandoning low-confidence pseudo boxes is definitely undesirable, since valuable hard examples cannot be fully exploited, which is actually cru-cial for training the object detection model.
In this work, we propose a novel approach called Har-monious Teacher (HT) to improve the self-training frame-work for the CDOD task. On the one hand, to generate high-quality pseudo labels, we first propose to regularize the consistency of the classification prediction and the lo-calization score when training the detection model. For this purpose, a supervised harmonious loss and an unsu-pervised harmonious loss are respectively designed for the labeled source domain and the unlabeled target domain. On the other hand, to simultaneously alleviate the damage of low-quality predictions while fully exploiting hard exam-ples, we design a harmony measure to estimate the quality of pseudo-labeled samples based on the consistency of the classification prediction and the localization score. Then, we take all predicted instances into consideration and use the harmony measure to reweigh these instances for self-training, thus avoiding simply abandoning those valuable hard examples.
The contributions of this paper are listed as follows:
• We improve the self-training framework for CDOD and reveal that existing methods neglect the inconsis-tency between classification and localization, which hinders the performance of self-training.
• We propose a simple yet effective approach named
Harmonious Teacher (HT). We first propose harmo-nious model learning to regularize the consistency of the classification and localization predictions for both source and target domains. Then, we design a har-mony measure to estimate the quality of predictions and leverage the harmony measure to reweigh all the predictions in self-training without abounding valuable hard examples.
• We have conducted extensive experiments on four widely used CDOD benchmarks. The experimen-tal results show that our method clearly outper-forms the state-of-the-art baselines by a large mar-gin. For example, our method reaches 50.4% mAP on Cityscapes→FoggyCityscapes, which exceeds the state-of-the-art method OADA [43] by 5% mAP. 2.