Abstract
To acquire a snapshot spectral image, coded aperture snapshot spectral imaging (CASSI) is proposed. A core problem of the CASSI system is to recover the reliable and fine underlying 3D spectral cube from the 2D measure-ment. By alternately solving a data subproblem and a prior subproblem, deep unfolding methods achieve good perfor-mance. However, in the data subproblem, the used sensing matrix is ill-suited for the real degradation process due to the device errors caused by phase aberration, distortion; in the prior subproblem, it is important to design a suitable model to jointly exploit both spatial and spectral priors.
In this paper, we propose a Residual Degradation Learn-ing Unfolding Framework (RDLUF), which bridges the gap between the sensing matrix and the degradation process.
Moreover, a MixS2 Transformer is designed via mixing pri-ors across spectral and spatial to strengthen the spectral-spatial representation capability. Finally, plugging the
MixS2 Transformer into the RDLUF leads to an end-to-end trainable neural network RDLUF-MixS2. Experimental re-sults establish the superior performance of the proposed method over existing ones. Code is available: https:
//github.com/ShawnDong98/RDLUF_MixS2 1.

Introduction
With the application of coded aperture snapshot spectral imaging (CASSI) [1, 22, 30, 34], it has become feasible to acquire a spectral image using a coded aperture and disper-sive elements to modulate the spectral scene. By capturing a multiplexed 2D projection of the 3D data cube, CASSI technique provides an efficient approach for acquiring spec-tral data. Nonetheless, the reconstruction of an accurate and detailed 3D hyperspectral image (HSI) cube from the 2D measurements poses a fundamental challenge for the
CASSI system.
Based on CASSI, various reconstruction techniques have
This work was supported by the National Key Research and Devel-opment Program of China (No. 2019YFA0706604), the Natural Science
Foundation (NSF) of China (Nos. 61976169, 62293483).
* Corresponding author.
Figure 1. Comparison of PSNR-Parameters with previous HSI re-construction methods. The PSNR (in dB) is plotted on the vertical axis, while memory cost parameters are represented on the hor-izontal axis. Our proposed Residual Degradation Learning Un-folding Framework with Mixing priors across Spatial and Spec-tral (RDLUF-MixS2) Transformers outperforms previous meth-ods while requiring fewer parameters. been developed to reconstruct the 3D HSI cube from 2D measurements. These methods range from model-based techniques [15, 17, 18, 30, 33, 35, 38, 43], to end-to-end ap-proaches [5, 13, 16, 22, 23], and deep unfolding methods
[14, 31, 32]. Among them, deep unfolding methods have demonstrated superior performance by transferring conven-tional iterative optimization algorithms into a series of deep neural network (DNN) blocks. Typically, the deep unfold-ing methods tackle a data subproblem and a prior subprob-lem iteratively.
The data subproblem is highly related to the degrada-tion process. The ways to acquire the degradation matrix in the data subproblem can be classified into two types, the first directly uses the sensing matrix as the degradation ma-trix [19, 21, 32] and the other learns the degradation matrix using a neural network [14,24,44]. However, since the sens-ing matrix is obtained from the equidistant lasers of differ-ent wavelengths on the sensor, it cannot reflect the device errors caused by phase aberration, distortion and alignment of the continuous spectrum. Thus, the earlier kind does not take into account the gap between the sensing matrix and 1
the degradation process. In the latter type, directly model-ing the degradation process is challenging. Considering the challenge of optimizing the original, unreferenced mapping, it is preferable to focus on optimizing the residual mapping.
Therefore, we explicitly model the degradation process as residual learning with reference to the sensing matrix.
For the prior subproblem, a denoiser is trained to rep-resent the regularization term as a denoising problem in an implicit manner, typically implemented as an end-to-end neural network. Recently, Spectral-wise Multi-head
Self-Attention (S-MSA) has been introduced to model long-range dependency in the spectral dimension. However, S-MSA may neglect spatial information that is crucial for gen-erating high-quality HSI images, due to its implicit model-ing of spatial dependency. To this end, the integration of
Convolutional Neural Networks (CNNs) with S-MSA can provide an ideal solution as CNNs have the inductive bias of modeling local similarity, thus enhancing the spatial mod-eling capabilities of S-MSA. To achieve this, we propose a multiscale convolution branch that processes visual in-formation at multiple scales and then aggregates it to en-able simultaneous feature abstraction from different scales, thereby capturing more textures and details.
In this paper, we first unfold the Proximal Gradient De-scent (PGD) algorithm under the framework of maximum a posteriori theory for HSI reconstruction. Then, we integrate the residual degradation learning strategy into the data sub-problem of PGD, which briges the gap between the sensing matrix and the degradation process, leading to our Resid-ual Degradation Learning Unfolding Framework (RDLUF).
Secondly, a multiscale convolution called Lightweight In-ception is combined with spectral self-attention in a paral-lel design to address the problem of weak spatial modeling ability of S-MSA. To provide complementary clues in the spectral and spatial branches, we propose a bi-directional interaction across branches, which enhance the modeling ability in spectral and spatial dimensions respectively, re-sulting in our Mixing priors across Spatial and Spectral (MixS2) Transformer. Finally, plugging the MixS2 Trans-former into the RDLUF as the denoiser of the prior sub-problem leads to an end-to-end trainable neural network
RDLUF-MixS2. Equipped with the proposed techniques,
RDLUF-MixS2 achieves state-of-the-art (SOTA) perfor-mance on HSI reconstruction, as shown in Fig. 1. 2.