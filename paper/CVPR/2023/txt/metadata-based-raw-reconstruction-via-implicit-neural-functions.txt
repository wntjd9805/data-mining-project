Abstract
PSNR: 49.15dB
PSNR: 46.72dB
Many low-level computer vision tasks are desirable to utilize the unprocessed RAW image as input, which remains the linear relationship between pixel values and scene ra-diance. Recent works advocate to embed the RAW im-age samples into sRGB images at capture time, and recon-struct the RAW from sRGB by these metadata when needed.
However, there still exist some limitations in making full
In this paper, instead of following use of the metadata. the perspective of sRGB-to-RAW mapping, we reformulate the problem as mapping the 2D coordinates of the meta-data to its RAW values conditioned on the corresponding sRGB values. With this novel formulation, we propose to reconstruct the RAW image with an implicit neural function, which achieves significant performance improvement (more than 10dB average PSNR) only with the uniform sampling.
Compared with most deep learning-based approaches, our method is trained in a self-supervised way that requiring no pre-training on different camera ISPs. We perform further experiments to demonstrate the effectiveness of our method, and show that our framework is also suitable for the task of guided super-resolution. 1.

Introduction
Low-level computer vision tasks benefit a lot from the scene-referred RAW images [7, 39, 19, 17, 16], which is rendered to the display-referred standard RGB (sRGB) im-ages via camera image signal processors (ISPs). Compared with sRGB images, typical RAW images has the advantages of linear relationship between pixel values and scene ra-diance, as well as higher dynamic range. However, RAW images occupy obviously more memory than the sRGB im-ages in common format like JPEG, which is unfavourable for transferring and sharing. Moreover, since most dis-play and printing devices are designed for images stored and shared in sRGB format, it is inconvenient to directly re-place sRGB with RAW. Consequently, mapping sRGB im-ages back to their RAW counterparts, which is also called
RAW reconstruction, is regarded as the appropriate way to sRGB (input)
RIR [25]
SAM [28]
PSNR: 51.12dB
PSNR: 63.59dB
RAW (GT)
CAM [24]
Ours
Figure 1. As RAW images are beneficial to many low-level com-puter vision tasks, we aim to reconstruct the RAW image from the corresponding sRGB image with the assistance of extra meta-data.
In this figure, the reconstructed RAW images are visual-ized through error maps. As can be seen, our method remarkably outperforms other related methods with the improvement of more than 10 dB PSNR. We owe this performance boost to the effec-tiveness of our proposed implicit neural function (INF) . utilize the advantage of RAW data [23, 25, 36, 10, 28, 24].
Early RAW reconstruction methods focus on building standard models to reverse ISPs, which is parameterized by either explicit functions [4, 18, 14, 5] or neural net-works [23, 36, 10]. However, these approaches are faced with the same issue that a parameterized model is only suitable for a specific ISP. Meanwhile, a series of meth-ods [25, 26, 28, 24] propose to overcome this problem by embedding extra metadata into sRGB images at capture time. For such methods, the main challenge is to improve the accuracy with lower metadata generation cost. RIR [25] implements complex optimization algorithm to estimate the global mapping parameters as metadata, but suffers high computational cost. SAM [28] adopts a uniform sampling on RAW images to generate the metadata, which is further replaced with a sampler network by CAM [24].
For the metadata-based methods of SAM [28] and
CAM [24], the embedded RAW samples stores partial infor-mation of ISPs which helps to reconstruct the RAW images better; also, by conditioning the reconstruction algorithm on
these metadata, the recovery of the RAW data turns into a conditional mapping function instead of a function fitted to a specific case, enabling the potential to achieve better gen-eralization. Therefore, we adopt this strategy in the paper.
Despite the progress that SAM [28] and CAM [24] have made, there still exist some limitations for the metadata-based RAW reconstruction methods. SAM utilizes RBF in-terpolation [3], the main idea of which is to calculate the difference between sampling and target points by a kernel function. However, a fixed kernel function lacks the flexi-bility to model various sRGB-to-RAW mappings. CAM di-rectly uses a neural network for reconstruction but requires pre-training on pairs of sRGB and raw data from different types of ISPs. Also, we observe that the results of these methods fail to recover the saturated regions [26] (i.e., pix-els with any channel value close to the maximum), as is shown in Figure 1.
To address the limitation, we propose a two-way RAW reconstruction algorithm based on an implicit neural func-tion (INF). Previously, RAW reconstruction is formulated as mapping a sRGB image and the metadata to its RAW im-age. In this paper, we reformulate the problem as mapping the 2D coordinates of the metadata to its RAW values con-ditioned on the corresponding sRGB values, i.e. an implicit function. With this novel formulation, we can also decom-pose the problem into two aspects: a mapping function from the sRGB values to the corresponding raw values; a super-resolution function to interpolate the RAW image from the sparse samples. We observe that the super-resolution part usually exhibits much higher errors, indicating the latter a more challenging task. Accordingly, two branches are de-signed for each task inside an implicit neural network and the hyper-parameters for these branches are tuned to accom-modate the difficulty of the tasks. Also, notice that with this formulation, the network can be trained in a self-supervised way, without the need of corresponding RAW images.
Our contribution can be summarized as follows:
• We reformulate the RAW reconstruction problem as a RAW image approximation problem that learns the 2D-to-RAW mapping of image coordinates to RAW values conditioned on its sRGB image.
• We decompose the reconstruction into two aspects and design the implicit neural network accordingly.
• We conduct extensive experiments on different cam-eras and demonstrate our algorithm outperforms exist-ing work significantly. 2.