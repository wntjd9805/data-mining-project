Abstract
We present a simple yet effective self-supervised pre-training method for image harmonization which can lever-age large-scale unannotated image datasets. To achieve this goal, we first generate pre-training data online with our Label-Efficient Masked Region Transform (LEMaRT) pipeline. Given an image, LEMaRT generates a foreground mask and then applies a set of transformations to perturb various visual attributes, e.g., defocus blur, contrast, satu-ration, of the region specified by the generated mask. We then pre-train image harmonization models by recovering the original image from the perturbed image. Secondly, we introduce an image harmonization model, namely SwinIH, by retrofitting the Swin Transformer [27] with a combina-tion of local and global self-attention mechanisms. Pre-training SwinIH with LEMaRT results in a new state of the art for image harmonization, while being label-efficient, i.e., consuming less annotated data for fine-tuning than ex-isting methods. Notably, on iHarmony4 dataset [8], SwinIH outperforms the state of the art, i.e., SCS-Co [16] by a mar-gin of 0.4 dB when it is fine-tuned on only 50% of the train-ing data, and by 1.0 dB when it is trained on the full training dataset. 1.

Introduction
The goal of image harmonization is to synthesize photo-realistic images by extracting and transferring foreground regions from an image to another (background) image. The main challenge is the appearance mismatch between the foreground and the surrounding background, due to dif-ferences in camera and lens settings, capturing conditions, such as illumination, and post-capture image processing.
Image harmonization aims to resolve this mismatch by ad-justing the appearance of the foreground in a composite im-age to make it compatible with the background. Research in image harmonization has relevant applications in photo-realistic image editing and enhancement [42,44], video syn-thesis [23, 37] and data augmentation for various computer vision tasks [11, 12, 35].
Figure 1. Top: given an image, LEMaRT applies a set of transfor-mations, e.g., brightness, hue adjustment, to obtain a transformed image. The transformed image is then combined with the original image to form a composite image, which is used to pre-train our
SwinIH image harmonization model. As shown in the right-hand column, SwinIH is capable of reconstructing photo-realistic out-put images after pre-training and fine-tuning. Bottom: using our
LEMaRT pre-training scheme, our image harmonization model (SwinIH) surpasses state of the art (SOTA) counterparts with less than 40% of the training data from iHarmony4 for fine-tuning.
Traditional image harmonization approaches perform color transforms to match the low-level color statistics of the foreground to the background with the aim to achieve photorealism [22, 31, 33, 39]. However, the generalization
ability of these methods is questionable because the eval-uation was only conducted at a small scale, mainly using human judgement. More recent works [8] have constructed real image harmonization datasets with tens to thousands of images to train learning-based methods. However, due to the bottleneck of manual editing, these datasets do not match the scale often required to train large-scale neural networks. Rendered image datasets [3, 15] are more scal-able but they suffer from the domain gap between synthetic and real images. As a result, the performance of image har-monization models is constrained by the limited size of a few existing datasets [8, 20] on which they can be trained.
Inspired by the impressive performance leap achieved by pre-trained models [17, 29] on various downstream tasks, e.g., image classification, object detection, image caption-ing, in this work, we introduce a novel self-supervised pre-training method to boost the performance of image harmo-nization models while being label-efficient, i.e., consum-ing small amounts of fine-tuning data. The novelty of our technique lies in the use of foreground masking strategies and the perturbation of foreground visual attributes to self-generate training data without annotations. Hence, we name our pre-training method as Label-Efficient Masked Region
Transform (LEMaRT). In the first step, LEMaRT proposes pseudo foreground regions in an image. Subsequently, it ap-plies a set of transformations to perturb visual attributes of the foreground, including contrast, sharpness, blur and satu-ration. These transformations aim to mimic the appearance discrepancy between the foreground and the background.
Using the transformed image, i.e., image with the perturbed foreground, as the input, LEMaRT pre-trains image harmo-nization models to reconstruct the original image, as shown in the top half of Figure 1.
Subsequently, we design an image harmonization model based on Swin Transformer [27], namely SwinIH, which is short for Swin Image Harmonization. We build our model upon Swin Transformer instead of the ViT model [10] mainly due to the efficiency gain offered by its local shifted window (Swin) attention. Similar to the design of the original Swin Transformer, we keep the local self-attention mechanism in all the Transformer blocks up except the last one, where we employ global self-attention. We introduce global self-attention into SwinIH to alleviate block bound-ary artifacts produced by the Swin Transformer model when it is directly trained for image harmonization.
We verify that LEMaRT consistently improves the per-formance of models with a range of vision Transformer and
CNN architectures compared to training only on the target dataset, e.g., iHarmony4. When we pre-train our SwinIH model on MS-COCO dataset with LEMaRT and then fine-tune it on iHarmony4 [8], it outperforms the state of the art [16] by 0.4 dB while using only 50% of the samples from iHarmony4 for fine-tuning, and by 1.0 dB when using all the samples (see the plot in the bottom half of Figure 1).
The key contributions of our work are summarized below.
• We introduce Label-Efficient Masked Region Transform (LEMaRT), a novel pre-training method for image harmo-nization, which is able to leverage large-scale unannotated image datasets.
• We design SwinIH, an image harmonization model based on the Swin Transformer architecture [27].
• LEMaRT (SwinIH) establishes new state of the art on iHarmony4 dataset, while consuming significantly less amount of training data. LEMaRT also boosts the perfor-mance of models with various network architectures. 2.