Abstract
Contrastive learning is a self-supervised representation learning method that achieves milestone performance in various classification tasks. However, due to its unsuper-vised fashion, it suffers from the false negative sample prob-lem: randomly drawn negative samples that are assumed to have a different label but actually have the same label as the anchor. This deteriorates the performance of contrastive learning as it contradicts the motivation of contrasting se-mantically similar and dissimilar pairs. This raised the at-tention and the importance of finding legitimate negative samples, which should be addressed by distinguishing be-tween 1) true vs. false negatives; 2) easy vs. hard negatives.
However, previous works were limited to the statistical ap-proach to handle false negative and hard negative samples with hyperparameters tuning. In this paper, we go beyond the statistical approach and explore the connection between hard negative samples and data bias. We introduce a novel debiased contrastive learning method to explore hard neg-atives by relative difficulty referencing the bias amplifying counterpart. We propose triplet loss for training a biased encoder that focuses more on easy negative samples. We theoretically show that the triplet loss amplifies the bias in self-supervised representation learning. Finally, we empiri-cally show the proposed method improves downstream clas-sification performance. 1.

Introduction
The key idea of contrastive learning [4, 5, 31] is to learn the representation that projects samples from the same class to be closer to each other than samples from different classes in the embedding space. To ensure this property in an unsupervised manner, we randomly draw a sample (anchor, xa) and enforce it to stay closer to its own aug-mentations (positive samples, x+) and be apart from the other samples (negative samples, xâˆ’) also randomly drawn
*Corresponding author. from the same training dataset. Such approach achieves superior performance over conventional supervised classi-fication methods in various tasks, such as object detection
[12, 39, 43] and natural language processing [28].
Recent works study sampling methods to draw good-quality positive and negative samples to train effective self-supervised contrastive learning models. Various augmen-tation and positive sampling techniques are developed to boost the performance and generalization. For example, random noise perturbations [4, 7, 39] are adopted in the computer vision domain to preserve semantic information such as random cropping, random noise injection, and tilt-ing. Unlike positive sampling, finding legitimate negative samples is not a trivial problem. First, negative samples are not guaranteed to have a different class from the an-chor [8, 19] due to the unsupervised fashion of contrastive learning. Thus, the debiasing method [8] was proposed to address this false negatives problem by decomposing the marginal data distribution. Second, finding hard negative samples, i.e., hard to distinguish from the anchor, is crucial as they are more informative [36]. Supervised contrastive learning [19] validated the importance of hard negative min-ing. However, this has been rarely studied in the literature.
In supervised learning, e.g., classification, some works observed hard samples are related to data bias. Because some models tend to be misled by some correlation between biasing attributes and target labels, such as texture, color, and background in image classification [2,25], and race and gender in face recognition [17], samples against such cor-relation are likely to be hard samples. For instance, in the animal classification task, if most bird images in the train-ing set are assumed to have sky as a background instead of others, sky would be strongly correlated with the class bird. However, birds may also exist in other backgrounds, such as water, rock, etc. We can consider these birds in the background other than the sky as bias-conflicting sam-ples. Then, it is natural to emphasize bias-conflicting sam-ples (birds on water) more than bias-aligned ones (birds in the sky) for better performance and generalization as they are more informative. From the contrastive learning view-point, these bias-conflicting samples are likely to be hard to distinguish from the anchor (e.g., frog on water) and are nat-urally linked to hard negatives in the representation space.
To address this, some methods [2, 20] specified the bias based on empirical observations on the task. For exam-ple, CNN is known to be biased towards the texture [10].
Bahng et al. [2] proposed an adversary that focuses exclu-sively on texture and limits the size of the receptive field of the convolutional layer to predict the target. However, it is almost infeasible to pre-define the bias attributes for each task, and also, the debiasing would be limited to the speci-fied attributes. Recent studies [25, 26, 30] proposed to em-phasize bias-conflicting samples by up-weighting hard sam-ples without pre-defined bias information in the supervised classification task. Yet, this approach is limited to classifi-cation tasks. Despite the importance of finding hard nega-tives [36], little attention is paid to finding bias-conflicting samples in self-supervised representation learning methods.
Unlike the previous studies, we delve into the question: what makes a sample hard negative or easy negative in self-supervised learning? To the best of our knowledge, few studies in contrastive learning have been done from this perspective. In this work, we propose a novel contrastive learning method to effectively find hard negative samples from the data bias perspective. We employ triplet loss [38] to learn bias-amplified representations in a self-supervised manner. In Section 5.2, we theoretically show that minimiz-ing triplet loss enforces a model to focus on easy samples and ignores hard samples. Along with the biased model, we train the debiased model based on the relative difficulty of each sample by measuring relative distance between the representation from two models and the anchor as the sur-rogate of sample difficulty.
The contribution of this work is summarized as follows: 1. We propose a debiased contrastive learning method that addresses two types of biases: hard vs. easy nega-tives and true vs. false negatives. 2. We introduce triplet loss to amplify the bias in the rep-resentation space, which serves as an effective surro-gate for learning the relative difficulty of samples in self-supervised contrastive learning. 3. We empirically validate that our learned representation achieves higher accuracy and reduced bias in down-stream tasks compared with related methods in image and tabular data classification. 2.