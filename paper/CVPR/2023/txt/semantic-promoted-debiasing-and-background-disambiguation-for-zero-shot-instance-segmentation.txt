Abstract
Zero-shot instance segmentation aims to detect and pre-cisely segment objects of unseen categories without any
Since the model is trained on seen training samples. categories, there is a strong bias that the model tends to classify all the objects into seen categories. Besides, there is a natural confusion between background and novel
These objects that have never shown up in training. two challenges make novel objects hard to be raised in the final instance segmentation results.
It is desired to rescue novel objects from background and dominated seen categories. To this end, we propose D2Zero with Semantic-Promoted Debiasing and Background Disambiguation to enhance the performance of Zero-shot instance segmenta-tion. Semantic-promoted debiasing utilizes inter-class se-mantic relationships to involve unseen categories in visual feature training and learns an input-conditional classifier to conduct dynamical classification based on the input im-age. Background disambiguation produces image-adaptive background representation to avoid mistaking novel objects for background. Extensive experiments show that we sig-nificantly outperform previous state-of-the-art methods by a large margin, e.g., 16.86% improvement on COCO. 1.

Introduction
Existing fully supervised instance segmentation meth-ods [4, 23, 52] are commonly benchmarked on predefined datasets with an offline setting, where all categories are defined beforehand and learned at once, thus can neither handle novel concepts outside training datasets nor scale the model’s ability after training. Perception errors inevitably arise when applying a trained instance segmentation model to scenarios that contain novel categories. To address these challenges, zero-shot instance segmentation (ZSIS) [65] is introduced to segment instances of unseen categories with no training images but semantic information only.
†Equal contribution. (cid:0) Corresponding author (henghui.ding@gmail.com).
Figure 1. Two key challenges in generalized zero-shot instance segmentation. 1) Bias issue: the model tends to label novel objects with seen categories, e.g., ZSI [65] incorrectly classifies unseen class dog as training class horse. 2)