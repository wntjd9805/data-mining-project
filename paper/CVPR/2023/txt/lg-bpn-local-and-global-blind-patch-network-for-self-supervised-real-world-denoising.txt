Abstract
Despite the significant results on synthetic noise un-der simplified assumptions, most self-supervised denoising methods fail under real noise due to the strong spatial noise correlation, including the advanced self-supervised blind-spot networks (BSNs). For recent methods targeting real-world denoising, they either suffer from ignoring this spatial correlation, or are limited by the destruction of fine textures for under-considering the correlation.
In this paper, we present a novel method called LG-BPN for self-supervised real-world denoising, which takes the spatial correlation statistic into our network design for local detail restora-tion, and also brings the long-range dependencies model-ing ability to previously CNN-based BSN methods. First, based on the correlation statistic, we propose a densely-sampled patch-masked convolution module. By taking more neighbor pixels with low noise correlation into account, we enable a denser local receptive field, preserving more use-ful information for enhanced fine structure recovery. Sec-ond, we propose a dilated Transformer block to allow dis-tant context exploitation in BSN. This global perception addresses the intrinsic deficiency of BSN, whose receptive field is constrained by the blind spot requirement, which can not be fully resolved by the previous CNN-based BSNs.
These two designs enable LG-BPN to fully exploit both the detailed structure and the global interaction in a blind manner. Extensive results on real-world datasets demon-strate the superior performance of our method. https:
//github.com/Wang-XIaoDingdd/LGBPN 1.

Introduction
Image denoising is a fundamental research topic for low-level vision [7, 36]. Noise can greatly degrade the quality of the captured images, thus bringing adverse impacts on the subsequent downstream tasks [22, 32]. Recently, with the rapid development of neural networks, learning-based methods have shown significant advances compared with traditional model-based algorithms [5, 8, 10, 11].
*Corresponding Author
DnCNN [36] 31.17/0.778
C2N [15] 28.09/0.706
R2R [26] 30.37/0.770
SIDD Validation: 0018-0031
CVF-SID [25] 28.56/0.792
AP-BSN [20] LG-BPN (Ours) 31.92/0.826 32.76/0.897
Figure 1. Visual comparison of various methods on the SIDD val-idation [1] dataset. Compared with DnCNN [36], C2N [15] and
R2R [15], LG-BPN can be trained in a self-supervised manner without extra data. CVF-SID [25] still contains noise in the out-put, and AP-BSN [20] suffers from the loss of details.
Unfortunately, learning-based methods often rely on massive labeled image pairs for training [2, 34, 35]. This can not be simply addressed by synthesizing additive white
Gaussian noise (AWGN) pairs, since the gap between
AWGN and real noise distribution severely degrades their performance in the real world [2, 12]. To this end, several attempts have been made for collecting real-world datasets
[1, 4]. Nonetheless, its application is still hindered by the rigorously-controlled and labor-intensive collection proce-dure. For instance, capturing ground truth images requires long exposure or multiple shots, which is unavailable in complex situations, e.g., dynamic scenes with motion.
To alleviate the constraint of the large-scale paired dataset, methods without the need for ground truth have at-tracted increasing attention. The pioneer work Noise2Noise (N2N) [21] uses paired noisy observations for training, which can be applied when clean images are not available.
Still, obtaining such noisy pairs under the same scene is less feasible. To make self-supervised methods more prac-tical, researchers seek to learn from one, instead of pairs of observations. Among these methods, blind-spot networks (BSNs) [3, 17, 19, 30] show significant advances to restore clean pixels by utilizing neighbor pixels, with a special blind spot receptive field requirement. Despite their promis-ing results on simple noise such as AWGN, these methods
usually work under simplified assumptions, e.g., the noise is pixel-wise independent. This obviously does not hold for real noise, where the distribution can be extremely complex and present a strong spatial correlation.
Accordingly, a few methods have been proposed for self-supervised real noise removal. Recorrupted-to-Recorrupted (R2R) [26] tries to construct noisy-noisy pairs, while it can not be directly applied without extra information, which is not practical in real situations. CVF-SID [25] disentangles the noise components from noisy images, but it assumes the real noise is spatially invariant and ignores the spatial correlation, which contradicts real noise distribution.
Recently, AP-BSN [20] combines pixel-shuffle down-sampling (PD) with the blind spot network (BSN). Though
PD can be utilized to meet the noise assumption of BSN, simply combining PD with CNN-based BSN is sub-optimal for dealing with spatially-correlated real noise.
It causes damage to local details, thus bringing artifacts to the sub-sampled images, e.g., aliasing artifact, especially for large
PD stride factors [20, 38]. Also, though more advanced de-signs of BSNs have been proposed [18, 19, 31], CNN-based
BSNs fail to capture long-range interactions due to their convolution operator, which is further bounded by the lim-ited receptive field under the blind spot requirement.
In this paper, we present a novel method, called LG-BPN, to address these issues on self-supervised real im-age denoising, including the reliance on extra information, the loss of local structures by noise correlation, and also the lacking of modeling distant pixel interaction. LG-BPN can be directly trained without external information. Fur-thermore, we ease the destruction of fine textures by care-fully considering the spatial correlation in real noise, at the same time injecting long-range interaction by tailoring
Transformers to the blind spot network. First, for local in-formation, we introduce a densely-sampled patch-masked convolution (DSPMC) module. Based on the prior statis-tic of real noise spatial correlation, we take more neighbor pixels into account with a denser receptive field, allowing the network to recover more detailed structures. Second, for global information, we introduce a dilated Transformer block (DTB). Under the special blind spot requirement, this greatly enlarges the receptive field compared with previous
CNN-based BSNs, permitting more neighbors to be utilized when predicting the central blind spot pixel. These two de-signs enable us to fully exploit local and global informa-tion, respectively. Extensive studies demonstrate that LG-BPN outperforms other state-of-the-art un-/self-supervised methods on real image denoising, as shown in Figure 1. We summarize our contributions as follows:
• We present a novel self-supervised method called LG-BPN for real-world image denoising, which can effec-tively encode both the local detailed structure and the capture of global representation.
• Based on the analysis of real noise spatial correlation, we propose DSPMC module, which takes advantage of the higher sampling density on the neighbor pixels, en-abling a denser receptive field for improved local tex-ture recovery.
• To establish long-distance dependencies in previous
CNN-based BSN methods, we introduce DTB, which aggregates global context while complying with the constraint of blind spot receptive field. 2.