Abstract
Neural-network-based single image depth prediction (SIDP) is a challenging task where the goal is to predict the scene’s per-pixel depth at test time. Since the prob-lem, by definition, is ill-posed, the fundamental goal is to come up with an approach that can reliably model the scene depth from a set of training examples. In the pursuit of per-fect depth estimation, most existing state-of-the-art learn-ing techniques predict a single scalar depth value per-pixel.
Yet, it is well-known that the trained model has accuracy limits and can predict imprecise depth. Therefore, an SIDP approach must be mindful of the expected depth variations in the model’s prediction at test time. Accordingly, we in-troduce an approach that performs continuous modeling of per-pixel depth, where we can predict and reason about the per-pixel depth and its distribution. To this end, we model per-pixel scene depth using a multivariate Gaussian distri-bution. Moreover, contrary to the existing uncertainty mod-eling methods—in the same spirit, where per-pixel depth is assumed to be independent, we introduce per-pixel covari-ance modeling that encodes its depth dependency w.r.t. all the scene points. Unfortunately, per-pixel depth covariance modeling leads to a computationally expensive continuous loss function, which we solve efficiently using the learned low-rank approximation of the overall covariance matrix.
Notably, when tested on benchmark datasets such as KITTI,
NYU, and SUN-RGB-D, the SIDP model obtained by opti-mizing our loss function shows state-of-the-art results. Our method’s accuracy (named MG) is among the top on the
KITTI depth-prediction benchmark leaderboard1. 1.

Introduction
Recovering the depth of a scene using images is critical to several applications in computer vision [2, 15, 25, 29, 30].
It is well founded that precise estimation of scene depth
*Corresponding Author (k.sur46@gmail.com) 1http : / / www . cvlibs . net / datasets / kitti / eval _ depth.php?benchmark=depth_prediction (a) Test Image (b) DPT [51] (c) AdaBins [7] (d) NeWCRFs [75] (e) Ours (f) Ground Truth
Figure 1. Qualitative Comparison. By modeling scene depth as multivariate Gaussian and enforcing the parametric low-rank covariance constraints in the loss function, we observe that our model can reliably predict depth for both high-frequency and low-frequency scene details. In the above example, we can notice bet-ter qualitative results than the state-of-the-art methods. from images is likely only under multi-view settings [65]— which is indeed a correct statement and hard to contend2.
But what if we could effectively learn scene depth using im-ages and their ground-truth depth values, and be able to pre-dict the scene depth using just a single image at test time?
With the current advancements in deep learning techniques, this seems quite possible empirically and has also led to ex-cellent results for the single image depth prediction (SIDP) task [40, 51]. Despite critical geometric arguments against
SIDP, practitioners still pursue this problem not only for a scientific thrill but mainly because there are several real-world applications in which SIDP can be extremely benefi-cial. For instance, in medical [42], augmented and virtual reality [21, 55], gaming [19], novel view synthesis [56, 57], robotics [64], and related vision applications [24, 51].
Regardless of remarkable progress in SIDP [1,36,37,39, 40, 50, 75], the recent state-of-the-art deep-learning meth-ods, for the time being, just predict a single depth value per pixel at test time [37]. Yet, as is known, trained models have accuracy limits. As a result, for broader adoption of SIDP in 2As many 3D scene configurations can have the same image projection.
applications, such as robot vision and control, it is essential to have information about the reliability of predicted depth.
Consequently, we model the SIDP task using a continuous distribution function. Unfortunately, it is challenging, if not impossible, to precisely model the continuous 3D scene. In this regard, existing methods generally resort to increasing the size and quality of the dataset for better scene modeling and improve SIDP accuracy. On the contrary, little progress is made in finding novel mathematical modeling strategies and exploiting the prevalent scene priors. To this end, we propose a multivariate Gaussian distribution to model scene depth. In practice, our assumption of the Gaussian model-ing of data is in consonance with real-world depth data (see
Fig. 2) and generalizes well across different scenes. Fur-thermore, many computer and robot vision problems have successfully used it and benefited from Gaussian distribu-tion modeling in the past [9, 20, 45, 53, 63, 72, 77].
Let’s clarify this out way upfront that this is not for the first time an approach with a motivation of continuous mod-eling for SIDP is proposed [4,22,26,28,31,47]. Yet, existing methods in this direction model depth per pixel indepen-dently. It is clearly unreasonable, in SIDP modeling, to as-sume absolute democracy among each pixel, especially for very closeby scene points. Therefore, it is natural to think of modeling this problem in a way where depth at a particu-lar pixel can help infer, refine, and constrain the distribution of depth value for other image pixels. Nevertheless, it has yet to be known a priori the neighboring relation among pixels in the scene space to define the depth covariance among them. We do that here by defining a very general covariance matrix of dimension number of pixels × number of pixels, i.e., depth prediction at a given pixel is assumed to be dependent on all other pixels’ depth.
Overall, we aim to advocate multivariate Gaussian mod-eling with a notion of depth dependency among pixels as a useful scene prior. Now, add a fully dependent covariance modeling proposal to it—as suitable relations among pixels are not known. This makes the overall loss function com-putationally expensive. To efficiently optimize the proposed formulation, we parameterize the covariance matrix, assum-ing that it lies in a rather low-dimensional manifold so that it can be learned using a simple neural network. For train-ing our deep network, we utilize the negative log likelihood as the loss function (cf. Sec. 3.1). The trained model when tested on standard benchmark datasets gives state-of-the-art results for SIDP task (see Fig. 1 for qualitative comparison).
Contributions. To summarize, our key contributions are:
• A novel formulation to perform multivariate Gaussian co-variance modeling for solving the SIDP task in a deep neural network framework is introduced.
• The introduced multivariate Gaussian covariance model-ing for SIDP is computationally expensive. To solve it efficiently, the paper proposes to learn the low-rank co-(a) First scene (b) Second scene
Figure 2. The marginal ground-truth depth distribution for a pixel pair Za, Zb for two scenes. The depth values for the pixel pair are taken from the fixed image location in the dataset, but the se-lected images are visually similar for the suitability of the feature and its corresponding depth values. The statistics show that the
Gaussian distribution assumption with covariance modeling is a sensible choice for SIDP problem and not an unorthodox belief arranged or staged for an intricate formulation. variance matrix approximation by deep neural networks.
• Contrary to the popular SIDP methods, the proposed ap-proach provides better depth as well as a measure of the suitability of the predicted depth value at test time. 2.