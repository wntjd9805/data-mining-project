Abstract 1.

Introduction
We propose a method that learns to camouflage 3D ob-jects within scenes. Given an object’s shape and a distribu-tion of viewpoints from which it will be seen, we estimate a texture that will make it difficult to detect. Successfully solv-ing this task requires a model that can accurately reproduce textures from the scene, while simultaneously dealing with the highly conflicting constraints imposed by each view-point. We address these challenges with a model based on texture fields and adversarial learning. Our model learns to camouflage a variety of object shapes from randomly sam-pled locations and viewpoints within the input scene, and is the first to address the problem of hiding complex object shapes. Using a human visual search study, we find that our estimated textures conceal objects significantly better than previous methods.
*Work done while at University of Michigan
Using fur, feathers, spots, and stripes, camouflaged ani-mals show a remarkable ability to stay hidden within their environment. These capabilities developed as part of an evolutionary arms race, with advances in camouflage lead-ing to advances in visual perception, and vice versa.
Inspired by these challenges, previous work [33] pro-posed the object nondetection problem: to create an appear-ance for an object that makes it undetectable. Given an ob-ject’s shape and a sample of photos from a scene, the goal is to produce a texture that hides the object from every view-point that it is likely to be observed from. This problem has applications in hiding unsightly objects, such as util-ity boxes [7], solar panels [29, 49], and radio towers, and in concealing objects from humans or animals, such as surveil-lance cameras and hunting platforms. Moreover, since cam-ouflage models must ultimately thwart highly effective vi-sual systems, they may provide a better scientific under-standing of the cues that these systems use. Animal cam-ouflage, for instance, has developed strategies for avoiding perceptual grouping and boundary detection cues [30, 52].
A successful learning-based camouflage system, likewise, must gain an understanding of these cues in order to thwart them.
Previous object nondetection methods are based on non-parametric texture synthesis. Although these methods have shown success in hiding cube-shaped objects, they can only directly “copy-and-paste” pixels that are directly occluded by the object, making it challenging to deal with complex backgrounds and non-planar geometry. While learning-based methods have the potential to address these shortcom-ings, they face a number of challenges. Since even tiny im-perfections in synthesized textures can expose a hidden ob-ject, the method must also be capable of reproducing real-world textures with high fidelity. There is also no single texture that can perfectly conceal an object from all view-points at once. Choosing an effective camouflage requires 3D reasoning, and making trade-offs between different so-lutions. This is in contrast to the related problem of image inpainting, which can be posed straightforwardly as esti-mating masked image regions in large, unlabeled photo col-lections [34], and which lack the ability to deal with multi-view constraints.
We propose a model based on neural texture fields [23, 32,35,42] and adversarial training that addresses these chal-lenges (Figure 2). The proposed architecture and learning procedure allow the model to exploit multi-view geometry, reproduce a scene’s textures with high fidelity, and satisfy the highly conflicting constraints provided by the input im-ages. During training, our model learns to conceal a variety of object shapes from randomly chosen 3D positions within a scene.
It uses a conditional generative adversarial net-work (GAN) to learn to produce textures that are difficult to detect using pixel-aligned representations [55] with hyper-columns [20] to provide information from each view.
Through automated evaluation metrics and human per-ceptual studies, we find that our method significantly out-performs the previous state-of-the-art in hiding cuboid ob-jects. We also demonstrate our method’s flexibility by us-ing it to camouflage a diverse set of complex shapes. These shapes introduce unique challenges, as each viewpoint ob-serves a different set of points on the object surface. Finally, we show through ablations that the design of our texture model leads to significantly better results. 2.