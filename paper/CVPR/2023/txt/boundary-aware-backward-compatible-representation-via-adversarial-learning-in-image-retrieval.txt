Abstract
Image retrieval plays an important role in the Inter-net world. Usually, the core parts of mainstream visual retrieval systems include an online service of the embed-ding model and a large-scale vector database. For tra-ditional model upgrades, the old model will not be re-placed by the new one until the embeddings of all the im-ages in the database are re-computed by the new model, which takes days or weeks for a large amount of data.
Recently, backward-compatible training (BCT) enables the new model to be immediately deployed online by making the new embeddings directly comparable to the old ones. For
BCT, improving the compatibility of two models with less negative impact on retrieval performance is the key chal-lenge. In this paper, we introduce AdvBCT, an Adversar-ial Backward-Compatible Training method with an elastic boundary constraint that takes both compatibility and dis-crimination into consideration. We first employ adversarial learning to minimize the distribution disparity between em-beddings of the new model and the old model. Meanwhile, we add an elastic boundary constraint during training to improve compatibility and discrimination efficiently. Exten-sive experiments on GLDv2, Revisited Oxford (ROxford), and Revisited Paris (RParis) demonstrate that our method outperforms other BCT methods on both compatibility and discrimination. The implementation of AdvBCT will be pub-licly available at https://github.com/Ashespt/AdvBCT. 1.

Introduction
Image retrieval brings great convenience to our daily life in various areas such as e-commerce search [8, 16], face recognition [17, 32], and landmark localization [13, 24].
With the rapid development of deep learning, visual re-*These authors contributed equally to this research.
†Corresponding authors. trieval systems develop towards larger models and richer databases to provide people with better services. Most mod-ern visual retrieval systems include two core parts: (i) an online service of the embedding model which maps an in-put image to a high-dimensional vector, i.e., the embedding, and (ii) a large-scale vector database which stores the em-beddings of the gallery set and is responsible for similarity search when a query image arrives. During the lifetime of the system, new models with better performance are trained and then deployed online to replace the old ones. Unfor-tunately, the embeddings of the query images extracted by the new model are not compatible with the old ones in the database in most cases. As a result, the vector database must be rebuilt by extracting embeddings for the whole gallery set with the new model. This process is called backfill-ing [18]. In general, practical industrial applications con-taining a database with millions to billions of images take days or even weeks for backfilling. During that time, the old model and database must be kept online to handle queries.
This so-called cold-refresh [30] model upgrade process is shown in Fig. 1a.
Recently, to save resources and simplify the complex backfilling process, backward-compatible learning was pro-posed [18]. Backward-compatible learning aims to ensure the compatibility of embedding representations between models. As shown in Fig. 1b, the new model can directly replace the old one and the embeddings of images in stock are updated on-the-fly. With the hot-refresh model-update strategy, the system only needs to maintain one service and one database at a time, effectively reducing the required re-source during backfilling.
Meanwhile, these hot-refresh model upgrades also pose new challenges for visual search systems. The retrieval per-formance during backfilling reflects the compatibility be-tween models, which should not degrade compared to the old system. However, making the new model perfectly back-compatible with the old one leaves no room for im-provement on the retrieval task. The ultimate goal of the compatible learning is to enable the compatibility between
(a) The process of the traditional upgrade. (b) The process of the compatible upgrade.
Figure 1. The processes of updating online systems on different models. Best viewed in color. adversarial learning as they measure and minimize the dis-crepancy between distributions in different ways, and this is complementary for compatible learning in our intuition.
Some works [23, 30] design the loss for the compatibil-ity in a point-to-point manner, which is sensitive to outliers in the training data. Other works [14, 18] propose point-to-set losses to address the issues by loosely constraining the new embeddings inside the class boundary estimated by the old model. However, these estimated boundaries remain constant when training the new model, which may not be flexible for the new model to learn more discriminative em-beddings. We design an elastic boundary loss in which the boundary can be dynamically adjusted during training.
In addition, existing methods are evaluated in different settings and on different datasets, which makes it difficult to fairly compare them.
In this paper, we adopt a uni-fied training and evaluation protocol to evaluate the ex-isting backward-compatible methods and our adversarial backward-compatible training method (AdvBCT).
In summary, the main contributions of our work are listed as follows:
• We first propose an adversarial backward-compatible learning method to close the distribution gap between different models and employ an elastic boundary loss to improve compatibility and discrimination.
• We unify the training and evaluation protocol to as-sess the performance of 5 BCT works. Meanwhile, we propose a new metric named Pβ−score to evaluate compatibility and discrimination in a comprehensive metric.
• By comprehensive experiments, we show that the pro-posed AdvBCT outperforms the related state-of-the-arts on several image retrieval datasets, e.g. GLDv2,
ROxford and RParis in most BCT settings.
Figure 2. Distributions visualization of the old embeddings and new embeddings on RParis without compatible training by t-SNE
[20]. Triangles represent old embeddings and circles represent new embeddings. The old embeddings are extracted by the model trained on 30% data of GLDv2 while the new embeddings ex-tracted by the model trained on 100% data of GLDv2. The em-beddings in the same color belong to same class. the new model and the old model while keeping the perfor-mance gain of the back-compatible trained new model as close as possible to that of the independently trained new model. When evaluating BCT methods, both the compat-ibility between models and the discrimination of the new model for the retrieval task must be taken into account.
The incompatibility between models results from the discrepancy of the embedding distributions of the models, which is illustrated in Fig. 2. Most of the previous works in BCT [14, 30, 31] narrow the distribution gap by adding some regularization losses involving the old and the new embeddings. The main idea of these methods is to pull the new and old embeddings of the same class closer and to push the new and old embeddings of different classes apart from each other in a metric learning manner. Another way to minimize the distribution discrepancy is adversarial learning, which was successfully applied in domain adapta-tion [2,5]. We decide to combine the metric learning and the
Figure 3. An overview of our AdvBCT framework. The adversarial and boundary-aware compatible modules minimize the discrepancy between distributions of the old and new embeddings, while the classification module improves the retrieval performance. In the compatible losses part, the blue and yellow circles refer to the boundary between the new embeddings and old class centers respectively. rmax minus the learnable re equals to remax. rmax is the maximum distance between old embeddings and the old class center. The solid circles and triangles represent embeddings from two different classes. 2.