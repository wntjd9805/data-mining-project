Abstract
Weakly supervised instance segmentation using only bounding box annotations has recently attracted much re-search attention. Most of the current efforts leverage low-level image features as extra supervision without explicitly exploiting the high-level semantic information of the ob-jects, which will become ineffective when the foreground ob-jects have similar appearances to the background or other objects nearby. We propose a new box-supervised instance segmentation approach by developing a Semantic-aware In-stance Mask (SIM) generation paradigm. Instead of heav-ily relying on local pair-wise afﬁnities among neighboring pixels, we construct a group of category-wise feature cen-troids as prototypes to identify foreground objects and as-sign them semantic-level pseudo labels. Considering that the semantic-aware prototypes cannot distinguish differ-ent instances of the same semantics, we propose a self-correction mechanism to rectify the falsely activated regions while enhancing the correct ones. Furthermore, to handle the occlusions between objects, we tailor the Copy-Paste operation for the weakly-supervised instance segmentation task to augment challenging training data. Extensive exper-imental results demonstrate the superiority of our proposed
SIM approach over other state-of-the-art methods. The source code: https://github.com/lslrh/SIM . 1.

Introduction
Instance segmentation is among the fundamental tasks of computer vision, with many applications in autonomous driving, image editing, human-computer interaction, etc.
The performance of instance segmentation has been im-proved signiﬁcantly along with the advances in deep learn-ing [6, 12, 34, 38]. However, training robust segmentation networks requires a large number of data with pixel-wise annotations, which consumes intensive human labor and
*denotes the equal contribution, †denotes the corresponding author.
This work is supported by the Hong Kong RGC RIF grant (R5001-18).
Figure 1. The pipeline of Semantic-aware Instance Mask (SIM) generation method. (a) shows the mask prediction produced by us-ing only low-level afﬁnity supervision, where the foreground heav-ily blends with background. (b) and (c) show the semantic-aware masks obtained with our constructed prototypes, which perceive the entity of objects but are unable to separate different instances of the same semantics. (d) shows the ﬁnal instance pseudo mask rectiﬁed by our proposed self-correction module. resources. To reduce the reliance on dense annotations, weakly-supervised instance segmentation based on cheap supervisions, such as bounding boxes [14,21,36], points [8] and image-level labels [1,18], has recently attracted increas-ing research attention.
In this paper, we focus on box-supervised instance seg-mentation (BSIS), where the bounding boxes provide coarse supervised information for pixel-wise prediction task. To provide pixel-wise supervision, conventional methods [10, 19] usually leverage off-the-shelf proposal techniques, such as MCG [30] and GrabCut [31], to create pseudo instance masks. However, the training pipelines of these meth-ods with multiple iterative steps are cumbersome. Sev-eral recent works [14, 36] enable end-to-end training by taking pairwise afﬁnities among pixels as extra supervi-sion. Though these methods have achieved promising per-formance, they heavily depend on low-level image features, such as color pairs [36], and simply assume that the proxi-mal pixels with similar colors are likely to have the same label. This leads to confusion when foreground objects have similar appearances to the background or other ob-jects nearby, as shown in Fig. 1 (a). It is thus error-prone to use only low-level image cues for supervision since they are weak to represent the inherent structure of objects.
Motivated by the fact that high-level semantic informa-tion can reveal intrinsic properties of object instances and hence provide effective supervision for segmentation model training, we propose a novel Semantic-aware Instance Mask generation method, namely SIM, to explicitly exploit the semantic information of objects. To distinguish proximal pixels with similar color but different semantics (please re-fer to Fig. 1 (a)), we construct a group of representative dataset-level prototypes, i.e., the feature centroids of differ-ent classes, to perform foreground/background segmenta-tion, producing semantic-aware pseudo masks (see Fig. 1 (b)). These prototypes abstracted from massive training data can capture the structural information of objects, en-abling more comprehensive semantic pattern understand-ing, which is complementary to afﬁnity supervision of pair-wise neighboring pixels. However, as shown in Fig. 1 (c), these prototypes are unable to separate the instances of the same semantics, especially for overlapping objects. We consequently develop a self-correction mechanism to rec-tify the false positives while enhancing the conﬁdence of true-positive foreground objects, resulting in more precise instance-aware pseudo masks, as shown in Fig. 1 (d).
In addition, considering that
It is worth mentioning that our generated pseudo masks could co-evolve with the segmentation model without cum-bersome iterative training procedures in previous meth-ods [10, 21]. the exist-ing weakly-supervised instance segmentation methods only provide very limited supervision for rare categories and overlapping objects due to the lack of ground truth masks, we propose an online weakly-supervised Copy-Paste ap-proach to create a combinatorial number of augmented training samples. Overall, the major contributions of this work can be summarized as follows:
• A novel BSIS framework is presented by developing a semantic-aware instance mask generation mechanism.
Speciﬁcally, we construct a group of representative proto-types to explore the intrinsic properties of object instances and identify complete entities, which produces more reli-able supervision than low-level features.
• A self-correction module is designed to rectify the semantic-aware pseudo masks to be instance-aware. The falsely activated regions will be reduced, and the correct ones will be boosted, enabling more stable training and progressively improving the segmentation results.
• We tailor the Copy-Paste operation for weakly-supervised segmentation tasks in order to create more occlusion pat-terns and more challenging training data. The overall framework can be trained in an end-to-end manner. Ex-tensive experiments demonstrate the superiority of our method over other state-of-the-art methods. 2.