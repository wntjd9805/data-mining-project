Abstract
Network structure learning aims to optimize network ar-chitectures and make them more efficient without compro-mising performance.
In this paper, we first study the as-trocytes, a new mechanism to regulate connections in the classic M-P neuron. Then, with the astrocytes, we propose an AstroNet that can adaptively optimize neuron connec-tions and therefore achieves structure learning to achieve higher accuracy and efficiency. AstroNet is based on our built Astrocyte-Neuron model, with a temporal regulation mechanism and a global connection mechanism, which is inspired by the bidirectional communication property of as-trocytes. With the model, the proposed AstroNet uses a neu-ral network (NN) for performing tasks, and an astrocyte net-work (AN) to continuously optimize the connections of NN, i.e., assigning weight to the neuron units in the NN adap-tively. Experiments on the classification task demonstrate that our AstroNet can efficiently optimize the network struc-ture while achieving state-of-the-art (SOTA) accuracy. 1.

Introduction
Neural networks have made remarkable success in visual tasks by leveraging a large number of learnable parameters.
Deployment of such big models, however, may lead to over-fitting and unnecessarily increase the computational of the network [15]. Neural network structure learning is a new learning paradigm to train neural networks by leveraging structured signals in addition to feature inputs.
Existing works can be generally divided into Learning
Sparse Networks (LSN) and Neural Architecture Search (NAS). LSN methods obtain sub-networks from a fixed ar-chitecture by minimizing the sum of the loss term, and the penalty term [51, 63]. Though efficiency, this strategy gen-erally sacrifices accuracy [2,32,44], especially for networks with more capacity [27]. NAS methods sample and com-bine different units in a defined search space to form an ar-chitecture, then evaluate the architecture to determine the
*Equal contribution, †corresponding authors (a) (b) (c)
Figure 1. Illustration of the M-P model and our Astrocyte-Neuron model. (a) A basic unit of the M-P model. The connection be-tween neurons propagates in one direction. (b) A basic unit of the
Astrocyte-Neuron model. The connection between astrocyte and neuron is propagating bidirectionally. (c) Our Astrocyte-Neuron model. The astrocyte communicates with neurons bidirectionally as key supportive elements in neuronal function. (Best viewed in color on the screen) optimal output [5, 29, 37]. This strategy requires huge time and computing resources. Though recent NAS works at-tempt to improve efficiency, their computational costs are still expensive [30, 53, 62, 65].
Inspired by the learning activity in mammalian brains, we propose an AstroNet to effectively optimize network structure while preserving accuracy. Considering the basic units in artificial neural networks are neurons, the strength of connections between neurons can potentially reflect neu-ron activity [14, 17]. We, therefore, re-assigning connec-tions (weight) for a given network by regulating the neuron connections adaptively to achieve structure learning. Differ-ent from NAS has a huge search space that may introduce
human bias [12], we obtain sub-networks from a fixed ar-chitecture to reduce the search space, while not relying on the sparse regularization from LSN.
To enable the adaptive connection regulation ability of neurons, we introduce astrocytes [13] to the M-P model
[33]. The previous M-P model (Fig. 1a) connect neurons using neurotransmitters in one direction, i.e., from multiple pre-neurons to the post-neuron. According to the new tri-partite synapse concept [11], astrocytes communicate with neurons bidirectionally and are recognized as key support-ive elements in neuronal function (Fig. 1b). Specifically, astrocytes are stimulated by neuron-released neurotransmit-ters. Then, astrocytes generate gliotransmitters to regu-late neuron connections [13]. In particular, astrocytes have a similar ability to integrate information as neurons [36], which allows us to model astrocytes as neurons. There-fore, we extend the M-P model to the Astrocyte-Neuron model for regulating neuron communications, i.e., connec-tions (Fig. 1c).
We explore the bidirectional communication property of astrocytes, and then formulate the Astrocyte-Neuron model by defining a temporal regulation mechanism and a global connection mechanism. Specifically, the astrocyte tempo-rally regulates the connections with pre-neurons, based on the received weights from all pre-neurons. When the regula-tion tends to be stable (the re-assigned weights are approxi-mate to the received weights), the astrocyte then propagates the updated weight to the post-neuron. With the model, we construct our AstroNet that can regulate network archi-tectures to achieve connection optimization, i.e., structure learning. Our AstroNet consists of a one-direction prop-agating neural network (NN), and a bidirectional astrocyte network (AN). The NN constitutes the network for perform-ing tasks, and the AN follows the Astrocyte-Neuron model to regulate the connections/weights of the NN adaptively.
The AstroNet can be utilized with multiple backbones (NN), e.g., ResNet18, ResNet34, DenseNet-BC, VggNet, and MLP, and we demonstrate our efficiency and accuracy in the classification task with three public datasets. Com-pared to LSN methods, our AstroNet improves the accu-racy by 0.17% ∼ 2.81%. While for NAS methods, the rel-ative improvements are 0.22% ∼ 2.79% in accuracy, and 3 ∼ 70+ times in efficiency.
Our main contributions are:
• We introduce astrocyte as a new neural unit to the M-P model to solve the structure learning efficiently with-out compromising network performance.
• By exploring the bidirectional connection of astro-cytes, we build the Astrocyte-Neuron model with a temporal regulation mechanism and a global connec-tion mechanism.
• With the Astrocyte-Neuron model, we conduct our As-troNet, which requires few computational resources and exhibits excellent accuracy improvement. 2.