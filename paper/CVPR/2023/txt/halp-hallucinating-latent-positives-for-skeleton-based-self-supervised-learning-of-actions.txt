Abstract
Supervised learning of skeleton sequence encoders for ac-tion recognition has received significant attention in recent times. However, learning such encoders without labels con-tinues to be a challenging problem. While prior works have shown promising results by applying contrastive learning to pose sequences, the quality of the learned representations is often observed to be closely tied to data augmentations that are used to craft the positives. However, augmenting pose sequences is a difficult task as the geometric constraints among the skeleton joints need to be enforced to make the augmentations realistic for that action. In this work, we pro-pose a new contrastive learning approach to train models for skeleton-based action recognition without labels. Our key contribution is a simple module, HaLP – to Halluci-nate Latent Positives for contrastive learning. Specifically,
HaLP explores the latent space of poses in suitable direc-tions to generate new positives. To this end, we present a novel optimization formulation to solve for the synthetic positives with an explicit control on their hardness. We pro-pose approximations to the objective, making them solv-able in closed form with minimal overhead. We show via experiments that using these generated positives within a standard contrastive learning framework leads to consistent improvements across benchmarks such as NTU-60, NTU-120, and PKU-II on tasks like linear evaluation, transfer learning, and kNN evaluation. Our code can be found at https://github.com/anshulbshah/HaLP.
Figure 1. HaLP: We propose an approach to hallucinate latent posi-tives for use within a contrastive learning pipeline. Our approach works as follows: 1) We extract prototypes which succinctly repre-sent the data at a particular step in training, 2) We randomly select a prototype from the prototype set, 3) Our approach then determines an optimal vector which when added to the anchor can generate positives of varying hardness. We generate a number of positives using this approach which are then used within a contrastive learn-ing pipeline to train a model without labels. 1.

Introduction
Recognizing human actions from videos is of immense practical importance with applications in behavior under-standing [52], medical assistive applications [5], AR/VR applications [26] and surveillance [12]. Action recognition has been an active area of research [29] with a focus on
*Aniket Roy and Ketul Shah contributed equally temporal understanding [14], faster and efficient models for understanding complex actions [38], etc. Most works in the past have focused on action recognition from appearance information. But recent methods have shown the advantages of using pose/skeleton information as a separate cue with benefits in robustness to scene and object biases [34, 35, 53], reduced privacy concerns [27], apart from succinctly rep-resenting human motion [24]. However, annotating videos for skeleton-based action recognition is an arduous task and
is difficult to scale. Prior work in self-supervised learning has shown advantages of learning without labels - including improved transfer performance [6, 22], robustness to domain shift [15, 51] and noisy labels [11, 16]. Inspired by these methodologies, we propose a new approach for skeleton-based action recognition without using labels.
There have been several interesting approaches to tack-ling self-supervision for skeleton sequences. Methods like
[41, 59] have proposed improved pretext tasks to train mod-els. Image-based self-supervised learning has shown impres-sive success using contrastive learning (CL)-based losses.
Inspired by these, some recent approaches [37, 48] have successfully applied CL to skeleton sequences, with modifi-cations such as data augmentations [48], use of multi-modal cues [37], etc. The success of CL for a problem is closely tied to the data augmentations used to create the positives and the quality and number of negatives used to offer contrast to the positives [6, 22]. While various works have tried focusing on negatives for improving the performance of Skeleton-SSL models, augmenting skeleton sequences is more difficult.
Unlike images, skeletons are geometric structures, and de-vising novel data augmentations to craft new positives is an interesting but difficult task.
In this work, we address the question of whether we can hallucinate new positives in the latent space (Fig. 1) for use in a CL framework. Our approach, which we call HaLP:
Hallucinating Latent Positives has dual benefits; generating positives in latent space can reduce reliance on hand-crafted data augmentations. Further, it allows for faster training than using multiple-view approaches [3, 4], which incur signif-icant overheads. Recall that, CL trains a model by pulling two augmented versions of a skeleton sequence close in the latent space while pushing them far apart from the negatives.
Our key idea in this work is to hallucinate new positives, thus exploring new parts of the latent space beyond the query and key to improve the learning process. We introduce two new components to the CL pipeline. The first extracts prototypes from the data which succinctly represent the high dimen-sional latent space using a few key centroids by clustering on the hypersphere. Next, we introduce a Positive Halluci-nation (PosHal) module. Na¨ıvely exploring the latent space might lead to sub-optimal positives or even negatives. We overcome this by proposing an objective function to define hard positives. The intuition is that the similarity of the gen-erated positives and real positives should be minimized such that both have identical closest prototypes. Since solving this optimization problem for each step of training could be expensive, we propose relaxations that let us derive a closed-form expression to find the hardest positive along a particular direction defined by a randomly selected prototype.
The final solution involves a spherical linear interpolation between the anchor and a randomly selected prototype with explicit control of hardness of the generated positives.
We experimentally verify the efficacy of HaLP approach by experiments on standard benchmark datasets: NTU RGB-D 60, NTU RGB-D 120, and PKU-MMD II and notice consistent improvements over state-of-the-art. For example, on the linear evaluation protocol, we obtain +2.3%, +2.3%, and +4.5% for cross-subject splits of the NTU-60, NTU-120, and PKU-II datasets respectively. Using our module with single-modality training leads to consistent improvements as well. Our model trained on single modality, obtains results competitive to a recent approach [37] which uses multiple modalities during training while being 2.5x faster.
In summary, the following are our main contributions: 1. We propose a new approach, HaLP which hallucinates latent positives for use in a skeleton-based CL frame-work. To the best of our knowledge, we are the first to analyze the generation of positives for CL in latent-space. 2. We define an objective function that optimizes for gener-ating hard positives. To enable fast training, we propose relaxations to the objective which lets us derive closed-form solutions. Our approach allows for easy control of the hardness of the generated positives. 3. We obtain consistent improvements over the state-of-the-art methods on all benchmark datasets and tasks.
Our approach is easy to use and works in uni-modal and multi-modal training, bringing benefits in both settings. 2.