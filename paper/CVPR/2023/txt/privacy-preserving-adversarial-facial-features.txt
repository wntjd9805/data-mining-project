Abstract
Face recognition service providers protect face privacy by extracting compact and discriminative facial features (representations) from images, and storing the facial fea-tures for real-time recognition. However, such features can still be exploited to recover the appearance of the original face by building a reconstruction network. Although sev-eral privacy-preserving methods have been proposed, the enhancement of face privacy protection is at the expense of accuracy degradation. In this paper, we propose an adver-sarial features-based face privacy protection (AdvFace) ap-proach to generate privacy-preserving adversarial features, which can disrupt the mapping from adversarial features to facial images to defend against reconstruction attacks.
To this end, we design a shadow model which simulates the attackers’ behavior to capture the mapping function from facial features to images and generate adversarial la-tent noise to disrupt the mapping. The adversarial features rather than the original features are stored in the server’s database to prevent leaked features from exposing facial information. Moreover, the AdvFace requires no changes to the face recognition network and can be implemented as a privacy-enhancing plugin in deployed face recogni-tion systems. Extensive experimental results demonstrate that AdvFace outperforms the state-of-the-art face privacy-preserving methods in defending against reconstruction at-tacks while maintaining face recognition accuracy. 1.

Introduction
Face recognition is a way of identifying an individual’s identity using their face, which has been widely used in many security-sensitive applications. Undoubtedly, biomet-ric facial images are private and discriminative information
∗Zhibo Wang is the corresponding author. to each person that should be protected. Recently, much at-tention has been paid to privacy protection, such as the Gen-eral Data Protection Regulation, making the preservation
In order to avoid of face privacy increasingly important. direct leakage of facial images, mainstream face recogni-tion systems usually adopt a client-server mode that extracts features from facial images with a feature extractor on the client side and stores the facial features rather than facial images on the server side for future online identification.
As facial features suppress the visual information of faces, face privacy protection can be realized to some extent.
However, recent studies showed that it is possible to reconstruct original images from facial features, which is called reconstruction attack, including optimization-based
[9, 29] and learning-based reconstruction attacks [7, 13, 23, 37]. The former gradually adjusts the pixels of the input image to make the output of the feature extractor as close as possible to a particular feature until the facial image (the input image) corresponding to this feature is reconstructed
[9, 29]. The latter trains a feature-image decoder with a de-convolutional neural network (D-CNN) to reconstruct im-ages directly from facial features [7, 13, 23, 37]. These stud-ies imply that existing face recognition systems suffer from severe privacy threats once the features in their database were leaked. Therefore, it is essential to provide approaches to prevent facial features from being reconstructed.
Several approaches have been proposed to protect face privacy. [1, 10, 18, 22] transform the features into the encrypted space and perform face recognition based on the cryptographic primitives and security protocols, which however bear prohibitive computation and communication costs for face recognition systems. [3, 24] utilize differen-tial privacy to protect face privacy by perturbing features with noises, which however suffers from a significant accu-racy drop in face recognition. [19, 34] proposed adversarial
training-based methods that retrain the main task network (e.g., gender classification from facial images) using adver-sarial training between the reconstruction network and the main task network to generate the privacy-preserving fea-tures directly. However, [19] demonstrated that facial fea-tures learned from adversarial training significantly com-promise accuracy when dealing with face recognition tasks.
Recently, several frequency domain-based methods [15, 25] were proposed, which transform raw images into the fre-quency domain and remove features’ critical channels used for visualization to protect face privacy. However, [15] struggles with the trade-off between accuracy and privacy protection and our experimental results demonstrate that
[25] actually cannot resist powerful reconstruction attacks.
In addition, both the adversarial learning-based and the fre-quency domain-based methods require retraining the face recognition network, which is not applicable to deployed face recognition systems.
In this paper, we aim to propose a novel approach to gen-erate privacy-preserving facial features which are able to thwart reconstruction attacks as well as maintain satisfac-tory recognition accuracy. Undoubtedly, it is non-trivial to realize this objective. The first challenge is how to defend against reconstruction attacks under the black-box setting.
An attacker may utilize different reconstruction networks, which are unknown to the face recognition systems in ad-vance, to reconstruct images from facial features. How to enable the generated facial features to defend against such unknown and different reconstruction attacks is very chal-lenging. The second challenge is how to disrupt the visual information embedded in facial features while keeping the recognition accuracy. Since visual information is some-what critical to face recognition, disrupting visual informa-tion may incur a reduction in recognition accuracy. The last challenge is how to generate privacy-preserving fea-tures without changing the face recognition network. Once a face recognition network is deployed, it would be expen-sive to retrain the network and redeploy it to millions of clients. Therefore, a plug-in module is more welcomed for the deployed face recognition systems.
To address the above challenges, we propose an ad-versarial features-based face privacy protection (AdvFace) method, which generates the privacy-preserving adversar-ial features against reconstruction attacks. The intuition of
AdvFace is to disrupt the mapping from features to facial images by obfuscating features with adversarial latent noise to maximize the difference between the original images and the reconstructed images from the features. To this end, we train a shadow model to simulate the behavior of the re-construction attacks to obtain the reconstruction loss which denotes the quality of the reconstructed images. Thereafter, we maximize the reconstruction loss to generate the adver-sarial features by iteratively adding the adversarial latent noise to features along the direction of the gradient (loss w.r.t. the targeted feature). Moreover, to ensure face recog-nition accuracy, the magnitude of adversarial latent noise would be constrained during the optimization.
Our main contributions are summarized as follows:
• We propose a novel facial privacy-preserving method (namely AdvFace), which can generate privacy-preserving adversarial features against unknown re-construction attacks while maintaining face recogni-tion accuracy. Moreover, AdvFace requires no changes to the deployed face recognition model and thus can be integrated as a plug-in privacy-enhancing module into face recognition systems.
• We unveil the rationale of the reconstruction attack and build a shadow model to simulate the behavior of the reconstruction attacks and generate adversarial fea-tures, which can disrupt the mapping from features to facial images by maximizing the reconstruction loss of the shadow model.
• Extensive experimental results demonstrate that our proposed AdvFace outperforms the state-of-the-art fa-cial privacy-preserving methods in terms of superior privacy protection performance while only incurring negligible face recognition accuracy loss. Moreover, the transferability of AdvFace is validated. That is, it can effectively resist different reconstruction networks. 2.