Abstract 1.

Introduction
In recent years, neural distance functions trained via volumetric ray marching have been widely adopted for multi-view 3D reconstruction. These methods, however, apply the ray marching procedure for the entire scene volume, leading to reduced sampling efficiency and, as a result, lower reconstruction quality in the areas of high-frequency details.
In this work, we address this problem via joint training of the implicit function and our new coarse sphere-based surface reconstruction. We use the coarse representation to efficiently exclude the empty volume of the scene from the volumetric ray marching procedure without additional forward passes of the neural surface network, which leads to an increased fidelity of the reconstructions compared to the base systems. We evaluate our approach by incorporating it into the training procedures of several implicit surface modeling methods and observe uniform improvements across both synthetic and real-world datasets. Our codebase can be accessed via the project page†.
† https://andreeadogaru.github.io/SphereGuided
The task of multi-view 3D reconstruction remains the focus of modern computer vision and graphics research.
It has major practical significance in AR/VR metaverses, synthetic media, medical imaging, and the special effects industry. This task is classically addressed via the multi-view stereo (MVS) reconstruction systems [3, 4, 6, 9, 10, 26, 38], which estimate the underlying scene geometry in the form of a point cloud using a photometric consistency between the different views. However, in recent years they have been largely phased out by the methods that represent the scene as neural implicit fields [5, 14, 16–19, 22, 29, 31–33, 35–37].
These approaches have multiple advantages compared to the classical MVS. For example, they can easily accommodate non-Lambertian and texture-less surfaces [8], are good at interpolating unseen parts of the geometry by leveraging regularization [12], and at the same time can achieve an impressive quality of renders [2].
This work focuses on improving the subset of such meth-ods specialized in opaque surface reconstruction [5, 22, 31, 35]. Most of these approaches employ neural signed dis-tance fields [23] (SDFs) trained using volumetric ray march-ing [5, 31, 35]. The training step of this procedure contains
two stochastic elements: sampling a ray corresponding to a training pixel and sampling a set of points along the ray to approximate the color integral. The sampling efficiency at these steps largely determines the resulting quality of the reconstructions. While in the abovementioned methods the training rays are selected uniformly within the scene vol-ume, their point sampling procedure typically employs a multi-stage importance [31] or uncertainty [5, 35] sampling to improve the accuracy of the reconstructions.
At the same time, it was shown [32] that neural signed distance fields benefit from the surface-based sampling of rays for surface rendering methods, such as IDR [36], which the modern multi-view reconstruction systems do not in-corporate. Additionally, some of the novel-view synthe-sis works [16, 18, 37] successfully combined a simple two-stage coarse-to-fine sampling with explicitly defined surface guides to achieve a better rendering quality, as opposed to using the sophisticated multi-stage sampling procedures of the surface reconstruction methods. To guide the ray march-ing, they use explicit coarse surface approximations in the form of a set of volumetric primitives [18] or sparse oc-trees [16, 37]. However, these methods require a complete scene reconstruction to fit such an approximation [18, 37] or employ a heuristic optimization procedure [16] which we show performs poorly for the surface reconstruction task.
Inspired by these approaches, we improve the existing surface reconstruction methods’ ray sampling and marching procedures using explicitly defined coarse representations.
We propose training a coarse reconstruction as a sphere cloud which guides both sampling steps during volume rendering.
We also propose a new optimization approach for coarse reconstruction based on gradient descent, which allows us to train it alongside the implicit surface field. Additionally, we introduce a point resampling scheme, which prevents the spheres from getting stuck in the local minima, and a repul-sion mechanism that ensures high degrees of exploration of the reconstructed surface. Finally, we provide empirical evi-dence of the proposed method’s applicability to different ap-proaches for implicit surface modeling. Specifically, we pair our method with several modern systems [5, 22, 31, 35] for surface reconstruction and observe uniform improvements in the resulting quality across multiple 3D reconstruction benchmarks. 2.