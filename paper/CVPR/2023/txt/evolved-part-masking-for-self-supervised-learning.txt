Abstract
Existing Masked Image Modeling methods apply fixed mask patterns to guide the self-supervised training. As those patterns resort to different criteria to mask local re-gions, sticking to a fixed pattern leads to limited vision cues modeling capability. This paper proposes an evolved part-based masking to pursue more general visual cues model-ing in self-supervised learning. Our method is based on an adaptive part partition module, which leverages the vi-sion model being trained to construct a part graph, and partitions parts with graph cut. The accuracy of parti-tioned parts is on par with the capability of the pre-trained model, leading to evolved mask patterns at different training stages. It generates simple patterns at the initial training stage to learn low-level visual cues, which hence evolves to eliminate accurate object parts to reinforce the learn-ing of object semantics and contexts. Our method does not require extra pre-trained models or annotations, and effectively ensures the training efficiency by evolving the training difficulty. Experiment results show that it substan-tially boosts the performance on various tasks including im-age classification, object detection, and semantic segmenta-tion. For example, it outperforms the recent MAE by 0.69% on imageNet-1K classification and 1.61% on ADE20K seg-mentation with the same training epochs. 1.

Introduction
Recent years have witnessed a boom in continuously growing representation learning capability and data de-mands of deep neural networks like CNN [21, 37] and vision transformers [14, 27, 33]. To tackle the increas-ing demand for labelled data, Masked Language Model-ing (MLM) [3, 13] has been adopted to train natural lan-guage processing models through self-supervised learning on large-scale data. Inspired by the success of MLM, many works propose Masked Image Modeling (MIM) to pre-train vision models on unlabeled images for a series of down-Figure 1. (a), (b), and (c) are three basic mask patterns adopted in existing MIM methods. (d) illustrates the proposed evolved part masking, where the generated mask patterns evolve with the capa-bility of vision model being trained. stream tasks [2,18,38]. MLM masks several words in the in-put sentences and supervises the network to recover masked words according to semantics provided by remaining words.
MIM follows a similar idea of MLM to mask a portion of regions in input images, then trains the vision model to re-cover masked contents from visible regions. As images are not structured representations like sentences, different MIM works have to resort to different criteria to generate mask patterns.
Mask patterns in existing works can be divided into three categories according to their masked image cues. Some works like MAE [18] and SimMIM [38] do not differentiate visual cues in images, and randomly mask local regions or patches. Another line of the works, such as MST [24], pro-pose to preserve crucial cues in the image to enhance the learning of local context. The third line of works such as
AttnMask [22] and SemMAE [23] propose to completely mask cues like object region in images to pose a more chal-ing images. An adaptive part partition module is adopted to leverage the vision model being trained to construct a part graph, and partition parts with graph cut. The accuracy of partitioned parts is on par with the capability of vision model, leading to evolved mask patterns at different train-ing stages, as illustrated in Fig. 1(d). In other words, the initial training stage generates simple patterns to learn low-level visual cues, which hence evolves to mask different ob-ject parts to reinforce the learning of object semantics and contexts.
The adaptive part partition module generates parts ac-cording to the relationship among image patches inferred by the vision model. The relevance among patches learned by the vision transformers are encoded in the attention map.
Our method hence constructs a patch association graph based on attention maps, and tackle the unlabeled part parti-tion as a classic graph cut problem. It implements the graph cut with an efficient Expectation-Maximization (EM) algo-rithm [1, 6, 30]. The generated masks embed extra contex-tual cues among image patches to supervise the training of vision model. The updated model in-turn boosts the accu-racy of part partition. Iteratively conducting mask genera-tion and model training results in a loop that trains vision models on the unlabeled dataset. The mask patterns thus could evolve to present different visual cues learning tasks.
We test the effectiveness of the proposed method on three popular MIM architectures, i.e., MAE [18], BEiT [2] and SimMIM [38]. Our method brings significant perfor-mance enhances for those three architectures, especially on the semantic segmentation task, e.g., boosts the mIoU by 2%. When compared with recent self-supervised learn-ing methods, our method achieves comparable performance with fewer pre-training epochs, and superior performance with similar training epochs. To the best of our knowl-edge, this is an original effort on evolved part masking for self-supervised learning. Our method does not require extra pre-trained models or annotations. It effectively ensures the training efficiency, and enhances the generalization ability of trained model by evolving the mask patterns, thus shows potentials to boost the performance of pre-trained vision models. 2.