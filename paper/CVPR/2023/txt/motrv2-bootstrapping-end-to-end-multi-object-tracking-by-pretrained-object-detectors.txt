Abstract
In this paper, we propose MOTRv2, a simple yet effective pipeline to bootstrap end-to-end multi-object tracking with a pretrained object detector. Existing end-to-end methods, e.g. MOTR [43] and TrackFormer [20] are inferior to their tracking-by-detection counterparts mainly due to their poor detection performance. We aim to improve MOTR by ele-gantly incorporating an extra object detector. We first adopt the anchor formulation of queries and then use an extra ob-ject detector to generate proposals as anchors, providing detection prior to MOTR. The simple modification greatly eases the conflict between joint learning detection and asso-ciation tasks in MOTR. MOTRv2 keeps the query propoga-tion feature and scales well on large-scale benchmarks.
MOTRv2 ranks the 1st place (73.4% HOTA on DanceTrack) in the 1st Multiple People Tracking in Group Dance Chal-lenge. Moreover, MOTRv2 reaches state-of-the-art perfor-mance on the BDD100K dataset. We hope this simple and effective pipeline can provide some new insights to the end-to-end MOT community. Code is available at https:
//github.com/megvii-research/MOTRv2. 1.

Introduction
Multi-object tracking (MOT) aims to predict the trajec-tories of all objects in the streaming video. It can be divided into two parts: detection and association. For a long time, the state-of-the-art performance on MOT has been domi-nated by tracking-by-detection methods [4, 36, 44, 45] with good detection performance to cope with various appear-ance distributions. These trackers [44] first employ an ob-ject detector (e.g., YOLOX [11]) to localize the objects in each frame and associate the tracks by ReID features or IoU matching. The superior performance of those methods par-tially results from the dataset and metrics biased towards detection performance. However, as revealed by the Dance-* The work was done during internship at MEGVII Technology and supported by National Key R&D Program of China (2020AAA0105200) and Beijing Academy of Artificial Intelligence (BAAI).
Figure 1. Performance comparison between MOTR (grey bar) and
MOTRv2 (orange bar) on the DanceTrack and BDD100K datasets.
MOTRv2 improves the performance of MOTR by a large margin under different scenarios.
Track dataset [27], their association strategy remains to be improved in complex motion.
Recently, MOTR [43], a fully end-to-end framework is introduced for MOT. The association process is performed by updating the tracking queries while the new-born ob-jects are detected by the detect queries. Its association per-formance on DanceTrack is impressive while the detection results are inferior to those tracking-by-detection methods, especially on the MOT17 dataset. We attribute the infe-rior detection performance to the conflict between the joint detection and association processes. Since state-of-the-art trackers [6, 9, 44] tend to employ extra object detectors, one natural question is how to incorporate MOTR with an ex-tra object detector for better detection performance. One direct way is to perform IoU matching between the predic-tions of track queries and extra object detector (similar to
TransTrack [28]). In our practice, it only brings marginal improvements in object detection while disobeying the end-to-end feature of MOTR.
Inspired by tracking-by-detection methods that take the detection result as the input, we wonder if it is possible to feed the detection result as the input and reduce the learning of MOTR to the association. Recently, there are some ad-Figure 2. The overall architecture of MOTRv2. The proposals produced by state-of-the-art detector YOLOX [11] are used to generate the proposal queries, which replaces the detect queries in MOTR [43] for detecting new-born objects. The track queries are transferred from previous frame and used to predict the bounding boxes for tracked objects. The concatenation of proposal queries and track queries as well as the image features are input to MOTR to generate the predictions frame-by-frame. vances [18, 35] for anchor-based modeling in DETR. For example, DAB-DETR initializes object queries with the center points, height, and width of anchor boxes. Sim-ilar to them, we modify the initialization of both detect and track queries in MOTR. We replace the learnable po-sitional embedding (PE) of detect query in MOTR with the sine-cosine PE [30] of anchors, producing an anchor-based
MOTR tracker. With such anchor-based modeling, propos-als generated by an extra object detector can serve as the anchor initialization of MOTR, providing local priors. The transformer decoder is used to predict the relative offsets w.r.t. the anchors, making the optimization of the detection task much easier.
The proposed MOTRv2 brings many advantages com-pared to the original MOTR. It greatly benefits from the good detection performance introduced by the extra object detector. The detection task is implicitly decoupled from the MOTR framework, easing the conflict between the de-tection and association tasks in the shared transformer de-coder. MOTRv2 learns to track the instances across frames given the detection results from an extra detector.
MOTRv2 achieves large performance improvements on the DanceTrack, BDD100K, and MOT17 datasets com-pared to the original MOTR (see Fig. 1).
On the
DanceTrack dataset, MOTRv2 surpasses the tracking-by-detection counterparts by a large margin (14.8% HOTA compared to OC-SORT [6]), and the AssA metric is 18.8% higher than the second-best method. On the large-scale multi-class BDD100K dataset [42], we achieved 43.6% mMOTA, which is 2.4% better than the previous best solu-tion Unicorn [41]. MOTRv2 also achieves state-of-the-art performance on the MOT17 dataset [15, 21]. We hope our simple and elegant design can serve as a strong baseline for future end-to-end multi-object tracking research. 2.