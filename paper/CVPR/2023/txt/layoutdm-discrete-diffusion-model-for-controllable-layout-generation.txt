Abstract
Controllable layout generation aims at synthesizing plausible arrangement of element bounding boxes with op-tional constraints, such as type or position of a specific el-ement. In this work, we try to solve a broad range of lay-out generation tasks in a single model that is based on dis-crete state-space diffusion models. Our model, named Lay-outDM, naturally handles the structured layout data in the discrete representation and learns to progressively infer a noiseless layout from the initial input, where we model the layout corruption process by modality-wise discrete diffu-sion. For conditional generation, we propose to inject lay-out constraints in the form of masking or logit adjustment during inference. We show in the experiments that our Lay-outDM successfully generates high-quality layouts and out-performs both task-specific and task-agnostic baselines on several layout tasks.1 1.

Introduction
Graphic layouts play a critical role in visual communica-tion. Automatically creating a visually pleasing layout has tremendous application benefits that range from authoring of printed media [45] to designing application user inter-face [5], and there has been a growing research interest in the community. The task of layout generation considers the arrangement of elements, where each element has a tuple of attributes, such as category, position, or size, and de-pending on the task setup, there could be optional control inputs that specify part of the elements or attributes. Due to the structured nature of layout data, it is crucial to con-sider relationships between elements in a generation. For this reason, current generation approaches either build an autoregressive model [2, 11] or develop a dedicated infer-ence strategy to explicitly consider relationships [19–21].
In this paper, we propose to utilize discrete state-space 1Please find the code and models at: https://cyberagentailab.github.io/layout-dm.
Figure 1. Overview of LayoutDM. Top: LayoutDM is trained to gradually generate a complete layout from a blank state in discrete state space. Bottom: During sampling, we can steer LayoutDM to perform various conditional generation tasks without additional training or external models. diffusion models [3, 9, 14] for layout generation tasks. Dif-fusion models have shown promising performance for var-ious generation tasks, including images and texts [13].
We formulate the diffusion process for layout structure by modality-wise discrete diffusion, and train a denoising back-bone network to progressively infer the complete layout with or without conditional inputs. To support variable-length layout data, we extend the discrete state-space with a special PAD token instead of the typical end-of-sequence token used in autoregressive models. Our model can incor-porate complex layout constraints via logit adjustment, so that we can refine an existing layout or impose relative size constraints between elements without additional training.
We discuss two key advantages of LayoutDM over ex-isting models for conditional layout generation. Our model avoids the immutable dependency chain issue [20] that hap-pens in autoregressive models [11]. Autoregressive mod-els fail to perform conditional generation when the con-dition disagrees with the pre-defined generation order of elements and attributes. Unlike non-autoregressive mod-els [20], our model can generate variable-length elements.
We empirically show in Sec. 4.5 that naively extending non-autoregressive models by padding results in suboptimal variable length generation while padding combined with our diffusion formulation leads to significant improvement.
We evaluate LayoutDM on various layout generation tasks tackled by previous works [20, 21, 33, 36] using two large-scale datasets, Rico [5] and PubLayNet [45]. Lay-outDM outperforms task-agnostic baselines in the major-ity of cases and shows promising performance compared with task-specific baselines. We further conduct an ablation study to prove the significant impact of our design choices in LayoutDM, including quantization of continuous vari-ables and positional embedding.
We summarize our contributions as follows:
• We formulate the discrete diffusion process for layout generation and propose a modality-wise diffusion and a padding approach to model highly structured layout data.
• We propose to inject complex layout constraints via masking and logit adjustment during the inference, so that our model can solve diverse tasks in a single model.
• We empirically show solid performance for various con-ditional layout generation tasks on public datasets. 2.