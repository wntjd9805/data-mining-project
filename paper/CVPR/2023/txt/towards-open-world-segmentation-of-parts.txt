Abstract
Segmenting object parts such as cup handles and animal bodies is important in many real-world applications but re-quires more annotation effort. The largest dataset nowa-days contains merely two hundred object categories, imply-ing the difficulty to scale up part segmentation to an un-constrained setting. To address this, we propose to explore a seemingly simplified but empirically useful and scalable task, class-agnostic part segmentation. In this problem, we disregard the part class labels in training and instead treat all of them as a single part class. We argue and demonstrate that models trained without part classes can better localize parts and segment them on objects unseen in training. We then present two further improvements. First, we propose to make the model object-aware, leveraging the fact that parts are “compositions”, whose extents are bounded by the cor-responding objects and whose appearances are by nature not independent but bundled. Second, we introduce a novel approach to improve part segmentation on unseen objects, inspired by an interesting finding — for unseen objects, the pixel-wise features extracted by the model often reveal high-quality part segments. To this end, we propose a novel self-supervised procedure that iterates between pixel clustering and supervised contrastive learning that pulls pixels closer or pushes them away. Via extensive experiments on PartIm-ageNet and Pascal-Part, we show notable and consistent gains by our approach, essentially a critical step towards open-world part segmentation. 1.

Introduction
Segmenting “objects” from images, such as cup, bird, is a fundamental task in computer vision vehicle, etc., and has experienced a series of breakthroughs in recent years thanks to deep learning [6, 15, 18] and large-scale data [12, 22, 30]. In many real-world applications like ob-ject grasping, behavior analysis, and image editing, how-ever, there is often a need to go beyond “objects” and dive
*This work was done during an internship at Adobe Research. 2Adobe Research
{qingl, bprice}@adobe.com deeper into their compositions, i.e., “parts”; for example, to segment cup handle, bird wing, vehicle wheel, etc.
Arguably, the most straightforward way to tackle this problem is to perform part “instance” segmentation, treat-ing each object part as a separate class; each appear-ance as a separate instance. A model then must localize parts, classify them, and demarcate their boundaries.
In object-level instance segmentation [15], these three sub-tasks are usually approached simultaneously, or at least, share a model backbone. Such a multi-task nature enables the model to benefit from the complementary cues among sub-tasks to attain higher accuracy. For instance, the shapes of segments often entail the class labels and vice versa.
Segmenting parts in this way, however, limits their scope to the closed world. That is, the learned model may not, or by default should not1, generalize to object categories (and their corresponding parts) that are unseen during training.
Although the largest dataset nowadays for part segmenta-tion, PartImageNet [14], has covered more than a hundred object categories, a scale similar to representative object-level datasets like MSCOCO [30] and OpenImages [22], it is arguable not enough to cover the need in the wild.
To equip the model with the open-world capability — the ability to segment parts for unseen objects — we propose to chop off the “classification” function from the model, as it is simply not applicable to unseen parts. Namely, we remove the pre-defined fences among different object parts and in-stead assign a single part class to them (i.e., class-agnostic).
At first glance, this design choice may seem like a purely simplified version of the original problem or an unavoid-able compromise. However, we argue that it indeed helps improve the model’s open-world generalizability.
Concretely, in training a model to correctly classify seen object parts, we implicitly force the model to classify future unseen object parts into the background, suppressing their chances to be detected and segmented. By treating all the seen object parts as a single class, we remove the competi-tion tension among them and in turn encourage the model 1The need to assign a “seen-class” label to every detected segment dis-courages the model from detecting segments that correspond to “unseen-class” classes in the first place.
to pay more attention to differentiating “parts” and “non-parts”. As a result, unseen parts appear to be more like the test data in conventional supervised learning; the model can more likely detect them. Besides, removing the competition tension also encourages the model to learn the general pat-terns of parts, which can potentially improve the segmen-tation quality on unseen parts.
In Sec. 4, we empirically demonstrate the effectiveness of class-agnostic training in segmenting parts from unseen objects.
We propose two further improvements towards open-world class-agnostic part segmentation. First, we incorpo-rate into the model a unique semantic cue of parts. Com-pared to objects which are usually considered as “entities”, i.e., things that can exist and appear distinctively and inde-pendently, object parts are “compositions”, located within an object and often appearing together in a functionally meaningful way. We hypothesize that by making models aware of this object-part relationship, the resulting segmen-tation quality can be improved. To this end, we propose to introduce class-agnostic object masks (e.g., extracted by an off-the-shelf segmentation model) as an additional channel to the model. While extremely simple, we found this ap-proach highly effective, leading to notable gains, especially on unseen objects. Moreover, it is model-agnostic and can easily be incorporated into any network architecture.
Second, we propose a novel way to fine-tune the model using unlabeled data, e.g., data it sees in its deployed en-vironment, which may include unseen objects. We found that on unseen objects, pixel-wise features the model inter-nally extracts often reveal high-quality segment boundaries.
To take advantage of this, we propose a self-supervised approach to adapt the model backbone, which iterates be-tween online pixel clustering (e.g., using k-means) and su-pervised contrastive learning using the cluster assignment.
Concretely, we update the model backbone to pull pixels of the same clusters closer; push pixels between different clusters farther away. As will be demonstrated in Sec. 4, this approach leads to a consistent gain on unseen objects and can be further improved via a combination with self-training [2, 23]. Please see Fig. 1 for an illustration.
We validate our proposed approach, which we name
Open Part Segmenter (OPS), on two part segmentation datasets, PartImageNet [14] and Pascal-Part [5]. We train the model on PartImageNet, and evaluate it on a PartIma-geNet out-of-distribution set and Pascal-Part: to our knowl-edge, we are the first to conduct a cross-dataset study for part segmentation. Data in these two sets contain a variety of unseen objects, and we use class-agnostic Average Preci-sion (AP) as the metric. We show that OPS achieves signif-icant and consistent gains against the baselines. On PartIm-ageNet, we improve the AP from 38.21 to 42.61; on Pascal-Part, we improve from 9.48 to 23.02, almost a 142.8% rel-Importantly, all our proposed components — ative gain. class-agnostic segmentation, object mask channel, and self-supervised fine-tuning — contribute to the gain. Moreover, if given ground-truth object masks (e.g., form a user in an interactive setting), OPS can encouragingly improve the AP to 85.12 on PartImageNet and 25.26 on Pascal-Part, making it a highly flexible approach. Our analyses further reveal cases that OPS can segment even finer-grained parts than the ground truths, essentially a critical step towards open-world part segmentation. 2.