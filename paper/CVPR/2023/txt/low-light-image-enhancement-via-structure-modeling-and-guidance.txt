Abstract
This paper proposes a new framework for low-light im-age enhancement by simultaneously conducting the appear-ance as well as structure modeling. It employs the struc-tural feature to guide the appearance enhancement, lead-ing to sharp and realistic results. The structure model-ing in our framework is implemented as the edge detection in low-light images.
It is achieved with a modified gen-erative model via designing a structure-aware feature ex-tractor and generator. The detected edge maps can accu-rately emphasize the essential structural information, and the edge prediction is robust towards the noises in dark ar-eas. Moreover, to improve the appearance modeling, which is implemented with a simple U-Net, a novel structure-guided enhancement module is proposed with structure-guided feature synthesis layers. The appearance model-ing, edge detector, and enhancement module can be trained end-to-end. The experiments are conducted on represen-tative datasets (sRGB and RAW domains), showing that our model consistently achieves SOTA performance on all datasets with the same architecture. The code is available at https://github.com/xiaogang00/SMG-LLIE. 1.

Introduction
The low-light enhancement aims to recover normal-light and noise-free images from dark and noisy pictures, which is a long-standing and significant computer vision topic.
It has broad application fields, including low-light imag-ing [11, 27, 50], and also benefits many downstream vision tasks, e.g., nighttime detection [28, 48, 64]. Some meth-ods have been proposed to tackle the low-light enhancement problem. They design networks that learn to manipulate color, tone, and contrast [7, 10, 45, 63], and some recent works also account for noise in images [24, 55]. Most of these works optimize the appearance distance between the output and the ground truth. However, they ignore the ex-plicit modeling of structural details in dark areas and thus
*Corresponding author.
Figure 1. Our method consistently achieves SOTA performance on different sRGB/RAW datasets with the same network architecture. resulting in blurry outcomes and low SSIM [51] values, as shown in Fig. 2. Some works [34, 74] have noticed the ef-fect of employing structural information, e.g., edge, to pro-mote the enhancement. Edge guides the enhancement by distinguishing between different parts in the dark regions.
Moreover, adding sensible edge priors into dark regions re-duces the ill-posed degree in optimizing the appearance re-construction. These frameworks [34, 74] perform the struc-ture modeling with encoder-decoder-based networks and a regression loss. However, the corresponding structure mod-eling results are not satisfying due to the uncertainty in the dark areas caused by severely poor visibility and noise. Fur-thermore, the strategy of using the extracted structural infor-mation needs to be improved from the existing straightfor-ward concatenation approach [34, 74].
In this paper, we propose to utilize a generative model S trained with a GAN loss to perform the structure modeling with the form of edges. Then, we design a new mechanism
E to facilitate the initial low-light appearance enhancement (the module is denoted as A) with structure-guided feature synthesis. With effective structure modeling and guidance, our framework can output sharp and realistic results with satisfactory reconstruction quality as shown in Fig. 2.
Compared with previous structure modeling networks,
(a) Input (b) Structure of (a) (c) SNR (CVPR 2022) (d) Structure Modeling (e) Ours (f) Ground Truth
Figure 2. A challenging low-light frame (a), from SID-sRGB [3], enhanced by a SOTA method (c) and our method (e). Our method can synthesize the structure map (d) from the input image, leading to clearer details, more distinct contrast, and more vivid color. Al-though (c) has high PSNR as 28.17, its SSIM is low as 0.75. Ours achieves high scores for both dB and SSIM, as 28.60dB and 0.80. the proposed generative model S has two significant modi-fications. First, we notice the impact of providing structure-aware descriptors into both the encoder and decoder of S, disentangling the appearance representation and underlin-ing the structural information. Thus, we design a Structure-Aware Feature Extractor (SAFE) as the encoder part, which extracts structure-aware features from the dark image and its gradients via spatially-varying operations (achieved with adaptive long-range and short-range computations). The extracted structure-aware tensors are then fed into the de-coder part to generate the desired structure maps. Moreover, different from current approaches, which employ the struc-ture maps of normal-light images to conduct the regression learning, we find the nice property of using a GAN loss. The
GAN loss can reduce the artifacts in the generated structure maps that are caused by the noise and invisibility, highlight-ing the essential structure required for enhancement. The backbone of S is implemented as a modified StyleGAN.
To boost the appearance by leveraging the obtained structure maps, we design a Structure-Guided Enhancement
Module (SGEM) as E. The main target of SGEM is to learn the residual, which can improve the initial appearance mod-eling results. In SGEM, spatially-adaptive kernels and nor-malization parameters are generated according to the struc-ture maps. Then, the features in each layer of the SGEM’s decoder will be processed with spatially-adaptive convolu-tions and normalization. Although the overall architecture of SGEM takes the form of a simple U-Net [38], it can ef-fectively enhance the original appearance.
S, A, and E can be trained end-to-end simultane-ously. Extensive experiments are conducted on representa-tive benchmarks. Experimental results show that our frame-work achieves SOTA performance on both PSNR and SSIM metrics with the same architecture on all datasets, as shown in Fig. 1. In summary, our work’s contribution is four-fold. 1. We propose a new framework for low-light enhance-ment by conducting structure modeling and guidance simultaneously to boost the appearance enhancement. 2. We design a novel structure modeling method, where structure-aware features are formulated and trained with a GAN loss. 3. A novel structure-guided enhancement approach is proposed for appearance improvement guided by the restored structure maps. 4. Extensive experiments are conducted on different datasets in both sRGB and RAW domains, showing the effectiveness and generalization of our framework. 2.