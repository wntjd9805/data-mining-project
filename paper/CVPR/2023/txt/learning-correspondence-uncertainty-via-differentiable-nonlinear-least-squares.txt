Abstract
We propose a differentiable nonlinear least squares framework to account for uncertainty in relative pose es-timation from feature correspondences. Specifically, we introduce a symmetric version of the probabilistic normal epipolar constraint, and an approach to estimate the co-variance of feature positions by differentiating through the camera pose estimation procedure. We evaluate our ap-proach on synthetic, as well as the KITTI and EuRoC real-world datasets. On the synthetic dataset, we confirm that our learned covariances accurately approximate the true noise distribution. In real world experiments, we find that our approach consistently outperforms state-of-the-art non-probabilistic and probabilistic approaches, regardless of the feature extraction algorithm of choice. 1.

Introduction
Estimating the relative pose between two images given mutual feature correspondences is a fundamental problem in computer vision. It is a key component of structure from motion (SfM) and visual odometry (VO) methods which in turn fuel a plethora of applications from autonomous vehi-cles or robots to augmented and virtual reality.
Project Page: https://dominikmuhle.github.io/dnls covs/
Estimating the relative pose – rotation and translation – between two images, is often formulated as a geomet-ric problem that can be solved by estimating the essen-tial matrix [42] for calibrated cameras, or the fundamental matrix [24] for uncalibrated cameras. Related algorithms like the eight-point algorithm [23, 42] provide fast solu-tions. However, essential matrix based approaches suffer issues such as solution multiplicity [18, 24] and planar de-generacy [33]. The normal epipolar constraint (NEC) [34] addresses issues such as by estimating the issues such as which leads to more accurate relative poses [33].
Neither of the aforementioned algorithms takes into ac-count the quality of feature correspondences – an impor-tant cue that potentially improves pose estimation accuracy.
Instead, feature correspondences are classified into inliers and outliers through a RANSAC scheme [11]. However, keypoint detectors [12, 56] for feature correspondences or tracking algorithms [63] yield imperfect points [40] that ex-hibit a richer family of error distributions, as opposed to an inlier-outlier distribution family. Algorithms, that make use of feature correspondence quality have been proposed for essential/fundamental matrix estimation [7, 53] and for the
NEC [48], respectively.
While estimating the relative pose can be formulated as a classical optimization problem [15, 33], the rise in popu-larity of deep learning has led to several works augmenting
(a) covariances from [48] per pixel (b) points and covariances [48] (c) learned covariances per pixel (Ours) (d) points and learned covariances (Ours)
Figure 2. Comparison between covariances used in [48] (first row) and our learned covariances (second row). The first column shows a dense color coded (s, α, β mapped to HLS with γ correction) representation for each pixel, while the second column shows subsampled keypoints and their corresponding (enlarged) covariances. The higher saturation in (a) shows that the covariances are more anisotropic.
The learned covariances (c) show a more fine-grained detail in the scale (brightness) and less blurring than the covariances in (a).
VO or visual simultaneous localisation and mapping (VS-LAM) pipelines with learned components. GN-Net [67] learns robust feature representations for direct methods like
DSO [15]. For feature based methods Superpoint [12] pro-vides learned features, while Superglue [57] uses graph neu-ral networks to find corresponding matches between feature points in two images. DSAC introduces a differential re-laxation to RANSAC that allows gradient flow through the otherwise non-differentiable operation. In [53] a network learns to re-weight correspondences for estimating the fun-damental matrix. PixLoc [58] estimates the pose from an image and a 3D model based on direct alignment.
In this work we combine the predictive power of deep learning with the precision of geometric modeling for highly accurate relative pose estimation. Estimating the noise distributions for the feature positions of different fea-ture extractors allows us to incorporate this information into relative pose estimation. Instead of modeling the noise for each feature extractor explicitly, we present a method to learn these distributions from data, using the same domain that the feature extractors work with - images. We achieve this based on the following technical contributions:
• We introduce a symmetric version of the probabilistic normal epipolar constraint (PNEC), that more accurately models the geometry of relative pose estimation with un-certain feature positions.
• We propose a learning strategy to minimize the rela-tive pose error by learning feature position uncertainty through differentiable nonlinear least squares (DNLS), see Fig. 1.
• We show with synthetic experiments, that using the gradi-ent from the relative pose error leads to meaningful esti-mates of the positional uncertainty that reflect the correct error distribution.
• We validate our approach on real-world data in a vi-sual odometry setting and compare our method to non-probabilistic relative pose estimation algorithms, namely
Nist´er 5pt [50], and NEC [33], as well as to the PNEC with non-learned covariances [48].
• We show that our method is able to generalize to different feature extraction algorithms such as SuperPoint [12] and feature tracking approaches on real-world data.
• We release the code for all experiments and the training setup to facilitate future research. 2.