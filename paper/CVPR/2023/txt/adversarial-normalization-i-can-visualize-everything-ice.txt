Abstract
Vision transformers use [CLS] tokens to predict image classes. Their explainability visualization has been stud-ied using relevant information from [CLS] tokens or fo-cusing on attention scores during self-attention. Such vi-sualization, however, is challenging because of the depen-dence of the structure of a vision transformer on skip con-nections and attention operators, the instability of non-linearities in the learning process, and the limited reflec-tion of self-attention scores on relevance. We argue that the output vectors for each input patch token in a vision trans-former retain the image information of each patch location, which can facilitate the prediction of an image class.
In this paper, we propose ICE (Adversarial Normalization: I
Can visualize Everything), a novel method that enables a model to directly predict a class for each patch in an im-age; thus, advancing the effective visualization of the ex-plainability of a vision transformer. Our method distin-guishes background from foreground regions by predicting background classes for patches that do not determine im-age classes. We used the DeiT-S model, the most repre-*Both authors contributed equally to this research sentative model employed in studies, on the explainabil-ity visualization of vision transformers. On the ImageNet-Segmentation dataset, ICE outperformed all explainabil-ity visualization methods for four cases depending on the model size. We also conducted quantitative and qualita-tive analyses on the tasks of weakly-supervised object lo-calization and unsupervised object discovery. On the CUB-200-2011 and PASCALVOC07/12 datasets, ICE achieved comparable performance to the state-of-the-art methods.
We incorporated ICE into the encoder of DeiT-S and im-proved efficiency by 44.01% on the ImageNet dataset over that achieved by the original DeiT-S model. We showed performance on the accuracy and efficiency comparable to EViT, the state-of-the-art pruning model, demonstrating the effectiveness of ICE. The code is available at https:
//github.com/Hanyang-HCC-Lab/ICE. 1.

Introduction
The emergence of vision transformers in the field of computer vision has driven improvements in model per-formance [2, 5]. Unlike a CNN model, a vision trans-former learns the association between image patches and
classifies images using a [CLS] token. A CNN model and a vision transformer have structural differences that lead to variances in explainability visualization approaches. A representative approach is GradCAM, which demonstrates the explainability of CNN models by reflecting the impor-tance of pixel levels using the feature maps and gradients of the models. However, it is somewhat difficult to effec-tively apply GradCAM to vision transformers because the structural characteristics of vision transformers pose several challenges, such as skip connections, dependency on atten-tion operators, and unstable learning due to non-linearities.
To overcome these challenges, previous research mainly used attention score information between [CLS] tokens and other patches to discriminate patches with a significant im-pact on learning and visualizing the explainability of vi-sion transformers [2, 35]. Later studies have evaluated the degree to which each attention head contributes to perfor-mance [36] or integrated the relevance and attention scores in layers through the proposal of a relevance propagation rule [3]. Most recently, the optimization of relevance maps has improved the explainability of a vision transformer by assigning a lower relevance to the background region of an image, whereas high relevance is placed on the foreground region [4]. Despite the advantage of this optimization, chal-lenges to explainability visualization for vision transform-ers remain given their structural characteristics [3, 4].
We note that the output embedding vectors for each in-put patch token in a vision transformer retain the image information of each patch location, and these vectors can help predict image classes. Based on this motivation, in this paper, we propose ICE (I Can visualize Everything), a novel method that uses the output embedding vectors of a vision transformer for each patch token, except for [CLS] tokens, in visualizing explainability. ICE initially assumes that the class of all patches is a background and gradually learns the direction in which the class of each patch in an image is predicted. With this approach, we propose a loss function for adversarial normalization that combines back-ground and classification losses for each patch token. ICE predicts a class for each patch in a foreground region of an image where the object of the class is likely to exist and classifies other regions as a background.
To evaluate the explainability visualization performance of ICE, we mainly used DeiT-S [33], pre-trained with Ima-geNet [25], the most representatively adopted model in pre-vious studies. On the ImageNet-Segmentation [14] dataset,
ICE (with DeiT-S) achieved improvements of 4.05% and 3.94% in pixel-wise accuracy and mean intersection over union (mean IoU), respectively, compared with state-of-the-art methods. To verify the scalability and robustness of ICE, we additionally considered ViT AugReg (AR) [31] and evaluated ICE for four cases depending on the model size (i.e., Small and Tiny). Through qualitative analyses, we showed that ICE was good at predicting not only the class of a single object but also the same class of multiple objects in an image. We found that other methods failed to segment objects, especially in multi-object conditions.
We further evaluated the foreground and background separation performance of ICE on unsupervised seman-tic segmentation, weakly supervised object localization, and unsupervised object discovery tasks using the Pas-calVOC07/12 [11] validation sets and the CUB-200-2011 [37] dataset.
ICE (with DeiT-S)
As a result, achieved comparable and superior performance compared to the existing self-supervised learning-based methods (i.e.,
DINO [7], DINO-based LOST [8], and DINO-based To-kenCut [9]). We found that ICE could distinish between background and foreground regions despite the presence of multiple objects of different sizes and classes that were not learned in the images of PascalVOC07/12 (Figure 1).
Regarding our experiment in efficiency on inference, we incorporated ICE into the encoder of DeiT-S and achieved an improved efficiency of 44.01% on ImageNet [25] com-pared with the original DeiT-S, while maintaining compa-rable accuracy. ICE also achieved accuracy and efficiency comparable to that of EViT, the state-of-the-art pruning method [20].
Our contributions are as follows.
• We propose ICE that can be employed to vision trans-formers based on the notion of patch-wise classifica-tion and adversarial normalization. DeiT-S models with ICE and ICE-f improve class-specific explainabil-ity visualization performance (Section 4.2).
• We show that ICE significantly improves foreground and background separations over the original DeiT-S and. Even without segmentation or object location labels, ICE achieves comparable or superior perfor-mance than existing self-supervised learning methods (Sections 4.3 and 4.4).
• We demonstrate that ICE is effective in background patch selection by showing comparable efficiency and accuracy of DeiT-S that incorporates the ICE’s capa-bility to its encoder, to EViT (Section 4.5).
With the experimental results as grounding, we discuss the scalability of our methodology in terms of improving the efficiency of a vision transformer-based model. 2.