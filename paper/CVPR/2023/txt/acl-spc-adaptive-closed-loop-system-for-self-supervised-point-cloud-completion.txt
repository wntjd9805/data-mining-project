Abstract
Point cloud completion addresses filling in the missing parts of a partial point cloud obtained from depth sensors and generating a complete point cloud. Although there has been steep progress in the supervised methods on the synthetic point cloud completion task, it is hardly applica-ble in real-world scenarios due to the domain gap between the synthetic and real-world datasets or the requirement of prior information. To overcome these limitations, we pro-pose a novel self-supervised framework ACL-SPC for point cloud completion to train and test on the same data. ACL-SPC takes a single partial input and attempts to output the complete point cloud using an adaptive closed-loop (ACL) system that enforces the output same for the variation of an input. We evaluate our ACL-SPC on various datasets to prove that it can successfully learn to complete a partial point cloud as the first self-supervised scheme. Results show that our method is comparable with unsupervised meth-ods and achieves superior performance on the real-world dataset compared to the supervised methods trained on the synthetic dataset. Extensive experiments justify the neces-sity of self-supervised learning and the effectiveness of our proposed method for the real-world point cloud completion task. The code is publicly available from this link. 1.

Introduction
Along with the development of autonomous driving cars and robotics, the usage of depth sensors such as LiDARs has increased. These sensors can collect numerous points in the 3D space, and the combination of these points forms a 3D representation called a point cloud. Point cloud rep-resentation has been widely used in many applications as it is highly convertible to other 3D data representations, e.g., voxel and mesh, and accessible for obtaining information from the real world. However, point clouds obtained from a real-world sensor, e.g., a LiDAR, are often incomplete
*equal contribution
Figure 1. Overview of our proposed pipeline. We first generate
C0 using the initial partial point cloud. Then, multiple synthetic point clouds Pv are generated from the random views of C0. We input the generated Pv to the network and make predicted com-plete point clouds. We take the loss between C0 and Cv to opti-mize the parameters of the network fθ. and sparse due to occlusion, limitations of sensor resolu-tion, and viewing angle [49] leading to loss of some geo-metric information and difficulty in proceeding with further applications e.g., object detection [26] and object segmenta-tion [7]. We define such point clouds as partial point clouds.
Therefore, point cloud completion is a crucial task that in-fers completing geometric 3D shapes by using such partial point cloud observations.
With the advent of deep learning, previous data-driven works [40, 43, 49] have been able to solve this task us-ing complete point cloud ground-truths. Even though such methods have achieved decent performance, they are not applicable in real-world scenarios where the ground-truth point clouds are not easy to obtain. For these rea-sons, researchers have recently attempted to overcome the lack of high-quality and large-scale paired training data using multiple views of the point cloud in unsupervised and weakly-supervised manners. Especially, recent meth-ods [15, 21] leverage multi-view consistency of the desired object, which shows effectiveness in supervising 3D shape prediction. PointPnCNet [21] claims that its method is based on self-supervised learning. However, combining multi-view consistency enables reconstructing a complete 3D point cloud and can be weak supervision. Moreover, collecting multiple partial views of an object in real-world
scenarios is difficult as gathering ground-truth point clouds.
Therefore, the necessity for multi-view consistency pre-vents this method from being fully self-supervised. Mean-while, other methods [6, 13, 41, 50] exploit unpaired par-tial and complete point clouds [6, 41] or pre-trained mod-els [13, 50] on synthetic data to overcome the difficulty of collecting ground-truth. However, the need for unpaired data limits the methods’ applicability to a few categories.
To overcome the challenges mentioned above, we pro-pose a novel and the first self-supervised method called
ACL-SPC for point cloud completion using only a sin-gle partial point cloud. We develop an adaptive closed-loop (ACL) [2] system as shown in Figure 1 to design our self-supervised point cloud completion framework ACL-SPC. In ACL-SPC, an encoder adaptively reacts to the vari-ance in the input by adjusting its parameters to generate the same output. Using our developed ACL, our method tries to generate a complete point cloud from a single partial in-put captured from an unknown viewpoint without any prior information or multi-view consistency and also simulates several synthetic partial point clouds from the reconstructed point cloud. Under our defined novel loss function, our
ACL-SPC can learn to generate the same complete point cloud from all such synthetic point clouds and the initial partial point cloud without any supervision. In the experi-ments, we demonstrate the ability of our method to restore a complete point cloud and the effect of our designed loss functions on saving fine details and improving quantitative performance. We also evaluate our method with various datasets, including real-world scenarios, and verify that our method can be applied in practice. Evaluation results show that our method is comparable to other unsupervised meth-ods and performs better than the supervised method trained on a synthetic dataset.
Our main contributions can be summarized as follows:
• We propose ACL-SPC by developing an adaptive control-loop ACL framework to solve the point cloud completion problem in a self-supervised manner.
• We also design an effective self-supervised loss func-tion to train our method without requiring any other information and using only a single partial point cloud taken from an unknown viewpoint.
• Our method achieves superior performance in real-world scenarios compared to methods trained on syn-thetic datasets and comparative performance among other unsupervised methods. 2.