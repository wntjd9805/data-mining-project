Abstract
Recent cascade Multi-View Stereo (MVS) methods can efficiently estimate high-resolution depth maps through nar-rowing hypothesis ranges. However, previous methods ig-nored the vital geometric information embedded in coarse stages, leading to vulnerable cost matching and sub-optimal reconstruction results.
In this paper, we propose a ge-ometry awareness model, termed GeoMVSNet, to explic-itly integrate geometric clues implied in coarse stages for delicate depth estimation. In particular, we design a two-branch geometry fusion network to extract geometric pri-ors from coarse estimations to enhance structural feature extraction at finer stages. Besides, we embed the coarse probability volumes, which encode valuable depth distri-bution attributes, into the lightweight regularization net-work to further strengthen depth-wise geometry intuition.
Meanwhile, we apply the frequency domain filtering to mit-igate the negative impact of the high-frequency regions and adopt the curriculum learning strategy to progres-sively boost the geometry integration of the model. To in-tensify the full-scene geometry perception of our model, we present the depth distribution similarity loss based on the Gaussian-Mixture Model assumption. Extensive exper-iments on DTU and Tanks and Temples (T&T) datasets demonstrate that our GeoMVSNet achieves state-of-the-art results and ranks first on the T&T-Advanced set. Code is available at https://github.com/doubleZ0108/GeoMVSNet. 1.

Introduction
Multi-View Stereo (MVS) reconstructs the dense ge-ometry representation of a scene from multiple overlap-ping photographs, which is an influential branch of three-dimensional (3D) computer vision and has been extensively studied for decades. Learning-based MVS methods aggre-gate cost volume from different viewpoints and use neu-ral networks for cost regularization, which achieve superior performance compared with traditional methods.
Recently, cascade-based architectures [7, 14, 54] have been widely applied. They compute different resolution depth maps in a coarse-to-fine manner and progressively narrow hypothesis plane guidance to reduce computational complexity. However, these approaches do not take ad-vantage of valuable insight contained in early phases and only consider the pixel-wise depth attribute. Some meth-ods, e.g. deformable kernel-based [47] and transformer-based [4, 8, 22, 27, 46], introduce finely designed external structures for feature extraction but do not fully exploit the geometric clues embedded in the MVS scenarios.
Unlike existing works, we propose to explore the ge-ometric structures embedded in coarse stages for delicate estimations in finer stages. In particular, we build a two-branch fusion network to integrate geometric priors con-tained in coarse depth maps with ordinary features extracted by the classic FPN [23], and the fused geometry awareness features can provide solid foundations for robust aggrega-tion. Meanwhile, coarse probability volumes with abundant geometric structures are embedded into the regularization network, and we replace the heavy 3D convolution with en-hanced 2D regularization without degrading the quality of depth-wise correlation, resulting in lightweight but robust cost matching. However, MVS networks tend to produce severe misestimation at high-frequency clutter textures due to confused matching in coarse stages, which inevitably af-fects explicit geometry perception. We are inspired by the human behavior that a nearsighted person can still perceive a scene well without glasses, even if the texture details can-not be seen clearly. Based on the observation, we refer to the idea of curriculum learning [2] to embed coarse geo-metric priors into finer stages from easy to difficult. Specif-ically, we utilize the frequency domain filtering strategy to effectively alleviate redundant high-frequency textures without producing more learning parameters and leverage geometric structures embedded in different hierarchies of frequency for gradually delicate depth estimation.
In addition, depth ranges of MVS scenarios are often concentrated in several intervals, for this, we adopt the
Gaussian-Mixture Model to simulate full-scene depth dis-tribution and PauTa Criterion [31] allows us to depict loca-tions that are too close or too far hidden in the long tailing of the depth distribution curve, e.g. sky. The depth distribution loss is proposed finally for full-scene similarity supervision.
In summary, the main contributions are as follows.
• We propose the geometric prior guided feature fusion and the probability volume geometry embedding ap-proaches for robust cost matching.
• We enhance geometry awareness via the frequency do-main filtering strategy and adopt the idea of curriculum learning for progressively introducing geometric clues from easy to difficult.
• We model the depth distribution of MVS scenarios us-ing the Gaussian-Mixture Model assumption and build the full-scene geometry perception loss function.
• The proposed method is extensively evaluated on the
DTU dataset and both intermediate and advanced sets of Tanks and Temples benchmark, all achieving brand-new state-of-the-art performance. 2.