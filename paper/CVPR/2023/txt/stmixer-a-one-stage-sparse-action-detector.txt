Abstract
Traditional video action detectors typically adopt the two-stage pipeline, where a person detector is first em-ployed to generate actor boxes and then 3D RoIAlign is used to extract actor-specific features for classification.
This detection paradigm requires multi-stage training and inference, and cannot capture context information outside the bounding box. Recently, a few query-based action de-tectors are proposed to predict action instances in an end-to-end manner. However, they still lack adaptability in fea-ture sampling and decoding, thus suffering from the issues of inferior performance or slower convergence. In this pa-per, we propose a new one-stage sparse action detector, termed STMixer. STMixer is based on two core designs.
First, we present a query-based adaptive feature sampling module, which endows our STMixer with the flexibility of mining a set of discriminative features from the entire spa-tiotemporal domain. Second, we devise a dual-branch fea-ture mixing module, which allows our STMixer to dynami-cally attend to and mix video features along the spatial and the temporal dimension respectively for better feature de-coding. Coupling these two designs with a video backbone yields an efficient end-to-end action detector. Without bells and whistles, our STMixer obtains the state-of-the-art re-sults on the datasets of AVA, UCF101-24, and JHMDB. 1.

Introduction
Video action detection [14,18,20,30,32,44,46] is an im-portant problem in video understanding, which aims to rec-ognize all action instances present in a video and also local-ize them in both space and time. It has drawn a significant amount of research attention, due to its wide applications in many areas like security and sports analysis.
Since the proposal of large-scale action detection bench-marks [16, 22], action detection has made remarkable progress. This progress is partially due to the advances of video representation learning such as video convolution
*: Equal contribution. (cid:0): Corresponding author.
Figure 1. Comparion of mAP versus GFLOPs. We report detection mAP on AVA v2.2. The GFLOPs of CSN, SlowFast, and VideoMAE are the sum of Faster RCNN-R101-FPN detector
GFLOPs and classifier GFLOPs. Different methods are marked by different makers and models with the same backbone are marked in the same color. The results of CSN are from [53]. Our STMixer achieves the best effectiveness and efficiency balance. neural networks [5, 11, 39–41, 45, 50] and video transform-ers [1, 3, 9, 27, 38, 43, 52].
Most current action detectors adopt the two-stage Faster
R-CNN-alike detection paradigm [31]. They share two ba-sic designs. First, they use an auxiliary human detector to generate actor bounding boxes in advance. The training of the human detector is decoupled from the action classifica-tion network. Second, in order to predict the action category for each actor box, the RoIAlign [17] operation is applied on video feature maps to extract actor-specific features. How-ever, these two-stage action detection pipeline has several critical issues. First, it requires multi-stage training of per-son detector and action classifier, which requires large com-puting resources. Furthermore, the RoIAlign [17] opera-tion constrains the video feature sampling inside the actor bounding box and lacks the flexibility of capturing context information in its surroundings. To enhance RoI features, recent works use an extra heavy module that introduces in-teraction features of context or other actors [29, 36].
Recently sparse query-based object detector [4, 35, 54] has brought a new perspective on detection tasks. Several
query-based sparse action detectors [6, 53] are proposed.
The key idea is that action instances can be represented as a set of learnable queries, and detection can be formulated as a set prediction task, which could be trained by a match-ing loss. These query-based methods detect action instances in an end-to-end manner, thus saving computing resources.
However, the current sparse action detectors still lack adapt-ability in feature sampling or feature decoding, thus suffer-ing from inferior accuracy or slow convergence issues. For example, building on the DETR [4] framework, TubeR [53] adaptively attends action-specific features from single-scale feature maps but perform feature transformation in a static mannner. On the contrary, though decoding sampled fea-tures with dynamic interaction heads, WOO [6] still uses the 3D RoIAlign [17] operator for feature sampling, which constrains feature sampling inside the actor bounding box and fails to take advantage of other useful information in the entire spatiotemporal feature space.
Following the success of adaptive sparse object detector
AdaMixer [12] in images, we present a new query-based one-stage sparse action detector, named STMixer. Our goal is to create a simple action detection framework that can sample and decode features from the complete spatiotem-poral video domain in a more flexible manner, while re-taining the benefits of sparse action detectors, such as end-to-end training and reduced computational cost. Specifi-cally, we come up with two core designs. First, to over-come the aforementioned fixed feature sampling issue, we present a query-guided adaptive feature sampling module.
This new sampling mechanism endows our STMixer with the flexibility of mining a set of discriminative features from the entire spatiotemporal domain and capturing context and interaction information. Second, we devise a dual-branch feature mixing module to extract discriminative represen-tations for action detection. It is composed of an adaptive spatial mixer and an adaptive temporal mixer in parallel to focus on appearance and motion information, respectively.
Coupling these two designs with a video backbone yields a simple, neat, and efficient end-to-end actor detector, which obtains a new state-of-the-art performance on the datasets of AVA [16], UCF101-24 [33], and JHMDB [19]. In sum-mary, our contribution is threefold:
• We present a new one-stage sparse action detection framework in videos (STMixer). Our STMixer is easy to train in an end-to-end manner and efficient to deploy for action detection in a single stage.
• We devise two flexible designs to yield a powerful ac-tion detector. The adaptive sampling can select the discriminative feature points and the adaptive feature mixing can enhance spatiotemporal representations.
• STMixer achieves a new state-of-the-art performance on three challenging action detection benchmarks. 2.