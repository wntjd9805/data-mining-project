Abstract
Image cropping aims to find visually appealing crops in an image. Despite the great progress made by previous methods, they are weak in capturing the spatial relationship between crops and aesthetic elements (e.g., salient objects, semantic edges). Besides, due to the high annotation cost of labeled data, the potential of unlabeled data awaits to be excavated. To address the first issue, we propose spatial-aware feature to encode the spatial relationship between candidate crops and aesthetic elements, by feeding the con-catenation of crop mask and selectively aggregated feature maps to a light-weighted encoder. To address the second issue, we train a pair-wise ranking classifier on labeled images and transfer such knowledge to unlabeled images to enforce rank consistency. Experimental results on the benchmark datasets show that our proposed method per-forms favorably against state-of-the-art methods. 1.

Introduction
The task of image cropping aims to find good crops in an image that can improve the image quality and meet aes-thetic requirement. Image cropping is a prevalent and criti-cal operation in numerous photography-related applications like image thumbnailing, view recommendation, and cam-era view adjustment suggestion.
Many Researchers [2, 4–7, 12, 21, 23, 36, 43, 46, 52, 54, 60, 62, 63] have studied automatic image cropping in the past decades with the goal to reduce the workload of man-ual cropping. Earlier works [2, 3, 12, 31, 43, 44] mainly used saliency detection [49, 59] to detect salient objects and crop around salient objects. Another group of meth-ods [6, 12, 26, 33, 54, 62] designed hand-crafted features to represent specific composition rules in photography.
With the construction of moderate-sized image cropping datasets [4, 52, 54, 56], recently proposed image cropping methods [4, 5, 7, 21, 23, 36, 52, 56, 57, 63] are usually data-driven manner and directly learn how to crop visually ap-*Corresponding author
Source Image
Low-level
High-level
Figure 1. Two examples of the spatial relationship between crops (yellow bounding box) and aesthetic elements (e.g., semantic edges and salient objects). The first column shows the source im-ages, and the second (resp., third) column shows their low-level (resp., high-level) feature maps extracted by a pre-trained Mo-bileNetv2 [39] network with channel-wise max pooling.
It can be seen that low-level feature maps emphasize semantic edges and high-level feature maps highlight salient objects. pealing views from the labeled data. Although these ap-proaches have achieved impressive improvement on image cropping task, there still exist some drawbacks which will be discussed below.
One problem is that when considering the spatial rela-tionship between crops and aesthetic elements (e.g., salient objects, semantic edges), which is very critical for image cropping, previous methods usually designed some intu-itive rules. For example, the crop should enclose the salient object [2, 43, 44], or should not cut through the semantic edges [2, 54]. However, these hand-crafted rules did not consider the spatial layout of all aesthetic elements as a whole, and may not generalize well to various scenes be-cause the rules designed for specific subjects can not cover complex image cropping principles [10].
In this work, we explore learnable spatial-aware fea-tures, which encode the spatial relationship between crops and aesthetic elements. We observe that the feature map obtained using channel-wise max pooling can emphasize some aesthetic elements.
In Figure 1, we show several pooled feature maps from MobileNetv2 [39], from which
it can be seen that the low-level feature maps emphasize semantic edges (e.g., the outlines of semantic objects and regions) and the high-level feature maps emphasize salient objects (e.g., bird, balloon). With concatenated feature maps from different layers, we learn channel attention [16] to select important layers. The weighted feature maps are concatenated with candidate crop masks and sent to a light-weighted encoder to produce spatial-aware features. The extracted spatial-aware features encode the spatial relation-ship between candidate crops and aesthetic elements with-out being limited by any hand-crafted rules.
Another problem is that the cost of crop annotation is very high and the performance is limited by the scale of the annotated training set. Therefore, some previous works explored how to utilize unlabeled data to improve the crop-ping performance. For example, VFN [5] collects unlabeled professional photographs from public websites and perform pairwise ranking based on the assumption that the entire image has higher aesthetic quality than any of its crops.
However, such assumption does not always hold obviously.
VPN [52] used a pre-trained network VEN [52] to predict aesthetic scores for the crops from unlabeled images, which function as pseudo labels to supervise training a new net-work. However, the predicted pseudo labels may be very noisy and provide misleading guidance.
In this work, we explore transferring ranking knowl-edge from labeled images to unlabeled images. Specifically, given two annotated crops from a labeled image, we learn a binary pairwise ranking classifier to judge which crop has higher aesthetic quality, by sending the concatenation of two crop features to a fully connected layer. We expect that the knowledge of comparing the aesthetic quality of two crops with similar content could be transferred to unlabeled data. Given two unannotated crops from an unlabeled im-age, we can obtain two types of ranks. On the one hand, we can rank them according to the predicted crop-level scores.
On the other hand, we can employ the pairwise ranking clas-sifier to get the rank. Then, we enforce two types of ranks to be consistent.
We conduct experiments on GAICD [57] and FCDB [4] dataset. For unlabeled images, we use unlabeled test im-ages, which falls into the scope of transductive learning.
Our major contributions can be summarized as:
• We design a novel spatial-aware feature to model the spatial relationship between candidate crops and aes-thetic elements.
• We propose to transfer ranking knowledge from la-beled images to unlabeled images, and enforce ranking consistency on unlabeled images.
• Our proposed method obtains the state-of-the-art per-formance on benchmark datasets. 2.