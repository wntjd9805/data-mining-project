Abstract
While today’s high dynamic range (HDR) image fusion algorithms are capable of blending multiple exposures, the acquisition is often controlled so that the dynamic range within one exposure is narrow. For HDR imaging in photon-limited situations, the dynamic range can be enormous and the noise within one exposure is spatially varying. Exist-ing image denoising algorithms and HDR fusion algorithms both fail to handle this situation, leading to severe limita-tions in low-light HDR imaging.
This paper presents two contributions. Firstly, we iden-tify the source of the problem. We ﬁnd that the issue is asso-ciated with the co-existence of (1) spatially varying signal-to-noise ratio, especially the excessive noise due to very dark regions, and (2) a wide luminance range within each exposure. We show that while the issue can be handled by a bank of denoisers, the complexity is high. Secondly, we propose a new method called the spatially varying high dy-namic range (SV-HDR) fusion network to simultaneously denoise and fuse images. We introduce a new exposure-shared block within our custom-designed multi-scale trans-former framework. In a variety of testing conditions, the performance of the proposed SV-HDR is better than the ex-isting methods. 1.

Introduction
Today’s high dynamic range (HDR) image fusion al-gorithms have demonstrated remarkable performances in blending images across a wide range of luminance levels.
Many algorithms are able to handle an interior room with a sunlit view, of which the overall dynamic range is in the order of 100000:1 or more. However, most of these algo-rithms are designed for well-illuminated scenes. Even in the shortest exposure frame, the noise is maintained at a modest level so that the algorithm can focus on the blending task.
The question we ask in this paper is: What if we push the shortest exposure to a photon-starving condition?
Such an extreme HDR problem arises in many low-light
Kalantari [17]
Wu [36]
NHDRRNet [39]
Proposed
Figure 1. [Top] Real captures using a Sony ILCE-7M2 camera.
Three low-dynamic range (LDR) images are captured. [Bottom]
Image denoising and HDR fusion results. scenarios. Figure 1 is a real image captured by a Sony
ILCE-7M2 camera. The imaging condition is a night-time scenario in front of a building. The challenge of the prob-lem is the co-existence of heavy noise in the darkest spots of the image and the high dynamic range. We refer to this as the spatially varying signal-to-noise ratio (SNR) problem where brighter pixels have higher SNR and darker pixels have lower SNR.
The goal of this paper is to articulate the spatially vary-ing SNR problem. We emphasize the difﬁculty of the prob-lem by referring to the performance of three state-of-the-art
HDR fusion algorithms, namely, Kalantari and Ramamoor-thi [17], Wu et al. [36], and NHDRRNet [39]. As we can see from Figure 1, these methods produce disappointing re-sults, mostly failing in denoising the dark regions.
The position of the paper can be visualized in Figure 2.
While existing HDR fusion methods can handle the blend-ing task, the individual exposures are sufﬁciently high so that the amount of noise is limited. Single image denois-ers today seldom handle the dynamic range problem. They are mostly focusing on a tonemapped image normalized to
[0, 1]. Therefore, when facing a wide dynamic range scene,
Table 1. Image Sensor Model Parameters
Symbol Meaning
ADC
Clip
τ
µdark
QE
α
σread
P
N
Analog-digital
Full well limit
Exposure dark current
Quantum efﬁciency
Conversion gain
Read noise
Poisson distribution
Gaussian distribution
Typical Value 14-bit 5000 e-50ms 0.02 e-/s 50% 1 at ISO 500 10 ADU at ISO 500
The above equation is sufﬁcient for the problem we are interested in. The model does not take into consideration of other “high-order” effects such as instability of the ADC thresholds, dead pixels (including non-responsive, overly sensitive, random telegraph signal, cross-talk, etc), pixel re-sponse non-uniformity, underﬂow offsets, and more. It also assumes a perfect color ﬁlter array, i.e., the electric and op-tical cross-talks are negligible. 2.2.