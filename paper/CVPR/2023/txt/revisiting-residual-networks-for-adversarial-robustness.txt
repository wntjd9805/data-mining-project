Abstract
Efforts to improve the adversarial robustness of convo-lutional neural networks have primarily focused on devel-oping more effective adversarial training methods. In con-trast, little attention was devoted to analyzing the role of architectural elements (e.g., topology, depth, and width) on adversarial robustness. This paper seeks to bridge this gap and present a holistic study on the impact of architectural design on adversarial robustness. We focus on residual net-works and consider architecture design at the block level as well as at the network scaling level. In both cases, we first derive insights through systematic experiments. Then we design a robust residual block, dubbed RobustResBlock, and a compound scaling rule, dubbed RobustScaling, to distribute depth and width at the desired FLOP count.
Finally, we combine RobustResBlock and RobustScaling and present a portfolio of adversarially robust residual networks, RobustResNets, spanning a broad spectrum of model capacities. Experimental validation across multiple datasets and adversarial attacks demonstrate that Robus-tResNets consistently outperform both the standard WRNs and other existing robust architectures, achieving state-of-the-art AutoAttack robust accuracy 63.7% with 500K exter-nal data while being 2 more compact in terms of parame-ters. Code is available at this URL.
× 1.

Introduction
Robustness to adversarial attacks is critical for prac-tical deployments of deep neural networks. Current re-search on defenses against such attacks has primarily fo-cused on developing better adversarial training (AT) meth-ods [19, 27, 32, 35, 39]. These techniques and the insights derived from them have primarily been developed by fixing the architecture of the network, typically variants of wide residual networks (WRNs) [38]. While a significant body of knowledge exists on designing effective neural networks for vision tasks under standard empirical risk minimization
*Corresponding author
Figure 1. (L) Impact of architectural components on adversar-ial robustness on CIFAR-10, relative to that of adversarial train-ing methods. The variations of each component are elaborated in
§4. (R) Progress of SotA robust accuracy against AutoAttack without additional data on CIFAR-10 with ℓ∞ perturbations of
ϵ = 8/255 chronologically. We show that innovation in architec-ture (this paper) can improve SotA robust accuracy while simulta-neously being almost 2× more compact. Zoom in for details. (ERM) training, i.e., traditional learning without inner op-timization needed in AT, limited attention has been devoted to studying the role of architectural components on adver-sarial robustness. However, as we preview in Figure 1, ar-chitectural components can impact adversarial robustness as much as, if not more than, different AT methods. As such, there is a large void in practitioners’ toolboxes for designing architectures with better adversarial robustness properties.
The primary goal of this paper is to bridge this knowl-edge gap by (i) systematically studying the contribution of architectural components to adversarial robustness, (ii) identify critical design choices that aid adversarial robust-ness, and (iii) finally construct a new adversarially robust network that can serve as a baseline and test bed for study-ing adversarial robustness. We adopt an empirical approach and conduct an extensive amount of carefully designed ex-periments to realize this goal.
We start from the well-founded observation that net-works with residual connections exhibit more robustness to adversarial attacks [3], and thus, consider the family of residual networks. Then we systematically assess the two main aspects of architecture design, block structure and net-work scaling, and adversarially train and evaluate more than 1200 networks. For block structure, we consider the choice of layers, connections among layers, types of resid-ual connections, activation, etc. For network scaling, we
consider the width, depth, and interplay between them. To ensure the generality of the experimental observations, we evaluate them on three different datasets and against four adversarial attacks. To ensure the reliability of the empiri-cal observations, we repeat each experiment multiple times with different seeds. Based on our empirical observations, we identify architectural design principles that significantly improve the adversarial robustness of residual networks.
Specifically, we make the following new observations:
❶ Placing activation functions before convolutional lay-ers (i.e., pre-activation) is, in general, more beneficial with adversarial training, as opposed to post-activation used in standard ERM training. And sometimes, it can critically affect block structures such as the basic block used in WRNs. (§4.1.1, Figure 3a - 3c)
❷ Bottleneck block improves adversarial robustness over the de-facto basic block used in WRNs. In addition, both aggregated and hierarchical convolutions derived under standard ERM training lead to improvements under adversarial training. (§4.1.1, Figure 3d and 4).
❸ A straightforward application of SE [16] degrades ad-versarial robustness. Note that this is unlike in standard
ERM training, where SE consistently improves perfor-mance across most vision tasks when incorporated into residual networks (§4.1.1, Figure 5).
❺ The performance of smooth activation functions is crit-ically dependent on adversarial training (AT) settings and datasets. In particular, removing BN affine param-eters from weight decay is crucial for the effectiveness of smooth activation functions under AT. (§4.1.2)
❹ Under the same FLOPs, deep and narrow residual net-works are adversarially more robust than wide and shallow networks. Specifically, the optimal ratio be-tween depth and width is 7 : 3. (§4.2.2)
❻ In summary, architectural design contributes signifi-cantly to adversarial robustness, particularly the block topology and network scaling factors.
With these insights, we make the following contributions:
• We propose a simple yet effective SE variant, dubbed residual SE, for adversarial training. Empirically, we demonstrate that it leads to consistent improvements in the adversarial robustness of residual networks across multiple datasets, attacks, and model capacities.
• We propose RobustResBlock, a novel residual block
It consistently topology for adversarial robustness. outperforms the de-facto basic block in WRNs by
∼ 3% robust accuracy across multiple datasets, attacks, and model capacities.
• We present RobustScaling, the first compound scaling rule to efficiently scale both network depth and width for adversarial robustness. Technically, RobustScal-ing can scale any architecture (e.g., ResNets, VGGs,
DenseNets, etc.). Experimentally, we demonstrate that
RobustScaling is highly effective in scaling WRNs, where the scaled models yield consistent 2% im-∼ provements on robust accuracy while being 2
× more compact in terms of learnable parameters over standard WRNs (e.g., WRN-28-10, WRNs-70-16).
• We present a new family of residual networks, dubbed
RobustResNets, achieving state-of-the-art AutoAttack
[5] robust accuracy of 61.1% without generated or ex-ternal data and 63.7% with 500K external data while being 2 more compact in terms of parameters.
∼
× 2.