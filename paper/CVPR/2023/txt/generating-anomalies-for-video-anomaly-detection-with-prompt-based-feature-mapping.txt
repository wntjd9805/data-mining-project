Abstract
Anomaly detection in surveillance videos is a challeng-ing computer vision task where only normal videos are available during training. Recent work released the first virtual anomaly detection dataset to assist real-world detec-tion. However, an anomaly gap exists because the anoma-lies are bounded in the virtual dataset but unbounded in the real world, so it reduces the generalization ability of the virtual dataset. There also exists a scene gap between vir-tual and real scenarios, including scene-specific anomalies (events that are abnormal in one scene but normal in an-other) and scene-specific attributes, such as the viewpoint of the surveillance camera. In this paper, we aim to solve the problem of the anomaly gap and scene gap by proposing a prompt-based feature mapping framework (PFMF). The
PFMF contains a mapping network guided by an anomaly prompt to generate unseen anomalies with unbounded types in the real scenario, and a mapping adaptation branch to narrow the scene gap by applying domain classifier and anomaly classifier. The proposed framework outperforms the state-of-the-art on three benchmark datasets. Exten-sive ablation experiments also show the effectiveness of our framework design. 1.

Introduction
Video anomaly detection (VAD) aims to identify abnor-mal scenarios in surveillance videos with broad applications in public security. However, due to the small probability of occurrence, abnormal events are difficult to be observed in real-life surveillance. The challenge increases because of the unconstrained nature of abnormal events. Given a spe-cific scenario, the event different from normal events can all be regarded as anomalies, so the anomaly type is un-bounded.
*Corresponding author
Most VAD approaches address this challenge by learn-ing the distribution of normal events in the training stage and detecting the out-of-distribution events in the testing stage. These methods are categorized into reconstruction-based methods [1, 14, 31] to reconstruct the current frame and prediction-based methods [26, 27, 27, 30, 34] to predict the upcoming frame. Significant reconstruction or predic-tion error is regarded as an anomaly. However, due to the strong generalization ability of the deep networks and the similarity between normal and abnormal events, the anoma-lies do not always lead to enough error to be detected. With-out prior knowledge of abnormal distribution, it is difficult for the network to detect unseen anomalies.
Therefore, instead of calculating error with the distri-bution of normal behaviors, some methods [11, 12, 53, 54] try to generate pseudo anomalies to simulate the distribu-tion of abnormal behaviors. For example, Georgescu et al. [12] collect a large number of images from Tiny Ima-geNet unrelated to the detection scenario as pseudo anoma-lous samples. Their other work [11] tries to generate tempo-ral anomalies by reversing the action order or motion irreg-ularity by extracting intermittent frames. The network can get a glimpse of the feature distribution different from nor-mal events by manually applying pseudo anomalies. How-ever, the main drawback of these methods is the unavoid-able gap between pseudo and natural anomalies.
To solve the problem of pseudo anomalies, Acsintoae et al. [2] released a virtual VAD dataset named Ubnormal us-ing 3D animations and 2D background images. It contains 22 types of anomaly, such as fighting, stealing, laying down, etc. The distribution of real anomalies can be well eval-uated by applying the virtual dataset. However, applying virtual anomalies to real scenarios is a great challenge due to the large domain gap. Acsintoae et al. [2] train a Cycle-GAN [60] to achieve video-level style transfer from virtual to the real domain to address the challenge.
However, existing methods fail to address two key chal-lenges. Firstly, the anomalies are bounded in the virtual dataset but unbounded in the real world, and we define
Figure 1. An overview of prompt-based feature mapping framework (PFMF). The PFMF totally contains three parts, i.e., feature extractor, prompt-based feature mapping network, and mapping adaptation branch. The feature extractor is used to transform the input instances into corresponding features, so the mapping process can be completed at the feature level. The prompt-based feature mapping network aims to map normal features into abnormal feature space under the same domain guided by an anomaly prompt, so the unseen anomalies in the real domain can be generated from normal features. The mapping adaptation branch is added to make the generated anomalies scene-specific and solve the problem of scene-specific attributes. this difference as anomaly gap. Secondly, different scenar-ios have scene-specific anomalies (events that are abnormal in one scene but normal in another) and scene-specific at-tributes (such as the viewpoint of the surveillance camera), and we define this difference as scene gap.
Our work is motivated by the above two key challenges.
To solve the problem of anomaly gap and scene gap, we pro-pose a novel framework named prompt-based feature map-ping framework (PFMF), as shown in Fig. 1. In terms of narrowing the anomaly gap, the PFMF employs a prompt-guided mapping network to generate unbounded anomalies through a divergent mapping process. The prompts are sam-pled from distribution learned by a variational auto-encoder (VAE) [17]. As for the scene gap, we introduce a mapping adaptation branch to solve it. In detail, the branch consists of an anomaly classifier to make the generated anomalies scene-specific, and two domain classifiers to reduce the in-consistency caused by scene-specific attributes.
In summary, this paper makes the following contribu-tions: (1) Proposing a novel prompt-based feature mapping framework (PFMF) for video anomaly detection. This framework addresses the challenge of applying virtual VAD datasets with limited anomalies to the real scenario by gen-erating unseen anomalies with unbounded types. (2) Proposing a mapping adaptation branch to ensure the anomalies generated by PFMF are scene-specific and solve the problem of scene-specific attributes. (3) Showing the effectiveness of the proposed framework on three public VAD datasets, ShanghaiTech, Avenue, and
UCF-Crime. Extensive experiments show that the proposed framework performs the best compared with the state-of-the-art. 2.