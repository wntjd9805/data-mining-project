Abstract
Medical images usually suffer from image degradation in clinical practice, leading to decreased performance of deep learning-based models. To resolve this problem, most previous works have focused on filtering out degradation-causing low-quality images while ignoring their potential value for models. Through effectively learning and leverag-ing the knowledge of degradations, models can better resist
In this pa-their adverse effects and avoid misdiagnosis. per, we raise the problem of image quality-aware diagnosis, which aims to take advantage of low-quality images and im-age quality labels to achieve a more accurate and robust di-agnosis. However, the diversity of degradations and super-ficially unrelated targets between image quality assessment and disease diagnosis makes it still quite challenging to ef-fectively leverage quality labels to assist diagnosis. Thus, to tackle these issues, we propose a novel meta-knowledge co-embedding network, consisting of two subnets: Task Net and Meta Learner. Task Net constructs an explicit quality information utilization mechanism to enhance diagnosis via knowledge co-embedding features, while Meta Learner en-sures the effectiveness and constrains the semantics of these features via meta-learning and joint-encoding masking. Su-perior performance on five datasets with four widely-used medical imaging modalities demonstrates the effectiveness and generalizability of our method. 1.

Introduction
Medical imaging is one of the most valuable sources of diagnostic information about anatomical structures and pathological characteristics [1]. Advanced deep learning-based methods applied to high-quality (HQ) medical im-ages have shown significant potential in disease analysis and diagnosis [2, 3], achieving favorable results compared with human healthcare professionals [4]. However, in clin-ical practice, obtaining HQ images is not always feasible.
Medical images often exhibit significant variations in imag-ing quality due to factors such as patient movements or en-*Corresponding author: Hao Chen, email: jhc@cse.ust.hk.
Figure 1. Illustration of impact of image degradations on diagno-sis semantics for fundus (top) and OCTA (bottom) images. Top:
Degradations obscure parts of the vessel structure and present lesion-like spots. Bottom: Degradations result in a fake enlarge-ment of the foveal avascular zone (central circular area). vironmental conditions [5,6]. For instance, a medical image quality assessment study of 28,780 fundus images revealed that approximately 41.6% of them contained image artifacts and corruption and were considered low-quality (LQ) [7].
Such degradations can increase the uncertainty in patholog-ical observation, leading to misdiagnosis [8, 9].
Medical image degradations can significantly affect di-agnostic semantics, as illustrated in Figure 1. For instance, shadow degradation can obscure anatomical structures cru-cial for diagnosis, while spot artifacts can obfuscate patho-logical signs that typically manifest as circular shapes [10].
Furthermore, image degradations can also affect diagnos-tic measurements, such as the vessel area density in optical coherence tomography angiography (OCTA) images, ren-dering them unreliable [6]. These close relationships raise challenges in distinguishing degradations from actual ab-normalities [10], leading to false knowledge of lesions and undesired misdiagnosis during training and deployment [9].
Aware of the profound influence of image quality on diag-nosis, many previous works have focused on utilizing image quality assessment to select relatively HQ images for train-ing and testing, thereby avoiding the influence of LQ im-ages [7, 11–14]. However, discarding LQ images contain-ing diagnostically valuable information results in a waste of precious clinical data [7]. Including LQ images and corre-sponding quality information in training can assist models in recognizing potential false abnormalities, thus achieving more robust and accurate diagnosis [15–17].
In this paper, we reconsider the value of LQ images and corresponding image quality labels, and introduce the prob-lem of image quality-aware diagnosis (IQAD). The goal of
IQAD is to enable models to leverage LQ images while si-multaneously learning image quality labels to achieve an accurate and robust diagnosis. However, effectively lever-aging quality labels for diagnosis is non-trivial with a multi-task learning framework. Specifically, image quality assess-ment can be considered as a task “unrelated” to disease di-agnosis [18], since it focuses on capturing image degrada-tions, while diagnosis emphasizes identifying lesions. This distinction makes it challenging for models to effectively utilize image quality labels. Further, commonly-used coarse annotations of quality may not sufficiently reflect the diver-sity of image degradation, making it difficult to provide in-formation that could be useful for precise diagnosis.
To achieve IQAD, we propose a novel meta-knowledge co-embedding network (MKCNet) consisting of two sub-nets, Task Net and Meta Learner. To enable leveraging potential benefits of quality information, Task Net con-ducts diagnosis predictions by explicitly leveraging knowl-edge co-embedding features with desired knowledge of image quality and disease diagnosis. These features are constructed by learning auxiliary label embeddings from
Meta Learner. Further, we employ meta-learning and joint-encoding masking to ensure the effectiveness and seman-tics of auxiliary label embedding and circumvent the bar-rier of obtaining fine-grained image quality labels. Specif-ically, joint-encoding masking selects a part of the Meta
Learner output as auxiliary label embedding through com-binations of quality and diagnosis labels. Moreover, Meta
Learner learns to provide auxiliary label embedding in a meta-learning manner to assist Task Net optimization, en-couraging it to learn effective knowledge co-embedding features. Our main contributions are highlighted as follows: (1) We tackle a novel problem named IQAD. To the best of our knowledge, this is the first work to discuss and ana-lyze this critical and practical problem. (2) We propose a novel method, MKCNet, to effectively handle the challenges posed by annotation granularity and task focus discrepancy via leveraging quality information explicitly and introducing a meta-learning paradigm. (3) We conduct extensive experiments on five datasets spanning four different yet widely-used medical imaging modalities. Our in-depth analytical study demonstrates the effectiveness and generalizability of MKCNet. 2.