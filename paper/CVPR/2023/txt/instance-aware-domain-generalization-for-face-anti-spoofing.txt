Abstract
Face anti-spoofing (FAS) based on domain generaliza-tion (DG) has been recently studied to improve the gener-alization on unseen scenarios. Previous methods typically rely on domain labels to align the distribution of each do-main for learning domain-invariant representations. How-ever, artificial domain labels are coarse-grained and sub-jective, which cannot reflect real domain distributions ac-curately. Besides, such domain-aware methods focus on domain-level alignment, which is not fine-grained enough to ensure that learned representations are insensitive to do-main styles. To address these issues, we propose a novel perspective for DG FAS that aligns features on the instance
Specifically, level without the need for domain labels.
Instance-Aware Domain Generalization framework is pro-posed to learn the generalizable feature by weakening the features’ sensitivity to instance-specific styles. Concretely, we propose Asymmetric Instance Adaptive Whitening to adaptively eliminate the style-sensitive feature correlation, boosting the generalization. Moreover, Dynamic Kernel
Generator and Categorical Style Assembly are proposed to first extract the instance-specific features and then generate the style-diversified features with large style shifts, respec-tively, further facilitating the learning of style-insensitive features. Extensive experiments and analysis demonstrate the superiority of our method over state-of-the-art competi-tors. Code will be publicly available at this link. 1.

Introduction
Face anti-spoofing (FAS) plays a critical role in protect-ing face recognition systems from various presentation at-tacks, e.g., printed photos, video replay, etc. To cope with these presentation attacks, a series of FAS works based on
*Equal contribution.
†Corresponding author.
Figure 1. Conventional DG-based FAS approaches typically rely on artificially-defined domain labels to perform domain-aware do-main generalization, which cannot guarantee that the learned rep-resentations are still insensitive to domain-specific styles. In con-trast, our method does not rely on such domain labels and focuses on the instance-aware domain generalization via exploring asym-metric instance adaptive whiting on the fine-grained instance level. hand-crafted features [3, 15, 23, 33, 47], and deeply-learned features [12, 19, 28, 49, 51] have been proposed. Although these methods have achieved promising performance in intra-dataset scenarios, they suffer from poor generalization when adapting to various unseen domains.
To improve the generalization ability on unseen do-mains, recent studies introduce domain generalization (DG) techniques into the FAS tasks, which utilize the adversar-ial learning [21, 39, 44] or meta-learning [7, 11, 29, 30, 61] to learn domain-invariant representations. Despite its grat-ifying progress, most of these DG-based FAS methods uti-lize domain labels to align the distribution of each domain for domain-invariant representations, as shown in Figure 1. However, such domain-aware methods suffer from two major limitations. Firstly, the artificial domain labels uti-lized in their methods are very coarse, and cannot accu-rately and comprehensively reflect the real domain distri-butions. For example, numerous illumination conditions, attack types, and background scenes are ignored in the
source domains, which might lead to various fine-grained sub-domains. Though D2AM [7] tries to alleviate these is-sues via assigning pseudo domain labels to divide the mixed source domains, it still manually sets the number of pseudo source domains and does not solve the problem in essence.
Secondly, such domain-level alignment only constrains fea-tures from the perspective of distribution, which is not fine-grained enough to guarantee that all channels of features are insensitive to the instance-specific styles. Thus, the learned features might still contain information sensitive to instance-specific styles when encountering novel samples, failing to generalize on the unseen domain.
To address these issues, we propose a novel perspec-tive of DG-FAS that explores the style-insensitive features and aligns them on a fine-grained instance level without the need for domain labels, improving the generalization abilities towards unseen domains. Specifically, we propose an Instance-Aware Domain Generalization (IADG) frame-work to dynamically extract generalized representations for each sample by encouraging their features to be insensitive to the instance-specific styles. Concretely, we first intro-duce Asymmetric Instance Adaptive Whitening (AIAW) to boost the generalization of features via adaptively whiten-ing the style-sensitive feature correlation for each instance.
Instead of directly learning the domain-agnostic features,
AIAW aims to weaken the feature correlation (i.e., covari-ance matrix) from higher-order statistics on a fine-grained instance level. Considering the distribution discrepancies of real and spoof samples, AIAW adopts asymmetric strate-gies to supervise them, boosting the generalization capabil-ity. Moreover, to facilitate the learning of style-insensitive features in AIAW, Dynamic Kernel Generator (DKG) and
Categorical Style Assembly (CSA) are proposed to gen-erate style-diversified features for further AIAW. Specifi-cally, DKG models the instance-adaptive features, which automatically generates instance-adaptive filters that work with static filters to facilitate comprehensive instance-aware feature learning. Based on such instance-adaptive features,
CSA simulates instance-wise domain shifts by considering the instance diversity to generate style-diversified samples in a wider feature space, which augments real and spoof faces separately to prevent the label changes in the FAS task. Our main contributions are three-fold:
• We propose a novel perspective of DG FAS that aligns feature representations on the fine-grained instance level in-stead of relying on artificially-defined domain labels.
• We present an innovative Instance-Aware Domain
Generalization (IADG) framework, which actively simu-lates the instance-wise domain shifts and whitens the style-sensitive feature correlation to improve the generalization.
• Extensive experiments with analysis demonstrate the superiority of our method against state-of-the-art competi-tors on the widely-used benchmark datasets. 2.