Abstract
Reconstructing dynamic 3D garment surfaces with open boundaries from monocular videos is an important problem as it provides a practical and low-cost solution for clothes digitization. Recent neural rendering methods achieve high-quality dynamic clothed human reconstruction results from monocular video, but these methods cannot separate the garment surface from the body. Moreover, despite ex-isting garment reconstruction methods based on feature curve representation demonstrating impressive results for garment reconstruction from a single image, they struggle to generate temporally consistent surfaces for the video in-put. To address the above limitations, in this paper, we for-mulate this task as an optimization problem of 3D garment feature curves and surface reconstruction from monocular video. We introduce a novel approach, called REC-MV, to jointly optimize the explicit feature curves and the implicit signed distance ﬁeld (SDF) of the garments. Then the open garment meshes can be extracted via garment template reg-istration in the canonical space. Experiments on multiple casually captured datasets show that our approach outper-forms existing methods and can produce high-quality dy-namic garment surfaces. The source code is available at https://github.com/GAP-LAB-CUHK-SZ/REC-MV. 1.

Introduction
High-ﬁdelity clothes digitization plays an essential role in various human-related vision applications such as vir-tual shopping, ﬁlm, and gaming.
In our daily life, hu-mans are always in a moving status, driving their clothes to move together. To realize this very common scenario, it is indispensable to gain dynamic garments in real applica-tions. Thanks to the rapid development of mobile devices in terms of digital cameras, processors, and storage, shoot-ing a monocular video in the wild becomes highly conve-nient and accessible for general customers. In this paper,
* Equal contribution.
† Corresponding author: hanxiaoguang@cuhk.edu.cn.
Figure 1. Can we extract dynamic 3D garments from monocu-lar videos? The answer is Yes! By jointly optimizing the dynamic feature curves and garment surface followed by non-rigid template registration, our method can reconstruct high-ﬁdelity and tempo-rally consistent garment meshes with open boundaries. our goal is deﬁnite – extracting dynamic 3D garments from monocular videos, which is signiﬁcantly meaningful and valuable for practical applications, but is yet an uncultivated land with many challenges.
We attempt to seek a new solution to this open prob-lem and start by revisiting existing works from two main-streams. i) Leveraging the success of neural rendering methods [35, 37, 57], several works are able to recon-struct dynamic clothed humans from monocular videos
[8, 19, 29, 47, 49], by representing the body surface with an implicit function in the canonical space and apply skin-ning based deformation for motion modeling. One naive way to achieve our goal is: ﬁrst to get the clothed human through these methods and separate the garments from hu-man bodies. However, such a separation job requires la-borious and non-trivial processing by professional artists, which is neither straightforward nor feasible for general application scenarios. ii) As for garment reconstruction, many methods [5, 10, 20, 61, 62] make it possible to recon-struct high-quality garment meshes from single-view im-ages in the wild. Speciﬁcally, ReEF [62] estimates 3D fea-ture curves* and an implicit surface ﬁeld [34] for non-rigid garment template registration. Nonetheless, these meth-ods struggle to produce temporally consistent surfaces when taking videos as inputs.
The above discussion motivates us to combine the mer-its of both the dynamic surface modeling in recent neu-ral rendering methods and the explicit curve representation for garment modeling. To this end, we try to delineate a new path towards our goal: optimizing dynamic explicit feature curves and implicit garment surface from monocu-lar videos, to extract temporally consistent garment meshes with open boundaries. We represent the explicit curves and implicit surface in the canonical space with skinning-based motion modeling, and optimize them by 2D supervision au-tomatically extracted from the video (e.g., image intensities, garment masks, and visible feature curves). After that, the open garment meshes can be extracted by a garment tem-plate registration in the canonical space (see Fig. 1).
We strive to probe this path as follows: (1) As a feature curve is a point set whose deformation has a high degree of freedom, directly optimizing the per-point offsets often leads to undesired self-intersection and spike artifacts. To better regularize the deformation of curves, we introduce an intersection-free curve deformation method to maintain the order of feature curves. (2) We optimize the 3D fea-ture curves using 2D projection loss measured by the esti-mated 2D visible curves, where the key challenge is to ac-curately compute the visibility of curves. To address this problem, we propose a surface-aware curve visibility esti-mation method based on the implicit garment surface and z-buffer. (3) To ensure the accuracy of curve visibility es-timation during the optimization process, the curves should always be right on the garment surface. We therefore in-troduce a progressive curve and surface evolution strategy to jointly update the curves and surface while imposing the on-surface regularization for curves.
To summarize, the main contributions of this work are:
• We introduce REC-MV, to our best knowledge, the
ﬁrst method to reconstruct dynamic and open loose garments from the monocular video.
• We propose a new approach for joint optimization of explicit feature curves and implicit garment sur-face from monocular video, based on carefully de-signed intersection-free curve deformation, surface-aware curve visibility estimation, and progressive curve and surface evolution methods.
• Extensive evaluations on casually captured monocular videos demonstrate that our method outperforms exist-ing methods.
* feature curves of the garment (e.g., necklines, hemlines) can provide criti-cal cues for determining the shape contours of the garment. 2.