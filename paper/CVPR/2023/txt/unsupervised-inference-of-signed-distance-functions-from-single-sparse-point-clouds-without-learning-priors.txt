Abstract
It is vital to infer signed distance functions (SDFs) from 3D point clouds. The latest methods rely on generalizing the priors learned from large scale supervision. Howev-er, the learned priors do not generalize well to various ge-ometric variations that are unseen during training, espe-cially for extremely sparse point clouds. To resolve this issue, we present a neural network to directly infer SDFs from single sparse point clouds without using signed dis-tance supervision, learned priors or even normals. Our in-sight here is to learn surface parameterization and SDFs inference in an end-to-end manner. To make up the spar-sity, we leverage parameterized surfaces as a coarse sur-face sampler to provide many coarse surface estimations in training iterations, according to which we mine super-vision and our thin plate splines (TPS) based network in-fers SDFs as smooth functions in a statistical way. Our method signiﬁcantly improves the generalization ability and accuracy in unseen point clouds. Our experimental result-s show our advantages over the state-of-the-art method-s in surface reconstruction for sparse point clouds under synthetic datasets and real scans.The code is available at https://github.com/chenchao15/NeuralTPS. 1.

Introduction
Signed distance functions (SDFs) have been a popular 3D representation that shows impressive performance in various tasks [1–4, 7, 12, 15, 17, 21, 22, 30, 31, 34, 35, 41, 42, 44, 47, 50, 57, 62, 64, 68, 69, 77, 80, 84]. An SDF describes a signed distance ﬁeld as a mapping from a coordinate to a signed distance, and represents a surface as a level set of (cid:3)The corresponding author is Yu-Shen Liu. This work was supported by National Key R&D Program of China (2022YFC3800600), the Nation-al Natural Science Foundation of China (62272263, 62072268), and in part by Tsinghua-Kuaishou Institute of Future Media Data. the ﬁeld. We can learn SDFs from signed distance super-vision using coordinate-based neural networks. However, obtaining the signed distance supervision requires continu-ous surfaces such as water-tight manifolds, hence it is still challenging to infer signed distance supervision from raw point clouds due to the discrete character.
Current methods [17, 21, 28, 30, 36, 41, 50, 51, 55, 56, 58, 62,64] mainly leverage priors to infer SDFs for point cloud-s. They learn priors from well established signed distance supervision around point clouds during training, and then generalize the learned priors to infer SDFs for unseen point clouds during testing. Although local priors learned at a part level [7,9,31,45,65,73] improve the generalization of global priors learned at a shape level [17, 21, 30, 41, 50, 60, 62, 64], the geometric variations that local priors can cover are still limited. Hence, some methods [1–3, 14, 22, 44, 80, 84] try to directly infer SDFs from single point clouds using various strategies [1, 2, 12, 22, 44, 84]. However, they require dense point clouds to assure the inference performance, which drastically limits their performance with sparse point cloud-s in real scans. Therefore, how to infer SDFs from sparse point clouds to achieve better generalization is still a chal-lenge.
To overcome this challenge, we introduce a neural net-work to infer SDFs from single sparse point clouds. Our novelty lies in the way of inferring SDFs without signed distance supervision, learned priors or even normals, which signiﬁcantly improves the generalization ability and accu-racy in unseen point clouds. We achieve this by learning surface parameterization and SDF inference in an end-to-end manner using a neural network that overﬁts a single sparse point cloud. To make up the sparsity, the end-to-end learning turns parameterized surfaces as a coarse surface sampler which produces many coarse surface estimations on the ﬂy to statistically infer the SDF. To target extremely sparse point clouds, we parameterize the surface of a point cloud as a single patch on a 2D plane, where 2D samples can be mapped to 3D points that lead to a coarse surface es-timation. We further leverage the estimated coarse surface
as a reference to infer the SDF based on thin plate splines (TPS) in the feature space, which produces smooth signed distance ﬁelds. Our method can statistically infer the S-DFs from the permutation of coarse surfaces in different iterations, which reduces the effect of inaccuracy brought by each single coarse surface. Our method outperforms the latest methods under the widely used benchmarks. Our con-tributions are listed below. i) We introduce a neural network to infer SDFs from sin-gle sparse point clouds without using signed distance supervision, learned priors or even normals. ii) We justify the feasibility of learning surface parameter-ization and inferring SDFs from sparse point clouds in an end-to-end manner. We provide a novel perspective to use surface parameterization to mine supervision. iii) Our method outperforms the state-of-the-art methods in surface reconstruction for sparse point clouds under the widely used benchmarks. 2.