Abstract
The existing few-shot medical segmentation networks share the same practice that the more prototypes, the bet-ter performance. This phenomenon can be theoretically in-terpreted in Vector Quantization (VQ) view: the more pro-totypes, the more clusters are separated from pixel-wise feature points distributed over the full space. However, as we further think about few-shot segmentation with this perspective, it is found that the clusterization of feature points and the adaptation to unseen tasks have not received enough attention. Motivated by the observation, we propose a learning VQ mechanism consisting of grid-format VQ (GFVQ), self-organized VQ (SOVQ) and residual oriented
VQ (ROVQ). To be specific, GFVQ generates the prototype matrix by averaging square grids over the spatial extent, which uniformly quantizes the local details; SOVQ adap-tively assigns the feature points to different local classes and creates a new representation space where the learn-able local prototypes are updated with a global view; ROVQ introduces residual information to fine-tune the aforemen-tioned learned local prototypes without re-training, which benefits the generalization performance for the irrelevance to the training task. We empirically show that our VQ framework yields the state-of-the-art performance over ab-domen, cardiac and prostate MRI datasets and expect this work will provoke a rethink of the current few-shot medical segmentation model design. Our code will soon be publicly available. 1.

Introduction
Semantic segmentation is one of the fundamental tasks in medical imaging applications, e.g., disease diagnosis [1, 2], monitoring [3, 4], and screening [5]. With sufficient labeled data being fed into the deep network, segmentation models can achieve promising results. However, in most practical scenarios, the segmentation models often suffer from the
*Correspondence to: Tingfa Xu and Jianan Li.
Figure 1. Schematic diagram of different clustering representa-tion schemes of few-shot medical segmentation: (a) the basic VQ with each class represented by a prototype vector; (b) the GFVQ, i.e., the existing local prototype generation, extracts prototype ar-ray via mobile pooling window; (c) the proposed SOVQ assigns the pixel-wise features to multiple local classes adaptively; (d) the proposed ROVQ fine-tunes the learned prototype vectors param-eterlessly to enhance the adaption performance to unseen tasks.
The arrows denote the more accurate edge in (d). lack of required data due to the expensive cost of expertise dense annotations and limited number of abnormal organ and rare lesion samples.
Recently, few-shot medical image segmentation has been widely studied to reduce the requirement for large-scale datasets with dense annotations [6–8]. Currently, the common inference paradigm of few-shot medical image segmentation is to encode a prototype to represent the novel class appearing in the support image (Fig. 1(a)) and com-pute the similarity with query features to perform segmen-tation [9–12]. The essential work of such a framework lies in prototype learning, which is carried out only by the fea-ture encoder. This encoder is learned with training tasks in the training stage and generalized to unseen tasks in the test-ing stage. From a vector quantization (VQ) view, the pro-totype vectors representing different classes can be consid-ered as the known sample points in a coding space, and the pixel-wise query feature points are supposed to be classified by decision boundaries determined by the known support points [13–15]. In this view, the prototype learning problem is rethought to be a VQ optimization problem and the pro-totype vectors learned from support features are thought to serve as the support vectors delineating the encoding space for query features. Therefore, the aim of prototypical few-shot segmentation task translates into the requirements for the prototype vectors learned by VQ: discriminative repre-sentation and strong generalization.
The requirement for discriminative representation is of concern to many researchers as the prototype generation strategy. Ouyang et al. [10] applied non-overlapping pool-ing windows to support features generating multiple local prototypes; Yu et al. [11] extracted prototype arrays in the presence of grid constraint and performed a location-guided comparison; Li et al. [12] designed a registration mecha-nism to align local prototypes between support and query features. The aforementioned schemes can be summarized intuitively that the more prototypes, the better the segmen-tation performance. However, experiments show that as the number of prototypes increases, the performance deterio-rates: on one hand, the set of pooling prototypes reaches saturation of representation capacity; on the other hand, too many prototypes cannot distinguish between classes, result-ing in blurred edges or even misclassification. Unlike the requirement for discriminative representation, requirement for strong generalization is often ignored by the previous works in prototype learning. To improve the generaliza-tion capability, most researches adopt a unified lightweight encoding network to simultaneously process support and query images [7, 16]. However, few efforts have put gen-eralization studies on prototype learning.
To meet the requirement for discriminative representa-tion, we detail two sub-requirements, i.e., ❶ the clustering of feature points and ❷ the embedding of prototype vec-tors. Considering this two sub-requirements, we propose a self-organized vector quantization (SOVQ) method, in-spired by self-organized mapping algorithm [17, 18], con-taining a self-organized clustering (SOC) and a local map-ping (LM). To abstract features more exactly, SOVQ first creates a new neuron representation space, where neurons are initialized as prototypes and arranged in a normative ar-ray. Then the feature points are assigned to different neu-rons adaptively (for ❶), and the learnable neurons are opti-mized by the features collaboratively (for ❷). Through it-erative learning, the feature points are clustered reasonably and each cluster is represented by a neuron with a global view (Fig. 1(c)).
Furthermore, LM strategy is designed to remap neurons to the encoding space ensuring the prototypes and query features are embedded consistently. Each neuron is inter-preted as a weighted sum of GFVQ prototypes via inverse distance weighting and interpolated to GFVQ forming a topologically prototype layout. In summary, through self-organizing the feature points in an unsupervised manner,
SOVQ fits the space of interest.
The requirement for strong generalization is also divided into two sub-requirements: ❸ to avoid overfitting to train-ing tasks and ❹ to adapt the model to testing tasks. Thus a residual oriented vector quantization (ROVQ) is put for-ward, which introduces the residual connection to final vec-tor layout and fine-tunes the learned vectors. On the one hand, the parameter-free learning acts as a regularization term in the training phase to prevent overfitting (for ❸); on the other hand, the residual information with labels guides the prototype vector to get closer to its inherent characteris-tics and differentiate from other classes (for ❹), which con-tributes to maintaining details and forming a clearer edge (Fig. 1(d)).
Additionally, following the earlier works on multiple prototype generation, we employ a grid-format vector quan-tization (GFVQ) to obtain a compressed feature points.
As shown in Fig. 1(a), the features are rasterized in grid and compressed by average pooling. Although GFVQ and
SOVQ both extract prototypes representing local features,
SOVQ is equipped with global receptive field and provides a more specific division of the feature space, while GFVQ is restricted in its grid-format receptive field.
Overall, the medical prototypical few-shot segmenta-tion task is formalized as the vector quantization learn-ing for few-shot class representing. To satisfy the require-ment for strong representation and generalization, i.e., sub-requirements ❶-❹, we propose a learning VQ mechanism: a dual structure is employed to integrate GFVQ and SOVQ generating well-representative and limited-quantity proto-type vector set, and the former serves as compressed fea-ture reference for LM of SOVQ. Then the prototype set is fine-tuned with ROVQ to maintain the detailed informa-tion and enhance generalization capability, and finally the dense prediction is performed by similarity measurement.
We show our method achieves the state-of-the-art perfor-mance on Abdomen, Cardiac and Prostate MR images with extensive experiments. 2.