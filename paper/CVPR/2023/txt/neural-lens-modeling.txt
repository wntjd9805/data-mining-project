Abstract
Recent methods for 3D reconstruction and rendering in-creasingly benefit from end-to-end optimization of the entire image formation process. However, this approach is cur-rently limited: effects of the optical hardware stack and in particular lenses are hard to model in a unified way. This limits the quality that can be achieved for camera calibra-tion and the fidelity of the results of 3D reconstruction. In this paper, we propose NeuroLens, a neural lens model for distortion and vignetting that can be used for point projec-tion and ray casting and can be optimized through both operations. This means that it can (optionally) be used to perform pre-capture calibration using classical calibration targets, and can later be used to perform calibration or re-finement during 3D reconstruction, e.g., while optimizing a radiance field. To evaluate the performance of our proposed model, we create a comprehensive dataset assembled from the Lensfun database with a multitude of lenses. Using this and other real-world datasets, we show that the quality of our proposed lens model outperforms standard packages as well as recent approaches while being much easier to use and extend. The model generalizes across many lens types and is trivial to integrate into existing 3D reconstruc-tion and rendering systems. Visit our project website at: https://neural-lens.github.io. 1.

Introduction
Camera calibration is essential for many computer vision applications: it is the crucial component mapping measure-ments and predictions between images and the real world.
This makes calibration a fundamental building block of 3D reconstruction and mapping applications, and of any system that relies on spatial computing, such as autonomous driving or augmented and virtual reality. Whereas camera extrin-sics and the parameters of a pinhole model can be easily described and optimized, this often does not hold for other parameters of an optical system and, in particular, lenses. Yet
*Work done during an internship at RLR. 1The approach is visualized on FisheyeNeRF recordings [23].
Figure 1. Method Overview. The optical stack leads to light ray distortion and vignetting. We show that invertible residual networks are a powerful tool to model the distortion for projection and ray casting across many lenses and in many scenarios. Additionally, we propose a novel type of calibration board (top left) that can optionally be used to improve calibration accuracy. For evaluation, we propose the ‘SynLens’ dataset to evaluate lens models at scale.1 lenses have a fundamental influence on the captured image through distortion and vignetting effects.
Recent results in 3D reconstruction and rendering sug-gest that end-to-end modeling and optimization of the im-age formation process leads to the highest fidelity scene reproductions [33, 34]. Furthermore, per-pixel gradients are readily available in this scenario and could serve as a means to optimize a model of all components of the optical stack to improve reconstruction quality. However, modeling and optimizing lens parameters in full generality and also differ-entiably is hard: camera lenses come in all kinds of forms and shapes (e.g., pinhole, fisheye, catadioptric) with quite different optical effects.
So how can we create a flexible and general and differ-entiable lens model with enough parameters to approximate any plausible distortion? In classical parametric models, the internals of the camera are assumed to follow a model with a limited number of parameters (usually a polynomial approx-imation). These approaches work well when the distortion is close to the approximated function, but cannot general-ize beyond that specific function class. On the other hand, non-parametric models that associate each pixel with a 3D ray have also been explored. These models are designed to model any type of lens, but tend to require dense key-point measurements due to over-parameterization. Hence, we aim to find models with some level of regularization to prevent such issues, without unnecessarily constraining the complexity of the distortion function. Our key insight is to use an invertible neural network (INN) to model ray distortion, combined with standard camera intrinsics and extrinsics. This means that we model the camera lens as a mapping of two vector fields using a diffeomorphism (i.e., a bijective mapping where both the mapping and its inverse are differentiable), represented by an INN. This approach usefully leverages the invertibility constraints provided by
INNs to model the underlying physics of the camera lens.
Our lens model has several advantages. Its formulation makes it easy to differentiate point projection and ray cast-ing operations in deep learning frameworks and it can be integrated into any end-to-end differentiable pipeline, with an inductive bias that serves as a useful regularizer for lens models. It is flexible: we can scale the model parameters to adapt to different kinds of lenses.using gradient-based methods for point projection as well as ray casting. This makes our model applicable to pattern-based camera cal-ibration as well as to dense reconstruction where camera parameter refinement is desired. In the case of (optional) marker-based calibration, we suggest to use an end-to-end optimized marker board and keypoint detector. The proposed marker board outperforms several other alternatives in our experiments, and can easily be adjusted to be particularly robust to distortions of different sensor and lens types.
It is currently impossible to evaluate lens models at scale in a standardized way: large-scale camera lens benchmarks including ground truth data simply do not exist. We pro-pose to address this issue by generating a synthetic dataset, called SynLens, consisting of more than 400 different lens profiles from the open-source Lensfun database. To create
SynLens, we simulate distortion and vignetting and (option-ally) keypoint extraction noise using real lens characteristics to account for a wide variety of lenses and cameras.
We provide qualitative and quantitative comparisons with prior works and show that our method produces more ac-curate results in a wide range of settings, including pre-calibration using marker boards, fine-tuning camera models during 3D reconstruction, and using quantitative evaluation on the proposed SynLens dataset. We show that our model achieves subpixel accuracy even with just a few keypoints and is robust to noisy keypoint detections. The proposed method is conceptually simple and flexible, yet achieves state-of-the-art results on calibration problems. We attribute this success to the insight that an INN provides a useful in-ductive bias for lens modeling and validate this design choise via ablations on ResNet-based models. To summarize, we claim the following contributions:
• A novel formulation and analysis of an invertible ResNet-based lens distortion model that generalizes across many lens types, is easy to implement and extend;
• A new way to jointly optimize marker and keypoint de-tectors to increase the robustness of pattern-based cali-bration;
• A large-scale camera lens benchmark for evaluating the performance of marker detection and camera calibration;
• Integration of the proposed method into a neural ren-dering pipeline as an example of purely photometric calibration. 2.