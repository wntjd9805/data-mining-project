Abstract
We propose Cut-and-LEaRn (CutLER), a simple ap-proach for training unsupervised object detection and seg-mentation models. We leverage the property of self-supervised models to ‘discover’ objects without supervision and amplify it to train a state-of-the-art localization model without any human labels. CutLER first uses our proposed
MaskCut approach to generate coarse masks for multiple objects in an image, and then learns a detector on these masks using our robust loss function. We further improve performance by self-training the model on its predictions.
Compared to prior work, CutLER is simpler, compatible with different detection architectures, and detects multiple objects. CutLER is also a zero-shot unsupervised detec-tor and improves detection performance AP50 by over 2.7× on 11 benchmarks across domains like video frames, paint-ings, sketches, etc. With finetuning, CutLER serves as a low-shot detector surpassing MoCo-v2 by 7.3% APbox and 6.6%
APmask on COCO when training with 5% labels. 1.

Introduction
Object localization is a critical task in computer vision that enables AI systems to perceive, reason, plan and act in an object-centric manner. Training models for localization require special annotations like object boxes, masks, local-ized points, etc. which are both difficult and resource inten-sive to collect. Without accounting for overhead, annotating
∼164K images in the COCO dataset [32] with masks for just 80 classes took more than 28K human hours of annota-tion time. In this work, we study unsupervised object detec-tion and instance segmentation models that can be trained without any human labels. Our key insight is that simple probing and training mechanisms can amplify the innate lo-calization ability of self-supervised models [7], leading to state-of-the-art unsupervised zero-shot detectors.
Our method Cut-and-LEaRn (CutLER) consists of three simple, architecture- and data-agnostic mechanisms. Con-sistent with prior self-supervised learning methods [7–9, 26], CutLER is trained exclusively on unlabeled ImageNet data without needing additional training data, but contrary to these methods, CutLER can be directly employed to per-form complex segmentation and detection tasks over a wide range of domains. First, we propose MaskCut that can au-tomatically produce multiple initial coarse masks for each image, using the pretrained self-supervised features. Sec-ond, we propose a simple loss dropping strategy to train detectors using the coarse masks while being robust to ob-jects missed by MaskCut. Finally, we observe that despite learning from these coarse masks, the detectors ‘clean’ the
ground truth and produce masks (and boxes) that are bet-ter than the coarse masks used to train them. Therefore, we further show that multiple rounds of self-training on the models’ own predictions allow it to evolve from capturing the similarity of local pixels to capturing the global geome-try of the object, thus producing finer segmentation masks.
Prior work shows that a self-supervised vision trans-former (ViT) [15] can automatically learn patch-wise fea-tures that detect a single salient object in an image [7,38,43, 44,50]. However, unlike CutLER, such salient object detec-tion methods only locate a single, usually the most promi-nent, object and cannot be used for real world images con-taining multiple objects. While some recent methods, e.g.,
FreeSOLO [47] and DETReg [3], also aim at unsupervised multi-object detection (or multi-object discovery), they rely on a particular detection architecture, e.g., SOLO-v2 [48] or DDETR [5, 54]. Additionally, apart from self-supervised features trained on ImageNet [12], the current state-of-the-art methods FreeSOLO and MaskDistill [42] also require
‘in-domain’ unlabeled data for model training.
In contrast, CutLER works with various detection archi-tectures and can be trained solely on ImageNet, without requiring in-domain unlabeled data. Thus, during model training, CutLER does not see any images from any target dataset and yields a zero-shot model capable of detecting and segmenting multiple objects in diverse domains.
Features of CutLER. 1) Simplicity: CutLER is simple to train and agnostic to the choice of detection and backbone architectures. Thus, it can be integrated effortlessly into existing object detection and instance segmentation works. 2) Zero-shot detector: CutLER trained solely on ImageNet shows strong zero-shot performance on 11 different bench-marks where it outperforms prior work trained with addi-tional in-domain data. We double the APbox 50 performance on 10 of these benchmarks, as shown in Fig. 1, and even outperform supervised detectors on the UVO video instance segmentation benchmark. 3) Robustness: CutLER exhibits strong robustness against domain shifts when tested on im-ages from different domains such as video frames, sketches, paintings, clip arts, etc. 4) Pretraining for supervised de-tection: CutLER can also serve as a pretrained model for training fully supervised object detection and instance seg-mentation models and improves performance on COCO, in-cluding on few-shot object detection benchmarks. 2.