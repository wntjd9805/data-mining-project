Abstract
Neural signed distance functions (SDFs) have shown re-markable capability in representing geometry with detail-s. However, without signed distance supervision, it is still a challenge to infer SDFs from point clouds or multi-view images using neural networks. In this paper, we claim that gradient consistency in the ﬁeld, indicated by the parallelis-m of level sets, is the key factor affecting the inference ac-curacy. Hence, we propose a level set alignment loss to evaluate the parallelism of level sets, which can be mini-mized to achieve better gradient consistency. Our novel-ty lies in that we can align all level sets to the zero lev-el set by constraining gradients at queries and their pro-jections on the zero level set in an adaptive way. Our in-sight is to propagate the zero level set to everywhere in the
ﬁeld through consistent gradients to eliminate uncertainty in the ﬁeld that is caused by the discreteness of 3D point clouds or the lack of observations from multi-view images.
Our proposed loss is a general term which can be used up-on different methods to infer SDFs from 3D point clouds and multi-view images. Our numerical and visual compar-isons demonstrate that our loss can signiﬁcantly improve the accuracy of SDFs inferred from point clouds or multi-view images under various benchmarks. Code and data are available at https://github.com/mabaorui/
TowardsBetterGradient. 1.

Introduction
Signed distance functions (SDFs) have shown remark-able abilities in representing high ﬁdelity 3D geometry [6, 14,16,28,32,36,38,41,42,45,51,52,54,55,62,63,67–69,76].
Current methods mainly use neural networks to learn SDFs
∗Equal contribution.
†The corresponding author is Yu-Shen Liu. This work was supported by National Key R&D Program of China (2022YFC3800600), the Nation-al Natural Science Foundation of China (62272263, 62072268), and in part by Tsinghua-Kuaishou Institute of Future Media Data. as a mapping from 3D coordinates to signed distances. Us-ing gradient descent, we can train neural networks by ad-justing parameters to minimize errors to either signed dis-tance ground truth [9, 31, 45, 51, 52] or signed distances in-ferred from 3D point clouds [1,2,11,22,38,60,77] or multi-view images [19, 24, 66–69, 73, 74, 76]. However, factors like the discreteness in point clouds and the lack of obser-vations in multi-view images result in 3D ambiguity, which makes inferring SDFs without ground truth signed distances remain a challenge.
Recent solutions [1,23,32,60,68] impose additional con-straints on gradients with respect to input coordinates. The gradients determine the rate of change of signed distances in a ﬁeld, which is vital for the accuracy of SDFs. Speciﬁcally,
Eikonal term [1,23,32] is widely used to learn SDFs, which constrains the norm of gradients to be one at any location in the ﬁeld. This regularization ensures the networks to pre-dict valid signed distances. NeuralPull [38] constrains the directions of gradients to pull arbitrary queries onto the sur-face. One issue here is that these methods merely constrain gradients at single locations, without considering gradient consistency to their corresponding projections on different level sets. This results in inconsistent gradients in the ﬁeld, indicated by level sets with poor parallelism, which drasti-cally decreases the accuracy of inferred SDFs.
To resolve this issue, we introduce a level set alignment loss to pursue better gradient consistency for SDF inference without ground truth signed distances. Our loss is a general term which can be used to train different networks for learn-ing SDFs from either 3D point clouds or multi-view images.
Our key idea is to constrain gradients at corresponding lo-cations on different level sets of the inferred SDF to be con-sistent. We achieve this by minimizing the cosine distance between the gradient of a query and the gradient of its pro-jection on the zero level set. Minimize our loss is equivalent to aligning all level sets onto a reference, i.e. the zero lev-el set, in a pairwise way. This enables us to propagate the zero level set to everywhere in the ﬁeld, which eliminates uncertainty in the ﬁeld that is caused by the discreteness of
3D point clouds or the lack of observations from multi-view images. Moreover, we introduce an adaptive weight to fo-cus more on the gradient consistency nearer to the zero level set. We evaluate our loss upon the latest methods in surface reconstruction and multi-view 3D reconstruction under the widely used benchmarks. Our improvements over baselines justify not only our effectiveness but also the importance of gradient consistency to the inference of signed distance
ﬁelds. Our contributions are listed below. i) We introduce a level set alignment loss to achieve bet-ter gradient consistency for inferring SDFs without signed distance ground truth. ii) We justify the importance of gradient consistency to the accuracy of SDFs inferred from 3D point cloud-s and multi-view images, and show that aligning level sets together is an effective way of learning more con-sistent gradients for eliminating 3D ambiguity. iii) We show our superiority over the state-of-the-art meth-ods in surface reconstruction from point clouds and multi-view 3D reconstruction under the widely used benchmarks. 2.