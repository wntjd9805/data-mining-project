Abstract
In this work, we present a robust approach for joint part and object segmentation. Specifically, we reformulate ob-ject and part segmentation as an optimization problem and build a hierarchical feature representation including pixel, part, and object-level embeddings to solve it in a bottom-up clustering manner. Pixels are grouped into several clus-ters where the part-level embeddings serve as cluster cen-ters. Afterwards, object masks are obtained by compositing the part proposals. This bottom-up interaction is shown to be effective in integrating information from lower seman-tic levels to higher semantic levels. Based on that, our novel approach Compositor produces part and object seg-mentation masks simultaneously while improving the mask quality. Compositor achieves state-of-the-art performance on PartImageNet and Pascal-Part by outperforming previ-ous methods by around 0.9% and 1.3% on PartImageNet, 0.4% and 1.7% on Pascal-Part in terms of part and object mIoU and demonstrates better robustness against occlusion by around 4.4% and 7.1% on part and object respectively. 1.

Introduction
Detecting objects and parsing them into semantic parts is a fundamental ability of human visual system. When view-ing images, humans not only detect, segment, and classify objects but also segment their semantic parts and identify them. This gives a hierarchical representation that enables a detailed and interpretable understanding of the object which is useful for downstream tasks. For example, humans can estimate the pose of a tiger based on the spatial configura-tion of its parts and hence judge whether it is about to attack or if it is peacefully sleeping. It is conjectured by cognitive psychologists [3, 27] that these hierarchical representations are constructed in a bottom-up manner where humans first perceive parts and then group them together to form objects.
By contrast, the computer vision literature on semantic
*These authors contributed equally to this work. segmentation mostly concentrates on object-level, neglect-ing intermediate part representations, although object and part segmentation have been shown to be mutually benefi-cial to each other [13, 43]. We emphasize that parts help many other tasks such as pose estimation [11, 46], detec-tion [2, 7], and fine-grained recognition [49]. In addition, exploiting local features or part information can increase robustness of object models against occlusion [1, 25, 40].
Recently, He et al. [20] proposed PartImageNet, where both part and object annotations are provided. Meanwhile, their studies showed that naively using part annotation as deep supervision can improve object segmentation. This motivates us to further design a better interaction pipeline between objects and parts for high-quality segmentation.
In this work, we present a strategy for jointly segment-ing parts and objects in a bottom-up process. Specifically, we consider a hierarchical representation of images in terms of pixels, parts, and objects. We learn feature embeddings which enables us to reformulate semantic segmentation as an optimization problem whose goal is to find feature cen-troids that represent parts and objects. As shown in Fig-ure 1, our method uses a bottom-up strategy where pixels are grouped to form part embeddings which, in turn, are grouped to form object embeddings. We implement this in two steps. First, we cluster image pixels to make pro-posals for object parts. Here the feature embeddings are learned so that pixels belonging to the same part have sim-ilar features. Second, we use a similar approach to com-pose these part proposals to segment the whole object which involves selecting some part proposals and rejecting oth-ers. Our complete algorithm, Compositor, for segmenting parts and objects consists of these clustering and composit-ing steps. This novel algorithm not only helps us to build a hierarchical segmentation model but also increases the ro-bustness of the model against occlusion since our parts are clustered based on the similarity of pixel features, which are less affected by occlusion compared to other context-based methods. Moreover, objects are constructed using parts that helps minimize the influence of occlusion.
We verify Compositorâ€™s effectiveness on both PartIma-geNet [20] and Pascal-Part [7], where the former focuses on
Figure 1. Paradigm comparison among traditional FCN-based method, Mask Classification-based method, and our proposed Compositor for object segmentation. We show example with single object instance here for simplicity. single-instance and the latter contains more multi-instances scenarios. We show that Compositor generates high-quality semantic parts from pixels which further benefits object segmentation. Quantitatively, Compositor achieves 61.44% and 71.78% mIoU on part and object segmentation with the ResNet-50 [22], outperforming single-task specialized
MaskFormer [9] by 1.1% and 1.6% respectively. We get consistent improvement on Pascal-Part by surpassing Mask-Former by 0.4% and 1.7% in terms of part and object mIoU.
We further show the robustness of Compositor against occlusion with Occluded-PartImageNet, which is obtained by appending artificial occluders on the original images in PartImageNet following the protocol of OccludedPAS-CAL3D+ [40]. As a result, Compositor outperforms Mask-Former by around 4.4% and 7.1% on part and object mIoU respectively. Ablation studies are conducted to validate the effectiveness of our key designs. Qualitative visualization results on both clean images and occluded images are pre-sented. Error analysis is conducted to better understand the model and guide future work. In summary, we make the following contributions in this work: 1. We propose a bottom-up strategy for segmentation, where we first generate parts from pixels followed by compositing parts into objects. This strategy gives us a joint solution for part and object segmentation. 2. We validate Compositor on PartImageNet and Pascal-Part by extensive experiments showing that interac-tions between parts and objects help each other and result in state-of-the-art performance on both tasks. 3. We create Occluded-PartImageNet by adding occlud-ers enabling us to demonstrate the innate robustness of
Compositor against occlusion. 2.