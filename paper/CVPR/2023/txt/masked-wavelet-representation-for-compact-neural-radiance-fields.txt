Abstract
Neural radiance fields (NeRF) have demonstrated the potential of coordinate-based neural representation (neural fields or implicit neural representation) in neural rendering.
However, using a multi-layer perceptron (MLP) to represent a 3D scene or object requires enormous computational re-sources and time. There have been recent studies on how to reduce these computational inefficiencies by using addi-tional data structures, such as grids or trees. Despite the promising performance, the explicit data structure neces-sitates a substantial amount of memory. In this work, we present a method to reduce the size without compromising the advantages of having additional data structures. In de-tail, we propose using the wavelet transform on grid-based neural fields. Grid-based neural fields are for fast con-vergence, and the wavelet transform, whose efficiency has been demonstrated in high-performance standard codecs, is to improve the parameter efficiency of grids. Further-more, in order to achieve a higher sparsity of grid coeffi-cients while maintaining reconstruction quality, we present a novel trainable masking approach. Experimental re-sults demonstrate that non-spatial grid coefficients, such as wavelet coefficients, are capable of attaining a higher level of sparsity than spatial grid coefficients, resulting in a more compact representation. With our proposed mask and com-pression pipeline, we achieved state-of-the-art performance within a memory budget of 2 MB. Our code is available at https://github.com/daniel03c1/masked wavelet nerf. 1.

Introduction
Recent advances in coordinate-based neural representa-tion (neural fields or implicit neural representation) have demonstrated remarkable performance in many applica-In particular, neural radiance fields (NeRF) have tions.
*Equal contribution
†Corresponding authors
Figure 1. Rate-distortion curves on the NeRF synthetic dataset.
The numbers inside parenthesis denote the axis resolution of grids. sparked interest by synthesizing high-quality images from novel viewpoints. It uses a multi-layer perceptron (MLP) with positional encoding to map coordinates to correspond-ing colors and opacities. Combined with the differentiable volumetric rendering and the neural network’s architectural priors, it has shown great potential to be a new representa-tion paradigm. However, the high computational costs (in both training and inference) have been a significant bottle-neck, often taking several days to converge.
Several follow-up studies have been proposed to ac-celerate training and inference times [5, 9, 11, 14, 16, 31, 32, 40, 44]. To speed up inference, KiloNeRF [32] pro-posed splitting a 3D scene into thousands of partial scenes, each of which is assigned a tiny, distinct neural network.
While achieving impressive speed-up, it requires a mas-sive amount of memory storage. On the other hand, Fast-NeRF [14] suggested caching and factorizing the NeRF network to reduce computational costs. Meanwhile, meta-learning algorithms [12, 26, 29] have also been applied to accelerate the training time, and they have shown faster convergence with the learned initialization [34, 40]. How-ever, it requires well-organized large-scale datasets and a pre-training process. Furthermore, the rendering costs re-main unchanged since they use the same network architec-ture [40], and meta-learning algorithms often suffer from poor out-of-distribution generalization performance.
Alternatively, there has been a surge of recent interest in incorporating classical data structures, such as grids or trees, into the NeRF framework [13, 22, 24, 33, 38, 39, 49].
Incorporating additional data structures has significantly re-duced training and inference time (from days to a few min-utes) without compromising reconstruction quality. How-ever, the overall size dramatically increases due to these dense and volumetric structures. In order to reduce the spa-tial complexity, several methods have been proposed, in-cluding pruning areas [33, 37, 49], encodings [24, 38], and tensor decomposition [3, 4, 17].
This paper aims to further improve the spatial com-plexity while maintaining the rendering quality. Leverag-ing the decades of research on standard compression algo-rithms [35,36,46], we propose compressing grid-based neu-ral fields using frequency-based transformations. In the fre-quency domain, a large portion of the coefficients can be discarded without considerably degrading the reconstruc-tion quality, and most standard compression algorithms have exploited frequency domain representations. Thus, we propose using this property on grid-based neural fields to maximize parameter efficiency. Among other alternatives, we employ the discrete wavelet transform (DWT) due to its compactness and ability to efficiently capture both global and local information.
Once we obtain sparse representations via frequency do-main representations, we can take advantage of the exist-ing compression techniques. Unlike conventional media data (e.g., image and audio), however, no off-the-shelf com-pression tools exist that we can leverage without compli-cated engineering efforts. In addition, since NeRF, or neu-ral rendering networks in general, is a relatively new data format, the characteristics or patterns of their coefficients have not been thoroughly investigated. Thus, we present a compression pipeline for our purposes. To automati-cally filter out unnecessary coefficients, we propose a train-able binary mask. For each 3D scene, we jointly optimize grid parameters and their corresponding masks. This per-scene optimization strategy can be more optimal than the global quantization table used in standard image compres-sion codecs [43].
To compress sparse grid representations, we first merge masks with wavelet coefficients to zero out coefficients and then apply standard compression algorithms to masked co-efficients. We utilize the run-length encoding to encode bi-nary information about which coefficients are non-zero. For further compression, we apply one of the entropy coding al-gorithms, Huffman encoding [19], to these encoded outputs.
Our method incurs negligible computational costs at test time, requiring only one inverse DWT (IDWT) per grid. Af-ter the IDWT, the wavelet grids are transformed into spa-tial grids, eliminating the need for additional IDWT during rendering. As a result, the computing time and costs (in-cluding memory costs) are identical to the original spatial grid-based NeRF.
In summary, our contributions are as follows:
• We propose using wavelet coefficients to improve pa-rameter sparsity and reconstruction quality. Through experiments, we show that the wavelet coefficients can be more compact than the spatial domain coefficients in neural radiance fields.
• We propose a trainable mask that can be applied to any grid-based neural representation. Experimental results demonstrate that our proposed masking method can zero out more than 95% of the total grid parameters while maintaining high reconstruction quality.
• We achieve state-of-the-art performance in novel view synthesis under a memory budget of 2 MB. 2.