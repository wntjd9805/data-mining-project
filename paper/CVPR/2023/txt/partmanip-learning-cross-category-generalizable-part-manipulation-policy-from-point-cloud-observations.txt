Abstract
Learning a generalizable object manipulation policy is vital for an embodied agent to work in complex real-world scenes. Parts, as the shared components in different object categories, have the potential to increase the generaliza-tion ability of the manipulation policy and achieve cross-In this work, we build the category object manipulation. first large-scale, part-based cross-category object manip-ulation benchmark, PartManip, which is composed of 11 object categories, 494 objects, and 1432 tasks in 6 task classes. Compared to previous work, our benchmark is also more diverse and realistic, i.e., having more objects and using sparse-view point cloud as input without oracle information like part segmentation. To tackle the difficul-ties of vision-based policy learning, we first train a state-*Equal contribution.
â€ Corresponding author: hewang@pku.edu.cn. based expert with our proposed part-based canonicaliza-tion and part-aware rewards, and then distill the knowledge to a vision-based student. We also find an expressive back-bone is essential to overcome the large diversity of different objects. For cross-category generalization, we introduce domain adversarial learning for domain-invariant feature extraction. Extensive experiments in simulation show that our learned policy can outperform other methods by a large margin, especially on unseen object categories. We also demonstrate our method can successfully manipulate novel objects in the real world. Our benchmark has been released in https://pku-epic.github.io/PartManip. 1.

Introduction
We as humans are capable of manipulating objects in a wide range of scenarios with ease and adaptability. For building general-purpose intelligent robots that can work in
unconstrained real world environments, it is thus important to equip them with generalizable object manipulation skills.
Towards this goal, recent advances in deep learning and re-inforcement learning have led to the development of some generalist agents such as GATO [32] and SayCan [1], how-ever their manipulation skills are limited to a set of known instances and fail to generalize to novel object instances.
ManiSkill [25] proposes the first benchmark for learning category-level object manipulation, e.g., learn open drawers on tens of drawer sets and test on held-out ones. However, this generalization is limited within different instances from one object category, thus falling short to reach human-level adaptability. The most recent progress is shown in GAPart-Net [53], which defines several classes of generalizable and actionable parts (GAParts), e.g. handles, buttons, doors, that can be found across many different object categories but similar ways. For these GAPart classes, the paper then find a way to consistently define GAPart pose across object categories and devise heuristics to manipulate those parts, e.g., pull handles to open drawers, based on part poses. As a pioneering work, GAPartNet points a promising way to perform cross-category object manipulation but leave the manipulation policy learning unsolved.
In this work, we thus propose the first large-scale, part-based cross-category object manipulation benchmark, Part-Manip, built upon GAPartNet. Our cross-category bench-mark requires agents to learn skills such as opening a door on storage furniture and generalizing to other object cate-gories such as an oven or safe, which presents a great chal-lenge for policy learning to overcome the huge geometry and appearance gaps among object categories.
Furthermore, our benchmark is more realistic and di-verse. We use partial point clouds as input without any ad-ditional oracle information like part segmentation masks in the previous benchmark ManiSkill [17,25], making our set-ting very close to real-world applications. Our benchmark also has much more objects than ManiSkill. We selected around 500 object assets with more than 1400 parts from
GAPartNet [11] and designed six classes of cross-category manipulation tasks in simulation. Thanks to the rich annota-tion provided in GAPartNet, we can define part-based dense rewards to ease policy learning.
Due to the difficulty presented by our realistic and di-verse cross-category setting, we find that directly using state-of-the-art reinforcement learning (RL) algorithms to learn a vision-based policy does not perform well. Ideally, we wish the vision backbone to extract informative geomet-ric and task-aware representations, which can facilitate the actor to take correct actions. However, the policy gradient in this case would be very noisy and thus hinder the vision backbone from learning, given the huge sampling space.
To mitigate this problem, we propose a two-stage training framework: first train a state-based expert that can access oracle part pose information using reinforcement learning; and then distill the expert policy to a vision-based student that only takes realistic inputs.
For state-based expert policy learning, we propose a novel part-based pose canonicalization method that trans-forms all state information into the part coordinate frame, which can significantly reduce the task variations and ease the learning. In addition, we devise several part-aware re-ward functions that can access the pose of the part under interaction, providing a more accurate guidance to achieve the manipulation objective.
In combination, these tech-niques greatly improve the policy training on diverse in-stances from different categories as well as generalization to unseen object instances and categories.
For the vision-based student policy learning, we first in-troduce a 3D Sparse UNet-based backbone [16] to han-dle diverse objects, yielding much more expressivity than
PointNet. To tackle the generalization issue, we thus propose to learn domain-invariant (category-independent) features via introducing an augmentation strategy and a
These domain adversarial two strategies can alleviate the problem of overfitting and greatly boost the performance on unseen object instances and even categories. Finally, we propose a DAgger [33] + behavior clone strategy to carefully distill the expert policy to the student and thus maintain the high-performance of the expert. training strategy [8, 9, 22].
Through extensive experiments in simulation, we vali-date our design choices and demonstrate that our approach outperforms previous methods by a significant margin, es-pecially for unseen object categories. We also show real-world experiments. 2.