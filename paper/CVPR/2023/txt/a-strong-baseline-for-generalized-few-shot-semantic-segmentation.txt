Abstract
This paper introduces a generalized few-shot segmenta-tion framework with a straightforward training process and an easy-to-optimize inference phase. In particular, we pro-pose a simple yet effective model based on the well-known
InfoMax principle, where the Mutual Information (MI) be-tween the learned feature representations and their corre-sponding predictions is maximized. In addition, the terms derived from our MI-based formulation are coupled with a knowledge distillation term to retain the knowledge on base classes. With a simple training process, our inference model can be applied on top of any segmentation network trained on base classes. The proposed inference yields sub-stantial improvements on the popular few-shot segmenta-tion benchmarks, PASCAL-5i and COCO-20i. Particularly, for novel classes, the improvement gains range from 7% to 26% (PASCAL-5i) and from 3% to 12% (COCO-20i) in the 1-shot and 5-shot scenarios, respectively. Furthermore, we propose a more challenging setting, where performance gaps are further exacerbated. Our code is publicly avail-able at https://github.com/sinahmr/DIaM . 1.

Introduction
With the advent of deep learning methods, the automatic interpretation and semantic understanding of image content have drastically improved in recent years. These models are nowadays at the core of a broad span of visual recognition tasks and have enormous potential in strategic domains for our society, such as autonomous driving, healthcare, or se-curity. Particularly, semantic segmentation, whose goal is to assign pixel-level categories, lies as one of the mainstays in visual interpretation. Nevertheless, the remarkable per-formance achieved by deep learning segmentation models is typically limited by the amount of available training data.
Indeed, standard segmentation approaches are often trained on a fixed set of predefined semantic categories, commonly requiring hundreds of examples per class. This limits their scalability to novel classes, as obtaining annotations for new categories is a cumbersome and labor-intensive process.
*Corresponding author: seyed-mohammadsina.hajimiri.1@etsmtl.net
Few-shot semantic segmentation (FSS) has recently emerged as an appealing alternative to overcome this lim-itation [1,30,33]. Under this learning paradigm, models are trained with an abundant labeled dataset on base classes, and only a few instances of novel classes are seen during the adaptation stage. However, [29] identified two important limitations that hamper the application of these methods in real-life scenarios. First, existing literature on FSS assumes that the support samples contain the categories present in the query images, which may incur costly manual selection processes. Second, even though significant achievements have been made, all these methods focus on leveraging sup-ports as much as possible to extract effective target infor-mation, but neglect to preserve the performance on known categories. Furthermore, while in many practical applica-tions the number of novel classes is not limited, most FSS approaches are designed to work on a binary basis, which is suboptimal in the case of multiple novel categories.
Inspired by these limitations, a novel Generalized Few-Shot Semantic Segmentation (GFSS) setting has been re-cently introduced in [29]. In particular, GFSS relaxes the strong assumption that the support and query categories are the same. This means that, under this new learning paradigm, providing support images that contain the same target categories as the query images is not required. Fur-thermore, the evaluation in this setting involves not only novel classes but also base categories, which provides a more realistic scenario.
Although the setting in [29] overcomes the limitations of few-shot semantic segmentation, we argue that a gap still remains between current experimental protocols and real-world applications. Hereafter, we highlight limiting points of the current literature and further discuss them in Sec. 3.2.
Unrealistic prior knowledge. We found that existing works explicitly rely on prior knowledge of the novel classes (supposed to be seen at test-time only) during the training phase. This, for instance, allows to filter out im-ages containing novel objects [14, 29] from the training set.
Recent empirical evidence [28] found out that such assump-tions indeed boost the results in a significant manner.
Modularity. Another limitation is the tight entanglement between the training and testing phases of current ap-proaches, which often limits their ability to handle arbi-trary tasks at test time. Specifically, existing meta-learning-based approaches are designed to handle binary segmen-tation [14], and need to be consequently modified to han-dle multiple classes. While we technically address that by using multiple forward passes (one per class) followed by some heuristic aggregation of segmentation maps, this scales poorly and lacks principle.
Contributions. Motivated by these limitations, we aim to address a more practical setting and develop a fully modular inference procedure. Our inference abstracts away the train-ing stage, making no assumption about the type of training or the format of tasks met at test time. Specifically:
• We present a new GFSS framework, DIaM (Distilled
Information Maximization). Our method is inspired by the well-known InfoMax principle, which maxi-mizes the Mutual Information between the learned fea-ture representations and their corresponding predic-tions. To reduce performance degradation on the base categories, without requiring explicit supervision, we introduce a Kullback-Leibler term that enforces con-sistency between the old and new model’s base class predictions.
• Although disadvantaged by rectifications to improve the practicality of previous experimental protocols, we still demonstrate that DIaM outperforms current SOTA on existing GFSS benchmarks, particularly excelling in the segmentation of novel classes.
• Based on our observations, we go beyond standard benchmarks and present a more challenging scenario, where the number of base and novel classes is the same. In this setting, the gap between our method and the current GFSS SOTA widens, highlighting the poor ability of modern GFSS SOTA to handle numerous novel classes and the need for more modular/scalable methods. 2.