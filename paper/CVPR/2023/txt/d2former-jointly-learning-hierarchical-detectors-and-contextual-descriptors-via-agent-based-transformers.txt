Abstract
Establishing pixel-level matches between image pairs is vital for a variety of computer vision applications. How-ever, achieving robust image matching remains challenging because CNN extracted descriptors usually lack discrim-inative ability in texture-less regions and keypoint detec-tors are only good at identifying keypoints with a specific level of structure. To deal with these issues, a novel im-age matching method is proposed by Jointly Learning Hier-archical Detectors and Contextual Descriptors via Agent-based Transformers (D2Former), including a contextual feature descriptor learning (CFDL) module and a hierar-chical keypoint detector learning (HKDL) module. The proposed D2Former enjoys several merits. First, the pro-posed CFDL module can model long-range contexts effi-ciently and effectively with the aid of designed descriptor agents. Second, the HKDL module can generate keypoint detectors in a hierarchical way, which is helpful for detect-ing keypoints with diverse levels of structures. Extensive experimental results on four challenging benchmarks show that our proposed method significantly outperforms state-of-the-art image matching methods. 1.

Introduction
Finding pixel-level matches accurately between images depicting the same scene is a fundamental task with a wide range of 3D vision applications, such as 3D reconstruc-tion [35, 53, 55], simultaneous localization and mapping (SLAM) [15, 25, 39], pose estimation [13, 29], and visual localization [35,43]. Owing to its broad real-world applica-tions, the image matching task has received increasing at-tention in the past decades [9, 16,31, 33,34]. However, real-izing robust image matching remains difficult due to various challenges such as illumination changes, viewpoint trans-formations, poor textures and scale variations.
To conquer the above challenges, tremendous image matching approaches have been proposed [7,9,12,16,31,34, 42], among which some dense matching methods [7,16,42]
*Equal Contribution
â€ Corresponding Author
Figure 1. Illustration of our motivation. (a) shows the compari-son between our proposed agent-based attention and full attention, where full attention would aggregate features from irrelevant ar-eas. (b) shows the diverse structures contained in the image. are proposed to consider all possible matches adequately and have achieved great success. However, because of the large matching space, these dense matching methods are ex-pensive in computation cost and memory consumption. To achieve high efficiency, we notice that the detector-based matching methods [4, 9, 20, 31] can effectively reduce the matching space by designing keypoint detectors to extract a relatively small keypoint set for matching, thus having high research value. Generally, existing detector-based match-ing methods can be categorized into two main groups in-cluding detect-then-describe approaches [18, 37, 40, 41, 54] and detect-and-describe approaches [12, 20, 31]. Detect-then-describe approaches refer to first detect repeatable key-points [3, 5, 18], and then keypoint features [19, 23, 28] are represented by describing image patches extracted around
In this way, matches can be established these keypoints. by nearest neighbor search according to the Euclidean dis-tance between keypoint features. However, since the key-point detector and descriptor are usually designed sepa-rately in detect-then-describe approaches, keypoint features may not be suitable for detected keypoints, resulting in poor performance under extreme appearance changes. Dif-ferently, detect-and-describe approaches [12, 31] are pro-posed to tightly couple the keypoint detector learning with the descriptor learning. For example, both D2-Net [12] and R2D2 [31] use a single convolutional neural network (CNN) for joint detection and description. These methods
have achieved great performance mainly benefiting from the superiority of joint learning. However, the receptive field of features extracted by CNN is limited, and keypoint de-tectors are usually learned at a single feature scale, which restricts further progress.
Based on the above discussions, we find that both the descriptor and detector learning are crucial for detector-based matching methods. To make image matching more robust to real-world challenges, the following two issues (1) How to should be taken into consideration carefully. learn feature descriptors with long-range dependencies.
Current detector-based matching methods [9, 12, 31] usu-ally use CNN to extract image features. Due to the limited receptive field of CNN, the extracted features would lack discriminative ability in texture-less regions. Although sev-eral works [11, 48] leverage full attention to capture long-range dependencies, as shown in Figure 1 (a), full attention may aggregate irrelevant noise, which is harmful to learn discriminative features. Besides, the computation cost of full attention is rather expensive. Therefore, an effective and efficient attention mechanism needs to be proposed ur-gently to capture long-range contexts of features. (2) How to learn keypoint detectors suitable for various struc-tures. As shown in Figure 1 (b), there are diverse levels of structures in an image, from simple corner points (low-level structures) to complex object parts (high-level structures).
However, existing keypoint detectors are usually good at identifying keypoints with a specific level of structure, such as corners (or edges) [14, 49], and blobs [18, 21]. Thus, it is necessary to learn hierarchical keypoint detectors to detect keypoints with different structures.
Motivated by the above observations, we propose a novel model by Jointly Learning Hierarchical Detectors and Contextual Descriptors via Agent-based Transformers (D2Former) for image matching, which mainly consists of a contextual feature descriptor learning (CFDL) module and a hierarchical keypoint detector learning (HKDL) module.
In the contextual feature descriptor learning module, it is proposed to capture reliable long-range contexts efficiently.
Specifically, original image features are first extracted by a standard CNN. Then, we design a set of descriptor agents to aggregate contextual information by interacting with im-age features via attention mechanisms. Finally, contex-tual features are obtained by fusing the updated descriptor agents into original features. In the hierarchical keypoint detector learning module, it is proposed to detect key-points with different structures, which can achieve robust keypoint detection. Specifically, we design a set of detec-tor agents, which can interact with contextual features via attention mechanisms to obtain low-level keypoint detec-tors. Then, we aggregate these low-level keypoint detectors to form high-level keypoint detectors in a hierarchical way.
Finally, the hierarchical keypoint detectors are obtained by gathering keypoint detectors from different levels.
The main contributions of this work can be summarized as follows. (1) A novel image matching method is proposed by jointly learning hierarchical detectors and contextual de-scriptors via agent-based Transformers, which can extract discriminative feature description and realize robust key-point detection under some extremely challenging scenar-ios. (2) The proposed CFDL module can model long-range dependencies effectively and efficiently with the aid of de-signed descriptor agents. And the HKDL module can gen-erate keypoint detectors in a hierarchically aggregated man-ner, so that keypoints with diverse levels of structures can be detected. (3) Extensive experimental results on four chal-lenging benchmarks show that our proposed method per-forms favorably against state-of-the-art detector-based im-age matching methods. 2.