Abstract
Existing instance segmentation models learn task-speciﬁc information using manual mask annotations from base (training) categories. These mask annotations re-quire tremendous human effort, limiting the scalability to annotate novel (new) categories. To alleviate this prob-lem, Open-Vocabulary (OV) methods leverage large-scale image-caption pairs and vision-language models to learn novel categories. In summary, an OV method learns task-speciﬁc information using strong supervision from base an-notations and novel category information using weak su-pervision from image-captions pairs. This difference be-tween strong and weak supervision leads to overﬁtting on base categories, resulting in poor generalization towards
In this work, we overcome this issue novel categories. by learning both base and novel categories from pseudo-mask annotations generated by the vision-language model in a weakly supervised manner using our proposed Mask-free OVIS pipeline. Our method automatically generates pseudo-mask annotations by leveraging the localization ability of a pre-trained vision-language model for objects present in image-caption pairs. The generated pseudo-mask annotations are then used to supervise an instance segmentation model, freeing the entire pipeline from any labour-expensive instance-level annotations and overﬁtting.
Our extensive experiments show that our method trained with just pseudo-masks signiﬁcantly improves the mAP scores on the MS-COCO dataset and OpenImages dataset compared to the recent state-of-the-art methods trained with manual masks. Codes and models are provided in https://vibashan.github.io/ovis-web/. 1.

Introduction
Instance segmentation is a challenging task as it requires models to detect objects in an image while also precisely
*This work was done when Vibashan VS interned at Salesforce Re-search. Primary contact: vvishnu2@jhu.com
Figure 1. A) Previous Methods: Learn task-speciﬁc information (detection/segmentation) in a fully-supervised manner and novel category information with weak supervision. During training, this difference in strong and weak supervision signals leads to overﬁt-ting and requires expensive base annotations. B) Our method:
Given image-caption pairs, we generate pseudo-annotations for both base and novel categories under weak supervision, solving the problems of labour-expensive annotation and overﬁtting. segment each object at the pixel-level. Although the rise of deep neural networks has signiﬁcantly boosted the state-of-the-art instance segmentation performance [7, 15, 42], these methods are still trained for a pre-deﬁned set of object cat-egories and are data-hungry [33]. Particularly, one needs to manually annotate thousands of instance-level masks for each object category, which takes around 78 seconds per in-stance mask [3]. If we look at this quantitatively on Open
Images [21], a large-scale dataset with 2.1M instance-level mask annotations requires around 5 years of human labour.
Even after extensive annotation, these training datasets are still limited to a small number of categories and segmenting objects from a novel category requires further annotation.
Therefore, it is difﬁcult to scale up existing methods to seg-ment a large number of categories due to intensive labour.
Recently, Open-Vocabulary (OV) methods have gained much attention due to their success in detecting [11, 14,
Figure 2. RPN is supervised using bounding box annotations from COCO base and WSPN is supervised using image-labels from COCO base. A) WSPN produces better quality proposals for novel object categories compared to fully-supervised RPN. B) WSPN consistently produces better recall for all COCO novel categories than RPN. 46, 52] and segmenting [17] novel categories beyond base (training) categories. An OV method learns task-speciﬁc information (detection/segmentation) from base categories that have manual instance-level bounding boxes or masks and learns novel category information from the pre-trained
Vision-Language Model (VLM) [19, 34] (see Fig. 1). All these methods produce promising results on novel cate-gories by leveraging different forms of weak supervision such as caption pretaining [46, 50], knowledge distillation
[14, 52] and pseudo-labelling [17, 28]. However, all above-mentioned OV methods still rely on the manually-annotated base categories to improve their performances on novel cat-egories. Without ﬁne-tuning on base categories, existing
OV methods lack task/domain speciﬁc knowledge and the performances on novel categories will be affected [14, 46].
Although manual instance-level annotations of base cat-egories are critical to open-vocabulary segmentation meth-ods, we ﬁnd empirically that such fully-supervised informa-tion causes OV methods to overﬁt to base categories, lead-ing to a higher failure rate when evaluated on novel cate-gories. Speciﬁcally, OV methods utilize a region proposal network (RPN) [37] supervised with bounding box annota-tions obtained from the base categories to generate a set of bounding box proposals for all objects categories in a given image [46]. The feature representation from these object proposals is later matched with text embedding to learn the visual-semantic space for base and novel categories [46].
Therefore, the quality of proposals generated for novel ob-ject categories plays a key role in determining the perfor-mance in later stages. However, from our experiments, we
ﬁnd that many objects of novel categories wouldn’t be in-cluded in such proposals due to the RPN’s overﬁtting to base categories. Fig. 2 (A) - Top gives some examples where the RPN trained with COCO base categories fails to generate high-quality region proposals for novel categories such as elephant, cat and skateboard. Therefore, a fully-supervised proposal network is a bottleneck in OV pipeline due to its poor generalization towards novel categories.
Given the aforementioned observations of poor general-ization, we raise the question of whether we can improve the generalization by using weak supervision instead of relying on strong supervision from manual base annotations. If so, we can reduce overﬁtting to the base categories and the re-quirement for costly instance-level human annotations can be entirely removed from the pipeline. Our preliminary ex-periments give us some hope. Our experiments show that if we train a weakly-supervised proposal network (WSPN) with image-level annotations instead of box-level annota-tions, the region proposals it generates can better generalize to novel objects. As shown in Fig. 2 A), the novel objects that the RPN proposals miss are covered by WSPN. Fig. 2
B) shows WSPN proposals have consistently better average recall than RPN for all COCO novel categories, indicating that WSPN proposals are more likely to cover the ground-truth bounding boxes of novel objects.
Inspired by these observations, we propose open-vocabulary segmentation without manual mask annotations.
We do not use any human-provided box-level or pixel-level annotations during the training of our method. We ﬁrst train a simple WSPN model with image-level annotations on base categories as a proposal generator to generate pro-posals for all objects given an image. Then, we adopt pre-trained vision-language models to select proposals as pseudo bounding boxes for novel objects. Given a novel object’s text name, we can utilize the name as a text prompt to localize this object in an image with a pre-trained vision-language model. To obtain a more accurate pseudo-mask that covers the entire object, we conduct iterative mask-ing with GradCAM [39] given the vision-language model.
Finally, we train a weakly-supervised segmentation (WSS)
[20] network with previously generated bounding box and
GradCAM activation map to obtain pixel-level annotation.
Our contributions are summarized as follows: (1) We propose a Mask-free OVIS pipleline where we produce manual-effort-free pseudo-mask annotations for base and novel instance segmentation using open-vocabulary and (2) We propose a novel weakly supervised techniques. pseudo-mask generation pipeline leveraging a pre-trained vision-language model to generate instance-level annota-tions. (3) Beneﬁting from pseudo-labels, our method sets up
SOTA’s for both detection and instance segmentation tasks compared to recent methods trained with manual masks on
MS-COCO and OpenImages datasets. 2.