Abstract
Few-shot object detection, the problem of modelling novel object detection categories with few training instances, is an emerging topic in the area of few-shot learning and ob-ject detection. Contemporary techniques can be divided into two groups: fine-tuning based and meta-learning based approaches. While meta-learning approaches aim to learn dedicated meta-models for mapping samples to novel class models, fine-tuning approaches tackle few-shot detection in a simpler manner, by adapting the detection model to novel classes through gradient based optimization. Despite their simplicity, fine-tuning based approaches typically yield competitive detection results. Based on this observation, we focus on the role of loss functions and augmentations as the force driving the fine-tuning process, and propose to tune their dynamics through meta-learning principles. The pro-posed training scheme, therefore, allows learning inductive biases that can boost few-shot detection, while keeping the advantages of fine-tuning based approaches. In addition, the proposed approach yields interpretable loss functions, as opposed to highly parametric and complex few-shot meta-models. The experimental results highlight the merits of the proposed scheme, with significant improvements over the strong fine-tuning based few-shot detection baselines on benchmark Pascal VOC and MS-COCO datasets, in terms of both standard and generalized few-shot performance metrics. 1.

Introduction
Object detection is one of the computer vision problems that has greatly benefited from the advances in supervised deep learning approaches. However, similar to the case in many other problems, state-of-the-art in object detection re-lies on the availability of large-scale fully-annotated datasets, which is particularly problematic due to the difficulty of collecting accurate bounding box annotations [18, 46]. This practical burden has lead to a great interest in the approaches
Figure 1. The overall architecture of the meta-tuning approach. that can potentially reduce the annotation cost, such as weakly-supervised learning [29, 57], learning from point annotations [7], and mixed supervised learning [45]. A more recently emerging paradigm in this direction is few-shot ob-ject detection (FSOD). In the FSOD problem, the goal is to build detection models for the novel classes with few labeled training images by transferring knowledge from the base classes with a large set of training images. In the closely related Generalized-FSOD (G-FSOD) problem, the goal is to build few-shot detection models that perform well on both base and novel classes.
FSOD methods can be categorized into meta-learning and fine-tuning approaches. Although meta-learning based methods are predominantly used in the literature in FSOD research [8,22,31,36,52,75,76,79,81,83], several fine-tuning based works have recently reported competitive results [6, 15, 32, 53, 61, 65, 72, 84]. The main premise of meta-learning approaches is to design and train dedicated meta-models that map given few train samples to novel class detection models, e.g. [73] or learn easy-to-adapt models [30] in a
MAML [16] fashion. In contrast, however, fine-tuning based methods tackle the problem as a typical transfer learning problem and apply the general purpose supervised training techniques, i.e. regularized loss minimization via gradient-based optimization, to adapt a pre-trained model to few-shot classes. It is also worth noting that the recent results on fine-tuning based FSOD are aligned with related observations on few-shot classification [9, 12, 63] and segmentation [4].
While some of the FSOD meta-learning approaches are at-tractive for being able to learn dedicated parametric training
mechanisms, they also come with two important shortcom-ings: (i) the risk of overfitting to the base classes used for training the meta-model due to model complexity, and (ii) the difficulty of interpreting what is actually learned; both of which can be crucially important for real-world, in-the-wild utilization of a meta-learned model. From this point of view, the simplicity and generality of a fine-tuning based FSOD ap-proach can be seen as major advantages. In fact, one can find a large machine learning literature on the components (opti-mization techniques, loss functions, data augmentation, and architectures) of an FT approach, as opposed to the unique and typically unknown nature of a meta-learned inference model, especially when the model aims to replace standard training procedures for modeling the novel few-shot classes.
While MAML [16] like meta-learning for quick adaptation is closer in nature to fine-tuning based approaches, the van-ishing gradient problems and the overall complexity of the meta-learning task practically limits the approach to target only one or few model update steps, whereas an FT approach has no such computational difficulty.
Perhaps the biggest advantage of a fine-tuning based
FSOD approach, however, can also be its biggest disad-vantage: its generality may lack the inductive biases needed for effective learning with few novel class samples while preserving the knowledge of base classes. To this end, such approaches focus on the design of fine-tuning details, e.g. whether to freeze the representation parameters [65], use contrastive fine-tuning losses [61], increase the novel class variances [84], introduce the using additional detection heads and branches [15, 72]. However, optimizing such details specifically for few-shot classes in a hand-crafted manner is clearly difficult, and likely to be sub-optimal.
To address this problem, we focus on applying meta-learning principles to tune the loss functions and augmen-tations to be used in the fine-tuning stage for FSOD, which we call meta-tuning (Figure 1). More specifically, much like the meta-learning of a meta-model, we define an episodic training procedure that aims to progressively discover the optimal loss function and augmentation details for FSOD purposes in a data-driven manner. Using reinforcement learn-ing (RL) techniques, we aim to tune the loss function and augmentation details such that they maximize the expected detection quality of an FSOD model obtained by fine-tuning to a set of novel classes. By defining meta-tuning over well-designed loss terms and an augmentation list, we restrict the search process to effective function families, reducing the computational costs compared to AutoML methods that aim to discover loss terms from scratch for fully-supervised learn-ing [20, 42]. The resulting meta-tuned loss functions and augmentations, therefore, inject the learned FSOD-specific inductive biases into a fine-tuning based approach.
To explore the potential of the meta-tuning scheme for
FSOD, we focus on the details of classification loss func-tions, based on the observations that FSOD prediction mis-takes tend to be in classification rather than localization details [61]. In particular, we first focus on the softmax temperature parameter, for which we define two versions: (i) a simple constant temperature, and (ii) time (fine-tuning iteration index) varying dynamic temperature, parameterized as an exponentiated polynomial. In all cases, the parameters learned via meta-tuning yield an interpretable loss function that has a negligible risk of over-fitting to the base classes, in contrast to a complex meta-model. We also model augmen-tation magnitudes during meta-tuning for improving the data loading pipeline for few-shot learning purposes. Addition-ally, we incorporate a score scaling coefficient for learning to balance base versus novel class scores.
We provide an experimental analysis on the Pascal
VOC [13] and MS-COCO [40] benchmarks for FSOD, using the state-of-the-art fine-tuning based baselines MPSR [72] and DeFRCN [53]. Our experimental results show that the proposed meta-tuning approach provides significant perfor-mance gains in both FSOD and Generalized FSOD settings, suggesting that meta-tuning loss functions and data augmen-tation can be a promising direction in FSOD research. 2.