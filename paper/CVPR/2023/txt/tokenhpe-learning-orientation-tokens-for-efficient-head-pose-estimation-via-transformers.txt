Abstract
Head pose estimation (HPE) has been widely used in the fields of human machine interaction, self-driving, and attention estimation. However, existing methods cannot deal with extreme head pose randomness and serious oc-clusions. To address these challenges, we identify three cues from head images, namely, neighborhood similari-ties, significant facial changes, and critical minority rela-tionships. To leverage the observed findings, we propose a novel critical minority relationship-aware method based on the Transformer architecture in which the facial part relationships can be learned. Specifically, we design sev-eral orientation tokens to explicitly encode the basic ori-entation regions. Meanwhile, a novel token guide multi-loss function is designed to guide the orientation tokens as they learn the desired regional similarities and relation-ships. We evaluate the proposed method on three chal-lenging benchmark HPE datasets. Experiments show that our method achieves better performance compared with state-of-the-art methods. Our code is publicly available at https://github.com/zc2023/TokenHPE. 1.

Introduction
Head pose estimation (HPE) is a popular research area in computer vision and has been widely applied to driver assis-tance [29], human–computer interaction [36], virtual reality
[22], and attention detection [5]. In recent years, HPE has been actively studied and the accuracy has been consider-ably improved in terms of utilizing extra facial landmark in-formation [2,20], extra RGB-depth information [13,26–28], extra temporal information [16], stage-wise regression strat-egy [42], multi-task learning [1, 38], and alternative param-eterization of orientation [3, 15, 18, 19, 24]. Currently, many methods focus on the representation of the head pose ori-*: Corresponding author (Hai Liu, Youfu Li)
Figure 1. Left part: Missing facial parts and our finding on critical minority relationships. Although some of the facial parts are miss-ing or occluded (marked with a red rectangle), the pose orientation still can be inferred from the existing critical minority facial parts (marked with a green circle). Right part: different head orientation images in a panoramic overview. The rectangular boxes highlight several significant facial changes, such as i) appearance of the eye on one side, ii) appearance of the nostril, and iii) overlapping of the nose and mouth. The circled areas show some regions in which the facial part features are similar. entation and have achieved impressive performance, but the intrinsic facial part relationships are usually neglected. A possible reason is that these relationships are difficult to learn by existing CNN architectures. However, in some challenging scenarios, as shown in the left part of Fig. 1, many remarkable facial parts are missing. Consequently, the remaining facial parts and their geometric relationships must be leveraged to achieve robust and high-accuracy pre-diction. Therefore, how to leverage the facial part relation-ships for high-accuracy HPE is an attractive research topic.
To begin with, we firstly identify three implicit facial part relationships in head poses. First, a local similarity in spe-cific spatial orientation exists. Inside the circled region in
Fig. 1, the facial appearances are similar. Second, sev-eral significant facial part changes are observed in specific orientations. For example, in Fig. 1, the two circled fa-cial regions can be distinguished by a significant facial part change, which is the appearance of the right eye. Third, critical minority relationships of facial parts exist, and they can determine the orientation of a head pose despite pos-sible occlusions. As Fig. 1 shows, if a person’s mouth is occluded, the head pose can be determined by the geomet-ric spatial relationships of the eyes, nose, and the outline of the face. In these scenarios, the remaining minor facial parts and their relationships are crucial for high-accuracy HPE.
Given the aforementioned facial part relationships, the question is how to design a model that can utilize this heuristic knowledge. The traditional CNN architecture can-not easily learn these relationships. In contrast, the Trans-former architecture can effectively address this drawback of
CNN. Recently, Vision Transformer (ViT) [11] emerged as a new choice for various computer vision tasks. The Trans-former architecture is known for its extraordinary ability to learn long-distance, high-level relationships between image patches. Therefore, using Transformer to learn the rela-tionships among critical minority facial parts is reasonable.
Moreover, the basic orientation regions can be well repre-sented by learnable tokens in Transformer.
Inspired by the three findings and Transformer’s prop-erties, we propose TokenHPE, a method that can discover and leverage facial part relationships and regional similari-ties via the Transformer architecture. The proposed method can discover facial part geometric relationships via self-attention among visual tokens, and the orientation tokens can encode the characteristics of the basic orientation re-gions. The latent relationships between visual and orienta-tion tokens can be learned from large HPE datasets. Then, the learned information is encoded into the orientation to-kens, which can be visualized by vector similarities.
In addition, a special token guide multi-loss function is con-structed to help the orientation token learn the general in-formation. Our main contributions can be summarized as follows: (1) Three findings are derived on head images, including facial part relationships and neighborhood orientation simi-larities. Furthermore, to leverage our findings and cope with challenging scenarios, a novel token-learning model based on Transformer for HPE is presented for the first time. (2) We find that the head pose panoramic overview can be partitioned into several basic regions according to the orientation characteristics. The same number of learnable orientation tokens are utilized to encode this general infor-mation. Moreover, a novel token guide multi-loss function is designed to train the model. (3) We conduct experiments on three widely used HPE datasets. TokenHPE achieves state-of-the-art performance with a novel token-learning concept compared with its ex-isting CNN-based counterparts. Abundant visualizations are also provided to illustrate the effectiveness of the pro-posed orientation tokens. 2.