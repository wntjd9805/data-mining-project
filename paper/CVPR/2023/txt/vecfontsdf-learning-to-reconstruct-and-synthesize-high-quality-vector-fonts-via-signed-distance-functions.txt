Abstract
Font design is of vital importance in the digital con-tent design and modern printing industry. Developing al-gorithms capable of automatically synthesizing vector fonts can significantly facilitate the font design process. How-ever, existing methods mainly concentrate on raster image generation, and only a few approaches can directly syn-thesize vector fonts. This paper proposes an end-to-end trainable method, VecFontSDF, to reconstruct and synthe-size high-quality vector fonts using signed distance func-tions (SDFs). Specifically, based on the proposed SDF-based implicit shape representation, VecFontSDF learns to model each glyph as shape primitives enclosed by sev-eral parabolic curves, which can be precisely converted to quadratic B´ezier curves that are widely used in vec-tor font products. In this manner, most image generation methods can be easily extended to synthesize vector fonts.
Qualitative and quantitative experiments conducted on a publicly-available dataset demonstrate that our method ob-tains high-quality results on several tasks, including vector font reconstruction, interpolation, and few-shot vector font synthesis, markedly outperforming the state of the art. 1.

Introduction
Traditional vector font designing process relies heavily on the expertise and effort from professional designers, set-ting a high barrier for common users. With the rapid de-velopment of deep generative models in the last few years, a large amount of effective and powerful methods [1, 7, 32] have been proposed to synthesize visually-pleasing glyph images. In the meantime, how to automatically reconstruct and generate high-quality vector fonts is still considered as a challenging task in the communities of Computer Vi-sion and Computer Graphics. Recently, several methods
*Denotes equal contribution.
†Corresponding author. E-mail: lianzhouhui@pku.edu.cn
This work was supported by National Language Committee of China (Grant No.: ZDI135-130), Center For Chinese Font Design and Research, and Key Laboratory of Science, Technology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology).
Figure 1. Examples of results obtained by our method in the tasks of vector font reconstruction (a) and vector font interpolation (b). based on sequential generative models [3,11,20,30,33] have been reported that treat a vector glyph as a draw-commands sequence and use Recurrent Neural Networks (RNNs) or
Transformer [31] to encode and decode the sequence. How-ever, this explicit representation of vector graphics is ex-tremely difficult for the learning and comprehension of deep neural networks, mainly due to the long-range dependence and the ambiguity in how to draw the outlines of glyphs.
More recently, DeepVecFont [33] was proposed to use dual-modality learning to alleviate the problem, showing state-of-the-art performance on this task. Its key idea is to use a
CNN encoder and an RNN encoder to extract features from both image and sequence modalities. Despite using richer information of dual-modality data, it still needs repetitively random samplings of synthesis results to find the optimal one and then uses Diffvg [18] to refine the vector glyphs un-der the guidance of generated images in the inference stage.
Another possible solution to model the vector graphic is to use implicit functions which have been widely used
For instance, to represent 3D shapes in recent years.
DeepSDF [25] adopts a neural network to predict the values of signed distance functions for surfaces, but it fails to con-vert those SDF values to the explicit representation. BSP-Net [4] uses hyperplanes to split the space in 2D shapes and 3D meshes, but it generates unsmooth and disordered re-sults when handling glyphs consisting of numerous curves.
Inspired by the above-mentioned existing methods, we propose an end-to-end trainable model, VecFontSDF, to reconstruct and synthesize high-quality vector fonts using signed distance functions (SDFs). The main idea is to treat a glyph as several primitives enclosed by parabolic curves which can be translated to quadratic B´ezier curves that are widely used in common vector formats like SVG and TTF.
Specifically, we use the feature extracted from the input glyph image by convolutional neural networks and decode it to the parameters of parabolic curves. Then, we calculate the value of signed distance function for the nearest curve of every sampling point and leverage these true SDF values as well as the target glyph image to train the model.
The work most related to ours is [19], which also aims to provide an implicit shape representation for glyphs, but possesses a serious limitation mentioned below. For conve-nience, we name the representation proposed in [19] IGSR, standing for “Implicit Glyph Shape Representation”. The quadratic curves used in IGSR are not strictly parabolic curves, which cannot be translated to quadratic B´ezier curves. As a consequence, their model is capable of synthe-sizing high-resolution glyph images but not vector glyphs.
Furthermore, it only uses raster images for supervision which inevitably leads to inaccurate reconstruction results.
On the contrary, our proposed VecFontSDF learns to recon-struct and synthesize high-quality vector fonts that consist of quadratic B´ezier curves by training on the corresponding vector data in an end-to-end manner. Major contributions of our paper are threefold:
• We design a new implicit shape representation to pre-cisely reconstruct high-quality vector glyphs, which can be directly converted into commonly-used vector font formats (e.g., SVG and TTF).
• We use the true SDF values as a strong supervision instead of only raster images to produce much more precise reconstruction and synthesis results compared to previous SDF-based methods.
• The proposed VecFontSDF can be flexibly integrated with other generative methods such as latent space in-terpolation and style transfer. Extensive experiments have been conducted on these tasks to verify the supe-riority of our method over other existing approaches, indicating its effectiveness and broad applications. 2.