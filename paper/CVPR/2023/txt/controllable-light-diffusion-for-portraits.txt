Abstract 1.

Introduction
We introduce light diffusion, a novel method to im-prove lighting in portraits, softening harsh shadows and specular highlights while preserving overall scene illumi-nation.
Inspired by professional photographers’ diffusers and scrims, our method softens lighting given only a single portrait photo. Previous portrait relighting approaches fo-cus on changing the entire lighting environment, removing shadows (ignoring strong specular highlights), or removing shading entirely. In contrast, we propose a learning based method that allows us to control the amount of light diffu-sion and apply it on in-the-wild portraits. Additionally, we design a method to synthetically generate plausible external shadows with sub-surface scattering effects while conform-ing to the shape of the subject’s face. Finally, we show how our approach can increase the robustness of higher level vi-sion applications, such as albedo estimation, geometry es-timation and semantic segmentation.
High quality lighting of a subject is essential for cap-turing beautiful portraits. Professional photographers go to great lengths and cost to control lighting. Outside the stu-dio, natural lighting can be particularly harsh due to direct sunlight, resulting in strong shadows and pronounced spec-ular effects across a subject’s face. While the effect can be dramatic, it is usually not the desired look. Professional photographers often address this problem with a scrim or diffuser (Figure 2), mounted on a rig along the line of sight from the sun to soften the shadows and specular highlights, leading to much more pleasing portraits [9]. Casual photog-raphers, however, generally lack the equipment, expertise, or even the desire to spend time in the moment to perfect the lighting in this way. We take inspiration from professional photography and propose to diffuse the lighting on a sub-ject in an image, i.e., directly estimating the appearance of the person as though the lighting had been softer, enabling anyone to improve the lighting in their photos after the shot
Figure 2. Using a bulky scrim (left), a photographer can reduce strong shadows and specularities. Our proposed approach operates directly on the original image to produce a similar softening effect. is taken.
Deep learning approaches have led to great advances in relighting portraits [12, 21, 23, 26, 27, 29, 33, 35, 37, 38]. Our goal is different: we want to improve the existing lighting rather than replace it entirely. This goal has two advan-tages: the resulting portrait has improved lighting that is visually consistent with the existing background, and the task is ultimately simpler, leading to a more robust solution than completely relighting the subject under arbitrary illu-mination. Indeed, one could estimate the lighting [14, 15], diffuse (blur) it, and then relight the subject [12, 23, 33], but lighting estimation and the full relighting task themselves are open research questions. We instead go directly from input image to diffused-lighting image without any illumi-nation estimation.
Past works [11, 37] speciﬁcally focused on removing shadows from a subject via CNNs. However, these meth-ods do not address the unﬂattering specularities that remain which our work tackles.
In the extreme, lighting can be diffused until it is com-pletely uniform. The problem of “delighting,” recovering the underlying texture (albedo) as though a subject has been uniformly lit by white light1, has also been studied (most re-cently in [30]). The resulting portrait is not suitable as an end result – too ﬂat, not visually consistent with the back-ground – but the albedo map can be used as a step in portrait relighting systems [23]. Delighting, however, has proved to be a challenging task to do well, as the space of materials, particularly clothing, can be too large to handle effectively.
In this paper, we propose light diffusion, a learning-based approach to controllably adjust the levels of diffuse light-ing on a portrait subject. The proposed method is able to soften specularities, self shadows, and external shadows while maintaining the color tones of the subject, leading to a result that naturally blends into the original scene (see
Fig. 1). Our variable diffusion formulation allows us to go from subtle shading adjustment all the way to removing the shading on the subject entirely to obtain an albedo robust to shadows and clothing variation.
Our overall contributions are the following: 1Technically, uniform lighting will leave ambient occlusion in the re-covered albedo, often desirable for downstream rendering tasks.
• A novel, learning-based formulation for the light dif-fusion problem, which enables controlling the strength of shadows and specular highlights in portraits.
• A synthetic external shadow generation approach that conforms to the shape of the subject and matches the diffuseness of the illumination.
• A robust albedo predictor, able to deal with color am-biguities in clothing with widely varying materials and colors.
• Extensive experiments and comparisons with state-of-art approaches, as well as results on downstream appli-cations showing how light diffusion can improve the performance of a variety of computer visions tasks. 2.