Abstract
Human pose is typically represented by a coordinate vec-tor of body joints or their heatmap embeddings. While easy for data processing, unrealistic pose estimates are admit-ted due to the lack of dependency modeling between the body joints. In this paper, we present a structured repre-sentation, named Pose as Compositional Tokens (PCT), to explore the joint dependency. It represents a pose by M dis-crete tokens with each characterizing a sub-structure with several interdependent joints (see Figure 1). The composi-tional design enables it to achieve a small reconstruction error at a low cost. Then we cast pose estimation as a clas-sification task. In particular, we learn a classifier to pre-dict the categories of the M tokens from an image. A pre-learned decoder network is used to recover the pose from the tokens without further post-processing. We show that it achieves better or comparable pose estimation results as the existing methods in general scenarios, yet continues to work well when occlusion occurs, which is ubiquitous in practice. The code and models are publicly available at https://github.com/Gengzigang/PCT. 1.

Introduction
Human pose estimation is a fundamental task in com-puter vision which aims to estimate the positions of body joints from images. The recent progress has focused on net-work structures [74, 87, 96], training methods [31, 68, 93], and fusion strategies [14,15,61,67,84,102], which have no-tably advanced the accuracy on public datasets. However, it remains an open problem in challenging scenarios, e.g., in the presence of occlusion, which hinders its application in practice.
Current 2/3D pose estimators usually represent a pose by a coordinate vector [23, 34, 79, 110] or its heatmap em-beddings [40, 55, 60, 74, 75, 80, 87, 90]. In both represen-tations, the joints are treated independently, ignoring the fact that the body joints can serve as mutual context to each
*Equal Advising
Figure 1. Our approach represents a pose by M discrete tokens which are indices to the codebook entries (top). Each token is learned to represent a sub-structure. In each row, we show that if we change the state of one token to different values, it consistently changes the same sub-structure highlighted by orange. The black poses are before changing (bottom). other. As a result, they may get unrealistic estimates when occlusion occurs as shown in Figure 2 (top). However, it is interesting to note that humans can easily predict intact poses from only the visible joints and the visual features.
This is probably because people are able to use context to aid recognition as evidenced by some psychology experi-ments [5, 58]. Some works attempt to introduce a tree or graph structure [2, 21, 65, 85] to model joint dependency.
However, the hand-designed rules usually make unrealistic assumptions on the relationships, making them incapable to represent complex patterns.
In this work, we hope to learn the dependency between the joints earlier in the representation stage without any as-sumptions. Our initial idea is to learn a set of prototype poses that are realistic, and represent every pose by the near-est prototype. While it can guarantee that all poses are real-istic, it requires a large number of prototypes to reduce the quantization error to a reasonable level which is computa-Figure 2. Heatmap-based method (top) v.s. our PCT method (bottom) in occluded scenes. PCT predicts reasonable poses even under severe occlusion. The images are from COCO val2017. tionally infeasible. Instead, we propose a discrete represen-tation, named pose as compositional tokens (PCT). Figure 3 shows the two stages of the representation. In Stage I, we learn a compositional encoder to transform a pose into
M token features, with each encoding a sub-structure of the pose. See Figure 1 for some examples. Then the tokens are quantized by a shared codebook. So, a pose is simply represented by M discrete indices. The space represented by the codebook is sufficiently large to represent all poses accurately. We jointly learn the encoder, the codebook, and the decoder by minimizing a reconstruction error.
In Stage II, we cast human pose estimation as a classifi-cation task. Given an image, we predict the categories of the
M tokens, from which the pose is recovered by the decoder network. The PCT representation has several advantages.
First, the dependency between the joints is modeled by the tokens, which helps to reduce the chance of getting unre-alistic pose estimates. In particular, we see evidence that it has the potential to obtain reasonable estimates even when a large portion of the body is occluded. See Figure 2 (bottom) for some examples. Second, it does not require any expen-sive post-processing modules such as UDP [29] which is required by the heatmap representation to reduce the quan-tization errors. Third, it provides a unified representation for 2D and 3D poses. In addition, the discrete representa-tion potentially facilitates its interactions with other discrete modalities such as text and speech. But this is not the focus of this work.
We extensively evaluate our approach in 2D human pose estimation on five benchmark datasets. It gets better or com-parable accuracy as the state-of-the-art methods on all of them. But more importantly, it achieves significantly better results when evaluated only on the occluded joints, validat-ing the advantages of its dependency modeling capability.
We also present the results in 3D pose estimation on the
H36M dataset on which it achieves comparable accuracy as the state-of-the-art methods using a simple architecture.
The results demonstrate that it has wide applicability. 2.