Abstract
Modern image classifiers perform well on populated classes, while degrading considerably on tail classes with only a few instances. Humans, by contrast, effortlessly han-dle the long-tailed recognition challenge, since they can learn the tail representation based on different levels of se-mantic abstraction, making the learned tail features more discriminative. This phenomenon motivated us to propose
SuperDisco, an algorithm that discovers super-class repre-sentations for long-tailed recognition using a graph model.
We learn to construct the super-class graph to guide the representation learning to deal with long-tailed distribu-tions. Through message passing on the super-class graph, image representations are rectified and refined by attending to the most relevant entities based on the semantic simi-larity among their super-classes. Moreover, we propose to meta-learn the super-class graph under the supervision of a prototype graph constructed from a small amount of imbal-anced data. By doing so, we obtain a more robust super-class graph that further improves the long-tailed recognition per-formance. The consistent state-of-the-art experiments on the long-tailed CIFAR-100, ImageNet, Places and iNaturalist demonstrate the benefit of the discovered super-class graph for dealing with long-tailed distributions. 1.

Introduction
This paper strives for long-tailed visual recognition. A computer vision challenge that has received renewed at-tention in the context of representation learning, as real-world deployment demands moving from balanced to im-balanced scenarios. Three active strands of work involve class re-balancing [15, 22, 32, 43, 65], information augmenta-tion [34, 51, 54] and module improvement [29, 31, 76]. Each of these strands is intuitive and has proven empirically suc-cessful. However, all these approaches seek to improve the classification performance of the original feature space. In this paper, we instead explore a graph learning algorithm to discover the imbalanced super-class space hidden in the original feature representation.
*Currently with United Imaging Healthcare, Co., Ltd., China. (a) 100 original classes (b) 20 ground truth super-classes (c) 16 discovered super-classes (d) 32 discovered super-classes
Figure 1. SuperDisco learns to project the original class space (a) into a relatively balanced super-class space. Different color curves indicate the different imbalance factors on the long-tailed
CIFAR-100 dataset. Like the 20 super-class ground truth (b) our discovered super-classes for 16 super-classes (c) or 32 super-classes (d) provide a much better balance than the original classes.
The fundamental problem in long-tailed recognition [18, 32, 44, 77] is that the head features and the tail features are indistinguishable. Since the head data dominate the feature distribution, they cause the tail features to fall within the head feature space. Nonetheless, humans effortlessly handle long-tailed recognition [2, 16] by leveraging semantic ab-stractions existing in language to gain better representations of tail objects. This intuition hints that we may discover the semantic hierarchy from the original feature space and use it for better representations of tail objects. Moreover, intermediate concepts have been shown advantageous for classification [5, 36] by allowing the transfer of shared fea-tures across classes. Nevertheless, it remains unexplored to exploit intermediate super-classes in long-tailed visual recognition that rectify and refine the original features.
In the real world, each category has a corresponding super-class, e.g., bus, taxi, and train all belong to the vehicle super-class. This observation raises the question: are super-classes of categories also distributed along a long-tail? We find em-pirical evidence that within the super-class space of popular datasets, the long-tailed distribution almost disappears, and each super-class has essentially the same number of samples.
In Figure 1, we show the number of training samples for each of the original classes and their corresponding super-classes in the long-tailed CIFAR-100 dataset. We observe the data imbalance of super-classes is considerably lower than those of the original classes. This reflects the fact that the original imbalanced data hardly affects the degree of imbalance of the super-classes, which means the distribution of the super-classes and original data is relatively independent. These balanced super-class features could be used to guide the orig-inal tail data away from the dominant role of the head data, thus making the tail data more discriminative. Therefore, if the super-classes on different levels of semantic abstraction over the original classes can be accurately discovered, it will help the model generalize over the tail classes. As not all datasets provide labels for super-classes, we propose to learn to discover the super-classes in this paper.
Inspired by the above observation, we make in this paper two algorithmic contributions. First, we propose in Section 3 an algorithm that learns to discover the super-class graph for long-tailed visual recognition, which we call SuperDisco.
We construct a learnable graph that discovers the super-class in a hierarchy of semantic abstraction to guide feature rep-resentation learning. By message passing on the super-class graph, the original features are rectified and refined, which attend to the most relevant entities according to the similarity between the original image features and super-classes. Thus, the model is endowed with the ability to free the original tail features from the dominance of the head features using the discovered and relatively balanced super-class represen-tations. Even when faced with the severe class imbalance challenges, e.g., iNaturalist, our SuperDisco can still refine the original features by finding a more balanced super-class space using a more complex hierarchy. As a second contri-bution, we propose in Section 4 a meta-learning variant of our SuperDisco algorithm to discover the super-class graph, enabling the model to achieve even more balanced image representations. To do so, we use a small amount of balanced data to construct a prototype-based relational graph, which captures the underlying relationship behind samples and al-leviates the potential effects of abnormal samples. Last, in
Section 5 we report experiments on four long-tailed bench-marks: CIFAR-100-LT, ImageNet-LT, Places-LT, and iNatu-ralist, and verify that our discovered super-class graph per-forms better for tail data in each dataset. Before detailing our contributions, we first embed our proposal in related work. 2.