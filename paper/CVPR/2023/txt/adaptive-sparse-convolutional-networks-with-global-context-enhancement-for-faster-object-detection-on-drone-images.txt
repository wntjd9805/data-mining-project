Abstract
Object detection on drone images with low-latency is an important but challenging task on the resource-constrained unmanned aerial vehicle (UAV) platform. This paper inves-tigates optimizing the detection head based on the sparse convolution, which proves effective in balancing the accu-racy and efficiency. Nevertheless, it suffers from inadequate integration of contextual information of tiny objects as well as clumsy control of the mask ratio in the presence of fore-ground with varying scales. To address the issues above, we propose a novel global context-enhanced adaptive sparse convolutional network (CEASC). It first develops a context-enhanced group normalization (CE-GN) layer, by replacing the statistics based on sparsely sampled features with the global contextual ones, and then designs an adaptive multi-layer masking strategy to generate optimal mask ratios at distinct scales for compact foreground coverage, promoting both the accuracy and efficiency. Extensive experimental re-sults on two major benchmarks, i.e. VisDrone and UAVDT, demonstrate that CEASC remarkably reduces the GFLOPs and accelerates the inference procedure when plugging into the typical state-of-the-art detection frameworks (e.g. Reti-naNet and GFL V1) with competitive performance. Code is available at https://github.com/Cuogeihong/CEASC. 1.

Introduction
Recent progress of deep neural networks (e.g. CNNs and
Transformers) has significantly boosted the performance of object detection on public benchmarks such as COCO [23].
By contrast, building detectors for unmanned aerial vehicle (UAV) platforms currently remains a challenging task. On the one hand, existing studies are keen on designing com-plicated models to reach high accuracies of tiny objects on
† indicates equal contribution.
∗ refers to the corresponding author. (a) (b)
Figure 1. (a) Comparison of foreground proportions on the COCO and drone imagery databases; and (b) visualization of foregrounds (highlighted in yellow) on samples from VisDrone and UAVDT. high-resolution drone imagery, which are computationally consuming. On the other hand, the hardware equipped with
UAVs is often resource-constrained, raising an urgent de-mand in lightweight deployed models for fast inference and low latency.
To deal with the dilemma of balancing the accuracy and efficiency, a number of efforts are made, mainly on general object detection, which basically concentrate on reducing
the complexity of the backbone networks [2, 13, 47]. De-spite some potential, these methods leave much room for improvement since they fail to take into account the heavy detection heads which are widely used by the state-of-the-art detectors [14, 21, 22, 46]. For instance, RetinaNet [22] taking ResNet18 [11] as backbone with 512 input channels adopts a detection head that occupies 82.3% of the overall
GFLOPs. Recently, several methods have been presented to solve this problem, including network pruning [24, 45] and structure redesigning [1, 7], and prove effective in ac-celerating inference. However, the former is criticized by the sharp performance drop when computations are greatly decreased, evidenced by the attempt on detection for UAVs
[45], and the latter is primarily optimized for low-resolution input (e.g. 640 × 640), making it not straightforward to adapt to high-resolution aerial images.
Sparse convolutions [6, 41] show another promising al-ternative, which limit computations by only operating con-volutions on sparsely sampled regions or channels via learn-able masks. While theoretically attractive, their results are highly dependent on the selection of meaningful areas, be-cause the focal region of the learned mask in sparse con-volutions is prone to locate within foreground. Regard-ing drone images, the vast majority of objects are of small scales (as shown in Fig. 1 (a)) and the scale of foreground areas varies along with flying altitudes and observing view-points (as shown in Fig. 1 (b)), and this issue becomes even more prominent. An inadequate mask ratio enlarges the fo-cal part and more unnecessary computations are consumed on background, which tends to simultaneously deteriorate efficiency and accuracy. On the contrary, an exaggerated one shrinks the focal part and incurs the difficulty in fully covering foreground and crucial context, thus leading to performance degradation. DynamicHead [31] and Query-Det [42] indeed apply sparse convolutions to the detection head; unfortunately, their primary goal is to offset the in-creased computational cost when additional feature maps are jointly used for performance gain on general object de-tection. They both follow the traditional way in original sparse convolutions that set fixed mask ratios or focus on foreground only and are thus far from reaching the trade-off between accuracy and efficiency required by UAV detec-tors. Therefore, it is still an open question to leverage sparse convolutions to facilitate lightweight detection for UAVs.
In this paper, we propose a novel plug-and-play detec-tion head optimization approach to efficient object detection on drone images, namely global context-enhanced adaptive sparse convolution (CEASC). Concretely, we first develop a context-enhanced sparse convolution (CESC) to capture global information and enhance focal features, which con-sists of a residual structure with a context-enhanced group normalization (CE-GN) layer. Since CE-GN specifically preserves a set of holistic features and applies their statis-tics for normalization, it compensates the loss of context caused by sparse convolutions and stabilizes the distribu-tion of foreground areas, thus bypassing the sharp drop on accuracy. We then propose an adaptive multi-layer mask-ing (AMM) scheme, and it separately estimates an optimal mask ratio by minimizing an elaborately designed loss at distinct levels of feature pyramid networks (FPN), balanc-ing the detection accuracy and efficiency. It is worth noting that CESC and AMM can be easily extended to various de-tectors, indicating that CEASC is generally applicable to existing state-of-the-art object detectors for acceleration on drone imagery.
The contribution of our work lies in three-fold: 1) We propose a novel detection head optimization ap-proach based on sparse convolutions, i.e. CEASC, to effi-cient object detection for UAVs. 2) We introduce a context-enhanced sparse convolution layer and an adaptive multi-layer masking scheme to opti-mize the mask ratio, delivering an optimal balance between the detection accuracy and efficiency. 3) We extensively evaluate the proposed approach on two major public benchmarks of drone imagery by integrating
CEASC to various state-of-the-art detectors (e.g. RetinaNet and GFL V1), significantly reducing their computational costs while maintaining competitive accuracies. 2.