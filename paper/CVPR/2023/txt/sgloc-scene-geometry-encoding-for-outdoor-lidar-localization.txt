Abstract
LiDAR-based absolute pose regression estimates the global pose through a deep network in an end-to-end manner, achieving impressive results in learning-based localization.
However, the accuracy of existing methods still has room to improve due to the difficulty of effectively encoding the scene geometry and the unsatisfactory quality of the data.
In this work, we propose a novel LiDAR localization frame-work, SGLoc, which decouples the pose estimation to point cloud correspondence regression and pose estimation via this correspondence. This decoupling effectively encodes the scene geometry because the decoupled correspondence regression step greatly preserves the scene geometry, lead-ing to significant performance improvement. Apart from this decoupling, we also design a tri-scale spatial feature aggre-gation module and inter-geometric consistency constraint loss to effectively capture scene geometry. Moreover, we empirically find that the ground truth might be noisy due to GPS/INS measuring errors, greatly reducing the pose estimation performance. Thus, we propose a pose quality evaluation and enhancement method to measure and cor-rect the ground truth pose. Extensive experiments on the
Oxford Radar RobotCar and NCLT datasets demonstrate the effectiveness of SGLoc, which outperforms state-of-the-art regression-based localization methods by 68.5% and 67.6% on position accuracy, respectively. 1.

Introduction
Estimating the position and orientation of LiDAR from point clouds is a fundamental component of many applica-tions in computer vision, e.g., autonomous driving, virtual reality, and augmented reality.
Contemporary state-of-the-art LiDAR-based localization methods explicitly use maps, which match the query point
*Equal contribution.
†Corresponding author.
Figure 1.
LiDAR Localization results of our method and
PosePN++ [51] (state-of-the-art method) in urban (left) and school (right) scenes from Oxford Radar RobotCar [2] and NCLT [34] datasets. The star indicates the starting position. cloud with a pre-built 3D map [18, 23, 27, 49]. However, these methods usually require expensive 3D map storage and communication. One alternative is the regression-based approach, absolute pose regression (APR), which di-rectly estimates the poses in the inference stage without maps [8, 24, 25, 40, 45]. APR methods typically use a CNN to encode the scene feature and a multi-layer perceptron to regress the pose. Compared to map-based methods, APR does not need to store the pre-built maps, accordingly reduc-ing communications.
For (1), APR networks learn highly abstract global scene representations, which allow the network to classify the scene effectively [25]. However, the global features usually cannot encode detailed scene geometry, which is the key to achieving an accurate pose estimation [10, 11, 38, 39].
Prior efforts have tried to minimize the relative pose or photometric errors to add geometry constraints by pose graph optimization (PGO) [4, 21] or novel view synthesis (NVS) [10,11]. However, this introduces additional computa-tions, limiting its wide applications. For (2), we empirically find current large-scale outdoor datasets suffer from various errors in the data due to GPS/INS measuring errors. It affects the APR learning process and makes it difficult to evaluate the localization results accurately. To our knowledge, the impact of data quality on localization has not been carefully investigated in the existing literature.
This paper proposes a novel framework, SGLoc, which can (1) effectively capture the scene geometry; In addition, we propose a data pre-processing method, Pose Quality Eval-uation and Enhancement (PQEE), which can (2) improve (1) Existing APR methods conduct end-to-data quality. end regression from the point cloud in LiDAR coordinate to pose. Unlike them, SGLoc decouples this process to (a) regression from the point cloud in LiDAR coordinate to world coordinate and (b) pose estimation via the point cloud correspondence in LiDAR and world coordinate us-ing RANSAC [17]. Importantly, step (a) can effectively preserve the scene geometry, which is key for pose estima-tion [10, 11, 38, 39]. To achieve high accuracy in step (a), we design a Tri-scale Spatial Feature Aggregation (TSFA) mod-ule and an Inter-Geometric Consistency Constraint (IGCC) loss to effectively capture scene geometry. (2) We empir-ically find that pose errors in the data greatly degrade the pose estimation performance. For example, the ground truth pose obtained by GPS/INS suffers from measuring errors.
To address this problem, we proposed a PQEE method which can measure the errors in the pose and correct them after-ward. We conduct extensive experiments on Oxford Radar
RobotCar [2] and NCLT [34] datasets, and results show that our method has great advantages over the state-of-the-art, as demonstrated in Fig. 1.
Our contributions can be summarized as follows:
• SGLoc is the first work to decouple LiDAR localization into point cloud correspondences regression and pose estimation via predicted correspondences, which can ef-fectively capture scene geometry, leading to significant performance improvement.
• We propose a novel Tri-Scale Spatial Feature Aggre-gation (TSFA) module and an Inter-Geometric Consis-tency Constraint (IGCC) loss to further improve the encoding of scene geometry.
• We propose a generalized pose quality evaluation and enhancement (PQEE) method to measure and correct the pose errors in the localization data, improving 34.2%/16.8% on position and orientation for existing
LiDAR localization methods.
• Extensive experiments demonstrate the effectiveness of SGLoc, which outperforms state-of-the-art LiDAR localization methods by 68.1% on position accuracy. In addition, to our knowledge, we are the first to reduce the error to the level of the sub-meter on some trajectories. 2.