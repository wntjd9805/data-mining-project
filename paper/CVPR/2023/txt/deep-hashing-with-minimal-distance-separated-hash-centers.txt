Abstract
Deep hashing is an appealing approach for large-scale image retrieval. Most existing supervised deep hashing methods learn hash functions using pairwise or triple image similarities in randomly sampled mini-batches. They suffer from low training efficiency, insufficient coverage of data distribution, and pair imbalance problems. Recently, cen-tral similarity quantization (CSQ) attacks the above prob-lems by using “hash centers” as a global similarity metric, which encourages the hash codes of similar images to ap-proach their common hash center and distance themselves from other hash centers. Although achieving SOTA retrieval performance, CSQ falls short of a worst-case guarantee on the minimal distance between its constructed hash centers, i.e. the hash centers can be arbitrarily close. This pa-per presents an optimization method that finds hash cen-ters with a constraint on the minimal distance between any pair of hash centers, which is non-trivial due to the non-convex nature of the problem. More importantly, we adopt the Gilbert-Varshamov bound from coding theory, which helps us to obtain a large minimal distance while ensuring the empirical feasibility of our optimization approach. With these clearly-separated hash centers, each is assigned to one image class, we propose several effective loss functions to train deep hashing networks. Extensive experiments on three datasets for image retrieval demonstrate that the pro-posed method achieves superior retrieval performance over the state-of-the-art deep hashing methods. 1.

Introduction
Hashing methods are widely-used in large-scale image retrieval due to their excellent efficiency in both storage and retrieval. Recently, much effort has been devoted to deep-learning-based hashing (deep hashing) methods for image retrieval. They use deep neural networks to learn hash functions that encode similar/dissimilar images to nearby/faraway binary codes, respectively. Most of the ex-*Corresponding Author isting deep hashing methods train models on pairwise/triple similarities among training samples in randomly sampled mini-batches (e.g., [1, 10, 18, 22, 24]). Very recently, Yuan et al. [26] pointed out that these methods lead to restricted performance due to three problems: low-efficiency to obtain global similarity of the dataset, incomplete coverage of data distribution that harms the discriminability of the generated hash codes, and ineffectiveness on imbalanced amount of similar/dissimilar data pairs. They then proposed central similarities that finds mutually separated hash centers for each class of similar images, and uses these centers to en-sure small distances between the hash codes of similar im-ages and large distances between those of dissimilar ones.
For deep hashing methods that use hash centers, it is cru-cial to construct well-separated hash centers, i.e. the Ham-ming distance between two hash centers should be signifi-cantly larger than the Hamming distance between the hash codes of two similar images, which makes it challenging to generalize to various length of hash code and different number of image classes. For instance, CSQ [26] adopts
Hadamard matrix and Bernoulli sampling to produce hash centers with nice properties that any two centers’ Hamming distance is on average half of the hash code length. How-ever, pairs of hash centers constructed in this way can be arbitrarily small in the worst case, i.e. zero in Hamming distance (see Table 4). These degenerated hash centers are expected to harm the retrieval performance.
To address this issue, we propose a novel deep hashing method that uses an optimization procedure to produce hash centers, with an additional constraint on a given minimal distance d between any pair of hash centers. The value of d is derived using the Gilbert-Varshamov bound [20] adopted from coding theory, which help us to find a large d while ensuring the feasibility of our optimization procedure.
As shown in Fig.1, the proposed method employs a two-stage pipeline. In Stage 1, we tackle the optimization prob-lem stated above to produce clearly-separated hash centers.
To solve this optimization problem, we propose an alternat-ing optimization procedure that relies on the ℓp-box binary optimization technique [23].
In Stage 2, we train a deep hashing network by using the constructed hash centers as a
Figure 1. The proposed method comprises of a two-stage pipeline. Stage 1 (left) employs a optimization procedure to produce hash centers constrained by a minimal Hamming distance d between any pair of hash centers, each is assigned to one image class. d is given by the
Gilbert-Varshamov bound that guarantees the optimization’s feasibility. Stage 2 (right) employs a deep hashing network with three loss functions. The first one brings the hash code of an image close to its corresponding hash center while keeping it distant from the other centers. The second one draws similar data points within the same class even closer. The last one is to minimize quantization errors. global similarity metric. Specifically, loss functions are de-fined to make that (1) an input image’s hash code is close to its class’s hash center but is distanced from other centers, (2) the hash codes of images in the same class should be close to each other, and (3) quantization errors are minimized.
The proposed method is assessed on three datasets for image retrieval. The results indicate that the obtained hash centers are always separated by the minimal distance we derived, and the proposed method outperforms the state-of-the-art deep hashing methods. 2.