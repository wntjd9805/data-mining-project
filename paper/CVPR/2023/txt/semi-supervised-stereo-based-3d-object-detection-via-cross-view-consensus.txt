Abstract
Stereo-based 3D object detection, which aims at detect-ing 3D objects with stereo cameras, shows great potential in low-cost deployment compared to LiDAR-based methods and excellent performance compared to monocular-based algorithms. However, the impressive performance of stereo-based 3D object detection is at the huge cost of high-quality manual annotations, which are hardly attainable for any given scene. Semi-supervised learning, in which limited an-notated data and numerous unannotated data are required to achieve a satisfactory model, is a promising method to address the problem of data deficiency. In this work, we pro-pose to achieve semi-supervised learning for stereo-based 3D object detection through pseudo annotation generation from a temporal-aggregated teacher model, which tempo-rally accumulates knowledge from a student model. To fa-cilitate a more stable and accurate depth estimation, we introduce Temporal-Aggregation-Guided (TAG) disparity consistency, a cross-view disparity consistency constraint between the teacher model and the student model for robust and improved depth estimation. To mitigate noise in pseudo annotation generation, we propose a cross-view agreement strategy, in which pseudo annotations should attain high degree of agreements between 3D and 2D views, as well as between binocular views. We perform extensive exper-iments on the KITTI 3D dataset to demonstrate our pro-posed method’s capability in leveraging a huge amount of unannotated stereo images to attain significantly improved detection results. 1.

Introduction 3D object detection, as one of the most significant per-ception tasks in the computer vision community, has wit-nessed great progress in recent years, especially after the advent of neural-network-based deep learning. Most state-of-the-art works which focus on 3D object detection mainly
*Corresponding author.
Illustration of the proposed Temporal-Aggregation-Figure 1.
Guided (TAG) disparity consistency constraint, in which the teacher model, temporally collecting knowledge from the student model, leads the disparity estimation of the student model across the views. rely on LiDAR data [17,32,33,43,51] to extract accurate 3D information, such as 3D structure and depth of the points.
However, LiDAR data are costly to harvest and annotate, and have limited sensing ranges in some cases.
Instead, vision-based methods, which detect 3D objects based on images only, have drawn more attention in recent years.
While it is convenient to collect image data, there are signif-icant challenges in applying image-based methods to depth sensing, which is an ill-posed problem when localizing ob-jects with only images. This problem is further exacerbated in monocular-based 3D object detection [24, 25, 48]. Stereo images, in which image pairs took at different viewpoints are available, can be used to reconstruct depth information through pixel-to-pixel correspondence or stereo geometry, making them more useful for detecting 3D objects without the introduction of expensive LiDAR data.
With more attention focusing on stereo-based 3D object detection, the performance of these methods gets continu-ously improved, and the gap between LiDAR-based meth-ods and stereo-based methods becomes progressively nar-rower. However, the improving performance is built on large-scale manual annotation, which is costly in terms of both time and human resources. When the amount of an-notation is limited, the performance of stereo-based meth-ods deteriorates rapidly. Semi-supervised learning, which
makes use of a limited set of annotated data and plenty of unannotated data, is a promising method for solving the data deficiency problem. In this work, we propose an effective and efficient semi-supervised stereo-based 3D object detec-tion method to alleviate this limited annotation problem.
With limited annotated stereo images, depth estima-tion, a key stage for accurately localizing 3D objects, be-comes increasingly unstable, which in turn leads to poor object localization. However, the inherent constraint be-tween the left and right image in each stereo pair can be adopted to promote the model’s performance in depth es-timation.
Inspired by the left-right disparity consistency constraint proposed by Godard et al. [11], we propose a Temporal-Aggregation-Guided (TAG) disparity consis-tency constraint, as shown in Fig. 1. In this method, dis-parity estimation of the base model, as the student model, should pursue that of the teacher model, with continuous knowledge accumulation from the base model, across the views. With the proposed TAG method, the base model can enhance its capability in depth estimation when provided with extra data without annotations. In addition, to gener-ate more accurate pseudo annotations for the unannotated data, we propose a cross-view agreement strategy, which comprises a 3D-2D agreement constraint, in which pseudo annotations with high localization consistency in both 2D view and 3D view are kept, and a left-right agreement con-straint, in which pseudo annotations with high similarities in both the left and right view at the feature space are re-tained for pseudo-supervision. With the proposed cross-view agreement strategy, the remaining pseudo annotations can effectively encompass the objects and provide high-quality supervision on the unannotated data, further improv-ing the detection performance of the base model.
We evaluate the proposed method on the KITTI 3D dataset [10]. With our proposed method, the base model achieves relative performance gains of up to 18 percentage points under the evaluation metric of AP3D and 20 percent-age points under the evaluation metric of APBEV with the
IoU threshold of 0.7 in the car category when only 5% of training data are annotated, thus verifying the effectiveness of our proposed method in making full use of data without annotations.
We summarize our main contributions as follows: 1) We propose a semi-supervised method for stereo-based 3D object detection, in which plentiful and easy-to-access unannotated images are fully utilized to en-hance the base model. 2) We propose a Temporal-Aggregation-Guided (TAG) disparity consistency constraint to direct the dispar-ity estimation of the base model through the teacher model, with cumulative knowledge from the base model, across the views. 3) We introduce a cross-view agreement strategy to re-fine the generated pseudo annotations through enforc-ing agreements between the 3D view and 2D view, and between the left view and right view. 4) Our proposed semi-supervised method leads to signifi-cant performance gains without requiring extensive an-notations on the KITTI 3D dataset. 2.