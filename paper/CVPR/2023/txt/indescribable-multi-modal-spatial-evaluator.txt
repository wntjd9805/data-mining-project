Abstract
Multi-modal image registration spatially aligns two im-ages with different distributions. One of its major challenges is that images acquired from different imaging machines have different imaging distributions, making it difficult to focus only on the spatial aspect of the images and ignore differences in distributions. In this study, we developed a self-supervised approach, Indescribable Multi-model Spatial
Evaluator (IMSE), to address multi-modal image registration.
IMSE creates an accurate multi-modal spatial evaluator to measure spatial differences between two images, and then op-timizes registration by minimizing the error predicted of the evaluator. To optimize IMSE performance, we also proposed a new style enhancement method called Shuffle Remap which randomizes the image distribution into multiple segments, and then randomly disorders and remaps these segments, so that the distribution of the original image is changed. Shuffle
Remap can help IMSE to predict the difference in spatial location from unseen target distributions. Our results show that IMSE outperformed the existing methods for registration using T1-T2 and CT-MRI datasets. IMSE also can be easily integrated into the traditional registration process, and can provide a convenient way to evaluate and visualize registra-tion results. IMSE also has the potential to be used as a new paradigm for image-to-image translation. Our code is avail-able at https://github.com/Kid-Liet/IMSE.
*Corresponding author.
Figure 1. The GAN based methods can only ensure that the distri-bution of the X domain is mapped that of the Y domain. Ideally, we want to achieve instance registration in which moving and target images are one-to-one corresponded. 1.

Introduction
The purpose of multi-modal image registration is to align two images with different distributions (Moving (M ) and
Target (T ) images) by warping the space through the defor-mation field ϕ. A major challenge in multi-modal image registration is that images from different modalities may dif-fer in multiple aspects given the fact that images are acquired using different imaging machines, or different acquisition parameters. Due to dramatically different reconstruction and acquisition methods, there is no simple one-to-one map-ping between different imaging modalities. From the per-spective of measuring similarity, mainstream unsupervised multi-modal registration methods can be divided into two categories: similarity operator based registration and image-to-image translation based registration.
Similarity operator based registration uses multi-modal similarity operators as loss functions for registration, for ex-ample, normalized cross-correlation (NCC) [15, 22, 31, 32], mutual information (MI) [5, 23, 27, 35], and modality-independent neighborhood descriptor (MIND) [3, 8, 13, 39].
Similarity operators are based on a prior mathematical knowl-edge. These are carefully designed and improved over time.
They can be applied to both traditional registration process (Eq. 1) and neural network registration (Eq. 2):
ˆϕ = arg min
ϕ
Lsim (M (ϕ) , T ) .
Or
ˆθ = arg min
θ (cid:2)E(M,T ) [Lsim (M, T, gθ (M, T ))](cid:3) . (1) (2)
Similarity operators have several limitations. 1) It is un-likely to design similarity operators that can maintain high accuracy for all data from various imaging modalities. 2)
It is not possible to estimate the upper limit these operators can achieve and hence it is difficult to find the improvement directions.
Image-to-image translation [1, 16, 17, 21, 29, 38, 42] based multi-modal registration first translations multi-modal images into single-modal images (Eq 3) using a generative adversarial network (GAN [10]), and then use Mean Abso-lute Error (MAE) or Mean Squared Error (MSE) to evaluate the error at each pixel in space (Eq 4). min
G max
D
LAdv (G, D) = ET [log (D (T ))] +
EM [log (1 − D (G (M )))] . (3)
And
θ
ˆθ = arg min (cid:2)E(M,T ) [∥G (M ) , T, gθ (G (M ) , T ) ∥1](cid:3) . (4)
Image-to-image translation based registration cleverly avoids the complex multi-modal problem and reduces the difficulty of registration to a certain extent. However, it has obvious drawbacks. 1) The methods based on GAN require training a generator using existing multi-modal data. The trained model will not work if it encounters unseen data, which greatly limits its applicable scenarios. 2) More importantly, registration is an instance problem. However, the method based on GAN is to remap the data distribution between different modal. As shown in Figure 1, the distribution has bias and variance. We cannot guarantee that the translated image corresponds exactly to the instance target image at the pixel level. For example, Figure 2 shows that there is still residual distribution difference between the target image and translated image. Therefore, even if they are well aligned in space, there is still a large error in the same organ.
To address these challenges, we propose a novel idea based on self-supervision, namely, Indescribable Multi-modal Spatial Evaluator, or IMSE for short. The IMSE
Figure 2. The distributions of the Moving images translated by Cy-cleGAN still have large residual differences from the Target images.
IMSE gives smaller error assessment values in the overlapping regions (converging to blue). approach creates an accurate multi-modal spatial evaluator to metric spatial differences between two images, and then optimizes registration by minimizing the error predicted by the evaluator. In Figure 2, we provide a visual demonstration of IMSE in terms of spatial location for T1-T2 and MRI-CT, respectively. Even though distribution differences between the Moving and Target images are still significant, IMSE is low in overlapping regions of the same organs. The main contributions of this study can be summarized as follows:
• We introduce the concepts of relative single-modal and absolute single-modal as an extension of the current definition of single-modality.
• Based on relative single-modal and absolute single-modal, we propose a self-supervised IMSE method to evaluate spatial differences in multi-modal image registration. The main advantage of IMSE is that it focuses only on differences in spatial location while ignoring differences in multi-modal distribution caused by different image acquisition mechanisms. Our results show that IMSE outperformed the existing metrics for registration using T1-T2 and CT-MRI datasets.
• We propose a new style enhancement method named
Shuffle Remap. Shuffle Remap can help IMSE to ac-curate predict the difference in spatial location from an unseen target distribution. As a enhancement method,
Shuffle Remap can be impactful in the field of domain generalization.
• We develop some additional functions for IMSE. 1)
As a measure, IMSE can be integrated into both the registration based on neural network and the traditional registration. 2) IMSE can also be used to establish a new image-to-image translation paradigm. 3) IMSE can provide provide a convenient way to evaluate and visualize registration results.
2.