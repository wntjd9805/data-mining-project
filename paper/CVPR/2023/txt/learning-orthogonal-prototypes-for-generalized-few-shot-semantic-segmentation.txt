Abstract
Generalized few-shot semantic segmentation (GFSS) distinguishes pixels of base and novel classes from the back-ground simultaneously, conditioning on sufficient data of base classes and a few examples from novel class. A typical
GFSS approach has two training phases: base class learn-ing and novel class updating. Nevertheless, such a stand-alone updating process often compromises the well-learnt features and results in performance drop on base classes.
In this paper, we propose a new idea of leveraging Projec-tion onto Orthogonal Prototypes (POP), which updates fea-tures to identify novel classes without compromising base classes. POP builds a set of orthogonal prototypes, each of which represents a semantic class, and makes the prediction for each class separately based on the features projected onto its prototype. Technically, POP first learns prototypes on base data, and then extends the prototype set to novel classes. The orthogonal constraint of POP encourages the orthogonality between the learnt prototypes and thus miti-gates the influence on base class features when generalizing to novel prototypes. Moreover, we capitalize on the residual of feature projection as the background representation to dynamically fit semantic shifting (i.e., background no longer includes the pixels of novel classes in updating phase). Ex-tensive experiments on two benchmarks demonstrate that our POP achieves superior performances on novel classes without sacrificing much accuracy on base classes. No-tably, POP outperforms the state-of-the-art fine-tuning by 3.93% overall mIoU on PASCAL-5i in 5-shot scenario. 1.

Introduction
Semantic segmentation is to assign semantic labels to every pixel of an image. With the recent development of
CNNs [10, 13] and vision transformers [6, 18, 23, 24, 35, 41, 42], the state-of-the-art networks have successfully pushed the limits of semantic segmentation [1, 3, 25, 49] with re-markable performance improvements. Such achievements
*Corresponding author.
Figure 1. Comparisons between fine-tuning [26] and Projection onto Orthogonal Prototypes (POP). In novel class updating phase, fine-tuning (a) updates the network to predict base and novel classes, and inevitably compromises the well-learnt representa-tions for base classes. Instead, POP (b) only updates prototypes for novel classes and executes predictions for each class separately on the features projected onto different orthogonal prototypes. heavily rely on the requirements of large quantities of pixel-level annotations and it is also difficult to directly apply the models to the classes unseen in the training set. A straight-forward way to alleviate this issue is to leverage Few-shot
Semantic Segmentation (FSS) [30, 36, 44], which utilizes the limited support annotations from unseen/novel classes to adapt the models. Nevertheless, FSS performs on the as-sumption that the support images and the query image con-tain the same novel classes, and solely emphasizes the seg-mentation of one novel class in the query image at a time. A more practical scenario namely Generalized Few-shot Se-mantic Segmentation (GFSS) [33] is recently presented to simultaneously identify the pixels of base and novel classes in a query image.
A typical GFSS solution has proceeded along two train-ing phases: base class learning and novel class updating. In the first phase, models are trained on abundant base classes’ annotations to classify the pixels of base categories, and then updated with the limited labeled novel examples in the second phase to additionally recognize pixels of novel
classes. For instance, Myers Dean et al. [26] sample some base data plus novel examples as the supervision to fine-tune the network, as depicted in Figure 1(a). Despite having good performances on novel classes, there still exists a clear performance degradation on base classes. We speculate that this may be the results of compromising the well-learnt fea-tures of base classes in fine-tuning. As such, a valid ques-tion then emerges as is it possible for GFSS to nicely gener-alize the model to novel classes without sacrificing much
In an effort to segmentation capability on base classes. answer this question, we seek to represent an image via a group of uncorrelated feature components each of which characterizes a specific class. By doing so, it is readily ap-plicable to learn and integrate new components for novel classes without affecting the ones learnt for base classes.
To materialize our idea, we propose a new Projection onto Orthogonal Prototypes (POP) framework for GFSS.
POP learns a series of orthogonal prototypes and each pro-totype corresponds to one specific semantic class. As shown in Figure 1(b), POP employs an encoder to extract feature maps of a given query image and then projects them onto prototypes. The projection on each prototype is regarded as the discriminative representation with respect to the cor-responding class and exploited to predict the probability map of pixels belonging to the class. More specifically,
POP deliberately devises the learning of prototypes from three standpoints. The first one is to freeze the base pro-totypes when learning novel ones from support images in the updating phase. In this way, feature projections on base prototypes maintain their discriminability of base classes.
Second, POP encourages the prototypes of base and novel classes to be orthogonal through a prototype orthogonality loss. Such a constraint decorrelates features projected onto different prototypes and mitigates the inter-class confusion caused by extending to novel classes. Finally, in view that background no longer contains the pixels of novel classes in updating phase, known as “semantic shifting”, POP mea-sures the residual of feature projection as the background representation instead of learning a prototype for “back-ground”. This way further improves the differentiation be-tween novel classes and background.
The main contribution of this work is the proposal of a
Projection on Orthogonal Prototypes (POP) framework for generalized few-shot semantic segmentation. The solution also leads to the elegant views of how to adapt the trained model to novel classes without sacrificing well-learnt fea-tures, and how to represent background pixels dynamically in the context of semantic shifting, which are problems not yet fully explored in the literature. We demonstrate that
POP outperforms the state-of-the-art fine-tuning [26] on two benchmarks (PASCAL-5i and COCO-20i) with evident improvements on both base and novel classes. 2.