Abstract
Continual learning for segmentation has recently seen increasing interest. However, all previous works focus on narrow semantic segmentation and disregard panoptic seg-mentation, an important task with real-world impacts. In this paper, we present the first continual learning model capable of operating on both semantic and panoptic seg-mentation. Inspired by recent transformer approaches that consider segmentation as a mask-classification problem, we design CoMFormer. Our method carefully exploits the prop-erties of transformer architectures to learn new classes over time. Specifically, we propose a novel adaptive distilla-tion loss along with a mask-based pseudo-labeling tech-nique to effectively prevent forgetting. To evaluate our ap-proach, we introduce a novel continual panoptic segmenta-tion benchmark on the challenging ADE20K dataset. Our
CoMFormer outperforms all the existing baselines by for-getting less old classes but also learning more effectively new classes. In addition, we also report an extensive eval-uation in the large-scale continual semantic segmentation scenario showing that CoMFormer also significantly out-performs state-of-the-art methods. 1 1.

Introduction
Image segmentation is a fundamental computer vision problem that enables machines to assign an image’s pix-els to discrete segments. Multiple segmentation tasks have been defined depending on the segments definitions. Se-mantic segmentation clusters pixels by classes, merging in a single segment pixels belonging to instances of the same class. Panoptic segmentation assigns to every pixel a se-mantic class while separating different instances into dif-ferent segments. This latter kind of segmentation has real-world impacts in autonomous robots and vehicles [7, 41].
Despite tremendous progress in image segmentation, the current approaches are trained on a static dataset with a pre-*Work done during the visiting period at Sorbonne Universit´e.
†Work done at Sorbonne Universit´e, currently affiliated to DeepMind. 1https://github.com/fcdl94/CoMFormer
Figure 1. Illustration of our model, CoMFormer, operating in continual segmentation. Relying on the mask classification paradigm, it is able to cope with both continual semantic and panoptic segmentation without any modification by predicting masks for both old (e.g. car in red) and new (e.g. person in green) classes. The figure reports two classes and no “stuff” (e.g. road, building) only for illustration purposes. defined set of classes. Whenever an update of the model is required to fit new classes, the common solution is to train a model from scratch on the union of the old and new class data. A computationally more efficient solution would be to fine-tune the existing model solely on the new class data.
Unfortunately, this approach would cause a catastrophic forgetting [21] of the old classes on which the model per-formance would be extremely degraded.
The problem of updating the knowledge of the model over time is typically referred as continual learning. It has been traditionally studied in the context of image classifi-cation [17, 19, 29, 33, 43, 45] and is gaining attention on the segmentation task [3, 4, 15, 39, 59] due to the more realis-tic applications and the additional challenges it introduces, such as the background shift [4]. However, current state-of-the-art methods mainly focus on semantic segmentation and are not designed to work in other segmentation tasks, strongly limiting their application in the real world.
In this paper, we design the first method operating in both continual semantic and panoptic segmentation, as il-lustrated in Fig. 1. Our method, CoMFormer (Continual
MaskFormer), takes inspiration from recent transformer architectures [11, 12], approaching segmentation as a mask classification problem. Instead of predicting a class proba-bility for each pixel, as in previous semantic segmentation works [9, 37], it predicts a set of binary masks, each as-sociated with a single class prediction, effectively address-ing both segmentation tasks without any modification in the training architecture and procedure. Differently from previ-ous works [11, 12], however, CoMFormer forces the output binary masks to be mutually exclusive to one another: a pixel can only be predicted by a single binary mask to pre-vent having several masks classifying the same pixel with different classes. This behavior is crucial in continual learn-ing to reduce the interference among old and new classes.
Furthermore, CoMFormer introduces a novel adaptive distillation loss to alleviate forgetting. It enforces consis-tency of the model’s classification predictions across learn-ing steps only when it is useful to remember old classes, ensuring a better tradeoff between rigidity (not forgetting old classes) and plasticity (learning efficiently new classes).
Finally, since at each training iteration the dataset reports annotations only for the current classes, we design a mask-based pseudo-labeling technique to generate annotations for the old classes, effectively alleviating forgetting. To reduce the noise, we consider the prediction confidence and we avoid interference with ground-truth annotations.
We validate CoMFormer on both continual segmenta-tion tasks. For panoptic segmentation, we define a new benchmark relying on the challenging ADE20K where we demonstrate that CoMFormer largely outperforms all pre-vious baselines. On semantic segmentation, we show that
CoMFormer outperforms the existing state-of-the-art meth-ods on every setting of the large-scale ADE20K benchmark.
To sum up, the contributions of this paper are as follows:
• We introduce continual panoptic segmentation which has real-world impacts in addition to being signifi-cantly more challenging than previous benchmarks.
• We propose CoMFormer to tackle both continual panoptic and semantic segmentation. To avoid forget-ting, we design a novel adaptive distillation and an ef-ficient mask-based pseudo-labeling strategy.
• Through extensive quantitative and qualitative bench-marks, we showcase the state-of-the-art performance of our model on both continual segmentation tasks. 2.