Abstract
Class-agnostic object counting aims to count object in-stances of an arbitrary class at test time. Current methods for this challenging problem require human-annotated ex-emplars as inputs, which are often unavailable for novel categories, especially for autonomous systems. Thus, we propose zero-shot object counting (ZSC), a new setting where only the class name is available during test time.
Such a counting system does not require human annotators in the loop and can operate automatically. Starting from a class name, we propose a method that can accurately iden-tify the optimal patches which can then be used as counting exemplars. Specifically, we first construct a class prototype to select the patches that are likely to contain the objects of interest, namely class-relevant patches. Furthermore, we introduce a model that can quantitatively measure how suit-able an arbitrary patch is as a counting exemplar. By ap-plying this model to all the candidate patches, we can se-lect the most suitable patches as exemplars for counting.
Experimental results on a recent class-agnostic counting dataset, FSC-147, validate the effectiveness of our method.
Code is available at https://github.com/cvlab-stonybrook/zero-shot-counting. 1.

Introduction
Object counting aims to infer the number of objects in an image. Most of the existing methods focus on counting objects from specialized categories such as human crowds
[37], cars [29], animals [4], and cells [46]. These meth-ods count only a single category at a time. Recently, class-agnostic counting [28, 34, 38] has been proposed to count objects of arbitrary categories. Several human-annotated bounding boxes of objects are required to specify the ob-jects of interest (see Figure 1a). However, having humans in the loop is not practical for many real-world applications, such as fully automated wildlife monitoring systems or vi-*Work done prior to joining Amazon (a) Few-shot Counting (b) Zero-Shot Counting
Figure 1. Our proposed task of zero-shot object counting (ZSC).
Traditional few-shot counting methods require a few exemplars of the object category (a). We propose zero-shot counting where the counter only needs the class name to count the number of object instances. (b). Few-shot counting methods require human annota-tors at test time while zero-shot counters can be fully automatic. sual anomaly detection systems.
A more practical setting, exemplar-free class-agnostic counting, has been proposed recently by Ranjan et al. [33].
They introduce RepRPN, which first identifies the objects that occur most frequently in the image, and then uses them as exemplars for object counting. Even though RepRPN does not require any annotated boxes at test time, the method simply counts objects from the class with the high-est number of instances. Thus, it can not be used for count-ing a specific class of interest. The method is only suitable for counting images with a single dominant object class, which limits the potential applicability.
Our goal is to build an exemplar-free object counter where we can specify what to count. To this end, we in-troduce a new counting task in which the user only needs to provide the name of the class for counting rather than the exemplars (see Figure 1b). In this way, the counting model can not only operate in an automatic manner but also allow the user to define what to count by simply providing the class name. Note that the class to count during test time can be arbitrary. For cases where the test class is completely unseen to the trained model, the counter needs to adapt to the unseen class without any annotated data. Hence, we
name this setting zero-shot object counting (ZSC), inspired by previous zero-shot learning approaches [6, 57].
To count without any annotated exemplars, our idea is to identify a few patches in the input image containing the target object that can be used as counting exemplars. Here the challenges are twofold: 1) how to localize patches that contain the object of interest based on the provided class name, and 2) how to select good exemplars for counting.
Ideally, good object exemplars are visually representative for most instances in the image, which can benefit the object counter. In addition, we want to avoid selecting patches that contain irrelevant objects or backgrounds, which likely lead to incorrect object counts.
To this end, we propose a two-step method that first lo-calizes the class-relevant patches which contain the objects of interest based on the given class name, and then selects among these patches the optimal exemplars for counting.
We use these selected exemplars, together with a pre-trained exemplar-based counting model, to achieve exemplar-free object counting.
In particular, to localize the patches containing the ob-jects of interest, we first construct a class prototype in a pre-trained embedding space based on the given class name. To construct the class prototype, we train a conditional vari-ational autoencoder (VAE) to generate features for an ar-bitrary class conditioned on its semantic embedding. The class prototype is computed by taking the average of the generated features. We then select the patches whose em-beddings are the k-nearest neighbors of the class prototype as the class-relevant patches.
After obtaining the class-relevant patches, we further se-lect among them the optimal patches to be used as counting exemplars. Here we observe that the feature maps obtained using good exemplars and bad exemplars often exhibit dis-tinguishable differences. An example of the feature maps obtained with different exemplars is shown in Figure 2. The feature map from a good exemplar typically exhibits some repetitive patterns (e.g., the dots on the feature map) that center around the object areas while the patterns from a bad exemplar are more irregular and occur randomly across the image. Based on this observation, we train a model to mea-sure the goodness of an input patch based on its correspond-ing feature maps. Specifically, given an arbitrary patch and a pre-trained exemplar-based object counter, we train this model to predict the counting error of the counter when us-ing the patch as the exemplar. Here the counting error can indicate the goodness of the exemplar. After this error pre-dictor is trained, we use it to select those patches with the smallest predicted errors as the final exemplars for counting.
Experiments on the FSC-147 dataset show that our method outperforms the previous exemplar-free counting method [33] by a large margin. We also provide analy-ses to show that patches selected by our method can be
Figure 2. Feature maps obtained using different exemplars given a pre-trained exemplar-based counting model. The feature maps obtained using good exemplars typically exhibit some repetitive patterns while the patterns from bad exemplars are more irregular. used in other exemplar-based counting methods to achieve exemplar-free counting.
In short, our main contributions can be summarized as follows:
• We introduce the task of zero-shot object counting that counts the number of instances of a specific class in the input image, given only the class name and without relying on any human-annotated exemplars.
• We propose a simple yet effective patch selec-tion method that can accurately localize the optimal patches across the query image as exemplars for zero-shot object counting.
• We verify the effectiveness of our method on the FSC-147 dataset, through extensive ablation studies and vi-sualization results. 2.