Abstract
In this paper we present Mask DINO, a unified object detection and segmentation framework. Mask DINO extends
DINO (DETR with Improved Denoising Anchor Boxes) by adding a mask prediction branch which supports all im-age segmentation tasks (instance, panoptic, and semantic).
It makes use of the query embeddings from DINO to dot-product a high-resolution pixel embedding map to predict a set of binary masks. Some key components in DINO are extended for segmentation through a shared architecture and training process. Mask DINO is simple, efficient, and scalable, and it can benefit from joint large-scale detec-tion and segmentation datasets. Our experiments show that
Mask DINO significantly outperforms all existing special-ized segmentation methods, both on a ResNet-50 backbone and a pre-trained model with SwinL backbone. Notably,
Mask DINO establishes the best results to date on instance segmentation (54.5 AP on COCO), panoptic segmentation (59.4 PQ on COCO), and semantic segmentation (60.8 mIoU on ADE20K) among models under one billion parameters.
Code is available at https://github.com/IDEA-Research/MaskDINO. 1.

Introduction
Object detection and image segmentation are fundamen-tal tasks in computer vision. Both tasks are concerned with localizing objects of interest in an image but have differ-ent levels of focus. Object detection is to localize objects of interest and predict their bounding boxes and category
*Equal contribution.
†Work done when Feng Li and Hao Zhang were interns at IDEA.
‡Corresponding author. labels, whereas image segmentation focuses on pixel-level grouping of different semantics. Moreover, image segmenta-tion encompasses various tasks including instance segmen-tation, panoptic segmentation, and semantic segmentation with respect to different semantics, e.g., instance or category membership, foreground or background category.
Remarkable progress has been achieved by classical convolution-based algorithms developed for these tasks with specialized architectures, such as Faster RCNN [24] for ob-ject detection, Mask RCNN [9] for instance segmentation, and FCN [21] for semantic segmentation. Although these methods are conceptually simple and effective, they are tai-lored for specialized tasks and lack the generalization ability to address other tasks. The ambition to bridge different tasks gives rise to more advanced methods like HTC [2] for object detection and instance segmentation and Panoptic FPN [14],
K-net [33] for instance, panoptic, and semantic segmenta-tion. Task unification not only helps simplify algorithm development but also brings in performance improvement in multiple tasks.
Recently, DETR-like [1] models developed based on
Transformers [27] have achieved inspiring progress on many detection and segmentation tasks. As an end-to-end object detector, DETR adopts a set-prediction objective and elimi-nates hand-crafted modules such as anchor design and non-maximum suppression. Although DETR addresses both the object detection and panoptic segmentation tasks, its segmen-tation performance is still inferior to classical segmentation models. To improve the detection and segmentation perfor-mance of Transformer-based models, researchers have devel-oped specialized models for object detection [15, 18, 32, 35], image segmentation [3, 4, 33], instance segmentation [7], panoptic segmentation [23], and semantic segmentation [12]. to improve object detection,
DINO [32] takes advantage of the dynamic anchor box for-Among the efforts
mulation from DAB-DETR [18] and query denoising train-ing from DN-DETR [15], and further achieves the SOTA result on the COCO object detection leaderboard for the first time as a DETR-like model. Similarly, for improving image segmentation, MaskFormer [4] and Mask2Former [3] propose to unify different image segmentation tasks using query-based Transformer architectures to perform mask clas-sification. Such methods have achieved remarkable perfor-mance improvement on multiple segmentation tasks.
However, in Transformer-based models, the best-performing detection and segmentation models are still not unified, which prevents task and data cooperation between detection and segmentation tasks. As an evidence, in CNN-based models, Mask-R-CNN [9] and HTC [2] are still widely acknowledged as unified models that achieve mutual cooper-ation between detection and segmentation to achieve superior performance than specialized models. Though we believe detection and segmentation can help each other in a unified architecture in Transformer-based models, the results of sim-ply using DINO for segmentation and using Mask2Former for detection indicate that they can not do other tasks well, as shown in Table 1 and 2. Moreover, trivial multi-task training can even hurt the performance of the original tasks. It nat-urally leads to two questions: 1) why cannot detection and segmentation tasks help each other in Transformer-based models? and 2) is it possible to develop a unified architecture to replace specialized ones?
To address these problems, we propose Mask DINO, which extends DINO with a mask prediction branch in par-allel with DINO’s box prediction branch. Inspired by other unified models [3, 4, 28] for image segmentation, we reuse content query embeddings from DINO to perform mask clas-sification for all segmentation tasks on a high-resolution pixel embedding map (1/4 of the input image resolution) obtained from the backbone and Transformer encoder fea-tures. The mask branch predicts binary masks by simply dot-producting each content query embedding with the pixel embedding map. As DINO is a detection model for region-level regression, it is not designed for pixel-level alignment.
To better align features between detection and segmentation, we also propose three key components to boost the segmenta-tion performance. First, we propose a unified and enhanced query selection. It utilizes encoder dense prior by predicting masks from the top-ranked tokens to initialize mask queries as anchors. In addition, we observe that pixel-level segmen-tation is easier to learn in the early stage and propose to use initial masks to enhance boxes, which achieves task cooper-ation. Second, we propose a unified denoising training for masks to accelerate segmentation training. Third, we use a hybrid bipartite matching for more accurate and consistent matching from ground truth to both boxes and masks.
Mask DINO is conceptually simple and easy to imple-ment under the DINO framework. To summarize, our contri-butions are three-fold. 1) We develop a unified Transformer-based framework for both object detection and segmentation.
As the framework is extended from DINO, by adding a mask prediction branch, it naturally inherits most algorithm im-provements in DINO including anchor box-guided cross attention, query selection, denoising training, and even a better representation pre-trained on a large-scale detection dataset. 2) We demonstrate that detection and segmenta-tion can help each other through a shared architecture de-sign and training method. Especially, detection can signifi-cantly help segmentation tasks, even for segmenting back-ground "stuff" categories. Under the same setting with a
ResNet-50 backbone, Mask DINO outperforms all exist-ing models compared to DINO (+0.8 AP on COCO de-tection) and Mask2Former (+2.6 AP, +1.1 PQ, and +1.5 mIoU on COCO instance, COCO panoptic, and ADE20K semantic segmentation). 3) We also show that, via a uni-fied framework, segmentation can benefit from detection pre-training on a large-scale detection dataset. After de-tection pre-training on the Objects365 [26] dataset with a
SwinL [20] backbone, Mask DINO significantly improves all segmentation tasks and achieves the best results on in-stance (54.5 AP on COCO), panoptic (59.4 PQ on COCO), and semantic (60.8 mIoU on ADE20K) segmentation among models under one billion parameters. 2.