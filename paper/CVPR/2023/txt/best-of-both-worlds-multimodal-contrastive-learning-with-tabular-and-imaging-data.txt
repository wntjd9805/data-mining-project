Abstract
Medical datasets and especially biobanks, often contain extensive tabular data with rich clinical information in ad-dition to images. In practice, clinicians typically have less data, both in terms of diversity and scale, but still wish to deploy deep learning solutions. Combined with increasing medical dataset sizes and expensive annotation costs, the necessity for unsupervised methods that can pretrain multi-modally and predict unimodally has risen.
To address these needs, we propose the first self-supervised contrastive learning framework that takes ad-vantage of images and tabular data to train unimodal en-coders. Our solution combines SimCLR and SCARF, two leading contrastive learning strategies, and is simple and effective. In our experiments, we demonstrate the strength of our framework by predicting risks of myocardial infarc-tion and coronary artery disease (CAD) using cardiac MR images and 120 clinical features from 40,000 UK Biobank subjects. Furthermore, we show the generalizability of our approach to natural images using the DVM car advertise-ment dataset.
We take advantage of the high interpretability of tabu-lar data and through attribution and ablation experiments find that morphometric tabular features, describing size and shape, have outsized importance during the contrastive learning process and improve the quality of the learned embeddings. Finally, we introduce a novel form of super-vised contrastive learning, label as a feature (LaaF), by ap-pending the ground truth label as a tabular feature during multimodal pretraining, outperforming all supervised con-trastive baselines.1 1.

Introduction
Modern medical datasets are increasingly multimodal, often incorporating both imaging and tabular data. Images 1https : / / github . com / paulhager / MMCL - Tabular -Imaging can be acquired by computed tomography, ultrasound, or magnetic resonance scanners, while tabular data commonly originates from laboratory tests, medical history and patient lifestyle questionnaires. Clinicians have the responsibility to combine and interpret this tabular and imaging data to diagnose, treat, and monitor patients. For example, cardiol-ogists may ask about a patientsâ€™ family history and record their weight, cholesterol levels, and blood pressure to better inform diagnoses when examining images of their heart.
Beyond diagnostics, multimodal data is also crucial to advance the understanding of diseases motivating the cre-ation of biobanks. Going far beyond the scale of typical datasets in hospitals, biobanks pool vast amount of informa-tion from large populations. Multimodal biobanks include the German National Cohort [21] with 200,000 subjects,
Lifelines [52] with 167,000 subjects, and the UK Biobank
[54] with 500,000 subjects. The UK Biobank includes thou-sands of data fields from patient questionnaires, laboratory tests, and medical examinations, in addition to imaging and genotyping information. Biobanks have already proven use-ful in the training of machine learning models to predict many diseases such as anaemia [39], early brain aging [32] and cardiovascular disease [1, 51].
There is a substantial interest in deploying algorithms that have been developed using these large-scale population studies in clinical practice. However, acquiring the same quality of data, both in terms of diversity of modalities and number of features, is not feasible in a busy clinical work-flow [20]. Furthermore, low disease frequencies make su-pervised solutions hard to train. Consequently, there is a clear need for unsupervised strategies that can learn from biobank scale datasets and be applied in the clinic where considerably less data, in size and dimension, is available.
Our contribution To address these needs, we propose the first contrastive framework that utilizes imaging and tabular data, shown in figure 1. Our framework is based on Sim-CLR [13] and SCARF [6], two leading contrastive learning solutions, and is simple and effective. We demonstrate the utility of our pretraining strategy on the challenging task of
Figure 1. We combine imaging and tabular data in a contrastive learning framework. We observe that morphometric features, describing shape and size, are of outsized importance in multimodal contrastive training and their inclusion boosts downstream task performance.
By simply adding the label as a tabular feature we introduce a novel form of supervised contrastive learning that outperforms all other supervised contrastive strategies. predicting cardiac health from MR images. Beyond medical imaging, we show that our framework can also be applied when combining natural images and tabular data using the
DVM car advertisement dataset [29].
Experimentally, we observe that our tool leverages mor-phometric features during contrastive learning. Morphome-tric features describe the size and shape of an object and therefore correlate with extractable imaging features. We quantitatively demonstrate the importance of these features in the contrastive learning process using attribution meth-ods, such as integrated gradients [55], and ablation experi-ments.
Finally, we introduce a new supervised contrastive learn-ing method called label as a feature (LaaF). By appending the target label as a tabular feature, our method outperforms previously published strategies that incorporate labels into the contrastive framework. Our method is also highly flexi-ble and can be combined with the aforementioned strategies to further improve performance. 2.