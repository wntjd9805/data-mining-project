Abstract
Misinformation has become a pressing issue. Fake me-dia, in both visual and textual forms, is widespread on the web. While various deepfake detection and text fake news detection methods have been proposed, they are only de-signed for single-modality forgery based on binary classi-fication, let alone analyzing and reasoning subtle forgery traces across different modalities. In this paper, we high-light a new research problem for multi-modal fake me-dia, namely Detecting and Grounding Multi-Modal Media
Manipulation (DGM4). DGM4 aims to not only detect the authenticity of multi-modal media, but also ground the ma-nipulated content (i.e., image bounding boxes and text to-kens), which requires deeper reasoning of multi-modal me-dia manipulation. To support a large-scale investigation, we construct the first DGM4 dataset, where image-text pairs are manipulated by various approaches, with rich anno-tation of diverse manipulations. Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities. HAMMER per-forms 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reason-ing, and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning. Dedicated ma-nipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information. Finally, we build an extensive bench-mark and set up rigorous evaluation metrics for this new re-search problem. Comprehensive experiments demonstrate the superiority of our model; several valuable observations are also revealed to facilitate future research in multi-modal media manipulation. 1.

Introduction
*This work was done at S-Lab, Nanyang Technological University
†Corresponding author
With recent advances in deep generative models, in-creasing hyper-realistic face images or videos can be au-Table 1. Comparison of the proposed DGM4 with existing tasks related to image and text forgery detection.
Problem Setting
DeepFake Detection [26, 55]
Text Fake News Detection [48, 53]
Multi-Modal Misinformation Detection [1, 25]
DGM4
Image Forgery
Text Forgery
Detection (cid:34) (cid:37) (cid:37) (cid:34)
Grounding (cid:37) (cid:37) (cid:37) (cid:34)
Detection (cid:37) (cid:34) (cid:37) (cid:34)
Grounding (cid:37) (cid:37) (cid:37) (cid:34)
Multi-Modal
Forgery Detection (cid:37) (cid:37) (cid:34) (cid:34) tomatically generated, which results in various security is-sues [35–41, 43, 52] such as serious deepfake problem [7, 12, 21, 34, 42] spreading massive fabrication on visual me-dia. This threat draws great attention in computer vision community and various deepfake detection methods have been proposed. With the advent of Large Language Model, e.g., BERT [6], GPT [31], enormous text fake news [48, 53] can be readily generated to maliciously broadcast mislead-ing information on textual media. Natural Language Pro-cessing (NLP) field pays great attention to this issue and presents diverse text fake news detection methods.
Compared to a single modality, the multi-modal media (in form of image-text pairs) disseminates broader infor-mation with greater impact in our daily life. Thus, multi-modal forgery media tends to be more harmful. To cope with this new threat with a more explainable and inter-pretable solution, this paper proposes a novel research prob-lem, namely Detecting and Grounding Multi-Modal Media
Manipulation (DGM4). As shown in Table 1 and Fig. 1, two challenges are brought by DGM4: 1) while current deepfake detection and text fake news detection methods are designed to detect forgeries of single modality, DGM4 demands simultaneously detecting the existence of forgery in both image and text modality and 2) apart from binary classification like current single-modal forgery detection,
DGM4 further takes grounding manipulated image bound-ing boxes (bboxes) and text tokens into account. This means existing single-modal methods are unavailable for this novel research problem. A more comprehensive and deeper reasoning of the manipulation characteristics be-tween two modalities is of necessity. Note that some multi-modal misinformation works [1, 25] are developed. But they are only required to determine binary classes of multi-modal media, let alone manipulation grounding.
To facilitate the study of DGM4, this paper contributes the first large-scale DGM4 dataset. In this dataset, we study a representative multi-modal media form, human-centric news. It usually involves misinformation regarding politi-cians and celebrities, resulting in serious negative influ-ence. We develop two different image manipulation (i.e., face swap/attribute manipulation) and two text manipula-tion (i.e., text swap/attribute manipulation) approaches to form the multi-modal media manipulation scenario. Rich annotations are provided for detection and grounding, in-cluding binary labels, fine-grained manipulation types, ma-nipulated image bboxes and manipulated text tokens.
Compared to pristine image-text pairs, manipulated multi-modal media is bound to leave manipulation traces in manipulated image regions and text tokens. All of these traces together alter the cross-modal correlation and thus cause semantic inconsistency between two modali-ties. Therefore, reasoning semantic correlation between images and texts provides hints for the detection and grounding of multi-modal manipulation. To this end, in-spired by existing vision-language representation learning works [16, 17, 30], we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to tackle DGM4. To fully capture the interaction between images and texts, HAMMER 1) aligns image and text em-beddings through manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reasoning and 2) aggregates multi-modal embeddings via modality-aware cross-attention of multi-modal aggregator as deep manipulation reasoning. Based on the interacted multi-modal embeddings in different levels, dedicated ma-nipulation detection and grounding heads are integrated hi-erarchically to detect binary classes, fine-grained manipula-tion types, and ground manipulated image bboxes, manipu-lated text tokens. This hierarchical mechanism contributes to more fine-grained and comprehensive manipulation de-tection and grounding. Main contributions of our paper:
• We introduce a new research problem Detecting and
Grounding Multi-Modal Media Manipulation (DGM4), with the objective of detecting and grounding manipula-tions in image-text pairs of human-centric news.
• We contribute a large-scale DGM4 dataset with samples generated by two image manipulation and two text ma-nipulation approaches. Rich annotations are provided for detecting and grounding diverse manipulations.
• We propose a powerful HierArchical Multi-modal
Manipulation rEasoning tRansformer (HAMMER). A comprehensive benchmark is built based on rigorous eval-uation protocols and metrics. Extensive quantitative and qualitative experiments demonstrate its superiority. 2.