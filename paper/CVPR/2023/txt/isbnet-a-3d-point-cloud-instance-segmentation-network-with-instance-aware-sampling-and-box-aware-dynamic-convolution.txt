Abstract
Existing 3D instance segmentation methods are predomi-nated by the bottom-up design – manually fine-tuned algo-rithm to group points into clusters followed by a refinement network. However, by relying on the quality of the clus-ters, these methods generate susceptible results when (1) nearby objects with the same semantic class are packed together, or (2) large objects with loosely connected re-gions. To address these limitations, we introduce ISBNet, a novel cluster-free method that represents instances as ker-nels and decodes instance masks via dynamic convolution.
To efficiently generate high-recall and discriminative ker-nels, we propose a simple strategy named Instance-aware
Farthest Point Sampling to sample candidates and lever-age the local aggregation layer inspired by PointNet++ to encode candidate features. Moreover, we show that pre-dicting and leveraging the 3D axis-aligned bounding boxes in the dynamic convolution further boosts performance.
Our method set new state-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2) in terms of AP and retains fast inference time (237ms per scene on Scan-NetV2). The source code and trained models are available at https://github.com/VinAIResearch/ISBNet. 1.

Introduction 3D instance segmentation (3DIS) is a core problem of deep learning in the 3D domain. Given a 3D scene repre-sented by a point cloud, we seek to assign each point with a semantic class and a unique instance label. 3DIS is an important 3D perception task and has a wide range of ap-plications in autonomous driving, augmented reality, and robot navigation where point cloud data can be leveraged to complement the information provided by 2D images. Com-pared to 2D image instance segmentation (2DIS), 3DIS is arguably harder due to much higher variations in appearance and spatial extent along with unequal distribution of point cloud, i.e., dense near object surface and sparse elsewhere.
Thus, it is not trivial to apply 2DIS methods to 3DIS.
Figure 1. In DyCo3D [16], kernel prediction quality is greatly affected by the centroid-based clustering algorithm which has two issues: 1 mis-grouping nearby instances and 2 over-segment a large object into multiple fragments. Our method addresses these issues by instance-aware point sampling, achieving far better results. Each sample point aggregates information from its local context to generate a kernel for predicting its own object mask, and the final instances will be filtered and selected by an NMS.
A typical approach for 3DIS, DyCo3D [16], adopts dy-namic convolution [33, 37] to predict instance masks. Specif-ically, points are clustered, voxelized, and passed through a 3D Unet to generate instance kernels for dynamic convolu-tion with the feature of all points in the scene. This approach is illustrated in Fig. 2 (a). However, this approach has several limitations. First, the clustering algorithm heavily relies on the centroid-offset prediction whose quality deteriorates sig-nificantly when: (1) objects are densely packed so that two objects can be mistakenly grouped together as one object, or (2) large objects whose parts are loosely connected resulting
in different objects when clustered. These two scenarios are visualized in Fig. 1. Second, the points’ feature mostly encodes object appearance which is not distinct enough for separating different instances, especially between objects having the same semantic class.
To address the limitations of DyCo3D [16], we propose
ISBNet, a cluster-free framework for 3DIS with Instance-aware Farthest Point Sampling and Box-aware Dynamic
Convolution. First, we revisit the Farthest Point Sampling (FPS) [10] and the clustering method in [5, 16, 34] and find that these algorithms generate considerably low instance recall. As a result, many objects are omitted in the sub-sequent stage, leading to poor performance. Motivated by this, we propose our Instance-aware Farthest Point Sampling (IA-FPS), which aims to sample query candidates in a 3D scene with high instance recall. We then introduce our Point
Aggregator, incorporating the IA-FPS with a local aggrega-tion layer to encode semantic features, shapes, and sizes of instances into instance-wise features.
Additionally, the 3D bounding box of the object is an existing supervision but has not yet been explored in the 3D instance segmentation task. Therefore, we add an auxil-iary branch to our model to jointly predict the axis-aligned bounding box and the binary mask of each instance. The ground-truth axis-aligned bounding box is deduced from the existing instance mask label. Unlike Mask-DINO [25] and
CondInst [33], where the auxiliary bounding box prediction is just used as a regularization of the learning process, we leverage it as an extra geometric cue in the dynamic convo-lution, thus further boosting the performance of the instance segmentation task.
To evaluate the performance of our approach, we conduct extensive experiments on three challenging datasets: Scan-NetV2 [8], S3DIS [1], and STPLS3D [4]. ISBNet not only achieves the highest accuracy among these three datasets, surpassing the strongest method by +2.7/3.4/3.0 on Scan-NetV2, S3DIS, and STPLS3D, but also demonstrates to be highly efficient, running at 237ms per scene on ScanNetV2.
In summary, the contributions of our work are as follows:
• We propose ISBNet, a cluster-free paradigm for 3DIS, that leverages Instance-aware Farthest Point Sampling and
Point Aggregator to generate an instance feature set.
• We first introduce using the axis-aligned bounding box as an auxiliary supervision and propose the Box-aware
Dynamic Convolution to decode instance binary masks.
• ISBNet achieves state-of-the-art performance on three dif-ferent datasets: ScanNetV2, S3DIS, and STPLS3D with-out comprehensive modifications of the model architecture and hyper-parameter tuning for each dataset.
In the following, Sec. 2 reviews prior work; Sec. 3 speci-fies our approach; and Sec. 4 presents our implementation details and experimental results. Sec. 5 concludes with some remarks and discussions. 2.