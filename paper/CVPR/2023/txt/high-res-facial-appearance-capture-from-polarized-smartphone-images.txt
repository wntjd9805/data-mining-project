Abstract
We propose a novel method for high-quality facial tex-ture reconstruction from RGB images using a novel captur-ing routine based on a single smartphone which we equip with an inexpensive polarization foil. Specifically, we turn the flashlight into a polarized light source and add a polar-ization filter on top of the camera. Leveraging this setup, we capture the face of a subject with cross-polarized and parallel-polarized light. For each subject, we record two short sequences in a dark environment under flash illu-mination with different light polarization using the modi-fied smartphone. Based on these observations, we recon-struct an explicit surface mesh of the face using structure from motion. We then exploit the camera and light co-location within a differentiable renderer to optimize the fa-cial textures using an analysis-by-synthesis approach. Our
All data has been captured at the Technical University of Munich. method optimizes for high-resolution normal textures, dif-fuse albedo, and specular albedo using a coarse-to-fine op-timization scheme. We show that the optimized textures can be used in a standard rendering pipeline to synthesize high-quality photo-realistic 3D digital humans in novel environ-ments. 1.

Introduction
In recent years, we have seen tremendous advances in the development of virtual and mixed reality devices. At the same time, the commercial availability of such hardware has led to a massive interest in the creation of ’digital hu-man’ assets and photo-realistic renderings of human faces.
In particular, the democratization to commodity hardware would open up significant potential for asset creation in video games, other home entertainment applications, or im-mersive teleconferencing systems. However, rendering a
human face realistically in a virtual environment from ar-bitrary viewpoints with changing lighting conditions is an extremely difficult problem. It involves an accurate recon-struction of the face geometry and skin textures, such as the diffuse albedo, specular gain, or skin roughness. Tra-ditionally, this problem has been approached by recording data in expensive and carefully calibrated light stage cap-ture setups, under expert supervision. We seek to simplify this capture process to allow individuals to reconstruct their own faces, while keeping the quality degradation compared to a light stage to a minimum.
The disentanglement of geometry and material of human faces is an extremely ill-posed problem. Current solutions involve a capture setup with multiple cameras and light sources, with millimeter-accurate calibration. A common approach to disentangling face skin surface from subsurface response is the use of polarization filters [9] in tandem with such expensive capture setups. Given such a carefully cali-brated capture setting, one can use differentiable rendering to estimate the individual skin parameters in an analysis-by-synthesis approach. While these methods do produce visually impressive results, they are limited to high-budget production studios.
In this paper, we propose a capture setup consisting of only a smartphone and inexpensive polarization foils, which can be attached to the camera lens and flashlight. Inspired by light stage capture setups, a user captures two sequences of their face, one with perpendicular filter alignment, and one with parallel alignment. This allows for a two-stage op-timization, where we first reconstruct a high-resolution dif-fuse albedo texture of a user’s face from the cross-polarized capture, followed by recovery of the specular albedo, nor-mal map, and roughness from the parallel-polarized views.
Data is captured in a dark room to avoid requiring pre-computation of an environment map. In addition to visually compelling novel view synthesis and relighting results, our method produces editable textures and face geometry.
In summary, the key contributions of our project are:
• We propose a commodity capture setup that combines a smartphone’s camera and flashlight with polarization foils. The polarization allows us to separate diffuse from specular parts, and to reconstruct the user’s face textures, such as diffuse albedo, specular albedo and normal maps.
• Our proposed capture setting with the co-located cam-era and light enables separation of skin properties from illumination, which is of key importance for realistic rendering of faces.
• We propose a coarse-to-fine optimization strategy with mip-mapping, which increases sharpness of the recon-structed appearance textures. 2.