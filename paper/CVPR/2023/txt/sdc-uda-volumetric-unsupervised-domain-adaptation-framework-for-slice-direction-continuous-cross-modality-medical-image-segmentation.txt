Abstract
Recent advances in deep learning-based medical im-age segmentation studies achieve nearly human-level per-formance in fully supervised manner. However, acquiring pixel-level expert annotations is extremely expensive and laborious in medical imaging fields. Unsupervised domain adaptation (UDA) can alleviate this problem, which makes it possible to use annotated data in one imaging modal-ity to train a network that can successfully perform seg-In mentation on target imaging modality with no labels. this work, we propose SDC-UDA, a simple yet effective volumetric UDA framework for Slice-Direction Continuous cross-modality medical image segmentation which com-bines intra- and inter-slice self-attentive image translation, uncertainty-constrained pseudo-label refinement, and volu-metric self-training. Our method is distinguished from pre-vious methods on UDA for medical image segmentation in that it can obtain continuous segmentation in the slice di-rection, thereby ensuring higher accuracy and potential in clinical practice. We validate SDC-UDA with multiple pub-licly available cross-modality medical image segmentation datasets and achieve state-of-the-art segmentation perfor-mance, not to mention the superior slice-direction continu-ity of prediction compared to previous studies. 1.

Introduction
With the surprising development of deep learning (DL), many studies are now showing remarkable performance in various applications [8,16,20]. However, when a DL model
* Equal contribution.
† Corresponding author.
Figure 1. An illustration that describes the comparison between our proposed method with previous methods. (A) Previous UDA for medical image segmentation studies mostly utilize 2D UDA, which leads to inconsistent predictions in the slice direction when the predictions are stacked. (B) The proposed framework (SDC-UDA) considers volumetric information in the translation and seg-mentation process, respectively, which leads to improved slice-direction continuity of segmentation that is much practical for clin-ical use. faces data from an unseen domain, performance degrada-tion occurs [9, 32]. Resolving this issue is important for the
DL techniques to be applied in real world since collecting data from all domains and labeling them is very impractical and inefficient. Unsupervised Domain Adaptation (UDA) aims to alleviate this problem by adapting a model trained on source domain data to target domain, without the neces-sity of supervision in the target domain. Data dependency is more serious in medical image segmentation field since acquiring pixel-level expert annotation is extremely expen-sive and time-consuming [3, 22, 37].
Previous studies on UDA in the field of cross-modality med-Figure 2. Overview of our volumetric UDA framework. First, source-to-target image transformation is performed via unpaired image translation with intra- and inter-slice self-attention (stage 1-2). Second, volumetric self-training is performed (stage 3-5). During self-training, uncertainty-constrained pseudo-label refinement is conducted to improve pseudo-labels, thereby maximizing the effect of self-training (stage 4). The reverse loop of image translation is omitted for ease of illustration. Detailed architecture of image translation network is described in Fig. 3. Best viewed in color and on high-resolution display. II-SA: Intra- and inter-slice self-attention. ical image segmentation are normally conducted by simul-taneously learning 2D image translation and target-domain segmentation, inferring the trained model on each slice of target data, and then stacking the predictions in the slice direction (Fig. 1). As a result, they can lead to inconsis-tent or fluctuating predictions in the slice direction that are not revealed in quantitative metrics and may interrupt ac-curate analysis of target structure, making it difficult to use in real world clinical practice. In contrast, SDC-UDA can achieve improved slice-direction continuity by incorpo-rating volumetric natures of medical imaging, which has not been thoroughly explored in previous works.
It effi-ciently generates synthetic target volumes with neighbor-aware image translation by utilizing intra- and inter-slice self-attention module [27]. Then, volumetric self-training is followed with uncertainty-constrained pseudo-label re-finement strategy that adaptively increases the accuracy of pseudo-labels according to the target data (Fig. 2). Pre-liminary version of this work has won the 1st place in an unsupervised cross-modality domain adaptation for medical image segmentation challenge [7, 26]. We up-dated the framework and extended it to multiple datasets.
The main contribution of our work can be summarized as follows:
• We present SDC-UDA, a unified volumetric UDA framework for cross-modality medical image seg-mentation.
• Intra- and inter-slice self-attention for efficient medical image translation: Proposed 2.5D translation frame-work with intra- and inter-slice self-attention module leads to increased anatomy preservation and slice-direction smoothness in the synthesized volume, en-abling the synthetic volume to be used effectively in the following self-training steps.
• Volumetric self-training with uncertainty-constrained pseudo-label refinement: We propose a novel uncertainty-constrained pseudo-label refinement mod-ule that can adaptively enhance the accuracy (i.e., sensitivity or specificity) of pseudo-labels, thereby maximizing the performance of self-training on medi-cal image segmentation.
• SDC-UDA was validated on multiple public datasets with different data characteristics for cross-modality medical image segmentation.
It not only surpassed the performance of previous methods, but also showed superior slice-direction segmenta-tion continuity which can provide precise analysis in clinical practice. 2.