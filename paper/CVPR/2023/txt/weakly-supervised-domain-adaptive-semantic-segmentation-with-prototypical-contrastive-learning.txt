Abstract
There has been a lot of effort in improving the perfor-mance of unsupervised domain adaptation for semantic seg-mentation task, however, there is still a huge gap in perfor-mance when compared with supervised learning.
In this work, we propose a common framework to use different weak labels, e.g., image, point and coarse labels from the target domain to reduce this performance gap. Specifically, we propose to learn better prototypes that are representa-tive class features by exploiting these weak labels. We use these improved prototypes for the contrastive alignment of class features. In particular, we perform two different fea-ture alignments: first, we align pixel features with proto-types within each domain and second, we align pixel fea-tures from the source to prototype of target domain in an asymmetric way. This asymmetric alignment is beneficial as it preserves the target features during training, which is essential when weak labels are available from the tar-get domain. Our experiments on various benchmarks show that our framework achieves significant improvement com-pared to existing works and can reduce the performance gap with supervised learning. Code will be available at https://github.com/anurag-198/WDASS. 1.

Introduction
Semantic segmentation requires pixel level annotation, which is expensive and time consuming. For real world ur-ban scenes [5, 9, 32, 42], this becomes more challenging as there are far too many objects to annotate in the scene. For example, it takes around 90 min to annotate an image for
Cityscapes [5]. To reduce this annotation effort, the task of
Unsupervised Domain Adaptative Semantic Segmentation (UDASS) [31, 44, 47, 48] proposes to learn from photore-alistic synthetic images [26, 28, 38] with relatively cheap labels. However, due to the domain gap between the real (target domain) and synthetic (source domain) images, this
*Currently with Google. This work was done at ETH Z¨urich.
Figure 1. We propose a common framework for different weak la-bel (image, point and coarse labels) for the task of Weakly Super-vised Domain Adaptative Semantic Segmentation(WDASS). Our proposed framework, utilising cheaper weak labels bridges the gap between UDA (CorDA [35], ProDA [43], DASS [16]) and super-vised learning. Notably, for coarse annotation, our method outper-forms supervised learning, exhibiting the potential of weak labels for domain adaptation task. problem becomes more challenging. There have been many efforts [16, 29, 31, 41, 43, 44, 44, 48] to improve the perfor-mance on the UDASS task, yet there is a big performance gap compared to supervised learning. In this work, we pro-pose to exploit additional weak labels (image [13,22], point and [1] coarse labels [5]) for the real images to improve over the UDASS performance and reduce the performance gap with supervised learning.
Weakly supervised Domain Adaptive Semantic Segmen-tation (WDASS) relaxes the problem of UDASS by allow-ing weak labels from the target domain. However, it is non trivial to optimally use the weak labels. [25] works with im-age and point labels and focuses on pixel level adversar-ial alignment between source and target domains. [6] works with coarse labels and uses self-training for feature align-ment. Both these methods use the weak labels only as addi-tional supervision signal from the target domain and do not use them for aligning features between the source and tar-get domain. Moreover, these works do not have a common framework that works with different weak labels. We pro-pose a common framework that works with different weak labels (e.g., image, point and coarse labels) and use these weak labels for feature alignment between source and target domains, improving domain adaptation for semantic seg-mentation task.
Inspired by the recent success of prototype based learn-ing for semantic segmentation [8, 45], few shot learn-ing [7,34,40] and UDASS [16,20,43], we propose to extend prototype learning for the WDASS task. For the UDASS task, prototypes are constructed on the target domain by av-eraging features from noisy pseudo labels [16,43], resulting in noisy prototypes. With the guidance of additional weak labels from the target domain, we improve the quality of the prototypes. Specifically, we use the pixel labeled weak labels (point or coarse labels) to correct the prototypes and image labels to further improve the features by penalising the category features not present in an image. Next, we perform contrastive alignment of features using the proto-types. We propose two alignments, namely intra domain alignment and inter domain alignment. Intra domain align-ment aligns pixel features with prototypes within individual domains (source and target). This helps in learning compact and better features. On the other hand, inter domain align-ment aligns features from the source to prototypes from the target domain in an asymmetric manner, reducing the do-main gap between source and target domains. This asym-metric alignment only changes the source features and pre-serves the target features during training. This type of align-ment is essential when we have weak labels from the target domain. Overall our proposed framework uses weak labels and improves the performance of UDASS task substantially.
We summarise our main contributions as:
• We propose a new framework for WDASS task that works seamlessly with image, point and coarse labels from the target domain. Our method constructs better prototypes using different weak labels. Further, we in-troduce intra and inter domain contrastive alignment of features with prototypes for source and target domains for WDASS task.
• Our framework using different weak labels (image, point and coarse labels) is able to bridge the gap be-tween UDASS and supervised learning, showing the effectiveness of the weak labels. Distinctly, with coarse labels, our framework even outperforms super-vised learning.
• We show the tradeoff between annotation cost vs. se-mantic segmentation performance for different weak labels. Notably, point annotation achieves better per-formance in lower annotation budget scenarios than coarse and image label.
• Our framework sets a new state of the art for WDASS on standard benchmarks for different weak labels, with significant improvement over prior works. 2.