Abstract
Discriminative representation is essential to keep a unique identiﬁer for each target in Multiple object tracking (MOT). Some recent MOT methods extract features of the bounding box region or the center point as identity embed-dings. However, when targets are occluded, these coarse-grained global representations become unreliable. To this end, we propose exploring diverse ﬁne-grained represen-tation, which describes appearance comprehensively from global and local perspectives. This ﬁne-grained represen-tation requires high feature resolution and precise semantic information. To effectively alleviate the semantic misalign-ment caused by indiscriminate contextual information ag-gregation, Flow Alignment FPN (FAFPN) is proposed for multi-scale feature alignment aggregation. It generates se-mantic ﬂow among feature maps from different resolutions to transform their pixel positions. Furthermore, we present a Multi-head Part Mask Generator (MPMG) to extract ﬁne-grained representation based on the aligned feature maps.
Multiple parallel branches of MPMG allow it to focus on different parts of targets to generate local masks without label supervision. The diverse details in target masks fa-cilitate ﬁne-grained representation. Eventually, beneﬁting from a Shufﬂe-Group Sampling (SGS) training strategy with positive and negative samples balanced, we achieve state-of-the-art performance on MOT17 and MOT20 test sets.
Even on DanceTrack, where the appearance of targets is ex-tremely similar, our method signiﬁcantly outperforms Byte-Track by 5.0% on HOTA and 5.6% on IDF1. Extensive ex-periments have proved that diverse ﬁne-grained representa-tion makes Re-ID great again in MOT. 1.

Introduction
As a fundamental task in computer vision, multi-object tracking (MOT) is crucial for automatic driving, video 1 Equal contribution
∗ Corresponding author (a) Bbox-based (b) Center-based
... local global (c) Ours
Figure 1. Comparison with different methods of appearance representation: (a) Bbox-based, (b) Center-based, (c) global-local ﬁne-grained representation (ours). surveillance, etc. MOT aims to localize targets and maintain their unique identities. Recent MOT methods [3, 4, 48, 50, 54] mainly follow the paradigm of tracking-by-detection, and divide tracking into two independent steps: detection and association. The detector detects targets in each frame
ﬁrst, and then appearance representation and position in-formation are employed as the association basis to link tar-gets with the corresponding trajectories. As the inherent at-tributes of the target, appearance and position complement each other in the association.
However, due to targets or camera motion, intra-class and inter-class occlusion are inevitable, which puts for-ward stricter requirements for appearance representation.
As shown in Fig. 1a and Fig. 1b, these methods extract the features of the bounding box region or the center point as appearance embeddings. However, these coarse-grained global embeddings are extremely sensitive to noise, so that become unreliable once the signal-to-noise ratio is reduced.
With the headway of the detector [5, 11, 27, 35, 58], appear-ance representation gradually cannot keep the same perfor-mance as detection. Some researchers [54] ﬁnd that simply using position cues is enough to obtain satisfactory results, while appearance cues are unfavorable for further improve-ment.
To break this situation, we re-examine the recent appearance-based methods. The bbox-based methods [38]
in Fig. 1a adopt global average pooling, which converts fea-tures of the bounding box region into appearance embed-dings. These methods equally treat target and interference features (background and other objects), which is unreason-able. As shown in Fig. 1b, researchers [49, 55, 57] notice this issue and utilize features at the target centers as their appearance embeddings, eliminating interference from the background as much as possible. Despite this, when the tar-get is occluded, the feature at its center is still inevitably interfered with noise information from other objects. The fuzziness of global representation has become an impedi-ment of these methods. On the contrary, our method focuses on different local details of targets, which is illustrated in
Fig. 1c. Fine-grained global and local representations com-plement each other and jointly describe appearance. When the target is occluded, our method can still identify it ac-cording to visible parts, similar to human judgment.
As the basis of ﬁne-grained representation, target fea-ture maps require high-resolution and unambiguous seman-tic information. Shallow or deep outputs cannot meet these two requirements simultaneously. Therefore, it is feasible to enrich the semantic information of shallow features or improve the resolution of deep features. To reduce the bur-den, researchers usually adopt FPN [21] to aggregate multi-scale shallow feature maps indiscriminately, which causes semantic misalignment among features with different res-olutions. Speciﬁcally, there is a spatial misalignment be-tween the late feature maps after up-sampling and the early feature maps.
To solve this issue, we construct a Flow Alignment FPN (FAFPN) to learn the semantic ﬂow among feature maps with different scales and effectively broadcast high-level features to high-resolution features. FAFPN aligns feature maps by semantic ﬂow and aggregates context information to enrich semantic information while maintaining high reso-lution. Further, Multi-head Part Mask Generator (MPMG) is proposed to generate part masks for detailed representa-tions without label supervision. Inspired by multi-head self-attention in Transformer [37], MPMG implements a multi-branch parallel structure, which can efﬁciently and com-prehensively focus on different parts of the target. Com-bining FAFPN and MPMG, we can obtain a diverse ﬁne-grained representation, including diverse local embeddings and background-ﬁltered global embeddings.
In the training phase, some current MOT methods [20, 55] train Re-ID (re-identiﬁcation) by following the video sequence or shufﬂing all video frames. The former does not disperse training data, while the latter is positive and negative samples imbalanced. To train Re-ID more rea-sonably, we propose a training strategy named Shufﬂe-Group Sampling (SGS). In this strategy, we group video frames into short segments in their order and then shuf-ﬂe these segments. SGS disperses data and balances pos-itive and negative samples. Our model incorporates all the above proposed techniques, named ﬁne-grained representa-tion tracker (FineTrack).
The main contributions of our work can be summarized as follows:
• We propose a Flow Alignment FPN (FAFPN). It learns the semantic ﬂow among feature maps with different resolutions to correct spatial dislocation. Feature maps after FAFPN include high resolution and precise se-mantic information, which is the basis of ﬁne-grained representation.
• We construct a Multi-head Part Mask Generator (MPMG) to focus on details of targets. MPMG em-ploys self-attention to ﬁltrate background noise and ex-tract global-local embeddings to represent targets com-prehensively.
• Shufﬂe-Group Sampling (SGS) is proposed to disperse training data and balance positive and negative sam-It reduces oscillation in model convergence to ples. achieve better performance. 2.