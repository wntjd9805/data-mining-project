Abstract
Test-time adaptation (TTA) intends to adapt the pre-trained model to test distributions with only unlabeled test data streams. Most of the previous TTA methods have achieved great success on simple test data streams such as independently sampled data from single or multiple distri-butions. However, these attempts may fail in dynamic sce-narios of real-world applications like autonomous driving, where the environments gradually change and the test data is sampled correlatively over time.
In this work, we ex-plore such practical test data streams to deploy the model on the fly, namely practical test-time adaptation (PTTA).
To do so, we elaborate a Robust Test-Time Adaptation (RoTTA) method against the complex data stream in PTTA.
More specifically, we present a robust batch normalization scheme to estimate the normalization statistics. Meanwhile, a memory bank is utilized to sample category-balanced data with consideration of timeliness and uncertainty. Further, to stabilize the training procedure, we develop a time-aware reweighting strategy with a teacher-student model. Exten-sive experiments prove that RoTTA enables continual test-time adaptation on the correlatively sampled data streams.
Our method is easy to implement, making it a good choice for rapid deployment. The code is publicly available at https://github.com/BIT-DA/RoTTA 1.

Introduction
In recent years, many machine learning problems have made considerable headway with the success of deep neu-ral networks [13, 22, 33, 38]. Unfortunately, the perfor-mance of deep models drops significantly when training data and testing data come from different distributions [59], which limits their utility in real-world applications. To re-duce the distribution shift, a handful of works focus on transfer learning field [56], in particular, domain adapta-tion (DA) [17, 42, 45, 48, 69, 72] or domain generalization (DG) [40, 41, 52, 71, 83], in which one or more different but (cid:12)Corresponding author
Figure 1. We consider the practical test-time adaptation (TTA) setup and compare it with related ones. First, Fully TTA [70] adapts models on a fixed test distribution with an independently sampled test stream. Then, on this basis, Continual TTA [73] takes the continually changing distributions into consideration. Next,
Non-i.i.d. TTA [19] tries to tackle the correlatively sampled test streams on a single test distribution, where the label distribution among a batch of data deviates from that of the test distribution.
To be more practical, Practical TTA strives to connect both worlds: distribution changing and correlation sampling. related labeled datasets (a.k.a. source domain) are collected to help the model generalize well to unlabeled or unseen samples in new datasets (a.k.a. target domain).
While both DA and DG have extensively studied the problem of distribution shifts, they typically assume acces-sibility to the raw source data. However, in many practical scenarios like personal consumption records, the raw data should not be publicly available due to data protection reg-ulations. Further, existing methods have to perform heavy backward computation, resulting in unbearable training costs. Test-time adaptation (TTA) [3,11,16,24,26,54,65,81] attempts to address the distribution shift online at test time with only unlabeled test data streams. Unequivocally, TTA has drawn widespread attention in a variety of applications, e.g., 2D/3D visual recognition [2, 29, 49, 65, 82], multi-modality [63, 64] and document understanding [15].
Prior TTA studies [7, 20, 70, 73] mostly concentrate on a simple adaptation scenario, where test samples are inde-pendently sampled from a fixed target domain. To name a few, Sun et al. [65] adapt to online test samples drawn from a constant or smoothly changing distribution with an auxil-iary self-supervised task. Wang et al. [70] adapt to a fixed
Table 1. Comparison between our proposed practical test-time adaptation (PTTA) and related adaptation settings.
Available Data
Source Target
Setting
Adaptation Stage
Train (cid:33)
Domain Adaptation (cid:33)
Domain Generalization (cid:33)
Test-Time Training [65] (cid:37)
Fully Test-Time Adaptation [70] (cid:37)
Continual Test-Time Adaptation [73] (cid:37)
Non-i.i.d. Test-Time Adaptation [5, 19]
Practical Test-Time Adaptation (Ours) (cid:37)
Test (cid:37) (cid:37) (cid:33) (cid:33) (cid:33) (cid:33) (cid:33) (cid:33) (cid:33) (cid:33) (cid:37) (cid:37) (cid:37) (cid:37)
Test Data Stream
Distribution
--stationary stationary (cid:33) (cid:37) (cid:33) (cid:33) (cid:33) continually changing (cid:33) (cid:33) continually changing stationary
Sampling Protocol
--independently independently independently correlatively correlatively
Confronting continually changing distributions, target distribution by performing entropy minimization on-line. However, such an assumption is violated when the test environments change frequently [73]. Later on, Boudiaf et al. [5] and Gong et al. [19] consider the temporal correlation ship within test samples. For example, in autonomous driv-ing, test samples are highly correlated over time as the car will follow more vehicles on the highway or will encounter more pedestrians in the streets. More realistically, the data distribution changes as the surrounding environment alerts in weather, location, or other factors. In a word, distribution change and data correlation occur simultaneously in reality. tradi-tional algorithms like pseudo labeling or entropy minimiza-tion become more unreliable as the error gradients cumu-late. Moreover, the high correlation among test samples re-sults in the erroneous estimation of statistics for batch nor-malization and collapse of the model. Driven by this analy-sis, adapting to such data streams will encounter two major obstacles: 1) incorrect estimation in the batch normaliza-tion statistics leads to erroneous predictions of test samples, consequently resulting in invalid adaptation; 2) the model will easily or quickly overfit to the distribution caused by the correlative sampling. Thus, such dynamic scenarios are pressing for a new TTA paradigm to realize robust adapta-tion.
In this work, we launch a more realistic TTA setting, where distribution changing and correlative sampling oc-cur simultaneously at the test phase. We call this Practical
Test-Time Adaptation, or briefly, PTTA. To understand more clearly the similarities and differences between PTTA and the previous setups, we visualize them in Figure 1 and sum-marize them in Table 1. To conquer this challenging prob-lem, we propose a Robust Test-Time Adaptation (RoTTA) method, which consists of three parts: 1) robust statistics es-timation, 2) category-balanced sampling considering time-liness and uncertainty and 3) time-aware robust training.
More concretely, we first replace the erroneous statistics of the current batch with global ones maintained by the expo-nential moving average. It is a more stable manner to esti-mate the statistics in BatchNorm layers. Then, we simulate a batch of independent-like data in memory with category-balanced sampling while considering the timeliness and un-certainty of the buffered samples. That is, samples that are newer and less uncertain are kept in memory with higher priority. With this batch of category-balanced, timely and confident samples, we can obtain a snapshot of the current distribution. Finally, we introduce a time-aware reweight-ing strategy that considers the timeliness of the samples in the memory bank, with a teacher-student model to perform robust adaptation. With extensive experiments, we demon-strate that RoTTA can robustly adapt in the practical setup, i.e., PTTA.
In a nutshell, our contributions can be summarized as:
• We propose a new test-time adaptation setup that is more suitable for real-world applications, namely practical test-time adaptation (PTTA). PTTA considers both distribution changing and correlation sampling.
• We benchmark the performance of prior methods in
PTTA and uncover that they only consider one aspect of the problem, resulting in ineffective adaptation.
• We propose a robust test-time adaptation method (RoTTA), which has a more comprehensive considera-tion of PTTA challenges. Ease of implementation and effectiveness make it a practical deployment option.
• We extensively demonstrate the practicality of PTTA and the effectiveness of RoTTA on common TTA benchmarks [23], i.e., CIFAR-10-C and CIFAR-100-C and a large-scale DomainNet [58] dataset. RoTTA obtains state-of-the-art results, outperforming the best baseline by a large margin (reducing the averaged classification error by over 5.9%, 5.5% and 2.2% on
CIFAR-10-C, CIFAR-100-C and DomainNet, respec-tively). 2.