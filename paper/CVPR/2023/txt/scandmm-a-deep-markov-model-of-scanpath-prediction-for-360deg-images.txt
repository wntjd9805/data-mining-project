Abstract
Scanpath prediction for 360◦ images aims to produce dy-namic gaze behaviors based on the human visual perception mechanism. Most existing scanpath prediction methods for 360◦ images do not give a complete treatment of the time-dependency when predicting human scanpath, resulting in inferior performance and poor generalizability. In this pa-per, we present a scanpath prediction method for 360◦ im-ages by designing a novel Deep Markov Model (DMM) architecture, namely ScanDMM. We propose a semantics-guided transition function to learn the nonlinear dynam-ics of time-dependent attentional landscape. Moreover, a state initialization strategy is proposed by considering the starting point of viewing, enabling the model to learn the dynamics with the correct “launcher”. We further demon-strate that our model achieves state-of-the-art performance on four 360◦ image databases, and exhibit its generalizabil-ity by presenting two applications of applying scanpath pre-diction models to other visual tasks – saliency detection and image quality assessment, expecting to provide profound in-sights into these fields. 1.

Introduction 360◦ images, also referred to as omnidirectional, sphere or virtual reality (VR) images, have been a popular type of visual data in many applications, providing us with immer-sive experiences. Nevertheless, how people explore virtual environments in 360◦ images has not been well understood.
The scanpath prediction model that aims at generating real-istic gaze trajectories has obtained increasing attention due to its significant influence in understanding users’ viewing behaviors in VR scenes, as well as in developing VR ren-dering, display, compression, and transmission [51].
Scanpath prediction has been explored for many years in 2D images [29]. However, 360◦ images are different greatly from 2D images, as a larger space is offered to interact with
*Corresponding author (email: fa0001ng@e.ntu.edu.sg)
Figure 1. Existing scanpath prediction models for 360◦ images could be classified to two types: saliency-based models [2, 70, 71] and generative models [42, 43]. The scanpaths produced by saliency-based models, taking the study [2] as an example, com-monly exhibits unstable behavior with large displacements and scarce focal regions. Generative models, taking the study [43] as an example, shows less attention to regions of interest. The pro-posed ScanDMM can produce more realistic scanpaths that focus on regions of interests. – humans are allowed to use both head and gaze move-ments to explore viewports of interest in the scene. In such a case, viewing conditions, e.g., the starting point of viewing, has an important impact on humans’ scanpaths [20, 21, 52], and leads to complex and varied scanpaths among humans.
This is inherently different from what happens in 2D visu-als since humans can directly guide their attention to the regions of interest. Therefore, scanpath prediction for 360◦ images is a more complex task.
Current 360◦ image scanpath prediction methods could
be roughly divided into two categories: saliency-based [2, 70, 71] and generative methods [42, 43]. The basic idea of the former one is to sample predicted gaze points from a saliency map. The performance of such methods is highly dependent on that of the saliency maps. Furthermore, con-structing a satisfactory sampling strategy to account for time-dependent visual behavior is non-trivial – the results of
SaltiNet [2] exhibit unstable behavior with large displace-ments and scarce focal regions (see Fig. 1). The latter group of methods utilizes the advance of generative models, e.g.,
Generative Adversarial Network (GAN), to predict realis-tic scanpaths. However, such methods show less attention to regions of interests (see Fig. 1). In addition, the GAN-based methods are less flexible in determining the length of scanpaths and commonly suffer from unstable training.
None of above-mentioned studies give a complete treat-ment of the time-dependency of viewing behavior, which is critical for modeling dynamic gaze behaviors in 360◦ im-ages. For time-series data, a popular approach is to leverage sequential models, e.g., recurrent neural networks (RNNs), as exemplified in gaze prediction for 360◦ videos [17, 35, 45]. However, such deterministic models are prone to over-fitting, particularly on small 360◦ databases. More impor-tantly, they typically make simplistic assumptions, e.g., one choice is to concatenate the saliency map to the model’s hid-den states [17, 45], which assumes that the network learns how the states evolve by learning from saliency maps. Nev-ertheless, the neuroscience research [62] reveals that in ad-dition to top-down and bottom-up features, prior history and scene semantics are essential sources for guiding visual at-tention. Moreover, to be identified as interests or rejected as distractors, items must be compared to target templates held in memory [62]. Inspired by this, we argue that hu-mans’ scanpaths in 360◦ scenes are complex nonlinear dy-namic attentional landscapes over time as a function of in-terventions of scene semantics on visual working memory.
We present a probabilistic approach to learning the visual states that encode the time-dependent attentional landscape by specifying how these states evolve under the guidance of scene semantics and visual working memory. We instanti-ate our approach in the Deep Markov Model (DMM) [28], namely ScanDMM. Our contributions can be summarized as follows:
• We present a novel method for time-dependent vi-sual attention modeling for 360◦ images. Specifically, we model the mechanism of visual working memory by maintaining and updating the visual state in the
Markov chain. Furthermore, a semantics-guided tran-sition function is built to learn the nonlinear dynamics of the states, in which we model the interventions of scene semantics on visual working memory.
• We propose a practical strategy to initialize the visual state, facilitating our model to focus on learning the dynamics of states with correct “launcher”, as well as enabling us to assign a specific starting point for scan-path generation. Moreover, ScanDMM is capable of producing 1, 000 variable-length scanpaths within one second, which is critical for real-world applications.
• We apply the proposed ScanDMM to two other com-puter vision tasks – saliency detection and image qual-ity assessment, which demonstrates our model equips with strong generalizability and is expected to provide insights into other vision tasks. 2.