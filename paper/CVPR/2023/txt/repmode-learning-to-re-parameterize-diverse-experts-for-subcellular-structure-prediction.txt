Abstract
In biological research, fluorescence staining is a key technique to reveal the locations and morphology of subcel-lular structures. However, it is slow, expensive, and harm-ful to cells. In this paper, we model it as a deep learning task termed subcellular structure prediction (SSP), aiming to predict the 3D fluorescent images of multiple subcellu-lar structures from a 3D transmitted-light image. Unfortu-nately, due to the limitations of current biotechnology, each image is partially labeled in SSP. Besides, naturally, sub-cellular structures vary considerably in size, which causes the multi-scale issue of SSP. To overcome these challenges, we propose Re-parameterizing Mixture-of-Diverse-Experts (RepMode), a network that dynamically organizes its pa-rameters with task-aware priors to handle specified single-label prediction tasks. In RepMode, the Mixture-of-Diverse-Experts (MoDE) block is designed to learn the generalized parameters for all tasks, and gating re-parameterization (GatRep) is performed to generate the specialized param-eters for each task, by which RepMode can maintain a com-pact practical topology exactly like a plain network, and meanwhile achieves a powerful theoretical topology. Com-prehensive experiments show that RepMode can achieve state-of-the-art overall performance in SSP. 1.

Introduction
Recent years have witnessed great progress in biological research at the subcellular level [1,2,7,21,23,59,61], which plays a pivotal role in deeply studying cell functions and behaviors. To address the difficulty of observing subcellu-*Corresponding Author: gychen@zhejianglab.com
Figure 1. (a) Illustration of subcellular structure prediction (SSP), which aims to predict the 3D fluorescent images of multiple sub-cellular structures from a 3D transmitted-light image. This task faces two challenges, i.e. (b) partial labeling and (c) multi-scale. lar structures, fluorescence staining was invented and has become a mainstay technology for revealing the locations and morphology of subcellular structures [26]. Specifically, biologists use the antibodies coupled to different fluores-cent dyes to ªstainº cells, after which the subcellular struc-tures of interest can be visualized by capturing distinct flu-orescent signals [64]. Unfortunately, fluorescence staining is expensive and time-consuming due to the need for ad-vanced instrumentation and material preparation [29]. Be-sides, phototoxicity during fluorescent imaging is detrimen-tal to living cells [28]. In this paper, we model fluorescence
staining as a deep learning task, termed subcellular struc-ture prediction (SSP), which aims to directly predict the 3D fluorescent images of multiple subcellular structures from a 3D transmitted-light image (see Fig. 1(a)). The adoption of
SSP can significantly reduce the expenditure on subcellular research and free biologists from this demanding workflow.
Such an under-explored and challenging bioimage prob-lem deserves the attention of the computer vision commu-nity due to its high potential in biology. Specifically, SSP is a dense regression task where the fluorescent intensities of multiple subcellular structures need to be predicted for each transmitted-light voxel. However, due to the limita-tions of current biotechnology, each image can only obtain partial labels. For instance, some images may only have the annotations of nucleoli, and others may only have the anno-tations of microtubules (see Fig. 1(b)). Moreover, different subcellular structures would be presented at multiple scales under the microscope, which also needs to be taken into ac-count. For example, the mitochondrion is a small structure inside a cell, while obviously the cell membrane is a larger one since it surrounds a cell (see Fig. 1(c)).
Generally, there are two mainstream solutions: 1) Multi-Net [5,32,33,47]: divide SSP into several individual predic-tion tasks and employs multiple networks; 2) Multi-Head
[6, 9, 46]: design a partially-shared network composed of a shared feature extractor and multiple task-specific heads (see Fig. 2(a)). However, these traditional approaches or-ganize network parameters in an inefficient and inflexible manner, which leads to two major issues. First, they fail to make full use of partially labeled data in SSP, resulting in label-inefficiency. In Multi-Net, only the images contain-ing corresponding labels would be selected as the training set for each network and thus the other images are wasted, leading to an unsatisfactory generalization ability. As for
Multi-Head, although all images are adopted for training, only partial heads are updated when a partially labeled im-age is input and the other heads do not get involved in train-ing. Second, to deal with the multi-scale nature of SSP, they require exhausting pre-design of the network architecture, and the resultant one may not be suitable for all subcellular structures, which leads to scale-inflexibility.
In response to the above issues, herein we propose Re-parameterizing Mixture-of-Diverse-Experts (RepMode), an all-shared network that can dynamically organize its pa-rameters with task-aware priors to perform specified single-label prediction tasks of SSP (see Fig. 2(b)). Specifically,
RepMode is mainly constructed of the proposed Mixture-of-Diverse-Experts (MoDE) blocks. The MoDE block contains the expert pairs of various receptive fields, where these task-agnostic experts with diverse configurations are designed to learn the generalized parameters for all tasks. Moreover, gating re-parameterization (GatRep) is proposed to conduct the task-specific combinations of experts to achieve efficient expert utilization, which aims to generate the specialized parameters for each task. With such a parameter organiz-ing manner (see Fig. 2(c)), RepMode can maintain a practi-cal topology exactly like a plain network, and meanwhile achieves a theoretical topology with a better representa-tional capacity. Compared to the above solutions, RepMode can fully learn from all training data, since the experts are shared with all tasks and thus participate in the training of each partially labeled image. Besides, RepMode can adap-tively learn the preference of each task for the experts with different receptive fields, thus no manual intervention is re-quired to handle the multi-scale issue. Moreover, by fine-tuning few newly-introduced parameters, RepMode can be easily extended to an unseen task without any degradation of the performance on the previous tasks. Our main contri-butions are summarized as follows:
• We propose a stronger baseline for SSP, named Rep-Mode, which can switch different ªmodesº to predict multiple subcellular structures and also shows its po-tential in task-incremental learning.
• The MoDE block is designed to enrich the generalized parameters and GatRep is adopted to yield the special-ized parameters, by which RepMode achieves dynamic parameter organizing in a task-specific manner.
• Comprehensive experiments show that RepMode can achieve state-of-the-art (SOTA) performance in SSP.
Moreover, detailed ablation studies and further analy-sis verify the effectiveness of RepMode. 2.