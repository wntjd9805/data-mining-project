Abstract
We present an approach to learning regular spatial trans-formations between image pairs in the context of medical image registration. Contrary to optimization-based registra-tion techniques and many modern learning-based methods, we do not directly penalize transformation irregularities but instead promote transformation regularity via an inverse consistency penalty. We use a neural network to predict a map between a source and a target image as well as the map when swapping the source and target images. Different from existing approaches, we compose these two resulting maps and regularize deviations of the Jacobian of this composi-tion from the identity matrix. This regularizer – GradICON – results in much better convergence when training registra-tion models compared to promoting inverse consistency of the composition of maps directly while retaining the desir-able implicit regularization effects of the latter. We achieve state-of-the-art registration performance on a variety of real-world medical image datasets using a single set of hyperpa-rameters and a single non-dataset-specific training protocol.
Code is available at https://github.com/uncbiag/ICON. 1.

Introduction
Image registration is a key component in medical image analysis to estimate spatial correspondences between image pairs [14, 53]. Applications include estimating organ motion between treatment fractions in radiation therapy [25, 37], capturing disease progression [64], or allowing for localized analyses in a common coordinate system [19].
Many different registration algorithms have been pro-posed over the last decades in medical imaging [10, 41, 44, 63, 64] and in computer vision [21, 33]. Contributions have focused on different transformation models (i.e., what types of transformations are considered permissible), similarity measures (i.e., how “good alignment” between image pairs is quantified), and solution strategies (i.e., how transforma-tion parameters are numerically estimated). The respective choices are generally based on application requirements as
*Equal Contribution.
Figure 1. Example source (left), target (middle) and warped source (right) images obtained with our method, trained with a single protocol, using the proposed GradICON regularizer. well as assumptions about image appearance and the ex-pected transformation space. In consequence, while reli-able registration algorithms have been developed for trans-formation models ranging from simple parametric models (e.g., rigid and affine transformations) to significantly more complex nonparametric formulations [41, 44, 63] that allow highly localized control, practical applications of registration typically require many choices and rely on significant pa-rameter tuning to achieve good performance. Recent image registration work has shifted the focus from solutions based on numerical optimization for a specific image pair to learn-ing to predict transformations based on large populations of image pairs via neural networks [10, 15, 17, 34, 35, 56, 57, 68].
However, while numerical optimization is now replaced by training a regression model which can be used to quickly pre-dict transformations at test time, parameter tuning remains a
key challenge as loss terms for these two types of approaches are highly related (and frequently the same). Further, one also has additional choices regarding network architectures.
Impressive strides have been made in optical flow estima-tion as witnessed by the excellent performance of recent approaches [34] on Sintel [7]. However, our focus is medical image registration, where smooth and often diffeomorphic transformations are desirable; here, a simple-to-use learning-based registration approach, which can adapt to different types of data, has remained elusive. In particular, nonpara-metric registration approaches require a balance between image similarity and regularization of the transformation to assure good matching at a high level of spatial regularity, as well as choosing a suitable regularizer. This difficulty is compounded in a multi-scale approach where registrations at multiple scales are used to avoid poor local solutions.
Instead of relying on a complex spatial regularizer, the recent ICON approach [23] uses only inverse consistency to regularize the sought-after transformation map, thereby dra-matically reducing the number of hyperparameters to tune.
While inverse consistency is not a new concept in image registration and has been explored to obtain transformations that are inverses of each other when swapping the source and the target images [11], ICON [23] has demonstrated that a sufficiently strong inverse consistency penalty, by itself, is sufficient for spatial regularity when used with a registration network. Further, as ICON does not explicitly penalize spatial gradients of the deformation field, it does not require pre-registration (e.g., rigid or affine), unlike many other related works. However, while conceptually attractive, ICON suf-fers from the following limitations: 1) training convergence is slow, rendering models costly to train; and 2) enforcing approximate inverse consistency strictly enough to prevent folds becomes increasingly difficult at higher spatial res-olutions, necessitating a suitable schedule for the inverse consistency penalty, which is not required for GradICON.
Our approach is based on a surprisingly simple, but ef-fective observation: penalizing the Jacobian of the inverse consistency condition instead of inverse consistency directly1 applies zero penalty for inverse consistent transform pairs but 1) yields significantly improved convergence, 2) no longer re-quires careful scheduling of the inverse consistency penalty, 3) results in spatially regular maps, and 4) improves regis-tration accuracy. These benefits facilitate a unified training protocol with the same network structure, regularization parameter, and training strategy across registration tasks.
Our contributions are as follows:
• We develop GradICON (Gradient Inverse CONsistency), a versatile regularizer for learning-based image registration that relies on penalizing the Jacobian of the inverse consis-1i.e., penalizing deviations from ∇(ΦAB
◦ ΦBA
θ − Id) = 0 instead of deviations from ΦAB
θ
◦ ΦBA
θ
θ − Id = 0. tency constraint and results, empirically and theoretically, in spatially well-regularized transformation maps.
• We demonstrate state-of-the-art (SOTA) performance of models trained with GradICON on three large medical datasets: a knee magnetic resonance image (MRI) dataset of the Osteoarthritis Initiative (OAI) [46], the Human Con-nectome Project’s collection of Young Adult brain MRIs (HCP) [60], and a computed tomography (CT) inhale/ex-hale lung dataset from COPDGene [47]. 2.