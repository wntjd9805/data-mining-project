Abstract
Assisting people in efficiently producing visually plausi-ble 3D characters has always been a fundamental research topic in computer vision and computer graphics. Recent learning-based approaches have achieved unprecedented accuracy and efficiency in the area of 3D real human digiti-zation. However, none of the prior works focus on modeling 3D biped cartoon characters, which are also in great demand in gaming and filming. In this paper, we introduce 3DBiCar, the first large-scale dataset of 3D biped cartoon characters, and RaBit, the corresponding parametric model. Our dataset contains 1,500 topologically consistent high-quality 3D tex-tured models which are manually crafted by professional artists. Built upon the data, RaBit is thus designed with a
SMPL-like linear blend shape model and a StyleGAN-based neural UV-texture generator, simultaneously expressing the shape, pose, and texture. To demonstrate the practicality
*Z. Luo and S. Cai contribute equally.
†Corresponding author. of 3DBiCar and RaBit, various applications are conducted, including single-view reconstruction, sketch-based modeling, and 3D cartoon animation. For the single-view reconstruc-tion setting, we find a straightforward global mapping from input images to the output UV-based texture maps tends to lose detailed appearances of some local parts (e.g., nose, ears). Thus, a part-sensitive texture reasoner is adopted to make all important local areas perceived. Experiments fur-ther demonstrate the effectiveness of our method both quali-tatively and quantitatively. 3DBiCar and RaBit are available at gaplab.cuhk.edu.cn/projects/RaBit. 1.

Introduction
With the rapid development of digitization, creating high-quality 3D articulated characters is highly demanded in game platforms, film industries, and metaverse scenarios. How-ever, even for expert artists, creating a 3D character is labor-intensive and time-consuming. Therefore, reducing the cost of producing visually plausible 3D characters is essential in the field of computer vision and graphics.
Recently, researchers have made great progress in digitiz-ing realistic human characters. The emergence and popular-ity of various 3D sensing devices make capturing 3D data from the real world convenient, prompting a growing number of 3D real-people scanned datasets [3,7,12,43,45,53,54,56].
Based on these large-scale datasets, several powerful para-metric models [5,12,35,39] have been developed to facilitate the reconstruction and analysis of human shapes, actions, and interactions. With the help of parametric models, deep learn-ing techniques have shown the potential to efficiently infer accurate 3D digital humans from single-view images [26,39] or even sparse sketches [9, 24, 48]. Most recently, there are some works [36, 41] that devote to exploring the intelligent generation of cartoon-like character heads. However, none of the prior works focuses on the modeling of 3D full-body biped cartoon characters, which are also in great demand in the area of gaming (e.g., Animal Crossing), filming (e.g.,
Zootopia), and virtualizing (e.g., Metaverse). In this work, we raise a new problem to the community: How to quickly produce 3D biped cartoon characters from easy-to-obtain inputs (e.g., a single image)?
Revisiting the road map of realistic human digitization, the first step to tackling the above problem is building a high-quality 3D biped cartoon characters dataset. We thus introduce 3DBiCar, the first large-scale publicly available 3D biped cartoon character dataset following three criteria: 1) Diversity. 3DBiCar spans a wide range of 3D biped car-toon characters, containing 1,500 high-quality 3D models covering 15 species, as shown in the Fig. 3. 2) Richness.
Each model in 3DBiCar owns not only a detailed shape but also a texture UV-map, which are matched with a reference image. Additionally, each character is attached with two models, one with T-pose and another with the reference pose. 3) Topological-consistency. Each 3D model is created by carefully deforming a pre-defined template mesh. All 3D characters in 3DBiCar are unified in topology, paving the way to learn a skinned parametric model. Fig. 1 shows some representative models of the proposed dataset.
Based on 3DBiCar, we further propose a generative model, dubbed RaBit, for 3D biped cartoon character genera-tion. It combines a linear blend shape model with a neural tex-ture generator and simultaneously parameterizes the shape, pose, and texture to a low-dimensional parametric space. For shape and pose modeling, numerous methods have shown principal component analysis’s (PCA’s) advantage in build-ing decent statistical shape models [5, 12, 32, 39]. Inspired by SMPL [35], we utilize the traditional PCA technique to parameterize shape. Due to the variety and complexity of cartoon texture, directly adopting PCA for texture model-ing fails to reconstruct details and falls into blurry results.
We tackle this problem by introducing a StyleGAN-based generator.
To explore the practical usage of 3DBiCar and RaBit, we first conduct the application of single-view reconstruction.
Considering prior works for SMPL-based human geometry generation from single-view images [6, 26, 30], we build a baseline method with our dataset and the parametric model.
We select one regression-based method for pose and shape inference. For texture inference, we find directly applying a global texture-generator tends to make the results lose de-tailed appearances, especially for some local but important regions (e.g., nose and ears). Thus a part-sensitive reasoner is utilized to deal with different local regions. We term our baseline method for single-view reconstruction as BiCar-Net. Moreover, two further applications, i.e., sketch-based modeling and 3D character animation, are also explored. Ex-perimental results on these applications demonstrate that it is already able to generate reasonable outputs.
To summarize, our contributions include:
• We introduce 3DBiCar, the first large-scale 3D biped cartoon character dataset. It contains 1,500 high-quality textured 3D models with a consistent mesh topology.
• We propose RaBit, the first 3D full-body cartoon para-metric model for biped character modeling. We will release both 3DBiCar and RaBit for future research.
• We build BiCarNet, the baseline method to reconstruct 3D biped cartoon characters from a single-view image.
A part-sensitive reasoner is adopted for detailed texture generation.
• Two other applications, i.e., sketch-based modeling and 3D character animation, are also conducted to demon-strate the promising potential of 3DBiCar and RaBit. 2.