Abstract
Privacy and memory are two recurring themes in a broad conversation about the societal impact of AI. These con-cerns arise from the need for huge amounts of data to train deep neural networks. A promise of Generalized Few-shot
Object Detection (G-FSOD), a learning paradigm in AI, is to alleviate the need for collecting abundant training sam-ples of novel classes we wish to detect by leveraging prior knowledge from old classes (i.e., base classes). G-FSOD strives to learn these novel classes while alleviating catas-trophic forgetting of the base classes. However, existing ap-proaches assume that the base images are accessible, an assumption that does not hold when sharing and storing data is problematic. In this work, we propose the first data-free knowledge distillation (DFKD) approach for G-FSOD that leverages the statistics of the region of interest (RoI) features from the base model to forge instance-level fea-tures without accessing the base images. Our contribution is three-fold: (1) we design a standalone lightweight gener-ator with (2) class-wise heads (3) to generate and replay di-verse instance-level base features to the RoI head while fine-tuning on the novel data. This stands in contrast to standard
DFKD approaches in image classification, which invert the entire network to generate base images. Moreover, we make careful design choices in the novel finetuning pipeline to regularize the model. We show that our approach can dra-matically reduce the base memory requirements, all while setting a new standard for G-FSOD on the challenging MS-COCO and PASCAL-VOC benchmarks. 1.

Introduction
Object detection (OD) is an integral element in mod-ern computer vision perception systems (e.g., robotics and self-driving cars). However, object detectors [1–8] require abundant annotated data to train, which is labor and time
In some applications requiring rare class de-intensive. tection, collecting much data is challenging. Striving to learn in limited data scenarios, few-shot object detection (FSOD) [9] is an uprising field. It mimics the human cog-nitive ability by leveraging prior knowledge from previous
† Authors have equally contributed to this work.
Corresponding author: karim.guirguis@de.bosch.com
Figure 1. The base memory requirements for G-FSOD are dra-matically reduced by our framework, while improving the overall detection performance on MS-COCO (10-shot). We only store a lightweight generator that synthesizes deep features for the RoI head. BF denotes base-data free finetuning. experiences with abundant base data, to rapidly learn novel classes from limited samples. Despite the success of meta-learning [10–15] and transfer learning [16–19] paradigms in
FSOD, most methods prioritize the detection performance of the novel classes while ignoring the catastrophic forget-ting of the base ones. This might lead to critical failure cases in real-life operational perception systems.
To address the aforementioned concern, generalized few-shot object detection (G-FSOD) has been introduced to jointly detect the base and novel classes. One of the first ap-proaches to address the G-FSOD task was TFA [16], which finetunes the detector using a balanced set of base and novel class samples while freezing the backbone and the region proposal network (RPN). While this has reduced forgetting, the performance on novel classes has dropped significantly.
Since then, a plethora of works have attempted to improve the overall detection performance. DeFRCN [19] proposed a gradient manipulation approach to modify the RPN and
RoI head gradients. Retentive R-CNN [22], a knowledge distillation approach and CFA [23], a gradient manipula-tion approach were proposed to explicitly tackle the catas-trophic forgetting of base classes. However, all the above approaches rely on the assumption that base data is avail-able while learning the new classes. This made us raise the following question: How to alleviate forgetting without base data in case of a memory constraint or privacy con-cerns restricting the storage and replay of old base data?
Our two key insights are as follows. First, we show that the statistics of instance-level RoI head features sufficiently represent the distribution of base classes. Second, we show that a standalone lightweight generator can be trained in a distillation fashion to match the gathered statistics and syn-thesize class-wise base features to train a G-FSOD model.
This stands in contrast to MI approaches which optimize the pre-trained model to synthesize high-fidelity images. Our contributions are summarized as follows: 1. We forge instance-level features instead of synthesiz-ing images (Fig. 2) as the feature space (1024 × 7 × 7) is much smaller than the image space (3×600×1000). 2. Rather than inverting the whole model, instead we de-sign a standalone lightweight generator in the feature space to forge instance-level base features. The gen-erator is able to better capture the feature distribution than the complex MI. 3. We equip the generator with class-aware heads rather than a class-agnostic one, and we train it to synthesize features with a distribution that matches the class-wise statistics of the pre-trained base RoI head, hence pro-moting feature diversity. We demonstrate that class-aware heads trained on class-aware statistics outper-form a shared model trained on class-wise statistics. 4. We dramatically reduce the overall memory footprint by two orders of magnitude while setting a new stan-dard for the overall detection performance in G-FSOD on MS-COCO [27] and PASCAL-VOC [28]. For in-stance, the base images and annotations for MS-COCO dataset (10-shot) are ∼ 150MB large, while our gener-ator parameters only occupy ∼ 4MB. 2.