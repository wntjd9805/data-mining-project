Abstract
Modeling non-Lambertian effects such as facial specu-larity leads to a more realistic 3D Morphable Face Model.
Existing works build parametric models for diffuse and specular albedo using Light Stage data. However, only dif-fuse and specular albedo cannot determine the full BRDF.
In addition, the requirement of Light Stage data is hard to fulfill for the research communities. This paper proposes the first 3D morphable face reflectance model with spa-tially varying BRDF using only low-cost publicly-available data. We apply linear shiness weighting into parametric modeling to represent spatially varying specular intensity and shiness. Then an inverse rendering algorithm is devel-oped to reconstruct the reflectance parameters from non-Light Stage data, which are used to train an initial mor-phable reflectance model. To enhance the model’s gener-alization capability and expressive power, we further pro-pose an update-by-reconstruction strategy to finetune it on an in-the-wild dataset. Experimental results show that our method obtains decent rendering results with plausible fa-cial specularities. Our code is released here. 1.

Introduction 3D Morphable Face Models (3DMM) [4, 19] have at-tracted much attention in the past two decades, as it pro-vides a powerful and compact statistical prior of 3D face geometry and appearance with dense point-to-point corre-spondence to various downstream applications like face re-construction [14,22,52,55,56], rendering [13,53,57,58,70], and animation [3,7,9,20,21,68]. Existing works [52,54,55] have demonstrated promising results for improving the gen-eralization capability and expressive power of 3DMM under the assumption that faces are Lambertian surfaces. How-ever, it is still challenging to model non-Lambertian effects such as facial specularity in 3DMM, which can lead to a more realistic face model.
A few recent works [37, 50] involve non-Lambertian fa-cial reflectance in the morphable face model. Using a Light
Stage [11, 24, 39], they capture diffuse and specular albedo maps of tens of participants. Then, they model the dif-fuse and specular albedo by training a PCA model [50] or a deep generative network [37] on the acquired data.
However, only the diffuse and specular albedo cannot de-termine the complete Bidirectional Reflectance Distribution
Function (BRDF). Thus, other works [15–17] set the re-maining reflectance parameters (e.g. specular exponent for the Blinn-Phong BRDF [5], roughness for the Torrance-Sparrow BRDF [59]) of all face vertices to a reasonable value to characterize specular shiness and obtain the com-plete BRDF. As shown in Figure 7, these spatially uniform parameters lead to unpleasing rendering results since face reflectance is inherently spatially varying [65]. Besides, the
requirement of Light Stage data is hard to fulfill since build-ing a Light Stage is quite difficult, and no publicly available
Light Stage dataset is sufficient to construct a 3DMM.
To overcome these limitations, we propose and train the first morphable face reflectance model with spatially vary-ing BRDF from low-cost publicly-available data. Inspired by previous works [41, 42], we represent face reflectance as a Lambertian BRDF combined with the linear combination of several Blinn-Phong BRDFs corresponding to different predefined specular exponents. Thus, the reflectance pa-rameters of each face vertex include an RGB color for the
Lambertian BRDF and a set of weights for the Blinn-Phong
BRDFs. As illustrated in Figure 2, our representation can naturally modulate specular intensity and shiness by adjust-ing the absolute and relative scales of the linear combination weights, respectively. Compared to previous works [37, 50] not modeling specular shiness, we define a complete BRDF by this representation in 3DMM. Compared to the tradi-tional Blinn-Phong BRDF that models specular intensity and shiness in a nonlinear formulation [5], our linear rep-resentation (Equation (2)) is much easier to reconstruct the reflectance parameters from recorded images. With this lin-ear reflectance representation, we develop an inverse ren-dering approach to estimate the spatially varying reflectance parameters for the 128 selected identities in Multi-PIE [25], a public dataset with face images captured under controlled camera views and light directions. Then, we learn a PCA model for the estimated reflectance parameters as our initial morphable face reflectance model.
Considering that the Multi-PIE dataset only contains 128 identities which is far from sufficient to capture the vari-ability of human faces, we propose to finetune the initial model on a large-scale in-the-wild dataset, FFHQ [29], to improve its generalization capability and expressive power.
As the inputs are in-the-wild images with unknown lighting information, it is not easy to reconstruct accurate reflectance from them. Our key observation is that, on the one hand, we already have an initial parametric reflectance model that can better formulate the reflectance reconstruction from in-the-wild images. On the other hand, the reconstructed re-flectance from in-the-wild data could provide feedback to enhance the face prior knowledge in our morphable re-flectance model. Based on this observation, we jointly re-construct the face reflectance coefficients and update the pa-rameters of our morphable face reflectance model (the mean and bases). Another challenge here is to predict high-order spherical harmonics (SH) lighting [44] for in-the-wild im-ages, which is crucial for updating the high-frequency in-formation of our non-Lambertian reflectance model [45].
To solve this problem, we build another PCA model for real-world environment lighting in SH coefficients space, which largely reduces the searching space of the high-order
SH coefficients. During face reconstruction, we first predict the parameters of the PCA lighting model and then retrieve the high-order SH coefficients from it. Finally, the in-the-wild images are well reconstructed with our parametric re-flectance model, and the model itself is also updated gradu-ally in this process to achieve high generalization capability and expressive power.
In summary, our contributions include:
• We propose the first 3D morphable face reflectance model with spatially varying BRDF and a technique to train the model with low-cost publicly-available data.
• We apply linear shiness weighting into parametric face modeling to represent spatially varying specular shi-ness and intensity and ease the process of reconstruct-ing reflectance from images.
• We propose an update-by-reconstruction strategy to finetune our face reflectance model on an in-the-wild dataset, improving its generalization capability and ex-pressive power. 2.