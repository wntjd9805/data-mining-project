Abstract
Open vocabulary object detection has been greatly ad-vanced by the recent development of vision-language pre-trained model, which helps recognize novel objects with only semantic categories. The prior works mainly focus on knowledge transferring to the object proposal classification and employ class-agnostic box and mask prediction. In this work, we propose CondHead, a principled dynamic network design to better generalize the box regression and mask seg-mentation for open vocabulary setting. The core idea is to conditionally parameterize the network heads on semantic embedding and thus the model is guided with class-specific knowledge to better detect novel categories. Specifically,
CondHead is composed of two streams of network heads, the dynamically aggregated head and dynamically gener-ated head. The former is instantiated with a set of static heads that are conditionally aggregated, these heads are optimized as experts and are expected to learn sophisticated prediction. The latter is instantiated with dynamically gen-erated parameters and encodes general class-specific infor-mation. With such a conditional design, the detection model is bridged by the semantic embedding to offer strongly gen-eralizable class-wise box and mask prediction. Our method brings significant improvement to the state-of-the-art open vocabulary object detection methods with very minor over-head, e.g., it surpasses a RegionClip model by 3.0 detection
AP on novel categories, with only 1.1% more computation. 1.

Introduction
Given the semantic object categories of interest, object detection aims at localizing each object instance from the input images. The prior research efforts mainly focus on the close-set setting, where the images containing the interested object categories are annotated and used to train a detector.
The obtained detector only recognizes object categories that are annotated in the training set. In such a setting, more data needs to be collected and annotated if novel category1 needs 1we treat category and class interchangeably in this paper
Figure 1.
Illustration of our main intuition. Given the object proposals, the bounding box regression and mask segmentation learned from some object categories could generalize to the tar-get category. For example, the knowledge learned from a chicken could help detect and segment the long thin feet and the small head of an ibis (upper row). Similarly for the hairbrush, the knowledge learned from the toothbrush could better handle the extreme aspect ratio and occlusion from the hand (lower row). to be detected. However, data collection and annotation are very costly for object detection, which raises a significant challenge for traditional object detection methods.
To address the challenge, the open vocabulary object de-tection methods are widely explored recently, these meth-ods [1, 7, 9, 11, 14, 21, 23, 30â€“32] aim at generalizing ob-ject detection on novel categories by only training on a set of labeled categories. The core of these methods is trans-ferring the strong image-text aligned features [16, 22] to classify objects of novel categories. To achieve bound-ing box regression and mask segmentation on novel cat-egories, they simply employ the class-agnostic network heads. Although class agnostic heads can be readily ap-plied to novel target object categories, they offer limited capacity to learn category-specific knowledge like object
Figure 2. Overview of CondHead. To detect objects of novel categories, we aim at conditionally parameterizing the bounding box regression and mask segmentation based on the semantic embedding, which is strongly correlated with the visual feature and provides effective class-specific cues to refine the box and predict the mask. shape, and thus provide sub-optimal performance. On the other hand, training class-wise heads is not feasible as we do not have bounding box and mask annotation for the tar-get categories. As shown in Figure 1, our intuition is that the class-wise knowledge could naturally generalize across object categories, and may be leveraged to achieve much higher quality box regression and mask segmentation on the target categories, in a category-specific manner. However, we find a brute force way of training class-wise heads on the base categories and manually gathering the class-specific prediction with closet semantic similarity during inference provides limited gain. The reason is that there still remains gap between the base and target categories, such as appear-ance and context.
Motivated by the strong semantic-visual aligned repre-sentation [7, 11, 31, 32] in open vocabulary object detection, we propose to exploit the semantic embedding as a condi-tional prior to parameterize class-wise bounding box regres-sion and mask segmentation. Such conditioning is learned on base categories and easily generalizes to novel cate-gories with the semantic embedding. Our method, named
CondHead, is based on dynamic parameter generation of neural networks [5, 6, 15, 17, 29]. To achieve strong ef-ficiency, it exploits both large complex network head for their representative power and small light network head for their efficiency. The complex head is employed by condi-tional weight aggregation over a set of static heads. The light head is employed by dynamically basing its param-eters on the semantic embedding. The final prediction is obtained by combining the predictions from the two stream results. Through optimization on the base categories, the set of static heads are expected to learn sophisticated expert knowledge to cope with complex shapes and appearance, the dynamic head is endowed with general class-specific knowledge such as color and context.
Our CondHead is flexible regarding the choice of semantic-visual representation. The stronger quality of the aligned representation is expected to bring higher perfor-mance, as the conditional knowledge from the semantic embedding could generalize better to the target visual fea-tures. This is demonstrated by the clear grow of improve-ment over three baselines with increasing quality of pre-trained semantic-visual encoder networks, OVR-CNN [31],
ViLD [11] and RegionCLIP [32], on both COCO [19] and
LVIS [12] datasets. Remarkably, CondHead brings an av-erage 2.8 improvement w.r.t both box and mask AP for the strong RegionCLIP baseline, with only about 1% more computation. We also demonstrate intriguing qualitative re-sults, showing how the semantic conditioning positively af-fects the regression and segmentation tasks.
Our contributions are three-fold. 1) To the best of our knowledge, we are the first to leverage semantic-visual aligned representation for open vocabulary box regression 2) We design a differentiable and mask segmentation. semantic-conditioned head design to efficiently bridge the strong category-specific prediction learned on base cate-gories to the target novel categories. 3) We extensively val-idate the proposed method on various benchmark datasets and conduct thorough ablation and analysis to understand how the semantic conditioning helps detect and segment the novel categories. 2.