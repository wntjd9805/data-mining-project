Abstract
When taking a picture, any camera shake during the shutter time can result in a blurred image. Recovering a sharp image from the one blurred by camera shake is a chal-lenging yet important problem. Most existing deep learning methods use supervised learning to train a deep neural net-work (DNN) on a dataset of many pairs of blurred/latent images. In contrast, this paper presents a dataset-free deep learning method for removing uniform and non-uniform blur effects from images of static scenes. Our method in-volves a DNN-based re-parametrization of the latent image, and we propose a Monte Carlo Expectation Maximization (MCEM) approach to train the DNN without requiring any latent images. The Monte Carlo simulation is implemented via Langevin dynamics. Experiments showed that the pro-posed method outperforms existing methods signiﬁcantly in removing motion blur from images of static scenes. 1.

Introduction
Motion blur occurs when the camera shakes during the shutter time, resulting in a blurring effect. Blur is uniform when the scene depth is constant and moves along the im-age plane. For other camera movements, the blur is non-uniform. In dynamic scenes with moving objects, the blur is also non-uniform. Different types of motion blur are illus-trated in Figure 1. This paper aims to address the problem of removing uniform and non-uniform motion blur caused by camera shake from an image. Removing motion blur from an image is a blind deblurring problem. It is a chal-lenging task as it requires estimating two unknowns the la-tent image and blurring operator from a single input.
Deep learning, particularly supervised learning, has re-cently emerged as a powerful tool for solving various im-age restoration problems, including blind deblurring. Many of these works rely on supervised learning, as seen in e.g. [1–15]. Typically, these supervised deep learning meth-ods train a deep neural network (DNN) on a large number of training samples, which consist of pairs of latent/blur im-ages. Furthermore, to address general blurring effects, most (a) (b) (c)
Figure 1. Different motion-blurring effects. (a)–(b) Uniform and non-uniform blurring caused by camera shake; (c) Non-uniform blurring of the dynamic scene (not addressed in this paper). methods take a physics-free approach. In other words, these methods directly learn a model that maps a blurred image to a latent image without using any prior information about the blurring process.
The advantage of a physics-free supervised learning method is its ability to handle many types of motion blur effects. However, it has a signiﬁcant disadvantage: to achieve good generalization, the training dataset must cover all motion-blurring effects. Because motion blur is de-termined by both 3D camera motion (six parameters) and scene depth, which can vary signiﬁcantly among images, an enormous number of training samples are required to ad-equately cover the motion blur effects. This task can be very costly and challenging. One possible solution is to synthe-size blurred images. However, as shown in [16], a model trained on samples synthesized using existing techniques (e.g. [17]) does not generalize well to real-world images.
Some approaches consider the physics of motion blur.
Phong et al. [18] proposed learning a family of blurring op-erators in an encoded blur kernel space, and Li et al. [19] proposed learning a more general class of degradation op-erators from input images. However, these physics-aware methods also rely on supervised learning and thus face the same dataset limitations as the physics-free methods. 1.1. Discussion on existing dataset free methods
Motivated by the challenge of practical data collec-tion, there is a growing interest in relaxing the require-ment for training data when developing deep learning solu-tions for motion deblurring. Some approaches require spe-ciﬁc data acquisition, such as multiple frames of the same scene [20], while others are semi-supervised, relying on un-paired training samples with ground truth images for train-ing a GAN [21]. There are also a few works on dataset-free deep learning methods for uniform blind image deblurring; see e.g. [22–24].
When training a DNN to deblur an image without see-ing ground truth images, it is necessary to incorporate prior knowledge of the physics of motion blur. However, existing dataset-free methods [22] for blind deblurring are limited to uniform blur, where the blur process is modeled by a convo-lution: g = k f , where f denotes the latent image, g de-notes the input, and k denotes the blur kernel. Uniform mo-tion blur only occurs when the scene depth is constant and camera motion is limited to in-image translation, making it not applicable to more complex camera motion. Moreover, these methods have a lot of room for improvement, as they do not achieve competitive performance compared to state-of-the-art non-learning methods.
⊗ 1.2. Main idea
In this paper, our goal is to develop a dataset-free deep learning method for removing motion blur from a single im-age, caused by general camera shake. Similar to existing dataset-free methods, when training a DNN to deblur an image without seeing any truth image, some prior knowl-edge about the physics of motion blur needs to be utilized.
In this paper, we limit our study to recovering images of static scenes without any moving objects. In our proposed approach, we utilize the so-called space-variant overlap-add (SVOLA) formulation [25, 26] to model motion blur of static scenes. This formulation describes the relationship between a blurred image g and its corresponding latent im-age f as follows: g = F (f , K) + n = ki
P (w( ci)
· −
⊙ P
⊗ if ) + n, (1)
P
⊗ i=1
X denotes entry-wise multiplication, denotes con-Here,
⊙ i is a mask operator that extracts the i-th volution, and patch from the image. ki is the i-th kernel and w( ci) is a window function that is translated to align with the center ci of the i-th image patch. The window function w is nor-ci) = 1, for example, using malized such that
· − the 2D Modiﬁed Bartlett-Hanning window [27]. When all
P
P kernels i=1 are the same, the SVOLA model degen-} erates to the case of uniform blurring:
P i=1 w(
· −
P ki
{ g = k f . (2)
⊗
For an SVOLA-based model, there are two unknowns: the latent image f and the kernel set K =
Similar to existing works, such as Double-DIP for im-age decomposition and Ren et al. for uniform deblurring, we re-parameterize the latent image and kernel set using kj
{
P j=1.
} two DNNs. This DNN-based re-parametrization is moti-vated by the implicit prior induced by convolutional neural networks (CNNs), known as the deep image prior (DIP).
However, the regularization effect induced by DIP alone is not sufﬁcient to avoid likely overﬁtting. One approach is to introduce additional regularization drawn inspiration from traditional non-learning methods.
Discussion on MAP-relating methods. consider the case of uniform blur where g = k
ML (maximum likelihood) estimator of the pair (k, f ) by
For simplicity, f . As the
⊗ max k,f log p(g k, f )
| (3) does not resolve solution ambiguity of blind deblurring, most non-learning methods are based on the maximum a posteriori (MAP) estimator, which estimates (k, f ) by log p(k).
|
|
− k, f ) k,f − log p(g log p(f ) log p(k, f g) = min max k,f
An MAP estimator requires the deﬁnition of two prior dis-tributions: p(k) and p(f ). A commonly used prior distribu-tion for motion deblurring assumes that f follows a Lapla-cian distribution: log p(f )
∥1, also known as total variation (TV) regularization. Such a TV-based MAP esti-mator is proposed in [22] for blind uniform deblurring.
∝ −∥∇
− f
There are two concerns about a TV-relating MAP esti-mator. One is the pre-deﬁned TV regularization for latent images limits the beneﬁt of data adaptivity brought by a
DNN. The other is the possible convergence to an incor-rect local minimum far away from the truth (f , k) or even degenerated trivial solution (g, δ). Indeed, the second is-sue has been extensively discussed in existing works; see e.g. [28–30].
From MAP estimator of (f , K) to EM algorithm for
ML estimator of K. Besides MAP, many other statisti-cal inference schemes have also been successfully used for blind uniform deblurring, e.g. variational Bayesian infer-ence [30, 31]; and EM algorithm [32]. EM is an iterative scheme to ﬁnd maximum likelihood (ML) estimate with the introduction of latent variables. For blind deblurring, EM aims at ﬁnding ML estimate of the marginal likelihood of the unknown parameter K only by marginalizing over the image f (latent variable).
Our approach. Inspired by the effectiveness of the EM al-gorithm and marginal likelihood optimization for uniform deblurring in terms of performance and stability, we pro-pose to use the EM algorithm as a guide to develop a self-supervised learning approach. Speciﬁcally, we introduce a dataset-free deep learning method for both uniform and non-uniform blind motion deblurring, which is based on the Monte Carlo expectation maximization (MCEM) algo-rithm. In summary, our method is built upon the efﬁcient
EM algorithm in DNN-based representation of latent image and blurring operator.
1.3. Main contribution
In this paper, we present a self-supervised deep learning approach for restoring motion-blurred images. Our main contributions can be summarized as follows: 1. The ﬁrst dataset-free deep learning method for removing general motion blur (uniform and non-uniform) from im-ages due to camera shake. To our knowledge, all existing dataset-free methods are limited to uniform motion blur. 2. The ﬁrst approach that combines DNN-based re-parametrization and EM algorithm, bridging the gap be-tween classical non-learning algorithms and deep learn-ing. The proposed MCEM-based deep learning method can see its applications in other image recovery tasks. 3. A powerful method that signiﬁcantly outperforms exist-ing solutions for blind motion deblurring. Our method demonstrates superior performance in recovering images affected by both uniform and non-uniform motion blur. 2.