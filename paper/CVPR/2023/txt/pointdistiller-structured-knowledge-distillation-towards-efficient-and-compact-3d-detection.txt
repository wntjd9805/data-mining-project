Abstract
The remarkable breakthroughs in point cloud represen-tation learning have boosted their usage in real-world ap-plications such as self-driving cars and virtual reality. How-ever, these applications usually have a strict requirement for not only accurate but also efficient 3D object detec-tion. Recently, knowledge distillation has been proposed as an effective model compression technique, which trans-fers the knowledge from an over-parameterized teacher to a lightweight student and achieves consistent effectiveness in 2D vision. However, due to point clouds’ sparsity and irregularity, directly applying previous image-based knowl-edge distillation methods to point cloud detectors usually leads to unsatisfactory performance. To fill the gap, this paper proposes PointDistiller, a structured knowledge dis-tillation framework for point clouds-based 3D detection.
Concretely, PointDistiller includes local distillation which extracts and distills the local geometric structure of point clouds with dynamic graph convolution and reweighted learning strategy, which highlights student learning on the crucial points or voxels to improve knowledge distillation efficiency. Extensive experiments on both voxels-based and raw points-based detectors have demonstrated the effective-ness of our method over seven previous knowledge distilla-tion methods. For instance, our 4× compressed PointPillars student achieves 2.8 and 3.4 mAP improvements on BEV and 3D object detection, outperforming its teacher by 0.9 and 1.8 mAP, respectively. Codes are available in https:
//github.com/RunpeiDong/PointDistiller. 1.

Introduction
The growth in large-scale lidar datasets [14] and the achievements in end-to-end 3D representation learning [46, 47] have boosted the developments of point cloud based seg-mentation, generation, and detection [25, 48]. As one of the essential tasks of 3D computer vision, 3D object detection
†The first two authors contribute equally. This work is done during the internship of L. Zhang in DIDI. K. Ma is the corresponding author.
Figure 1. Experimental results (mAP of moderate difficulty) of our methods on 4×, 8×, and 16× compressed students on KITTI. The area of dash lines indicates the benefits of knowledge distillation. plays a fundamental role in real-world applications such as autonomous driving cars [3, 6, 14] and virtual reality [43].
However, recent research has shown a growing discrepancy between cumbersome 3D detectors that achieve state-of-the-art performance and lightweight 3D detectors which are affordable in real-time applications on edge devices. To ad-dress this problem, sufficient model compression techniques have been proposed, such as network pruning [18,35,37,73], quantization [8,12,40], lightweight model design [21,38,51], and knowledge distillation [20].
Knowledge distillation, which aims to improve the per-formance of a lightweight student model by training it to mimic a pre-trained and over-parameterized teacher model, has evolved into one of the most popular and effective model compression methods in both computer vision and natu-ral language processing [20, 50, 52, 66]. Sufficient theoret-ical and empirical results have demonstrated its effective-ness in image-based visual tasks such as image classifica-tion [20, 50], semantic segmentation [33] and object detec-tion [1, 5, 28, 71]. However, compared with images, point clouds have their properties: (i) Point clouds inherently lack topological information, which makes recovering the local topology information crucial for the visual tasks [26, 39, 65]. (ii) Different from images that have a regular structure, point clouds are irregularly and sparsely distributed in the metric space [13, 15].
These differences between images and point clouds have hindered the image-based knowledge distillation methods from achieving satisfactory performance on point clouds and also raised the requirement to design specific knowledge dis-tillation methods for point clouds. Recently, a few methods have been proposed to apply knowledge distillation to 3D
Extensive experiments on both voxels-based and raw-points based detectors have been conducted to demonstrate the effectiveness of our method over the previous seven knowledge distillation methods. As shown in Figure 1, on
PointPillars and SECOND detectors, our method leads to 4× compression and 0.9∼1.8 mAP improvements at the same time. On PointRCNN, our method leads to 8× compression with only 0.2 BEV mAP drop. Our main contributions be summarized as follows.
• We propose local distillation, which firstly encodes the local geometric structure of point clouds with dynamic graph convolution and then distills them to students.
• We propose reweighted learning strategy to handle the sparsity and noise in point clouds. It highlights stu-dent learning on the voxels, which have more points inside them, by giving them higher learning weights in knowledge distillation.
• Extensive experiments on both voxels-based and raw points-based detectors have been conducted to demon-strate the performance of our method over seven previ-ous methods. Besides, we have released our codes to promote future research. 2.