Abstract
Self-supervised facial representation has recently at-tracted increasing attention due to its ability to perform face understanding without relying on large-scale anno-tated datasets heavily. However, analytically, current contrastive-based self-supervised learning (SSL) still per-forms unsatisfactorily for learning facial representation.
More specifically, existing contrastive learning (CL) tends to learn pose-invariant features that cannot depict the pose details of faces, compromising the learning performance.
To conquer the above limitation of CL, we propose a novel
Pose-disentangled Contrastive Learning (PCL) method for general self-supervised facial representation. Our PCL first devises a pose-disentangled decoder (PDD) with a deli-cately designed orthogonalizing regulation, which disen-tangles the pose-related features from the face-aware fea-tures; therefore, pose-related and other pose-unrelated fa-cial information could be performed in individual subnet-works and do not affect each other’s training. Furthermore, we introduce a pose-related contrastive learning scheme that learns pose-related information based on data augmen-tation of the same image, which would deliver more effective face-aware representation for various downstream tasks.
We conducted linear evaluation on four challenging down-stream facial understanding tasks, i.e., facial expression recognition, face recognition, AU detection and head pose estimation. Experimental results demonstrate that PCL sig-nificantly outperforms cutting-edge SSL methods. Our Code is available at https://github.com/DreamMr/PCL. 1.

Introduction
Human face perception and understanding is an impor-tant and long-lasting topic in computer vision. By analyzing
*Equally-contributed first authors
†Corresponding author
Figure 1. The motivation of our method. Affected by differ-ent poses, the popular CL method, e.g., SimCLR, treats pose and other face information uniformly, resulting in sub-optimal results.
To alleviate this limitation for CL, our PCL attempts to disentan-gle the learning on pose-related features and pose-unrelated facial features, thus achieving more effective self-supervised facial rep-resentation learning for downstream facial tasks. faces, we can obtain various kinds of information, including identities, emotions, and gestures. Recently, deep convolu-tional neural networks (DCNNs) [20, 30, 62] have achieved promising facial understanding results, but they require a large amount of annotated data for model training. Since labeling face data is generally a labor- and time-costly pro-cess [61], it becomes important to enable DCNN models to learn from unlabelled face images, which are much easier to collect. Accordingly, researchers have introduced self-supervised learning (SSL) schemes to achieve better learn-ing performance on unlabeled facial data.
To achieve effective SSL performance, contrastive learn-ing (CL) based strategy is widely applied in the community
[6,26,43]. In general, a CL-based method pulls two features representing similar samples closer to each other and pushes those of diverse samples far away from each other [56], thus facilitating the DCNNs to learn various visual patterns without annotations. Generally, without supervision, simi-lar/positive samples of CL are obtained by augmenting the same image, and the diverse/negative samples can refer to different images. To learn from unlabelled face images, ex-isting CL-based methods [48,53,65] have achieved effective self-supervised facial representation learning.
However, despite progress, we found that directly uti-lizing CL-based methods still obtained sub-optimal perfor-mance due to the facial poses. In particular, CL-based meth-ods treat the augmented images from the same image as positive samples.
In such a manner, the learned features are pose-invariant, which cannot recognize the variances of facial poses. Nevertheless, poses are one significant con-sideration for facial understanding [1, 51]; for example, a person tends low their head when they feel sad.
To tackle the above limitation of CL, we propose a Pose-disentangled Contrastive Learning (PCL) method, which disentangles the learning on pose-related features and pose-unrelated facial features for CL-based self-supervised facial representation learning. Fig. 1 has shown an intuitive exam-ple of contrastive learning results. Specifically, Our method introduces two novel modules, i.e., a pose-disentangled de-coder (PDD) and a pose-related contrastive learning scheme (see Fig. 2).
In the PDD, we first obtain the face-aware features from a backbone, such as ResNet [10, 27], Trans-former [11, 16–18, 40], and then disentangle pose-related features and pose-unrelated facial features from the face-aware features using two different subnets through facial reconstruction. In facial reconstruction, the combination of one pose-unrelated facial feature and one pose-related fea-ture can reconstruct an image with the same content as the pose-unrelated facial feature and the same pose as the pose-related feature. Furthermore, an orthogonalizing regulation is designed to make the pose-related and pose-unrelated fea-tures more independent.
In the pose-related contrastive learning, instead of learn-ing pose-invariant features by normal CL, we introduce two types of data augmentation for one face image, one containing pose augmentation and another only containing pose-unrelated augmentation. Therefore, image pairs gen-erated by using pose augmentation contain different poses and serve as negative pairs, whereas image pairs generated from pose-unrelated augmentation contain the same pose as the original image and are treated as positive pairs. The pose-related CL is conducted to learn pose-related features, and face CL is used to learn pose-unrelated facial features.
Therefore, our proposed pose-related CL can learn detailed pose information without disturbing the learning of pose-unrelated facial features in the images.
In general, the major contributions of this paper are sum-marized as follows: 1. We propose a novel pose-disentangled contrastive learning framework, termed PCL, for learning unla-beled facial data. Our method introduces an effec-tive mechanism that could disentangle pose features from facial features and enhance contrastive learning for pose-related facial representation learning. 2. We introduce a PDD using facial image reconstruction with a delicately designed orthogonalizing regulation to help effectively identify and separate the face-aware features obtained from the backbone into pose-related and pose-unrelated facial features. The PDD is easy-to-implement and efficient for head pose extraction. 3. We further propose a pose-related contrastive learn-ing scheme for pose-related feature learning. Together with face contrastive learning on pose-unrelated facial features, we make both learning schemes cooperate with each other adaptively and obtain more effective learning performance on the face-aware features. 4. Our PCL can be well generalized to several down-stream tasks, e.g., facial expression recognition (FER), facial AU detection, facial recognition, and head pose estimation. Extensive experiments show the superior-ity of our PCL over existing SSL methods, accessing state-of-the-art performance on self-supervised facial representation learning. 2.