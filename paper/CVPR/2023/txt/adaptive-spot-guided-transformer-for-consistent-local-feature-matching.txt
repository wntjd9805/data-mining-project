Abstract 1.

Introduction
Local feature matching aims at finding correspondences between a pair of images. Although current detector-free methods leverage Transformer architecture to obtain an im-pressive performance, few works consider maintaining lo-cal consistency. Meanwhile, most methods struggle with large scale variations. To deal with the above issues, we propose Adaptive Spot-Guided Transformer (ASTR) for lo-cal feature matching, which jointly models the local consis-tency and scale variations in a unified coarse-to-fine archi-tecture. The proposed ASTR enjoys several merits. First, we design a spot-guided aggregation module to avoid in-terfering with irrelevant areas during feature aggregation.
Second, we design an adaptive scaling module to adjust the size of grids according to the calculated depth information at fine stage. Extensive experimental results on five stan-dard benchmarks demonstrate that our ASTR performs fa-vorably against state-of-the-art methods. Our code will be released on https://astr2023.github.io.
*Equal Contribution
â€ Corresponding Author
Local feature matching (LFM) is a fundamental task in computer vision, which aims to establish correspondence for local features across image pairs. As a basis for many 3D vision tasks, local feature matching can be applied in
Structure-from-Motion (SfM) [49], 3D reconstruction [13], visual localization [48, 51], and pose estimation [18, 41].
Because of its broad applications, local feature matching has attracted substantial attention and facilitated the devel-opment of many researches [14, 27, 42, 44, 50]. However, finding consistent and accurate matches is still difficult due to various challenging factors such as illumination varia-tions, scale changes, poor textures, and repetitive patterns.
To deal with the above challenges, numerous matching methods have been proposed, which can be generally cat-egorized into two major groups, including detector-based matching methods [2, 14, 15, 39, 42, 47] and detector-free matching methods [9, 23, 27, 43, 44, 50]. Detector-based matching methods require to first design a keypoint de-tector to extract the keypoints between two images, and then establish matches between these extracted keypoints.
The quality of detected keypoints will significantly af-fect the performance of detector-based matching methods.
Therefore, many works aim to improve keypoint detection through multi-scale detection [36], repeatable and reliable
verification [42]. Thanks to the high-quality keypoints de-tected, these methods can achieve satisfactory performance while maintaining high computational and memory effi-ciency. However, these detector-based matching methods may have difficulty in finding reliable matches in textureless areas, where keypoints are challenging to detect. Differ-ently, detector-free matching methods do not need to detect keypoints and try to establish pixel-level matches between local features. In this way, it is possible to establish matches in the texture-less areas. Due to the power of attention in capturing long-distance dependencies, many Transformer-based methods [9, 50, 52, 57] have emerged in recent years.
As a representative work, considering the computation and memory costs, LoFTR [50] applies Linear Transformer [25] to aggregate global features at the coarse stage and then crops fixed-size grids for further refinement. To alleviate the problem caused by scale changes, COTR [24] calculate the co-visible area iteratively through attention mechanism.
The promising performance of Transformer-based methods proves that attention mechanism is effective on local feature matching. Nevertheless, some recent works [28, 60] indi-cate Transformer lacks spatial inductive bias for continuous dense prediction tasks, which may cause inconsistent local matching results.
By studying the previous matching methods, we sum up two issues that are imperative for obtaining the dense cor-respondence between images. (1) How to maintain local consistency. The correct matching result usually satisfies the local matching consistency, i.e., for two similar adja-cent pixels, their matching points are also extremely close to each other. Existing methods [24,50,57] utilize global at-tention in feature aggregation, introducing many irrelevant regions that affect feature updates. Some pixels are dis-turbed by noisy or similar areas and aggregate information from wrong regions, leading to false matching results. As shown in Figure 1 (b), for two adjacent similar pixels, high-lighted regions of global linear attention are decentralized and inconsistent with each other. The inconsistency is also present in vanilla attention (see Figure 1 (c)). Therefore, it is necessary to utilize local consistency to focus the attention area on the correct place. (2) How to handle scale vari-ation. In a coarse-to-fine architecture, since the attention mechanism at the coarse stage is not sensitive to scale vari-ations, we should focus on the fine stage. Previous meth-ods [9, 27, 50, 57] select fixed-size grids for matching at the fine stage. However, when the scale varies too much across images, the correct match point may be out of the range of the grid, resulting in matching failure. Hence, the scheme of cropping grids should be adaptively adjusted according to scale variation across views.
To deal with the above issues, we propose a novel Adap-tive Spot-guided Transformer (ASTR) for consistent local feature matching, including a spot-guided aggregation mod-ule and an adaptive scaling module. In the spot-guided ag-gregation module, towards the goal of maintaining local consistency, we design a novel attention mechanism called spot-guided attention: each point is guided by similar high-confidence points around it, focusing on a local candidate region at each layer. Here, we also adopt global features to enhance the matching ability of the network in the can-didate regions. Specifically, for any point p, we pick the points with high feature similarity and matching confidence in the local area. Their corresponding matching regions are used for the next attention of point p. In addition, global features are applied to help the network to make judgments.
The coarse feature maps are iteratively updated in the above way. With our spot-guided aggregation module, the red and green pixels are guided to the correct area, avoiding the in-terference of repetitive patterns (see Figure 1 (d)). In Fig-ure 1 (e), our ASTR produces more accurate matching re-sults, which maintains local matching consistency. In the adaptive scaling module, to fully account of possible scale variations, we attempt to adaptively crop different sizes of grids for alignment. In detail, we compute the correspond-ing depth map using the coarse matching result and leverage the depth information to crop adaptive size grids from the high-resolution feature maps for fine matching.
The contributions of our method could be summarized (1) We propose a novel Adaptive Spot-into three-fold: guided Transformer (ASTR) for local feature matching, in-cluding a spot-guided aggregation module and an adap-tive scaling module. (2) We design a spot-guided aggre-gation module that can maintain local consistency and be unaffected by irrelevant regions while aggregating features.
Our adaptive scaling module is able to leverage depth in-formation to adaptively crop different size grids for refine-ment. (3) Extensive experimental results on five challeng-ing benchmarks show that our proposed method performs favorably against state-of-the-art image matching methods. 2.