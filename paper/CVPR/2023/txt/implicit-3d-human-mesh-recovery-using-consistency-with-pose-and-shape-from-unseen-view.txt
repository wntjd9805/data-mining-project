Abstract
From an image of a person, we can easily infer the nat-ural 3D pose and shape of the person even if ambiguity ex-ists. This is because we have a mental model that allows us to imagine a person’s appearance at different viewing direc-tions from a given image and utilize the consistency between them for inference. However, existing human mesh recovery methods only consider the direction in which the image was taken due to their structural limitations. Hence, we propose
“Implicit 3D Human Mesh Recovery (ImpHMR)” that can implicitly imagine a person in 3D space at the feature-level via Neural Feature Fields. In ImpHMR, feature fields are generated by CNN-based image encoder for a given image.
Then, the 2D feature map is volume-rendered from the fea-ture field for a given viewing direction, and the pose and shape parameters are regressed from the feature. To uti-lize consistency with pose and shape from unseen-view, if there are 3D labels, the model predicts results including the silhouette from an arbitrary direction and makes it equal to the rotated ground-truth. In the case of only 2D labels, we perform self-supervised learning through the constraint that the pose and shape parameters inferred from different directions should be the same. Extensive evaluations show the efficacy of the proposed method. 1.

Introduction
Human Mesh Recovery (HMR) is a task that regresses the parameters of a three-dimensional (3D) human body model (e.g., SMPL [34], SMPL-X [42], and GHUM [57]) from RGB images. Along with 3D joint-based methods [7, 32, 46], HMR has many downstream tasks such as AR/VR, and computer graphics as a fundamental topic in computer vision.
In recent years, there has been rapid progress in
HMR, particularly in regression-based approaches [6,19,22, 25–27,30,49,55,62]. However, despite these achievements, the existing algorithms still have a gap with the way humans do, so most of them do not show robust performance against the inherent ambiguity of the task.
Figure 1. Mental model of human that infers pose and shape from a single image. From an image of a person, we infer pose and shape robustly by imagining the person’s appearance not only from the direction in which the image was taken, but also from other viewing directions (e.g., left and right sides).
Consider the image of a baseball player running, as shown in Fig. 1. For the given single image, we can easily infer that the person’s right elbow and left leg are extended backward in a 3D space, despite the presence of inherent ambiguity (e.g., depth and occlusion). This is because we have a mental model that allows us to imagine a person’s ap-pearance at different viewing directions from a given image and utilize the consistency between them for inference. Re-cently, many state-of-the-art studies have successfully uti-lized knowledge similar to that used by humans such as hu-man dynamics [20] and temporal information [8,23,35,55].
However, to the best of our knowledge, there have been no studies proposed methods that consider 3D space for HMR similar to the way we infer pose and shape through appear-ance check between different views in 3D space.
To overcome this issue, we propose “Implicit 3D Human
Mesh Recovery (ImpHMR)” that can implicitly imagine a human placed in a 3D space via Neural Feature Fields [40].
Our assumption is that if the model is trained to infer a hu-man’s pose and shape at arbitrary viewing directions in a 3D space from a single image, then the model learns better spatial prior knowledge about human appearance; conse-quently, the performance in the canonical viewing direction in which the image was taken is improved.
To achieve this, we incorporate Neural Feature Fields into regression-based HMR methods. In ImpHMR, it gen-erates feature fields using a CNN-based image encoder for a given image to construct a person in 3D space, as shown in
Fig. 2. A feature field represented by a Multi-Layer Percep-tron (MLP) is a continuous function that maps the position of a point in 3D space and a ray direction to a feature vec-tor and volume density. In a feature field, which is implicit representation, all continuous points in a space can have a respective feature and volume density. Hence, the feature field is more expressive than explicit representation [59] and more suitable for representing human appearance from dif-ferent viewing directions in 3D space.
To infer the pose and shape parameters from the Fea-ture Field, the 2D feature map is generated by volume ren-dering for a given viewing direction, and the parameters are regressed from the rendered feature. Unlike previous methods, our model can look at a person from an arbitrary viewing direction by controlling the viewing direction deter-mined by camera extrinsic (i.e., camera pose). Therefore, to utilize consistency with pose and shape from unseen-view, if there are 3D labels, ImpHMR predicts results including silhouette used as geometric guidance from an arbitrary di-rection and makes it equal to the rotated ground-truth. In addition, in the case of only 2D labels, we perform self-supervised learning through the constraint that SMPL pa-rameters inferred from different directions should be the same. These constraints help feature fields represent a bet-ter 3D space by disentangling human appearance and view-ing direction; as a result, SMPL regression from canoni-cal viewing direction in which the image was taken is im-proved. To verify the efficacy of our method, we conduct experiments on 3DPW, LSP, COCO, and 3DPW-OCC. The contributions of our work can be summarized as follows:
• We propose a novel HMR model called “ImpHMR” that can implicitly imagine a human in 3D space from a given 2D observation via Neural Feature Fields.
• To utilize consistency with pose and shape from unseen-view, we propose arbitrary view imagination loss and ap-pearance consistency loss.
• We propose the geometric guidance branch so that the model can learn better geometric information.
• ImpHMR has 2 ∼ 3 times faster fps than current SOTAs thanks to efficient spatial representation in feature fields.
• We confirm that having the model imagine a person in 3D space and checking consistency between human ap-pearance from different viewing directions improves the
HMR performance in the canonical viewing direction in which the image was taken. 2.