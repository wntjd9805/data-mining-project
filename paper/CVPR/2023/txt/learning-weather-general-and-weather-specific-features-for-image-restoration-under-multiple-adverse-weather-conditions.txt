Abstract
Image restoration under multiple adverse weather con-ditions aims to remove weather-related artifacts by using a single set of network parameters. In this paper, we find that image degradations under different weather conditions con-tain general characteristics as well as their specific charac-teristics. Inspired by this observation, we design an efficient unified framework with a two-stage training strategy to ex-plore the weather-general and weather-specific features.
The first training stage aims to learn the weather-general features by taking the images under various weather con-ditions as inputs and outputting the coarsely restored re-sults. The second training stage aims to learn to adaptively expand the specific parameters for each weather type in the deep model, where the requisite positions for expand-ing weather-specific parameters are automatically learned.
Hence, we can obtain an efficient and unified model for im-age restoration under multiple adverse weather conditions.
Moreover, we build the first real-world benchmark dataset with multiple weather conditions to better deal with real-world weather scenarios. Experimental results show that our method achieves superior performance on all the syn-thetic and real-world benchmarks. Codes and datasets are available at this repository. 1.

Introduction
Adverse weather conditions, such as rain, haze, and snow, are common climatic phenomena in our daily life.
They often lead to the poor visual quality of captured im-ages and primarily deteriorate the performance of many outdoor vision systems, such as outdoor security cameras
⋆ : This work was done during their internship at Shanghai Artificial Intel-ligence Laboratory.
† : Co-first authors contributed equally. (cid:0) : Corresponding authors.
Figure 1. Illustration of the proposed method and the currently ex-isting solutions. (a) The weather-specific methods; (b) the method of [41]; (c) methods of [6, 69]; (d) our method, which learns the weather-specific and weather-general features in an efficient man-ner to remove multiple weather-related artifacts. and automatic driving [53, 107]. To make these systems more robust to various adverse weather conditions, many restoration solutions have been proposed, such as deraining
[16, 17, 25, 40, 72, 73, 82, 83], dehazing [1, 23, 49, 65, 80, 84], desnowing [4, 51, 97], and raindrop removal [22, 59, 96].
Albeit these approaches exhibit promising performance in the given weather situation, they are only applicable to certain typical weather scenarios. However, it is in-evitable to tackle various kinds of weather in the applica-tion of outdoor vision intelligent systems. Consequently, as shown in Fig. 1 (a), multiple sets of weather-specific model parameters are required to deal with various condi-tions, which brings additional computational and storage burdens. Hence, it is vitally requisite to develop a uni-fied model capable of addressing various types of adverse weather conditions via a single set of network parameters.
Recently, several methods [6, 41, 69] adopt a single set of network parameters to remove different weather-related artifacts. However, these solutions contain limitations for practical deployment and applications. Firstly, some meth-ods [6,69] fail to consider the specific characteristics of each weather condition in their proposed unified models, limit-ing their restoration performance on specific weather con-ditions. Secondly, as shown in Fig. 1 (b), although Li et al. [41] tackle the differences and similarities of weather degradation with multiple individual encoders and a shared decoder. Such multiple fixed encoders may largely in-crease network parameters. Thirdly, existing unified mod-els [6, 41, 69] often require a large number of parameters, limiting the model efficiency. Lastly, current state-of-the-art methods [6, 41, 69] mainly employ synthesized datasets in their training phase, causing apparent performance drops in real-world scenarios.
In this paper, we argue that images with different weather distortions contain general characteristics as well as their specific characteristics. According to the atmosphere scat-tering model [55, 57], due to the attenuation and scattering effects, these weather disturbances often share some sim-ilar visual degradation appearances, e.g., low contrast and color degradation. Meanwhile, the typical type of weather distortion has its unique characteristics. For example, rainy images often suffer from occlusion by rain steaks with dif-ferent shapes and scales [32, 82]; haze exhibits global dis-tortions on the entire images [34, 65]. Pioneer works also have devised many specific priors [23,72,80,83,97] for dif-ferent weather conditions, which motivates us to explore weather-general and weather-specific features to perform image restoration under multiple weather conditions.
To achieve this, we design an efficient unified frame-work for multiple adverse weather-related artifacts removal by exploring both weather-general and weather-specific fea-tures. The training procedure of our framework consists of two stages. The first training stage aims to learn the general features by taking various images under different weather conditions as the inputs and outputting coarse re-sults for multiple weather conditions. In the second train-ing stage, we devise a regularization-based optimization scheme, which learns to adaptively expand the specific pa-rameters for each weather type in the deep model. Note that these requisite positions to expand weather-specific parame-ters could be learned automatically, thus avoiding redundant parameters pre-designed by researchers. Hence, we are able to obtain an efficient and unified model for image restora-tion under multiple adverse weather conditions. Further-more, we newly construct the first real-world benchmark dataset with multiple weather conditions to better deal with various weather-related artifacts in real-world scenarios.
The contributions of this paper could be summarized as:
• We reveal that image degradations under different weather conditions contain both general and specific characteristics, which motivates us to design a uni-fied deep model by exploring the weather-general and weather-specific features for removing weather-related artifacts under multiple weather conditions.
• We present a two-stage training strategy to learn the weather-general and weather-specific features auto-matically. Moreover, the weather-specific features are adaptively added at the learned positions, which makes our model efficient and effective.
• In order to better deal with real-world weather con-ditions, we construct the first real-world benchmark dataset with multiple weather conditions. Addition-ally, experimental results validate the superiority of our proposed method on various benchmarks. 2.