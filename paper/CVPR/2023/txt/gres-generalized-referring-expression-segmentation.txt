Abstract proposed gRefCOCO dataset and method are available at https://henghuiding.github.io/GRES.
Referring Expression Segmentation (RES) aims to gen-erate a segmentation mask for the object described by a given language expression. Existing classic RES datasets and methods commonly support single-target expressions only, i.e., one expression refers to one target object. Multi-target and no-target expressions are not considered. This limits the usage of RES in practice.
In this paper, we introduce a new benchmark called Generalized Referring
Expression Segmentation (GRES), which extends the classic
RES to allow expressions to refer to an arbitrary number of target objects. Towards this, we construct the first large-scale GRES dataset called gRefCOCO that contains multi-target, no-target, and single-target expressions. GRES and gRefCOCO are designed to be well-compatible with RES, facilitating extensive experiments to study the performance gap of the existing RES methods on the GRES task. In the experimental study, we find that one of the big challenges of GRES is complex relationship modeling. Based on this, we propose a region-based GRES baseline ReLA that adaptively divides the image into regions with sub-instance clues, and explicitly models the region-region and region-language dependencies. The proposed approach
ReLA achieves new state-of-the-art performance on the both newly proposed GRES and classic RES tasks. The
†Equal contribution. (cid:0) Corresponding author (henghui.ding@gmail.com). 1.

Introduction
Referring Expression segmentation (RES) is one of the most important tasks of multi-modal information process-ing. Given an image and a natural language expression that describes an object in the image, RES aims to find this target object and generate a segmentation mask for it. It has great potential in many applications, such as video production, human-machine interaction, and robotics. Currently, most of the existing methods follow the RES rules defined in the popular datasets ReferIt [20] and RefCOCO [34, 47] and have achieved great progress in recent years.
Limitations of classic RES. However, most classic
RES methods have some strong pre-defined constraints to the task. First, the classic RES does not consider no-target expressions that do not match any object in the image. This means that the behavior of the existing RES methods is undefined if the target does not exist in the input image. When it comes to practical applications under such constraint, the input expression has to match an object in the image, otherwise problems inevitably occur. Second, most existing datasets, e.g., the most popular RefCOCO
[34, 47], do not contain multi-target expressions that point to multiple instances. This means that multiple inputs are needed to search objects one by one. E.g., in Fig. 1, four distinct expressions with four times of model calls are
Table 1. Comparison among different referring expression data-sets, including ReferIt [20], RefCOCO(g) [34, 47], PhraseCut
[40], and our proposed gRefCOCO. Multi-target: expression that specifies multiple objects in the image. No-target: expression that does not touch on any object in the image. proposed methods against other RES methods, showing that the explicit modeling of interaction and flexible region features greatly contributes to the performance of GRES.
In summary, our contributions are listed as follows:
Image Source
Multi-target
No-target
Expression type
CLEF [8] COCO [25]
ReferIt
✗
✗ free
RefCOCO(g) PhraseCut gRefCOCO
COCO [25]
VG [22]
✓ (fallback)
✓
✗
✗
✗ free templated free required to segment “All people”. Our experiments show that classic RES methods trained on existing datasets cannot be well-generalized to these scenarios.
New benchmark and dataset. In this paper, we propose a new benchmark, called Generalized Referring Expression
Segmentation (GRES), which allows expressions indicating any number of target objects. GRES takes an image and a referring expression as input, the same as classic RES.
Different from classic RES, as shown in Fig. 1, GRES further supports multi-target expression that specifies mul-tiple target objects in a single expression, e.g., “Everyone except the kid in white”, and no-target expression that does not touch on any object in the image, e.g., “the kid in blue”. This provides much more flexibility for input expression, making referring expression segmentation more useful and robust in practice. However, existing referring expression datasets [20, 34, 47] do not contain multi-target expression nor no-target samples, but only have single-target expression samples, as shown in Tab. 1. To facilitate research efforts on realistic referring segmentation, we build a new dataset for GRES, called gRefCOCO. It complements
RefCOCO with two kinds of samples: multi-target samples, in which the expression points to two or more target instances in the image, and no-target samples, in which the expression does not match any object in the image.
A baseline method. Moreover, we design a baseline method based on the objectives of the GRES task.
It is known that modeling relationships, e.g., region-region interactions, plays a crucial role in RES [46]. However, classic RES methods only have one target to detect so that many methods can achieve good performance without explicit region-region interaction modeling. But in GRES, as multi-target expressions involve multiple objects in one expression, it is more challenging and essential to model the long-range region-region dependencies.
From this point, we propose a region-based method for GRES that explicitly model the interaction among regions with sub-instance clues. We design a network that splits the image into regions and makes them explicitly interact with each other. Moreover, unlike previous works where regions come from a simple hard-split of the input image, our network soft-collates features for each region, achieving more flexibility. We do extensive experiments on our 1. We propose a benchmark of Generalized Referring
Expression Segmentation (GRES), making RES more flexible and practical in real-world scenarios. 2. We propose a large-scale GRES dataset gRefCOCO.
To the best of our knowledge, this is the first referring expression dataset that supports expressions indicating an arbitrary number of target objects. 3. We propose a solid baseline method ReLA for GRES to model complex ReLAtionships among objects, which achieves the new state-of-the-art performance on both classic RES and newly proposed GRES tasks. 4. We do extensive experiments and comparisons of the proposed baseline method and other existing RES methods on the GRES, and analyze the possible causes of the performance gap and new challenges in GRES. 2.