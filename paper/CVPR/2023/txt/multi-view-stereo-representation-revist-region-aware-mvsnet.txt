Abstract
Deep learning-based multi-view stereo has emerged as a powerful paradigm for reconstructing the complete geometrically-detailed objects from multi-views. Most of the existing approaches only estimate the pixel-wise depth value by minimizing the gap between the predicted point and the intersection of ray and surface, which usually ig-nore the surface topology. It is essential to the textureless regions and surface boundary that cannot be properly re-constructed. To address this issue, we suggest to take ad-vantage of point-to-surface distance so that the model is able to perceive a wider range of surfaces. To this end, we predict the distance volume from cost volume to esti-mate the signed distance of points around the surface. Our proposed RA-MVSNet is patch-awared, since the percep-tion range is enhanced by associating hypothetical planes with a patch of surface. Therefore, it could increase the completion of textureless regions and reduce the outliers at the boundary. Moreover, the mesh topologies with fine de-tails can be generated by the introduced distance volume.
Comparing to the conventional deep learning-based multi-view stereo methods, our proposed RA-MVSNet approach obtains more complete reconstruction results by taking ad-vantage of signed distance supervision. The experiments on both the DTU and Tanks & Temples datasets demonstrate that our proposed approach achieves the state-of-the-art re-sults. 1.

Introduction
Multi-view stereo (MVS) is able to efficiently recover geometry from multiple images, which makes use of the matching relationship and stereo correspondences of over-lapping images.
To achieve the promising reconstruction results, the con-ventional patch-based and PatchMatch-based methods [2, 11, 27] require rich textures and restricted lighting condi-*Corresponding author is Jianke Zhu.
Figure 1. Comparison on reconstruction results between base-line and RA-MVSNet. Our RA-MVSNet enables the model to perceive a wider range of surfaces so as to achieve the promising performance in complementing textureless regions and removing outliers at boundaries. Furthermore, our model is able to gener-ate correct mesh topologies with fine details based on estimated point-to-surface distances of spatially sampled points. tions. Alternatively, the deep learning-based approaches [4, 14,15,40] try to take advantage of global scene semantic in-formation, including environmental illumination and object materials, to maintain high performance in complex light-ing. The key of these methods is to warp deep image fea-tures into the reference camera frustum so that the 3D cost volume can be built via differentiable homographies. Then, the depth map is predicted by regularizing cost volume with 3D CNNs.
Despite the encouraging results, the pixel-wise depth es-timation suffers from two intractable flaws. One is the low estimation confidence in the textureless area. The other is many outliers near the boundary of the object. This is mainly because the surface is usually treated as a set of un-correlated sample points rather than the one with topology.
As each ray is only associated with a single surface sam-pling point, it is impossible to pay attention to the adjacent area of the surface. As shown in Fig. 1, the estimation of each depth value is constrained by only one surface sample point, which makes it unable to use the surrounding surface for inference. Unfortunately, it is difficult to infer without
broader surface information in textureless regions and ob-ject boundaries. Therefore, too small perception range lim-its the existing learning-based MVS methods.
To tackle this issue, we present a novel RA-MVSNet framework that is able to make each hypothetical plane as-sociated with a wider surface area through point-to-surface distance. Thus, our presented method is capable of inferring the surrounding surface information at textureless areas and object boundaries. To this end, our network not only es-timates the probability volume but also predicts the point-to-surface distance of each hypothetical plane. Specifically,
RA-MVSNet makes use of the cost volume to generate the probability and distance volumes, which are further com-bined to estimate the final depth map. The introduction of point-to-surface distance supervision uses the model patch-aware in estimating the depth value corresponding to a par-ticular pixel. This leads to the improved performance in textureless or boundary areas. Since the distance volume estimates the length of the sample points near the surface, we are able to predict a SDF-based implicit representation with the correct topology and fine details.
In summary, our contribution is three-fold:
• We introduce point-to-surface distance supervision of sampled points to expand the perception range pre-dicted by the model, which achieves complete estima-tion in textureless areas and reduce outliers in object boundary regions.
• To tackle the challenge of lacking the ground-truth mesh, we compute the signed distance between point sets based on the triangulated mesh, which trades off between accuracy and speed.
• Experimental results on the challenging MVS datasets show that our proposed approach performs the best both on indoor dataset DTU [1] and large-scale out-door dataset Tanks and Temples [17]. 2.