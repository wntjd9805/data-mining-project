Abstract
Video snapshot compressive imaging (SCI) uses a two-dimensional detector to capture consecutive video frames during a single exposure time. Following this, an effi-cient reconstruction algorithm needs to be designed to re-construct the desired video frames. Although recent deep learning-based state-of-the-art (SOTA) reconstruction al-gorithms have achieved good results in most tasks, they still face the following challenges due to excessive model complexity and GPU memory limitations: 1) these models need high computational cost, and 2) they are usually un-able to reconstruct large-scale video frames at high com-pression ratios. To address these issues, we develop an ef-ficient network for video SCI by using dense connections and space-time factorization mechanism within a single residual block, dubbed EfficientSCI. The EfficientSCI net-work can well establish spatial-temporal correlation by us-ing convolution in the spatial domain and Transformer in the temporal domain, respectively. We are the first time to show that an UHD color video with high compression ra-tio can be reconstructed from a snapshot 2D measurement using a single end-to-end deep learning model with PSNR above 32 dB. Extensive results on both simulation and real data show that our method significantly outperforms all pre-vious SOTA algorithms with better real-time performance.
The code is at https://github.com/ucaswangls/
EfficientSCI.git. 1.

Introduction
Traditional high-speed camera imaging methods usually suffer from high hardware and storage transmission cost.
Inspired by compressed sensing (CS) [5, 9], video snapshot compressive imaging (SCI) [45] provides an elegant solu-tion. As shown in Fig. 2, video SCI consists of a hardware encoder and a software decoder. In the encoder part, multi-ple raw video frames are modulated by different masks and
*Equal Contribution, † Corresponding Author
Figure 1. Comparison of reconstruction quality (average PSNR in dB on 6 benchmark grayscale datasets) and testing time of several
SOTA deep learning based algorithms. Our proposed EfficientSCI achieves higher reconstruction quality with fewer parameters and shorter testing time. then integrated by the camera to get a compressed measure-ment, giving low-speed cameras the ability to capture high-speed scenes. For the decoding part, the desired high-speed video is retrieved by the reconstruction algorithm using the captured measurement and masks.
So far, many mature SCI imaging systems [14, 24, 31] have been built, but for the decoding part, there are still many challenges. In particular, although the model-based methods [21, 43, 44] have good flexibility and can recon-struct videos with different resolutions and compression rates, they require long reconstruction time and can only achieve poor reconstruction quality. In order to improve the reconstruction quality and running speed, PnP-FFDNet [46] and PnP-FastDVDnet [47] integrate the pre-trained denois-ing network into an iterative optimization algorithm. How-ever, they still need a long reconstruction time on large-scale datasets, e.g., PnP-FastDVDNet takes hours to recon-struct a UHD video from a single measurement.
By contrast, deep learning based methods [28,30,35,40]
• Based on the space-time factorization mechanism, a
Convolution and Transformer hybrid block (CFormer) is built, which can efficiently establish space-time cor-relation by using convolution in the spatial domain and
Transformer in the temporal domain, respectively.
• Experimental results on a large number of simu-lated and real datasets demonstrate that our proposed method achieves state-of-the-art (SOTA) results and better real-time performance. 2.