Abstract
The ability of scene understanding has sparked active re-search for panoramic image semantic segmentation. How-ever, the performance is hampered by distortion of the equirectangular projection (ERP) and a lack of pixel-wise annotations. For this reason, some works treat the ERP and pinhole images equally and transfer knowledge from the pinhole to ERP images via unsupervised domain adap-tation (UDA). However, they fail to handle the domain gaps caused by: 1) the inherent differences between camera sen-sors and captured scenes; 2) the distinct image formats (e.g., ERP and pinhole images). In this paper, we propose a novel yet flexible dual-path UDA framework, DPPASS, tak-ing ERP and tangent projection (TP) images as inputs. To reduce the domain gaps, we propose cross-projection and intra-projection training. The cross-projection training in-cludes tangent-wise feature contrastive training and predic-tion consistency training. That is, the former formulates the features with the same projection locations as positive ex-amples and vice versa, for the models’ awareness of distor-tion, while the latter ensures the consistency of cross-model predictions between the ERP and TP. Moreover, adversarial intra-projection training is proposed to reduce the inherent gap, between the features of the pinhole images and those of the ERP and TP images, respectively. Importantly, the
TP path can be freely removed after training, leading to no additional inference cost. Extensive experiments on two benchmarks show that our DPPASS achieves +1.06% mIoU increment than the state-of-the-art approaches. https:
//vlis2022.github.io/cvpr23/DPPASS 1.

Introduction
Increasing attention has been paid to the emerging 360◦ cameras for their omnidirectional scene perception abilities
Figure 1. We tackle a new problem by addressing two types of do-main gaps, i.e., the inherent gap (style) and format gap (distortion) between the pinhole and panoramic (360◦) images. with a broader field of view (FoV) than the traditional pin-hole images [1]. Intuitively, the ability to understand the surrounding environment from the panoramic images has triggered the research for semantic segmentation as it is pivotal to practical applications, such as autonomous driv-ing [45, 50] and augmented reality [28]. Equirectangular projection (ERP) [46] is the most commonly used projec-tion type for the 360◦ images 1 and can provide a complete view of the scene. However, the ERP type suffers from se-vere distortion in the polar regions, resulting in noticeable object deformation. This significantly degrades the perfor-mance of the pixel-wise dense prediction tasks, e.g., seman-tic segmentation. Some attempts have been made to de-sign the convolution filters for feature extraction [32,50,53]; however, the specifically designed networks are less gener-alizable to other spherical image data. Moreover, labeled datasets are scarce, thus making it difficult to train effective 360◦ image segmentation models.
To tackle these issues, some methods, e.g., [50] treat the
ERP and pinhole images equally, like the basic UDA task,
*Corresponding author. 1Here, panoramic and 360◦ images are interchangeably used.                                                                                      
and directly alleviate the mismatch between ERP and pin-hole images by adapting the neural networks trained in the pinhole domain to the 360◦ domain via unsupervised do-main adaptation (UDA). For instance, DensePASS [23] pro-poses a generic framework based on different variants of attention-augmented modules. Though these methods can relieve the need for the annotated 360◦ image data [50], they fail to handle the existing domain gaps caused by: 1) diverse camera sensors and captured scenes; 2) distinct im-age representation formats (ERP and pinhole images) and yield unsatisfied segmentation performance. Accordingly, we define these two types of domain gaps as the inherent gap and format gap (See Fig. 1).
In this paper, we consider using the tangent projection (TP) along with the ERP. It has been shown that TP, the ge-ometric projection [7] of the 360◦ data, suffers from less distortion than the ERP. Moreover, the deep neural network (DNN) models designed for the pinhole images can be di-rectly applied [10]. To this end, we propose a novel dual-path UDA framework, dubbed DPPASS, taking ERP and
TP images as inputs to each path. The reason is that the
ERP provides a holistic view while TP provides a patch-wise view of a given scene. For this, the pinhole images (source domain) are also transformed to the pseudo ERP and TP formats as inputs. To the best of our knowledge, our work takes the first effort to leverage two projection for-mats, ERP and TP, to tackle the inherent and format gaps for panoramic image semantic segmentation. Importantly, the TP path can be freely removed after training, therefore, no extra inference cost is induced.
Specifically, as shown in Fig. 2, the cross-projection training is proposed at both the feature and prediction lev-els for tackling the challenging format gap (Sec. 3.2). At the feature level, the tangent-wise feature contrastive train-ing aims at mimicking the tangent-wise features with the same distortion and discerning the features with distinct distortion, to further learn distortion-aware models and de-crease the format gap. Meanwhile, the less distorted tan-gent images are used in the prediction consistency train-ing. It ensures the consistency between the TP predictions and the tangent projections of the ERP predictions for mod-els’ awareness of the distortion variations. For the long-existing inherent gap, the intra-projection training imposes the style and content similarities between the features from the source and target domains for both the ERP and TP im-ages (Sec. 3.3). As such, we can reduce the large inherent and format gaps between the 360◦ and pinhole images by taking advantage of dual projections.
We conduct extensive experiments from the pinhole dataset, Cityscapes [6], to two 360◦ datasets: DenseP-ASS [23] and WildPASS [44]. The experimental results show that our framework surpasses the existing SOTA methods by 1.06% on the DensePASS test set. In summary, our main contributions are summarized as follows: (I) We study a new problem by re-defining the domain gaps be-tween 360◦ images and pinhole images as two types: the inherent gap and format gap. (II) We propose the first UDA framework taking ERP and tangent images to reduce the types of domain gaps for semantic segmentation. (III) We propose corss- and intra- projection training that take the
ERP and TP at the prediction and feature levels to reduce the domain gaps. 2.