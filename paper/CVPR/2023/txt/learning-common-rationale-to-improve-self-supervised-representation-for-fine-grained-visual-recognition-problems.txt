Abstract
Self-supervised learning (SSL) strategies have demon-strated remarkable performance in various recognition tasks. However, both our preliminary investigation and recent studies suggest that they may be less effective in learning representations for fine-grained visual recognition (FGVR) since many features helpful for optimizing SSL ob-jectives are not suitable for characterizing the subtle differ-ences in FGVR. To overcome this issue, we propose learn-ing an additional screening mechanism to identify discrimi-native clues commonly seen across instances and classes, dubbed as common rationales in this paper.
Intuitively, common rationales tend to correspond to the discriminative patterns from the key parts of foreground objects. We show that a common rationale detector can be learned by sim-ply exploiting the GradCAM induced from the SSL objec-tive without using any pre-trained object parts or saliency detectors, making it seamlessly to be integrated with the existing SSL process. Specifically, we fit the GradCAM with a branch with limited fitting capacity, which allows the branch to capture the common rationales and discard the less common discriminative patterns. At the test stage, the branch generates a set of spatial weights to selectively aggregate features representing an instance. Extensive ex-perimental results on four visual tasks demonstrate that the proposed method can lead to a significant improvement in different evaluation settings.1 1.

Introduction
Recently, self-supervised representations Learning (SSL) has been shown to be effective for transferring to different downstream the learned representations
*Corresponding author. This work is supported by the Centre for Aug-mented Reasoning. 1The source code will be publicly available at: https://github. com/GANPerf/LCR
Figure 1. GradCAM [30] visualization for MoCo v2 [18], VI-CReg [4] and our method on the CUB-200-2011, Stanford
Cars and FGVC Aircraft datasets. Compared with the ex-isting method MoCo v2 and VICReg, which are prone to be dis-tracted by background patterns, our method can identify features from the foreground and potentially the key parts of the object. tasks [2, 4, 5, 14, 18]. Methods such as contrastive learning [7, 9, 16, 18] have demonstrated state-of-the-art feature learning capability and have been intensively studied recently. However, recent studies [11] suggest that contrastive learning may have a “coarse-grained bias” and could be less effective for fine-grained classification is to distinguish visually similar problems whose goal subcategories of objects under the basic-level category.
This phenomenon is rooted in fine-grained visual recog-nition (FGVR) properties and the training objective of SSL.
SSL tries to minimize a pretext task, e.g., contrastive learn-ing minimizes the distance between same-instance features while maximizing the distance among different-instance features, and any visual patterns that could contribute to loss minimization will be learned. On the other hand, the discriminative patterns for FGVR can be subtle. It is more likely to reside on key object parts. Thus, the feature learned
from SSL may not necessarily be useful for FGVR. Figure 1 shows our investigation of this issue. As seen, the existing
SSL paradigms, such as MoCo [18] and VICReg [4] are prone to learn patterns from irrelevant regions2. Existing works [31, 38, 42] usually handle this issue by recoursing to pre-trained object part detectors or saliency detectors to regularize SSL using patterns from valid regions to achieve the training objective. However, both the part detectors and saliency detectors could restrict the applicability of SSL for
FGVR since part detectors are trained from human anno-tations, and the saliency regions are not always coincident with the discriminative regions.
Therefore, this work aims to directly solve the problem from the target domain data. Specifically, we propose to learn an additional screening mechanism in addition to the contrastive learning process. The purpose of the screen-ing mechanism is to filter out the patterns that might con-tribute to SSL objectives but are irrelevant to FGVR. Some-how surprisingly, we find that such a screening mechanism can be learned from the GradCAM [30] of the SSL loss via an extremely simple method. The whole process can be described as a “fitting and masking” procedure: At the training time, we use an additional branch with limited fit-ting capacity (see more discussion about it in Section 3.2) to fit the GradCAM calculated from the SSL objective. At the testing time, we apply this additional branch to predict an attention mask to perform weighted average pooling for the final presentation. The motivation for such a design is that the GradCAM fitting branch tends to characterize the discriminative patterns that commonly occur across sam-ples due to its limited fitting capacity, and those common patterns, dubbed common rationale in this paper, are more likely corresponding to the discriminative clues from key object parts or at least foreground regions.
We implement our method based on MoCo v2 [8], one of the state-of-the-art approaches in unsupervised fea-ture learning, which also produces the best performance on FGVR in our setting. Our implementation uses the training objective of MoCo v2 to learn feature represen-tations and derive the GradCAM. Through extensive ex-periments, we show that our approach can significantly boost the quality of the learned feature. For example, when evaluating the learned feature for retrieval tasks, our method achieves 49.69% on the CUB-200-2011 retrieval task, which is 32.62% higher than our baseline method (MoCo v2 [8]). In the linear evaluation phase, the proposed method achieves new state-of-the-art 71.31% Top-1 accu-racy, which is 3.01% higher than MoCo v2. 2The weakness of existing SSL methods on FGVR can also be quanti-tively demonstrated by their performance on retrieval tasks shown in Sec-tion 4.3. As will be seen from our experiments, using only the features learned from SSL and without any further supervision from the target data, existing SSL methods achieve very poor performance in the retrieval task, i.e., based on feature similarity to identify same-class images. 2.