Abstract
This paper presents a DETR-based method for cross-domain weakly supervised object detection (CDWSOD), aiming at adapting the detector from source to target do-main through weak supervision. We think DETR has strong potential for CDWSOD due to an insight: the encoder and the decoder in DETR are both based on the attention mech-anism and are thus capable of aggregating semantics across the entire image. The aggregation results, i.e., image-level predictions, can naturally exploit the weak supervi-sion for domain alignment. Such motivated, we propose
DETR with additional Global Aggregation (DETR-GA), a
CDWSOD detector that simultaneously makes “instance-level + image-level” predictions and utilizes “strong + weak“ supervisions. The key point of DETR-GA is very simple: for the encoder / decoder, we respectively add mul-tiple class queries / a foreground query to aggregate the semantics into image-level predictions. Our query-based aggregation has two advantages. First, in the encoder, the weakly-supervised class queries are capable of roughly lo-cating the corresponding positions and excluding the dis-traction from non-relevant regions. Second, through our design, the object queries and the foreground query in the decoder share consensus on the class semantics, therefore making the strong and weak supervision mutually benefit each other for domain alignment. Extensive experiments on four popular cross-domain benchmarks show that DETR-GA significantly improves cross-domain detection accuracy (e.g., 29.0% → 79.4% mAP on PASCAL VOC → Clipartall dataset) and advances the states of the art. 1.

Introduction
The cross-domain problem is a critical challenge for ob-ject detection in real-world applications. Concretely, there is usually a domain gap between the training and testing
*Corresponding author: Si Liu
Figure 1. To exploit the weak supervision, DETR-GA aggregates the semantic information across the entire image into image-level predictions. Specifically, DETR-GA adds multiple class queries / a foreground query into the transformer encoder / decoder, respec-tively. The foreground query is correlated with the object queries but has no position embedding. We visualize the attention score of some queries, e.g., “person“ and “dog”. Despite no position su-pervision, each class query / the foreground query attends to the class-specific / foreground regions for semantic aggregation. data. This domain gap significantly compromises the detec-tion accuracy when the detector trained on the source do-main is directly deployed on a novel target domain. To mit-igate the domain gap, existing domain adaptation methods can be categorized into supervised, unsupervised [7,10,39], and weakly supervised approaches [17, 21, 33, 58]. Among the three approaches, we are particularly interested in the weakly supervised one because it requires only image-level annotations and achieves a good trade-off between the adap-tation effect and the annotation cost. Therefore, this paper challenges the cross-domain weakly supervised object de-tection (CDWSOD), aiming at adapting the detector from the source to target domain through weak supervision.
We think the DETR-style detector [3,27,67] has high po-tential for solving CDWSOD. In contrast to current CDW-SOD methods dominated by pure convolutional neural net-work detectors (“CNN detectors”), this paper is the first to explore DETR-style detectors for CDWSOD, to the best of our knowledge. Our optimism for DETR is NOT due to its prevalence or competitive results in generic object detec-tion. In fact, we empirically find the DETR-style detector barely achieves any superiority against CNN detectors for direct cross-domain deployment (Section 4.4). Instead, our motivation is based on the insight, i.e., the DETR-style de-tector has superiority for combining the strong and weak supervision, which is critical for CDWSOD [17, 21, 58].
Generally, CDWSOD requires using weak (i.e., image-level) supervision on target domain to transfer the knowl-edge from source domain. Therefore, it is essential to sup-plement the detector with image-level prediction capability.
We argue that this essential can be well accommodated by two basic components in DETR, i.e., the encoder and the decoder. Both the encoder and the decoder are based on the attention mechanism and thus have strong capability to capture long-range dependencies. This long-range model-ing capability, by its nature, is favorable for aggregating se-mantic information to make image-level predictions.
To fully exploit the weak supervision in CDWSOD, this paper proposes DETR with additional Global Aggregation (DETR-GA). DETR-GA adds attention-based global aggre-gation into DETR so as to make image-level predictions, while simultaneously preserving the original instance-level predictions. Basically, DETR uses multiple object queries in the decoder to probe local regions and gives instance-level predictions. Based on DETR, DETR-GA makes two simple and important changes: for the encoder / decoder, it respectively adds multiple class queries / a foreground query to aggregate semantic information across the entire image. The details are explained below: 1) The encoder makes image-level prediction through a novel class query mechanism. Specifically, the encoder adds multiple class queries into its input layer, with each query responsible for an individual class. Each class query probes the entire image to aggregate class-specific informa-tion and predicts whether the corresponding class exists in the image. During training, we use the image-level multi-class label to supervise the class query predictions.
Despite NO position supervision, we show these class queries are capable to roughly locate the corresponding po-sition (Fig. 1) and thus exclude the distraction from non-relevant regions. Therefore, our class query mechanism achieves better image-level aggregation effect than the av-erage pooling strategy that is commonly adopted in pure-CNN CDWSOD methods. Empirically, we find this simple component alone brings significant improvement for CDW-SOD, e.g., +20.8 mAP on PASCAL VOC → Cliparttest. 2) The decoder gives image-level and instance-level pre-dictions simultaneously through correlated object and fore-ground queries. To this end, we simply remove the position embedding from an object query and use the remained con-tent embedding as the foreground query. The insight for this design is: in a object query, the position embedding en-courages focus on local region [27,31,32], while the content embedding is prone to global responses to all potential fore-ground regions. Therefore, when we remove the position embedding, an object query discards the position bias and becomes a foreground query with global responses (as visu-alized in Fig. 1). Except this difference (i.e., with or without position embedding), the object queries and the foreground query share all the other elements in the decoder, e.g., the self-attention layer, cross-attention layer. Such correlation encourages them to share consensus on the class semantic and thus benefits the domain alignment along all the classes.
Overall, DETR-GA utilizes the weak supervision on the encoder and decoder to transfer the detection capability from source to target domain. Experimental results show that DETR-GA improves cross-domain detection accuracy by a large margin. Our main contributions can be summa-rized as follows:
• As the first work to explore DETR-style detector for
CDWSOD, this paper reveals that DETR has strong poten-tial for weakly-supervised domain adaptation because its attention mechanism can fully exploit image-level supervi-sion by aggregating semantics across the entire image.
• We propose DETR-GA, a CDWSOD detector that si-multaneously makes “instance-level + image-level” predic-tions and can utilize both “strong + weak” supervision. The key point of DETR-GA is the newly-added class queries / foreground query in the encoder / decoder, which promotes global aggregation for image-level prediction.
• Extensive experiments on four popular cross-domain benchmarks show that DETR-GA significantly improves
CDWSOD accuracy and advances the states of the art. For example, on PASCAL VOC → Clipartall, DETR-GA im-proves the baseline from 29.0% to 79.4% . 2.