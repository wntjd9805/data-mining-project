Abstract
Existing methods mainly handle single weather types.
However, the connections of different weather conditions at deep representation level are usually ignored. These con-nections, if used properly, can generate complementary rep-resentations for each other to make up insufficient train-ing data, obtaining positive performance gains and better generalization. In this paper, we focus on the very corre-lated rain and snow to explore their connections at deep representation level. Because sub-optimal connections may cause negative effect, another issue is that if rain and snow are handled in a multi-task learning way, how to find an optimal connection strategy to simultaneously improve de-raining and desnowing performance. To build desired con-nection, we propose a smart knowledge assignment strat-egy, called SmartAssign, to optimally assign the knowledge learned from both tasks to a specific one. In order to fur-ther enhance the accuracy of knowledge assignment, we propose a novel knowledge contrast mechanism, so that the knowledge assigned to different tasks preserves better uniqueness. The inherited inductive biases usually limit the modelling ability of CNNs, we introduce a novel trans-former block to constitute the backbone of our network to ef-fectively combine long-range context dependency and local image details. Extensive experiments on seven benchmark datasets verify that proposed SmartAssign explores effec-tive connection between rain and snow, and improves the performances of both deraining and desnowing apparently.
The implementation code will be available at https:// gitee.com/mindspore/models/tree/master/ research/cv/SmartAssign. 1.

Introduction
Bad weather types, such as haze, rain, and snow in-evitably degrade the visual quality of images, meanwhile decrease the performances of other downstream computer
Input
Restormer [58]
Ours
Input
HDCWNet [7]
Ours
Figure 1. Given challenging rainy (with blurry rain streaks) and snowy (with high bright snowflakes) images , the proposed method effectively removes the artifacts of rain and snow simultaneously, achieving better results than the state-of-the-art approaches. This is attributed to the unique knowledge which captures accurate fea-tures of rain/snow as well as the common knowledge boosting the generalization of our model to real data. vision tasks, e.g., autonomous driving [57]. Existing meth-ods mainly focus on single weather types, e.g., deraining
[14,19,26,45,46,48–50,56,60], dehazing [5,10,31,41,54], and desnowing [6, 7, 32, 49]. However, these methods usu-ally ignore the connections among these weather types, which, if used properly, may simultaneously improve the performance of multiple image recovery tasks.
Some methods attempt to explore the connections among different weather types by handling them with an uni-fied architecture and one set of pre-trained weights, e.g.,
[8, 25, 27]. But they neglect the difference of multiple weather types, the uniqueness belonging to single weather types may harm the performance of other weather recovery tasks. Therefore, the performances of such unified networks
are usually lower than the ones for single weather types [8].
In this paper, we focus on the very similar rain and snow and develop a novel Multi-Task Learning (MTL) strategy to explore their connections at deep representation level, meanwhile avoiding the uniqueness of one weather type from damaging the performance of the other weather re-covery task. Specifically, our goal is to accurately find the representations (i.e., connections) which can be shared by deraining and desnowing to simultaneously enhance both their performance, and meanwhile determine the exclusive representations (i.e., uniqueness) for one task to specially promote its own performance as well as avoid such unique-ness from damaging the other task. To facilitate the descrip-tion of our method, we define the deep representation of a single network channel as a knowledge atom. All the knowl-edge atoms constitute the knowledge learned by networks.
Similar to conventional MTL method, we also use a backbone encoder E(·) to learn the whole image-recovery knowledge simultaneously from rainy and snowy images, and two task-targeted decoders Ddr(·) and Dds(·) are fol-lowed in parallel to remove rain and snow, separately. Con-ventional MTL takes the whole knowledge as the input for the subsequent decoders. Though such mechanism makes the best of the connections between both tasks, the in-fluences of the uniqueness of single tasks are neglected, i.e., the uniqueness of rain may harm the performance of desnowing, and vice versa.
Instead, we propose a novel
Gated Knowledge Filtering Module (GKFM) to select op-timal knowledge atoms for both tasks via a highly smart strategy, so that the connections between both tasks are suf-ficiently explored and the uniqueness of single tasks is prop-erly used. To coordinate with GKFM, we design a Task-targeted Knowledge FeedForward mechanism (TKFF) to let every knowledge atom flow to its related tasks. Through our
GKFM and TKFF, we realize a smart knowledge assign-ment, in which both tasks adaptively explore their connec-tions and uniqueness via gradient backward-propagation.
Hence, we term our MTL mechanism as SmartAssign.
In order to further enhance the accuracy of knowledge assignment, i.e., toward optimally exploring the connec-tions and uniqueness of deraining and desnowing, we in-troduce a novel knowledge contrast, making the same kind of knowledge atoms more closer, and the ones belonging to different kinds more discriminative under a similarity met-ric. In this process, all the knowledge atoms are transformed into a new low-dimension feature space by a Dimension Re-duction Module (DRM) to avoid model collapse when op-erating on the original high-dimension knowledge atoms.
Currently, CNNs are still the mainstream choice for image recovery. However, the inherited inductive biases limit their modelling capacity for long-range context depen-dency. Though they can also obtain a large receptive field by stacking a deep architecture, such indirect modelling is indeed inferior to that of a transformer, which models both short and long range dependency directly via self-attention.
In this paper, we adopt transformer blocks to constitute our backbone encoder E(·). Usually, transformer needs suffi-cient training pairs to ensure good performance. Hence, our transformer block introduces a gated CNN branch to complement limited training data via the inductive biases.
Moreover, the locality of CNN helps to recover degraded image details and the gated operation is used to reduce re-dundant features caused by the combination of CNN and transformer. Figure 1 gives two examples of deraining and desnowing. By contrast, our method obtains better image recovery quality on both tasks than SOTA methods.
Our contributions are summarized in the following:
• We propose a novel knowledge assignment strategy, i.e., SmartAssign, to excavate the connections and uniqueness of rain and snow, so that their connections are used to enhance the performance of both tasks and the uniqueness is applied to boost corresponding task and avoided from damaging the other task.
• We propose a novel knowledge contrast mechanism to further boost the accuracy of knowledge assignment, in which a dimension reduction module (DRM) is in-troduced to stabilize the training of our model.
• We propose a novel transformer block to make the best use of the superiority of self-attention and convolution, in which gated operations are introduced to alleviate the feature redundancy. 2.