Abstract
We present a novel method, called NeuralUDF, for re-constructing surfaces with arbitrary topologies from 2D im-ages via volume rendering. Recent advances in neural ren-dering based reconstruction have achieved compelling re-sults. However, these methods are limited to objects with closed surfaces since they adopt Signed Distance Function (SDF) as surface representation which requires the target shape to be divided into inside and outside.
In this pa-per, we propose to represent surfaces as the Unsigned Dis-tance Function (UDF) and develop a new volume rendering scheme to learn the neural UDF representation. Specifi-cally, a new density function that correlates the property of
UDF with the volume rendering scheme is introduced for robust optimization of the UDF fields. Experiments on the
DTU and DeepFashion3D datasets show that our method not only enables high-quality reconstruction of non-closed shapes with complex typologies, but also achieves compa-rable performance to the SDF based methods on the re-construction of closed surfaces. Visit our project page at https://www.xxlong.site/NeuralUDF/. 1.

Introduction
Reconstructing high-quality surfaces from multi-view images is a long-standing problem in computer vision and computer graphics. Neural implicit fields have become an emerging trend in recent advances due to its superior capability of representing surfaces of complex geometry.
NeRF [35] and its variants [2, 26, 27, 36, 40, 52] have re-cently achieved compelling results in novel view synthesis.
For each point in the 3D space, NeRF-based methods learn two neural implicit functions based on volume rendering: a volume density function and a view-dependent color func-tion. Despite their successes in novel view synthesis, NeRF-based methods still struggle to faithfully reconstruct the ac-*Corresponding authors.
†This work was conducted during an internship at Tencent Games.
Reference Images
Ours
NeuS [46]
Figure 1. We show three groups of multi-view reconstruction re-sults generated by our proposed NeuralUDF and NeuS [46] re-spectively. Our method is able to faithfully reconstruct the high-quality geometries for both the closed and open surfaces, while
NeuS can only model shapes as closed surfaces, thus leading to inconsistent typologies and erroneous geometries. curate scene geometry from multi-view inputs, because of the difficulty in extracting high-quality surfaces from the representation of volume density.
VolSDF [49] and NeuS [46] incorporate the Signed Dis-tance Function (SDF) into volume rendering to facilitate high-quality surface reconstruction in a NeRF framework.
However, as a continuous function with clearly defined in-side/outside, SDF is limited to modeling only closed water-tight surfaces. Although there have been efforts to modify the SDF representation by learning an additional truncation function (e.g., 3PSDF [5], TSDF [44]), their surface rep-resentations are still built upon the definition of SDF, thus they are not suitable for representing complex topologies.
We therefore propose to employ the Unsigned Distance
Function (UDF) to represent surfaces in volume rendering.
With a surface represented by its zero level set without signs, UDF is a unified representation with higher-degree of freedom for both closed and open surfaces, thus making it possible to reconstruct shapes with arbitrary topologies.
There are two major challenges in learning a neural UDF field by volume rendering. First, UDF is not occlusion-aware, while the formulation of volume rendering with dis-tance fields requires to estimate surface occlusion for points.
Considering a camera ray intersecting with a surface, SDF assumes that the surface is closed and distinguishes the in-side/outside with signs, so that a negative SDF value on the ray clearly indicates an occluded point inside the surface.
In contrast, UDF does not impose the closed surface as-sumption and always gives non-negative values along the ray. Hence, the UDF value of a point alone cannot be used to infer occlusion.
The second challenge is that the UDF is not differen-tiable at its zero-level sets. The non-differentiability at the zero-level sets imposes barriers in the learning of UDF field.
The gradients are ill-defined near the iso-surface, leading to difficulty in optimization. Consequently, the distance field surrounding the iso-surface is not accurate and the exact zero-level set of a learned UDF cannot be identified in a stable manner.
In this paper, we present a novel method for learning neural UDF fields by volume rendering. We introduce a density function that correlates the property of the UDF rep-resentation with the volume rendering process, which effec-tively tackles the aforementioned challenges induced by the unsigned representation and enables robust learning of sur-faces with arbitrary topologies. Experiments on DTU [15] and DeepFashion3D [53] datasets show that our method not only enables the high-quality reconstruction of non-closed shapes with complex topologies, but also achieves compa-rable performance to the SDF based methods on the recon-struction of closed surfaces.
Our contributions can be summarized as:
• We incorporate the UDF into volume rendering, which extends the representation of the underlying geometry of neural radiance fields.
• We introduce an effective density function that corre-lates the property of the UDF with the volume render-ing process, thus enabling robust optimization of the distance fields.
• Our method achieves SOTA results for reconstructing high-quality surfaces with various topologies (closed or open) using the UDF in volume rendering. 2.