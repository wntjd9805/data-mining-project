Abstract
In recent years, deep learning-based approaches have shown great strength in multi-view stereo because of their outstanding ability to extract robust visual features. How-ever, most learning-based methods need to build the cost volume and increase the receptive field enormously to get a satisfactory result when dealing with large-scale tex-tureless regions, consequently leading to prohibitive mem-ory consumption. To ensure both memory-friendly and textureless-resilient, we innovatively transplant the spirit of deformable convolution from deep learning into the tra-ditional PatchMatch-based method. Specifically, for each pixel with matching ambiguity (termed unreliable pixel), we adaptively deform the patch centered on it to extend the receptive field until covering enough correlative reliable pixels (without matching ambiguity) that serve as anchors.
When performing PatchMatch, constrained by the anchor pixels, the matching cost of an unreliable pixel is guar-anteed to reach the global minimum at the correct depth and therefore increases the robustness of multi-view stereo significantly. To detect more anchor pixels to ensure bet-ter adaptive patch deformation, we propose to evaluate the matching ambiguity of a certain pixel by checking the con-vergence of the estimated depth as optimization proceeds.
As a result, our method achieves state-of-the-art perfor-mance on ETH3D and Tanks and Temples while preserving low memory consumption. 1.

Introduction
Multi-view stereo (MVS) is one of the core tasks in com-puter vision which aims to recover the 3D geometry of
*Corresponding author. Contact him at whoiszzj@outlook.com or zhaojiezeng@hust.edu.cn. Code: https://github.com/whoiszzj/APD-MVS.
Figure 1. Comparison with the latest learning-based methods [6, 19, 27–29, 32] and traditional methods [12, 36, 37, 39] on Tanks and Temples [10] and ETH3D [23]. When comparing memory cost, we set the number of source images to 10 for all methods and the image size 6, 221 × 4, 146 (ETH3D) as 100% resolution (8.04% corresponds to Tanks and Temples). Note that learning-based methods train their models on DTU [1] or BlendedMVS [44] and only regard the train set of ETH3D as one of their test sets. a scene using images captured from different viewpoints.
It has been playing an essential role in many downstream tasks, such as automatic drive and virtual reality. Plentiful ideas stem from this vein [5,13,20,31,33] and continuously boost the reconstruction performances to a new level. These prior arts can be roughly divided into traditional and deep learning-based methods.
Many existing newly-proposed traditional MVS meth-ods [22, 37, 39, 47] are extended versions of the Patch-Match [2] (PM), which calculate the matching cost between
a fixed-size reference patch and patches in source images according to a plane hypothesis. These PM-based meth-ods avoid the construction of cost volume as they employ a propagation and local refinement strategy to find proper matches and hence require little memory. Nevertheless, ac-cording to [14], when a patch lies in a textureless region, the matching cost will lose credibility since there is no useful feature information in the receptive field. To mitigate this problem, attempts [14, 30, 37, 40] either downsample im-ages or use multiple window sizes to increase the receptive field. However, they can only handle small areas of texture-less regions well. To better cope with large-scale textureless regions, methods such as ACMP [39], PCF-MVS [12], and
ACMMP [36] introduce a coarse fitting plane hypothesis to the textureless region. Nevertheless, such an approach suffers from gradual deviation from the provided plane hy-pothesis, leading to inaccurate depth estimation.
On the contrary, deep learning-based methods [15–17, 34, 38] usually suffer less from the above issue. Benefiting from the prevalent application of convolution operation, the receptive field of these methods is much larger than tradi-tional ones. AA-RMVSNet [32] and TransMVSNet [6] fur-ther expand the receptive field by introducing deformable convolution [4]. As the receptive field increases, unreliable pixels can obtain adequate geometrical information from surrounding reliable pixels, which results in better depth es-timation. Nevertheless, as shown in Fig. 1, a larger receptive field results in more memory consumption, making them hard to handle datasets with large-scale textureless regions or high-resolution images using mainstream GPU devices.
Although several recent works have endeavored to reduce the memory consumption [19, 27, 28], the results are still not satisfactory compared with traditional methods [36,39].
To develop a memory-friendly solution that can well handle large-scale textureless regions at the same time, in this paper, we transplant the spirit of deformable convolu-tion to a traditional PM-based MVS pipeline. Specifically, for each unreliable pixel, we adaptively deform its corre-sponding patch to extend the receptive field until covering enough reliable pixels, as shown in Fig. 2. We then use
RANSAC to filter out unrelated reliable pixels (belonging to different geometry hyperthesis or gathered due to occlu-sion). The residual reliable pixels serve as anchor pixels for the deformable patch. Then we conduct PM based on the widely-used normalized cross-correlation (NCC) metric within this deformable patch. As demonstrated in Fig. 2, the profile of matching cost using our deformable PM reaches a salient single valley at the ground-truth depth and hence guides the unreliable pixels to find a correct match.
One remaining and non-trivial issue that affects the suc-cess of our adaptive patch deformation is how to evaluate pixel reliability. Many existing approaches [14, 21, 40] rely solely on the pixel’s intensity, which is unreliable when fac-Figure 2. The right image is a demo of adaptive patch deforma-tion. The green point represents the center pixel, the blue points around it represent the conventional patch, and the red points form the receptive field of our deformable patch. The left profile shows matching costs around the ground truth (green dashed line). Com-pared with conventional PM, our deformable PM has significant convergence performance around the ground truth for the unreli-able pixel. ing repetitive texture or drastic changes in illumination that can also cause matching ambiguity. Others [36, 39] simply set a threshold for the pixel’s matching cost to evaluate re-liability. However, as mentioned before, the matching cost is unreliable in textureless regions, making it hard to set a proper threshold. Instead, we propose to evaluate the reli-ability of pixels by checking the convergence of estimated depth as optimization proceeds. Specifically, in each itera-tion, we use conventional PM to calculate the matching cost of each pixel within a neighboring window of the current depth and form a matching cost profile. Then we evalu-ate pixel reliability by analyzing the geometric features of the profile, including local and global minima. Our eval-uation approach can help to find more anchor pixels while maintaining their credibility, bringing better adaptive patch deformation.
In summary, our contributions are as follows:
• For PM-based MVS, we propose to adaptively de-form the patch of an unreliable pixel when comput-ing the matching cost, which increases the receptive field when facing textureless regions to ensure robust matching.
• We propose to detect reliable pixels by checking the convergence of matching cost profiles, maintaining the accuracy of detection while being able to find more an-chor pixels, which ensures better adaptive patch defor-mation.
• We realize a PM-based MVS method, APD-MVS, which adopts our adaptive patch deformation and an
NCC-based matching metric. Our method achieves state-of-the-art results on ETH3D dataset and Tanks and Temples dataset with lower memory consumption. 2.