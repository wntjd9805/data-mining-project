Abstract
We present Generative Semantic Segmentation (GSS), a generative learning approach for semantic segmentation.
Uniquely, we cast semantic segmentation as an image-conditioned mask generation problem. This is achieved by replacing the conventional per-pixel discriminative learn-ing with a latent prior learning process. Specifically, we model the variational posterior distribution of latent vari-ables given the segmentation mask. To that end, the seg-mentation mask is expressed with a special type of image (dubbed as maskige). This posterior distribution allows to generate segmentation masks unconditionally. To achieve semantic segmentation on a given image, we further intro-duce a conditioning network. It is optimized by minimizing the divergence between the posterior distribution of maskige (i.e. segmentation masks) and the latent prior distribution of input training images. Extensive experiments on standard benchmarks show that our GSS can perform competitively to prior art alternatives in the standard semantic segmentation setting, whilst achieving a new state of the art in the more challenging cross-domain setting. 1.

Introduction
The objective of semantic segmentation is to predict a label for every single pixel of an input image [32]. Condi-tioning on each pixel’s observation, existing segmentation methods [4,9,50,56] naturally adopt the discriminative learn-ing paradigm, along with dedicated efforts on integrating task prior knowledge (e.g., spatial correlation) [9, 23, 46, 56].
For example, existing methods [4, 50, 56] typically use a linear projection to optimize the log-likelihood classification for each pixel. Despite the claim of subverting per-pixel clas-sification, the bipartite matching-based semantic segmenta-tion [8, 9] still cannot avoid the per-pixel max log-likelihood.
In this paper, we introduce a new approach, Genera-tive Semantic Segmentation (GSS), that formulates seman-*Li Zhang (lizhangfd@fudan.edu.cn) is the corresponding author with
School of Data Science, Fudan University.
Figure 1. Schematic comparison between (a) conventional discrim-inative learning and (b) our generative learning based model for semantic segmentation. Our GSS introduces a latent variable z and, given the segmentation mask c, it learns the posterior distri-bution of z subject to the reconstruction constraint. Then, we train a conditioning network to model the prior of z by aligning with the corresponding posterior distribution. This formulation can thus generate the segmentation mask for an input image. tic segmentation as an image-conditioned mask generation problem. This conceptually differs from the conventional for-mulation of discriminative per-pixel classification learning, based on the log-likelihood of a conditional probability (i.e. the classification probability of image pixels). Taking the manner of image generation instead [24,44], we generate the whole segmentation masks with an auxiliary latent variable distribution introduced. This formulation is not only simple and more task-agnostic, but also facilitates the exploitation of off-the-shelf big generative models (e.g. DALL·E [39] trained by 3 billion iterations on a 300 million open-image dataset, far beyond both the data scale and training cost of semantic segmentation).
However, achieving segmentation segmentation in a generic generation framework (e.g. the Transformer archi-tecture [15]) is non-trivial due to drastically different data format. To address this obstacle, we propose a notion of maskige that expresses the segmentation mask in the RGB image form. This enables the use of a pretrained latent posterior distribution (e.g. VQVAE [39]) of existing gener-ative models. Our model takes a two-stage optimization: (i) Learning the posterior distribution of the latent variables conditioned on the semantic segmentation masks so that the latent variables can simulate the target segmentation masks; To achieve this, we introduce an fixed pre-trained
VQVAE [39] and a couple of lightweight transformation modules, which can be trained with minimal cost, or they can be manually set up without requiring any additional training. In either case, the process is efficient and does not add significant overhead to the overall optimization. (ii)
Minimizing the distance between the posterior distribution and the prior distribution of the latent variables given input training images and their masks, enabling to condition the generation of semantic masks on the input images. This can be realized by a generic encoder-decoder style architecture (e.g. a Transformer).
We summarize the contributions as follows. (i) We pro-pose a Generative Semantic Segmentation approach that reformulates semantic segmentation as an image-conditioned mask generation problem. This represents a conceptual shift from conventional discriminative learning based paradigm. (ii) We realize a GSS model in an established conditional image generation framework, with minimal need for task-specific architecture and loss function modifications while fully leveraging the knowledge of off-the-shelf generative models. (iii) Extensive experiments on several semantic segmentation benchmarks show that our GSS is competitive with prior art models in the standard setting, whilst achieving a new state of the art in the more challenging and practical cross-domain setting (e.g. MSeg [26]). 2.