Abstract
A self-driving vehicle (SDV) must be able to perceive its surroundings and predict the future behavior of other traf-fic participants. Existing works either perform object de-tection followed by trajectory forecasting of the detected objects, or predict dense occupancy and flow grids for the whole scene. The former poses a safety concern as the num-ber of detections needs to be kept low for efficiency rea-sons, sacrificing object recall. The latter is computation-ally expensive due to the high-dimensionality of the out-put grid, and suffers from the limited receptive field inher-ent to fully convolutional networks. Furthermore, both ap-proaches employ many computational resources predicting areas or objects that might never be queried by the motion planner. This motivates our unified approach to percep-tion and future prediction that implicitly represents occu-pancy and flow over time with a single neural network. Our method avoids unnecessary computation, as it can be di-rectly queried by the motion planner at continuous spatio-temporal locations. Moreover, we design an architecture that overcomes the limited receptive field of previous ex-plicit occupancy prediction methods by adding an efficient yet effective global attention mechanism. Through exten-sive experiments in both urban and highway settings, we demonstrate that our implicit model outperforms the cur-rent state-of-the-art. For more information, visit the project website: https://waabi.ai/research/implicito. 1.

Introduction
The goal of a self-driving vehicle is to take sensor ob-servations of the environment and offline evidence such as high-definition (HD) maps and execute a safe and comfort-able plan towards its destination. Meanwhile, it is important to produce interpretable representations that explain why the vehicle performed a certain maneuver, particularly if a dangerous event were to occur. To satisfy this, traditional autonomy stacks [2, 6, 9, 14, 15, 20, 32, 38, 39] break down the problem into 3 tasks: perception, motion forecasting and motion planning. Perception leverages sensor data to local-ize the traffic participants in the scene. Motion forecasting
*Denotes equal contribution
Figure 1. Left: Explicit approaches predict whole-scene occu-pancy and flow on a spatio-temporal grid. Right: Our implicit approach only predicts occupancy and flow at queried continuous points, focusing on what matters for downstream planning. outputs the distribution of their future motion, which is typ-ically multimodal. Finally, motion planning is tasked with deciding which maneuver the SDV should execute.
Most autonomy systems are object-based, which in-volves detecting the objects of interest in the scene. To do so, object detectors threshold predicted confidence scores to determine which objects in the scene, a trade off be-tween precision and recall. Furthermore, object-based mo-tion forecasting methods are limited to predict only a hand-ful of sample trajectories or parametric distributions with closed-form likelihood for tractability, as they scale linearly with the number of objects and must run online in the vehi-cle. This causes information loss that could result in unsafe situations [30], e.g., if a solid object is below the detection threshold, or the future behavior of the object is not captured by the simplistic future trajectory estimates.
In recent years, object-free approaches [3, 12, 29, 30] that model the presence, location and future behavior of all agents in the scene via a non-parametric distribution have emerged to address the shortcomings of object-based mod-els. Object-free approaches predict occupancy probability and motion for each cell in a spatio-temporal grid, directly from sensor data. More concretely, the spatio-temporal grid is a 3-dimensional dense grid with two spatial dimensions representing the birdâ€™s-eye view, and a temporal dimension from the current observation time to a future horizon of choice. All dimensions are quantized at regular intervals.
In this paradigm, no detection confidence thresholding is re-quired and the distribution over future motion is much more expressive, enabling the downstream motion planner to plan with consideration of low-probability objects and futures.
Unfortunately, object-free approaches are computationally expensive as the grid must be very high-dimensional to mit-igate quantization errors. However, most of the computa-tion and memory employed in object-free methods is un-necessary, as motion planners only need to cost a set of spatio-temporal points around candidate trajectories, and not a dense region of interest (RoI). We refer the reader to
Fig. 1 for an illustration.
This motivates our approach, IMPLICITO, which utilizes an implicit representation to predict both occupancy proba-bility and flow over time directly from raw sensor data and
HD maps. This enables downstream tasks such as motion planning to efficiently evaluate a large collection of spatio-temporal query points in parallel, focusing on areas of in-terest where there are potential interactions with the self-driving vehicle. We design an architecture that overcomes the limited receptive field of fully convolutional explicit ar-chitectures [12, 24, 29, 30] by adding an efficient yet effec-tive global attention mechanism. In particular, we leverage deformable convolutions [8] and cross attention [37] to fo-cus on a compact set of distant regions per query, giving the predictions a global context. This is useful as dynamic objects can move at very high speeds, particularly on the highway. For instance, when predicting in-lane occupancy 3 seconds into the future on a road where the speed limit is 30 m/s, the attention can look approximately 90 meters back along the lane to find the corresponding sensor evidence.
Extensive experiments in both urban and highway scenar-ios show that our object-free implicit approach outperforms the two prevalent paradigms in the literature on the task of occupancy-flow prediction: (i) object-based methods that first perform object detection to localize a finite set of ob-jects in the scene, and then predict their future trajectory dis-tribution (ii) object-free explicit methods that predict dense spatio-temporal grids of occupancy and motion. 2.