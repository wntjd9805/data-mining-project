Abstract
In this work, we focus on reducing the annotation cost for video action detection which requires costly frame-wise dense annotations. We study a novel hybrid active learning (AL) strategy which performs efficient labeling using both intra-sample and inter-sample selection. The intra-sample selection leads to labeling of fewer frames in a video as op-posed to inter-sample selection which operates at video level.
This hybrid strategy reduces the annotation cost from two dif-ferent aspects leading to significant labeling cost reduction.
The proposed approach utilize Clustering-Aware Uncertainty
Scoring (CLAUS), a novel label acquisition strategy which relies on both informativeness and diversity for sample se-lection. We also propose a novel Spatio-Temporal Weighted (STeW) loss formulation, which helps in model training un-der limited annotations. The proposed approach is evaluated on UCF-101-24 and J-HMDB-21 datasets demonstrating its effectiveness in significantly reducing the annotation cost where it consistently outperforms other baselines. Project details available at https://tinyurl.com/hybridclaus
Figure 1. Comparison of the proposed CLAUS based AL method with random selection for video action detection. The plots show scores for (a-b) UCF-101-24 and (c-d) J-HMDB-21 for different annotation amount. The green line represents model performance with 90% annotations. 1.

Introduction
Video action detection requires spatio-temporal annota-tions which include bounding-box or pixel-wise annotation on each frame of the video in addition to video level anno-tations [22, 27, 35, 50, 66]. Cost for such dense annotation is much higher compared to classification task where only video level annotations is sufficient [8, 18, 59, 60]. In this work, we study how this high annotation cost for spatio-temporal detection can be reduced with minimal perfor-mance trade-off.
The existing works on label efficient learning for videos are mainly focused on classification task [10, 23, 57]. Video action detection methods focus on weakly-supervised or semi-supervised methods to save annotation costs [12,31,39, 40, 64]. Weakly-supervised methods use partial annotations such as point-level [39], video-level [3, 12], and temporal annotations [9, 64]. Similarly, semi-supervised methods use unlabeled samples with the help of pseudo-labeling [40] and prediction consistency [31]. Such approaches have been effective for classification tasks, however spatio-temporal detection is more challenging under limited annotations with inferior performance compared to fully supervised methods.
One of the main limitation of these methods is lack of se-lection criteria which can guide in labeling only informative samples. To overcome this limitation, we investigate the use of active learning for label efficient video action detection.
Traditional active learning (AL) approach typically fo-cuses on classification task where selection is performed at sample level [19, 34, 61]. In video action detection, a frame-level spatio-temporal localization is required in addition to video level class prediction. Therefore, active learning strat-egy should also consider detection on every frame within a video apart from video-level decisions. We argue that frame-level informativeness is also crucial for spatio-temporal de-tection along with video-level informativeness. Motivated
by this, we explore a hybrid active learning strategy which performs both intra-sample and inter-sample selection. The intra-sample selection targets informative frames within a video and inter-sample selection aims at informative sam-ples at video-level. This hybrid approach results in efficient labeling by significantly reducing the annotation costs.
Informativeness and diversity, both are important for sam-ple selection in active learning [4]. The proposed approach utilize Clustering-Aware Uncertainty Scoring (CLAUS), a novel clustering assisted AL strategy which considers both these aspects for sample selection. It relies on model un-certainty for informative sample selection and clustering for reducing redundancy. Clustering is jointly performed on fea-ture space while model training where diversity is enforced based on cluster assignments. Moreover, the intra-sample selection will lead to limited annotations making model train-ing difficult. To overcome this, we propose a novel training objective, Spatio-Temporal Weighted (STeW) loss, which re-lies on temporal continuity for pseudo labels and helps in learning under limited annotations.
We make the following contributions in this work: 1) novel hybrid AL strategy that selects frames and videos based on informativeness and diversity; 2) clustering based selection criteria that enables diversity in sample selection; 3) novel training objective for effective utilization of limited labels using temporal continuity. We evaluate the proposed approach on UCF-101-24 and JHMDB-21 and demonstrate that it outperforms other AL baselines and achieves compa-rable performance with model trained on 90% annotations at a fraction (5% vs 90%) of the annotation cost (Figure 1). 2.