Abstract
We propose Mask Auto-Labeler (MAL), a high-quality
Transformer-based mask auto-labeling framework for in-stance segmentation using only box annotations. MAL takes box-cropped images as inputs and conditionally generates their mask pseudo-labels. We show that Vision Transform-ers are good mask auto-labelers. Our method significantly reduces the gap between auto-labeling and human annota-tion regarding mask quality. Instance segmentation models trained using the MAL-generated masks can nearly match the performance of their fully-supervised counterparts, re-taining up to 97.4% performance of fully supervised mod-els. The best model achieves 44.1% mAP on COCO in-stance segmentation (test-dev 2017), outperforming state-of-the-art box-supervised methods by significant margins.
Qualitative results indicate that masks produced by MAL are, in some cases, even better than human annotations. 1.

Introduction
Computer vision has seen significant progress over the last decade. Tasks such as instance segmentation have made it possible to localize and segment objects with pixel-level accuracy. However, these tasks rely heavily on expan-sive human mask annotations. For instance, when creat-ing the COCO dataset, about 55k worker hours were spent on masks, which takes about 79% of the total annotation time [1]. Moreover, humans also make mistakes. Human annotations are often misaligned with actual object bound-aries. On complicated objects, human annotation quality tends to drop significantly if there is no quality control. Due to the expensive cost and difficulty of quality control, some other large-scale detection datasets such as Open Images [2] and Objects365 [3], only contain partial or even no instance segmentation labels.
In light of these limitations, there is an increasing in-terest in pursuing box-supervised instance segmentation, where the goal is to predict object masks from bounding box supervision directly. Recent box-supervised instance segmentation methods [4â€“8] have shown promising perfor-mance. The emergence of these methods challenges the long-held belief that mask annotations are needed to train instance segmentation models. However, there is still a non-negligible gap between state-of-the-art approaches and their fully-supervised oracles.
Our contributions: To address box-supervised instance segmentation, we introduce a two-phase framework consist-ing of a mask auto-labeling phase and an instance segmenta-tion training phase (see Fig. 2). We propose a Transformer-based mask auto-labeling framework, Mask Auto-Labeler (MAL), that takes Region-of-interest (RoI) images as inputs
2.