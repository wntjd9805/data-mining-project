Abstract
Recent work leverages the expressive power of genera-tive adversarial networks (GANs) to generate labeled syn-thetic datasets. These dataset generation methods often require new annotations of synthetic images, which forces practitioners to seek out annotators, curate a set of synthetic images, and ensure the quality of generated labels. We in-troduce the HandsOff framework, a technique capable of producing an unlimited number of synthetic images and cor-responding labels after being trained on less than 50 pre-existing labeled images. Our framework avoids the practi-cal drawbacks of prior work by unifying the field of GAN in-version with dataset generation. We generate datasets with rich pixel-wise labels in multiple challenging domains such as faces, cars, full-body human poses, and urban driving scenes. Our method achieves state-of-the-art performance in semantic segmentation, keypoint detection, and depth es-timation compared to prior dataset generation approaches and transfer learning baselines. We additionally showcase its ability to address broad challenges in model develop-ment which stem from fixed, hand-annotated datasets, such as the long-tail problem in semantic segmentation. Project page: austinxu87.github.io/handsoff. 1.

Introduction
The strong empirical performance of machine learning (ML) models has been enabled, in large part, by vast quan-tities of labeled data. The traditional machine learning paradigm, where models are trained with large amounts of human labeled data, is typically bottlenecked by the signif-icant monetary, time, and infrastructure investments needed to obtain said labels. This problem is further exacerbated when the data itself is difficult to collect. For example, col-lecting images of urban driving scenes requires physical car infrastructure, human drivers, and compliance with relevant government regulations. Finally, collecting real labeled data
*Work done as an intern at Amazon. axu@gatech.edu
†Work done while at Amazon
Figure 1. The HandsOff framework uses a small number of exist-ing labeled images and a generative model to produce infinitely many labeled images. can often lead to imbalanced datasets that are unrepresenta-tive of the overall data distribution. For example, in long-tail settings, the data used to train a model often does not contain rare, yet crucial edge cases [39].
These limitations make collecting ever increasing amounts of hand labeled data unsustainable. We advocate for a shift away from the standard paradigm towards a world where training data comes from an infinite collection of au-tomatically generated labeled images. Such a dataset gen-eration approach can allow ML practitioners to synthesize datasets in a controlled manner, unlocking new model de-velopment paradigms such as controlling the quality of gen-erated labels and mitigating the long-tail problem.
In this work, we propose HandsOff, a generative adver-sarial network (GAN) based dataset generation framework.
HandsOff is trained on a small number of existing labeled images and capable of producing an infinite set of synthetic images with corresponding labels (Fig. 1). To do so, we unify concepts from two disparate fields: dataset genera-tion and GAN inversion. While the former channels the expressive power of GANs to dream new ideas in the form of images, the latter connects those dreams to the knowl-edge captured in annotations. In this way, our work brings together what it means to dream and what it means to know.
Concretely, our paper makes the following contributions: 1. We propose a novel dataset generating framework, called HandsOff, which unifies the fields of dataset
generation and GAN inversion. While prior meth-ods for dataset generation [40] require new human annotations on synthetically generated images, Hand-sOff uses GAN inversion to train on existing labeled datasets, eliminating the need for human annotations.
With ≤ 50 real labeled images, HandsOff is capable of producing high quality image-label pairs (Sec. 3). 2. We demonstrate the HandsOff framework’s ability to generate semantic segmentation masks, keypoint heatmaps, and depth maps across several challeng-ing domains (faces, cars, full body fashion poses, and urban driving scenes) by evaluating performance of a downstream task trained on our synthetic data (Sec. 4.2, 4.3, and 4.4). 3. We show that HandsOff is capable of mitigating the effects of the long-tail in semantic segmentation tasks.
By modifying the distribution of the training data,
HandsOff is capable of producing datasets that, when used to train a downstream task, dramatically improve performance in detecting long-tail parts (Sec. 4.5). 2.