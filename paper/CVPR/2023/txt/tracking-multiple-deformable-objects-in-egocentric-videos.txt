Abstract
Most existing multiple object tracking (MOT) methods that solely rely on appearance features struggle in tracking highly deformable objects. Other MOT methods that use motion clues to associate identities across frames have dif-ficulty handling egocentric videos effectively or efficiently.
In this work, we present DogThruGlasses, a large-scale deformable multi-object tracking dataset, with 150 videos and 73K annotated frames, which is collected exclusively by smart glasses. We also propose DETracker, a new MOT method that jointly detects and tracks deformable objects in egocentric videos. DETracker uses three novel mod-ules, namely the motion disentanglement network (MDN), the patch association network (PAN) and the patch memory network (PMN), to explicitly tackle severe ego motion and track fast morphing target objects. DETracker is end-to-end trainable and achieves near real-time speed, which outper-forms existing state-of-the-art method on DogThruGlasses and YouTube-Hand. 1.

Introduction
Wearable cameras have become an emerging trend, pro-moted by the rapidly growing collection of consumer prod-†Work done during Mingzhen’s internship with Meta. ucts such as smart glasses. As the wearable cameras became more powerful with increased battery capacity, sensor size, on-board memory volume, and sophisticated in-device pro-cessors, there is an increasing demand for real-time scene understanding to run reliably and yet efficiently on-device.
The underlying computer vision algorithms, on the other hand, frequently starts from the detection and tracking of objects within the scene. For the egocentric videos captured from wearable cameras, besides being challenged by oc-clusion, morphing shapes, and multiple visually resembling objects, the multiple object tracking (MOT) algorithms are stressed by the constantly changing egocentric viewpoint.
Unique to wearable cameras, the large ego motion caused by the head movements of the wearer is often dras-tic, unpredictable, and largely uncorrelated to the object motions. The reduced predictability of motion patterns forces traditional MOT algorithms [45] to search in larger regions to maintain same performance level, which in turn compromises the running speed and makes them less suit-In the meanwhile, the ego able for on-device execution. motion may also exacerbate the deformation and occlu-sion of objects, by imposing lens distortion, blurriness and rolling shutter, especially those in the near field. The ego motion also aggravates object occlusion due to the con-stantly changing of points of view. These side effects fur-ther downgrade the performance of appearance-based MOT
approaches [16, 42, 53]. 2.