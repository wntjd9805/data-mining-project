Abstract
Despite incredible advances, deep learning has been shown to be susceptible to adversarial attacks. Numerous approaches have been proposed to train robust networks both empirically and certiﬁably. However, most of them de-fend against only a single type of attack, while recent work takes steps forward in defending against multiple attacks. In this paper, to understand multi-target robustness, we view this problem as a bargaining game in which different players (adversaries) negotiate to reach an agreement on a joint direction of parameter updating. We identify a phenomenon named player domination in the bargaining game, namely that the existing max-based approaches, such as MAX and
MSD, do not converge. Based on our theoretical analysis, we design a novel framework that adjusts the budgets of differ-ent adversaries to avoid any player dominance. Experiments on standard benchmarks show that employing the proposed framework to the existing approaches signiﬁcantly advances multi-target robustness. 1.

Introduction
Machine learning (ML) models [15, 47, 48] have been shown to be susceptible to adversarial examples [39], where human-imperceptible perturbations added to a clean example might arbitrarily change the output of machine learning mod-els. Adversarial examples are generated by maximizing the loss within a small perturbation region around a clean exam-ple, e.g., `
, `1 and `2 balls. On the other hand, numerous heuristic defenses have been proposed to be robust against 1
*Corresponding author.
Figure 1. Robust accuracy against PGD attacks and AutoAttack (“AA” in this ﬁgure) on CIFAR-10. “All” means that the model suc-cessfully defends against the `1, `2, and ` (PGD or AutoAttack) attacks simultaneously. Compared with the previously best-known methods, our proposed framework achieves improved performance.
“w. `1” and “w. `2” refer to the model training with our proposed
AdaptiveBudget algorithm with `1 or `2 norms, respectively. 1 adversarial examples, e.g., distillation [31], logit-pairing [19] and adversarial training [25].
However, most of the existing defenses are only robust against one type of attacks [11, 25, 33, 49], while they fail to defend against other adversaries. For example, existing work [18, 26] showed that robustness in the `p threat model does not necessarily generalize to other `q threat models
= q. However, for the sake of the safety of ML when p systems, it has been argued that one should target robustness against multiple adversaries simultaneously [7]. 6
Recently, various methods [26,35,41] have been proposed to address this problem. Multi-target adversarial training, which targets defending against multiple adversarial per-turbations, has attracted signiﬁcant attention: a variational autoencoder-based model [35] learns a classiﬁer robust to multiple perturbations; after that, MAX and AVG strategies, which aggregate different adversaries for adversarial training against multiple threat models, have been shown to enjoy improved performance [41]. To further advance the robust-ness against multiple adversaries, MSD [26] is proposed and outperformed MAX and AVG by taking the worst case over all steepest descent directions. These methods follow a general scheme similar to the (single-target) adversarial training. They ﬁrst sample adversarial examples by different adversaries and then update the model with the aggregation of the gradients from these adversarial examples.
This general scheme for multi-target adversarial training can be seen as an implementation of a cooperative bargaining game [40]. In this game, different parties have to decide how to maximize the surplus they jointly get. In the multi-target adversarial training, we view each party as an adversary, and they negotiate to reach an agreed gradient direction that maximizes the overall robustness.
Inspired by the bargaining game modelling for multi-target adversarial training, we ﬁrst analyze the convergence property of existing methods, i.e., MAX [41], MSD [26], and AVG [41], and identify a phenomenon namely player domination. Speciﬁcally, it refers to the case where one player dominates the bargaining game at any time t, and the gradient at any time t is the same as this player’s gradi-ent. Furthermore, we notice that under the SVM and linear model setups, player domination always occurs when using
MAX and MSD, which leads to non-convergence. Based on such theoretical results, we propose a novel mechanism that adaptively adjusts the budgets of adversaries to avoid the player domination. We show that with our proposed mecha-nism, the overall robust accuracy of MAX, AVG and MSD improves on three representative datasets. We also illustrate the performance improvement on CIFAR-10 in Figure 1.
In this paper, we present the ﬁrst theoretical analysis of the convergence of multi-target robustness on three algo-rithms under two models. Building on our theoretical results, we introduce a new method called AdaptiveBudget, de-signed to prevent the player domination phenomenon that can cause MSD and MAX to fail to converge. Our exten-sive experimental results demonstrate the superiority of our approach over previous methods. 2.