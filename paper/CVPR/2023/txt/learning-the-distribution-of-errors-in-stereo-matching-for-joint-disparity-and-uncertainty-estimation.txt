Abstract
We present a new loss function for joint disparity and uncertainty estimation in deep stereo matching. Our work is motivated by the need for precise uncertainty estimates and the observation that multi-task learning often leads to improved performance in all tasks. We show that this can be achieved by requiring the distribution of uncertainty to match the distribution of disparity errors via a KL diver-gence term in the network’s loss function. A differentiable soft-histogramming technique is used to approximate the distributions so that they can be used in the loss. We exper-imentally assess the effectiveness of our approach and ob-serve significant improvements in both disparity and uncer-tainty prediction on large datasets. Our code is available at https://github.com/lly00412/SEDNet.git. 1.

Introduction
Many computer vision problems can be formulated as estimation tasks. Considering, however, that even high-performing estimators are not error-free, associating con-fidence or uncertainty with their estimates is of great im-portance, particularly in critical applications. In this paper, we focus on disparity estimation via stereo matching, but we are confident that our approach is applicable to other pixel-wise regression tasks after minor modifications.
We distinguish between confidence and uncertainty: the former refers to a probability or likelihood of correctness, while the latter is related to the magnitude of the expected error of an estimate. Confidence can be used to reject es-timates that are suspected to be incorrect, or to rank them from most to least reliable. We argue that uncertainty is more valuable because it can also used for fusing multiple observations, e.g. in a Kalman filtering framework. Most research has focused on confidence estimation for stereo matching [12, 30]. Moreover, most methods estimate confi-dence for pre-computed disparities that are not further im-proved. Joint estimation of disparity and confidence, which benefits both due to multi-task learning, is addressed infre-quently [19, 20, 26, 34].
Our work is partially inspired by the joint treatment of epistemic and aleatoric uncertainty by Kendall and Gal
[14], who propose novel loss functions that give rise to un-certainty estimates in pixel-wise vision tasks. Results on semantic segmentation and single-image depth estimation demonstrate how the primary task benefits from simulta-neous uncertainty estimation. Kendall and Gal argue that
“in many big data regimes (such as the ones common to deep learning with image data), it is most effective to model aleatoric uncertainty,” while epistemic uncertainty can be reduced when large amounts of data are available. Here, we restrict our attention to aleatoric uncertainty.
Our motivation is that ideally we should be able to pre-dict the magnitude of the estimator’s error at each pixel. Of course, this is unrealistic, since if it was possible, we could drive all errors down to zero. A feasible objective is to train an uncertainty estimator whose outputs follow the same dis-tribution as the true errors of the disparity estimator.
In this paper, we present an implementation of this con-cept via a deep network that jointly estimates disparity and its uncertainty from a pair of rectified images. We named the network SEDNet, for Stereo Error Distribution Net-work. SEDNet includes a novel, lightweight uncertainty es-timation subnetwork that predicts the aleatoric uncertainty
Left Image
Predicted Disparity
Figure 1. Examples of left images and predicted disparity maps by
SEDNet on DrivingStereo [36]. The first example is taken around sunset with over-exposure. The second example is taken on a rainy day with under-exposure. In both challenge cases, SEDNet pre-dicts accurate disparity.
of stereo matching, and a new loss to match the distribution of uncertainties with that of disparity errors. To generate the inputs to this new loss, we approximate the distributions from the samples of disparity errors and uncertainty values in a differentiable way via a soft-histogramming technique.
We present extensive experimental validation of SED-Net’s performance in disparity estimation and uncertainty prediction on large datasets with ground truth. SEDNet is superior to baselines with similar, even identical, architec-ture, but without the proposed loss function. Our main con-tributions are:
• a novel uncertainty estimation subnetwork that extracts information from the intermediate multi-resolution disparity maps generated by the disparity subnetwork,
• a differentiable soft-histogramming technique used to approximate the distributions of disparity errors and estimated uncertainties,
• a loss based on KL divergence applied on histograms obtained with the above technique. 2.