Abstract
Previous methods solve feature matching and pose esti-mation using a two-stage process by ﬁrst ﬁnding matches and then estimating the pose. As they ignore the geomet-ric relationships between the two tasks, they focus on ei-ther improving the quality of matches or ﬁltering poten-tial outliers, leading to limited efﬁciency or accuracy. In contrast, we propose an iterative matching and pose es-timation framework (IMP) leveraging the geometric con-nections between the two tasks: a few good matches are enough for a roughly accurate pose estimation; a roughly accurate pose can be used to guide the matching by pro-viding geometric constraints. To this end, we implement a geometry-aware recurrent attention-based module which jointly outputs sparse matches and camera poses. Specif-ically, for each iteration, we ﬁrst implicitly embed geo-metric information into the module via a pose-consistency loss, allowing it to predict geometry-aware matches pro-gressively. Second, we introduce an efﬁcient IMP, called
EIMP, to dynamically discard keypoints without potential matches, avoiding redundant updating and signiﬁcantly re-ducing the quadratic time complexity of attention computa-tion in transformers. Experiments on YFCC100m, Scannet, and Aachen Day-Night datasets demonstrate that the pro-posed method outperforms previous approaches in terms of accuracy and efﬁciency. Code is available at https:
//github.com/feixue94/imp-release 1.

Introduction
Feature matching and relative pose estimation are two fundamental tasks in computer vision and especially impor-tant to visual localization and 3D reconstruction. Tradition-ally, the two tasks are performed in two stages separately by ﬁrst ﬁnding correspondences between keypoints ex-tracted from two images with nearest neighbor (NN) match-ing and then estimating the relative pose from predicted matches with robust estimators, e.g. RANSAC [6, 7, 20, 32].
This pipeline has been the de-facto standard framework for decades [5]. However, due to repetitive textures/structures,
For each image pair, we report
Process of iterative matching and pose esti-Figure 1. mation. the number in-liers/rotation/translation errors (top-left) and retained keypoints in left/right images (top-right) at iterations from 1 to 4.
In the it-erative process, our method ﬁnds more inliers spanning almost the whole image, estimates increasingly precise pose and discards keypoints without true matches gradually. changing appearances and viewpoint variations, matches given by NN often contain a large number of outliers, lead-ing to poor pose accuracy [36, 37]. To mitigate this prob-lem, some works [8, 10, 16, 27, 40, 48, 49, 52] ﬁlter potential outliers of predicted matches with neural networks to im-prove the pose accuracy. Although they report better results, their performance is limited by the quality of initial matches and require extra time for ﬁltering at test time. Alterna-tively, advanced matchers such as SuperGlue [36] enhance the matching quality directly by using global information from all keypoints via transformers [45] with a ﬁxed num-ber (e.g. 9) of iterations. These methods have obtained re-markable performance. Yet, their quadratic time complex-ity for the attention computation degrades the efﬁciency in real applications. Some following works [12,38,41] explore more efﬁcient variations, they run faster but are signiﬁcantly less accurate (see Table 1 and 3).
In this paper, we aim to introduce an efﬁcient and accu-rate framework for iterative matching and pose estimation.
Our approach is built upon the following observations: (1) a few well distributed matches (e.g. 5) could give a roughly accurate pose (e.g. essential matrix); (2) in turn, a roughly
accurate pose could provide strong geometric constraints (e.g. epipolar line) to ﬁnd more accurate matches at low cost; (3) the pose also reveals which keypoints have po-tential correspondences, preventing redundant operations.
Based on the geometric connections of the two tasks, we propose an iterative matching and pose estimation frame-work (IMP), to perform matching and pose estimation it-eratively as opposed to in two separate stages. Speciﬁcally, we progressively augment descriptors with self and cross at-tention as [12,36,38,41], ﬁnd matches and estimate the rela-tive pose. As descriptors get gradually more discriminative, more correct matches can be found, leading to increasingly more precise pose, as shown in Fig. 1. However, due to the noise [26] and degeneration (e.g. co-planar keypoints) [13], not all inliers could give a good pose [4, 18]. In addition to the classiﬁcation loss mainly used by prior methods [12,36], we apply a pose-consistency loss [49] to the matching pro-cess, enabling the model to ﬁnd matches which are not only accurate but also able to give a good pose.
Moreover, in order to avoid redundant operations on un-informative keypoints, we employ a sampling strategy by combining the matching and attention scores of keypoints and the uncertainty of predicted poses to adaptively remove useful keypoints, as shown in Fig. 1. Compared with prior sampling approaches [19, 44] based mainly on attention scores, our adaptive strategy overcomes the over-sampling problem effectively. Our framework reduces the time cost from two aspects. First, in contrast to adopting a ﬁxed num-ber of iterations for all cases [12, 36, 38], it runs fewer it-erations for easy cases with few viewpoint or appearance changes and more for challenging cases. Second, it re-duces the cost of each iteration, signiﬁcantly reducing the quadratic time complexity of attention computation. We also show that discarding potential outliers increases not only efﬁciency but also accuracy (see Sec. 5). The efﬁcient version of IMP is called EIMP. Ours contributions are as follows:
• We propose to perform geometry-aware matching and pose estimation iteratively, allowing the two tasks to boost each other in an iterative manner.
• We adopt a robust sampling strategy to adaptively dis-card redundant keypoints in the iteration process, sig-niﬁcantly decreasing the time complexity.
• We apply the pose uncertainty to the sampling strat-egy, which further improves the accuracy matching and pose estimation.
Our experiments on relative pose estimation and large-scale localization tasks demonstrate that our method out-performs previous competitors and is more efﬁcient. We organize the rest of the paper as follows. In Sec. 2, we dis-cuss related works. In Sec. 3, we give a detailed description of our method. We test the performance of our model in
Sec. 5 and conclude the paper in Sec. 6. 2.