Abstract
Recently, tampered text detection in document image has attracted increasingly attention due to its essential role on information security. However, detecting visually consis-tent tampered text in photographed document images is still a main challenge. In this paper, we propose a novel frame-work to capture more fine-grained clues in complex scenar-ios for tampered text detection, termed as Document Tam-pering Detector (DTD), which consists of a Frequency Per-ception Head (FPH) to compensate the deficiencies caused by the inconspicuous visual features, and a Multi-view It-erative Decoder (MID) for fully utilizing the information of features in different scales.
In addition, we design a new training paradigm, termed as Curriculum Learning for
Tampering Detection (CLTD), which can address the con-fusion during the training procedure and thus to improve the robustness for image compression and the ability to generalize. To further facilitate the tampered text detec-tion in document images, we construct a large-scale docu-ment image dataset, termed as DocTamper, which contains 170,000 document images of various types. Experiments demonstrate that our proposed DTD outperforms previous state-of-the-art by 9.2%, 26.3% and 12.3% in terms of
F-measure on the DocTamper testing set, and the cross-domain testing sets of DocTamper-FCD and DocTamper-SCD, respectively. Codes and dataset will be available at https://github.com/qcf-568/DocTamper. 1.

Introduction
Document images are one of the most essential media for information transmission in modern society, which con-tains amounts of sensitive and privacy information such as telephone numbers. As the rapid development of the image editing technologies, such sensitive text informa-tion can be more easily to be tampered for malicious pur-Figure 1. Tampered text in document images usually have rela-tively small areas and few visual tampering clue. poses such as defraud, causing serious information security risks [33,42,48,50]. Therefore, detecting tampering in doc-ument images has become an important research topic in re-cent years [18,47]. It is crucial to develop effective methods to examine whether a document image is modified, mean-while identifying the exact location of the tampered text.
Most text tamper methods in documents images can be generally categorized into three types: (1) Splicing, which copies regions from one image and paste to other images; (2) Copy-move, which shifts the spatial locations of objects within images; (3) Generation, which replaces regions of images with visually plausible but different contents, As shown in Fig. 1. Though tampering detection in natural images has been studied for years [14, 49], it differs a lot from that in document images. For natural images, tam-pering detection mainly relies on the relatively obvious vi-sual tampered clues on edge or surface of the object, which hardly exist in documents, especially for copy-move and splicing [1, 47]. This is because document images mostly have the same background color, and text within clusters usually has the same font and size. Therefore, the tampered
text regions can not be effectively detected based only on vi-sual clues. To this end, in this paper we propose to incorpo-rate both visual and frequency clues to improve the ability on identifying the tampered text regions in documents.
Recently, some promising methods have been proposed for tampered text detection [8,18,47] by analysing the text’s appearance on scanned documents. Though significant pro-gresses have been achieved on simple and clean documents, detecting elaborately tampered text regions in various pho-tographed documents is still an open challenge.
In this paper, we propose a multi-modality Transformer-based method, termed as Document Tampering Detector (DTD), for Document Image Tampering Detection (DITD).
The proposed model utilizes features from both visual do-main and frequency domain. The former one are extracted from Visual Perception Head with the original image as in-put. For the latter one, different from the previous work [43] that leveraged the high-pass filtered results of RGB images, we utilize the DCT coefficients as the input of our model’s
Frequency Perception Head to obtain the corresponding em-bedding. Through a fusion module with a concatenation op-eration and an attention module, the features in these two modules are incorporated effectively and then fed into a
Swin-Transformer [27] based encoder. Finally, we intro-duce a new Multi-view Iterative Decoder to progressively perceive the tampered text regions.
From our experiments, we find image compression can cover up some of tampering clues and models usually lack robustness to it at start. Training in randomly compressed images will bring confusion to models and they couldn’t work well on the challenging DITD tasks. Therefore, we further propose a new training paradigm, termed as Curricu-lum Learning for Tampering Detection (CLTD), to train the models in an easy-to-hard manner. In such way, the model can firstly learn how to spot tampering clues accurately and then gradually gain the robustness to image compression.
As there lack large-scale tampered document dataset, We introduce a new method to create realistic tampered text data and construct a large-scale dataset, termed as DocTam-per, with 170k tampered document images of diverse types.
We conduct sufficient experiments on both our proposed
DocTamper and the T-SROIE dataset [47]. Both the qualita-tive and quantitative results demonstrate that our DTD can significantly outperform previous state-of-the-art methods.
In summary, our main contributions are as follows:
• We introduce DTD, a powerful multi-modality model for tampered text detection in document images.
• We propose CLTD, a new training paradigm to en-hance the generalization ability and robustness of the proposed tampering detection model
• We propose a novel data synthetic method to gener-ate realistic tampered documents efficiently with only unlabeled document images.
• We construct a comprehensive large-scale dataset with various scenarios and tampering methods to further fa-cilitate the research on tampered text detection task. 2.