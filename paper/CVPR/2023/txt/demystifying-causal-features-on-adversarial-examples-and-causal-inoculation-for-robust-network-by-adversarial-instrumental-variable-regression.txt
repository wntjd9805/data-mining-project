Abstract
The origin of adversarial examples is still inexplicable in research fields, and it arouses arguments from various view-points, albeit comprehensive investigations. In this paper, we propose a way of delving into the unexpected vulnera-bility in adversarially trained networks from a causal per-spective, namely adversarial instrumental variable (IV) re-gression. By deploying it, we estimate the causal relation of adversarial prediction under an unbiased environment dis-sociated from unknown confounders. Our approach aims to demystify inherent causal features on adversarial exam-ples by leveraging a zero-sum optimization game between a casual feature estimator (i.e., hypothesis model) and worst-case counterfactuals (i.e., test function) disturbing to find causal features. Through extensive analyses, we demon-strate that the estimated causal features are highly related to the correct prediction for adversarial robustness, and the counterfactuals exhibit extreme features significantly devi-ating from the correct prediction. In addition, we present how to effectively inoculate CAusal FEatures (CAFE) into defense networks for improving adversarial robustness. 1.

Introduction
Adversarial examples, which are indistinguishable to hu-man observers but maliciously fooling Deep Neural Net-works (DNNs), have drawn great attention in research fields due to their security threats used to compromise machine learning systems. In real-world environments, such poten-tial risks evoke weak reliability of the decision-making pro-cess for DNNs and pose a question of adopting DNNs in safety-critical areas [4, 58, 66].
To understand the origin of adversarial examples, semi-nal works have widely investigated the adversarial vulner-ability through numerous viewpoints such as excessive lin-earity in a hyperplane [26], aberration of statistical fluctu-ations [59, 63], and phenomenon induced from frequency
*Equal contribution. † Corresponding author.
Figure 1. Data generating process (DGP) with IV. By deploying Z, it can estimate causal relation between treatment T and outcome
Y under exogenous condition for unknown confounders U . information [73]. Recently, several works [34, 35, 40] have revealed the existence and pervasiveness of robust and non-robust features in adversarially trained networks and pointed out that the non-robust features on adversarial ex-amples can provoke unexpected misclassifications.
Nonetheless, there still exists a lack of common consen-sus [22] on underlying causes of adversarial examples, al-beit comprehensive endeavors [32,64]. It is because that the earlier works have focused on analyzing associations be-tween adversarial examples and target labels in the learning scheme of adversarial training [42, 54, 67, 72, 77], which is canonical supervised learning. Such analyses easily induce spurious correlation (i.e., statistical bias) in the learned as-sociations, thereby cannot interpret the genuine origin of adversarial vulnerability under the existence of possibly bi-ased viewpoints (e.g., excessive linearity, statistical fluc-tuations, frequency information, and non-robust features).
In order to explicate where the adversarial vulnerability comes from in a causal perspective and deduce true adver-sarial causality, we need to employ an intervention-oriented approach (i.e., causal inference) that brings in estimating causal relations beyond analyzing merely associations for the given data population of adversarial examples.
One of the efficient tools for causal inference is in-strumental variable (IV) regression when randomized con-trolled trials (A/B experiments) or full controls of unknown confounders are not feasible options.
It is a popular ap-proach used to identify causality in econometrics [13, 16, 47], and it provides an unbiased environment from un-known confounders that raise the endogeneity of causal in-In IV regression, the instrument is utilized ference [55].
to eliminate a backdoor path derived from unknown con-founders by separating exogenous portions of treatments.
For better understanding, we can instantiate a case of find-ing causal relations [9] between education T and earnings
Y as illustrated in Fig. 1. Solely measuring correlation be-tween the two variables does not imply causation, since there may exist unknown confounders U (e.g., individual ability, family background, etc.). Ideally, conditioning on
U is the best way to identify causal relation, but it is impos-sible to control the unobserved variables. David Card [9] has considered IV as the college proximity Z, which is di-rectly linked with education T but intuitively not related with earnings Y . By assigning exogenous portion to Z, it can provide an unbiased environment dissociated from U for identifying true causal relation between T and Y .
Specifically, once regarding data generating process (DGP) [53] for causal inference as in Fig. 1, the existence of unknown confounders U could create spurious correlation generating a backdoor path that hinders causal estimator h (i.e., hypothesis model) from estimating causality between treatment T and outcome Y (T ← U → Y ). By adopt-ing an instrument Z, we can acquire the estimand of true causality from h in an unbiased state (Z → T → Y ). Bring-ing such DGP into adversarial settings, the aforementioned controversial perspectives (e.g., excessive linearity, statisti-cal fluctuations, frequency information, and non-robust fea-tures) can be regarded as possible candidates of unknown confounders U to reveal adversarial origins.
In most ob-servational studies, everything is endogenous in practice so that we cannot explicitly specify all confounders and con-duct full controls of them in adversarial settings. Accord-ingly, we introduce IV regression as a powerful causal ap-proach to uncover adversarial origins, due to its capability of causal inference although unknown confounders remain.
Here, unknown confounders U in adversarial settings easily induce ambiguous interpretation for the adversarial origin producing spurious correlation between adversarial
In order to uncover the examples and their target labels. adversarial causality, we first need to intervene on the in-termediate feature representation derived from a network f and focus on what truly affects adversarial robustness irre-spective of unknown confounders U , instead of model pre-diction. To do that, we define the instrument Z as feature variation in the feature space of DNNs between adversar-ial examples and natural examples, where the variation Z is originated from the adversarial perturbation in the im-age domain such that Z derives adversarial features T for the given natural features. Note that regarding Z as in-strument is reasonable choice, since the feature variation alone does not serve as relevant information for adversar-ial prediction without natural features. Next, once we find causality-related feature representations on adversarial ex-amples, then we name them as causal features Y that can encourage robustness of predicting target labels despite the existence of adversarial perturbation as in Fig. 1.
In this paper, we propose adversarial instrumental vari-able (IV) regression to identify causal features on adversar-ial examples concerning the causal relation of adversarial prediction. Our approach builds an unbiased environment for unknown confounders U in adversarial settings and es-timates inherent causal features on adversarial examples by employing generalized method of moments (GMM) [28] which is a flexible estimation for non-parametric IV regres-sion. Similar to the nature of adversarial learning [5, 25], we deploy a zero-sum optimization game [20, 41] between a hypothesis model and test function, where the former tries to unveil causal relation between treatment and outcome, while the latter disturbs the hypothesis model from esti-mating the relation. In adversarial settings, we regard the hypothesis model as a causal feature estimator which ex-tracts causal features in the adversarial features to be highly related to the correct prediction for the adversarial robust-ness, while the test function makes worst-case counterfac-tuals (i.e., extreme features) compelling the estimand of causal features to significantly deviate from correct predic-tion. Consequently, it can further strengthen the hypothesis model to demystify causal features on adversarial examples.
Through extensive analyses, we corroborate that the es-timated causal features on adversarial examples are highly related to correct prediction for adversarial robustness, and the test function represents the worst-case counterfactuals on adversarial examples. By utilizing feature visualiza-tion [43, 50], we interpret the causal features on adversar-ial examples in a human-recognizable way. Furthermore, we introduce an inversion of the estimated causal features to handle them on the possible feature bound and present a way of efficiently injecting these CAusal FEatures (CAFE) into defense networks for improving adversarial robustness. 2.