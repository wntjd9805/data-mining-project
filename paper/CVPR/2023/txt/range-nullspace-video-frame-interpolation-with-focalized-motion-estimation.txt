Abstract
Continuous-time video frame interpolation is a funda-mental technique in computer vision for its flexibility in synthesizing motion trajectories and novel video frames at arbitrary intermediate time steps. Yet, how to infer accu-rate intermediate motion and synthesize high-quality video frames are two critical challenges. In this paper, we present a novel VFI framework with improved treatment for these challenges. To address the former, we propose focalized trajectory fitting, which performs confidence-aware motion trajectory estimation by learning to pay focus to reliable optical flow candidates while suppressing the outliers. The second is range-nullspace synthesis, a novel frame renderer cast as solving an ill-posed problem addressed by learning decoupled components in orthogonal subspaces. The pro-posed framework sets new records on 7 of 10 public VFI benchmarks. 1.

Introduction
Continuous-time Video Frame Interpolation (VFI) aims at upsampling the temporal resolution of low frame-rate videos steplessly by synthesizing the missing frames at ar-bitrary time steps. It is a fundamental technology for vari-ous downstream video applications such as streaming [34], stabilization [5], and compression [35].
A key challenge of this task is to find a continuous map-ping from arbitrary time step to the latent scene motion to correctly render the target frame, observing the low frame-rate video. Typically, it was realized via two stages: motion trajectory fitting and frame synthesis, e.g. [1, 3, 4, 10, 13, 17,
In the former, a parametric trajectory 21, 29, 36, 38, 39]. model is fitted from the optical flows extracted from input frames, which can be resampled at any time step to get in-termediate motion. For representing such a motion model,
∗ This work is done during Zhiyang’s internship at SenseTime. (cid:0) Correspondence be (zhangyulb@gmail.com) and Shunqing Ren (renshunqing@hit.edu.cn). addressed should
Yu to
Zhang
Figure 1. Motivation of the proposed method. Given input frames and extracted optical flows (a), common VFI pipeline (b) is to fit a continuous motion trajectory model, resample flows at the target time step, based on which rendering rays are predicted to synthe-size the intermediate frame by reorganizing pixels from the input frames. Our pipeline (c) proposes improved treatment in two as-pects: 1) our focalized motion estimation assigns dynamic weights to the extracted optical flows to suppress the outlier flows and im-prove fitting accuracy, and the novel range-nullspace solver treats intermediate frame synthesis as an inverse problem instead of di-rect rendering. Please see text for more details. the Taylor polynomial is often adopted with different or-ders [4,13,36]. However, fitting trajectory models are prone to optical flow errors, which are inevitable due to occlusion.
Besides motion fitting, the frame synthesis step faces the challenges of correctly inferring scene geometry. Particu-larly, the intermediate flows resampled from the continuous motion model only depict partial correspondences between the intermediate frame with input frames, while existing methods predict complete rendering rays in a data-driven manner to facilitate full rendering, as shown in Fig. 1 (b).
Though powerful architectures [15] and rendering mecha-nisms [10] were proposed, it requires the network to fully encode the scene geometry to predict correct rays, which may raise the difficulty of architecture design and the bur-den of learning.
To overcome these issues, we propose a novel framework with improved motion fitting and frame synthesis compo-nents. As shown in Fig. 1 (c), the first is focalized trajectory fitting, which extracts a set of optical flow candidates from the input video and assigns learned confidence weights to them. Confidence-aware, differentiable trajectory fitting is then followed, focalizing only the confident flows and pro-ducing improved parametric motion models. Such models, when resampled at the target time step, can produce accu-rate flows even at the occlusion boundary. For the latter, we follow the fact that intermediate frame synthesis is an ill-posed task and propose a deep solver based on the range nullspace theory [2]. Our solver decomposes the latent in-termediate frame into several orthogonal image components and adopts different networks to learn each of them. Such physics-guided design encourages learning decoupled sub-tasks for each network, relieving the burden of encoding scene geometry and benefiting the use of lightweight mod-els.
In particular, our framework sets new records on 7 out of 10 public VFI benchmarks while being parameter-efficient.
We summarize the contributions of this paper as follows. 1) A novel lightweight VFI framework is proposed, which refreshes the records of 7 out of 10 public VFI benchmarks. 2) The idea of focalized trajectory fitting, which improves parametric motion estimation in VFI and generates better resampling quality of intermediate flows. 3) A new perspec-tive that treats intermediate frame synthesis as an ill-posed problem, solved with a deep range nullspace solver that de-couples frame synthesis into several orthogonal tasks. 2.