Abstract
Due to the modality gap between visible and infrared im-ages with high visual ambiguity, learning diverse modality-shared semantic concepts for visible-infrared person re-identification (VI-ReID) remains a challenging problem.
Body shape is one of the significant modality-shared cues for VI-ReID. To dig more diverse modality-shared cues, we expect that erasing body-shape-related semantic concepts in the learned features can force the ReID model to ex-tract more and other modality-shared features for identifi-cation. To this end, we propose shape-erased feature learn-ing paradigm that decorrelates modality-shared features in two orthogonal subspaces. Jointly learning shape-related feature in one subspace and shape-erased features in the orthogonal complement achieves a conditional mutual in-formation maximization between shape-erased feature and identity discarding body shape information, thus enhancing the diversity of the learned representation explicitly. Ex-tensive experiments on SYSU-MM01, RegDB, and HITSZ-VCM datasets demonstrate the effectiveness of our method. 1.

Introduction
Recently, person re-identification (ReID) for pedestrian matching in non-overlapping camera views has experienced fast development. However, ReID is still challenging when people appear both in the daytime and in low-light situa-tions where only infrared cameras can clearly capture their appearances, raising the task of visible-infrared ReID (VI-ReID). Many remarkable works [4, 5, 14, 15, 27, 30] have been witnessed in the field of VI-ReID. For realistic scenar-ios, discovering rich and diverse modality-shared seman-tic concepts usually helps to improve the effectiveness of
VI-ReID [31, 39]. So far, diverse modality-shared feature learning remains challenging.
*Corresponding author
Figure 1. An illustration of our motivation on VI-ReID. It is as-sumed that body shape information and identity-related modality-shared information (presented in dashed box) are partially over-lapped with each other. To make extracted features more di-verse, we propose shape-erased feature learning paradigm that de-composes the representation into shape-related feature and shape-erased one. Learning shape-erased feature drives the model to dis-cover richer modality-shared semantic concepts other than body shape.
Among the cues for VI-ReID, we can identify pedes-trians by their body shapes in many situations, for it con-tains modality-invariant information and also robust to light changes. Nevertheless, body shape is not the only or a sufficient semantic concept that interprets the identity of a person.
It may be hard in some situations to tell the difference only depending on the body shape, but we can still distinguish them by other semantic concepts, such as their belongings, hairstyles or face structures.
Inspired by this, we illustrate an information theoretic measure be-tween visible and infrared modality as a Venn diagram on
It is assumed that the left of the dashed line in Fig. 1. body shape (presented in red) and identity-related modality-shared information (presented in dashed box) are partially overlapped with each other. Note that partially is also due to there exists identity-unrelated information contained in body shape map, e.g., human pose. This partially over-lapped assumption indicates that the target information for
VI-ReID, which is identity-related and modality-shared, can be divided into two independent components that are related and unrelated to body shape.
Based on the above observation and assumption, to dig more diverse modality-shared cues for VI-ReID, we ex-pect to erase the body-shape-related semantic concepts in the features to force the VI-ReID model to extract more and other modality-shared features for identification. As illustrated on the right of the dashed line in Fig. 1, the shape-erased feature is decorrelated from the shape-related feature to simultaneously discover shape-unrelated knowl-edge, while shape-related feature can be explicitly guided by some given body shape prior, which is easy to obtain by existing pre-trained human parsing models [16]. In this way, both shape-related and shape-erased features are ex-plicitly quantified while the discriminative nature of the two features can be independently maintained.
Specifically, we propose shape-erased feature learning paradigm that introduces orthogonality into representation to satisfy a relaxation of independent constraint. The repre-sentation is then decomposed into two sub-representations lying in two orthogonal subspaces for shape-related and shape-erased feature learning, respectively. By learning and covering most discriminative body shape feature in one subspace, the shape-erased feature is forced to dis-cover other modality-shared discriminative semantic con-cepts in the the other subspace as shape-related feature is constrained in its orthogonal complement. Under the above assumptions, we formulate this shape-erased feature learn-ing paradigm from a mutual information perspective, and demonstrate that jointly learning shape-erased and shape-related objectives achieves a conditional mutual informa-tion maximization between shape-erased feature and iden-tity discarding body shape information, thus enhancing the diversity of the learned representation explicitly. We finally design a Shape-Guided dIverse fEature Learning (SGIEL) framework that jointly optimizes shape-related and shape-erased objectives to learn modality-shared and discrimi-native integrated representation. The contributions of our work are summarized as follows:
• We propose a shape-erased feature learning paradigm for VI-ReID that decorrelates shape-erased feature from shape-related one by orthogonal decomposition.
Shape-related feature in one subspace is guided by body shape prior while shape-erased feature is con-to discover strained in its orthogonal complement more and other modality-shared discriminative se-mantic concepts, thus enhancing the diversity of the learned representation explicitly.
• Based on the proposed shape-erased feature learning paradigm, we design a Shape-Guided dIverse fEa-ture Learning framework that jointly optimizes shape-related and shape-erased objectives to learn modality-shared and discriminative integrated representation.
• Extensive experiments on SYSU-MM01, RegDB, and
HITSZ-VCM datasets demonstrate the effectiveness of our method. 2.