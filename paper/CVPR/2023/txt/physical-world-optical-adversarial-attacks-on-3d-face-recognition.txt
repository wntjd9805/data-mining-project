Abstract
The success rate of current adversarial attacks remains low on real-world 3D face recognition tasks because the 3D-printing attacks need to meet the requirement that the generated points should be adjacent to the surface, which limits the adversarial example’ searching space. Addition-ally, they have not considered unpredictable head move-ments or the non-homogeneous nature of skin reflectance in the real world. To address the real-world challenges, we propose a novel structured-light attack against structured-light-based 3D face recognition. We incorporate the 3D reconstruction process and skin’s reflectance in the opti-mization process to get the end-to-end attack and present 3D transform invariant loss and sensitivity maps to im-prove robustness. Our attack enables adversarial points to be placed in any position and is resilient to random head movements while maintaining the perturbation unnotice-able. Experiments show that our new method can attack point-cloud-based and depth-image-based 3D face recog-nition systems with a high success rate, using fewer pertur-bations than previous physical 3D adversarial attacks. 1.

Introduction
As 2D face recognition becomes increasingly vulnerable to attacks, researchers are turning to 3D face data for secure user authentication and other tasks. Structured light imag-ing is a popular method of acquiring 3D face data due to its high precision and superiority in uniform textures [10].
It is widely used in off-the-shelf devices such as Kinect v1 and iPhone [45]. Various 3D face recognition algorithms are proposed based on structured light [11, 15, 29]. FaceID, for example, collects 3D face data using a structured light camera and then uses 3D face data for user authentication.
Although real-world attacks for 2D face recognition have been thoroughly studied [5,27,41], studies on physically re-alizable 3D face recognition attacks are insufficient. Tsai
*B. Xiao is the corresponding author. Our code is available at https://github.com/PolyLiYJ/SLAttack.git.
Figure 1. A demonstration of our attack. We project optical noises on the 3D faces to generate adversarial point clouds. Our attack modifies fewer points than previous attacks and does not need the adversarial points to be adjacent to the 3D surface, thus with a high attack success rate. et al. [30] first proposed 3D printable adversarial examples for point cloud classification tasks. However, the perturba-tions must be strictly adjacent to the surface rather than in arbitrary positions in 3D-printed examples, greatly limiting the adversary’s attack ability. Previous optical adversarial attacks [6, 12, 19, 20, 36, 47] cannot be applied directly to 3D face recognition either. Face reflection is more complex than opaque objects like the stop sign and the principle of 3D reconstruction is different from 2D imaging.
To address the limitations of existing 3D-printing-based adversarial attacks, we propose a new attack called
Structured-Light Attack on 3D face recognition systems, which uses adversarial illumination to attack structured-light-based 3D face recognition. The perturbation can be concealed in the normal fringe patterns or superimposed on the original illumination by using the inherent or an addi-tional projector. Figure 1 shows an overview of our attack.
Without the optical noises, the 3D reconstructed point cloud is recognized as David. While with the elaborate optical noises, the adversarial point cloud is recognized as Athena.
Our attack achieves a higher success rate than previous attacks by precisely simulating the real-world 3D recon-struction process and taking the random head movements into account. We first incorporate the 3D face relighting process in the attack pipeline through the Lambertian re-flectance model. Then, we propose a differential 3D recon-struction substitution. The adversarial illuminations can re-sult in point shiftings in the point cloud and cause dodging or impersonation attacks. Utilizing the 3D reconstruction principle, our attack is end-to-end and can generate adver-sarial points in arbitrary 3D positions. It needs fewer per-turbations than previous 3D attacks with the average attack success rate of 47% in impersonation attacks and 95% in dodging attacks respectively. Our contributions are summa-rized as follows.
• We are the first to realize physical 3D face attacks through adversarial illuminations. The optical pertur-bations are generated end-to-end and are camouflaged by the normal patterns of structured-light projectors.
• Our physical attack is feasible and effective by involv-ing the face relighting process and random 3D trans-formations in the attack pipeline, which significantly improve the 3D reconstruction precision and adversar-ial examples’ robustness to random head movements.
• We attack both point-cloud-based and depth-image-based 3D face recognition models. Compared with previous attacks, our method needs fewer perturba-tions with a high success rate in experiments. 2.