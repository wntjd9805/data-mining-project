Abstract 1.

Introduction
Robust point cloud parsing under all-weather condi-tions is crucial to level-5 autonomy in autonomous driving.
However, how to learn a universal 3D semantic segmen-tation (3DSS) model is largely neglected as most existing benchmarks are dominated by point clouds captured under normal weather. We introduce SemanticSTF, an adverse-weather point cloud dataset that provides dense point-level annotations and allows to study 3DSS under various ad-verse weather conditions. We study all-weather 3DSS mod-eling under two setups: 1) domain adaptive 3DSS that adapts from normal-weather data to adverse-weather data; 2) domain generalizable 3DSS that learns all-weather 3DSS models from normal-weather data. Our studies reveal the challenge while existing 3DSS methods encounter adverse-weather data, showing the great value of SemanticSTF in steering the future endeavor along this very meaningful re-search direction. In addition, we design a domain random-ization technique that alternatively randomizes the geome-try styles of point clouds and aggregates their embeddings, ultimately leading to a generalizable model that can im-prove 3DSS under various adverse weather effectively. The
SemanticSTF and related codes are available at https:
//github.com/xiaoaoran/SemanticSTF.
â€  Corresponding author 3D LiDAR point clouds play an essential role in se-mantic scene understanding in various applications such as self-driving vehicles and autonomous drones. With the re-cent advance of LiDAR sensors, several LiDAR point cloud datasets [2, 11, 49] such as SemanticKITTI [2] have been proposed which greatly advanced the research in 3D se-mantic segmentation (3DSS) [19, 41, 62] for the task of point cloud parsing. As of today, most existing point cloud datasets for outdoor scenes are dominated by point clouds captured under normal weather. However, 3D vision ap-plications such as autonomous driving require reliable 3D perception under all-weather conditions including various adverse weather such as fog, snow, and rain. How to learn a weather-tolerant 3DSS model is largely neglected due to the absence of related benchmark datasets.
Although several studies [3, 33] attempt to include ad-verse weather conditions in point cloud datasets, such as the
STF dataset [3] that consists of LiDAR point clouds cap-tured under various adverse weather, these efforts focus on object detection benchmarks and do not provide any point-wise annotations which are critical in various tasks such as 3D semantic and instance segmentation. To address this gap, we introduce SemanticSTF, an adverse-weather point cloud dataset that extends the STF Detection Benchmark by providing point-wise annotations of 21 semantic categories, as illustrated in Fig. 1. Similar to STF, SemanticSTF cap-tures four typical adverse weather conditions that are fre-quently encountered in autonomous driving including dense fog, light fog, snow, and rain.
SemanticSTF provides a great benchmark for the study of 3DSS and robust point cloud parsing under adverse weather conditions. Beyond serving as a well-suited test bed for examining existing fully-supervised 3DSS meth-ods that handle adverse-weather point cloud data, Semantic-STF can be further exploited to study two valuable weather-tolerant 3DSS scenarios: 1) domain adaptive 3DSS that adapts from normal-weather data to adverse-weather data, and 2) domain generalizable 3DSS that learns all-weather 3DSS models from normal-weather data. Our studies reveal the challenges faced by existing 3DSS methods while pro-cessing adverse-weather point cloud data, highlighting the significant value of SemanticSTF in guiding future research efforts along this meaningful research direction.
In addition, we design PointDR, a new baseline frame-work for the future study and benchmarking of all-weather 3DSS. Our objective is to learn robust 3D representations that can reliably represent points of the same category across different weather conditions while remaining dis-criminative across categories. However, robust all-weather 3DSS poses two major challenges: 1) LiDAR point clouds are typically sparse, incomplete, and subject to substantial geometric variations and semantic ambiguity. These chal-lenges are further exacerbated under adverse weather con-ditions, with many missing points and geometric distortions due to fog, snow cover, etc. 2) More noises are introduced under adverse weather due to snow flicks, rain droplets, etc.
PointDR addresses the challenges with two iterative oper-ations: 1) Geometry style randomization that expands the geometry distribution of point clouds under various spatial augmentations; 2) Embedding aggregation that introduces contrastive learning to aggregate the encoded embeddings of the randomly augmented point clouds. Despite its sim-plicity, extensive experiments over point clouds of different adverse weather conditions show that PointDR achieves su-perior 3DSS generalization performance.
The contribution of this work can be summarized in three major aspects. First, we introduce SemanticSTF, a large-scale adverse-weather point cloud benchmark that provides high-quality point-wise annotations of 21 semantic cate-gories. Second, we design PointDR, a point cloud do-main randomization baseline that can be exploited for future study and benchmarking of 3DSS under all-weather condi-tions. Third, leveraging SemanticSTF, we benchmark exist-ing 3DSS methods over two challenging tasks on domain adaptive 3DSS and domain generalized 3DSS. The bench-marking efforts lay a solid foundation for future research on this highly meaningful problem. 2.