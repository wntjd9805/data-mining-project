Abstract
We propose a simple and application-friendly network (called SimpleNet) for detecting and localizing anoma-lies. SimpleNet consists of four components: (1) a pre-trained Feature Extractor that generates local features, (2) a shallow Feature Adapter that transfers local features to-wards target domain, (3) a simple Anomaly Feature Gener-ator that counterfeits anomaly features by adding Gaussian noise to normal features, and (4) a binary Anomaly Dis-criminator that distinguishes anomaly features from normal features. During inference, the Anomaly Feature Generator would be discarded. Our approach is based on three in-tuitions. First, transforming pre-trained features to target-oriented features helps avoid domain bias. Second, gen-erating synthetic anomalies in feature space is more ef-fective, as defects may not have much commonality in the image space. Third, a simple discriminator is much effi-cient and practical. In spite of simplicity, SimpleNet outper-forms previous methods quantitatively and qualitatively. On
*Corresponding author the MVTec AD benchmark, SimpleNet achieves an anomaly detection AUROC of 99.6%, reducing the error by 55.5% compared to the next best performing model. Further-more, SimpleNet is faster than existing methods, with a high frame rate of 77 FPS on a 3080ti GPU. Additionally,
SimpleNet demonstrates significant improvements in per-formance on the One-Class Novelty Detection task. Code: https://github.com/DonaldRR/SimpleNet. 1.

Introduction
Image anomaly detection and localization task aims to identify abnormal images and locate abnormal subregions.
The technique to detect the various anomalies of interest has a broad set of applications in industrial inspection [3, 6]. In industrial scenarios, anomaly detection and localization is especially hard, as abnormal samples are scarce and anoma-lies can vary from subtle changes such as thin scratches to large structural defects, e.g. missing parts. Some examples from the MVTec AD benchmark [3] along with results from our proposed method are shown in Figure 1. This situation
prohibits the supervised methods from approaching.
Current approaches address this problem in an unsuper-vised manner, where only normal samples are used dur-ing the training process. The reconstruction-based meth-ods [10, 21, 31], synthesizing-based methods [17, 30], and embedding-based methods [6, 22, 24] are three main trends for tackling this problem. The reconstruction-based meth-ods such as [21,31] assume that a deep network trained with only normal data cannot accurately reconstruct anomalous regions. The pixel-wise reconstruction errors are taken as anomaly scores for anomaly localization. However, this as-sumption may not always hold, and sometimes a network can ”generalize” so well that it can also reconstruct the ab-normal inputs well, leading to misdetection [10, 19]. The synthesizing-based methods [17, 30] estimate the decision boundary between the normal and anomalous by training on synthetic anomalies generated on anomaly-free images.
However, the synthesized images are not realistic enough.
Features from synthetic data might stray far from the normal features, training with such negative samples could result in a loosely bounded normal feature space, meaning indistinct defects could be included in in-distribution feature space.
Recently, the embedding-based methods [6, 7, 22, 24] achieve state-of-the-art performance. These methods use
ImageNet pre-trained convolutional neural networks (CNN) to extract generalized normal features. Then a statistical al-gorithm such as multivariate Gaussian distribution [6], nor-malizing flow [24], and memory bank [22] is adopted to em-bed normal feature distribution. Anomalies are detected by comparing the input features with the learned distribution or the memorized features. However, industrial images gener-ally have a different distribution from ImageNet. Directly using these biased features may cause mismatch problems.
Moreover, the statistical algorithms always suffer from high computational complexity or high memory consumption.
To mitigate the aforementioned issues, we propose a novel anomaly detection and localization network, called
SimpleNet. SimpleNet takes advantage of the synthesizing-based and the embedding-based manners, and makes sev-eral improvements. First, instead of directly using pre-trained features, we propose to use a feature adaptor to produce target-oriented features which reduce domain bias.
Second, instead of directly synthesizing anomalies on the images, we propose to generate anomalous features by pos-ing noise to normal features in feature space. We argue that with a properly calibrated scale of the noise, a closely bounded normal feature space can be obtained. Third, we simplify the anomalous detection procedure by training a simple discriminator, which is much more computational efficient than the complex statistical algorithms adopted by the aforementioned embedding-based methods. Specifi-cally, SimpleNet makes use of a pre-trained backbone for normal feature extraction followed by a feature adapter to transfer the feature into the target domain. Then, anomaly features are simply generated by adding Gaussian noise to the adapted normal features. A simple discriminator con-sisting of a few layers of MLP is trained on these features to discriminate anomalies.
SimpleNet is easy to train and apply, with outstand-ing performance and inference speed. The proposed Sim-pleNet, based on a widely used WideResnet50 backbone, achieves 99.6 % AUROC on MVTec AD while running at 77 fps, surpassing the previous best-published anomaly de-tection methods on both accuracy and efficiency, see Fig-ure 2. We further introduce SimpleNet to the task of One-Class Novelty Detection to show its generality. These ad-vantages make SimpleNet bridge the gap between academic research and industrial application. Code will be publicly available. 2.