Abstract
Humans universally dislike the task of cleaning up a messy room.
If machines were to help us with this task, they must understand human criteria for regular arrange-ments, such as several types of symmetry, co-linearity or co-circularity, spacing uniformity in linear or circu-lar patterns, and further inter-object relationships that re-late to style and functionality. Previous approaches for this task relied on human input to explicitly specify goal state, or synthesized scenes from scratch – but such meth-ods do not address the rearrangement of existing messy scenes without providing a goal state.
In this paper, we present LEGO-Net, a data-driven transformer-based it-erative method for LEarning reGular rearrangement of
Objects in messy rooms. LEGO-Net is partly inspired by diffusion models – it starts with an initial messy state and iteratively “de-noises” the position and orientation of ob-jects to a regular state while reducing distance traveled.
Given randomly perturbed object positions and orientations
∗Core contribution. in an existing dataset of professionally-arranged scenes, our method is trained to recover a regular re-arrangement.
Results demonstrate that our method is able to reliably re-arrange room scenes and outperform other methods. We additionally propose a metric for evaluating regularity in room arrangements using number-theoretic machinery. 1.

Introduction
What makes the arrangement of furniture and objects in a room appear regular? While exact preferences may vary, humans have by-and-large universally shared criteria of reg-ular room arrangements: for instance, heavy cabinets are arranged to align with walls, chairs are positioned evenly around a table in linear or circular configurations, or night stands are placed symmetrically on the two sides of a bed.
Humans also share a common dislike of physically perform-ing the task of rearranging a messy room. To build auto-mated robotic systems that can guide or actually rearrange objects in a room, we first need methods that understand the shared human criteria for regular room rearrangements and respect the physical constraints of rearrangements.
Human criteria for regular rearrangements can be sub-tle and complex, including geometric rules of reflexional, translational, or rotational symmetry, linear or circular alignments, and spacing uniformity. Functional and stylistic inter-object relationships are also important: for example, a
TV tends to be in front of and facing a sofa, chairs are next to a table, etc. Many of these criteria interact and, at times, conflict with one another. As a result, in general, there is more than one desirable clean arrangement for any given messy arrangement. In our setting, we further desire that the clean rearrangement we create to be informed by the initial messy arrangement – and not be entirely different – for multiple reasons. First, there may have been a particular clean arrangement that gave rise to the messy one – and it may be desirable to recover a similar arrangement. Second, we want to minimize the motion of objects as much as pos-sible to respect the physical constraints and effort involved – especially the motion of big and heavy furniture. Unfortu-nately, extant methods fail to capture these criteria: methods for scene synthesis from scratch [25, 29, 37, 69, 70, 72] ig-nore the initial state of objects in a room, and rearrangement methods often require scene-specific human input in the form of a goal state [1, 46] or language description [27, 47].
In this paper, we present LEGO-Net, a method for
LEarning reGular rearrangement of Objects in rooms di-rectly from data. Different from work that focuses on ar-ranging new objects from scratch or requires goal state specification, we focus on rearranging existing objects without any additional input at inference time. We take as input the position, orientation, class label, and extents of room objects in a specific arrangement, and output a room with the same objects but regularly re-arranged. LEGO-Net uses a transformer-based architecture [53] that is, in part, motivated by recent denoising diffusion probabilistic mod-els that learn a reverse diffusion process for generative mod-eling [16, 49, 50]. We learn human criteria for regular rear-rangements from a dataset of professionally designed clean (regular) scenes [15], and represent each scene as a collec-tion of objects and a floor plan. Prior to training, we perturb the regular scenes to generate noisy configurations. During training, our transformer learns to predict the original, de-noised arrangement from the perturbed scene and its floor plan. During inference, instead of directly re-arranging scenes with our model, which would amount to na¨ıve re-gression, we run a Langevin dynamics-like reverse process to iteratively denoise object positions and orientations. This iterative process retains the flavor of original room state, while limiting object movement during re-arrangement.
We conduct extensive experiments on public datasets to show that our approach realistically rearranges noisy scene arrangements, while respecting initial object positions. We also demonstrate that our method is able to generalize to previously unseen collection of objects in a wide variety of floor plans. Furthermore, we include extensive experimen-tal results (e.g., Fig. 1 and Fig. 4), including a new metric to evaluate regularity of re-arrangements, aimed at measuring the presence of sparse linear integer relationships among object positions in the final state (using the PSLQ algo-rithm [13]). To sum up, we contribute:
• A generalizable, data-driven method that learns to reg-ularly re-arrange the position and orientation of ob-jects in various kinds of messy rooms.
• An iterative approach to re-arrangement at inference time that retains flavor of the original arrangement and minimizes object travel distance.
• An in-depth analysis of the performance and charac-teristics of the denoising-based scene rearrangement.
• A new metric to measure the regularity of object ar-rangements based on integer relation algorithms. 2.