Abstract
In contrast to the natural capabilities of humans to learn new tasks in a sequential fashion, neural networks are known to suffer from catastrophic forgetting, where the model’s performances on old tasks drop dramatically after being optimized for a new task. Since then, the continual learning (CL) community has proposed several solutions aiming to equip the neural network with the ability to learn the current task (plasticity) while still achieving high accu-racy on the previous tasks (stability). Despite remarkable improvements, the plasticity-stability trade-off is still far from being solved and its underlying mechanism is poorly understood. In this work, we propose Auxiliary Network
Continual Learning (ANCL), a novel method that applies an additional auxiliary network which promotes plasticity to the continually learned model which mainly focuses on stability. More concretely, the proposed framework mate-rializes in a regularizer that naturally interpolates between plasticity and stability, surpassing strong baselines on task incremental and class incremental scenarios.
Through extensive analyses on ANCL solutions, we identify some essential principles beneath the stability-plasticity trade-off. The code implementation of our work is available at https://github.com/kim-sanghwan/ANCL. 1.

Introduction
The continual learning (CL) model aims to learn from current data while still maintaining the information from previous training data. The naive approach of continuously fine-tuning the model on sequential tasks, however, suffers from catastrophic forgetting [8, 21]. Catastrophic forget-ting occurs in a gradient-based neural network because the updates made with the current task are likely to override the model weights that have been changed by the gradients from the old tasks.
Catastrophic forgetting can be understood in terms of stability-plasticity dilemma [22], one of the well-known challenges in continual learning. Specifically, the model not only has to generalize well on past data (stability) but also learn new concepts (plasticity). Focusing on stability will hinder the neural network from learning the new data, whereas too much plasticity will induce more forgetting of the previously learned weights. Therefore, CL model should strike a balance between stability and plasticity.
There are various ways to define the problem of CL.
Generally speaking, it can be categorized into three sce-narios [27] : Task Incremental Learning (TIL), Domain In-cremental Learning (DIL), and Class Incremental Learning (CIL). In TIL, the model is informed about the task that needs to be solved; the task identity is given to the model during the training session and the test time. In DIL, the model is required to solve only one task at hands without the task identity. In CIL, the model should solve the task itself and infer the task identity. Since the model should discriminate all classes that have been seen so far, it is usu-ally regarded as the hardest continual learning scenario. Our study performs extensive evaluations on TIL and CIL set-ting which will be further explained in Sec. 4.
Recently, several papers [19, 20, 28, 31] proposed the usage of an auxiliary network or an extra module that is solely trained on the current dataset, with the purpose of combining this additional structure with the previous net-work or module that has been continuously trained on the old datasets. For example, Active Forgetting with synap-tic Expansion-Convergence (AFEC) [28] regularizes the weights relevant to the current task through a new set of network parameters called the expanded parameters based on weight regularization methods. The expanded param-eters are solely optimized on the current task and are al-lowed to forget the previous ones. As a result, AFEC can reduce potential negative transfer by selectively merging the old parameters with the expanded parameters. The stability-plasticity balance in AFEC is adjusted via hyperparameters which scale the regularization terms for remembering the old tasks and learning the new tasks.
The authors of the above papers propose to mitigate the stability-plasticity dilemma by infusing plasticity through the auxiliary network or module (detailed explanation in
Appendix A). However, a precise characterization of the in-teractive mechanism between the previous model and the auxiliary model is still missing in the literature. Therefore, in this paper, we first formalize the framework of CL that adopts the auxiliary network called Auxiliary Network Con-tinual Learning (ANCL). Given this environment, we then investigate the stability-plasticity trade-off through various analyses from both a theoretical and empirical point of view.
Our main contributions can be summarized as follows:
• We propose the framework of Auxiliary Network Con-tinual Learning (ANCL) that can naturally incorporate the auxiliary network into a variety of CL approaches as a plug-in method (Sec. 3.1).
• We empirically show that ANCL outperforms existing
CL baselines on both CIFAR-100 [16] and Tiny Ima-geNet [17] (Sec. 4).
• Furthermore, we perform three analyses to investigate the stability-plasticity trade-off within ANCL (Sec. 5):
Weight Distance, Centered Kernel Alignment, and
Mean Accuracy Landscape. 2.