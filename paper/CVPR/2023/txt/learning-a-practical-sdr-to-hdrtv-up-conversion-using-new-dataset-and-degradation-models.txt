Abstract at: https://github.com/AndreGuo/HDRTVDM .
In media industry, the demand of SDR-to-HDRTV up-conversion arises when users possess HDR-WCG (high dy-namic range-wide color gamut) TVs while most off-the-shelf footage is still in SDR (standard dynamic range). The re-search community has started tackling this low-level vision task by learning-based approaches. When applied to real
SDR, yet, current methods tend to produce dim and desat-urated result, making nearly no improvement on viewing experience. Different from other network-oriented meth-ods, we attribute such deficiency to training set (HDR-SDR pair). Consequently, we propose new HDRTV dataset (dubbed HDRTV4K) and new HDR-to-SDR degradation models. Then, it’s used to train a luminance-segmented network (LSN) consisting of a global mapping trunk, and two Transformer branches on bright and dark luminance range. We also update assessment criteria by tailored met-rics and subjective experiment. Finally, ablation studies are conducted to prove the effectiveness. Our work is available 1.

Introduction
The dynamic range of image is defined as the maxi-mum recorded luminance to the minimum. Larger lumi-nance container endows high dynamic range (HDR) a bet-ter expressiveness of scene. In media and film industry, the superiority of HDR is further boosted by advanced electro-optical transfer function (EOTF) e.g. PQ/HLG [2], and wide color-gamut (WCG) RGB primaries e.g. BT.2020 [3].
While WCG-HDR displays are becoming more readily available in consumer market, most commercial footage is still in standard dynamic range (SDR) since WCG-HDR version is yet scarce due to exorbitant production workflow.
Hence, there raise the demand of converting vast existing
SDR content for HDRTV service. Such SDR may carry ir-reproducible scenes, but more likely, imperfections brought by old imaging system and transmission. This indicates that
SDR-to-HDRTV up-conversion is an ill-posed low-level vi-sion task, and research community has therefore begun in-volving learning-based methods ( [4–9] etc.).
Yet, versatile networks they use (§2.1), we find current methods’ result dim and desaturated when feeding real SDR images (Fig.1), conflicting with the perceptual motive of
SDR-to-HDRTV up-conversion. As reported by CVPR22-1st Workshop on Vision Dataset Understanding [10], most methods are network-oriented and understate the impact of training set. For restoration-like low-level vision, there are 2 ingredients of a training set: the quality of label GT itself, and the GT-to-LQ degradation model (DM) i.e. what the network learns to restore. Such neglect is getting remedied in other low-level vision tasks [11–16], but still pervasive in learning-based SDR-to-HDRTV up-conversion.
Not serendipitously, we find dataset the reason why cur-rent methods underperform. We exploit several HDRTV-tailored metrics (Tab.4) to assess current training set:(1) by measuring label HDR’s extent of HDR/WCG etc. (Tab.5), we notice that its quality and diversity are inadequate to in-centive the network to produce appealing result, (2) via the statistics of degraded SDR, we find current HDR-to-SDR
DMs’ tendency to exaggeratedly alter the saturation and brightness (see Tab.6) thus network will learn a SDR-to-HDR deterioration. Hence, we propose HDRTV4K dataset (§3.2) consisting of high-quality and diversified (Fig.4)
HDRTV frames as label. Then exploit 3 new HDRTV-to-SDR DMs (§3.3) avoiding above insufficiency, meanwhile possessing appropriate degradation capability (Tab.6) so the network can learn reasonable restoration ability.
Afterwards, we formulate the task as the combination of global mapping on the full luminance range and recovery of low/high luminance range. Correspondingly, we propose
Luminance Segmented Network (LSN, §3.1) where a global trunk and two Transformer-style UNet [17] branches are as-signed to respectively execute divergent operations required in different segmented luminance ranges (areas).
Lastly, as found by [18,19], conventional distance-based metrics well-performed in solely-reconstruction task (e.g. denoising) fail for perceptual-motivated HDR reconstruc-tion, we therefore update the assessment criteria with fine-grained metrics (§4.2) and subjective experiment (§4.3) etc.
Our contributions are three-fold: (1) Emphasizing & ver-ifying the impact of dataset on SDR-to-HDRTV task, which (2) Exploiting novel HDRTV has long been understated. dataset and HDR-to-SDR degradation models for network to learn. (3) Introducing new problem formulation, and ac-cordingly proposing novel luminance segmented network. 2.