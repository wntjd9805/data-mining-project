Abstract
Single domain generalization aims to learn a model from a single training domain (source domain) and apply it to multiple unseen test domains (target domains). Existing methods focus on expanding the distribution of the training domain to cover the target domains, but without estimating the domain shift between the source and target domains. In this paper, we propose a new learning paradigm, namely simulate-analyze-reduce, which first simulates the domain shift by building an auxiliary domain as the target domain, then learns to analyze the causes of domain shift, and finally learns to reduce the domain shift for model adaptation.
Under this paradigm, we propose a meta-causal learning method to learn meta-knowledge, that is, how to infer the causes of domain shift between the auxiliary and source do-mains during training. We use the meta-knowledge to ana-lyze the shift between the target and source domains during testing. Specifically, we perform multiple transformations on source data to generate the auxiliary domain, perform counterfactual inference to learn to discover the causal fac-tors of the shift between the auxiliary and source domains, and incorporate the inferred causality into factor-aware do-main alignments. Extensive experiments on several bench-marks of image classification show the effectiveness of our method. 1.

Introduction
Single domain generalization [28] aims to generalize a model trained using one training domain (source domain) into multiple unseen test domains (target domains). Since only one source domain is given and the target domains are out-of-distribution and unavailable during training, single
∗ Jin Chen and Zhi Gao are co-first authors.
† Corresponding author: Xinxiao Wu.
Figure 1. Illustration of the simulate-analyze-reduce paradigm. In this paradigm, we first simulate the domain shift by constructing an auxiliary domain as the unseen target domain, then learn to analyze the domain shift, and finally learn to reduce the domain shift based on inferred causes. domain generalization is a challenging task and attracts in-creasing interests. Existing works have made considerable successes through expanding the distribution of the source domain by data augmentation [19, 28, 34] or learning adap-tive data normalization [8] typically. However, such suc-cesses have been achieved without explicitly considering the domain shift between the source and target domains, which limits the generalization performance of model in real-world scenarios.
In this paper, we propose a new learning paradigm, namely simulate-analyze-reduce, to address single domain generalization by enabling the model to analyze the real domain shift between the source domain and unseen tar-get domain. This new paradigm is shown in Figure 1. We first build an auxiliary domain as the target domain to sim-ulate the real domain shift between the source and target domains, since the target data is unavailable during train-ing. We then learn to analyze the intrinsic causal factors of the domain shift to facilitate the subsequent model adapta-tion. Finally, we learn to reduce the domain shift with its inferred causes.
Under this paradigm, we propose a meta-causal learn-ing method to learn the meta-knowledge about how to infer the causes of the simulated domain shift between the aux-iliary and source domains via causal inference in training, and then apply the meta-knowledge to analyze the real do-main shift between the target and source domains during testing, through which the source and given target domains are adaptively aligned. Specifically, we perform multiple transformations on source data to generate an auxiliary do-main with great diversity. Then we build a causal graph to represent the dependency among data, variant factors, semantic concepts and category labels, and conduct coun-terfactual inference over the causal graph to exploit the in-trinsic causality of the simulated domain shift between the auxiliary and source domains. For each sample in the aux-iliary domain, we construct counterfactual scenes by inter-vening variant factors to infer their causal effects on the cat-egory prediction, and these inferred causal effects of vari-ant factors can be regarded as the causes of domain shift.
To reduce the domain shift, we propose a factor-aware do-main alignment by learning and integrating multiple feature mappings, where an effect-to-weight network is designed to convert the causal effects of variant factors into the weights of feature mappings.
During testing, the distribution discrepancy between the input target sample and the source domain is analyzed and reduced by applying the learnt meta-knowledge, i.e., infer-ring the causal effects of variant factors and incorporating them into the factor-aware domain alignment. In summary, the main contributions of this paper are as follows:
• We propose a novel learning paradigm, simulate-analyze-reduce, for single domain generalization. This paradigm empowers the model with the ability to esti-mate the domain shift between the source domain and unseen target domains, thus boosting the model adap-tation across different domains.
• We propose a meta-causal learning method based on counterfactual inference to learn the meta-knowledge about analyzing the intrinsic causality of domain shift, thus facilitating the reduction of domain shift.
• Our method achieves the state-of-the-art results on sev-eral benchmarks of image classification, especially on the more challenging tasks with a large domain shift, clearly demonstrating the effectiveness of our method. 2.