Abstract
Self-supervised learning (SSL) has the potential to ben-efit many applications, particularly those where manually annotating data is cumbersome. One such situation is the semantic segmentation of point clouds. In this context, ex-isting methods employ contrastive learning strategies and define positive pairs by performing various augmentation of point clusters in a single frame. As such, these meth-ods do not exploit the temporal nature of LiDAR data. In this paper, we introduce an SSL strategy that leverages pos-itive pairs in both the spatial and temporal domain. To this end, we design (i) a point-to-cluster learning strategy that aggregates spatial information to distinguish objects; and (ii) a cluster-to-cluster learning strategy based on unsu-pervised object tracking that exploits temporal correspon-dences. We demonstrate the benefits of our approach via extensive experiments performed by self-supervised train-ing on two large-scale LiDAR datasets and transferring the resulting models to other point cloud segmentation bench-marks. Our results evidence that our method outperforms the state-of-the-art point cloud SSL methods. 1 1.

Introduction
Semantic segmentation from LiDAR point clouds can be highly beneficial in practical applications, e.g., for self-driving vehicles to safely interact with their surroundings.
Nowadays, state-of-the-art methods [13, 36, 46] achieve this with deep neural networks. While effective, the training of such semantic segmentation networks requires large amounts of annotated data, which is prohibitively costly to acquire, particularly for point-level LiDAR anno-tations [45]. By contrast, with the rapid proliferation of self-driving vehicles, large amounts of unlabeled LiDAR data are generated. Here, we develop a method to exploit such unlabeled data in a self-supervised learning framework.
Self-supervised learning (SSL) aims to learn features without any human annotations [1, 2, 22, 26, 33, 35, 40, 45] but so that they can be effectively used for fine-tuning on a 1Our code and pretrained models will be found at https://github.com/YanhaoWu/STSSL. Correspondence to Ke Wei.
Figure 1. Our method vs existing ones. (Top) Previous methods create positive pairs for SSL by applying different augmentations,
τ1 and τ2 (e.g., random flipping, clipping), to a single frame. (Bot-tom) By contrast, we leverage both spatial and temporal informa-tion via a point-to-cluster and an inter-frame SSL strategy. Points in the same color are from the same cluster in the latent space. downstream task with a small number of labeled samples.
This is achieved by defining a pre-task that does not re-quire annotations. While many pre-tasks have been pro-posed [27], contrastive learning has nowadays become a highly popular choice [30, 33, 40, 41, 45]. In general, it aims to maximize the similarity of positive pairs while potentially minimizing that of negative ones. In this context, most of
• We introduce an SSL strategy for point cloud segmen-tation based only on positive pairs. It does not require any external information, such as pose, GPS, and IMU.
• We propose a novel Point-to-Cluster (P2C) training paradigm that combines the advantages of point-level and cluster-level representations to learn a structured point-level embedding space.
• We introduce the use of cluster-level inter-frame self-supervised leaning on point clouds generated by a Li-DAR sensor, which introduces a new way to integrate temporal information into SSL.
Figure 2. Cars in the same frame but under different illumina-tion angles. Note that the main source of difference between the two instance point clouds arises from the different illumination an-gles.
Our experiments on several datasets, including KITTI [17], nuScene [5], SemanticKITTI [4] and SemanticPOSS [34], evidence that our method outperforms the state-of-the-art
SSL techniques for point cloud data. the point cloud SSL literature focuses on indoor scenes, for which relatively dense point clouds are available. Unfor-tunately, for outdoor scenes, such as the ones we consider here, the data is more complex and much sparser, and cre-ating effective pairs remains a challenge.
Several approaches [33, 45] have nonetheless been pro-posed to perform SSL on outdoor LiDAR point cloud data.
As illustrated in the top portion of Fig. 1, they construct positive pairs of point clusters or scenes by applying aug-mentations to a single frame. As such, they neglect the tem-poral information of the LiDAR data. By contrast, in this paper, we introduce an SSL approach to LiDAR point cloud segmentation based on extracting effective positive pairs in both the spatial and temporal domain.
To achieve this without requiring any pose sensor as in [24, 40], we introduce (i) a point-to-cluster (P2C) SSL strategy that maximizes the similarity between the features encoding a cluster and those of its individual points, thus encouraging the points belonging to the same object to be close in feature space; (ii) a cluster-level inter-frame self-supervised learning strategy that tracks an object across consecutive frames in an unsupervised manner and encour-ages feature similarity between the different frames. These two strategies are depicted in the bottom portion of Fig. 1.
Note that the illumination angle of one object seen in two different frames typically differs. As shown in Fig. 2, this is also the main source of difference between two objects of the same class in the same frame. Therefore, our inter-frame SSL strategy lets us encode not only temporal infor-mation, but also the fact that points from different objects from the same class should be close to each other in feature space. As simulating different illumination angles via data augmentation is challenging, our approach yields positive pairs that better reflects the intra-class variations in LiDAR point clouds than existing single-frame methods [33, 45].
Our contribution can be summarized as follows: 2.