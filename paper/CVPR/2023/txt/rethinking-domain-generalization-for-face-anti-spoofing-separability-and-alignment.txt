Abstract
Live
Spoof
Domain 1
This work studies the generalization issue of face anti-spooﬁng (FAS) models on domain gaps, such as image res-olution, blurriness and sensor variations. Most prior works regard domain-speciﬁc signals as a negative impact, and apply metric learning or adversarial losses to remove them from feature representation. Though learning a domain-invariant feature space is viable for the training data, we show that the feature shift still exists in an unseen test do-main, which backﬁres on the generalizability of the clas-In this work, instead of constructing a domain-siﬁer. invariant feature space, we encourage domain separabil-ity while aligning the live-to-spoof transition (i.e., the tra-jectory from live to spoof) to be the same for all domains.
We formulate this FAS strategy of separability and align-ment (SA-FAS) as a problem of invariant risk minimization (IRM), and learn domain-variant feature representation but domain-invariant classiﬁer. We demonstrate the effective-ness of SA-FAS on challenging cross-domain FAS datasets and establish state-of-the-art performance. Code is avail-able at https://github.com/sunyiyou/SAFAS. 1.

Introduction
Face recognition (FR) [16] has achieved remarkable suc-cess and has been widely employed in mobile access control and electronic payments. Despite the promise, FR systems still suffer from presentation attacks (PAs), including print attacks, digital replay, and 3D masks. As a result, face anti-spooﬁng (FAS) has been an important topic for almost two decades [3, 35, 45, 47, 66, 74, 76].
In early systems like building access and border con-trol with limited variations (e.g., lighting and poses), sim-ple methods [6, 17, 41] have exhibited promise. These al-gorithms are designed for the closed-world setting, where
*This work was done during Yiyou Sun’s internship at Google. 1In statistics, spurious correlation is a mathematical relationship in which multiple events or variables are associated but not causally related.
Decision Factors
Live-to-Spoof 
Transition
Domain Gaps
✗ 
Domain 1
Domain 2
Domain 2
Spurious Correlation! (a)
Common Solution With Mixed Domains
Live
Spoof
Domain 1
Domain 1
Domain 2
Domain 2 (b)
SA-FAS (Ours)
Decision Factors
Live-to-Spoof 
Transition
Domain Gaps
Invariant to the  classiﬁer!
Figure 1. Cross-domain FAS: (a) Common FAS solutions aim to remove domain-speciﬁc signals and mix domains in one cluster.
However, we empirically show domain-speciﬁc signals still exists in the feature space, and model might pick domain-speciﬁc signals as spurious correlation1 for classiﬁcation. (b) Our SA-FAS aims to retain domain signal. Speciﬁcally, we train a feature space with two critical properties: (1) Separability: Samples from differ-ent domains and live/spoof classes are well-separated; (2) Align-ment: Live-to-spoof transitions are aligned in the same direction for all domains. With these two properties, our method keeps the domain-speciﬁc signals invariant to the decision boundary. the camera and environment are assumed to be the same be-tween train and test. This assumption, however, rarely holds for in-the-wild applications, e.g., mobile face unlock and sensor-invariant ID veriﬁcation. Face images in those FAS cases may be acquired from wider angles, complex scenes, and different devices, where it is hard for training data to cover all the variations. These differences between training
and test data are termed domain gaps and the FAS solutions to tackle the domain gaps are termed cross-domain FAS.
Learning domain-invariant representation is the main ap-proach in generic domain generalization [70], and has soon been widely applied to cross-domain FAS [30,43,44,60,67, 72]. Those methods consider domain-speciﬁc signals as a confounding factor for model generalization, and hence aim to remove domain discrepancy from the feature representa-tion partially or entirely. Adversarial training is commonly applied so that upon convergence the domain discriminator cannot distinguish which domain the features come from.
In addition, some methods apply metric learning to further regularize the feature space, e.g., triplet loss [67], dual-force triplet loss [60], and single-side triplet loss [30].
There are two crucial issues that limit the generaliza-tion ability of these methods [30, 43, 44, 60, 67, 72] with domain-invariant feature losses. First, these methods posit a strong assumption that the feature space is perfectly domain-invariant after removing the domain-speciﬁc sig-nals from training data. However, this assumption is un-realistic due to the limited size and domain variants of the training data, on which the loss might easily overﬁt during training. As shown in Fig. 7, the test distribution is more expanded compared to the training one, and the spatial re-lation between live and spoof has largely deviated from the learned classiﬁer. Second, feature space becomes ambigu-ous when domains are mixed together. Note that the domain can carry information on certain image resolutions, blur-riness and sensor patterns.
If features from different do-mains are collapsed together [54], the live/spoof classiﬁer will undesirably leverage spurious correlations to make the live/spoof predictions as shown in Fig. 1 (a), e.g., compar-ing live from low-resolution domains to spoof from high-resolution ones. Such a classiﬁer will unlikely generalize to a test domain when the correlation does not exist.
In this work, we rethink feature learning for cross-domain FAS. Instead of constructing a domain-invariant feature space, we aim to ﬁnd a generalized classiﬁer while explicitly maintaining domain-speciﬁc signals in the repre-sentation. Our strategy can be summarized by the following two properties:
• Separability: We encourage features from different domains and live/spoof classes to be separated which facilitates maintaining the domain signal. According to [4], representations with well-disentangled domain variation and task-relevant features are more general and transferable to different domains.
• Alignment: Inspired by [31], we regard spooﬁng as the process of transition. For similar PA types2, the transition process would be similar, regardless of envi-ronments and sensor variations. With this assumption, 2This work focuses on print and replay attacks. we regularize the live-to-spoof transition to be aligned in the same direction for all domains.
We refer to this new learning framework as FAS with sepa-rability and alignment (dubbed SA-FAS), shown in Fig. 1 (b). To tackle the separability, we leverage Supervised Con-trastive Learning (SupCon) [33] to learn representations that force samples from the same domain and the same live/spoof labels to form a compact cluster. To achieve the alignment, we devise a novel Projected Gradient optimiza-tion strategy based on Invariant Risk Minimization (PG-IRM) to regularize the live-to-spoof transition invariant to the domain variance. With normalization, the feature space is naturally divided into two symmetric half-spaces: one for live and one for spoof (see Fig. 6). Domain variations will manifest inside the half-spaces but have minimal impact to the live/spoof classiﬁer.
We summarize our contributions as three-fold:
• We offer a new perspective for cross-domain FAS. In-stead of removing the domain signal, we propose to maintain it and design the feature space based on sep-arability and alignment;
• We ﬁrst systematically exploit the domain-variant rep-resentation learning by combining contrastive learn-ing and effectively optimizing invariant risk minimiza-tion (IRM) through the projected gradient algorithm for cross-domain FAS;
• We achieve state-of-the-art performance on widely-used cross-domain FAS benchmark, and provide in-depth analysis and insights on how separability and alignment lead to the performance boost. 2.