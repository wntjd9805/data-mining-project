Abstract
We present Pose Integrated Gradient (PoseIG), the first in-terpretability technique designed for pose estimation. We ex-tend the concept of integrated gradients for pose estimation to generate pixel-level attribution maps. To enable compari-son across different pose frameworks, we unify different pose outputs into a common output space, along with a likelihood approximation function for gradient back-propagation.
To complement the qualitative insight from the attribution maps, we propose three indices for quantitative analysis.
With these tools, we systematically compare different pose estimation frameworks to understand the impacts of network design, backbone and auxiliary tasks. Our analysis reveals an interesting shortcut of the knuckles (MCP joints) for hand pose estimation and an under-explored inversion error for keypoints in body pose estimation. Project page and code: https://qy-h00.github.io/poseig/. 1.

Introduction
Human pose estimation of both the body and the hand is a critical vision task for augmented and virtual reality applications. State-of-the-art methods [12, 15, 19, 20, 33, 36] perform impressively on benchmarks but are difficult to compare beyond differences in average end-point-error (EPE). Averaged results on large-scale benchmarks depend on the underlying data distribution and tend to obscure the behaviour of pose estimation systems [10]. As such, we are motivated to find alternative ways to interpret and compare pose estimates across different methods. To that end, we present the first method for estimating pixel-level attribution maps designed specifically for pose estimation.
Integrated Gradients (IG) [35] is a commonly used attri-bution technique. IG and its derived variants [21, 35, 40] can produce pixel-level attribution maps for various image and natural language classification tasks. IG computes gradients to measure the relationship between changes to an input and changes to the target likelihood. However, IG is not directly applicable to pose estimation. Unlike in classification, where
*Equal contribution
Figure 1. Pose Integrated Gradients (PoseIG) generates spatial attribution maps for pose estimation. Based on the attribution maps, we propose numerical indices to quantitatively characterize the attributions throughout the scene. models always directly output a class likelihood, pose es-timation models vary in their output, ranging from spatial likelihoods to regressed coordinates. Therefore, we must in-troduce a likelihood approximation function between the pre-dicted outputs and their targets to approximate the target like-lihood. Based on these likelihoods, we can back-propagate the gradients and generate attribution maps. Moreover, to enable meaningful comparison across frameworks, we pro-pose unifying the different outputs into a common output space and use the same likelihood approximation function
S(·) for back-propagation. Fig. 1 shows our interpretability pipeline for generating pixel-level attribution maps that can be compared across different pose frameworks.
Existing works [35] and [21] focus on qualitative attri-butions and produce visualizations for single inputs. We are interested in these visualizations for pose estimation; however, we additionally target quantitative analysis of the attributions. As such, we have designed attribution-based indices to help analyze and diagnose pose estimation frame-works. Based on PoseIG’s attribution maps, we introduce three indices to numerically characterize the attributions.
The Foreground Index (FI) measures the extent to which the foreground is considered in the attributions. The Locality
Index (LI) measures the amount of attribution around an im-age coordinate, and the Diffusion Index (DI) measures how concentrated or dispersed the attributions are in the scene.
Armed with PoseIG’s attribution maps and the associated indices, we study existing body and hand pose estimation frameworks and provide insights on their design and archi-tectures. Finally, we diagnose existing models and find two overlooked issues in pose estimation. First, we reveal an artifically high performance of MCP1 or knuckle joints in the hand, likely from shortcut learning as a result of data preprocessing. Secondly, we observe an under-explored phenomenon of keypoint inversion [27], where keypoints are mistakenly predicted at the location of other keypoints.
Accordingly, we introduce simple mitigating solutions and recommend these be incorporated into future protocols to improve hand and body pose estimation.
Our main contributions can be summarized as follows:
• We introduce PoseIG, the first interpretability technique designed for pose estimation. PoseIG provides pixel-level attributions and can be applied to compare differ-ent pose estimation works based on a unified output space and a likelihood approximation function.
• We propose three numerical indices to quantitatively characterize the attributions in the scene.
• Using PoseIG’s attributions and indices, we analyze and compare different body and hand pose estimation frameworks and provide insight on their design.
• We diagnose a shortcut problem in hand pose estimation and keypoint inversion errors in human pose estimation and propose simple solutions to alleviate these issues.
We hope it will serve as a useful tool to the community for analyzing, diagnosing, and improving pose estimation frameworks. 2.