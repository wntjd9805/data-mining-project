Abstract
In this paper, we consider the face swapping detection from the perspective of face identity. Face swapping aims to replace the target face with the source face and gener-ate the fake face that the human cannot distinguish between real and fake. We argue that the fake face contains the ex-plicit identity and implicit identity, which respectively cor-responds to the identity of the source face and target face during face swapping. Note that the explicit identities of faces can be extracted by regular face recognizers. Partic-ularly, the implicit identity of real face is consistent with the its explicit identity. Thus the difference between explicit and implicit identity of face facilitates face swapping detec-tion. Following this idea, we propose a novel implicit iden-tity driven framework for face swapping detection. Specifi-cally, we design an explicit identity contrast (EIC) loss and an implicit identity exploration (IIE) loss, which supervises a CNN backbone to embed face images into the implicit identity space. Under the guidance of EIC, real samples are pulled closer to their explicit identities, while fake sam-ples are pushed away from their explicit identities. More-over, IIE is derived from the margin-based classification loss function, which encourages the fake faces with known target identities to enjoy intra-class compactness and inter-class diversity. Extensive experiments and visualizations on several datasets demonstrate the generalization of our method against the state-of-the-art counterparts. 1.

Introduction
The development of deep learning has promoted the con-tinuous progress of face forgery technology [5, 16, 48]. Es-pecially for face swapping, it can replace the target face with the source face to generate a fake face that is not distin-guishable by the human eyes. With this technology, attack-ers can easily forge high-quality videos of public celebrities and political figures to achieve illegal political or commer-cial purposes. To alleviate the abuse of face swapping, it is
*Corresponding author.
Figure 1. Motivation of our approach. The target face is replaced by the source face through face swapping to generate a fake face.
In appearance, the fake face looks like the source face instead of the target face. We resort the general face recognition (FR) model
CosFace [51] to obtain the explicit distance of these faces. Partic-ularly, since the fake face is synthesized from the source face and the target face, we aim to explore a implicit face recognition (IFR) model that can mine the corresponding target face identity based on the fake face. With the similarity between explicit and implicit embeddings of the given face, we can significantly distinguish it as real and fake, which facilitates forgery detection. urgent to exploit corresponding detection methods.
Early researches [1, 10, 37, 42] usually treat face swap detection as a binary image classification task. Specifically, face images are fed into an existing deep convolutional neu-ral network (CNN) and then classified as real and fake.
Such methods can learn the data distribution of the training set, resulting in considerable performance in intra-domian tests. However, the simple classification guidance cannot incorporate the connotation of face swapping, thus the deep network lacks the understanding of forgery [50]. Recent works are devoted to exploring specific forgery patterns, such as noise analysis [27], local regions [7, 53] and fre-quency information [19, 41]. In this way, fake traces in fake faces can be better detected. Albeit gaining the benefits, they still revolve around certain manipulation methods and
are not conducive to generalize well to unseen real-world scenarios. Therefore, in practice, many emerging forgery methods as well as unknown environmental factors bring serious performance degradation to existing face swapping detection methods.
To address the above issues, we consider the face swap-ping detection from the perspective of face identity. As shown in Figure 1, face swapping aims to replace the tar-get face with the source face, further generating a fake face that is even indistinguishable for human eyes. Here, we introduce two new concepts for fake faces, including ex-plicit identity and implicit identity. Specifically, the explicit identity represents what the fake face looks like, that is, the source face identity. Thus, the explicit distance between the fake face and the real face can be measured by existing gen-eral face recognition models [11, 22, 51]. For implicit iden-tity, we believe that the fake face comes from the source face and the target face. Although it looks like the source face, it might contain more or less target face identity in-formation. We call this potential target face information the implicit identity of the fake face. It is worth noting that the implicit identities of the real face are consistent with its ex-plicit identities. Therefore, given a face image, we embed it into the explicit and implicit identity feature spaces, re-spectively. The distance between its explicit and implicit features is taken as the basis for judging real and fake. Pro-vided the distance is very close, the given image is real, otherwise it is a fake image.
With the above considerations in mind, in this paper, we propose a novel implicit identity driven (IID) framework to detect face swapping. Our key motivation is to explore the implicit identity of the face, which guides deep networks to make more reasonable detection results. To this end, we first employ the generic face recognition model to ob-tain its explicit identity embedding. Subsequently, we pro-pose the explicit identity contrast (EIC) loss and the implicit identity exploration (IIE) loss to supervise the off-the-shelf
CNN backbone, aiming to transform the face image into the implicit identity feature space. Specifically, under the guidance of EIC, real samples are pulled closer to their ex-plicit identities, while fake samples are pushed away from their explicit identities. In this way, the difference between the real and fake samples in the feature space is enlarged.
It is worth noting that the real sample feature at this time denotes its implicit identity (close to the explicit identity).
Moreover, to further explore the implicit identity of the fake sample, we label the identity of the fake face with its cor-responding target face identity. Particularly, for those fake faces whose target faces are unknown but come from the same video, we label their identities as extra and identical to ensure identity consistency. Inspired by general face recog-nition algorithms [11, 51], our proposed IIE is derived from the margin-based classification loss function, which guides fake faces with known target identities to have small intra-class distances and large inter-class distances. Besides, fake faces with unknown target identities originating from the same video have consistent identity embeddings. Thereby, implicit identities of fake faces can be mined comprehen-sively. Finally, we use the difference between the implicit identity and explicit identity of the face as the basis for dis-tinguishing real and fake.
In brief, the main contributions are as follows:
• From a completely new perspective, we propose the implicit identity driven framework for face swapping detection, which explores the implicit identity of fake faces. This enhances the deep network to distinguish fake faces with unknown manipulations.
• We specially design explicit identity contrast (EIC) loss and the implicit identity exploration (IIE) loss.
EIC aims to pull real samples closer to their explicit identities and push fake samples away from their ex-plicit identities. IIE is margin-based and guides fake faces with known target identities to have small intra-class distances and large inter-class distances.
• Extensive experiments and visualizations demonstrate the superiority of our method over the state-of-the-art approaches. 2.