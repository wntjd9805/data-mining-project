Abstract
The transformation of features from 2D perspective space to 3D space is essential to multi-view 3D object de-tection. Recent approaches mainly focus on the design of view transformation, either pixel-wisely lifting perspective view features into 3D space with estimated depth or grid-wisely constructing BEV features via 3D projection, treat-ing all pixels or grids equally. However, choosing what to transform is also important but has rarely been discussed before. The pixels of a moving car are more informative than the pixels of the sky. To fully utilize the informa-tion contained in images, the view transformation should be able to adapt to different image regions according to their contents. In this paper, we propose a novel framework named FrustumFormer, which pays more attention to the features in instance regions via adaptive instance-aware re-sampling. Specifically, the model obtains instance frustums on the bird’s eye view by leveraging image view object pro-posals. An adaptive occupancy mask within the instance frustum is learned to refine the instance location. More-over, the temporal frustum intersection could further reduce the localization uncertainty of objects. Comprehensive ex-periments on the nuScenes dataset demonstrate the effec-tiveness of FrustumFormer, and we achieve a new state-of-the-art performance on the benchmark. Codes and mod-els will be made available at https://github.com/
Robertwyq/Frustum. 1.

Introduction
Perception in 3D space has gained increasing attention in both academia and industry. Despite the success of LiDAR-based methods [14, 33, 41, 44], camera-based 3D object de-tection [19, 35, 36, 43] has earned a wide audience, due to the low cost for deployment and advantages for long-range detection. Recently, multi-view 3D detection in Bird’s-Eye-View (BEV) has made fast progresses. Due to the unified representation in 3D space, multi-view features and tem-poral information can be fused conveniently, which leads to significant performance improvement over monocular methods [5, 28, 35, 39].
Transforming perspective view features into the bird’s-eye view is the key to the success of modern BEV 3D de-tectors [12,18,19,22]. As shown in Fig. 1, we categorize the existing methods into lifting-based ones like LSS [30] and
BEVDet [12] and query-based ones like BEVFormer [19] and Ego3RT [25]. However, these methods mainly focus on the design of view transformation strategies while over-looking the significance of choosing the right features to transform during view transformation. Regions containing objects like vehicles and pedestrians are apparently more in-formative than the empty background like sky and ground.
But all previous methods treat them with equal importance.
We suggest that the view transformation should be adaptive with respect to the image content. Therefore, we propose
Adaptive Instance-aware Resampling (AIR), an instance-aware view transformation, as shown in Fig. 1c. The core idea of AIR is to reduce instance localization uncertainty by focusing on a selective part of BEV queries. Localizing in-stance regions is difficult directly on the BEV plane but rel-atively easy in the image view. Therefore, the instance frus-tum, lifting from instance proposals in image views, gives geometrical hints of the possible locations of objects in the 3D space. Though the instance frustum has provided initial prior locations, it is still a large uncertain area. We propose an occupancy mask predictor and a temporal frustum fusion module to further reduce the localization uncertainty. Our model learns an occupancy mask for frustum queries on the
BEV plane, predicting the possibility that a region might contain objects. We also fuse instance frustums across dif-ferent time steps, where the intersection area poses geomet-(a) Grid Sampling in Image. (b) Grid Sampling in BEV. (c) Instance-aware Sampling in Frustum.
Figure 1. Comparison of different sampling strategies for the feature transformation from image view to bird’s eye view. (a) represents the sampling in image view and lift features [12] to BEV plane with pixel-wise depth estimation. (b) shows the grid sampling in BEV and queries back [19] to obtain image features via cross-attention. (c) illustrates our proposed instance-aware sampling strategy in the frustum, which adapts to the view content by focusing more attention on instance regions. This approach is designed to enhance the learning of instance-aware BEV features. ric constraints for actual locations of objects. 2.