Abstract
Neural Radiance Fields (NeRFs) are emerging as a ubiq-uitous scene representation that allows for novel view syn-Increasingly, NeRFs will be shareable with other thesis. people. Before sharing a NeRF, though, it might be desir-able to remove personal information or unsightly objects.
Such removal is not easily achieved with the current NeRF editing frameworks. We propose a framework to remove objects from a NeRF representation created from an RGB-D sequence. Our NeRF inpainting method leverages re-cent work in 2D image inpainting and is guided by a user-provided mask. Our algorithm is underpinned by a confi-dence based view selection procedure. It chooses which of the individual 2D inpainted images to use in the creation of the NeRF, so that the resulting inpainted NeRF is 3D consis-tent. We show that our method for NeRF editing is effective for synthesizing plausible inpaintings in a multi-view co-herent manner, outperforming competing methods. We vali-date our approach by proposing a new and still-challenging dataset for the task of NeRF inpainting. 1.

Introduction
Since the initial publication of Neural Radiance Fields (NeRFs) [42], there has been an explosion of extensions to the original framework, e.g., [3, 4, 8, 12, 25, 35, 39, 42].
NeRFs are being used beyond the initial task of novel view synthesis. It is already appealing to get them into the hands of non-expert users for novel applications, e.g., for NeRF editing [80] or live capture and training [47], and these more casual use cases are driving interesting new technical issues.
One of those issues is how to seamlessly remove parts of the rendered scene. Removing parts of the scene can be desirable for a variety of reasons. For example, a house scan being shared on a property selling website may need unappealing or personally identifiable objects to be re-moved [68]. Similarly, objects could be removed so they can be replaced in an augmented reality application, e.g., removing a chair from a scan to see how a new chair fits
Figure 1. Removal of unsightly objects. Our method allows for objects to be plausibly removed from NeRF reconstructions, in-painting missing regions whilst preserving multi-view coherence. in the environment [51]. Removing objects might also be desirable when a NeRF is part of a traditional computer vi-sion pipeline, e.g., removing parked cars from scans that are going to be used for relocalization [44].
Some editing of NeRFs has already been explored. For example, object-centric representations disentangle labeled objects from the background, which allows editing of the trained scene with user-guided transformations [74, 77], while semantic decomposition allows selective editing and transparency for certain semantic parts of the scene [26].
However, these previous approaches only augment informa-tion from the input scan, limiting their generative capabil-ities, i.e., the hallucination of elements that have not been observed from any view.
With this work, we tackle the problem of removing ob-jects from scenes, while realistically filling the resulting holes, as shown in Fig. 1. Solving this problem requires: a) exploiting multi-view information when parts of the scene are observed in some frames but occluded in others and, b) leveraging a generative process to fill areas that are never observed. To this end, we pair the multi-view consistency of NeRFs with the generative power of 2D inpainting mod-els [69] that are trained on large scale 2D image datasets.
Such 2D inpaintings are not multi-view consistent by con-struction, and may contain severe artefacts. Using these in-paintings directly causes corrupted reconstructions, so we design a new confidence-based view-selection scheme that iteratively removes inconsistent inpaintings from the opti-mization. We validate our approach on a new dataset and show that we outperform existing approaches for novel view synthesis on standard metrics of image quality, as well as producing multi-view consistent results.
In summary, we make the following contributions: 1) We propose the first approach focusing on inpainting
NeRFs by leveraging the power of single image inpainting. 2) We introduce a novel view-selection mechanism that au-tomatically removes inconsistent views from the optimiza-tion. 3) We present a new dataset for evaluating object re-moval and inpainting in indoor and outdoor scenes. 2.