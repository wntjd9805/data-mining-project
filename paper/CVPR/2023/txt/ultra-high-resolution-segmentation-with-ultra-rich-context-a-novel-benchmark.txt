Abstract
To this end,
With the increasing interest and rapid development of methods for Ultra-High Resolution (UHR) segmentation, a large-scale benchmark covering a wide range of scenes with full fine-grained dense annotations is urgently needed to facilitate the field. the URUR dataset is introduced, in the meaning of Ultra-High Resolution dataset with Ultra-Rich Context. As the name suggests,
URUR contains amounts of images with high enough res-olution (3,008 images of size 5,120×5,120), a wide range of complex scenes (from 63 cities), rich-enough context (1 million instances with 8 categories) and fine-grained annotations (about 80 billion manually annotated pixels), which is far superior to all the existing UHR datasets including DeepGlobe, Inria Aerial, UDD, etc.. More-over, we also propose WSDNet, a more efficient and ef-fective framework for UHR segmentation especially with ultra-rich context. Specifically, multi-level Discrete Wavelet
Transform (DWT) is naturally integrated to release com-putation burden while preserve more spatial details, along with a Wavelet Smooth Loss (WSL) to reconstruct orig-inal structured context and texture with a smooth con-strain. Experiments on several UHR datasets demonstrate its state-of-the-art performance. The dataset is available at https://github.com/jankyee/URUR. 1.

Introduction
Benefited from the advancement of photography and sensor technologies, the accessibility and analysis of ultra-high resolution (UHR) images has opened new horizons for the computer vision community, playing an increasingly important role in a wide range of applications, including but
*Corresponding Authors. not limited to disaster control, environmental monitoring, land resource protection and urban planning. The focus of this paper is on semantic segmentation for UHR images.
The most commonly-used datasets in existing UHR seg-mentation methods include DeepGlobe [4], Inria Aerial [8] and Citysacpes [3]. According the definition of UHR me-dias [9,10], an image with at least 2048×1080 (2.2M) pixels are regarded as 2K high resolution media. An image with at least 3,840×1,080 (4.1M) pixels reaches the bare mini-mum bar of 4K resolution, and 4K ultra-high definition me-dia usually refers to a minimum resolution of 3,840×2,160 (8.3M). However, except for Inria Aeral which reaches to 5,000×5,000 pixels, the average resolution of all other two datasets are below 2,500×2,500 (6.2M), thus actually they are not strictly UHR medias. Besides, DeepGlobe also adopts coarse annotations that result in numbers of noises. Although the utra-high resolution, Inria Aerial con-tains only 180 images in limited scenes, and only anno-tates one category of building, which is not sufficient to fully verify the performance of UHR segmentation methods and limits the development of the community. Therefore, a novel large-scale benchmark dataset covering a wide range of scenes with full fine-grained dense annotations is ur-gently needed to facilitate the field. To this end, the URUR dataset is proposed in the paper, in this meaning of Ultra-High Resolution dataset with Ultra-Rich Context. Firstly for the resolution, URUR contains 3,008 UHR images of size 5,120×5,120 (up to 26M), coming from a wide range of complex scenes in 63 cities. For annotations, there are 80 billion manually annotated pixels, including 2 million fine-grained instances with 8 categories, which is of ultra-high context and far superior to all the existing UHR datasets.
Visualization samples and detailed statistics are revealed in
Figure 1 and Section 3.
In order to balance the memory occupation and accu-racy when the image resolution grows to ultra-high, earlier
Figure 1. The comparison between natural datasets (Pascal VOC [1], COCO [2], Cityscapes [3]), and representative UHR datasets (Deep-Globe [4], ISIC [5], UDD6 [6], UAVid [7], Inria Aerial [8] and URUR). As shown that UHR images (from b to g) cover a larger filed of view and contain more regions with very large contrast in both scale and shape, than natural images (a). Existing UHR datasets either adopt coarse annotations (b, d, e) or only annotate one category (c, f). The proposed URUR dataset (h) utilizes fine-grained dense annotations for whole 8 categories. works for UHR segmentation utilize a two-branch global-local collaborative network to preserve both global and lo-cal information, taking the globally down-sampled image and locally cropped patches as inputs respectively. The representative works include GLNet [10] and FCtL [11].
However, this type of framework requires multiple predic-tions on the patches thus the overall inference speed is very slow. To further achieve a better balance among accuracy, memory and inference speed, ISDNet [12] is proposed to integrate shallow and deep networks for efficient segmen-tation. The shallow branch has fewer layers and faster in-ference speed, its input does not need any downsampling or cropping. For the deep branch, the input image is di-rectly down-sampled to ensure high inference speed. Then a heavy relation-aware feature (RAF) module is utilized to exploit the relationship between the shallow and deep feature.
In this paper, we propose WSDNet, the evolu-tion of ISDNet, to formulate a more efficient and effective framework for UHR segmentation. Specifically, multi-level
Discrete Wavelet Transform (DWT) and Inverse Discrete
Wavelet Transform (IWT) are naturally integrated to release computation burden while preserve more spatial details in the deep branch, thus RAF can be removed for higher infer-ence speed. The Wavelet Smooth Loss (WSL) is also de-signed to reconstruct original structured context and texture distribution with the smooth constrain in frequency domain.
Overall, the contributions of this paper are summarized as follows:
• We introduce the URUR dataset, a novel large-scale dataset covering a wide range of scenes with full fine-grained dense annotations, which is superior to all the exiting UHR datastes to our knowledge.
• WSDNet is proposed to preserve more spatial details with multi-level DWT-IWT, and a Wavelet Smooth
Loss is presented to reconstruct original structured context and texture distribution with the smooth con-strain in frequency domain.
• Statistics and experiments demonstrate the superior-ity of URUR and WSDNet. WSDNet achieves state-of-the-art balance among accuracy, memory and infer-ence speed on several UHR datasets. 2.