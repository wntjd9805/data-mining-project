Abstract
Neural Radiance Fields (NeRF) have achieved photo-realistic novel views synthesis; however, the requirement of accurate camera poses limits its application. Despite analysis-by-synthesis extensions for jointly learning neu-ral 3D representations and registering camera frames exist, they are susceptible to suboptimal solutions if poorly initial-ized. We propose L2G-NeRF, a Local-to-Global registra-tion method for bundle-adjusting Neural Radiance Fields:
ﬁrst, a pixel-wise ﬂexible alignment, followed by a frame-wise constrained parametric alignment. Pixel-wise local alignment is learned in an unsupervised way via a deep network which optimizes photometric reconstruction errors.
Frame-wise global alignment is performed using differen-tiable parameter estimation solvers on the pixel-wise corre-spondences to ﬁnd a global transformation. Experiments on synthetic and real-world data show that our method outper-forms the current state-of-the-art in terms of high-ﬁdelity reconstruction and resolving large camera pose misalign-ment. Our module is an easy-to-use plugin that can be applied to NeRF variants and other neural ﬁeld applica-tions. The Code and supplementary materials are available at https://rover-xingyu.github.io/L2G-NeRF/. 1.

Introduction
Recent success with neural ﬁelds [47] has caused a resurgence of interest in visual computing problems, where coordinate-based neural networks that represent a ﬁeld gain traction as a useful parameterization of 2D images [4,7,40], and 3D scenes [27, 29, 34]. Commonly, these coordinates are warped to a global coordinate system by camera param-eters obtained via computing homography, structure from motion (Sf M), or simultaneous localization and mapping
*Authors contributed equally to this work.
†Corresponding Author. This work is partly supported by the Na-tional Key Research and Development Program of China under Grant 2022YFB3303800 and National Key Projects of China, 2021XJTU0040.
Figure 1. We present L2G-NeRF, a new bundle-adjusting neural radiance ﬁelds — employing local-to-global registration — that is much more robust than the current state-of-the-art BARF [24]. (SLAM) [17] with off-the-shelf tools like COLMAP [39], before being fed to the neural ﬁelds.
This paper considers the generic problem of simultane-ously reconstructing the neural ﬁelds from RGB images and registering the given camera frames, which is known as a long-standing chicken-and-egg problem — registration is needed to reconstruct the ﬁelds, and reconstruction is needed to register the cameras.
One straightforward way to solve this problem is to jointly optimize the camera parameters with the neural
ﬁelds via backpropagation. Recent work can be broadly placed into two camps: parametric and non-parametric.
Parametric methods [10, 20, 24, 44] directly optimize global geometric transformations (e.g. rigid, homography). Non-parametric methods [22, 31] do not make any assumptions
on the type of transformation, and attempt to directly op-timize some pixel agreement metric (e.g. brightness con-stancy constraint in optical ﬂow and stereo).
However, both approaches have ﬂaws: parametric meth-ods fail to minimize the photometric errors (falling into the suboptimal solutions) if poorly initialized, as shown in
Fig. 1, while non-parametric methods have trouble dealing with large displacements (e.g. although the photometric er-rors are minimized, the alignments do not obey the geomet-ric constraint). It is natural, therefore, to consider a hybrid approach, combining the beneﬁts of parametric and non-parametric methods together.
In this paper, we propose L2G-NeRF, a local-to-global process integrating parametric and non-parametric methods for bundle-adjusting neural radiance ﬁelds — the joint prob-lem of reconstructing the neural ﬁelds and registering the camera parameters, which can be regarded as a type of clas-sic photometric bundle adjustment (BA) [3, 12, 25]. Fig. 2 shows an overview. In the ﬁrst non-parametric stage, we initialize the alignment by predicting a local transformation
ﬁeld for each pixel of the camera frames. This is achieved by self-supervised training of a deep network to optimize standard photometric reconstruction errors. In the second stage, differentiable parameter estimation solvers are ap-plied to a set of pixel-wise correspondences to obtain a global alignment, which is then used to apply a soft con-straint to the local alignment. In summary, we present the following contributions:
• We show that the optimization of bundle-adjusting neural ﬁelds is sensitive to initialization, and we present a simple yet effective strategy for local-to-global registration on neural ﬁelds.
• We introduce two differentiable parameter estimation solvers for rigid and homography transformation re-spectively, which play a crucial role in calculating the gradient ﬂow from the global alignment to the local alignment.
• Our method is agnostic to the particular type of neural
ﬁelds, speciﬁcally, we show that the local-to-global process works quite well in 2D neural images and 3D Neural Radiance Fields (NeRF) [29], allowing for applications such as image reconstruction and novel view synthesis.
However, the explicit point clouds assume a diffuse sur-face, hence cannot model view-dependent appearance. And the sparse nature of point clouds also limits downstream vision tasks, such as photorealistic rendering. In contrast,
L2G-NeRF encodes the scenes as coordinate-based neural
ﬁelds, which is qualiﬁed for solving the high-ﬁdelity visual computing problems.
Neural Fields. Recent advances in neural ﬁelds [47], which employ coordinate-based neural networks to parameterize physical properties of scenes or objects across space and time, have led to increased interest in solving visual com-puting problems, causing more accurate, higher ﬁdelity, more expressive, and memory-efﬁcient solutions. They have seen widespread success in problems such as image synthesis [4,7,40], 3D shape [9,27,34], view-dependent ap-pearance [6,18,29,33], and animation of humans [8,35,45].
While these neural ﬁelds have achieved impressive re-sults, the requirement of camera parameters limits its ap-plication. We are able to get around the requirement with our proposed L2G-NeRF.
Bundle-Adjusting Neural Fields. Since neural ﬁelds are end-to-end differentiable, camera parameters can be jointly estimated with the neural ﬁelds. The optimization problem is known to be non-convex, and is reﬂected by NeRF-- [44], in which the authors jointly optimize the scene and cam-eras for forward-facing scenes. Adversarial objective is uti-lized [26] to relax forward-facing assumption and supports inward-facing 360◦ scenes. SCNeRF [20] is further devel-oped to learn the camera intrinsics. BARF [24] shows that bundle-adjusting neural ﬁelds could beneﬁt from coarse-to-ﬁne registration. Recent approaches employ Gaussian acti-vations [10] or Sinusoidal activations [46] to overcome local minima in optimization.
Nevertheless, these parametric methods directly opti-mize global geometric transformations, which are prone to falling into suboptimal solutions if poorly initialized. Non-parametric methods [22, 31] directly optimize decent local transformations based on brightness constancy constraints, whereas they can not handle large displacements. We show that by combining the parametric and non-parametric meth-ods together with a simple local-to-global process, we can achieve surprising anti-noise ability, allowing utilities for various NeRF extensions and other neural ﬁeld applications. 2.