Abstract
Multi-scale features have been proven highly effective for object detection but often come with huge and even prohibitive extra computation costs, especially for the re-cent Transformer-based detectors.
In this paper, we pro-pose Iterative Multi-scale Feature Aggregation (IMFA) – a generic paradigm that enables efficient use of multi-scale features in Transformer-based object detectors. The core idea is to exploit sparse multi-scale features from just a few crucial locations, and it is achieved with two novel de-signs. First, IMFA rearranges the Transformer encoder-decoder pipeline so that the encoded features can be iter-atively updated based on the detection predictions. Second,
IMFA sparsely samples scale-adaptive features for refined detection from just a few keypoint locations under the guid-ance of prior detection predictions. As a result, the sam-pled multi-scale features are sparse yet still highly ben-eficial for object detection. Extensive experiments show that the proposed IMFA boosts the performance of multiple
Transformer-based object detectors significantly yet with only slight computational overhead. 1.

Introduction
Detecting objects of vastly different scales has always been a major challenge in object detection [28]. Fortu-nately, strong evidence [11, 22, 25, 48, 69, 72] shows that object detectors can significantly benefit from multi-scale features while dealing with large scale variation.
For
ConvNet-based object detectors like Faster R-CNN [42] and
FCOS [49], Feature Pyramid Network (FPN) [25] and its variants [12, 18, 19, 30, 48, 69, 70] have become the go-to components for exploiting multi-scale features.
Other than ConvNet-based object detectors, the recently proposed DEtection TRansformer (DETR) [4] has estab-lished a fully end-to-end object detection paradigm with
* marks corresponding author.
† marks equal technical contribution.
Project Page: https://github.com/ZhangGongjie/IMFA .
Figure 1. The proposed Iterative Multi-scale Feature Aggregation (IMFA) is a generic approach for efficient use of multi-scale fea-tures in Transformer-based object detectors.
It boosts detection accuracy on multiple object detectors at minimal costs of addi-tional computational overhead. Results are obtained with ResNet-50. Best viewed in color. promising performance. However, naively incorporating multi-scale features using FPN in these Transformer-based detectors [4, 11, 20, 29, 35, 55, 66, 72] often brings enormous and even unfeasible computation costs, primarily due to the poor efficiency of the attention mechanism in processing high-resolution features. Concretely, to handle a feature map with a spatial size of H × W , ConvNet requires a com-putational cost of O(HW ), while the complexity of the at-tention mechanism in Transformer-based object detectors is
O(H 2W 2). To mitigate this issue, Deformable DETR [72] and Sparse DETR [43] replace the original global dense attention with sparse attention. SMCA-DETR [11] re-stricts most Transformer encoder layers to be scale-specific, with only one encoder layer to integrate multi-scale fea-tures. However, as the number of tokens increases quadrati-cally w.r.t. feature map size (typically 20x∼80x compared to single-scale), these methods are still costly in computation and memory consumption, and rely on special operators like
deformable attention [72] that introduces extra complexity for deployment. To the best of our knowledge, there is yet no generic approach that can efficiently exploit multi-scale features for Transformer-based object detectors.
In this paper, we present Iterative Multi-scale Feature
Aggregation (IMFA), a concise and effective technique that can serve as a generic paradigm for efficient use of multi-scale features in Transformer-based object detectors. The motivation comes from two key observations: (i) the com-putation of high-resolution features is highly redundant as the background usually occupies most of the image space, thus only a small portion of high-resolution features are useful to object detection; (ii) unlike ConvNet, the Trans-former’s attention mechanism does not require grid-shaped feature maps, which offers the feasibility of aggregating multi-scale features only from some specific regions that are likely to contain objects of interest. The two observa-tions motivate us to sparsely sample multi-scale features from just a few informative locations and then aggregate them with encoded image features in an iterative manner.
Concretely, IMFA consists of two novel designs in the
Transformer-based detection pipelines. First, IMFA rear-ranges the encoder-decoder pipeline so that each encoder layer is immediately connected to its corresponding de-coder layer. This design enables iterative update of en-coded image features along with refined detection predic-tions. Second, IMFA sparsely samples multi-scale features from the feature pyramid generated by the backbone, with the sampling process guided by previous detection predic-tions. Specifically, motivated by the spatial redundancy of high-resolution features, IMFA only focuses on a few promising regions with high likelihood of object occurrence based on prior predictions. Furthermore, inspired by the significance of objects’ keypoints for recognition and lo-calization [39, 59, 66, 71], IMFA first searches several key-points within each promising region, and then samples use-ful features around these keypoints at adaptively selected scales. The sampled features are finally fed to the subse-quent encoder layer along with the image features encoded by the previous layer. With the two new designs, the pro-posed IMFA aggregates only the most crucial multi-scale features from those informative locations. Since the number of the aggregated features is small, IMFA introduces min-imal computational overhead while consistently improving the detection performance of Transformer-based object de-tectors. It is noteworthy that IMFA is a generic paradigm for efficient use of multi-scale features: (i) as shown in Fig. 1, it can be easily integrated with multiple Transformer-based object detectors with consistent performance boosts; (ii) as discussed in Section 5.4, IMFA has the potential to boost
DETR-like models on tasks beyond object detection.
To summarize, the contributions of this work are threefold.
• We propose a novel DETR-based detection pipeline, where encoded features can be iteratively updated along with refined detection predictions. This new pipeline al-lows to leverage intermediate predictions as guidance for robust and efficient multi-scale feature encoding.
• We propose a sparse sampling strategy for multi-scale features, which first identifies several promising regions under the guidance of prior detections, then searches sev-eral keypoints within each promising region, and finally samples their features at adaptively selected scales. We demonstrate that such sparse multi-scale features can sig-nificantly benefit object detection.
• Based on the two contributions above, we propose Iter-ative Multi-scale Feature Aggregation (IMFA) – a sim-ple and generic paradigm that enables efficient use of multi-scale features in Transformer-based object detec-tors.
IMFA consistently boosts detection performance on multiple object detectors, yet remains computationally efficient. This is the pioneering work that investigates a generic approach for exploiting multi-scale features effi-ciently in Transformer-based object detectors. 2.