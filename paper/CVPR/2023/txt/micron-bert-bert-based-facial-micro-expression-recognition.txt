Abstract
Micro-expression recognition is one of the most chal-lenging topics in affective computing.
It aims to recog-nize tiny facial movements difficult for humans to per-ceive in a brief period, i.e., 0.25 to 0.5 seconds. Re-cent advances in pre-training deep Bidirectional Trans-formers (BERT) have significantly improved self-supervised learning tasks in computer vision. However, the standard
BERT in vision problems is designed to learn only from full images or videos, and the architecture cannot accu-rately detect details of facial micro-expressions. This pa-per presents Micron-BERT (µ-BERT), a novel approach to facial micro-expression recognition. The proposed method can automatically capture these movements in an unsu-pervised manner based on two key ideas. First, we em-ploy Diagonal Micro-Attention (DMA) to detect tiny dif-Second, we introduce a ferences between two frames. new Patch of Interest (PoI) module to localize and high-light micro-expression interest regions and simultaneously reduce noisy backgrounds and distractions. By incorpo-rating these components into an end-to-end deep network, the proposed µ-BERT significantly outperforms all previ-ous work in various micro-expression tasks. µ-BERT can be trained on a large-scale unlabeled dataset, i.e., up to 8 million images, and achieves high accuracy on new un-seen facial micro-expression datasets. Empirical experi-ments show µ-BERT consistently outperforms state-of-the-art performance on four micro-expression benchmarks, in-cluding SAMM, CASME II, SMIC, and CASME3, by sig-nificant margins. Code will be available at https:// github.com/uark-cviu/Micron-BERT 1.

Introduction
Facial expressions are a complex mixture of conscious reactions directed toward given stimuli. They involve ex-periential, behavioral, and physiological elements. Be-cause they are crucial to understanding human reactions, this topic has been widely studied in various application do-mains [5].
In general, facial expression problems can be classified into two main categories, macro-expression, and
Figure 1. Given two frames from a high-speed video, the proposed
µ-BERT method can localize and highlight the regions of micro-movements. Best viewed in color. micro-expression. The main differences between the two are facial expression intensities, and duration [2]. In partic-ular, macro-expressions happen spontaneously, cover large movement areas in a given face, e.g., mouth, eyes, cheeks, and typically last from 0.5 to 4 seconds. Humans can usually recognize these expressions. By contrast, micro-expressions are involuntary occurrences, have low inten-sity, and last between 5 milliseconds and half a second. In-deed, micro-expressions are challenging to identify and are mostly detectable only by experts. Micro-expression under-standing is essential in numerous applications, primarily lie detection, which is crucial in criminal analysis.
Micro-expression identification requires both semantics and micro-movement analysis. Since they are difficult to observe through human eyes, a high-speed camera, usu-ally with 200 frames per second (FPS) [6, 15, 51], is typi-cally used to capture the required video frames. Previous work [11] tried to understand this micro information using
MagNet [29] to amplify small motions between two frames, e.g., onset and apex frames. However, these methods still have limitations in terms of accuracy and robustness.
In summary, the contributions of this work are four-fold:
• A novel Facial Micro-expression Recognition (MER) via Pre-training of Deep Bidirectional Transformers approach (Micron-BERT or µ-BERT) is presented to
tackle the problem in a self-supervised learning man-ner. The proposed method aims to identify and localize micro-movements in faces accurately.
• As detecting the tiny moment changes in faces is an essential input to the MER module, a new Diagonal
Micro Attention (DMA) mechanism is proposed to pre-cisely identify small movements in faces between two consecutive video frames.
• A new Patch of Interest (POI) module is introduced to efficiently spot facial regions containing the micro-expressions. Far apart from prior methods, it is trained in an unsupervised manner without using any facial la-bels, such as facial bounding boxes or landmarks.
• The proposed µ-BERT framework is designed in a self-supervised learning manner and trained in an end-to-end deep network. Indeed, it consistently achieves
State-of-the-Art (SOTA) results in various standard micro-expression benchmarks, including CASME II
[50], CASME3 [14], SAMM [6] and SMIC [15]. It achieves high recognition accuracy on new unseen subjects of various gender, age, and ethnicity. 2.