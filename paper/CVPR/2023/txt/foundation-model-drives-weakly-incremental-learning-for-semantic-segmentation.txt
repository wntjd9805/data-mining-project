Abstract
Modern incremental learning for semantic segmentation methods usually learn new categories based on dense anno-tations. Although achieve promising results, pixel-by-pixel labeling is costly and time-consuming. Weakly incremen-tal learning for semantic segmentation (WILSS) is a novel and attractive task, which aims at learning to segment new classes from cheap and widely available image-level labels.
Despite the comparable results, the image-level labels can not provide details to locate each segment, which limits the performance of WILSS. This inspires us to think how to im-prove and effectively utilize the supervision of new classes given image-level labels while avoiding forgetting old ones.
In this work, we propose a novel and data-efficient frame-work for WILSS, named FMWISS. Specifically, we propose pre-training based co-segmentation to distill the knowl-edge of complementary foundation models for generating dense pseudo labels. We further optimize the noisy pseudo masks with a teacher-student architecture, where a plug-in teacher is optimized with a proposed dense contrastive loss. Moreover, we introduce memory-based copy-paste augmentation to improve the catastrophic forgetting prob-lem of old classes. Extensive experiments on Pascal VOC and COCO datasets demonstrate the superior performance of our framework, e.g., FMWISS achieves 70.7% and 73.3% in the 15-5 VOC setting, outperforming the state-of-the-art method by 3.4% and 6.1%, respectively. 1.

Introduction
Semantic segmentation is a fundamental task in com-puter vision and has witnessed great progress using deep learning in the past few years.
It aims at assigning each pixel a category label. Modern supervised semantic seg-mentation methods [12, 14] are usually based on published large-scale segmentation datasets with pixel annotations.
Despite the promising results, one model pre-trained on one
Figure 1. Illustration of the major difference of pipeline between previous WILSS work and FMWISS. Given a model pre-trained on old classes with pixel-level labels (Y t−1), previous work [8] learn new classes (e.g., horse) via image-level labels (Ct), while
FMWISS improves and effectively utilizes the supervision from complementary foundation models. dataset is prone to easily forget learned knowledge when be-ing retrained on another dataset with new classes. This phe-nomenon is known as catastrophic forgetting [37], which is caused by large changes of model parameters to model new samples with novel categories without accessing old sam-ples.
A promising approach to solve such catastrophic for-getting problem is called incremental learning. Many methods have been proposed to solve image classification task [7, 10, 17, 25, 28, 33, 41, 44, 46, 49, 50]. Recently, a few methods have been presented to address incremental learning for semantic segmentation (ILSS) task, where only new classes of training samples of the current step are la-beled with pixel annotations and old classes of the previ-ous step are labeled as background. Modern ILSS methods can be classified into two categories: regularization-based and replay-based. Regularization-based methods [9, 18, 39] focus on distilling knowledge, e.g., output probability, in-termedia features, from pre-trained model of previous step.
Replay-based methods [36] propose to store the information of previous old classes or web-crawled images and replay for new training steps. However, a key barrier to further de-velop these methods is the requirement for pixel-level an-notations for new classes. Very recently, WILSON [8] first proposes a new task, weakly incremental learning for se-mantic segmentation (WILSS), to incrementally update the model from image-level labels for new classes. Despite the comparable results, the image-level labels can not provide
details to accurately locate each segment, which limits the performance and development of WILSS.
In this work, we explore to improve and more effec-tively utilize the supervision of new classes given image-level labels while preserving the knowledge of old ones. We propose a Foundation Model drives Weakly Incremental learning for Semantic Segmentation framework, dubbed
FMWISS.
Firstly, as shown in Figure 1, we are the first attempt to leverage pre-trained foundation models to improve the su-pervision given image-level labels for WILSS in a training-free manner. To be specific, we propose pre-training based co-segmentation to distill the knowledge of vision-language pre-training models (e.g., CLIP [42]) and self-supervised pre-training models (e.g., iBOT [52]), which can be com-plementary to each other. However, it is not trivial to apply the pre-trained models. We first adapt CLIP for category-aware dense mask generation. Based on the initial mask for each new class, we then propose to extract compact category-agnostic attention maps with seeds guidance us-ing self-supervised models. We finally refine the pseudo masks via mask fusion. We further propose to optimize the still noisy pseudo masks with a teacher-student archi-tecture, where the plug-in teacher is optimized with the pro-posed dense contrastive loss. Thus we can more effectively utilize the pseudo dense supervision. Finally, we present memory-based copy-paste augmentation to remedy the for-getting problem of old classes and can further improve the performance.
The contributions of this paper are as follows:
• We present a novel and data-efficient WILSS frame-work, called FMWISS, which is the first attempt to uti-lize complementary foundation models to improve and more effectively use the supervision given only image-level labels.
• We propose pre-training based co-segmentation to generate dense masks by distilling both category-aware and category-agnostic knowledge from pre-trained foundation models, which provides dense su-pervision against original image labels.
• To effectively utilize pseudo labels, we use a teacher-student architecture with a proposed dense contrastive loss to dynamically optimize the noisy pseudo labels.
• We further introduce memory-based copy-paste aug-mentation to remedy the forgetting problem of old classes and can also improve performance.
• Extensive experiments on Pascal VOC and COCO datasets demonstrate the significant efficacy of our
FMWISS framework. 2.