Abstract
The rapid advances in Vision Transformer (ViT) refresh the state-of-the-art performances in various vision tasks, overshadowing the conventional CNN-based models. This ignites a few recent striking-back research in the CNN world showing that pure CNN models can achieve as good performance as ViT models when carefully tuned. While encouraging, designing such high-performance CNN mod-els is challenging, requiring non-trivial prior knowledge of network design. To this end, a novel framework termed
Mathematical Architecture Design for Deep CNN (Deep-MAD1) is proposed to design high-performance CNN mod-els in a principled way. In DeepMAD, a CNN network is modeled as an information processing system whose expres-siveness and effectiveness can be analytically formulated by their structural parameters. Then a constrained mathe-matical programming (MP) problem is proposed to optimize these structural parameters. The MP problem can be eas-ily solved by off-the-shelf MP solvers on CPUs with a small memory footprint. In addition, DeepMAD is a pure math-ematical framework: no GPU or training data is required during network design. The superiority of DeepMAD is val-idated on multiple large-scale computer vision benchmark datasets. Notably on ImageNet-1k, only using conventional convolutional layers, DeepMAD achieves 0.7% and 1.5% higher top-1 accuracy than ConvNeXt and Swin on Tiny level, and 0.8% and 0.9% higher on Small level. 1.

Introduction
Convolutional neural networks (CNNs) have been the predominant computer vision models in the past decades [23,31,41,51,62]. Until recently, the emergence of
*These Authors contributed equally.
†Work done before joining Amazon.
‡Corresponding Author 1Source codes are available at https://github.com/alibaba/ lightweight-neural-architecture-search
Figure 1. Comparison between DeepMAD models, Swin [40] and
ConvNeXt [41] on ImageNet-1k. DeepMAD achieves better per-formance than Swin and ConvNeXt with the same scales.
Vision Transformers (ViTs) [18, 40, 63] establishes a novel deep learning paradigm surpassing CNN models [40, 63] thanks to the innovation of self-attention [65] mechanism and other dedicated components [3, 17, 28, 29, 54] in ViTs.
Despite the great success of ViT models in the 2020s,
CNN models still enjoy many merits. First, CNN models do not require self-attention modules which require quadratic computational complexity in token size [45]. Second, CNN models usually generalize better than ViT models when trained on small datasets [41]. In addition, convolutional operators have been well-optimized and tightly integrated on various hardware platforms in the industry, like IoT [5].
Considering the aforementioned advantages, recent re-searches try to revive CNN models using novel architecture designs [16,22,41,76]. Most of these works adopt ViT com-ponents into CNN models, such as replacing the attention matrix with a convolutional counterpart while keeping the
macrostructure of ViTs. After modiﬁcations, these modern
CNN backbones are considerably different from the con-ventional ResNet-like CNN models. Although these efforts abridge the gap between CNNs and ViTs, designing such high-performance CNN models requires dedicated efforts in structure tuning and non-trivial prior knowledge of net-work design, therefore is time-consuming and difﬁcult to generalize and customize.
In this work, a novel design paradigm named Mathemat-ical Architecture Design (DeepMAD) is proposed, which designs high-performance CNN models in a principled way. DeepMAD is built upon the recent advances of deep learning theories [8, 48, 50]. To optimize the architecture of CNN models, DeepMAD innovates a constrained mathe-matical programming (MP) problem whose solution reveals the optimized structural parameters, such as the widths and depths of the network. Particularly, DeepMAD maximizes the differential entropy [26,32,58,59,67,77] of the network with constraints from the perspective of effectiveness [50].
The effectiveness controls the information ﬂow in the net-work which should be carefully tuned so that the generated networks are well behaved. The dimension of the proposed
MP problem in DeepMAD is less than a few dozen. There-fore, it can be solved by off-the-shelf MP solvers nearly in-stantly on CPU. NO GPU is required and no deep model is created in memory2. This makes DeepMAD lightning fast even on CPU-only servers with a small memory footprint.
After solving the MP problem, the optimized CNN archi-tecture is derived from the MP solution.
DeepMAD is a mathematical framework to design op-timized CNN networks with strong theoretical guarantees and state-of-the-art (SOTA) performance. To demonstrate the power of DeepMAD, we use DeepMAD to optimize
CNN architectures only using the conventional convolu-tional layers [2,53] as building blocks. DeepMAD achieves comparable or better performance than ViT models of the same model sizes and FLOPs. Notably, DeepMAD achieves 82.8% top-1 accuracy on ImageNet-1k with 4.5G
FLOPs and 29M Params, outperforming ConvNeXt-Tiny (82.1%) [41] and Swin-Tiny (81.3%) [40] at the same scale;
DeepMAD also achieves 77.7% top-1 accuracy at the same scale as ResNet-18 [21] on ImageNet-1k, which is 8.9% better than He’s original ResNet-18 (70.9%) and is even comparable to He’s ResNet-50 (77.4%). The contributions of this work are summarized as follows:
• A Mathematical Architecture Design paradigm, Deep-MAD, is proposed for high-performance CNN archi-tecture design.
• DeepMAD is backed up by modern deep learning the-ories [8, 48, 50].
It solves a constrained mathemati-cal programming (MP) problem to generate optimized 2Of course, after solving the MP, training the generated DeepMAD models needs GPU
CNN architectures. The MP problem can be solved on
CPUs with a small memory footprint.
• DeepMAD achieves SOTA performances on multi-ple large-scale vision datasets, proving its superiority.
Even only using the conventional convolutional lay-ers, DeepMAD designs high-performance CNN mod-els comparable to or better than ViT models of the same model sizes and FLOPs.
• DeepMAD is transferable across multiple vision tasks, including image classiﬁcation, object detection, se-mantic segmentation and action recognition, with con-sistent performance improvements. 2.