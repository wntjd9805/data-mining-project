Abstract
Temporal Action Localization (TAL) methods typically operate on top of feature sequences from a frozen snippet encoder that is pretrained with the Trimmed Action Classiﬁ-cation (TAC) tasks, resulting in a task discrepancy problem.
While existing TAL methods mitigate this issue either by re-training the encoder with a pretext task or by end-to-end ﬁne-tuning, they commonly require an overload of high memory and computation. In this work, we introduce Soft-Landing (SoLa) strategy, an efﬁcient yet effective framework to bridge the transferability gap between the pretrained encoder and the downstream tasks by incorporating a light-weight neural network, i.e., a SoLa module, on top of the frozen encoder.
We also propose an unsupervised training scheme for the
SoLa module; it learns with inter-frame Similarity Match-ing that uses the frame interval as its supervisory signal, eliminating the need for temporal annotations. Experimen-tal evaluation on various benchmarks for downstream TAL tasks shows that our method effectively alleviates the task discrepancy problem with remarkable computational efﬁ-ciency. 1.

Introduction
Our world is full of untrimmed videos, including a plethora of Youtube videos, security camera recordings, and online streaming services. Analyzing never-ending video streams is thus one of the most promising directions of com-puter vision research in this era [29]. Amongst many long-form video understanding tasks, the task of ﬁnding action instances in time and classifying their categories, known as
Temporal Action Localization (TAL), has received intense attention from both the academia and the industry in recent years; TAL is considered to be the fundamental building block for more sophisticated video understanding tasks since it plays the basic role of distinguishing frame-of-interest from irrelevant background frames [19, 34, 40]. (cid:15)(cid:30) (cid:31)(cid:30) (cid:9)(cid:3)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)(cid:8)(cid:15)(cid:16)(cid:7)(cid:17) (cid:9)(cid:3)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)(cid:8)(cid:15)(cid:16)(cid:7)(cid:17) (cid:2) (cid:3) (cid:4) (cid:5) (cid:6) (cid:7) (cid:8) (cid:2) (cid:3) (cid:4) (cid:5) (cid:6) (cid:7) (cid:8) (cid:18) (cid:19) (cid:20) (cid:21) (cid:22) (cid:7) (cid:15) (cid:6) (cid:25)(cid:30) (cid:23)(cid:12)(cid:15)(cid:3)(cid:6)(cid:15)(cid:8)(cid:6)(cid:13)(cid:18)(cid:19)(cid:20) (cid:25)(cid:25)(cid:30) (cid:25)(cid:25)(cid:25)(cid:30)(cid:13) (cid:24)(cid:25)(cid:26)(cid:26)(cid:7)(cid:8)(cid:7)(cid:3)(cid:12)(cid:13) (cid:27)(cid:8)(cid:7)(cid:12)(cid:7)(cid:28)(cid:12)(cid:13)(cid:18)(cid:15)(cid:17)(cid:29)(cid:17) (cid:2)(cid:3)(cid:6)(cid:21)(cid:12)(cid:5)(cid:21)(cid:2)(cid:3)(cid:6)(cid:13)(cid:18)(cid:19)(cid:20) (cid:23)(cid:5)(cid:20)(cid:15) (cid:18) (cid:19) (cid:20) (cid:21) (cid:22) (cid:7) (cid:15) (cid:6)  (cid:13)!(cid:7)(cid:17)(cid:7)(cid:15)(cid:8)(cid:4)(cid:22)(cid:13)(cid:14)(cid:5)(cid:4)(cid:11)(cid:17)  (cid:13)(cid:27)(cid:15)(cid:8)(cid:15)(cid:16)(cid:7)(cid:12)(cid:7)(cid:8)(cid:17)(cid:13)(cid:14)(cid:8)(cid:5)"(cid:7)(cid:3)  (cid:13)(cid:23)(cid:3)(cid:25)(cid:10)(cid:10)(cid:7)(cid:12)(cid:13)(cid:14)(cid:7)(cid:15)(cid:12)(cid:11)(cid:8)(cid:7)(cid:17)  (cid:13)(cid:2)(cid:3)(cid:22)(cid:15)(cid:3)(cid:4)(cid:7)(cid:6)(cid:13)(cid:23)(cid:3)(cid:25)(cid:10)(cid:10)(cid:7)(cid:12)(cid:13)(cid:14)(cid:7)(cid:15)(cid:12)(cid:11)(cid:8)(cid:7)(cid:17) (cid:2)(cid:3)(cid:13)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:6)(cid:9)(cid:10)(cid:13)(cid:11)(cid:12)(cid:13)(cid:13)(cid:14)(cid:15)(cid:8)(cid:16)(cid:17)(cid:18)(cid:7) (cid:19)(cid:3)(cid:13)(cid:20)(cid:17)(cid:13)(cid:2) (cid:21)(cid:17)(cid:22)(cid:23)(cid:7)(cid:3)
Figure 1. (a-i) Standard TAL framework assumes a “frozen snip-pet encoder” and only focuses on designing a good TAL head, causing the task discrepancy problem. Straightforward approaches to alleviating the issue include devising (a-ii) a temporally sensi-tive pretext task [1, 32, 41], and (a-iii) an end-to-end TAL training procedure [20, 33]. However, both approaches break the aforemen-tioned frozen snippet encoder assumption. On the other hand, (b) our SoLa strategy shares the “frozen snippet encoder assumption” with the standard TAL framework by providing a smooth linkage between the frozen encoder and the downstream head. It offers gen-eral applicability and more importantly, exceptional computational efﬁciency.
Despite its importance, training a TAL model has a unique computational challenge that hinders the naive extension of conventional image processing models, mainly due to the large size of the model input. For instance, videos in the wild can be several minutes or even hours long, implying that loading the whole video to a device for processing is often infeasible. In this context, the prevailing convention in processing a long-form video for TAL is to divide the video into non-overlapping short snippets and deal with the snippet-wise feature sequences. Speciﬁcally, a standard train-ing pipeline for the long-form video understanding tasks consists of two steps: (i) Train the snippet encoder with a large-scale action recognition dataset (e.g., Kinetics400), which is often different from the dataset for the downstream task; (ii) Train the downstream head (e.g., TAL) that takes the snippet feature sequences extracted from the pretrained encoder. An issue here is that the mainstream pretext task for the snippet-wise video encoder is “Trimmed” Action Classi-ﬁcation (TAC), which does not handle action boundaries and background frames. Although the current pipeline achieves remarkable performance in TAL tasks due to the power of large action recognition datasets, recent works [1, 32, 33, 41] point out the task discrepancy problem that is inherent in this two-staged approach. The task discrepancy problem,
ﬁrst introduced in [33], comes from the pretrained snippet encoder’s insensitivity to different snippets within the same action class.
It results in a temporally invariant snippet feature sequence, making it hard to distinguish foreground actions from backgrounds. A straightforward approach to the problem is adopting a temporally sensitive pretext task to train the snippet encoder [1, 32], or devising an end-to-end framework [20, 33], which are brieﬂy described in Figure 1 (a). However, as all previous methods involve retraining the snippet encoder, an excessive use of memory and computa-tion is inevitable.
To tackle the task discrepancy problem, we propose a new approach, namely Soft-Landing (SoLa) strategy, which is neither memory nor computationally expensive. SoLa strategy is a novel method which incorporates a light-weight neural network, i.e., Soft-Landing (SoLa) module, between the pretrained encoder and the downstream head. The prop-erly trained SoLa module will act like a middleware between the pretext and the downstream tasks, mitigating the task dis-crepancy problem (Figure 1 (b)). Since the task adaptation is solely done by the SoLa module, the parameters of the pretrained encoder are ﬁxed in our SoLa strategy. The use of a frozen encoder signiﬁcantly differentiates our approach from previous methods that mainly focus on designing an appropriate training methodology for a snippet encoder. In addition, our SoLa strategy only requires an access to the pre-extracted snippet feature sequence, being fully compatible with the prevailing two-stage TAL framework.
We also propose Similarity Matching, an unsupervised training scheme for the SoLa module that involves neither frame-level data manipulation nor temporal annotations. Our training strategy circumvents the need for strong frame-level data augmentation which most existing unsupervised repre-sentation learning techniques [5, 10] rely on. This strategy perfectly suits our condition where frame-level data aug-mentation is impossible, as we only have an access to pre-extracted snippet features. The new loss is based on a simple empirical observation: “adjacent snippet features are simi-lar, while distant snippet features remain distinct”. Coupled with the Simsiam [6] framework, Similarity Matching not only prevents the collapse, but also induces temporally sen-sitive feature sequences, resulting in a better performance in various downstream tasks.
The contributions of the paper can be summarized as follows:
• To tackle the task discrepancy problem, we introduce a novel Soft-Landing (SoLa) strategy, which does not involve retraining of the snippet encoder. As we can directly deploy the “frozen” pretrained snippet encoder without any modiﬁcation, our SoLa strategy offers eas-ier applicability compared to previous works that re-quire snippet encoders to be retrained.
• We propose Similarity Matching, a new self-supervised learning algorithm for the SoLa strategy.
As frame interval is utilized as its only learning signal, it requires neither data augmentation nor temporal an-notation.
• With our SoLa strategy, we show signiﬁcant improve-ment in performance for downstream tasks, outperform-ing many of the recent works that involve computation-ally heavy snippet encoder retraining. 2.