Abstract
The recent detection transformer (DETR) simplifies the object detection pipeline by removing hand-crafted designs and hyperparameters as employed in conventional two-stage object detectors. However, how to leverage the sim-ple yet effective DETR architecture in domain adaptive ob-ject detection is largely neglected. Inspired by the unique
DETR attention mechanisms, we design DA-DETR, a do-main adaptive object detection transformer that introduces information fusion for effective transfer from a labeled source domain to an unlabeled target domain. DA-DETR introduces a novel CNN-Transformer Blender (CTBlender) that fuses the CNN features and Transformer features inge-niously for effective feature alignment and knowledge trans-fer across domains. Specifically, CTBlender employs the
Transformer features to modulate the CNN features across multiple scales where the high-level semantic information and the low-level spatial information are fused for accu-rate object identification and localization. Extensive experi-ments show that DA-DETR achieves superior detection per-formance consistently across multiple widely adopted do-main adaptation benchmarks. 1.

Introduction
Object detection aims to predict a bounding box and a class label for interested objects in images and it has been a longstanding challenge in the computer vision re-search. Most existing work adopts a two-stage detection pipeline that involves heuristic anchor designs, complicated post-processing such as non-maximum suppression (NMS), etc. The recent detection transformer (DETR) [5] has at-tracted increasing attention which greatly simplifies the two-stage detection pipeline by removing hand-crafted an-chors [21, 22, 49] and NMS [21, 22, 49]. Despite its great detection performance under a fully supervised setup, how to leverage the simple yet effective DETR architecture in domain adaptive object detection is largely neglected.
*Equal contribution, {jingyi.zhang, jiaxing.huang}@ntu.edu.sg.
†Corresponding author, shijian.lu@ntu.edu.sg.
Figure 1. The vanilla Deformable-DETR [81] trained with la-beled source data cannot handle target data well due to cross-domain shift. The introduction of adversarial feature alignment in Deformable-DETR + Direct-align [19] improves the detection clearly. The proposed DA-DETR fuses CNN features and trans-former features ingeniously which achieves superior unsupervised domain adaptation consistently across four widely adopted bench-marks including Cityscapes → Foggy cityscapes in (a), SIM 10k
→ Cityscapes in (b), KITTI → Cityscapes in (c) and PASCAL
VOC → Clipart1k in (d).
Different from the conventional CNN-based detection architectures such as Faster RCNN [49], DETR has a CNN backbone followed by a transformer head consisting of an encoder-decoder structure. The CNN backbone and the transformer head learn different types of features [17,48,69]
- the former largely captures low-level localization features (e.g., edges and lines around object boundaries) while the latter largely captures global inter-pixel relationship and high-level semantic features. At the other end, many prior studies show that fusing different types of features often is often helpful in various visual recognition tasks [9, 11].
Hence, it is very meaningful to investigate how to fuse the two types of DETR features to address the domain adaptive object detection challenge effectively.
We design DA-DETR, a simple yet effective Domain
Adaptive DETR that introduces information fusion into the DETR architecture for effective domain adaptive ob-ject detection. The core design is a CNN-Transformer
Blender (CTBlender) that employs the high-level semantic
features in the Transformer head to conditionally modulate the low-level localization features in the CNN backbone.
CTBlender consists of two sequential fusion components, including split-merge fusion (SMF) that fuses CNN and
Transformer features within an image and scale aggregation fusion (SAF) that fuses the SMF features across multiple feature scales. Different from the existing weight-and-sum fusion [9, 11], SMF first splits CNN features into multiple groups with different semantic information as captured by the Transformer head and then merges them with channel shuffling for effective information communication among different groups. The SMF features of each scale are then aggregated by SAF for fusing both semantic and localiza-tion information across multiple feature scales. Hence, CT-Blender captures both semantic and localization features in-geniously which enables comprehensive and effective inter-domain feature alignment with a single discriminator.
The main contributions of this work can be summarized in three aspects. First, we propose DA-DETR, a simple yet effective domain adaptive detection transformer that intro-duces information fusion for effective domain adaptive ob-ject detection. To the best of our knowledge, this is the first work that explores information fusion for domain adaptive object detection. Second, we design a CNN-Transformer
Blender that fuses the CNN features and Transformer fea-tures ingeniously for effective feature alignment and knowl-edge transfer across domains. Third, extensive experi-ments show that DA-DETR achieves superior object detec-tion over multiple widely studied domain adaptation bench-marks as compared with the state-of-the-art as shown in
Fig. 1. 2.