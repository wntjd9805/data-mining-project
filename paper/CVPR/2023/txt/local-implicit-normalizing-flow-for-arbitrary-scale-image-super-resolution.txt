Abstract
Flow-based methods have demonstrated promising re-sults in addressing the ill-posed nature of super-resolution (SR) by learning the distribution of high-resolution (HR) images with the normalizing ﬂow. However, these methods can only perform a predeﬁned ﬁxed-scale SR, limiting their potential in real-world applications. Meanwhile, arbitrary-scale SR has gained more attention and achieved great progress. Nonetheless, previous arbitrary-scale SR meth-ods ignore the ill-posed problem and train the model with per-pixel L1 loss, leading to blurry SR outputs. In this work, we propose “Local Implicit Normalizing Flow” (LINF) as a uniﬁed solution to the above problems. LINF models the distribution of texture details under different scaling fac-tors with normalizing ﬂow. Thus, LINF can generate photo-realistic HR images with rich texture details in arbitrary scale factors. We evaluate LINF with extensive experiments and show that LINF achieves the state-of-the-art perceptual quality compared with prior arbitrary-scale SR methods. 1.

Introduction
Arbitrary-scale image super-resolution (SR) has gained increasing attention recently due to its tremendous appli-cation potential. However, this ﬁeld of study suffers from two major challenges. First, SR aims to reconstruct high-resolution (HR) image from a low-resolution (LR) counter-part by recovering the missing high-frequency information.
This process is inherently ill-posed since the same LR im-age can yield many plausible HR solutions. Second, prior deep learning based SR approaches typically apply upsam-pling with a pre-deﬁned scale in their network architectures, such as squeeze layer [1], transposed convolution [2], and sub-pixel convolution [3]. Once the upsampling scale is de-termined, they are unable to further adjust the output res-olutions without modifying their model architecture. This causes inﬂexibility in real-world applications. As a result,
* and indicate equal contribution. This work was developed during the internship of Jie-En Yao and Li-Yuan Tsao at MediaTek Inc.
†
Figure 1. A comparison of the previous arbitrary-scale SR ap-proaches and LINF. LINF models the distribution of texture details in HR images at arbitrary scales. Therefore, unlike the prior meth-ods that tend to produce blurry images, LINF is able to generate arbitrary-scale HR images with rich and photo-realistic textures. discovering a way to perform arbitrary-scale SR and pro-duce photo-realistic HR images from an LR image with a single model has become a crucial research direction.
A natural approach to addressing the one-to-many in-verse problem in SR is to consider the solution as a dis-tribution. Consequently, a number of generative-based SR methods [1, 4–8] have been proposed to tackle this ill-posed problem. Among them, ﬂow-based SR methods show promise, as normalizing ﬂow [9–12] offers several advantages over other generative models. For instance,
ﬂow does not suffer from the training instability and mode collapse issues present in generative adversarial networks (GANs) [13]. Moreover, ﬂow-based methods are compu-tationally efﬁcient compared to diffusion [14] and autore-gressive (AR) [15, 16] models. Representative ﬂow-based models, such as SRFlow [1] and HCFlow [7], are able to generate high-quality SR images and achieve state-of-the-art results on the benchmarks. However, these methods are restricted to ﬁxed-scale SR, limiting their applicability.
Another line of research focuses on arbitrary-scale SR.
LIIF [17] employs local implicit neural representation to represent images in a continuous domain.
It achieves arbitrary-scale SR by replacing ﬁxed-scale upsample mod-ules with an MLP to query the pixel value at any coordi-nate. LTE [18] further estimates the Fourier information at a given coordinate to make MLP focus on learning high-frequency details. However, these works did not explicitly account for the ill-posed nature of SR. They adopt a per-pixel L1 loss to train the model in a regression fashion. The reconstruction error favors the averaged output of all possi-ble HR images, leading the model to generate blurry results.
Based on the observation above, combining ﬂow-based
SR model with the local implicit module is a promising di-rection in which ﬂow can account for the ill-posed nature of SR, and the local implicit module can serve as a solu-tion to the arbitrary-scale challenge. Recently, LAR-SR [8] claimed that details in natural images are locally correlated without long-range dependency. Inspired by this insight, we formulated SR as a problem of learning the distribution of local texture patch. With the learned distribution, we per-form super-resolution by generating the local texture sepa-rately for each non-overlapping patch in the HR image.
With the new problem formulation, we present Local Im-plicit Normalizing Flow (LINF) as the solution. Speciﬁ-cally, a coordinate conditional normalizing ﬂow models the local texture patch distribution, which is conditioned on the
LR image, the central coordinate of local patch, and the scaling factor. To provide the conditional signal for the
ﬂow model, we use the local implicit module to estimate
Fourier information at each local patch. LINF excels the previous ﬂow-based SR methods with the capability to up-scale images with arbitrary scale factors. Different from prior arbitrary-scale SR methods, LINF explicitly addresses the ill-posed issue by learning the distribution of local tex-ture patch. As shown in Fig 1, hence, LINF can generate
HR images with rich and reasonable details instead of the over-smoothed ones. Furthermore, LINF can address the is-sue of unpleasant generative artifacts, a common drawback of generative models, by controlling the sampling tempera-ture. Speciﬁcally, the sampling temperature in normalizing
ﬂow controls the trade-off between PSNR (ﬁdelity-oriented metric) and LPIPS [19] (perceptual-oriented metric). The contributions of this work can be summarized as follows:
•
•
•
We proposed a novel LINF framework that leverages the advantages of a local implicit module and normal-izing ﬂow. To the best of our knowledge, LINF is the
ﬁrst framework that employs normalizing ﬂow to gen-erate photo-realistic HR images at arbitrary scales.
We validate the effectiveness of LINF to serve as a uni-ﬁed solution for the ill-posed and arbitrary-scale chal-lenges in SR via quantitative and qualitative evidences.
We examine the trade-offs between the ﬁdelity- and perceptual-oriented metrics, and show that LINF does yield a better trade-off than the prior SR approaches. 2.