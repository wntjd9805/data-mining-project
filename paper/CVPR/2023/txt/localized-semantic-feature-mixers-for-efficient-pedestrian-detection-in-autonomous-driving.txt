Abstract 1.

Introduction
Autonomous driving systems rely heavily on the underly-ing perception module which needs to be both performant and efﬁcient to allow precise decisions in real-time. Avoid-ing collisions with pedestrians is of topmost priority in any autonomous driving system. Therefore, pedestrian detec-tion is one of the core parts of such systems’ perception modules. Current state-of-the-art pedestrian detectors have two major issues. Firstly, they have long inference times which affect the efﬁciency of the whole perception module, and secondly, their performance in the case of small and heavily occluded pedestrians is poor. We propose Local-ized Semantic Feature Mixers (LSFM), a novel, anchor-free pedestrian detection architecture. It uses our novel Super
Pixel Pyramid Pooling module instead of the, computation-ally costly, Feature Pyramid Networks for feature encod-ing. Moreover, our MLPMixer-based Dense Focal Detec-tion Network is used as a light detection head, reducing computational effort and inference time compared to ex-isting approaches. To boost the performance of the pro-posed architecture, we adapt and use mixup augmentation which improves the performance, especially in small and heavily occluded cases. We benchmark LSFM against the state-of-the-art on well-established trafﬁc scene pedestrian datasets. The proposed LSFM achieves state-of-the-art per-formance in Caltech, City Persons, Euro City Persons, and
TJU-Trafﬁc-Pedestrian datasets while reducing the infer-ence time on average by 55%. Further, LSFM beats the human baseline for the ﬁrst time in the history of pedestrian detection. Finally, we conducted a cross-dataset evaluation which proved that our proposed LSFM generalizes well to unseen data.
Autonomous driving is currently under the spotlight in the computer vision community [3, 20]. Detecting and avoiding collisions with pedestrians is one of the numer-ous challenges of autonomous driving. Pedestrian detectors for autonomous driving not only have to be performant but efﬁcient as well, since rapid perception is required to make timely decisions. Furthermore, these systems need to ful-ﬁll additional constraints such as good portability and low computational footprint, as compute-intensive systems can have a heavy impact on the milage of autonomous vehicles.
Pedestrian detection for autonomous driving aims to pro-vide the autonomous vehicle with a timely perception of all pedestrians in its surroundings. The problem becomes more challenging as most of the pedestrians are occluded either by other pedestrians or by other objects [5,48]. Addi-tionally, the camera stream is introduced with motion blur since it is coming from the camera mounted on a moving vehicle [15]. The motion blur problem further intensiﬁes when the vehicle moves faster. Dealing with motion blur and occlusion is vital for a pedestrian detector to perform well. Another major challenge for pedestrian detectors is the scale variance in pedestrians. Since the camera images are subject to perspective distortion the pedestrian scales vary from a few pixels large to almost equal to the height of the image frame. Small-scale pedestrians (far or short) are the bottleneck of scale variance problem [5]. The pedestrian detector needs to sufﬁciently understand the core visual fea-tures of a pedestrian and use them to detect pedestrians ir-respective of their scales.
Furthermore, domain generalization is critical for a pedestrian detector as it is expected to perform in all cir-cumstances e.g., all kinds of weather, lighting, and trafﬁc densities, which might or might not be part of the training data [14, 15]. Therefore, pedestrian detectors should per-form well on unseen data to be reliable under real-world circumstances.
(a) Reasonable (b) Heavy Occlusion
Figure 1. Performance of pedestrian detectors in different settings and their evolution over the years. Both ﬁgures contain data on three different pedestrian detection datasets namely, City Persons [48] (Green), Euro City Persons [1] (Pink), and Caltech Pedestrians [10] (Yellow). Y-axis values are % based in both (a, b). The proposed LSFM beats the human baseline on the Caltech dataset [47].
Recent research focuses on improving pedestrian detec-tors in terms of accuracy while ignoring their computational costs [5]. The performance of pedestrian detectors has im-proved a lot recently. However, there is still room for im-provement, especially in heavy occlusion and small cases
[14,15,20,24]. Fig. 1 shows the performance improvements in pedestrian detection over the last decade. Further, an im-provement in accuracy usually comes with an increase in inference time [5], especially in the case of methods based on Vision-Transformers (ViT) [6, 9, 30]. A similar trade-off can be observed when using multi-modal sensor fusion.
The accuracy improves while bearing heavy computational costs. A major component of ViT is self-attention, which has a complexity of O(n2) and does not scale well for high-resolution images [41]. Researchers have proposed alterna-tives to self-attention to avoid heavy computational costs, one of which is MLPMixers [37]. MLPMixer alternates between the channel and token dimension, thus maximiz-ing cache efﬁciency, and achieving almost similar perfor-mance to transformers in image classiﬁcation. However, when the image resolution is high, the MLPMixer feature map sizes increase quadratically, making it memory and compute-intensive backbones for downstream tasks. Also, the fully-connected nature of the MLP-based networks pre-vents them from being resolution independent like convolu-tions, as the number of parameters needs to be predeﬁned.
We propose a novel pedestrian detection network that in-cludes a Multi Layer Perceptron (MLP) based neck and a patched MLP mixer-based object detection head [37]. The proposed neck efﬁciently extracts and enriches key features from different stages of the backbone, and the detection head enables the dense connections between high-level se-mantic features. Together, when combined with a back-bone, they constitute a lightweight, cache-efﬁcient, and yet performant pedestrian detector. To train our network to be immune to motion blur and occlusion, we used hard mixup augmentation, which provides our network with data for soft occlusion and motion blur-like effects. Also, the hard mixup augmentation generates additional data for small de-tection cases to help the network absorb the key features which work across all scales.
We conduct an exhaustive evaluation of the proposed network on renowned pedestrian datasets to test it against the existing state-of-the-art methods in terms of both per-formance and efﬁciency. We conduct a cross dataset eval-uation to test the domain generalization capabilities of the proposed network. Further, we perform the ablation study to check the effectiveness of different components of the proposed network. Major contributions of this work are as follows:
• We propose Super Pixel Pyramid Pooling (SP3), a
MLP-based feature pyramid network.
• We propose Dense Focal Detection Network (DFDN), a lightweight head to allow denser connections.
• We pre-trained a deep but not wide ConvMLP [21] based backbone, ConvMLP Pin, for the proposed net-work to reduce inference time.
• We propose pedestrian detectors with backbones of different sizes to enable applications in resource-constrained environments.
• Our proposed model beats the human baseline [47] for the ﬁrst time in the history of pedestrian detection.
2.