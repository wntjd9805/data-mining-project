Abstract
The main challenge in domain generalization (DG) is to handle the distribution shift problem that lies between the training and test data. Recent studies suggest that test-time training (TTT), which adapts the learned model with test data, might be a promising solution to the problem. Gen-erally, a TTT strategy hinges its performance on two main factors: selecting an appropriate auxiliary TTT task for up-dating and identifying reliable parameters to update during the test phase. Both previous arts and our experiments in-dicate that TTT may not improve but be detrimental to the learned model if those two factors are not properly consid-ered. This work addresses those two factors by proposing an Improved Test-Time Adaptation (ITTA) method. First, in-stead of heuristically defining an auxiliary objective, we pro-pose a learnable consistency loss for the TTT task, which con-tains learnable parameters that can be adjusted toward bet-ter alignment between our TTT task and the main prediction task. Second, we introduce additional adaptive parameters for the trained model, and we suggest only updating the adap-tive parameters during the test phase. Through extensive ex-periments, we show that the proposed two strategies are ben-eficial for the learned model (see Figure 1), and ITTA could achieve superior performance to the current state-of-the-art methods on several DG benchmarks. Code is available at https://github.com/liangchen527/ITTA. 1.

Introduction
Recent years have witnessed the rapid development of deep learning models, which often assume the training and test data are from the same domain and follow the same distribution. However, this assumption does not always hold in real-world scenarios. Distribution shift among the source and target domains is ubiquitous in related areas [35], such as autonomous driving or object recognition tasks, resulting
*Corresponding authors. This work is done when L. Chen is an intern in Tencent AI Lab.
Figure 1. Performance improvements from the proposed two strate-gies (i.e. introducing a learnable consistency loss and including additional adaptive parameters to improve TTT) for the baseline model (i.e. ResNet18 [30] with existing augmentation strategy [74]).
Experiments are conducted on the PACS dataset [37] with the leave-one-out setting. Following [27], we use 60 sets of random seeds and hyper-parameters for each target domain. The reported average accuracy and error bars verify the effectiveness of our method. in poor performances for delicately designed models and hindering the further application of deep learning techniques.
Domain generalization (DG) [2,8,16,23,24,31,38–40,40, 44, 46, 50, 51, 68], designed to generalize a learned model to unseen target domains, has attracted a great deal of attention in the research community. The problem can be traced back to a decade ago [7], and various approaches have been pro-posed to push the DG boundary ever since. Those efforts in-clude invariant representation learning [28, 46, 48, 57], adver-sarial learning [23,40,44,68], augmentation [9,41,42,65,74], or meta-learning [2, 16, 38, 39]. Despite successes on certain occasions, a recent study [27] shows that, under a rigorous evaluation protocol, most of these arts are inferior to the baseline empirical risk minimization (ERM) method [60].
This finding is not surprising, as most current arts strive to decrease the distribution shift only through the training data while overlooking the contributions from test samples.
Recently, the test-time training (TTT) technique [59] has been gaining momentum for easing the distribution shift problem. TTT lies its success in enabling dynamic tuning of the pretrained model with the test samples via an auxil-iary TTT task, which seems to be a promising effort when
confronting data from different domains. However, TTT is not guaranteed to improve the performance. Previous arts [45, 62] indicate that selecting an appropriate auxiliary
TTT task is crucial, and an inappropriate one that does not align with the main loss may deteriorate instead of improv-ing the performance. Meanwhile, it is pointed out in [62] that identifying reliable parameters to update is also essential for generalization, which is in line with our experimental findings in Sec. 5.3. Both of these two tasks are non-trivial, and there are limited efforts made to address them.
This paper aims to improve the TTT strategy for better
DG. First, different from previous works that empirically define auxiliary objectives and assume they are aligned with the main task, our work does not make such assumptions.
Instead, we suggest learning an appropriate auxiliary loss for test-time updating. Specifically, encouraged by recent successes in multi-view consistency learning [13, 26, 29], we propose to augment the consistency loss by adding learn-able parameters based on the original implementation, where the parameters can be adjusted to assure our TTT task can be more aligned with the main task and are updated by en-forcing the two tasks share the same optimization direction.
Second, considering that identifying reliable parameters to update is an everlasting job given the growing size of current deep models, we suggest introducing new adaptive param-eters after each block during the test phase, and we only tune the new parameters by the learned consistency loss while leaving the original parameters unchanged. Through extensive evaluations on the current benchmark [27], we illustrate that the learnable consistency loss performs more effectively than the self-supervised TTT tasks adopted in previous arts [59, 62], and by tuning only the new adaptive parameters, our method is superior to existing strategies that update all the parameters or part of them.
This work aims to ease the distribution shift problem by improving TTT, and the main contributions are three-fold:
• We introduce a learnable consistency loss for test-time adaptation, which can be enforced to be more aligned with the main loss by tuning its learnable parameters.
• We introduce new adaptive parameters for the trained model and only update them during the test phase.
• We conduct experiments on various DG benchmarks and illustrate that our ITTA performs competitively against current arts under the rigorous setting [27] for both the multi-source and single-source DG tasks. 2.