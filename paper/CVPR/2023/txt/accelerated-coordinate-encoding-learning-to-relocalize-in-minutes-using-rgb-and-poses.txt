Abstract 1.

Introduction
Learning-based visual relocalizers exhibit leading pose accuracy, but require hours or days of training. Since train-ing needs to happen on each new scene again, long train-ing times make learning-based relocalization impractical for most applications, despite its promise of high accu-racy.
In this paper we show how such a system can ac-tually achieve the same accuracy in less than 5 minutes.
We start from the obvious: a relocalization network can be split in a scene-agnostic feature backbone, and a scene-specific prediction head. Less obvious: using an MLP prediction head allows us to optimize across thousands of view points simultaneously in each single training itera-tion. This leads to stable and extremely fast convergence.
Furthermore, we substitute effective but slow end-to-end training using a robust pose solver with a curriculum over a reprojection loss. Our approach does not require priv-ileged knowledge, such a depth maps or a 3D model, for speedy training. Overall, our approach is up to 300x faster in mapping than state-of-the-art scene coordinate regres-sion, while keeping accuracy on par. Code is available: https://nianticlabs.github.io/ace
Time is really the only capital that any human being has, and the only thing he can’t afford to lose.
Thomas Edison
Time is relative. Time spent waiting can stretch to infin-ity. Imagine waiting for a visual relocalizer to finally work in a new environment. It can take hours – and feel like days – until the relocalizer has finished its pre-processing of the scene. Only then can it estimate the camera’s position and orientation to support real-time applications like navigation or augmented reality (AR).
Relocalizers need that extensive pre-processing to build a map of the environment that defines the coordinate space we want to relocalize in. Visual relocalizers typically build maps from sets of images of the environment, for each of which the camera pose is known. There are two prevalent families of structure-based relocalizers that meet the high accuracy requirements of applications like AR.
Sparse feature-matching approaches [12, 25, 40, 44, 48, 49,67] need to build an explicit 3D reconstruction of a scene using structure-from-motion (SfM) software [51, 55, 63].
Even when poses of mapping images are known, the run-time of SfM for scene triangulation varies a lot, and can lie anywhere between 10 minutes and 10 hours depending on how many mapping frames are used. When mapping suc-ceeds, feature-based relocalizers are fast at query time and accurate [44,49]. Less refined maps can be built in real time using SLAM, if one is willing to accept the detrimental ef-fect on accuracy [4]. In either case, the underlying maps can consume vast amounts of storage, and can reveal private in-formation that was present in the mapping images [16, 56].
On the other hand, scene coordinate regression [5, 7, 10, 20, 31, 53, 64] learns an implicit representation of the scene via gradient descent. The resulting maps can be as small as 4MB [10], and privacy preserving [67]. But, while scene coordinate regression is on-par with feature-matching in terms of accuracy and relocalization time [4], the fact that they map an environment via hours-long training of a network makes them unattractive for most applications.
The state-of-the-art scene coordinate regression pipeline,
DSAC* [10], requires 15 hours to reach top accuracy on a premium GPU, see Fig. 1. We can stop training any time, and see which accuracy we get but, after 5 minutes mapping time, DSAC* has a relocalization rate in the single digits. In fact, the corresponding data point for the plot in Fig. 1 can be found at the bottom of the previous page.
The aim of this work is summarized quickly: we take a scene coordinate regression-based relocalizer, the slow-est approach in terms of mapping time, and make it one of the fastest. In particular, we present Accelerated Coordi-nate Encoding (ACE), a schema to train scene coordinate regression in 5 minutes to state-of-the-art accuracy.
Speeding up training time normally causes moderate in-terest in our community, at best. This is somewhat justified in train-once-deploy-often settings. Still, learning-based visual relocalization does not fall within that category, as training needs to happen on each new scene, again. There-fore, fast training has a range of important implications:
• Mapping delay. We reduce the time between collect-ing mapping data, and having a top-performing relo-calizer for that environment.
• Cost. Computation time is expensive. Our approach maps a scene within minutes on a budget GPU.
• Energy consumption. Extensive computation is an environmental burden. We significantly reduce the re-source footprint of learning-based relocalization.
• Reproducibility. Using ACE to map all scenes of the datasets used in this paper can be done almost five times over on a budget GPU, in the time it takes
DSAC* to map a single scene on a premium GPU.
We show that a thoughtful split of a standard scene coor-dinate regression network allows for more efficient train-ing. In particular, we regard scene coordinate regression as a mapping from a high-dimensional feature vector to a 3D point in scene space. We show that a multi-layer perceptron (MLP) can represent that mapping well, as opposed to con-volutional networks normally deployed [7,10,20]. Training a scene-specific MLP allows us to optimize over many (of-tentimes all available) mapping views at once in each single training iteration. This leads to very stable gradients that allow us to operate in very aggressive, high-learning rate regimes. We couple this with a curriculum over a repro-jection loss that lets the network burn in on reliable scene structures at later stages of training. This mimics end-to-end training schemes that involve differentiating through robust pose estimation during training [10], but are much slower than our approach. We summarize our contributions:
• Accelerated Coordinate Encoding (ACE), a scene co-ordinate regression system that maps a new scene in 5 minutes. Previous state-of-the-art scene coordinate re-gression systems require hours of mapping to achieve comparable relocalization accuracy.
• ACE compiles a scene into 4MB worth of network weights. Previous scene coordinate regression systems required 7-times more storage, or had to sacrifice ac-curacy for scene compression.
• Our approach requires only posed RGB images for mapping. Previous fast mapping relocalizers relied on priviledged knowledge like depth maps or a scene mesh for speedy mapping. 2.