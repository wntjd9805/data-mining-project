Abstract
Neural Radiance Field (NeRF) has exhibited outstand-ing three-dimensional (3D) reconstruction quality via the novel view synthesis from multi-view images and paired calibrated camera parameters. However, previous NeRF-based systems have been demonstrated under strictly con-trolled settings, with little attention paid to less ideal sce-narios, including with the presence of noise such as expo-sure, illumination changes, and blur. In particular, though blur frequently occurs in real situations, NeRF that can handle blurred images has received little attention. The few studies that have investigated NeRF for blurred im-ages have not considered geometric and appearance con-sistency in 3D space, which is one of the most important factors in 3D reconstruction. This leads to inconsistency and the degradation of the perceptual quality of the con-structed scene. Hence, this paper proposes a DP-NeRF, a novel clean NeRF framework for blurred images, which is constrained with two physical priors. These priors are derived from the actual blurring process during image ac-quisition by the camera. DP-NeRF proposes rigid blurring kernel to impose 3D consistency utilizing the physical pri-ors and adaptive weight proposal to refine the color com-position error in consideration of the relationship between depth and blur. We present extensive experimental results for synthetic and real scenes with two types of blur: camera motion blur and defocus blur. The results demonstrate that
DP-NeRF successfully improves the perceptual quality of the constructed NeRF ensuring 3D geometric and appear-ance consistency. We further demonstrate the effectiveness of our model with comprehensive ablation analysis. 1 2 1.

Introduction
The synthesis of the photo-realistic novel view image of complex three-dimensional (3D) scenes has advanced rapidly due to the emergence of the Neural Radiance
Field(NeRF) [26]. NeRF has introduced implicit scene rep-resentation to the field, which maps an arbitrary continuous 1Code: https://github.com/dogyoonlee/DP-NeRF 2Project: https://dogyoonlee.github.io/dpnerf/
Figure 1. (a) Deblur-NeRF models blurring kernel based on 2D offset on the image pixels. This modeling break the consistency in trained neural radiance field due to the lack of a 3D consis-tency priors. However, (b) DP-NeRF can render clean neural ra-diance field guaranteeing the 3D consistency with rigid motion of the camera based on the physical priors of the blur occurrence. 3D coordinate to the volume density and radiance color us-ing volume-rendering technique and implicit neural repre-sentation. NeRF densely reconstructs continuous 3D space to produce photorealistic rendered images with novel view.
Though NeRF has achieved remarkable success in a va-riety of fields, most of the NeRF variants have been de-signed and tested for a carefully controlled environment that requires well-captured images from multiple views with calibrated camera parameters. However, various forms of noises are usually included in the data captured for the
NeRF in real scenarios, complicating geometric and appear-ance consistency in 3D representation.
Several NeRF variants have attempted to reconstruct 3D scene in the presence of noise, including exposure noise [8, 11, 25], motion [17–19, 29, 30, 33, 49, 55], illumi-nation changes [6, 23, 57], and aliasing [1, 2]. However, although it frequently occurs in real-world settings, blur has not been sufficiently addressed to date, despite the fact that it generates critical artifacts in 3D scene reconstruc-tion. Deblur-NeRF [22] introduced blurring kernel estima-tion for a NeRF by imitating in-camera blurred image ac-quisition based on a blind deblurring method. Their method demonstrated excellent performance and produced clearly rendered images from multi-view images. However, the blurring kernel in [22] is implemented by optimizing ray deformation and composition weights depending on the 2D
pixel location independently, leading to insufficient 3D in-formation. In reality, the blurring process occurs simultane-ously for all pixels in an image due to the physical process of in-camera image acquisition, but [22] overlooks the prior for blurring, leading to a lack of consistency in an image.
Moreover, the designed kernel can be inherently optimized to subobtimal in regions with complex depth or similar ap-pearance due to the independent optimization of the defor-mation of each ray. As a result, the estimated kernel has difficulty aggregating 3D information in a way that guaran-tees geometric and appearance consistency.
In this paper, we propose a deblurred NeRF based on two physical scene priors (hereafter, DP-NeRF) with a novel rigid blurring kernel (RBK) and adaptive weight pro-posal (AWP). The RBK consists of rigid ray transformation (RRT) and coarse composition weights (CCW), which uti-lize explicit physical scene priors derived from the blurring process to construct a consistent 3D scene representation from blurred images. In addition, the AWP proposes fine-grained color composition weights considering the relation-ship between depth and blur to create more realistic and clean 3D representation. Furthermore, we propose coarse-to-fine optimization for stable training and to gradually in-crease the effect of the AWP during training by introducing exponential weight decay between the two losses from the
RBK and AWP. Figure 1 summarizes the DP-NeRF’s sys-tem using the rigid motion of the camera.
The RBK generates a 3D deformation field and coarse weights for color composition based on the view informa-tion for each scene regardless of the pixel for each ray. This architecture is inspired by the physical scene prior that the blurring process consistently occurs for all pixels for a spe-cific view. Specifically, the deformation field is constructed as the 3D rigid motion of the camera for each view and does not depend on the 2D spatial position of each ray. In con-trast to Deblur-NeRF [22], our model successfully models 3D space with consistent geometry and appearance due to the use of these conditional physical priors and not fully depending on 2D pixel-wise independent ray optimization.
Previous studies have claimed that color composition process in a blurring kernel are affected by the depth values of the pixels when compositing blurred colors from both camera motion and defocus blur [43, 44]. Hence, RBK can lose detail in regions that have a complex depth or simi-lar textures even though it achieves remarkably realistic 3D scene. For this reason, the AWP refines the composition weights using feature modulation (FM) [59] and novel mo-tion feature aggregation module(MAM) based on the depth features of samples for transformed rays, the viewing di-rection, and the view information. Following the [22], we jointly optimize the RBK, AWP, and sharp NeRF with only the reconstruction loss from the blurred input as supervi-sion. During inference stage, we can clearly render a recon-structed 3D scene using only the trained sharp NeRF model.
The rest of the paper is structured as follows. In Sec-tion 3, we describe the RBK and AWP in detail. In Sec-tion 4.1 and supplementary material, we provide experi-mental results for novel view synthesis using synthetic and real scene datasets with two types of blur that are provided from [22]. The results show that DP-NeRF achieves signif-icant quantitative and qualitative improvement, preserving 3D consistency with a cleanly rendered novel view. In ad-dition, we extensively analyze the effectiveness of the pro-posed model in Section 4.2. We also demonstrate how the
RBK approximately models the blurring process in the sup-plementary material. To summarize, this paper offers the following major contributions.
• Rigid blurring kernel. We propose a novel RBK to construct a clean NeRF from blurred images utilizing physical scene priors derived from the blurring process during image acquisition.
• Adaptive weight proposal. We propose an AWP to re-fine the composition weights in the RBK considering the relationship between depth and blur to generate more realistic results.
• Coarse-to-fine optimization. To fully utilize proposed methods in training, we propose coarse-to-fine opti-mization by applying exponential weight decay be-tween the reconstruction loss from the RBK and AWP.
• Significant improvement in perceptual quality. DP-NeRF produces enhanced 3D scene representation with greater perceptual quality and clean photo-realistic rendered images. 2.