Abstract
Current 3D scene stylization methods transfer textures and colors as styles using arbitrary style references, lack-ing meaningful semantic correspondences. We introduce
Reference-Based Non-Photorealistic Radiance Fields (Ref-NPR) to address this limitation. This controllable method stylizes a 3D scene using radiance fields with a single styl-ized 2D view as a reference. We propose a ray registra-tion process based on the stylized reference view to ob-tain pseudo-ray supervision in novel views. Then we ex-ploit semantic correspondences in content images to fill oc-cluded regions with perceptually similar styles, resulting in non-photorealistic and continuous novel view sequences.
Our experimental results demonstrate that Ref-NPR out-performs existing scene and video stylization methods re-garding visual quality and semantic correspondence. The code and data are publicly available on the project page at https://ref-npr.github.io. 1.

Introduction
In the past decade, there has been a rising demand for stylizing and editing 3D scenes and objects in various fields, including augmented reality, game scene design, and digital artwork. Traditionally, professionals achieve these tasks by creating 2D reference images and converting them into styl-ized 3D textures. However, establishing direct cross-modal correspondence is challenging and often requires significant time and effort to obtain stylized texture results similar to the 2D reference schematics.
A critical challenge in the 3D stylization problem is to ensure that stylized results are perceptually similar to the given style reference. Benefiting from radiance fields [2, 10, 28, 29, 37, 46], recent novel-view stylization meth-ods [5,8,15,16,30,45] greatly facilitated style transfer from an arbitrary 2D style reference to 3D implicit representa-tions. However, these methods do not provide explicit con-trol over the generated results, making it challenging to specify the regions where certain styles should be applied and ensure the visual quality of the results. On the other hand, reference-based video stylization methods allow for the controllable generation of stylized novel views with bet-ter semantic correspondence between content and style ref-erence, as demonstrated in works like [17, 38]. However, these methods may diverge from the desired style when styl-izing a frame sequence with unseen content, even with the assistance of stylized keyframes.
To address the aforementioned limitations, we propose
a new paradigm for stylizing 3D scenes using a single stylized reference view. Our approach, called Reference-Based Non-Photorealistic Radiance Fields (Ref-NPR), is a controllable scene stylization method that takes advantage of volume rendering to maintain cross-view consistency and establish semantic correspondence in transferring style across the entire scene.
Ref-NPR utilizes stylized views from radiance fields as references instead of arbitrary style images to achieve both flexible controllability and multi-view consistency.
A reference-based ray registration process is designed to project the 2D style reference into 3D space by utilizing the depth rendering of the radiance field. This process provides pseudo-ray supervision to maintain geometric and percep-tual consistency between stylized novel views and the styl-ized reference view. To obtain semantic style correspon-dence in occluded regions, Ref-NPR performs template-based feature matching, which uses high-level semantic fea-tures as implicit style supervision. The correspondence in the content domain is utilized to select style features in the given style reference, which are then used to transfer style globally, especially in occluded regions. By doing so, Ref-NPR generates the entire stylized 3D scene from a single stylized reference view.
Ref-NPR produces visually appealing stylized views that maintain both geometric and semantic consistency with the given style reference, as presented in Fig. 1. The generated stylized views are perceptually consistent with the refer-ence while also exhibiting high visual quality across various datasets. We have demonstrated that Ref-NPR, when using the same stylized view as reference, outperforms state-of-the-art scene stylization methods [30, 45] both qualitatively and quantitatively.
In summary, our paper makes three contributions.
Firstly, we introduce a new paradigm for stylizing 3D scenes that allows for greater controllability through the use of a stylized reference view. Secondly, we propose a novel approach called Ref-NPR, consisting of a reference-based ray registration process and a template-based feature matching scheme to achieve geometrically and percep-tually consistent stylizations.
Finally, our experiments demonstrate that Ref-NPR outperforms state-of-the-art scene stylization methods such as ARF and SNeRF both qualitatively and quantitatively. More comprehensive results and a demo video can be found in the supplementary material and on our project page. 2.