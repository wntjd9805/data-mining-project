Abstract
Cell detection is a fundamental task in computational pathology that can be used for extracting high-level medical information from whole-slide images. For accurate cell de-tection, pathologists often zoom out to understand the tissue-level structures and zoom in to classify cells based on their morphology and the surrounding context. However, there is a lack of eﬀorts to reﬂect such behaviors by pathologists in the cell detection models, mainly due to the lack of datasets containing both cell and tissue annotations with overlap-ping regions. To overcome this limitation, we propose and publicly release OCELOT, a dataset purposely dedicated to the study of cell-tissue relationships for cell detection in histopathology. OCELOT provides overlapping cell and tis-sue annotations on images acquired from multiple organs.
Within this setting, we also propose multi-task learning ap-proaches that beneﬁt from learning both cell and tissue tasks simultaneously. When compared against a model trained only for the cell detection task, our proposed approaches improve cell detection performance on 3 datasets: proposed
OCELOT, public TIGER, and internal CARP datasets. On the OCELOT test set in particular, we show up to 6.79 improvement in F1-score. We believe the contributions of this paper, including the release of the OCELOT dataset at https://lunit- io.github.io/research/ publications/ocelot are a crucial starting point to-ward the important research direction of incorporating cell-tissue relationships in computation pathology. 1.

Introduction
Computational Pathology (CPATH) [3] is a branch of digital pathology that develops methodologies for the anal-ysis of digitized patient specimens, such as Whole-Slide-Images (WSIs). Cell detection in histology images [26, 37, 49] is one of the most important tasks in CPATH. It allows the quantiﬁcation and analysis of diﬀerent cell types, which can lead to better prognosis evaluation [34, 40] and patient
∗: Equal contribution treatment planning while maintaining medical interpretabil-ity [13]. Since it has the potential to impact human lives, high-performance cell detection models are essential in real-world applications and need to be investigated.
To better locate and classify cells, detailed morphological characteristics such as color and shape are crucial. Conse-quently, cell detection datasets are typically collected at high magniﬁcation but small Field-of-View (FoV). However, this can make the cell detection model overly rely on appear-ance details, without understanding the broader context [42].
This context can help cell detection by providing informa-tion about how cells are arranged and grouped together to form high-level tissue structures. In practice, expert annota-tors (pathologists) ﬁrst zoom out to understand these broad tissue structures. Next, they zoom in to better classify indi-vidual cells while taking into account the context informa-tion, as depicted in Fig. 1.
The behavior of pathologists can be transferred to deep learning, for instance, through a multi-task strategy com-bining cell detection tasks at high magniﬁcation and tissue segmentation at low magniﬁcation. This type of approach would allow the model to share knowledge across diﬀer-ent tasks and FoVs. However, to train such an approach, a combined dataset with cell-tissue overlapping regions is required; unfortunately, most existing datasets only target a single task, either cell detection [17, 25] or tissue segmenta-tion [7, 11].
In this paper, we introduce a new research direction: studying cell-tissue relationships for cell detection. First, we publish the OCELOT dataset, which contains cell and tis-sue annotations in small and large FoV patches, respectively, with overlapping regions. Additionally, the data is collected from WSIs of multiple organs. This can provide the nec-essary data for researchers to study cell-tissue relationships and their eﬀect on cell detection. Second, we introduce sim-ple multi-task learning approaches for cell detection that can beneﬁt from cell-tissue relationships and demonstrate their advantages over 3 diﬀerent datasets. These approaches con-sistently show better cell detection performance compared to
Understand tissue contexts in a large FoV
Identify cells with tissue context
Pathologist:
Zoom-in
Identify cells without tissue context
Tumor cell