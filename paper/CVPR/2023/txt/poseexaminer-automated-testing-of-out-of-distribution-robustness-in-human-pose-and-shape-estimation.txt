Abstract
Human pose and shape (HPS) estimation methods achieve remarkable results. However, current HPS bench-marks are mostly designed to test models in scenarios that are similar to the training data. This can lead to criti-cal situations in real-world applications when the observed data differs significantly from the training data and hence is out-of-distribution (OOD). It is therefore important to test and improve the OOD robustness of HPS methods. To address this fundamental problem, we develop a simula-tor that can be controlled in a fine-grained manner us-ing interpretable parameters to explore the manifold of im-ages of human pose, e.g. by varying poses, shapes, and clothes. We introduce a learning-based testing method, termed PoseExaminer, that automatically diagnoses HPS algorithms by searching over the parameter space of hu-man pose images to find the failure modes. Our strat-egy for exploring this high-dimensional parameter space is a multi-agent reinforcement learning system, in which the agents collaborate to explore different parts of the pa-rameter space. We show that our PoseExaminer discov-ers a variety of limitations in current state-of-the-art mod-els that are relevant in real-world scenarios but are missed by current benchmarks. For example, it finds large regions of realistic human poses that are not predicted correctly, as well as reduced performance for humans with skinny and corpulent body shapes.
In addition, we show that fine-tuning HPS methods by exploiting the failure modes found by PoseExaminer improve their robustness and even their performance on standard benchmarks by a significant margin. The code are available for research purposes at https://github.com/qihao067/PoseExaminer. 1.

Introduction
In recent years, the computer vision community has made significant advances in 3D human pose and shape (HPS) estimation. But despite the high performance on standard benchmarks, current methods fail to give reliable predictions for configurations that have not been trained on
Figure 1. PoseExaminer is an automatic testing tool used to study the performance and robustness of HPS methods in terms of ar-ticulated pose, shape, global rotation, occlusion, etc. It system-atically explores the parameter space and discovers a variety of failure modes. (a) illustrates three failure modes in PARE [18] and (b) shows the efficacy of training with PoseExaminer. or in difficult viewing conditions such as when humans are significantly occluded [18] or have unusual poses or cloth-ing [34]. This lack of robustness in such out-of-distribution (OOD) situations, which typically would not fool a human observer, is generally acknowledged and is a fundamental open problem for HPS methods that should be addressed.
The main obstacle, however, to testing the robustness of
HPS methods is that test data is limited, because it is ex-pensive to collect and annotate. One way to address this problem is to diagnose HPS systems by generating large synthetic datasets that randomly generate images of humans in varying poses, clothing, and background [4, 34]. These studies suggest that the gap between synthetic and real do-mains in HPS is sufficiently small for testing on synthetic to be a reasonable strategy, as we confirm in our experiments.
These methods, however, only measure the average per-formance on the space of images.
In sensitive domains that use HPS (e.g. autonomous driving), the failure modes, where performance is low, can matter more. Most impor-tantly, despite large scale, these datasets lack diversity in some dimensions. For example, they mostly study pose for common actions such as standing, sitting, walking, etc.
Inspired by the literature on adversarial machine learn-ing [5, 11], recent approaches aim to systematically ex-plore the parameter space of simulators for weaknesses in the model performance. This has proven to be an effec-tive approach for diagnosing limitations in image classifi-cation [45], face recognition [43], and path planning [39].
However, they are not directly applicable to testing the ro-bustness of the high-dimensional regression task of pose es-timation. For example, [43, 45] were designed for simple binary classification tasks and can only optimize a limited number of parameters, and [39] only perturbs an initial real-world scene to generate adversarial examples, which does not enable the full exploration of the parameter space.
In this work, we introduce PoseExaminer (Fig. 1), a learning-based algorithm to automatically diagnose the ro-bustness of HPS methods.
It efficiently searches through the high-dimensional continuous space of a simulator of human images to find failure modes. The strategy in Pose-Examiner is a multi-agent reinforcement learning approach, in which the agents collaborate with one another to search the latent parameter space for model weaknesses. More specifically, each agent starts at different random initialized seeds and explores the latent parameter space to find failure cases, while at the same time avoiding exploring the regions close to the other agents in the latent space. This strategy enables a highly parallelizable way of exploring the high-dimensional continuous latent space of the simulator. After converging to a local optimum, each agent explores the lo-cal parameter space to find a connected failure region that defines a whole subspace of images where the pose is in-correctly predicted (i.e. failure mode). We demonstrate that very large subspaces of failures exist even in the best HPS models. We use the size of these failure subspaces together with the success rate of the agents as a new measure of out-of-distribution robustness.
Our experiments on four state-of-the-art HPS models show that PoseExaminer successfully discovers a variety of failure modes that provide new insights about their real-world performance. For example, it finds large subspaces of realistic human poses that are not predicted correctly, and reduced performance for humans with skinny and corpulent body shapes. Notably, we find that the failure modes found in synthetic data generalize well to real images: In addi-tion to using PoseExaminer as a new benchmark, we also find that fine-tuning SOTA methods using the failure modes discovered by PoseExaminer enhances their robustness and even the performance on 3DPW [52] and AIST++ [25, 50] benchmarks. We also note that computer graphics rendering pipelines become increasingly realistic, which will directly benefit the quality of our automated testing approach.
In short, our contributions are three-fold:
• We propose PoseExaminer, a learning-based algorithm to automatically diagnose the robustness of human pose and shape estimation methods. Compared to prior work, PoseExaminer is the first to efficiently search for a variety of failure modes in the high-dimensional con-tinuous parameter space of a simulator using a multi-agent reinforcement learning framework.
• We introduce new metrics, which have not been pos-sible to measure before, for quantifying the robust-ness of HPS methods based on our automated testing framework. We perform an in-depth analysis of cur-rent SOTA methods, revealing a variety of diverse fail-ure modes that generalize well to real images.
• We show that the failure modes discovered by PoseEx-aminer can be used to significantly improve the real-world performance and robustness of current methods. 2.