Abstract 1.

Introduction 3D object detection is an essential perception task in autonomous driving to understand the environments. The
Bird’s-Eye-View (BEV) representations have significantly improved the performance of 3D detectors with camera in-puts on popular benchmarks. However, there still lacks a systematic understanding of the robustness of these vision-dependent BEV models, which is closely related to the safety of autonomous driving systems. In this paper, we evaluate the natural and adversarial robustness of various represen-tative models under extensive settings, to fully understand their behaviors influenced by explicit BEV features com-pared with those without BEV. In addition to the classic settings, we propose a 3D consistent patch attack by ap-plying adversarial patches in the 3D space to guarantee the spatiotemporal consistency, which is more realistic for the scenario of autonomous driving. With substantial experi-ments, we draw several findings: 1) BEV models tend to be more stable than previous methods under different natural conditions and common corruptions due to the expressive spatial representations; 2) BEV models are more vulnera-ble to adversarial noises, mainly caused by the redundant
BEV features; 3) Camera-LiDAR fusion models have supe-rior performance under different settings with multi-modal inputs, but BEV fusion model is still vulnerable to adver-sarial noises of both point cloud and image. These findings alert the safety issue in the applications of BEV detectors and could facilitate the development of more robust models.
Autonomous driving systems have great demand for reli-able 3D object detection models [21], which aim to predict 3D bounding boxes and categories of road objects, in order to understand the surroundings. To extract holistic repre-sentations in the 3D space, the Bird’s-Eye-View (BEV) is commonly adopted as a unified representation [30], since it contains both locations and semantic features of objects without being affected by occlusion, and shows promise for various 3D perception tasks in autonomous driving, such as map restoration [41, 44]. Although being broadly used for LiDAR point clouds [28, 65], the BEV representation has recently achieved great success for 3D object detec-tion with multiple cameras, arousing tremendous attention from both industry and academia due to low cost of cam-era sensors and better exploitation of semantic information in images. These vision-dependent BEV models1 typically project 2D image features to explicit BEV feature maps in the 3D space and make predictions based on BEV features
[25,26,31,32,35]. As representative models, BEVDet [26],
BEVDepth [31] and BEVFusion [35] distribute the 2D fea-tures into 3D space according to the estimated depth map, while BEVFormer [32] adopts cross attention to query BEV features from 2D images. With expressive spatial semantics of BEV, these models achieve the state-of-the-art results on popular benchmarks (e.g., nuScenes [8]).
Despite the excellent performance, these models are still far from practical deployment due to the robustness issues.
Previous works have shown that deep learning models are
* Equal Contribution. (cid:66) Corresponding authors. This work was done 1In this paper, we use the term vision-dependent BEV models to indi-when Zijian Zhu and Hai Chen were visiting Tsinghua University. cate both camera-only and LiDAR-camera fusion BEV models.
(a) Settings for Robustness Evaluation (b) Pipeline of 3D Consistent Patch Attack
Figure 1. Overview. (a) We measure the natural and adversarial robustness of vision-dependent BEV models in 3D object detection under various settings to thoroughly understand the influence of explicit BEV representations on robustness. (b) By pasting an adversarial patch on a car in the 3D space and projecting it to the 2D images, the generated patch is aligned spatially (across adjacent cameras) and temporally (across continuous frames). The patch cloaks the car in all 3 frames from BEVDepth [31], bringing high safety risks to autonomous driving. vulnerable to adversarial examples [20, 51], common cor-ruptions [22], natural transformations [14, 15], etc. The robustness issues rooted in the data-driven deep learning based 3D object detectors can raise severe concerns about the safety and reliability of autonomous driving, making it imperative to evaluate and understand model robustness before being deployed. As vision-dependent BEV mod-els achieve superior performance and become increasingly prevalent in the field, it is of particular importance to com-pare their robustness to other models that do not rely on
BEV representations, given the inherent trade-off between accuracy and robustness [47, 61].
In this paper, we take the first step to systematically ana-lyze and understand the robustness of representative vision-dependent BEV models, by performing thorough experi-mental evaluations ranging from natural robustness to ad-versarial robustness as illustrated in Fig. 1(a). We draw sev-eral important findings as below:
• We first evaluate the natural robustness under common corruptions, various weather and lighting conditions, and partially missing cameras. We find that camera-based BEV models are generally more robust to natu-ral corruptions of images as a result of the rich spatial information carried by BEV representations.
• We then evaluate the adversarial robustness under the global ℓp adversarial perturbations, instance-level and category-level adversarial patches. We observe that
BEV models are more vulnerable to adversarial noises, owing to the redundant spatial features represented by
BEV based on an in-depth analysis.
• Based on the results, we find that camera-LiDAR fu-sion models have superior performance under all set-tings due to the aid of multi-modal inputs. Besides,
BEVFusion [35] is less robust when both point cloud and image perturbations are imposed.
In addition to digital adversarial patches, we propose a novel attack method called 3D consistent patch attack. As shown in Fig. 1(b), adversarial patches are attached to ob-jects for sptiotemporal consistency in the 3D space. We pro-vide two case studies of 3D consistent patch attack. First, we paste patches on objects falling into the overlap regions of multiple cameras, which are observed in different shapes from different viewpoints. Second, we generate temporally universal patches for objects across a continuous sequence of frames in a certain scene, which is a step further from case one. Both spatial alignment and temporal consistency are considered, which distinguishes 3D object detection for autonomous driving cars from the traditional 2D object de-tection task. The conclusions are consistent with those of adversarial robustness above and can inspire more works to guarantee safe autonomous driving. 2.