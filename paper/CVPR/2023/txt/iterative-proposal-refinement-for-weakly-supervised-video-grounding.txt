Abstract
Weakly-Supervised Video Grounding (WSVG) aims to localize events of interest in untrimmed videos with only video-level annotations. To date, most of the state-of-the-art
WSVG methods follow a two-stage pipeline, i.e., firstly gen-erating potential temporal proposals and then grounding with these proposal candidates. Despite the recent progress, existing proposal generation methods suffer from two draw-backs: 1) lack of explicit correspondence modeling; and 2) partial coverage of complex events. To this end, we propose a novel IteRative prOposal refiNement network (dubbed as
IRON) to gradually distill the prior knowledge into each proposal and encourage proposals with more complete cov-erage. Specifically, we set up two lightweight distillation branches to uncover the cross-modal correspondence on both the semantic and conceptual levels. Then, an itera-tive Label Propagation (LP) strategy is devised to prevent the network from focusing excessively on the most discrim-inative events instead of the whole sentence content. Pre-cisely, during each iteration, the proposal with the minimal distillation loss and its adjacent ones are regarded as the positive samples, which refines proposal confidence scores in a cascaded manner. Extensive experiments and ablation studies on two challenging WSVG datasets have attested to the effectiveness of our IRON. The code will be available at https://github.com/mengcaopku/IRON. 1.

Introduction
Weakly-Supervised Video Grounding (WSVG) [21, 37, 41, 72, 73] aims to localize the moment of interest from an untrimmed video according to a query sentence with-out frame-wise annotations. It has drawn increasing atten-tion in both industry and academia due to its wide applica-tions, e.g., video retrieval [13, 19], video question answer-* Work done during the internship at Microsoft.
†Corresponding author: Daxin Jiang (djiang@microsoft.com). (a) (b) (a) The conventional WSVG pipeline (i.e., baseline)
Figure 1. lacks explicit correspondence modeling. (b) Partial coverage of complex events. Proposal #1 with the high confidence score (i.e., 0.87) tends to be of short duration. The more reasonable proposal
#2 has the lower confidence score. ing [1], human-computer interaction [49], etc. Currently, the overwhelming majority of state-of-the-art WSVG meth-ods follow a two-stage pipeline, i.e., they firstly generate potential proposals and then use these proposals to conduct grounding via multi-instance learning (MIL) [21, 27, 40, 41] or query reconstruction [37, 40, 50, 72]. This paradigm commonly relies on densely-placed proposals to achieve high recall and ensure as much coverage as possible, which causes severe computation redundancy. Recent works [72, 73] reduce the number of required proposals by predict-ing Gaussian masks to highlight query-relevant segments.
However, a such constraint is too rigorous and lacks flexi-bility. Thus, in this paper, we work toward designing sparse and reliable proposals without any distribution assumptions.
Despite of the dominated performance achieved, it is worth noting that current proposal generation methods suf-fer from two inherent drawbacks: 1) Lack of explicit cor-respondence modeling: A simple pipeline1 for the conven-tional proposal-based WSVG methods is illustrated in Fig-1We call this pipeline as baseline and refer to the appendix for details.
ure 1a. As shown, under the weakly-supervised scenario, there exist no explicit regression supervisions (e.g., tempo-ral boundary annotations) for the proposal generation proce-dure. Accordingly, the proposal coordinate update is solely based on the outputs of the grounding module. This leads to a chicken and egg situation, i.e., the succeeding grounding module requires plausibly reliable proposals to achieve ac-curate localization results while the proposal distributions rely on decent grounding results to update. 2) Partial cov-erage of complex events. Compared to the atomic action instances in Temporal Action Localization (TAL) [8,47,71], the query sentences in WSVG are much more complex, e.g., containing multiple events. Empirically, it is easy to ex-cessively concentrate on the most discriminative parts in-stead of the whole picture [37]. For example, the case in
Figure 1b aims to ground the complete process of the kite, i.e., weaving, turning, and twisting. However, the top-ranking proposal #1 only covers the weaving process and overlooks the other parts.
In contrast, a more accu-rate proposal #2 has much lower confidence scores. In Fig-ure 2a, we compute the length distribution of the proposals with highest confidence score (Charades-STA [48] test set), which are always obviously shorter than their ground truths.
To alleviate these aforementioned problems, we propose a novel IteRative prOposal refiNement network for WSVG (dubbed as IRON), which distills the prior knowledge into the proposal generation in a cascaded manner.
For correspondence modeling, we contend that it should be conducted from two aspects: 1) Semantic-level: The overall semantics of the proposals should match the query sentence. Specifically, we respectively feed the proposal frames and the query sentence into the visual and language encoders of the pre-trained video-language (VL) model [56] to estimate their semantic similarity. Due to the powerful transfer ability of pre-trained VL models [28, 39, 44, 56], we use the estimated similarity as the semantic distillation target. Then a lightweight semantic distillation branch is leveraged to optimize towards this target, referred to as the semantic distillation loss. 2) Conceptual-level: The pro-posal ought to be sensitive to the linguistic salient concepts including object words (e.g., kite), attribute words (e.g., white) and relationship words (e.g., through). This is similar to the human way of reasoning, i.e., tending to fo-cus on the most prominent objects when assessing given videos. Here we define the concepts as the high-frequency words (i.e., verbs, adjectives, and nouns) in the dataset cor-pus. Then, one multi-hot label is generated for each query sentence according to whether it hits the corresponding con-cept. We introduce a concept classification branch to esti-mate proposal-wise concept predictions supervised by the multi-hot label, yielding the conceptual distillation loss.
To mitigate the partial coverage issue, we devise a Label
Propagation (LP) algorithm, which aims to refine proposal-(a) (b)
Figure 2. (a) The gaussian distributions of normalized average length of the ground truth and the proposals with highest confi-dence scores in baseline1. Results are calculated based on the test set of Charades-STA [48]. (b) The normalized average length of proposals with highest confidence scores v.s. iteration numbers. wise confidence scores in an iterative manner. Our motiva-tion lies in that proposals with the minimal distillation loss (both semantic and conceptual distillation loss) can be re-garded as the biased indicator, i.e., these proposals always contain some salient events-of-interest and have short dura-tions (cf . Sec. 4.5). Therefore, during each iteration in LP, we assign the positive pseudo label to the proposal with the minimal distillation loss and its adjacent ones2. Based on the generated pseudo label, the proposal confidence scores are rectified via a binary cross-entropy loss in the conse-quent stage. After the multi-step refinements, our IRON gradually converges to more complete intervals instead of parts (cf . Figure 2b).
In summary, we make three contributions in this paper:
• We propose to model explicit correspondence for each proposal at both semantic and conceptual levels, which distills in-depth knowledge from the well-trained VL model and the linguistic structure of the query sentence.
• To avoid biased and partial grounding results, a label propagation algorithm is crafted to refine proposal-wise confidence scores iteratively.
• Extensive experiments on both Charades-STA and Ac-tivityNet Captions datasets have witnessed the state-of-the-art performance of our proposed IRON. 2.