Abstract
Albeit achieving high predictive accuracy across many challenging computer vision problems, recent studies sug-gest that deep neural networks (DNNs) tend to make over-confident predictions, rendering them poorly calibrated.
Most of the existing attempts for improving DNN calibra-tion are limited to classification tasks and restricted to cal-Surprisingly, very little ibrating in-domain predictions. to no attempts have been made in studying the calibra-tion of object detection methods, which occupy a pivotal space in vision-based security-sensitive, and safety-critical
In this paper, we propose a new train-time applications. technique for calibrating modern object detection meth-ods.
It is capable of jointly calibrating multiclass confi-dence and box localization by leveraging their predictive uncertainties. We perform extensive experiments on several in-domain and out-of-domain detection benchmarks. Re-sults demonstrate that our proposed train-time calibration method consistently outperforms several baselines in reduc-ing calibration error for both in-domain and out-of-domain predictions. Our code and models are available at https:
//github.com/bimsarapathiraja/MCCL 1.

Introduction
Deep neural networks (DNNs) are the backbone of many top-performing systems due to their high predictive perfor-mance across several challenging domains, including com-puter vision [16,17,41,45,52] and natural language process-ing [5,7]. However, some recent works [14,15,38,47] report that DNNs are susceptible to making overconfident predic-tions, which leaves them miscalibrated. This not only spurs a mistrust in their predictions, but more importantly, could lead to disastrous consequences in several safety-critical ap-plications, such as healthcare diagnosis [8, 43], self-driving cars [13], and legal research tools [50]. For instance, in self-driving cars, if the perception component wrongly detects a stop sign as a speed limit sign with high confidence, it can potentially lead to disastrous outcomes.
Several strategies have been proposed in the recent past for improving model calibration. A simple calibration tech-nique is a post-processing step that re-scales the outputs of a trained model using parameters which are learnt on a hold-out portion of the training set [14]. Despite being easy to implement, these post-processing approaches are restrictive. They assume the availability of a hold-out set, which is not always possible in many real-world settings.
Another route to reducing calibration error is train-time cal-ibration techniques, which intervene at the training time by involving all model parameters. Typically train-time cali-bration methods feature an auxiliary loss term that is added to the application-specific loss function to regularize predic-tions [18, 27, 33, 35].
We note that almost all prior efforts towards improving model calibration target the task of visual image classifica-tion. Surprisingly, little to no noticeable attempts have been made in studying the calibration of visual object detection models. Visual object detection methods account for a ma-jor and critical part of many vision-based decision-making systems. Moreover, most of the current calibration tech-niques only aim at reducing calibration error for in-domain predictions. However, in many realistic settings, it is likely that, after model deployment, the incoming data distribution could continuously change from the training data distribu-tion. In essence, the model should be well-calibrated for both in-domain and out-of-domain predictions.
To this end, in this paper, we aim to study the cali-bration of (modern) deep learning-based object detection methods. In this pursuit, we observe that, (a) object detec-tion methods are intrinsically miscalibrated, (b) besides dis-playing noticeable calibration errors for in-domain predic-tions, they are also poorly calibrated for out-of-domain pre-dictions and, (c) finally, the current calibration techniques for classification are sub-optimal for object detection (Fig-ure 1). Towards improving the calibration performance of object detection methods, inspired by the train-time cali-bration route, we propose a new train-time calibration ap-proach aims at jointly calibrating the predictive multiclass confidence and bounding box localization.
(a) (b) (c)
Figure 1. DNN-based object detectors are inherently miscalibrated for both in-domain and out-of-domain predictions. Also, calibration methods for image classification are sub-optimal for object detection. Our proposed train-time calibration method for object detection is capable of reducing the calibration error (D-ECE%) of DNN-based detectors in both in-domain and out-domain scenarios.
Contributions: (1) We study the relatively unexplored di-rection of calibrating modern object detectors and observe that they are intrinsically miscalibrated in both in-domain and out-of-domain predictions. Also, the existing calibra-tion techniques for classification are sub-optimal for cali-brating object detectors. (2) We propose a new train-time calibration method for detection, at the core of which is an auxiliary loss term, which attempts to jointly calibrate multiclass confidences and bounding box localization. We leverage predictive uncertainty in multiclass confidences and bounding box localization. (3) Our auxiliary loss term is differentiable, operates on minibatches, and can be uti-lized with other task-specific loss functions. (4) We perform extensive experiments on challenging datasets, featuring several in-domain and out-of-domain scenarios. Our train-time calibration method consistently reduces the calibra-tion error across DNN-based object detection paradigms, including FCOS [45] and Deformable DETR [52], both in in-domain and out-of-domain predictions. 2.