Abstract
Recent deep learning methods have achieved promising results in image shadow removal. However, their restored images still suffer from unsatisfactory boundary artifacts, due to the lack of degradation prior embedding and the de-ficiency in modeling capacity. Our work addresses these issues by proposing a unified diffusion framework that in-tegrates both the image and degradation priors for highly effective shadow removal.
In detail, we first propose a shadow degradation model, which inspires us to build a novel unrolling diffusion model, dubbed ShandowDiffusion.
It remarkably improves the model’s capacity in shadow re-moval via progressively refining the desired output with both degradation prior and diffusive generative prior, which by nature can serve as a new strong baseline for image restoration. Furthermore, ShadowDiffusion progressively refines the estimated shadow mask as an auxiliary task of the diffusion generator, which leads to more accurate and robust shadow-free image generation. We conduct exten-sive experiments on three popular public datasets, including
ISTD, ISTD+, and SRD, to validate our method’s effective-ness. Compared to the state-of-the-art methods, our model achieves a significant improvement in terms of PSNR, in-creasing from 31.69dB to 34.73dB over SRD dataset.1 1.

Introduction
Shadow removal aims to enhance visibility of the im-age shadow regions, pursuing a consistent illumination dis-tribution between shadow and non-shadow regions. Deep learning-based methods [4, 7, 10, 20, 54] achieved superior performance recently by fully utilizing the power of large collections of data. While most of the existing methods fo-*Corresponding author: Bihan Wen.
This work was carried out at ROSE Lab, supported in part by the MOE
AcRF Tier 1 (RG61/22) and Start-Up Grant.
Figure 1. (a) Input shadow image and corresponding ground truth shadow-free image, (b) shadow removal results of two most recent competing methods Fu et al. [7] and BMNet [54], and (c) our pro-posed ShadowDiffusion iteratively (T → 0) restores the shadow-free image and refines the shadow mask, in which the x0 and m0 are the final enhanced result and refined mask, respectively. cused on learning the discriminative models for shadow re-moval, modeling the underlying distribution of nature im-ages is overlooked in their restoration process. Conse-quently, the shadow removal results usually contain severe boundary artifacts and remaining shadow patterns, as shown in Figure 1(b).
Though the adversarial loss can alleviate this issue, these approaches [19, 38] require careful adjustment during train-ing, might overfit certain visual features or data distribution, and might hallucinate new content and artifacts. Very re-cently, various diffusion models, such as the popular diffu-sion denoising diffusion probability model (DDPM) [17], have gained wide interest in the field of low-level vi-sion [33, 34]. Comparing to other deep generative mod-1https://github.com/GuoLanqing/ShadowDiffusion 1
els, diffusion models are more powerful for modeling image pixel distribution, which provides great potential for signif-icantly improving visual quality and benefits high-quality image restoration. However, no work to-date has exploited diffusion models for shadow removal tasks.
Moreover, there are two major limitations in existing shadow removal methods: First, the shadow degradation prior that reflects its corresponding physical properties has not been well exploited in deep learning. Though recent work [25] attempted to incorporate simple shadow model as a linear and uniform degradation, such an assumption is too restrictive for restoring real shadow images subjec-tive to complicated lighting conditions. Second, most of the deep shadow removal methods requires an estimated shadow mask as the inputs, which are either provided by the benchmark datasets [38] or generated by a pre-trained shadow detector [5]. However, these mask estimates are usually inaccurate, e.g., wrong indicators near the boundary or small shadow objects. Even the carefully hand-crafted masks sometimes contain coarse boundaries. Since existing methods blindly rely on the estimated masks without ex-ploiting their correlation to the actual shadow images for re-finement, there are usually severe boundary artifacts in their shadow removal results [7, 54], as shown in Figure 1(b).
To alleviate the challenges in shadow removal, we first introduce a general shadow model of spatially-variant degradation, by decomposing the degradation matrix into the shadow mask and shadow intensities. Based on the new shadow model, we propose a novel unrolling diffusion-based shadow removal framework, called ShadowDiffu-sion, which integrates both the generative and degradation priors. Specifically, we formulate the shadow removal prob-lem as to jointly pursue the shadow-free image and refined shadow mask. Mask refinement is designed as an auxiliary task of the diffusion generator to progressively refine the shadow mask along with shadow-free image restoration in an interactive manner as shown in Figure 1(c). After that, we further propose an unrolling-inspired diffusive sampling strategy to explicitly integrate the degradation prior into the diffusion framework. Experimental results show that Shad-owDiffusion can achieve superior performance consistently over the three widely-used shadow removal datasets and significantly outperform the state-of-the-art methods. Be-sides, our model can be applied to other image enhancement tasks, e.g., low-light image enhancement and exposure cor-rection. Our main contributions are summarized as follows:
• We propose the first diffusion-based model for shadow removal. A novel dynamic mask-aware diffusion model (DMDM) is introduced to jointly pursue a shadow-free image and refined shadow mask, which leads to robust shadow removal even with an inaccu-rate mask estimate.
• We further propose an unrolling-inspired diffusive sampling strategy to explicitly integrate the shadow degradation prior into the intrinsic iterative process of
DMDM. and SRD datasets
• Extensive experimental results on the public ISTD,
ISTD+, the pro-posed ShadowDiffusion outperforms the state-of-the-art shadow removal methods by large margins. Be-sides, our method can be generalized to a series of im-age enhancement tasks. show that 2.