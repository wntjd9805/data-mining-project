Abstract
Recently, point cloud semantic segmentation has attracted much attention in computer vision. Most of the existing works in literature assume that the training and testing point clouds have the same object classes, but they are gen-erally invalid in many real-world scenarios for identifying the 3D objects whose classes are not seen in the training set. To address this problem, we propose an Adversarial
Prototype Framework (APF) for handling the open-set 3D semantic segmentation task, which aims to identify 3D unseen-class points while maintaining the segmentation performance on seen-class points.
The proposed APF consists of a feature extraction module for extracting point features, a prototypical constraint module, and a feature adversarial module. The prototypical constraint module is designed to learn prototypes for each seen class from point features. The feature adversarial module utilizes generative adversarial networks to estimate the distribution of unseen-class features implicitly, and the synthetic unseen-class features are utilized to prompt the model to learn more effective point features and prototypes for discriminating unseen-class samples from the seen-class ones. Experi-mental results on two public datasets demonstrate that the proposed APF outperforms the comparative methods by a large margin in most cases. 1.

Introduction
Point cloud semantic segmentation is an important and challenging topic in computer vision. Most of the existing works [9–11, 29] in literature are based on the assumption that both the training and testing point clouds have the same
*Corresponding author (a) AD (b) O3D
Figure 1. Visualization of the goals of anmaly detection (AD) and open-set 3D semantic segmentation (O3D) on SemanticKITTI [2].
AD is to identify the unseen-class data, while O3D is to simultane-ously identify the unseen-class data and segment seen-class data.
The unseen-class points are colorized in yellow. object classes, however, this assumption is no more valid in many real-world scenarios, due to the fact that the classes of some observed 3D points may not be presented in the training set. Hence, the following problem on open-set 3D semantic segmentation is naturally raised: How does a seg-mentation model simultaneously identify unseen-class 3D points and maintain the segmentation accuracy of seen-class 3D points in open-set scenarios?
Compared with anomaly detection [3, 23, 26], open-set 3D semantic segmentation (O3D) is more challenging, for it also needs to assign labels to seen-class data simultane-ously, as shown in Figure 1. In fact, some existing tech-niques [6,15,17,18] for open-set 2D semantic segmentation (O2D) task could be extended to handle the O3D task, how-ever, their open-set ability is generally limited in 3D scenar-ios. In addition, to our best knowledge, only one pioneering work [7] has investigated a special technique for O3D task.
In [7], an O3D method called REAL is proposed to utilize normal classifiers to segment seen-class points and regard the randomly resized objects as unseen-class objects which are detected by the redundancy classifiers. REAL outper-forms some extended O2D methods in the O3D task, how-ever, the AUPR (Area Under the Precision-Recall curve) is lower than 21% on two public datasets as shown in Ta-ble 1 and Table 2 in Section 4, mainly because the resizing process in REAL alters the geometric structure of the ini-tial point clouds to some extent. These results indicate that there still exists a huge space for improvement on O3D task.
Addressing the above issue, we propose an Adversarial
Prototype Framework (APF) for open-set 3D segmentation, which segments point clouds from a discriminative perspec-tive and estimates the distribution of unseen-class features from a generative perspective. The proposed APF consists of three modules: a feature extraction module, a prototyp-ical constraint module, and a feature adversarial module.
The feature extraction module is employed to extract latent features from the input point clouds, which could be an ar-bitrary closed-set point cloud segmentation network in prin-ciple. Given the point features, the prototypical constraint module is explored from the discriminative perspective to learn a prototype for each seen class. The feature adver-sarial module is explored from the generative perspective, which employs the generative adversarial networks (GAN) to synthesize point features to estimate the unseen-class feature distribution, based on the finding stated in [6] that the unseen-class features usually aggregate in the center of the feature space. And the synthesized unseen-class fea-tures in this module could further prompt the model to learn more discriminative point features and prototypes. After the whole APF is trained, a point-to-prototype hybrid distance-based criterion is introduced for open-set 3D segmentation.
In sum, the contributions of this paper are as follows:
• We propose the adversarial prototype framework (APF) for handling the open-set 3D semantic segmen-tation task. Under the proposed APF, various open-set 3D segmentation methods could be straightforwardly derived by utilizing existing closed-set 3D segmenta-tion networks as the feature extraction module. The effectiveness of the proposed APF has been demon-strated by the experimental results in Section 4.
• Under the proposed framework, we explore the pro-totypical constraint module, which learns the corre-sponding prototype for each seen class. The learned prototypes are not only conducive to segmenting seen-class points, but also to detecting unseen-class points.
• Under the proposed framework, we explore the fea-ture adversarial module to synthesize unseen-class fea-tures. The synthetic features are helpful for improving the discriminability of both the seen-class features and prototypes via the adversarial mechanism. 2.