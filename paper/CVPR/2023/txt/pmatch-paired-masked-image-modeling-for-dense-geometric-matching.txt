Abstract
Dense geometric matching determines the dense pixel-wise correspondence between a source and support image corresponding to the same 3D structure. Prior works em-ploy an encoder of transformer blocks to correlate the two-frame features. However, existing monocular pretraining tasks, e.g., image classification, and masked image model-ing (MIM), can not pretrain the cross-frame module, yield-ing less optimal performance. To resolve this, we reformu-late the MIM from reconstructing a single masked image to reconstructing a pair of masked images, enabling the pre-training of transformer module. Additionally, we incorpo-rate a decoder into pretraining for improved upsampling results. Further, to be robust to the textureless area, we pro-pose a novel cross-frame global matching module (CFGM).
Since the most textureless area is planar surfaces, we pro-pose a homography loss to further regularize its learning.
Combined together, we achieve the State-of-The-Art (SoTA) performance on geometric matching. Codes and models are available at https://github.com/ShngJZ/PMatch. 1.

Introduction
When a 3D structure is viewed in both a source and a support image, for a pixel (or keypoint) in the source image, the task of geometric matching identifies its corresponding pixel in the support image. This task is a cornerstone for many downstream vision applications, e.g. homography es-timation [18], structure-from-motion [45], visual odometry estimation [21] and visual camera localization [7].
There exist both sparse and dense methods for geomet-ric matching. The sparse methods [16, 19, 32, 33, 40, 42, 48, 48, 56] only yield correspondence on sparse or semi-dense locations while the dense methods [20, 54, 55] es-timate pixel-wise correspondence. They primarily differ in that the sparse methods embed a keypoint detection or a global matching on discrete coordinates, which underly-ingly assumes a unique mapping between source and sup-port frames. Yet, the existence of textureless surfaces in-Figure 1. Most vision tasks start with a pretrained network. In geo-metric matching, the unique network components processing two-view features cannot benefit from the monocular pretraining task, e.g., image classification, and masked image modeling (MIM). As in the figure, this work enables the pretraining of a matching model via reformulating MIM from reconstructing a single masked im-age to reconstructing a pair of masked images. troduces multiple similar local patches, disabling keypoint detection or causing ambiguous matching results. Dense methods, though facing similar challenges at the coarse level, alleviate it with the additional fine-level local context and smoothness constraint. Until recently, the dense meth-ods demonstrate a comparable or better geometric matching performance over the sparse methods [20, 54, 55].
A relevant task to dense geometric matching is the opti-cal flow estimation [50]. Both tasks estimate dense corre-spondences, whereas the optical flow is applied over con-secutive frames with the constant brightness assumption.
In geometric matching [9, 48], apart from the encoder encodes source and support frames into feature maps, there exist transformer blocks which correlate two-frame fea-tures, e.g., the LoFTR module [48]. Since these network components consume two-frame inputs, the monocular pre-training task, e.g., the image classification and masked im-age modeling (MIM) defined on ImageNet dataset, is un-able to benefit the network. This limits both the geometric matching performance and its generalization capability.
To address this, we reformulate the MIM from single masked image reconstruction to paired masked images re-construction, i.e., pMIM. Paired MIM benefits the geomet-ric matching as both tasks rely on the cross-frame module to correlate two frames inputs for prediction.
With a pretrained encoder, the decoder in dense geomet-ric matching is still randomly initialized. Following the idea of pretraining encoder, we extend pMIM pretraining to the decoder. As part functionality of decoder is to upsample the coarse-scale initial prediction to the same resolution as input, we also task the decoder in pMIM to upsample the coarse-scale reconstruction to its original resolution. Corre-spondingly, we consist the decoder as stacks of the depth-wise convolution except for the last prediction head. With the depth-wise decoder, when transferring from pMIM to geometric matching, we duplicate the decoder along the channel dimension to finish the initialization. To this end, there exists only a small number of components in the de-coder randomly initialized, we pretrain the rest network components using synthetic image pair augmentation [54].
To further improve the dense geometric matching perfor-mance, we propose a cross-frame global matching module (CFGM). In CFGM, we first compute the correlation vol-ume. We model the correspondences of coarse scale pixels as a summation over the discrete coordinates in the support frame, weighted by the softmaxed correlation vector. How-ever, this modeling fails when multiple similar local patches exit. As a solution, we impose positional embeddings to the discrete coordinates and decode with a deep architec-ture to avoid ambiguity. Meanwhile, we notice that the tex-tureless surfaces are mostly planar structures described by a low-dimensional 8 degree-of-freedom (DoF) homography matrix. We thus design a homography loss to augment the learning of the low DoF planar prior.
We summarize our contributions as follows:
• We introduce the paired masked image modeling pretext task, pretraining both the encoder and decoder of a dense geometric matching network.
• We propose a novel cross-frame global matching module that is robust to textureless local patches. Since the most textureless patches are planar structures, we augment their learning with a homography loss.
• We outperform dense and sparse geometric matching methods on diverse datasets. 2.