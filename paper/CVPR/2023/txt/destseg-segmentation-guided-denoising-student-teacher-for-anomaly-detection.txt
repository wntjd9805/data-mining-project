Abstract
Visual anomaly detection, an important problem in com-puter vision, is usually formulated as a one-class classifi-cation and segmentation task. The student-teacher (S-T) framework has proved to be effective in solving this chal-lenge. However, previous works based on S-T only empir-ically applied constraints on normal data and fused multi-level information. In this study, we propose an improved model called DeSTSeg, which integrates a pre-trained teacher network, a denoising student encoder-decoder, and to a segmentation network into one framework. First, strengthen the constraints on anomalous data, we intro-duce a denoising procedure that allows the student net-work to learn more robust representations. From synthet-ically corrupted normal images, we train the student net-work to match the teacher network feature of the same im-ages without corruption. Second, to fuse the multi-level S-T features adaptively, we train a segmentation network with rich supervision from synthetic anomaly masks, achieving a substantial performance improvement. Experiments on the industrial inspection benchmark dataset demonstrate that our method achieves state-of-the-art performance, 98.6% on image-level AUC, 75.8% on pixel-level average preci-sion, and 76.4% on instance-level average precision. 1.

Introduction
Visual anomaly detection (AD) with localization is an essential task in many computer vision applications such as industrial inspection [24, 36], medical disease screening
[27, 32], and video surveillance [18, 20]. The objective of these tasks is to identify both corrupted images and anoma-lous pixels in corrupted images. As anomalous samples oc-cur rarely, and the number of anomaly types is enormous, it is unlikely to acquire enough anomalous samples with all possible anomaly types for training. Therefore, AD tasks were usually formulated as a one-class classification and segmentation, using only normal data for model training.
The student-teacher (S-T) framework, known as knowl-edge distillation, has proven effective in AD [3, 9, 26, 31,
In this framework, a teacher network is pre-trained 33]. on a large-scale dataset, such as ImageNet
[10], and a student network is trained to mimic the feature represen-tations of the teacher network on an AD dataset with nor-mal samples only. The primary hypothesis is that the stu-dent network will generate different feature representations from the teacher network on anomalous samples that have never been encountered in training. Consequently, anoma-lous pixels and images can be recognized in the inference phase. Notably,
[26, 31] applied knowledge distillation at various levels of the feature pyramid so that discrepan-cies from multiple layers were aggregated and demonstrated good performance. However, there is no guarantee that the features of anomalous samples are always different between
S-T networks because there is no constraint from anoma-lous samples during the training. Even with anomalies, the student network may be over-generalized [22] and output similar feature representations as those by the teacher net-work. Furthermore, aggregating discrepancies from multi-level in an empirical way, such as sum or product, could be suboptimal. For instance, in the MVTec AD dataset under the same context of [31], we observe that for the category of transistor, employing the representation from the last layer, with 88.4% on pixel-level AUC, outperforms that from the multi-level features, with 81.9% on pixel-level AUC.
To address the problem mentioned above, we propose
DeSTSeg, illustrated in Fig. 1, which consists of a denois-ing student network, a teacher network, and a segmenta-tion network. We introduce random synthetic anomalies into the normal images and then use these corrupted im-ages1 for training. The denoising student network takes a corrupted image as input, whereas the teacher network takes the original clean image as input. During training, 1All samples shown in this paper are licensed under the CC BY-NC-SA 4.0.
Figure 1. Overview of DeSTSeg. Synthetic anomalous images are generated and used during training. In the first step (a), the student network with synthetic input is trained to generate similar feature representations as the teacher network from the clean image. In the second step (b), the element-wise product of the student and teacher networksâ€™ normalized outputs are concatenated and utilized to train the segmentation network. The segmentation output is the predicted anomaly score map. the feature discrepancy between the two networks is min-imized. In other words, the student network is trained to perform denoising in the feature space. Given anomalous images as input to both networks, the teacher network en-codes anomalies naturally into features, while the trained denoising student network filters anomalies out of feature space. Therefore, the two networks are reinforced to gen-erate distinct features from anomalous inputs. For the ar-chitecture of the denoising student network, we decided to use an encoder-decoder network for better feature denoising instead of adopting an identical architecture as the teacher network. In addition, instead of using empirical aggrega-tion, we append a segmentation network to fuse the multi-level feature discrepancies in a trainable manner, using the generated binary anomaly mask as the supervision signal.
We evaluate our method on a benchmark dataset for sur-face anomaly detection and localization, MVTec AD [2].
Extensive experimental results show that our method out-performs the state-of-the-art methods on image-level, pixel-level, and instance-level anomaly detection tasks. We also conduct ablation studies to validate the effectiveness of our proposed components.
Our main contributions are summarized as follows. (1)
We propose a denoising student encoder-decoder, which is trained to explicitly generate different feature representa-tions from the teacher with anomalous inputs. (2) We em-ploy a segmentation network to adaptively fuse the multi-level feature similarities to replace the empirical inference approach. (3) We conduct extensive experiments on the benchmark dataset to demonstrate the effectiveness of our method for various tasks. 2.