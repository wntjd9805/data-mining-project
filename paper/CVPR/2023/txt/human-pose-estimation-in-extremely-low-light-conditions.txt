Abstract
We study human pose estimation in extremely low-light images. This task is challenging due to the difficulty of collecting real low-light images with accurate labels, and severely corrupted inputs that degrade prediction quality significantly. To address the first issue, we develop a ded-icated camera system and build a new dataset of real low-light images with accurate pose labels. Thanks to our cam-era system, each low-light image in our dataset is coupled with an aligned well-lit image, which enables accurate pose labeling and is used as privileged information during train-ing. We also propose a new model and a new training strat-egy that fully exploit the privileged information to learn rep-resentation insensitive to lighting conditions. Our method demonstrates outstanding performance on real extremely low-light images, and extensive analyses validate that both of our model and dataset contribute to the success. 1.

Introduction
Deep neural networks [6, 55, 56, 64, 66] trained with large-scale datasets [1, 18, 30, 35, 38] have driven dramatic advances in human pose estimation recently. However, their success demands high-quality inputs taken in controlled en-vironments while in real-world applications images are of-ten corrupted by low-light conditions, adverse weather con-ditions, sensor noises, motion blur, etc. Indeed, a precon-dition for human pose estimation in the wild is robustness against such adverse conditions.
Motivated by this, we study pose estimation under ex-∗ Equal contribution. † Corresponding authors. tremely low-light conditions using a single sRGB image, in which humans can barely see anything. The task is highly practical as its solution enables nighttime applications of pose estimation without raw-RGB data or additional de-vices like IR cameras. It is at the same time challenging due to the following two reasons. The first is the difficulty of data collection. Manual annotation of human poses in low-light images is often troublesome due to their limited visibility. The second is the difficulty of pose estimation on low-light images. The poor quality of low-light im-ages in terms of visibility and signal-to-noise ratio largely degrades prediction accuracy of common pose estimation models. A na¨ıve way to mitigate the second issue is to ap-ply low-light image enhancement [5, 28, 41, 42, 62] to input images. However, image enhancement is in general highly expensive in both computation and memory. Also, it is not aware of downstream recognition tasks and thus could be sub-optimal for pose estimation in low-light conditions.
To tackle this challenging problem, we first present a new dataset of real extremely low-light images with ground-truth pose labels. The key feature of our dataset is that each low-light image is coupled with a well-lit image of the same content. The advantage of using the well-lit im-ages is two-fold. First, they enable accurate labeling for their low-light counterparts thanks to their substantially bet-ter visibility. Second, they can be utilized as privileged in-formation [13, 32, 40, 57, 58], i.e., additional input data that are more informative than the original ones (low-light im-ages in our case) but available only in training, to further improve performance on low-light images. Such benefits of paired training images have also been validated in other robust recognition tasks [9, 34, 46–49]. The beauty of our dataset is that pairs of low-light and well-lit images are all
real and aligned, unlike existing datasets that provide pairs of synthetic-real images [9, 47, 48] or those of largely mis-aligned real images [46, 49]. Since it is practically impossi-ble to capture such paired images using common cameras, we build a dedicated camera system for data collection.
We also propose an effective method based on learning using privileged information (LUPI) [58] to fully exploit our dataset. The proposed method considers a model tak-ing low-light inputs as a student and a model dealing with corresponding well-lit images as a teacher. Both of the teacher and student are trained by a common pose estima-tion loss, and the student further utilizes knowledge of the teacher as additional supervision. Specifically, our method employs neural styles of intermediate feature maps as the knowledge and forces neural styles of low-light images to approximate those of well-lit images by an additional loss.
As will be demonstrated, this LUPI approach allows the learned representation to be insensitive to lighting condi-tions. Moreover, we design a new network architecture that unifies the teacher and student through lighting-condition specific batch normalization (LSBN). LSBN consists of two batch normalization (BN) layers, each of which serves im-ages of each lighting condition, i.e., ‘well-lit’ or ‘low-light’.
We replace BNs of an existing network with LSBNs so that images of different lighting conditions are processed by dif-ferent BNs. Hence, in our architecture, the teacher and stu-dent share all the parameters except for those of their corre-sponding BNs, which allows the student to enjoy the strong representation learned using well-lit images.
The efficacy of our method is evaluated on real low-light images we collected for testing. Our method outperforms its reduced versions and relevant approaches such as lighting-condition adversarial learning and a combination of image enhancement and pose estimation. These results clearly demonstrate the advantages of our dataset and method. In short, our major contribution is three-fold:
• We propose a novel approach to human pose estimation in extremely low-light conditions using a single sRGB image. To the best of our knowledge, we are the first to tackle this challenging but highly practical problem.
• We build a new dataset that provides real and aligned low-light and well-lit images with accurate pose labels.
• We present a strong baseline method that fully exploits the low-light and well-lit image pairs of our dataset. 2.