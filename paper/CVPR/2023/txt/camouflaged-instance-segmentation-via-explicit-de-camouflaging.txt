Abstract
Camouflaged Instance Segmentation (CIS) aims at pre-dicting the instance-level masks of camouflaged objects, which are usually the animals in the wild adapting their ap-pearance to match the surroundings. Previous instance seg-mentation methods perform poorly on this task as they are easily disturbed by the deceptive camouflage. To address these challenges, we propose a novel De-camouflaging Net-work (DCNet) including a pixel-level camouflage decou-pling module and an instance-level camouflage suppression module. The proposed DCNet enjoys several merits. First, the pixel-level camouflage decoupling module can extract camouflage characteristics based on the Fourier transfor-mation. Then a difference attention mechanism is proposed to eliminate the camouflage characteristics while reserv-ing target object characteristics in the pixel feature. Sec-ond, the instance-level camouflage suppression module can aggregate rich instance information from pixels by use of instance prototypes. To mitigate the effect of background noise during segmentation, we introduce some reliable ref-erence points to build a more robust similarity measure-ment. With the aid of these two modules, our DCNet can ef-fectively model de-camouflaging and achieve accurate seg-mentation for camouflaged instances. Extensive experimen-tal results on two benchmarks demonstrate that our DCNet performs favorably against state-of-the-art CIS methods, e.g., with more than 5% performance gains on COD10K and NC4K datasets in average precision. 1.

Introduction
In the field of biology, camouflage is defined as a strategy that animals use to adapt their body’s appearance (e.g., color and pattern) to match their surroundings in order to achieve concealing and avoid being hunted by predators [37]. Cam-*Equal contribution
†Corresponding author
Figure 1. Illustration of our motivation. (a) We propose to ex-tract camouflage characteristics to model explicit de-camouflaging for CIS. (b) Pairwise similarity between prototype and pixel is al-ways erroneous. (c) The prototype-pixel correlation is based on the prototype-reference and pixel-reference similarity distribution, which is more accurate. ouflaged Instance Segmentation (CIS) [22] aims at identi-fying the location and predicting instance-level masks of camouflaged objects, which has attracted more and more attention due to its widespread applications in medical im-age analysis [11, 44], search-and-rescue work [9] and recre-ational art [7], etc.
Despite the tremendous progress in instance segmen-tation [14, 40, 41], there are few efforts [22, 33] working on Camouflaged Instance Segmentation, as CIS is a more challenging task where most camouflaged instances lack obvious contrast with the background, making general in-stance segmentation methods work poorly on this task. Re-cent CIS approaches [22, 33] are generally based on tradi-tional instance segmentation models, either by naively fus-ing various general instance segmentation models [22] to get better representations, or by directly using global in-teraction [33]. However, these approaches fail to explore the core of CIS: de-camouflaging, i.e., eliminating camou-flage characteristics of the target object. Without explicitly de-camouflaging, the previous methods are easily disturbed by similar background. De-camouflaging is a challenging problem as no image-specific camouflage information is provided as supervision signals. Intuitively, humans have the ability to quickly recognise objects in a highly cam-ouflaged scene. They first repeatedly discriminate the real target characteristics from the camouflage characteristics at the pixel level, and then aggregate the pixel information to discern the whole target instance from the background.
This human visual mechanism motivates us to explore de-camouflaging strategy from the pixel level to the instance level in a progressive manner.
In order to model de-camouflage at both the pixel and instance levels, a series of issues need to be considered. (1) The pixel level de-camouflage. In essence, each pixel feature of a camouflaged image contains the camouflage characteristics and the target object characteristics. Note that our goal is to remove camouflage characteristics and maintain target object information, thus a question natu-rally arises: How to decouple these two pieces of informa-tion at the pixel level? (2) The instance level segmentation.
Based on the de-camouflaged pixels, we can naturally ag-gregate the pixel information and infer the mask of the tar-get instance. Currently, the transformer-based models [5, 6] have achieved leading performance for instance segmenta-tion, where instance-specific prototypes are learned by con-stantly interacting with pixel features for final segmenta-tion. However, directly applying the transformer to CIS is not trivial, as the prototypes would frequently absorb decep-tive background information that has high similarity with the objects during the interaction, thus failing to discover desired targets accurately. As proved in Figure 1(b), the pro-totype fish is more similar to background pixels than target pixels in the camouflaged image. Therefore, we inevitably face another question: How to focus on camouflaged in-stances to achieve de-camouflaging?
Motivated by the above discussions, we propose an end-to-end De-camouflaging Network (DCNet) by jointly modeling pixel-level camouflage decoupling and instance-level camouflage suppression for CIS. In the Pixel-level
Camouflage Decoupling module (PCD), we focus on de-coupling camouflage characteristics and target information fused in the pixel feature. First, we extract camouflage characteristics with the assistance of frequency domain in-formation. The Fourier spectrum amplitude contains low-level statistics [34, 42] (e.g., color and texture of the en-vironment, see Figure 5) that accords with the camouflage characteristics. Based on the obtained description of cam-ouflage characteristics, we propose a novel difference at-tention mechanism to acquire de-camouflaged pixel fea-tures. In this mechanism, we calculate the discrepancy be-tween features of the original image and camouflage char-acteristics (see Figure 1(a)), thereby decoupling the camou-flage characteristics and valuable target information while filtering out the background interference. In the Instance-level Camouflage Suppression module (ICS), we aggre-gate the de-camouflaged pixels to achieve final segmenta-tion and meanwhile mitigate the effect of background noise in prototype-pixel interactions. Specifically, we introduce a set of instance prototypes to capture each camouflaged in-stance through long-range context-aware interactions. To constrain the interactions to favor target pixels over back-ground pixels, we design a novel reference attention mecha-nism, where we select de-camouflaged pixels with high con-tribution to prototypes as reference points (see Figure 1(c)).
Then we calculate the similarity of prototype-reference and pixel-reference, respectively, thereby obtaining similarity distributions serving as soft multilabel to measure correla-tions between prototypes and pixels. Highly similar pix-els and prototypes must have consistent similarity distri-butions. In this way, the soft multilabel-based correlation is more accurate than the normal pairwise correlation, as it benefits from consensus among reliable reference points with a global receptive field. As a result, the correlation noise brought by deceptive background can be suppressed and more effective prototypes that contain rich instance in-formation can be obtained.
The contributions of our method could be summarized as follows: (1) We propose a novel De-camouflaging Network (DCNet) by jointly modeling pixel-level camouflage decou-pling and instance-level camouflage suppression for CIS. (2) We propose two effective designs in DCNet, i.e., dif-ference attention mechanism and reference attention mech-anism, which can highlight target information and suppress background interference. (3) Extensive experimental results on two benchmark datasets demonstrate the effectiveness of the proposed method, e.g., with more than 5% performance gains on COD10K and NC4K datasets in average precision. 2.