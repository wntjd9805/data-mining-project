Abstract
Semantic editing of images is the fundamental goal of computer vision. Although deep learning methods, such as generative adversarial networks (GANs), are capable of producing high-quality images, they often do not have an inherent way of editing generated images semantically. Re-cent studies have investigated a way of manipulating the latent variable to determine the images to be generated.
However, methods that assume linear semantic arithmetic have certain limitations in terms of the quality of image editing, whereas methods that discover nonlinear semantic pathways provide non-commutative editing, which is incon-sistent when applied in different orders. This study proposes a novel method called deep curvilinear editing (DeCurvEd) to determine semantic commuting vector fields on the latent space. We theoretically demonstrate that owing to commu-tativity, the editing of multiple attributes depends only on the quantities and not on the order. Furthermore, we exper-imentally demonstrate that compared to previous methods, the nonlinear and commutative nature of DeCurvEd facili-tates the disentanglement of image attributes and provides higher-quality editing. 1.

Introduction
Generating and editing realistic images is one of the fun-damental goals in computer vision. Generative adversar-ial networks (GANs) [20] have emerged as a major im-age generation approach owing to the quality of generated images [7, 33–36, 48] and provide various real-world ap-plications [1, 13, 18, 53, 63, 68]. Other notable methods include variational autoencoders (VAEs) [24], conditional
PixelCNN [61], and diffusion-based models [26, 56], which are collectively called deep generative models. However, deep generative models cannot inherently edit images se-mantically. They can be viewed as mappings from latent space to image space, and the latent variables determine the generated images. Therefore, several methods have been developed to train deep generative models such that each semantic attribute the user wants to edit is assigned to each element of the latent variable [10, 45, 46] (see the first col-umn of Table 1). However, this approach requires computa-tionally expensive training and can conflict with the quality of image generation. Other studies have developed image-to-image translation that translates images from one domain to another [28,64,68]. However, this approach also requires training from scratch and limits image editing to be discon-tinuous unless combined with latent variable manipulation.
Therefore, a general and promising approach is necessary to identify manipulations on latent variables of already trained models that edit images semantically.
A study reported that adding certain vectors to latent variables can modify the corresponding attributes of the ob-ject in the generated images [51]. This indicates that the latent space can be regarded as a linear vector space. Some studies have aimed to identify attribute vectors in a super-vised or an unsupervised manner [17, 19, 22, 27, 49, 50, 54, 55, 62, 69]. In any case, these studies introduce the strong assumption of linear semantic arithmetic on the latent space (see the second column of Table 1), which limits the qual-ity of image editing. Other studies have proposed methods to determine attribute vectors depending on the position in the latent space, that is, the attribute vector fields (or local attribute coordinates). [2, 11, 12, 17, 29, 37, 44, 52, 58, 60]; these methods edit an image attribute by moving the latent variable nonlinearly along the corresponding attribute vec-tor field. Although this approach is elegant, the edits of different attributes are generally non-commutative (see the third column of Table 1). That is, what we get is different when we edit attributes (denoted by e1 and e2) one after an-other, or in the reverse order. This property can harm the disentanglement between attributes considering that the re-lationships among attributes change at different points. In contrast, linear arithmetic ensures that the edits of different attributes are commutative.
To overcome this dilemma, this study proposes deep
Table 1. Comparison of Our Proposal against Related Methods.
Training under constraints
[10, 45, 46]
Linear arithmetic
[27, 55, 62]
Vector fields/Local basis
[12, 52, 60]
Global coordinate
No retraining
Nonlinear edit
Commutative edit
Cartesian
✗ –
✓ oblique
✓
✗
✓ (only local)
✓
✓
✗
DeCurvEd (proposed) curvilinear
✓
✓
✓
Conceptual diagram curvilinear editing (DeCurvEd), a method that determines a set of commuting attribute vector fields in the latent space of a pre-trained deep generative model. The key idea is adopted from the theorem that a set of vector fields is lo-cally expressed as partial derivatives of a coordinate chart if it is linearly independent and commuting [43]. There-fore, we define a curvilinear coordinate system globally [3] by employing a normalizing flow [9, 39], from which we derive commuting vector fields (see the rightmost panel of
Table 1). The advantages of DeCurvEd are as follows (see also Table 1): 1. Edits of different attributes are always commutative, unlike previous methods that assume attribute vector fields (e.g., [60]). Therefore, an edited image does not depend on the order of editing, but on the amount of editing performed. 2. Edits are nonlinear, which indicates that DeCurvEd provides better editing quality than methods that as-sume linear arithmetic of attribute vectors (e.g., [62]). 3. DeCurvEd does not require retraining of deep gener-ative models, but identifies attribute vector fields in the latent space of pre-trained models, unlike image-to-image translation and training under constraints (e.g., [10, 28]). 4. We propose CurvilinearGANSpace by combining De-CurvEd with GANs and experimentally demonstrate that the nonlinear and commutative nature disentangles attributes and enables high-quality editing. 5. The key idea is not limited to GANs, and is available for any generative models that are conditioned on la-tent variables, including VAEs [24], conditional Pixel-CNN [61], and diffusion-based models [26, 56]. 2.