Abstract
Weakly Supervised Video Anomaly Detection (WSVAD) is challenging because the binary anomaly label is only given on the video level, but the output requires snippet-level predictions. So, Multiple Instance Learning (MIL) is prevailing in WSVAD. However, MIL is notoriously known to suffer from many false alarms because the snippet-level detector is easily biased towards the abnormal snippets with simple context, confused by the normality with the same bias, and missing the anomaly with a different pattern. To this end, we propose a new MIL framework: Unbiased MIL (UMIL), to learn unbiased anomaly features that improve
WSVAD. At each MIL training iteration, we use the cur-rent detector to divide the samples into two groups with dif-ferent context biases: the most confident abnormal/normal snippets and the rest ambiguous ones. Then, by seeking the invariant features across the two sample groups, we can remove the variant context biases. Extensive exper-iments on benchmarks UCF-Crime and TAD demonstrate the effectiveness of our UMIL. Our code is provided at https://github.com/ktr-hubrt/UMIL. 1.

Introduction
Video Anomaly Detection (VAD) aims to detect events among video sequences that deviate from expectation, which is widely applied in real-world tasks such as intel-ligent manufacturing [8], TAD surveillance [9,22] and pub-lic security [25, 30]. To learn such a detector, conventional fully-supervised VAD [1] is impractical as the scattered but diverse anomalies require extremely expensive labeling cost. On the other hand, unsupervised VAD [3, 11, 13, 35, 42] by only learning on normal videos to detect open-set anomalies often triggers false alarms, as it is essentially ill-posed to define what is normal and abnormal by giving only
*Corresponding author (a) (b)
Figure 1. Two anomalies of Explosion and Vandalism are illus-trated. Among each video sequence, we use red boxes to highlight the ground-truth anomaly regions as in the first row. The corre-sponding anomaly curves of an MIL-based model are depicted be-low. False alarms and real anomalies are linked to the curves with blue arrows and green arrows respectively. Best viewed in color. normal videos without any prior knowledge. Hence, we are interested in a more practical setting: Weakly Supervised
VAD (WSVAD) [12, 43], where only video-level binary la-bels (i.e., normal vs. abnormal) are available.
In WSVAD, each video sequence is partitioned into multiple snippets. Hence, all the snippets are normal in a normal video, and at least one snippet contains the anomaly in an abnormal one. The goal of WSVAD is to train a snippet-level anomaly detector using video-level la-bels. The mainstream method is Multiple Instance Learn-ing (MIL) [22, 30]—multiple instances refer to the snip-pets in each video, and learning is conducted by decreas-ing the predicted anomaly score for each snippet in a nor-mal video, and increasing that only for the snippet with the largest anomaly score in an abnormal video. For example,
Figure 1a shows an abnormal video containing an explo-sion scene, and the detector is trained by MIL to increase the anomaly score for the most anomalous explosion snip-pet (green link).
However, MIL is easily biased towards the simplest con-text shortcut in a video. We observe in Figure 1a that the de-Figure 2a), substantial motion but normal (equipment main-tenance in Figure 2b), or subtle motion but abnormal (van-dalizing the rear-view mirror in Figure 2c), leading to the aforementioned failure cases.
To this end, we aim to build an unbiased MIL detector by training with both the confident abnormal/normal and the ambiguous ones. Specifically, at each UMIL training iteration, we divide the snippets into two sets using the cur-rent detector: 1) the confident set with abnormal and nor-mal snippets and 2) the ambiguous set with the rest snip-pets, e.g., the two sets are enclosed with red circles and blue circles in Figure 2, respectively. The ambiguous set is grouped into two unsupervised clusters (e.g., the two blue circles separated by the blue line) to discover the intrinsic difference between normal and abnormal snippets. Then, we seek an invariant binary classifier between the two sets that separate the abnormal/normal in the confident set and the two clusters in the ambiguous one. The rationale of the proposed invariance pursuit is that the snippets in the ambiguous set must have a different context bias from the confident set, otherwise, they will be selected into the same set. Therefore, given a different context but the same true anomaly, the invariant pursuit will turn to the true anomaly (e.g., the black line).
Overall, we term our approach as Unbiased MIL (UMIL). Our contributions are summarized below:
• UMIL is a novel WSVAD method that learns an unbiased anomaly detector by pursuing the invariance across the confident and ambiguous snippets with different context biases.
• Thanks to the unbiased objective, UMIL is the first WS-VAD method that combines feature fine-tuning and de-tector learning into an end-to-end training scheme. This leads to a more tailored feature representation for VAD.
• UMIL is equipped with a fine-grained video partitioning strategy for preserving the subtle anomaly information in video snippets.
• These contribute to the improved performance over the current state-of-the-art methods on UCF-Crime [30] ( 1.4% AUC) and TAD [22] (3.3% AUC) benchmarks.
Note that UMIL brings more than 2% AUC gain com-pared with the MIL baseline on both datasets, which jus-tifies the effectiveness of UMIL. 2.