Abstract
Two-stage object detectors generate object proposals and classify them to detect objects in images. These pro-posals often do not contain the objects perfectly but overlap with them in many possible ways, exhibiting great variabil-ity in the difficulty levels of the proposals. Training a ro-bust classifier against this crop-related variability requires abundant training data, which is not available in few-shot settings. To mitigate this issue, we propose a novel vari-ational autoencoder (VAE) based data generation model, which is capable of generating data with increased crop-related diversity. The main idea is to transform the latent space such latent codes with different norms represent dif-ferent crop-related variations. This allows us to generate features with increased crop-related diversity in difficulty levels by simply varying the latent norm. In particular, each latent code is rescaled such that its norm linearly correlates with the IoU score of the input crop w.r.t. the ground-truth box. Here the IoU score is a proxy that represents the dif-ficulty level of the crop. We train this VAE model on base classes conditioned on the semantic code of each class and then use the trained model to generate features for novel classes.
In our experiments our generated features con-sistently improve state-of-the-art few-shot object detection methods on the PASCAL VOC and MS COCO datasets. 1.

Introduction
Object detection plays a vital role in many computer vi-sion systems. However, training a robust object detector often requires a large amount of training data with accurate bounding box annotations. Thus, there has been increas-ing attention on few-shot object detection (FSOD), which learns to detect novel object categories from just a few an-notated training samples. It is particularly useful for prob-lems where annotated data can be hard and costly to ob-tain such as rare medical conditions [31, 41], rare animal species [20, 44], satellite images [2, 19], or failure cases in (a) DeFRCN [33] (b) Ours
Figure 1. Robustness to different object crops of the same ob-ject instance. (a) The classifier head of the state-of-the-art FSOD method [33] classifies correctly a simple crop of the bird but mis-classifies a hard crop where some parts are missing. (b) Our method can handle this case since it is trained with additional gen-erated features with increased crop-related diversity. We show the class with the highest confidence score. autonomous driving systems [27, 28, 36].
For the most part, state-of-the-art FSOD methods are built on top of a two-stage framework [35], which includes a region proposal network that generates multiple image crops from the input image and a classifier that labels these proposals. While the region proposal network generalizes well to novel classes, the classifier is more error-prone due to the lack of training data diversity [40]. To mitigate this is-sue, a natural approach is to generate additional features for novel classes [12, 55, 57]. For example, Zhang et al. [55] propose a feature hallucination network to use the varia-tion from base classes to diversify training data for novel classes. For zero-shot detection (ZSD), Zhu et al. [57] pro-pose to synthesize visual features for unseen objects based on a conditional variational auto-encoder. Although much progress has been made, the lack of data diversity is still a challenging issue for FSOD methods.
Here we discuss a specific type of data diversity that greatly affects the accuracy of FSOD algorithms. Specifi-cally, given a test image, the classifier needs to accurately classify multiple object proposals1 that overlap the object instance in various ways. The features of these image crops exhibit great variability induced by different object scales, object parts included in the crops, object positions within the crops, and backgrounds. We observe a typical scenario where the state-of-the-art FSOD method, DeFRCN [33], only classifies correctly a few among many proposals over-lapping an object instance of a few-shot class. In fact, dif-ferent ways of cropping an object can result in features with various difficulty levels. An example is shown in Figure 1a where the image crop shown in the top row is classified cor-rectly while another crop shown in the bottom row confuses the classifier due to some missing object parts. In general, the performance of the method on those hard cases is signif-icantly worse than on easy cases (see section 5.4). However, building a classifier robust against crop-related variation is challenging since there are only a few images per few-shot class.
In this paper, we propose a novel data generation method to mitigate this issue. Our goal is to generate features with diverse crop-related variations for the few-shot classes and use them as additional training data to train the classi-fier. Specifically, we aim to obtain a diverse set of features whose difficulty levels vary from easy to hard w.r.t. how the object is cropped.2 To achieve this goal, we design our generative model such that it allows us to control the diffi-culty levels of the generated samples. Given a model that generates features from a latent space, our main idea is to enforce that the magnitude of the latent code linearly corre-lates with the difficulty level of the generated feature, i.e., the latent code of a harder feature is placed further away from the origin and vice versa. In this way, we can con-trol the difficulty level by simply changing the norm of the corresponding latent code.
In particular, our data generation model is based on a conditional variational autoencoder (VAE) architecture.
The VAE consists of an encoder that maps the input to a latent representation and a decoder that reconstructs the in-put from this latent code. In our case, inputs to the VAE are object proposal features, extracted from a pre-trained ob-ject detector. The goal is to associate the norm (magnitude) of the latent code with the difficulty level of the object pro-posal. To do so, we rescale the latent code such that its norm linearly correlates with the Intersection-Over-Union (IoU) score of the input object proposal w.r.t. the ground-truth ob-ject box. This IoU score is a proxy that partially indicates the difficulty level: A high IoU score indicates that the ob-1Note that an RPN typically outputs 1000 object proposals per image. 2In this paper, the difficulty level is strictly related to how the object is cropped. ject proposal significantly overlaps with the object instance while a low IoU score indicates a harder case where a part of the object can be missing. With this rescaling step, we can bias the decoder to generate harder samples by increasing the latent code magnitude and vice versa. In this paper, we use latent codes with different norms varying from small to large to obtain a diverse set of features which can then serve as additional training data for the few-shot classifier.
To apply our model to FSOD, we first train our VAE model using abundant data from the base classes. The VAE is conditioned on the semantic code of the input instance category. After the VAE model is trained, we use the se-mantic embedding of the few-shot class as the conditional code to synthesize new features for the corresponding class.
In our experiments, we use our generated samples to fine-tune the baseline few-shot object detector - DeFRCN [33].
Surprisingly, a vanilla conditional VAE model trained with only ground-truth box features brings a 3.7% nAP50 im-provement over the DeFRCN baseline in the 1-shot setting of the PASCAL VOC dataset [4]. Note that we are the first
FSOD method using VAE-generated features to support the training of the classifier. Our proposed Norm-VAE can fur-ther improve this new state-of-the-art by another 2.1%, i.e., from 60% to 62.1%. In general, the generated features from
Norm-VAE consistently improve the state-of-the-art few-shot object detector [33] for both PASCAL VOC and MS
COCO [24] datasets.
Our main contributions can be summarized as follows:
• We show that lack of crop-related diversity in training data of novel classes is a crucial problem for FSOD.
• We propose Norm-VAE, a novel VAE architecture that can effectively increase crop-related diversity in diffi-culty levels into the generated samples to support the training of FSOD classifiers.
• Our experiments show that the object detectors trained with our additional features achieve state-of-the-art
FSOD in both PASCAL VOC and MS COCO datasets. 2.