Abstract
In point cloud analysis, point-based methods have rapidly developed in recent years. These methods have re-cently focused on concise MLP structures, such as Point-NeXt, which have demonstrated competitiveness with Con-volutional and Transformer structures. However, standard
MLPs are limited in their ability to extract local features effectively. To address this limitation, we propose a Vector-oriented Point Set Abstraction that can aggregate neighbor-ing features through higher-dimensional vectors. To facil-itate network optimization, we construct a transformation from scalar to vector using independent angles based on 3D vector rotations. Finally, we develop a PointVector model that follows the structure of PointNeXt. Our experimental results demonstrate that PointVector achieves state-of-the-art performance 72.3% mIOU on the S3DIS Area 5 and 78.4% mIOU on the S3DIS (6-fold cross-validation) with only 58% model parameters of PointNeXt. We hope our work will help the exploration of concise and effective fea-ture representations. The code will be released soon. 1.

Introduction
Point cloud analysis is a cornerstone of various down-stream tasks. With the introduction of PointNet [25] and
PointNet++ [26], the direct processing of unstructured point clouds has become a hot topic. Many point-based net-works introduced novel and sophisticated modules to ex-tract local features, e.g., attention-based methods [52] ex-plore attention mechanisms as Fig.1a with lower consump-tion, convolution-based methods [36] explore the dynamic convolution kernel as Fig.1c, and graph-based methods [39]
[53] use graph to model relationships of points. The appli-cation of these methods to the feature extraction module of
PointNet++ brings an improvement in feature quality. How-ever, they are somewhat complicated to design in terms of network structure. PointNeXt [28] adapts the SetAbstrac-*Co-first authors with equal contribution to refining the theory and ex-perimental design
â€ Corresponding authors tion (SA) module of PointNet++ [26] and proposes the In-verted Residual MLP (InvResMLP) module. The simple design of MLP network achieves good results. Motivated by this work, we try to further explore the potential of the
MLP structure. (a) Attention (b) Templated-based method (c) Dynamic Conv (d) Vector
Figure 1. Illustrations of the core operations of the different meth-ods. (a) The features of each point are calculated separately by applying a fixed/isotropic kernel (black arrow) like Linear layer.
Then, it imparts anisotropy by weights generated from inputs. (b)
The displacement vector is used to filter points that approximate the kernel pattern for features aggregation. (c) It applies unique dynamic kernels with anisotropy for each point feature. (d) Dif-ferently, we generate vector representations based on features, and the aggregation methods for vectors are anisotropic due to the di-rection of the vectors.
PointNeXt uses all standard MLPs, which has insuffi-cient feature extraction capability.
In addition to atten-tion and dynamic convolution mechanisms, template-based methods as Fig.1b such as 3D-GCN [19] employ relative displacement vectors to modulate the association between input points and the convolutional kernel. We introduce a vector representation of features to extend the range of fea-ture variation with the intention of more effectively regulat-ing the connections between local features. Our approach as Fig.1d differs from template-based methods. Instead of using displacement vectors as a property of the kernel, we
generate a vector representation for each neighboring point and aggregate them. Our method introduces less inductive bias, resulting in improved generalization capabilities. Fur-thermore, we enhance the generation of 3D vector repre-sentations by utilizing a vector rotation matrix with two in-dependent angles in 3D space. This method facilitates the network to find the better solution.
Influenced by PointNeXt [28] and PointNet++ [26], we present the VPSA module. This module adheres to the structure of Point Set Abstraction (SA) module of the Point-Net series. Vector representations are obtained from input features and aggregated using a reduction function. The vector of each channel is then projected into a scalar to de-rive local features. By combining VPSA and SA modules, we construct a PointVector model with an architecture akin to that of PointNeXt.
Our model undergoes comprehensive validation on pub-It achieves state-of-the-art per-lic benchmark datasets. formance on the S3DIS [1] semantic segmentation bench-mark and competitive results on the ScanObjectNN [47] and ShapeNetPart [48] datasets. By incorporating a pri-ori knowledge of vectors, our model attains superior results with fewer parameters on S3DIS. Detailed ablation experi-ments further demonstrate the efficacy of our methodology.
The contributions are summarized below:
- We propose a novel immediate vector representation with relative features and positions to better guide local feature aggregation.
- We explore the method of obtaining vector representa-tion and propose the generation method of 3D vector by utilizing the vector rotation matrix in 3D space.
- Our proposed PointVector model achieves 72.3% mean Intersection over Union (mIOU) on S3DIS area5 and 78.4% mIOU on S3DIS (6-fold cross-validation) with only 58% model parameters of PointNeXt. 2.