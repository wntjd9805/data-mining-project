Abstract
We consider a scenario where we have access to the tar-get domain, but cannot afford on-the-fly training data an-notation, and instead would like to construct an alternative training set from a large-scale data pool such that a com-petitive model can be obtained. We propose a search and pruning (SnP) solution to this training data search prob-lem, tailored to object re-identification (re-ID), an appli-cation aiming to match the same object captured by differ-ent cameras. Specifically, the search stage identifies and merges clusters of source identities which exhibit similar distributions with the target domain. The second stage, subject to a budget, then selects identities and their im-ages from the Stage I output, to control the size of the re-sulting training set for efficient training. The two steps provide us with training sets 80% smaller than the source pool while achieving a similar or even higher re-ID accu-racy. These training sets are also shown to be superior to a few existing search methods such as random sampling and greedy sampling under the same budget on training data size. If we release the budget, training sets resulting from the first stage alone allow even higher re-ID accu-racy. We provide interesting discussions on the specificity of our method to the re-ID problem and particularly its role in bridging the re-ID domain gap. The code is available at https://github.com/yorkeyao/SnP 1.

Introduction
The success of a deep learning-based object re-ID relies on one of its critical prerequisites: the labeled training data.
To achieve high accuracy, typically a massive amount of data needs to be used to train deep learning models. How-ever, creating large-scale object re-ID training data with manual labels is expensive. Furthermore, collecting training data that contributes to the high test accuracy of the trained model is even more challenging. Recent years have seen a large amount of datasets proposed and a significant increase in the data size of a single dataset. For example, the Rand-Person [37] dataset has 8000 identities, which is more than
Figure 1. We present a search and pruning (SnP) solution to the training data search problem in object re-ID. The source data pool is 1 order of magnitude larger than existing re-ID training sets in terms of the number of images and the number of identities. When the target is AlicePerson [1], from the source pool, our method (SnP) results in a training set 80% smaller than the source pool while achieving a similar or even higher re-ID accuracy. The searched training set is also superior to existing individual train-ing sets such as Market-1501 [54], Duke [55], and MSMT [45]. 6× larger than the previous PersonX [37] dataset.
However, these datasets generally have their own dataset bias, making the model trained on one dataset unable to generalize well to another. For example, depending on the filming scenario, different person re-ID datasets generally have biases on camera positions, human races, and cloth-ing style. Such dataset biases usually lead to model bias, which results in the model’s difficulty performing well in an unseen filming scenario. To address this, many try to improve learning algorithms, including domain adaptation and domain generalization methods [2, 10, 27, 33, 35, 56].
Whereas these algorithms are well-studied and have proven successful in many re-ID applications, deciding what kind of data to use for training the re-ID model is still an open research problem, and has received relatively little attention in the community. We argue that this is a crucial problem
to be answered in light of the ever-increasing scale of the available datasets.
In this paper, we introduce SnP, a search and pruning so-lution for sampling an efficient re-ID training set to a target domain. SnP is designed for the scenario in that we have a target dataset that does not have labeled training data. Our collected source pool, in replace, provides suitable labeled data to train a competitive model. Specifically, given a user-specified budget (e.g., maximum desired data size), we sam-ple a subset of the source pool, which satisfies the budget re-quirement and desirably has high-quality data to train deep learning models. This scenario is especially helpful for de-ploying a re-ID system for unknown test environments, as it is difficult to manually label a training set for these new environments. We note that due to the absence of an in-distribution training set, the searched data are directly used for training the re-ID model rather than pre-training.
In particular, we combine several popular re-ID datasets into a source pool, and represent each image in the pool with features. Those features are extracted from an Imagenet-pretrained model [39]. The images with features are stored on the dataserver to serve as a gallery. When there is a query from the target, we extract the feature of the query image, and search in the gallery for similar images on a feature level. Specifically, in the search stage, we calculate feature-level distance, i.e., Fréchet Inception Distance (FID) [16].
Given the constraint of a budget, we select the most repre-sentative samples in the pruning stage, based on the outputs from the search stage. This limits the size of the constructed training set and enables efficient training.
Combining search and pruning, we construct a train-ing dataset that empirically shows significant accuracy im-provements on several object re-ID targets, compared to the baselines. Without budget constraints, our searched training sets allow higher re-ID accuracy than the complete source pool, due to its target-specificity. With budget constraints, the pruned training set still achieves comparable or better performance than the source pool. The proposed SnP is demonstrated to be superior to random or greedy sampling.
We show in Fig. 1 that the training set constructed by SnP leads to the best performance on the target compared to the others. We provide discussions on the specificity of our method and its role in bridging the re-ID domain gap. 2.