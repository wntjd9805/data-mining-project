Abstract
Generalized few-shot object detection aims to achieve precise detection on both base classes with abundant an-notations and novel classes with limited training data. Ex-isting approaches enhance few-shot generalization with the sacriﬁce of base-class performance, or maintain high pre-cision in base-class detection with limited improvement in novel-class adaptation. In this paper, we point out the rea-son is insufﬁcient Discriminative feature learning for all of the classes. As such, we propose a new training frame-work, DiGeo, to learn Geometry-aware features of inter-class separation and intra-class compactness. To guide the separation of feature clusters, we derive an ofﬂine sim-plex equiangular tight frame (ETF) classiﬁer whose weights serve as class centers and are maximally and equally sep-arated. To tighten the cluster for each class, we include adaptive class-speciﬁc margins into the classiﬁcation loss and encourage the features close to the class centers. Ex-perimental studies on two few-shot benchmark datasets (VOC, COCO) and one long-tail dataset (LVIS) demon-strate that, with a single model, our method can effectively improve generalization on novel classes without hurting the detection of base classes. Our code can be found here. 1.

Introduction
Recent years have witnessed the tremendous growth of object detection through deep neural models and large-scale training [2, 13–15, 40, 42, 45, 60, 65]. However, the success of detection models heavily relies on the amount and qual-ity of annotations, which requires expensive annotation cost and time. In addition, traditional object detection models perform worse on the classes with a limited number of an-notations [11, 52, 56], while human are able to learn from few observations. In order to close the gap between human vision system and detection models, recent studies have investigated how to generalize well on rare classes under
∗Corresponding Author.
Figure 1. Performance on few-shot object detection on Pascal
VOC [3]. Previous transfer-learning approaches (blue) balancing the training data by aggressively down-sampling the base set and may result in overﬁtting. Instead, we (red) use the full train set, aiming to both maintain precise base detection but learn discrimi-native features from the limited annotations for few-shot classes. the few-shot object detection (FSOD) setting. Speciﬁcally, given many-shot (base) classes with plenty of training data and few-shot (novel) classes with extremely limited training data (e.g., 5 annotated instances per class), FSOD expects the model to detect the objects in the novel classes well.
To improve the generalization ability on novel-class de-tection, recent studies [6, 44, 52] conduct transfer learning in a two-step manner.
In detail, the model is pre-trained on the whole set of base classes, and then ﬁne-tuned on the union of the set of novel classes and an aggressively down-sampled base subset. However, the efﬁcient few-shot adap-tation is often achieved at the expense of sacriﬁcing preci-sion on base detection (Fig. 1). Being aware of this limita-tion, Fan et al. [6] proposed to evaluate the performance of both base and novel classes in the generalized few-shot ob-ject detection (GFSOD) setting. In addition, they proposed a consistency regularization to emphasize the pre-trained base knowledge during ﬁne-tuning and employed an ensem-bling strategy. However, they design different classiﬁers for base and novel classes, and the adaptation on novel classes is impeded due to a complex ensembling process.
In this paper, we pointed out that the devil is in in-sufﬁcient discriminative feature learning for few-shot ob-ject detection, including inefﬁcient knowledge adaptation to novel classes and unexpected knowledge forgetting of base classes. First, as the novel instances are extremely limited during training, it is hard to capture the representative vi-sual information of novel classes and adapt the knowledge learned from base classes to novel classes. As a result, the model cannot distinguish between the novel classes, which weakens the few-shot adaptation. Secondly, balanced train-ing strategies such as down-sampling fail to utilize the di-verse training samples from base set. Thus, it is hard to pre-serve the complete knowledge of base classes, which leads to overﬁtting and further decreases the detection scores.
To tackle these challenges, we proposed a new training framework, DiGeo, to make the best of both worlds for generalized few-shot object detection, i.e., improving gen-eralization on novel classes without hurting the detection of base classes. Our motivation is to learn Discriminative
Geometry-aware features via inter-class separation and intra-class compactness. For inter-class separation, we ex-pect the class centers [53] to be well distinct from each other. Motivated by the symmetric geometry of simplex equiangular tight frame (ETF) [36], we proposed to use ETF as classiﬁer to guide the separation of features. To be spe-ciﬁc, we derive an ofﬂine ETF whose weights are maxi-mally & equivalently separated (i.e., independent from the training data distribution) and are assigned as ﬁxed centers for all classes. For intra-class compactness, we expect the features to be closed to the class centers for a clear deci-sion boundary. In practice, we add class-speciﬁc margins to output logits during training to push the features close to the class centers. The margins are based on instance dis-tribution prior and are then adaptively adjusted though self-distillation. Meanwhile, we consider the huge imbalance between base set and novel set, and up-sample the novel set to facilitate the feature extraction.
We validate the effectiveness of DiGeo under the GF-SOD setting on Pascal VOC [3, 4] and MS COCO [27].
Compared to existing methods, we can both achieve pre-cise detection on base classes and sufﬁciently improve the adaptation efﬁciency on novel classes using a single model.
Furthermore, our DiGeo can be intuitively extended to long-tailed object detection. Experimental results on LVIS datasets demonstrate the generalizibility of our approach.
Our contributions are summarized as follows:
• We revisit few-shot object detection from a perspective of discriminative feature learning, and point out that exist-ing methods fail in knowledge adaptation to novel classes and suffer from knowledge forgetting of base classes.
• We propose DiGeo to pursue an desired feature geom-etry, i.e., inter-class separation and intra-class compact-ness, which consistently improves the performance on both base and novel classes.
• We conduct extensive experiments on three benchmark datasets for few-shot object detection and long-tailed ob-ject detection to verify the generalizability of DiGeo. 2.