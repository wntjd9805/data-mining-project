Abstract
The success of existing multi-view clustering relies on the assumption of sample integrity across multiple views.
However, in real-world scenarios, samples of multi-view are partially available due to data corruption or sensor failure, which leads to incomplete multi-view clustering study (IMVC). Although several attempts have been pro-posed to address IMVC, they suffer from the following draw-backs: i) Existing methods mainly adopt cross-view con-trastive learning forcing the representations of each sam-ple across views to be exactly the same, which might ig-nore view discrepancy and flexibility in representations; ii)
Due to the absence of non-observed samples across mul-tiple views, the obtained prototypes of clusters might be unaligned and biased, leading to incorrect fusion. To ad-dress the above issues, we propose a Cross-view Partial
Sample and Prototype Alignment Network (CPSPAN) for
Deep Incomplete Multi-view Clustering. Firstly, unlike ex-isting contrastive-based methods, we adopt pair-observed data alignment as ’proxy supervised signals’ to guide instance-to-instance correspondence construction among views. Then, regarding of the shifted prototypes in IMVC, we further propose a prototype alignment module to achieve incomplete distribution calibration across views. Exten-sive experimental results showcase the effectiveness of our proposed modules, attaining noteworthy performance im-provements when compared to existing IMVC competitors on benchmark datasets. 1.

Introduction
In modern society, data collected for real-world appli-cations usually stems from different domains, sensors or feature extractors, which gives rise to multi-view learning in literature [2, 44]. For instance, an autonomous car may have diverse sensors, and a movie is typically made up of images and audio. As an important paradigm of multi-view
*Corresponding author learning, multi-view clustering (MVC) [10,20,21,24,40,47] divides data by exploiting the consistent and complemen-tary information across multiple views. The success of ex-isting multi-view clustering methods heavily relies on the fully-available data assumption. However, in practical ap-plications, some views of instances are only partially avail-able due to unstable sensors and damaged storage media.
When some views are missing [9], the natural alignment property of same instances across multiple views is de-stroyed, which may result in insufficient mining of comple-mentary and consistent information. To handle the incom-pleteness issue, many incomplete multi-view clustering al-gorithms (IMVC) [15,31,38] with satisfactory performance have been proposed. Typical strategies are mainly based on matrix decomposition, incomplete multiple kernel learning and graph-based methods. Learning more discriminative consensus representations with incomplete view informa-tion is crucial to achieve better incomplete multi-view clus-tering performance. However, conventional IMVC methods are based on raw features and therefore, the performance heavily relies on the feature quality.
As deep neural networks [5,8,16,17,25,43] have demon-strated superior performance in learning high-level repre-sentations, deep learning has become prevalent in various fields of computer vision and pattern classification. To this end, researchers have explored combining deep neu-ral networks [26, 35] and conventional IMVC methods to improve clustering performance, and the resulting cluster-ing method is called Deep Incomplete Multi-View Cluster-ing (DIMVC) [11, 30, 37, 39, 42]. Most existing DIMVC methods adopt the principle of contrastive learning, treat-ing different views of the same sample as positive pairs and their representations should be consistent. Such algorithms ignore the cross-view alignment correlation of samples and force instances of different views with unified representa-tion, which may destroy the flexibility and variety of rep-resentations. We argue that the essence of IMVC task lies in discovering structural correspondence between different views, rather than rigidly and simply enforcing uniform rep-In fact, IMVC can be re-resentations across each view.
garded as a special case of ’partially-aligned’ multi-view setting, where the pair-observed data provides supervised instance-alignment signals.
Moreover, as shown in the Fig. 1, the distribution learned from the incomplete multi-view data can be biased due to inadequate multi-view data. Specifically, during the clus-tering task, flexible representations may cause prototypes of each cluster to shift and become biased, which we re-fer to as the Prototype-Shifted Problem (termed PSP). Such a problem has been demonstrated in the Anchor-Unaligned
Problem [32] for complete multi-view data, and undoubt-edly has more essential impact on incomplete multi-view data. At the same time, contrastive-based DIMVC methods neglect this issue and do not explore relationships among different instances within the same view, which may further aggravate PSP. Therefore, it is necessary to match the rela-tionship between the prototypes among views and perform clustering task accordingly.
To address the aforementioned issues, we propose a novel approach termed Cross-view Partial Sample and
Prototype Alignment Network (CPSPAN) for Deep Incom-plete Multi-view Clustering to perform cross-view partial sample alignment and solve the prototype-shifted problem.
The framework of CPSPAN is illustrated in Fig. 3. In de-tail, different from the contrastive learning mode, the cross-view instance alignment module establishes the view-to-view correspondence of samples through the pair-observed data in Fig. 2 between each pair-wise views, so as to mine the structural information between views. Afterwards, to address the prototype-shifted problem in incomplete sce-nario, the prototype alignment module takes one view’s prototype set as anchors, and solves the permutation ma-trix between the two sets of prototypes, thereby establish-ing prototype-to-prototype correspondence based on opti-mal transport theory. Since prototypes are obtained based on samples, this module not only calibrates correspon-dences between cross-view shifted prototypes but also en-codes the relationships between within-view samples. Ul-timately, since our model is imputation-free upfront, in or-der to align the embeddings between views before finally performing feature fusion and clustering, we build cross-view structural relationship transfer for missing item impu-tations.
We summarize the major contributions of our work as follows,
• We propose a novel deep network to handle IMVC task, termed as CPSPAN. Differ from existing multi-view contrastive learning manner, we considers the
IMVC from a novel insight with partially-aligned set-ting. To this end, CPSPAN optimal maximizes match-ing alignment between paired-observed data and con-struct cross-view intersection.
Figure 1. An example illustration of shifted prototype across multi-view caused by incomplete setting. With different missing status, the prototypes learned by incomplete multi-view data may be shifted and leads to wrong correspondences.
• In order to solve the Prototype-Shifted Problem caused by incomplete information, CPSPAN proposes to fur-ther align the prototype sets between different views, so as to mine consistent cross-view structural informa-tion.
• Extensive experiments have clearly demonstrated the effectiveness of the proposed cross-view partial sample and prototype alignment modules and the superiority over both conventional and deep SOTA methods. 2.