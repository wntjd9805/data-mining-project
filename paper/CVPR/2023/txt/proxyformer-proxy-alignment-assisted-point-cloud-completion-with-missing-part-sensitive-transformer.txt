Abstract
Problems such as equipment defects or limited view-points will lead the captured point clouds to be incomplete.
Therefore, recovering the complete point clouds from the partial ones plays an vital role in many practical tasks, and one of the keys lies in the prediction of the missing part. In this paper, we propose a novel point cloud completion ap-proach namely ProxyFormer that divides point clouds into existing (input) and missing (to be predicted) parts and each part communicates information through its proxies. Specif-ically, we fuse information into point proxy via feature and position extractor, and generate features for missing point proxies from the features of existing point proxies. Then, in order to better perceive the position of missing points, we design a missing part sensitive transformer, which con-verts random normal distribution into reasonable position information, and uses proxy alignment to refine the missing proxies. It makes the predicted point proxies more sensitive to the features and positions of the missing part, and thus makes these proxies more suitable for subsequent coarse-to-fine processes. Experimental results show that our method outperforms state-of-the-art completion networks on sev-eral benchmark datasets and has the fastest inference speed. 1.

Introduction 3D data is used in many different fields, including autonomous driving, robotics, remote sensing, and more
[5, 12, 14, 17, 43]. Point cloud has a very uniform struc-ture, which avoids the irregularity and complexity of com-position. However, in practical applications, due to the oc-clusion of objects, the difference in the reflectivity of the target surface material, and the limitation of the resolution and viewing angle of the visual sensor, the collected point cloud data is often incomplete. The resultant missing geo-metric and semantic information will affect the subsequent 3D tasks [26]. Therefore, how to use a limited amount of in-*Corresponding author.
Figure 1. Visual comparison of point cloud completion results.
Compared with GRNet [38] and PoinTr [41]. ProxyFormer com-pletely retains the partial input (blue bounding box) and restores the missing part with details (purple bounding box). complete data to complete point cloud and restore the orig-inal shape has become a hot research topic, and is of great significance to downstream tasks [3, 4, 10, 19, 34, 39].
With the great success of PointNet [23] and PointNet++
[24], direct processing of 3D coordinates has become a mainstream method for point cloud analysis.
In recent years, there have been many point cloud completion meth-ods [1, 11, 37, 38, 41, 42, 48], and the emergence of these networks has also greatly promoted the development of this area. Many methods [1, 38, 42] adopt the common encoder-decoder structure, which usually get global feature from the incomplete input by pooling operation and map this feature back to the point space to obtain a complete one. This kind of feature can predict the approximate shape of the complete point cloud. However, there are two drawbacks: (1) The global feature is extracted from partial input and thus lack the ability to represent the details of the missing part; (2)
These methods discard the original incomplete point cloud and regenerate the complete shape after extracting features, which will cause the shape of the original part to deform
to a certain extent. Methods like [11, 41] attempt to predict the missing part separately, but they do not consider the fea-ture connection between the existing and the missing parts, which are still not ideal solutions to the first drawback. The results of GRNet [38] and PoinTr [41] in Fig. 1 illustrate the existence of these problems. GRNet failed to keep the ring on the light stand while PoinTr incorrectly predicted the straight edge of the lampshade as a curved edge. Be-sides, some methods [16, 37, 41, 48] are based on the trans-former structure and use the attention mechanism for fea-ture correlation calculation. However, this also brings up two other problems: (3) In addition to the feature, the po-sition encoding also has a great influence on the effect of the transformer. Existing transformer-based methods, ei-ther directly using 3D coordinates [9, 48] or using MLP to upscale the coordinates [37,41], the position information of the point cloud cannot be well represented; (4) It also leads to the problem of excessive parameters or calculation. Fur-thermore, we also note that most of the current supervised methods do not make full use of the known data. During the training process, the point cloud data we can obtain includes incomplete input and Ground Truth (GT). This pair of data can indeed undertake the point cloud completion task well, but in fact, we can obtain a new data through these two data, that is, the missing part of the point cloud, so as to increase our prior knowledge.
In order to solve the above-mentioned problems, we pro-pose a novel point cloud completion network dubbed Prox-yFormer, which completely preserves the incomplete input and has better detail recovery capability as shown in Fig. 1. Firstly, we design a feature and position extractor to convert the point cloud to proxies, with a particular atten-tion to the representation of point position. Then, we let the proxies of the partial input interact with the generated missing part proxies through a newly proposed missing part sensitive transformer, instead of using the global feature ex-tracted from incomplete input alone as in prior methods.
After mapping proxies back to the point space, we splice it with the incomplete input points to 100% preserve the orig-inal data. During training, we use the true missing part of the point cloud to increase prior knowledge and for predic-tion error refinement. Overall, the main contributions of our work are as follows:
• We design a Missing Part Sensitive Transformer, which focuses on the geometry structure and details of the missing part. We also propose a new position encoding method that aggregates both the coordinates and features from neighboring points.
• We introduce Proxy Alignment into the training pro-cess. We convert the true missing part into proxies, which are used to enhance the prior knowledge while refining the predicted missing proxies.
• Our proposed method ProxyFormer discards the trans-former decoder adopted in most transformer based completion methods such as PointTr, which achieves
SOTA performance compared to various baselines while having considerably few parameters and the fastest inference speed in terms of GFLOPs. 2.