Abstract
Learned image compression (LIC) methods have exhib-ited promising progress and superior rate-distortion per-formance compared with classical image compression stan-dards. Most existing LIC methods are Convolutional Neural
Networks-based (CNN-based) or Transformer-based, which have different advantages. Exploiting both advantages is a point worth exploring, which has two challenges: 1) how to effectively fuse the two methods? 2) how to achieve higher performance with a suitable complexity? In this pa-per, we propose an efficient parallel Transformer-CNN Mix-ture (TCM) block with a controllable complexity to incor-porate the local modeling ability of CNN and the non-local modeling ability of transformers to improve the overall ar-chitecture of image compression models. Besides, inspired by the recent progress of entropy estimation models and at-tention modules, we propose a channel-wise entropy model with parameter-efficient swin-transformer-based attention (SWAtten) modules by using channel squeezing. Experi-mental results demonstrate our proposed method achieves state-of-the-art rate-distortion performances on three dif-ferent resolution datasets (i.e., Kodak, Tecnick, CLIC Pro-fessional Validation) compared to existing LIC methods.
The code is at https://github.com/jmliu206/
LIC_TCM . 1.

Introduction
Image compression is a crucial topic in the field of im-age processing. With the rapidly increasing image data, lossy image compression plays an important role in storing and transmitting efficiently. In the passing decades, there were many classical standards, including JPEG [31], WebP
[11], and VVC [29], which contain three steps: transform, quantization, and entropy coding, have achieved impres-sive Rate-Distortion (RD) performance. On the other hand, different from the classical standards, end-to-end learned
*Heming Sun is the corresponding author.
Figure 1. Visualization of decompressed images of kodim23 from
Kodak dataset based on different methods (The subfigure is titled as “Method|Bit rate|PSNR|MS-SSIM”). image compression (LIC) is optimized as a whole. Some very recent LIC works [5, 13, 32, 34, 36, 37] have outper-formed VVC which is the best classical image and video coding standards at present, on both Peak signal-to-noise ratio (PSNR) and Multi-Scale Structural Similarity (MS-SSIM). This suggests that LIC has great potential for next-generation image compression techniques.
Most LIC methods are CNN-based methods [6, 10, 20, 21, 33] using the variational auto-encoder (VAE) which is proposed by Ball´e et al. [3]. With the development of vision transformers [9,22] recently, some vision transformer-based
LIC methods [23, 36, 37] are also investigated. For CNN-based example, Cheng et al. [6] proposed a residual block-based image compression model. For transformer-based ex-ample, Zou et al. [37] tried a swin-transformer-based image compression model. These two kinds of methods have dif-ferent advantages. CNN has the ability of local modeling, while transformers have the ability to model non-local in-formation. It is still worth exploring whether the advantages of these two methods can be effectively combined with a suitable complexity.
In our method, we try to efficiently incorporate both advantages of CNN and transformers by proposing an efficient parallel Transformer-CNN Mixture (TCM) block under a controllable complexity to improve
the RD performance of LIC.
In addition to the type of the neural network, the design of entropy model is also an important technique in LIC.
The most common way is to introduce extra latent variables as hyper-prior to convert the probability model of compact coding-symbols to a joint model [3]. On that basis, many methods spring up. Minnen et al. [26] utilized the masked convolutional layer to capture the context information. Fur-thermore, they [27] proposed a parallel channel-wise auto-regressive entropy model by splitting the latent to 10 slices.
The results of encoded slices can assist in the encoding of remaining slices in a pipeline manner.
Recently, many different attention modules [6, 21, 37] were designed and proposed to improve image compres-sion. Attention modules can help the learned model pay more attention to complex regions. However, many of them are time-consuming, or can only capture local informa-tion [37]. At the same time, these attention modules are usually placed in both the main and the hyper-prior path of image compression network, which will further intro-duce large complexity because of a large input size for the main path. To overcome that problem, we try to move at-tention modules to the channel-wise entropy model which has 1/16 input size compared with that of main path to re-duce complexity. Nevertheless, if the above attention mod-ules are directly added to the entropy model, a large num-ber of parameters will be introduced. Therefore, we pro-pose a parameter-efficient swin-transformer-based attention module (SWAtten) with channel squeezing for the channel-wise entropy model. At the same time, to avoid the latency caused by too many slices, we reduce the number of slices from 10 to 5 to achieve the balance between running speed and RD-performance. As Fig. 1 shows, our method can get pleasant results compared with other methods.
The contributions of this paper can be summarized as follows:
• We propose a LIC framework with parallel transformer-CNN mixture (TCM) blocks that ef-ficiently incorporate the local modeling ability of
CNN and the non-local modeling ability of transform-ers, while maintaining controllable complexity.
• We design a channel-wise auto-regressive entropy model by proposing a parameter-efficient swin-transformer-based attention (SWAtten) module with channel squeezing.
• Extensive experiments demonstrate that our approach achieves state-of-the-art (SOTA) performance on three datasets (i.e., Kodak, Tecnick, and CLIC datasets) with different resolutions. The method outperforms
VVC (VTM-12.1) by 12.30%, 13.71%, 11.85% in
Bjøntegaard-delta-rate (BD-rate) [4] on Kodak, Tec-nick, and CLIC datasets, respectively. 2.