Abstract
Automatic remote sensing tools can help inform many large-scale challenges such as disaster management, cli-mate change, etc. While a vast amount of spatio-temporal satellite image data is readily available, most of it remains unlabelled. Without labels, this data is not very useful for supervised learning algorithms. Self-supervised learning instead provides a way to learn effective representations for various downstream tasks without labels. In this work, we leverage characteristics unique to satellite images to learn better self-supervised features. Specifically, we use the tem-poral signal to contrast images with long-term and short-term differences, and we leverage the fact that satellite im-ages do not change frequently. Using these characteristics, we formulate a new loss contrastive loss called Change-Aware Contrastive (CACo) Loss. Further, we also present a novel method of sampling different geographical regions.
We show that leveraging these properties leads to better performance on diverse downstream tasks. For example, we see a 6.5% relative improvement for semantic segmenta-tion and an 8.5% relative improvement for change detection over the best-performing baseline with our method. 1.

Introduction
Our planet is surrounded by a large number of satellites constantly collecting images of the world. This massive trove of visual information can help monitor phenomena at the world-scale, and inform solutions to global problems such as climate change or loss of biodiversity. Automatic vision tools can help by, for example, monitoring land-use change over time [36] or the evolution of urban areas [6].
However, training all these models requires labeled data.
Unfortunately, labeling the massive trove of satellite images is expensive, more so than internet images because of the expertise necessary. This issue is exacerbated by the differ-ent label requirements of many monitoring applications.
One way to alleviate this problem of limited labeled data is to use self-supervised learning techniques to learn a good feature representation from unlabeled satellite im-Figure 1. Images of the same location at three different times.
Changes from 2016 to 2020 are due to major urban development, while those from July to September are seasonal variations. Our approach, CACo, learns features that are sensitive to the former but invariant to the latter. agery. This representation can then be further finetuned with much fewer labels for specific applications. Mod-ern self-supervised learning approaches are based on con-trastive learning. These techniques train a feature space so that each image in the dataset is embedded close to aug-mented versions of itself (e.g., with jittered colors) but far from other images of the dataset. A possible approach is to directly apply these techniques on satellite image datasets.
However, the spatio-temporal structure of satellite imagery is much richer than the unstructured collections of internet images typically used in standard self-supervised learning.
In this work, we ask, how can we best leverage the structure of satellite images for better self-supervised learning?
The first important aspect of the spatio-temporal struc-ture of satellite images is the availability of multiple temporally-spaced images for the same location. Past work has used this structure to sample images spread over a few weeks or months from each location to encourage invari-ance to seasonal variations [25]. However, we can access images not just over a few months, but over many years.
Over such long time spans, we often see significant, per-manent change, such as the construction of houses, the dry-ing of lakes, or the logging of forests (Fig. 1). While we want feature representations to be invariant to temporary, seasonal change, we want the representation to be sensitive to permanent, long-term change. To capture this intuition, we sample multiple images from the same location covering both short and long time spans and encourage invariance to the former but sensitivity to the latter.
A second and more important aspect of satellite images is that permanent change is spatially rare. Change is con-centrated near urban areas, but many parts of the planet see little change. When there is no change, we want our feature representation to be the same even over long time spans.
We capture this insight with a novel strategy to robustly estimate whether or not there is a long-term change, even in the middle of training, by comparing long-term feature differences to short-term variations. We then design a loss function that is conditional on this change estimate: it en-courages invariances to long-term differences depending on whether a change occurs or not. We call this novel loss function Change-aware Contrastive Loss (or CaCo).
The above loss function uses the temporal structure of satellite images. We can also utilize geographical struc-ture by carefully sampling the most informative locations on the planet. We provide an improvement over a previ-ously proposed geographical sampling [25]. We show that sampling closer to cities, and ignoring samples completely in the ocean can result in a dataset much more useful for learning a general representation for various downstream tasks. We evaluate our new representation on a diverse set of downstream tasks such as landcover classification, se-mantic segmentation, and change detection. Our method achieves significant relative improvements (ranging from 6.5% to 8.5%) over the state-of-the-art for a variety tasks such as segmentation and change detection.
To summarize, we make the following contributions:
• We propose a new self-supervised learning loss that uses long-term temporal information in satellite im-agery to encourage invariance to seasonal variations but sensitivity to permanent, long-term changes.
• We introduce a novel approach to robustly estimate whether a location has undergone significant change by comparing long-term changes to seasonal varia-tions. Our new change-aware loss function (CACo) uses this to decide when to encourage invariance.
• We use an improved geographical sampling that pro-vides more diverse data for representation learning. 2.