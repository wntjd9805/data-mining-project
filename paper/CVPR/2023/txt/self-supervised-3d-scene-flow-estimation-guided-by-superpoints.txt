Abstract 3D scene ﬂow estimation aims to estimate point-wise motions between two consecutive frames of point clouds.
Superpoints, i.e., points with similar geometric features, are usually employed to capture similar motions of local regions in 3D scenes for scene ﬂow estimation. However, in existing methods, superpoints are generated with the ofﬂine clustering methods, which cannot characterize local regions with similar motions for complex 3D scenes well, leading to inaccurate scene ﬂow estimation. To this end, we propose an iterative end-to-end superpoint based scene
ﬂow estimation framework, where the superpoints can be dynamically updated to guide the point-level ﬂow predic-tion. Speciﬁcally, our framework consists of a ﬂow guided superpoint generation module and a superpoint guided ﬂow reﬁnement module. In our superpoint generation module, we utilize the bidirectional ﬂow information at the previ-ous iteration to obtain the matching points of points and superpoint centers for soft point-to-superpoint association construction, in which the superpoints are generated for pairwise point clouds. With the generated superpoints, we ﬁrst reconstruct the ﬂow for each point by adaptively aggregating the superpoint-level ﬂow, and then encode the consistency between the reconstructed ﬂow of pairwise point clouds. Finally, we feed the consistency encod-ing along with the reconstructed ﬂow into GRU to reﬁne point-level ﬂow. Extensive experiments on several different datasets show that our method can achieve promising performance. Code is available at https://github. com/supersyq/SPFlowNet. 1.

Introduction
Scene ﬂow estimation is one of the vital components of numerous applications such as 3D reconstruction [10],
∗Corresponding authors
Yaqi Shen, Le Hui, Jin Xie, and Jian Yang are with PCA Lab,
Key Lab of Intelligent Perception and Systems for High-Dimensional
Information of Ministry of Education, and Jiangsu Key Lab of Image and
Video Understanding for Social Security, School of Computer Science and
Engineering, Nanjing University of Science and Technology, China.
Figure 1. Comparison with other clustering-based methods. (a) Other clustering based methods utilize ofﬂine clustering algorithms to split the point clouds into some ﬁxed superpoints for subsequent ﬂow reﬁnement, which is not learnable. (b)
Our method embeds the differentiable clustering (superpoint generation) into our pipeline and generates dynamic superpoints at each iteration. We visualize part of the scene in FlyingThings3D
[38] for better visualization. Different colors indicate different superpoints and red lines indicate the ground truth ﬂow. autonomous driving [37], and motion segmentation [2].
Estimating scene ﬂow from stereo videos and RGB-D images has been studied for many years [17, 19]. Recently, with the rapid development of 3D sensors, estimating scene
ﬂow from two consecutive point clouds has receiving more and more attention. However, due to the irregularity and sparsity of point clouds, scene ﬂow estimation from point clouds is still a challenging problem in real scenes.
In recent years, many 3D scene ﬂow estimation methods have been proposed [11, 34, 37, 56, 57, 59]. Most of these methods [34, 56] rely on dense ground truth scene
ﬂow as supervision for model training. However, col-lecting point-wise scene ﬂow annotations is expensive and time-consuming. To avoid the expensive point-level an-notations, some efforts have been dedicated to weakly-supervised and self-supervised scene ﬂow estimation [9, 23, 46, 60]. For example, both Rigid3DSceneFlow [9] and LiDARSceneFlow [7] propose a weakly-supervised scene ﬂow estimation framework, which only take the ego-motion and background masks as inputs. Especially, they utilize the DBSCAN clustering algorithm [8] to segment the foreground points into local regions with ﬂow rigid-ity constraints.
In addition, RigidFlow [31] ﬁrst utilizes the off-line oversegmentation method [32] to decompose the source point clouds into some ﬁxed supervoxels, and then estimates the rigid transformations for supervoxels as pseudo scene ﬂow labels for model training. In summary, these clustering based methods utilize ofﬂine clustering algorithms with hand-crafted features (i.e., coordinates and normals) to generate the superpoints and use the consistent
ﬂow constraints on these ﬁxed superpoints for scene ﬂow estimation. However, for some complex scenes, the ofﬂine clustering methods may cluster points with different ﬂow patterns into the same superpoints. Figure 1(a) shows that
[32] falsely clusters points with the entirely different ﬂow into the same superpoint colored in purple (highlighted by the dotted circle). Thus, applying ﬂow constraints to the incorrect and ﬁxed superpoints for ﬂow estimation will mislead the model to generate false ﬂow results.
To address this issue, we propose an iterative end-to-end superpoint guided scene ﬂow estimation framework (dubbed as “SPFlowNet”), which consists of an online su-perpoint generation module and a ﬂow reﬁnement module.
Our pipeline jointly optimizes the ﬂow guided superpoint generation and superpoint guided ﬂow reﬁnement for more accurate ﬂow prediction (Figure 1(b)). Speciﬁcally, we
ﬁrst utilize farthest point sampling (FPS) to obtain the initial superpoint centers, including the coordinate, ﬂow, and feature information. Then, we use the superpoint-level and point-level ﬂow information in the previous iteration to obtain the matching points of points and superpoint centers.
With the pairs of points and superpoint centers, we can learn the soft point-to-superpoint association map. And we utilize the association map to adaptively aggregate the coordinates, features, and ﬂow values of points for superpoint center updating. Next, based on the updated superpoint-wise
ﬂow values, we reconstruct the ﬂow of each point via the generated association map. Furthermore, we encode the consistency between the reconstructed ﬂow of pairwise point clouds. Finally, we feed the reconstructed ﬂow along with the consistency encoding into a gated recurrent unit to reﬁne the point-level ﬂow. Extensive experiments on several benchmarks show that our approach achieves state-of-the-art performance.
Our main contributions are summarized as follows:
• We propose a novel end-to-end self-supervised scene
ﬂow estimation framework, which iteratively gener-ates dynamic superpoints with similar ﬂow patterns and reﬁnes the point-level ﬂow with the superpoints.
• Different from other ofﬂine clustering based methods, we embed the online clustering into our model to dynamically segment point clouds with the guidance from pseudo ﬂow labels generated at the last iteration.
• A superpoint guided ﬂow reﬁnement layer is intro-duced to reﬁne the point-wise ﬂow with superpoint-level ﬂow information, where the superpoint-wise ﬂow patterns are adaptively aggregated into the point-level with the learned association map.
• Our self-supervised scene ﬂow estimation method out-performs state-of-the-art methods by a large margin. 2.