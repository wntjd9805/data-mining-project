Abstract
Recent advances in modeling 3D objects mostly rely on synthetic datasets due to the lack of large-scale real-scanned 3D databases. To facilitate the development of 3D perception, reconstruction, and generation in the real world, we propose OmniObject3D, a large vocabulary 3D object dataset with massive high-quality real-scanned 3D objects. OmniObject3D has several appealing properties: 1) Large Vocabulary: It comprises 6,000 scanned objects in 190 daily categories, sharing common classes with pop-ular 2D datasets (e.g., ImageNet and LVIS), benefiting the pursuit of generalizable 3D representations. 2) Rich An-notations: Each 3D object is captured with both 2D and (cid:66)Corresponding authors. https://omniobject3d.github.io/ 3D sensors, providing textured meshes, point clouds, multi-view rendered images, and multiple real-captured videos. 3)
Realistic Scans: The professional scanners support high-quality object scans with precise shapes and realistic ap-pearances. With the vast exploration space offered by Om-niObject3D, we carefully set up four evaluation tracks: a) robust 3D perception, b) novel-view synthesis, c) neural sur-face reconstruction, and d) 3D object generation. Extensive studies are performed on these four benchmarks, revealing new observations, challenges, and opportunities for future research in realistic 3D vision. 1.

Introduction
Sensing, understanding, and synthesizing realistic 3D objects is a long-standing problem in computer vision, with
rapid progress emerging in recent years. However, a major-ity of the technical approaches rely on unrealistic synthetic datasets [6, 19, 64] due to the absence of a large-scale real-world 3D object database. However, the appearance and distribution gaps between synthetic and real data cannot be compensated for trivially, hindering their real-life applica-tions. Therefore, it is imperative to equip the community with a large-scale and high-quality 3D object dataset from the real world, which can facilitate a variety of 3D vision tasks and downstream applications.
Recent advances partially fulfill the requirements while still being unsatisfactory. As shown in Table 1, CO3D [48] contains 19k videos capturing objects from 50 MS-COCO categories, while only 20% of the videos are annotated with accurate point clouds reconstructed by COLMAP [50].
Moreover, they do not provide textured meshes. GSO [16] has 1k scanned objects while covering only 17 household classes. AKB-48 [33] focuses on robotics manipulation with 2k articulated object scans in 48 categories, but the focus on articulation leads to a relatively narrow semantic distribution, failing to support general 3D object research.
To boost the research on general 3D object understand-ing and modeling, we present OmniObject3D: a large-vocabulary 3D object dataset with massive high-quality, real-scanned 3D objects. Our dataset has several appealing properties: 1) Large Vocabulary: It contains 6,000 high-quality textured meshes scanned from real-world objects, which, to the best of our knowledge, is the largest among real-world 3D object datasets with accurate 3D meshes. It comprises 190 daily categories, sharing common classes with popular 2D and 3D datasets (e.g., ImageNet [15],
LVIS [25], and ShapeNet [6]), incorporating most daily object realms (See Figure 1 and Figure 2). 2) Rich An-notations: Each 3D object is captured with both 2D and 3D sensors, providing textured 3D meshes, sampled point clouds, posed multi-view images rendered by Blender [13], and real-captured video frames with foreground masks and
COLMAP camera poses. 3) Realistic Scans: The object scans are of high fidelity thanks to the professional scan-ners, bearing precise shapes with geometric details and re-alistic appearance with high-frequency textures.
Taking advantage of the vast exploration space offered by OmniObject3D, we carefully set up four evaluation tracks: a) robust 3D perception, b) novel-view synthesis, c) neural surface reconstruction, and d) 3D object genera-tion. Extensive studies are performed on these benchmarks:
First, the high-quality, real-world point clouds in OmniOb-ject3D allow us to perform robust 3D perception analysis on both out-of-distribution (OOD) styles and corruptions, two major challenges in point cloud OOD generalization.
Furthermore, we provide massive 3D models with multi-view images and precise 3D meshes for novel-view syn-thesis and neural surface reconstruction. The broad diver-Table 1. A comparison between OmniObject3D and other commonly-used 3D object datasets. Rlvis denotes the ratio of the 1.2k LVIS [25] categories being covered.
Dataset
Real Full Mesh Video
# Objs
# Cats Rlvis (%)
ShapeNet [6]
ModelNet [64] 3D-Future [19]
ABO [12]
Toys4K [53]
CO3D V1 / V2 [48] ✓
✓
DTU [1]
ScanObjectNN [56] ✓
✓
GSO [16]
✓
AKB-48 [33]
✓
Ours
✓
✓
✓
✓
✓
✓
✓
✓
✓ 51k 12k 16k 8k 4k
✓ 19 / 40k 124 15k 1k 2k 6k
✓ 55 40 34 63 105 50
NA 15 17 48 190 4.1 2.4 1.3 3.5 7.7 4.2 0 1.3 0.9 1.8 10.8 sity in shapes and textures offers a comprehensive training and evaluation source for both scene-specific and general-izable algorithms. Finally, we equip the community with a database for large vocabulary and realistic 3D object gener-ation, which pushes the boundary of existing state-of-the-art generation methods to real-world 3D objects. The four benchmarks reveal new observations, challenges, and op-portunities for future research in realistic 3D vision. 2.