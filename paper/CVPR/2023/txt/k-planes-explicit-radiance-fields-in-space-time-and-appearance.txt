Abstract 1.

Introduction 2
We introduce k-planes, a white-box model for radiance fields in arbitrary dimensions. Our model uses (cid:0)d (cid:1) (“d-choose-2”) planes to represent a d-dimensional scene, pro-viding a seamless way to go from static (d = 3) to dynamic (d = 4) scenes. This planar factorization makes adding dimension-specific priors easy, e.g. temporal smoothness and multi-resolution spatial structure, and induces a nat-ural decomposition of static and dynamic components of a scene. We use a linear feature decoder with a learned color basis that yields similar performance as a nonlinear black-box MLP decoder. Across a range of synthetic and real, static and dynamic, fixed and varying appearance scenes, k-planes yields competitive and often state-of-the-art recon-struction fidelity with low memory usage, achieving 1000x compression over a full 4D grid, and fast optimization with a pure PyTorch implementation. For video results and code, please see sarafridov.github.io/K-Planes.
* equal contribution
Recent interest in dynamic radiance fields demands rep-resentations of 4D volumes. However, storing a 4D vol-ume directly is prohibitively expensive due to the curse of dimensionality. Several approaches have been proposed to factorize 3D volumes for static radiance fields, but these do not easily extend to higher dimensional volumes.
We propose a factorization of 4D volumes that is simple, interpretable, compact, and yields fast training and render-ing. Specifically, we use six planes to represent a 4D vol-ume, where the first three represent space and the last three represent space-time changes, as illustrated in Fig. 1(d).
This decomposition of space and space-time makes our model interpretable, i.e. dynamic objects are clearly visible in the space-time planes, whereas static objects only appear in the space planes. This interpretability enables dimension-specific priors in time and space.
More generally, our approach yields a straightforward, prescriptive way to select a factorization of any dimension with 2D planes. For a d-dimensional space, we use k = (cid:0)d (cid:1) 2 (“d-choose-2”) k-planes, which represent every pair of di-2 2 (cid:1) = 6 hex-mensions — for example, our model uses (cid:0)4 planes in 4D and reduces to (cid:0)3 (cid:1) = 3 tri-planes in 3D.
Choosing any other set of planes would entail either using more than k planes and thus occupying unnecessary mem-ory, or using fewer planes and thereby forfeiting the ability to represent some potential interaction between two of the d dimensions. We call our model k-planes; Fig. 1 illustrates its natural application to both static and dynamic scenes.
Most radiance field models entail some black-box com-ponents with their use of MLPs. Instead, we seek a simple model whose functioning can be inspected and understood.
We find two design choices to be fundamental in allowing k-planes to be a white-box model while maintaining recon-struction quality competitive with or better than previous black-box models [15, 27]: (1) Features from our k-planes are multiplied together rather than added, as was done in prior work [5, 6], and (2) our linear feature decoder uses a learned basis for view-dependent color, enabling greater adaptivity including the ability to model scenes with vari-able appearance. We show that an MLP decoder can be re-placed with this linear feature decoder only when the planes are multiplied, suggesting that the former is involved in both view-dependent color and determining spatial structure.
Our factorization of 4D volumes into 2D planes leads to a high compression level without relying on MLPs, using 200 MB to represent a 4D volume whose direct represen-tation at the same resolution would require more than 300
GB, a compression rate of three orders of magnitude. Fur-thermore, despite not using any custom CUDA kernels, k-planes trains orders of magnitude faster than prior implicit models and on par with concurrent hybrid models.
In summary, we present the first white-box, interpretable model capable of representing radiance fields in arbi-trary dimensions, including static scenes, dynamic scenes, and scenes with variable appearance. Our k-planes model achieves competitive performance across reconstruction quality, model size, and optimization time across these var-ied tasks, without any custom CUDA kernels. 2.