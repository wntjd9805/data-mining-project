Abstract
We present a novel method for recovering the absolute pose and shape of a human in a pre-scanned scene given a single image. Unlike previous methods that perform scene-aware mesh optimization, we propose to first estimate ab-solute position and dense scene contacts with a sparse 3D
CNN, and later enhance a pretrained human mesh recovery network by cross-attention with the derived 3D scene cues.
Joint learning on images and scene geometry enables our method to reduce the ambiguity caused by depth and oc-clusion, resulting in more reasonable global postures and contacts. Encoding scene-aware cues in the network also allows the proposed method to be optimization-free, and opens up the opportunity for real-time applications. The ex-periments show that the proposed network is capable of re-covering accurate and physically-plausible meshes by a sin-gle forward pass and outperforms state-of-the-art methods in terms of both accuracy and speed. Code is available on our project page: https://zju3dv.github.io/sahmr/. 1.

Introduction
Monocular human mesh recovery (HMR), i.e., estimat-ing pose and shape parameters of a parametric human model from a single image, has gained significant atten-tion in recent years. To better capture and understand hu-man behaviors, many recent works [1–5] propose to ad-dress the problem of scene-aware HMR which involves human-scene interaction constraints when recovering hu-man meshes, given the 3D geometry of the scene scanned by range sensors [5–7], as well as the camera pose of the input image relative to the scene, which may enable more applications in video surveillance, household robots, and motion analysis in gyms and clinics.
Most existing methods propose using scene-aware opti-mization to fit the human mesh into a pre-scanned scene.
They optimize a parametric human model iteratively, e.g.,
†Corresponding author.
Figure 1. Comparison between the optimization-based method and the proposed method. Optimization-based methods typi-cally fit a parametric human model iteratively by minimizing 2D reprojection error and scene conflicts. In contrast, the proposed method utilizes a single forward pass of the network to estimate the global position (blue ball), contact scene points (colored scene points), and a scene-aware human mesh. This design leads to im-provements in both efficiency and accuracy.
SMPL [8], to minimize scene penetration, chamfer distance of contact regions, and the 3D-2D re-projection error. How-ever, optimization tends to be slow at inference time and is sensitive to initialization and hyperparameters, failing to re-spond in low-latency applications. As illustrated in Fig. 1, an optimization-based method PROX [5] takes 18.4s to fit a human model into the scene, while the incorrect position and pose still occur.
Recent works [9–13] propose to recover human mesh with neural networks trained on large-scale datasets [14– 17]. Specifically, the networks learn a mapping from an input image to a human mesh in the canonical coordi-nates. Applying these methods in the scene-aware HMR
task still requires post-processing optimization, where the global translation and the human poses are refined in accor-dance with the given scene. However, the monocular pre-diction is conditioned on the input image solely, omitting the joint distribution of human pose and scene geometry, and therefore tends to suffer from depth ambiguity and oc-clusion. As a result, the optimization-based post-processing could be easily deteriorated by the erroneous initial poses and may even worsen the initial prediction.
In this work, we propose a Scene-Aware Human Mesh
Recovery network (SA-HMR), the first learning-based ap-proach that predicts the absolute position and mesh of a human in the scene by a single forward pass. The overall pipeline is illustrated in Fig. 2. Given the input image and scene point cloud, we first use a sparse 3D CNN to estimate dense scene contacts and absolute human position, where the scene contact estimation is treated as a point cloud la-beling task, and the human position prediction is presented as a voting vector field refinement task. The predicted dense contact points are centered by the human position and passed to a scene network in the human mesh recovery step.
Specifically, we enhance a pretrained monocular HMR net-work METRO [12] by cross-attention with the proposed scene network in parallel. In this way, SA-HMR learns a joint distribution of human pose and scene geometry, result-ing in more reasonable postures, contacts, and global posi-tions, as illustrated in Fig. 1. Learning scene-aware cues in the network also avoids scene-aware optimization as post-processing and achieves fast inference speed.
We evaluate the proposed method on the RICH [6] and
PROX [5] datasets of indoor and outdoor scenes. The ex-perimental results show that SA-HMR is not only effective in recovering absolute positions and meshes that are in ac-cordance with the given scene, but also significantly faster than the optimization-based baselines.
In summary, we make the following contributions:
• The first optimization-free framework for scene-aware human mesh recovery from a single image and a pre-scanned scene.
• The cross-attention design for enhancing a pretrained
HMR network with a parallel scene network, enabling joint learning on the human pose and scene geometry.
• Superior performance compared to optimization-based baselines in terms of both accuracy and speed. 2.