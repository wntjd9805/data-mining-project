Abstract
Neural scene representations have achieved great suc-cess in parameterizing and reconstructing images, but cur-rent state of the art models are not optimized with the preservation of physical quantities in mind. While current architectures can reconstruct color images correctly, they create artifacts when trying to fit maps of polar quanti-ties. We propose polarimetric coordinate networks (pCON), a new model architecture for neural scene representations aimed at preserving polarimetric information while accu-rately parameterizing the scene. Our model removes arti-facts created by current coordinate network architectures when reconstructing three polarimetric quantities of inter-est. All code and data can be found at this link: https:
//visual.ee.ucla.edu/pcon.htm. 1.

Introduction
Neural scene representations are a popular and useful tool in many computer vision tasks, but these models are optimized to preserve visual content, not physical informa-tion. Current state-of-the-art models create artifacts due to the presence of a large range of spatial frequencies when re-constructing polarimetric data. Many tasks in polarimetric imaging rely on precise measurements, and thus even small artifacts are a hindrance for downstream tasks that would like to leverage neural reconstructions of polarization im-ages. In this work we present pCON, a new architecture for neural scene representations. pCON leverages images’ sin-gular value decompositions to effectively allocate network capacity to learning the more difficult spatial frequencies at each pixel. Our model reconstructs polarimetric images without the artifacts introduced by state-of-the-art models.
The polarization of light passing through a scene con-tains a wealth of information, and while current neural rep-resentations can represent single images accurately, but they produce noticeable visual artifacts when trying to represent
*Equal contribution. multiple polarimetric quantities concurrently.
We propose a new architecture for neural scene repre-sentations that can effectively reconstruct polarimetric im-ages without artifacts. Our model reconstructs color images accurately while also ensuring the quality of three impor-tant polarimetric quantities, the degree (ρ) and angle (ϕ) of linear polarization (DoLP and AoLP), and the unpolarized intensity Iun. This information is generally captured using images of a scene taken through linear polarizing filters at four different angles. Instead of learning a representation of these images, our model operates directly on the DoLP,
AoLP and unpolarized intensity maps. When learning to fit these images, current coordinate network architectures produce artifacts in the predicted DoLP and unpolarized in-tensity maps. To alleviate this issue, we take inspiration from traditional image compression techniques and fit im-ages using their singular value decompositions. Images can be compressed by reconstructing them using only a subset of their singular values [28]. By utilizing different, non-overlapping sets of singular values to reconstruct an image, the original image can be recovered by summing the indi-vidual reconstructions together. Our model is supervised in a coarse-to-fine manner, which helps the model to represent both the low and and high frequency details present in maps of polarimetric quantities without introducint noise or tiling artifacts. A demonstration of the efficacy our model can be seen in Fig. 1 and Table 1. Furthermore, our model is capa-ble of representing images at varying levels of detail, creat-ing a tradeoff between performance and model size without retraining. 1.1. Contributions
To summarize, the contributions of our work include:
• a coordinate network architecture for neural scene rep-resentations of polarimetric images;
• a training strategy for our network which learns a se-ries of representations using different sets of singular values, allowing for a trade-off between performance and model size without retraining;
GT
SIREN [52]
ACORN [34]
ReLU P.E
Ours
Figure 1. Our model reconstructs the training scene more accurately than other architectures. Our model does not have the noise pattern present in reconstructions from SIREN [52] or a ReLU MLP with positional encoding [38], nor does it show tiling artifacts as in
ACORN’s [34] prediction.
• results demonstrating that our model reconstructs maps of polarimetric quantities without the artifacts created by current state-of-the-art approaches. 2.