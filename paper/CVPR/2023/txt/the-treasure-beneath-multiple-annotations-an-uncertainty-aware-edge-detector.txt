Abstract
Deep learning-based edge detectors heavily rely on pixel-wise labels which are often provided by multiple an-notators. Existing methods fuse multiple annotations using a simple voting process, ignoring the inherent ambiguity of edges and labeling bias of annotators.
In this paper, we propose a novel uncertainty-aware edge detector (UAED), which employs uncertainty to investigate the subjectivity and ambiguity of diverse annotations. Speciﬁcally, we ﬁrst convert the deterministic label space into a learnable Gaus-sian distribution, whose variance measures the degree of ambiguity among different annotations. Then we regard the learned variance as the estimated uncertainty of the pre-dicted edge maps, and pixels with higher uncertainty are likely to be hard samples for edge detection. Therefore we design an adaptive weighting loss to emphasize the learn-ing from those pixels with high uncertainty, which helps the network to gradually concentrate on the important pix-els. UAED can be combined with various encoder-decoder backbones, and the extensive experiments demonstrate that
UAED achieves superior performance consistently across multiple edge detection benchmarks. The source code is available at https://github.com/ZhouCX117/
UAED. 1.

Introduction
Edge detection is a fundamental low-level vision task. It greatly reduces irrelevant information and retains the most important structural attributes. An efﬁcient edge detector can generate structural edges that depict important areas from a whole image, thereby beneﬁting many downstream tasks [31, 37, 42, 50, 63]. Early pioneering methods [4, 26] compute the gradient and choose suitable thresholds to se-lect pixels with obvious brightness changes. Hand-crafted
*Corresponding author. a c e b d f
Figure 1. Illustration of the proposed Uncertainty-Aware Edge De-tector (UAED). The ﬁrst row shows (a) an image from the BSDS test set and (b) four diverse labels by different annotators. The second row shows (c) the ﬁnal edge label computed by majority voting and (d) our estimated uncertainty map (red means high un-certainty and blue means low uncertainty). The third row shows the edge detection results by (e) EDTER [41] and (f) our UAED, both processed by non-maximum suppression. feature based methods [1, 35] extract features from low-level cues including density and texture, and then design complex rules to distinguish edges. Beneﬁting from the powerful feature representation of Convolution Neural Net-work (CNN) and Transformer, recent works [16, 32, 41, 59] concentrate on designing elaborate network architectures to learn high-level semantic representations.
The previous efforts are mainly dedicated to designing advanced networks to extract distinctive features. Except for the well-designed models, precise pixel-level annota-tion is another key factor in building an efﬁcient edge de-tector under the supervised setting. Due to the complex-ity of the scenes and the ambiguity of the edges, most of the works [1, 36] involve multiple annotators for labeling edges. However, the subjectivity of the annotators, e.g., dif-ferent people may perceive the same scene differently and annotate the edges at different granularities, leading to in-consistent annotations (Fig. 1(b)). Previous methods simply utilize the majority voting strategy to fuse multiple anno-tations into single ground truth, where all annotations are averaged to generate an edge probability map (Fig. 1(c)), ranging from 0 to 1. During training, the pixels with proba-bility higher than a ﬁxed threshold are regarded as positive and the pixels with probability equal to 0 as negative. And the remaining pixels are dropped. Such a simple voting pro-cess neglects the inherent ambiguity and label bias caused by the labeling process.
To address the issues, in this paper, we propose a novel uncertainty-aware edge detection (UAED) framework that converts the deterministic labels into distributions to ex-plore the inherent label ambiguity in the edge detection task.
Unlike previous works that focus on architecture modiﬁ-cation, we target modeling the uncertainty underlying the multiple edge annotations.
Speciﬁcally, the proposed UAED is designed based on the encoder-decoder architecture, where the encoder gen-erates the feature representations followed by two separate decoders. Instead of using ﬁxed labels, we treat the predic-tion as a learnable Gaussian distribution, whose mean and variance are learned by two decoders respectively, and the variance can be supervised by multiple annotations. The learned variance can be naturally regarded as uncertainty, which measures the label ambiguity. Therefore we further utilize the learned uncertainty to boost the performance.
Fig. 1(d) shows the estimated uncertainty map. We can ob-serve that the uncertainties of pixels that are close to edges are much higher than those of smooth regions. This phe-nomenon suggests that pixels with higher uncertainty are visually more important than pixels with lower uncertainty and can be regarded as hard samples for detecting edges.
Thus inspired, unlike most uncertainty estimation meth-ods that regard the pixels with higher uncertainty as unre-liable and discard them, we encourage the model to learn more from the hard samples with higher uncertainty pro-gressively. The experiments on two popular edge detection datasets with multiple annotations show the effectiveness of our proposed method. Compared with transformer-based
EDTER [41] (Fig. 1(e)), our proposed UAED combined with CNN-based architecture can generate more detailed edges (Fig. 1(f)), while requires less computation resource and time. Our contributions can be summarized as follows:
• We propose an uncertainty-aware edge detector, named UAED, which captures the inherent ambiguity caused by multiple subjective annotations. To our best knowledge, this is the ﬁrst work that provides an un-certainty perspective in edge detection.
• We concentrate on the pixels with higher uncertainty that play a more important role in edge detection, and further design an adaptive weighting loss to emphasize the training from those hard pixels.
• UAED can be combined with various encoder-decoder backbones without increasing much computation bur-den. We conduct comprehensive experiments on pop-ular datasets across different model architectures and achieve consistent improvement. 2.