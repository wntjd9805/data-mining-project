Abstract
Feature invariance under different data transformations, i.e., transformation invariance, can be regarded as a type of self-supervision for representation learning. In this pa-per, we present PointClustering, a new unsupervised rep-resentation learning scheme that leverages transformation invariance for point cloud pre-training. PointClustering formulates the pretext task as deep clustering and employs transformation invariance as an inductive bias, following the philosophy that common point cloud transformation will not change the geometric properties and semantics. Techni-cally, PointClustering iteratively optimizes the feature clus-ters and backbone, and delves into the transformation in-variance as learning regularization from two perspectives: point level and instance level. Point-level invariance learn-ing maintains local geometric properties through gathering point features of one instance across transformations, while instance-level invariance learning further measures cluster-s over the entire dataset to explore semantics of instances.
Our PointClustering is architecture-agnostic and readily applicable to MLP-based, CNN-based and Transformer-based backbones. We empirically demonstrate that the models pre-learnt on the ScanNet dataset by PointClus-tering provide superior performances on six benchmark-s, across downstream tasks of classification and segmen-tation. More remarkably, PointClustering achieves an ac-curacy of 94.5% on ModelNet40 with Transformer back-bone. Source code is available at https://github. com/FuchenUSTC/PointClustering. 1.

Introduction 3D point cloud analysis has seen tremendous progress and made great success in industrial applications, e.g., au-tonomous driving, augmented reality and robotics. The achievements heavily rely on large quantities of human an-Figure 1. Illustration of (a) clustering learning on point cloud by using feature invariance at (b) point level and (c) instance level. notations for supervised learning. However, acquiring and manual labeling 3D point cloud data is very expensive and time-consuming, while the underlying rich data structure is also not yet fully leveraged. In contrast, unsupervised learn-ing leaves it on its own to characterize the underlying fea-ture distribution completely on data itself and is therefore an appealing way towards more generic model pre-training.
The research in unsupervised point cloud pre-training has mainly proceeded along two dimensions with respec-t to the formulation of pretext task: contrastive learning
[23, 65, 74] and reconstruction [34, 52, 60]. Early works of contrastive learning generally suggest to leverage point or scene discrimination across different views [65] or modal-ities [1, 74] for similarity learning.
Instead, the direction of point cloud reconstruction [34, 60] formulates the learn-ing target as shape completion from the partial points. Un-like existing discrimination or reconstruction paradigm in a
sample-specific manner, clustering technique estimates the data distribution holistically for class level. We rely on such recipe and shape a new unsupervised point cloud pre-training scheme that capitalizes on deep clustering as the pretext task. Technically, we iteratively optimize feature clusters and backbone as shown in Figure 1(a), and utilize transformation invariance as an inductive bias. We look into the feature invariance learning across data transformations from two aspects: point level and instance level. The ratio-nale behind point level feature invariance is that the point features of an identical object (e.g., points of the chair in
Figure 1(b)) should be invariant across different transfor-mations since the geometric properties will not change with transformations. Similar in spirit, the high-level semantics of instances across 3D scenes (e.g., the instances of chair in Figure 1(c)) do not vary along with the transformations.
As such, we delve into both point-level and instance-level transformation invariance to regulate deep clustering.
By materializing the idea of transformation invariance as regularization for deep clustering, we present a novel
PointClustering approach for unsupervised point cloud pre-training. Specifically, we first obtain the instance masks of objects in each 3D scene via Density-Based Spatial Cluster-ing of Applications with Noise (DBSCAN) [12] algorithm.
Based on the instance masks, the point features of an iden-tical object under different transformations are clustered to-gether to characterize geometric properties of points. The instance-level feature of one object is then computed by globally pooling all point features of that object. Given al-l instance features over the entire dataset, PointClustering further seeks the feature consistency across transformations at instance level. We employ InfoNCE loss to optimize the similarity between points or instances and their correspond-ing clustering centroids (i.e., prototypes).
The main contribution of this work is a new paradigm that leverages feature invariance under different data trans-formations for unsupervised point cloud pre-training. The solution also leads to the elegant view of how to explore self-supervision from the standpoint of transformation in-variance, and how to indicate geometric properties and se-mantics of point cloud for unsupervised pre-training. Ex-tensive experiments on six benchmarks over three down-stream tasks verify that PointClustering outperforms the state-of-the-art unsupervised pre-training models. 2.