Abstract
Multi-instance learning (MIL) is an effective paradigm for whole-slide pathological images (WSIs) classification to handle the gigapixel resolution and slide-level label. Pre-vailing MIL methods primarily focus on improving the fea-ture extractor and aggregator. However, one deficiency of these methods is that the bag contextual prior may trick the model into capturing spurious correlations between bags and labels. This deficiency is a confounder that limits the performance of existing MIL methods.
In this paper, we propose a novel scheme, Interventional Bag Multi-Instance
Learning (IBMIL), to achieve deconfounded bag-level pre-diction. Unlike traditional likelihood-based strategies, the proposed scheme is based on the backdoor adjustment to achieve the interventional training, thus is capable of sup-pressing the bias caused by the bag contextual prior. Note that the principle of IBMIL is orthogonal to existing bag
MIL methods. Therefore, IBMIL is able to bring consis-tent performance boosting to existing schemes, achieving new state-of-the-art performance. Code is available at https://github.com/HHHedo/IBMIL. 1.

Introduction
The quantitative analysis of whole-slide pathological im-ages (WSIs) is essential for both diagnostic and research purposes [13]. Beyond complex biological structures, WSIs are quite different from natural images in the gigapixel res-olution and expensive annotation, which is thus formulated as a multi-instance learning (MIL) [9] problem: treating each WSI as a labeled bag and the corresponding patches as unlabeled instances. Such a de facto paradigm has been demonstrated in extensive tasks on WSIs, e.g., classifica-tion [7, 15, 18, 46], regression [40, 41, 48] and segmenta-tion [37]. The prevailing scheme for WSI classification — bag-level MIL — is depicted in Fig. 1a. Given the patchified
*Corresponding author. (a) (b) (c)
Figure 1. (a) Traditional scheme and our interventional training. (b) Dataset bias. (c) Unreasonable attention maps with right pre-dictions. images as instances, each instance is embedded in vectors by a feature extractor in the first stage. Second, for each bag, their corresponding instance features are aggregated as a bag-level feature for classification.
More and more new frameworks are proposed to im-prove the two stages following this scheme [19,28,31,44]. It is convinced that learning better instance features and mod-eling more accurate instance relationships can bring better performance of MIL. While we have witnessed the great efforts, they still leave the “bag contextual prior” issue un-solved: the information shared by bags of the same class but irrelevant to the label, which may affect the final predic-tions. For example, in Fig. 1b, due to the dataset bias, most of the instances in the positive bags are stained pink but pur-ple in the negative bags. The co-occurrence of specific color patterns and labels may mislead the model to classify bags by color statistics instead of the key instances — the more
pink instances a bag contains, the more likely it is a posi-tive bag. Fig. 1c illustrates another example: even if the prediction is correct, the underlying visual attention is not reasonable, where the high attention scores are put on the disease-irrelevant instances outside the blue curves in the bags. From the causal lens, the bag contextual prior is a con-founder that opens up a backdoor path for bags and labels, causing spurious correlations between them. To suppress such a bias, we need a more efficient mechanism for the actual causality between bags and labels, i.e., the bag pre-diction is based on the bag’s content (e.g., key instances), which can not be fully achieved only by above mentioned new frameworks.
In fact, it is challenging to achieve unbiased bag pre-dictions as such a bias happens in the data generation – the tissue preparations, staining protocols, digital scan-ners, etc. In this paper, we propose a novel MIL scheme,
Interventional Bag Multi-Instance Learning (IBMIL), to tackle this challenge. In particular, we propose a structure causal model (SCM) [24] to analyze the causalities among bag contextual prior, bags and labels. The key difference of IBMIL is that it contains another stage of interventional training (see Fig. 1a right). Given the aggregator trained in the second stage, instead of directly using it for inference via likelihood: P (Y |X), we apply it for the approxima-tion of confounders. With the confounders observed, we eliminate their effect via the backdoor adjustment formu-lation [23], where the intuitive understanding is: if a WSI model can learn from “purple” and “pink” positive/negative bags, respectively, then the bag context of color will no longer confound the recognition. Therefore, our IBMIL is fundamentally different from the existing scheme as we use a causal intervention: P (Y |do(X)) for bag prediction.
We conduct experiments on two public WSI datasets, i.e., Camelyon16 [1] and TCGA-NSCLC. Experimental re-sults show that IBMIL is agnostic to both feature extractors and aggregation networks, i.e., it brings consistent perfor-mance boosting to all compared state-of-the-art MIL meth-ods in the WSI classification tasks. Further ablation studies and analyses demonstrate the effectiveness of interventional training. 2.