Abstract
Diffusion-based models have shown the merits of gener-ating high-quality visual data while preserving better diver-sity in recent studies. However, such observation is only jus-tified with curated data distribution, where the data samples are nicely pre-processed to be uniformly distributed in terms of their labels. In practice, a long-tailed data distribution appears more common and how diffusion models perform on such class-imbalanced data remains unknown. In this work, we first investigate this problem and observe signifi-cant degradation in both diversity and fidelity when the dif-fusion model is trained on datasets with class-imbalanced distributions. Especially in tail classes, the generations largely lose diversity and we observe severe mode-collapse issues. To tackle this problem, we set from the hypothesis that the data distribution is not class-balanced, and pro-pose Class-Balancing Diffusion Models (CBDM) that are trained with a distribution adjustment regularizer as a so-lution. Experiments show that images generated by CBDM exhibit higher diversity and quality in both quantitative and qualitative ways. Our method benchmarked the generation results on CIFAR100/CIFAR100LT dataset and shows out-standing performance on the downstream recognition task. 1.

Introduction
In recent years, log-likelihood-based diffusion models have evolved rapidly and established new benchmarks on a range of generation tasks [1, 7]. Based on them, researchers have been able to further control the model generation pro-cess and the generation quality. This improves the applica-tions of generative models in numerous domains including text-image generation [31], image editing [28, 38], speech synthesis [17], medical imaging [26, 44], video generation
[13] and adversarial learning [18, 33], etc.
Although diffusion models are known for the power of high fidelity and diversity in generation, most of the exist-ing diffusion models are trained with the hypothesis that the data are uniformly distributed w.r.t. their labels. However,
Figure 1. Generation degrades along with class frequency. Se-mantics of generated images become less recognizable when class frequency decreases, while the FID score increases significantly. in the real world, the distribution is often very skewed. Es-pecially for many domain-specific generation tasks such as medical images [14], fine-grained dataset for taxology [15] and data grabbed from the web [24], it is difficult to col-lect large amounts of data for each class equally, and the size of the training set for head and tail categories can differ by a factor of hundred or more. For such datasets, uncon-ditional diffusion models tend to produce a significant por-tion of low-quality images. Conditional models, as shown in Figure 1, generate head class images with satisfying per-formance, while conversely the generated images on tail classes are very likely to show unrecognizable semantics.
Concerning training generative models with limited data, there already exist several methods [21, 37, 50] based on
GAN models [2]. However, quite few studies examine the impact of imbalanced class distribution [34] especially on diffusion models, which is practical yet under-explored.
Our work first introduces diffusion models to imbalance generation tasks on several long-tailed datasets [19], and then build some straightforward baselines according to the common methods used in long-tailed recognition [27, 29].
To overcome the potential degeneration induced by the skewed distribution, we propose a novel Class-Balancing
Diffusion Model (CBDM). Theoretically, CBDM resorts to adjusting the conditional transfer probability during sam-pling in order to implicitly force generated images to have a balanced prior distribution during every sampling step.
Technically, the adjusted transfer probability of CBDM re-sults in an additional MSE-form loss for a conditional dif-fusion model, which functions as a regularizer. Intuitively, this loss augments the similarity of generated images con-ditioned on different classes, and turns out to be an effective approach to transfer common information from head classes to tail classes without hurting the model’s expressiveness on head classes. CBDM can be implemented within several flines of codes, and its lighter version admits fine-tuning an existing conditional model. We conducted extensive ex-periments on CIFAR10/CIFAR100 and their corresponding long-tailed dataset to show the promise of CBDM over ex-isting state-of-the-art methods. In a nutshell, the contribu-tions of this work can be summarized as follows:
• We identify the severe degeneration problem of diffu-sion models in long-tailed generation tasks and bench-mark some straightforward baselines in this direction.
• We propose a new perspective to handle the genera-tion quality collapse on tail classes, and derive a novel
Class-Balancing Diffusion Model, which is effective and lightweight as a regularizer to existing methods.
• We validate that CBDM is capable of generating more diverse images with convincing fidelity, especially for datasets with large number of categories. In addition,
CBDM is robust with accelerating algorithms such as
DDIM [43], and can be transplanted to different con-ditional diffusion-based backbones easily. 2.