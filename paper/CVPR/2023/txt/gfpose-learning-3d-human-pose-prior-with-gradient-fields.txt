Abstract
Learning 3D human pose prior is essential to human-centered AI. Here, we present GFPose, a versatile frame-work to model plausible 3D human poses for various appli-cations. At the core of GFPose is a time-dependent score network, which estimates the gradient on each body joint and progressively denoises the perturbed 3D human pose to match a given task specification. During the denois-ing process, GFPose implicitly incorporates pose priors in gradients and unifies various discriminative and genera-tive tasks in an elegant framework. Despite the simplic-ity, GFPose demonstrates great potential in several down-stream tasks. Our experiments empirically show that 1) as a multi-hypothesis pose estimator, GFPose outperforms exist-ing SOTAs by 20% on Human3.6M dataset. 2) as a single-hypothesis pose estimator, GFPose achieves comparable re-sults to deterministic SOTAs, even with a vanilla backbone. 3) GFPose is able to produce diverse and realistic samples in pose denoising, completion and generation tasks.1 1.

Introduction
Modeling 3D human pose is a fundamental problem in human-centered applications, e.g. augmented reality [34, 43], virtual reality [1, 42, 69], and human-robot collabora-tion [9, 15, 36]. Considering the biomechanical constraints, natural human postures lie on a low-dimensional manifold of the physical space. Learning a good prior distribution over the valid human poses not only helps to discriminate the infeasible ones but also enables sampling of rich and diverse human poses. The learned prior has a wide spec-trum of use cases with regard to recovering the 3D hu-man pose under different conditions, e.g., monocular im-ages with depth ambiguities and occlusions [8, 29, 63], in-ertial measurement unit (IMU) signals with noises [72], or even partial sensor inputs [23, 65]. 1Project page https://sites.google.com/view/gfpose/
Figure 1. GFPose learns the 3D human pose prior from 3D hu-man pose datasets and represents it as gradient fields for various applications, e.g., multi-hypothesis 3D pose estimation from 2D keypoints, correcting noisy poses, completing missing joints, and generating natural poses from noise.
Previous works explore different ways to model human pose priors. Pioneers [16, 27] attempt to explicitly build joint-angle limits based on biomechanics. Unfortunately, the complete configuration of pose-dependent joint-angle constraints for the full body is unknown. With the recent advances in machine learning, a rising line of works seek to learn the human pose priors from data. Representa-tive methods include modeling the distribution of plausible poses with GMM [5], VAE [46], GAN [12] or neural im-plicit functions [61]. These methods learn an independent probabilistic model or energy function to characterize the data distribution pdata(x). They usually require additional optimization process to introduce specific task constraints when applied to downstream tasks. Therefore extra efforts such as balancing prior terms and different task objectives are inevitable. Some methods jointly learn the pose priors and downstream tasks via adversarial training [24,26] or ex-plicit task conditions [35,48,50] pdata(x|c). These methods seamlessly integrate priors into learning-based frameworks, but limit their use to a single given task.
In this work, we take a new perspective to learn a versa-tile 3D human pose prior model for general purposes. Dif-ferent from previous works that directly model the plausi-ble pose distribution pdata(x), we learn the score (gradi-ent of a log-likelihood) of a task conditional distribution
∇x log pdata(x|c), where c is the task-specific condition, e.g., for 3D human pose estimation, c could be 2D images or detected 2D poses. x represents plausible 3D human poses. In this way, we can jointly encode the human pose prior and the task specification into the score, instead of considering the learned prior model as an ad-hoc plugin as in an optimization process. To further enhance the flexibil-ity and versatility, we introduce a condition masking strat-egy, where task conditions are randomly masked to vary-ing degrees during training. Different masks correspond to different task specifications. Thus we can handle various pose-related tasks in a unified learning-based framework.
We present GFPose, a general framework for pose-related tasks. GFPose learns a time-dependent score net-work sθ(x, t|c) to approximate ∇x log pdata(x|c) on a large scale 3D human pose dataset [18] via Denoising Score
Matching (DSM) [17, 54–57, 59, 62]. Specifically, for any valid human pose x ∈ RJ×3 in Euclidean space, we sam-ple a time-dependent noise z(t) from a prior distribution, perturb x to get the noisy pose (cid:101)x, then train sθ((cid:101)x, t|c) to learn the score towards the valid pose. Intuitively, the score points in the direction of increasing pose plausibility. To handle a wider range of downstream tasks, we adopt a hier-archical condition masking strategy in training. Concretely, we randomly mask out the task condition c by sampling masks from a hierarchy of candidate masks. The candidate masks cover different levels of randomness, including hu-man level, body part level, and joint level. This helps the model to build the spatial relation between different body joints and parts, and enables GFPose directly applicable to different task settings at test time (Figure 1), e.g., recovering 3D pose from severe occlusions when c is partially masked 2D pose or unconditional pose generation when c is fully masked (c = Ø).
We evaluate GFPose on various downstream tasks, in-cluding monocular 3D human pose estimation, pose denois-ing, completion, and generation. Empirical results on the
H3.6M benchmark [18] show that: 1) GFPose outperforms
SOTA in both multi-hypothesis and single-hypothesis pose estimation tasks [63] and demonstrates stronger robustness to severe occlusions in pose completion [30]. Notably, un-der the single-hypothesis setting, GFPose can achieve com-parable pose estimation performance to previous determin-istic SOTA methods [11,47,70] that learns one-to-one map-ping. To the best of our knowledge, this is for the first time that a probabilistic model can achieve such performance. 2)
As a pose generator, GFPose can produce diverse and real-istic samples that can be used to augment existing datasets.
We summarize our contributions as follows:
• We introduce GFPose, a novel score-based generative framework to model plausible 3D human poses.
• We design a hierarchical condition masking strategy to enhance the versatility of GFPose and make it directly applicable to various downstream tasks.
• We demonstrate that GFPose outperforms SOTA on multiple tasks under a simple unified framework. 2.