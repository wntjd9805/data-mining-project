Abstract
The goal of domain generalization (DG) is to enhance the generalization capability of the model learned from a source domain to other unseen domains. The recently devel-oped Sharpness-Aware Minimization (SAM) method aims to achieve this goal by minimizing the sharpness measure of the loss landscape. Though SAM and its variants have demonstrated impressive DG performance, they may not al-ways converge to the desired ﬂat region with a small loss value. In this paper, we present two conditions to ensure that the model could converge to a ﬂat minimum with a small loss, and present an algorithm, named Sharpness-Aware Gradient Matching (SAGM), to meet the two condi-tions for improving model generalization capability. Specif-ically, the optimization objective of SAGM will simultane-ously minimize the empirical risk, the perturbed loss (i.e., the maximum loss within a neighborhood in the parameter space), and the gap between them. By implicitly aligning the gradient directions between the empirical risk and the perturbed loss, SAGM improves the generalization capabil-ity over SAM and its variants without increasing the com-putational cost. Extensive experimental results show that our proposed SAGM method consistently outperforms the state-of-the-art methods on ﬁve DG benchmarks, including
PACS, VLCS, OfﬁceHome, TerraIncognita, and DomainNet.
Codes are available at https://github.com/Wang-pengfei/SAGM . 1.

Introduction
Deep learning methods have achieved remarkable suc-cess in various computer vision tasks when the source data and target data are independently and identically distributed (i.i.d). However, the performance of deep models trained in a source domain can drop signiﬁcantly when applied to unseen target domains. Domain generalization (DG) aims
*Corresponding author to train a model from a set of source data such that it can be well generalized to new domains without retrain-ing. Over the past decade, research on DG has led to a plethora of methods, including those based on domain alignment [35, 16, 32, 2, 52], meta-learning [29, 3, 11, 51], and data augmentation [53, 43, 7]. Though numerous DG approaches have been proposed, a recent study called Do-mainBed [18] reveals that under a fair evaluation proto-col, the naive empirical risk minimization (ERM) method can even outperform most existing DG methods. Unfortu-nately, simply minimizing the empirical loss on a complex and non-convex loss landscape is typically insufﬁcient to achieve a good generalization capability [23, 17, 22, 15].
As a result, ERM tends to overﬁt the training data set and converge to sharp local minima [15].
Recent studies such as Sharpness-Aware Minimization (SAM) [15] try to improve the model generalization ability by minimizing the sharpness measure of the loss landscape.
Denote by L(θ) the loss to be minimized (e.g., the cross-entropy loss for classiﬁcation), where θ is the parameters of the neural network. SAM ﬁrst adversarially computes a weight perturbation (cid:15) that maximizes the empirical risk
L(θ) and then minimizes the loss of the perturbed network, i.e., L(θ + (cid:15)). Speciﬁcally, the objective of SAM is to mini-mize the maximum loss around the model parameter θ. Due to the high complexity of this min-max optimization prob-lem, SAM chooses to minimize an approximation of L(θ), denoted by Lp(θ) (perturbed loss, see Section 3 for details).
However, minimizing Lp(θ) is not guaranteed to converge to ﬂat minimum regions [55].
While Lp(θ) may not characterize well the sharpness of loss surface, the surrogate gap h(θ) (cid:44) Lp(θ) − L(θ) can better describe it. Intuitively, the loss surface will be-come ﬂatter when h(θ) is closer to zero because the pertur-bation parameters around θ will have a similar loss value.
Zhuang et al. [55] proved that h(θ) is an equivalent measure of the dominant eigenvalue of Hessian (which is the mea-sure of sharpness) at a local minimum. Therefore, we can seek ﬂat minima for better generalization ability by mini-mizing the surrogate gap h(θ). Unlike SAM which only optimizes the perturbation loss Lp(θ), GSAM [55] jointly minimizes Lp(θ) and the surrogate gap h(θ). However,
GSAM minimizes h(θ) by increasing the loss L(θ), which will reduce the generalization performance. Zhang et al.
[55] have shown that when the perturbation amplitude ρ is sufﬁciently small, the surrogate gap is always non-negative, i.e., Lp(θ) ≥ L(θ), ∀θ. Therefore, increasing L(θ) will also increase the difﬁculty of optimizing Lp(θ; D).
We propose two conditions that should be met to obtain a model with good generalization performance. (i) First, the loss within a neighborhood of the desired minimum should be sufﬁciently low. (ii) Second, the minimum is within a ﬂat loss surface. More speciﬁcally, condition (i) implies a low training loss and represents good performance on the source training data, while condition (ii) reduces the performance gap of the model on training and testing data.
Based on the above analysis, we propose a new
DG method, namely Sharpness-Aware Gradient Matching (SAGM), to simultaneously minimize three objectives, the empirical risk L(θ), the perturbed loss Lp(θ) and the surro-gate gap h(θ). By minimizing L(θ) and Lp(θ), we search for a region with low loss, which satisﬁes condition (i). By minimizing h(θ), we avoid steep valleys, which meets con-dition (ii). However, optimizing these three objectives si-multaneously is difﬁcult due to the inevitable gradient con-ﬂicts during training. Fortunately, we ﬁnd that when the gradient directions of L(θ) and Lp(θ) are consistent, the gradient direction of h(θ) is also consistent with them, and hence the gradient descent can be effectively applied to all the three losses. Therefore, we transform the optimiza-tion objective into minimizing L(θ), Lp(θ), and the angle between their gradients, and achieve this goal by implic-itly aligning the gradient directions between the L(θ) and
Lp(θ). The proposed SAGM improves the generalization performance of the model by facilitating the model to con-verge to a ﬂat region with a small loss value. Compared with SAM, our SAGM does not increase the computational cost. In addition, SAGM can be combined with previous data augmentation methods, such as Mixstyle [54] for fur-ther performance improvements.
The contributions of this work are summarized as fol-lows. First, we analyze the limitations of SAM-like meth-ods and propose two conditions to ensure the model conver-gence to a ﬂat region with a small loss. Second, we propose the SAGM algorithm to improve the DG capability of deep models. Finally, we demonstrate the superior performance of SAGM to state-of-the-arts on ﬁve DG benchmarks. 2.