Abstract
Analogical reasoning enables agents to extract relevant information from scenes, and efficiently navigate them in familiar ways. While progressive-matrix problems (PMPs) are becoming popular for the development and evaluation of analogical reasoning in computer vision, we argue that the dominant methodology in this area struggles to expose the lack of meaningful generalisation in solvers, and rein-forces an objectivist stance on perception – that objects can only be seen one way – which we believe to be counter-productive. In this paper, we introduce the Unicode Analo-gies challenge, consisting of polysemic, character-based
PMPs to benchmark fluid conceptualisation ability in vision systems. Writing systems have evolved characters at mul-tiple levels of abstraction, from iconic through to symbolic representations, producing both visually interrelated yet ex-ceptionally diverse images when compared to those exhib-ited by existing PMP datasets. Our framework has been de-signed to challenge models by presenting tasks much harder to complete without robust feature extraction, while remain-ing largely solvable by human participants. We therefore argue that Unicode Analogies elegantly captures and tests for a facet of human visual reasoning that is severely lack-ing in current-generation AI. 1.

Introduction
Traditionally, statistical classification models have been designed to neatly cleave data into categories. Even in tasks such as visual scene decomposition, where data re-sists full description by any one label, there is an underly-ing objectivist assumption being made; the expectation of there being an objective number of distinguishable “things” present, themselves belonging to singular classes. Human visual perception makes a departure from this. The sym-bolic world to which we attend, with firm compositional rules for scenes and their objects, and with their parts and positions, is subsisted by a churning sea of ongoing concep-tualisation processes deeply fluid and contextual [15].
In recent years, there has been a proliferation of com-puter vision architectures built with object-centric inductive
Figure 1. An example problem in UA, instantiating the Distribute-Three rule with the Closure concept. Five out of six context frames are provided (left), with four answer frames to choose from (right).
The correct answer is emboldened. biases [21], many of which represent states-of-the-art on popular datasets [7, 35, 41]. This is an important direction, as training models to decompose scenes into objects allows for an explicit abstraction stage promoting feature reuse.
However, abstract visual reasoning tasks such as Bongard problems [3] expose philosophically [20] — and in this pa-per, experimentally — that such an approach might work against the creation of models that possess the ability to ab-stract and deploy useful concepts. This observation also en-gages a current debate in the literature regarding the scala-bility of built-in knowledge and inductive biases [24, 36].
Humans display flexibility in how they decompose scenes, and perceive such scenes at a level of abstraction informed by past experiences and appropriate to present goals [8,9]. Scene understanding in humans is therefore un-dergirded by something other than the perception of static objects [22], and the idea that scene modelling research can separate perception and higher cognition into a pipeline of self-contained modules is strongly critiqued [5]. including brittleness
Noticing other shortcomings of deep-learnt approaches to computer vision, to out-of-distribution (OOD) data, a small number of abstraction datasets inspired by Raven’s Progressive Matrices have been recently released [23]. Further motivations to this direction include a) the expectation that tasks with such an extended history in general psychometric testing would be useful to import into computer vision research, and b) the opinion that the more broadly applicable a model’s ab-stracted concepts become, the more robust that model will
be under OOD conditions [29, 35]. While the applicabil-ity of such concepts should ideally be evaluated by these datasets, common approaches to dataset creation feature conceptual schemas consisting of simple objects that can be neatly dropped into scenes, and extracted by scene de-composition stages [35]. This seems to require little in the way of contextual perception, such as Hofstadter’s notion of “conceptual slippage” [16].
We observe that the world’s writing systems present a diverse resource of characters that are amenable to con-tent analysis, and can assemble novel reasoning problems of their own. We introduce the Unicode Analogies (UA) challenge, consisting of character-based progressive ma-trix problems (PMPs) to benchmark fluid conceptualisation ability in vision systems. The characters in UA are poly-semic, and may instantiate any number of concepts, with the salient concept only revealing itself given context (Fig. 1).
By generating training and testing problems from disjoint sets of characters, we challenge these systems by present-ing tasks much harder to complete without robust feature extraction, while remaining largely solvable by human par-ticipants. In doing so, we contribute a dataset that unlike others in this area, operates on a rich conceptual schema that invites fine-grained experimentation, and is easily ex-tensible to new user-defined concepts. Over five key ex-periments, we explore human and model performance on a number of dataset splits generated by UA, demonstrate that state-of-the-art solvers are still far from achieving the founding goals their datasets were created for, and encour-age new solvers to overcome these limitations. 2.