Abstract
Restoring sharp high frame-rate videos from low frame-rate blurry videos is a challenging problem. Existing blurry frame interpolation methods assume a predefined and known exposure time, which suffer from severe perfor-mance drop when applied to videos captured in the wild. In this paper, we study the problem of blurry frame interpola-tion under blind exposure with the assistance of an event camera. The high temporal resolution of the event camera is beneficial to obtain the exposure prior that is lost during the imaging process. Besides, sharp frames can be restored using event streams and blurry frames relying on the mu-tual constraint among them. Therefore, we first propose an exposure estimation strategy guided by event streams to es-timate the lost exposure prior, transforming the blind expo-sure problem well-posed. Second, we propose to model the mutual constraint with a temporal-exposure control strat-egy through iterative residual learning. Our blurry frame interpolation method achieves a distinct performance boost over existing methods on both synthetic and self-collected real-world datasets under blind exposure. 1.

Introduction
Blurry frame interpolation (BFI) [23, 46, 73] aims to re-store sharp high frame-rate videos from blurry low frame-rate videos, which is highly desirable for a wide range of applications, such as novel view interpolation synthesis [7], frame rate conversion [32], slow motion [21] and inter-frame video compression [64]. Compared with the cascade scheme, i.e., combining frame deblurring [20, 25, 33, 39, 40, 51, 53, 59] with frame interpolation [2, 21, 31, 32, 35, 37, 38, 68], the joint method [46, 73] is more effective, which over-comes the error accumulation problem and ambiguity of the temporal scope [46].
Despite remarkable improvement, prior works [23, 46]
*Corresponding author. This work was supported in part by the Na-tional Natural Science Foundation of China under Grants 62131003 and 62021001.
Figure 1. (a) Non-blind exposure setting and blind exposure set-ting. (b) Illustrative flow of our solution to blurry frame interpola-tion under blind exposure. assume that the exposure time is predefined or known as the shutter period, which we call non-blind exposure as shown in the left part of Fig. 1 (a). However, the com-plicated video capturing in the wild gives rise to variable and unknown exposure time, which we call blind exposure.
The right part of Fig. 1 (a) presents that the shutter period is the summation of exposure time and data readout time.
For better imaging, the exposure time is variable to fit the changing light conditions in the real imaging environments, especially when the auto-exposure function turns on [73].
Challenges and Motivation. In this paper, we focus on the problem of BFI under blind exposure, which is prac-tical yet has barely been investigated explicitly. The first challenge of this problem can be attributed to the intrinsic imaging mechanism of frame-based cameras. As can be seen from Fig. 1 (a), the accumulation operation of frame-based cameras inevitably results in the loss of motion infor-mation during the exposure time. Particularly, the variable exposure time further leads to the temporal jittering, which degrades the performance of the video enhancement algo-rithms with constant/predefined exposure time assumption.
Another challenge is that there misses a decent model as the effective guidance. Conventional frame-based methods for
BFI are vulnerable to the artifacts introduced by flow-based warping or straight forward prediction.
To overcome the above challenges, we attempt to pro-vide a new perspective, by resorting to a novel sensor.
Event cameras [8, 69], also known as neuromorphic sen-sors, are bio-inspired visual sensors that output events by detecting spatiotemporal brightness changes. We demon-strate that event cameras are suitable for BFI under blind exposure from two points as shown in Fig. 1 (b). First, the high temporal resolution property of event cameras is able to compensate for the exposure prior that is lost dur-ing the imaging process of frame-based cameras. To this end, we propose an exposure estimation strategy guided by event streams to estimate the lost exposure prior. In such a way, the blind exposure problem can be made well-posed, which eases the difficulty of video restoration. Second, the event stream is a natural constraint between blurry frames and sharp frames, providing a physical model for video restoration. To effectively model this physical correlation, we propose a temporal-exposure control strategy that takes timestamps and exposure priors as inputs for interpolation through iterative residual learning. By exploiting the pro-posed strategies of exposure estimation and time-exposure control, we are able to perform arbitrary-time interpolation from blurry frames under blind exposure. To evaluate our method in real-world scenarios, we collect a real blurry video dataset using a DAVIS-346 color event camera, which includes multiple exposure assumptions. Experimental re-sults on synthetic and self-collected real datasets demon-strate our superior performance over existing methods.
The contributions of this paper can be summarized as follows: 1) we provide a decent solution for BFI under blind exposure by using event cameras, for the first time; 2) we propose an exposure estimation strategy guided by event streams, which makes the blind exposure problem well-posed; 3) we propose a temporal-exposure control strategy, which enables BFI at an arbitrary timestamp under blind exposure; 4) we achieve superior performance over existing state-of-the-art methods on both synthetic and self-collected real-world datasets. 2.