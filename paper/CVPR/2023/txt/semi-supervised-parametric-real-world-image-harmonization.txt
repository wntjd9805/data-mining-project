Abstract
Learning-based image harmonization techniques are usu-ally trained to undo synthetic random global transforma-tions applied to a masked foreground in a single ground truth photo. This simulated data does not model many of the important appearance mismatches (illumination, object boundaries, etc.) between foreground and background in real composites, leading to models that do not generalize well and cannot model complex local changes. We propose a new semi-supervised training strategy that addresses this problem and lets us learn complex local appearance harmo-nization from unpaired real composites, where foreground and background come from different images. Our model is fully parametric. It uses RGB curves to correct the global colors and tone and a shading map to model local vari-ations. Our method outperforms previous work on estab-lished benchmarks and real composites, as shown in a user study, and processes high-resolution images interactively.
Code, and project page available at: https://kewang0622.github.io/sprih/. 1.

Introduction
Image harmonization [12, 22, 23, 26, 28, 32] aims to iron out visual inconsistencies created when compositing a fore-ground subject onto a background image that was captured under different conditions [18, 32], by altering the fore-ground’s colors, tone, etc., to make the composite more re-alistic. Despite significant progress, the practicality of to-day’s most sophisticated learning-based image harmoniza-tion techniques [3, 4, 9, 10, 13, 14, 16, 32] is limited by a se-vere domain gap between the synthetic data they are trained on and real-world composites.
As shown in Figure 2, the standard approach to generat-ing synthetic training composites applies global transforms
our harmonized results with a large dataset of realistic im-age composites. Adversarial training requires no paired ground truth. The foreground and background for the com-posite in this dataset are extracted from different images so that their appearance mismatch is consistent with what the model would see at test time.
To reap the most benefits from our semi-supervised train-ing, we also introduce a new model that is fully paramet-ric. To process a high-resolution input composite at test time, our proposed network first creates a down-sampled copy of the image at 512 × 512 resolution, from which it predicts global RGB curves and a smooth, low-resolution shading map. We then apply the RGB curves pointwise to the high-resolution input and multiply them by the upsam-pled shading map. The shading map enables more realistic local tonal variations, unlike previous harmonization meth-ods limited to global tone and color changes, either by con-struction [14, 16, 31] or because of their training data [4].
Our parametric approach offers several benefits. First, by restricting the model’s output space, it regularizes the adver-sarial training. Unrestricted GAN generators often create spurious image artifacts or other unrealistic patterns [36].
Second, it exposes intuitive controls for an artist to adjust and customize the harmonization result post-hoc. This is unlike the black-box nature of most current learning-based approaches [3, 4, 9, 10], which output an image directly.
And, third our parametric model runs at an interactive rate, even on very high-resolution images (e.g., 4k), whereas sev-eral state-of-the-art methods [4, 9, 10] are limited to low-resolution (e.g., 256 × 256) inputs.
To summarize, we make the following contributions:
• A novel dual-stream semi-supervised training strategy that, for the first time, enables training from real com-posites, which contains much richer local appearance mismatches between foreground and background.
• A parametric harmonization method that can capture these more complex, local effects (using our shading map) and produces more diverse and photorealistic harmonization results.
• State-of-the-art results on both synthetic and real com-posite test sets in terms of quantitative results and visual comparisons, together with a new evaluation benchmark. 2.