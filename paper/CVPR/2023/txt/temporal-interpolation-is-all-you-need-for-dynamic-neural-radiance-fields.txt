Abstract
Temporal interpolation often plays a crucial role to learn meaningful representations in dynamic scenes. In this pa-per, we propose a novel method to train spatiotemporal neu-ral radiance fields of dynamic scenes based on temporal interpolation of feature vectors. Two feature interpolation methods are suggested depending on underlying represen-tations, neural networks or grids. In the neural representa-tion, we extract features from space-time inputs via multi-ple neural network modules and interpolate them based on time frames. The proposed multi-level feature interpolation network effectively captures features of both short-term and long-term time ranges. In the grid representation, space-time features are learned via four-dimensional hash grids, which remarkably reduces training time. The grid repre-sentation shows more than 100× faster training speed than the previous neural-net-based methods while maintaining the rendering quality. Concatenating static and dynamic features and adding a simple smoothness term further im-prove the performance of our proposed models. Despite the simplicity of the model architectures, our method achieved state-of-the-art performance both in rendering quality for the neural representation and in training speed for the grid representation. 1.

Introduction 3D reconstruction and photo-realistic rendering have been long-lasting problems in the fields of computer vision and graphics. Along with the advancements of deep learn-ing, differentiable rendering [11, 14] or neural rendering, has emerged to bridge the gap between the two problems.
Recently proposed Neural Radiance Field (NeRF) [18] has finally unleashed the era of neural rendering. Using NeRF,
it is able to reconstruct accurate 3D structures from multiple 2D images and to synthesize photo-realistic images from unseen viewpoints. Tiny neural networks are sufficient to save and retrieve complex 3D scenes, which can be trained in a self-supervised manner given 2D images and camera parameters.
Meanwhile, as our world typically involves dynamic changes, it is crucial to reconstruct the captured scene through 4D spatiotemporal space. Since it is often not pos-sible to capture scenes at different viewpoints simultane-ously, reconstructing dynamic scenes from images is in-herently an under-constrained problem. While NeRF was originally designed to deal with only static scenes, there have been a few approaches in the literature that extend
NeRF to dynamic scenes [13,22,23,25], which are so called as dynamic NeRFs.
Inspired by the non-rigid structure-from-motion algorithms [1, 4] that reconstruct 3D struc-tures of deformable objects, most previous works solved the under-constrained setting by estimating scene deforma-tions [21,22,25] or 3D scene flows [5,9,12] for each frame.
However, since the parameters of deformation estima-tion modules are jointly optimized with NeRF network si-multaneously, it is questionable that the modules can accu-rately estimate deformations or scene flows in accordance with its design principles. In many dynamic scenes, it is challenging to resolve the ambiguities whether a point was newly appeared, moved, or changed its color. It is expected that those ambiguities and deformation estimation can be separately solved within a single network, but in practice, it is hard to let the network implicitly learn the separation, especially for general dynamic scenes without any prior knowledge of deformation.
On the other hand, grid representations in NeRF train-ing [7, 19, 24] have grabbed a lot of attentions mainly due to its fast training speed. Simple trilinear interpola-tion is enough to fill in the 3D space between grid points.
While the representation can be directly adopted to dynamic
NeRFs together with the warping estimation module [6], it still requires additional neural networks that affects training and rendering speed.
Motivated by the aforementioned analyses, we present a simple yet effective architecture for training dynamic
NeRFs. The key idea in this paper is to apply feature in-terpolation to the temporal domain instead of using warp-ing functions or 3D scene flows. While the feature inter-polation in 2D or 3D space has been thoroughly studied, to the best of our knowledge, feature interpolation method in temporal domain for dynamic NeRF has not been pro-posed yet. We propose two multi-level feature interpolation methods depending on feature representation which is ei-ther neural nets or hash grids [19]. Overview of the two representations, namely the neural representation and the
In addition, grid representation, are illustrated in Fig. 1. noting that 3D shapes deform smoothly over time in dy-namic scenes, we additionally introduced a simple smooth-ness term that encourages feature similarity between the ad-jacent frames. We let the neural networks or the feature grids to learn meaningful representations implicitly without imposing any constraints or restrictions but the smoothness regularizer, which grants the flexibility to deal with various types of deformations. Extensive experiments on both syn-thetic and real-world datasets validate the effectiveness of the proposed method. We summarized the main contribu-tions of the proposed method as follows:
• We propose a simple yet effective feature extraction network that interpolates two feature vectors along the temporal axis. The proposed interpolation scheme out-performs existing methods without having a deforma-tion or flow estimation module.
• We integrate temporal interpolation into hash-grid rep-resentation [19], which remarkably accelerates train-ing speed more than 100× faster compared to the neu-ral network models.
• We propose a smoothness regularizer which effectively improves the overall performance of dynamic NeRFs. 2.