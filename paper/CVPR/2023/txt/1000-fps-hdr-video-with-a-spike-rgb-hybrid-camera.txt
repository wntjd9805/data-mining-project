Abstract
Capturing high frame rate and high dynamic range (HFR&HDR) color videos in high-speed scenes with con-ventional frame-based cameras is very challenging. The in-creasing frame rate is usually guaranteed by using shorter exposure time so that the captured video is severely inter-fered by noise. Alternating exposures can alleviate the noise issue but sacrifice frame rate due to involving long-exposure frames. The neuromorphic spiking camera records high-speed scenes of high dynamic range without colors using a completely different sensing mechanism and visual repre-sentation. We introduce a hybrid camera system composed of a spiking and an alternating-exposure RGB camera to capture HFR&HDR scenes with high fidelity. Our insight is to bring each camera’s superiority into full play. The spike frames, with accurate fast motion information encoded, are firstly reconstructed for motion representation, from which the spike-based optical flows guide the recovery of missing temporal information for long-exposure RGB images while retaining their reliable color appearances. With the strong temporal constraint estimated from spike trains, both miss-ing and distorted colors cross RGB frames are recovered to generate time-consistent and HFR color frames. We collect a new Spike-RGB dataset that contains 300 sequences of synthetic data and 20 groups of real-world data to demon-strate 1000 FPS HDR videos outperforming HDR video re-construction methods and commercial high-speed cameras. 1.

Introduction
The spiking camera [17] and event camera [10] are neuromorphic sensors working differently from conven-tional frame-based digital cameras, which have many at-tractive characteristics, e.g., high-speed (perceiving scene
*Corresponding author.
Project page: https://changyakun.github.io/1000FPS-HDR
Figure 1. (a) We build a spike-RGB hybrid camera system to achieve 1000 FPS HDR video reconstruction1. (b) The RGB cam-era uses alternating-exposure mode with a frame rate of 60 FPS, where ts, 4ts, and 12ts are the short, middle, and long exposure in our setup, respectively. The sampling frequency of the spiking camera is 20000 Hz. radiance changes at the microsecond level), high dynamic range (HDR, ≥ 100 dB). However, since they only record i.e., spike trains [64] and event neuromorphic signals, streams [25], which are less friendly to the human visual system and cannot be directly processed by CNN-based models for video frames [40, 41], preprocessing modules that convert neuromorphic signals into compatible formats are usually required when applying them to frame-based vi-sion algorithms [61, 65]. In comparison with event streams, spike trains contain concrete textured information of scene radiances, which are more suitable for reconstructing high frame rate (HFR) videos [61–64]. However, since the spik-ing camera only encodes the absolute intensities of environ-ments, colors are absent in the reconstructed video frames.
When capturing with a frame-based RGB camera, qual-ity of recorded colors for each frame is determined by trad-ing off the exposure time, ambient light, and target objects’ moving speed [57]. For high-speed dynamic scenes, it often 1The video result is available on our project page.
requires to set shorter exposure time to guarantee a higher frame rate and avoid motion blur. In such a situation, since the exposure time is extremely short, the quality of video frames would be severely degenerated due to noise. Merg-ing a burst of short-exposure images is a simple yet effec-tive approach to reduce the noise level [8, 11], however, the color shift caused by noise is difficult to be corrected. Fus-ing alternating-exposure (using short, middle, and long ex-posures) RGB frames is commonly used for synthesizing well-exposed images [3,19,21]. However, they are not suit-able for high-speed scenes. As illustrated in Fig. 1(b), given a sequence of alternating-exposure RGB images, the total time from the starting of the current exposure to the starting of the next frame, denoted by T , is consistent for all frames, and it is composed of the exposure time Texp and interval time Titv (containing the readout and waiting time). It can be seen that the information during interval time is lost, and the frame rate they could achieve is thus limited to dozens of FPS. Another possible solution is to build a hybrid cam-era system to capture low frame rate (LFR) color sequence and high-speed neuromorphic signals simultaneously, then use the neuromorphic signals to interpolate [51, 52] and de-blur [14, 18, 59] the RGB frames. However, the saturated regions are usually ignored, leaving the colors of the in-terpolated frames still unsatisfactory. HDR intensity map (does not contain any chromatic information) built from the neuromorphic signals can also be used to compensate the missing textures in the saturated regions [15]. But such an approach is not robust for scenes with large areas of satu-rated regions, due to the heavy reliance on the chrominance compensation network to hallucinate the color.
In this paper, we propose an all-in-one framework to re-construct HRF (Fig. 1(a), at the level of 1000 FPS) color videos with high fidelity from the spike trains and a series of alternating-exposure frames captured by a Spike-RGB hy-brid camera system simultaneously (Fig. 1(b)). To make full use of the color information in RGB images, we pro-pose a three-stage strategy to deal with different situations using specific modules: (i) For the blurry middle- and long-exposure images, we design a spike guided deblurring mod-ule to recover the corresponding sharp images with faithful colors; (ii) for missing colors during the interval time, we design a spike guided interpolation module that exploits the abundant motion information (SC-Flow [16]) obtained from spike trains; (iii) for suppressing noise in short-exposure images and maintaining temporal consistency, we design a merging module, which exploits the variant of recurrent
U-Net [42] as its backbone, to complete the HFR&HDR color video reconstruction process. To summarize, this pa-per makes contributions by proposing:
• an all-in-one framework to reconstruct high-speed
HDR color video by jointly fusing spike trains and a sequence of alternating-exposure frames;
• a three-stage strategy fusing alternating exposures of
RGB frames for the generation of well-exposure col-ors, via a recurrent convolution neural network for con-tinuous frames interpolation guided by spike trains;
• a Spike-RGB hybrid camera system to demonstrate the applicability of the proposed method for capturing high-speed and high dynamic range scenes.
Experimental results show that the proposed method out-performs the state-of-the-art HDR video reconstruction method [3] and commercial cameras with the slow-motion photography capability in reconstructing 1000 FPS HDR color videos on synthetic data and real-world data. 2.