Abstract
In this paper, we propose binary sparse convolutional networks called BSC-Net for efﬁcient point cloud analysis.
We empirically observe that sparse convolution operation causes larger quantization errors than standard convolu-tion. However, conventional network quantization methods directly binarize the weights and activations in sparse con-volution, resulting in performance drop due to the signif-icant quantization loss. On the contrary, we search the optimal subset of convolution operation that activates the sparse convolution at various locations for quantization error alleviation, and the performance gap between real-valued and binary sparse convolutional networks is closed without complexity overhead. Speciﬁcally, we ﬁrst present the shifted sparse convolution that fuses the information in the receptive ﬁeld for the active sites that match the pre-deﬁned positions. Then we employ the differentiable search strategies to discover the optimal opsitions for active site matching in the shifted sparse convolution, and the quanti-zation errors are signiﬁcantly alleviated for efﬁcient point cloud analysis. For fair evaluation of the proposed method, we empirically select the recently advances that are bene-ﬁcial for sparse convolution network binarization to con-struct a strong baseline. The experimental results on Scan-Net and NYU Depth v2 show that our BSC-Net achieves sig-niﬁcant improvement upon our srtong baseline and outper-forms the state-of-the-art network binarization methods by a remarkable margin without additional computation over-head for binarizing sparse convolutional networks. 1.

Introduction 3D deep learning on point clouds [6, 12, 25, 27] has been widely adopted in a wide variety of downstream applica-tions including autonomous driving, AR/VR and robotics due to its strong discriminative power and generalization ability. In these applications, real-time interaction and fast
*Corresponding author.
Figure 1. Demonstration of sparse convolution and the proposed shifted sparse convolution. (a) Sparse convolution only operates (b) Our when the center of kernel slides over the active sites. shifted sparse convolution performs different operations for each group of output channels, which brings more information from the neighbor active sites. response are required to guarantee safety and practicality.
Submanifold sparse convolution (we call it ”sparse con-volution” for short in the rest of this paper) [12] is one of the most popular and basic operator for point cloud analy-sis, which ﬁrst voxelizes the point clouds and then applies 3D convolution on the voxels while keeping the same spar-sity pattern throughout the layers of the network. Sparse convolution is widely adopted in most state-of-the-art ar-chitectures for point cloud analysis and so it is desirable to further improve its efﬁciency for more practical applica-tion. We opt for architecture-agnostic methods such as em-ploying network binarization to achieve this goal. Binarized neural networks [19,36] restrict the bitwidth of weights and activations to only one bit and substitute the multiplication-addition by xnor-bitcount operations, which decreases the
storage and computational cost by 32× and 64× respec-tively. We empirically ﬁnd sparse convolution operation brings larger quantization errors compared to standard con-volution, which leads to signiﬁcant performance degrada-tion when directly applying existing network binarization methods due to the large quantization errors.
In this paper, we present BSC-Net to learn binary sparse convolutional networks for efﬁcient point cloud analysis in resource-exhaustive scenarios. Instead of directly binariz-ing the weights and activations in sparse convolutional net-works, we search the optimal subset of convolution oper-ation that activates the sparse convolution at various loca-tions for binarization. The acquired convolution patterns signiﬁcantly reduces the quantization errors in deployment, and achieves remarkable performance enhancement with-out extra computational cost. More speciﬁcally, we propose the shifted sparse convolutional networks whose convolu-tion operations are activated for active sites consistent with the pre-deﬁed locations, and the optimal positions for ac-tive site matching across various channels are obtained via differentiable search strategies. Therefore, the quantization errors in the ﬁxed convoltion operations are signiﬁcantly al-leviated by leveraging the shifted sparse convolution with the searched active site matching locations. Moreover, we empirically select the recently advances that are beneﬁcial for sparse convolution network binarization to construct a strong baseline. Extensive experimental results on Scan-Net and NYU Depth v2 for semantic segmentation of point clouds show that our BSC-Net reduces the operations per second (OPs) by 92.4% with only 3% mIOU degradation. 2.