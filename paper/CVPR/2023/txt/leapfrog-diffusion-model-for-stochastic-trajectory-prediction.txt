Abstract
To model the indeterminacy of human behaviors, stochas-tic trajectory prediction requires a sophisticated multi-modal distribution of future trajectories. Emerging diffusion models have revealed their tremendous representation capacities in numerous generation tasks, showing potential for stochastic trajectory prediction. However, expensive time consumption prevents diffusion models from real-time prediction, since a large number of denoising steps are required to assure sufficient representation ability. To resolve the dilemma, we present LEapfrog Diffusion model (LED), a novel diffusion-based trajectory prediction model, which provides real-time, precise, and diverse predictions. The core of the proposed
LED is to leverage a trainable leapfrog initializer to directly learn an expressive multi-modal distribution of future tra-jectories, which skips a large number of denoising steps, significantly accelerating inference speed. Moreover, the leapfrog initializer is trained to appropriately allocate cor-related samples to provide a diversity of predicted future tra-jectories, significantly improving prediction performances.
Extensive experiments on four real-world datasets, including
NBA/NFL/SDD/ETH-UCY, show that LED consistently im-proves performance and achieves 23.7%/21.9% ADE/FDE improvement on NFL. The proposed LED also speeds up the inference 19.3/30.8/24.3/25.1 times compared to the stan-dard diffusion model on NBA/NFL/SDD/ETH-UCY, satisfy-ing real-time inference needs. Code is available at https:
//github.com/MediaBrain-SJTU/LED. 1.

Introduction
Trajectory prediction aims to predict the future trajecto-ries for one or multiple interacting agents conditioned on their past movements. This task plays a significant role in numerous applications, such as autonomous driving [24], drones [10], surveillance systems [45], human-robot inter-action systems [5], and interactive robotics [20]. Recently, lots of fascinating research progresses have been made from
*Corresponding author.
Figure 1. Leapfrog diffusion model uses the leapfrog initializer to estimate the denoised distribution and substitute a long sequence of traditional denoising steps, accelerating inference and maintaining representation capacity. many aspects, including temporal encoding [6, 13, 46, 53], interaction modeling [1, 15, 18, 43, 49], and rasterized predic-tion [11, 12, 26, 48]. In practice, to capture multiple possi-bilities of future trajectories, a real-world prediction system needs to produce multiple future trajectories. This leads to the emergence of stochastic trajectory prediction, aiming to precisely model the distribution of future trajectories.
Previous works have proposed a series of deep gen-erative models for stochastic trajectory prediction. For example, [15, 18] exploit the generator adversarial net-works (GANs) to model the future trajectory distribu-tion; [27, 38, 49] consider the conditional variational auto-encoders (CVAEs) structure; and [3] uses the conditional normalizing flow to relax the Gaussian prior in CVAEs and learn more representative priors. Recently, with the great suc-cess in image generation [17, 33] and audio synthesis [4, 21], denoising diffusion probabilistic models have been applied to time-series analysis and trajectory prediction, and show promising prediction performances [14, 44]. Compared to many other generative models, diffusion models have advan-tages in stable training and modeling sophisticated distribu-tions through sufficient denoising steps [8].
However, there are two critical problems in diffusion mod-els for stochastic trajectory prediction. First, the real-time inference is time-consuming [14]. To ensure the representa-tion ability and generate high-quality samples, an adequate number of denoising steps are required in standard diffu-sion models, which costs more computational time. For
example, experiments show that on the NBA dataset, dif-fusion models need about 100 denoising steps to achieve decent prediction performances, which would take ∼886ms to predict; while the next frame comes every 200ms. Sec-ond, as mentioned in [2], a limited number of independent and identically distributed samples might not be able to cap-ture sufficient modalities in the underlying distribution of a generative model. Empirically, a few independent sampled trajectories could miss some important future possibilities due to the lack of appropriate sample allocation, significantly deteriorating prediction performances.
In this work, we propose leapfrog diffusion model (LED), a novel diffusion-based trajectory prediction model, which significantly accelerates the inference speed and enables adaptive and appropriate allocations of multiple correlated predictions, providing sufficient diversity in predictions. The core idea of the proposed LED is to learn a rough, yet suffi-ciently expressive distribution to initialize denoised future trajectories; instead of using a plain Gaussian distribution as in standard diffusion models. Specifically, our forward diffusion process is the same as standard diffusion models, which assures that the ultimate representation ability is pris-tine; while in the reverse denoising process, we leverage a powerful initializer to produce correlated diverse samples and leapfrog or skip a large number of denoising steps; and then, use only a few denoising steps to refine the distribution.
To implement such a leapfrog initializer, we consider a reparameterization to alleviate the learning burden. We disassemble a denoised distribution into three parts: mean trajectory, variance, and sample positions under the normal-ized distribution. To estimate these three, we design three corresponding trainable modules, each of which leverages both a social encoder and a temporal encoder to learn the social-temporal features and produce accurate estimation.
Furthermore, all the sample positions are simultaneously generated based on the same social-temporal features, en-abling appropriate sample allocations to provide diversity.
To evaluate the effectiveness of the proposed method, we conduct experiments on four trajectory prediction datasets:
NBA, NFL Football Dataset, Standford Drones Dataset, and
ETH-UCY. The quantitative results show we outperform the previous methods and achieve state-of-the-art performance.
Specifically, compared to MID [14], the proposed leapfrog diffusion model reduces the average prediction time from
∼886ms to ∼46ms on the NBA dataset, while achieving a 15.6%/13.4% ADE/FDE improvement.
The main contributions are concluded as follows,
• We propose a novel LEapfrog Diffusion model (LED), which is a denoising-diffusion-based stochastic trajectory prediction model. It achieves precise and diverse predictions with fast inference speed.
• We propose a novel trainable leapfrog initializer to directly model sophisticated denoised distributions, acceler-ating inference speed, and adaptively allocating the sample diversity, improving prediction performance.
• We conduct extensive experiments on four datasets including NBA, NFL, SDD, and ETH-UCY. Results show that i) our approach consistently achieves state-of-the-art performance on all datasets; and ii) our method speeds up the inference by around 20 times compared to the standard diffusion model, satisfying real-time prediction needs. 2.