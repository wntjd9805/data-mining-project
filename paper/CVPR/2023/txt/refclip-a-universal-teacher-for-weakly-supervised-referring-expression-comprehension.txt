Abstract
Referring Expression Comprehension (REC) is a task of grounding the referent based on an expression, and its de-velopment is greatly limited by expensive instance-level an-notations. Most existing weakly supervised methods are built based on two-stage detection networks, which are computationally expensive. In this paper, we resort to the efficient one-stage detector and propose a novel weakly su-pervised model called RefCLIP. Specifically, RefCLIP re-defines weakly supervised REC as an anchor-text matching problem, which can avoid the complex post-processing in existing methods. To achieve weakly supervised learning, we introduce anchor-based contrastive loss to optimize Re-fCLIP via numerous anchor-text pairs. Based on RefCLIP, we further propose the first model-agnostic weakly super-vised training scheme for existing REC models, where Ref-CLIP acts as a mature teacher to generate pseudo-labels for teaching common REC models. With our careful designs, this scheme can even help existing REC models achieve better weakly supervised performance than RefCLIP, e.g.,
TransVG and SimREC. To validate our approaches, we con-duct extensive experiments on four REC benchmarks, i.e.,
RefCOCO, RefCOCO+, RefCOCOg and ReferItGame. Ex-perimental results not only report our significant perfor-mance gains over existing weakly supervised models, e.g.,
+24.87% on RefCOCO, but also show the 5x faster infer-ence speed. Project: https://refclip.github.io. 1.

Introduction
Referring Expression Comprehension (REC), also known as visual grounding [5, 16], aims to locate the target instance in an image based on a referring expres-*Equal Contribution.
†Corresponding Author.
Figure 1.
Illustration of the proposed RefCLIP and weakly-supervised training scheme. RefCLIP selects the target bounding box from YOLOv3 via anchor-text matching, which is optimized by anchor-based contrastive learning. Our training scheme uses
RefCLIP as a mature teacher to supervise common REC models , which requires no network modifications. sion [25–27, 42, 48]. As a cross-modal recognition task,
REC is not limited to a fixed set of object categories and is theoretically capable of any open-ended detection [45].
These appealing properties give REC increasing attention from the community of computer vision [25, 28, 45–48].
However, the expensive instance-level annotation has long plagued its development.
To this end, recent progress has been devoted to the re-search of weakly supervised REC models, which aim to learn detection based merely on language information [7, 38, 43]. Specifically, existing methods extend the two-stage object detector like Faster-RCNN [37] to a weakly super-vised REC model. In terms of methodology, they regard the
REC as a region-text ranking problem, where the salient re-gions of an image are first extracted by Faster-RCNN and then ranked via cross-modal matching. To achieve weakly supervised training, they only use expressions as supervi-sion information and optimize the ranking modules via se-mantic reconstruction [19,20,38] or cross-modal contrastive learning [7, 43]. However, these methods are often inferior in inference speed due to the use of Faster-RCNN.
To overcome these limitations, we resort to one-stage de-tectors for weakly supervised REC. Compared with Faster-RCNN, one-stage detectors like YOLOv3 [36] have obvi-ous advantages in efficiency, but it is intractable to directly adapt them to existing weakly supervised schemes. Above all, existing one-stage detectors [17, 36] predict the bound-ing boxes based on the features of the last few convolution layers, also known as anchor points [36]. In terms of multi-scale detection, thousands of bounding boxes will be pre-dicted for an image, so transforming them into region fea-tures becomes more time consuming1. However, we notice that the receptive field of convolution features will be much larger than the actual areas they represent [29], suggesting that an anchor point in the one-stage detector may contain enough information for recognition.
Motivated by the above observations, we define weakly supervised REC as an anchor-text matching problem and propose a novel weakly supervised model named RefCLIP.
Specifically, we change the task definition from which de-tected region is the referent to which anchor point has the target bounding box. In this case, we can directly rank an-chor points without complex post-processing like ROI pool-ing and NMS [37]. To achieve weakly supervised learning,
RefCLIP performs anchor-based contrastive learning inter and intra images, thereby learning vision-language align-ments via numerous anchor-text pairs. Notably, this con-trastive learning scheme also exhibits superior flexibility in negative sample augmentation, which is not constrained by the batch size.
In this paper, we also focus on the model-agnostic train-ing scheme for weakly supervised REC. Including Ref-CLIP, all existing solutions are model-specific, which can not directly generalize to existing supervised REC mod-els
[5, 25, 42, 45]. To this end, we further propose the first model-agnostic weakly supervised training scheme for
REC. Specifically, we use RefCLIP as a teacher to produce pseudo-labels, i.e., bounding boxes, to supervise common
REC models. Meanwhile, we also alleviate the confirma-tion bias [1] caused by pseudo-label noise via EMA [39] and data augmentation [13]. In this scheme, existing REC models can be weakly trained without any modification, which makes our work greatly different from the existing ones [7, 18–20, 38].
To validate the proposed RefCLIP and weakly su-pervised training scheme, we conduct extensive experi-ments on four REC benchmarks, i.e., RefCOCO [32], Ref-COCO+ [32], RefCOCOg [30] and ReferItGame [10], and 1With confidence filtering, this processing still requires about 26.6% additional computation on COCO images. compare with a bunch of latest weakly supervised REC models [18, 22, 38, 41]. We apply our training scheme to several representative REC models including RealGIN [45],
TransVG [5] and SimREC [25]. Experimental results show obvious performance gains of our RefCLIP over existing weakly supervised REC models, e.g., +21.25% on Ref-COCO. Meanwhile, with our careful designs, the proposed training scheme can even help these REC models obtain new SOTA performance of weakly supervised REC.
Conclusively, our main contributions are three-fold:
• We propose a novel one-stage contrastive model called
RefCLIP, which achieves weakly supervised REC via anchor-based cross-modal contrastive learning and significantly improves the inference speed by 5 times.
• We propose the first generic weakly supervised train-ing scheme for common REC models, which can effec-tively boost any REC model using pseudo-labels gen-erated by our RefCLIP.
• The proposed RefCLIP outperforms existing ap-poroaches on four benchmarks, and our training scheme also helps previous REC models obtain new weakly supervised SOTA performance. 2.