Abstract
Single image defocus deblurring (SIDD) refers to recov-ering an all-in-focus image from a defocused blurry one. It is a challenging recovery task due to the spatially-varying defocus blurring effects with signiﬁcant size variation. Mo-tivated by the strong correlation among defocus kernels of different sizes and the blob-type structure of defocus ker-nels, we propose a learnable recursive kernel representa-tion (RKR) for defocus kernels that expresses a defocus ker-nel by a linear combination of recursive, separable and pos-itive atom kernels, leading to a compact yet effective and physics-encoded parametrization of the spatially-varying defocus blurring process. Afterwards, a physics-driven and efﬁcient deep model with a cross-scale fusion structure is presented for SIDD, with inspirations from the truncated
Neumann series for approximating the matrix inversion of the RKR-based blurring operator. In addition, a reblurring loss is proposed to regularize the RKR learning. Extensive experiments show that, our proposed approach signiﬁcantly outperforms existing ones, with a model size comparable to that of the top methods. 1.

Introduction
Defocus blurring is a type of degradation that can occur in optical systems when capturing an image with varying scene depths. In an optical system, in order to project an im-age of objects onto ﬁlm, a lens is used to bend the incoming light inwards, causing the light rays to trace out the shape of a cone and converge at the cone apex. When the distance between an object and the lens makes the cone apex just touch the ﬁlm, the light rays will produce tiny illuminated circles and the object will appear in focus. In other words, the captured image is only clear for objects that are at a cer-tain distance from the lens, known as the focal plane, which
*This work was supported by Natural Science Foundation of Guang-dong Province (Grant No. 2022A1515011755 and 2023A1515012841), and Singapore MOE AcRF Tier 1 Grant (WBS No. A-8000981-00-00). is determined by the distance between the lens and the ﬁlm.
For the objects away from the focal plane, the light rays will spread out, resulting in big illuminated circles (called circle(s) of confusion, CoC) that overlap with others. As a result, these objects appear blurry in the image.
As defocus blurring can cause the loss of image details that are crucial for subsequent vision tasks, many appli-cations can beneﬁt from the recovery of all image details from a defocused image, such as photo refocusing, seman-tic segmentation, text recognition, and object detection; see e.g. [25]. Single image defocus deblurring (SIDD) is a tech-nique for this purpose, i.e., recovering an all-in-focus (AIF) image with sharp and clear details from a defocused image.
In a defocused image, each pixel is associated with a de-focus kernel Kh,w related to CoC. As the CoC of a pixel is determined by the distance of its scene point to the focal plane, pixels with different scene depths will have differ-ent defocus kernels, i.e., the defocus blurring is spatially-varying. The relation between a defocused image Y and its
AIF counterpart X can be expressed as Y = D ◦ X, i.e. applying a blurring operator D to X as follows:
Y [h, w] = (D◦X)[h, w] := (cid:88) r,c
Kh,w[r, c]X[h−r, w−c].
SIDD then needs to estimate X and {Kh,w}h,w, which is a challenging non-uniform blind deblurring problem.
Most existing studies on SIDD are a by-product of defo-cus map estimation [4,7,9,16,17,20,26,29,37,42,44,50,51].
That is, a defocused image is deblurred by calling some non-blind deblurring method using the defocus kernels de-rived from an estimated defocus map; see e.g. [10, 18, 19, 22,26,33,43]. Such an approach often suffers from the sen-sitivity of non-blind deblurring to kernel estimation errors and is usually computationally expensive. In recent years, it has emerged as a promising approach to train an end-to-end deep neural network (DNN) for SIDD using one or more datasets; see e.g. [1, 14, 21, 25, 27, 32, 35, 49]. However, ex-isting work still has a large room for performance improve-ment. The aim of this paper is to develop an end-to-end
deep learning-based approach for SIDD that brings notice-able performance improvement over existing methods. 1.1. Main Idea
Given a defocused image, estimating the defocus kernel
Kh,w for each pixel suffers from severe solution ambiguity.
As their sizes have signiﬁcant variations, a plain matrix ex-pression of these kernels with the maximum size will lead to an overwhelming number of unknowns and overﬁtting. It is critical to have a compact representation of defocus kernels with a much reduced number of unknowns, yet sufﬁcient to express a wide range of defocus kernels. Our solution is the so-called recursive kernel representation (RKR) model.
The RKR model expresses a defocus kernel via a linear combination over a learnable dictionary composed by a set of atom kernels. The atom kernels are deﬁned using the tensor product of 1D positive kernels in a recursive scheme.
Such a recursive and separable structure leads to a compact parametrization of defocus kernels whose sizes may vary over a wide range, as well as a fast computational scheme for the spatially-varying blurring operator, involving only a few convolutions and point-wise multiplications. In addi-tion, RKR also encodes implicit physical priors of defocus kernels, such as strong correlation among defocus kernels of different sizes in the same image, and blob-type kernel supports. Further, RKR provides a learnable and more ex-pressive representation for real-world defocus kernels, com-pared to predeﬁned Gaussian-based models [32, 37].
Different from uniform blurring modeled by a convolu-tion, whose inversion can be efﬁciently calculated via fast
Fourier transform (FFT), the inversion of a defocus blur-ring operator has no known transform for fast calculation.
Inspired by the approximation of truncated Neumann series (NS) to matrix inversion, we utilize truncated NS expansion and the RKR model to express such an inversion, leading to an efﬁcient formulation that only involves standard convo-lutions and point-wise multiplications. Then, we develop a DNN called NRKNet (Neumann Recursive Kernel Net-work) for SIDD, with a cross-scale fusion structure inspired from the truncated NS expansion expressed in a coarse-to-ﬁne fashion. The NRKNet mainly contains a learnable atom kernel set for RKR and a learnable module for predict-ing coefﬁcient matrices at different scales for cross-scale fusion-based deblurring, both of which are efﬁcient. In ad-dition, we introduce a reblurring loss for further regulariz-ing the learning of RKR-based defocus kernel prediction, which measures the reconstruction error w.r.t. input image using learned atoms kernels and predicted coefﬁcients. 1.2. Contributions
Modeling defocus kernels and designing a deblurring process are two key parts for developing an effective SIDD approach. This paper provides new solutions to both. Com-pared to existing Gaussian-based models of defocus ker-nels, our RKR model is applicable to more-general non-Gaussian and non-isotropic defocus kernels. Moreover, our proposed cross-scale fusion structure inspired from the truncated NS approximation leads to a computationally-efﬁcient physics-driven DNN for SIDD. See below for a summary of our technical contributions:
• An RKR model for compact parametric representation of defocus kernels, with physical priors encoded;
• An efﬁcient DNN for SIDD with a cross-scale fusion structure inspired from truncated NS approximation;
• A reblurring loss for regularizing the learning of defo-cus kernel prediction.
The results in extensive experiments show that our proposed approach brings noticeable performance gain over existing ones, with a relatively-small model size. 2.