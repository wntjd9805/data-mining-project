Abstract
Monocular depth estimation is fundamental for 3D scene understanding and downstream applications. However, even under the supervised setup, it is still challenging and ill-posed due to the lack of full geometric constraints. Although a scene can consist of millions of pixels, there are fewer high-level patterns. We propose iDisc to learn those patterns with internal discretized representations. The method im-plicitly partitions the scene into a set of high-level patterns.
In particular, our new module, Internal Discretization (ID), implements a continuous-discrete-continuous bottleneck to learn those concepts without supervision. In contrast to state-of-the-art methods, the proposed model does not en-force any explicit constraints or priors on the depth output.
The whole network with the ID module can be trained end-to-end, thanks to the bottleneck module based on attention.
Our method sets the new state of the art with significant improvements on NYU-Depth v2 and KITTI, outperform-ing all published methods on the official KITTI benchmark. iDisc can also achieve state-of-the-art results on surface normal estimation. Further, we explore the model gener-alization capability via zero-shot testing. We observe the compelling need to promote diversification in the outdoor scenario. Hence, we introduce splits of two autonomous driving datasets, DDAD and Argoverse. Code is available at http://vis.xyz/pub/idisc. 1.

Introduction
Depth estimation is essential in computer vision, espe-cially for understanding geometric relations in a scene. This task consists in predicting the distance between the projec-tion center and the 3D point corresponding to each pixel.
Depth estimation finds direct significance in downstream applications such as 3D modeling, robotics, and autonomous cars. Some research [62] shows that depth estimation is a crucial prompt to be leveraged for action reasoning and execution. In particular, we tackle the task of monocular depth estimation (MDE). MDE is an ill-posed problem due to its inherent scale ambiguity: the same 2D input image can correspond to an infinite number of 3D scenes. (a) Input image (b) Output depth (c) Intermediate representations (d) Internal discretization
Figure 1. We propose iDisc which implicitly enforces an internal discretization of the scene via a continuous-discrete-continuous bottleneck. Supervision is applied to the output depth only, i.e., the fused intermediate representations in (c), while the internal discrete representations are implicitly learned by the model. (d) displays some actual internal discretization patterns captured from the input, e.g., foreground, object relationships, and 3D planes. Our iDisc model is able to predict high-quality depth maps by capturing scene interactions and structure.
State-of-the-art (SotA) methods typically involve convo-lutional networks [12, 13, 24] or, since the advent of vision
Transformer [11], transformer architectures [3, 41, 54, 59].
Most methods either impose geometric constraints on the image [22, 33, 38, 55], namely, planarity priors or explicitly discretize the continuous depth range [3,4,13]. The latter can be viewed as learning frontoparallel planes. These imposed priors inherently limit the expressiveness of the respective models, as they cannot model arbitrary depth patterns, ubiq-uitous in real-world scenes.
We instead propose a more general depth estimation model, called iDisc, which does not explicitly impose any constraint on the final prediction. We design an Internal
Discretization (ID) of the scene which is in principle depth-agnostic. Our assumption behind this ID is that each scene can be implicitly described by a set of concepts or patterns,
such as objects, planes, edges, and perspectivity relation-ships. The specific training signal determines which patterns to learn (see Fig. 1).
We design a continuous-to-discrete bottleneck through which the information is passed in order to obtain such inter-nal scene discretization, namely the underlying patterns. In the bottleneck, the scene feature space is partitioned via learnable and input-dependent quantizers, which in turn transfer the information onto the continuous output space.
The ID bottleneck introduced in this work is a general con-cept and can be implemented in several ways. Our partic-ular ID implementation employs attention-based operators, leading to an end-to-end trainable architecture and input-dependent framework. More specifically, we implement the continuous-to-discrete operation via “transposed” cross-attention, where transposed refers to applying softmax on the output dimension. This softmax formulation enforces the input features to be routed to the internal discrete rep-resentations (IDRs) in an exclusive fashion, thus defining an input-dependent soft clustering of the feature space. The discrete-to-continuous transformation is implemented via cross-attention. Supervision is only applied to the final out-put, without any assumptions or regularization on the IDRs.
We test iDisc on multiple indoor and outdoor datasets and probe its robustness via zero-shot testing. As of to-day, there is too little variety in MDE benchmarks for the outdoor scenario, since the only established benchmark is
KITTI [17]. Moreover, we observe that all methods fail on outdoor zero-shot testing, suggesting that the KITTI dataset is not diverse enough and leads to overfitting, thus implying that it is not indicative of generalized performance. Hence, we find it compelling to establish a new benchmark setup for the MDE community by proposing two new train-test splits of more diverse and challenging high-quality outdoor datasets: Argoverse1.1 [8] and DDAD [18].
Our main contributions are as follows: (i) we introduce the Internal Discretization module, a novel architectural com-ponent that adeptly represents a scene by combining under-lying patterns; (ii) we show that it is a generalization of SotA methods involving depth ordinal regression [3, 13]; (iii) we propose splits of two raw outdoor datasets [8, 18] with high-quality LiDAR measurements. We extensively test iDisc on six diverse datasets and, owing to the ID design, our model consistently outperforms SotA methods and presents better transferability. Moreover, we apply iDisc to surface nor-mal estimation showing that the proposed module is general enough to tackle generic real-valued dense prediction tasks. 2.