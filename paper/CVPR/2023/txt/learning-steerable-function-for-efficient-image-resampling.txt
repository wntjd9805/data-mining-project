Abstract
Image resampling is a basic technique that is widely employed in daily applications. Existing deep neural net-works (DNNs) have made impressive progress in resam-pling performance. Yet these methods are still not the per-fect substitute for interpolation, due to the issues of effi-ciency and continuous resampling. In this work, we propose a novel method of Learning Resampling Function (termed
LeRF), which takes advantage of both the structural priors learned by DNNs and the locally continuous assumption of interpolation methods. Specifically, LeRF assigns spatially-varying steerable resampling functions to input image pix-els and learns to predict the hyper-parameters that deter-mine the orientations of these resampling functions with a neural network. To achieve highly efficient inference, we adopt look-up tables (LUTs) to accelerate the inference of the learned neural network. Furthermore, we design a directional ensemble strategy and edge-sensitive indexing patterns to better capture local structures. Extensive exper-iments show that our method runs as fast as interpolation, generalizes well to arbitrary transformations, and outper-forms interpolation significantly, e.g., up to 3dB PSNR gain over bicubic for ×2 upsampling on Manga109. 1.

Introduction
Due to the rapid growth of visual data, there is a strong demand for digital image processing.
Image resampling, one of the most common techniques, aims to obtain an-other image by generating new pixels following a geomet-ric transformation rule from existing pixels in a given im-age [8]. Common transformations include upsampling (i.e., single image super-resolution), downsampling, affine trans-formation, etc. Image resampling enjoys various applica-tions, ranging from photo editing, optical distortion com-*Equal contribution. †Corresponding author. This work was done when
Jiacheng Li was a research intern at Huawei Noah’s Ark Lab.
Figure 1. LeRF assigns steerable resampling functions to input pixels, and learns to predict the hyper-parameters that determine the orientations of these continuous functions for resampling un-der arbitrary transformations. pensation [10], online content streaming [35], and visual special effects production [38].
Recently, deep neural networks (DNNs) have made im-pressive progress in the field of image resampling [9,12,17, 27, 39, 40], thanks to the learning-from-data paradigm that obtains powerful structural priors from large-scale datasets.
Despite the superior performance that DNN-based methods have achieved, long-lived interpolation methods like bicu-bic [16] are still preferred choices in most cases.
We attribute this phenomenon to the following two rea-sons: 1) Interpolation is simple and highly efficient, result-ing in less dependency and thus the practicality to be de-ployed on a variety of devices, ranging from IoT devices to gaming workstations. 2) Interpolation supports arbitrary transformations. It assumes a continuous resampling func-tion for a local area, resulting in the versatility in applying to not only homographic transformations like upsampling and downsampling, but also general warping. Although re-cent DNN-based methods explore beyond fixed-scale up-sampling [5, 12, 27, 39, 43, 48], an efficient and continuous
solution that matches interpolation remains less explored.
In this work, we aim to fill this blank research area by taking a middle way between DNN-based methods and interpolation methods. We propose a novel method of
Learning Resampling Function (termed LeRF), where pa-rameterized continuous functions for resampling different structures are learned from data. Specifically, as illustrated in Fig. 1, we assign spatially-varying steerable resampling functions to image pixels, whose orientations are parame-terized with several hyper-parameters. Then, we train a neu-ral network to predict these hyper-parameters for each pixel in an input image, thus defining the resampling function for that pixel location. Finally, we obtain the output image by interpolating an input image with these locally adapted resampling functions. LeRF takes advantage of both the structural priors learned by DNN and the locally continu-ous assumption of interpolation methods. Furthermore, we present an efficient implementation, where the inference of the learned neural network is accelerated with look-up ta-bles (LUTs) [15, 22, 23, 29]. We further design a directional ensemble strategy and edge-sensitive indexing patterns to better capture local structures in images.
We examine the advantages and generalization abil-ity of LeRF in various image resampling tasks, includ-ing arbitrary-scale upsampling, homographic transforma-In particular, as illustrated in tion, and general warping.
Fig. 2, at a similar running time, our method outperforms popular interpolation methods significantly in upsampling, which demonstrates the superiority of LeRF in terms of per-formance and efficiency.
Contributions of this paper are summarized as follows: 1) We propose LeRF, a novel method for continuous re-sampling. We assign spatially-varying steerable resampling functions to image pixels, where we train a neural network to predict the hyper-parameters that determine the orienta-tions of these resampling functions. 2) We present an efficient implementation of LeRF by adopting look-up tables to accelerate the inference of the trained neural network. Furthermore, we design a direc-tional ensemble strategy and edge-sensitive indexing pat-terns to better capture local structures. 3) Extensive experiments demonstrate that our method operates as efficient as interpolation, generalizes well to ar-bitrary transformations, and obtains significantly better per-formance over interpolation. 2.