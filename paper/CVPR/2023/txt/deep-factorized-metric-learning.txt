Abstract
Learning a generalizable and comprehensive similarity metric to depict the semantic discrepancies between images is the foundation of many computer vision tasks. While ex-isting methods approach this goal by learning an ensemble of embeddings with diverse objectives, the backbone net-work still receives a mix of all the training signals. Differ-ently, we propose a deep factorized metric learning (DFML) method to factorize the training signal and employ different samples to train various components of the backbone net-work. We factorize the network to different sub-blocks and devise a learnable router to adaptively allocate the training samples to each sub-block with the objective to capture the most information. The metric model trained by DFML cap-ture different characteristics with different sub-blocks and constitutes a generalizable metric when using all the sub-blocks. The proposed DFML achieves state-of-the-art per-formance on all three benchmarks for deep metric learn-ing including CUB-200-2011, Cars196, and Stanford On-line Products. We also generalize DFML to the image clas-sification task on ImageNet-1K and observe consistent im-provement in accuracy/computation trade-off. Specifically, we improve the performance of ViT-B on ImageNet (+0.2% accuracy) with less computation load (-24% FLOPs). 1 1.

Introduction
Learning good representations for images has always been the core of computer vision, yet measuring the sim-ilarity between representations after obtaining them is an equally important problem. Focusing on this, metric learn-ing aims to learn a discriminative similarity metric un-der which the interclass distances are large and the intra-class distances are small. Using a properly learned simi-larity metric can improve the performance of downstream tasks and has been employed in many applications such
*Equal contribution.
â€ Corresponding author. 1Code is available at: https://github.com/wangck20/DFML.
Figure 1. Comparisons between ensemble-based deep metric learning methods and DFML. Ensemble-based DML learns an ensemble of embeddings where diverse objectives are employed.
Differently, DFML factorizes the backbone and learns a certain routine for each sample to achieve the diversity of features, which further boosts the generalization ability of the model on unseen classes. (Best viewed in color.) as semantic instance segmentation [7, 21, 37], remote sens-ing [5, 10, 31], and room layout estimation [77].
Modern metric learning methods [44, 55, 56, 78] usually exploit deep neural networks to map an image to a single embedding and use the Euclidean distance or cosine simi-larity between embeddings to measure the similarity. As a single embedding might not be able to fully characterize an image, a number of methods [1, 43, 47, 49, 72, 79, 80] begin to explore using an ensemble of embeddings to represent an image, where each embedding describes one attribute of the image. The key to ensemble-based methods lies in how to enforce diversity in the ensemble of embeddings so that they can capture more characteristics. They achieve this by using a diversity loss [47, 49], selecting different samples [53, 72, 80], and adopting various tasks [43, 79], etc. Most existing methods adopt a shared backbone net-work to extract a common feature and only apply a single fully connected layer to obtain each specialized embedding.
However, the shared backbone limits the diversity of the en-semble and hinders its ability to capture more generalizable features. It still receives a mix of all the training signals and can hardly produce diverse embeddings.
To address this, we propose a deep factorized metric learning (DFML) method to adaptively factorize the train-ing signals to learn more generalizable features, as shown in 1. We first factorize each block of the metric back-bone model to a number of sub-blocks, where we make the summed features of all the sub-blocks to be equal to that of the full block. As different samples may possess distinct characteristics [80], we devise a learnable router to adaptively allocate the training samples to the correspond-ing sub-blocks. We learn the router using a reconstruction objective to encourage each sample to be processed by the most consistent sub-block. We demonstrate the proposed
DFML framework is compatible with existing deep met-ric learning methods with various loss functions and sam-pling strategies and can be readily applied to them. Due to the better modularity of vision transformers (ViTs) [15,61], we mainly focus on factorizing ViTs and further bench-mark various existing deep metric learning methods on
ViTs. Extensive experiments on the widely used CUB-200-2011 [63], Cars196 [35], and Stanford Online Products [56] datasets show consistent improvements of DFML over ex-isting methods. We also provide an in-depth analysis of the proposed DFML framework to verify its effectiveness.
Specifically, we show that backbone models trained by our
DFML achieve better accuracy/computation trade-off than the original model on ImageNet-1K [52] and even improve the performance of ViT-B (+0.2% accuracy) with less com-putation load (-24% FLOPs). 2.