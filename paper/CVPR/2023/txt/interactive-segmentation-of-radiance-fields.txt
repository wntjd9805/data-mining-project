Abstract
Radiance Fields (RF) are popular to represent casually-captured scenes for new view synthesis and several ap-plications beyond it. Mixed reality on personal spaces needs understanding and manipulating scenes represented as RFs, with semantic segmentation of objects as an im-portant step. Prior segmentation efforts show promise but don’t scale to complex objects with diverse appearance.
We present the ISRF method to interactively segment ob-jects with fine structure and appearance. Nearest neighbor feature matching using distilled semantic features identifies high-confidence seed regions. Bilateral search in a joint spatio-semantic space grows the region to recover accu-rate segmentation. We show state-of-the-art results of seg-menting objects from RFs and compositing them to another scene, changing appearance, etc., and an interactive seg-mentation tool that others can use. 1.

Introduction
Scene representation is a crucial step for any scene un-derstanding or manipulation task. Relevant scene parame-ters, be it shape, appearance, or illumination, can be rep-resented using various modalities like 2D (depth/texture) maps, point clouds, surface meshes, voxels, parametric functions, etc. Each modality has its strengths and weak-Project Page: https://rahul-goel.github.io/isrf/
∗ Equal Contribution nesses. For example, shape correspondence is straightfor-ward between point clouds compared to surface meshes but compromises rendering fidelity. Thus, choosing an appro-priate representation has a major impact on downstream analyses and applications.
Neural implicit representations have emerged as a promising modality for 3D analysis recently. Although ini-tially proposed only for shapes [28, 34], they have been extended to encode complete directional radiance at a point [30], other rendering parameters like lightfields, spec-textual context, object semantics, etc. [1, 9, 11, ularity, 12, 16, 19, 50]. The representation was extended beyond static inward-looking and front-facing scenes to complex outward-looking unbounded 360◦ views, dynamic clips, oc-cluded egocentric videos, and unconstrained images.
Radiance fields have also been used beyond Novel View
Synthesis (NVS) for other applications [5, 26, 35, 43, 46, 48, 52, 55, 58]. Segmenting objects of the scene representation is a first step towards its understanding and manipulation for different downstream tasks. There have been a few ef-forts at segmenting and editing of radiance fields. Recently,
N3F [47], and DFF [21] presented preliminary solutions to this in the neural space of radiance fields. Both use dis-tillation for feature matching between user-provided cues with the learned 3D feature volume, with N3F using user-provided patches and DFF using textual prompts or patches as the segmentation cues. These methods struggle to seg-ment objects with a wide appearance variation. The NVOS system provides segmentation with strokes but have poor quality and non-interactive computations [37].
Figure 2. ISRF System overview: We capture a 3D scene of voxelized radiance field and distill the semantic feature into it. Once captured, the user can easily mark regions using a brush tool on a reference view (green[ ] stroke). The features are collected corresponding to the marked pixels and clustered using K-Means. The voxel-grid is then matched using NNFM (nearest neighbor feature matching) to obtain a high confidence seed using a tight threshold. The seed is then grown using bilateral search to smoothly cover the boundaries of the object, conditioning the growth in the spatio-semantic domain.
In this paper, we present a simple and efficient method to interactively segment objects in a radiance field represen-tation. Our ISRF method uses an intuitive process with the user providing easy strokes to guide it interactively. We use the fast and memory-efficient TensoRF representation [7] to train and render. TensoRF uses an explicit voxel repre-sentation that is more amenable to manipulation. We in-clude a DINO feature [6] at every voxel to facilitate seman-tic matching from 2D to 3D. DINO features are trained on a large collection of images and are known to capture seman-tics effectively. We condense the DINO features from the user-specified regions to create a fixed-length set using K-Means. A nearest neighbor feature matching (NNFM) on this set in the 3D voxels identifies a high-confidence seed region of the object to be segmented. The seed region is grown using a bilateral filtering-inspired search to include neighboring proximate voxels in a joint feature-geometric space. We show results of segmenting several challenging objects in forward facing [29] and 360 degrees [2] scenes.
The explicit voxel space we use facilitates simple modifi-cation for segmenting objects. We also show examples of compositing objects from one RF into another. In summary, the following are the core contributions of ISRF:
◦ An easily interpretable and qualitatively improved 3D object segmentation framework for radiance fields.
◦ Interactive modification of segmentation to capture fine structure, starting with high-confidence matching.
Our representation allows a spatio-semantic bilateral search to make this possible. The framework can also use other generalized distances to grow the region for specific applications.
◦ A hybrid implicit-explicit representation that is memory-efficient and fast to render also facilitates the distillation of semantic information for improved seg-mentation. Our results show improved accuracy and fine-grain object details in very challenging situations over contemporary efforts.
◦ An easy-to-use, GUI based tool to interactively seg-ment objects from an RF representation to facilitate object replacement, alteration, etc.
◦ Consistent 2D/3D segmentation masks for a few scenes and objects created manually using our method to facilitate future work in segmentation, manipula-tion, and understanding of RFs.
2.