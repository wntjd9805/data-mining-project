Abstract
Product Retrieval (PR) and Grounding (PG), aiming to seek image and object-level products respectively according to a textual query, have attracted great interest recently for better shopping experience. Owing to the lack of relevant datasets, we collect two large-scale benchmark datasets from Taobao Mall and Live domains with about 474k and 101k image-query pairs for PR, and manually annotate the object bounding boxes in each image for PG. As anno-tating boxes is expensive and time-consuming, we attempt to transfer knowledge from annotated domain to unanno-tated for PG to achieve un-supervised Domain Adaptation (PG-DA). We propose a Domain Adaptive Product Seeker (DATE) framework, regarding PR and PG as Product Seek-ing problem at different levels, to assist the query date the product. Concretely, we first design a semantics-aggregated feature extractor for each modality to obtain concentrated and comprehensive features for following efficient retrieval and fine-grained grounding tasks. Then, we present two cooperative seekers to simultaneously search the image for PR and localize the product for PG. Besides, we de-vise a domain aligner for PG-DA to alleviate uni-modal marginal and multi-modal conditional distribution shift be-tween source and target domains, and design a pseudo box generator to dynamically select reliable instances and gen-erate bounding boxes for further knowledge transfer. Exten-sive experiments show that our DATE achieves satisfactory performance in fully-supervised PR, PG and un-supervised
PG-DA. Our desensitized datasets will be publicly available here1. 1.

Introduction
Nowadays, with the rapid development of e-commerce and livestreaming, consumers can enjoy shopping on e-mall or various livestreaming platforms. Although the fact that
*Corresponding author. 1https://github.com/Taobao-live/Product-Seeking
Figure 1.
Illustration of Product Retrieval (PR) and Grounding (PG) problems on two datasets collected from Taobao Mall and
Live. (1) Given a text query (i.e. Chinese title or description of a product), PR is to seek the corresponding image-level product from gallery while PG is to seek the object-level product from an (2) We further explore PG-DA, which aims to transfer image. knowledge from the annotated source domain to the unannotated target domain under the influence of multi-modal domain gap to achieve un-supervised PG. diverse products can be presented and purchased on screen brings us convenience, we are immersed in this miscel-laneous product world. Therefore, cross-modal Retrieval
[1, 3, 15, 21, 41, 43, 55] for Product (PR), aiming to seek the corresponding image based on a text query, is significant for boosting holistic product search engine and promoting consumers’ shopping experience.
Besides, provided that the object-level product can be localized on the target product image or live room im-age according to a query, it will help consumers focus on the desired product and also benefit the downstream vision-to-vision retrieval. And we name this interesting task as Product Grounding (PG) like Visual Grounding
[29, 36, 40, 45, 56]. Generally, PR and PG are seen as two separate tasks, but we consider mining the commonalities of
PR and PG and regard them as Product Seeking at image-level and object-level respectively. And we design a uni-fied architecture to simultaneously solve PR and PG, which is more time-saving and memory-economical than separate methods.
To research the PR and PG with great practical applica-tion value, we collect two large-scale benchmark Product
Seeking datasets TMPS and TLPS from Taobao Mall and
Taobao Live domains with about 474k image-title pairs and 101k frame-description pairs respectively, and the locations of object-level products in images are manually annotated.
As annotating bounding box of product is time-consuming and expensive, we explore how to transfer knowledge from an annotated domain to the unannotated one, and achieve un-supervised PG in domain adaptation setting (PG-DA).
Thus, we propose the Domain Adaptive Product Seeker (DATE) to solve the following aspects of the challenging
PR, PG and PG-DA problems.
Firstly, due to the complexity of the mall and live scenar-ios, discriminative representations of the image and query are prerequisite to accurately localize the object. Consid-ering conventional CNNs are hard to achieve long-distance relation reasoning and full-scale understanding, we utilize and improve the Swin-TF [37] to extract hierarchical and comprehensive features. As large-scale image seeking is demanding for PR, it is vital to ensure seeking inference is of trivial cost. Thus, we inject [REP] token into Swin-TF to absorb the weighted global semantics, and condense them into a single vector, which will be discriminative and concentrated for following efficient image seeking. And we perform the same semantics-aggregated technique for query feature extraction.
Secondly, the capacity of both macroscopic image seek-ing and microcosmic fine-grained object seeking is neces-sary for PR and PG. Therefore, we present two cooperative seekers, where image seeker calculates the cosine similar-ity between visual and textual concentrated features for PR, and object seeker based on cross-modal interaction trans-former directly predicts the coordinates of the product by comprehensive features for PG. We validate the reasonable-ness of such cooperative strategy through experiments.
Thirdly, due to the domain gap between two datasets as
Figure 1 shown, applying the model straightway to test on target domain will cause performance degeneration severely for PG-DA. To the best of our knowledge, this is the first work to consider un-supervised Visual Grounding in do-main adaptation setting, and most uni-modal DA [8, 34, 38] and multi-modal DA [5,7] methods are not directly applica-ble in our complicated object seeking. Therefore, we devise a domain aligner based on Maximum Mean Discrepancy to align the domain by minimizing uni-modal marginal distri-bution and multi-modal conditional distribution divergence between source and target domains, and design a dynamic pseudo bounding box generator to select similar instances in target domain and generate reliable boxes for knowledge transfer.
To summarize, the contributions of this paper are as fol-lows:
• We collect and manually annotate two large-scale benchmark datasets for PR and PG with great practi-cal application value.
• We propose a unified framework with semantics-aggregated feature extractor and cooperative seekers to simultaneously solve fully-supervised PR and PG.
• We explore un-supervised PG in domain adaptation setting and design the multi-modal domain aligner and dynamic box generator to transfer knowledge.
• We conduct extensive experiments which shows that our methods achieve satisfactory performance in fully-supervised PR, PG and un-supervised PG-DA. 2.