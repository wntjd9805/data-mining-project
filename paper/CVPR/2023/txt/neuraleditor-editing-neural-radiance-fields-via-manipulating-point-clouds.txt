Abstract
This paper proposes NeuralEditor that enables neural radiance fields (NeRFs) natively editable for general shape editing tasks. Despite their impressive results on novel-view synthesis, it remains a fundamental challenge for NeRFs to edit the shape of the scene. Our key insight is to exploit the explicit point cloud representation as the underlying struc-ture to construct NeRFs, inspired by the intuitive interpreta-tion of NeRF rendering as a process that projects or “plots” the associated 3D point cloud to a 2D image plane. To this end, NeuralEditor introduces a novel rendering scheme based on deterministic integration within K-D tree-guided density-adaptive voxels, which produces both high-quality rendering results and precise point clouds through opti-mization. NeuralEditor then performs shape editing via mapping associated points between point clouds. Exten-sive evaluation shows that NeuralEditor achieves state-of-the-art performance in both shape deformation and scene morphing tasks. Notably, NeuralEditor supports both zero-shot inference and further fine-tuning over the edited scene.
Our code, benchmark, and demo video are available at im-mortalco.github.io/NeuralEditor. 1.

Introduction
Perhaps the most memorable shot of the film Transform-ers, Optimus Prime is seamlessly transformed between a humanoid and a Peterbilt truck – such free-form editing of 3D objects and scenes is a fundamental task in 3D com-puter vision and computer graphics, directly impacting ap-plications such as visual simulation, movie, and game in-dustries. In these applications, often we are required to ma-nipulate a scene or objects in the scene by editing or mod-ifying its shape, color, light condition, etc., and generate visually-faithful rendering results on the edited scene effi-ciently. Among the various editing operations, shape edit-ing has received continued attention but remains challeng-ing, where the scene is deformed in a human-guided way, while all of its visual attributes (e.g., shape, color, bright-ness, and light condition) are supposed to be natural and consistent with the ambient environment.
State-of-the-art rendering models are based on implicit neural representations, as exemplified by neural radiance field (NeRF) [27] and its variants [3, 33, 37, 39, 48]. Despite their impressive novel-view synthesis results, most of the
NeRF models substantially lack the ability for users to ad-just, edit, or modify the shape of scene objects. On the other hand, shape editing operations can be natively applied to ex-plicit 3D representations such as point clouds and meshes.
Inspired by this, we propose NeuralEditor – a general and flexible approach to editing neural radiance fields via manipulating point clouds (Fig. 1). Our key insight is to benefit from the best of both worlds: the superiority in rendering performance from implicit neural representation
combined with the ease of editing from explicit point cloud representation. NeuralEditor enables us to perform a wide spectrum of shape editing operations in a consistent way.
Such introduction of point clouds into NeRF for general shape editing is rooted in our interpretation of NeRF ren-dering as a process that projects or “plots” the associated 3D point cloud to a 2D image plane. Conceptually, with a dense enough point cloud where each point has an opacity and its color is defined as a function of viewing direction, di-rectly plotting the point cloud would achieve similar visual effects (i.e., transparency and view-dependent colors) that are rendered by NeRF. This intrinsic integration between
NeRF and point clouds underscores the advantage of our
NeuralEditor over existing mesh-based NeRF editing meth-ods such as NeRF-Editing [51], Deforming-NeRF [44], and
CageNeRF [30], where the process of constructing and op-timizing the mesh is separated from the NeRF modeling, making them time-consuming. More importantly, with the point cloud constructed for a scene, the shape editing can be natively defined as and easily solved by just moving each point into the new, edited position and re-plotting the point cloud. Therefore, our approach supports more general scene editing operations which are difficult to achieve via mesh-guided space deformation.
The key component in our NeuralEditor lies in a point cloud-guided NeRF model that natively supports general shape editing operations. While the recent method Point-NeRF [43] has demonstrated improved novel-view synthe-sis capability based on point clouds, it is not supportive to shape editing. Our idea then is to exploit the underlying point cloud in ways of not only optimizing its structure and features (e.g., adaptive voxels) for rendering, but also ex-tracting additional useful attributes (e.g., normal vectors) to guide the editing process. To this end, we introduce K-D trees [4] to construct density-adaptive voxels for efficient and stable rendering, together with a novel deterministic in-tegration strategy. Moreover, we model the color with the
Phong reflection [31] to decompose the specular color and better represent the scene geometry.
With a much more precise point cloud attributed to these improvements, our NeuralEditor achieves high-fidelity ren-dering results on deformed scenes compared with prior work as shown in Fig. 1, even in a zero-shot inference man-ner without additional training. Through fast fine-tuning, the visual quality of the deformed scene is further enhanced, almost perfectly consistent with the surrounding light con-dition. In addition, under the guidance of a point cloud dif-fusion model [24], NeuralEditor can be naturally extended for smooth scene morphing across multiple scenes, which is difficult for existing NeRF editing work.
Our contributions are four-fold. (1) We introduce
NeuralEditor, a flexible and versatile approach that makes neural radiance fields editable through manipulating point clouds. (2) We propose a point cloud-guided NeRF model based on K-D trees and deterministic integration, which produces precise point clouds and supports general scene editing. (3) Due to the lack of publicly available bench-marks for shape editing, we construct and release a repro-ducible benchmark that promotes future research on shape editing. (4) We investigate a wide range of shape editing tasks, covering both shape deformation (as studied in exist-ing NeRF editing work) and challenging scene morphing (a novel task addressed here). NeuralEditor achieves state-of-the-art performance on all shape editing tasks in a unified framework, without extra information or supervision. 2.