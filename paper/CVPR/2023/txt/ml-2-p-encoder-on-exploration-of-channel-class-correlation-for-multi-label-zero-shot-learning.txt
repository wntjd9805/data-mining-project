Abstract
Recent studies usually approach multi-label zero-shot learning (MLZSL) with visual-semantic mapping on spatial-class correlation, which can be computationally costly, and worse still, fails to capture fine-grained class-specific semantics. We observe that different channels may usually have different sensitivities on classes, which can correspond to specific semantics. Such an intrinsic channel-class correlation suggests a potential alternative for the more accurate and class-harmonious feature representa-tions. In this paper, our interest is to fully explore the power of channel-class correlation as the unique base for MLZSL.
Specifically, we propose a light yet efficient Multi-Label
Multi-Layer Perceptron-based Encoder, dubbed (ML)2P-Encoder, to extract and preserve channel-wise semantics.
We reorganize the generated feature maps into several groups, of which each of them can be trained independently with (ML)2P-Encoder. On top of that, a global group-wise attention module is further designed to build the multi-label specific class relationships among different classes, which eventually fulfills a novel Channel-Class Correlation
MLZSL framework (C3-MLZSL)1. Extensive experiments on large-scale MLZSL benchmarks including NUS-WIDE and
Open-Images-V4 demonstrate the superiority of our model against other representative state-of-the-art models. 1.

Introduction
The proliferation of smart devices has greatly enriched human life when it comes to the era of big data. These smart devices are usually equipped with cameras such that users can easily produce and share their images. With the increas-ing abundance of public images, how to analyze them ac-curately has become a challenging problem. Recent years
Figure 1. Example of Channel-Class Correlation. Our method achieves the prediction of unseen classes by exploiting the unique distribution of channel responses as semantic information for the class and building correlations with responses from the same chan-nel (zoom in for a better view). have witnessed great success in classifying an image into a specific class [20, 37, 39], namely, single-label classifica-tion. However, in reality, the images [17,46] usually contain abundant information and thereby consist of multiple labels.
In recent years, the multi-label classification has been widely investigated by exploring the relationship among different labels from multiple aspects [9, 13, 14, 16, 42].
However, in some scenarios where extensive collections of images exist, e.g., Flickr2, users can freely set one or more individual tags/labels for each image, while the presented objects and labels in these images may not be fully shown in any previous collection, and thus result in a domain gap for the recognition. Therefore, in real-world applications, the model is required to gain the ability to predict unseen classes as well. As one of the thriving research topics, zero-*Jingcai Guo is the corresponding author. 1Released code: github.com/simonzmliu/cvpr23_mlzsl 2https://www.flickr.com
shot learning (ZSL) [1, 12, 15, 34] is designed to transfer tasks from seen classes to unseen classes, and naturally recognizes novel objects of unseen classes. Specifically,
ZSL has made continuous success in single-label classifica-tion [19, 26, 31, 45, 48]. However, these methods can hardly be extended to the multi-label scenario since exploring the cross-class relationships in an image is non-trivial.
Recently, some works have focused on multi-label zero-shot learning (MLZSL) tasks and obtained some promising results [33, 36, 49]. Other works considered incorporating attention mechanisms into their models, such as LESA [22] and BiAM [35]. LESA [22] designed an attention-sharing mechanism for different patches in the image so that each patch can output the corresponding class. In another way,
BiAM [35] designed a bi-level attention to extract relations from regional context and scene context, which can enrich the regional features of the model and separate the features of different classes.
Although previous works have made considerable progress, their designed methods have been limited to the processing of spatial-domain information. First of all, the over-reliance on spatial-class correlation fails to capture fine-grained class-specific semantics. In addition, the ad-ditional processing of spatial information greatly increases the computational cost of the model and limits the infer-ence speed. Given the shortcomings of the above methods, we found through analysis that the channel response can be used as the semantic information of the class. Firstly, the response of each class in the channel is unique, which creates conditions for obtaining the unique semantics. Sec-ondly, for classes with certain semantic associations, there must be some channels that capture their common infor-mation. Therefore, channel information, as an easily over-looked part after feature extraction, can complete the task of capturing multi-label information. In MLZSL, we can complete the prediction of unseen classes by obtaining the responses of seen classes in the channel domain, and the relationship between seen and unseen classes. Finally, the subsequent analysis of the channel response greatly saves computational costs.
Specifically, as shown in Figure 1, as seen classes, “wa-ter” and “tree” have unique response distributions on feature channels, and these responses can be used as semantic infor-mation for classification tasks. Besides, in order to explore the correlation of classes, we found that although the se-mantic information of “water” and “tree” is different, there are still some channels that respond simultaneously (i.e. the blue channel). We need to build this correlation during the training process through modeling so that the model can learn multi-label correlations. In the ZSL process, for the unseen class “garden”, we know that it is related to “water” (i.e. purple layer) and “tree” (i.e. green, orange, and gray layer) by obtaining its semantic information and matching with seen classes. This observation suggests that channels can help not only to classify objects but also to establish as-sociations between classes. Previous methods which only consider spatial information are unable to obtain this intrin-sic channel-class correlation and dissimilarity, thus achiev-ing sub-optimal performance on the MLZSL task.
To address the above challenges and construct a more ac-curate and robust MLZSL system, we propose to group the generated feature maps and process them in a group-wise manner, thus enhancing the model by fully exploring the channel-class correlations. Besides, by properly designing a light yet efficient Multi-Label Multi-Layer Perceptron-based Encoder, i.e., (ML)2P-Encoder, we can easily analyze the local relationship between channels while significantly reducing the computation overhead. Finally, these groups are recombined and then perform the calculation of group attention, indicating that the model is analyzed locally and globally from the perspective of the channels, which can ensure the integrity of the representation.
In summary, our contributions are four-fold: 1. To the best of our knowledge, our method first suggests the concept of channel-class correlation in MLZSL, and proposes a channel-sensitive attention module (ML)2P-Encoder to extract and preserve channel-wise semantics for channel groups. 2. Different from previous works that use spatial-class correlation to extract global and local features, we al-ternatively explore the channel-class correlation as the unique base for MLZSL. 3. In conjunction with (ML)2P-Encoder, a global group-wise attention is also designed to establish the multi-label specific class relationships among classes. 4. Extensive experiments on large-scale datasets NUS-WIDE and Open-Images-V4 demonstrate the effec-tiveness of our method against other state-of-the-art models. 2.