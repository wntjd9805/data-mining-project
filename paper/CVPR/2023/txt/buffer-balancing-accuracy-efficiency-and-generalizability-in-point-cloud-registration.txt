Abstract
An ideal point cloud registration framework should have superior accuracy, acceptable efficiency, and strong gener-alizability. However, this is highly challenging since exist-ing registration techniques are either not accurate enough, far from efficient, or generalized poorly. It remains an open question that how to achieve a satisfying balance between this three key elements. In this paper, we propose BUFFER, a point cloud registration method for balancing accuracy, efficiency, and generalizability. The key to our approach is to take advantage of both point-wise and patch-wise tech-niques, while overcoming the inherent drawbacks simulta-neously. Different from a simple combination of existing methods, each component of our network has been carefully crafted to tackle specific issues. Specifically, a Point-wise
Learner is first introduced to enhance computational effi-ciency by predicting keypoints and improving the represen-tation capacity of features by estimating point orientations, a Patch-wise Embedder which leverages a lightweight lo-cal feature learner is then deployed to extract efficient and general patch features. Additionally, an Inliers Generator which combines simple neural layers and general features is presented to search inlier correspondences. Extensive experiments on real-world scenarios demonstrate that our method achieves the best of both worlds in accuracy, effi-ciency, and generalization. In particular, our method not only reaches the highest success rate on unseen domains, but also is almost 30 times faster than the strong base-lines specializing in generalization. Code is available at https://github.com/aosheng1996/BUFFER. 1.

Introduction
Point cloud registration plays a critical role in LiDAR
SLAM [23, 25], 3D reconstruction [44], and robotic navi-gation [22, 36]. An ideal registration framework not only requires aligning geometries accurately and efficiently, but
*Corresponding author: guoyulan@sysu.edu.cn.
Figure 1. Comparisons of the registration accuracy on the indoor 3DMatch [66] dataset, efficiency, and generalizability on the out-door ETH [49] dataset of different approaches. Note that, all meth-ods are trained only on the 3DMatch dataset. Our method not only achieves the highest recall on 3DMatch, but also has the best gen-eralization ability and efficiency across the unseen ETH dataset. also can be generalized to unseen scenarios acquired by dif-ferent sensors. However, due to uneven data quality (e.g., noise distribution, non-uniform density, varying viewing angles, domain gaps across different sensors), it remains challenging to simultaneously achieve a satisfactory bal-ance between efficiency, accuracy, and generalization.
Existing registration techniques can be mainly cat-egorized into correspondences-based [30, 63, 66] and correspondences-free methods [3, 60, 61]. By establishing a series of reliable correspondences, the correspondences-based methods usually have better registration performance compared with correspondences-free methods, especially in large-scale scenarios. However, these correspondence-based methods are still not ready for large-scale real-world applications as they are either not accurate enough, far from efficient, or generalized poorly.
Overall, the limitations of existing correspondence-based methods lie in two aspects. First, there is currently no unified, efficient, and general feature learning framework.
A number of patch-wise methods [21, 66] usually employ complex networks coupled with sophisticated steps to en-code the fine-grained geometry of local 3D patches. Ben-efiting from local characteristics that are inherently robust to occlusion and easy to be discriminated, patch-wise meth-ods usually have good generalization ability whilst low effi-ciency. To improve computational efficiency, several point-wise methods [5, 26] resort to adopting a hierarchical ar-chitecture [51] to consecutively sample raw point clouds.
However, the hierarchical architecture tends to capture the global context rather than local geometry, which makes the learned point-wise features easy to homogenize and hard to be matched correctly especially for unseen contexts [1].
Second, there is no efficient and general correspondence search mechanism. Most correspondences-based registra-tion frameworks [1, 52] leverage the RANSAC [18] or a coarse-to-fine matching strategy [64] to search reliable cor-respondences. Considering the efficiency of the RANSAC algorithm is related to the inliers, this mechanism would be time-consuming when inlier rate is very low. Additionally, the coarse-to-fine strategy failed to generalize to unseen do-mains due to the reliance on global context matching.
A handful of recent works also attempt to leverage un-supervised domain adaptation techniques [24] or simplify the network architecture [1] to achieve a better trade-off be-tween generalization and efficiency. However, they either need an extra target dataset for training or sacrifice the rep-resentation capacity of the learned models. Overall, effi-ciency and generalization seem to contradict each other as existing techniques inherently specialize in one field and do not complement each other.
In this paper, we achieve the best of both worlds on ef-ficiency and generalizability by combining the point-wise and patch-wise methods. An efficient and general search mechanism is also proposed to increase the inlier rate of correspondences. The proposed registration framework, termed BUFFER, mainly consists of a Point-wise Learner, a Patch-wise Embedder, and an Inliers Generator. The in-put point clouds are first fed into the Point-wise Learner, where a novel equivariant fully convolutional architecture is used to predict point-wise saliencies and orientations, fur-ther reducing computational cost and enhancing the repre-sentation ability of features. With the selected keypoints the Patch-wise Embedder uti-and learned orientations, lizes a lightweight patch-based feature learner, i.e., Mini-SpinNet [1], to extract efficient and general local features and cylindrical feature maps. By matching local features, a set of initial correspondences coupled with correspond-ing cylindrical feature maps can be obtained. These general cylindrical feature maps are then fed into the Inlier Gener-ator, which predicts a rigid transformation for each corre-spondence using a lightweight 3D cylindrical convolutional network [1] and generates the final reliable set of correspon-dences by seeking an optimal transformation, followed by
RANSAC [18] to estimate a finer transformation.
Actually, it is non-trivial to achieve a satisfactory balance between accuracy, efficiency, and generalizability if sim-ply combining existing methods. For example, the point-wise method Predator [26] is vulnerable to unseen scenar-ios while the patch-wise method SpinNet [1] is highly time-consuming. When combining them together directly, the whole framework is neither efficient nor general as verified in Fig. 1. In contrast, each component of our BUFFER has been carefully crafted to tackle specific issues, and thus a superior balance is more likely to be realized.
As shown in Fig. 1, being trained only on the 3DMatch dataset, our BUFFER not only achieves the highest regis-tration recall of 92.9% on the 3DMatch dataset, but also reaches the best success rate of 99.30% on the unseen out-door ETH dataset (significantly surpassing the best point-wise baseline GeoTrans [52] by nearly 10%). Meanwhile, our BUFFER is almost an order of magnitude faster than patch-wise methods [1, 48, 57]. Extensive experiments jus-tify the superior performance and compelling efficiency of our method. Overall, our contributions are three-fold:
• We propose a new point cloud registration framework by skillfully combining the point-wise and patch-wise paradigms, achieving the best of both worlds in accuracy, efficiency, and generalizability.
• We introduce an equivariant fully convolutional architec-ture to predict point-wise orientations and saliencies.
• A new correspondence search strategy is introduced to enhance the inlier ratio of initial correspondences. 2.