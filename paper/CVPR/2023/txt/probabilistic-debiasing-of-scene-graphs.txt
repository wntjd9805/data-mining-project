Abstract
The quality of scene graphs generated by the state-of-the-art (SOTA) models is compromised due to the long-tail nature of the relationships and their parent object pairs.
Training of the scene graphs is dominated by the major-ity relationships of the majority pairs and, therefore, the object-conditional distributions of relationship in the mi-nority pairs are not preserved after the training is con-verged. Consequently, the biased model performs well on more frequent relationships in the marginal distribution of relationships such as ‘on’ and ‘wearing’, and performs poorly on the less frequent relationships such as ‘eating’
In this work, we propose virtual evi-or ‘hanging from’. dence incorporated within-triplet Bayesian Network (BN) to preserve the object-conditional distribution of the re-lationship label and to eradicate the bias created by the marginal probability of the relationships. The insufficient number of relationships in the minority classes poses a sig-nificant problem in learning the within-triplet Bayesian net-work. We address this insufficiency by embedding-based augmentation of triplets where we borrow samples of the minority triplet classes from its neighboring triplets in the semantic space. We perform experiments on two different datasets and achieve a significant improvement in the mean recall of the relationships. We also achieve a better balance between recall and mean recall performance compared to the SOTA de-biasing techniques of scene graph models.1 1.

Introduction
Any visual relationship can be expressed as a triplet subject-relationship-object and all triplets in an image can be represented as a concise graph called Scene Graph (SG)
[21] where the nodes represent the objects and the edges represent relationships. This representation has been proven useful for many downstream tasks such as image caption-ing [39], visual reasoning [26], and image generation [12].
Scene Graph Generation (SGG) has become one of the ma-1Code available at https://github.com/bashirulazam/ within-triplet-debias. jor computer vision research arenas after the introduction of Visual Genome (VG) dataset [13]. The distribution of triplets in VG images has two distinct characteristics: (1) the presence of strong within-triplet prior, and (2) the long-tail distribution of the relationship. As shown in Figure 1 (a), the within-triplet prior dictates that ‘window’ will most likely be ‘on’ the ‘building’ rather than ‘eating’ it. Zeller et al. [45] has utilized this within-triplet prior as the condi-tional probability of relationships given subject and object by proposing a frequency baseline in the SGG task. On the other hand, the distribution of relationship labels suffers from a long-tailed nature and Tang et al. [29] addressed this long-tailed issue by considering a causal interpretation of the biased prediction. We argue that these two seemingly different characteristics of the relationship distribution are interrelated. The abundance of the head classes of the rela-tionship distribution in Figure 1 (c), such as ‘on’ and ‘wear-ing’, arises from the abundance of their parent subject and object lying in the head region of Figure 1 (b).
As indicated by [7], the long-tailed distribution exists both in relationship and object label. Since relationship la-bels are dependent on their object pair, the long tail in object labels worsens the long tail in relationship labels. Crowd-collection of VG images creates selection bias and crowd-annotation of these images create label-bias [31] and co-occurring-bias [27]. We investigate such biases through the distribution of the object pair of the triplets in VG database.
As shown in Figure 1 (b), ‘window-building’ and ‘man-shirt’ are the most frequently annotated pairs and top 1% object pair covers 33% of all triplets. As a result, the dom-inant relationships in these head pairs, such as ‘on’ and
‘wearing’, dominate the marginal distribution of Figure 1 (c).
In training a deep-learning-based SGG model, samplers will sample more relationships from the head pairs. As a result, the Maximum Likelihood Estimation (MLE) of the parameters is biased to predict the relationship classes in the head pairs [29] and the object-conditional representation of the relationship in the tail pairs will be lost in the training process. Therefore, various deep learning-based models, which attempt to implicitly capture such object-conditional
Figure 1. (a) Within-triplet dependency of relationship on its parent object pair; (b) long-tail nature of the pair statistics where 33% pair samples originated from top 1% pairs; (c) long-tail nature of the relationships showing the dominance of ‘on’ and ‘wearing’. The skewness in (c) is an effect of skewness in (b). Since ‘on’, ‘has’ or ‘wearing’ dominates in these top 1% pairs, they become the majority relationships in (c) and many other relationships, such as ‘eating’ or ‘flying in’, which dominate in the tail pairs of (b), are suppressed in the training process. representation [6, 47], fail to preserve the representation in the trained model and perform poorly on the tail region of the relationships.
Previous works attempt to retrieve the tail regions through re-sampling/re-weighting the minority classes in training [4, 7, 9] or through causal intervention in testing
[29]. Their success is well-demonstrated by the signifi-cant increase of minority-driven evaluation metric mean re-call. However, these approaches do not consider the strong within-triplet prior of triplets and hurt the performance of majority-driven evaluation metric recall. Keeping this gap in mind, we propose an inference-time post-processing methodology that bolsters the minority tail classes as well as hurts the majority head classes less brutally. We pro-pose a within-triplet Bayesian Network (BN) that combines the within-triplet prior with uncertain biased evidence from
SOTA models. Posterior inference with this BN simultane-ously eradicates the long-tailed bias in the marginal distri-bution of the relationship and restores the object-conditional within-triplet prior.
Learning such a small within-triplet BN from the train-ing data is a seemingly trivial task where we can perform simple MLE of parameters by counting. However, because of restricting our training samples only belonging to some top-Nr classes based on the marginal probability of rela-tionship, we sacrifice many information-revealing triplets in the minority pairs. For example, in the ‘man-pizza’ pair, we see there exist many interesting relationships such as ‘man-biting-pizza’ or ‘man consuming pizza’ which are semanti-cally similar to one of the top-Nr valid triplets ‘man-eating-pizza’. This phenomenon is also a result of label bias [31] where the annotator chooses some labels over another for the same category of objects or relationships. We propose a novel method of borrowing samples from such invalid triplets into learning the distribution of the valid triplets us-ing embedding-based augmentation.
The posterior inference is the most efficient probabilis-tic tool to combine domain-dependent prior with instance-dependent evidence and, to the best of our knowledge, no prior work in SGG literature formulates the problem of triplet generation as a posterior inference problem. The overview of our approach is illustrated in Figure 2. In sum-mary, our contribution is proposing a posterior inference-based post-processing method where we
• integrate the within-triplet priors with the evidence un-certainties generated by the measurement model and,
• introduce a simple yet novel learning scheme of the within-triplet network where we borrow samples from the semantically similar yet invalid triplet categories. 2.