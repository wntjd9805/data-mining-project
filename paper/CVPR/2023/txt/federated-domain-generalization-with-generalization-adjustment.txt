Abstract
Federated Domain Generalization (FedDG) attempts to learn a global model in a privacy-preserving manner that generalizes well to new clients possibly with domain shift.
Recent exploration mainly focuses on designing an unbi-ased training strategy within each individual domain. How-ever, without the support of multi-domain data jointly in the mini-batch training, almost all methods cannot guar-antee the generalization under domain shift. To overcome this problem, we propose a novel global objective incorpo-rating a new variance reduction regularizer to encourage fairness. A novel FL-friendly method named Generaliza-tion Adjustment (GA) is proposed to optimize the above ob-jective by dynamically calibrating the aggregation weights.
The theoretical analysis of GA demonstrates the possibility to achieve a tighter generalization bound with an explicit re-weighted aggregation, substituting the implicit multi-domain data sharing that is only applicable to the con-ventional DG settings. Besides, the proposed algorithm is generic and can be combined with any local client training-based methods. Extensive experiments on several bench-mark datasets have shown the effectiveness of the proposed method, with consistent improvements over several FedDG algorithms when used in combination. The source code is released at https://github.com/MediaBrain-SJTU/FedDG-GA 1.

Introduction
Federated Learning (FL) has recently emerged as a prevalent privacy-preserving paradigm for collaborative learning on distributed data [32]. Existing studies mainly investigate the problem of how to improve the conver-gence and performance of the source clients’ data distribu-tion [18, 27, 44]. A more practical problem, how to make models trained on sites of heterogeneous distributions gen-Figure 1. The difference between DG and FedDG is whether the domains are isolated in training. Specifically, previous SOTA DG methods that require access to multiple domains in the mini-batch training are inapplicable to FedDG. eralize to target clients of unknown distributions, i.e. Feder-ated Domain Generalization (FedDG) [30], remains under-explored. While label distribution shift has been considered in traditional FL, FedDG focuses on the domain shift among clients and considers each client as an individual domain.
The challenge lies in the domain shift [19] both among the training clients and from training to testing clients.
While FedDG shares a similar goal as standard Do-main Generalization (DG) [4,12,40], i.e., generalizing from multi-source domains to unseen domains, it disallows di-rect data sharing among clients, as shown in Figure 1, which makes most existing DG methods hardly applica-ble. Current methods for FedDG focus on unbiased lo-cal training within each isolated domain. As the first at-tempt, Liu et al. [30] propose a meta-learning framework 1
with Fourier-based augmentation during the local training
Jiang et al. [17] further pro-for better generalization. pose constraining local models’ flatness on top of a simi-lar Fourier-based normalization method. However, only fo-cusing on an improved local training strategy cannot guar-antee that the global model is generalizable enough to un-seen domains.
Instead, a common practice for aggregat-ing local models into a global model is by fixed weights as in FedAvg [32], assuming that each client constantly con-tributes to the global model. Even the subsequent improve-ments from the federated optimization perspective, e.g.,
FedNova [44], are mainly designed for the statistical het-erogeneity of the same domain, not for the setting of treat-ing each client as an individual domain. Yuan et al. [50] have suggested that domains tend to contribute non-equally to the global model and ignoring their differences may sig-nificantly reduce the model’s generalizability.
As one has no clue regarding to the distribution of unseen domains, it is reasonable to assume that a global model with fair performance among all clients may lead to better gener-alization performance. We thus introduce a new fairness ob-jective measured by the variance of the generalization gaps among different source domains. The data privacy issue in the FL setting has prevented direct optimization of the pro-posed objective. We thus design a novel privacy-preserving method named Generalization Adjustment to optimize the objective. At the high level, GA leverages the domain flat-ness constraint, a surrogate of the intractable domain di-vergence constraint, to approximately explore the optimal domain weights. Technically, we use a momentum mech-anism to dynamically compute a weight for each isolated domain by tracing the domain generalization gap, which is then involved in the aggregation of FedDG to enhance the generalization ability. Because the gap information does not contain any domain information of each client, GA will not cause additional risk of privacy leakage. Meanwhile, the theoretical analysis of our method shows that a tighter generalization bound is achieved by setting the aggregation weights inversely proportional to the generalization gaps, which leads to reduced variance in generalization gaps. The contribution of our paper is summarized as follows:
• We introduce a novel optimization objective for FedDG with a new variance reduction regularizer, which can con-strain the fairness of the global model.
• We design an FL-friendly method named Generalization
Adjustment to tackle the aforementioned novel objective.
Our theoretical analysis has revealed that GA leads to a tighter generalization bound for FedDG.
• Extensive experiments on a range of benchmark datasets have shown consistent improvement when combining GA with different federated learning algorithms. 2.