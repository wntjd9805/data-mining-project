Abstract
Since experiencing domain shifts during test-time is in-evitable in practice, test-time adaption (TTA) continues to adapt the model after deployment. Recently, the area of continual and gradual test-time adaptation (TTA) emerged.
In contrast to standard TTA, continual TTA considers not only a single domain shift, but a sequence of shifts. Grad-ual TTA further exploits the property that some shifts evolve gradually over time. Since in both settings long test se-quences are present, error accumulation needs to be ad-dressed for methods relying on self-training. In this work, we propose and show that in the setting of TTA, the sym-metric cross-entropy is better suited as a consistency loss for mean teachers compared to the commonly used cross-entropy. This is justified by our analysis with respect to the (symmetric) cross-entropy’s gradient properties. To pull the test feature space closer to the source domain, where the pre-trained model is well posed, contrastive learning is leveraged. Since applications differ in their require-ments, we address several settings, including having source data available and the more challenging source-free setting.
We demonstrate the effectiveness of our proposed method
“robust mean teacher“ (RMT) on the continual and grad-ual corruption benchmarks CIFAR10C, CIFAR100C, and
Imagenet-C. We further consider ImageNet-R and propose a new continual DomainNet-126 benchmark. State-of-the-art results are achieved on all benchmarks. 1 1.

Introduction
Assuming that training and test data originate from the same distribution, deep neural networks achieve remarkable performance. In the real world, this assumption is often vio-lated for a deployed model, as many environments are non-stationary. Since the occurrence of a data shift [35] during test-time will likely result in a performance drop, domain generalization aims to improve robustness and generaliza-*Equal contribution. 1Code is available at: https://github.com/mariodoebler/ test-time-adaptation tion already during training [11, 13, 32, 43, 45]. However, these approaches are often limited, due to the wide range of potential data shifts [30] that are unknown during train-ing. To gain insight into the current distribution shift, re-cent approaches leverage the test samples encountered dur-ing model deployment to adapt the pre-trained model. This is also known as test-time adaptation (TTA) and can be done either offline or online. While offline TTA assumes to have access to all test data at once, online TTA considers the set-ting where the predictions are needed immediately and the model is adapted on the fly using only the current test batch.
While adapting the batch normalization statistics dur-ing test-time can already significantly improve the perfor-mance [38], more sophisticated methods update the model weights using self-training based approaches, like entropy minimization [49]. However, the effectiveness of most TTA methods is only demonstrated for a single domain shift at a time. Since encountering just one domain shift is very unlikely in real world applications, [50] introduced contin-ual test-time adaptation where the model is adapted to a se-quence of domain shifts. As pointed out by [50], adapting the model to long test sequences in non-stationary environ-ments is very challenging, as self-training based methods are prone to error accumulation due to miscalibrated pre-dictions. Although it is always possible to reset the model after it has been updated, this prevents exploiting previously acquired knowledge, which is undesirable for the following reason: While some domain shifts occur abruptly in prac-tice, there are also several shifts which evolve gradually over time [17]. In [26], this setting is denoted as gradual test-time adaptation. [17, 26] further showed that in the set-ting of gradual shifts, pseudo-labels are more reliable, re-sulting in a better model adaptation to large domain gaps.
However, if the model is reset and the domain gap increases over time, model adaptation through self-training or self-supervised learning may not be successful [17, 24].
To tackle the aforementioned challenges, we introduce a robust mean teacher (RMT) that exploits a symmetric cross-entropy (SCE) loss instead of the commonly used cross-entropy (CE) loss to perform self-training. This is motivated by our findings that the CE loss has undesirable gradient
properties in a mean teacher framework which are compen-sated for when using an SCE loss. Furthermore, RMT uses a multi-viewed contrastive loss to pull test features towards the initial source space and learn invariances with regards to the input space. While our framework performs well for both continual and gradual domain shifts, we observe that mean teachers are especially well suited for easy-to-hard problems. We empirically demonstrate this not only for gradually shifting test sequences, but also for the case where the domain difficulty with respect to the error of the initial source model increases. Since source data might not be available during test-time due to privacy or accessibil-ity reasons, recent approaches in TTA focus on the source-free setting. Lacking labeled source data, source-free ap-proaches can be susceptible to error accumulation. There-fore, as an extension to our framework, we additionally look into the setting where source data is accessible.
We summarize our contributions as follows:
• By analyzing the gradient properties, we motivate and propose that in the setting of TTA, the symmetric cross-entropy is better suited for a mean teacher than the commonly used cross-entropy.
• We present a framework for both continual and grad-ual TTA that achieves state-of-the-art results on the ex-isting corruption benchmarks, ImageNet-R, and a new proposed continual DomainNet-126 benchmark.
• For our framework, we address a wide range of practi-cal requirements, including the source-free setting and having source data available. 2.