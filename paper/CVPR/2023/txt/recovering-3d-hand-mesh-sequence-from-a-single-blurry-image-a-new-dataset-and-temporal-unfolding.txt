Abstract
Hands, one of the most dynamic parts of our body, suffer from blur due to their active movements. However, previous 3D hand mesh recovery methods have mainly focused on sharp hand images rather than considering blur due to the absence of datasets providing blurry hand images. We first present a novel dataset BlurHand, which contains blurry hand images with 3D groundtruths. The BlurHand is con-structed by synthesizing motion blur from sequential sharp hand images, imitating realistic and natural motion blurs.
In addition to the new dataset, we propose BlurHandNet, a baseline network for accurate 3D hand mesh recovery from a blurry hand image. Our BlurHandNet unfolds a blurry input image to a 3D hand mesh sequence to utilize tem-poral information in the blurry input image, while previ-ous works output a static single hand mesh. We demon-strate the usefulness of BlurHand for the 3D hand mesh recovery from blurry images in our experiments. The pro-posed BlurHandNet produces much more robust results on blurry images while generalizing well to in-the-wild images.
The training codes and BlurHand dataset are available at https://github.com/JaehaKim97/BlurHand_RELEASE. 1.

Introduction
Since hand images frequently contain blur when hands are moving, developing a blur-robust 3D hand mesh esti-mation framework is necessary. As blur makes the bound-ary unclear and hard to recognize, it significantly degrades the performance of 3D hand mesh estimation and makes the task challenging. Despite promising results of 3D hand mesh estimation from a single sharp image [5,13,16,17,22], research on blurry hands is barely conducted.
A primary reason for such lack of consideration is the ab-sence of datasets that consist of blurry hand images with ac-curate 3D groundtruth (GT). Capturing blurry hand datasets
*Authors contributed equally. (a) Examples of the presented BlurHand dataset. (b) Illustration of the temporal unfolding.
Figure 1. Proposed BlurHand dataset and BlurHandNet. (a)
We present a novel BlurHand dataset, providing natural blurry hand images with accurate 3D annotations. (b) While most pre-vious methods produce a single 3D hand mesh from a sharp im-age, our BlurHandNet unfolds the blurry hand image into three sequential hand meshes. is greatly challenging. The standard way of capturing mark-erless 3D hand datasets [8, 23, 50] consists of two stages: 1) obtaining multi-view 2D grounds (e.g., 2D joint coordinates and mask) manually [50] or using estimators [14, 15, 44] and 2) triangulating the multi-view 2D grounds to the 3D space. Here, manual annotations or estimators in the first stage are performed from images. Hence, they become un-reliable when the input image is blurry, which results in tri-angulation failure in the second stage.
Contemplating these limitations, we present the Blur-Hand, whose examples are shown in Figure 1a. Our Blur-Hand, the first blurry hand dataset, is synthesized from In-terHand2.6M [23], which is a widely adopted video-based
hand dataset with accurate 3D annotations. Following state-of-the-art blur synthesis literature [25, 26, 39], we approxi-mate the blurry images by averaging the sequence of sharp hand frames. As such technique requires high frame rates of videos, we employ a widely used video interpolation method [27] to complement the low frame rate (30 frames per second) of InterHand2.6M. We note that our synthetic blur dataset contains realistic and challenging blurry hands.
For a given blurry hand image, the most straightforward baseline is sequentially applying state-of-the-art deblurring methods [3, 29, 30, 46] on blurry images and 3D hand mesh estimation networks [21, 22, 38] on the deblurred image.
However, such a simple baseline suffers from two limita-tions. First, since hands contain challenging blur caused by complex articulations, even state-of-the-art deblurring methods could not completely deblur the image. Therefore, the performance of the following 3D hand mesh estima-tion networks severely drops due to remaining blur artifacts.
Second, since conventional deblurring approaches only re-store the sharp images corresponding to the middle of the motion, it limits the chance to make use of temporal infor-mation, which might be useful for 3D mesh estimation. In other words, the deblurring process restricts networks from exploiting the motion information in blurry hand images.
To overcome the limitations, we propose BlurHandNet, which recovers a 3D hand mesh sequence from a single blurry image, as shown in Figure 1b. Our BlurHandNet effectively incorporates useful temporal information from the blurry hand. The main components of BlurHandNet are Unfolder and a kinematic temporal Transformer (KT-Former). Unfolder outputs hand features of three timesteps, i.e., middle and both ends of the motion [12, 28, 32, 36].
The Unfolder brings benefits to our method in two aspects.
First, Unfolder enables the proposed BlurHandNet to out-put not only 3D mesh in the middle of the motion but also 3D meshes at both ends of the motion, providing more in-formative results related to motion. We note that this prop-erty is especially beneficial for the hands, where the motion has high practical value in various hand-related works. For example, understanding hand motion is essential in the do-main of sign language [2,34] and hand gestures [40], where the movement itself represents meaning. Second, extract-ing features from multiple time steps enables the following modules to employ temporal information effectively. Since hand features in each time step are highly correlated, ex-ploiting temporal information benefits reconstructing more accurate 3D hand mesh estimation.
To effectively incorporate temporal hand features from the Unfolder, we propose KTFormer as the following mod-ule. The KTFormer takes temporal hand features as input and leverages self-attention to enhance the temporal hand features. The KTFormer enables the proposed BlurHand-Net to implicitly consider both the kinematic structure and temporal relationship between the hands in three timesteps.
The KTFormer brings significant performance gain when coupled with Unfolder, demonstrating that employing tem-poral information plays a key role in accurate 3D hand mesh estimation from blurry hand images.
With a combination of BlurHand and BlurHandNet, we first tackle 3D hand mesh recovery from blurry hand im-ages. We show that BlurHandNet produces robust results from blurry hands and further demonstrate that BlurHand-Net generalizes well on in-the-wild blurry hand images by taking advantage of effective temporal modules and Blur-Hand. As this problem is barely studied, we hope our work could provide useful insights into the following works. We summarize our contributions as follows:
• We present a novel blurry hand dataset, BlurHand, which contains natural blurry hand images with accu-rate 3D GTs.
• We propose the BlurHandNet for accurate 3D hand mesh estimation from blurry hand images with novel temporal modules, Unfolder and KTFormer.
• We experimentally demonstrate that the proposed
BlurHandNet achieves superior 3D hand mesh estima-tion performance on blurry hands. 2.