Abstract 2D-based Industrial Anomaly Detection has been widely discussed, however, multimodal industrial anomaly detec-tion based on 3D point clouds and RGB images still has many untouched fields. Existing multimodal industrial anomaly detection methods directly concatenate the mul-timodal features, which leads to a strong disturbance be-tween features and harms the detection performance. In this paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly detection method with hybrid fusion scheme: firstly, we design an unsupervised feature fusion with patch-wise contrastive learning to encourage the in-teraction of different modal features; secondly, we use a decision layer fusion with multiple memory banks to avoid loss of information and additional novelty classifiers to make the final decision. We further propose a point fea-ture alignment operation to better align the point cloud and
RGB features. Extensive experiments show that our multi-modal industrial anomaly detection model outperforms the state-of-the-art (SOTA) methods on both detection and seg-mentation precision on MVTec-3D AD dataset. Code at github.com/nomewang/M3DM. 1.

Introduction
Industrial anomaly detection aims to find the abnormal region of products and plays an important role in industrial quality inspection. In industrial scenarios, it’s easy to ac-quire a large number of normal examples, but defect exam-ples are rare. Current industrial anomaly detection methods are mostly unsupervised methods, i.e., only training on nor-mal examples, and testing on detect examples only during inference. Moreover, most existing industrial anomaly de-tection methods [2,9,25,34] are based on 2D images. How-ever, in the quality inspection of industrial products, human inspectors utilize both the 3D shape and color characteris-tics to determine whether it is a defective product, where
*Equal contributions. This work was done when Yue Wang was a intern at Tencent Youtu Lab.
†Corresponding author.
Figure 1. Illustrations of MVTec-3D AD dataset [3]. The second and third rows are the input point cloud data and the RGB data.
The fourth and fifth rows are prediction results, and according to the ground truth, our prediction has more accurate prediction re-sults than the previous method. 3D shape information is important and essential for correct detection. As shown in Fig. 1, for cookie and potato, it is hard to identify defects from the RGB image alone. With the development of 3D sensors, recently MVTec-3D AD dataset [3] (Fig. 1) with both 2D images and 3D point cloud data has been released and facilitates the research on multi-modal industrial anomaly detection.
The core idea for unsupervised anomaly detection is to find out the difference between normal representations and anomalies. Current 2D industrial anomaly detec-tion methods can be categorized into two categories: (1)
Reconstruction-based methods. Image reconstruction tasks are widely used in anomaly detection methods [2, 9, 14, 22, 34, 35] to learn normal representation. Reconstruction-based methods are easy to implement for a single modal input (2D image or 3D point cloud). But for multimodal in-puts, it is hard to find a reconstruction target. (2) Pretrained feature extractor-based methods. An intuitive way to uti-lize the feature extractor is to map the extracted feature to a normal distribution and find the out-of-distribution one as an anomaly. Normalizing flow-based methods [15, 27, 33]
use an invertible transformation to directly construct nor-mal distribution, and memory bank-based methods [8, 25] store some representative features to implicitly construct the feature distribution. Compared with reconstruction-based methods, directly using a pretrained feature extractor does not involve the design of a multimodal reconstruction tar-get and is a better choice for the multimodal task. Besides that, current multimodal industrial anomaly detection meth-ods [16, 27] directly concatenate the features of the two modalities together. However, when the feature dimension is high, the disturbance between multimodal features will be violent and cause performance reduction.
To address the above issues, we propose a novel mul-timodal anomaly detection scheme based on RGB images and 3D point cloud, named Multi-3D-Memory (M3DM).
Different from the existing methods that directly concate-nate the features of the two modalities, we propose a hy-brid fusion scheme to reduce the disturbance between mul-timodal features and encourage feature interaction. We pro-pose Unsupervised Feature Fusion (UFF) to fuse multi-modal features, which is trained using a patch-wise con-trastive loss to learn the inherent relation between multi-modal feature patches at the same position. To encourage the anomaly detection model to keep the single domain in-ference ability, we construct three memory banks separately for RGB, 3D and fused features. For the final decision, we construct Decision Layer Fusion (DLF) to consider all of the memory banks for anomaly detection and segmentation.
Anomaly detection needs features that contain both global and local information, where the local information helps detect small defects, and global information focuses on the relationship among all parts. Based on this obser-vation, we utilize a Point Transformer [20, 36] for the 3D feature and Vision Transformer [5, 11] for the RGB feature.
We further propose a Point Feature Alignment (PFA) opera-tion to better align the 3D and 2D features.
Our contributions are summarized as follows:
• We propose M3DM, a novel multimodal industrial anomaly detection method with hybrid feature fusion, which outperforms the state-of-the-art detection and segmentation precision on MVTec-3D AD.
• We propose Unsupervised Feature Fusion (UFF) with patch-wise contrastive loss to encourage interaction between multimodal features.
• We design Decision Layer Fusion (DLF) utilizing mul-tiple memory banks for robust decision-making.
• We explore the feasibility of the Point Transformer in multimodal anomaly detection and propose Point (PFA) operation to align the
Feature Alignment
Point Transformer feature to a 2D plane for high-performance 3D anomaly detection. 2.