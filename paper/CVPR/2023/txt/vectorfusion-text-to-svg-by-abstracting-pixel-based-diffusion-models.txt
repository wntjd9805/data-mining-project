Abstracting Pixel-Based Diffusion Models
Ajay Jain∗
Amber Xie∗
Pieter Abbeel
UC Berkeley
{ajayj,amberxie,pabbeel}@berkeley.edu
Figure 1. Text-to-SVG with VectorFusion. When (a) raster graphics sampled from Stable Diffusion are (b) auto-traced, they lose details that are hard to represent within the constraints of the abstraction. (c-d) VectorFusion improves fidelity and consistency with the caption by directly optimizing paths with a distillation-based diffusion loss. Find videos and more results at https://ajayj.com/vectorfusion.
Abstract 1.

Introduction
Diffusion models have shown impressive results in text-to-image synthesis. Using massive datasets of captioned images, diffusion models learn to generate raster images of highly diverse objects and scenes. However, designers frequently use vector representations of images like Scalable
Vector Graphics (SVGs) for digital icons or art. Vector graphics can be scaled to any size, and are compact. We show that a text-conditioned diffusion model trained on pixel representations of images can be used to generate SVG-exportable vector graphics. We do so without access to large datasets of captioned SVGs. By optimizing a differentiable vector graphics rasterizer, our method, VectorFusion, distills abstract semantic knowledge out of a pretrained diffusion model. Inspired by recent text-to-3D work, we learn an SVG consistent with a caption using Score Distillation Sampling.
To accelerate generation and improve fidelity, VectorFusion also initializes from an image sample. Experiments show greater quality than prior work, and demonstrate a range of styles including pixel art and sketches.
∗Equal contribution
Graphic designers and artists often express concepts in an abstract manner, such as composing a few shapes and lines into a pattern that evokes the essence of a scene. Scal-able Vector Graphics (SVGs) provide a declarative format for expressing visual concepts as a collection of primitives.
Primitives include B´ezier curves, polygons, circles, lines and background colors. SVGs are the defacto format for export-ing graphic designs since they can be rendered at arbitrarily high resolution on user devices, yet are stored and transmit-ted with a compact size, often only tens of kilobytes. Still, designing vector graphics is difficult, requiring knowledge of professional design tools.
Recently, large captioned datasets and breakthroughs in diffusion models have led to systems capable of generating diverse images from text including DALL-E 2 [28], Im-agen [33] and Latent Diffusion [31]. However, the vast majority of images available in web-scale datasets are raster-ized, expressed at a finite resolution with no decomposition into primitive parts nor layers. For this reason, existing dif-fusion models can only generate raster images. In theory,
a train* an owl standing on a wire*
Underwater Submarine* a boat*
A photo of a Ming Dynasty vase on a leather topped table.*
A smiling sloth wearing a leather jacket, a cowboy hat and a kilt.* a tuba with red flowers protruding from its bell* a blue poison dart frog sitting on a water lily* a crown* the silhouette of an elephant* an espresso machine* the Sydney Opera House* a baby penguin* a tree* a family vacation to Walt Disney
World* a spaceship flying in a starry night sky* the Great Wall*
Electric guitar**
A delicious hamburger**
Daft Punk** watercolor painting of a fire-breathing dragon† a bottle of beer next to an ashtray with a half-smoked cigarette† a brightly colored mushroom growing on a log†
Figure 2. Given a caption, VectorFusion generates abstract vector graphics in an SVG format. We use a pre-trained diffusion model trained only on rasterized images to guide a differentiable vector renderer. VectorFusion supports diverse objects and styles. To select a style such as flat polygonal vector icons, abstract line drawings or pixel art, we constrain the vector representation to subset of possible primitive shapes and use different prompt modifiers to encourage an appropriate style: * ...minimal flat 2d vector icon. lineal color. on a white background. trending on artstation, ** ...pixel art. trending on artstation, †...minimal 2d line drawing. trending on artstation. Please see videos of the optimization process on our project webpage.
diffusion models could be trained to directly model SVGs, but would need specialized architectures for variable-length hierarchical sequences, and significant data collection work.
How can we use diffusion models pretrained on pixels to generate high-quality vector graphics? In this work, we provide a method for generating high quality abstract vector graphics from text captions, shown in Fig. 1.
We start by evaluating a two phase text-to-image and image-to-vector baseline: generating a raster image with a pretrained diffusion model, then vectorizing it. Traditionally, designers manually convert simple rasterized images into a vector format by tracing shapes. Some ML-based tools [19] can automatically approximate a raster image with an SVG.
Unfortunately, we find that text-to-image diffusion models frequently produce complex images that are hard to represent with simple vectors, or are incoherent with the caption (Fig 1,
Stable Diffusion + LIVE).
To improve quality of the SVG and coherence with the caption, we incorporate the pretrained text-to-image diffu-sion model in an optimization loop. Our approach, VectorFu-sion, combines a differentiable vector graphics renderer [16] and a recently proposed score distillation sampling (SDS) loss [26] to iteratively refine shape parameters. Intuitively, score distillation converts diffusion sampling into an opti-mization problem that allows the image to be represented by an arbitrary differentiable function. In our case, the differen-tiable function is the forward rasterization process, and the diffusion model provides a signal for improving the raster.
To adapt SDS to text-to-SVG synthesis, we make the follow-ing contributions:
• We extend score distillation sampling to open source latent space diffusion models like Stable Diffusion,
• improve efficiency and quality by initializing near a raster image sample,
• propose SVG-specific regularization including path reinitialization,
• and evaluate different sets of shape primitives and their impact on style.
In experiments, VectorFusion generates iconography, pixel art and line drawings from diverse captions. VectorFusion also achieves greater quality than CLIP-based approaches that transfer a discriminative vision-language representation. 2.