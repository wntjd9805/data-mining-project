Abstract
Point cloud sampling is crucial for efficient large-scale point cloud analysis, where learning-to-sample methods have recently received increasing attention from the com-munity for jointly training with downstream tasks. However, the above-mentioned task-specific sampling methods usu-ally fail to explore the geometries of objects in an explicit manner. In this paper, we introduce a new skeleton-aware learning-to-sample method by learning object skeletons as the prior knowledge to preserve the object geometry and topology information during sampling. Specifically, with-out labor-intensive annotations per object category, we first learn category-agnostic object skeletons via the medial axis transform definition in an unsupervised manner. With ob-ject skeleton, we then evaluate the histogram of the local feature size as the prior knowledge to formulate skeleton-aware sampling from a probabilistic perspective. Addition-ally, the proposed skeleton-aware sampling pipeline with the task network is thus end-to-end trainable by explor-ing the reparameterization trick. Extensive experiments on three popular downstream tasks, point cloud classification, retrieval, and reconstruction, demonstrate the effectiveness of the proposed method for efficient point cloud analysis. 1.

Introduction
With the development of 3D sensing technologies, ac-quiring 3D data becomes more accessible than before, and there are a growing number of data repositories available online, such as ModelNet [62], ShapeNet [6], ScanNet [11], and KITTI [18]. Among popular 3D shape representa-tions such as point cloud [41], voxel [72], mesh [55], and multi-view images [51], the point cloud is becoming in-creasingly popular as the first-hand data captured by Li-DAR or depth camera (e.g., Kinect), which has been widely applied in various applications such as scene reconstruc-tion [19, 26], autonomous driving navigation [35], and vir-tual reality (VR) [59]. Though a high-resolution point cloud
*Equal contribution (a) (b) (c) (d)
Figure 1. (a) Point cloud; (b) Object skeleton; (c) Random sam-pling; (d) Skeleton-aware sampling. Compared with random sam-pling, skeleton-aware sampling tends to preserve the object geom-etry and topology information. can accurately capture the geometry and topology details of complex objects, it remains challenging for those devices with limited computation and storage resources. Therefore, point cloud sampling, aiming to find a small set of points to represent the object shape and topology effectively, is usu-ally indispensable for efficient large-scale point cloud anal-ysis [24, 29, 32, 33, 41, 42, 57, 61, 71].
Traditional point cloud sampling methods such as ran-dom sampling (RS) and farthest point sampling (FPS) [15, 42] usually select a subset of points directly using the raw data information [7, 42, 43, 47, 68]. Specifically, RS is very efficient but may miss sparse regions, while FPS has better coverage on the entire point set but suffers from the latency bottleneck in parallel computation. To improve the per-formances on downstream tasks, learn-to-sample methods have been recently proposed to jointly optimize the sam-pling algorithm and each specific downstream task [10, 14, 20,27,56]. Though considerable progress has been achieved in downstream tasks such as point cloud classification and reconstruction, one critical issue remains poorly investi-gated: as objects usually have complex topology structures and irregular surface morphology, it is challenging to pre-serve the object’s geometrical information during the point cloud sampling process.
Skeleton is an efficient representation to capture the un-derlying object shape structures, which has been widely used as the structural abstraction in many visual understand-ing tasks [31, 37, 53]. Inspired by this, we build our point cloud sampling strategy on top of the object skeleton to
preserve different objects’ intrinsic geometrical and topo-logical natures. Here we illustrate a comparison between random sampling and skeleton-aware sampling in Fig. 1.
However, the skeleton extraction is usually non-trivial due to the following reasons [30, 52]: 1) given the diversity of object topological structures, it is difficult to have a con-sistent category-agnostic skeleton definition at the semantic level, where existing datasets usually consider only single or a few known object categories, such as human skele-ton; 2) topological methods are usually category-agnostic by emphasizing geometrical and topological properties of the shape, such as its connectivity, topology, length, direc-tion, and width. Nevertheless, they usually require a sub-stantial amount of time for geometrical processing and are also notoriously sensitive to surface noise. Therefore, we resort to the medial axis transform (MAT) definition of ob-ject skeleton and deep neural networks to learn effective skeletal representations in an unsupervised manner.
With the learned object skeleton, we then formulate the skeleton-aware point cloud sampling pipeline from a proba-bilistic perspective. Specifically, we first calculate the local feature size (LFS) [2] for each point to measure the object’s size near a particular point. We then explore the LFS distri-bution as the prior sampling probability on each point and use the LFS histogram in practice since per-point LFS is usually sensitive to point cloud noise. By learning object skeletons with deep neural networks, we have the skeleton-aware prior probability for sampling each point. To adapt skeleton-aware sampling for downstream tasks, we jointly optimize the posterior sampling probability on each point in an end-to-end manner. Notably, by exploring the categori-cal reparameterization with Gumbel-softmax [22], the cate-gorical sampling based on LFS histogram is differentiable.
Therefore, both sampling and task networks are end-to-end learnable for task-specific point cloud sampling. In this pa-per, our main contributions can be summarized as follows: 1. We propose a new skeleton-aware point cloud sam-pling method to preserve the object geometry and topology information during sampling. 2. We introduce the category-agnostic skeleton learning in an unsupervised manner to provide the prior knowl-edge for skeleton-aware point cloud sampling. 3. We conduct extensive experiments on three important downstream tasks, point cloud classification, retrieval, and reconstruction, to evaluate the proposed approach. 2.