Abstract
Masked signal modeling has greatly advanced self-supervised pre-training for language and 2D images. How-ever, it is still not fully explored in 3D scene understand-ing. Thus, this paper introduces Masked Shape Prediction (MSP), a new framework to conduct masked signal model-ing in 3D scenes. MSP uses the essential 3D semantic cue, i.e., geometric shape, as the prediction target for masked points. The context-enhanced shape target consisting of ex-plicit shape context and implicit deep shape feature is pro-posed to facilitate exploiting contextual cues in shape pre-diction. Meanwhile, the pre-training architecture in MSP is carefully designed to alleviate the masked shape leakage from point coordinates. Experiments on multiple 3D under-standing tasks on both indoor and outdoor datasets demon-strate the effectiveness of MSP in learning good feature rep-resentations to consistently boost downstream performance. 1.

Introduction
Self-supervised pre-training has witnessed considerable progress in natural language processing (NLP) [4, 10, 42] and 2D computer vision [2, 15, 17, 18], the main idea of which is to define a pretext task to leverage unlabeled data to learn meaningful representations. With the development of transformer [11,30,59], masked signal modeling (MSM) has been proved to be an effective pretext task, attaining bet-ter results than other tasks like contrastive learning [6, 18].
An MSM architecture first partially masks out the input and then reconstructs the masked part given the remaining con-tent, forcing the network to learn semantic knowledge for completing the missing part.
Compared to 2D images, the labeling of 3D real-scene data is more labor-intensive. Therefore, self-supervised pre-training is important in 3D scene understanding for its abil-ity in boosting the performance with limited labeled data.
Previous 3D scene-level pre-training methods mostly fol-low the contrastive pipeline [20, 21, 43, 64]. Though effec-tive, MSM is less explored in 3D scene level. Some recent methods [36, 74] also explore MSM with point clouds but focus on single-object-level understanding. In contrast, we investigate MSM for more practical scene-level understand-ing that contains complicated contextual environments, and we propose a Masked Shape Prediction (MSP) framework to conduct pre-training on point cloud scenes.
There are several key problems when performing masked signal modeling in 3D scenes. The first is the de-sign of the reconstruction target. In 2D images, pixel colors constitute the semantic contents, making appearance sig-nals [17,62] good choices as targets. In 3D, the most essen-tial semantic clue is geometric shape, which motivates us to explore shape information in target design. In 3D scene-level understanding with complex object distribution, broad contextual information is essential in achieving outstand-ing performance. Therefore, to promote the network to ex-ploit contextual cues in shape prediction, we propose the context-enhanced shape target, which includes two compo-nents: shape context and deep shape feature. Shape con-text explicitly describes the 3D shape by discretizing the local space into multiple bins, which is robust to the un-even point distributions. Deep shape feature is extracted from point clouds with complete shapes by a deep network.
As a learned shape descriptor, deep shape feature is able to adaptively integrate contextual information in a larger range, thanks to the large receptive field of the deep net-work. By combining shape context and deep shape feature as our context-enhanced shape target, the network is pro-moted to not only focus on explicit shape patterns, but also on contextual object relations in a larger scope.
Using the geometric shapes as reconstruction target, however, raises another problem. Shape information can be inferred from the point coordinates, yet masked signal modeling requires the coordinates of masked points to spec-ify the target positions for reconstruction, which may reveal the masked shape and thus create a shortcut for network learning.
In this paper, we discuss several MSP network designs to prevent the masked shape from being revealed by the masked point coordinates. The core idea is to either avoid the information interactions between masked points
or restrict the interactions to sparsely sampled keypoints.
We follow [20, 64] to perform unsupervised pre-training on ScanNet v2 [9] indoor scene dataset, and then evalu-ate it via supervised fine-tuning in different downstream tasks. Our MSP extracts representative 3D features that are beneficial in indoor scene understanding tasks on mul-tiple datasets [1, 9, 54], achieving excellent performance in both segmentation and detection and showing great ability in data-efficient learning. We also evaluate its transferring ability to outdoor scenes. Our core technical contributions are listed below:
• We propose a self-supervised pre-training method for 3D scene understanding, namely, Masked Shape Pre-diction (MSP), which consistently boosts the down-stream performance.
• We present the context-enhanced shape target, com-bining the strengths of explicit shape context descrip-tor and implicit deep shape feature.
• We explore different MSP network architecture de-signs to promote feature learning and mitigate the masked shape leakage problem. 2.