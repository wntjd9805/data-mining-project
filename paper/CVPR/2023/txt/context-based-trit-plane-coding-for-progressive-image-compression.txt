Abstract
Trit-plane coding enables deep progressive image com-pression, but it cannot use autoregressive context mod-els. In this paper, we propose the context-based trit-plane coding (CTC) algorithm to achieve progressive compres-sion more compactly. First, we develop the context-based rate reduction module to estimate trit probabilities of la-tent elements accurately and thus encode the trit-planes compactly. Second, we develop the context-based distor-tion reduction module to reﬁne partial latent tensors from the trit-planes and improve the reconstructed image qual-ity. Third, we propose a retraining scheme for the de-coder to attain better rate-distortion tradeoffs. Extensive experiments show that CTC outperforms the baseline trit-plane codec signiﬁcantly, e.g. by −14.84% in BD-rate on the Kodak lossless dataset, while increasing the time com-plexity only marginally. The source codes are available at https://github.com/seungminjeon-github/CTC. 1.

Introduction
Image compression is a fundamental problem in both image processing and low-level vision. A lot of tradi-including standards tional codecs have been developed,
JPEG [47], JPEG2000 [40], and VVC [11]. Many of these codecs are based on discrete cosine transform or wavelet transform. Using handcrafted modules, they provide de-cent rate-distortion (RD) results. However, with the rapidly growing usage of image data, it is still necessary to develop advanced image codecs with better RD performance.
Deep learning has been explored with the advance of big data analysis and computational power, and it also has been successfully adopted for image compression. Learning-based codecs have similar structures to traditional ones: they transform an image into latent variables and then en-code those variables into a bitstream. They often adopt con-volutional neural networks (CNNs) for the transformation.
Several innovations have been made to improve RD per-formance, including differentiable quantization approxima-*Corresponding author. 34 34.5
)
B d (
R
N
S
P 33 33.5
Context models (0.191, 33.27)
CDR
Baseline (0.210, 32.47)
CRR
Original 32 0.18 0.19 0.20 0.21 bpp
Baseline
Context models
RD points
Figure 1. Illustration of the proposed context models: CRR re-duces the bitrate, while CDR improves the image quality, as com-pared with the context-free baseline [27]. tions [5, 6], hyperprior [7], context models [20, 32, 33], and prior models [13,15]. As a result, the deep image codecs are competitive with or even superior to the traditional ones.
It is desirable to compress images progressively in ap-plications where a single bitstream should be used for mul-tiple users with different bandwidths. But, relatively few deep codecs support such progressive compression or scal-able coding [35]. Many codecs should train their networks multiple times to achieve compression at as many bitrates
[7, 13, 33, 53]. Some codecs support variable-rate coding
[15, 51], but they should generate multiple bitstreams for different bitrates.
It is more efﬁcient to truncate a single bitstream to satisfy different bitrate requirements. Lu et al.
[30] and Lee et al. [27] are such progressive codecs, based on nested quantization and trit-plane coding, respectively.
But, they cannot use existing context models [20,26,32–34], which assume the synchronization of the latent elements, used as contexts, in the encoder and the decoder. Those latent elements are at different states depending on bitrates.
In this paper, we propose the context-based trit-plane coding (CTC) algorithm for progressive image compres-sion, based on novel context models. First, we develop the context-based rate reduction (CRR) module, which entropy-encodes trit-planes more compactly by exploiting already decoded information. Second, we develop the context-based distortion reduction (CDR) module, which reﬁnes  
partial latent tensors after entropy decoding for higher-quality image reconstruction. Also, we propose a simple yet effective retraining scheme for the decoder to achieve better
RD tradeoffs. It is demonstrated that CTC outperforms the existing progressive codecs [27, 30] signiﬁcantly.
This paper has the following major contributions:
• We propose the ﬁrst context models, CRR and CDR, for deep progressive image compression. As illus-trated in Figure 1, CRR reduces the bitrate, while CDR improves the image quality effectively, in comparison with the baseline trit-plane coding [27].
• We develop a decoder retraining scheme, which adapts the decoder to reﬁned latent tensors by CDR to im-prove the RD performance greatly.
• The proposed CTC algorithm outperforms the state-of-the-art progressive codecs [27, 30] signiﬁcantly. Rela-tive to [27], CTC yields BD-rates of −14.84% on the
Kodak dataset [3], −14.75% on the CLIC validation set [4], and −17.00% on the JPEG-AI testset [1]. 2.