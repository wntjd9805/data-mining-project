Abstract
Most existing point cloud upsampling methods have roughly three steps: feature extraction, feature expansion and 3D coordinate prediction. However, they usually suf-fer from two critical issues: (1) fixed upsampling rate after one-time training, since the feature expansion unit is cus-tomized for each upsampling rate; (2) outliers or shrink-age artifact caused by the difficulty of precisely predicting 3D coordinates or residuals of upsampled points. To adress them, we propose a new framework for accurate point cloud upsampling that supports arbitrary upsampling rates. Our method first interpolates the low-res point cloud according to a given upsampling rate. And then refine the positions of the interpolated points with an iterative optimization process, guided by a trained model estimating the differ-ence between the current point cloud and the high-res tar-get. Extensive quantitative and qualitative results on bench-marks and downstream tasks demonstrate that our method achieves the state-of-the-art accuracy and efficiency.
Figure 1. The comparison between previous point cloud upsam-pling methods and ours, and N N denotes the deep neural net-work. Given the low-res input PL, previous methods directly pre-dict the 3D coordinates or residuals of high-res output PH . And most of them need retraining to satisfy various upsampling rates.
Instead we first interpolate points in Euclidean space, which sep-arates point generation from network learning and thus achieves arbitrary upsampling rates. Then we formulate the refinement of interpolated points as an iterative process aiming to minimize the learned point-to-point distance function N N (PI ). 1.

Introduction more geometric details.
With the popularity of commercial 3D scanners, cap-turing point clouds from real-world scenes becomes con-venient and affordable.
Thus point clouds have been widely utilized in applications such as autonomous driving, robotics, remote sensing, etc [11]. That being said, the raw point clouds produced by 3D scanners or depth cameras are often sparse and noisy, sometimes with small holes [16], which greatly affects the performance of downstream tasks, such as semantic classification [38], rendering [5], surface reconstruction [1], etc. Consequently, it is vital to upsample a raw point cloud to a dense, clean and complete one, with
Yun He and Xiangyang Xue are with the School of Computer Sci-ence, Fudan University.
Yanwei Fu is with the School of Data Science, Fudan University.
He is also with Shanghai Key Lab of Intelligent Information Processing, and Fudan ISTBI±ZJNU Algorithm Centre for Brain-inspired Intelligence,
Zhejiang Normal University, Jinhua, China.
The common practice towards point cloud upsampling usually consists of three key steps [15, 16, 18, 27, 30, 41, 43]. (1) Feature extraction: capturing point-wise semantic fea-tures from the low-res point clouds. (2) Feature expan-sion: expanding the extracted features w.r.t the specified upsampling rate. (3) Coordinate prediction: predicting 3D coordinates or residuals of upsampled points from the ex-panded features. However, there are two critical issues in this paradigm. Firstly, these models are usually dependent on the upsampling rate. To support different upsampling rates, multiple models need to be trained. Secondly, pre-cisely estimating the 3D coordinates or offsets to the tar-get points is hard, which leads to outliers or shrinkage ar-tifact [20]. Although some recent methods try to handle the fixed upsampling rate problem via affine combination of neighboring points [19, 29] or implicit neural representa-tion [8, 46], their performance is still limited by the inaccu-racy of 3D coordinate prediction.
In this paper, we propose a novel point cloud upsampling algorithm to address these two issues.
In particular, our method decouples the upsampling process into two steps.
First, we propose to directly upsample the input low-res point cloud in Euclidean space by midpoint interpolation, instead of expanding in the feature space. And the amount of interpolated points is determined by a given upsampling ratio. This makes the learning part independent with the up-sampling module and helps the whole method generalize to arbitrary upsampling rates. Secondly, the interpolated point cloud is refined by an iterative process aiming to minimize the difference between the interpolated point cloud and the ground truth high-res point cloud. To measure the differ-ence, we choose to use point-to-point distance, which elimi-nates the need of surface extraction and can handle arbitrary topologies. Moreover, comparing to coordinates (∈ R3), the point-to-point distance (∈ R1) is an easier objective to optimize, thus results in much more accurate upsampling results in our experiments. Since the ground truth point cloud is not available during inference, a model is trained to approximate the point-to-point distance function in a dif-ferentiable manner, thus termed as P2PNet. To improve the training efficiency, we come up with a simple but effective training scheme, by adding Gaussian noise to the data to simulate varying degrees of difference between the input and ground truth point cloud. The P2PNet is then trained to minimize the difference, i.e., the refinement step is regarded as a distance minimization process.
In this paper, we propose a novel framework for accurate point cloud upsampling with arbitrary upsampling rates.
Specifically, our contributions can be summarized as:
• Decompose the upsampling problem into midpoint in-terpolation and location refinement, which achieves ar-bitrary upsampling rates.
• Formulate the refinement step as a point-to-point dis-tance minimization process.
• Propose the P2PNet to estimate the point-to-point dis-tance in a differentiable way.
Extensive experiments show that our method significantly outperforms existing methods in accuracy, efficiency, ro-bustness, and generalization to arbitrary upsampling rates, also improves the performance of downstream tasks such as semantic classification and surface reconstruction. 2.