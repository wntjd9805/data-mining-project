Abstract
The quality of point clouds is often limited by noise in-troduced during their capture process. Consequently, a fun-damental 3D vision task is the removal of noise, known as point cloud filtering or denoising. State-of-the-art learning based methods focus on training neural networks to infer fil-tered displacements and directly shift noisy points onto the underlying clean surfaces. In high noise conditions, they it-erate the filtering process. However, this iterative filtering is only done at test time and is less effective at ensuring points converge quickly onto the clean surfaces. We propose It-erativePFN (iterative point cloud filtering network), which consists of multiple IterationModules that model the true it-erative filtering process internally, within a single network.
We train our IterativePFN network using a novel loss func-tion that utilizes an adaptive ground truth target at each it-eration to capture the relationship between intermediate fil-tering results during training. This ensures that the filtered results converge faster to the clean surfaces. Our method is able to obtain better performance compared to state-of-the-art methods. The source code can be found at: https:
//github.com/ddsediri/IterativePFN . 1.

Introduction
Point clouds are a natural representation of 3D geo-metric information and have a multitude of applications in the field of 3D Computer Vision. These applications range from robotics and autonomous driving to urban plan-ning [14, 19, 35, 38]. They are captured using 3D sensors and comprise of unordered points lacking connectivity in-formation. Furthermore, the capturing of point cloud data is error-prone as sensor quality and environmental factors may
*Corresponding author: X. Lu, supported by PJ03906.PG00507.F002.
†Z. Shao is supported by the NSFC (No. 62106268).
Figure 1. Histograms of filtered point distances from clean surface after 1, 4, 8 and 24 test time iterations for ScoreDenoise [22] on the Casting shape with 50K points and 2.5% Gaussian noise. We compare it with our proposed IterativePFN where 1 IterationMod-ule (ItM) corresponds to 1 internal iteration and 4 ItMs equal 1 external iteration (EI). There are 4 ItMs in the proposed network.
Note 1 ItM is analogous to 1 test time iteration of ScoreDenoise.
Our filtering results converge closer to the surface. introduce noisy artifacts. The process of removing noise is a fundamental research problem which motivates the field of point cloud filtering, also known as denoising. Filtering facilitates other tasks such as normal estimation and, by ex-tension, 3D rendering and surface reconstruction.
Conventional point cloud filtering methods such as
MLS based methods [2, 12], bilateral filtering mecha-nisms [9] and edge recovery algorithms [18, 34] rely on lo-cal information of point sets, i.e., point normals, to filter point clouds. However, such methods are limited by the accuracy of normals. Alternatives include the Locally Opti-mal Projection (LOP) family of methods [13, 17, 25], which downsample and regularize point clouds but incur the loss of important geometric details. More recently, deep learn-ing based filtering methods have been proposed to allevi-ate the disadvantages and limitations of conventional meth-ods [22–24, 28, 41].
Early deep learning based filtering methods, such as
PointProNets [31], require pre-processed 2D height maps to filter point clouds. However, the advent of PointNet,
PointNet++ and DGCNN, made direct point set convolution a possibility [26, 27, 37]. Feature encoders based on these architectures were exploited by recent methods to produce richer latent representations of point set inputs and filter noise more effectively [20,22,28,41]. These methods can be broadly characterized as 1) resampling, 2) probability and 3) displacement based methods. Resampling based meth-ods such as DMRDenoise [20] suffer from the loss of ge-ometric details as the method relies on identifying down-sampled underlying clean surfaces and upsampling along them. ScoreDenoise, which models the gradient-log of the noise-convolved probability to find a point at a given posi-tion, iteratively performs Langevin sampling-inspired gra-dient ascent [22] to filter points. However, filtered points are slow to converge to the clean surface after many test time iterations of filtering, as illustrated in Fig. 1. By con-trast, for an IterativePFN network with 4 IterationModules, where 1 iterationModule (ItM) represents 1 internal itera-tion of filtering and is analogous to 1 test time iteration of
ScoreDenoise, we see that a higher number of filtered points converge closer to the clean surface within the same number of test time iterations.
Among displacement based methods, PointCleanNet (PCN) [28] shows sensitivity to high noise while Pointfil-ter [41] utilizes a bilateral filtering inspired weighted loss function that causes closely separated surfaces to collapse into a single surface during filtering. Moreover, gradient as-cent and displacement based methods filter point clouds it-eratively during test times and do not consider true iterative filtering during training. Although RePCDNet [7] offers a recurrent neural network inspired alternative to capture this information during training, at each iteration RePCDNet at-tempts to directly shift points onto the clean surface without considering, that at different iterations, their existing resid-ual noise, in decreasing order w.r.t. iteration number. Fur-thermore, it uses a single network to filter points, increasing the burden on the network to correctly distinguish between noise scales and requires multiple test time iterations which lead to low efficiency. Based on these major limitations, we propose:
• a novel neural network architecture of stacked encoder-decoder modules, dubbed IterationModule, to model the true iterative filtering process internally (see Fig. 2). Each IterationModule represents an iter-ation of filtering and the output of the τ -th Iteration-Module becomes the input for the τ + 1-th Iteration-Module. Thereby, the τ + 1-th IterationModule repre-sents the filtering iteration t = τ + 1. This allows the network to develop an understanding of the filtering relationship across iterations.
• a novel loss function that formulates the nearest neigh-bor loss at each iteration as the L2 norm minimization between the filtered displacements, inferred by the τ -th
IterationModule, and the nearest point within a target point cloud at t = τ , of a lower noise scale στ com-pared to the noise scale στ −1 of the target at t = τ − 1.
This promotes a gradual filtering process that encour-ages convergence to the clean surface.
• a generalized patch-stitching method that designs
Gaussian weights when determining best filtered points within overlapping patches. Patch stitching improves efficiency as it facilitates filtering multiple points simultaneously.
We conduct comprehensive experiments, in compari-son with state-of-the-art methods, which demonstrate our method’s advantages on both synthetic and real world data. 2.