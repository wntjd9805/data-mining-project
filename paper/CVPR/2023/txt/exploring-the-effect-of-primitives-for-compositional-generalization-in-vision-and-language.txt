Abstract
Compositionality is one of the fundamental properties of human cognition (Fodor & Pylyshyn, 1988). Compositional generalization is critical to simulate the compositional ca-pability of humans, and has received much attention in the
It is essential to vision-and-language (V&L) community. understand the effect of the primitives, including words, im-age regions, and video frames, to improve the compositional generalization capability. In this paper, we explore the ef-fect of primitives for compositional generalization in V&L.
Specifically, we present a self-supervised learning based framework that equips existing V&L methods with two char-acteristics: semantic equivariance and semantic invari-ance. With the two characteristics, the methods understand primitives by perceiving the effect of primitive changes on sample semantics and ground-truth. Experimental results on two tasks: temporal video grounding and visual question answering, demonstrate the effectiveness of our framework. 1.

Introduction
Compositionality is one of the fundamental properties of human cognition argued by Fodor and Pylyshyn [11]. Com-positional generalization in vision-and-language (V&L) has received increasing attention and significant progress in re-cent years, but has not been fully explored. Compositional generalization requires V&L methods to generalize well to sentences with novel combinations of seen words, which is critical to simulate the compositional properties of human cognition.
*Corresponding author: Chenchen Jing and Yuwei Wu
Figure 1. An example in the context of temporal video grounding, showing that primitives are the determinants of sample semantics and ground-truth.
An indispensable premise for improving compositional generalization is to understand the effect of the primitives, including words, image regions, and video frames. Primi-tives are compositional building blocks mainly involved in
V&L tasks and the determinants of sample semantics. For example, for a sample with the query “A person opens the door” in the context of temporal video grounding (TVG), its semantics are changed completely when the primitive
“opens” is changed to “closed”, but are unchanged when the primitives “A” and “the” are modified to “The” and “a”, respectively, as shown in Fig. 1. We investigate if existing
V&L methods are sensitive to the sample semantic changes brought by primitive changes. Our observations show that the methods erroneously keep almost 90% of the predic-tions unchanged when the sample semantics are corrupted by replacing 50% critical words (e.g., nouns, verbs) in sen-tences. This suggests that existing methods cannot correctly establish the relationship between the primitives and the sample semantics and thus the ground-truth, so they cannot achieve compositional generalization.
In this paper, we explore the effect of primitives for com-positional generalization from two aspects: semantic equiv-experiments on two V&L tasks: temporal video grounding
[2] and visual question answering [3], demonstrate that our framework improves the compositional generalization ca-pability of existing methods.
In summary, our contributions are as follows:
• We explore the effect of primitives on improving the compositional generalization capability of exist-ing V&L methods by perceiving the effect of primitive changes on sample semantics and ground-truth.
• We propose a self-supervised learning based frame-work for compositional generalization, in which nu-merous labeled samples are generated to equip existing
V&L methods with semantic equivariance and seman-tic invariance. 2.