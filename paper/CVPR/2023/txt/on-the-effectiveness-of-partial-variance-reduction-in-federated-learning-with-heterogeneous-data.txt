Abstract
Data heterogeneity across clients is a key challenge in federated learning. Prior works address this by either aligning client and server models or using control vari-ates to correct client model drift. Although these methods achieve fast convergence in convex or simple non-convex problems, the performance in over-parameterized models such as deep neural networks is lacking.
In this paper, we ﬁrst revisit the widely used FedAvg algorithm in a deep neural network to understand how data heterogeneity in-ﬂuences the gradient updates across the neural network layers. We observe that while the feature extraction lay-ers are learned efﬁciently by FedAvg, the substantial diver-sity of the ﬁnal classiﬁcation layers across clients impedes the performance. Motivated by this, we propose to correct model drift by variance reduction only on the ﬁnal layers.
We demonstrate that this signiﬁcantly outperforms existing benchmarks at a similar or lower communication cost. We furthermore provide proof for the convergence rate of our algorithm. 1.

Introduction
Federated learning (FL) is emerging as an essential dis-tributed learning paradigm in large-scale machine learning.
Unlike in traditional machine learning, where a model is trained on the collected centralized data, in federated learn-ing, each client (e.g. phones and institutions) learns a model with its local data. A centralized model is then obtained by aggregating the updates from all participating clients with-out ever requesting the client data, thereby ensuring a cer-tain level of user privacy [13, 17]. Such an algorithm is es-pecially beneﬁcial for tasks where the data is sensitive, e.g. chemical hazards detection and diseases diagnosis [33].
Two primary challenges in federated learning are i) han-⇤ Work done while at CISPA
‡ CISPA Helmholtz Center for Information Security
Client 2 1
N
.....
Server
Feature extractor 
Classifier 
Variance reduction
Figure 1. Our proposed FedPVR framework with the performance server). Smaller ↵ (communicated parameters per round client corresponds to higher data heterogeneity. Our method achieves a better speedup than existing approaches by transmitting a slightly larger number of parameters than FedAvg. () dling data heterogeneity across clients [13] and ii) lim-iting the cost of communication between the server and clients [10].
In this setting, FedAvg [17] is one of the most widely used schemes: A server broadcasts its model to clients, which then update the model using their local data in a series of steps before sending their individual model to the server, where the models are aggregated by averaging the parameters. The process is repeated for multiple com-munication rounds. While it has shown great success in many applications, it tends to achieve subpar accuracy and convergence when the data are heterogeneous [14, 24, 31].
The slow and sometimes unstable convergence of Fe-dAvg can be caused by client drift [14] brought on by data heterogeneity. Numerous efforts have been made to im-prove FedAvg’s performance in this setting. Prior works attempt to mitigate client drift by penalizing the distance between a client model and the server model [20, 31] or by performing variance reduction techniques while updat-ing client models [1, 14, 32]. These works demonstrate fast convergence on convex problems or for simple neu-ral networks; however, their performance on deep neural
networks, which are state-of-the-art for many centralized learning tasks [11, 34], has yet to be well explored. Adapt-ing techniques that perform well on convex problems to neural networks is non-trivial [7] due to their “intriguing properties” [38] such as over-parametrization and permuta-tion symmetries.
To overcome the above issues, we revisit the FedAvg al-gorithm with a deep neural network (VGG-11 [34]) under the assumption of data heterogeneity and full client partici-pation. Speciﬁcally, we investigate which layers in a neural network are mostly inﬂuenced by data heterogeneity. We deﬁne drift diversity, which measures the diversity of the di-rections and scales of the averaged gradients across clients per communication round. We observe that in the non-IID scenario, the deeper layers, especially the ﬁnal classiﬁcation layer, have the highest diversity across clients compared to an IID setting. This indicates that FedAvg learns good fea-ture representations even in the non-IID scenario [5] and that the signiﬁcant variation of the deeper layers across clients is a primary cause of FedAvg’s subpar performance.
Based on the above observations, we propose to align the classiﬁcation layers across clients using variance reduc-tion. Speciﬁcally, we estimate the average updating direc-tion of the classiﬁers (the last several fully connected layers) at the client ci and server level c and use their difference as a control variate [14] to reduce the variance of the classi-ﬁers across clients. We analyze our proposed algorithm and derive a convergence rate bound.
We perform experiments on the popular federated learn-ing benchmark datasets CIFAR10 [19] and CIFAR100 [19] using two types of neural networks, VGG-11 [34] and
ResNet-8 [11], and different levels of data heterogene-ity across clients. We experimentally show that we re-quire fewer communication rounds compared to the exist-ing methods [14,17,31] to achieve the same accuracy while transmitting a similar or slightly larger number of param-eters between server and clients than FedAvg (see Fig. 1).
With a (large) ﬁxed number of communication rounds, our method achieves on-par or better top-1 accuracy, and in some settings it even outperforms centralized learning. Us-ing conformal prediction [3], we show how performance can be improved further using adaptive prediction sets.
We show that applying variance reduction on the last lay-ers increases the diversity of the feature extraction layers.
This diversity in the feature extraction layers may give each client more freedom to learn richer feature representations, and the uniformity in the classiﬁer then ensures a less biased decision. We summarize our contributions here:
• We present our algorithm for partial variance-reduced federated learning (FedPVR). We experimentally demonstrate that the key to the success of our algo-rithm is the diversity between the feature extraction layers and the alignment between the classiﬁers.
• We prove the convergence rate in the convex set-tings and non-convex settings, precisely characterize its weak dependence on data-heterogeneity measures and show that FedPVR provably converges as fast as the centralized SGD baseline in most practical relevant cases.
• We experimentally show that our algorithm is more communication efﬁcient than previous works across various levels of data heterogeneity, datasets, and neu-ral network architectures. In some cases where data heterogeneity exists, the proposed algorithm even per-forms slightly better than centralized learning. 2.