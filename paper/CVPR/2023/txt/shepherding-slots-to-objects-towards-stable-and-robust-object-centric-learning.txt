Abstract
Object-centric learning (OCL) aspires general and com-positional understanding of scenes by representing a scene as a collection of object-centric representations. OCL has also been extended to multi-view image and video datasets to apply various data-driven inductive biases by utilizing geometric or temporal information in the multi-image data.
Single-view images carry less information about how to dis-entangle a given scene than videos or multi-view images do. Hence, owing to the difficulty of applying inductive bi-ases, OCL for single-view images remains challenging, re-sulting in inconsistent learning of object-centric represen-tation. To this end, we introduce a novel OCL framework for single-view images, SLot Attention via SHepherding (SLASH), which consists of two simple-yet-effective mod-ules on top of Slot Attention. The new modules, Attention
Refining Kernel (ARK) and Intermediate Point Predictor and Encoder (IPPE), respectively, prevent slots from be-ing distracted by the background noise and indicate loca-tions for slots to focus on to facilitate learning of object-centric representation. We also propose a weak semi-supervision approach for OCL, whilst our proposed frame-work can be used without any assistant annotation during the inference. Experiments show that our proposed method enables consistent learning of object-centric representa-tion and achieves strong performance across four datasets.
Code is available at https://github.com/object-understanding/SLASH.
Figure 1. Results of training Slot Attention [35] with different seeds, which show inconsistent learning results. In the first trial, object-centric representations fail to grasp each distinct object due to the background noise.
In the second, the model succeeds in distinguishing each different object from the background. 1.

Introduction
Object-centric learning (OCL) decomposes an image into a set of vectors corresponding to each distinct ob-ject to acquire object-wise representations [16]. Learning object-centric representation enables machines to perceive the visual world in a manner similar to humans. We recog-*Equal contribution, a coin is flipped. nize the world as a composition of objects [27] and extend the object-related knowledge to various environments [48].
Therefore, OCL enables a compositional understanding of an image and generalization for downstream tasks, such as visual reasoning [36] and object localization [6].
Mainstream OCL has adopted an autoencoding-based compositional generative model [10, 15, 35]. Slot Atten-tion [35] is the most prominent technique for OCL, which
uses slots as the intermediate representation bottlenecks. In the Slot Attention, randomly initialized slots compete with each other to occupy their attention regions in terms of pix-els. Eventually, each slot attains object-centric representa-tion by aggregating visual features according to the atten-tion map between the slot and pixels.
Recently, OCL has been extended to multi-view im-ages [4, 42] and videos [9, 30, 46]. Multi-view image [43] or video [13, 14, 51] datasets allow models to learn spa-tial geometry or temporal dynamics of objects through supplementary objective tasks such as novel view synthe-sis [42] and optical flow inference [30]. Consequently, these datasets provide additional information that enables the adoption of data-driven inductive biases, facilitating the learning of better object-centric representations.
In contrast, it is challenging to obtain data-driven in-ductive biases, such as geometric or temporal informa-tion, for single-view images. To address this problem, novel architectures, such as auto-regressive generative mod-els [3,10,11,15] and Transformer [53] for encoders [44] and decoders [45], have been proposed. However, owing to the absence of additional inductive biases, OCL for complex single-view images suffers from unstable training results.
This stability issue implies inconsistent learning of object-centric representation, that is, not all trials of train-ing a model with the same architecture consistently succeed in distinguishing objects from the background (Fig. 1). The attention-leaking problem, or bleeding issue, can mislead a model to yield object-centric representations based on dis-torted attention maps. The bleeding issue is fatal for OCL because it is difficult to predict the behavior of a model, that is, whether a slot will seize a distinct object or an object en-tangled with a background.
To solve this bleeding issue, we propose a novel OCL framework, SLASH (SLot Attention via SHepherding).
SLASH resolves the bleeding by guiding the randomly ini-tialized slots to successfully grasp objects 1) without being distracted by the background and 2) by keeping informed of the destination. These are accomplished by adding two simple-yet-effective modules, Attention Refining Ker-nel (ARK) and Intermediate Point Predictor and Encoder (IPPE), to the Slot Attention framework.
ARK is a single-channel single-layer convolutional ker-nel, designed to prevent slots from focusing on a noisy background. We adopt the Weights-Normalized Convolu-tional (WNConv) kernel, a learnable low-pass filter, as the kernel for ARK. This simple kernel refines the attention map between slots and pixels by reducing noise and solidi-fying object-like patterns.
IPPE serves as an indicator to nudge a slot to focus on the proper location. Thus, the slots can consistently update their representations without being confused by the background.
IPPE consists of two submodules with simple MLPs. The first submodule predicts the position of an object in two-dimensional coordinates, and the second encodes the pre-dicted coordinates into a high-dimensional vector.
Since IPPE needs to be trained to provide locational cues to slots, it is necessary to introduce positional labels. How-ever, using fully annotated ground-truths is costly, partic-ularly for densely-annotated labels such as object masks.
Hence, we adopt a weak semi-supervision approach in which only a small subset of the dataset includes weak annotations, such as the centers of bounding boxes. We show that IPPE can be successfully trained with weakly semi-supervised learning and can be deployed under cir-cumstances where no assistant ground-truth exists.
For a comprehensive study, we validate our method on numerous datasets, including CLEVR, CLEVRTEX, PTR, and MOVi. Moreover, we conduct 10 trials of train-ing for each method, including the baselines and ours, to thoroughly evaluate the results. We estimate the perfor-mance of the models using three metrics: mean Intersec-tion over Union (mIoU), Adjusted Rand Index (ARI), and foreground-ARI (fg-ARI) In particular, mIoU and ARI in-vestigate whether the bleeding issue occurs by considering the background separation. A model is defined as being sta-ble over the metrics when deviations are lower, and as being robust when averages are higher across all datasets. Exper-imental results demonstrate that our method achieves stable and robust OCL that prevents the bleeding issue.
Our main contributions are as follows:
• We observe OCL for single-view images suffers from the stability issue with inconsistent training results.
To resolve this issue, we propose a novel framework,
SLASH (SLot Attention via SHepherding) consisting of two simple-yet-strong modules: ARK and IPPE.
• ARK is a learnable low-pass filter designed to prevent the bleeding issue where the attention of a slot leaks into a background.
• IPPE is introduced to inform slots of the regions to be focused. By leveraging weak semi-supervision, IPPE can inject positional information into a slot.
• We empirically prove SLASH achieves stable and ro-bust OCL against four distinctive datasets. SLASH shows the best stability while outperforming the pre-vious methods for all datasets over multiple metrics. 2.