Abstract
The cost of pathological examination makes virtual re-staining of pathological images meaningful. However, due to the ultra-high resolution of pathological images, tradi-tional virtual re-staining methods have to divide a WSI im-age into patches for model training and inference. Such a limitation leads to the lack of global information, result-ing in observable differences in color, brightness and con-trast when the re-stained patches are merged to generate an image of larger size. We summarize this issue as the square effect. Some existing methods try to solve this is-sue through overlapping between patches or simple post-processing. But the former one is not that effective, while the latter one requires carefully tuning. In order to elim-inate the square effect, we design a bi-directional feature fusion generative adversarial network (BFF-GAN) with a
It learns the inter-global branch and a local branch. patch connections through the fusion of global and local features plus patch-wise attention. We perform experiments on both the private dataset RCC and the public dataset AN-HIR. The results show that our model achieves competitive performance and is able to generate extremely real images that are deceptive even for experienced pathologists, which means it is of great clinical significance. 1.

Introduction
Pathological examination is the primary method of can-cer diagnosis. Different dyes can interact with different components in tissues or cells, making it easier to distin-*Zhineng Chen is the corresponding author. guish different microstructures, abnormal substances and lesions. Among various staining methods, the most com-mon and basic one is the hematoxylin-eosin (HE) staining.
However, given the result of HE staining, it is not always enough to make a diagnosis. Therefore, immunohistochem-istry (IHC) staining based on specific binding of antigen and antibody is also necessary in diagnosis, even though it is complex, time-consuming and expensive [7, 25].
Due to the cost of IHC, some researchers have tried to generate one type of staining images from another type (usually HE) via computational methods. This can reduce the consumption of materials, money and time during di-agnosis. Such a task is usually called virtual re-staining.
This task is close to the style transfer of natural images, so it is possible to apply style transfer methods to virtual re-staining. Since pathological images are usually unpaired, virtual re-staining is generally done by unsupervised meth-ods, such as [4, 19, 22]. These approaches are all based on style transfer models for natural images. Researchers made some improvements according to the characteristics of pathological images, and finally achieved better results.
However, on the other hand, pathological images have their own characteristics. For example, the reliability of the results is more critical for this task due to the clinical sig-nificance of pathological examination. Meanwhile, the res-olution of pathological images is usually higher than that of natural images, reaching 10k ×10k or more. Therefore, vir-tual re-staining requires additional computational resources as the GPU memory is limited. Most of the existing vir-tual re-staining models solve this problem by splitting WSI (whole-slide imaging) images into smaller patches for train-ing and inference, and then incorporating these patches into
WSI images through post-processing. This results in dif-Figure 1. Illustration of the square effect. (a) a real 1600 × 1600
HE-stained image. (b) a virtually re-stained CK7 image obtained by merging separately re-stained 400 × 400 patches (using Cy-(c) image obtained by merging cleGAN) without overlapping. 448 × 448 patches with an overlap of 64 pixels. (d) the result generated by our BFF-GAN. ferences in color and brightness between adjacent patches, which we call the square effect. As shown in Fig. 1, (a) is a real HE image, (b) and (c) are CK7 images re-stained by
CycleGAN without and with an overlap. Generally, over-lapping is used to solve this problem, but we can see that the square effect always exists no matter whether there is an overlap. Meanwhile, the result of our BFF-GAN is shown in (d), and it is not easy to find the square effect in it.
Indeed, the square effect exists because patch-based vir-tual re-staining lacks global information, resulting in mis-matches in hue, contrast and brightness between adjacent patches, especially for the regions with different tissue structures and the boundary regions. In addition, since the re-staining of each patch is independent, there may also be color differences between the re-staining results of patches with similar tissue structures. Most existing studies did not consider the global information, leading to serious square effect. To solve this problem, [18] proposed perceptual embedding consistency (PEC) loss, which forces the gen-erator to learn features like color, brightness and contrast.
But it is hard to say only using the PEC loss on the patch level can solve this problem to what extent. Subsequently,
URUST [11] attempted to correct the mean value and stan-dard deviation of the central patch with those of the sur-rounding patches. However, the parameters of this method are artificially designed and may not generalize well.
In the natural image domain, some researchers have at-tempted to get improvement through context aggregation.
For example, PSPNet [39] improved the performance of se-mantic segmentation by increasing the receptive field with pooling kernels of different sizes. HRNet [32] designed par-allel branches with different resolutions and integrated fea-ture maps between different branches, achieving impressive performance in a number of visual tasks. GLNet [6] com-bined feature maps of the entire image with those of patches to improve segmentation performance of high-resolution images. These methods obtained nulti-scale information through feature fusion, and worked well on multiple tasks.
Based on these observations, in this paper, we propose a model that combines global-local features to learn the re-lationship between patches to solve the square effect, and meanwhile, bypasses the memory constraint for ultra-high resolution images. We design an architecture that consists of a global branch and a local branch, where the former takes the down-sampled whole images as input, and the lat-ter takes the patch-level images coming in batches as input.
The two branches perform feature fusion in both directions in the encoder and use patch-wise attention and skip con-nections to enhance feature expression capability. Finally, we fuse the features of the two branches to output the re-staining results. To verify the effectiveness of the method, extensive experiments were conducted on the private dataset
RCC and the public dataset ANHIR [3]. The results show that our model achieves good performance on a variety of metrics, not only significantly eliminating the square effect, but also being generalizable to various datasets. Mean-while, subjective experiments have also demonstrated the clinical significance of our model. In summary, our main contributions are listed as follows:
- The square effect significantly influences the quality of the virtually re-stained images. Thus, we propose to solve the square effect through the fusion of global and local features. Such an idea can be used in various networks, not only CycleGAN, but also other more ad-vanced style transfer models.
- We propose a model with feature fusion between two branches called BFF-GAN to learn the inter-patch re-lations. To our knowledge, it is the first network for style transfer of ultra-high resolution images.
- Our proposed BFF-GAN achieves impressive results.
It is of great clinical significance and can be general-ized to various datasets. 2.