Abstract
Data augmentation (DA) is an efficient strategy for im-proving the performance of deep neural networks. Recent
DA strategies have demonstrated utility in single image super-resolution (SR). Little research has, however, focused on the DA strategy for light field SR, in which multi-view information utilization is required. For the first time in light field SR, we propose a potent DA strategy called CutMIB to improve the performance of existing light field SR networks while keeping their structures unchanged. Specifically, Cut-MIB first cuts low-resolution (LR) patches from each view at the same location. Then CutMIB blends all LR patches to generate the blended patch and finally pastes the blended patch to the corresponding regions of high-resolution light field views, and vice versa. By doing so, CutMIB en-ables light field SR networks to learn from implicit geo-metric information during the training stage. Experimen-tal results demonstrate that CutMIB can improve the re-construction performance and the angular consistency of existing light field SR networks. We further verify the ef-fectiveness of CutMIB on real-world light field SR and light field denoising. The implementation code is available at https://github.com/zeyuxiao1997/CutMIB. 1.

Introduction
Light field cameras, which can record spatial and angular information of light rays, have rapidly become prominent imaging devices in virtual and augmented reality. Light fields are suitable for various applications, such as post-capture refocusing [35, 55], disparity estimation [52], and foreground occlusion removal [54, 69], thanks to the abun-dance of 4D spatial-angular information they contain. Com-mercialized light field cameras generally adopt micro-lens-array in front of the sensor, which poses an essential trade-off between the angular and spatial resolutions [29, 35].
Therefore, light field super-resolution (SR) has been an im-portant and popular topic. Convolutional neural network
*Corresponding author.
Figure 1. Comparisons on the reconstruction fidelity (PSNR, ↑) and the angular consistency (MSE, ↓) between light fields super-resolved through different methods. Following [9], we super-resolve the whole light field of the scene Bicycle from the HCI dataset to analyze the angular consistency of the super-resolved results in terms of disparity estimation using SPO [70]. Note that,
CutMIB improves the values of PSNR and lowers the values of
MSE by a large margin as compared to na¨ıve light field SR meth-ods (e.g., ATO [27], InterNet [53], IINet [33], and DPT [47]). (CNN) based and Transformer based methods have recently shown promising performance for light field SR [7, 8, 10, 26, 31, 33, 47, 52, 53, 56], outperforming traditional non-learning based methods [1, 38] with noticeable gains. This performance boost is obtained by training deep methods on external datasets. Few works have investigated data aug-mentation (DA) strategies for light field SR, which can im-prove the model performance without the need for addi-tional training datasets given that obtaining these light field data is often time-consuming and expensive [19, 23, 36, 48].
DA has been well studied in high-level vision tasks (e.g., image recognition, image classification, and semantic seg-mentation) for achieving better network performance and alleviating the overfitting problem [14,44,49,64,66,71]. For example, as one of the pioneering strategies, Mixup [66]
Figure 2. Illustrative examples of (a) CutBlur and (b) our proposed CutMIB. CutBlur generates augmented SAIs view-by-view via the
“cutting-pasting” operation. CutMIB generates the augmented light field via the “cutting-blending-pasting” operation. The implicit geo-metric information can be utilized during the training stage. shown in Figure 2(a). However, the ignorance of the inher-ent correlation in the spatial-angular domain makes it sub-optimal. We provide a visual observation using the phase spectrum since it contains rich texture information [46, 62] in Figure 3. Specifically, we use CutBlur on the LR center view (Figure 3(a)) in a 5×5 light field, cut an HR patch, and then paste it to the original LR image, and analyze the phase spectrum of the processed LR image. We can directly ob-serve from the calculated residual map in Figure 3(c) that there is little additional information from the pasted HR patch using the CutBlur strategy. This encourages us to re-alize the need for a more effective strategy to exploit patches from multiple views.
Based on the aforementioned observation, we propose
CutMIB, a novel DA strategy specifically designed for light field SR, as shown in Figure 2(b). Our CutMIB, which is inspired by CutBlur [60], first cuts LR patches from differ-ent views in an LR light field at the same position. The cut LR patches are then blended to generate the blended
LR patch, which is then pasted to the corresponding areas of various HR light field views, and vice versa. There-fore, each augmented light field pair has partially blended
LR and blended HR pixel distributions with a random ra-tio. By feeding the augmented training pairs into light field
SR networks, these networks can not only learn “how” and
“where” to super-resolve the LR light field (i.e., benefit from the cutting-blending operation [60]), but also utilize the implicit geometric information in multi-view images, resulting in better performance and higher angular consis-tency among super-resolved light field views (i.e., benefit from the blending operation [2, 5, 17]). Figure 3(f) illus-trates that pasting the blended HR patch to the LR center view (Figure 3(a)) results in more additional details in the pasted area. This demonstrates that our CutMIB can more effectively use multi-view information in a light field.
Thanks to CutMIB, we can improve both the reconstruc-tion quality and the angular consistency of light field SR
Figure 3. Analyzing CutBlur and CutMIB from a phase spectrum perspective. (a) The center view image in a 5 × 5 light field. The red rectangle denotes the area for the cutting and pasting operation. (b) The phase spectrum of the original LR center view image. (c) is the calculated residual map between (b) and (d). (d) The phase spectrum of the LR center view image with the pasted LR patch us-ing CutBlur. We cut an HR patch from the HR center view image, and paste it to the LR center view image. (e) The phase spectrum of the LR center view image with the pasted blended patch using
CutMIB. We cut all HR patches from the HR light field, blend them, and then paste the blended patch to the LR center view im-age. (f) is the calculated residual map between (b) and (e). blends two images to generate an unseen training sample.
The effectiveness of the DA strategy on light field SR has received very little attention. Instead, only geometric trans-formation strategies such as flipping and rotating are used in light field SR. Recently, Yoo et al. [60] propose CutBlur, a
DA strategy for training a stronger single image SR model, in which a low-resolution (LR) patch is cut and pasted to the corresponding high-resolution (HR) image region, and vice versa. A straightforward way to utilize the DA strategy on light field SR is to perform CutBlur on each view in a light field and train single image SR networks view by view, as
results while maintaining the network structures unchanged (see Figure 1). Additionally, we verify the effectiveness of the proposed CutMIB on real-world light field SR and light field denoising tasks.
Contributions of this paper are summarized as follows: (1) We propose a novel DA strategy, CutMIB, to improve the performance of existing light field SR networks. To our best knowledge, it is the first DA strategy for light field SR.
Through the “cutting-blending-pasting” operation, CutMIB is designed to efficiently explore the geometric information in light fields during the training stage. (2) Extensive experiments demonstrate CutMIB can boost the reconstruction fidelity and the angular consistency of existing typical light field SR methods. (3) We verify the effectiveness of CutMIB on real-world light field SR and light field denoising tasks. 2.