Abstract
Advancements in the generation quality of various Gen-erative Models (GMs) has made it necessary to not only perform binary manipulation detection but also localize the modified pixels in an image. However, prior works termed as passive for manipulation localization exhibit poor gener-alization performance over unseen GMs and attribute mod-ifications. To combat this issue, we propose a proactive scheme for manipulation localization, termed MaLP. We encrypt the real images by adding a learned template. If the image is manipulated by any GM, this added protec-tion from the template not only aids binary detection but also helps in identifying the pixels modified by the GM.
The template is learned by leveraging local and global-level features estimated by a two-branch architecture. We show that MaLP performs better than prior passive works. We also show the generalizability of MaLP by testing on 22 different GMs, providing a benchmark for future research on manipulation localization. Finally, we show that MaLP can be used as a discriminator for improving the gener-ation quality of GMs. Our models/codes are available at www.github.com/vishal3477/pro_loc. 1.

Introduction
We witness numerous Generative Models (GMs) [8, 9, 15, 17, 23–25, 28, 34, 39, 44, 50, 52, 60] being proposed to generate realistic-looking images. These GMs can not only generate an entirely new image [23, 24], but also perform partial manipulation of an input image [9, 9, 28, 60]. The proliferation of these GMs has made it easier to manipulate personal media for malicious use. Prior methods to combat manipulated media focus on binary detection [1,2,5,11,14, 30, 45, 48, 55, 56], using mouth movement, model parsing, hand-crafted features, etc.
Recent works go one step further than detection, i.e. ma-nipulation localization, which is defined as follows: given
*All data sourcing, modeling codes, and experiments were developed at
Michigan State University. Meta did not obtain the data/codes or conduct any experiments in this work.
Figure 1. (a) High-level idea of MaLP. We encrypt the image by adding a learnable template, which helps to estimate the fakeness (b) The cosine similarity (CS) between ground-truth and map. predicted fakeness maps for 22 unseen GMs. The performance is better for almost all GMs when using our proactive approach. a partially manipulated image by a GM (e.g. STGAN [28] modifying hair colors of a face image), the goal is to iden-tify which pixels are modified by estimating a fakeness map [21]. Identifying modified pixels helps to determine the severity of the fakeness in the image, and aid media-forensics [11, 21]. Also, manipulation localization pro-vides an understanding of the attacker’s intent for modifica-tion which may further benefit identifying attack toolchains used [13].
Recent methods for manipulation localization [27,37,49] focus on estimating the manipulation mask of face-swapped images. They localize modified facial attributes by lever-aging attention mechanisms [11], patch-based classifier [4], and face-parsing [21]. The main drawback of these methods is that they do not generalize well to GMs unseen in train-ing. That is when the test images and training images are modified by different GMs, which will likely happen given the vast number of existing GMs. Thus, our work aims for a localization method generalizable to unseen GMs.
All aforementioned methods are based on a passive scheme as the method receives an image as is for estima-tion. Recently, proactive methods are gaining success for deepfake tasks such as detection [1], disruption [46, 57], and tagging [51]. These methods are considered proactive as they add different types of signals known as templates for encrypting the image before it is manipulated by a GM.
This template can be one-hot encoding [51], adversarial per-turbation [46], or a learnable noise [1], and is optimized to improve the performance of the defined tasks.
Motivated by [1], we propose a Proactive scheme for
MAnipulation Localization, termed as MaLP, in order to improve generalization. Specifically, MaLP learns an op-timized template which, when added to real images, would improve manipulation localization, should they get manip-ulated. This manipulation can be done by an unseen GM trained on either in-domain or out-of-domain datasets. Fur-thermore, face manipulation may involve modifying facial attributes unseen in training (e.g. train on hair color mod-ification yet test on gender modification). MaLP incorpo-rates three modules that focus on encryption, detection, and localization. The encryption module selects and adds the template from the template set to the real images. These encrypted images are further processed by localization and detection modules to perform the respective tasks.
First,
Designing a proactive manipulation localization ap-proach comes with several challenges. it is not straightforward to formulate constraints for learning the template unsupervisedly. Second, calculating a fakeness map at the same resolution as the input image is compu-tationally expensive if the decision for each pixel has to be made. Prior works [4, 11] either down-sample the images or use a patch-wise approach, both of which result in inac-curate low-resolution fakeness maps. Lastly, the templates should be generalizable to localize modified regions from unseen GMs.
We design a two-branch architecture consisting of a shal-low CNN network and a transformer to optimize the tem-plate during training. While the former leverages local-level features due to its shallow depth, the latter focuses on global-level features to better capture the affinity of the far-apart regions. The joint training of both networks enables the MaLP to learn a better template, having embedded the information of both levels. During inference, the CNN net-work alone is sufficient to estimate the fakeness map with a higher inference efficiency. Compared to prior passive works [11, 21], MaLP improves the generalization perfor-mance on unseen GMs. We also demonstrate that MaLP can be used as a discriminator for fine-tuning conventional
GMs to improve the quality of GM-generated images.
In summary, we make the following contributions.
• We are the first to propose a proactive scheme for im-age manipulation localization, applicable to both face and generic images.
• Our novel two-branch architecture uses both local and global level features to learn a set of templates in an unsu-pervised manner. The framework is guided by constraints based on template recovery, fakeness maps classification, and high cosine similarity between predicted and ground-truth fakeness maps.
Table 1. Comparison of our approach with prior works on manip-ulation localization and proactive schemes. We show the general-ization ability of all works across different facial attribute modi-fications, unseen GMs trained on datasets with the same domain (in-domain) and different domains (out-domain). [Keys: Attr.: At-tributes, Imp.: Improving, L.: Localization, D.: Detection]
Work
Scheme
Task
Template
[51]
[47]
[46]
[57]
[1]
[37]
[49]
[27]
[11]
[4]
[21]
MaLP
Tag
Proactive
Proactive Disrupt
Proactive Disrupt
Proactive Disrupt
Proactive
Passive
Passive
Passive
Passive
Passive
Passive
Proactive
D.
L. + D.
L. + D.
L. + D.
L. + D.
L. + D.
L. + D.
L. + D.
Fix
Learn
Learn
Learn
Learn
------Learn
Attr.
✔
✔
✔
✔
✖
✖
✖
✖
✔
✖
✔
✔
Generalization
Imp.
In-domain Out-domain GM
✖
✖
✖
✖
✖
✖
✖
✖
✖
✖
✖
✔
✔
✖
✔
✖
✔
✖
✖
✔
✔
✔
✔
✔
✖
✖
✖
✖
✔
✖
✖
✖
✖
✖
✖
✔
• MaLP can be used as a plug-and-play discriminator mod-ule to fine-tune the generative model to improve the qual-ity of the generated images.
• Our method outperforms State-of-The-Art (SoTA) meth-ods in manipulation localization and detection. Further-more, our method generalizes well to GMs and modified attributes unseen in training. To facilitate the research of localization, we develop a benchmark for evaluating the generalization of manipulation localization, on im-ages where the train and test GMs are different. 2.