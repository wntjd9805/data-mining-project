Abstract
We present CARTO, a novel approach for reconstruct-ing multiple articulated objects from a single stereo RGB observation. We use implicit object-centric representations and learn a single geometry and articulation decoder for multiple object categories. Despite training on multiple cat-egories, our decoder achieves a comparable reconstruction accuracy to methods that train bespoke decoders separately for each category. Combined with our stereo image encoder we infer the 3D shape, 6D pose, size, joint type, and the joint state of multiple unknown objects in a single forward pass.
Our method achieves a 20.4% absolute improvement in mAP 3D IOU50 for novel instances when compared to a two-stage pipeline. Inference time is fast and can run on a NVIDIA
TITAN XP GPU at 1 HZ for eight or less objects present.
While only trained on simulated data, CARTO transfers to real-world object instances. Code and evaluation data is available at: carto.cs.uni-freiburg.de 1.

Introduction
Reconstructing 3D shapes and inferring the 6D pose and sizes of objects from partially observed input observations remains a fundamental problem in computer vision with ap-plications in Robotics [10, 11, 13, 20] and AR/VR [8, 44].
This object-centric 3D scene understanding problem is chal-lenging and under-constrained since inferring 6D pose and shape can be ambiguous without prior knowledge about the object of interest. Previous work has shown that it is possible to perform category-level 3D shape reconstruction and 6D pose estimation in real-time [7], enabling the reconstruction of complete, fine-grained 3D shapes and textures. However, there are a wide variety of real-world objects that do not have a constant shape but can be articulated according to the object’s underlying kinematics. There has been great progress in articulated object tracking [5,9,32,37] and recon-struction [10, 26] from a sequence of observations. However, a sequence of observations is cumbersome since it often requires prior interaction with the environment. In contrast, object reconstruction from a single stereo image through inferring latent information about an object a priori enables both grasping and manipulation of previously unknown artic-ulated objects. Additionally, estimates from a single image can also serve as a good initial guess for object tracking approaches [37].
Previous approaches to articulated object reconstruction from a single observation use a two-stage approach [16] where first objects are detected using, e.g., Mask-RCNN [4].
Then, based on the detection output, object properties, e.g. part-poses and NOCS maps [35], are predicted and the object is reconstructed using backward optimization [24]. Such an
approach is complex, error prone, does not scale across many categories, and does not run in real-time.
To mitigate the aforementioned challenges, building on ideas from [7] - a single-shot approach to output complete 3D information (3D shape, 6D pose, and sizes of multiple ob-jects) on a per-pixel manner - we present “Category and Joint
Agnostic Reconstruction of ARTiculated Objects” (CARTO).
First, extending [24], we train a robust category- and joint-agnostic 3D decoder [3, 24, 28] by learning disentangled latent shape and joint codes. The shape code encodes the canonical shape of the object while the joint code captures the articulation state of the object consisting of the type of articulation (e.g., prismatic or revolute) and the amount of articulation (i.e. joint state). To disentangle both codes we impose structure among our learned joint codes by propos-ing a physically grounded regularization term. Second, in combination with our stereo RGB image encoder we can do inference in a single-shot manner to detect the objects’ spatial centers, 6D poses and sizes as well as shape and joint codes. The latter two can then be used as input to our category- and joint-agnostic decoder to directly reconstruct all detected objects.
To evaluate CARTO, we first evaluate the reconstruction and articulation state prediction quality of our category- and joint-agnostic decoder and compare against decoders trained on a single category. In an ablation study we show the neces-sity of our proposed joint code regularization over naively training the joint codes. We then quantitatively compare our full pipeline to a two-stage approach on synthetic data and show qualitative results on a new real-world dataset.
Our main contributions can be summarized as follows:
• An approach for learning a shape and joint decoder jointly in a category- and joint-agnostic manner.
• A single shot method, which in addition to predicting 3D shapes and 6D pose, also predicts the articulation amount and type (prismatic or revolute) for each object.
• Large-scale synthetic and annotated real-world evalua-tion data for a set of articulated objects across 7 cate-gories.
• Training and evaluation code for our method. 2.