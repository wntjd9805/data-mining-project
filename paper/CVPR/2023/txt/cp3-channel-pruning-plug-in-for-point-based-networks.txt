Abstract
Channel pruning can effectively reduce both compu-tational cost and memory footprint of the original net-work while keeping a comparable accuracy performance.
Though great success has been achieved in channel pruning for 2D image-based convolutional networks (CNNs), exist-ing works seldom extend the channel pruning methods to 3D point-based neural networks (PNNs). Directly imple-menting the 2D CNN channel pruning methods to PNNs undermine the performance of PNNs because of the dif-ferent representations of 2D images and 3D point clouds as well as the network architecture disparity.
In this pa-per, we proposed CP3, which is a Channel Pruning Plug-in for Point-based network. CP3 is elaborately designed to leverage the characteristics of point clouds and PNNs in order to enable 2D channel pruning methods for PNNs.
Specifically, it presents a coordinate-enhanced channel im-portance metric to reflect the correlation between dimen-sional information and individual channel features, and it recycles the discarded points in PNN’s sampling process and reconsiders their potentially-exclusive information to enhance the robustness of channel pruning. Experiments on various PNN architectures show that CP3 constantly improves state-of-the-art 2D CNN pruning approaches on different point cloud tasks. For instance, our compressed
PointNeXt-S on ScanObjectNN achieves an accuracy of 88.52% with a pruning rate of 57.8%, outperforming the baseline pruning methods with an accuracy gain of 1.94%.
* Equal contributions. (cid:66) Corresponding authors.
This work is done during Yaomin Huang and Xinmei Liu’s internship at Midea Group. 1.

Introduction
Convolutional Neural Networks (CNNs) often encounter the problems of overloaded computation and overweighted storage. The cumbersome instantiation of a CNN model leads to inefficient, uneconomic, or even impossible de-ployment in practice. Therefore, light-weight models that provide comparable results with much fewer computational costs are in great demand for nearly all applications. Chan-nel pruning is a promising solution to delivering efficient networks.
In recent years, 2D CNN channel pruning, e.g., pruning classical VGGNets [37], ResNets [14], Mo-bileNets [16], and many other neural networks for process-ing 2D images [6, 7, 12, 24, 26, 29, 40], has been success-fully conducted. Most channel pruning approaches focus on identifying redundant convolution filters (i.e., channels) by evaluating their importance. The cornerstone of 2D chan-nel pruning methods is the diversified yet effective channel evaluation metrics. For instance, HRank [24] uses the rank of the feature map as the pruning metric and removes the low-rank filters that are considered to contain less informa-tion. CHIP [40] leverages channel independence to repre-sent the importance of each feature mapping and eliminates less important channels.
With the widespread application of depth-sensing tech-nology, 3D vision tasks [9, 10, 36, 44] are a rapidly growing field starving for powerful methods. Apart from straight-forwardly applying 2D CNNs, models built with Point-based Neural Networks (PNNs), which directly process point clouds from the beginning without unnecessary ren-dering, show their merits and are widely deployed on edge devices for various applications such as robots [22, 49] and self-driving [2, 53]. Compressing PNNs is crucial due to the limited resources of edge devices and multiple models for different tasks are likely to run simultaneously [8, 30].
Given the huge success of 2D channel pruning and the great
demand for efficient 3D PNNs, we intuitively raise one question: shall we directly implement the existing pruning methods to PNNs following the proposed channel impor-tance metrics in 2D CNNs pruning?
With this question in mind, we investigate the fundamen-tal factors that potentially impair 2D pruning effectiveness on PNNs. Previous works [19, 48] have shown that point clouds record visual and semantic information in a signifi-cantly different way from 2D images. Specifically, a point cloud consists of a set of unordered points on objects’ and environments’ surfaces, and each point encodes its features, such as intensity along with the spatial coordinates (x, y, z).
In contrast, 2D images organize visual features in a dense and regular pixel array. Such data representation differences between 3D point clouds and 2D images lead to a) different ways of exploiting information from data and b) contrasting network architectures of PNNs and 2D CNNs. It is credible that only the pruning methods considering the two aspects (definitely not existing 2D CNN pruners) may obtain supe-rior performance on PNNs.
From the perspective of data representations, 3D point clouds provide more 3D feature representations than 2D im-ages, but the representations are more sensitive to network channels. To be more specific, for 2D images, all three
RGB channels represent basic information in an isotropic and homogeneous way so that the latent representations ex-tracted by CNNs applied to the images. On the other hand, point clouds explicitly encode the spatial information in three coordinate channels, which are indispensable for ex-tracting visual and semantic information from other chan-nels. Moreover, PNNs employ the coordinate information in multiple layers as concatenated inputs for deeper feature extraction. Nevertheless, existing CNN pruning methods are designed only suitable for the plain arrangements of 2D data but fail to consider how the informative 3D information should be extracted from point clouds.
Moreover, the network architectures of PNNs are de-signed substantially different from 2D CNNs. While using smaller kernels [37] is shown to benefit 2D CNNs [37], it does not apply to networks for 3D point clouds. On the contrary, PNNs leverage neighborhoods at multiple scales to obtain both robust and detailed features. The reason is that small neighborhoods (analogous to small kernels in 2D CNNs) in point clouds consist of few points for PNNs to capture robust features. Due to the necessary sampling steps, the knowledge insufficiency issue becomes more se-In addition, PNNs use the vere for deeper PNN layers. random input dropout procedure during training to adap-tively weight patterns detected at different scales and com-bine multi-scale features. This procedure randomly discards a large proportion of points and loses much exclusive infor-mation of the original data. Thus, the architecture disparity between 2D CNNs and PNNs affects the performance of directly applying existing pruning methods to PNNs.
In this paper, by explicitly dealing with the two charac-teristics of 3D task, namely the data representation and the
PNN architecture design, we propose a Channel Pruning
Plug-in for Point-based network named CP3, which can be applied to most 2D channel pruning methods for compress-ing PNN models. The proposed CP3 refines the channel importance, the key factor of pruning methods, from two aspects. Firstly, considering the point coordinates (x, y, and z) encode the spatial information and deeply affects fea-ture extraction procedures in PNN layers, we determine the channel importance by evaluating the correlation between the feature map and its corresponding point coordinates by introducing a coordinate-enhancement module. Secondly, calculating channel importance in channel pruning is data-driven and sensitive to the input, and the intrinsic sampling steps in PNN naturally makes pruning methods unstable. To settle this problem, we make full use of the discarded points in the sampling process via a knowledge recycling mod-ule to supplement the evaluation of channel importance.
This reduces the data sampling bias impact on the chan-nel importance calculation and increases the robustness of the pruning results. Notably, both the coordinates and re-cycled points in CP3 do not participate in network training (with back-propagation) but only assist channel importance calculation in the reasoning phase. Thus, CP3 does not in-crease any computational cost of the pruned network. The contributions of this paper are as follows:
• We systematically consider the characteristics of PNNs and propose a channel pruning plug-in named CP3 to enhance 2D CNN channel pruning approaches on 3D
PNNs. To the best of our knowledge, CP3 is the first method to export existing 2D pruning methods to PNNs.
• We propose a coordinate-enhanced channel importance score to guide point clouds network pruning, by evaluat-ing the correlation between feature maps and correspond-ing point coordinates.
• We design a knowledge recycling pruning scheme that increases the robustness of the pruning procedure, using the discarded points to improve the channel importance evaluation.
• We show that using CP3 is consistently superior to di-rectly transplanting 2D pruning methods to PNNs by ex-tensive experiments on three 3D tasks and five datasets with different PNN models and pruning baselines. 2.