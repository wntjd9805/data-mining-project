Abstract
Transfer learning is fundamental for addressing prob-lems in settings with little training data. While several transfer learning approaches have been proposed in 3D, unfortunately, these solutions typically operate on an en-tire 3D object or even scene-level and thus, as we show, fail to generalize to new classes, such as deformable or-ganic shapes. In addition, there is currently a lack of un-derstanding of what makes pre-trained features transfer-able across significantly different 3D shape categories. In this paper, we make a step toward addressing these chal-lenges. First, we analyze the link between feature local-ity and transferability in tasks involving deformable 3D ob-jects, while also comparing different backbones and losses for local feature pre-training. We observe that with proper training, learned features can be useful in such tasks, but, crucially, only with an appropriate choice of the recep-tive field size. We then propose a differentiable method for optimizing the receptive field within 3D transfer learn-ing. Jointly, this leads to the first learnable features that can successfully generalize to unseen classes of 3D shapes such as humans and animals. Our extensive experiments show that this approach leads to state-of-the-art results on several downstream tasks such as segmentation, shape cor-respondence, and classification. Our code is available at https://github.com/pvnieo/vader. 1.

Introduction
Extracting informative representations from 3D geome-try is a central task in Computer Vision, Computer Graph-ics, and related fields. Classical approaches have relied on hand-crafted features derived from basic geometric princi-ples [8, 10, 53, 82, 94]. More recently, the focus has shifted towards data-driven approaches that learn features directly from 3D data [16, 19, 45] in a task-specific manner.
In addition to methods that learn features from scratch for each application, several recent works have also advo-cated for general-purpose representation learning on geo-metric data [49, 97, 103]. Inspired by the success of transfer learning in other domains [109], these methods aim to learn
Figure 1. We present VADER, a novel feature pre-training tech-nique aiming for deformable shapes. By pre-training local feature extractors on 3D scenes for rigid alignment, our approach enables transfer learning to downstream deformable shape analysis tasks, such as shape matching and semantic segmentation. informative representations of 3D data, which can then be exploited in data-limited downstream tasks.
Despite this progress, state-of-the-art architectures in de-formable shape analysis still either rely on classical hand-crafted features as input signals to their learning pipelines
[67, 78, 83, 93], or are trained from scratch for each task
[29, 41, 64], thus requiring significant amounts of labeled data. Unfortunately, as we demonstrate in our work, exist-ing 3D representation learning approaches fail to provide a useful signal in tasks that involve highly deformable shapes, such as shape correspondence or segmentation.
This result is perhaps expected since existing approaches have primarily focused on transfer learning across man-made 3D objects or scenes [102], and are typically restricted to settings with significant domain overlap between training and test data. Furthermore, there is currently a lack of un-derstanding of what makes pre-trained features transferable, especially across significantly different shape classes.
In this work, we aim to investigate the transferabil-ity of geometric features to develop representation learn-ing approaches that are useful in downstream deformable shape analysis tasks, such as non-rigid shape matching and semantic segmentation (see Fig. 1). Taking inspira-tion from recent studies that emphasize the importance of low and mid-level features in enabling 2D transfer learn-ing [75, 108], we explore the impact of feature locality on downstream task accuracy across significantly different 3D shape categories. Our study shows that, with a carefully chosen architecture, successful general-purpose represen-Figure 2. Method overview. We propose generalizable local feature pre-training for deformable shape analysis. We first pre-train a local feature extractor Fs,Θ, which has a learnable receptive field size s and network parameters Θ, on a pretext task of matching local features for 3D alignment. We then propose a differentiable method for optimizing the receptive field size s to transfer Fs,Θ to downstream tasks.
For illustration purposes, we use a molecular surface segmentation task as an example on the right. tation learning for deformable 3D shape analysis is possi-ble. We also find that the receptive field (or local support) size plays a crucial role in the transferability of features and needs to be adapted between training and test data. To ad-dress this, we propose a receptive field optimization strat-egy, which, combined with a specific pre-training approach, leads to state-of-the-art results on a wide range of down-stream tasks. An overview of our proposed method can be found in Fig. 2.
To summarize, our main contributions are as follows: 1. We investigate the link between the locality of geomet-ric (3D) features and their transferability in challeng-ing deformable shape tasks. 2. We build upon the investigation and propose a novel method for optimizing the receptive field size of local features in the context of transfer learning in 3D tasks.
We demonstrate that this optimization brings signifi-cant improvement and allows pre-trainable features to generalize well to unseen data in downstream tasks. 3. We show that pre-training local features with an unsu-pervised cycle consistency loss outperforms the stan-dard contrastive PointInfoNCE loss. 4. Based on all of these insights, we propose a new lo-cal feature pre-training mechanism and show its utility in a wide range of tasks involving deformable objects, going beyond man-made objects or scenes considered in previous 3D transfer learning approaches. 2.