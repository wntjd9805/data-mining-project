Abstract
In theory, vector quantization (VQ) is always better than scalar quantization (SQ) in terms of rate-distortion (R-D) performance [33]. Recent state-of-the-art methods for neural image compression are mainly based on nonlinear transform coding (NTC) with uniform scalar quantization, overlooking the benefits of VQ due to its exponentially in-creased complexity.
In this paper, we first investigate on some toy sources, demonstrating that even if modern neu-ral networks considerably enhance the compression per-formance of SQ with nonlinear transform, there is still an insurmountable chasm between SQ and VQ. Therefore, re-volving around VQ, we propose a novel framework for neu-ral image compression named Nonlinear Vector Transform
Coding (NVTC). NVTC solves the critical complexity is-sue of VQ through (1) a multi-stage quantization strategy and (2) nonlinear vector transforms. In addition, we apply entropy-constrained VQ in latent space to adaptively deter-mine the quantization boundaries for joint rate-distortion optimization, which improves the performance both theo-retically and experimentally. Compared to previous NTC approaches, NVTC demonstrates superior rate-distortion performance, faster decoding speed, and smaller model size. Our code is available at https://github.com/
USTC-IMCL/NVTC. 1.

Introduction
Recent works based on nonlinear transform coding (NTC) [5] have achieved remarkable success in neural im-age compression [12, 34]. Unlike these traditional image codecs that employ linear transform such as discrete co-sine transform (DCT), NTC is constructed with the nonlin-ear transform layers and optimized with data-driven tech-niques, where the modern neural networks present excellent capability in both encoding/decoding transform and entropy estimation [12, 20, 35]. Most NTC methods apply scalar quantization (SQ) to discretize the latent variables and use the additive uniform noise to approximate the quantization error during training [6]. However, in the era of 1990s, it
Figure 1. BD-rate vs. decoding time vs. model size on the
CLIC2021 validation set [1]. has already been known that vector quantization, in spite of it exponentially increased complexity, is always better than
SQ in terms of rate-distortion (RD) performance [33]. It in-spires us to design a novel neural image compression model to fully leverages vector quantization.
Vector quantization (VQ) [18] is designed to map a con-tinuous source distribution to a set of discrete vectors. The discrete nature of VQ has been successfully applied in gen-erative models to avoid the “posterior collapse” issue, in-cluding these well-known image synthesis models such as
VQVAE [40], VQGAN [16] and text-to-image synthesis models such as DALLE [36], latent diffusion [38]. How-ever, if we go back to the basic requirement of quantiza-tion, we will find that VQ offers unique advantages in terms of rate-distortion performance, particularly the space-filling advantage and the memory advantage [33].
Given a source distribution, the goal of quantization (no matter SQ or VQ) is to determine the quantization centers and boundaries, and then assign indices to denote these sep-arated quantization regions/cells. Combining these regions fills the whole space of source distribution. The space-filling advantage of VQ against SQ is related to the sphere
Figure 2. Quantization results for NTC (SQ with nonlinear transform) and ECVQ (entropy-constrained VQ) on 2-d distributions. Blue lines represent quantization boundaries and orange points represent quantization centers (codewords). “Isotropic Gaussian” refers to a 2-d isotropic Gaussian distribution. “Banana” and “Boomerang” are two different 2-d distributions. It is observed that NTC cannot achieve the space-filling advantage (i.e. learning hexagon-like quantization cells for 2-d sources) even on an isotropic gaussian distribution. Moreover,
NTC’s decorrelation capability is insufficient as source correlation becomes more complex. For example, quantization boundaries collide in the red circle of ”Boomerang”, leading to a performance drop. The corresponding BD-PSNR results are shown in Table 2. packing problem in geometry [14, 21, 41]. If we compare the quantization results of SQ and VQ, as shown in Fig-ure 2, we will find that even for a simple isotropic Gaus-sian distribution, SQ with nonlinear transform cannot learn to approximate hexagon-like quantization cells, where the hexagon is the polytope with the best space-filling proper-ties in 2-d space. Under the high-rate assumption, the gain of space-filling advantage is about 1.53 dB as the dimen-sion approaches infinity [15, 33]. Following this conclu-sion, we experimentally provide the BD-PSNR results by comparing SQ with nonlinear transform to VQ on isotropic
Gaussian distributions in Table 1.
In addition, to reduce the redundancies of data distributions, existing NTC meth-ods (SQ with nonlinear transform) rely on highly expen-sive nonlinear transform [12,44,45] and context-based auto-regressive entropy models [20,35]. However, different from
NTC methods, VQ has superior decorrelation ability, which is known as the memory advantage of vector quantizers.
This advantage is more obvious when quantizing complex source distributions, such as the Boomerang distribution in
Figure 2 (especially in the red circle area).
In this paper, we build a novel framework that applies modern neural networks to leverage the space-filling ad-vantages and memory advantages of VQ for image com-pression. We propose nonlinear vector transform coding (NVTC), which achieves encouraging rate-distortion per-formance with relatively low coding complexity. Specifi-cally, as shown in Figure 3, we introduce three key points to design a practical VQ, including 1) a multi-stage prod-uct VQ rather than a single-stage VQ to reduce the expo-nentially increased complexity, 2) nonlinear vector trans-form rather than scalar transform to remove redundancy be-tween sub-vectors with fewer parameters, and 3) entropy-constrained VQ rather than unconstrained VQ to achieve su-perior R-D optimality and joint optimization of latent-space
VQ models.
For the first point, many well-known VQ variants have been proposed in recent decades, such as product VQ [22, 39], multi-stage VQ [23], tree-structured VQ [11] and lat-tice VQ [17]. Although tree-structured and lattice VQ offer fast encoding speeds, they do not reduce the storage com-plexity of codebooks or entropy-coding frequency tables In
Figure 3. Three key points to design a practical vector quantizer. For VQ complexity (left), we suggest a hybrid VQ structure called
KR multi-stage product VQ which reduces the VQ complexity from O(2KR) to O(M L2
M L ). For transform complexity (middle), we use vector transform instead of scalar transform to remove inter-vector redundancy. For RD optimality (right), we find that ECVQ [13] is essential for the joint rate-distortion optimization, which is neglected in previous works [2, 31, 40, 43]
. this paper, we suggest a hybrid VQ structure that incorpo-rates both product VQ and multi-stage VQ, as shown in the left column of Figure 3. The quantization procedure com-prises multiple stages, and each stage employs multiple in-dependent low-dimension quantizers to compress the sub-vectors of the input vector. As the number of stages and subvectors increases, the proposed multi-stage product VQ exhibits a significant decrease in complexity.
While the intra-vector redundancy (i.e. the redundancy inside each subvector) can be removed by vector quantiza-tion, the inter-vector redundancy (i.e. the redundancy be-tween subvectors) is still overlooked. Therefore, our sec-ond point focuses on efficiently eliminating inter-vector re-dundancy. Transform VQ [25] introduces a linear trans-form for decorrelation and performs product quantization on the transformed coefficients. Similar coding structures are observed in recent learning-based VQ methods [2, 43], which are improved by learnable nonlinear transform with superior decorrelation capabilities. However, the transform used in these works is designed to decorrelate scalar compo-nents, which is computationally inefficient for vector decor-relation. The intra-vector redundancy, which is intended to be removed by VQ, might be partially reduced in ad-vance by the scalar transform. Therefore, certain parts of the scalar transform could be eliminated to improve com-intra-transform and inter-transform. putational efficiency. Motivated by the linear vector trans-form [28, 30, 31], we propose a new VT variant that de-couples a fully-connected scalar transform into two light-weight parts:
In the middle of Figure 3, we provide a simple comparison be-tween the scalar transform and the proposed vector trans-form. We further stack the single-layer VT to build a pow-erful nonlinear vector transform. The differences between our VT and the linear VT are discussed in Section 4.1.
Regarding the third point, we emphasize that the quan-tization process (either SQ or VQ) used in most previ-ous methods [2, 5, 31, 40, 43] (including VQVAE) is not entropy-constrained, which is theoretically suboptimal for
In the right of Figure 3, we rate-distortion performance. provide a quantization illustration of unconstrained VQ and entropy-constrained VQ (ECVQ [13]), where uncon-strained VQ determines the quantization boundaries (blue line) using the nearest neighbor search. ECVQ introduces an additional rate bias − log pi in the quantization process, which shifts the quantization boundaries from the high-probability region to the low-probability region.
In other words, ECVQ search the codewords with the best RD performance, instead of just the neighboring codewords.
ECVQ provides an optimal VQ encoding process described in Section 2. With the help of latent-space ECVQ, we de-λ
sign a training strategy for joint RD optimization. Instead of manually controlling the RD trade-off by varying codebook size [43], our model can learn layer-adaptive bit allocation.
Our contributions can be summarized as 1) investigating on VQ advantages over SQ with nonlinear transform based on empirical results on some toy sources, 2) presenting a
VQ-based coding scheme named nonlinear vector trans-form coding (NVTC) with three technical contributions that effectively leverages VQ while keeping complexity low, and 3) demonstrating that NVTC offers superior rate-distortion performance, faster decoding speed and smaller model size, compared with previous neural image codecs. 2.