Abstract (cid:54)(cid:91)(cid:82)(cid:82) (cid:54)(cid:91)(cid:89)(cid:78)
Recent developments of the application of Contrastive
Learning in Semi-Supervised Learning (SSL) have demon-strated signiﬁcant advancements, as a result of its ex-ceptional ability to learn class-aware cluster representa-tions and the full exploitation of massive unlabeled data.
However, mismatched instance pairs caused by inaccurate pseudo labels would assign an unlabeled instance to the incorrect class in feature space, hence exacerbating SSL’s renowned conﬁrmation bias. To address this issue, we intro-duced a novel SSL approach, HyperMatch, which is a plug-in to several SSL designs enabling noise-tolerant utilization of unlabeled data. In particular, conﬁdence predictions are combined with semantic similarities to generate a more ob-jective class distribution, followed by a Gaussian Mixture
Model to divide pseudo labels into a ’conﬁdent’ and a ’less conﬁdent’ subset. Then, we introduce Relaxed Contrastive
Loss by assigning the ’less-conﬁdent’ samples to a hyper-class, i.e. the union of top-K nearest classes, which effec-tively regularizes the interference of incorrect pseudo la-bels and even increases the probability of pulling a ’less conﬁdent’ sample close to its true class. Experiments and in-depth studies demonstrate that HyperMatch delivers re-markable state-of-the-art performance, outperforming Fix-Match on CIFAR100 with 400 and 2500 labeled samples by 11.86% and 4.88%, respectively. 1.

Introduction
Semi-supervised learning (SSL) [2, 3, 5, 20, 21, 26, 29, 38, 39, 42] has become a promising solution for leverag-ing unlabeled data to save the expensive annotation cost and simultaneously improve model performance, especially in applications where large amounts of annotated data are required to obtain a model with high performance [4, 18].
Modern SSL algorithms generally fall into two categories: the Pseudo Label-based [22, 30, 38] focuses on generating
∗Equal contribution. †Corresponding author.
?
? (cid:71)(cid:15) (cid:54)(cid:89)(cid:75)(cid:91)(cid:74)(cid:85)(cid:19)(cid:50)(cid:71)(cid:72)(cid:75)(cid:82)(cid:19)(cid:72)(cid:71)(cid:89)(cid:75)(cid:74)(cid:3) (cid:41)(cid:82)(cid:71)(cid:89)(cid:89)(cid:3)(cid:39)(cid:89)(cid:89)(cid:79)(cid:77)(cid:84)(cid:83)(cid:75)(cid:84)(cid:90) (cid:72)(cid:15)(cid:3)(cid:46)(cid:95)(cid:86)(cid:75)(cid:88)(cid:19)(cid:41)(cid:82)(cid:71)(cid:89)(cid:89)(cid:3)(cid:39)(cid:89)(cid:89)(cid:79)(cid:77)(cid:84)(cid:83)(cid:75)(cid:84)(cid:90) (cid:73)(cid:15) (cid:58)(cid:85)(cid:86)(cid:19)(cid:49)(cid:3)(cid:39)(cid:73)(cid:73)(cid:91)(cid:88)(cid:71)(cid:73)(cid:95)(cid:3)(cid:85)(cid:76)(cid:3) (cid:54)(cid:89)(cid:75)(cid:91)(cid:74)(cid:85)(cid:3)(cid:50)(cid:71)(cid:72)(cid:75)(cid:82)(cid:89)
Figure 1. Illustration of our ideas. (a) Pseudo-label-based assign-ment: the instance is pulled close to the wrong pseudo label class and pushed away from ground-truth class (green pentagon). (b)
Hyper-class assignment: the instance is assigned to its hyper-class (the union of top-K nearest classes), which includes the ground truth class. (c) Top-K accuracy for clean and noisy pseudo labels (divided by our Gaussian Mixture Model) in CIFAR100@400 ex-periment. As K grows, noisy labels beneﬁt more than clean labels. reliable pseudo labels for unlabeled data, whereas the Con-sistency Regularization-based [2, 3, 20, 29] constrains the model to make consistent predictions on perturbed samples.
Recently, a prominent advance is the combination of
Contrastive Learning [6, 8, 11, 13] with SSL techniques
[19, 21, 24, 25, 39, 42], which sets the remarkable state-of-the-art performance. The naive Self-supervised Contrastive
Learning [6, 13] in pre-training tasks pushes instance-level features away, thereby potentially driving samples within the same class apart, its class-agnostic nature has been proved to conﬂict with the class-clustering property of
SSL [24, 39], hence most recent studies [21, 24, 39] turn to
Class-Aware Contrastive Learning [16]. The general rou-tine is to ﬁrst assign each unlabeled instance to the top-1 nearest class based on their pseudo labels, then two unla-beled instances from the same class are randomly selected to form a positive pair, followed by a class-aware con-trastive loss to compel instances from positive pairs to share similar features while pushing away the representations of different classes.
The precision of pseudo labels has a direct impact on the class assignment of the aforementioned methods. By con-ﬁdence threshold, unlabeled data can be roughly grouped into ’conﬁdent’ and ’less conﬁdent’ [39]. For ’conﬁdent’
data that tends to yield accurate pseudo labels for class as-signment, contrastive loss could constrain the model to ac-quire better clustered feature representations for each class, hence facilitating SSL learning. But for ’less conﬁdent’ data with a much higher probability to provide incorrect pseudo labels, mismatched instance pairs tends to be induced and the contrastive constraint will pull the features of differ-ent classes closer while pushing the features from the same class further apart, which will inevitably degrade the learn-ing. As shown in Fig. 1 (a), the ’less conﬁdent’ instance the red circle) could be drawn close to a false class (i.e. while being pushed away from the true class, represented by green pentagons. For convenience, we also refer to the two kinds of unlabeled data as ’clean’ and ’noisy’ data.
To mitigate the detrimental effects of ’less conﬁdent’ (i.e., noisy) data, existing studies can be generally cat-egorized into two categories: (1) Discarding low-quality pseudo labels [21, 24] with a low threshold, leaving some unlabeled data unused; (2) Adopting re-weighting strate-gies [39, 42] to lessen the effect of noisy labels. How-ever, these approaches continue to closely adhere to the the paradigm of assigning noisy data to a single error-prone class, therefore they can only reduce the errors to a limited amount. Also, the accuracy of pseudo labels suffers from conﬁrmation bias [1] in SSL, which is the accumulation of false predictions during training.
The aforesaid interference of ’less conﬁdent’ data is caused by the inaccurate class assignment, it is more ef-fective to devise a class assignment approach that can resist the distraction of wrong pseudo labels in order to mitigate their effects. In light of this, we propose to relax the conven-tional class assignment. Instead of assigning a noisy sam-ple to a single class, we relax the assignment by grouping it into a ’hyper-class’, which is the union of top-K (K > 1) nearest classes. As depicted in Fig. 1 (b), the chance of the ground-truth class slipping into the hyper-class is dra-matically enhanced by implementing the relaxation (as K steadily grows). It’s also worth noting that the marginal gain brought by relaxation for noisy data is signiﬁcantly greater than that for clean data, as the top-1 pseudo label accuracy of clean data is already adequate. This suggests that the relaxation is more suitable for applying on noisy data.
In conjunction with the hyper-class assignment, a Re-laxed Contrastive Loss is intended to restrain the feature of noisy samples being close to their corresponding hyper-class while increasing the distantce from the remaining classes. The simple yet effective relaxing has two bene-ﬁts: (1) the likelihood of ’less conﬁdent’ data being pushed away from its ground truth class can be lowered, and (2) the likelihood of data being pulled close to its ground truth class can be successfully raised. As seen in Fig. 1 (b), the ground truth class for the noisy unlabeled instance falls within the hyper-class, thus its feature will no longer be driven away from the actual class, but rather drawn close to it.
In order to manage the effective exploitation of bother clean and noisy unlabeled data, we proposed HyperMatch.
First, predicted class probabilities are integrated with se-mantic similarities to produce unbiased per-sample class distributions. Next, a Gaussian Mixture Model (GMM) model is ﬁtted on the calibrated distribution to separate clean unlabeled data from the noisy ones. The common class-aware contrastive loss is applied to clean data to con-strain their features to approach the corresponding class.
For noisy unlabeled data, a Relaxed Contrastive Loss is carefully developed to drive the noisy unlabeled data falling into their corresponding hyper-class. In summary, we con-tribute in three ways:
• We propose an enhanced contrastive learning method,
HyperMatch, to handle the effective separation and ex-ploitation of both clean and noisy pseudo labels for learning better-clustered feature representations. It is a plug-in that can be used to various SSL architectures to increase resilience while utilizing noisy data.
• Unlike previous studies that assign a ’less conﬁdent’ sample to an error-prone class, we relax the assignment by categorizing the noisy sample into a hyper-class (a union of top-K nearest classes), followed by the pro-posed Relaxed Contrastive Loss, which is effective at mitigating the problematic conﬁrmation bias.
• With thorough experiments on SSL benchmarks, our
HyperMatch demonstrates competitive performance and establishes the new state-of-the-art on multiple benchmarks. In-depth investigation reveals its effec-tiveness in handling the noisy pseudo labels. 2.