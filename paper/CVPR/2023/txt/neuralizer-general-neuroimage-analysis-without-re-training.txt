Abstract
Neuroimage processing tasks like segmentation, recon-struction, and registration are central to the study of neu-roscience. Robust deep learning strategies and architec-tures used to solve these tasks are often similar. Yet, when presented with a new task or a dataset with different vi-sual characteristics, practitioners most often need to train a new model, or ﬁne-tune an existing one. This is a time-consuming process that poses a substantial barrier for the thousands of neuroscientists and clinical researchers who often lack the resources or machine-learning expertise to train deep learning models. In practice, this leads to a lack of adoption of deep learning, and neuroscience tools being dominated by classical frameworks.
We introduce Neuralizer, a single model that general-izes to previously unseen neuroimaging tasks and modali-ties without the need for re-training or ﬁne-tuning. Tasks do not have to be known a priori, and generalization happens in a single forward pass during inference. The model can solve processing tasks across multiple image modalities, ac-quisition methods, and datasets, and generalize to tasks and modalities it has not been trained on. Our experiments on coronal slices show that when few annotated subjects are available, our multi-task network outperforms task-speciﬁc baselines without training on the task. 1.

Introduction
Computational methods for the processing and analysis of neuroimages have enabled a deep understanding of the human brain. The ﬁeld has also led to advanced patient care by facilitating non-invasive methods of diagnosis and treatment. Recent deep learning research promises to sub-stantially increase the accuracy and speed of neuroimaging analysis methods.
A drawback of most current deep-learning-based ap-proaches is that each model is limited to solving the task it has been trained on, on the type of data it has been trained on. Generalization to new tasks and domains, such as different acquisition protocols or new segmentation, is
Figure 1. Neuralizer can solve a broad range of image processing tasks, including new ones not seen during training, with a single model by conditioning the prediction on a context set of examples.
After training on a diverse set of tasks, the model can generalize to new tasks in a single forward pass without re-training or ﬁne-tuning. The model is highly ﬂexible, requiring no prior deﬁnition of the set of tasks, and can be conditioned with context sets of any length. a main barrier to adoption [62]. Performing neuroimag-ing tasks like segmentation, registration, reconstruction, or motion correction requires different models for each pro-cessing step, despite operating on the same input data and methods exhibiting strong similarities in network architec-ture [13,45,85]. Yet, designing and training models to solve these tasks on each dataset is prohibitively expensive. To train a deep learning model, a dataset needs to be compiled and often manually annotated, and the network, training, and data loading logic needs to be implemented. All these steps generally require machine learning and neuroimaging expertise. In addition, computational resources like special-ized graphics processing hardware and software infrastruc-ture needs to be available. These requirements are particu-larly problematic in clinical research settings due to a high cost of annotation and a lack of machine learning expertise and hardware.
Figure 2. Example neuroimaging tasks and modalities included in our dataset (top: input images, bottom: output images).
Contribution
We introduce Neuralizer, a general-purpose neuroimag-ing model that can solve a broad range of neuroimaging tasks on diverse image modalities (Fig. 2), without the need for task-speciﬁc training or ﬁne-tuning. Neuralizer can solve new tasks, unseen during training, using a set of ex-amples of the new task at inference (Fig. 1)
Neuralizer involves a convolutional architecture (Fig. 3), that takes as input a context set of examples that deﬁne the processing task, and thus does not require prior speciﬁca-tion of the tasks. The method enables single-pass gener-alization during inference and can process any number of reference images in a single pass to inform the prediction.
As a ﬁrst method tackling task generalization in neu-roimaging, we focus on analyzing the capabilities of such system and presenting general insights, and limit our ex-periments to 2D. We evaluate our model by comparing the single-pass generalization performance to task-speciﬁc baselines conditioned on an equivalent amount of data.
We ﬁnd that Neuralizer outperforms the baselines on tasks where ≤ 32 labeled examples are available, despite never training on the task. When generalizing to new segmenta-tion protocols, Neuralizer matches the performance of base-lines trained directly on the dataset. 2.