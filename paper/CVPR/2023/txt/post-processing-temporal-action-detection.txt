Abstract
Existing Temporal Action Detection (TAD) methods typ-ically take a pre-processing step in converting an input varying-length video into a fixed-length snippet represen-tation sequence, before temporal boundary estimation and action classification. This pre-processing step would tem-porally downsample the video, reducing the inference res-olution and hampering the detection performance in the original temporal resolution.
In essence, this is due to a temporal quantization error introduced during resolution downsampling and recovery. This could negatively impact the TAD performance, but is largely ignored by existing methods. To address this problem, in this work we intro-duce a novel model-agnostic post-processing method with-out model redesign and retraining. Specifically, we model the start and end points of action instances with a Gaus-sian distribution for enabling temporal boundary inference at a sub-snippet level. We further introduce an efficient
Taylor-expansion based approximation, dubbed as Gaus-sian Approximated Post-processing (GAP). Extensive ex-periments demonstrate that our GAP can consistently im-prove a wide variety of pre-trained off-the-shelf TAD mod-els on the challenging ActivityNet (+0.2%∼0.7% in aver-age mAP) and THUMOS (+0.2%∼0.5% in average mAP) benchmarks. Such performance gains are already signif-icant and highly comparable to those achieved by novel model designs. Also, GAP can be integrated with model training for further performance gain.
Importantly, GAP enables lower temporal resolutions for more efficient in-ference, facilitating low-resource application. The code is available at https://github.com/sauradip/GAP 1.

Introduction
The objective of Temporal action detection (TAD) is to identify both the temporal interval (i.e., start and end points) and the class label of all action instances in an untrimmed video [3, 7]. Given a test video, existing TAD methods 1
Figure 1. A typical pipeline for temporal action detection. (a) For efficiency and model design ease, temporal resolution reduction is often applied during pre-processing. This causes model infer-ence at lower (coarse) temporal resolutions. (b) After bringing the prediction results back to the original temporal resolution during inference, quantization error will be introduced inevitably. typically generate a set of action instance candidates via proposal generation based on regressing predefined anchor boxes [4, 6, 13, 23] or directly predicting the start and end times of proposals [2,9,10,15,25–27] and global segmenta-tion masking [14]. To facilitate deep model design and im-prove computational efficiency, most TAD methods would pre-process a varying-length video into a fixed-length snip-pet sequence by first extracting frame-level visual features
benefited from our proposed GAP method without algorith-mic modification and model retraining, achieving the best single model accuracy on THUMOS and ActivityNet. De-spite this simplicity, the performance improvement obtained from GAP can match those achieved by designing novel models [5]. At the cost of model retraining, our GAP can be integrated with existing TAD models for achieving fur-ther gain. Further, our GAP favorably enables lower tem-poral resolutions for higher inference efficiency with little performance degradation. Crucially, GAP can be applied generally in a variety of learning settings (e.g., supervised, semi-supervised, zero-shot, few-shot). 2.