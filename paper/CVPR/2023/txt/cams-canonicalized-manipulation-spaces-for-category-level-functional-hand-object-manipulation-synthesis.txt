Abstract 1.

Introduction
In this work, we focus on a novel task of category-level functional hand-object manipulation synthesis cover-ing both rigid and articulated object categories. Given an object geometry, an initial human hand pose as well as a sparse control sequence of object poses, our goal is to gen-erate a physically reasonable hand-object manipulation se-quence that performs like human beings. To address such a challenge, we first design CAnonicalized Manipulation
Spaces (CAMS), a two-level space hierarchy that canon-icalizes the hand poses in an object-centric and contact-centric view. Benefiting from the representation capability of CAMS, we then present a two-stage framework for syn-thesizing human-like manipulation animations. Our frame-work achieves state-of-the-art performance for both rigid and articulated categories with impressive visual effects.
Codes and video results can be found at our project home-page: https://cams-hoi.github.io/.
*Equal contribution with the order determined by rolling dice.
†Corresponding author.
Human conducts hand-object manipulation (HOM) for certain functional purposes commonly in daily life, e.g. opening a laptop and using scissors to cut. Understand-ing how such manipulation happens and being able to synthesize realistic hand-object manipulation has naturally become a key problem in computer vision. A genera-tive model that can synthesize human-like functional hand-object manipulation plays an essential role in various ap-plications, including video games, virtual reality, dexterous robotic manipulation, and human-robot interaction.
This problem has only been studied with a very limited scope previously. Most existing works focus on the synthe-sis of a static grasp either with [3] or without [17] a func-tional goal. Recently, there have been works started focus-ing on dynamic manipulation synthesis [7, 41]. However, these works restrict their scope to rigid objects and do not consider the fact that functional manipulation might change the object geometry as well, such as in opening a laptop by hand. Moreover, these works usually require a strong input, including hand and object trajectories or a grasp reference,
limiting their application scenarios.
To expand the scope of HOM synthesis, we propose a new task of category-level functional hand-object manip-ulation synthesis. Given a 3D shape from a known cate-gory as well as a sequence of functional goals, our task is to synthesize human-like and physically realistic hand-object manipulation to sequentially realize the goals as shown in
Figure 1. Besides rigid objects, we also consider articulated objects, which support richer manipulations than a simple move. We represent a functional goal as a 6D pose for each rigid part of the object. We emphasize category-level for generalization to unseen geometry and for more human-like manipulations revealing the underlying semantics.
In this work, we choose to tackle the above task with a learning approach. We can learn from human demon-strations for HOM synthesis thanks to the recent ef-fort in capturing category-level human-object manipulation dataset [25]. The key challenges lie in three aspects. First, a synthesizer needs to generalize to a diverse set of geometry with complex kinematic structures. Second, humans can interact with an object in diverse ways. Faithfully captur-ing such distribution and synthesizing in a similar manner is difficult. Third, physically realistic synthesis requires un-derstanding the complex dynamics between the hand and the object. Such understanding makes sure that the syn-thesized hand motion indeed drives the object state change without violating basic physical rules.
To address the above challenges, we choose to gener-ate object motion through motion planning and learn a neu-ral synthesizer to generate dynamic hand motion accord-ingly. Our key idea is to canonicalize the hand pose in an object-centric and contact-centric view so that the neural synthesizer only needs to capture a compact distribution.
This idea comes from the following key observations. Dur-ing functional hand-object manipulation, human hands usu-ally possess a strong preference for the contact regions, and such preference is highly correlated to the object geometry, e.g. hand grasping the display edge while opening a laptop.
From the contact point’s perspective, the finger pose also lies in a low-dimensional space. Representing hand poses from an object-centric view as a set of contact points and from a contact-centric view as a set of local finger embed-dings could greatly reduce the learning complexity.
Specifically, given an input object plus several functional goals, we first interpolate per-part object poses between ev-ery adjacent functional goal, resulting in an object motion trajectory. Then we take a two-stage method to synthesize the corresponding hand motion. In the first stage, we intro-duce CAnonicalized Manipulation Spaces (CAMS) to plan the hand motion. CAMS is defined as a two-level space hierarchy. At the root level, all corresponding parts from the category of interest are scale-normalized and consis-tently oriented so that the distribution of possible contact points becomes concentrated. At the leaf level, each contact point would define a local frame. This local frame would simplify the distribution of the corresponding finger pose.
With CAMS, we could represent a hand pose as an object-centric and contact-centric CAMS embedding. At the core of our method is a conditional variation auto-encoder, which learns to predict a CAMS embedding sequence given an ob-ject motion trajectory. In the second stage, we introduce a contact- and penetration-aware motion synthesizer to fur-ther synthesize an object motion-compatible hand motion given the CAMS embedding sequence.
To summarize, our main contributions include: i) A new task of functional category-level hand-object manipulation synthesis. ii) CAMS, a hierarchy of spaces canonicalizing category-level HOM enabling manipulation synthesis for unseen objects. iii) A two-stage motion synthesis method to synthesize human-like and physically realistic HOM. iv)
State-of-the-art HOM synthesis results for both articulated and rigid object categories. 2.