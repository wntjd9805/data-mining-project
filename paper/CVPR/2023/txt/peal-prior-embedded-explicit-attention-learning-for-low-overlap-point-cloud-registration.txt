Abstract
Recently,
Learning distinctive point-wise features is critical for low-overlap point cloud registration. it has achieved huge success in incorporating Transformer into point cloud feature representation, which usually adopts a self-attention module to learn intra-point-cloud features first, then utilizes a cross-attention module to perform fea-ture exchange between input point clouds. The advan-tage of Transformer models mainly benefits from the use of self-attention to capture the global correlations in fea-ture space. However, these global correlations may in-volve ambiguity for point cloud registration task, espe-cially in indoor low-overlap scenarios, because the corre-lations with an extensive range of non-overlapping points may degrade the feature distinctiveness. To address this is-sue, we present PEAL, a Prior-embedded Explicit Attention
Learning model. By incorporating prior knowledge into the learning process, the points are divided into two parts.
One includes points lying in the putative overlapping region and the other includes points located in the putative non-overlapping region. Then PEAL explicitly learns one-way attention with the putative overlapping points. This simplis-tic design attains surprising performance, significantly re-lieving the aforementioned feature ambiguity. Our method improves the Registration Recall by 6+% on the challenging 3DLoMatch benchmark and achieves state-of-the-art per-formance on Feature Matching Recall, Inlier Ratio, and
Registration Recall on both 3DMatch and 3DLoMatch. 1.

Introduction
Rigid point cloud registration has always been a foun-dational yet challenging task in 3D vision and robotics
[2, 3, 10, 25], which aims to estimate an optimal rigid trans-formation to align two point clouds.
Benefiting from the superior feature representation of deep networks, keypoints-based point cloud registration methods have become dominant in recent years [4, 9, 12,
∗Corresponding author: Wenhui Zhou, zhouwenhui@hdu.edu.cn; Yu
Zhang, zhangyu606@gmail.com
Figure 1. Given two low-overlap point clouds, PEAL adopts an explicit attention learning fashion and learns discriminative su-perpoint (patch) features (c), which results in significant higher patch and point inlier ratios. In contrast, GeoTransformer learns ambiguous patch features (a). For example, PEAL is able to ac-curately identify corresponding chairs among multiple chairs and distinguish them from the floor and table, while GeoTransformer mismatches them. Zoom in for details. 34, 37]. The core idea is to learn to match the learned key-points across different point clouds. Recently, the keypoint-free methods [25, 36] demonstrate promising performance following the coarse-to-fine fashion. They seek correspon-dences between downsampled point clouds (superpoints), which are then propagated to individual points to yield dense correspondences. Thus, the accuracy of superpoint matching is crucial to the overall performance of point cloud registration. GeoTransformer [25] proposes a geo-metric self-attention module that encodes the distance of point pairs and the angle of triplet to extract transformation-invariant features. This approach significantly improves the accuracy of superpoint matching.
However, GeoTransformer may still suffer from am-biguous matching in certain scenarios with numerous sim-ilar structure or low geometric discriminative patches (su-perpoints) [25]. Moreover, the self-attention mechanism may exacerbate matching ambiguity, especially for low-overlap registration tasks. Prior works [3, 25] advocate that modeling geometric consistent correlations among overlap-ping superpoints/points is the key to the success of super-points/points matching, while the global correlations learn-ing via the geometric self-attention is inevitably interfered by numerous superpoints in the non-overlapping region. In other words, the correlations with non-overlapping super-points may disrupt the inter-frame geometric consistency learning and degrade the feature distinctiveness for registra-tion, which makes the resultant learned superpoint features ambiguous and leads to numerous outlier matches (Fig. 1 (a)).
To address the aforementioned issues, we design a Prior-embedded Explicit Attention Learning model (PEAL). It first leverages an overlap prior to divide the superpoints into anchor ones (the superpoints lying in putative overlapping region) and non-anchor ones (the superpoints located in pu-tative non-overlapping region). Then it alleviates the inter-ference of non-anchor superpoints by introducing an one-way attention mechanism, which solely models the correla-tions from non-anchor superpoints to anchor ones. Benefit-ting from the promising overlap ratio in the anchor region, anchor superpoints can be reckoned as simultaneously ex-isting in both two frames, thus the one-way attention is ca-pable of acquiring the essential local geometric consistent correlation from the anchor region, which helps the non-anchor superpoints encoding the inter-frame local geomet-ric consistency and relieves the global feature ambiguity (Fig. 1 (c) ). Furthermore, the embedding prior design in-volved in PEAL makes refining transformation possible in an iterative fashion.
In this paper, we introduce two models depending on the methods of obtaining prior, with extensive experiments on indoor benchmarks demonstrating the superiority of PEAL.
Compared to state-of-the-art methods, both of the two mod-els achieve significant improvements on Registration Recall on the challenging 3DLoMatch benchmark. In summary, our contributions are summarized as follows:
• To the best of our knowledge, we are the first to explic-itly inject overlap prior into Transformer to facilitate low-overlap point cloud registration, and various over-lap priors can be integrated into this framework, such as 3D overlap prior, 2D overlap prior, and self-overlap-prior.
• An explicit one-way attention module, which can sig-nificantly relieves the feature ambiguity generated by self-attention. It can be plugged into other transformer-based point cloud registration networks.
• A novel iterative pose refined fashion for low-overlap point cloud registration. 2.