Abstract
Vision Transformers (ViTs) have demonstrated the state-of-the-art performance in various vision-related tasks. The success of ViTs motivates adversaries to perform back-door attacks on ViTs. Although the vulnerability of tradi-tional CNNs to backdoor attacks is well-known, backdoor attacks on ViTs are seldom-studied. Compared to CNNs capturing pixel-wise local features by convolutions, ViTs extract global context information through patches and at-tentions. Na¨ıvely transplanting CNN-specific backdoor at-tacks to ViTs yields only a low clean data accuracy and a low attack success rate. In this paper, we propose a stealth and practical ViT-specific backdoor attack TrojViT. Rather than an area-wise trigger used by CNN-specific backdoor attacks, TrojViT generates a patch-wise trigger designed to build a Trojan composed of some vulnerable bits on the pa-rameters of a ViT stored in DRAM memory through patch salience ranking and attention-target loss. TrojViT further uses parameter distillation to reduce the bit number of the
Trojan. Once the attacker inserts the Trojan into the ViT model by flipping the vulnerable bits, the ViT model still produces normal inference accuracy with benign inputs.
But when the attacker embeds a trigger into an input, the
ViT model is forced to classify the input to a predefined tar-get class. We show that flipping only few vulnerable bits identified by TrojViT on a ViT model using the well-known
RowHammer can transform the model into a backdoored one. We perform extensive experiments of multiple datasets on various ViT models. TrojViT can classify 99.64% of test images to a target class by flipping 345 bits on a ViT for
ImageNet. 1.

Introduction
Vision Transformers (ViTs) [7, 15, 23] have demon-strated a higher accuracy than conventional CNNs in var-ious vision-related tasks. The unprecedented effectiveness of recent ViTs motivates adversaries to perform malicious attacks, among which backdoor (aka, Trojan) [4, 8] is one
Figure 1. The overview of our proposed TrojViT attack. The top part shows the normal inference of a clean model. The bottom part shows that after flipping a few critical bits of the clean model (marked in red), the generated trojaned model misclassify the input with a trigger to the target output. of the most dangerous attacks. In a backdoor attack, a back-door is injected into a neural network model, so that the model behaves normally for benign inputs, yet induces a predefined behavior for any inputs with a trigger. Although it is well-known that CNNs are vulnerable to backdoor at-tacks [1, 8, 14, 19, 24, 27–29, 31, 32], backdoor attacks on
ViTs are not well-studied. Recently, several backdoor at-tacks including DBIA [17], BAVT [22], and DBAVT [6] are proposed to abuse ViTs using an area-wise trigger designed for CNN backdoor attacks, but they suffer from either a sig-nificant accuracy degradation for benign inputs, or an ultra-low attack success rate for inputs with a trigger. Differ-ent from a CNN capturing pixel-wise local information, a
ViT spatially divides an image into small patches, and ex-tracts patch-wise information by attention. Moreover, most prior ViT backdoor attacks require a slow training phase to achieve a reasonably high attack success rate. BAVT [22] and DBAVT [6] even assume training data is available for attackers, which is not typically the real-world case.
In this paper, we aim to breach the security of ViTs by creating a novel, stealthy, and practical ViT-specific back-door attack TrojViT. The overview of TrojViT is shown in
Figure 1. A clean ViT model having no backdoor can ac-curately classify an input image to its corresponding class (e.g., a dog) by splitting the image into multiple patches.
However, a backdoored ViT model classifies an input into a predefined target class (e.g., a shark) with high confidence when a specially designed trigger is embedded in the input.
If the trigger is removed from the input, the backdoored ViT model will still act normally with almost the same accuracy as its clean counterpart. The ViT model can be backdoored and inserted with a Trojan using the well-known RowHam-mer method [18]. Unlike prior ViT-specific backdoor at-tacks [6, 17, 22] directly using an area-wise trigger, we pro-pose a patch-wise trigger for TrojViT to effectively high-light the patch-wise information that the attacker wants the backdoored ViT model to pay more attention to. Moreover, during the generation of a patch-wise trigger, we present an
Attention-Target loss for TrojViT to consider both attention scores and the predefined target class. At last, we create a tuned parameter distillation technique to reduce the modi-fied bit number of the ViT parameters during the the Tro-jan insertion, so that our TrojViT backdoor attack is more practical. We perform extensive experiments of TrojViT on various ViT architectures with multiple datasets. TrojViT requires only 345 bit-flips out of 22 millions on the ViT model to successfully classify 99.64% test images to a tar-get class on ImageNet. 2.