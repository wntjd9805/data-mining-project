Abstract
Humans have long been recorded in a variety of forms since antiquity. For example, sculptures and paintings were the primary media for depicting human beings before the in-vention of cameras. However, most current human-centric computer vision tasks like human pose estimation and hu-man image generation focus exclusively on natural images in the real world. Artificial humans, such as those in sculp-tures, paintings, and cartoons, are commonly neglected, making existing models fail in these scenarios.
As an abstraction of life, art incorporates humans in both natural and artificial scenes. We take advantage of it and introduce the Human-Art dataset to bridge related tasks in natural and artificial scenarios. Specifically, Human-Art contains 50k high-quality images with over 123k person instances from 5 natural and 15 artificial scenarios, which are annotated with bounding boxes, keypoints, self-contact points, and text information for humans represented in both 2D and 3D. It is, therefore, comprehensive and versatile for various downstream tasks. We also provide a rich set of baseline results and detailed analyses for related tasks, including human detection, 2D and 3D human pose estima-tion, image generation, and motion transfer. As a challeng-ing dataset, we hope Human-Art can provide insights for relevant research and open up new research questions. 1.

Introduction
" Art is inspired by life but beyond it."
Human-centric computer vision (CV) tasks such as hu-man detection [39], pose estimation [30], motion trans-fer [59], and human image generation [35] have been in-tensively studied and achieved remarkable performances in the past decade, thanks to the advancement of deep learning techniques. Most of these works use datasets [14,23,27,39]
*Equal contribution.
†Work in part done during an internship at IDEA.
‡Corresponding author. that focus on humans in natural scenes captured by cameras due to the practical demands and easy accessibility.
However, besides being captured by cameras, humans are frequently present and recorded in various other forms, from ancient murals on walls to portrait paintings on pa-per to computer-generated virtual figures in digital form.
However, existing state-of-the-art (SOTA) human detection and pose estimation models [64, 71] trained on commonly used datasets such as MSCOCO [27] generally work poorly on these scenarios. For instance, the average precision of such models can be as high as 63.2% and 79.8% on natural scenes but drops significantly to 12.6% and 28.7% on the sculpture scene. A fundamental reason is the domain gap between natural and artificial scenes. Also, the scarcity of datasets with artificial human scenes significantly restricts the development of tasks such as anime character image generation [9, 67, 74], character rendering [29], and char-acter motion retargeting [1, 37, 68] in computer graphics and other areas. With the growing interest in virtual reality (VR), augmented reality (AR), and metaverse, this problem is exacerbated and demands immediate attention.
There are a few small datasets incorporating humans in artificial environments in the literature. Sketch2Pose [4] and ClassArch [33] collect images in sketch and vase paint-ing respectively. Consequently, they are only applicable to the corresponding context. People-Art [61] is a human de-tection dataset that consists of 1490 paintings. It covers arti-ficial scenes in various painting styles, but its categories are neither mutually exclusive nor collectively comprehensive.
More importantly, the annotation type and image number in People-Art are limited, and hence this dataset is mainly used for testing (instead of training) object detectors.
Art presents humans in both natural and artificial scenes in various forms, e.g., dance, paintings, and sculptures. In this paper, we take advantage of the classification of vi-sual arts to introduce Human-Art, a versatile human-centric dataset, to bridge the gap between natural and artificial scenes. Human-Art is hierarchically structured and includes high-quality human scenes in rich scenarios with precise
Figure 1. Human-Art is a versatile human-centric dataset to bridge the gap between natural and artificial scenes. It includes 20 high-quality scenes, including natural and artificial humans in both 2D representation (yellow dashed boxes) and 3D representation (blue solid boxes). manual annotations. Specifically, it is composed of 50k images with about 123k person instances in 20 artistic cate-gories, including 5 natural and 15 artificial scenarios in both 2D and 3D, as shown in Fig. 1. To support both recog-nition and generation tasks, Human-Art provides precise manual annotations containing human bounding boxes, 2D keypoints, self-contact points, and text descriptions. It can compensate for the lack of scenarios in prior datasets (e.g.,
MSCOCO [27]), link virtual and real worlds, and introduce new challenges and opportunities for human-centric areas.
Human-Art has the following unique characteristics:
• Rich scenario: Human-Art focuses on scenes missing in mainstream datasets (e.g., [27]), which covers most human-related scenarios. Challenging human appear-ances, diverse contexts, and various poses largely com-plement the scenario deficiency of existing datasets and will open up new challenges and opportunities.
• High quality: We guarantee inter-category variabil-ity and intra-category diversity in style, author, origin, and age. The 50k images are manually selected from 1, 000k carefully collected images using standardized data collection, filtering, and consolidating processes.
• Versatile annotations: Human-Art provides carefully manual annotations of 2D human keypoints, human bounding boxes, and self-contact points to support var-ious downstream tasks. Also, we provide accessible text descriptions to enable multi-modality learning.
With Human-Art, we conduct comprehensive experi-ments and analysis on various downstream tasks including human detection, human pose estimation, human mesh re-covery, image generation, and motion transfer. Although training on Human-Art can lead to a separate 31% and 21% performance boost on human detection and human pose es-timation, results demonstrate that human-related CV tasks still have a long way to go before reaching maturity. 2.