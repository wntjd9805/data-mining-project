Abstract
Eyeglasses play an important role in the perception of identity. Authentic virtual representations of faces can ben-eﬁt greatly from their inclusion. However, modeling the geometric and appearance interactions of glasses and the face of virtual representations of humans is challenging.
Glasses and faces affect each other’s geometry at their con-tact points, and also induce appearance changes due to light transport. Most existing approaches do not capture these physical interactions since they model eyeglasses and faces independently. Others attempt to resolve interactions as a 2D image synthesis problem and suffer from view and temporal inconsistencies. In this work, we propose a 3D compositional morphable model of eyeglasses that accu-rately incorporates high-ﬁdelity geometric and photometric interaction effects. To support the large variation in eye-glass topology efﬁciently, we employ a hybrid representa-tion that combines surface geometry and a volumetric rep-resentation. Unlike volumetric approaches, our model natu-rally retains correspondences across glasses, and hence ex-plicit modiﬁcation of geometry, such as lens insertion and frame deformation, is greatly simpliﬁed. In addition, our model is relightable under point lights and natural illumi-nation, supporting high-ﬁdelity rendering of various frame materials, including translucent plastic and metal within a
* Work done while Junxuan Li was an intern at Reality Labs Research. single morphable model. Importantly, our approach mod-els global light transport effects, such as casting shadows between faces and glasses. Our morphable model for eye-glasses can also be ﬁt to novel glasses via inverse rendering.
We compare our approach to state-of-the-art methods and demonstrate signiﬁcant quality improvements. 1.

Introduction
Humans are social animals. How we dress and acces-sorize is a key mode of self-expression and communication in daily life [11]. As social media and gaming has expanded social life into the online medium, virtual presentations of users have become increasingly focal to social presence, and with it, the demand for the digitization of clothes and accessories. In this paper, we focus on modeling eyeglasses, an everyday accessory for billions of people worldwide.
In particular, we argue that to achieve realism it is not sufﬁcient to model eyeglasses in isolation: their interactions with the face have to be considered. Geometrically, glasses and faces are not rigid, and they mutually deform one an-other at the contact points. Thus, the shapes of eyeglasses and faces cannot be determined independently. Similarly, their appearance is coupled via global light transport, and shadows as well as inter-reﬂections may appear and affect the radiance. A computational approach to model these in-teractions is therefore necessary to achieve photorealism.
Photorealistic rendering of humans has been a focus of computer graphics for over 50 years, and yet the realism of avatars created by classical authoring tools still requires extensive manual reﬁnement to cross the uncanny valley.
Modern realtime graphics engines [10] support the compo-sition of individual components (e.g., hair, clothing), but the interaction between the face and other objects is by necessity approximated with overly simpliﬁed physically-inspired constraints or heuristics (e.g., “no interpenetra-tions”). Thus, they do not faithfully reconstruct all geomet-ric and photometric interactions present in the real world.
Another group of approaches aims to synthesize the composition of glasses in the image domain [28, 66, 69] by leveraging powerful 2D generative models [25]. While these approaches can produce photorealistic images, anima-tion results typically suffer from view and temporal incon-sistencies due to the lack of 3D information.
Recently, neural rendering approaches [56] achieve pho-torealistic rendering of human heads [14, 17, 35, 36, 48] and general objects [40, 44, 60, 70] in a 3D consistent manner.
These approaches are further extended to generative mod-eling for faces [6] and glasses [39, 64], such that a sin-gle morphable model can span the shape and appearance variation of each object category. However, in these ap-proaches [6, 39, 64] interactions between objects are not leading to implausible object compositions. considered,
While a recent work shows that unsupervised learning of a 3D compositional generative model from an image collec-tion is possible [43], we observe that the lack of structural prior about faces or glasses leads to suboptimal ﬁdelity. In addition, the aforementioned approaches are not relightable, thus not allowing us to render glasses on faces in a novel il-lumination.
In contrast to existing approaches, we aim at model-ing the geometric and photometric interactions between eyeglasses frames and faces in a data-driven manner from image observations. To this end, we present MEGANE (Morphable Eyeglass and Avatar Network), a morphable and relightable eyeglass model that represents the shape and appearance of eyeglasses frames and its interaction with faces. To support variations in topology and rendering efﬁ-ciency, we employ a hybrid representation combining sur-face geometry and a volumetric representation [37]. As our hybrid representation offers explicit correspondences across glasses, we can trivially deform its structure based on head shapes. Most importantly, our model is conditioned by a high-ﬁdelity generative human head model [6], allow-ing it to specialize deformation and appearance changes to the wearer. Similarly, we propose glasses-conditioned de-formation and appearance networks for the morphable face model to incorporate the interaction effects caused by wear-ing glasses. We also propose an analytical lens model that produces photorealistic reﬂections and refractions for any prescription and simpliﬁes the capture task, enabling lens insertion in a post-hoc manner.
To jointly render glasses and faces in novel illumina-tions, we incorporate physics-inspired neural relighting into our proposed generative modeling. The method infers out-put radiance given view, point-light positions, visibility, and specular reﬂection with multiple lobe sizes. The proposed approach signiﬁcantly improves generalization and sup-ports subsurface scattering and reﬂections of various mate-rials including translucent plastic and metal within a single model. Parametric BRDF representations can not handle such diverse materials, which exhibit signiﬁcant transmis-sive effects, and inferring their parameters for photorealistic relighting remains challenging [41, 74, 77].
To evaluate our approach, we captured 25 subjects us-ing a multi-view light-stage capture system similar to Bi et al. [3]. Each subject was captured three times; once with-out glasses, and another two times wearing a random se-lection out of a set of 43 glasses. All glasses were cap-tured without lenses. As a preprocess, we separately recon-struct glasses geometry using a differentiable neural SDF from multi-view images [60]. Our study shows that care-fully designed regularization terms based on this precom-puted glasses geometry signiﬁcantly improves the ﬁdelity of the proposed model. We also compare our approach with state-of-the-art generative eyeglasses models, demonstrat-ing the efﬁcacy of our representation as well as the pro-posed joint modeling of interactions. We further show that our morphable model can be ﬁt to novel glasses via inverse rendering and relight them in new illumination conditions.
In summary, the contributions of this work are:
• the ﬁrst work that tackles the joint modeling of ge-ometric and photometric interactions of glasses and faces from dynamic multi-view image collections.
• a compositional generative model of eyeglasses that represents topology varying shape and complex ap-pearance of eyeglasses using a hybrid mesh-volumetric representation.
• a physics-inspired neural relighting approach that sup-ports global light transport effects of diverse materials in a single model. 2.