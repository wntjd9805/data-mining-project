Abstract
We present HandAvatar, a novel representation for hand animation and rendering, which can generate smoothly compositional geometry and self-occlusion-aware texture.
Specifically, we first develop a MANO-HD model as a high-resolution mesh topology to fit personalized hand shapes.
Sequentially, we decompose hand geometry into per-bone rigid parts, and then re-compose paired geometry encod-ings to derive an across-part consistent occupancy field.
As for texture modeling, we propose a self-occlusion-aware shading field (SelF). In SelF, drivable anchors are paved on the MANO-HD surface to record albedo information under a wide variety of hand poses. Moreover, directed soft occupancy is designed to describe the ray-to-surface relation, which is leveraged to generate an illumination field for the disentanglement of pose-independent albedo and pose-dependent illumination. Trained from monocu-lar video data, our HandAvatar can perform free-pose hand animation and rendering while at the same time achiev-ing superior appearance fidelity. We also demonstrate that
HandAvatar provides a route for hand appearance editing.
Project website: https://seanchenxy.github. io/HandAvatarWeb. 1.

Introduction
Human avatars [5,16,19,20,27,74] have been vigorously studied for years. However, there has been limited research that particularly focuses on hand avatars [9]. Due to the nature of distinctive properties (e.g., serious self-occlusion and contact) between the hand and the rest of the human parts (i.e., face, head, and body), it is essential to investigate a specialized representation tailored for modeling both the hand geometry and texture.
Traditional pipeline tends to adopt texture maps and col-ored mesh for hand appearance modeling [7, 11, 12, 24, 43], but developing an elaborate personalized hand mesh and texture map usually requires expensive scan data [54] and artistic knowledge. Recently, the neural rendering tech-nique has gained raising attention, where neural radiance field (NeRF) [32] has been adapted to represent humans by predicting geometry and texture properties for an arbitrary
3D point query [9, 10, 20, 25, 37, 39, 40, 48, 51, 58, 62–64, 69, 72, 75] . Compared to the conventional mesh-texture pipeline, NeRF is cheap in training data collection and su-perior in rendering fidelity. Despite the huge success of hu-man body and face modeling, neural rendering-based hand representation [9] remains much less explored. The hand is highly articulated such that the complex hand motion brings difficulties for neural rendering. Firstly, the deformation of hand geometry is hard to model. When coping with large and complex hand deformations (e.g., self-contact), previ-ous skinning-based methods can hardly find accurate skin-ning weights for an arbitrary query [3, 6, 18, 19, 31, 35, 39, 47, 62, 74], while part-aware methods usually suffer from across-part inconsistency issue [17, 21, 30, 60]. Secondly, hand texture is hard to model because of the highly ar-ticulated structure. For example, articulated hand motion induces serious self-occlusion so that different hand poses lead to noticeable variations in illumination and shadow pat-terns. Illumination is important for realistic rendering, but we are not aware of any prior work in estimating illumina-tion caused by articulated self-occlusion.
Motivated by the above challenges, we propose Han-dAvatar for animatable realistic hand rendering. Consid-ering different difficulties in geometry and texture model-ing, we follow the idea of inverse graphics [76] to disen-tangle hand geometry, albedo, and illumination. At first, we employ explicit mesh to depict hand shapes. However, the popular hand mesh model, i.e., MANO [44], only pro-vides a coarse mesh with 778 vertices, whose shape fitting capacity is limited. Therefore, we design a super-resolution version of MANO with 12,337 vertices and 24,608 faces, namely MANO-HD, which can fit personalized hand shapes with per-vertex displacements. Additionally, massive exist-ing MANO-annotated data can be seamlessly represented by MANO-HD. For introducing mesh-based hand shape to the volume rendering pipeline [32], we propose a local-pair occupancy field (PairOF), where every two part-level geometry encodings are reassembled according to physi-cal connections to yield an across-part consistent field. As for hand texture, we propose a self-occlusion-aware shad-ing field (SelF). SelF is comprised of an albedo field and an illumination field. The albedo field resorts to anchors that are uniformly paved on MANO-HD surfaces, each of which holds positional and albedo encodings to model a small hand region. The illumination field is to cope with articulated self-occlusion, where directed soft occupancy is designed to estimate illumination and shadow patterns.
MANO-HD and PairOF are pre-trained with MANO pa-rameter annotations, then they cooperate with SelF in end-to-end training on monocular video data. Finally, with hand pose as the input, our HandAvatar can perform hand an-imation and rendering. We evaluate our approach on the
InterHand2.6M dataset [34] and achieve high-fidelity ge-ometry and texture for free-pose hand animation. We also demonstrate that it is convenient to edit hand appearance in
HandAvatar as shown in Fig. 1. Therefore, our main contri-butions are summarized as follows:
• We propose a HandAvatar framework, the first method for neural hand rendering with self-occluded illumination.
• We develop MANO-HD and a local-pair occupancy field that fit hand geometry with personalized shape details.
• We propose a self-occlusion-aware shading field that can render hand texture with faithful shadow patterns.
• Our framework is end-to-end developed for free-pose re-alistic hand avatars. Extensive evaluations indicate our method outperforms prior arts by a large margin. 2.