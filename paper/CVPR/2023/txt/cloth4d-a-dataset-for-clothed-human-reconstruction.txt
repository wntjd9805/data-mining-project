Abstract
Clothed human reconstruction is the cornerstone for cre-ating the virtual world. To a great extent, the quality of re-covered avatars decides whether the Metaverse is a passing fad. In this work, we introduce CLOTH4D, a clothed hu-man dataset containing 1,000 subjects with varied appear-ances, 1,000 3D outfits, and over 100,000 clothed meshes with paired unclothed humans, to fill the gap in large-scale and high-quality 4D clothing data.
It enjoys ap-pealing characteristics: 1) Accurate and detailed cloth-ing textured meshes—all clothing items are manually cre-ated and then simulated in professional software, strictly following the general standard in fashion design. 2) Sep-arated textured clothing and under-clothing body meshes, closer to the physical world than single-layer raw scans. 3) Clothed human motion sequences simulated given a set of 289 actions, covering fundamental and complicated dy-namics. Upon CLOTH4D, we novelly designed a series of temporally-aware metrics to evaluate the temporal stability of the generated 3D human meshes, which has been over-looked previously. Moreover, by assessing and retraining current state-of-the-art clothed human reconstruction meth-ods, we reveal insights, present improved performance, and propose potential future research directions, confirming our dataset’s advancement. The dataset is available at 1. 1.

Introduction
As we enter the volumetric and XR content era, re-searchers have been trailblazing their way into the Meta-verse. With the converging of technologies and practical applications, e.g., fashion NFTs (non-fungible tokens), im-mersive AR and VR, and games, clothed human recon-struction demands are rapidly growing. While current re-search has made astonishing results in creating digital hu-1www.github.com/AemikaChow/AiDLab-fAshIon-Data
*X. Zou and X. Han contribute equally. † Corresponding author.
Table 1. Comparisons of CLOTH4D with existing representative datasets. Gray color indicates synthetic datasets generated with graphics engines. #Subjects: number of peoples in different appearances; #Action: number of actions adopted; #Scans: numbers of 3D meshes; 2D Pattern: 2D clothing pattern; TexCloth: with textured clothed model; TexHuman: with textured naked human model. w/ SMPL: with registered SMPL [33] parameters. Public: publicly available and free of charge. Photorealistic: whether the images in the dataset are realistic. -: not applicable or reported. CLOTH4D presents more desirable characteristics compared with others.
Dataset
#Subjects
#Action
#Scan 2D Pattern
TexCloth
TexHuman w/ SMPL
Public
Photorealistic
BUFF [52]
RenderPeople [1]
DeepWrinkles [30]
CAPE [35]
THuman2.0 [51]
DRAPE [16]
Wang et al. [47] 3DPeople [40]
DCA [43]
GarNet [17]
TailorNet [38]
Cloth3D [8]
Cloth3D++ [36]
CLOTH4D 6
-2 15 200 7
-80
-600 9 8.5k 9.7k 1k
--2 600
-23
-72 56
--7.9k 8k 289 13.6k 825 9.2k 140k 525 24.5k 24k
-7.1k 18.8k 5.5k 2.1M 2.2M 100k
------✓
-----✓
✓ mans, these reconstructed meshes have issues, e.g., flex-ible body motions and diverse appearances, owing to the lack of datasets with richness in clothing and realistic dy-namics of garments. To this end, we introduce CLOTH4D, an open-sourced dataset facilitating physically plausible dy-namic clothed human reconstruction.
Prior to us, many datasets have been collected, and we sort out them in Table 1. Currently, scanned datasets are widely adopted as they are photorealistic and can be eas-ily processed to watertight meshes, which does an excel-lent favor for current deep models to learn an implicit func-tion (e.g., signed distance function) followed by marching cubes [34] for surface reconstruction. However, it is born with some weaknesses: 1) Scanned meshes are single-layer and inherently fail to capture the space between clothing and skin surface. Thus, body shape under clothing can-not be accurately inferred, let alone the multi-layer and thin clothing structures as in the real physical world. 2) It is time-consuming and expensive to obtain high-quality and large-scale temporal scanned sequences (i.e., 4D scanned sequences) due to the limited efficiency and precision of 4D scanners, especially for complicated clothing and large mo-tions. Although synthetic datasets can to some extent over-come these limitations, existing synthetic datasets are either of small scale in terms of appearances and motions or are highly unrealistic. Moreover, many datasets are not made publicly available and free.
In contrast, CLOTH4D possesses several attractive at-tributes: 1) We made great efforts to the diversity and quality of clothing. All clothes are manually designed in
CLO [3] and cater to the requirement of the fashion indus-try. 2) Meshes in CLOTH4D are clothing/humans sepa-rated. Such flexibility makes studying and modeling the
✓
✓
✓
-✓
-✓
✓
--✓
✓
✓
✓
------------✓
✓
✓
✓
-✓
✓
-✓
-✓
✓
✓
✓
✓
✓
✓
--✓
✓
-✓
--✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
--✓
-----✓ relations and interactions between clothing simulation and body movement possible. 3) CLOTH4D provides plenty of temporal motion sequences with realistic clothing dynam-ics. As the human body moves, the dressed clothing, e.g., the skirt in Figure 1, naturally deforms. 4) The dataset is large-scale and openly accessible.
To demonstrate the advantages of CLOTH4D, we use it to evaluate the state-of-the-art (SOTA) clothed human re-construction methods. In addition to the generally adopted static evaluation metrics, we propose a set of temporally-aware metrics to assess the temporal coherence in a video inference scenario thanks to the rich and true-to-life 4D syn-thetic sequences in the dataset. Quantitative and qualitative results of SOTA methods on CLOTH4D suggest that our dataset is challenging and the temporal stability of the re-constructed mesh is vital for evaluating the perceptual qual-ity. Meanwhile, we retrain SOTA methods on CLOTH4D, revealing interesting observations of how they perform on multi-layer meshes with thin clothing structures. With in-depth analysis and a summary of challenges for the exist-ing approaches, CLOTH4D makes an essential step toward more realistic reconstructions of clothed humans and stim-ulates several exciting future work directions. All in all:
• We contribute CLOTH4D, a large-scale, high-quality, and open-accessible 4D synthetic dataset for clothed human reconstruction.
• We introduce a series of temporally-aware metrics to evaluate the reconstructed performance in the aspect of tem-poral consistency.
• With the proposed dataset and metrics, we thoroughly analyze the pros and cons of SOTAs, summarize the existing challenges toward more realistic 3D modeling, and propose potential new directions.
Figure 2. Pipeline for creating instances in CLOTH4D, which primarily adopts CLO for clothing design and simulation, Mixamo for animation, and Blender for processing and exporting meshes. 2.