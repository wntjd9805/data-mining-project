Abstract
We present a large-scale facial UV-texture dataset that contains over 50,000 high-quality texture UV-maps with even illuminations, neutral expressions, and cleaned facial regions, which are desired characteristics for rendering re-alistic 3D face models under different lighting conditions.
The dataset is derived from a large-scale face image dataset namely FFHQ, with the help of our fully automatic and ro-bust UV-texture production pipeline. Our pipeline utilizes the recent advances in StyleGAN-based facial image editing approaches to generate multi-view normalized face images from single-image inputs. An elaborated UV-texture extrac-tion, correction, and completion procedure is then applied to produce high-quality UV-maps from the normalized face images. Compared with existing UV-texture datasets, our dataset has more diverse and higher-quality texture maps.
We further train a GAN-based texture decoder as the nonlin-ear texture basis for parametric fitting based 3D face recon-struction. Experiments show that our method improves the
*Work done during an internship at Tencent AI Lab.
†Corresponding author. reconstruction accuracy over state-of-the-art approaches, and more importantly, produces high-quality texture maps that are ready for realistic renderings. The dataset, code, and pre-trained texture decoder are publicly available at https://github.com/csbhr/FFHQ-UV . 1.

Introduction
Reconstructing the 3D shape and texture of a face from single or multiple images is an important and challenging task in both computer vision and graphics communities.
Since the seminal work by Blanz and Vetter [3] showed that the reconstruction can be effectively achieved by parametric fitting with a linear statistical model, namely 3D Morphable
Model (3DMM), it has received active research efforts in the past two decades [14]. While most 3DMM-based recon-struction approaches focused on improving the shape esti-mation accuracy, only a few works addressed the problem on texture UV-map recovery [2, 15, 23, 24, 26, 35, 41].
There are two key aspects that deserve attention in the texture map recovery problem, which are the fidelity and the quality of the acquired texture maps. In order to recover a
high-fidelity texture map that better preserves the face iden-tity of the input image, the texture basis in a 3DMM needs to have larger expressive capacities. On the other hand, a higher-quality texture map requires the face region to be evenly illuminated and without undesired hairs or acces-sories, such that the texture map can be used as facial assets for rendering under different lighting conditions.
The method GANFIT [15] trains a generative adversar-ial network (GAN) [19] from 10,000 UV-maps as a tex-ture decoder to replace the linear texture basis in 3DMM to increase the expressiveness. However, their UV-maps in the training dataset are extracted from unevenly illuminated face images, and the resulting texture maps contain obvious shadows and are not suitable for differently lighted render-ings. The same problem exists in another work [24] based on UV-GAN [11]. The work AvatarMe [23] combines a linear texture basis fitting with a super-resolution network trained from high-quality texture maps of 200 individuals under controlled conditions. HiFi3DFace [2] improves the expressive capacity of linear texture basis by introducing a regional fitting approach and a detail refinement network, which is also trained from 200 texture maps. The Nor-malized Avatar work [26] trains a texture decoder from a larger texture map dataset with over 5,000 subjects, consist-ing of high-quality scan data and synthetic data. Although the quality of the resulting texture maps of these methods is pretty high, the reconstruction fidelity is largely limited by the number of subjects in the training dataset. Besides, all these texture map datasets are not publicly available. A recent high-quality, publicly accessible texture map dataset is in the Facescape dataset [42], obtained in a controlled en-vironment. However, the dataset only has 847 identities.
In this paper, we intend to contribute a large-scale, pub-licly available facial UV-texture dataset consisting of high-quality texture maps extracted from different subjects. To build such a large-scale dataset, we need a fully auto-matic and robust pipeline that can produce high-quality tex-ture UV-maps from large-scale “in-the-wild” face image datasets. For the produced texture map, we expect it to have even illumination, neutral expression, and complete facial texture without occlusions such as hair or accessories. This is not a trivial task, and there exist several challenges: 1)
The uncontrolled conditions of the in-the-wild face images cannot provide high-quality normalized textures; 2) From a single-view face image, the complete facial texture cannot be extracted; 3) Imperfect alignment between the face im-age and the estimated 3D shape would cause unsatisfactory artifacts in the unwrapped texture UV-maps.
To address these issues, we first utilize StyleGAN-based image editing approaches [1, 21, 37] to generate multi-view normalized faces from a single in-the-wild image. Then a
UV-texture extraction, correction, and completion process is developed to fix unsatisfactory artifacts caused by imper-fect 3D shape estimation during texture unwrapping, so that high-quality texture UV-maps can be produced stably. With the proposed pipeline, we construct a large-scale normal-ized facial UV-texture dataset, namely FFHQ-UV, based on the FFHQ dataset [20]. The FFHQ-UV dataset inherits the data diversity of FFHQ, and consists of high-quality texture
UV-maps that can directly serve as facial assets for realistic digital human rendering (see Fig. 1 for a few examples). We further train a GAN-based texture decoder using the pro-posed dataset, and demonstrate that both the fidelity and the quality of the reconstructed 3D faces with our texture de-coder get largely improved.
In summary, our main contributions are:
• The first large-scale, publicly available normalized fa-cial UV-texture dataset, namely FFHQ-UV, which con-tains over 50,000 high-quality, evenly illuminated fa-cial texture UV-maps that can be directly used as facial assets for rendering realistic digital humans.
• A fully automatic and robust pipeline for producing the proposed UV-texture dataset from a large-scale, in-the-wild face image dataset, which consists of StyleGAN-based facial image editing, elaborated UV-texture ex-traction, correction, and completion procedure.
• A 3D face reconstruction algorithm that outperforms state-of-the-art approaches in terms of both fidelity and quality, based on the GAN-based texture decoder trained with the proposed dataset. 2.