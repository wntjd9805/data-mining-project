Abstract
Automatic generation of fonts can be an important aid to typeface design. Many current approaches regard glyphs as pixelated images, which present artifacts when scaling and inevitable quality losses after vectorization. On the other hand, existing vector font synthesis methods either fail to represent the shape concisely or require vector supervision during training. To push the quality of vector font synthesis to the next level, we propose a novel dual-part representa-tion for vector glyphs, where each glyph is modeled as a collection of closed “positive” and “negative” path pairs.
The glyph contour is then obtained by boolean operations on these paths. We first learn such a representation only from glyph images and devise a subsequent contour refine-ment step to align the contour with an image representation to further enhance details. Our method, named DualVector, outperforms state-of-the-art methods in vector font synthe-sis both quantitatively and qualitatively. Our synthesized vector fonts can be easily converted to common digital font formats like TrueType Font for practical use. The code is released at https://github.com/thuliu-yt16/dualvector. 1.

Introduction
Fonts with various styles play an important role in con-tent display and distribution. Excellent font design is time-consuming and labor-intensive. Recent machine learning
∗Corresponding author innovations have made font generation possible, but how to automatically generate high-quality vector fonts remains a task of practical importance in the artistic and computer graphics and vision communities.
Benefiting from the development of image generation techniques, mainstream font synthesis methods [2, 12, 24, 41, 42] could generate pixelated glyph images. Despite the promising quality, images of glyphs incur aliasing artifacts on edges when discretely sampled, and thus are not compe-tent for high-quality rendering or printing at arbitrary res-olutions. To alleviate this problem, some methods [7, 34] adopt coordinate-based neural networks to model a glyph as a contiguous neural field, which have also shown great po-tential in modeling 3D geometry and scenes [7, 30, 32]. Al-though glyphs represented by the implicit field can be ren-dered at arbitrary resolutions, it is hard to preserve details in high-frequency regions such as edges and corners, not to mention the high computational costs as the network needs to be evaluated for every pixel. Researchers have made much effort to directly synthesize vector fonts [4,27,33,39] in recent years, with the main difficulty lying in finding a representation of vector graphics that can be encoded or de-coded effectively in a deep learning framework. One typical approach represents a vector shape as a sequence of drawing commands and adopts sequence modeling techniques such as recurrent networks and transformers. The drawbacks are twofold: (1) Modeling command sequences can be much harder than images. There are infinitely many command se-quences that correspond to the same-looking shape, which brings ambiguities in learning and makes it hard to construct
an effective manifold for valid glyph shapes. (2) Ground-truth drawing commands are often required to provide suf-ficient supervision for high-quality modeling and synthesis.
To overcome these challenges, we first propose a dual-part vector font representation, where each glyph shape is the union of a fixed number of dual parts. Each dual part is formed by the subtraction of a “positive” and a “nega-tive” geometric primitive. While there are many choices for the geometric primitives [6, 8, 25], we adopt closed B´ezier paths for their great representational ability. They are also widely supported in digital font formats which makes it easy to convert our representation to these formats for practi-cal use. We reduce the problem of predicting complicated drawing command sequences to predicting multiple basic primitives. From this perspective, both manifold learning and latent space interpolation become more feasible.
Based on the dual-part representation, we introduce Du-alVector, a method to learn such a representation for high-quality font modeling and synthesis from only glyph images without any vector supervision. A straightforward way to achieve this is to directly optimize the parameters of the
B´ezier curves with differentiable rendering techniques for vector graphics [22]. However, this approach easily gets stuck in the local minima as valuable gradients are only de-fined at shape intersections. Taking inspiration from im-plicit field training for 2D and 3D shapes [6, 25, 32], we supervise the occupancy value derived from the analytical expression of the B´ezier curves and adopt an initialization strategy based on unsigned distance field (UDF) to provide dense gradients across the entire pixel space. For local de-tail fidelity, we also train a glyph image generation model and devise a subsequent contour refinement step to align the contour of the vector shape with that of the image by differentiable rendering [22]. We compare our approach with state-of-the-art methods in font modeling and genera-tion and demonstrate the superior quality of our vector font outputs. Our main contributions are:
• A new dual-part font representation based on boolean operations of B´ezier paths, which enables efficient shape modeling and unsupervised manifold learning.
• A method named DualVector that models both the dual-part and pixelated representation, and introduces a contour refinement step to obtain vector fonts with richer details as well as a UDF initialization strategy for better convergence.
• DualVector achieves state-of-the-art quality in font modeling and generation, with outputs that can be eas-ily converted to common digital font formats. 2.