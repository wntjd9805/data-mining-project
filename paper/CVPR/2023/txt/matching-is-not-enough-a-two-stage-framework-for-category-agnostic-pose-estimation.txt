Abstract
Category-agnostic pose estimation (CAPE) aims to pre-dict keypoints for arbitrary categories given support im-ages with keypoint annotations. Existing approaches match the keypoints across the image for localization. However, such a one-stage matching paradigm shows inferior ac-curacy: the prediction heavily relies on the matching re-sults, which can be noisy due to the open set nature in
CAPE. For example, two mirror-symmetric keypoints (e.g., left and right eyes) in the query image can both trigger high similarity on certain support keypoints (eyes), which leads to duplicated or opposite predictions. To calibrate the inaccurate matching results, we introduce a two-stage framework, where matched keypoints from the first stage are viewed as similarity-aware position proposals. Then, the model learns to fetch relevant features to correct the initial proposals in the second stage. We instantiate the framework with a transformer model tailored for CAPE.
The transformer encoder incorporates specific designs to improve the representation and similarity modeling in the first matching stage. In the second stage, similarity-aware proposals are packed as queries in the decoder for refine-ment via cross-attention. Our method surpasses the previ-ous best approach by large margins on CAPE benchmark
MP-100 on both accuracy and efficiency. Code available at github.com/flyinglynx/CapeFormer 1.

Introduction
Humans can quickly grasp the essentials of a keypoint for arbitrary objects (e.g., the nose of an animal) and then pinpoint the same keypoint on another object in the same category. However, most pose estimation models are still category-specific, which cannot be applied to a new category unless they are trained with sufficient category-*: Equal contribution. †: Corresponding author.
Figure 1. Comparison with existing methods. (a) Compared with previous one-stage matching paradigm that entirely relies on keypoint matching, we propose a novel two-stage framework, which learns to correct unreliable matching results in the second stage. (b) The proposed approach attains better accuracy and effi-ciency compared with the previous best approach. specific data. Recently, category-agnostic pose estimation (CAPE) [40] is proposed to address such a generic pose estimation problem. CAPE aims to localize instance key-points for arbitrary categories given one or few support im-ages with keypoint annotations (support keypoints).
Unlike category-specific pose estimation models that learn to recognize specific keypoints for a fixed category,
CAPE models learn to represent and compare keypoints for open-world categories. As shown in Fig. 1 (a), existing
CAPE approaches [40] match the support keypoints across the query image in an embedding space. Then, the match-ing results are used as clues for keypoint localization. Al-though a sophisticated feature embedding pipeline is elabo-rated [40], we find that such a one-stage pipeline shows in-ferior accuracy and efficiency for CAPE tasks. Specifically, the prediction heavily relies on matching results. However, due to the open set nature in CAPE, the similarity results often contain some noises: 1) insufficient similarity when support and query instances differ significantly in poses, textures, or styles; 2) false positive similarity is triggered when points in the query image share similar appearance with support keypoints. For example, one-stage matching paradigm has difficulties distinguishing the left and right of keypoints due to similar visual characteristics. Thus, the left eye in support keypoints can be indiscriminately predicted to the right eye in the query image.
In this paper, we remedy these issues from two aspects.
First, to refine the matching results, we introduce a two-stage framework for CAPE, where matched keypoints in the first stage are viewed as similarity-aware position proposals.
The model learns to refine the proposals in the second stage.
In addition, to construct a robust matching process, we also improve the representation quality and similarity metrics.
Specifically, we instantiate the two-stage framework with a transformer, termed CAPE transformer (Cape-Former). The transformer encoder encodes the support key-points and query images in the first stage, with specific de-signs to improve the representation quality. We first design a query-support joint refine encoder to mutually transfer in-formation among support keypoints and the query images, thus narrowing the gap between the support and query in-stances (poses or styles). Then, we add a support keypoint identifier to alleviate the ambiguity between two support keypoints when they are geometrically close or with simi-lar appearance. After the feature encoding, similarity-aware position proposals are generated for the second stage. We directly match the support keypoint with query image fea-tures using a learnable inner-product [34]. The similarity peaks are selected as the similarity-aware position propos-als for support keypoints. In the second stage, the position proposals are packed with support keypoint features as the queries in the transformer decoder. In each decoder layer, queries extract relevant features with cross-attention, which are used as clues to update the proposals.
We evaluate our method on a category-agnostic pose es-timation benchmark MP-100 [40]. Our method outperforms the previous best approach POMNet [40] by large margins, with an improvement of 5.6% and 8.6% under 1-shot and 5-shot settings, respectively. When training and test cate-gories almost have no properties in common, a more signif-icant improvement (up to 10.5%) can be obtained compared with POMNet. Note that, our method is trained end-to-end and shows better efficiency compared with previous best ap-proach, as in Fig. 1 (b).
Our contributions can be summarized as follows:
• We propose a two-stage framework for category-agnostic pose estimation tackling the noisy matching results.
• We instantiate the two-stage framework with a trans-former model, termed CapeFormer, with specific de-signs to enhance the representation and similarity modeling in the matching pipeline.
• CapeFormer outperforms the previous best approach significantly in both accuracy and efficiency. 2.