Abstract
Semantic Scene Completion (SSC) transforms an image of single-view depth and/or RGB 2D pixels into 3D vox-els, each of whose semantic labels are predicted. SSC is a well-known ill-posed problem as the prediction model has to “imagine” what is behind the visible surface, which is usually represented by Truncated Signed Distance Func-tion (TSDF). Due to the sensory imperfection of the depth camera, most existing methods based on the noisy TSDF estimated from depth values suffer from 1) incomplete vol-umetric predictions and 2) confused semantic labels. To this end, we use the ground-truth 3D voxels to generate a perfect visible surface, called TSDF-CAD, and then train a “cleaner” SSC model. As the model is noise-free, it is expected to focus more on the “imagination” of un-seen voxels. Then, we propose to distill the intermediate
“cleaner” knowledge into another model with noisy TSDF input. In particular, we use the 3D occupancy feature and the semantic relations of the “cleaner self” to supervise the counterparts of the “noisy self” to respectively address the above two incorrect predictions. Experimental results validate that our method improves the noisy counterparts with 3.1% IoU and 2.2% mIoU for measuring scene com-pletion and SSC, and also achieves new state-of-the-art ac-curacy on the popular NYU dataset. The code is available at https://github.com/fereenwong/CleanerS. 1.

Introduction 3D scene understanding is an important visual task for many practical applications, e.g., robotic navigation [16] and augmented reality [55], where the scene geometry and semantics are two key factors to the agent interaction with the real world [24, 64]. However, visual sensors can only perceive a partial world given their limited field of view with sensory noises [49]. Therefore, an agent is expected to leverage prior knowledge to estimate the complete geome-*Corresponding author. try and semantics from the imperfect perception. Semantic
Scene Completion (SSC) is designed for such an ability to infer complete volumetric occupancy and semantic labels for a scene from a single depth and/or RGB image [49, 52].
Based on an input 2D image, the 2D→3D projection is a vital bond for mapping 2D perception to the correspond-ing 3D spatial positions, which is determined by the depth value [6]. After this, the model recovers the visible surface in 3D space, which sheds light on completing and labeling the occluded regions [31, 52], because the geometry of the visible and occluded areas is tightly intertwined. For exam-ple, you can easily infer the shapes and the semantic labels when you see a part of a “chair” or “bed”. Thus, a high-quality visible surface is crucial for the SSC task.
However, due to the inherent imperfection of the depth camera, the depth information is quite noisy, what follows is an imperfect visible surface that is usually represented by
Truncated Signed Distance Function (TSDF) [52]. In gen-eral, the existing depth noises can be roughly categorized into the following two basic types: 1) Zero Noise. This type of noise happens when a depth sensor cannot confirm the depth value of some local regions, it will fill these regions with zeroes [14,43]. Zero noise gen-erally occurs on object surfaces with reflection or uneven-ness [41]. Based on zero noise, the visible surface will be incomplete after the 2D-3D projection via TSDF [49], so the incomplete volumetric prediction problem may occur in the final 3D voxels. For example, as shown in the upper-half of Figure 1, for the input RGB “kitchen” image, the depth value of some parts of the “cupboard” surface (marked with the red dotted frames) (in (b)) is set to zero due to reflec-tions. Based on this, both the visible surface (in (d)) and the predicted 3D voxels (in (f)) appear incomplete in reflective regions of this “cupboard”. Our method uses the perfect vis-ible surface (in (e)) generated by the noise-free ground-truth depth value (in (c)) as intermediate supervision in training , which helps the model to estimate “cupboard” 3D voxels in inference even with the noisy depth value as input. 2) Delta Noise. This type of noise refers to the inevitable deviation of the obtained depth value due to the inherent
Figure 1. The existing depth noises can be roughly categorized into: 1) zero noise and 2) delta noise. By zero noise, we mean that when the depth camera cannot confirm the depth value of some local regions, it fills these regions with zeroes, leading to the problem of incomplete volumetric predictions. By delta noise, we mean the inevitable deviation (i.e., ∆d) of the obtained depth value due to the inherent quality defects of the depth camera, which leads to the problem of confused semantic labels in the final 3D voxels. In the above blocks, the pairwise subfigures (e.g., (d) and (e)) show the cases of “with noise” and “without noise” on the left and right, respectively. quality defects of the depth camera [41], i.e., the obtained depth value does not match the true depth value. Delta noise shifts the 3D position of the visible surface, resulting in the wrong semantic labels, such that the final 3D voxels will suffer from the problem of confusing semantic labels [52].
A real delta noise case is shown in the bottom half part of
Figure 1. For the input RGB “classroom” image, the depth camera mistakenly estimates the depth value of the “table” as the depth value of “furniture” (in (b)). Therefore, the vis-ible surface represented by TSDF shifts from the class of
“table” (marked with blue points) to the class of “furniture” (marked with orange points in (d)). Based on this, the final estimated 3D voxels (in (f)) also mistakenly estimate the part of the “table” as the “furniture”. In comparison, when our SSC model is trained on the visible surface in (e), which is generated by the correct depth value in (c), as the interme-diate supervision, semantic labels for both the “table” and the “furniture” can be estimated correctly in (g).
In practice, these two types of noise are randomly mixed together to form a more complex noise [14, 65]. To handle these two noise types, although some recent SSC attempts have been made by rendering the noise-free depth value from 3D voxel ground-truth [12, 51], they are not of practi-cal use as the 3D voxels ground-truth is still needed in infer-ence. However, they indeed validate the potential that more accurate recognition performance can be achieved using the noise-free depth value [4, 56, 66]. To the best of our knowl-edge, no prior work focuses on mitigating the noisy depth values in SSC without the use of ground-truth depth val-ues in inference. Therefore, the crux is to transfer the clean knowledge learned from ground-truth depth into the noisy-depth pipeline only during training. So, in inference, we can directly use this pipeline without the need for ground-truth.
In this paper, we propose a Cleaner Self (CleanerS) framework to shield the harmful effects of the two depth noises for SSC. CleanerS consists of two networks that share the same network architecture (that is what “self” means). The only difference between these two networks is that the depth value of the teacher network is rendered from ground-truth, while the depth value of the student network is inherently noisy. Therefore, the depth value of the teacher network is cleaner than the depth value of the student net-work. In the training stage, we make the teacher network to provide intermediate supervision for learning of the stu-dent network via knowledge distillation (KD), such that the student network can disentangle the clean visible surface
reconstruction and occluded region completion. To pre-serve both the detailed information and the abstract seman-tics of the teacher network, we adopt both feature-based and logit-based KD strategies. In inference, only the stu-dent network is used. Compared to the noisy self, as shown in Figure 1, CleanerS achieves more accurate performance with the help of ground-truth depth values in training but not in testing.
The main contributions of this work are summarized as the following two aspects: 1) we propose a novel Clean-erS framework for SSC, which can mitigate the negative effects of the noisy depth value in training; 2) CleanerS achieves the new state-of-the-art results on the challenging
NYU dataset with the input of noisy depth values. 2.