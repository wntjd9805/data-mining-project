Abstract
While original Neural Radiance Fields (NeRF) have shown impressive results in modeling the appearance of a scene with compact MLP architectures, they are not able to achieve real-time rendering. This has been recently ad-dressed by either baking the outputs of NeRF into a data structure or arranging trainable parameters in an explicit feature grid. These strategies, however, significantly in-crease the memory footprint of the model which prevents their deployment on bandwidth-constrained applications.
In this paper, we extend the grid-based approach to achieve real-time view synthesis at more than 150 FPS using a lightweight model. Our main contribution is a novel ar-chitecture in which the density field of NeRF-based repre-sentations is split into N regions and the density is mod-eled using N different decoders which reuse the same fea-ture grid. This results in a smaller grid where each feature is located in more than one spatial position, forcing them to learn a compact representation that is valid for differ-ent parts of the scene. We further reduce the size of the final model by disposing of the features symmetrically on each region, which favors feature pruning after training while also allowing smooth gradient transitions between neighboring voxels. An exhaustive evaluation demonstrates that our method achieves real-time performance and quality metrics on a pair with state-of-the-art with an improvement of more than 2× in the FPS/MB ratio. 1.

Introduction
The use of 3D objects reconstructed from real images is becoming popular in a number of applications, such as virtual-reality or online video-games. The increasing need for realistic elements makes image-based reconstruction an adequate alternative to modeling these objects from scratch using fully manual or semi-automatic design engines. At the same time, however, the larger the number of these as-sets is, the higher the constrain of their size in order to meet
Figure 1. NeRFLight is able to double the FPS/MB ratio of the second best method while obtaining similar quality metrics to state-of-the-art. certain bandwidth and storage requirements.
Methods based on neural rendering have arisen as a promising approach to solve this challenge.
In particu-lar, Neural Radiance Fields (NeRF) [25] have demonstrated outstanding potential.
Instead of modeling the plenop-tic function [1] by means of explicit geometry representa-tions such as point clouds [2] or voxels [22], NeRF uses a coordinate-based multi-layer perceptron (MLP) to model a density and a color field that acts as a proxy of the plenop-tic function. Applying this MLP in combination with posi-tional encoding, NeRF achieves exceptional results in scene representation, improving the quality and compactness of
the previous methods [22, 24] and resulting in an explosion of variants [4,30,55]. However, one of the major limitations of NeRF-based methods is their low rendering speed, being a barrier to being used in applications that require real-time.
This limitation has been addressed in different works, by either “baking” the outputs of NeRF in a data structure
[10,11,54] or using additional features located in an explicit grid [26, 48]. Nevertheless, all these real-time NeRF ren-dering methods sacrifice the compactness of the representa-tion and require relatively large models, resulting in a poor render-time performance vs storage-cost ratio (FPS/MB).
This prevents these models from being deployed in applica-tions that, besides requiring real-time, have memory storage constraints.
In this work, we introduce NeRFLight, a new approach to reduce the size of grid-based NeRF models while achiev-ing real-time view synthesis and retaining the rendering quality of slower and computationally expensive models.
Our key idea consists in splitting the volume of the den-sity field used in NeRF into eight different regions, each with a different decoder, but sharing a common feature grid.
This allows an 8× reduction in the number of total features.
We also propose a novel configuration of the features that exploits the symmetry of neighboring voxel grids and fa-vors a seamless reconstruction throughout all regions. This not only increases the rendering quality but also results in a more compact model. In addition, we also leverage the de-terministic volume integration introduced in [48] to obtain a better representation than using Monte Carlo integration.
We perform an exhaustive evaluation on both synthetic and real data in terms of the FPS/MB ratio1.
The NeRFLight architecture we propose achieves ren-dering speeds of up do 181 FPS with models of only 14MB.
As shown in Fig. 1 this yields an FPS/MB metric that is 2× larger than the closest approach in the state-of-the-art, while achieving a rendering quality (measured using PSNR and
SSIM) on pair with much larger models.
To summarize, our main contributions are the following: 1) We introduce a NeRF architecture based on several den-sity fields and a shared feature grid that provides a light and fast representation; 2) We devise an approach that enforces symmetry of neighboring voxels that favors a seamless re-construction, increases the model accuracy and further re-duces its size; 3) All this results in the Neural Radiance
Field implementation with the highest frame rate vs. stor-age cost ratio of the current state of the art. 2.