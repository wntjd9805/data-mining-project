Abstract
Optical ﬂow has achieved great success under clean scenes, but suffers from restricted performance under foggy scenes. To bridge the clean-to-foggy domain gap, the ex-isting methods typically adopt the domain adaptation to transfer the motion knowledge from clean to synthetic foggy domain. However, these methods unexpectedly neglect the synthetic-to-real domain gap, and thus are erroneous when applied to real-world scenes. To handle the practical optical
ﬂow under real foggy scenes, in this work, we propose a novel unsupervised cumulative domain adaptation optical
ﬂow (UCDA-Flow) framework: depth-association motion adaptation and correlation-alignment motion adaptation.
Speciﬁcally, we discover that depth is a key ingredient to in-ﬂuence the optical ﬂow: the deeper depth, the inferior optical
ﬂow, which motivates us to design a depth-association mo-tion adaptation module to bridge the clean-to-foggy domain gap. Moreover, we ﬁgure out that the cost volume correlation shares similar distribution of the synthetic and real foggy im-ages, which enlightens us to devise a correlation-alignment motion adaptation module to distill motion knowledge of the synthetic foggy domain to the real foggy domain. Note that synthetic fog is designed as the intermediate domain. Under this uniﬁed framework, the proposed cumulative adaptation progressively transfers knowledge from clean scenes to real foggy scenes. Extensive experiments have been performed to verify the superiority of the proposed method. 1.

Introduction
Optical ﬂow has made great progress under clean scenes, but may suffer from restricted performance under foggy scenes [15]. The main reason is that fog weakens scene contrast, breaking the brightness and gradient constancy assumptions, which most optical ﬂow methods rely on.
To alleviate this, researchers start from the perspective
*Corresponding author.
Figure 1. Illustration of the main idea. We propose to transfer motion knowledge from the source domain (clean scene) to the target domain (real foggy scene) through two-stage adaptation.
We design the synthetic foggy scene as the intermediate domain.
As for the clean-to-foggy domain gap (fog), we transfer motion knowledge from the source domain to the intermediate domain via depth association. As for the synthetic-to-real domain gap (style), we distill motion knowledge of the intermediate domain to the target domain by aligning the correlation of both the domains. of domain adaptation, which mainly seeks the degradation-invariant features to transfer the motion knowledge from the clean scene to the adverse weather scene [14–16, 40]. For example, Li [15,16] attempted to learn degradation-invariant features to enhance optical ﬂow under rainy scenes in a su-pervised manner. Yan et al. [40] proposed a semi-supervised framework for optical ﬂow under dense foggy scenes, which relies on the motion-invariant assumption between the paired clean and synthetic foggy images. These pioneer works have made a good attempt to handle the clean-to-foggy domain gap with synthetic degraded images through one-stage do-main adaptation. However, they lack the constraints to guide the network to learn the motion pattern of real foggy domain, and fail for real foggy scenes. In other words, they have un-expectedly neglected the synthetic-to-real domain gap, thus limiting their performances on real-world foggy scenes. In this work, our goal is to progressively handle the two domain gaps: the clean-to-foggy gap and the synthetic-to-real gap in a cumulative domain adaptation framework in Fig. 1.
As for the clean-to-foggy gap, we discover that depth is a key ingredient to inﬂuence the optical ﬂow: the deeper the depth, the inferior the optical ﬂow. This observation inspires us to explore the usage of depth as the key to bridging the clean-to-foggy gap (seeing the fog gap in Fig. 1). On one hand, depth physically associates the clean image with the foggy image through atmospheric scattering model [26]; on the other hand, there exists a natural 2D-3D geometry pro-jection relationship between depth and optical ﬂow, which is used as a constraint to transfer motion knowledge from the clean domain to the synthetic foggy domain.
As for the synthetic-to-real gap, we ﬁgure out that cost volume correlation shares similar distribution of synthetic and real foggy images. Cost volume stores correlation value, which can physically measure the similarity between adja-cent frames, regardless of synthetic and real foggy images.
Therefore, cost volume beneﬁts to bridging the synthetic-to-real domain gap (seeing the style gap in Fig. 1). We align the correlation distributions to distill motion knowledge of the synthetic foggy domain to the real foggy domain.
In this work, we propose a novel unsupervised cumulative domain adaptation optical ﬂow (UCDA-Flow) framework for real foggy scene, including depth-association motion adapta-tion (DAMA) and correlation-alignment motion adaptation (CAMA). Speciﬁcally, in DAMA stage, we ﬁrst estimate optical ﬂow, ego-motion and depth with clean stereo images, and then project depth into optical ﬂow space with 2D-3D geometry formula between ego-motion and scene-motion to enhance rigid motion. To bridge the clean-to-foggy gap, we utilize atmospheric scattering model [26] to synthesize the corresponding foggy images, and then transfer motion knowledge from the clean domain to the synthetic foggy do-main. In CAMA stage, to bridge the synthetic-to-real domain gap, we transform the synthetic and real foggy images to the cost volume space, in which we align the correlation distri-bution to distill the motion knowledge of the synthetic foggy domain to the real foggy domain. The proposed cumulative domain adaptation framework could progressively transfer motion knowledge from clean domain to real foggy domain via depth association and correlation alignment. Overall, our main contributions are summarized as follows:
• We propose an unsupervised cumulative domain adapta-tion framework for optical ﬂow under real foggy scene, consisting of depth-association motion adaptation and correlation-alignment motion adaptation. The proposed method can transfer motion knowledge from clean domain to real foggy domain through two-stage adaptation.
• We reveal that foggy scene optical ﬂow deteriorates with depth. The geometry relationship between depth and opti-cal ﬂow motivates us to design a depth-association motion adaptation to bridge the clean-to-foggy domain gap. prior beneﬁts to close the synthetic-to-real domain gap through correlation-alignment motion adaptation. 2.