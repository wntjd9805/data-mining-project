Abstract
Machine learning society has witnessed the emergence of a myriad of Out-of-Distribution (OoD) algorithms, which address the distribution shift between the training and the testing distribution by searching for a unified predictor or invariant feature representation. However, the task of di-rectly mitigating the distribution shift in the unseen testing set is rarely investigated, due to the unavailability of the testing distribution during the training phase and thus the impossibility of training a distribution translator mapping between the training and testing distribution. In this pa-per, we explore how to bypass the requirement of testing distribution for distribution translator training and make the distribution translation useful for OoD prediction. We propose a portable Distribution Shift Inversion (DSI) algo-rithm, in which, before being fed into the prediction model, the OoD testing samples are first linearly combined with ad-ditional Gaussian noise and then transferred back towards the training distribution using a diffusion model trained only on the source distribution. Theoretical analysis reveals the feasibility of our method. Experimental results, on both multiple-domain generalization datasets and single-domain generalization datasets, show that our method provides a general performance gain when plugged into a wide range of commonly used OoD algorithms. Our code is available at https://github.com/yu-rp/Distribution-Shift-Iverson. 1.

Introduction
The ubiquity of the distribution shift between the training and testing data in the real-world application of machine
†Corresponding author. learning systems induces the study of Out-of-Distribution (OoD) generalization (or domain generalization). [18, 64, 71, 79] Within the scope of OoD generalization, machine learning algorithms are required to generalize from the seen training domain to the unseen testing domain without the independent and identically distributed assumption. The bulk of the OoD algorithms in previous literature focuses on promoting the generalization capability of the machine learning models themselves by utilizing the domain invariant feature [2, 13, 36], context-based data augmentation [47, 74], distributionally robust optimization [59], subnetwork searching [81], neural network calibration [70], etc.
In this work, orthogonal to enhancing the generalization capability of the model, we consider a novel pathway to
OoD prediction. On the way, the testing(target) distribution is explicitly transformed towards the training(source) dis-tribution to straightforwardly mitigate the distribution shift between the testing and the training distribution. Therein, the OoD prediction can be regarded as a two-step procedure, (1) transferring testing samples back towards training dis-tribution, and (2) drawing prediction. The second step can be implemented by any OoD prediction algorithm. In this paper, we concentrate on the exploration of the first step, the distribution transformation.
Unlike previous works on distribution translation and do-main transformation, in which certain target distribution is accessible during the training phase, here the target distri-bution is arbitrary and unavailable during the training. We term this new task as Unseen Distribution Transformation (UDT), in which a domain translator is trained on the source distribution and works to transform unseen target distribu-tion towards the source distribution. The uniqueness, as well as the superiority, of UDT is listed as followings.
the weights controlling the alignment.Then, in the second step, the outcome of the first step is transferred towards the source distribution by a generative model, thereafter we refer to this process as the backward transformation. In this paper, the generative model is chosen to be the diffusion model [21].
The superiority of the diffusion model is that its input is the linear combination of the source sample and the noise with varying magnitude, which is in accord with our design of the forward transformation and naturally allows strength control.
Comparatively, VAE [28] and GAN [16] have a fixed level of noise in their input, which makes the forward transfor-mation strength control indirect. Our theoretical analyses of the diffusion model also show the feasibility of using the diffusion model for UDT.
Illustrative Example. A one-dimensional example is shown in Fig. 2.The example considers a binary classifica-tion problem, in which, given label, the conditional distribu-tions of the samples are Gaussian in both the source and the testing domain. The testing distribution is constructed to be
OoD and located in the region where the source distribution has a low density. The diffusion model is trained only on the source distribution. Passing through the noise space align-ment and diffusion model transformation, the OoD samples are transformed to the source distribution with limited failure of label preservation.
Transformed Images. Fig. 1 shows some transformation results of OoD images towards the source distribution. The observation is twofold. (1) The distribution (here is the style) of the images is successfully transformed. All of the transferred images can be correctly classified by the ERM model trained on the source domain. (2) The transformed images are correlated to the original images. Some structural and color characteristics are mutually shared between them.
This indicates that the diffusion model has extracted some low-level information and is capable to preserve it during the transformation. We would like to highlight again that, during the training, the diffusion model is isolated from the testing domain.
Our contributions are therefore summarized as:
• We put forward the unseen distribution transformation (UDT) and study its application to OoD prediction.
• We offer theoretical analyses of the feasibility of UDT.
• we propose DSI, a sample adaptive distribution trans-formation algorithm for efficient distribution adaptation and semantic information preservation.
• We perform extensive experiments to demonstrate that our method is suitable for various OoD algorithms to achieve performance gain on diversified OoD bench-marks. On average, adding in our method produces 2.26% accuracy gain on multi-training domain general-ization datasets and 2.28% on single-training domain generalization datasets.
Figure 2. Using a Diffusion Model to solve the one-dimensional
UDT. OoD samples are transformed to the source distribution with limited failure of label preservation.
• UDT puts no requirements on the data from both source and testing distribution like previous works do. This is practically valuable, because the real-world testing dis-tributions are uncountable and dynamically changing.
• UDT is able to transform various distributions using only one model. However, the previous distribution translator works for the translation between certain source and target distributions. With a different source-target pair, a new translator is required.
• Considering the application of UDT in OoD prediction, it is free from the extra assumptions commonly used by the OoD generalization algorithms, such as the multi-training domain assumption and the various forms of the domain invariant assumption.
Despite the advantages, the unavailability of the testing distribution poses new difficulty. Releasing this constraint, the idea of distribution alignment is well established in do-main adaptation (DA). Wherein, a distribution translator is trained with the (pixel, feature, and semantic level) cycle consistency loss [23, 38, 82]. However, the training of such distribution transfer modules necessitates the testing distribu-tion, which is unsuitable under the setting of OoD prediction and makes the transplant of the methods in DA to OoD even impossible.
To circumvent the requirement of testing distribution dur-ing training time, we propose a novel method, named Distri-bution Shift Inversion (DSI). Instead of using a model trans-ferring from testing distribution to training distribution, an unconditional generative model, trained only on the source distribution, is used, which transfers data from a reference noise distribution to the source distribution. The method operates in two successive parts. First, the OoD target dis-tribution is transferred to the neighborhood of the noise dis-tribution and aligned with the input of the generative model, thereafter we refer to this process as the forward transforma-tion. The crux of this step is designing to what degree the target distribution is aligned to the noise distribution. In our implementation, the forward transformation is conducted by linearly combining the OoD samples and random noise with
2.