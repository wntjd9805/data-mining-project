Abstract
Intrinsic image decomposition (IID) is the task that de-composes a natural image into albedo and shade. While
IID is typically solved through supervised learning meth-ods, it is not ideal due to the difficulty in observing ground truth albedo and shade in general scenes. Conversely, un-supervised learning methods are currently underperforming supervised learning methods since there are no criteria for solving the ill-posed problems. Recently, light detection and ranging (LiDAR) is widely used due to its ability to make highly precise distance measurements. Thus, we have fo-cused on the utilization of LiDAR, especially LiDAR inten-sity, to address this issue. In this paper, we propose unsu-pervised intrinsic image decomposition with LiDAR inten-sity (IID-LI). Since the conventional unsupervised learning methods consist of image-to-image transformations, sim-ply inputting LiDAR intensity is not an effective approach.
Therefore, we design an intensity consistency loss that com-putes the error between LiDAR intensity and gray-scaled albedo to provide a criterion for the ill-posed problem. In addition, LiDAR intensity is difficult to handle due to its sparsity and occlusion, hence, a LiDAR intensity densifica-tion module is proposed. We verified the estimating quality using our own dataset, which include RGB images, LiDAR intensity and human judged annotations. As a result, we achieved an estimation accuracy that outperforms conven-tional unsupervised learning methods. 1.

Introduction
Intrinsic image decomposition (IID) is the task that aims to decompose a natural image into an illumination-invariant component (albedo) and an illumination-variant component (shade), and contributes to high level computer vision tasks such as relighting and scene understanding. Research on decomposing a natural image has a long history, beginning with the proposal of the Retinex theory [19] and IID [2].
Focusing on Lambertian scenes, decomposition of a natural
Figure 1. Our proposed approach (IID-LI) is unsupervised intrin-sic image decomposition utilizing LiDAR intensity. We densified
LiDAR intensity to be robust for LiDAR sparsity or occlusions by a LiDAR intensity densification module. In addition, we designed an intensity consistency loss to provide a criterion for the albedo in IID of ill-posed problems. image I is expressed as follows.
I = R · S, (1) where, R and S denote albedo and shade, respectively. “·” represents a channel-wise multiplication. To solve the ill-posed problem, some researchers assumed that sharp and smooth color variation are caused by albedo and shade change, respectively [12, 19, 41, 44]. As other methods, IID was performed by defining and minimizing energy based on the assumptions such as albedo flatness [3, 4]. More-over, since shades depend on object geometry, IID methods with a depth map were also proposed [8, 15, 22]. With the development of deep learning, supervised learning meth-ods began to be used for IID [9, 29, 32–34, 45, 46]. Due to the difficulty of observing ground truth albedo and shade in a practical scenario, supervised learning methods are typ-ically either small [12], synthetic [6,7,24] or sparsely anno-tated [3]. Hence, these supervised learning methods are not ideal for IID in observed data. To address this issue, a few semi-supervised [14, 42] and unsupervised [25, 28, 30, 38] learning methods are proposed. However, these methods are currently underperforming supervised learning methods due to the lack of criteria for solving ill-posed problems by only using image and depth.
In recent years, light detection and ranging (LiDAR), which accurately measures the distance to objects, is widely used. LiDAR usually obtains reflectance intensity (LiDAR intensity) as well as object distance. Since albedo is the proportion of the incident light and reflected light, LiDAR intensity utilization as a criterion for albedo helps to solve the ill-posed problem.
In this paper, we propose unsupervised intrinsic image decomposition with LiDAR intensity (IID-LI). The brief flow of IID-LI is depicted in Fig. 1. Since the conven-tional unsupervised learning methods consist of image-to-image transformations based on variational autoencoder (VAE) [17] , it is not effective to simply input LiDAR inten-sity. Thus, we design an intensity consistency loss that com-putes the error between LiDAR intensity and gray-scaled albedo to provide a criterion for the ill-posed problem of decomposing a single image.
In addition, LiDAR inten-sity is difficult to handle due to its sparsity and occlusion, hence, LiDAR intensity densification (LID) module is pro-posed. The novelty of the LID module lies in the simultane-ous convolution of sparse data (LiDAR intensity) and dense data of different modality (RGB image). Then, we verified the estimating quality with our own dataset that combines
RGB images and LiDAR intensities in outdoor scenes. In summary, our contributions are as follows.
• We propose LiDAR intensity utilization for intrinsic image decomposition (IID), and an architecture of un-supervised intrinsic image decomposition with LiDAR intensity (IID-LI).
• We design an intensity consistency loss to provide a criterion for the ill-posed problem of decomposing a single image.
• We propose a LiDAR intensity densification (LID) module based on deep image prior (DIP) to be robust for LiDAR sparsity or occlusions.
• We create a publicly available dataset for evaluating
IID quality with LiDAR intensity. 1
The rest of the paper is organized as follows. Sec. 2 and
Sec. 3 describe related works and baseline methods, respec-tively. Sec. 4 explains our proposed method. The details of the experiment and experimental results are described in 1Our dataset are publicly available at https://github.com/ntthilab-cv/NTT-intrinsic-dataset
Sec. 5 and Sec. 6, respectively. Finally, a summary of the research is given in Sec. 7. 2.