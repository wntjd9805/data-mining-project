Abstract
Inspired by the success of volumetric 3D pose estima-tion, some recent human mesh estimators propose to esti-mate 3D skeletons as intermediate representations, from which, the dense 3D meshes are regressed by exploiting the mesh topology. However, body shape information is lost in extracting skeletons, leading to mediocre performance.
The advanced motion capture systems solve the problem by placing dense physical markers on the body surface, which allows to extract realistic meshes from their non-rigid mo-tions. However, they cannot be applied to wild images without markers. In this work, we present an intermedi-ate representation, named virtual markers, which learns 64 landmark keypoints on the body surface based on the large-scale mocap data in a generative style, mimicking the effects of physical markers. The virtual markers can be ac-curately detected from wild images and can reconstruct the intact meshes with realistic shapes by simple interpolation.
Our approach outperforms the state-of-the-art methods on three datasets. In particular, it surpasses the existing meth-ods by a notable margin on the SURREAL dataset, which has diverse body shapes. Code is available at https:
//github.com/ShirleyMaxx/VirtualMarker. 1.

Introduction 3D human mesh estimation aims to estimate the 3D positions of the mesh vertices that are on the body sur-face. The task has attracted a lot of attention from the computer vision and computer graphics communities
[3, 10, 18, 24, 26, 29, 34, 36, 41, 49] because it can benefit many applications such as virtual reality [14]. Recently, the deep learning-based methods [7, 18, 28] have significantly
*Corresponding author
Figure 1. Mesh estimation results on four examples with different body shapes. Pose2Mesh [7] which uses 3D skeletons as the inter-mediate representation fails to predict accurate shapes. Our virtual marker-based method obtains accurate estimates. advanced the accuracy on the benchmark datasets.
The pioneer methods [18, 49] propose to regress the pose and shape parameters of the mesh models such as SMPL [35] directly from images. While straightforward, their accu-racy is usually lower than the state-of-the-arts. The first reason is that the mapping from the image features to the model parameters is highly non-linear and suffers from image-model misalignment [28]. Besides, existing mesh datasets [15, 27, 37, 52] are small and limited to simple labo-ratory environments due to the complex capturing process.
The lack of sufficient training data severely limits its perfor-mance.
Recently, some works [25, 38] begin to formulate mesh estimation as a dense 3D keypoint detection task inspired by the success of volumetric pose estimation [42, 43, 45, 48, 57, 63]. For example, in [25, 38], the authors propose to regress the 3D positions of all vertices. However, it is computationally expensive because it has more than several thousand vertices. Moon and Lee [38] improve the efficiency by decomposing the 3D heatmaps into multiple 1D heatmaps at the cost of mediocre accuracy. Choi et al. [7] propose to first detect a sparser set of skeleton joints in the images, from which the dense 3D meshes are regressed by exploiting the mesh topology. The methods along this direction have attracted increasing attention [7, 28, 53] due to two reasons.
First, the proxy task of 3D skeleton estimation can leverage the abundant 2D pose datasets which notably improves the accuracy. Second, mesh regression from the skeletons is efficient. However, important information about the body shapes is lost in extracting the 3D skeletons, which is largely overlooked previously. As a result, different types of body shapes, such as lean or obese, cannot be accurately estimated (see Figure 1).
The professional marker-based motion capture (mocap) method MoSh [34] places physical markers on the body sur-face and explore their subtle non-rigid motions to extract meshes with accurate shapes. However, the physical markers limit the approach to be used in laboratory environments.
We are inspired to think whether we can identify a set of landmarks on the mesh as virtual markers, e.g., elbow and wrist, that can be detected from wild images, and allow to recover accurate body shapes? The desired virtual mark-ers should satisfy several requirements. First, the number of markers should be much smaller than that of the mesh vertices so that we can use volumetric representations to efficiently estimate their 3D positions. Second, the markers should capture the mesh topology so that the intact mesh can be accurately regressed from them. Third, the virtual markers have distinguishable visual patterns so that they can be detected from images.
In this work, we present a learning algorithm based on archetypal analysis [12] to identify a subset of mesh vertices as the virtual markers that try to satisfy the above require-ments to the best extent. Figure 2 shows that the learned virtual markers coarsely outline the body shape and pose which paves the way for estimating meshes with accurate shapes. Then we present a simple framework for 3D mesh estimation on top of the representation as shown in Figure 3.
It first learns a 3D keypoint estimation network based on [45] to detect the 3D positions of the virtual markers. Then we recover the intact mesh simply by interpolating them. The interpolation weights are pre-trained in the representation learning step and will be adjusted by a light network based on the prediction confidences of the virtual markers for each image.
We extensively evaluate our approach on three bench-mark datasets. It consistently outperforms the state-of-the-art methods on all of them. In particular, it achieves a signifi-cant gain on the SURREAL dataset [51] which has a variety of body shapes. Our ablation study also validates the ad-vantages of the virtual marker representation in terms of recovering accurate shapes. Finally, the method shows de-cent generalization ability and generates visually appealing results for the wild images. 2.