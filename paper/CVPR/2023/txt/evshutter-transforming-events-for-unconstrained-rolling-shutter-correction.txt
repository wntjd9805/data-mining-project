Abstract
Widely used Rolling Shutter (RS) CMOS sensors capture high resolution images at the expense of introducing dis-tortions and artifacts in the presence of motion.
In such situations, RS distortion correction algorithms are critical.
Recent methods rely on a constant velocity assumption and require multiple frames to predict the dense displacement field.
In this work, we introduce a new method, called
Eventful Shutter (EvShutter)1, that corrects RS artifacts us-ing a single RGB image and event information with high temporal resolution. The method firstly removes blur us-ing a novel flow-based deblurring module and then com-pensates RS using a double encoder hourglass network. In contrast to previous methods, it does not rely on a constant velocity assumption and uses a simple architecture thanks to an event transformation dedicated to RS, called Filter and Flip (FnF), that transforms input events to encode only 1The evaluation code and the dataset can be found here https:// github.com/juliuserbach/EvShutter the changes between GS and RS images. To evaluate the proposed method and facilitate future research, we collect the first dataset with real events and high-quality RS im-ages with optional blur, called RS-ERGB. We generate the
RS images from GS images using a newly proposed simula-tor based on adaptive interpolation. The simulator permits the use of inexpensive cameras with long exposure to cap-ture high-quality GS images. We show that on this realistic dataset the proposed method outperforms the state-of-the-art image- and event-based methods by 9.16 dB and 0.75 dB respectively in terms of PSNR and an improvement of 23 % and 21 % in LPIPS. 1.

Introduction
Most consumer cameras like cell phones or action cam-eras use a rolling shutter (RS) sensor which instead of capturing the whole frame in a single shot as in a global shutter (GS) camera, it acquires each row sequentially as shown in Fig. 2. Specifically, it obtains each row y at time
constant velocity assumption and uses a simple architec-ture thanks to the newly introduced event transformation, that we call Filter and Flip (FnF). FnF transforms the input events to encode just changes between GS and RS images.
To train and evaluate the proposed method, we collect the first dataset with real events and high quality RS images (optionally with blur), called RS-ERGB. The RS images are generated from GS images using our new simulator based on adaptive interpolation. This pipeline allows the use of an inexpensive high speed camera and the use of long expo-sures while capturing the GS images.
Contributions of this work are as follows 1. Eventful Shutter (EvShutter) : the first event-assisted
RS distortion compensation and deblurring method that avoids constant speed motion assumptions. 2. Filter and Flip (FnF): an event transformation module that transforms the input event stream to encode only the brightness change from GS to RS image and sim-plifies the architecture of downstream modules. 3. Rolling Shutter Events and RGB (RS-ERGB) dataset and simulator: the first dataset with real events and RS images with optional blur generated using a new real-istic RS-simulator, based on adaptive interpolation. 2.