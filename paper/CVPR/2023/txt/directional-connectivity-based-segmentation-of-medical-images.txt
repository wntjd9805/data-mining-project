Abstract 
Anatomical  consistency  in  biomarker  segmentation  is  crucial  for  many  medical  image  analysis  tasks.  A  promising paradigm for achieving anatomically consistent  segmentation  via  deep  networks  is  incorporating  pixel  connectivity, a basic concept in digital topology, to model  inter-pixel  relationships.  However,  previous  works  on  connectivity modeling have ignored the rich channel-wise  directional information in the latent space. In this work, we  demonstrate  that  effective  disentanglement  of  directional  sub-space  from  the  shared  latent  space  can  significantly  enhance  the  feature  representation  in  the  connectivity-based  network.  To  this  end,  we  propose  a  directional  connectivity  modeling  scheme  for  segmentation  that  decouples, tracks, and utilizes the directional information  across the network. Experiments on various public medical  image segmentation benchmarks show the effectiveness of  our  model  as  compared  to  the  state-of-the-art  methods. 
Code is available at https://github.com/Zyun-Y/DconnNet.   1.

Introduction 
Maintaining anatomical consistency in the segmentation  of medical images is important but challenging, as minor  geometric errors may change the global topology [1, 2] and  cause functional mistakes in downstream clinical decision-making  [3].  Anatomical  consistency  in  images  can  be  expressed  with  topological  properties,  such  as  pixel  connectivity  and  adjacency  [4,  5].  As  such,  by  directly  modeling  the  mutual  information  between  pixels  or  regions,  graph-based  methods  have  long  been  used  to  correct topological and geometrical errors [6-8]. However,  such classic machine vision techniques usually depend on  manually  defined  priors  and  thus  are  not  easily  generalizable for a wide variety of applications. 
Alternative  to  the  classic  approaches,  deep  learning-based  segmentation  methods  utilized  an  encoder-decoder  architecture  [9]  to  learn  from  a  group  of  pixels  in  a  particular  receptive  field  at  each  layer.  More  recently,  significant progress has been made in capturing the inter-  pixel dependency inside a networkâ€™s latent space [10-12];  
Figure 1. The latent space differences between traditional pixel-classification-based and connectivity-based models. In the former,  only categorical features, e.g., boundaries, are highlighted; while  in the latter, the feature map also contains directional information  (e.g., the horizontal connections between boundary pixels). 
Figure  2.  The  flows  of  the  two  groups  of  latent  features  (categorical and directional) in the latent space of DconnNet, are  visualized by T-SNE [13]. They were first disentangled (Sec 3.2)  and  then  effectively  fused  in  a  projected  shared  manifold  (Sec  3.3). The colors are rendered based on the results of clustering.  however,  very  few  studies  have  been  conducted  on  the  problem  modeling  side  of  the  networks.  A  typical  segmentation network models the problem as a pure pixel-wise classification task and uses a segmentation mask as  the  only  label.  Yet,  this  pixel-wise  modeling  scheme  is  suboptimal  as  it  does  not  directly  exploit  inter-pixel  relationships  and  geometrical  properties  [14,  15].  Thus,  these  models  may  result  in  low  spatial  coherence  (i.e.,  inconsistent  predictions  for  neighboring  pixels  that  share  similar spatial features) in their prediction [16]. Especially,  when applied to high noise/artifacts medical data, the lower  spatial consistency may lead to topological issues [17]. 
The concept of pixel connectivity has long been used to  ensure  the  basic  topological  duality  of  separation  and  connectedness in digital images [18]. More recently, in the  context of deep learning, the connectivity masks, reviewed                              
2.