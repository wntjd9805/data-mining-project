Abstract
Federated learning shows a bright promise as a privacy-preserving collaborative learning technique. However, prevalent solutions mainly focus on all private data sampled from the same domain. An important challenge is that when distributed data are derived from diverse domains. The pri-vate model presents degenerative performance on other do-mains (with domain shift). Therefore, we expect that the global model optimized after the federated learning pro-cess stably provides generalizability performance on mul-tiple domains. In this paper, we propose Federated Proto-types Learning (FPL) for federated learning under domain shift. The core idea is to construct cluster prototypes and unbiased prototypes, providing fruitful domain knowledge and a fair convergent target. On the one hand, we pull the sample embedding closer to cluster prototypes belonging to the same semantics than cluster prototypes from distinct classes. On the other hand, we introduce consistency reg-ularization to align the local instance with the respective unbiased prototype. Empirical results on Digits and Ofﬁce
Caltech tasks demonstrate the effectiveness of the proposed solution and the efﬁciency of crucial modules. 1.

Introduction
Federated learning is a privacy-preserving paradigm [47, 83], which reaches collaborative learning without leaking privacy. The cornerstone solution, FedAvg [47], aggregates parameters from participants and then distributes the global model (averaged parameters) back for further training, which aims to learn a high-quality model without central-izing private data. However, an inherent challenge in feder-ated learning is data heterogeneity [26, 39, 69, 87]. Speciﬁ-cally, the private data is collected from distinct sources with diverse preferences and presents non-iid (independently and
*Corresponding Author: Mang Ye, Bo Du (cid:5)(cid:6)(cid:4)(cid:8)(cid:9) (cid:1)(cid:5)(cid:2) (cid:10)(cid:8)(cid:7)(cid:8) (cid:1)(cid:10)(cid:2) (cid:8)(cid:11)(cid:3)(cid:6) (cid:1)(cid:8)(cid:11)(cid:2) (cid:8)(cid:12)(cid:6) (cid:1)(cid:8)(cid:12)(cid:2) (cid:3)(cid:5)(cid:10)(cid:17)(cid:7) (cid:1)(cid:7)(cid:5)(cid:14)(cid:11)(cid:10)(cid:11)(cid:8) (cid:4)(cid:14)(cid:12)(cid:13)(cid:12)(cid:15)(cid:7)(cid:6) (cid:2)(cid:7)(cid:16)(cid:9)(cid:12)(cid:6) (cid:2)(cid:1)(cid:2) (cid:4) (cid:2)(cid:1)(cid:2) (cid:3)(cid:5) (cid:2)(cid:1)(cid:2) (cid:3)(cid:6)
Figure 1. Illustration of heterogeneous federated learning. The feature visualization on inter domains (→ represents testing on tar-get domain i.e., M → SV means that local dataset is from MNIST and test model on SVHN). The top row indicates that local train-ing results in domain shift. The bottom row shows that our method acquires generalizable performance on different domains. identically distributed) distribution [87]. Each participant optimizes toward the local empirical risk minimum, which is inconsistent with the global direction. Therefore, the av-eraged global model unavoidably faces a slow convergence speed [40] and achieves limited performance improvement.
A mainstream of subsequent efforts delves into introduc-ing a variety of global signals to regulate private model
[13, 28, 38, 40, 51, 66, 70]. These methods focus on la-bel skew, where distributed data are from the same do-main, and simulate data heterogeneity via imbalanced sam-pling, e.g., Dirichlet strategy [32] to generate different la-bel distributions. Nonetheless, another noticeable data het-erogeneous property in federated learning is domain shift
[21,22,41,55,57]. In particular, private data is derived from various domains, leading to distinct feature distributions.
In this scenario, we argue that naive learning on private data brings poor generalizable ability in Fig. 1. Speciﬁcally, the private model fails to provide discrimination on other do-mains because it overﬁts local domain distribution. The aforementioned methods mainly regulate the private model via global knowledge (i.e., the average signals from partici-pants). Therefore, these algorithms share a common weak-ness: the global information is insufﬁcient to describe di-verse domain knowledge, which is magniﬁed under the do-main shift and thus hinders the improvement of generaliz-ability. An intuitive solution is to preserve multiple models for distilling respective domain knowledge. However, it in-curs a high cost of both communication and computation.
Taking into account both the effectiveness and efﬁciency, we rethink the prototype [11, 36, 67, 82, 91], which is the
It rep-mean value of features with identical semantics. resents class-wise characteristics and is vector type [90].
Given the enormous participant scale in federated learning, it is not efﬁcient and feasible to maintain all prototypes.
However, directly averaging all prototypes to get global pro-totypes would arise the same impediment as global mod-els because averaging operation weakens the domain diver-sity. Besides, global prototypes probably yield biased to the dominant domain due to the unknown of private domains proportion, which results in disadvantageous performance on minority domains. Driven by these two issues, on the one hand, we ﬁnd representative prototypes by clustering all prototypes. Therefore, each class is abstracted by a set of diverse prototypes, capturing rich domain variance. On the other hand, we generate unbiased prototypes based on cluster prototypes to construct fair and stable global signals, which avoid optimizing toward the underlying primary do-main and thus ensure stability on different domains. Com-pared with original feature vectors, cluster and unbiased prototypes are privacy-friendly because it experiences twice and third times averaging operation [70]. Hence, it is less feasible to disentangle each raw representation and subse-quently reconstruct private data. We analyze the superiority of cluster prototypes and unbiased prototypes in Sec. 3.2.
In this paper, we propose Federated Prototype Learning (FPL), which consists of two components. First, in or-der to improve the generalizability on the premise of dis-criminability. We introduce Cluster Prototypes Contrastive
Learning (CPCL), which leverages cluster prototypes to construct contrastive learning [7,19,79,84,85]. CPCL adap-tively enforces the query embedding to be more similar to cluster prototypes from the same class than other prototypes with different semantics. In particular, such an objective en-courages instance feature to be close to representative proto-types in the same semantic and separates it away from other class prototypes, which incorporates diverse domain knowl-edge and maintains a clear decision boundary. Second, we utilize unbiased prototypes to provide a fair and stable con-vergence point and propose Unbiased Prototypes Consis-tent Regularization (UPCR). Speciﬁcally, we average clus-ter prototypes to acquire unbiased prototypes. The local instance is required to minimize the feature-level distance with the corresponding unbiased prototype. Therefore, the local model would not be biased toward dominant domains and exhibits stable performance on inferior domains. We conjecture that these two components together make FPL a competitive method for federated learning with domain shift. The main contributions are summarized below.
• We focus on heterogeneous federated learning with do-main shift and identify that the inherent limitation of ex-isting methods is that global regularization signal is in-sufﬁcient to depict diverse domain knowledge and biased toward major domain among participants.
• We propose a simple yet effective strategy to learn a well generalizable global model in federated learning with do-main shift.
Inspired by the success of prototype learn-ing, we introduce cluster prototypes to provide rich do-main knowledge and further construct unbiased proto-types based on the average of cluster prototypes to further offer fair and stable objective signal.
• We conduct extensive experiments on Digits [23, 33, 52, 61] and Ofﬁce Caltech [16] tasks. Accompanied with a set of ablative studies, promising results validate the efﬁ-cacy of FPL and the indispensability of each module. 2.