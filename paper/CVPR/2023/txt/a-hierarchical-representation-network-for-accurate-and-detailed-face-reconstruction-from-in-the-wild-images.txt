Abstract
Limited by the nature of the low-dimensional represen-tational capacity of 3DMM, most of the 3DMM-based face reconstruction (FR) methods fail to recover high-frequency facial details, such as wrinkles, dimples, etc. Some attempt to solve the problem by introducing detail maps or non-linear operations, however, the results are still not vivid. To this end, we in this paper present a novel hierarchical repre-sentation network (HRN) to achieve accurate and detailed face reconstruction from a single image. Specifically, we implement the geometry disentanglement and introduce the hierarchical representation to fulfill detailed face modeling.
Meanwhile, 3D priors of facial details are incorporated to enhance the accuracy and authenticity of the reconstruction results. We also propose a de-retouching module to achieve better decoupling of the geometry and appearance.
It is noteworthy that our framework can be extended to a multi-view fashion by considering detail consistency of different views. Extensive experiments on two single-view and two multi-view FR benchmarks demonstrate that our method outperforms the existing methods in both reconstruction ac-curacy and visual effects. Finally, we introduce a high-quality 3D face dataset FaceHD-100 to boost the research of high-fidelity face reconstruction. The project homepage is at https://younglbw.github.io/HRN-homepage/. 1.

Introduction
High-fidelity 3D face reconstruction finds a wide range of applications in many scenarios, such as AR/VR, medical treatment, film production, etc. While extensive works al-ready achieved excellent reconstruction performance using specialized hardware like LightStage [2, 11, 35], estimating highly detailed face models from single or sparse-view im-ages is still a challenging problem. Based on 3DMM [8], a statistical model learned from a collection of face scans, many works [16, 22, 23, 32] attempt to reconstruct the 3D face from a single image and achieve impressive results.
However, limited by the nature of the low dimensional rep-resentational ability of the 3DMM, these methods can not recover the detailed facial geometry.
Recently, some methods [13, 24, 38] devote to capturing high-frequency facial details such as wrinkles by predicting a displacement map. They achieve realistic results, how-ever, fail to model the mid-frequency details, such as the detailed contour of the jaw, cheeck, etc. To this end, some works try to capture the overall details by introducing latent encoding of details [19] or non-linear operations [20, 44].
Nevertheless, it is hard to make a trade-off when handling the mid- and high-frequency details simultaneously. An-other challenge is how to obtain accurate shapes and de-tailed 3D facial priors considering multifarious lightings and skins for different images. [10, 13] resort to the wrin-kle statistics computed from 3D face scans to fulfill realis-tic high-frequency details, but still fail to model the mid-frequency details.
Based on the observations above, we introduce a hierar-chical representation network (HRN) for accurate and de-tailed face reconstruction from single image, as shown in
Fig. 2. Firstly, we decouple the facial geometry into low-frequency geometry, mid-frequency (MF) details, and high-frequency (HF) details. Then, in a hierarchical fashion, we model these parts with face-wise blendshape coefficients, vertex-wise deformation map, and pixel-wise displacement map, respectively (shown in Fig. 1). Concretely, we employ two image translation networks [27] to estimate the corre-sponding detail maps (deformation and displacement map), and further employ them to generate the detailed face model in a coarse-to-fine manner. Moreover, we introduce the 3D priors of MF and HF details by fitting face scans with our hierarchical representation to facilitate accurate and faith-ful modeling. Inspired by [33], we propose a de-retouching module to adaptively refine the base texture to overcome the ambiguities between skin blemishes and illuminations. Ex-tensive experiments show that our method outperforms the existing methods on two large-scale benchmarks, exhibiting excellent performance in terms of detail capturing and accu-rate shape modeling. Thanks to the detail disentanglement strategy and the guidance of detail priors, we extend HRN to a multi-view fashion and achieve accurate FR from only a few views. Finally, to boost the research of sparse-view and high-fidelity FR, we introduce a high-quality 3D face dataset named FaceHD-100.
Our main contributions in this work are as follows: (A) We present a hierarchical modeling strategy and pro-pose a novel framework HRN for single-view FR task. Our
HRN produces accurate and highly detailed FR results and outperforms the existing state-of-the-art methods on two large-scale single-view FR benchmarks. (B) We introduce detail priors to guide the faithful modeling of hierarchical details and design a de-retouching module to facilitate the decoupling of geometry and appearance. (C) We extend HRN to a multi-view fashion to form MV-HRN, which enables accurate face modeling from sparse-view images and outperforms the existing methods on two large-scale multi-view FR benchmarks. (D) To boost the research on sparse-view and high-fidelity
FR tasks, we introduce a high-quality 3D face dataset
FaceHD-100, containing 2,000 detailed 3D face models and corresponding high-definition multi-view images. 2.