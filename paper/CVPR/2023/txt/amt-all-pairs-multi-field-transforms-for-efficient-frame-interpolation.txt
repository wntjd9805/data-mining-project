Abstract
We present All-Pairs Multi-Field Transforms (AMT), a new network architecture for video frame interpolation. It is based on two essential designs. First, we build bidirec-tional correlation volumes for all pairs of pixels, and use the predicted bilateral ﬂows to retrieve correlations for up-dating both ﬂows and the interpolated content feature. Sec-ond, we derive multiple groups of ﬁne-grained ﬂow ﬁelds from one pair of updated coarse ﬂows for performing back-ward warping on the input frames separately. Combining these two designs enables us to generate promising task-oriented ﬂows and reduce the difﬁculties in modeling large motions and handling occluded areas during frame interpo-lation. These qualities promote our model to achieve state-of-the-art performance on various benchmarks with high efﬁciency. Moreover, our convolution-based model com-petes favorably compared to Transformer-based models in terms of accuracy and efﬁciency. Our code is available at https://github.com/MCG-NKU/AMT. 1.

Introduction
Video frame interpolation (VFI) is a long-standing video processing technology, aiming to increase the temporal res-olution of the input video by synthesizing intermediate frames from the reference ones.
It has been applied to various downstream tasks, including slow-motion genera-tion [22, 61], novel view synthesis [11, 29, 71], video com-pression [60], text-to-video generation [52], etc.
Recently, ﬂow-based VFI methods [17, 22, 26, 34, 53, 69] have been predominant in referenced research due to their effectiveness. A common ﬂow-based technique estimates bilateral/bidirectional ﬂows from the given frames and then propagates pixels/features to the target time step via back-ward [2, 17, 26] or forward [14, 37, 38] warping. Thus, the quality of a synthesized frame relies heavily on ﬂow esti-In fact, it is cumbersome to approximate mation results. intermediate ﬂows through pretrained optical ﬂow models,
*Equal contribution
†C.L. Guo is the corresponding author.
[26]
[43]
[26]
[17]
[26]
[14]
Figure 1. Performance vs. number of parameters and FLOPs. The
PSNR values are obtained from the Vimeo90K dataset [65]. We use a 720p frame pair to calculate FLOPs. Our AMT outperforms the state-of-the-art methods and is with higher efﬁciency. and these ﬂows are unqualiﬁed for VFI usage [14, 17].
A feasible way to alleviate this issue is to estimate task-oriented ﬂows in an end-to-end training manner [22, 26, 32, 65]. However, some major challenges, such as large motions and occlusions, are still pending to be resolved.
These challenges mainly arise from the defective estimation of optical ﬂows. Thus, a straightforward question should be: Why do previous methods have difﬁculties in predict-ing promising task-oriented ﬂows when facing these chal-lenges? Inspired by the recent studies [26, 65] that demon-strate task-oriented ﬂow is generally consistent with ground truth optical ﬂow but diverse in local details, we attempt to answer the above question from two perspectives: (i) The ﬂow ﬁelds predicted by existing VFI methods are not consistent enough with the true displacements, es-pecially when encountering large motions (see Fig. 2). Ex-isting methods mostly adopt the UNet-like architecture [48] with plain convolutions to build VFI models. However, this type of architecture is vulnerable to accumulating errors at early stages when modeling large motions [45, 56, 63, 70].
As a result, the predicted ﬂow ﬁelds are not accurate. (ii) Existing methods predict one pair of ﬂow ﬁelds, re-Overlaid
IFRNet [26] Flow IFRNet [26] Result
Ground Truth
Our Flow
Figure 2. Qualitative comparisons of estimated ﬂows and the inter-polated frames. Our AMT guarantees the general consistency of intermediate ﬂows and synthesizes fast-moving objects with oc-cluded regions precisely, while the previous state-of-the-art IFR-Net [26] fails to achieve them.
Our Result stricting the solution set in a tight space. This makes them struggle to handle occlusions and details around the mo-tion boundaries, which consequently deteriorates the ﬁnal results (see Fig. 2 and Fig. 5).
In this paper, we present a new network architecture, dubbed All-pairs Multi-ﬁeld Transforms (AMT), for video frame interpolation. AMT explores two new designs to im-prove the ﬁdelity and diversity of predicted ﬂows regarding the above two main shortcomings of previous works.
Our ﬁrst design is based on all-pairs correlation in
RAFT [56], which adequately models the dense correspon-dence between frames, especially for large motions. We propose to build bidirectional correlation volumes instead of unidirectional one and introduce a scaled lookup strat-egy to solve the coordinate mismatch issue caused by the invisible frame. Besides, the retrieved correlations assist our model in jointly updating bilateral ﬂows and the inter-polated content feature in a cross-scale manner. Thus, the network guarantees the ﬁdelity of ﬂows across scales, lay-ing the foundation for the following reﬁnement.
Second, considering that predicting one pair of ﬂow
ﬁelds is hard to cope with the occlusions, we propose to derive multiple groups of ﬁne-grained ﬂow ﬁelds from one pair of updated coarse bilateral ﬂows. The input frames can be separately backward warped to the target time step by these ﬂows. Such diverse ﬂow ﬁelds provide adequate po-tential solutions for each pixel to be interpolated, particu-larly alleviating the ambiguity issue in the occluded areas.
We examine the proposed AMT on several public bench-marks with different model scales, showing strong perfor-mance and high efﬁciency in contrast to the state-of-the-art (SOTA) methods (see Fig. 1). Our small model outper-forms IFRNet-B, a SOTA lightweight model, by +0.17dB
PSNR on Vimeo90K [65] with only 60% of its FLOPs and parameters. For large-scale setting, our AMT exceeds the previous SOTA (i.e., IFRNet-L) by +0.15 dB PSNR on
Vimeo90K [65] with 75% of its FLOPs and 65% of its pa-rameters. Besides, we provide a huge model for comparison with the SOTA transformer-based method VFIFormer [34].
Our convolution-based AMT shows a comparable perfor-mance but only needs nearly 23× less computational cost compared to VFIFormer [34]. Considering its effectiveness, we hope our AMT could bring a new perspective for the ar-chitecture design in efﬁcient frame interpolation. 2.