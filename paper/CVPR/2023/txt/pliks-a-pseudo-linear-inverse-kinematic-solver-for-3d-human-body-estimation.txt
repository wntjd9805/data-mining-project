Abstract
We introduce PLIKS (Pseudo-Linear Inverse Kinematic
Solver) for reconstruction of a 3D mesh of the human body from a single 2D image. Current techniques directly regress the shape, pose, and translation of a parametric model from an input image through a non-linear mapping with mini-mal flexibility to any external influences. We approach the task as a model-in-the-loop optimization problem. PLIKS is built on a linearized formulation of the parametric SMPL model. Using PLIKS, we can analytically reconstruct the human model via 2D pixel-aligned vertices. This enables us with the flexibility to use accurate camera calibration information when available. PLIKS offers an easy way to introduce additional constraints such as shape and transla-tion. We present quantitative evaluations which confirm that
PLIKS achieves more accurate reconstruction with greater than 10% improvement compared to other state-of-the-art methods with respect to the standard 3D human pose and shape benchmarks while also obtaining a reconstruction er-ror improvement of 12.9 mm on the newer AGORA dataset. 1.

Introduction
Estimating human surface meshes and poses from single images is one of the core research directions in computer vi-sion, allowing for multiple applications in computer graph-ics, robotics and augmented reality [14, 46]. Since humans have complex body articulations and the scene parameters are typically unknown, we are essentially dealing with an ill-posed problem that is difficult to solve in general.
Thanks to models such as SMPL [35] and SMPL-X [44] additional constraints on body shape and pose became avail-able. They made the problem somewhat more tractable.
Most state-of-the-art methods [19, 21, 24, 27, 52] directly regress the shape and pose parameters from a given input image. These approaches rely completely on neural net-Figure 1. Network predicts a pixel-aligned vertex map (u, v, d) which is used to obtain an initial pose estimate. Then a closed-form solution is made use of to solve the Inverse kinematics between the 2D pixel-aligned vertex map (u, v) and a pseudo-parametric model given the detected bounding-box camera intrin-sic and initial pose estimate. works, while making several assumptions about the image generation process. One typical assumption is the use of a simplified camera model such as the weak perspective cam-era. In this scenario, the camera is assumed to be far away from the subject, which is generally realized by setting a large focal length constant for all images. A weak perspec-tive camera can be described based on three parameters, two with respect to translation in the horizontal and vertical di-rections, and the third being scale. While these methods can estimate plausible shape and pose parameters, it can happen that the resulting meshes are either misaligned in the 2D image space or in the 3D object space. This is because the underlying optimization problem is often not constrained enough such that it is difficult for the underlying networks to optimize between the 2D re-projection loss and the 3D loss.
Some a workaround by tackling the problem using a hybrid
[23, 25, 31] propose existing methods
approach involving learning-based and optimization-based techniques while incorporating a full perspective cam-era [23]. Optimization-based approaches are, however, prone to local minima, and they are computationally the authors propose to regress the expensive.
SMPL parameters by conditioning on features from a
CamCalib network meant to predict the camera parameters.
Unfortunately, this camera prediction network needs a specialized dataset to train on, which is very hard to acquire in practice. It also prevents end-to-end learning.
In [25],
On the other hand, recent non-parametric or model-free approaches [33, 40] directly regress the mesh vertex coor-dinates based on their 2D projections, aligning well to the input image. However, by ignoring the effects of a perspec-tive camera, even these methods suffer from the same limi-tations as the parametric models.
Motivated by the above observations, we present a novel approach, named PLIKS, for 3D human shape and pose estimation that incorporates the perspective camera while analytically solving for all the parameters of the paramet-ric model. The pipeline of our approach comprises of two modules, namely the mesh regressor and PLIKS. The mesh regressor provides a mapping between an image and the 3D vertices of the SMPL model. Given a single image, any off-the-shelf Convolution Neural Network (CNN) can be used for feature extraction. The extracted features can then be used to obtain a mesh representation either by us-ing 1D CNNs [40], GraphCNNs [28], or even transform-ers [33]. This way, correspondences to the image space can be found and a relative depth estimate can be computed.
From the image-aligned mesh prediction, we can roughly estimate the rotations with respect to a template mesh in canonical space with the application of Inverse Kinematics (IK), denoted in this work as the Approximate Rotation Es-timator (ARE). Finally, we reformulate the SMPL model as a linear system of equations, with which we can use the 2D pixel-aligned vertex maps and any known camera intrin-sic parameters to fully estimate the model without the need for any additional optimization. As our approach is end-to-end differentiable and fits the model within the training loop, it is self-improving in nature. The proposed approach is benchmarked against various 3D human pose and shape datasets, and significantly outperforms other state-of-the-art approaches.
To summarize, the contribution of our paper is the fol-lowing: (1) We bridge the gap between the 2D pixel-aligned vertex maps and the parametric model by reformulating the
SMPL model as a linear system of equations. Since the pro-posed approach is fully differentiable, we can perform end-to-end training. (2) We propose a 3D human body estima-tion framework that reconstructs the 3D body without rely-ing on weak-perspective assumptions. (3) We show that our approach can improve upon other state-of-the-art methods when evaluated across various 3D human pose and shape benchmarks. 2.