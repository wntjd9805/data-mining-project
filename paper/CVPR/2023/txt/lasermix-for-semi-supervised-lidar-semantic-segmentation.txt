Abstract
Densely annotating LiDAR point clouds is costly, which often restrains the scalability of fully-supervised learning methods. In this work, we study the underexplored semi-supervised learning (SSL) in LiDAR semantic segmenta-tion. Our core idea is to leverage the strong spatial cues of LiDAR point clouds to better exploit unlabeled data. We propose LaserMix to mix laser beams from different Li-DAR scans and then encourage the model to make con-sistent and confident predictions before and after mixing.
Our framework has three appealing properties. 1) Generic:
LaserMix is agnostic to LiDAR representations (e.g., range view and voxel), and hence our SSL framework can be uni-versally applied. 2) Statistically grounded: We provide a detailed analysis to theoretically explain the applicabil-ity of the proposed framework. 3) Effective: Comprehen-sive experimental analysis on popular LiDAR segmentation (∗) Lingdong and Jiawei contributed equally to this work. ((cid:66)) Ziwei serves as the corresponding author. E-mail: ziwei.liu@ntu.edu.sg. datasets (nuScenes, SemanticKITTI, and ScribbleKITTI) demonstrates our effectiveness and superiority. Notably, we achieve competitive results over fully-supervised coun-terparts with 2× to 5× fewer labels and improve the supervised-only baseline significantly by relatively 10.8%.
We hope this concise yet high-performing framework could facilitate future research in semi-supervised LiDAR seg-mentation. Code is publicly available1. 1.

Introduction
LiDAR segmentation is one of the fundamental tasks in autonomous driving perception [41]. It enables autonomous vehicles to semantically perceive the dense 3D structure of the surrounding scenes [15, 34, 39]. However, densely an-notating LiDAR point clouds is inevitably expensive and labor-intensive [18, 23, 47], which restrains the scalability of fully-supervised LiDAR segmentation methods. Semi-supervised learning (SSL) that directly leverages the easy-to-acquire unlabeled data is hence a viable and promising 1https://github.com/ldkong1205/LaserMix.
solution to achieve scalable LiDAR segmentation [13, 14].
Yet, semi-supervised LiDAR segmentation is still under-explored. Modern SSL frameworks are mainly designed for image recognition [2, 3, 42] and semantic segmenta-tion [6, 21, 37] tasks, which only yield sub-par performance on LiDAR data due to the large modality gap between 2D and 3D. Recent research [20] proposed to consider semi-supervised point cloud semantic segmentation as a fresh task and proposed a point contrastive learning framework.
However, their solutions do not differentiate indoor and out-door scenes and therefore overlook the intrinsic and impor-tant properties that only exist in LiDAR point clouds.
In this work, we explore the use of spatial prior for semi-supervised LiDAR segmentation. Unlike the general 2D/3D segmentation tasks, the spatial cues are especially signif-icant in LiDAR data.
In fact, LiDAR point clouds serve as a perfect reflection of real-world distributions, which is highly dependent on the spatial areas in the LiDAR-centered 3D coordinates. As shown in Fig. 1 (left), the top laser beams travel outward long distance and perceive mostly vegetation, while the middle and bottom beams tend to detect car and road from the medium and close distances, respectively. To effectively leverage this strong spatial prior, we propose LaserMix to mix laser beams from different
LiDAR scans, and then encourage the LiDAR segmenta-tion model to make consistent and confident predictions be-fore and after mixing. Our SSL framework is statistically grounded, which consists of the following components: 1) Partitioning the LiDAR scan into low-variation areas.
We observe a strong distribution pattern on laser beams as shown in Fig. 1 (left) and thus propose the laser partition. 2) Efficiently mixing every area in the scan with foreign data and obtaining model predictions. We propose Laser-Mix to manipulate the laser-grouped areas from two LiDAR scans in an intertwining way as depicted in Fig. 1 (middle) and serves as an efficient LiDAR mixing strategy for SSL. 3) Encouraging models to make confident and consistent predictions on the same area in different mixing. We hence propose a mixing-based teacher-student training pipeline.
Despite the simplicity of our overall pipeline, it achieves competitive results over the fully supervised counterpart us-ing 2× to 5× fewer labels as shown in Fig. 1 (right) and sig-nificantly outperforms all prevailing semi-supervised seg-mentation methods on nuScenes [11] (up to +5.7% mIoU) and SemanticKITTI [1] (up to +3.5% mIoU). Moreover,
LaserMix directly operates on point clouds so as to be agnostic to different LiDAR representations, e.g., range view [32] and voxel [58]. Therefore, our pipeline is highly compatible with existing state-of-the-art (SoTA)
LiDAR segmentation methods under various representa-tions [46, 56, 57]. Besides, our pipeline achieves compet-itive performance using very limited annotations on weak supervision dataset [47]: it achieves 54.4% mIoU on Se-manticKITTI [1] using only 0.8% labels, which is on-par with PolarNet [56] (54.3%), RandLA-Net [19] (53.9%), and RangeNet++ [32] (52.2%) using 100% labels. Spatial prior is proven to play a pivotal role in the success of our framework through comprehensive empirical analysis. To summarize, this work has the following key contributions:
• We present a statistically grounded SSL framework that effectively leverages the spatial cues in LiDAR data to facilitate learning with semi-supervisions.
• We propose LaserMix, a novel and representation-agnostic mixing technique that strives to maximize the
“strength” of the spatial cues in our SSL framework.
• Our overall pipeline significantly outperforms previ-ous SoTA methods in both low- and high-data regimes.
We hope this work could lay a solid foundation for semi-supervised LiDAR segmentation. 2.