Abstract
Monocular 3D human pose estimation is quite challeng-ing due to the inherent ambiguity and occlusion, which often lead to high uncertainty and indeterminacy. On the other hand, diffusion models have recently emerged as an effec-tive tool for generating high-quality images from noise. In-spired by their capability, we explore a novel pose estima-tion framework (DiffPose) that formulates 3D pose estima-tion as a reverse diffusion process. We incorporate novel de-signs into our DiffPose to facilitate the diffusion process for 3D pose estimation: a pose-specific initialization of pose uncertainty distributions, a Gaussian Mixture Model-based forward diffusion process, and a context-conditioned re-verse diffusion process. Our proposed DiffPose significantly outperforms existing methods on the widely used pose estimation benchmarks Human3.6M and MPI-INF-3DHP.
Project page: https://gongjia0208.github.io/Diffpose/. 1.

Introduction 3D human pose estimation, which aims to predict the 3D coordinates of human joints from images or videos, is an important task with a wide range of applications, including augmented reality [5], sign language translation [21] and human-robot interaction [40], attracting a lot of attention in recent years [23, 46, 50, 52]. Generally, the mainstream approach is to conduct 3D pose estimation in two stages: the 2D pose is first obtained with a 2D pose detector, and then 2D-to-3D lifting is performed (where the lifting process is the primary aspect that most recent works [2, 10, 16, 17, 19, 32, 54] focus on). Yet, despite the considerable progress, monocular 3D pose estimation still remains challenging. In particular, it can be difficult to accurately predict 3D pose from monocular data due to many challenges, including the inherent depth ambiguity and the potential occlusion, which often lead to high indeterminacy and uncertainty.
† Equal contribution; § Currently at Meta; ‡ Corresponding author
Figure 1. Overview of our DiffPose framework. In the forward process (denoted with blue dotted arrows), we gradually diffuse a “ground truth” 3D pose distribution H0 with low indetermi-nacy towards a 3D pose distribution with high uncertainty HK by adding noise ϵ at every step, which generates intermediate dis-tributions to guide model training. Before the reverse process, we first initialize the indeterminate 3D pose distribution HK from the input. Then, during the reverse process (denoted with red solid arrows), we use the diffusion model g, conditioned on the context information from 2D pose sequence, to progressively transform
HK into a 3D pose distribution H0 with low indeterminacy.
On the other hand, diffusion models [12, 38] have re-cently become popular as an effective way to generate high-quality images [33]. Generally, diffusion models are capa-ble of generating samples that match a specified data distri-bution (e.g., natural images) from random (indeterminate) noise through multiple steps where the noise is progres-sively removed [12, 38].
Intuitively, such a paradigm of progressive denoising helps to break down the large gap be-tween distributions (from a highly uncertain one to a deter-minate one) into smaller intermediate steps [39] and thus successfully helps the model to converge towards smoothly generating samples from the target data distribution.
Inspired by the strong capability of diffusion models to generate realistic samples even from a starting point with high uncertainty (e.g., random noise), here we aim to tackle 3D pose estimation, which also involves handling uncer-tainty and indeterminacy (of 3D poses), with diffusion mod-els. In this paper, we propose DiffPose, a novel framework that represents a new brand of diffusion-based 3D pose es-timation approach, which also follows the mainstream two-stage pipeline. In short, DiffPose models the 3D pose esti-mation procedure as a reverse diffusion process, where we progressively transform a 3D pose distribution with high uncertainty and indeterminacy towards a 3D pose with low uncertainty.
Intuitively, we can consider the determinate ground truth 3D pose as particles in the context of thermodynamics, where particles can be neatly gathered and form a clear pose with low indeterminacy at the start; then eventually these particles stochastically spread over the space, leading to high indeterminacy. This process of particles evolving from low indeterminacy to high indeterminacy is the for-ward diffusion process. The pose estimation task aims to perform precisely the opposite of this process, i.e., the re-verse diffusion process. We receive an initial 2D pose that is indeterminate and uncertain in 3D space, and we want to shed the indeterminacy to obtain a determinate 3D pose distribution containing high-quality solutions.
Overall, our DiffPose framework consists of two oppo-site processes: the forward process and the reverse process, as shown in Fig. 1. In short, the forward process generates supervisory signals of intermediate distributions for training purposes, while the reverse process is a key part of our 3D pose estimation pipeline that is used for both training and testing. Specifically, in the forward process, we gradually diffuse a “ground truth” 3D pose distribution H0 with low indeterminacy towards a 3D pose distribution with high in-determinacy that resembles the 3D pose’s underlying uncer-tainty distribution HK. We obtain samples from the inter-mediate distributions along the way, which are used during training as step-by-step supervisory signals for our diffu-sion model g. To start the reverse process, we first initialize the indeterminate 3D pose distribution (HK) according to the underlying uncertainty of the 3D pose. Then, our diffu-sion model g is used in the reverse process to progressively transform HK into a 3D pose distribution with low indeter-minacy (H0). The diffusion model g is optimized using the samples from intermediate distributions (generated in the forward process), which guide it to smoothly transform the indeterminate distribution HK into accurate predictions.
However, there are several challenges in the above for-ward and reverse process. Firstly, in 3D pose estimation, we start the reverse diffusion process from an estimated 2D pose which has high uncertainty in 3D space, instead of starting from random noise like in existing image genera-tion diffusion models [12, 38]. This is a significant differ-ence, as it means that the underlying uncertainty distribution of each 3D pose can differ. Thus, we cannot design the out-put of the forward diffusion steps to converge to the same
Gaussian noise like in previous image generation diffusion works [12, 38]. Moreover, the uncertainty distribution of 3D poses can be irregular and complicated, making it hard to characterize via a single Gaussian distribution. Lastly, it can be difficult to perform accurate 3D pose estimation with just HK as input. This is because our aim is not just to generate any realistic 3D pose, but rather to predict accurate 3D poses corresponding to our estimated 2D poses, which often requires more context information to achieve.
To address these challenges, we introduce several novel designs in our DiffPose. Firstly, we initialize the indetermi-nate 3D pose distribution HK based on extracted heatmaps, which captures the underlying uncertainty of the desired 3D pose. Secondly, during forward diffusion, to generate the indeterminate 3D pose distributions that eventually (after
K steps) resemble HK, we add noise to the ground truth 3D pose distribution H0, where the noise is modeled by a Gaussian Mixture Model (GMM) that characterizes the uncertainty distribution HK. Thirdly, the reverse diffusion process is conditioned on context information from the in-put video or frame in order to better leverage the spatial-temporal relationship between frames and joints. Then, to effectively use the context information and perform the pro-gressive denoising to obtain accurate 3D poses, we design a
GCN-based diffusion model g.
The contributions of this paper are threefold: (i) We pro-pose DiffPose, a novel framework which represents a new brand of method with the diffusion architecture for 3D pose estimation, which can naturally handle the indeterminacy and uncertainty of 3D poses. (ii) We propose various de-signs to facilitate 3D pose estimation, including the initial-ization of 3D pose distribution, a GMM-based forward dif-fusion process and a conditional reverse diffusion process. (iii) DiffPose achieves state-of-the-art performance on two widely used human pose estimation benchmarks. 2.