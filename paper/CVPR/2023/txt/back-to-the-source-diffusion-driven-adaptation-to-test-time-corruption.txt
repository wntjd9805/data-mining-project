Abstract
Test-time adaptation harnesses test inputs to improve the accuracy of a model trained on source data when tested on shifted target data. Most methods update the source model by (re-)training on each target domain. While re-training can help, it is sensitive to the amount and order of the data and the hyperparameters for optimization. We update the target data instead, and project all test inputs to-ward the source domain with a generative diffusion model.
Our diffusion-driven adaptation (DDA) method shares its models for classiﬁcation and generation across all domains, training both on source then freezing them for all targets, to avoid expensive domain-wise re-training. We augment dif-fusion with image guidance and classiﬁer self-ensembling to automatically decide how much to adapt. Input adapta-tion by DDA is more robust than model adaptation across a variety of corruptions, models, and data regimes on the
ImageNet-C benchmark. With its input-wise updates, DDA succeeds where model adaptation degrades on too little data (small batches), on dependent data (correlated orders), or on mixed data (multiple corruptions). 1.

Introduction
Deep networks achieve state-of-the-art performance for visual recognition [3,8,25,26], but can still falter when there is a shift between the source data and the target data for test-ing [38]. Shift can result from corruption [10, 27]; adver-sarial attack [7]; or natural shifts between simulation and reality, different locations and times, and other such differ-ences [17, 36]. To cope with shift, adaptation and robust-ness techniques update predictions to improve accuracy on target data. In this work, we consider two fundamental axes of adaptation: what to adapt—the model or the input—and how much to adapt—using the update or not. We propose a test-time input adaptation method driven by a generative diffusion model to counter shifts due to image corruptions.
* indicates equal contribution, † indicates corresponding author.
The dominant paradigm for adaptation is to train the model by joint optimization over the source and target [6,13, 44, 53, 54]. However, train-time adaptation faces a crucial issue: not knowing how the data may differ during testing.
While train-time updates can cope with known shifts, what if new and different shifts should arise during deployment?
In this case, test-time updates are needed to adapt the model (1) without the source data and (2) without halting inference.
Source-free adaptation [15, 19, 20, 23, 51, 55] satisﬁes (1) by re-training the model on new targets without access to the source. Test-time adaptation [46,51,56,58] satisﬁes (1) and (2) by iteratively updating the model during inference. Al-though updating the model can improve robustness, these updates have their own cost and risk. Model updates may be too computationally costly, which prevents scaling to many targets (as each needs its own model), and they may be sen-sitive to different amounts or orders of target data, which may result in noisy updates that do not help or even hinder robustness. In summary, most methods update the source model, but this does not improve all deployments.
We propose to update the target data instead. Our diffusion-driven adaptation method, DDA, learns a diffu-sion model on the source data during training, then projects inputs from all targets back to the source during testing.
Figure 1 shows how just one source diffusion model en-ables adaptation on multiple targets. DDA trains a diffusion model to replace the source data, for source-free adaptation, and adapts target inputs while making predictions, for test-time adaptation. Figure 2 shows how DDA adapts the input then applies the source classiﬁer without model updates.
Our experiments compare and contrast input and model updates on robustness to corruptions. For input updates, we evaluate and ablate our DDA and compare it to Diff-Pure [30], the state-of-the-art in diffusion for adversarial defense. For model updates, we evaluate entropy mini-mization methods (Tent [56] and MEMO [58]), the state-of-the-art for online and episodic test-time updates, and
BUFR [5], the state-of-the-art for source-free ofﬂine up-dates. DDA achieves higher robustness than DiffPure and
MEMO across ImageNet-C and helps where Tent degrades
(a) Setting: Multi-Target Adaptation (b) Cycle-Consistent Paired Translation (c) DDA (ours): Many-to-One Diffusion
Figure 1. One diffusion model can adapt inputs from new and multiple targets during testing. Our adaptation method, DDA, projects inputs from all target domains to the source domain by a generative diffusion model. Having trained on the source data alone, our source diffusion model for generation and source classiﬁcation model for recognition do not need any updating, and therefore scale to multiple target domains without potentially expensive and sensitive re-training optimization. due to limited, ordered, or mixed data. DDA is model-agnostic, by adapting the input, and improves across stan-dard (ResNet-50) and state-of-the-art convolutional (Con-vNeXt [26]) and attentional (Swin Transformer [25]) archi-tectures without re-tuning.
Our contributions:
• We propose DDA as the ﬁrst diffusion-based method for test-time adaptation to corruption and include a novel self-ensembling scheme to choose how much to adapt.
• We identify and empirically conﬁrm weak points for on-line model updates—small batches, ordered data, and mixed targets—and highlight how input updates address these natural but currently challenging regimes.
• We experiment on the ImageNet-C benchmark to show that DDA improves over existing test-time adaptation methods across corruptions, models, and data regimes. 2.