Abstract (cid:11)(cid:68)(cid:12)(cid:3)(cid:38)(cid:79)(cid:68)(cid:86)(cid:86)(cid:16)(cid:36)(cid:70)(cid:87)(cid:76)(cid:89)(cid:68)(cid:87)(cid:72)(cid:3) (cid:41)(cid:72)(cid:68)(cid:87)(cid:88)(cid:85)(cid:72)(cid:86) (cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:68)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:54)(cid:83)(cid:68)(cid:70)(cid:72) (cid:11)(cid:71)(cid:12)(cid:3)(cid:49)(cid:82)(cid:85)(cid:80)(cid:68)(cid:79)
Weakly-supervised Video Anomaly Detection is the task of detecting frame-level anomalies using video-level labeled training data. It is difﬁcult to explore class representative features using minimal supervision of weak labels with a single backbone branch. Furthermore, in real-world sce-narios, the boundary between normal and abnormal is am-biguous and varies depending on the situation. For exam-ple, even for the same motion of running person, the ab-normality varies depending on whether the surroundings are a playground or a roadway. Therefore, our aim is to extract discriminative features by widening the relative gap between classes’ features from a single branch. In the proposed Class-Activate Feature Learning (CLAV), the fea-tures are extracted as per the weights that are implicitly activated depending on the class, and the gap is then en-larged through relative distance learning. Furthermore, as the relationship between context and motion is important in order to identify the anomalies in complex and diverse scenes, we propose a Context–Motion Interrelation Mod-ule (CoMo), which models the relationship between the ap-pearance of the surroundings and motion, rather than uti-lizing only temporal dependencies or motion information.
The proposed method shows SOTA performance on four benchmarks including large-scale real-world datasets, and we demonstrate the importance of relational information by analyzing the qualitative results and generalization ability. 1.

Introduction
Video anomaly detection (VAD) in surveillance systems refers to the identiﬁcation of undeﬁned, unusual, or unseen abnormal events (e.g., trafﬁc accidents, robberies, and other unforeseeable events) from amongst normal situations with temporal intervals. Currently, numerous CCTVs installed in public places such as banks, streets, and buildings record
This work was supported by the Institute of Information & communi-cations Technology Planning & Evaluation(IITP) grant funded by the Ko-rea government(MSIT) (No. 2021-0-00172, The development of human
Re-identiﬁcation and masked face recognition based on CCTV camera) (cid:51)(cid:85)(cid:82)(cid:77)(cid:72)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81) (cid:53)(cid:72)(cid:83)(cid:85)(cid:82)(cid:77)(cid:72)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81) (cid:48)(cid:82)(cid:87)(cid:76)(cid:82)(cid:81) (cid:38)(cid:82)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87) (cid:55)(cid:72)(cid:80)(cid:83)(cid:82)(cid:85)(cid:68)(cid:79)(cid:3)(cid:54)(cid:83)(cid:68)(cid:70)(cid:72) (cid:11)(cid:69)(cid:12)(cid:3)(cid:53)(cid:72)(cid:79)(cid:68)(cid:87)(cid:76)(cid:89)(cid:72) (cid:39)(cid:76)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:3)(cid:79)(cid:72)(cid:68)(cid:85)(cid:81)(cid:76)(cid:81)(cid:74) (cid:11)(cid:70)(cid:12)(cid:3)(cid:38)(cid:82)(cid:81)(cid:87)(cid:72)(cid:91)(cid:87)(cid:16)(cid:48)(cid:82)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3) (cid:44)(cid:81)(cid:87)(cid:72)(cid:85)(cid:85)(cid:72)(cid:79)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81) (cid:11)(cid:72)(cid:12)(cid:3)(cid:36)(cid:69)(cid:81)(cid:82)(cid:85)(cid:80)(cid:68)(cid:79) (cid:72) (cid:85) (cid:82) (cid:70) (cid:54) (cid:3) (cid:92) (cid:79) (cid:68) (cid:80) (cid:82) (cid:81) (cid:36) (cid:72) (cid:85) (cid:82) (cid:70) (cid:54) (cid:3) (cid:92) (cid:79) (cid:68) (cid:80) (cid:82) (cid:81) (cid:36)
Figure 1. Concept of proposed method. We extract discrimina-tive features that (a) are activated according to normal or abnormal classes, and (b) enlarge their gaps using relative distance learning.
Furthermore, by projecting features into an interaction space, we (c) explore relationships between the context and motion informa-tion of the scene. For detecting anomalies, the proposed method considers not only motion but also its relationship with the context.
For example, (d) shows a normal video with a physical ﬁghting in a basketball game while (e) shows an abnormal ﬁghting video. The red highlighted ranges are ground-truth abnormal frames and ours (red line) accurately detects anomalies without false alarms. our daily life and play an important role in public safety.
However, because it is time-consuming and laborious for humans to pinpoint anomalies in petabytes of surveillance videos or to monitor constantly, the VAD task, which pro-vides automatic and instantaneous responses, is a hot topic in the ﬁeld of deep learning [5, 26].
Weakly-supervised VAD (WVAD) utilizes minimal knowledge about abnormal events through video-level la-beled training data that only has a label stating whether an abnormal event exists in each video clip or not. WVAD faces several challenges. First, it is difﬁcult for the network to learn to classify anomalies at the frame-level through weak labeled training data. Therefore, most WVAD meth-ods [13,20,31,35] learn through a Multiple Instance Learn-ing (MIL)-based approach. When normal and abnormal video clips are divided into multiple snippets and each is
contained in a negative and positive bag, there is at least one abnormal snippet in the positive bag. Therefore, the MIL approach assumes that the highest abnormality score in the positive bag derives from the abnormal snippet, and forces it to be 1 while the highest score in the negative bag is set to 0. However, given that 1) the boundary between normal and abnormal is ambiguous in the real world, there is a limit to regression learning that forces the predicted score of snippets to a fixed values. Tian et al. [33] and Wu et al. [37] forced the gap between classes through feature learning by enlarging the feature magnitude and adjusting the distance of the feature with the center feature, respectively. How-ever, 2) it is difficult to extract the discrepancy of fea-tures from a single-branch model for enlarging the gap (shown in Fig. 7). Another challenging issue neglected in previous studies is that in real-world scenarios, for a com-plex and diverse scene, the definition of ‘abnormal event’ can differ depending on the context and motion relation-ship. Zhu et al. [47] extracted appearance-invariant features by utilizing only optical flow data to focus on moving parts, while [24,33,42] focused on temporal dependencies to con-sider multi-scale temporal information. However, 3) focus-ing only on motion or temporal information and even excluding appearance information leads to an incomplete understanding of complex scenes.
In complex scenes, the boundary between normal and abnormal is ambiguous, and the distinction sometimes dif-fers depending on the situation. That is, rather than having a fixed explicit prior to the abnormal class, it is necessary to implicitly learn class representative features by relatively comparing each class. Furthermore, abnormal events oc-curring in the real world vary depending on the relationship between context and motion. For example, in Fig. 1, (d) a physical skirmish during a basketball game is a normal and acceptable event; but (e) a physical fight on the street is an abnormal event. Thus, the same motion has a differ-ent class depending on the relationship between motion and surrounding or appearance. Therefore, our motivation is to extract class-activated features by considering the relative boundary between classes and to understand the reciprocal relationship between context and motion information.
To overcome the aforementioned challenges, we propose distance learning that adjusts the interval between normal and abnormal through 1) relative feature distance rather than individual values such as magnitude or score. This adjusts the relative distance between the hard-negative nor-mal sample and the abnormal sample based on the intra-In addition, 2) Class-class variance of normal samples.
Activate Feature Learning (CLAV) is proposed with an add-on Implicit Class-Activate (ICA) module to implicitly activate representative features from a single branch for each class with Class-Specific (CS) loss function as an aux-iliary task to explore each normal or abnormal pattern. Fur-thermore, for the first time in WVAD, we address the impor-tance of the relationship between static and dynamic infor-mation for WVAD and propose 3) a Context-Motion In-terrelation Module (CoMo) that has a dynamic path and a context path focusing on motion and appearance, respec-tively, in the scene, for modeling the relationship between these two information. Then, each feature is projected from the temporal space to the interaction space and correlate propagation is performed by the graph convolution module.
As shown in Fig. 1, (a) the CLAV feature enlarged the gap by (b) distance learning and explored relational information through (c) CoMo, and has no false alarm in (d) the basket-ball game scene with physical fighting, and shows accurate temporal localization in (e) the abnormal scene with fight-ing. We evaluate and discuss the effectiveness of the pro-posed method on four weak-labeled benchmarks, including large-scale real-world dataset UCF-Crimes [31] and XD-Violence [38], and it showed SOTA results. 2.