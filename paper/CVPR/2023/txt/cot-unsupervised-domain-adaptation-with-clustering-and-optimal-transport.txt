Abstract
Unsupervised domain adaptation (UDA) aims to trans-fer the knowledge from a labeled source domain to an unlabeled target domain. Typically, to guarantee desir-able knowledge transfer, aligning the distribution between source and target domain from a global perspective is widely adopted in UDA. Recent researchers further point out the importance of local-level alignment and propose to construct instance-pair alignment by leveraging on Optimal
Transport (OT) theory. However, existing OT-based UDA approaches are limited to handling class imbalance chal-lenges and introduce a heavy computation overhead when considering a large-scale training situation. To cope with two aforementioned issues, we propose a Clustering-based
Optimal Transport (COT) algorithm, which formulates the alignment procedure as an Optimal Transport problem and constructs a mapping between clustering centers in the source and target domain via an end-to-end manner. With this alignment on clustering centers, our COT eliminates the negative effect caused by class imbalance and reduces the computation cost simultaneously. Empirically, our COT achieves state-of-the-art performance on several authorita-tive benchmark datasets. 1.

Introduction
Benefiting from the availability of large-scale data, deep learning has achieved tremendous success over the past few years. However, directly applying a well-trained con-volution neural network on a new domain frequently suf-fers from the domain gap/discrepancy challenge, resulting in spurious predictions on the new domain. To remedy this, Unsupervised Domain Adaptation (UDA) has attracted many researchers’ attention, which can transfer the knowl-edge from a labeled domain to an unlabeled domain.
A major line of UDA approaches [1,1,28,42,49,53] aim
Email: ly261666@alibaba-inc.com
* Equal Contribution
† Corresponding Author to learn a global domain shift by aligning the global source and target distribution while ignoring the local-level align-ment between two domains. By leveraging on global do-main adaptation, the global distributions of source and tar-get domain are almost the same, thus losing the fine-grained information for each class (class-structure) on the source and target domain.
Recently, to preserve class structure in both domains, several works [6, 15, 23, 30, 38, 40, 44, 51, 54] adopt optimal transport (OT) to minimize the sample-level transportation cost between source and target domain, achieving a signifi-cant performance on UDA. However, there exist two issues on recent OT-based UDA approaches. (i) When considering a realistic situation, i.e. the class imbalance1 phenomenon occurs between the source and target domain, samples be-longing to the same class in the target domain are assigned with false pseudo labels due to the mechanism of optimal transport, which requires each sample in source domain can be mapped to target samples. As a result, existing OT-based
UDA methods provide poor pair-wise matching when fac-ing class imbalance challenges. (ii) OT-based UDA meth-ods tend to find a sample-level optimal counterpart, which requires a large amount of computation overhead, especially training on large-scale datasets.
To solve two aforementioned issues, we propose a
Clustering-based Optimal Transport algorithm, termed
COT, to construct a clustering-level instead of sample-level mapping between source and target domain. Clusters in the source domain are obtained from the classifiers supervised by the labeled source domain data. While for the target do-main, COT utilizes a set of learnable clusters to represent the feature distribution of the target domain, which can de-scribe the sub-domain information [50, 57]. For instance, in many object recognition tasks [13, 20] an object could contain many attributes. Each attribute can be viewed as a sub-domain. To this end, the clusters on the source and target domain can represent the individual sub-domain in-formation, respectively, such that optimal transport between clusters intrinsically provides a local mapping from the sub-domain in the source domain to those in the target domain.
Moreover, we provide a theoretical analysis and compre-1label distribution are different in two domains, P s(y) ̸= P t(y)
hensive experimental results to guarantee that (i) COT can alleviate the negative effect caused by class imbalance; (ii)
Compared to existing OT-based UDA approaches, our COT economizes much computation head.
In summary, our main contributions include:
• We propose a novel Clustering-based Optimal Trans-port module as well as a specially designed loss de-rived from the discrete type of Kantorovich dual form, which resolves two aforementioned challenges on the existing OT-based UDA algorithms, facilitating the de-velopment of OT-based UDA community.
• We provide a theoretical analysis to guarantee the ad-vantages of our COT.
• Our COT achieves state-of-the-art performance on sev-eral UDA benchmark datasets. 2.