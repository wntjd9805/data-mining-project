Abstract
Robust and reliable semantic segmentation in complex scenes is crucial for many real-life applications such as au-tonomous safe driving and nighttime rescue. In most ap-proaches, it is typical to make use of RGB images as in-put. They however work well only in preferred weather conditions; when facing adverse conditions such as rainy, overexposure, or low-light, they often fail to deliver sat-isfactory results. This has led to the recent investigation into multispectral semantic segmentation, where RGB and thermal infrared (RGBT) images are both utilized as input.
This gives rise to significantly more robust segmentation of image objects in complex scenes and under adverse condi-tions. Nevertheless, the present focus in single RGBT im-age input restricts existing methods from well addressing dynamic real-world scenes.
Motivated by the above observations, in this paper, we set out to address a relatively new task of semantic seg-mentation of multispectral video input, which we refer to as Multispectral Video Semantic Segmentation, or MVSS in short. An in-house MVSeg dataset is thus curated, con-sisting of 738 calibrated RGB and thermal videos, accom-panied by 3,545 fine-grained pixel-level semantic annota-âˆ—Corresponding author. tions of 26 categories. Our dataset contains a wide range of challenging urban scenes in both daytime and nighttime.
Moreover, we propose an effective MVSS baseline, dubbed
MVNet, which is to our knowledge the first model to jointly learn semantic representations from multispectral and tem-poral contexts. Comprehensive experiments are conducted using various semantic segmentation models on the MVSeg dataset. Empirically, the engagement of multispectral video input is shown to lead to significant improvement in seman-tic segmentation; the effectiveness of our MVNet baseline has also been verified. 1.

Introduction
As a fundamental computer vision problem, semantic segmentation concerns the assignment of category labels to each pixel in an image. It has received extensive research at-tention over the past decades [2,5,12,36,45,64,74,80]. Ex-isting semantic segmentation networks are predominantly designed to work with RGB images, which may fail in the presence of adverse conditions, such as rainy, low-light, or overexposure. On the other hand, we have evidenced a growing demand in using thermal images for semantic segmentation; a number of RGBT models have been subse-quently developed, to engage both RGB and thermal images
as input for semantic segmentation especially with complex scenes [21, 55, 76, 82, 83]. This may be attributed to the fact that thermal infrared imaging is relatively insensitive to il-lumination conditions, as it works by recording infrared ra-diations of an object above absolute zero temperature [19].
It is worth noting that the existing RGBT segmentation methods are based on single images. However, the lack of mechanism to account for the temporal contexts may limit their performance when working with video inputs contain-ing dynamic scenes, which are omnipresent in our daily lives. This leads us to explore in this paper a relatively new task of Multispectral Video Semantic Segmentation, or in short MVSS, with a specific focus on RGBT video inputs.
Fig. 1 illustrates several exemplar multispectral video se-quences and their ground-truth semantic annotations. As shown, the RGB frames and thermal frames provide rich and often complementary information for identifying mov-ing foreground objects and static background scenes in low-light night or facing strong headlights. The new task opens up possibilities for applications that require a holistic view of video segmentation under challenging conditions, e.g., autonomous safe driving, nighttime patrol, and fire rescue.
To our knowledge, this is the first work to address such mul-tispectral video semantic segmentation problem.
In the deep learning era, benchmark datasets have be-come the critical infrastructure upon which the computer vision research community relies to advance the state-of-the-arts. Thanks to the publicly available benchmarks, such as MFNet [21], PST900 [55], Cityscapes [12], and
CamVid [4], the related tasks of multispectral semantic seg-mentation (MSS) and video semantic segmentation (VSS) have evidenced notable progresses. Meanwhile, these ex-isting datasets provide as input either single pairs of RGB and thermal images, or RGB only video sequences. There unfortunately lacks a suitable dataset to train and evaluate learning based models for the proposed MVSS task. This leads us to curate a high-quality and large-scale MVSS dataset, referred to as MVSeg, that contains diverse situa-tions. Specifically, our MVSeg dataset comprises 738 syn-chronized and calibrated RGB and thermal infrared video sequences, with a total of 52,735 RGB and thermal image pairs. Among them, 3,545 image pairs are densely anno-tated with fine-grained semantic segmentation labels, con-sisting of a rich set of 26 object categories in urban scenes.
In particular, as showcased in Fig. 1, our MVSeg dataset in-volves many challenging scenes with adverse lighting con-It is expected to provide a sufficiently realistic ditions. benchmark in this field.
Furthermore, a dedicated baseline model is developed for this new task, which is called Multispectral Video se-mantic segmentation NETwork or simply MVNet. Our
MVNet possesses two key components in addressing the main challenges of MVSS task. Considering the high com-plexity of processing large-volume multispectral video data, a prototypical MVFuse module is devised to attend to rich contextual multispectral video features with a moderate memory footprint. A novel MVRegulator loss is further introduced, which regularizes the feature learning process to reduce cross-spectral modality difference and promote better exploitation of multispectral temporal data. Com-prehensive experiments on various state-of-the-art seman-tic segmentation models are also carried out at the MVSeg dataset. Experimental results demonstrate the significance of multispectral video data for semantic segmentation, and verify the effectiveness of our MVNet model. We expect the MVSeg dataset and the MVNet baseline will facilitate future research activities toward the MVSS task. 2.