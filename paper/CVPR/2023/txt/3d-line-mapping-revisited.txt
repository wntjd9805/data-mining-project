Abstract
In contrast to sparse keypoints, a handful of line segments can concisely encode the high-level scene layout, as they often delineate the main structural elements. In addition to offering strong geometric cues, they are also omnipresent in urban landscapes and indoor scenes. Despite their appar-ent advantages, current line-based reconstruction methods are far behind their point-based counterparts. In this paper we aim to close the gap by introducing LIMAP, a library for 3D line mapping that robustly and efficiently creates 3D line maps from multi-view imagery. This is achieved through revisiting the degeneracy problem of line triangu-lation, carefully crafted scoring and track building, and exploiting structural priors such as line coincidence, paral-lelism, and orthogonality. Our code integrates seamlessly with existing point-based Structure-from-Motion methods and can leverage their 3D points to further improve the line reconstruction. Furthermore, as a byproduct, the method is able to recover 3D association graphs between lines and points / vanishing points (VPs). In thorough experiments, we show that LIMAP significantly outperforms existing ap-proaches for 3D line mapping. Our robust 3D line maps also open up new research directions. We show two exam-ple applications: visual localization and bundle adjustment, where integrating lines alongside points yields the best re-sults. Code is available at https://github.com/cvg/limap. 1.

Introduction
The ability to estimate 3D geometry and build sparse maps via Structure-from-Motion (SfM) has become ubiq-uitous in 3D computer vision. These frameworks enable important tasks such as building maps for localization [60], providing initial estimates for dense reconstruction and re-finement [65], and novel view synthesis [45, 48]. Currently, the field is dominated by point-based methods in which 2D keypoints are detected, matched, and triangulated into 3D maps [20, 64]. These sparse maps offer a compact scene rep-resentation, only reconstructing the most distinctive points.
While there have been tremendous progress in point-based reconstruction methods, they still struggle in scenes (a) Point mapping [13, 64] (b) Line mapping (c) Line-point association (d) Line-VP association
Figure 1. In this paper, we propose a robust pipeline for mapping 3D lines (b), which offers stronger geometric clues about the scene layout compared to the widely used point mapping (a). Part of the success of our pipeline attributes to the modeling of structural priors such as coincidence (c), and parallelism / orthogonality (d).
The corresponding 3D association graphs between lines and points
/ vanishing points (VPs) are also recovered from our system as a byproduct. The degree-1 point and degree-2 junctions are colored in blue and red respectively in (c), while parallel lines associated with the same VP are colored the same in (d). where it is difficult to detect and match sufficiently many sta-ble keypoints, such as in indoor areas. On the contrary, these man-made scenes contain abundant lines, e.g. in walls, win-dows, doors, or ceilings. Furthermore, lines exhibit higher localization accuracy with less uncertainty in pixels [16].
Last but not least, lines appear in highly structured patterns, often satisfying scene-wide geometric constraints such as co-planarity, coincidence (line intersections), parallelism, and orthogonality. In practice, lines suffer from different is-sues, such as poor endpoint localization and partial occlusion.
However, recent line detectors and matchers are bridging the gap of performance between points and lines [25, 46, 84], making it timely to revisit the line reconstruction problem.
Despite their rich geometric properties and abundance in the real world, there exist very few line-based reconstruction methods in the literature [22, 23, 44, 77]. In practical applica-tions, they have also not achieved the same level of success as their point-based counterparts. We believe this is due to
several intrinsic challenges specific to line mapping:
• Inconsistent endpoints. Due to partial occlusion, lines often have inconsistent endpoints across images.
• Line fragmentation. In each image there might be mul-tiple line segments that belong to the same line in 3D.
This makes the process of creating track associations more complex compared to building 3D point tracks.
• No two-view geometric verification. While point matches can be verified in two views via epipolar geome-try, lines require at least three views to filter.
• Degenerate configurations. In practice line triangula-tion is more prone to unstable configurations (see Fig. 8), e.g. becoming degenerate whenever the line is parallel with the camera motion (i.e. to epipolar lines).
• Weaker descriptor-based matching. State-of-the-art de-scriptors for line segments are far behind their point-based counterparts, putting more emphasis on geometric verifi-cation and filtering during reconstruction.
In this paper we aim to reduce the gap between point-based and line-based mapping solutions. We propose a new robust mapping method, LIMAP, that integrates seamlessly into existing open-source point-based SfM frameworks [64, 67, 80]. By sharing the code with the research community we hope to enable more research related to lines; both for low-level tasks (such as improving line segment detection and description) and for integrating lines into higher-level tasks (such as visual localization or dense reconstruction). In particular, we make the following contributions in the paper:
• We build a new line mapping system that reliably recon-structs 3D line segments from multi-view RGB images.
Compared to previous approaches, our line maps are sig-nificantly more complete and accurate, while having more robust 2D-3D track associations.
• We achieve this by automatically identifying and ex-ploiting structural priors such as coincidence (junctions) and parallelism. Our technical contribution spans all stages of line mapping including triangulating proposals, scoring, track building, and joint optimization, with 3D line-point / VP association graphs output as a byproduct.
• The framework is flexible such that researchers can easily change components (e.g. detectors, matchers, vanishing point estimators, etc.) or integrate additional sensor data (e.g. depth maps or other 3D information).
• We are the first to go beyond small test sets by quanti-tatively evaluating on both synthetic and real datasets to benchmark the performance, with hundreds of images for each scene, in which LIMAP consistently and signifi-cantly outperforms existing approaches.
• Finally, we demonstrate the usefulness of having robust line maps by showing improvement over purely point-based methods in tasks such as visual localization and bundle adjustment in Structure-from-Motion. 2.