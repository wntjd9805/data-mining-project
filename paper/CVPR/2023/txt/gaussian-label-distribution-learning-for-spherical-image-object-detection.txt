Abstract
Spherical image object detection emerges in many appli-cations from virtual reality to robotics and automatic driv-ing, while many existing detectors use ln-norms loss for re-gression of spherical bounding boxes. There are two intrin-sic flaws for ln-norms loss, i.e., independent optimization of parameters and inconsistency between metric (dominated by IoU) and loss. These problems are common in planar image detection but more significant in spherical image de-tection. Solution for these problems has been extensively discussed in planar image detection by using IoU loss and related variants. However, these solutions cannot be mi-grated to spherical image object detection due to the undif-ferentiable of the Spherical IoU (SphIoU). In this paper, we design a simple but effective regression loss based on Gaus-sian Label Distribution Learning (GLDL) for spherical im-age object detection. Besides, we observe that the scale of the object in a spherical image varies greatly. The huge differences among objects from different categories make the sample selection strategy based on SphIoU challeng-ing. Therefore, we propose GLDL-ATSS as a better training sample selection strategy for objects of the spherical image, which can alleviate the drawback of IoU threshold-based strategy of scale-sample imbalance. Extensive results on various two datasets with different baseline detectors show the effectiveness of our approach. 1.

Introduction
In the past few years, with the numerous development of panoramic cameras with omnidirectional vision, the ap-plications of spherical images and videos are also becom-ing more extensive, such as virtual & augmented real-ity [9,17,24], robotics [7,8,18], automatic driving [1,28,31], etc. As these spherical data increase, the demand for spher-*This work was done when Hang Xu and Qiang Zhao were at ICT.
†Corresponding author.
Figure 1. Comparison between planar image and spherical image. (a) Moving centers of two bounding boxes in the planar image along the y-axis does not change the distance between the two centers, so IoU and L1 are unchanged. (b) Moving centers of two bounding boxes to the equator along the longitude changes the distance between two centers, which causes IoU decrease sharply whereas the L1 value is unchanged. ical vision analysis tasks increases, especially the object detection task of spherical image. However, compared with the large literature on planar image object detection
[2, 12, 16, 34, 39], research in spherical image object detec-tion is relatively in its earlier stage, with many open prob-lems to solve.
In spherical image object detection, a bounding box is represented by a Bounding Field of View (BFoV) [25].
Many existing detection benchmarks [4, 5, 26, 27, 29] use ln-norms loss for the regression of BFoVs. However, the ln-norms loss has some intrinsic flaws. First, parameters of the bounding box are optimized independently in the ln-norms loss, leading to the detection accuracy sensitive to the fitting of any of the parameters. Second, Intersection
Figure 2. Overview of our main contributions. Gaussian distributions of spherical bounding boxes are constructed, and the sample selection strategy (GLDL-ATSS) and regression loss (GLDL loss) are designed in an alignment manner on the basis of K-L divergence. Note that the GLDL-ATSS and GLDL loss are not involved in the inference phase. Therefore, the inference time remains unchanged. over Union (IoU) has been the standard metric for object detection, so ln-norms as regression loss cause the negative impact of the inconsistency between metric and loss. These problems are common in planar image detection but more significant in spherical image detection. Fig. 1(b) shows the inconsistency between IoU and L1 Loss in the spherical im-age. Specifically, moving centers of bounding boxes to the equator along the longitude changes the distance between two centers, which causes IoU decrease sharply while the
L1 value is unchanged. In contrast, as shown in Fig. 1(a), moving centers of bounding boxes in the planar image along the y-axis does not change the distance between the two centers, so IoU and L1 are unchanged. Solutions for these problems of ln-norms loss have become recently popular in planar image detection by using IoU-induced loss, such as
IoU loss [32], GIoU loss [23] and DIoU loss [37]. How-ever, when calculating the intersection area of two spher-ical boxes, the number of intersection points needs to be obtained. When two spherical boxes are completely coin-cident or one edge is coincident, the number of intersection points will not be fixed and duplicate points will appear.
The current SphIoU uses the DFS algorithm to remove these duplicate intersection points. To the best of our knowledge, the DFS algorithm is undifferentiable. Therefore, Spherical
IoU (SphIoU) [5, 27] is undifferentiable and these solutions based on IoU loss cannot be migrated to spherical image ob-ject detection. The more recent work [30] finds the key to maintaining the consistency between metric and regression loss lies in the trend-level consistency between regression loss and IoU loss rather than value-level consistency, which greatly decreases the difficulty of designing alternatives.
In this paper, we design a simple but effective regres-sion loss based on Gaussian Label Distribution Learning (GLDL) for spherical image object detection. Specifically, in the training phase, we first convert tangent planes of the predicted spherical bounding box and ground truth box into the Gaussian distribution. Then, we devise a dynamic sam-ple selection strategy (GLDL-ATSS) to select positive sam-ples, which can alleviate the drawback of IoU threshold-based strategy of scale-sample imbalance. Finally, we de-sign a regression loss function based on GLDL for spherical object detection task. We observe that GLDL loss achieves a trend-level alignment with SphIoU loss. In the inference phase, we directly obtain the output for the spherical bound-ing box from the trained model of the parameter weights, so the inference time of the network remains unchanged. The entire framework of the method in this paper is shown in
Fig. 2. The highlights of this paper are as follows:
• We explore a new regression loss function based on
Gaussian Label Distribution Learning (GLDL) for spherical object detection task.
It achieves a trend-level alignment with SphIoU loss and thus naturally improves the model.
• We align the measurement between sample selection and loss regression based on the GLDL, and then construct new dynamic sample selection strategies (GLDL-ATSS) accordingly. GLDL-ATSS can allevi-ate the drawback of IoU threshold-based strategy (i.e., scale-sample imbalance).
• Extensive experimental results on two datasets and popular spherical image detectors show the effective-ness of our approach. 2.