Abstract 3D human body representation learning has received in-creasing attention in recent years. However, existing works cannot flexibly, controllably and accurately represent hu-man bodies, limited by coarse semantics and unsatisfac-tory representation capability, particularly in the absence of supervised data.
In this paper, we propose a human body representation with fine-grained semantics and high reconstruction-accuracy in an unsupervised setting. Specif-ically, we establish a correspondence between latent vectors and geometric measures of body parts by designing a part-aware skeleton-separated decoupling strategy, which facili-tates controllable editing of human bodies by modifying the corresponding latent codes. With the help of a bone-guided auto-encoder and an orientation-adaptive weighting strat-egy, our representation can be trained in an unsupervised manner. With the geometrically meaningful latent space, it can be applied to a wide range of applications, from human body editing to latent code interpolation and shape style transfer. Experimental results on public datasets demon-strate the accurate reconstruction and flexible editing abil-ities of the proposed method. The code will be available
*Corresponding author at http://cic.tju.edu.cn/faculty/likun/ projects/SemanticHuman. 1.

Introduction
Learning low-dimensional representations of human bodies plays an important role in various applications in-cluding human body reconstruction [4, 19, 32, 37], gener-ation [7, 30, 31] and editing [35, 36, 39]. Existing meth-ods [2, 18, 22, 25, 29] are either too semantically coarse to enable personalized human body editing, or suffer from poor reconstruction performance due to limited representa-tion capability. This paper aims to develop a fine-grained semantic-aware human body representation with flexible representation ability.
Since human bodies are rich in variations of poses and shapes, traditional linear models [1, 25, 29, 35, 36] can-not handle complex nonlinear structures of human body meshes accurately. Therefore, parametric models have been proposed for better representation. The landmark works
SCAPE [2] and SMPL [22] represent human bodies by the shape and pose parameters. However, the semantics of their shape parameters are not sufficiently precise, making it im-possible to flexibly edit the body shape. Furthermore, the
representation ability of these methods is limited by the lin-ear shape space of human body shapes, and hence their re-construction accuracy is often unsatisfactory.
With the success of deep learning, the encoder-decoder architecture has demonstrated excellent representation ca-pability [7,10,13,14,26]. Such methods improve the recon-struction precision by constructing different convolution-like operators for feature extraction on irregular meshes.
However, these works lack disentangled representation and fail to obtain promising results for geometrically complex human body parts. Several works [3,9,11,18,38] pursue the disentanglement of latent representations, i.e., each latent code has clear semantics. But these methods either require paired supervised data or have poor performance on the re-construction, which significantly affects their generalization and robustness. In addition, the semantics of the above rep-resentations are coarse, which only enables person-level at-tribute transfer and cannot be applied to part-level flexible editing.
In this paper, we aim to build a human body represen-tation with fine-grained semantics and high reconstruction-accuracy in an unsupervised setting, which needs to over-come two main challenges. First, how to disentangle the human body to reconstruct precise semantics is a key but difficult problem. Although it is straightforward to decom-pose a human body into articulated parts for part-level edit-ing, the hidden space of each part is still coupled. Secondly, providing paired supervised data requires a lot of manual effort, and it is very challenging to make the representation disentangled without sacrificing reconstruction accuracy in an unsupervised manner.
To address these challenges, we propose SemanticHu-man, an editable human body representation with fine-grained semantics and high reconstruction-precision, which facilitates controllable human body editing without paired supervised data. To reconstruct fine-grained semantics, we design a part-aware skeleton-separated decoupling strategy with anatomical priors of the human body. Specifically, we disentangle body part variations into bone-related vari-ations (e.g., length and orientation variations) and bone-independent variations (e.g., circumference variations). In contrast to the previous pose and shape disentanglement on the entire person [2, 18, 22], this part-aware skeleton-separated decoupling strategy establishes a correspondence between latent vectors and geometric properties of body parts, which benefits part-level controllable editing.
To ensure high reconstruction accuracy and fine-grained semantics of the representation by unsupervised learn-ing, we propose a bone-guided autoencoder architecture and an orientation-adaptive geometry-preserving loss. The bone-guided auto-encoder fuses the geometric features of body parts with their joint information to achieve accu-rate and efficient modeling of human bodies. Besides, an orientation-adaptive weighting strategy is introduced to compute the geometry-preserving loss, which can provide effective geometric regularization for unsupervised disen-tanglement and part-level editing. Experimental results on two public datasets with different mesh connectivities demonstrate the high reconstruction-precision and control-lable editing capability of the proposed method. An ex-ample is given in Fig. 1. The code will be available at http://cic.tju.edu.cn/faculty/likun/ projects/SemanticHuman.
Our main contributions are summarized as follows:
• We propose a semantic-aware and editable human body representation with fine-grained representation ability. The latent space of our approach facilitates per-sonalized editing of human bodies by modifying their latent vectors.
• We propose a part-aware skeleton-separated decou-pling strategy exploiting structural priors of the human body to learn geometrically meaningful latent codes with fine-grained semantics.
• We propose a bone-guided auto-encoder architecture and an orientation-adaptive geometry-preserving loss to ensure the robust and effective disentanglement of the representation learned without supervision. 2.