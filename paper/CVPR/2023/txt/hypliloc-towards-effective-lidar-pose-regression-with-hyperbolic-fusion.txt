Abstract
LiDAR relocalization plays a crucial role in many fields, including robotics, autonomous driving, and computer vi-sion. LiDAR-based retrieval from a database typically incurs high computation storage costs and can lead to globally inaccurate pose estimations if the database is too sparse.
On the other hand, pose regression methods take images or point clouds as inputs and directly regress global poses in an end-to-end manner. They do not perform database matching and are more computationally efficient than re-trieval techniques. We propose HypLiLoc, a new model for LiDAR pose regression. We use two branched back-bones to extract 3D features and 2D projection features, respectively. We consider multi-modal feature fusion in both Euclidean and hyperbolic spaces to obtain more ef-fective feature representations. Experimental results indi-cate that HypLiLoc achieves state-of-the-art performance in both outdoor and indoor datasets. We also conduct ex-tensive ablation studies on the framework design, which demonstrate the effectiveness of multi-modal feature extrac-tion and multi-space embedding. Our code is released at: https://github.com/sijieaaa/HypLiLoc 1.

Introduction
Visual relocalization aims at estimating the 6-degree of freedom (DoF) pose of an agent using perception sensors, such as LiDARs and cameras. It plays a crucial role in many fields that include robot navigation [12], autonomous driv-ing [23], and scene recognition [22]. Image-based relocal-ization methods have achieved good performance in various applications [15, 33, 36]. However, images taken from cam-eras can only capture RGB color information and are easily influenced by environmental conditions, including low illu-mination and light reflections. By contrast, LiDARs, which cast active beams to estimate the depth of surrounding ob-jects, are more robust against those changes.
*These authors contribute equally.
In recent years, the LiDAR has become an important sensor in smart robots, autonomous vehicles, and mobile devices. LiDAR-based relocalization, which is a basic and important module impacting other perception tasks, has at-tracted more attention [8, 19, 20, 27, 37, 46]. One of the clas-sical approaches, LiDAR odometry, estimates the relative poses among successive LiDAR frames to obtain locally accurate pose estimation. However, errors accumulate over the trajectory, resulting in unsatisfactory global pose esti-mation. To compensate for the error, LiDAR odometry is usually treated as a component in a complete simultaneous localization and mapping system (SLAM), where the global pose estimated by a global positioning method or detected loop closure is used to correct the accumulated error in the
LiDAR odometry [32, 43].
LiDAR-based retrieval is also used for relocalization [34].
It first constructs a database of LiDAR features learned from all candidate LiDAR frames. During inference, given a query
LiDAR scan, the similarities between the query feature and all features stored in the database are computed so that the top-matched poses can be obtained. Although this approach provides accurate global pose estimation, it inherently suf-fers from high computation cost and storage burden [38].
Therefore, it is more appropriate for offline scenarios rather than for real-time mobile applications.
Pose regression is favored as a relocalization method due to its lower computation and storage cost during inference.
The pose regression network is still trained on a database containing LiDAR frames in an end-to-end manner to obtain a regression model. During inference, taking the LiDAR scan as input, the pose regression network directly regresses the global pose without any pre-constructed candidate database or map. It can mitigate the high computation and storage burden that occurs in the LiDAR-based retrieval methods.
As a result, pose regression can be operated in real-time to satisfy various relocalization requirements in robotics, un-manned aerial vehicles (UAVs), mobile relocalization APPs, autonomous vehicles, and SLAM systems.
In this paper, we propose a relocalization method called
HypLiLoc, which is a pose regression network with LiDAR
data as input. HypLiLoc uses a parallel feature extraction design, in which 3D features and 2D spherical projection fea-tures are obtained in two backbone branches simultaneously.
The paper [24] leverages hyperbolic embeddings for 3D point clouds that can be viewed as hierarchical compositions of small parts. We thus follow this motivation to design our pipeline with hyperbolic learning. Specifically, we conduct feature fusion in both Euclidean and hyperbolic spaces to enhance the information representation and to achieve more effective multi-modal feature interaction. We test HypLiLoc in both outdoor and indoor datasets. Experiments indicate that HypLiLoc surpasses current approaches and achieves state-of-the-art (SOTA) performance.
Our main contributions are summarized as follows: 1. We propose a novel LiDAR-based pose regression net-work HypLiLoc. It has one backbone that learns 3D features directly from the 3D point cloud and another backbone that learns features from a 2D projection of the point cloud onto a spherical surface. To achieve effective multi-modal feature interaction, the features are embedded in both Euclidean and hyperbolic spaces using multi-space learning. An attention mechanism is then used to fuse the features from different spaces together. 2. We test our network in both outdoor and indoor datasets, where it outperforms current LiDAR pose regression counterparts and achieves SOTA performance. We also conduct extensive ablation studies on the effectiveness of each design component. 2.