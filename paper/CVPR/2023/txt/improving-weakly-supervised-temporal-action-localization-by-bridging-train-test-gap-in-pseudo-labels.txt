Abstract com/zhou745/GauFuse_WSTAL.git.
The task of weakly supervised temporal action localiza-tion targets at generating temporal boundaries for actions of interest, meanwhile the action category should also be classified. Pseudo-label-based methods, which serve as an effective solution, have been widely studied recently.
However, existing methods generate pseudo labels during training and make predictions during testing under differ-ent pipelines or settings, resulting in a gap between train-ing and testing.
In this paper, we propose to generate high-quality pseudo labels from the predicted action bound-aries. Nevertheless, we note that existing post-processing, like NMS, would lead to information loss, which is insuf-ficient to generate high-quality action boundaries. More importantly, transforming action boundaries into pseudo labels is quite challenging, since the predicted action in-stances are generally overlapped and have different confi-dence scores. Besides, the generated pseudo-labels can be fluctuating and inaccurate at the early stage of training. It might repeatedly strengthen the false predictions if there is no mechanism to conduct self-correction. To tackle these issues, we come up with an effective pipeline for learn-ing better pseudo labels. Firstly, we propose a Gaussian weighted fusion module to preserve information of action instances and obtain high-quality action boundaries. Sec-ond, we formulate the pseudo-label generation as an opti-mization problem under the constraints in terms of the con-fidence scores of action instances. Finally, we introduce the idea of ∆ pseudo labels, which enables the model with the ability of self-correction. Our method achieves supe-rior performance to existing methods on two benchmarks,
THUMOS14 and ActivityNet1.3, achieving gains of 1.9% on THUMOS14 and 3.7% on ActivityNet1.3 in terms of av-erage mAP. Our code is available at https://github.
*Corresponding author. 1.

Introduction
The task of temporal action localization seeks to iden-tify the action boundaries and to recognize action categories that are performed in the video. Action localization can contribute to video understanding, editing, etc. Previous works [3, 19, 20, 43, 51] mainly solved this task in the fully supervised setting, which requires both video-level labels and frame-wise annotations. However, frame-wisely anno-tating videos is labor-intensive and time-consuming. To re-duce the annotation cost, researchers start to focus on the weakly supervised setting. Considering the rich video re-sources from various video websites and apps, weakly su-pervised setting would save tremendous annotation efforts.
Unlike its supervised counterpart, the weakly supervised temporal action localization task only requires video-level category labels. The existing works mainly follow the localization-by-classification pipeline [40, 50], which trains a video-level classifier with category labels [32], and ap-plies the trained classifier to each video snippet1. However, due to the lack of fine-grained annotations, the model may assign high confidence to incorrect snippets such as the con-textual background, which typically has a high correlation with the video-level labels, or only focus on the salient snip-pets, leading to incomplete localization results. There are many studies [21, 23, 25] that tried to address this discrep-ancy between classification and localization, and one of the promising solutions is to generate and utilize pseudo labels.
The advantage of using pseudo labels is that snippets are supervised with snippet-wise labels instead of video-level labels. Existing works [28, 36, 46, 47] achieve remark-able results by introducing pseudo labels into this prob-1We view snippets as the smallest granularity since the high-level fea-tures of consecutive frames vary smoothly over time [12, 42]. In our work, we treat every 16 frames as a snippet
lem. A commonly used strategy for generating pseudo la-bels is to directly utilize the temporal class activation map (TCAM) generated in previous training iterations. Never-theless, we would like to argue that the TCAMs are not desirable pseudo labels. During testing, our goal is to ob-tain the action boundaries, employing the TCAMs as train-ing targets arise the discrepancy between training and test-ing because they are quite different from the actual action boundaries. An intuitive way to address this issue is to leverage the predicted action boundaries as pseudo labels.
However, it is non-trivial to achieve this goal. First, cur-rent post-processing schemes, such as NMS, would induce a large amount of information loss and are not sufficient to obtain high-quality action boundaries for generating effec-tive pseudo labels. Second, the predicted action instances are usually overlapped with each other and have different confidence scores, it is hard to assign the action categories and confidence scores for each snippet.
To address the above issues, we propose the following two modules. First, we propose a Gaussian Weighted
Instance Fusion module to preserve information on the boundary distributions and produce high-quality action boundaries. Specifically, this module weightedly fuses the information of overlapped action instances. Each candi-date action instance is treated as an instance sampled from a Gaussian distribution. The confidence score of each ac-tion instance is viewed as its probability of being sampled.
Accordingly, we can obtain the most possible action bound-aries and their confidence scores by estimating the means of Gaussians from those candidate action instances. In this way, we can produce better action boundaries, which in re-turn help to generate more reasonable pseudo labels.
After generating high-quality action boundaries, we need to convert them into snippet-wise pseudo labels. To han-dle the overlapped action instances and assign snippets with proper confidence scores, we propose a LinPro Pseudo La-bel Generation module to formulate the process of pseudo-label generation as a ℓ1-minimization problem. First, we restrict that the average score of snippets within an action boundary should be equal to the confidence score of this ac-tion instance. This constraint guarantees that we can main-tain the information of confidence scores in the generated pseudo labels. Second, snippets within an action instance might be equivalent in terms of their contribution to the con-fidence score. Thus we require snippet-wise scores within each action instance to be uniform. Based on the two con-straints, we formulate the pseudo label generation as an op-timization problem and solve it to obtain pseudo labels that are consistent with our predicted action boundaries.
Furthermore, there is still one problem regarding to the use of pseudo labels. Since the generated pseudo labels can be fluctuating and inaccurate at early stage of training, with-out a proper self-correction mechanism, the model would keep generating wrong pseudo labels of high confidences at later training stages. To address this issue, we propose to utilize the ∆ pseudo labels, instead of the original pseudo labels, as our training targets. We calculate the difference between the pseudo labels of consecutive training epochs as the ∆ pseudo labels. In general, the model would provide more accurate predictions along with the training. In this way, the model will update its predictions toward the class with the confidence increasing instead of the class with the largest pseudo label value, and thus empowers the model with the ability of self-correction.
The contribution of this paper is four-fold. (a) We pro-pose a Gaussian Weighted Instance Fusion module, which can effectively generate high-quality action boundaries. (b)
We propose a novel LinPro Pseudo Label Generation strat-egy by transforming the process of pseudo-label generation into a ℓ1-minimization problem. (c) We propose to utilize
∆ pseudo labels to enable model with self-correction ability for the generated pseudo labels. (d) Compared with state-of-the-art methods, the proposed framework yields signifi-cant improvements of 1.9% and 3.7% in terms of average mAP on THUMOS14 and ActivityNet1.3, respectively. 2.