Abstract 1.

Introduction
We present a unified framework for camera-space 3D hand pose estimation from a single RGB image based on 3D implicit representation. As opposed to recent works, most of which first adopt holistic or pixel-level dense regression to obtain relative 3D hand pose and then follow with complex second-stage operations for 3D global root or scale recov-ery, we propose a novel unified 3D dense regression scheme to estimate camera-space 3D hand pose via dense 3D point-wise voting in camera frustum. Through direct dense mod-eling in 3D domain inspired by Pixel-aligned Implicit Func-tions for 3D detailed reconstruction, our proposed Neural
Voting Field (NVF) fully models 3D dense local evidence and hand global geometry, helping to alleviate common 2D-to-3D ambiguities. Specifically, for a 3D query point in camera frustum and its pixel-aligned image feature, NVF, represented by a Multi-Layer Perceptron, regresses: (i) its signed distance to the hand surface; (ii) a set of 4D offset vectors (1D voting weight and 3D directional vector to each hand joint). Following a vote-casting scheme, 4D offset vec-tors from near-surface points are selected to calculate the 3D hand joint coordinates by a weighted average. Experi-ments demonstrate that NVF outperforms existing state-of-the-art algorithms on FreiHAND dataset for camera-space 3D hand pose estimation. We also adapt NVF to the clas-sic task of root-relative 3D hand pose estimation, for which
NVF also obtains state-of-the-art results on HO3D dataset.
∗Work done during Lin Huang’s internship with Microsoft.
Monocular 3D hand pose estimation, which aims to re-cover 3D locations of hand joints from an RGB image, has attracted enormous attention and made remarkable progress in recent years. As a long-standing task in computer vision, it remains challenging due to its highly articulated structure, large variations in orientations, severe (self-)occlusion, and inherent 2D-to-3D scale and depth ambiguity.
Owing to the aforementioned difficulties, most existing works [4–7, 15, 19, 26, 32, 35, 36, 45, 52, 53, 59, 60, 63] fo-cused on one aspect of this general problem, which is to estimate root-relative 3D hand pose (i.e., 3D joint coordi-nates relative to a pre-defined root joint, such as hand wrist).
While accurate 2D-to-3D root-relative pose estimation is essential for numerous applications in Virtual/Augmented
Reality, there are various interactive tasks in which having root-relative hand joint coordinates alone is insufficient. For instance, being able to recover camera-space 3D hand joint coordinates in an AR view enables the user to directly use hands to manipulate virtual objects moving in 3D space.
To recover robust camera-space 3D hand pose, there are two key design elements: (1) the ability to exploit dense local evidence. Specifically, as demonstrated in pre-vious works [14, 16, 25, 29, 34, 42, 43, 47, 49, 54–56], dense regression-based methods are more effective than holistic regression-based counterparts for handling highly articu-lated 3D pose structure, attributed to its ability to main-tain the input data spatial structure and fully exploit local evidence; (2) the ability to reason 3D hand global geome-Method
Iqbal et al. [29]
ObMan [22]
I2L-MeshNet [42]
CMR [8]
Hasson et al. [21]
NVF (Ours)
First Stage 2D-Dense
Holistic 1D-Dense 2D-Dense+SpiralConv
Holistic
Unified 3D-Dense
Second Stage
Scale Estimation
Root Estimation
Root Depth Estimation
Registration
Model Fitting
Weighted Average
Table 1. Comparison of representative absolute 3D hand pose estimation schemes. Please refer to Sec. 2.1 for more details. try. As shown in previous literature [13, 29, 33], given 2D evidence and camera intrinsic parameters, reasonable un-derstanding towards target object 3D structure/geometry is crucial to alleviate 2D-to-3D depth ambiguity, which is the key to accurately locate 3D hand pose in camera space.
To fully integrate both elements into our algorithm de-sign in a unified manner, we connect with Pixel-aligned
Implicit Function (PIFu) [24, 27, 49, 50, 62]. Through di-rect dense modeling in 3D domain with pixel-aligned lo-cal features, PIFu-based methods reconstruct highly de-tailed 3D human geometry from an RGB image in a uni-fied way, showing its ability to model high-frequency local details such as clothing wrinkles while generating complete global geometry including largely occluded region such as the back of a person.
Inspired by these results, we pro-pose a novel unified 3D dense regression scheme based on a 3D implicit function for robust camera-space 3D hand pose estimation. Specifically, for each of the 3D query points densely sampled in camera frustum and its pixel-aligned image feature, unlike PIFu predicting occupancy value for each point, our proposed Neural Voting Field (NVF) re-gresses: (i) the signed distance between the point and the hand surface; (ii) a set of 4D offset vectors (1D voting weight and 3D directional vector from the point to each joint). Following a vote-casting scheme, 4D offset vectors from near-surface points (i.e., points for which the predicted signed distance is below a threshold) are selected to calcu-late the 3D hand joint coordinates by a weighted average.
Most existing works for camera-space 3D hand pose es-timation, as shown in Tab. 1, follow a two-stage estimation scheme. They first adopt holistic or pixel-level dense re-gression to obtain 2D and relative 3D hand poses and then follow with complex second-stage processing such as fit-ting, registration, using a separate network for 3D global root location or scale estimation. NVF instead provides a unified solution via direct dense modeling in 3D cam-era space followed by a simple weighted average operation, which enables reasoning about 3D dense local evidence and hand global geometry. As shown in Fig. 1, NVF makes solid 3D point-wise prediction and overall distribution of signed distance and voting weight even in highly occluded regions, leading to accurate camera-space pose estimation.
In Sec. 4, we show that NVF noticeably outperforms two baselines based on holistic regression and 2D dense regres-sion. Besides, NVF exhibits state-of-the-art performance for the task of camera-space 3D hand pose estimation on
FreiHAND dataset. We also adapt NVF to the classic task of root-relative 3D hand pose estimation, for which NVF also achieves state-of-the-art results on HO3D dataset.
Since estimating absolute 3D pose from an RGB image is an ill-posed problem due to scale and depth ambiguity
[13, 29], in Sec. 4.4, we also provide ablation analysis on hand scale based on results from NVF and the baselines.
This work makes the following contributions: 1. We propose Neural Voting Field (NVF), as the first 3D implicit representation-based unified solution to esti-mate camera-space 3D hand pose. 2. NVF follows a novel unified 3D dense regression scheme to estimate camera-space 3D hand pose via dense 3D point-wise voting in camera frustum. 3. NVF outperforms baseline methods based on holistic and 2D dense regression and achieves state-of-the-art results on absolute and relative hand pose estimation. 2.