Abstract
Compositional Zero-Shot Learning (CZSL) aims to train models to recognize novel compositional concepts based on learned concepts such as attribute-object combinations.
One of the challenges is to model attributes interacted with different objects, e.g., the attribute “wet” in “wet apple” and “wet cat” is different. As a solution, we provide anal-ysis and argue that attributes are conditioned on the recog-nized object and input image and explore learning condi-tional attribute embeddings by a proposed attribute learn-ing framework containing an attribute hyper learner and an attribute base learner. By encoding conditional at-tributes, our model enables to generate flexible attribute embeddings for generalization from seen to unseen compo-sitions. Experiments on CZSL benchmarks, including the more challenging C-GQA dataset, demonstrate better per-formances compared with other state-of-the-art approaches and validate the importance of learning conditional at-tributes. Code‡ is available at https://github.com/ wqshmzh/CANet-CZSL. 1.

Introduction
Deep machine learning algorithms today can learn knowledge of concepts to recognize patterns. Can a ma-chine compose different learned concepts to generalize to new compositions? Compositional generalization is one of the hallmarks of human intelligence [3, 18]. To make the models equipped with this ability, Compositional Zero-Shot
Learning (CZSL) [25] is proposed, where the models are trained to recognize images of unseen compositions com-posed of seen concepts. In this work, we concentrate on the situation where each composition is composed by attribute (e.g., wet) and object (e.g., apple). For example, given im-*E-mail: wqshmzh@mail.nwpu.edu.cn
†Corresponding author. E-mail: peng.wang@nwpu.edu.cn
‡Gitee: https://gitee.com/wqshmzh/canet-czsl
Figure 1. The diagram of our work. We aim to learn conditional attributes conditioned on the recognized object and input image through an attribute learning framework containing an attribute hy-per learner and an attribute base learner. We first recognize the ob-ject in the input image. Then, we feed prior knowledge extracted from the conditions, which are recognized object word embedding and input image visual embedding, to the attribute hyper learner.
Finally, conditional attribute embeddings are produced by the at-tribute base learner parameterized by the attribute hyper learner. ages of wet apple and dry cat, a well-trained model can rec-ognize images of new compositions dry apple and wet cat.
Compositional Zero-Shot Learning of attribute-object compositions requires modeling attributes, objects, and the contextuality between them. Learning to model objects in
CZSL is similar to conventional supervised object classi-fication task since the model has access to all objects in
CZSL task [33]. Learning to model contextuality between attribute and object is mostly addressed in the literature
[23,25,26,31,39–41]. One of the main challenges of CZSL is the appearance diversity of an attribute when composed with different objects, e.g., attribute wet in wet apple and wet cat is different. This reveals that the information of each attribute is dependent on different objects. However, most
recent works in CZSL [4, 27, 32, 33, 42, 45] extract attribute representations irrelevant to the object from seen composi-tions to infer the unseen compositions. These approaches neglect the nature of attribute diversity and learn concrete attribute representation agnostic to different objects.
In this paper, we learn conditional attributes rather than learning concrete ones in a proposed Conditional Attribute
Network (CANet). We first conduct analysis to determine the exact conditions by considering the recognition of at-tribute and object as computing a classification probability of attribute and object conditioned on the input image. By decomposing this probability, we demonstrate that the prob-ability of the input image belonging to an attribute is condi-tioned on the recognized object and the input image.
We present an attribute learning framework to learn con-ditional attribute embeddings conditioned on the above two conditions. The framework contains an attribute hyper learner and an attribute base learner, which are sketched in Fig. 1. The attribute hyper learner learns from prior knowledge extracted from the conditions. The attribute base learner is parameterized by the attribute hyper learner and is designed to encode all attribute word embeddings into conditional attribute embeddings. With the attribute learn-ing framework, the attribute embeddings are changed along with the recognized object and input image. Finally, the at-tribute matching is processed in an attribute space where the input image embedding is projected. The attribute classifi-cation logits are computed by cosine similarities between the projected input image embedding and all conditional attribute embeddings. Additionally, we model the contex-tuality between attribute and object as composing attribute and object word embeddings. We use cosine similarities between the projected input image embedding and all com-posed attribute-object embeddings to get the classification logits.
Our main contributions are as follows:
• We propose to learn attributes conditioned on the rec-ognized object and input image.
• We propose an attribute learning framework contain-ing an attribute hyper learner and an attribute base learner for learning conditional attribute embeddings.
• Experiments and ablation studies indicate the effec-tiveness of our proposed conditional attribute network, which further validates the importance of learning con-ditional attributes in the CZSL task. 2.