Abstract
Most camera lens systems are designed in isolation, sepa-rately from downstream computer vision methods. Recently, joint optimization approaches that design lenses alongside other components of the image acquisition and process-ing pipeline—notably, downstream neural networks—have achieved improved imaging quality or better performance on vision tasks. However, these existing methods optimize only a subset of lens parameters and cannot optimize glass materials given their categorical nature. In this work, we develop a differentiable spherical lens simulation model that accurately captures geometrical aberrations. We propose an optimization strategy to address the challenges of lens design—notorious for non-convex loss function landscapes and many manufacturing constraints—that are exacerbated in joint optimization tasks. Specifically, we introduce quan-tized continuous glass variables to facilitate the optimization and selection of glass materials in an end-to-end design con-text, and couple this with carefully designed constraints to support manufacturability. In automotive object detection, we report improved detection performance over existing de-signs even when simplifying designs to two- or three-element lenses, despite significantly degrading the image quality. 1.

Introduction
Figure 1. We introduce a differentiable lens simulation model and an optimization method to optimize compound lenses specifically for downstream computer vision tasks, and apply them to automo-tive object detection. Here, although the optimized two-element lens has a worse average spot size than the baseline lens (136 µm vs 80 µm), it achieves a better mean average precision (AP) on the
BDD100K dataset (32.0 vs 30.3). The optimized lens sacrifices optical performance near the corners for better performance in the small and medium field values where most of the objects are located.
In lens layout plots, dashed lines represent the baseline/optimized counterpart and annotations indicate the optimized glass materials.
The prevailing design paradigm for typical optical sys-tems is to conceive them in isolation by use of simplified im-age quality metrics such as spot size [28]. However, achiev-ing ideal imaging properties or optimal performance on com-puter vision tasks generally requires a more comprehensive approach that includes the remaining parts of the image acquisition and processing chain, in particular the sensor, image signal processing, and downstream neural networks.
Over the years, many works have addressed the joint de-sign of simple optical systems such as diffractive optical elements (DOEs) [3, 20, 27, 31]. These works approach joint optics design by simplifying the design to a single phase plate that allows for a differentiable paraxial Fourier image formation model, optimizable via stochastic gradi-ent descent (SGD) variants. More recently, several differ-entiable lens simulation models have been introduced to address the more complex compound lens systems present in most commodity-type cameras. Tseng et al. [35] build such a model by training a proxy neural network, whereas other works [11, 17, 32] directly implement differentiable ray-tracing operations in automatic differentiation frame-works [1, 22], an idea also discussed in [6, 40, 41]. However, all relevant previous works [11, 17, 32, 35] optimize over only a subset of possible surface profiles and spacings, and ignore the optimization of glass materials altogether. Yet, allowing all lens variables to be freely optimized—that is, without predefined boundaries—provides an opportunity for increased performance on downstream tasks.
Unfortunately, lens design optimization is no trivial pro-cess. Even optimizing for traditional optical performance metrics presents significant difficulties, notably: harsh loss function landscapes with abundant local minima and saddle points [30, 36, 39], restrictive manufacturing con-straints [2, 28], and risk of ray-tracing failures. Optimizing a lens jointly on vision tasks only exacerbates these pitfalls due to the noisy gradients of SGD when applied to complex vision models [35]. Moreover, joint optimization does not naturally allow external supervision from lens designers and, as such, does not necessarily result in a manufacturable lens.
In this work, we introduce a computationally efficient and differentiable pipeline for simulating and differentiating through compound spherical refractive lenses with respect to all design parameters in an end-to-end manner. Our for-ward model integrates exact optical ray tracing, accurate ray aiming, relative illumination, and distortion. Furthermore, we develop an optimization strategy to facilitate the end-to-end design of refractive lenses using SGD-based optimizers while strongly encouraging manufacturable outcomes. To this end, we carefully define losses to handle design con-straints, and introduce quantized continuous glass variables to facilitate the process of selecting the best glass materials among glass catalogs that contain dozens of candidates—a challenge unmet in prior joint optimization methods.
We apply our simulation and optimization pipeline to the task of object detection (OD). We find that even simple two-element lenses such as the ones in Fig. 1 can be compelling candidates for low-cost automotive OD despite a noticeably worse image quality. Then, we validate the proposed method by demonstrating that optimizing the lens jointly with the
OD model leads to consistent improvements in detection performance. We make the following contributions:
• We introduce a novel method for simulating and opti-mizing compound optics with respect to glass materials, surface profiles, and spacings.
• We validate the method on the end-to-end optimization of an OD downstream loss, with lenses specifically optimized for intersection over union (IoU) of bounding boxes predicted from a jointly trained detector.
• We demonstrate that the proposed method results in improved OD performance even when reducing the number of optical elements in a given lens stack.
In addition, we release our code and designs1 in the hope of enabling further joint design applications.
Limitations In end-to-end optics design, the inherent reso-lution of the dataset used to represent real-world scenes—a result of the pixel count, imaging quality, and compression artifacts—needs to be discernibly superior to the modeled optics if meaningful conclusions are to be drawn. Hence, we focus on simple lenses with strong geometrical aberrations, 1https : / / github . com / princeton - computational -imaging/joint-lens-design
Tseng [35] Sun [32] Hale [11] Li [17]
Ours
Differentiable Lens Model
Hands-Free
Efficient
Accurate PSFs
Distortion
Aspherics
✗
✓
✓ (✓)
✓
Optimized Lens Variables
No Boundaries
Spacings
Surface Profiles
Glass Materials
✗
✓
✓
✗
✓
✗
✓
✓
✓
✓
✗ (✓)
✗
✓
✓
✗ (✓) (✓)
✓ (✓)
✗
✗
✓
✓ (✓) (✓)
✓
✓
✗ (✓)
✗
✓
✓
✓
✓
✗
✓
✓
✓
✓
Table 1. Comparison of related work on the joint optimization of refractive compound optics, where each criterion is fully ✓, partially (✓), or not ✗ met. See text for explanations. namely refractive lenses with two to four spherical elements whose combination of aperture and field of view (FOV) ex-ceeds the capabilities of the lens configuration. Incidentally, our method does not completely alleviate the need for human supervision; as in most lens design problems, a suitable lens design starting point is required for best performance. 2.