Abstract
Despite excellent performance in image generation,
Generative Adversarial Networks (GANs) are notorious for its requirements of enormous storage and intensive com-putation. As an awesome “performance maker”, knowl-edge distillation is demonstrated to be particularly effica-cious in exploring low-priced GANs. In this paper, we in-vestigate the irreplaceability of teacher discriminator and present an inventive discriminator-cooperated distillation, abbreviated as DCD, towards refining better feature maps from the generator.
In contrast to conventional pixel-to-pixel match methods in feature map distillation, our DCD utilizes teacher discriminator as a transformation to drive intermediate results of the student generator to be percep-tually close to corresponding outputs of the teacher gen-erator. Furthermore, in order to mitigate mode collapse in GAN compression, we construct a collaborative adver-sarial training paradigm where the teacher discriminator is from scratch established to co-train with student gener-ator in company with our DCD. Our DCD shows superior results compared with existing GAN compression methods.
For instance, after reducing over 40× MACs and 80× pa-rameters of CycleGAN, we well decrease FID metric from 61.53 to 48.24 while the current SoTA method merely has 51.92. This work’s source code has been made accessible at https://github.com/poopit/DCD-official. 1.

Introduction
Image generation transforms random noise or source-domain images to other images in user-required domains.
Recent years have witnessed the burgeoning of genera-tive adversarial networks (GANs) that lead to substantial progress in image-to-image translation [8, 9, 18, 49], style transfer [11, 12, 42], image synthesis [3, 22, 23, 32, 46], etc.
*Corresponding Author (a) Layer-by-layer feature map distillation [34].
Figure 1.
Cross-layer feature map distillation [6]. cooperated feature map distillation. (b) (c) Our discriminator-Image generation has a wide application in daily enter-tainment such as TikTok AI image generator, Dream by
WOMBO, Google Imagen, and so on. Running platforms performing these applications are typically featured with poor memory storage and limited computational power.
However, GANs are also ill-famed for the growing spurt of learnable parameters and multiply-accumulate operations (MACs), raising a huge challenge to the storage require-ment and computing ability of deployment infrastructure.
To address the above dilemma for better usability of
GANs in serving human life, methods such as pruning [7, 27, 28, 33], neural network architecture search (NAS) [10, 19, 26] and quantization [39, 40], have been broadly ex-plored to obtain a smaller generator. On the premise of these compression researches, knowledge distillation, in particu-lar to distilling feature maps, has been accepted as a supple-mentary means to enhance the performance of compressed generators [1, 4, 17, 26, 29, 41]. Originated from image clas-sification, as illustrated in Fig. 1(a), feature map based dis-tillation, which extracts information of intermediate activa-tions and transfers the knowledge from the teacher model to the student one, has been extensively explored and demon-strated to well improve the capability of lightweight mod-els [5, 25, 34, 43, 45]. Distinctive from passing on common feature maps from teacher to student, AT [45] calculates feature attentions as the delivered knowledge; MGD [43] randomly masks feature maps to indirectly guide the stu-dent to learn from the teacher; KRD [6] uses a cross-layer distillation method to allow the “new knowledge” of the stu-dent to learn from the “old knowledge” in teacher, as shown in Fig. 1(b). Whatever, most methods execute pixel-to-pixel feature maps matching between teacher and student.
Alike to the implementations on image classification, feature map based distillation is also considered in GAN compression. For example, GCC [28] considers a well pre-trained discriminator to absorb high-level information from the teacher-generated image, and fuses it with intermediate activations from the teacher generator, results of which are passed to the corresponding position of the student genera-tor. OMGD [33] utilizes an online multi-granularity strat-egy to allow a deeper teacher generator and a wider one to simultaneously deliver output image knowledge of differ-ent granularities to the student generator.These two methods follow the pipeline of image classification to tune the inter-mediate outputs of student generator with those of teacher generator in a fashion of per-pixel matching. Although the sustainable progress on multiple benchmark datasets demonstrates the efficacy of intermediate activation outputs, the feature-based distillation, as we reveal in this paper, is not well compatible with the very nature of generating per-ceptually similar images and adversarial training paradigm.
Concretely speaking, conversely to image classification that relies on feature vector representations, the essence of image generation is to improve perceptually alike between the real images and generated images. Two important facts cause it is eventually difficult to use per-pixel match to an-alyze a pair of images: First, two similar images can con-tain many different pixel values; Second, two dissimilar im-ages can still comprise the same pixel values. Thus, it is not suitable to simply use the per-pixel match. Regarding adversarial training in GANs, a generator learns to synthe-size samples that best resemble the dataset, meanwhile a discriminator differentiate samples in the dataset from the generator generated samples. The adversarial results finally lead the generator to creating images of out-of-the-ordinary visual quality, indicating that the discriminator is also em-powered with informative capacity and can be exploited to enrich the distillation of feature maps. Therefore, it might be inappropriate to directly extend feature map distillation in image classification to image generation. And GAN com-pression oriented feature map distillation with discriminator included remains to be well explored.
In order to achieve this objective, in this paper, we pro-pose a discriminator-cooperated distillation (DCD) method to involve the teacher discriminator in distilling feature maps for student generator. A simple illustration is given in
Fig. 1(c), in contrast to the vanilla pixel-wise distance con-straint, our DCD measures the distance at the end of teacher discriminator with the intermediate generator outputs as its inputs. Our DCD is perspicacious in multiple benchmark datasets with a simple implementation. Akin to perceptual loss [20] which employs a pre-trained neural network such as a VGG model [36] to extract features upon which the ℓ1 distance is calculated from activations of hidden layers, the teacher discriminator in DCD also acts as a feature extrac-tor. Due to pooling operations in the hidden layers, feature maps from different sources (student generator and teacher generator) as inputs to the discriminator may lead to iden-tical latent representations, therefore encouraging natural and perceptually pleasing results. In addition, the proposed
DCD is used in conjunction with collaborative adversarial training, which is also simple but perspicacious to allow the student generator to fool the discriminator for generating
In contrast to discriminator-free paradigm better images. training [28], we find our DCD empowers the compressed student generator with a better capability to compete against teacher discriminator. Thus, we also employ the teacher dis-criminator to collaboratively determine whether inputs from the student generator are real or not.
This work intends to raise the level of feature map dis-tillation to strengthen the compressed student generator to generate high-quality images. The major contributions we have made across the entire paper are listed as follows: (1)
An incentive GAN-oriented discriminator-cooperated fea-ture map distillation method to produce images with high fidelity; (2) One novel collaborative adversarial training paradigm to better reach a global equilibrium point in com-pressing GANs; (3) Remarkable reduction on the generator complexity and significant performance increase. 2.