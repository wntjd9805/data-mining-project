Abstract
Generative adversarial network (GAN) is formulated as a two-player game between a generator (G) and a discriminator (D), where D is asked to differentiate whether an image comes from real data or is produced by G. Under such a formulation, D plays as the rule maker and hence tends to dominate the competition. Towards a fairer game in
GANs, we propose a new paradigm for adversarial training, which makes G assign a task to D as well. Specifically, given an image, we expect D to extract representative features that can be adequately decoded by G to reconstruct instead of learning freely, D is the input. urged to align with the view of G for domain classification.
Experimental results on various datasets demonstrate the substantial superiority of our approach over the baselines.
For instance, we improve the FID of StyleGAN2 from 4.30 to 2.55 on LSUN Bedroom and from 4.04 to 2.82 on LSUN
Church. We believe that the pioneering attempt present in this work could inspire the community with better designed generator-leading tasks for GAN improvement. Project page is at https://ezioby.github.io/glead/.
That way, 1.

Introduction
Generative adversarial networks (GANs) [18] have sig-nificantly advanced image synthesis, which is typically formulated as a two-player game. The generator (G) aims at synthesizing realistic data to fool the discriminator (D), while D pours attention on distinguishing the synthesized samples from the real ones.
Ideally, it would come to an optimal solution where G can recover the real data distribution, and D can hardly tell the source of images anymore [18].
However, the competition between G and D seems to be
∗ This work was done during an internship at Ant Group.
† Corresponding author. This work was partly supported by the Na-tional Natural Science Foundation of China (Grant No. U1903213) and the
Shenzhen Science and Technology Program (JCYJ20220818101014030).
Forward Pass
Backward Pass z x
G
D
G(z)
Gradients
D(x)
Gradients
D
G
Realness
Reconstruction 
Difference x
’
Figure 1. Concept diagram of our proposed generator-leading task (bottom), as complementary to the discriminator-leading task in the original formulation of GANs (upper). D is required to extract representative features that can be adequately decoded by
G to reconstruct the input. unfair. Specifically, on the one hand, D acts as a player in this adversarial game by measuring the discrepancy between the real and synthesized samples. But on the other hand, the learning signals (i.e., gradients) of G are only derived from D, making the latter naturally become a referee in the competition. Such a formulation easily allows
D to rule the game. Massive experimental results could serve as supporting evidence for the theoretical analysis.
For instance, in practice, D can successfully distinguish real and fake samples from a pretty early stage of training and is able to maintain its advantage in the entire training process [63]. Accordingly, the capability of the discrimi-nator usually determines the generation performance more or less. For instance, a discriminator that has over-fitted the whole training set always results in synthesis with limited diversity and poor visual quality [33]. Following this philosophy, many attempts [28, 29, 38, 40, 56, 70] have been made for discriminator improvement.
This work offers a different perspective on GAN im-provement.
In particular, we propose a new adversarial paradigm where G is assigned a new role, i.e., playing as the referee as well to guide D. Recall that producing realistic images usually requires G to generate all-level concepts
adequately. Nevertheless, due to the asymmetrical status of G and D, D is able to tell apart the real and synthesized data merely from limited discriminative regions [63]. We, therefore, would like to encourage D to extract as much the information from an image as possible, such that features learned by D could be rendered back to the input with a frozen G, as in Fig. 1. That is, D is enforced to align with the view of G (i.e. focusing on the entire image region) instead of learning freely for domain classification.
Our method is termed as GLeaD because we propose to assign D a generator-leading task. In particular, given a real or synthesized image, the discriminator would deliver extra spatial representations and latent representations that are then fed into a frozen generator to reproduce the original image. Reconstruction loss (perceptual loss is adopted in practice) penalties the difference between the input image and the reconstructed image and derives gradients from updating the parameters of the discriminator. Moreover, comprehensive experiments are then conducted on various datasets, demonstrating the effectiveness of the proposed method. Particularly, our method improves Frechet Incep-tion Distance (FID) [23] from 4.30 to 2.55 on LSUN Bed-room and 4.04 to 2.82 on LSUN Church. We also manage to improve Recall [39] largely (56%) from 0.25 to 0.39 on
LSUN Bedroom. In addition, thorough ablation studies also suggest that applying generator-leading tasks to require D to reconstruct only real or fake images could boost synthesis quality. While a larger improvement would be gained if both real and synthesized images were incorporated. Last but not least, experimental results in Sec. 4 reveal that our method can indeed boost the fairness between G and D as well as improve the spatial attention of D. 2.