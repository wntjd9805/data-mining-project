Abstract
We present Reference-guided Super-Resolution Neural
Radiance Field (RefSR-NeRF) that extends NeRF to super resolution and photorealistic novel view synthesis. Despite
NeRF’s extraordinary success in the neural rendering ﬁeld, it suffers from blur in high resolution rendering because its inherent multilayer perceptron struggles to learn high frequency details and incurs a computational explosion as resolution increases. Therefore, we propose RefSR-NeRF, an end-to-end framework that ﬁrst learns a low resolution
NeRF representation, and then reconstructs the high fre-quency details with the help of a high resolution reference image. We observe that simply introducing the pre-trained models from the literature tends to produce unsatisﬁed arti-facts due to the divergence in the degradation model. To this end, we design a novel lightweight RefSR model to learn the inverse degradation process from NeRF renderings to target HR ones. Extensive experiments on multiple bench-marks demonstrate that our method exhibits an impressive trade-off among rendering quality, speed, and memory us-age, outperforming or on par with NeRF and its variants while being 52× speedup with minor extra memory usage.
Code will be available at: Mindspore and Pytorch 1.

Introduction
Neural Radiance Field (NeRF) [29], which was ﬁrst pro-posed by Mildenhall et al. in 2020, is leading a trend in neural rendering ﬁeld for its realism and representa-tion parsimony, showing great potential in various down-stream industrial applications such as immersive view syn-thesis [1, 2, 41], 3D scene reconstruction [24, 60], au-tonomous driving [38, 18, 31, 50], aerial surveying [9, 21], digital human deformation [47, 62, 52, 36], robot naviga-tion and environment simulation [38].
In essence, NeRF synthesizes photorealistic renderings by encoding the volu-metric density and color of a scene within the weights of a coordinate-based multilayer perceptron (MLP) [2], and
∗Equal Contribution its magic manifests in reconstructing an intact 3D spacial representation from a handful of sparse observations, while simultaneously retaining a highly compact scene represen-tation [58].
While this approach works well when the training and testing images observe the scene content with low resolu-tion, NeRF, and its follow-ups exhibit signiﬁcant blurry ef-fects when the resolution goes up. This can be attributed to the following two reasons. First of all, MLPs perform poorly to regress the high frequency details from uniformly-sampled low-dimension 5D coordinates [39]. Although a positional encoding that uses Fourier Transformation will greatly leverage this inherent low frequency bias in neural networks, there is still a big room for photorealism. In addi-tion, as the resolution increases, or in other words, when the scene becomes more complex, NeRF requires a larger MLP to encode more high frequency information [38]. How-ever, simply enlarging the MLP only achieves minor gains in detail restoration [33] and will signiﬁcantly exacerbate the rendering efﬁciency.
Moreover, due to the dense sampling strategy and fre-quent MLP queries, rendering a NeRF is agonizingly slow.
It takes more than one day to train for a scene and 30 seconds to render an 800 × 800 image even running on a high-performance desktop GPU, and this issue would be more unacceptable when the resolution continues to as-cend. To accelerate the rendering speed, several follow-up works are proposed from different perspectives. One of the most strait-forward solutions is introducing voxel-grid rep-resentation to NeRF to model local properties of geome-tries [22, 48, 37, 58, 10, 49, 13, 30, 5]. Despite the fact that this paradigm achieves two or three orders of magni-tudes of speed up [37, 10], they consume massive storage and compromise rendering quality, which is unbearable for resource-limited mobile devices.
To tackle the issue of lacking high frequency details, a surge of interest is to introduce more advanced positional encoding algorithms [1, 39]. However, these approaches brought minor improvements. To this end, we propose that since MLPs have a natural defect in learning high fre-quency details, it is better to let MLPs learn low frequency 1
information only and introduce a high resolution reference frame to provide high frequency details in each scene. This begs our ﬁnal solution, as shown in Figure 1, an end-to-end reference-guided super-resolution NeRF framework which is a deft combination of NeRF and the experience from the
RefSR community. Speciﬁcally, We ﬁrst downsample the
HR training images to low resolution ones, then we opti-mize the low resolution NeRF with patch shufﬂe, followed by a lightweight RefSR model which takes an HR refer-ence image as its input to execute the upsampling and pro-duce our ﬁnal HR renderings. We observe that simply in-troducing the pre-trained RefSR models from the literature tends to produce unsatisﬁed artifacts due to divergence in the degradation model from HR to NeRF rendering. This prompted us to design a novel effective and lightweight
RefSR model. To sum up, RefSR-NeRF realizes a well-exempliﬁed trade-off among rendering quality, speed, and memory usage, outperforming or on par with NeRF and its variants while being 52× speedup with minor extra mem-ory and storage usage. The main contributions of this paper can be summarized as follows:
• We propose a novel end-to-end RefSR-NeRF frame-work that extends NeRF to high resolution and photo-realistic novel view synthesis.
• RefSR-NeRF can act as a novel NeRF acceleration paradigm, which can signiﬁcantly alleviate the prob-lem of NeRF computation and cache exploding as res-olution increases.
• Extensive experiments show that RefSR-NeRF quali-tatively and quantitatively outperforms baseline works by a large margin while being 52× faster. 2.