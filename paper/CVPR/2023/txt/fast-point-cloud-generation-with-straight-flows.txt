Abstract
Diffusion models have emerged as a powerful tool for point cloud generation. A key component that drives the impressive performance for generating high-quality sam-ples from noise is iteratively denoise for thousands of steps.
While beneﬁcial, the complexity of learning steps has lim-ited its applications to many 3D real-world. To address this limitation, we propose Point Straight Flow (PSF), a model that exhibits impressive performance using one step. Our idea is based on the reformulation of the standard diffusion model, which optimizes the curvy learning trajectory into a straight path. Further, we develop a distillation strategy to shorten the straight path into one step without a perfor-mance loss, enabling applications to 3D real-world with latency constraints. We perform evaluations on multiple 3D tasks and ﬁnd that our PSF performs comparably to the standard diffusion model, outperforming other efﬁcient 3D point cloud generation methods. On real-world applications such as point cloud completion and training-free text-guided generation in a low-latency setup, PSF performs favorably. 1.

Introduction 3D point cloud generation has many real-world appli-cations across vision and robotics, including self-driving and virtual reality. A lot of efforts have been devoted to realistic 3D point cloud generation, such as VAE [14],
GAN [1, 36], Normalizing Flow [13, 16, 43] and score-based method [5, 27, 47, 50], and diffusion model [27, 47, 50].
Among them, diffusion models gain increasing popularity for generating realistic and diverse shapes by separating the distribution map learning from a noise distribution to a meaningful shape distribution into thousands of steps.
Despite the foregoing advantages, the transport trajectory learning from a noise distribution to a meaningful shape distribution also turns out to be a major efﬁciency bottle-neck during inference since a diffusion model requires thou-sands of generative steps to produce high-quality and diverse shapes [11, 37, 50]. As a result, it leads to high computa-tion costs for generating meaningful point cloud in prac-tice. Notice that the learning transport trajectory follows the simulation process of solving stochastic differentiable equa-tion (SDE). A trained neural SDE can have different distri-bution mappings at each step, which makes the acceleration challenging even with an advanced ordinary differentiable equation (ODE) solver.
To address this challenge, several recent works have pro-posed strategies that avoid using thousands of steps for the meaningful 3D point cloud generation. For example, [26,35] suggest distilling the high-quality 3D point cloud generator,
DDIM model [37], into a few-step or one-step generator.
While the computation cost is reduced by applying distilla-tion to shorten the DDIM trajectory into one-step or few-step generator. The distillation process learns a direct mapping between the initial state and the ﬁnal state of DDIM, which needs to compress hundreds of irregular steps into one-step.
Empirically it leads to an obvious performance drop. Further, these distillation techniques are mainly developed for gener-ating images with the grid structure, which is unsuitable for applying to point cloud generation since the point cloud is an unordered set of points with irregular structures.
In this paper, we propose using one-step to generate 3D point clouds. Our method, Point Straight Flow (PSF), learns a straight generative transport trajectory from a noisy point cloud to a desired 3D shape for acceleration. This is achieved by passing the neural ﬂow model once to estimate the trans-port trajectory. Speciﬁcally, we ﬁrst formulate an ODE trans-port ﬂow as the initial 3D generator with a simpler trajectory compared with the diffusion model formulated in SDE. Then we optimize the transport ﬂow cost for the initial ﬂow model to signiﬁcantly straighten the learning trajectory while main-taining the model’s performance by adopting the ideas from recent works [20, 22]. This leads to a straight ﬂow by op-timizing the curvy learning trajectory into a straight path.
Lastly, with the straight transport trajectory, we further de-sign a distillation technique to shorten the path into one-step for 3D point cloud generation.
To evaluate our method, we undertake an extensive set of experiments on 3D point cloud tasks. We ﬁrst verify
Diffusion
PSF (ours)
Reflow
Distill
Generate
Random points
Shape manifold points (a)
Train velocity flow model (b)
Improving straightness (c)
Flow distillation (d)
Figure 1. Trajectories during the generate process for the point cloud generation. (a) The SDE (PVD) trajectory involves random noise in each step and thus gives a curvy trajectory. (b) The PSF initial ﬂow model removes the random noise term and gets a simulation procedure trajectories with smaller transport cost. (c) By utilizing the reﬂow process on the initial ﬂow model, we reduce the transport cost. As a result, the trajectories are becoming straightened and easy to simulate with one step. (d) The straight path leads to a small time-discrimination error during the simulation, which makes the model easy to distill into one-step. that our one-step PSF can generate high-quality point cloud shapes, performing favorably relative to the diffusion-based point cloud generator PVD [50] with a more than 700
⇥ faster sampling on the unconditional 3D shape generation task. Further, we demonstrate it is highly important to learn straight generative transport trajectory for faster sampling by comparing distillation baselines, including DDIM that are difﬁcult to generate shapes even with many more generative steps. Finally, we perform evaluations on 3D real-world applications, including point cloud completion and training-free text-guided generation, to show the ﬂexibility of our one-step PSF generator.
• For the ﬁrst time, we demonstrate that neural ﬂow trained with one step can generate high-quality 3D point clouds by applying distillation strategy.
• We propose a novel 3D point cloud generative model,
Point Straight Flow (PSF). Our proposed PSF optimizes the curvy transport trajectory between noisy samples and meaningful point cloud shapes as a straight path.
• We show our PSF can generate 3D shapes with high-efﬁciency on standard benchmarks such as uncondi-tional shape generation and point cloud completion. We also successfully extend PSF to real-world 3D appli-cations including large-scene completion and training-free text-guided generation. ing diffusion probabilistic models (DDPM) [11] demon-strate the power and ﬂexibility to generate high-quality sam-ples on large-scale image benchmarks and other domains
[7, 12, 30, 32, 33, 44], which makes the diffusion model be-come a mainstream to learn the transport ﬂow. 2.2. Fast sampling for transport model
Despite the huge success of DDPM, a major issue of this model is that it requires thousands of steps to generate high-quality desired samples. Previous works propose multiple strategies to decrease the simulation steps and accelerate the
DDPM to learn transport process. DDIM [37] formulates the sampling trajectory process as an ODE. FastDPM [17] bridges the connection between the discrete and continuous time step. These two methods can help reduce the learning trajectory to hundreds of steps. Beyond this, to further com-press the generation process to few-step simulation, [26, 35] apply knowledge distillation to learn a few mappings to re-cover the multiple DDIM steps. However, these methods are hard to maintain a good performance with a single step or even more steps. Recent ODE transport works [2, 20–22] try to build the ODE transport with a reduced cost for a faster simulation compared with DDIM. Motivated by the above ideas, we optimize the transport cost ﬁrst to learn the transport trajectory with one step in our PSF model. 2.