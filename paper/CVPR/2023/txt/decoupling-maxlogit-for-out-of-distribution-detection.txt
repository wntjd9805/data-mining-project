Abstract
In machine learning, it is often observed that standard training outputs anomalously high confidence for both in-distribution (ID) and out-of-distribution (OOD) data. Thus, the ability to detect OOD samples is critical to the model de-ployment. An essential step for OOD detection is post-hoc scoring. MaxLogit is one of the simplest scoring functions which uses the maximum logits as OOD score. To provide a new viewpoint to study the logit-based scoring function, we reformulate the logit into cosine similarity and logit norm and propose to use MaxCosine and MaxNorm. We empir-ically find that MaxCosine is a core factor in the effective-ness of MaxLogit. And the performance of MaxLogit is en-cumbered by MaxNorm. To tackle the problem, we propose the Decoupling MaxLogit (DML) for flexibility to balance
MaxCosine and MaxNorm. To further embody the core of our method, we extend DML to DML+ based on the new insights that fewer hard samples and compact feature space are the key components to make logit-based methods effec-tive. We demonstrate the effectiveness of our logit-based
OOD detection methods on CIFAR-10, CIFAR-100 and Im-ageNet and establish state-of-the-art performance. 1.

Introduction
In real-world applications, the closed-world assumption does not always hold where all the classes in the test phase would be available in the training phase. Out-of-distribution (OOD) detection [11] is a natural and challenging setting, and there is an open space containing outliers not belong-ing to any training classes. When the model is deployed in practice, OOD data often come from the open world [17].
Thus, it is crucial for a trustworthy model to not only pro-duce accurate predictions on in-distribution (ID) data, but also distinguish the OOD data and reject them. However, the machine-learning model easily produces over-confident
*Equal contribution, co-first author; also with Nat. Key Lab of MSIIPT.
Correspondence to Xiang Xiang (xex@hust.edu.cn) (a) AUROC of different methods (b) FPR95 of SOTA methods
Figure 1. AUROC and FPR95 (in percentage) of previous OOD detection methods on ImageNet and CIFAR-100. (a) shows the
AUROC (higher is better) of our methods (orange pentagons) and other methods (blue rectangles). (b) shows the FPR95 (lower is better) of our methods and SOTA methods w/ (LogitNorm [37]) and w/o (ViM [36]) training on CIFAR-100. wrong predictions on OOD data [25]. For instance, a model may wrongly detect the zebra as a horse with high confi-dence when the zebra is not in the training set.
A key of the OOD detection algorithm is a scoring func-tion that maps the input to the OOD score, indicating to what extent the sample is an OOD sample. Various scor-ing functions have been proposed to seek the properties that better distinguish OOD samples. The OOD score is calculated mainly from the output of the model, includ-ing features [20, 30, 36], logits [10, 11, 23]. For example,
MSP [11] uses the maximum Softmax probabilities, and
MaxLogit [10] uses the maximum logits as the OOD score.
MaxLogit and MSP are two simplest scoring functions that do not require extra computational costs. In contrast, other methods require extra storage [30], or extra compu-tational cost [14]. However, the logit-based methods MSP and MaxLogit are not state-of-the-art (SOTA). Intuitively, the simple logit-based method could achieve comparable performance as other complex scoring methods, because logit contains high-level semantic information. We hypoth-esize some underlying reasons limit the performance.
To revitalize the simple logit-based method, we start the work by analyzing the reasons which cause the performance gap between MSP and MaxLogit. The gap may be due to
the softmax operation normalizing out much feature norm information of the logits. To delve into the effect of feature norm, we divide the logit into two parts: (1) the cosine sim-ilarity between the features and classifier; (2) the feature norm. We discard the classifier weight norm because the norm is identical after the model coverage [27]. We use the top value of the two as the OOD score, named MaxCosine and MaxNorm. Therefore, MaxLogit is a coupled form.
We find that MaxCosine outperforms MaxLogit with the same model and MaxNorm performs much worse than MaxLogit. Thus, MaxLogit (1) is encumbered by
MaxNorm, (2) suppresses the effectiveness of MaxCo-sine, and (3) restricts the flexibility to balance MaxCosine and MaxNorm. The three problems are the bottleneck of
MaxLogit. To tackle the problem, we propose Decoupling
MaxLogit (DML) for flexibility to balance MaxCosine and
MaxNorm. DML decouples the MaxCosine from the equal coefficient with MaxNorm by replacing it with a constant.
The decoupling method solves the second and third problems but still leaves the first problem unsolved. Al-though MaxNorm helps DML to outperform MaxCosine, the improvement is marginal due to the low performance of MaxNorm. Therefore, we study the role of model train-ing and show that a simple modification to standard train-ing could significantly boost MaxNorm and MaxCosine for
OOD detection. Specifically, a feature space with fewer hard samples benefits MaxCosine and a compact feature space benefits MaxNorm. Also, the normalized feature and classifier are the key to the success of the logit-based meth-ods. These findings are not discussed in prior works. We extend DML to DML+ based on the above new insights to further boost the DML performance as shown in Fig. 1.
We summarize our contributions as follows.
• To overcome the limitations of MaxLogit, we propose a post-hoc scoring method DML, which decouples
MaxLogit for flexibility to balance MaxCosine and
MaxNorm. DML outperforms MaxLogit and achieves comparable performance with SOTA methods.
• We offer new insights into the key components to make
MaxCosine, MaxNorm and DML effective, including replacing the standard linear classifier with a cosine classifier and different training losses. The findings are supported by empirical results and theoretical analysis.
We also prove that the findings could greatly boost the performance of existing OOD scoring methods.
• Based on the insights, we extend DML to DML+ which changes the standard training. Significant im-provements on CIFAR and ImageNet have shown its effectiveness. 2.