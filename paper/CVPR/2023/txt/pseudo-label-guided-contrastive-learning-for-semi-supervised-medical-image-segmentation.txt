Abstract
Although recent works in semi-supervised learning (SemiSL) have accomplished significant success in nat-ural image segmentation, the task of learning discrimi-native representations from limited annotations has been an open problem in medical images. Contrastive Learn-ing (CL) frameworks use the notion of similarity measure which is useful for classification problems, however, they fail to transfer these quality representations for accurate pixel-level segmentation. To this end, we propose a novel semi-supervised patch-based CL framework for medical im-age segmentation without using any explicit pretext task.
We harness the power of both CL and SemiSL, where the pseudo-labels generated from SemiSL aid CL by providing additional guidance, whereas discriminative class informa-tion learned in CL leads to accurate multi-class segmen-tation. Additionally, we formulate a novel loss that syn-ergistically encourages inter-class separability and intra-class compactness among the learned representations. A new inter-patch semantic disparity mapping using aver-age patch entropy is employed for a guided sampling of positives and negatives in the proposed CL framework.
Experimental analysis on three publicly available datasets of multiple modalities reveals the superiority of our pro-posed method as compared to the state-of-the-art methods.
Code is available at: GitHub. 1.

Introduction
Accurate segmentation of medical images provides salient and insightful information to clinicians for appro-priate diagnosis, disease progression, and proper treatment planning. With the recent emergence of neural networks, supervised deep learning approaches have achieved state-of-the-art performance in multiple medical image segmen-tation tasks [11, 36, 41]. This can be attributed to the avail-ability of large annotated datasets. But, obtaining pixel-wise annotations in a large scale is often time-consuming, requires expertise, and incurs a huge cost, thus methods al-leviating these requirements are highly expedient.
Semi-supervised learning (SemiSL) based methods are promising directions to this end, requiring a very small amount of annotations, and producing pseudo-labels for a large portion of unlabeled data, which are further utilized to train the segmentation network [32, 33]. In recent years, these methods have been widely recognized for their supe-rior performance in downstream tasks (like segmentation, object detection, etc.), not only in natural scene images but also in biomedical image analysis [3, 4, 64]. Traditional
SemiSL methods employ regression, pixel-wise cross en-tropy (CE), or mean squared error (MSE) loss terms or their variants. But, none of these losses imposes intra-class compactness and inter-class separability, restricting their full learning potential. Recent SemiSL methods in medi-cal vision employing self-ensembling strategy [14, 44] have received attention because of their state-of-the-art perfor-mance in segmentation tasks. However, they are designed for a single dataset, failing to generalize across domains.
Unsupervised domain adaptation (UDA) [18, 61] can be utilized to address this problem, e.g., Xie et al. [60] pro-posed an efficient UDA method with self-training strat-egy to unleash the learning potential. However, most of these methods heavily rely upon abundant source labels, hence producing substandard performance with limited la-bels in clinical deployment [71]. Representational learn-ing is another promising way to learn from limited anno-tations, where models trained for pretext tasks on large source domains can be transferred for downstream tasks in the target domain. Current advancements in represen-tational learning have been ascribed as the upturn of con-trastive learning (CL) [23], that aims to distinguish simi-lar samples (positive) from dissimilar ones (negative) re-garding a specified anchor point in a projected embedding space. This idea has resulted in substantial advancements in self-supervision paradigms by learning useful represen-tations from large-scale unlabeled data [9, 43, 57]. The fun-damental idea of CL is to pull the semantically similar sam-ples together and push the dissimilar ones apart in the em-bedding space. This is accomplished by suitably designing an objective function, also known as the Contrastive Loss function, which optimizes the mutual information amongst different data points. The learned information from the pre-text task can thereafter be transferred for downstream tasks such as classification [62], segmentation [53, 66], etc.
Despite their great success in recent years, CL frame-works are not devoid of problems, which broadly include: (a) sampling bias and aggravated class collision are re-ported in [15] because semantically similar instances are forcefully contrasted due to unguided selection of negative samples [9], causing substandard performance; (b) as sug-gested in [21], it is a common and desirable practice in CL to adapt a model trained for some pretext task on an exist-ing large-scale dataset of source domain (e.g., ImageNet) to a specific downstream task of the target domain. How-ever, significant domain shifts in heterogeneous datasets may often hurt the overall performance [73], especially in medical images; and (c) designing a suitable pretext task can be challenging, and often cannot be generalized across datasets [37]. The first of these problems can be addressed by having access to labeled samples. For instance, [27] shows that including labels significantly improves the clas-sification performance, but this is in a fully supervised set-ting. There have been recent attempts to partially address the last two problems, which are highlighted in section 2.
Our Proposal and Contribution
Taking motivation from these unsolved problems, we aim to leverage the potential of CL in the realm of SemiSL through several novel contributions:
• We propose a novel end-to-end segmentation paradigm by harnessing the power of both CL and SemiSL. In our case, the pseudo-labels generated in SemiSL aids
CL by providing an additional guidance to the metric learning strategy, whereas the important class discrim-inative feature learning in CL boosts the multi-class segmentation performance of SemiSL. Thus SemiSL aids CL and vice-versa in medical image segmenta-tion tasks.
• We introduce a novel Pseudo-label Guided Contrastive
Loss (PLGCL) which can mine class-discriminative features without any explicit training on pretext tasks, thereby demonstrating generalizability across multiple domains.
• We employ a patch-based CL framework, where the positive and negative patches are sampled from an entropy-based metric guided by the pseudo-labels ob-tained in the SemiSL setting. This prevents (class col-lision), i.e., forceful and unguided contrast of semanti-cally similar instances in CL.
• Upon the evaluation on three datasets from different domains, our method is proven to be effective, adding to its generalizability and robustness. 2.