Abstract
LiDAR mapping is important yet challenging in self-driving and mobile robotics. To tackle such a global point cloud registration problem, DeepMapping [1] converts the complex map estimation into a self-supervised training of simple deep networks. Despite its broad convergence range on small datasets, DeepMapping still cannot produce sat-isfactory results on large-scale datasets with thousands of frames. This is due to the lack of loop closures and ex-act cross-frame point correspondences, and the slow con-vergence of its global localization network. We propose
DeepMapping2 by adding two novel techniques to address these issues: (1) organization of training batch based on map topology from loop closing, and (2) self-supervised
*Equal contribution
†The corresponding author is Chen Feng cfeng@nyu.edu local-to-global point consistency loss leveraging pairwise registration. Our experiments and ablation studies on pub-lic datasets such as KITTI, NCLT, and Nebula demonstrate the effectiveness of our method. 1.

Introduction
Mapping is a fundamental ability for autonomous mo-bile agents.
It organizes an agent’s local sensor observa-tions into a map, i.e., a global spatial representation of the environment. A pre-built map is useful in robotics, self-driving, and augmented reality for agents to localize them-selves [2–6]. Various simultaneous localization and map-ping (SLAM) methods can create maps of new environ-ments from 2D and/or 3D sensors [7–13].
In particular,
LiDAR-based mapping is often adopted to build large-scale maps in self-driving and mobile robotics due to LiDAR’s direct and accurate 3D point cloud sensing capability.
Similar to visual SLAM, LiDAR SLAM methods typ-ically contain front-end and back-end modules [14–17].
The front-end module tracks sensor movements by Li-DAR/inertial/wheel odometry and provides constraints be-tween sequential frames of point clouds by either iterative closest point (ICP) or 3D feature detection and correspon-dence matching algorithms. The back-end uses those con-straints in a pose/pose-landmark graph optimization [18,19] to minimize the odometry drift, similar to the bundle adjust-ment in visual SLAM and Structure-from-Motion (SfM).
However, without accurate GNSS/IMU as odometry, large-scale LiDAR mapping results could be unsatisfactory (see Fig. 1), due to errors in LiDAR odometry and diffi-culties in correspondence matching and loop closing, es-pecially outdoors. To tackle these issues, researchers start to explore deep learning methods. Some of them focus on replacing sub-tasks in LiDAR mapping with deep net-works [20–23], following the common machine learning paradigm: train-then-test. Yet such methods could face generalization issues when the training dataset domain is different than the testing one.
Differently, DeepMapping [1] proposes a new paradigm: training-as-optimization for point cloud map-ping.
It encapsulates the global registration in a point-cloud-based PoseNet [24] (L-Net), and evaluates the map quality using another binary occupancy network (M-Net) with a binary cross-entropy (BCE) loss. This converts the continuous map optimization into a self-supervised training of binary classifications. Since no testing is needed, it does not face any generalization issues because mapping is done once training is finished.
However, despite its superior performance on small-scale datasets, we found DeepMapping often fails on large-scale datasets due to the following challenges: (1) No-explicit-loop-closure: DeepMapping gradually optimizes L-Net using frames in each mini-batch that are temporal neighbors, and only relies on M-Net to control the global map consistency. This is like incremental registra-tion that is doomed to drift when the number of frames is large. SLAM solves this by loop closing, which is not yet clear how to be incorporated into DeepMapping. (2) No-local-registration: Although previous works have shown local registration to be locally accurate [25–28],
DeepMapping only uses it in the ICP-based pose initializa-tion but not in the optimization. This is due to a common problem faced by all LiDAR registration methods, the lack of point correspondences in LiDAR point clouds: the same 3D point rarely appears again in another scan, because of the sparse sensor resolution and long-range sensing. (3) Slow-convergence-in-global-registration: L-Net re-gresses a single frame of point cloud into its global pose, which is supervised only by the M-Net and BCE loss.
Unlike pairwise registration, this global registration lacks enough inference cues to output correct poses, thus leading to slow convergence when the dataset is large.
We propose DeepMapping2 that is able to effectively optimize maps on large-scale LiDAR datasets. It extends
DeepMapping with two novel techniques. The first one ad-dresses challenge (1) by organizing data frames into train-ing batches based on map topology from loop closing. This allows a frame with its topological/spatial neighbors to be grouped into the same batch. We find this to be the best way of adding loop closing into DeepMapping which uses free-space inconsistencies via M-Net and BCE loss to gen-erate self-supervision, because such inconsistencies happen mostly between unregistered neighboring frames.
The second technique is a novel self-supervised local-to-global point consistency loss that leverages precomputed pairwise registration. For each point in a frame, we can compute this new consistency as the L2 distance between different versions of its global coordinate calculated using a neighboring frame’s global pose and the relative pose be-tween the two frames from the pairwise registration. This allows us to address challenge (2) without relying on point correspondences between different frames: even if two neighboring frames do not have enough common points as correspondences for pairwise local registration, we can still incorporate the local registration’s results during training. It also addresses the challenge (3) because now L-Net is su-pervised by stronger gradients from not only the BCE loss, but also the new consistency loss.
Our contributions are summarized as follows:
• Our DeepMapping2 is the first self-supervised large-scale LiDAR map optimization method as far as we know, and this generic method achieves state-of-the-art mapping results on various indoor/outdoor public datasets, including KITTI [29], NCLT [30], and the challenging underground dataset Nebula [31].
• Our analysis reveals why DeepMapping fails to scale up and leads to the two novel techniques–batch orga-nization and local-to-global point consistency loss–to incorporate loop closing and local registration in the
DeepMapping framework. Their necessity and effec-tiveness are further validated in our ablation study. 2.