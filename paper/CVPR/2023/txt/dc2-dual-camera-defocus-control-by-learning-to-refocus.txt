Abstract 1.

Introduction
Smartphone cameras today are increasingly approach-ing the versatility and quality of professional cameras through a combination of hardware and software advance-ments. However, fixed aperture remains a key limitation, preventing users from controlling the depth of field (DoF) of captured images. At the same time, many smartphones now have multiple cameras with different fixed apertures -specifically, an ultra-wide camera with wider field of view and deeper DoF and a higher resolution primary camera with shallower DoF. In this work, we propose DC2, a system for defocus control for synthetically varying camera aper-ture, focus distance and arbitrary defocus effects by fusing information from such a dual-camera system. Our key in-sight is to leverage real-world smartphone camera dataset by using image refocus as a proxy task for learning to con-trol defocus. Quantitative and qualitative evaluations on real-world data demonstrate our system’s efficacy where we outperform state-of-the-art on defocus deblurring, bokeh rendering, and image refocus. Finally, we demonstrate cre-ative post-capture defocus control enabled by our method, including tilt-shift and content-based defocus effects.
Smartphone cameras are the most common modality for capturing photographs today [13]. Recent advance-ments in computational photography such as burst photog-raphy [18], synthetic bokeh via portrait mode [48], super-resolution [55], and more have been highly effective at clos-ing the gap between professional DSLR and smartphone photography. However, a key limitation for smartphone cameras today is depth-of-field (DoF) control, i.e., control-ling parts of the scene that appear in (and out of) focus. This is primarily an artifact of their relatively simple optics and imaging systems (e.g., fixed aperture, smaller imaging sen-sors, etc.). To bridge the gap, modern smartphones tend to computationally process the images for further post-capture enhancements such as synthesizing shallow DoF (e.g., por-trait mode [37, 48]). However, this strategy alone does not allow for DoF extension or post-capture refocus.
In this work, we propose Dual-Camera Defocus Control (DC2), a framework that can provide post-capture defocus control leveraging multi-camera systems prevalent in smartphones today. Figure 1 shows example outputs from our frame-work for various post-capture DoF variations. In particular,
our method is controllable and enables image refocus, DoF extension, and reduction.
Post-capture defocus control is a compound process that involves removing defocus blur (i.e., defocus deblurring) and then adding defocus blur selectively based on the scene depth. Defocus deblurring [2, 4, 5, 23, 27, 31, 35, 39, 40, 42, 43, 59, 60], itself, is challenging due to the nature of the defocus point spread function (PSF) formation which can be spatially varying in size and shape [28, 46]. The PSF’s shape and size are not only depth dependent, but also vary based on aperture size, focal length, focus distance, optical aberration, and radial distortion. Synthesizing and adding defocus blur [9, 17, 21, 33, 37, 38, 48, 57, 58] is also diffi-cult and requires an accurate depth map along with an all-in-focus image. Additionally, it requires realistic blur for-mation and blending around the object’s boundaries. Most prior work has addressed defocus deblurring and synthesiz-ing defocus blur as two isolated tasks. There has been less work on post-capture defocus control (e.g., image refocus-ing [22, 34, 41]). The image refocusing literature [22, 34] has focused on light-field data captured with specialized hardware. While the results in [51, 52] are the state-of-the-art, light-field data is not representative of smartphone and
DSLR cameras by lacking realistic defocus blur and spatial resolution [12].
Most modern smartphones are now equipped with two or more rear cameras to assist with computational imaging.
The primary camera – often referred to as the wide camera or W – has a higher resolution sensor, a higher focal length lens but a relatively shallower DoF. Alongside W is the ultra-wide (UW) camera, often with a lower resolution sen-sor, lower focal length (wider field of view) and wider DoF.
Our critical insight is to leverage this unique camera setup and cross-camera DoF variations to design a system for re-alistic post-capture defocus control. Differently from prior work, we tackle the problem of defocus control (deblurring and adding blur) and propose using real-world data easily captured using a smartphone device to train our learning-based system. Our primary contributions in this work are as follows:
• We propose a learning-based system for defocus con-trol on dual-camera smartphones. This subsumes the tasks of defocus deblurring, depth-based blur ren-dering, image refocusing and enables arbitrary post-capture defocus control.
• In the absence of defocus control ground-truth, we en-able training our system on real-world data captured from a smartphone device. To achieve that, we re-formulate the problem of defocus control as learning to refocus and define a novel training strategy to serve the purpose.
• We collect a dataset of diverse scenes with focus stack data at controlled lens positions the W camera and ac-companying UW camera images for training our sys-tem. Additionally, we compute all-in-focus images using the focus stacks to quantitatively evaluate im-age refocus, defocus deblurring and depth-based blur-ring tasks and demonstrate superior performance com-pared to state-of-the-art (SoTA) methods across all three tasks.
• Finally, we demonstrate creative defocus control ef-fects enabled by our system, including tilt-shift and content-based defocus. 2.