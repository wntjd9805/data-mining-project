Abstract
In this study, we dive deep into the inconsistency of pseudo targets in semi-supervised object detection (SSOD).
Our core observation is that the oscillating pseudo-targets undermine the training of an accurate detector. It injects noise into the student’s training, leading to severe overfit-ting problems. Therefore, we propose a systematic solu-tion, termed Consistent-Teacher , to reduce the in-consistency. First, adaptive anchor assignment (ASA) sub-stitutes the static IoU-based strategy, which enables the student network to be resistant to noisy pseudo-bounding boxes. Then we calibrate the subtask predictions by de-signing a 3D feature alignment module (FAM-3D). It allows each classification feature to adaptively query the optimal feature vector for the regression task at arbitrary scales and locations. Lastly, a Gaussian Mixture Model (GMM) dynamically revises the score threshold of pseudo-bboxes, which stabilizes the number of ground truths at an early stage and remedies the unreliable supervision signal dur-ing training. Consistent-Teacher provides strong re-sults on a large range of SSOD evaluations.
It achieves 40.0 mAP with ResNet-50 backbone given only 10% of an-notated MS-COCO data, which surpasses previous base-lines using pseudo labels by around 3 mAP. When trained on fully annotated MS-COCO with additional unlabeled data, the performance further increases to 47.7 mAP. Our code is available at https://github.com/Adamdad/
ConsistentTeacher. 1.

Introduction
The goal of semi-supervised object detection (SSOD) [3, 5, 12, 12, 13, 17, 24, 25, 30, 36, 43, 44] is to facilitate the training of object detectors with the help of a large amount
*Equally contributed.
‡Work done during internship at SenseTime.
†Work done during internship at Shanghai AI Laboratory. of unlabeled data. The common practice is first to train a teacher model on the labeled data and then generate pseudo labels and boxes on unlabeled sets, which act as the ground truth (GT) for the student model. Student detectors, on the other hand, are anticipated to make consistent predic-tions regardless of network stochasticity [35] or data aug-mentation [12, 30].
In addition, to improve pseudo-label quality, the teacher model is updated as a moving aver-age [24, 36, 44] of the student parameters.
In this study, we point out that the performance of semi-supervised detectors is still largely hindered by the incon-sistency in pseudo-targets. Inconsistency means that the pseudo boxes may be highly inaccurate and vary greatly at different stages of training. As a consequence, inconsistent oscillating bounding boxes (bbox) bias SSOD predictions with accumulated error. Different from semi-supervised classification, SSOD has one extra step of assigning a set of pseudo-bboxes to each RoI/anchor as dense supervision.
Common two-stage [24, 30, 36] and single-stage [4, 42]
SSOD networks adopt static criteria for anchor assignment, e.g. IoU score or centerness. It is observed that the static assignment is sensitive to noise in the bounding boxes pre-dicted by the teacher, as a small perturbation in the pseudo-bboxes might greatly affect the assignment results. It thus leads to severe overfitting on unlabeled images.
To verify this phenomenon, we train a single-stage de-tector with standard IoU-based assignment on MS-COCO (1), a small change in the 10% data. As shown in Fig. teacher’s output results in strong noise in the boundaries of pseudo-bboxes, causing erroneous targets to be associ-ated with nearby objects under static IoU-based assignment.
This is because some inactivated anchors are falsely as-signed positive in the student network. Consequently, the network overfits as it produces inconsistent labels for neigh-boring objects. The overfitting is also observed in the clas-sification loss curve on unlabeled images1. 1All GT bboxes on unlabeled data are only used to calculate the loss value but not for updating the parameters.
Figure 1. Illustration of inconsistency problem in SSOD on COCO 10 % evaluation. (Left) We compare the training losses between the
Mean-Teacher and our Consistent-Teacher . In Mean-Teacher, inconsistent pseudo targets lead to overfitting on the classification branch, while regression losses become difficult to converge. In contrast, our approach sets consistent optimization objectives for the stu-dents, effectively balancing the two tasks and preventing overfitting. (Right) Snapshots for the dynamics of pseudo labels and assignment.
The Green and Red bboxes refer to the ground-truth and pseudo bbox, respectively, for the polar bear. Red dots are the assigned anchor boxes for the pseudo label. The heatmap indicates the dense confidence score predicted by the teacher (brighter the larger). A nearby board is finally misclassified as a polar bear in the baseline while our adaptive assignment prevents overfitting.
Through dedicated investigation, We find that one im-portant factor that leads to the drifting pseudo-label is the mismatch between classification and regression tasks. Typ-ically, only the classification score is used to filter pseudo-bboxes in SSOD. However, confidence does not always in-dicate the quality of the bbox [36]. Two anchors with sim-ilar scores, as a result, can have significantly different pre-dicted pseudo-bboxes, leading to more false predictions and label drifting. Such phenomenon is illustrated in Fig. (1) with the varying pseudo-bboxes of the MeanTeacher around
T = 104K. Therefore, the mismatch between the quality of a bbox and its confidence score would result in noisy pseudo-bboxes, which in turn exacerbates the label drifting.
The widely-employed hard threshold scheme also causes threshold inconsistencies in pseudo labels. Traditional
SSOD methods [24,30,36] utilize a static threshold on con-fidence score for student training. However, the thresh-old serves as a hyper-parameter, which not only needs to be carefully tuned but should also be dynamically adjusted in accordance with the model’s capability at different time steps. In the Mean-Teacher [32] paradigm, the number of pseudo-bboxes may increase from too few to too many un-der a hard threshold scheme, which incurs inefficient and biased supervision for the student.
Therefore, we propose Consistent-Teacher in this study to address the inconsistency issues. First, we find that a simple replacement of the static IoU-based anchor assign-ment by cost-aware adaptive sample assignment (ASA) [10, 11] greatly alleviates the effect of inconsistency in dense pseudo-targets. During each training step, we calculate the matching cost between each pseudo-bbox with the student network’s predictions. Only feature points with the lowest costs are assigned as positive. It reduces the mismatch be-tween the teacher’s high-response features and the student’s assigned positive pseudo targets, which inhibits overfitting.
Then, we calibrate the classification and regression tasks so that the teacher’s classification confidence provides a better proxy of the bbox quality.
It produces consistent pseudo-bboxes for anchors of similar confidence scores, and thus the oscillation in pseudo-bbox boundaries is re-duced. Inspired by TOOD [9], we propose a 3-D feature alignment module (FAM-3D) that allows classification fea-tures to sense and adopt the best feature in its neighbor-hood for regression. Different from the single scale search-ing, FAM-3D reorders the features pyramid for regression across scales as well. In this way, a unified confidence score accurately measures the quality of classification and regres-sion with the improved alignment module and ultimately brings consistent pseudo-targets for the student in SSOD.
As for the threshold inconsistency in pseudo-bboxes, we apply Gaussian Mixture Model (GMM) to generate an adaptive threshold for each category during training. We consider the confidence scores of each class as the weighted sum of positive and negative distributions and predict the parameters of each Gaussian with maximum likelihood es-timation. It is expected that the model will be able to adap-tively infer the optimal threshold at different training steps so as to stabilize the number of positive samples.
The proposed Consistent-Teacher greatly sur-passes current SSOD methods. Our approach reaches 40.0 mAP with 10% of labeled data on MS-COCO, which is ˜3 mAP ahead of the state-of-the-art [43]. When using the 100% labels together with extra unlabeled MS-COCO data, the performance is further boosted to 47.7 mAP. The effec-tiveness of Consistent-Teacher is also testified on other ratios of labeled data and on other datasets as well.
Concretely, the paper contributes in the following aspects. and negative ones by fitting the anchor scores distribution.
OTA [10] treats the label assignment as an optimal transport problem so that the assignment cost is minimized.
Although the existing assignment methods are effective, they are limited to fully-supervised settings. In our work, we observe that using static assignment in SSOD induces server inconsistency issues and accumulates errors. We show that a simple cost-ware assignment stabilizes the label noise and significantly improves the performance of SSOD. 3. Consistent-Teacher
• We provide the first in-depth investigation of the incon-sistent target problem in SSOD, which incurs severe overfitting issues.
• We introduce an adaptive sample assignment to sta-bilize the matching between noisy pseudo-bboxes and anchors, leading to robust training for the student.
• We develop a 3-D feature alignment module (FAM-3D) to calibrate the classification confidence and regression quality, which improves the quality of pseudo-bboxes.
• We adopt GMM to flexibly determine the threshold for each class during training. The adaptive threshold evolves through time and reduces the threshold incon-sistencies for SSOD.
• Consistent-Teacher achieves compelling im-provement on a wide range of evaluations and serves as a new solid baseline for SSOD. 2.