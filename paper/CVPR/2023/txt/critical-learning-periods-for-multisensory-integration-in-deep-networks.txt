Abstract
We show that the ability of a neural network to integrate information from diverse sources hinges critically on be-ing exposed to properly correlated signals during the early
Interfering with the learning process phases of training. during this initial stage can permanently impair the devel-opment of a skill, both in artiﬁcial and biological systems where the phenomenon is known as a critical learning pe-riod. We show that critical periods arise from the complex and unstable early transient dynamics, which are decisive of ﬁnal performance of the trained system and their learned representations. This evidence challenges the view, engen-dered by analysis of wide and shallow networks, that early learning dynamics of neural networks are simple, akin to those of a linear model. Indeed, we show that even deep linear networks exhibit critical learning periods for multi-source integration, while shallow networks do not. To bet-ter understand how the internal representations change ac-cording to disturbances or sensory deﬁcits, we introduce a new measure of source sensitivity, which allows us to track the inhibition and integration of sources during training.
Our analysis of inhibition suggests cross-source reconstruc-tion as a natural auxiliary training objective, and indeed we show that architectures trained with cross-sensor recon-struction objectives are remarkably more resilient to crit-ical periods. Our ﬁndings suggest that the recent success in self-supervised multi-modal training compared to previ-ous supervised efforts may be in part due to more robust learning dynamics and not solely due to better architectures and/or more data. 1.

Introduction
Learning generally beneﬁts from exposure to diverse sources of information, including different sensory modal-ities, views, or features. Multiple sources can be more in-formative than the sum of their parts. For instance, both views of a random-dot stereogram are needed to extract the
*Work conducted during an internship at AWS AI Labs. synergistic information, which is absent in each individual view [17]. More generally, multiple sources can help iden-tify latent common factors of variation relevant to the task, and separate them from source-speciﬁc nuisance variability, as done in contrastive learning.
Much information fusion work in Deep Learning focuses on the design of the architecture, as different sources may require different architectural biases to be efﬁciently en-coded. We instead focus on the learning dynamics, since effective fusion of different sources relies on complex phe-nomena beginning during the early epochs of training. In fact, even slight interference with the learning process dur-ing this critical period can permanently damage a network’s ability to harvest synergistic information. Even in animals, which excel at multi-sensor fusion, a temporary deﬁcit in one source during early development can permanently im-pair the learning process: congenital strabismus in humans can cause permanent loss of stereopsis if not corrected suf-ﬁciently early; similarly, visual/auditory misalignment can impair the ability of barn owls to localize prey [18]. In artiﬁ-cial networks, the challenge of integrating different sources has been noted in visual question answering (VQA), where the model often resorts to encoding less rich but more read-ily accessible textual information [2, 6], ignoring the visual modality, or in audio-visual processing, where acoustic in-formation is often washed out by visual information [32].
Such failures are commonly attributed to the mismatch in learning speed between sources, or their “information asymmetry” for the task. It has also been suggested, based on limiting analysis for wide networks, that the initial dy-namics of DNNs are very simple [16], seemingly in contrast with evidence from biology. In this paper, we instead argue that the early learning dynamics of information fusion in deep networks are both highly complex and brittle, to the point of exhibiting critical learning periods similar to bio-logical systems.
In Sect. 2, we show that shallow networks do not exhibit critical periods when learning to fuse diverse sources of in-formation, but deep networks do. Even though, unlike an-imals, artiﬁcial networks do not age, their learning success is still decided during the early phases of training. The ex-Figure 1. Decomposition of information between different modalities. Two modalities can have unique information, common infor-mation (denoted by the overlap in the venn-diagram), or synergistic information (denoted by the additional ellipse in the right panel).
Task-relevant information (shown in red) can be distributed in a variety of ways across the different modalities. Task-relevant information can be mostly present in Modality A (left), shared between modalities (center-left), or could require unique (center-right) or synergistic information from both modalities (right). istence of critical learning periods for information fusion is not an artifact of annealing the learning rate or other details of the optimizer and the architecture. In fact, we show that critical periods for fusing information are present even in a simple deep linear network. This contradicts the idea that deep networks exhibit trivial early dynamics [16, 23]. We provide an interpretation for critical periods in linear net-works in terms of mutual inhibition/reinforcement between sources, manifest through sharp transitions in the learning dynamics, which in turn are related to the intrinsic structure of the underlying data distribution.
In Sect. 3, we introduce a metric called “Relative Source
Variance” to quantify the dependence of units in a repre-sentation to individual sources, allowing us to better under-stand inhibition and fusion between sources. Through it, in
Sect. 4, we show that temporarily reducing the information in one source, or breaking the correlation between sources, can permanently change the overall amount of information in the learned representation. Moreover, even when down-stream performance is not signiﬁcantly affected, such tem-porary changes result in units that are highly polarized and process only information from one source or the other. Sur-prisingly, we found that the ﬁnal representations in our arti-ﬁcial networks that were exposed to a temporary deﬁcit mir-rored single-unit animal representations exposed to analo-gous deﬁcits (Fig. 4, Fig. 6).
We hypothesize that features inhibit each other because they are competing to solve the task. But if the competitive effect is reduced, such as through an auxiliary cross-source reconstruction task, the different sources can interact syn-ergistically. This supports cross-modal reconstruction as a practical self-supervision criterion. In Sect. 4.4, we show that indeed auxiliary cross-source reconstruction can stabi-lize the learning dynamics and prevent critical periods. This lends an alternate interpretation for the recent achievements in multi-modal learning as due to the improved stability of the early learning dynamics due to auxiliary cross-modal reconstruction tasks, rather than to the design of the archi-tecture.
Empirically, we show the existence of critical learning periods for multi-source integration using state-of-the-art architectures (Sect. 4.3-4.4). To isolate different factors that may contribute to low-performance on multi-modal tasks (mismatched training dynamics, different informativeness), we focus on tasks where the sources of information are sym-metric and homogeneous, in particular stereo and multi-view imagery. Even in this highly controlled setting, we ob-serve the effect of critical periods both in downstream per-formance and/or in unit polarization. Our analysis suggests that pre-training on one modality, for instance text, and then adding additional pre-trained backbones, for instance visual and acoustic, as advocated in recent trends with Founda-tion Models, yields representations that fail to encode syn-ergistic information. Instead, training should be performed across modalities at the outset. Our work also suggests that asymptotic analysis is irrelevant for deep network fusion, as their fate is sealed during the initial transient learning. Also, conclusions drawn from wide and shallow networks do not transfer to deep networks in use in practice. 1.1.