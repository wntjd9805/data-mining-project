Abstract
The task of Visual Question Answering (VQA) is known to be plagued by the issue of VQA models exploiting bi-ases within the dataset to make its final prediction. Various previous ensemble based debiasing methods have been pro-posed where an additional model is purposefully trained to be biased in order to train a robust target model. How-ever, these methods compute the bias for a model simply from the label statistics of the training data or from single modal branches. In this work, in order to better learn the bias a target VQA model suffers from, we propose a gener-ative method to train the bias model directly from the target model, called GenB. In particular, GenB employs a gener-ative network to learn the bias in the target model through a combination of the adversarial objective and knowledge distillation. We then debias our target model with GenB as a bias model, and show through extensive experiments the effects of our method on various VQA bias datasets includ-ing VQA-CP2, VQA-CP1, GQA-OOD, and VQA-CE, and show state-of-the-art results with the LXMERT architecture on VQA-CP2. 1.

Introduction
Visual Question Answering (VQA) [5] is a challenging multi-modal task that requires a model to correctly under-stand and predict an answer given an input pair of image and question. Various studies have shown that VQA is prone to biases within the dataset and tend to rely heavily on lan-guage biases that exists within the dataset [2, 17, 51], and
VQA models tend to predict similar answers only depend-ing on the question regardless of the image.
In response to this, recent works have developed various bias reduction techniques, and recent methods have exploited ensemble based debiasing methods [7, 13, 19, 41] extensively.
Among ensemble based methods, additional models are introduced to concurrently learn biases that might exist within each modality or dataset. For example, in works such as [7, 19], the Question-Answer model is utilized to determine the language prior biases that exist when a model is asked to give an answer based solely off of the question.
Figure 1. Given a Question Type (“What color is...”), we show all of the averaged answers within the training dataset. The answer computed from the entire training dataset is the known dataset label average or dataset bias as in [13, 19]. We see that the averaged model predictions of the Question-Answer Model and
Visual-Question-Answer Model are significantly different.
This Question-Answer model is then utilized to train a ro-bust “target” model, which is used for inference. The key purpose of an ensemble “bias” model is to capture the biases that are formed with its given inputs (i.e., language prior bi-ases from the Question-Answer model). In doing so, if this model is able to represent the bias well, this bias model can be used to teach the target model to avoid such biased an-swers. In other words, the better the bias model can learn the biases, the better the target model can avoid such biases.
Existing ensemble based methods either use pre-computed label statistics of training data (GGE-D [19] and
LMH [13]), or single modal branches that compute the an-swer from either the question or image [7,13,19,37]. How-ever, we conjecture that there is a limit to the bias repre-sentation that can be obtained from such methods, as the model’s representative capacity is limited by its inputs. In addition, pre-computed label statistics represents only part of the bias [19]. As shown in Fig. 1, given a question type, the pre-computed label statistics (or known dataset bias) are noticeably different to the predictions of a model trained with the question or with the image and question. This dis-crepancy signifies that there is a part of the bias that we can-not fully model simply with the previous methods. There-fore, we propose a novel stochastic bias model that learns
the bias directly from the target model.
More specifically, to directly learn the bias distribution of the target model, we model the bias model as a Gen-erative Adversarial Network (GAN) [16] to stochastically mimic the target model’s answer distribution given the same question input by introducing a random noise vector. As seen through literature, most biases are held within the question [2], so we use questions as the main bias modal-ity. To further enforce this, we utilize knowledge distil-lation [20] on top of adversarial training to force the bias model to be as close as possible to the target model, so that the target model learns from harder negative supervi-sion from the bias model. Finally, with our generative bias model, we then use our modified debiasing loss function to train our target model. Our final bias model is able to train the target model that outperforms previous uni-modal and multi-modal ensemble based debiasing methods by a large margin. To the best of our knowledge, we are the first to train the bias model by directly leveraging the behavior of the target model using a generative model for VQA.
To show the efficacy and robustness of our method, we perform extensive experiments on commonly used robust-ness testing VQA datasets and various different VQA ar-chitectures. Our method show the state-of-the-art results on all settings without the use of external human annotations or dataset reshuffling methods.
Our contributions are as follows:
• We propose a novel bias model for ensemble based debiasing for VQA by directly leveraging the target model that we name GenB.
• In order to effectively train GenB, we employ a Gener-ative Adversarial Network and knowledge distillation loss to capture both the dataset distribution bias and the bias from the target model.
• We achieve state-of-the-art performance on VQA-CP2, VQA-CP1 as well as the more challenging GQA-OOD dataset and VQA-CE using the simple UpDn baseline without extra annotations or dataset reshuf-fling and state-of-the-art VQA-CP2 peformance on the
LXMERT backbone. 2.