Abstract
Vision-language models (VLMs) can effectively transfer to various vision tasks via prompt learning. Real-world sce-narios often require adapting a model to multiple similar yet distinct tasks. Existing methods focus on learning a specific prompt for each task, limiting the ability to exploit poten-tially shared information from other tasks. Naively training a task-shared prompt using a combination of all tasks ig-nores fine-grained task correlations. Significant discrepan-cies across tasks could cause negative transferring. Consid-ering this, we present Hierarchical Prompt (HiPro) learn-ing, a simple and effective method for jointly adapting a pre-trained VLM to multiple downstream tasks. Our method quantifies inter-task affinity and subsequently constructs a hierarchical task tree. Task-shared prompts learned by in-ternal nodes explore the information within the correspond-ing task group, while task-individual prompts learned by leaf nodes obtain fine-grained information targeted at each task. The combination of hierarchical prompts provides high-quality content of different granularity. We evaluate
HiPro on four multi-task learning datasets. The results demonstrate the effectiveness of our method. 1.

Introduction
Vision-language pre-training [23, 34, 49, 71, 74] has re-cently shown great potential to leverage human language for addressing a wide range of downstream recognition tasks. Vision-language models (VLMs), e.g., CLIP [49] and ALIGN [23], align embeddings of images and texts from massive web data, encouraging the matching image-text pair to be similar and pushing away the unmatched pair [6, 19]. During inference, the task-relevant content in text modality can be provided to query the latent knowledge of the pre-trained VLMs for facilitating visual recognition.
*Equal contribution.
†Corresponding author. (a) Train loss (b) Test error
Figure 1. Task-shared prompt vs. task-individual prompt on multi-task learning. We visualize (a) train loss and (b) test er-ror surface [15] for classifier weights (wrand, wind, and wshr), which synthesized from the random initialization prompt, task-individual prompt, and task-shared prompt, respectively, on one of the target tasks (i.e., the Art task of the Office-Home dataset [65]).
The task-individual prompt is only trained on this task. The task-shared prompt is trained on the combination of all tasks. The av-erage weights (wavg= 1 2 (wshr+wind)) can perform well to test samples. More details refer to the supplementary materials.
The provided task-relevant texts, often constructed by the prompt template and category words, can significantly influence the recognition performance. Prompt engineer-ing [23, 49], i.e., manually designing prompts, is a straight-forward way to obtain meaningful prompts for adapting
VLMs. However, it inevitably introduces artificial bias and relies on time-consuming attempts [49]. Recent advances on prompt learning [79, 80] show an alternative way, which
Figure 2. The benefits of prompt learning with multiple tasks. Note that DTD [9] dataset and EuroSAT [45] dataset employ the same task-shared prompt. Task-individual prompt and task-shared prompt can represent different contents of recognition tasks. Ensembling their zero-shot classifiers can improve performance. aims to learn the appropriate soft prompt in a data-driven manner on each downstream task. With few training data, prompt learning has shown considerable improvement com-pared with the hand-crafted prompt.
Despite substantial progress, existing approaches [79– 81] still focus on adapting VLMs to the individual task.
However, challenges in realistic situations demand adapting a model to several similar but different tasks, also known as the problem of multi-task learning [20, 75]. More im-portantly, current methods learn the specific prompt corre-sponding to each task, which can not leverage information in other tasks to benefit individual tasks. Actually, the trans-ferred prompt can be reused for similar tasks. For exam-ple, “a photo of a {class}.” is a general prompt for most recognition tasks. Specifically, as shown in Figure 2, for two distinct tasks, i.e., texture images and satellite images, a well-designed prompt can leverage the potential connec-tions across them.
This paper explores how to simultaneously adapt a pre-trained VLM to multiple target tasks through prompting.
A straightforward way is to learn the same prompt for all tasks. However, this na¨ıve approach ignores the charac-teristics of each task and fails to achieve the optimum on each task. Nevertheless, we found that the task-shared prompt can significantly complement the prompt designed (or learned) individually for each task. As shown in Fig-ure 2, the task-individual (hand-crafted) prompt captures the fine-grained content of each task. The task-shared (hand-crafted) prompt represents the general content across tasks. The combination of task-shared and task-individual prompts can embrace both general and fine-grained content to enhance recognition.
Another perspective is provided for an in-depth explana-tion. In Figure 1a, we see that, the classifier weights synthe-sized from the task-individual prompt (trained on the indi-vidual target task) have lower training loss than the weights from the task-shared prompt (trained on the combination of all tasks). However, the performance of task-individual prompt on the test set is poor (Figure 1b), which implies that the task-individual prompt has the risk of over-fitting.
Meanwhile, the task-shared prompt, generalizing on various tasks, can be considered as a regularization to avoid over-fitting. Averaging weights from the task-shared prompt and the task-individual prompt can improve the performance on test data (Figure 1b).
Although similar tasks can facilitate each other by shar-ing knowledge, we can not assume all the offered tasks can benefit from training together. Significant discrepancies across tasks could lead to poor performance, also known as negative-transfer [73]. On the other hand, even for the ideal case, i.e., there exists the same beneficial prompt across all tasks, only learning the global (coarse-grained) task-shared prompt neglects the information transferred within some fine-grained task groups.
To address this problem, we present Hierarchical Prompt (HiPro) learning to capture multi-grained shared informa-tion while mitigating negative transfer between dissimilar tasks. Our HiPro constructs a hierarchical task tree by agglomerative hierarchical clustering based on inter-task affinity. Specifically, the internal node of the tree repre-sents a task group containing a cluster of similar tasks (at descendant leaves). Meanwhile, dissimilar tasks would be divided into different sub-trees, mitigating conflict. For each node, HiPro learns a corresponding prompt to cap-ture the general information of the fine-grained task group.
Our HiPro learns not only task-individual prompts (for leaf nodes) but also multi-grained task-share prompts (for non-leaf nodes). For inference, HiPro combines various weights generated from learned prompts, leveraging the information in all tasks to improve the performance of the individual task.
Comprehensive experiments are constructed to validate the effectiveness of our method. HiPro works well on a large-scale multi-task learning benchmark consisting of di-verse visual recognition tasks. Compared with the existing prompt learning methods [40,79,80], HiPro has a significant improvement demonstrating the benefit of learning prompts with multiple tasks. Additional visualizations are also pro-vided for analysis.
2.