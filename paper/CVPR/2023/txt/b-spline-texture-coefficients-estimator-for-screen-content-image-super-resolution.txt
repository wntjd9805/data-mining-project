Abstract
Screen content images (SCIs) include many informative components, e.g., texts and graphics. Such content creates sharp edges or homogeneous areas, making a pixel distribu-tion of SCI different from the natural image. Therefore, we need to properly handle the edges and textures to minimize information distortion of the contents when a display de-vice’s resolution differs from SCIs. To achieve this goal, we propose an implicit neural representation using B-splines for screen content image super-resolution (SCI SR) with ar-bitrary scales. Our method extracts scaling, translating, and smoothing parameters of B-splines. The followed multi-layer perceptron (MLP) uses the estimated B-splines to re-cover high-resolution SCI. Our network outperforms both a transformer-based reconstruction and an implicit Fourier representation method in almost upscaling factor, thanks to the positive constraint and compact support of the B-spline basis. Moreover, our SR results are recognized as cor-rect text letters with the highest confidence by a pre-trained scene text recognition network. Source code is available at https://github.com/ByeongHyunPak/btc. 1.

Introduction
With the rapid development of multimedia applications, screen content images (SCIs) have been common in peo-ple’s daily life. Many users interact with SCIs through various display terminals, so resolution mismatch between a display device and SCIs occurs frequently.
In this re-gard, we need to consider a flexible reconstruction at ar-bitrary magnification from low-resolution (LR) SCI to its high-resolution (HR). As in Figs. 1a and 1b, SCI has dis-continuous tone contents, whereas natural image (NI) has smooth and continuous textures. Such characteristics are observed as a Gaussian distribution in the naturalness value of NIs [25] and sharp fluctuations in the naturalness value
*Equal contribution.
†Corresponding author. (a) Screen content image (b) Natural image (c) Naturalness value distributions for 500 images per each class
Figure 1. Comparison on naturalness value distribution [25] between screen content images and natural images. of SCIs in Fig. 1c. This observation leads to a screen con-tent image super-resolution (SCI SR) method considering such distributional properties. However, most SR meth-ods [4, 5, 8–10, 28, 29] are applied to NIs.
Recently, Yang et al. proposed a novel SCI SR method based on a transformer, implicit transformer super-resolution network (ITSRN) [26]. Since ITSRN evalu-ates each pixel value by a point-to-point implicit function through a transformer architecture, it outperforms CNN-based methods [28, 29]. However, even though ITSRN rep-resents SCI’s characters (e.g., sharp edges or homogeneous areas) continuously, it has a large model size leading to in-efficient memory consumption and slow inference time.
Meanwhile, Chen et al. first introduced implicit neu-ral representation (INR) to single image super-resolution (SISR) [4]. The implicit neural function enables arbitrary scale super-resolution by jointly combining the continuous query points and the encoded feature of the input LR image.
Nevertheless, such implicit neural function, implemented with a multi-layer perceptron (MLP), is biased to learn the low-frequency components, called spectral bias [15].
Lee and Jin suggested the local texture estimator (LTE) upon INR to overcome the above problem [8]. LTE es-timates the frequencies and corresponding amplitude fea-tures from the input LR image and feeds them into an MLP with the Fourier representation. Here, projecting input into a high-dimensional space with the sinusoids in Fourier rep-resentation allows the implicit neural function to learn high-frequency details. However, since LTE expresses a signal with a finite sum of sinusoids, it has a risk for the recon-structed values to under/overshoot at the discontinuities of
SCIs, called the Gibbs phenomenon. This phenomenon of-ten produces incorrect information about SCIs. Thus, we need to restore HR SCIs with fewer parameters, fewer com-putation costs, and less distortion of contents.
In this paper, we propose a B-spline Texture Coeffi-cients estimator (BTC) utilizing INR to represent SCIs continuously. BTC predicts scaling (coefficients), trans-lating (knots), and smoothing (dilations) parameters of B-splines from the LR image. Then, inspired by Lee and
Jin [8], we project the query point’s coordinate into the high-dimensional space with 2D B-spline representations and feed them into MLP. Since the B-spline basis has a posi-tive constraint and compact support, BTC preserves discon-tinuities well without under/overshooting.
Our main contributions are: (I) We propose a B-spline
Texture Coefficients estimator (BTC), which estimates B-spline features (i.e., coefficients, knots, and dilations) for
SCI SR. (II) With a 2D B-spline representation, we achieve better performances with fewer parameters and less mem-ory consumption. (III) We demonstrate that B-spline rep-resentation is robust to over/undershooting aliasing when reconstructing HR SCIs, owing to positive constraint and compact support of the B-spline basis function. 2.