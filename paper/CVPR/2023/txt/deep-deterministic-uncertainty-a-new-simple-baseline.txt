Abstract
Reliable uncertainty from deterministic single-forward pass models is sought after because conventional methods of uncertainty quantiﬁcation are computationally expensive.
We take two complex single-forward-pass uncertainty ap-proaches, DUQ and SNGP, and examine whether they mainly rely on a well-regularized feature space. Crucially, without using their more complex methods for estimating uncertainty, we ﬁnd that a single softmax neural net with such a reg-ularized feature-space, achieved via residual connections and spectral normalization, outperforms DUQ and SNGP’s epistemic uncertainty predictions using simple Gaussian Dis-criminant Analysis post-training as a separate feature-space density estimator—without ﬁne-tuning on OoD data, fea-ture ensembling, or input pre-procressing. Our conceptually simple Deep Deterministic Uncertainty (DDU) baseline can also be used to disentangle aleatoric and epistemic uncer-tainty and performs as well as Deep Ensembles, the state-of-the art for uncertainty prediction, on several OoD bench-marks (CIFAR-10/100 vs SVHN/Tiny-ImageNet, ImageNet vs
ImageNet-O), active learning settings across different model architectures, as well as in large scale vision tasks like se-mantic segmentation, while being computationally cheaper. 1.

Introduction
Two types of uncertainty are often of interest in ML: epis-temic uncertainty, which is inherent to the model, caused by a lack of training data, and hence reducible with more data, and aleatoric uncertainty, caused by inherent noise or ambiguity in data, and hence irreducible with more data
[7]. Disentangling these two is critical for applications such as active learning [16] or detection of out-of-distribution (OoD) samples [24]: in active learning, we wish to avoid inputs with high aleatoric but low epistemic uncertainty, and in OoD detection, we wish to avoid mistaking ambiguous
*Equal contribution. 1OATML, Department of Computer Sci-ence, University of Oxford, 2Torr Vision Group, Department of En-gineering Science, University of Oxford. Correspondence to: Jishnu
Mukhoti <jishnu.mukhoti@eng.ox.ac.uk>, Andreas Kirsch
<andreas.kirsch@cs.ox.ac.uk>. (a) Dirty-MNIST (iD) and Fashion-MNIST (OoD) (b) Softmax entropy (c) Feature-space density
Figure 1. Disentangling aleatoric and epistemic uncertainty on
Dirty-MNIST (iD) and Fashion-MNIST (OoD) (a) requires using softmax entropy (b) and feature-space density (GMM) (c) with a well-regularized feature space (ResNet-18+SN vs LeNet & VGG-16 without smoothness & sensitivity). (b): Softmax entropy cap-tures aleatoric uncertainty for iD data (Dirty-MNIST), thereby sepa-rating unambiguous MNIST samples and Ambiguous-MNIST sam-ples (stacked histogram). However, iD and OoD are confounded: softmax entropy has arbitrary values for OoD, indistinguishable from iD. (c): With a well-regularized feature space (DDU with
ResNet-18+SN), iD and OoD densities do not overlap, capturing epistemic uncertainty. However, without such feature space (LeNet
& VGG-16), feature density suffers from feature collapse: iD and
OoD densities overlap. Generally, feature-space density confounds unambiguous and ambiguous iD samples as their densities overlap. in-distribution (iD) examples as OoD. Disentangling uncer-tainties is particularly challenging for noisy and ambiguous datasets found in safety-critical applications like autonomous driving [32] and medical diagnosis [11; 13].