Abstract
Predicting natural and diverse 3D hand gestures from the upper body dynamics is a practical yet challenging task in virtual avatar creation. Previous works usually overlook the asymmetric motions between two hands and generate two hands in a holistic manner, leading to unnatural results.
In this work, we introduce a novel bilateral hand disen-tanglement based two-stage 3D hand generation method to achieve natural and diverse 3D hand prediction from body dynamics. In the first stage, we intend to generate natural hand gestures by two hand-disentanglement branches. Con-sidering the asymmetric gestures and motions of two hands, we introduce a Spatial-Residual Memory (SRM) module to model spatial interaction between the body and each hand by residual learning. To enhance the coordination of two hand motions wrt. body dynamics holistically, we then present a Temporal-Motion Memory (TMM) module. TMM can effectively model the temporal association between body dynamics and two hand motions. The second stage is built upon the insight that 3D hand predictions should be non-deterministic given the sequential body postures.
Thus, we further diversify our 3D hand predictions based on the initial output from the stage one. Concretely, we propose a Prototypical-Memory Sampling Strategy (PSS) to generate the non-deterministic hand gestures by gradient-*Corresponding author. based Markov Chain Monte Carlo (MCMC) sampling. Ex-tensive experiments demonstrate that our method outper-forms the state-of-the-art models on the B2H dataset and
The dataset our newly collected TED Hands dataset. and code are available at: https://github.com/XingqunQi-lab/Diverse-3D-Hand-Gesture-Prediction. 1.

Introduction
Given a sequence of upper body skeletons, our task aims at predicting natural and diverse 3D hand gestures. Such non-verbal body-hand coordination plays an important role in various virtual avatar scenarios, including human-agent interface [13, 17, 35, 40, 41], co-speech gesture synthesis [5, 20, 24, 46, 47], holoportation [29].
However, it is quite difficult to predict the natural and diverse 3D hand gestures due to three major challenges: (1) Spatially asymmetric motions: Asymmetric motions of two hands have been overlooked by previous works [28], e.g., when one hand moves, the other could be static or mov-ing slowly. (2) Temporal consistency wrt. body dynam-ics: Predicted sequential hand gestures should be tempo-rally consistent with respect to the body dynamics. (3) Non-deterministic hand prediction: Given the upper body dy-namics, various 3D hand gestures can match the body pos-tures rather than a deterministic result. Since the existing dataset has only a few avatar identities, the generated hands
often lack diversity.
Due to complex body-hand interaction and asymmetric movements of two hands, directly predicting the natural and diverse 3D hand is rather difficult. Therefore, we propose to address the aforementioned challenges in a prediction fol-lowed by a diversification paradigm. To be specific, we propose a novel bilateral hand disentanglement based two-stage method, to generate natural and diverse 3D hand ges-tures from upper body dynamics.
In the first stage, we aim to predict the natural 3D hand gestures. Our key insight is to establish the bilateral hand disentanglement for asymmetric motions of two hands. We construct two hand-disentangled branches that interact with a body-specific branch to initially predict natural 3D hands.
Here, we leverage a single-hand autoencoder to extract each hand feature respectively, thus achieving the effects of two hands disentanglement. Furthermore, we propose a Spatial-Residual Memory (SRM) module to model the spatial rela-tion between the body and each hand via residual learning.
Specifically, we employ a spatial memory bank to store the spatial residual deformation representations of each hand.
Then, we leverage the current upper body embedding as a query to retrieve the most relevant spatial residual defor-mation. The queried spatial residual deformation and the synchronized hand embedding vector are used to generate the next step hand representation.
To ensure the motions of both hands are temporally consistent with the upper body sequence, we present a
Temporal-Motion Memory (TMM) module. TMM mod-els the correlation between body dynamics and hand ges-tures. Similar to SRM, we utilize a temporal memory bank to store the motion features of each hand at the sequence level. Moreover, we employ a motion encoder to acquire the input body dynamics representation, and then use the body dynamics representation as a query to produce temporally consistent hand motion features. In this fashion, we can ef-fectively synchronize hand motions with body dynamics.
In the second stage, we develop a Prototypical-Memory
Sampling Strategy (PSS) to diversify our 3D hand predic-tions based on the initial prediction at stage one. Here, we leverage an external memory that stores realistic hand prototypes, and then search a prototype that is closest to our initial predicted hands. Once we obtain the prototype, we project it into the feature space. To increase the di-versity while preserving the authenticity of generated hand gestures, we perturb the prototype feature via gradient-based Markov Chain Monte Carlo (MCMC) sampling [23].
Specifically, a random noise is first sampled from a Gaus-sian distribution as a prior perturbation and then we update its posterior via Langevin dynamics based MCMC [4, 27].
Then, the perturbation is concatenated with the prototype feature to produce realistic new hand gestures.
Moreover, the existing 3D hand prediction dataset [28] contains less than 10 avatar identities, resulting in insuffi-cient diversity of gestures. Therefore, we newly collect a large-scale 3D hand gestures dataset (dubbed TED Hands) with more than 1.7K avatar identities from in-the-wild sce-narios. Our dataset contains around 100 hours of TED talk speeches, enabling research on diverse 3D hand ges-ture predictions. Extensive experiments conducted on the
B2H dataset [28] and our TED Hands dataset demonstrate our method outperforms the state-of-the-art.
Overall, our contributions are summarized as follows:
• We propose a novel bilateral hand disentanglement based two-stage 3D hand generation method to predict diverse 3D hand gestures from body dynamics in a prediction fol-lowed by diversification paradigm.
• We present a Spatial-Residual Memory (SRM) module to predict authentic hand poses from disentangled hand representations and a Temporal-Motion Memory (TMM) module to ensure temporal consistency of generated 3D hands.
• We design a Prototypical-Memory Sampling Strategy (PSS) to diversify our initial 3D hand prediction, thus ob-taining natural and diverse hand gestures.
• We collect a new large-scale sequential 3D hand dataset from 1.7K persons’ hand gestures, significantly facilitat-ing research on diverse 3D hands generation. 2.