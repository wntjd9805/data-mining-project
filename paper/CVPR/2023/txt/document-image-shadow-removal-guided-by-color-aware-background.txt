Abstract
Existing works on document image shadow removal mostly depend on learning and leveraging a constant back-ground (the color of the paper) from the image. However, the constant background is less representative and frequent-ly ignores other background colors, such as the printed col-ors, resulting in distorted results. In this paper, we present a color-aware background extraction network (CBENet) for extracting a spatially varying background image that ac-curately depicts the background colors of the documen-t. Furthermore, we propose a background-guided docu-ment images shadow removal network (BGShadowNet) us-ing the predicted spatially varying background as auxil-iary information, which consists of two stages. At Stage
I, a background-constrained decoder is designed to pro-mote a coarse result. Then, the coarse result is reﬁned with a background-based attention module (BAModule) to maintain a consistent appearance and a detail improvement module (DEModule) to enhance the texture details at Stage
II. Experiments on two benchmark datasets qualitatively and quantitatively validate the superiority of the proposed approach over state-of-the-arts. 1.

Introduction
Documents, such as textbooks, newspapers, leaﬂets, and receipts, are available daily, often saved as electronic doc-uments for digital document archives or online message transfer. Since the wide use and convenience of mobile phones, people currently prefer to use mobile phones for digital document copying. However, the captured docu-ment images become highly susceptible to shadows when the light sources are blocked. The low brightness in shadow regions reduces the quality and readability of the documen-∗Corresponding author: Chunxia Xiao (cxxiao@whu.edu.cn). (a) Shadow image (b) Our background (c) Our result (d) Result of [2] (e)