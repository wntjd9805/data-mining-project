Abstract
Quantifying motion in 3D is important for studying the behavior of humans and other animals, but manual pose an-notations are expensive and time-consuming to obtain. Self-supervised keypoint discovery is a promising strategy for estimating 3D poses without annotations. However, current keypoint discovery approaches commonly process single 2D views and do not operate in the 3D space. We propose a new method to perform self-supervised keypoint discovery in 3D from multi-view videos of behaving agents, without any keypoint or bounding box supervision in 2D or 3D. Our method, BKinD-3D, uses an encoder-decoder architecture with a 3D volumetric heatmap, trained to reconstruct spa-tiotemporal differences across multiple views, in addition to joint length constraints on a learned 3D skeleton of the sub-ject. In this way, we discover keypoints without requiring manual supervision in videos of humans and rats, demon-strating the potential of 3D keypoint discovery for studying behavior. 1.

Introduction
All animals behave in 3D, and analyzing 3D posture and movement is crucial for a variety of applications, includ-ing the study of biomechanics, motor control, and behav-ior [27]. However, annotations for supervised training of 3D pose estimators are expensive and time-consuming to obtain, especially for studying diverse animal species and varying experimental contexts. Self-supervised keypoint discovery has demonstrated tremendous potential in discov-ering 2D keypoints from video [19,20,40], without the need for manual annotations. These models have not been well-explored in 3D, which is more challenging compared to 2D
*Equal contribution
†Work done outside of SAIT
Figure 1. Self-supervised 3D keypoint discovery. Previous work studying self-supervised keypoints either requires 2D supervision for 3D pose estimation or focuses on 2D keypoint discovery. Cur-rently, self-supervised 3D keypoint discovery is not well-explored.
We propose methods for discovering 3D keypoints directly from multi-view videos of different organisms, such as human and rats, without 2D or 3D supervision. The 3D keypoint discovery exam-ples demonstrate the results from our method.
Self-Supervised 3D Keypoint Discovery. due to depth ambiguities, a larger search space, and the need to incorporate geometric constraints. Our goal is to enable 3D keypoint discovery of humans and animals from syn-chronized multi-view videos, without 2D or 3D supervision.
Previous works for self-supervised 3D keypoints typically start from a pre-trained 2D pose estimator [25,42], and thus do not per-form keypoint discovery (Figure 1). These models are suit-able for studying human poses because 2D human pose esti-mators are widely available and the pose and body structure
of humans is well-defined. However, for many scientific applications [27, 33, 40], it is important to track diverse or-ganisms in different experimental contexts. These situations require time-consuming 2D or 3D annotations for training pose estimation models. The goal of our work is to en-able 3D keypoint discovery from multi-view videos directly, without any 2D or 3D supervision, in order to accelerate the analysis of 3D poses from diverse animals in novel settings.
To the best of our knowledge, self-supervised 3D keypoint discovery have not been well-explored for real-world multi-view videos.
Behavioral Videos. We study 3D keypoint discovery in the setting of behavioral videos with stationary cameras and backgrounds. We chose this for several reasons. First, this setting is common in many real-world behavior analy-sis datasets [2,10,21,28,33,37,39], where there has been an emerging trend to expand the study of behavior from 2D to 3D [27]. Thus, 3D keypoint discovery would directly ben-efit many scientific studies in this space using approaches such as biomechanics, motor control, and behavior [27].
Second, studying behavioral videos in 3D enables us to leverage recent work in 2D keypoint discovery for behav-ioral videos [40]. Finally, this setting enables us to tackle the 3D keypoint discovery challenge in a modular way. For example, in behavior analysis experiments, many tools are already available for camera calibration [24], and we can assume that camera parameters are known.
Our Approach. The key to our approach, which we call Behavioral Keypoint Discovery in 3D (BKinD-3D), is to encode self-supervised learning signals from videos across multiple views into a single 3D geometric bottle-neck. We leverage the spatiotemporal difference recon-struction loss from [40] and use multi-view reconstruction to train an encoder-decoder architecture. Our method does not use any bounding boxes or keypoint annotations as su-pervision. Critically, we impose links between our discov-ered keypoints to discover connectivity across points.
In other words, keypoints on the same parts of the body are connected, so that we are able to enforce joint length con-straints in 3D. To show that our model is applicable across multiple settings, we demonstrate our approach on multi-view videos from different organisms. To summarize:
• We introduce self-supervised 3D keypoint discovery, which discovers 3D pose from real-world multi-view behavioral videos of different organisms, without any 2D or 3D supervision.
• We propose a novel method (BKinD-3D) for end-to-end 3D discovery from video using multi-view spa-tiotemporal difference reconstruction and 3D joint length constraints.
• We demonstrate quantitatively that our work signifi-cantly closes the gap between supervised 3D methods
Method 3D sup. 2D sup. camera params data type
Isakov et al. [17]
DANNCE [7]
Rhodin et al. [35]
Anipose [24]
DeepFly3D [12]
EpipolarPose [25]
CanonPose [43]
MetaPose [42]
Keypoint3D [3]
Ours (3D discovery)
✓
✓
×
×
×
×
×
✓ optional
✓
✓
✓
×
× intrinsics extrinsics intrinsics intrinsics extrinsics optional
× intrinsics extrinsics intrinsics extrinsics real real real real real simulation real
Table 1. Comparison of our work with representative related work for 3D pose using multi-view training. Previous works require either 3D or 2D supervision, or simulated environments to train jointly with reinforcement learning. Our method addresses a gap in discovering 3D keypoints from real videos without 2D or 3D supervision. and 3D keypoint discovery across different organisms (humans and rats). 2.