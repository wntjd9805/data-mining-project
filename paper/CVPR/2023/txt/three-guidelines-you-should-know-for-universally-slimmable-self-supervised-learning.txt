Abstract
We propose universally slimmable self-supervised learn-ing (dubbed as US3L) to achieve better accuracy-efficiency trade-offs for deploying self-supervised models across dif-ferent devices. We observe that direct adaptation of self-supervised learning (SSL) to universally slimmable networks misbehaves as the training process frequently collapses. We then discover that temporal consistent guidance is the key to the success of SSL for universally slimmable networks, and we propose three guidelines for the loss design to ensure this temporal consistency from a unified gradient perspec-tive. Moreover, we propose dynamic sampling and group regularization strategies to simultaneously improve training efficiency and accuracy. Our US3L method has been empiri-cally validated on both convolutional neural networks and vision transformers. With only once training and one copy of weights, our method outperforms various state-of-the-art methods (individually trained or not) on benchmarks includ-ing recognition, object detection and instance segmentation. 1.

Introduction
Deep supervised learning has achieved great success in the last decade, but the drawback is that it relies heavily on a large set of annotated training data. Self-supervised learning (SSL) has gained popularity because of its ability to avoid the cost of annotating large-scale datasets. Since the emergence of contrastive learning [7], SSL has clearly gained momentum and several recent works [8, 14] have achieved comparable or even better performance than the su-pervised pretraining when transferring to downstream tasks.
However, it remains challenging to deploy trained models for edge computing purposes, due to the limited memory, computation and storage capabilities of such devices.
*Corresponding author.
Table 1. Comparisons between supervised classification and Sim-Siam under S-Net on CIFAR-100. The accuracy for SimSiam is under linear evaluation. ‘-’ denotes the model collapses.
Type
Supervised
SimSiam [9]
Method
Individual
S-Net [32]
Accuracy (%) 1.0x 0.75x 0.5x 0.25x 73.8 72.8 71.4 67.3 71.9 71.7 70.8 66.2
S-Net+Distill [31] 73.1 71.9 70.5 67.2 65.2 64.0 60.6 51.2
-S-Net+Distill [31] 46.9 46.9 46.7 45.3 65.5 65.3 63.2 59.7
Ours
---Individual
S-Net [32]
To facilitate deployment, several model compression tech-niques have been proposed, including lightweight architec-ture design [29], knowledge distillation [20], network prun-ing [15], and quantization [33]. Among them, structured net-work pruning [25] is directly supported and accelerated by most current hardware and therefore the most studied. How-ever, most structured pruning methods require fine-tuning to obtain a sub-network with a specific sparsity, and a single trained model cannot achieve instant and adaptive accuracy-efficiency trade-offs across different devices. To address this problem in the context of supervised learning, the family of slimmable networks (S-Net) and universally slimmable networks (US-Net) [2, 22, 31, 32] were proposed, which can switch freely among different widths by training only once.
Driven by the success of slimmable networks, a ques-tion arises: Can we train a self-supervised model that can run at arbitrary width? A na¨ıve solution is to replace the supervised loss with self-supervised loss based on the US-Net framework. However, we find that this solution doesn’t work directly after empirical studies. Table 1 shows that the phenomenon in self-supervised scenarios is very different.
The model directly collapses after applying the popular SSL method SimSiam [9] to slimmable networks [32]. Although using inplace distillation [31] for sub-networks prevents the model from collapsing, there is still a big gap between the
results of S-Net+Distill and training each model individually for SimSiam. So why is the situation so different in SSL and how to further improve the performance (i.e., close the gap)?
In this paper, we present a unified perspective to ex-plain the differences and propose corresponding measures to bridge the gap. From a unified gradient perspective, we find that the key is that the guidance to sub-networks should be consistent between iterations, and we analyze which com-ponents of SSL incur the temporal inconsistency problem and why US-Net works in supervised learning. Based on these theoretical analyses, we propose three guidelines for the loss design of US-Net training to ensure temporal consis-tency. As long as one of them is satisfied, US-Net can work well, no matter in supervised or self-supervised scenarios.
Moreover, considering the characteristics of SSL and the deficiencies of US-Net, we propose dynamic sampling and group regularization to reduce the training overhead while improving accuracy. Our main contributions are:
• We discover significant differences between supervised and self-supervised learning when training US-Net. Based on these observations, we analyze and summarize three guidelines for the loss design of US-Net to ensure temporal consistency from a unified gradient perspective.
• We propose a dynamic sampling strategy to reduce the train-ing cost without sacrificing accuracy, which eases coping with the large data volumes in SSL.
• We analyze how the training scheme of US-Net limits the model capacity and propose group regularization as a solu-tion by giving different freedoms to different channels.
• We validate the effectiveness of our method on both CNNs and Vision Transformers (ViTs). Our method requires only once training and a single model, which can exceed the re-sults of training each model individually, and is comparable to knowledge distillation from pretrained teachers. 2.