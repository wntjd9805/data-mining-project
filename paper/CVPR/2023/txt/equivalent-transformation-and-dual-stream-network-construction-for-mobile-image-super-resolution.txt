Abstract
In recent years, there has been an increasing demand for real-time super-resolution networks on mobile devices.
To address this issue, many lightweight super-resolution models have been proposed. However, these models still contain time-consuming components that increase infer-ence latency, limiting their real-world applications on mo-bile devices. In this paper, we propose a novel model for single-image super-resolution based on Equivalent Trans-formation and Dual Stream network construction (ETDS).
ET method is proposed to transform time-consuming op-erators into time-friendly operations, such as convolution and ReLU, on mobile devices. Then, a dual stream net-work is designed to alleviate redundant parameters result-ing from the use of ET and enhance the feature extraction ability. Taking full advantage of the advance of ET and the dual stream network structure, we develop the efficient
SR model ETDS for mobile devices. The experimental re-sults demonstrate that our ETDS achieves superior infer-ence speed and reconstruction quality compared to previ-ous lightweight SR methods on mobile devices. The code is available at https://github.com/ECNUSR/ETDS. 1.

Introduction
Image super-resolution (SR) aims to reconstruct high-resolution images (HR) from low-resolution images (LR).
Over the years, numerous deep-learning methods have been proposed [3, 6, 17, 18, 33, 35, 36] with good fidelity and per-ceptual quality. However, these methods are not efficient and lightweight when it comes to mobile platforms where
SR application becomes increasingly ubiquitous. Thus, it is essential to devise an approach that takes into account the restrictions of mobile platforms.
Generally, mobile platforms have limitations such as a restricted amount of RAM, lower memory bandwidth,
*Corresponding author.
Figure 1. Comparisons of PSNR performance and the inference latency of different models. The inference latency is tested on Di-mensity 8100 SoC, NNAPI driver, INT8 precision and upsampling from 360 × 640 to 1080 × 1920. PSNR indexes are evaluated on
Set5 [2]. lower computational speed and insufficient support for many common deep learning layers and operators. To take the particularities into consideration, the recently proposed
SR models [27, 34] designed for mobile devices adopt a neat topology [34] as the base model to ensure low infer-ence latency. ABPN [8] further boosted efficiency by em-ploying the repeat operator instead of the time-consuming nearest neighbor interpolation. Nevertheless, in-depth in-vestigation reveals that some time-consuming components in current mobile SR models, such as the global residual connection and clip operator, are indispensable for overall reconstruction quality. Therefore, to accelerate the infer-ence on mobile devices and achieve a competitive recon-struction quality and inference latency, it is necessary to seek time-friendly surrogates for these time-consuming op-erators.
To this end, we propose Equivalent Transformation (ET), a method that speeds up the model by substituting time-consuming operators with time-friendly ones without im-pairing reconstruction quality. As shown in Fig. 1, the pro-posed ET can be directly applied to existing models (e.g.,
ECBSR [34] and ABPN [8]) and reduce inference latency without retraining. However, ET introduces some redun-dant and unlearnable parameters. To fully utilize these pa-rameters, we design the dual stream network that makes the redundant parameters partially learnable, to boost the fea-ture extraction ability. Finally, we propose a mobile image
SR model named ETDS that employs the dual stream net-work in the training stage and transforms it into an equiva-lent plain network by ET in the inference stage. As shown in Fig. 1, our ETDS not only achieves high reconstruction quality but also maintains low inference speed.
In summary, the main contributions of this paper are as follows: 1) We propose ET, a method that can transform time-consuming operators and speed up the inference with-out impairing reconstruction quality. It can be applied to existing models to accelerate the inference. 2) We design a dual stream network to alleviate the re-dundancy yielded from ET by making redundant pa-rameters partially learnable. 3) We propose an efficient and lightweight network named ETDS for real-time SR on mobile devices based on ET and dual stream networks. Experiments demonstrate that state-of-the-art models equipped with
ET have at most 80% improvement in inference la-tency and ETDS achieves 34% inference latency im-provement and 0.42dB PSNR performance improve-ment. 2.