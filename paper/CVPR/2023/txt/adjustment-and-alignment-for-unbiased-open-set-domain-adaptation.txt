Abstract
Open Set Domain Adaptation (OSDA) transfers the model from a label-rich domain to a label-free one con-taining novel-class samples. Existing OSDA works over-look abundant novel-class semantics hidden in the source domain, leading to a biased model learning and trans-fer. Although the causality has been studied to remove the semantic-level bias, the non-available novel-class samples result in the failure of existing causal solutions in OSDA.
To break through this barrier, we propose a novel causality-driven solution with the unexplored front-door adjustment theory, and then implement it with a theoretically grounded framework, coined Adjustment and Alignment (ANNA), to achieve an unbiased OSDA. In a nutshell, ANNA consists of
Front-Door Adjustment (FDA) to correct the biased learn-ing in the source domain and Decoupled Causal Align-ment (DCA) to transfer the model unbiasedly. On the one hand, FDA delves into fine-grained visual blocks to discover novel-class regions hidden in the base-class image. Then, it corrects the biased model optimization by implementing causal debiasing. On the other hand, DCA disentangles the base-class and novel-class regions with orthogonal masks, and then adapts the decoupled distribution for an unbiased model transfer. Extensive experiments show that ANNA achieves state-of-the-art results. The code is available at https://github.com/CityU-AIM-Group/Anna. 1.

Introduction
Unsupervised Domain Adaptation (UDA) [5, 8, 11, 13] has been well studied to transfer a model from a labeled domain to an unlabeled novel one, notably saving the label-ing labor for model re-implementation. However, existing
UDA research follows a strong assumption that the two do-mains must share the same class space, which cannot make correct predictions for novel-class samples. This severely
*Corresponding author.
This work was supported by Hong Kong Research Grants Council (RGC) General Research Fund 11211221, and Innovation and Technology
Commission-Innovation and Technology Fund ITS/100/20. limits real-world applications [25, 29], e.g., product recom-mendation and pathology identification with unseen classes.
Aiming at addressing this issue, Open Set Domain Adap-tation (OSDA) [3, 17, 20, 29, 35] has been studied, which also needs to recognize the novel-class samples in the target domain as unknown. As shown in Figure 1(a) (top), follow-ing a similar pipeline, most existing works [3, 17, 20, 29, 35] utilize labeled base-class data to train a closed-set classi-fier in the source domain. Then, in the target domain, they adjust the model with two objectives, i.e., exploring novel samples to achieve base/novel-class separation (novel-class detection) and adapting the base-class distribution (domain alignment). Based on this pipeline, these works can suc-cessfully recognize some novel samples in the unlabelled target domain and align the base-class distribution well.
While achieving great success, existing works [17, 20, 29] only consider base-class semantics in the source do-main, ignoring the novel-class spreading everywhere. This leads to a semantic-level bias between the base and novel class, further yielding a biased domain transfer for OSDA.
To explore the deficiency of this bias, we visualize the base/novel-class activated regions, as shown in col. 1-2 of
Figure 1(a) (bottom). It can be observed that existing ap-proaches can successfully find the base-class regions con-sistent with the image-level ground-truth chair, but can-not discover novel-class semantics, e.g., the yacht, sea, and ground, etc. (The base and novel regions are highlighted in Figure 1(c) for better view.) Further, we conduct a per-pixel prediction on deepest features without global average pooling (col. 3), illustrating that the novel regions are mis-classified as some non-correlated base classes. These obser-vations imply that this semantic-level bias severely affects the judgment of the classifier even though the classifier can give a correct prediction for the whole image.
Recently, several causality-based approaches [36, 44, 45] have been proposed to solve the semantic-level bias in the closed-set setting. These works [36,44,45] first conduct per-class statistics over the whole dataset to decouple the con-text, and then use decoupled components to correct the bi-ased model training in a class-balanced manner. This causal solution can successfully avoid biased model learning since
Figure 1. Illustration of the general pipeline (top) and observed bias (bottom) with the base/novel-class activation and per-pixel prediction (we conduct dense classification on each pixel of the 7×7 ResNet-50 [9] feature and highlight the pixels with the same result in the same color.) for (a) existing OSDA approaches, (b) our solution, and (c) base and novel regions in each image. the knowledge of all classes contributes to training each sample. Hence, the rational idea is to explore the causal-ity to solve the newly observed OSDA bias.
However, it is intractable to implement existing causal solutions [36, 45] in OSDA since the context is unobserv-able in open-set setting [42,43]. Existing works [36,45] use backdoor adjustment theory [26] to remove the bias, which relies on the observable context with available data samples.
Differently, in OSDA, the context is unobservable [42] since novel-class samples are missing in the source domain [29] and labels are non-available in the target domain, leading to the failure [42] of existing backdoor solutions [36, 44, 45].
Although the front-door adjustment [26] can break through this unobservable dilemma [26] by decoupling data samples instead of context1, it is still tricky to implement a semantic-level decoupling [36,45] on each data sample since each im-age is only assigned a single class label in classification [9].
Fortunately, as shown in Figure 1(c), we observe that each image can be decoupled into base/novel-class regions in this open-set setting, which motivates us to use the unexplored yet effective front-door adjustment [26] to remove the bias.
Thus, we aim to correct the biased learning in the source domain and then align the decoupled cross-domain distribu-tion to achieve unbiased OSDA. See Sec. 3 for a theoretical analysis with Structural Causal Model.
To address the problems mentioned above, we pro-pose a theoretically grounded framework, Adjustment and
Alignment (ANNA) for OSDA (see Figure 1(b) (top)) with causality, which consists of Front-Door Adjustment (FDA) to address the biased learning in the source domain, and
Decoupled Causal Alignment (DCA) to transfer the model to the target domain unbiasedly. Specifically, in each base-class image, FDA delves into fine-grained visual blocks to discover novel-class regions, serving for correcting biased model learning with causal adjustment. As for the DCA module, we disentangle cross-domain images into base-class and novel-class regions with orthogonal masks, and then align the decoupled distribution free of bias. As shown 1See supplementary materials for a more detailed explanation. in Figure 1(b) (bottom), after eliminating the OSDA bias, the model can capture labeled base-class regions (col. 1) and unlabeled novel-class regions (col. 2) well. Besides, the per-pixel prediction (col. 3) gives a closer look at model inference, showing that ANNA fully considers fine-grained novel semantics like humans before making an image-level prediction. Our main contributions are as follows,
• This work represents the first attempt that observes and formulates the ever-overlooked semantic-level bias in
OSDA. To address this issue, we propose a theoreti-cally grounded framework, Adjustment and Alignment (ANNA) with causality, achieving an unbiased OSDA.
• We propose a Front-Door Adjustment (FDA) module to correct the biased closed-set learning, discovering and fully using novel-class regions hidden in images.
• We design a Decoupled Causal Alignment (DCA) to achieve an unbiased model transfer, which decouples cross-domain images with fine-grained regions and aligns the decoupled distribution unbiasedly.
• Extensive experiments on three benchmarks verify that
ANNA achieves state-of-the-art performance. ANNA achieves the best HOS on all 12 sub-tasks of the chal-lenging Office-Home benchmark. 2.