Abstract
Learning inter-image similarity is crucial for 3D medi-cal images self-supervised pre-training, due to their sharing of numerous same semantic regions. However, the lack of the semantic prior in metrics and the semantic-independent variation in 3D medical images make it challenging to get a reliable measurement for the inter-image similarity, hin-dering the learning of consistent representation for same semantics. We investigate the challenging problem of this task, i.e., learning a consistent representation between im-ages for a clustering effect of same semantic features. We propose a novel visual similarity learning paradigm, Geo-metric Visual Similarity Learning, which embeds the prior of topological invariance into the measurement of the inter-image similarity for consistent representation of semantic regions. To drive this paradigm, we further construct a novel geometric matching head, the Z-matching head, to collaboratively learn the global and local similarity of se-mantic regions, guiding the efﬁcient representation learn-ing for different scale-level inter-image semantic features.
Our experiments demonstrate that the pre-training with our learning of inter-image similarity yields more power-ful inner-scene, inter-scene, and global-local transferring ability on four challenging 3D medical image tasks. Our codes and pre-trained models will be publicly available1. 1.

Introduction
Learning inter-image similarity [26, 33, 44, 47] is crucial for 3D medical image (e.g., CT, MR) self-supervised pre-training (SSP) [20]. As shown in Fig.1, different from nat-ural images which are widely researched in SSP, 3D med-ical images share numerous same semantic regions due to the consistency of human anatomies [28] and the complete spatial information in 3D vision [35], bringing a strong prior for effective SSP. Therefore, it targets on constrain-∗Corresponding author: yang.list@seu.edu.cn 1https://github.com/YutingHe-list/GVSL 3D medical image 3D medical image (cid:120) Consistent human  anatomies (cid:120) Complete spatial  information in 3D visionon
Lung
RV
Myo
LV
RA
Ao
Myo
LA
Lung
Lung
Do
Spine
Lung
RV
RA
Myo
LV
Ao
Lung
LA
Myo
Spine
Do
Lung a) Large semantic difference  between natural images b) Numerous same semantic regions  between 3D medical images
Figure 1. Learning inter-image similarity is crucial for 3D medical image SSP. a) Natural images have large semantic difference be-tween images whose inter-image similarity is weak. b) 3D medical images share numerous same semantic regions between images due to the consistent human anatomies and the complete spatial information in 3D vision, having large inter-image similarity. ing the pre-training network for a consistent representation of these same semantic regions between images without an-notations. Once successful, it will bring great clustering effect for same semantic features, powerful representability of pre-trained network, and effective transferring for poten-tial downstream tasks.
Although the existing SSP works have achieved promis-ing results in their tasks, they are limited in the learning of inter-image similarity in 3D medical images. 1) Clustering-based SSP methods [2, 24] measure the features’ similarity between images for their clustering pattern in an embedding space, and learn to aggregate same cluster’s features. How-ever, they simply employ the Mahalanobis or Euclidean dis-tance as the measurement function which is extremely inter-fered by images’ semantics-independent variations (Fig.2). 2) Contrastive learning works [3, 4] directly learn to sep-arate their features for inter-image dissimilarity. This vi-olates the learning inter-image similarity which is crucial in 3D images and will make the network represent distinct features for same semantic regions. Although some other contrastive learning works [4, 7, 41] have removed the sep-Image A
Image B
Image C
Image A
AO
AO
AO
PA
PA
PA
AO
AO
AO
Myo
Similar 
RA
Dissimilar 
RA a) Different semantic regions  with similar appearance b) Same semantic regions  with dissimilar appearance
Figure 2. It is challenging to measure a reliable inter-image simi-larity. a) There is a large similarity between the Myo and the RA regions between images A and B. b) Due to the variation of the scanning protocol, RA regions are different in images B and C. aration learning, they are still unable to learn the consis-tency of inter-image same semantics. 3) Generation-based methods [23,25,40,48] construct pretext labels via designed transformation methods (e.g., rotation [23]) and train net-works to predict these labels. These methods implicitly im-pose a bias into SSP via manually designing the transfor-mation methods. However, the bias extremely relies on the manual design which makes pre-training networks focus on the biased features of pretext labels and become sensitive to the change of scenario [25].
Thinking the limitations in above existing works, the large-scale mis-measurement for inter-image similarity is the key challenge in 3D medical SSP, interfering the dis-covery of semantics’ correspondence and hindering the learning of consistent representation for same semantic re-gions. Semantic-independent variations (Fig.2) make the 3D medical images have different appearance. Different semantic regions have similar appearances and same se-mantic regions have different appearances between images.
The direct measurement in the embedding space, like the clustering-based SSP methods [2, 24], is sensitive due to lack of semantic prior in their metrics. Therefore, in the non-supervision situation, once the features changed caused by the variations, these metrics will make mis-measurement of similarities for large-scale semantics, bringing their mis-correspondence. It will train network to aggregate the fea-tures with different semantic but similar appearance, caus-ing mis-representation.
Topological invariance [18,27] of the visual semantics in 3D medical images provides a motivation to construct a re-liable measurement for inter-image similarity (Fig.3). Due to the consistency of human anatomies [28], 3D medical images have consistent context topology between the visual semantics in image space (e.g., the four chambers of human hearts have a ﬁxed space relationship), and the same seman-tic regions have similar shapes in different images (e.g., the vessels (AO) have a stable tubular structure), constructing an invariant topology for the visual semantics. Therefore,
Image B
Image C
RV
RA
Myo
LV
Ao
LA
RA
RARA
RA
RV
RVRV
RV
LV
LV
LV
RA
RA
RA
RV
RV
RV
LA
LA
LA
Myo
Myo
Myo
PA
PA
PA
LV
LV
LV
LA
LA
LA
Myo
Myo
Myo
Topology of heart structures
Topology of heart structures
AO
RA
RV
Consistent topology of  visual semantics
PA
LV
LA
Myo
Topology of heart structures in image C
Figure 3. The topological invariance of the visual semantics be-tween the 3D medical images provides a motivation to discover their inter-image correspondence. according to the semantic prior of topological invariance, the semantic regions are able to be transformed to align in the image space via a topology-invariant mapping [10], thus discovering their reliable inter-image correspondence even with large variations in appearance. An intuitive strategy is to use the registration or geometric matching (GM) meth-ods [11, 13, 15, 16, 32] to discover correspondence indexes between images, and use these indexes to constrain the con-sistent representation for corresponding regions. However, the errors in these indexes will bring mis-correspondence.
In this paper, we propose a novel SSP paradigm, Ge-ometric Visual Similarity Learning (GVSL), to learn the inter-image similarity in 3D medical images. It embeds the prior of topological invariance into the measurement of the similarities, and train network to estimate semantics’ cor-respondence from the represented features in GM. Due to this effective semantic prior, the measurement will consider the semantic-related topology similarity avoiding the large interference of semantic-independent variation. Therefore, when learning to enlarge this similarity between two images for more accurate estimation of correspondence, the gradi-ent in backpropagation will constrain the network to clus-ter the corresponding features in embedding space for more consistent representation. To drive the GM learning, we fur-ther propose a Z-Matching head to explore the global and local collaborative representation learning of inter-image similarity in our GVSL paradigm.
It constructs a collab-orative learning head with afﬁne (global matching) and de-formable (local matching) transformations [13], thus em-bedding the pre-trained model with a powerful transferring ability for potential downstream tasks.
Our contributions are summarized as follows: 1) Our work advances the learning of inter-image similarity in 3D medical image SSP, and pre-trains the network to learn a consistent representation for same visual semantics between images without annotation, pushing the representability of pre-trained models. 2) We propose the Geometric Visual
Similarity Learning (GVSL) that embeds the prior of topo-logical invariance into the metric for a reliable measure-ment of inter-image similarity, learning a consistent repre-sentation for same semantic regions between images. 3) We present a novel GM head, Z-Matching head, for simultane-ously powerful global and local representation. It collabora-tively learns the afﬁne and deformable matching, realizing an effective optimization for the representation of different semantic granularity in our GVSL, and ﬁnally achieving a powerful transferring ability. tion with inter-image similarity. 3.1. GVSL for inter-image similarity
The proposed GVSL (Fig.4 a)) models the learning of inter-image similarity as the estimation of inter-image cor-respondence from represented features which embeds the prior of topological invariance into the measurement, thus utilizing the gradient in backpropagation to train the net-work to represent consistent features on same semantics. 2.