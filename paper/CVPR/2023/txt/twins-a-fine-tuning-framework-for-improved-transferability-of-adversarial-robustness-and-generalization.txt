Abstract
Recent years have seen the ever-increasing importance of pre-trained models and their downstream training in deep learning research and applications. At the same time, the defense for adversarial examples has been mainly inves-tigated in the context of training from random initialization on simple classification tasks. To better exploit the potential of pre-trained models in adversarial robustness, this paper focuses on the fine-tuning of an adversarially pre-trained model in various classification tasks. Existing research has shown that since the robust pre-trained model has already learned a robust feature extractor, the crucial question is how to maintain the robustness in the pre-trained model when learning the downstream task. We study the model-based and data-based approaches for this goal and find that the two common approaches cannot achieve the objective of improving both generalization and adversarial robustness.
Thus, we propose a novel statistics-based approach, Two-WIng NormliSation (TWINS) fine-tuning framework, which consists of two neural networks where one of them keeps the population means and variances of pre-training data in the batch normalization layers. Besides the robust informa-tion transfer, TWINS increases the effective learning rate without hurting the training stability since the relationship between a weight norm and its gradient norm in standard batch normalization layer is broken, resulting in a faster es-cape from the sub-optimal initialization and alleviating the robust overfitting. Finally, TWINS is shown to be effective on a wide range of image classification datasets in terms of both generalization and robustness. 1.

Introduction
The adversarial vulnerability of deep neural networks (DNNs) [59] is one of the major obstacles for their wide
*Corresponding author
Figure 1. The performance of fine-tuning robust and non-robust large-scale pre-trained (PT) ResNet50 [26, 55] on CIFAR10 [34] and Caltech-256 [22]. We compare standard adversarial training (AT), Learning without Forgetting (LwF) (model approach) [39], joint fine-tuning with UOT data selection (data approach) [46] and our TWINS fine-tuning. The robust accuracy is evaluated using l∞ norm bounded AutoAttack [11] with ϵ = 8/255. On
CIFAR10, the data-based and model-based approach fail to im-prove clean and robust accuracy. On Caltech, both approaches im-prove the clean accuracy but hurt the robust accuracy. Our TWINS fine-tuning improves the clean and robust performance on both datasets. The pink triangle denotes the performance of standard
AT with the non-robust pre-trained ResNet50, which drops con-siderably compared with fine-tuning starting from the robust pre-trained model. applications in safety-critical scenarios such as self-driving cars [18] and medical diagnosis [19]. Thus, addressing this issue has been one focus of deep learning research in the past eight years. Existing works have proposed to improve adversarial robustness from different perspec-tives, including data augmentation [21, 48, 53, 56], regu-larization [37, 43, 44, 51] and neural architecture [23, 28].
However, most of existing works investigate the problem under the assumption that the training data is sufficient enough, and training from scratch gives a satisfactory per-formance, which is not realistic in the real world. There are a large number of computer vision tasks where training from scratch is inferior to training from pre-trained weights, such as fine-grained image classification (e.g., Caltech-Figure 2. The TWINS structure and training pipeline. (a) The Frozen Net and Adaptive Net have the same structure and share the weight parameters, except for batch normalization (BN) layers. The Frozen Net uses pre-trained means and standard deviations (STD) in the normalization layer, while Adaptive Net uses the mean and STD computed from the current batch as in standard BN. (b) In each step of mini-batch stochastic gradient descent (SGD), we split the batch of adversarial examples, generated from attacking the Adaptive Net, into two sub-batches and feed them to the Adaptive Net and Frozen Net respectively. The loss of two networks are combined and back-propagated to their shared parameters to train the network. In the inference stage, only the Adaptive Net is used.
UCSD Birds-200-2011 or CUB200 [60]), object detection
[42] and semantic segmentation [49].
On the other hand, pre-trained models have been consid-ered as the foundation models in deep learning [5] as a result of their strong performance and wide employment in com-puter vision [17,24,25,45], as well as natural language pro-cessing [6, 13, 52]. Thus, how to better use the pre-trained model in downstream has emerged as a major research topic in many vision and language tasks, such as image classifica-tion under distribution shifts [47, 63], object detection [36] and semantic segmentation [29, 35]. There are a few papers that investigate the pre-trained model’s robustness in target tasks [7, 8, 15, 31, 32, 57, 62]. [7, 57] mainly considers the transfer between small-scale datasets (e.g., CIFAR100 to
CIFAR10), while [8, 32] use adversarial robust pre-training and fine-tuning on the same dataset, without considering a large-scale and general pre-trained model. Finally, [15, 62] investigate different kinds of robustness to corruption or out-of-distribution samples, and are not devoted to adver-sarial robustness.
In this paper, we consider how to transfer the adver-sarial robustness of a large-scale robust pre-trained model (e.g., a ResNet50 pre-trained on ImageNet [12] with adver-sarial training) on various downstream classification tasks when fine-tuning with adversarial training. This problem setting is becoming more important as the standard pre-trained models do not learn robust representations from the pre-training data and are substantially weaker than the ro-bust pre-trained counterparts in some challenging down-stream tasks, e.g., fine-grained classification as shown in our experiment. Meanwhile, more large-scale robust pre-trained models are released (e.g., ResNet [55] and ViT [4]), which makes the robust pre-trained models more accessible.
However, naively applying adversarial training to fine-tune from the robustly pre-trained model will lead to subopti-mal robustness, since the robust representations learned by the robust pre-trained model are not fully utilized. For ex-ample, [57] suggests that the robustness from a pre-trained model needs to be explicitly maintained for its better trans-fer to the downstream.
Following the idea that the key to improving the trans-ferability of robustness is to maintain the robustness of the pre-training stage during fine-tuning [57], we first evalu-ate the data-based and model-based approach on two rep-resentative datasets, CIFAR10 and Caltech-256. The data-based approach uses pre-trained data in the fine-tuning and keeps their performance under adversarial attack, while the model-based approach regularizes the distance of features of the fine-tuned and pre-trained model. Our experiment shows that both methods fail to improve the robustness and generalization (Fig. 1), since the two methods are too ag-gressive in retaining the robustness and hurt the learning in downstream. Thus, we propose a subtle approach that keeps the batch-norm (BN) statistics of pre-training for preserving the robustness, which we call Two-WIng NormaliSation (TWINS) fine-tuning. TWINS has two neural networks with fixed and adaptive BN layers respectively, where the fixed BN layers use the population means and STDs of pre-training for normalization, while the adaptive BN layers use the standard BN normalization. Our experiment first demonstrates the importance of pre-trained BN statistics in the robust fine-tuning and then finds the benefit of TWINS in adversarial training dynamics. As the relationship be-tween weight norm and its gradient norm no longer holds in
TWINS, it is able to increase the gradient magnitude with-out increasing the gradient variance. At the initial training stage, TWINS has a faster escaping speed from the sub-optimal initialization than vanilla adversarial training [41].
At the final training stage, the gradient of TWINS is more stable than adversarial training, which alleviates the robust
overfitting effect [56]. In summary, the contributions of our paper are as follows: 1. We focus on the fine-tuning of large-scale robust pre-trained models as a result of their potential importance in various downstream tasks. We evaluate current ap-proaches to retain the pre-training robustness in fine-tuning, and show that they cannot substantially im-prove the robustness. 2. We propose TWINS, a statistics-based approach for better transferability of robustness and generalization from the pre-training domain to the target domain.
TWINS has two benefits: a) it keeps the robust statis-tics for downstream tasks, thus helps the transfer the robustness to downstream tasks and b) it enlarges the gradient magnitude without increasing gradient vari-ance, thus helps the model escape from the initializa-tion faster and mitigates robust overfitting. The mech-anisms of these two benefits are validated by our em-pirical study. 3. The effectiveness of TWINS is corroborated on five downstream datasets by comparing with two popu-lar adversarial training baselines, adversarial training (AT) [48] and TRADES [64]. On average, TWINS improves the clean and robust accuracy by 2.18% and 1.21% compared with AT, and by 1.46% and 0.69% compared with TRADES. The experiment shows the strong potential of robust pre-trained models in boost-ing downstream’s robustness and generalization when using more effective fine-tuning methods. 2.