Abstract
In this paper, a novel virtual try-on algorithm, dubbed
SAL-VTON, is proposed, which links the garment with the person via semantically associated landmarks to alleviate misalignment. The semantically associated landmarks are a series of landmark pairs with the same local seman-tics on the in-shop garment image and the try-on image.
Based on the semantically associated landmarks, SAL-VTON effectively models the local semantic association between garment and person, making up for the misalign-ment in the overall deformation of the garment.
The outcome is achieved with a three-stage framework: 1) the semantically associated landmarks are estimated using the landmark localization model; 2) taking the landmarks as input, the warping model explicitly associates the corre-sponding parts of the garment and person for obtaining the local flow, thus refining the alignment in the global flow; 3) finally, a generator consumes the landmarks to better capture local semantics and control the try-on results. Moreover, we propose a new landmark dataset with a unified labelling rule of landmarks for diverse
Extensive experimental results on styles of garments.
*Co-first authors contributed equally, † Corresponding author. popular datasets demonstrate that SAL-VTON can handle misalignment and outperform state-of-the-art methods both qualitatively and quantitatively. The dataset is available on https://modelscope.cn/datasets/damo/SAL-HG/summary. 1.

Introduction
In recent years, with the rapid popularization of online try-on [6, 9, 16, 32, 52] has attracted shopping, virtual extensive attention for its potential applications.
Image-based virtual try-on [4, 34, 49] aims to synthesize a photo-realistic try-on image by transferring a garment image onto the corresponding region of a person. Commonly, there are significant spatial geometric gaps between the in-shop garment image and the person image, leading to garments failing to align the corresponding body parts of person.
To address the above issue, prior arts take geometric deformation models to align the garment with the person’s body.
Early works [16, 22, 43] widely use the Thin-Plate Spline (TPS) deformation model [39], whereas the smoothness constraint of TPS transformation limits the warping capacity. Recently, the flow operation is applied, with a high dimension of freedom to warp garments [5, 11, 15, 18]. Nonetheless, the flow operation falls short on gar-ment regions with large deformation. The aforementioned methods focus on modeling the overall deformation of the garment, but ignore the local semantic association between garment and person. Therefore, when there are large local deformations of garments, the try-on results usually occur misalignment, such as missing or mixing garments (see left part of Fig. 1). To address the local misalignment problem,
Xie et al. [46] introduce the patch-routed disentanglement module to splice different parts of the garment. However, this method may result in significant blank spaces between spliced parts of the garment.
Fortunately, the landmarks in the garment image and the person image naturally have local semantic associations. As can be observed from Fig. 2, the pixels around landmark A on the try-on result should come from the landmark A′ area on the garment. Such a pair of landmarks with the same local semantics are referred to as semantically associated landmarks. Based on this observation, this paper presents a novel virtual try-on algorithm named SAL-VTON, which links the garment with the person via semantically as-sociated landmarks to help align the garment with the person. Notably, the proposed approach varies differently from the previous landmark-guided try-on methods [28,37].
LM-VTON [28] and LG-VTON [37] utilize landmarks to supervise the TPS transformation. However, the potential of local semantic association has not been fully explored, and the limited degrees of freedom of TPS transformation further hinder performance improvements. SAL-VTON, for the first time, introduces the local flow estimated via semantically associated landmarks to effectively model the local semantic association.
In addition, a generator with
Landmark-Aware Semantic Normalization Layer (LASNL) is carried out to better capture local semantics.
Specifically, the proposed SAL-VTON consists of three stages. Firstly, the semantically associated landmarks are estimated using the landmark localization model. Sub-sequently, the semantically associated landmarks are em-ployed as a new representation for virtual try-on, and fed into the warping model. Based on the semantically associated landmarks and learnable deformable patches, the warping model explicitly associates the corresponding parts of the garment and person to obtain the local flow, which contributes significantly to refine the poor alignment in the global flow. Finally, conditioned on the landmarks, the LASNL generator can achieve improved alignment in virtual try-on images. The estimated landmarks on the try-on result assist the generator in determining if a specific region needs to generate corresponding garment parts. In this way, SAL-VTON can effectively model the local semantic association between the garment and the person, making up for the misalignment in the overall deformation of the garment. Moreover, the try-on results of SAL-VTON can be precisely controlled by manually manipulating the
Figure 2. An example for the semantically associated landmarks on the in-shop garment image and the try-on image. landmarks (see right part of Fig. 1).
To this end, we re-annotate images on the popular virtual try-on benchmarks including VITON [16] and VITON-HD
[4] datasets. Existing popular clothing landmark datasets
[12, 54] adopt different landmark definitions for different
In contrast to other datasets, we categories of garments. adopt a unified labelling rule of landmarks for diverse styles of garments, including both standard and non-standard va-rieties. In the proposed dataset 1, every image is annotated with 32 landmarks, each of which possesses three kinds of attributes: visible, occluded and absent. The landmarks with the same serial number have the same semantics, which enhances the universality of the dataset.
This work makes the following main contributions: (1)
A novel virtual try-on algorithm, SAL-VTON, is proposed, which links the garment with the person via semantically associated landmarks. SAL-VTON, for the first time, intro-duces the local flow that can alleviate the misalignment and the LASNL generator for virtual try-on. (2) A new land-mark dataset is proposed, providing a new representation for virtual try-on, with a unified labelling rule of landmarks for diverse styles of garments. (3) Extensive experiments over two popular datasets demonstrate that SAL-VTON is capable of handling misalignment and significantly out-performs other state-of-the-art methods. Furthermore, the extended experiments show that the virtual try-on results can be edited via the landmarks. 2.