Abstract
Despite the impressive performance obtained by recent single-image hand modeling techniques, they lack the capa-bility to capture sufficient details of the 3D hand mesh. This deficiency greatly limits their applications when high-fidelity hand modeling is required, e.g., personalized hand model-ing. To address this problem, we design a frequency split network to generate 3D hand mesh using different frequency bands in a coarse-to-fine manner. To capture high-frequency personalized details, we transform the 3D mesh into the frequency domain, and propose a novel frequency decom-position loss to supervise each frequency component. By leveraging such a coarse-to-fine scheme, hand details that correspond to the higher frequency domain can be preserved.
In addition, the proposed network is scalable, and can stop the inference at any resolution level to accommodate dif-ferent hardware with varying computational powers. To quantitatively evaluate the performance of our method in terms of recovering personalized shape details, we intro-duce a new evaluation metric named Mean Signal-to-Noise
Ratio (MSNR) to measure the signal-to-noise ratio of each mesh frequency component. Extensive experiments demon-strate that our approach generates fine-grained details for high-fidelity 3D hand reconstruction, and our evaluation metric is more effective for measuring mesh details com-pared with traditional metrics. The code is available at https://github.com/tyluann/FreqHand. 1.

Introduction
High-fidelity and personalized 3D hand modeling have seen great demand in 3D games, virtual reality, and the emerging Metaverse, as it brings better user experiences, e.g., users can see their own realistic hands in the virtual space instead of the standard avatar hands. Therefore, it is
Figure 1. An exemplar hand mesh of sufficient details and its graph frequency decomposition. The x-axis shows frequency compo-nents from low to high. The y-axis shows the amplitude of each component in the logarithm. At the frequency domain, the signal amplitude generally decreases as the frequency increases. of great importance to reconstruct high-fidelity hand meshes that can adapt to different users and application scenarios.
Despite previous successes in 3D hand reconstruction and modeling [3, 6, 7, 16, 22, 40, 44, 46], few existing solutions focus on enriching the details of the reconstructed shape, and most current methods fail to generate consumer-friendly high-fidelity hands. When we treat the hand mesh as graph signals, like most natural signals, the low-frequency compo-nents have larger amplitudes than those of the high-frequency parts, which we can observe in a hand mesh spectrum curve (Fig. 1). Consequently, if we generate the mesh purely in the spatial domain, the signals of different frequencies could be biased, thus the high-frequency information can be eas-ily overwhelmed by its low-frequency counterpart. More-over, the wide usage of compact parametric models, such as
MANO [32], has limited the expressiveness of personalized details. Even though MANO can robustly estimate the hand pose and coarse shape, it sacrifices hand details for compact-ness and robustness in the parameterization process, so the detail expression ability of MANO is suppressed.
To better model detailed 3D shape information, we trans-form the hand mesh into the graph frequency domain, and
design a frequency-based loss function to generate high-fidelity hand mesh in a scalable manner. Supervision in the frequency domain explicitly constrains the signal of a given frequency band from being influenced by other fre-quency bands. Therefore, the high-frequency signals of hand shape will not be suppressed by low-frequency sig-nals despite the amplitude disadvantage. To improve the expressiveness of hand models, we design a new hand model of 12, 337 vertices that extends previous parametric models such as MANO with nonparametric representation for resid-ual adjustments. While the nonparametric residual expresses personalized details, the parametric base ensures the over-all structure of the hand mesh, e.g., reliable estimation of hand pose and 3D shape. Instead of fixing the hand mesh resolution, we design our network architecture in a coarse-to-fine manner with three resolution levels U-net for scalability.
Different levels of image features contribute to different levels of detail. Specifically, we use low-level features in high-frequency detail generation and high-level features in low-frequency detail generation. At each resolution level, our network outputs a hand mesh with the corresponding resolution. During inference, the network outputs an increas-ingly higher resolution mesh with more personalized details step-by-step, while the inference process can stop at any one of the three resolution levels.
In summary, our contributions include the following. 1. We design a high-fidelity 3D hand model for reconstruct-ing 3D hand shapes from single images. The hand repre-sentation provides detailed expression, and our frequency decomposition loss helps to capture the personalized shape information. 2. To enable computational efficiency, we propose a fre-quency split network architecture to generate high-fidelity hand mesh in a scalable manner with multiple levels of de-tail. During inference, our scalable framework supports budget-aware mesh reconstruction when the computa-tional resources are limited. 3. We propose a new metric to evaluate 3D mesh details. It better captures the signal-to-noise ratio of all frequency bands to evaluate high-fidelity hand meshes. The effec-tiveness of this metric has been validated by extensive experiments.
We evaluate our method on the InterHand2.6M dataset [29]. In addition to the proposed evaluation met-rics, we also evaluate mean per joint position error (MPJPE) and mesh Chamfer distance (CD). Compared to MANO and other baselines, our proposed method achieves better results using all three metrics. 2.