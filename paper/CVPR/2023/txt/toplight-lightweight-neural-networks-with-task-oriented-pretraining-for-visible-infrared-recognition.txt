Abstract
Visible-infrared recognition (VI recognition) is a chal-lenging task due to the enormous visual difference across heterogeneous images. Most existing works achieve promis-ing results by transfer learning, such as pretraining on the ImageNet, based on advanced neural architectures like
ResNet and ViT. However, such methods ignore the neg-ative influence of the pretrained colour prior knowledge, as well as their heavy computational burden makes them hard to deploy in actual scenarios with limited resources.
In this paper, we propose a novel task-oriented pretrained lightweight neural network (TOPLight) for VI recognition.
Specifically, the TOPLight method simulates the domain conflict and sample variations with the proposed fake do-main loss in the pretraining stage, which guides the network to learn how to handle those difficulties, such that a more general modality-shared feature representation is learned for the heterogeneous images. Moreover, an effective fine-grained dependency reconstruction module (FDR) is devel-oped to discover substantial pattern dependencies shared in two modalities. Extensive experiments on VI person re-identification and VI face recognition datasets demonstrate the superiority of the proposed TOPLight, which signifi-cantly outperforms the current state of the arts while de-manding fewer computational resources. 1.

Introduction
Identity recognition technologies have provided numer-ous reliable solutions for monitoring systems, which strive to match the face (face recognition [6, 7]) or pedestrian (person re-identification [42]) images of the same identity.
However, the majority of previous efforts only consider vis-ible images. In real-life practice, many surveillance cam-eras can switch to infrared imaging mode at night. Thus, the essential cross-modality visible-infrared recognition (VI
*Corresponding Author (Email: xcheng@nuist.edu.cn) (a) The task-oriented pretraining strategy; (b) Per-Figure 1. formance comparison of the standard ImageNet-1k pretraining scheme (SP) and the proposed task-oriented pretraining scheme (TOP) on the SYSU-MM01 dataset [35] (All-Search mode). recognition) technology has been developed to match the visible and infrared photographs of the same people.
Recently, visible-infrared person re-identification (VI-ReID) [26, 38] and visible-infrared face recognition [8, 13, 44] have been widely studied. The key issue is identi-fying the modality-shared patterns. To this end, several works [29, 30] use generative adversarial networks (GANs) to implement cross-modality alignment at the pixel and fea-ture levels. Others [4, 26, 38] design the dual-path feature extraction network, coupled with inter-feature constraints, to close the embedding space of two modalities. However, these methods utilize at least one pretrained ResNet-50 [12] backbone to extract solid features, which makes them un-suitable for edge monitoring devices. Recent works [4, 38] employ auxiliary models (e.g., pose estimation, graph rea-soning) to relieve the modality discrepancy, which enhances the performance on academic benchmarks but reduces the real-time inference speed. Compared with conventional deep networks (e.g., ResNet, ViT), lightweight networks
[11,15,24] can extract basal features rapidly. In VI recogni-tion tasks, however, the vast modality discrepancy renders the performance of lightweight networks significantly infe-rior to that of conventional deep networks. The main rea-son is that lightweight networks lack the ability to identify modality-shared patterns from heterogeneous images.
To address this issue, we present an effective task-oriented pretraining (TOP) strategy. As shown in Fig. 1(a), we first train a lightweight network on the ImageNet-1k dataset to learn vision prior knowledge. After that, the trained network is transformed into the dual-path network and further trained by using task-oriented data augmenta-tions, identity consistency loss and fake domain loss on the ImageNet-mini dataset [18]. The task-oriented pretrain-ing (TOP) strategy simulates the sample differences in VI scenes and teaches the network how to represent and em-bed discrepant features. Fig. 1(b) reports the performance of three lightweight networks in the VI-ReID task. Com-pared with the ImageNet-1k pretraining, our TOP strategy can remarkably improve the baseline performance.
Another weakness of lightweight networks is that few feature maps are learned from raw images for rapid infer-ence. In the VI recognition scene, it is challenging to dis-cover modality-shared patterns with so few learned feature maps. In practice, the network can focus on a group of ag-gregated modality-specific patterns that offer the most gra-dient for identity classification. In contrast, the fine-grained and modality-shared patterns, which are crucial for achiev-ing robust cross-modality matching, are neglected.
Based on the above observations, we present a novel fine-grained dependency reconstruction (FDR) module to help lightweight networks learn modality-shared and fine-grained patterns. Specifically, inspired by the horizontal slice scheme [1], we first slice feature maps horizontally and vertically to extract fine-grained patterns from diver-sified local regions. Then, the original spatial dependen-cies of these patterns are eliminated by using pooling oper-ations. Further, the cross-modality dependencies are built by using up-sampling layers to amplify the modality-shared parts from these patterns. At last, to avoid overfitting, the shuffle attention is designed to re-weight the channel depen-dencies of all the feature maps, which spreads attention to local patterns as much as possible. In general, the major contributions of this paper can be summarized as follows.
• We propose an effective task-oriented pretrained lightweight neural network (TOPLight) for VI recog-nition. To the best of our knowledge, it is the first work to develop a paradigm for VI recognition on edge de-vices with an extremely low computation budget.
• An effective task-oriented pretraining strategy is pro-posed to enhance the heterogeneous feature learning capacity of lightweight networks with task-oriented augmentations and the proposed fake domain loss.
• A fine-grained dependency reconstruction module is designed to mine cross-modality dependencies.
• Extensive experiments demonstrate that the proposed method outperforms the state-of-the-art methods on mainstream VI-ReID and VI face recognition datasets by a remarkable margin and extremely low complexity. 2.