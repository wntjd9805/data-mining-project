Abstract
Volumetric scene representations enable photorealistic view synthesis for static scenes and form the basis of several ex-isting 6-DoF video techniques. However, the volume render-ing procedures that drive these representations necessitate careful trade-offs in terms of quality, rendering speed, and memory efficiency. In particular, existing methods fail to simultaneously achieve real-time performance, small mem-ory footprint, and high-quality rendering for challenging real-world scenes. To address these issues, we present Hy-perReel — a novel 6-DoF video representation. The two core components of HyperReel are: (1) a ray-conditioned sample prediction network that enables high-fidelity, high frame rate rendering at high resolutions and (2) a compact and memory-efficient dynamic volume representation. Our 6-DoF video pipeline achieves the best performance compared to prior and contemporary approaches in terms of visual quality with small memory requirements, while also rendering at up to 18 frames-per-second at megapixel resolution without any custom CUDA code. 1
1.

Introduction
Six–Degrees-of-Freedom (6-DoF) videos allow for free ex-ploration of an environment by giving the users the ability to change their head position (3 degrees of freedom) and orientation (3 degrees of freedom). As such, 6-DoF videos offer immersive experiences with many exciting applications in AR/VR. The underlying methodology that drives 6-DoF video is view synthesis: the process of rendering new, unob-served views of an environment—static or dynamic—from a set of posed images or videos. Volumetric scene representa-tions such as neural radiance fields [31] and instant neural graphics primitives [32] have recently made great strides toward photorealistic view synthesis for static scenes.
While several recent works build dynamic view synthe-sis pipelines on top of these volumetric representations
[14, 23, 24, 35, 64], it remains a challenging task to cre-ate a 6-DoF video format that can achieve high quality, fast rendering, and a small memory footprint (even given many synchronized video streams from multi-view camera rigs [9, 37, 46]). Existing approaches that attempt to create memory-efficient 6-DoF video can take nearly a minute to render a single megapixel image [23]. Works that target ren-dering speed and represent dynamic volumes directly with 3D textures require gigabytes of storage even for short video clips [59]. While other volumetric methods achieve memory efficiency and speed by leveraging sparse or compressed volume storage for static scenes [11, 32], only contemporary work [22, 51] addresses the extension of these approaches to dynamic scenes. Moreover, all of the above representations struggle to capture highly view-dependent appearance, such as reflections and refractions caused by non-planar surfaces.
In this paper, we present HyperReel, a novel 6-DoF video representation that achieves state-of-the-art quality while being memory efficient and real-time renderable at high res-olution. The first ingredient of our approach is a novel ray-conditioned sample prediction network that predicts sparse point samples for volume rendering. In contrast to exist-ing static view synthesis methods that use sample networks
[20, 33], our design is unique in that it both (1) acceler-ates volume rendering and at the same time (2) improves rendering quality for challenging view-dependent scenes.
Second, we introduce a memory-efficient dynamic vol-ume representation that achieves a high compression rate by exploiting the spatio-temporal redundancy of a dynamic scene. Specifically, we extend Tensorial Radiance Fields [11] to compactly represent a set of volumetric keyframes, and capture intermediate frames with trainable scene flow.
The combination of these two techniques comprises our high-fidelity 6-DoF video representation, HyperReel. We validate the individual components of our approach and our representation as a whole with comparisons to state-of-the-art sampling network-based approaches for static scenes as well as 6-DoF video representations for dynamic scenes. Not only does HyperReel outperform these existing works, but it also provides high-quality renderings for scenes with chal-lenging non-Lambertian appearances. Our system renders at up to 18 frames-per-second at megapixel resolution without using any custom CUDA code.
The contributions of our work include the following: 1. A novel sample prediction network for volumetric view synthesis that accelerates volume rendering and accu-rately represents complex view-dependent effects. 2. A memory-efficient dynamic volume representation that compactly represents a dynamic scene. 3. HyperReel, a 6-DoF video representation that achieves a desirable trade-off between speed, quality, and mem-ory, while rendering in real time at high resolutions. 2.