Abstract
In this paper, we propose multi-agent automated ma-chine learning (MA2ML) with the aim to effectively han-dle joint optimization of modules in automated machine learning (AutoML). MA2ML takes each machine learning module, such as data augmentation (AUG), neural archi-tecture search (NAS), or hyper-parameters (HPO), as an agent and the final performance as the reward, to formu-late a multi-agent reinforcement learning problem. MA2ML explicitly assigns credit to each agent according to its marginal contribution to enhance cooperation among mod-ules, and incorporates off-policy learning to improve search efficiency. Theoretically, MA2ML guarantees monotonic improvement of joint optimization. Extensive experiments show that MA2ML yields the state-of-the-art top-1 accuracy on ImageNet under constraints of computational cost, e.g., 79.7%/80.5% with FLOPs fewer than 600M/800M. Exten-sive ablation studies verify the benefits of credit assignment and off-policy learning of MA2ML. 1.

Introduction
Automated machine learning (AutoML) aims to find high-performance machine learning (ML) pipelines without human effort involvement. The main challenge of AutoML lies in finding optimal solutions in huge search spaces.
In recent years, reinforcement learning (RL) has been validated to be effective to optimize individual AutoML modules, such as data augmentation (AUG) [4], neural ar-chitecture search (NAS) [25, 53, 54], and hyper-parameter optimization (HPO) [38]. However, when facing the huge search space (Figure 1 left) and the joint optimization of these modules, the efficiency and performance challenges remain.
Through experiments, we observed that among AutoML modules there exists a cooperative relationship that facilities the joint optimization of modules. For example, a small net-work (ResNet-34) with specified data augmentation and op-†The work was done during his Master program at Peking University.
‡Correspondence to (cid:66) zongqing.lu@pku.edu.cn
Figure 1. Search spaces of machine learning pipelines. Left: sin-gle agent controls all modules, and the huge search space makes it ineffective to learn. Mid: each agent controls one module, and the learning difficulty is reduced by introducing MA2ML. Right:
MA2ML guarantees monotonic improvement of the searched pipeline, where pk and R(pk) denote the k-th searched pipeline and its expected performance, respectively. timized hyper-parameters significantly outperforms a large one (ResNet-50) with default training settings (76.8% vs. 76.1%).
In other words, good AUG and HPO alleviate the need for NAS to some extent. Accordingly, we pro-pose multi-agent automated machine learning (MA2ML), which explores the cooperative relationship towards joint optimization of ML pipelines.
In MA2ML, ML modules are defined as RL agents (Figure 1 mid), which take ac-tions to jointly maximize the reward, so that the training ef-ficiency and test accuracy are significantly improved. Spe-cially, we introduce credit assignment to differentiate the contribution of each module, such that all modules can be simultaneously updated. To handle both continuous (e.g., learning rate) and discrete (e.g., architecture) action spaces,
MA2ML employs a multi-agent actor-critic method, where a centralized Q-function is learned to evaluate the joint ac-tion. Besides, to further improve search efficiency, MA2ML adopts off-policy learning to exploit historical samples for policy updates.
MA2ML is justified theoretically and experimentally.
Theoretically, we prove that MA2ML guarantees mono-tonic policy improvement (Figure 1 right), i.e., the per-formance of the searched pipeline monotonically improves in expectation. This enables MA2ML to fit the joint op-timization problem and be adaptive to all modules in the
ML pipeline, potentially achieving full automation. Exper-imentally, we take the combination of individual RL-based modules to form MA2ML-Lite, and compare their perfor-mance on ImageNet [31] and CIFAR-10/100 [20] datasets.
To better balance performance and computational cost, we add constraints of FLOPs in the experiment on ImageNet.
Experiments show that MA2ML substantially outperforms
MA2ML-Lite w.r.t. both accuracy and sample efficiency, and MA2ML achieves remarkable accuracy compared with recent methods.
Our contributions are summarized as follows:
• We propose MA2ML, which utilizes credit assignment to differentiate the contributions of ML modules, pro-viding a systematic solution for the joint optimization of AutoML modules.
• We prove the monotonic improvement of module poli-cies, which enables to MA2ML fit the joint optimiza-tion problem and be adaptive to various modules in the
ML pipeline.
• MA2ML yields the state-of-the-art performance under constraints of computational cost, e.g., 79.7%/80.5% on ImageNet, with FLOPs fewer than 600M/800M, validating the superiority of the joint optimization of
MA2ML. 2.