Abstract
While long-tailed semi-supervised learning (LTSSL) has received tremendous attention in many real-world classi-fication problems, existing LTSSL algorithms typically as-sume that the class distributions of labeled and unlabeled data are almost identical. Those LTSSL algorithms built upon the assumption can severely suffer when the class dis-tributions of labeled and unlabeled data are mismatched since they utilize biased pseudo-labels from the model. To alleviate this issue, we propose a new simple method that can effectively utilize unlabeled data of unknown class dis-tributions by introducing the adaptive consistency regular-izer (ACR). ACR realizes the dynamic refinery of pseudo-labels for various distributions in a unified formula by esti-mating the true class distribution of unlabeled data. Despite its simplicity, we show that ACR achieves state-of-the-art performance on a variety of standard LTSSL benchmarks, e.g., an averaged 10% absolute increase of test accuracy against existing algorithms when the class distributions of labeled and unlabeled data are mismatched. Even when the class distributions are identical, ACR consistently outper-forms many sophisticated LTSSL algorithms. We carry out extensive ablation studies to tease apart the factors that are most important to ACRâ€™s success. Source code is available at https://github.com/Gank0078/ACR. 1.

Introduction
Semi-supervised learning (SSL) is an effective way of using unlabeled data to improve the generalization of deep neural networks (DNNs) [1, 10, 16] when only a limited amount of labeled data is accessible [3, 23, 29, 31]. The core idea of most SSL algorithms is to generate pseudo-labels for unlabeled data and select confident ones to train models. Recent progress on SSL has revealed promising
Tong Wei is the corresponding author. This research was supported by the National Science Foundation of China (62206049). performance in various tasks, such as image recognition
[29] and text categorization [35, 39]. However, most exist-ing SSL algorithms assume the datasets are class-balanced, i.e., each class is associated with an equivalent number of
In con-samples in both labeled and unlabeled datasets. trast, class distributions in many real-world tasks are long-tailed [6, 19, 33, 38, 43].
It is well known that classifiers trained on long-tailed datasets tend to be biased towards majority classes, leading to low test accuracy on minority classes [20, 37, 44].
To improve the performance, many long-tailed semi-supervised learning (LTSSL) algorithms have been pro-posed to generate unbiased pseudo-labels. They pursue class-balanced classifiers using techniques including re-sampling [18], re-weighting [17], label smoothing [36], and pseudo-label alignment [14, 34]. These algorithms have shown strong generalization for the minority class by as-suming the class distributions of labeled and unlabeled data are almost identical. However, this assumption is frequently violated in real-world applications, for instance, if the la-beled and unlabeled data are collected from different tasks.
The unlabeled data may have a large class distribution gap from labeled data, and using the erroneous assumption can severely deteriorate the performance [17, 25].
Contribution. This paper studies the under-explored yet practical LTSSL problem, i.e., learning from unlabeled data of unknown class distributions. Notably, we start with three representative types of class distributions of unlabeled data, i.e., consistent, uniform, and reversed, as illustrated in Fig-ures 1a to 1c. We then propose a new simple algorithm to effectively use unlabeled data through the adaptive con-sistency regularizer (ACR), which is built upon one of the most popular SSL algorithms FixMatch [29]. Concretely,
ACR is developed based on two findings: i) to learn a class-balanced classifier, it is helpful to generate pseudo-labels biased appropriately toward the minority class, whereas ii) to learn a better feature extractor, the accuracy of pseudo-labels is critical. Those two findings seem to contradict.
We thus present a two-branch network, including a bal-anced branch and a standard branch, to resolve this con-(a) Consistent class distribution (b) Uniform class distribution (c) Reversed class distribution (d) F1 gain of pseudo-labels
Figure 1. (1a to 1c): Three typical types of class distribution of unlabeled data. (1d): F1 gain due to our method ACR compares to a recent state of the art DASO [25] under three types of class distributions of unlabeled data. We can see that ACR significantly improves the quality of pseudo-labels, showing its great capability of taking advantage of unlabeled data to alleviate the class imbalance problem. flict. Specifically, ACR learns a class-balanced classifier via imposing consistency between its predictions and the adjusted outputs of the standard classifier. The adjusted outputs are designed to be appropriately biased toward the minority class. However, for the second finding, it is ob-served that the accuracy of pseudo-labels produced by the standard classifier varies as the class distribution of unla-beled data changes. We resolve this difficulty by refining the original pseudo-labels to match the true class distribu-tion of unlabeled data and enhance their accuracy. Impor-tantly, ACR realizes the adaptive refinery of pseudo-labels for various distributions in a unified formula by estimating the true class distribution.
We demonstrate the effectiveness of the proposed ap-proach under various realistic LTSSL scenarios by varying the class distributions of unlabeled data. Despite its sim-plicity, the proposed algorithm improves recent LTSSL al-gorithms in all test cases, e.g., our method improves DARP
[14], CReST [34], DASO [25] with up to 10.8%, 11.2%, and 7.2% absolute increase on the test accuracy, respec-tively. Nevertheless, more importantly, in addition to three types of representative class distributions, i.e., consistent, uniform, and reversed, we also test our method under many other class distributions. As expected, our method signif-icantly improves the performance when the class distribu-tions are mismatched between labeled and unlabeled data. 2.