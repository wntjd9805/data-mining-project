Abstract
With the ever-increasing popularity of edge devices, it is necessary to implement real-time segmentation on the edge for autonomous driving and many other applications. Vi-sion Transformers (ViTs) have shown considerably stronger results for many vision tasks. However, ViTs with the full-attention mechanism usually consume a large number of computational resources, leading to difficulties for real-time inference on edge devices. In this paper, we aim to de-rive ViTs with fewer computations and fast inference speed to facilitate the dense prediction of semantic segmentation on edge devices. To achieve this, we propose a pruning pa-rameterization method to formulate the pruning problem of semantic segmentation. Then we adopt a bi-level optimiza-tion method to solve this problem with the help of implicit gradients. Our experimental results demonstrate that we can achieve 38.9 mIoU on ADE20K val with a speed of 56.5
FPS on Samsung S21, which is the highest mIoU under the same computation constraint with real-time inference. 1.

Introduction
Inspired by the extraordinary performance of Deep Neu-ral Networks (DNNs), DNNs have been applied to various tasks.
In this work, we focus on semantic segmentation, which aims to assign a class label to each pixel of an image to perform a dense prediction. It plays an important role in many real-world applications, such as autonomous driving.
However, as a dense prediction task, segmentation models usually have complicated multi-scale feature fusion struc-tures with large feature sizes, leading to tremendous mem-ory and computation overhead with slow inference speed.
To reduce the memory and computation cost, certain lightweight CNN architectures [21, 40, 66] are designed for efficient segmentation. Besides CNNs, inspired by the re-cent superior performance of vision transformers (ViTs)
*These authors contributed equally to this work.
Figure 1. Comparison of accuracy versus FPS on ADE20K.
[17], some works [10, 11, 72] adopt ViTs in segmentation tasks to explore self-attention mechanism with the global receptive field. However, it is still difficult for ViTs to re-duce the computation cost of the dense prediction for seg-mentation with large feature sizes.
With the wide spread of edge devices such as mobile phones, it is essential to perform real-time inference of seg-mentation on edge devices in practice. To facilitate mo-bile segmentation, the state-of-the-art work TopFormer [68] adopts a token pyramid transformer to produce scale-aware semantic features with tokens from various scales. It signif-icantly outperforms CNN- and ViT-based networks across different semantic segmentation datasets and achieves a good trade-off between accuracy and latency. However, it only partially optimizes the token pyramid module, which costs most of the computations and latency.
In this work, we propose a pruning parameterization method with bi-level optimization to further enhance the performance of TopFormer. Our objective is to search for a suitable layer width for each layer in the token pyramid
module, which is the main cost of computations and latency (over 60%). To achieve this, we first formulate the problem with pruning parameterization to build a pruning framework with a soft mask as a representation of the pruning policy.
With this soft mask, we further adopt thresholding to con-vert the soft mask into a binary mask so that the model is trained with actual pruned weights to obtain pruning results directly. This is significantly different from other meth-ods [27, 47] to train with unpruned small non-zero weights and use fine-tuning to mitigate the performance degradation after applying pruning. Besides, to update the soft mask as long as the pruning policy, we adopt to straight though es-timator (STE) method to make the soft mask differentiable.
Thus, we can build the pruning parameterization framework with minimal overhead.
Based on this framework, we need to search the best-suited layer width for each layer in the token pyramid mod-It is non-trivial to perform the search. As the to-ule. ken pyramid module needs to extract multi-scale informa-tion from multiple spatial resolutions, the large hierarchical search space leads to difficulties of convergence. To resolve this problem, we adopt a bi-level optimization method. In the outer optimization, we try to obtain the pruning pol-icy based on the pruning parameters (the soft mask).
In the inner optimization, the optimized model weights with the best segmentation performance under this soft mask can be obtained. Compared with a typical pruning method, our work incorporates the implicit gradients with second-order derivatives to further guide the update of the soft mask and achieve better performance. Our experimental results demonstrate that we can achieve 38.9 mIoU (mean class-wise intersection-over-union) on the ADE20K dataset with a speed of 56.5 FPS on Samsung S21, which is the highest mIoU under the same computation constraint with real-time inference speed. As demonstrated in Figure 1, our models can achieve a better tradeoff between the mIoU and speed.
We summarize our contributions below,
• We propose a pruning parameterization method to build a pruning framework with a soft mask. We further use a threshold-based method to convert the soft mask into the binary mask to perform actual pruning during model training and inference. Besides, STE is adopted to update the soft mask efficiently through gradient descent opti-mizers.
• To solve the pruning problem formulated with the frame-work of pruning parameterization, we propose a bi-level optimization method to utilize implicit gradients for bet-ter results. We show that the second-order derivatives in the implicit gradients can be efficiently obtained through first-order derivatives, saving computations and memory.
• Our experimental results demonstrate that we can achieve the highest mIoU under the same computation constraint on various datasets. Specifically, we can achieve 38.9 mIoU on the ADE20K dataset with a real-time inference speed of 56.5 FPS on the Samsung S21. 2.