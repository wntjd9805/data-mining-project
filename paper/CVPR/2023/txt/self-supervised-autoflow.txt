Abstract
Recently, AutoFlow has shown promising results on learning a training set for optical ﬂow, but requires ground truth labels in the target domain to compute its search met-ric. Observing a strong correlation between the ground truth search metric and self-supervised losses, we introduce self-supervised AutoFlow to handle real-world videos with-out ground truth labels. Using self-supervised loss as the search metric, our self-supervised AutoFlow performs on par with AutoFlow on Sintel and KITTI where ground truth is available, and performs better on the real-world DAVIS dataset. We further explore using self-supervised AutoFlow in the (semi-)supervised setting and obtain competitive re-sults against the state of the art. 1.

Introduction
Data is the new oil. — Clive Humby, 2006 [13]
This well-known analogy not only foretold the critical role of data for developing AI algorithms in the last decade but also revealed the importance of data curation. Like re-ﬁned oil, data must be carefully curated to be useful for
AI algorithms to succeed. For example, one key ingredient for the success of AlexNet [21] is ImageNet [36], a large dataset created by extensive manual labeling.
The manual labeling process, however, is either not ap-plicable or difﬁcult to scale to many low-level vision tasks, such as optical ﬂow. A common practice for optical ﬂow is to pre-train models using large-scale synthetic datasets, e.g.,
FlyingChairs [6] and FlyingThings3D [26], and then ﬁne-tune them on limited in-domain datasets, e.g., Sintel [4] or
KITTI [28]. While this two-step process works better than directly training on the limited target datasets, there exists a domain gap between synthetic data and the target domain.
To narrow the domain gap, AutoFlow [41] learns to ren-der a training dataset to optimize performance on a tar-get dataset, obtaining superior results on Sintel and KITTI where the ground truth is available. As obtaining ground truth optical ﬂow for most real-world data is still an open challenge, it is of great interest to remove this dependency on ground truth to apply AutoFlow to real-world videos.
In this paper, we introduce a way to remove this reliance by connecting learning to render with another independent line of research on optical ﬂow, self-supervised learning (SSL). SSL methods for optical ﬂow [15, 23–25, 53] use a set of self-supervised losses to train models using only im-age pairs in the target domain. We observe a strong corre-lation between these self-supervised losses and the ground
truth errors, as shown in Fig. 2. This motivates us to con-nect these two lines of research by adopting self-supervised losses as a search metric for AutoFlow [41], calling our ap-proach “Self-supervised AutoFlow”.
Self-supervised AutoFlow obtains similar performance to AutoFlow on Sintel [4] and KITTI [28], and it can learn a better dataset for the real-world DAVIS data [29] where ground truth is not available. To further narrow the domain gap between synthetic data and the target domain, we also explore new ways to better synergize techniques from learn-ing to render and self-supervised learning.
Numerous self-supervised methods still rely on pre-training on a synthetic dataset. Our method replaces this pre-training with supervised training on self-supervised
AutoFlow data generated using self-supervised metrics.
This new pipeline is still self-supervised and obtains com-petitive performance among all self-supervised methods.
We further demonstrate that our method provides a strong initialization for supervised ﬁne-tuning and obtains compet-itive results against the state of the art.
We make the following main contributions:
• We introduce self-supervised AutoFlow to learn to ren-der a training set for optical ﬂow using self-supervision on the target domain, connecting two independently studied directions for optical ﬂow: learning to render and self-supervised learning.
• Self-supervised AutoFlow performs competitively against AutoFlow [41] that uses ground truth on Sintel and KITTI and better on DAVIS where ground truth is not available.
• We further analyze self-supervised AutoFlow in semi-supervised and supervised settings and obtain compet-itive performance against the state of the art. 2.