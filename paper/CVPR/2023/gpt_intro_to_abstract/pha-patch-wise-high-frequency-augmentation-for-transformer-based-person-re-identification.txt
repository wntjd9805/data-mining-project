Person re-identification (ReID) is a task that aims to identify a specific person from a set of images captured by different cameras. Previous research in this field has focused on extracting discriminative person representations using Convolutional Neural Networks (CNNs), Vision Transformers (ViTs), or hybrid approaches. While the combination of CNNs and ViTs has shown improved performance, the reasons behind this improvement remain unclear. In this paper, we explore the role of frequency components in digital image processing and its impact on ReID. We compare the performance of ResNet101 and TransReID on original images, low-frequency components, and high-frequency components using the Market1501 and MSMT17 datasets. Our findings reveal that certain texture details, which are associated with high-frequency components, are crucial for ReID. Additionally, we observe that ViTs perform worse than CNNs in preserving key high-frequency components, leading to their inadequate performance in capturing important details of person images. To address this issue, we propose a Patch-wise High-frequency Augmentation (PHA) method that empowers ViTs to enhance the representation ability of high-frequency components. We introduce a novel patch-wise contrastive loss to prevent the dilution of high-frequency components during network optimization. Experimental results on various datasets demonstrate that our PHA method outperforms existing methods in person re-identification tasks.