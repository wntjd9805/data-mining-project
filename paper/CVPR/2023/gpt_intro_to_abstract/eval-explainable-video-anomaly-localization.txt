We are interested in the problem of spatio-temporal localization of anomalous activities in videos of a given scene. This work addresses a setting where we have access to an initial set of videos that define the typical activities in a scene, but it is not practical to collect a representative set of possible anomalies. Our goal is to detect events in a test video from the same scene that differ substantially from the events in the nominal set. An anomaly is defined as any spatio-temporal region in the test video that is significantly different from all the nominal video in the same spatial region.Unlike most recent work in anomaly detection, our focus is not only on detecting anomalies but also on providing clear explanations for why they are anomalous. We are motivated by how humans would detect unusual incidents while monitoring a scene. We design our video anomaly detection system to use deep networks to gain a high-level understanding of the objects and motions in a scene. We train deep networks that take a spatio-temporal region of video as input and output attribute vectors representing object classes, motion directions and speeds, and the fraction of stationary pixels. These attribute vectors provide high-level representations of appearance and motion content.Unlike other methods, we do not learn new embedding functions for each scene. Instead, we store a representative set of embeddings found in the nominal video to characterize the nominal data for a new scene. We reduce this set to a smaller set called exemplars, which represent the appearance, motion, and background characteristics of each spatial region. This results in a compact and location-dependent model of the nominal data in a new scene. Our exemplar model allows for efficient updating when new nominal video is introduced.To detect anomalies, we compute high-level features for each video volume in the test video and compare them to the exemplars stored in the nominal model. Any test feature with a high distance to every nominal exemplar is considered anomalous. The human-interpretable attributes derived from the feature vectors can be used to provide explanations for the system's decisions.In summary, our contributions include demonstrating the effectiveness of modeling scenes using high-level attributes for robust anomaly detection, introducing the idea of estimating high-level motion attributes directly from raw video volumes using deep networks, enabling human-interpretable explanations using these attributes, and proposing a practical approach that does not require training deep networks for each new scene and allows for efficient updates to the scene model.