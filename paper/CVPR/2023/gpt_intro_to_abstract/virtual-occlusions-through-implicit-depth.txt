Augmented reality and digital image editing often require the placement of virtual objects in real-world scenes, requiring realistic occlusion. This involves determining whether a pixel should display the real-world object or the virtual object. Previous approaches estimate depth to make this decision. In this paper, we propose a novel approach where a network directly estimates the occlusion mask for compositing. This binary decision simplifies the process and allows for soft blending between the real and virtual objects. We introduce metrics for occlusion evaluation and demonstrate that our method produces more accurate and visually pleasing composites compared to alternatives. We also show that our approach improves temporal consistency by using temporal smoothing methods. Our method achieves state-of-the-art occlusions and can also compute dense depth when needed. Overall, our approach improves upon previous methods by framing the problem as a segmentation task.