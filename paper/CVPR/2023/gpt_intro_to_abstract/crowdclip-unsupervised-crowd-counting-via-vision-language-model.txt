Crowd counting is a challenging task that aims to estimate the number of people in various crowd scenes. It has wide applications in public safety and urban management. Most existing crowd counting methods require costly point-level annotations, making them impractical for large-scale datasets. In this paper, we propose CrowdCLIP, a novel unsupervised crowd counting method that leverages vision-language knowledge. We use a ranking-based contrastive fine-tuning strategy to enhance the image encoder's ability to capture crowd semantics. Additionally, we introduce a progressive filtering strategy for selecting high-related crowd patches during testing. Experimental results on multiple datasets demonstrate the effectiveness of our approach, outperforming the state-of-the-art unsupervised method by a significant margin. Our work makes two major contributions: (1) We propose the first method that transfers vision-language knowledge to crowd counting, and (2) We introduce novel strategies to improve crowd counting accuracy.