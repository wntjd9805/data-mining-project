Deep learning-based semantic segmentation has shown great promise but requires large amounts of data with precise pixel-level labels, which are time-consuming and labor-intensive to collect. To address this, weakly supervised semantic segmentation (WSSS) methods have been developed, focusing on using image-level tag labels as a low-cost annotation approach. Current WSSS methods mainly focus on generating high-quality Class Activation Maps (CAMs) and pseudo labels from CAMs, but the pseudo labels generated from CAMs can be incomplete and imprecise, leading to error predictions. In this paper, we propose an Out-of-Candidate Rectification (OCR) method to rectify these prediction errors, defined as Out-of-Candidate (OC) errors. OCR involves three procedures: OC pixel selection, IC/OC categories group split, and rectification using a ranking-based approach. We demonstrate the effectiveness of OCR on the PASCAL VOC 2012 and MS COCO 2014 datasets, showing improvements in performance compared to previous methods. Our OCR module improves AffinityNet, SEAM, and MCTformer by 3.2%, 3.3%, and 0.8% mIoU on PASCAL VOC 2012, and 1.0%, 1.3%, and 0.5% mIoU on MS COCO 2014. Overall, OCR provides reasonable supervision signals and improves segmentation results without additional training or inference costs.