Recent advancements in neural rendering approaches have led to impressive results in synthesizing novel views of static scenes. However, extending these methods to dynamic scenes, which involve thin structures, specular surfaces, and topological changes, remains a challenge. Traditional mesh-based representation approaches are prone to reconstruction errors and rendering artifacts in such scenes.This paper presents a novel approach for reconstructing and rendering dynamic scenes using explicit feature grids. By modeling a 4D field using a hierarchical tri-projection decomposition technique, we avoid the high time and computation costs associated with directly using MLPs. Our decomposition method projects the 4D field into time-aware volumes, which are further decomposed into feature planes. This representation allows for efficient modeling of dynamic scenes while avoiding excessive memory consumption.Our method not only enables efficient reconstruction and compact representation of dynamic scenes but also introduces implicit constraints on the representation. By approximating the 4D tensor with a small number of lower-dimensional components, our approach acts as an inherent regularization technique, particularly in scenarios with limited input observations such as sparse and fixed cameras or monocular inputs.We demonstrate the effectiveness of our method in both sparse-view and single-view dynamic reconstruction tasks. In the sparse-view case, we apply our Tensor4D decomposition to time-conditioned radiance fields in "NeRF-T". Additionally, we show that our decomposition method can be used for single-view dynamic reconstruction by decomposing both the 4D dynamic motion field and the canonical radiance field in "D-NeRF". With proper regularization, our system enables efficient and high-quality reconstruction of dynamic objects under various camera settings.