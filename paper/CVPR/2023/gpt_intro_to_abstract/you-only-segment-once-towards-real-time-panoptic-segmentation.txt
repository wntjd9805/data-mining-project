Panoptic segmentation, which involves assigning semantic labels and instance identities to each pixel of an image, is a challenging task in computer vision. One of the main challenges is the requirement for separate and computationally intensive branches for semantic and instance segmentation. While efforts have been made to improve the speed and accuracy of panoptic segmentation pipelines, achieving real-time processing remains an open problem. This paper presents YOSO, a real-time panoptic segmentation framework that predicts panoptic kernels to convolute image feature maps. To ensure lightweight processing, YOSO utilizes a feature pyramid aggregator for extracting image feature maps and a separable dynamic decoder for generating panoptic kernels. The proposed convolution-first aggregation (CFA) in the aggregator significantly reduces GPU latency without compromising performance. The separable dynamic convolution attention (SDCA) in the decoder performs multi-head cross-attention in a weight-sharing way, achieving better accuracy and higher efficiency compared to traditional methods. YOSO demonstrates notable advantages including reduced computational burden, improved accuracy and efficiency, and competitive performance compared to state-of-the-art models. The approach is validated on popular datasets such as COCO, Cityscapes, ADE20K, and Mapillary Vistas. YOSO presents a promising solution towards real-time panoptic segmentation with competitive accuracy.