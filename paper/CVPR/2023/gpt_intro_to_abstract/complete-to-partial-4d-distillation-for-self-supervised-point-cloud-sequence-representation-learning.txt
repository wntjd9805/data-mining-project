The paper introduces the concept of self-supervised representation learning for 4D point cloud sequences, which are widely used in applications such as robotics and augmented reality. The authors highlight the limitations of existing methods in capturing both the geometry and motion information in a dynamic context. To address this, they propose a Complete-to-Partial 4D Distillation (C2P) approach, which formulates the learning as a teacher-student knowledge distillation framework. The authors present a unified solution to three key questions: how to aggregate sequential geometry leveraging motion cues, how to predict motion based on better geometric understanding, and how to form a stable and high-quality teacher. They describe the design of the C2P method, which includes partial-view 4D sequence generation, multi-frame geometry completion, and asymmetric teacher-student distillation. The authors evaluate their method on three downstream tasks and demonstrate significant improvements over previous methods. The contributions of the paper include proposing a new 4D representation learning method, introducing a novel approach to generate partial-view 4D sequences, highlighting the importance of asymmetric design in knowledge distillation, and demonstrating superior performance in multiple tasks.