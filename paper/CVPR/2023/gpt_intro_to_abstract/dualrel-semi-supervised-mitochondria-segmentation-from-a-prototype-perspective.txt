Mitochondria are essential organelles that provide energy for cell activities and play a crucial role in metabolism. Quantification of mitochondrial morphology has implications for both basic scientific research and clinical diagnosis. Recent advancements in deep learning have enabled the exploration of mitochondrial morphology through semantic segmentation of high-resolution electron microscopy images. However, the cluttered nature of these images and the labor-intensive manual discrimination required limit the flexibility and scalability of existing methods. To address this, we propose a semi-supervised segmentation approach that leverages the assumption of large amounts of unlabeled data. Previous works in natural image segmentation, such as CPS, impose pixel-level consistency regularization but are not directly applicable to mitochondria segmentation due to the significant differences in image characteristics. We observe that unreliable pixels and prototypes contribute to the unreliability of pixel-level supervision. To overcome this issue, we introduce a Dual-Reliable (DualRel) network comprising a reliable pixel aggregation module and a reliable prototype selection module. The reliable pixel aggregation module employs referential correlation to rectify direct pairwise correlations, while the reliable prototype selection module uses a reliability-aware consistency loss to evaluate the reliability of prototypes. Our contributions include providing insights into the gap between mitochondrial and natural images and proposing a novel semi-supervised segmentation framework that outperforms existing methods on three benchmark datasets. Furthermore, our method achieves comparable performance to fully supervised methods even with limited training data.