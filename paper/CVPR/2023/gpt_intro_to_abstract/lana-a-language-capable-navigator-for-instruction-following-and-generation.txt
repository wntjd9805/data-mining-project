Developing agents that can interact naturally with humans in language while perceiving and taking actions in their environments is a fundamental goal in artificial intelligence. In the field of visual-language navigation (VLN), much work has been done on language grounding, teaching agents how to relate human instructions with actions. However, there has been limited work on the reverse side of language generation, teaching agents how to verbalize vivid descriptions of navigation routes. Existing VLN literature separately trains agents for each task, resulting in either strong wayfinding actors or conversable route instructors. In this paper, we propose LANA, a language-capable navigation agent that is capable of both navigation instruction following and route description creation. LANA formalizes human-to-robot and robot-to-human communication in a unified framework, completing the necessary communication cycle and promoting the real-world utility of VLN agents. LANA is built as a Transformer-based, multi-task learning framework and is trained to comprehend linguistic cues, visual perceptions, actions, and their relationships. Experimental results on three popular VLN datasets show that LANA achieves comparable or better performance than task-specific alternatives, while also being able to explain its navigation routes in human-readable descriptions. Our findings highlight the potential of LANA for explainable navigation agents and robot applications in the future.