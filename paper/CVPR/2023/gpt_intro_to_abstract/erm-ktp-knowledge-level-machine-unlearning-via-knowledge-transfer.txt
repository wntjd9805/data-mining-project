Privacy legislation, such as the European Union's GDPR, has been implemented to protect personal privacy and grant individuals the right to be forgotten. In the context of machine learning models, there is a need for efficient methods to remove data points and their corresponding impact on the model without the costly retraining process. This has led to the emergence of a research direction called machine unlearning. Existing approaches, such as exact unlearning and approximate unlearning, have limitations in terms of computational overhead, storage requirements, and potential performance degradation. Additionally, these approaches may have security flaws and struggle to estimate data points' contributions in complex models like convolutional neural networks (CNNs). In this paper, we propose a novel interpretable unlearning method called ERM-KTP that considers subsequent unlearning tasks during the model training phase. We define machine unlearning in the knowledge perspective, ensuring that the unlearned model's knowledge remains identical to the retrained model. We introduce an ERM structure and the KTP method to transfer knowledge from the original model to the unlearned model while prohibiting the knowledge of the unlearning set. Experimental results on different image classification datasets and CNNs validate the effectiveness, efficiency, fidelity, and scalability of ERM-KTP.