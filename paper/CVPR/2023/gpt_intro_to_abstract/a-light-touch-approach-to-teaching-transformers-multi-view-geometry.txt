Recent advances in computer vision have focused on using generic models trained with large amounts of data, such as attention-based models like Transformers. However, applying this strategy to tasks involving reasoning about multiple-view geometry, like object retrieval, has been challenging. Object retrieval tasks require overcoming variations in viewpoint and scale, and geometric priors have been used to address these challenges. In this work, we explore how to guide attention-based networks with soft guardrails that encourage them to respect multi-view geometry without rigid constraints. Specifically, we propose an Epipolar Loss to induce epipolar constraints into transformer-based reranking models for object retrieval. We demonstrate the effectiveness of our approach on the CO3Dv2 and Stanford Online Products datasets, outperforming previous methods. Our contributions include the proposal of the Epipolar Loss, the setup of an object retrieval benchmark, and the evaluation of implicit and explicit incorporation of epipolar constraints.