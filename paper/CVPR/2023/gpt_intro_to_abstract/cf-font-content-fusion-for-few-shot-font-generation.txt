This paper addresses the problem of few-shot font generation, which aims to create characters of a new font by transforming font images from a source domain to a target domain using just a few reference images. This approach can significantly reduce the workload of expert designers, particularly for logographic languages like Chinese, Japanese, and Korean, which contain a large number of characters. The paper introduces a novel content feature fusion scheme to improve the quality of few-shot font generation. This scheme explores the synchronization of content and style features and includes a content fusion module (CFM) that considers the content features of different fonts during training and inference. It also introduces an iterative style-vector refinement (ISR) strategy to find better style feature vectors for font-level style representation. The paper proposes a distribution-based projected character loss (PCL) to measure the shape difference between characters, which results in improved skeleton topology transfer results. The proposed method, CF-Font, outperforms state-of-the-art methods for both seen and unseen fonts, as demonstrated in extensive experimental evaluations.