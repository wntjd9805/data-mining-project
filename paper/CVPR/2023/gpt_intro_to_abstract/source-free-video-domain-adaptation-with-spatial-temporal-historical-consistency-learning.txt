In this paper, we address the problem of domain shift in action recognition models and propose a Source-Free Video Domain Adaptation (SFVDA) approach. SFVDA aims to learn an adaptive action recognition model using unlabeled target videos and a source model pre-trained with labeled source videos. We introduce a novel method called Stochastic Temporal Historical Consistency (STHC), which leverages temporal consistency in videos to adapt the source model. STHC enforces prediction consistency from spatial, temporal, and historical perspectives by storing historical predictions in a memory bank and retrieving them for consistency enforcement. We demonstrate the effectiveness of STHC in various SFVDA settings, including the open-set, partial, and black-box settings, and outperform existing methods in terms of performance. Our contributions include the comprehensive exploitation of consistency learning for videos, extension of STHC to different SFVDA problems, and achieving state-of-the-art performance in SFVDA.