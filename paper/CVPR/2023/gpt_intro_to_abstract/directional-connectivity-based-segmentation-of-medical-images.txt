Maintaining anatomical consistency in the segmentation of medical images is crucial for accurate clinical decision-making. Traditional machine vision techniques that rely on manual priors are not easily adaptable to different applications. Deep learning-based segmentation methods, on the other hand, have shown promise in capturing inter-pixel dependencies. However, these methods often treat segmentation as a purely pixel-wise classification task, ignoring inter-pixel relationships and geometrical properties. This can result in low spatial coherence and inconsistencies in predictions for neighboring pixels. In this paper, we propose a novel approach called DconnNet, which incorporates pixel connectivity and directional information into the segmentation network. We demonstrate that our approach improves spatial coherence and reduces topological issues, particularly in high noise/artifact medical images. Our results highlight the importance of considering inter-pixel relationships in medical image segmentation.