Deep learning-based generative models have seen significant advancements in recent years, particularly in the field of computer vision. While most generative models rely on convolutional architectures, recent developments have introduced the use of implicit neural representations (INR) that represent images as continuous functions of their coordinate locations. INR models provide flexibility for image transformations and high-resolution up-sampling, making them effective for 3D scene reconstruction and rendering. However, current INR models are typically trained to represent a single scene or image and have not been scaled to large and diverse datasets like ImageNet.One key component of INR models is the positional encoding module, which is often based on sinusoidal functions known as Fourier features. The use of Fourier features in conjunction with a multi-layer perceptron (MLP) model has been shown to generate blurry outputs that lack high-frequency information. Attempts to remove positional encoding by replacing the activation function in the MLP have also been unsuccessful. The inability of the ReLU-based MLP model to capture higher derivative information is attributed to the zero values of higher-order derivatives of ReLU and its linear nature.In this paper, we propose a novel approach for INR modeling called Poly-INR. Instead of using sinusoidal positional encoding, we model an image as a polynomial function of its coordinate location. This allows for easier parameterization of polynomial coefficients using an MLP and enables the representation of larger and diverse datasets like ImageNet. To address the limitation of conventional MLPs in approximating higher-order polynomials, we progressively increase the degree of the polynomial with the depth of the MLP. This is achieved by element-wise multiplication between the feature and affine transformed coordinate location after each ReLU layer. The affine parameters are influenced by the latent code sampled from a known distribution.Experimental results show that our Poly-INR model performs comparably to state-of-the-art CNN-based GAN models on the ImageNet dataset while requiring significantly fewer trainable parameters. It also outperforms previous INR models on the FFHQ dataset using a smaller model. We demonstrate the benefits of our model through various qualitative results, including interpolation, inversion, style-mixing, high-resolution sampling, and extrapolation.Overall, our proposed Poly-INR model addresses the limitations of previous INR models, allowing for more effective representation of large and diverse datasets with fewer parameters.