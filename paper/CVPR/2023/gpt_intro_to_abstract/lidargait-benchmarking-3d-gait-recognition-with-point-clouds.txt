Gait recognition is a valuable biometric for human identification, with applications in human retrieval, forensic identification, and servicing robots. While significant progress has been made in gait recognition, two inherent problems persist: the lack of 3D geometry information and poor feasibility in real-world scenarios. Existing camera-based methods do not consider the 3D nature of gait recognition, and visual ambiguity caused by poor illumination and complex backgrounds remains a challenge. In this paper, we introduce SUSTech1K, a large-scale LiDAR-based gait dataset, to facilitate 3D gait recognition with point clouds. This dataset offers high precision, scalability, diversity, and multimodality, enabling the study of various factors on gait recognition. We investigate cutting-edge point-based methods but find that they underperform compared to camera-based approaches. To address this, we propose LidarGait, a baseline method that projects 3D point clouds into depth images and extracts gait features using convolutional neural networks. Our experiments demonstrate the effectiveness of LidarGait in maintaining 3D structural information and its stable performance on various challenges. Our contributions include the study of 3D gait recognition, the introduction of SUSTech1K dataset, and the proposal of LidarGait as a superior gait recognition framework.