Abstract:Document images play a crucial role in transmitting information in modern society, but they are also prone to tampering, leading to serious information security risks. Detecting tampered text regions in document images is an important research topic, and existing methods are mainly focused on the appearance analysis of scanned documents. However, detecting elaborately tampered text regions in various photographed documents remains a challenge. In this paper, we propose a multi-modality Transformer-based method, called Document Tampering Detector (DTD), for Document Image Tampering Detection (DITD). Our proposed model utilizes features from both the visual domain and frequency domain, incorporating both visual and frequency clues to identify tampered text regions effectively. We also introduce a new training paradigm, Curriculum Learning for Tampering Detection (CLTD), to enhance the model's generalization ability and robustness to image compression. To facilitate research in this field, we create a large-scale dataset, DocTamper, with 170k tampered document images of diverse types. Experimental results on our proposed dataset and an existing dataset demonstrate the superiority of our DTD model compared to previous state-of-the-art methods.