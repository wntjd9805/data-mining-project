With the growing popularity of virtual reality, there is an increasing demand for high-resolution 360◦ images. However, acquiring, storing, and processing such images can be expensive. To address this issue, 360◦ image rescaling is necessary, which involves downscaling the image to generate low-resolution (LR) images and then upscaling them to reconstruct high-resolution (HR) 360◦ images. Unlike image super-resolution techniques, which only upscale LR images, image rescaling can directly utilize the texture information from the input HR 360◦ images, resulting in better reconstruction results. Current research on 2D image rescaling cannot be directly applied to 360◦ images due to their spherical characteristics and non-uniform sampling density. Therefore, a specialized framework is needed to fully consider the spherical characteristics of 360◦ images. In this paper, we present the first attempt at 360◦ image rescaling and propose a deformable invertible neural network (DINN360) that takes into account the latitude-aware characteristics of 360◦ images. Our method includes deformable downscaling and HF projection using invertible structures, as well as a novel latitude-aware conditional mechanism to better preserve the HF component of 360◦ images. Extensive experiments show that our DINN360 outperforms state-of-the-art image rescaling and 360◦ super-resolution methods. Our contributions include identifying the changes in low-level characteristics of 360◦ images with latitude, proposing a novel INN framework for 360◦ image rescaling, and developing a latitude-aware conditional mechanism to preserve the HF component of 360◦ images in a latitude-aware manner.