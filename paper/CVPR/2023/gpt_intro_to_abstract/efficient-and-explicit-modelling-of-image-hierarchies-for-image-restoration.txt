Image restoration is an important task in computer vision that aims to recover high-quality images from degraded ones. The degradation processes can include blurring, sub-sampling, noise corruption, and JPEG compression, resulting in the loss of important content information. To address this problem, deep neural networks have been utilized to utilize the rich information present in degraded images. These networks can model features at different ranges, including local features such as edges and colors, regional features within a window of pixels, and global features that span the entire image. However, existing approaches struggle to effectively capture the long-range dependencies required for modeling global features, and the increasing resolution of modern images poses additional computational challenges. In this paper, we propose a novel approach called anchored stripe self-attention, which efficiently models global range features using anchors and utilizes anisotropic image features to further reduce computational complexity. We also introduce a transformer network called GRL that integrates the proposed self-attention mechanism with window self-attention and channel-attention enhanced convolution to explicitly model global, regional, and local dependencies in a single computational module. We evaluate the performance of our approach on various image restoration tasks, including image super-resolution, denoising, compression artifact removal, demosaicking, motion deblurring, and defocus deblurring, and demonstrate promising results.