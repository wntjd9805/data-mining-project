Capturing and modeling the 3D shape and pose of animals has various applications in fields such as biology, conservation, entertainment, and virtual content creation. While studying animals using images has a long history, the development of expressive 3D models that can adapt to individual animal shapes and poses is relatively recent. In this paper, we specifically focus on the task of reconstructing dogs in 3D from a single image. Dogs are an ideal subject for this study as they exhibit a wide range of shape variability across different breeds and strong articulated deformations typical of quadrupeds. However, unlike humans, there is limited 3D observation and motion capture data for animals, making it challenging to create accurate 3D statistical models that cover all possible shapes and poses. Existing generic quadrupedal models, such as SMAL, cannot capture the distinctive characteristics of different dog breeds. Additionally, the lack of dog motion capture data, especially for sitting and lying poses, further adds to the complexity of inferring dog poses. To overcome these challenges, we introduce a dog-specific parametric model called D-SMAL. We also address the issue of limited motion capture data by leveraging ground contact information, which is often overlooked in animal modeling. By considering the physical contact that animals have with the ground, we can estimate complex poses, even in challenging cases with significant self-occlusion. Furthermore, we propose a novel reconstruction system called BITE, which combines the D-SMAL model with a refinement network that utilizes ground contact losses to improve pose estimation. We demonstrate the effectiveness of our approach by comparing it to previous methods using a semi-synthetic 3D test dataset that includes ground truth annotations. Our contributions include the introduction of D-SMAL, the development of the BITE model, advancements in monocular 3D pose estimation, and the creation of a new evaluation dataset.