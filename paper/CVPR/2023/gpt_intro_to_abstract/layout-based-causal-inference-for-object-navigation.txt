Abstract:This paper addresses the challenge of efficient goal-oriented navigation in unseen environments for visual object-oriented navigation tasks. Existing learning-based methods attempt to establish prior knowledge of spatial relationships among objects in training environments, but suffer from poor generalization in unseen environments due to limited training data. To analyze the causes of poor generalization, a causal graph is proposed to examine navigation works. The layout consistency assumption between training and unseen environments is only partially correct, leading to limited generalization. To improve generalization, a soft Total Direct Effect (sTDE) framework is proposed, which eliminates prediction bias caused by prior knowledge. The layout-based sTDE (L-sTDE) framework uses the Dirichlet-Multinomial distribution to model the contextual relationships between objects and learns the prior layout distribution through random exploration in training environments. In the training stage, Bayesian inference is used to estimate the posterior layout distribution, which is encoded into the navigation model to learn environment-adaptive experience. In the test stage, the agent calculates the layout gap and counter-fact prediction to determine whether to remove the experience effect from the original prediction. Experimental results demonstrate that L-sTDE can enhance existing methods and improve navigation performance in AI2THOR, RoboTHOR, and Habitat environments.