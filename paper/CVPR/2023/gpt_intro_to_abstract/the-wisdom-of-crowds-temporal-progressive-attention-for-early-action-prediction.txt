This computer science paper introduces the task of Early Action Prediction (EAP), which involves inferring the action label of a video based on only a partial observation of the video's start. The increasing number of recorded videos and the need for low-latency processing has driven interest in EAP. While previous methods have focused on using entire videos for action recognition, this study aims to model the observed partial video more effectively. The researchers draw inspiration from neurophysiological studies that suggest humans understand actions in a predictive manner. They propose a Temporally Progressive (TemPr) approach to modeling partially observed videos, using multiple scales to extract features and employing transformer towers for encoding and predicting actions. The paper highlights the contributions of the proposed approach, including a progressive fine-to-coarse temporal sampling method, the use of transformer towers for representation and aggregation, and evaluation on multiple video datasets where it consistently outperforms previous work.