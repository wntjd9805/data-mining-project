Visual anomaly detection (AD) with localization is a crucial task in computer vision applications such as industrial inspection, medical disease screening, and video surveillance. Traditionally, AD tasks have been formulated as one-class classification and segmentation, using only normal data for training. To address the limitations of this approach, the student-teacher (S-T) framework, known as knowledge distillation, has been proposed. In this framework, a teacher network is pre-trained on a large-scale dataset, and a student network is trained to mimic the teacher's feature representations on an AD dataset with normal samples. However, there is no guarantee that the features of anomalous samples are always different between the student and teacher networks. To overcome this issue, we propose DeSTSeg, a framework consisting of a denoising student network, a teacher network, and a segmentation network. Synthetic anomalies are introduced into normal images for training. The denoising student network is trained to generate similar feature representations as the teacher network from clean images while minimizing the feature discrepancy. The student network filters anomalies out of the feature space, reinforcing the generation of distinct features from anomalous inputs. We evaluate our method on the MVTec AD dataset and demonstrate its superior performance compared to state-of-the-art methods. The proposed framework contributes novel components, including a denoising student encoder-decoder and a segmentation network for adaptive feature fusion. Extensive experiments validate the effectiveness of our approach for various tasks.