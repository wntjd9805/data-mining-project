3D object detection is a crucial task for various applications, including autonomous driving. While significant progress has been made in architecture design and LiDAR-camera sensor fusion, detecting occluded and long-range objects remains challenging. Point cloud sequence data offers unique opportunities to address these challenges by capturing different viewpoints of objects over time and improving their visibility. However, leveraging sequence data efficiently and effectively for 3D object detection is a key challenge. Existing multi-frame detection methods fuse sequence data at different levels, either at the scene level by transforming point clouds to a target frame using ego motion poses or at the object level by aggregating longer temporal contexts. Despite these approaches, it is difficult to further improve detection models using more input frames due to the computational overhead and ineffective temporal data fusion, especially for moving objects. Moreover, scaling up temporal context aggregation to long sequences also faces efficiency issues or alignment challenges. In this paper, we propose a novel approach that utilizes motion forecasting to propagate object information from the past (and future) to a target frame, introducing a new modality named MoDAR (Motion forecasting based Detection And Ranging). We demonstrate the effectiveness of MoDAR in improving detection quality, particularly for long-range and occluded objects, using the Waymo Open Dataset. We achieve state-of-the-art results in mean Average Precision with the inclusion of MoDAR, surpassing existing methods. Additionally, we provide thorough analysis and ablation experiments to validate our design choices and showcase the impact of different MoDAR options.