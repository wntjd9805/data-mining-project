In recent years, there has been significant progress in text-conditioned image generation driven by advances in multimodal understanding. However, developing a text-conditioned 3D shape generator faces challenges due to the scarcity of (text, 3D shape) pairs at a large scale. Previous approaches have collected limited data for a small number of object categories. To overcome this data bottleneck, the use of weak supervision from large-scale vision/language models such as CLIP has shown promise. This paper proposes CLIP-Sculptor, a text-conditioned 3D shape generative model that outperforms existing methods in terms of shape diversity and fidelity with only (image, shape) pairs as supervision. CLIP-Sculptor utilizes a multi-resolution, voxel-based generation scheme and discrete latent representations to achieve high fidelity and diverse outputs. Additionally, a masked transformer architecture and a novel annealed strategy for classifier-free guidance are introduced. The contributions of this work include the development of CLIP-Sculptor and the novel variant of classifier-free guidance.