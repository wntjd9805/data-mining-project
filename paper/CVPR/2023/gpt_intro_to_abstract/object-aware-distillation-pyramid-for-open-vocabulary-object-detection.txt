Abstract:Open-vocabulary object detection (OVD) aims to enhance the generalizability of object detectors by enabling them to detect both base and novel categories. Pretrained Vision-and-Language Models (PVLMs) and Knowledge Distillation (KD) have shown promising results in transferring zero-shot visual recognition abilities to object detectors. However, conventional approaches still face limitations in knowledge extraction and transfer. In this paper, we propose an Object-Aware Distillation Pyramid (OADP) framework to accurately extract and transfer knowledge from PVLMs to object detectors. Our framework includes an Object-Aware Knowledge Extraction (OAKE) module to preserve complete information of proposals during knowledge extraction. Additionally, we introduce a Distillation Pyramid (DP) mechanism to address the limitations of previous object distillation methods by incorporating global and block distillation. Experimental results on MS-COCO and LVIS datasets demonstrate the effectiveness of our OADP framework, outperforming state-of-the-art methods in terms of mean Average Precision (mAP) and Average Precision (APr) in object detection and instance segmentation tasks.