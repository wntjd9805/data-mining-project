Few-shot classification involves recognizing concepts with only a few labeled examples. In this paper, we focus on the Few-Shot Open-Set Recognition (FSOSR) setting, where query instances may not belong to any known class. Most existing few-shot methods assume a closed-set setting, where query instances are constrained to the classes defined by the support set. However, in real-world scenarios, open-set instances that do not belong to any known class occur frequently. To address this challenge, we propose a principled framework called Open-Set Likelihood Optimization (OSLO) that reconciles transduction with the open nature of the FSOSR problem. Instead of using heuristics to assess the outlierness of query samples, OSLO treats the outlierness score as a latent variable and incorporates additional supervision constraints from the support set. We optimize our objective using block-coordinate descent, alternately co-optimizing the soft assignments, outlierness scores, and parametric models. Empirical evaluations on five datasets demonstrate that OSLO outperforms existing methods for both outlier detection and closed-set prediction, while remaining highly interpretable and modular. Our method consistently achieves significant improvements over strong baselines across different architectures and training strategies, without the need for re-optimization. Additionally, OSLO can be easily applied on top of any pre-trained model, allowing it to leverage the latest advances in standard image recognition. Overall, this work presents the first study and benchmarking of transductive methods for the FSOSR setting and introduces a novel framework that effectively handles the presence of outliers.