Capturing human motions is a challenging problem with various applications such as AR/VR, games, movies, and robotics. While there have been approaches to estimate human poses, most focus on upright frontal poses, neglecting activities like climbing. Climbing poses are unique and present challenges due to complex human-scene interactions and self-occlusion. Existing climbing datasets are limited, so to address this, we introduce CIMI4D, a large-scale multimodal climbing dataset. It includes LiDAR point clouds, RGB videos, and IMU measurements from 12 actors climbing 13 rock-climbing walls. We also provide high-quality static point clouds and annotated contact information. CIMI4D enables benchmarking for various 3D human pose tasks and presents new challenges for computer vision algorithms. Our contributions include the dataset, an annotation method, and an analysis of existing methods. Overall, CIMI4D aims to deepen the understanding of human-scene interactions and benefit digital reconstruction.