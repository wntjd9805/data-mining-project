Haze significantly reduces visibility and contrast in outdoor scenes, which negatively impacts the performance of vision tasks like autonomous driving and surveillance. This paper introduces a novel video dehazing framework called MAP-Net that addresses the limitations of existing methods. MAP-Net utilizes a memory-based physical prior guidance module to inject physical prior information into scene radiance recovery. It also incorporates a multi-range scene radiance recovery module to capture space-time dependencies in multiple ranges. Additionally, the paper introduces a large-scale outdoor video dehazing dataset, HazeWorld, for evaluation. Experimental results demonstrate the effectiveness of MAP-Net in both synthetic and real-world scenarios, outperforming existing methods. The contributions of this work include the development of MAP-Net, the construction of the HazeWorld dataset, and extensive experiments showcasing its superior performance.