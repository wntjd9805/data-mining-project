Dense prediction tasks, such as per-pixel classification and regression, are crucial for various computer vision applications. Neural networks have achieved success in solving these tasks through innovative architectures and training optimizations. This paper introduces a novel training strategy called DejaVu, which employs conditional image regeneration from redacted input images to improve performance on dense prediction tasks. By redacting the input image and reconstructing the missing information, the base network is encouraged to learn and use structure information, resulting in more accurate predictions. DejaVu does not incur extra computation at test time and can be extended with attention-based modules for further improvement. Experimental results on multiple dense prediction tasks demonstrate the effectiveness of DejaVu, outperforming state-of-the-art methods on large-scale benchmarks. The contributions of this paper include the development of DejaVu, the proposal of redacting input images to enhance dense predictions, the introduction of a shared attention scheme called DejaVu-SA, and the extension of DejaVu with text supervision and cyclic consistency losses. DejaVu is a universal framework that enhances the performance of multiple networks for essential dense prediction tasks without incurring additional inference cost.