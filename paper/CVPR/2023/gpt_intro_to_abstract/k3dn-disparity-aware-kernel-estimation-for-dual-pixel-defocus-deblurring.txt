Dual-pixel (DP) sensors are widely used in DSLR cameras and smartphone cameras for auto-focusing. Researchers have recently explored the use of DP sensors for computer vision tasks, particularly defocus deblurring. DP sensors provide two sub-views of a scene, and the disparity between these views can be used to estimate the blur kernel for deblurring. Existing DP-based defocus deblurring methods can be categorized as end-to-end-based or disparity-based methods. End-to-end-based methods directly restore an all-in-focus image without considering DP domain knowledge, while disparity-based methods estimate the DP disparity to aid in restoration. However, these methods have limitations such as requiring extra data or pre-calibrated kernel sets. In this paper, we propose a disparity-based defocus deblurring method called K3DN. K3DN consists of three modules: a disparity-aware deblur module, a re-blurring regularization module, and a sharp region preservation module. The disparity-aware deblur module estimates spatially-varying blur kernels based on a trainable kernel set and a disparity feature map. The re-blurring regularization module reuses the DP blur kernel and performs convolution to generate a blurred image. The sharp region preservation module preserves in-focus regions of the DP pairs to improve restoration performance. Our method does not require ground-truth information for training and achieves state-of-the-art performance on benchmark datasets.