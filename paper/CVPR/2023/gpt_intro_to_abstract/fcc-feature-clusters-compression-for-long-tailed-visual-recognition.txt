Recently, Deep Neural Networks (DNNs) have achieved considerable success in visual tasks such as object detection and visual recognition. However, these successes rely on large-scale balanced datasets, while real-world datasets often follow imbalanced and long-tailed distributions. DNNs trained on such datasets exhibit biases towards over-represented majority classes and produce low recognition accuracy for minority classes. Various remedies have been proposed, including re-sampling methods, re-weighting methods, two-stage training methods, and multi-expert networks. However, these methods overlook the impact of the density of Backbone Features (BFs) on this issue. In this paper, we propose a Feature Clusters Compression (FCC) technique to increase the density of BFs by compressing backbone feature clusters. This is achieved by multiplying the original BFs by a specific scaling factor during training, forcing the backbone to map the original features into denser clusters. In the test phase, the original BFs are directly fed to the trained classifier, resulting in improved feature density and performance. We demonstrate that FCC can be combined with existing long-tailed methods and achieves significant performance improvement on popular datasets. Our contributions include tackling long-tailed visual recognition from the novel perspective of increasing BF density, proposing the FCC technique, and achieving state-of-the-art results on multiple datasets.