This paper introduces a bi-directional fusion framework called Bi-LRFusion for combining LiDAR and Radar features to enhance 3D dynamic object detection in autonomous vehicles. Previous approaches have focused on uni-directional fusion by directly utilizing Radar data to enhance LiDAR features without improving the quality of the Radar feature representation. However, independently extracted Radar features lack the height information and are sparse, resulting in unstable improvements for objects with different heights. To address this issue, Bi-LRFusion first enriches Radar features using LiDAR data and then integrates them into the LiDAR processing branch for more effective fusion. The framework includes query-based height and BEV feature fusion techniques to enhance the Radar features. Extensive experiments on the nuScenes and Oxford Radar RobotCar datasets demonstrate the merits of Bi-LRFusion, with significant improvements in mAP and AP for 3D object detection. The contributions of this work include the proposal of Bi-LRFusion, the development of query-based fusion techniques, and the validation of improved results on different datasets.