Optical flow methods have achieved significant progress in clean scenes but struggle to perform well in foggy scenes. This is because fog weakens scene contrast and violates the brightness and gradient constancy assumptions that optical flow methods rely on. To address this issue, researchers have explored domain adaptation techniques to transfer motion knowledge from clean scenes to foggy scenes. However, existing approaches have neglected the synthetic-to-real domain gap, limiting their performance on real-world foggy scenes. In this paper, we propose an unsupervised cumulative domain adaptation framework for optical flow in real foggy scenes. Our framework consists of two stages: depth-association motion adaptation (DAMA) and correlation-alignment motion adaptation (CAMA). In DAMA, we use depth as a key factor to bridge the clean-to-foggy domain gap by associating clean images with foggy images through an atmospheric scattering model. In CAMA, we align the correlation distributions of synthetic and real foggy images to bridge the synthetic-to-real domain gap. Our method progressively transfers motion knowledge from clean scenes to real foggy scenes through depth association and correlation alignment. The experimental results demonstrate the effectiveness of our proposed framework in improving optical flow estimation in foggy scenes.