This paper introduces a new approach to Blind Image Decomposition (BID) for removing arbitrary image degradations without prior knowledge of the noise type and mixing mechanism. Existing methods for generic image restoration still rely on fine-tuning on individual datasets or use computationally complex separate encoders. To address this, the proposed method utilizes a pretrained model called Context-aware Pretrained Network (CPNet) that can remove arbitrary noise types or combinations at once. CPNet is designed with a dual-branch pattern combining mixed image separation and masked image reconstruction, allowing the network to mine context information and transfer knowledge to various restoration scenarios. The proposed method also includes an information fusion module and multi-scale self-attention for feature interaction. Experimental results show that the proposed method achieves competitive performance in blind image restoration and outperforms competitors in terms of efficiency. Overall, the contributions of this work include the introduction of a new self-supervised learning paradigm, the development of CPNet, and the achievement of improved performance in blind image restoration.