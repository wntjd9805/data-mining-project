The paper introduces a weakly-supervised semantic segmentation (WSSS) method using image-level labels to reduce annotation costs. Previous WSSS methods use Class Activation Maps (CAM) derived from convolutional neural networks (CNN), but CAMs often lack discriminative semantic regions. Recent works propose using Vision Transformer (ViT) architecture to address this issue, but ViT suffers from over-smoothing, resulting in uniform patch tokens and inaccurate CAMs. This paper proposes the Patch Token Contrast (PTC) module to supervise patch tokens with intermediate knowledge and counter over-smoothing. Additionally, the paper introduces the Class Token Contrast (CTC) module to enhance local-to-global representation consistency and object activation completeness. The proposed Token Contrast (ToCo) framework outperforms existing single-stage WSSS methods and achieves comparable performance with multi-stage competitors on benchmark datasets.