Reconstructing and re-rendering 3D scenes from 2D images is an important vision problem for AR/VR applications. Most existing approaches focus on static scenes, but the real world is dynamic and complex scenes often involve motion. Implicit representations like NeRF have been used for dynamic scenes, but they are computationally expensive and time-consuming. Recent methods for static scenes have shown speedups by using explicit and hybrid methods. In this paper, we propose HexPlane, an explicit representation for dynamic scenes. HexPlane overcomes the challenges of memory usage and sparse observations by decomposing the 4D spacetime grid into six feature planes, which can be tuned independently. We demonstrate that HexPlane is effective and efficient for novel view synthesis in dynamic scenes, outperforming prior approaches in both image quality and training time. Our experiments also validate the robustness of HexPlane to different feature fusion mechanisms, coordinate systems, and decoding mechanisms. HexPlane is a simple and general representation that can be applied to a broad range of research in dynamic scenes.