Rigid point cloud registration plays a critical role in various fields, such as robotics, augmented reality, and autonomous driving. Recent advancements in deep learning have led to the development of learning-based approaches for point cloud registration. These approaches can be categorized as correspondence-free or correspondence-based methods. However, correspondence-free methods are inadequate for handling real scenes with partial overlap, while correspondence-based methods face challenges with varying point densities or repetitive patterns. Existing methods also rely on large amounts of ground truth data for training, which is difficult to acquire in real-world scenarios. To address these limitations, we propose an unsupervised deep probabilistic registration framework that extends the distribution-to-distribution (D2D) method. We introduce distribution-consistency losses and a local contrastive loss to train the networks without using ground truth pose or correspondences. Our approach, UDPReg, achieves state-of-the-art results on various datasets and outperforms existing unsupervised methods. The main contributions of this work include the proposal of an unsupervised learning-based framework for partial point cloud registration, the adoption of the Sinkhorn algorithm for distribution-level correspondences, the formulation of consistency losses to train the networks in an unsupervised manner, and the achievement of state-of-the-art performance on synthetic and real-world datasets.