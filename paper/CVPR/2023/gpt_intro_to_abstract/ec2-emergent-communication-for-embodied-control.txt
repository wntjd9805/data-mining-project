We present a study on the problem of few-shot embodied control, where an embodied agent needs to execute language instructions or follow video demonstrations with limited examples in a new environment. We propose an approach called Emergent Communication for Embodied Control (EC2) that leverages emergent language as a bridge between natural language and videos. Our three-phase scheme involves learning an emergent language of demonstration videos, learning an embodied representation using a language model, and training a lightweight policy network for downstream embodied control. Extensive experiments demonstrate that EC2 outperforms existing methods in benchmark simulation environments. We also show that the performance of downstream tasks is best when the learned emergent language contains more information than natural language. Overall, our work contributes to the development of an embodied control framework that combines the abstract structure of language with low-level motion details in a few-shot learning setting.