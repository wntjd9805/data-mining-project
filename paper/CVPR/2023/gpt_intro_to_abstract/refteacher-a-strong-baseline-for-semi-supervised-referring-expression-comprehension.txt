Referring Expression Comprehension (REC) aims to locate objects in images based on natural language expressions. Unlike conventional object detection tasks, REC is not limited to a fixed set of categories and can be generalized to open-vocabulary recognition. However, REC requires a large amount of instance-level annotations for training, which poses challenges for practical applications. To address this, we propose a semi-supervised approach for REC called RefTeacher, which leverages the success of semi-supervised object detection (SSOD) methods. RefTeacher introduces two novel designs, Attention-based Imitation Learning (AIL) and Adaptive Pseudo-label Weighting (APW), to tackle the challenges of sparse supervision signals and worse pseudo-label noise in REC. Experimental results on benchmark datasets show that RefTeacher outperforms supervised baselines and achieves near fully supervised performance with only 10% labeled data. Our contributions include presenting the first attempt at semi-supervised learning for REC, identifying and addressing challenges in semi-supervised REC, and achieving significant performance gains over fully supervised methods on REC datasets.