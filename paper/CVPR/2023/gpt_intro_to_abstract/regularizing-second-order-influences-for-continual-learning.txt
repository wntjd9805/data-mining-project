This paper addresses the issue of catastrophic forgetting in machine learning systems, which struggle to remember old concepts after acquiring new ones. Continual learning, or the ability to learn on long task sequences, has emerged as a solution to this problem. Replay-based approaches, which buffer previously seen data for rehearsal, have shown strong results. However, existing works on coreset selection, which determines which samples are stored in the buffer, have primarily focused on refining single-round performance and have neglected the impact of prior selections on subsequent decisions. This can result in a degraded coreset after prolonged selection. To maximize overall performance, the paper proposes a continual learning method that takes into account the future influence of each round of selection. The method models the interplay among multiple selection steps using influence functions, which estimate the effect of each training point. It uncovers second-order influences that interfere with the initial selection strategy and proposes a regularizer to mitigate these effects. The regularizer is based on an upper bound for the magnitude of second-order influences and can be integrated with existing selection criteria. The paper presents an efficient implementation for selecting with neural networks and demonstrates the effectiveness of the proposed method through comprehensive experiments on three continual learning benchmarks.