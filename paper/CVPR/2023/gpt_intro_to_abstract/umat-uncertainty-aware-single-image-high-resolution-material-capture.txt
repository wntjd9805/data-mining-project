Digital twins, which are lifelike digital representations of real-world materials, are becoming increasingly important in various industries such as virtual design, online marketplaces, product lifecycle workflows, AR/VR, and videogames. However, acquiring these digital copies is often a cumbersome and slow process that hinders scalability, repeatability, and consistency. The fashion industry, in particular, faces the challenge of digitizing a large number of textile samples within short periods of time, a task that is not achievable with current technology.To address this problem, casual capture systems for optical digitization using handheld devices, multiple illuminations, and learning-based priors show promise for scalability. However, existing approaches have drawbacks that make them impractical for digitization workflows. Generative solutions often produce unrealistic artifacts and are slow to train and evaluate. Methods that rely on differentiable node graphs overcome some limitations but still face challenges related to perceptual losses and category-specific training.In this paper, we propose UMat, a practical and scalable approach for digitizing the optical appearance of textile material samples using SVBRDFs (Surface Appearance Bidirectional Reflectance Distribution Functions). We demonstrate that accurate digitizations can be achieved using a single diffuse image as input for albedo estimation and a neural network for estimating specular components. Our key insight is that the appearance variability of textile materials is primarily due to microgeometry, which can be approximated using a commodity flatbed scanner.Although single-image material estimation is an ill-posed problem, we address this challenge by proposing a novel uncertainty metric that measures the model's confidence in its prediction. This uncertainty quantification, computed using Monte Carlo Dropout, improves the trustworthiness of the capture process and enables smarter strategies for dataset creation, such as active learning.Our approach formulates the estimation problem as an Image-to-Image Translation problem and utilizes a novel residual architecture with attention modules for global consistency and reduced artifacts, specialized decoders for each reflectance map, and a U-Net discriminator for enhanced generalization.In summary, our contributions include a novel material capture system, an attention-enhanced GAN model and training procedure, and a generic uncertainty quantification framework for material capture algorithms. These advancements in digitizing material samples have the potential to revolutionize industries that rely on lifelike digital representations.