Temporal action localization (TAL) is a critical aspect of video understanding, aiming to identify and classify action instances in untrimmed long videos. The weakly-supervised setting (WTAL), which only has access to video-level category labels, has gained attention as a way to avoid costly temporal boundary annotations. However, existing WTAL methods based on Classification-Based Pre-training (CBP) suffer from incompleteness, only detecting sparse discriminative action frames and resulting in high false negatives. In this paper, we propose a distillation-collaboration framework that leverages the complementary nature of CBP and Vision-Language Pre-training (VLP) paradigms. We distill background knowledge from CBP and foreground knowledge from VLP to improve localization results. We address issues of over-completeness and confusion between action instances by using confident knowledge distillation and representation contrastive learning. Our method achieves state-of-the-art performance on two benchmark datasets, demonstrating the effectiveness of distilling VLP for WTAL. We contribute by pioneering the exploration of distilling free action knowledge from VLP, designing a novel collaboration framework, and providing extensive experimental evidence of our method's superiority.