Video prediction is a challenging task in computer science as it aims to predict future video frames based on the current frames. This task has gained increasing attention in both academia and industry, with potential applications in representation learning and various forecasting tasks such as human motion prediction, autonomous driving, and climate change. One of the main challenges in video prediction is accurately estimating the diverse and complex motion patterns present in real-world videos. Early methods focused on using recurrent neural networks to capture temporal motion information, while more recent approaches have incorporated semantic or instance segmentation maps for improved motion estimation in complex scenes. However, the reliance on these additional inputs limits the application scope of these methods. To address this limitation, the method of OPT utilizes only RGB images to estimate optical flow and achieve impressive performance. However, its inference speed is hindered by the computational costs of pre-trained optical flow and frame interpolation models. Another challenge in video prediction is the significant differences in motion scales and spatial resolution that exist between adjacent frames, particularly in high-resolution videos. In this paper, the authors propose a Dynamic Multi-scale Voxel Flow Network (DMVFN) to address these challenges. DMVFN explicitly models complex motion cues of diverse scales through dynamic optical flow estimation. The network consists of Multi-scale Voxel Flow Blocks (MVFBs) stacked in a sequential manner, with a Routing Module that dynamically selects a suitable sub-network for efficient future frame prediction. The authors conduct experiments on several benchmark datasets to demonstrate the advantages of DMVFN over previous video prediction methods in terms of visual quality, parameter efficiency, and computational efficiency. The contributions of this work include the design of a light-weight DMVFN that accurately predicts future frames using only RGB inputs, the introduction of MVFBs for modeling different motion scales, and the proposal of an effective Routing Module for dynamic sub-network selection. The experimental results show that DMVFN achieves state-of-the-art performance while being an order of magnitude faster than previous methods.