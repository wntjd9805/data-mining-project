Deep neural networks (DNNs) have shown great success with large-scale data, but they are often over-parameterized and require significant storage and computational resources. In real-time applications, there is a need for lightweight models that can be deployed on mobile devices with limited resources for prompt inference results. Teacher-student architectures have been proposed as a way to deploy computational-effective and high-performing models in such applications. However, small student models lack sufficient protection mechanisms and are more susceptible to malicious attacks compared to large-scale models. Therefore, it is crucial to improve the adversarial robustness of small models when applying them to real applications. Adversarial training (AT) has been studied as a defense mechanism to improve adversarial robustness in deep models, but it is more effective on over-parameterized models. Recently, adversarial distillation (AD) has been proposed as an alternative scheme in teacher-student architectures to improve adversarial robustness. However, existing AD methods have limitations in terms of model smoothness and interaction with teacher models. In this paper, we propose adaptive adversarial distillation (AdaAD) which fully involves a robust teacher model to adaptively search for more representative inner results in the knowledge distillation process. We formulate a new AD objective by maximizing the prediction discrepancy between teacher and student models in a min-max framework. We design AdaAD to adaptively search for optimal match points in the inner optimization, enabling a larger search radius and enhancing the robustness of student models. Extensive experimental results demonstrate that AdaAD outperforms state-of-the-art AT and AD methods in various scenarios, achieving top-rank performance on the RobustBench leaderboard under AutoAttack.