Recent advances in deep neural networks have led to significant progress in many machine learning problems. However, these deep models often suffer from a decrease in performance when the training and testing data come from different distributions, limiting their utility in real-world applications. To address this issue, transfer learning techniques, specifically domain adaptation (DA) and domain generalization (DG), have been proposed. DA and DG leverage labeled datasets from a source domain to help models generalize to unlabeled or unseen samples in a target domain. While DA and DG have extensively studied distribution shifts, they typically assume access to the raw source data, which is not always feasible due to privacy regulations. Additionally, existing methods for addressing distribution shifts require heavy backward computation, resulting in high training costs. Test-time adaptation (TTA) approaches aim to address distribution shifts online at test time using only unlabeled test data streams. TTA has gained attention across various applications, such as visual recognition, multi-modality, and document understanding. However, prior TTA studies have mostly focused on simple adaptation scenarios, where test samples are independently sampled from a fixed target domain. In reality, test samples are often temporally correlated and drawn from continuously changing distributions. This presents challenges in adapting models to dynamic scenarios, including incorrect estimation in batch normalization and overfitting to distribution caused by correlated sampling. To overcome these challenges, we propose a more realistic TTA setting called Practical Test-Time Adaptation (PTTA), which considers both distribution changing and correlative sampling. We introduce a Robust Test-Time Adaptation (RoTTA) method that includes robust statistics estimation, category-balanced sampling, and time-aware robust training. Our experiments demonstrate that RoTTA effectively adapts in the PTTA setting, outperforming existing methods on benchmark datasets. Therefore, our contributions include proposing the PTTA setup, benchmarking existing methods, introducing RoTTA, and demonstrating its practicality and effectiveness.