Sensing, understanding, and synthesizing realistic 3D objects in computer vision has made significant progress in recent years. However, most technical approaches rely on unrealistic synthetic datasets due to the absence of a large-scale real-world 3D object database. This limits their real-life applications as there are appearance and distribution gaps between synthetic and real data. To address this, there is a need for a large-scale and high-quality 3D object dataset from the real world.Existing datasets such as CO3D, GSO, and AKB-48 partially fulfill the requirements but are still unsatisfactory. They either lack accurate point cloud annotations, textured meshes, or have a narrow semantic distribution. In order to advance research on 3D object understanding and modeling, we present OmniObject3D, a large-vocabulary 3D object dataset consisting of 6,000 high-quality textured meshes scanned from real-world objects. It covers 190 daily object categories and incorporates common classes from popular 2D and 3D datasets.OmniObject3D offers several appealing properties, including rich annotations such as textured 3D meshes, sampled point clouds, multi-view images, and real-captured video frames. The dataset also provides realistic scans thanks to professional scanners, which capture precise shapes with geometric details and realistic appearance. To leverage the dataset, we set up four evaluation tracks for robust 3D perception, novel-view synthesis, neural surface reconstruction, and 3D object generation.By utilizing OmniObject3D, we can analyze robust 3D perception for out-of-distribution styles and corruptions, conduct novel-view synthesis and neural surface reconstruction using massive 3D models, and explore the generation of realistic 3D objects. These benchmarks offer new observations, challenges, and opportunities for future research in realistic 3D vision. OmniObject3D aims to bridge the gap between synthetic and real data, pushing the boundaries of existing generation methods and facilitating various 3D vision tasks and downstream applications.