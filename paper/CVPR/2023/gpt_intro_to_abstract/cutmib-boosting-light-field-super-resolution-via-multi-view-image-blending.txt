Light field cameras have gained popularity in virtual and augmented reality applications due to their ability to capture spatial and angular information of light rays. However, commercialized light field cameras face a trade-off between angular and spatial resolutions. To address this, light field super-resolution (SR) has emerged as an important topic. Convolutional neural network (CNN) and Transformer-based methods have shown promising performance in light field SR, outperforming traditional non-learning based methods. However, few studies have explored data augmentation (DA) strategies for light field SR, which can enhance model performance without the need for additional training datasets. DA has been extensively studied in high-level vision tasks, but its effectiveness in light field SR has been largely overlooked. In this paper, we propose a novel DA strategy called CutMIB specifically designed for light field SR. CutMIB leverages a cutting-blending-pasting operation to efficiently explore the geometric information in light fields during the training stage. Our experiments demonstrate that CutMIB significantly improves the reconstruction fidelity and angular consistency of existing light field SR methods. We also validate the effectiveness of CutMIB in real-world light field SR and light field denoising tasks. The contributions of this paper include the introduction of CutMIB as the first DA strategy for light field SR, its ability to boost performance, and its applicability in real-world scenarios.