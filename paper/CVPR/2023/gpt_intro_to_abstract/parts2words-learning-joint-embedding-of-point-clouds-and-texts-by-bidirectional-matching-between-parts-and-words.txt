The paper introduces a method for matching and retrieving 3D shapes and text descriptions. The existing methods have limitations in capturing detailed geometric descriptions and establishing connections between shape and text. To overcome these limitations, the authors propose an optimal transport based shape-text matching method. The method represents shapes as point clouds and incorporates regional-based matching approaches to achieve fine-grained alignment. The proposed end-to-end network framework learns the joint embedding of point clouds and texts, enabling bidirectional matching. Optimal transport theory and Earth Mover's Distance are used to obtain the best matches between parts and words and describe the matching score. The proposed method achieves state-of-the-art results in joint 3D shape/text understanding tasks. The paper presents a comparison between the proposed method and existing global-based matching methods.