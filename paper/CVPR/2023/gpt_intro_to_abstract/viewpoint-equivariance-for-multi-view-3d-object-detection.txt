Camera-based 3D object detection is an important research area with applications in autonomous driving and robotics. Monocular 3D detection has made significant progress, but it is inherently ambiguous in terms of depth. To address this, recent work has explored multi-view and multi-sweep 3D object detection. Existing multi-view algorithms aggregate information at the feature level, but less focus has been on learning objectives. This paper proposes a viewpoint-aware and viewpoint-equivariant learning objective for multi-view 3D detection models. The proposed framework, VEDet, incorporates geometry information through implicit geometric encodings and uses a transformer decoder to improve correspondence and 3D localization. Extensive experiments establish that VEDet achieves state-of-the-art performance on benchmark datasets. The contributions of this work include the proposal of a novel Viewpoint Equivariance learning objective, the development of the VEDet framework, and the analysis of its components.