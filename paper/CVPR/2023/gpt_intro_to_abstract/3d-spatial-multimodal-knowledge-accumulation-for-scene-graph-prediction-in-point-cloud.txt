In recent years, significant progress has been made in 3D point cloud scene understanding, particularly in semantic segmentation and object detection. However, the relationships between objects in a 3D scene are often overlooked. This paper focuses on the use of 3D scene graphs to represent the relationships between objects in a graph structure. Current methods for predicting these relationship graphs are not satisfactory due to noise and clutter in real 3D scans, and they lack the ability to incorporate useful spatial cues beyond visual information. This work proposes a hierarchical approach to 3D scene graph prediction, taking into account the structured regularities of 3D objects in real scenes. The key observation is that 3D scene structures are inherently hierarchical, and relationships between objects can be reasoned hierarchically. The authors introduce a knowledge-guided approach that explicitly merges hierarchical structures into the network to improve accuracy in 3D scene graph prediction. This approach incorporates a spatial multimodal knowledge accumulation module, which filters and classifies hierarchical tokens and constructs a symbolic knowledge graph. Additionally, a visual graph is built based on the hierarchical symbolic knowledge, and contextual features are extracted using a region-aware graph network. A graph reasoning network is then proposed to bridge the gap between symbolic knowledge and visual information. The results show that the learned knowledge and proposed modules improve the performance of 3D scene graph prediction. This work contributes by unifying the regular patterns of 3D spaces with deep architectures, introducing a hierarchical symbolic knowledge construction module, a knowledge-guided visual context encoding module, and a 3D spatial multimodal knowledge accumulation module.