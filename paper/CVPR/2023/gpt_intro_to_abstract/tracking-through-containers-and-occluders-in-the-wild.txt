This paper addresses the challenge of tracking and segmenting a target object as it becomes occluded or contained by other dynamic objects in a scene. This skill, referred to as object permanence, is crucial for perception systems to navigate real-world scenarios. The paper proposes a benchmark dataset of occlusion- and containment-rich scenes for evaluating the object permanence capabilities of neural networks. The dataset includes scenes sourced from both simulation and the real world, allowing for an extensive analysis of existing tracking systems. The paper also explores the performance of state-of-the-art video transformer architectures in tracking and segmenting a target object through occlusion and containment. The results highlight the need for improved reasoning about object permanence in complex environments. The dataset and benchmark are released to encourage progress in spatial reasoning capabilities.