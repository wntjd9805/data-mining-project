This paper addresses the challenging problem of 3D hand shape and texture reconstruction from a single RGB image. Such reconstruction has various applications, including human-machine interaction, virtual and augmented reality, and sign language translation. The existing approaches can be categorized into model-based and model-free methods, each having its limitations. Model-based approaches utilize a parametric model but are constrained by limited hand exemplars. Model-free approaches regress the coordinates of 3D hand joints and mesh directly but struggle with capturing long-range dependencies. To overcome these limitations, this paper proposes a probabilistic approach that combines the benefits of both model-based and model-free methods. The proposed Attention-based Mesh Vertices Uncertainty Regression (AMVUR) model incorporates the MANO model into a prior-net to estimate the prior probability distribution of joints and vertices. The AMVUR model employs a cross-attention model and a self-attention model to improve feature representation and capture correlations and dependencies among mesh vertices. The paper also introduces an occlusion-aware hand texture regression model for achieving high-fidelity texture reconstruction. The proposed approach achieves state-of-the-art performance on benchmark datasets and supports both fully supervised and weakly supervised training schemes.