Convolutional neural network (CNN)-based 3D object detection methods using point clouds have gained popularity for self-driving cars. However, these methods require increased computational complexity to achieve higher precision in various scenarios. Some studies have proposed methods to improve the speed of 3D object detection by removing non-maximum suppression (NMS) or anchor procedures but still have large network parameters. This paper presents a novel knowledge distillation (KD) method for lightweight point-cloud based 3D object detection. The proposed method consists of a channel-wise autoencoder for knowledge interchange and a head relation-aware self-attention mechanism. By compressing and decompressing the map-view features, the autoencoder effectively represents the 3D knowledge. The decoder reconstructs the features under the guidance of the teacher network, enabling effective learning in the student network. The head relation-aware self-attention mechanism refines the detection results and considers the inter-head and intra-head relations. Extensive experiments on Waymo and nuScenes datasets demonstrate the superior performance of the proposed method in reducing parameters and improving detection accuracy.