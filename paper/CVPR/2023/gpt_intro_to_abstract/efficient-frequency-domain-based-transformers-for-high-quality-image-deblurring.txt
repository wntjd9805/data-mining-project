Image deblurring is a problem that aims to restore clear images from blurry ones. Recently, significant progress has been made in this field thanks to the development of deep convolutional neural network (CNN) models. These models have been successful in image deblurring because of their innovative network architectural designs. However, the convolution operation used in these networks is a spatially-invariant local operation that does not effectively model the spatially variant properties of the image contents. To address this limitation, Transformers, which are able to model global contexts, have been proposed as an alternative to CNN models. Transformers have shown promise in high-level vision tasks, including image deblurring. However, the computation of Transformers has a quadratic complexity in terms of the number of tokens, which limits their applicability to high-resolution images. This paper presents an efficient method for image deblurring that utilizes the properties of Transformers. The method proposes a frequency domain-based self-attention solver to estimate the scaled dot-product attention, reducing the space and time complexity. Additionally, a discriminative frequency domain-based feed-forward network is developed to generate better features for latent clear image restoration. The method also introduces an asymmetric network architecture that uses the frequency domain-based solver only in the decoder module for improved image deblurring. Experimental results demonstrate that the proposed method outperforms state-of-the-art methods in terms of accuracy and efficiency. The main contributions of this paper are the efficient frequency domain-based solver, the discriminative frequency domain-based feed-forward network, the asymmetric network architecture, and the analysis of the exploring properties of Transformers in the frequency domain for blur removal.