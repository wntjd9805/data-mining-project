This paper introduces the concept of video codec and its philosophy of reducing redundancy in spatial-temporal signals. It compares the development of traditional codecs and their coding gains achieved through expanded coding modes. The complexity of traditional codecs and the need for rate distortion optimization (RDO) are discussed. The paper then introduces neural video codec (NVC) which changes the extraction and utilization of context from hand-crafted design to automatic-learned manner. The limitations of current NVCs are highlighted, leading to the research question of how to better learn and use contexts while maintaining low computational cost. The paper proposes a new model called DCVC-DC which efficiently utilizes diverse contexts to improve compression ratio. It describes the hierarchical quality pattern learning, the adoption of offset diversity, and the spatial context diversity through quadtree-based partition. The designs are parallel-efficient and employ depth-wise separable convolution. Experimental results show that DCVC-DC achieves higher efficiency and bitrate savings compared to previous state-of-the-art NVCs. It also outperforms the best traditional codec in both RGB and YUV420 colorspaces. The paper summarizes its contributions in efficiently increasing context diversity, guiding model extraction of high-quality contexts, adopting a quadtree-based partition, and achieving higher efficiency and compression ratio.