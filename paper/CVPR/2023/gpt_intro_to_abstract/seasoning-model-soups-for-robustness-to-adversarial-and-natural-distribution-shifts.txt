Deep neural networks have achieved remarkable success in computer vision tasks, but they often suffer from poor performance when faced with inputs that differ from the training data distribution, known as distribution shift. Adversarial perturbations, even minute changes to images, can cause these networks to make errors. Furthermore, natural shifts such as different weather conditions can significantly reduce the accuracy of vision models. Adversarial training and data augmentation have been effective in improving robustness to adversarial attacks and natural shifts, respectively. However, it remains challenging to create a single model that is robust to a wide range of threats and shifts. Existing approaches typically focus on defending against specific types of perturbations and require training multiple classifiers to control the trade-off between robustness and nominal performance. Inspired by model soups, which interpolate the parameters of a set of vision models to achieve high accuracy, we investigate the effects of interpolating robust image classifiers. We propose a method to pre-train, fine-tune, and combine the parameters of models trained against different types of adversarial attacks. Our approach allows for smooth trade-offs between different threat models and achieves competitive performance compared to methods that train on multiple adversaries simultaneously. Additionally, our model soups offer the ability to choose the level of robustness to each threat model without further training and can quickly adapt to new unseen attacks or shifts. We demonstrate that model soups of diverse classifiers provide greater flexibility in achieving high performance across various shifts, such as variations of the IMAGENET dataset. Furthermore, we show that a small number of images from a new distribution are sufficient to select the weights of the model soup. Our approach not only allows for selecting a model specific to each image distribution but also enables joint selection for improved accuracy across multiple IMAGENET variants. Overall, our contributions include the ability to merge nominal and robust models, control the level of robustness, extrapolate to find more effective classifiers, and adapt to unseen distribution shifts with limited examples.