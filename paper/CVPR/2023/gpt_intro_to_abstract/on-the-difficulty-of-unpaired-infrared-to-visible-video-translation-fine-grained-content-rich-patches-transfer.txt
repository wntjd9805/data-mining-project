This paper addresses the challenge of unpaired infrared-to-visible video translation in computer vision. While visible light cameras have broad applicability, their imaging results are often ambiguous in adverse weather conditions. Infrared sensors, on the other hand, capture stable structural information but suffer from semantic lacking issues. To address this, the paper proposes the CP-Trans framework, which focuses on improving the generation of content-rich patches. The framework introduces two novel modules: Content-aware Optimization (CO) to balance gradients for improved content-rich patches, and Content-aware Temporal Normalization (CTN) to handle motion. The paper also extends the InfraredCity dataset to adverse weather conditions for promoting infrared-related research. Extensive evaluations show that the proposed approach outperforms previous methods, setting new state-of-the-art performances. Further applications, including object detection, video fusion, and semantic segmentation, validate the effectiveness of the approach. The contributions of the paper include identifying the problem of optimized gradients along biased distribution, proposing the CPTrans framework, and extending the InfraredCity dataset.