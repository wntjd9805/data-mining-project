Neural Radiance Fields (NeRF) have the ability to learn scene representation from 2D images, but not all scenes are desirable due to occlusions. Removing occlusions using computational methods is of great interest. Current methods for occlusion removal have limitations, such as oversmoothing essential details and dependence on external supervision. To address these challenges, we propose a method that progressively aggregates an occlusion-free world by observing occluded parts from different viewing directions. We leverage NeRF to map viewing angles and scene details and introduce a depth constraint to probe occluded areas. We also refine camera pose using background features and employ a selective supervision scheme. Our method achieves occlusion-free representation without relying on external priors, effectively fuses multi-view features, and uses scene depth information to probe occluded areas. Experimental results demonstrate the effectiveness of our method in removing various types of occlusions without external supervision.