This paper introduces the concept of scaling in embodied AI experiments and highlights the need for larger-scale training in order to achieve comparable results to computer vision (CV) and natural language processing (NLP) experiments. The authors argue that current navigation experiments in embodied AI fall short in terms of scale compared to vision-and-language experiments. They present a large-scale simulation+RL framework called Galactic for robotic mobile manipulation in indoor environments. Galactic is designed to optimize the rendering+physics+RL interplay, achieving high simulation speed and enabling massive speed-ups in training time. The authors demonstrate the scalability of Galactic by training a mobile pick skill to high accuracy in a significantly shorter time compared to existing methods. They also perform the largest-scale experiment to date for rearrangement tasks, achieving impressive performance in GeometricGoal rearrangement. The learned policies show efficient navigation, avoidance of distractor objects, and synchronization of base and arm movement. Additionally, the authors show that models trained in Galactic exhibit some robustness to zero-shot sim2sim generalization, performing well when deployed in different simulation environments. Overall, this work contributes to the understanding and advancement of large-scale training in embodied AI.