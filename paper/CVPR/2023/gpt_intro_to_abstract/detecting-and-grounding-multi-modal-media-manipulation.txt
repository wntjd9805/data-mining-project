Recent advancements in deep generative models have led to the proliferation of hyper-realistic face images and videos, resulting in various security concerns such as deepfake dissemination. In response, numerous deepfake detection methods have been proposed in the computer vision community. Similarly, the rise of Large Language Models has facilitated the easy generation of text fake news, leading to the development of various detection methods in the field of Natural Language Processing.However, compared to a single modality, the dissemination of multi-modal media (image-text pairs) poses a greater threat due to its broader information and greater impact in daily life. To address this new threat, this paper introduces a novel research problem, referred to as Detecting and Grounding Multi-Modal Media Manipulation (DGM4). DGM4 presents two challenges: simultaneous detection of forgery in both image and text modality, and grounding manipulated image bounding boxes and text tokens.Existing single-modal forgery detection methods are inadequate for DGM4 due to the need for comprehensive reasoning of manipulation characteristics between two modalities. While previous works have explored multi-modal misinformation, they only determine binary classes of multi-modal media, without considering manipulation grounding.To enable research on DGM4, this paper contributes the first large-scale DGM4 dataset, focusing on human-centric news as a representative multi-modal media form. The dataset includes two image manipulation approaches (face swap/attribute manipulation) and two text manipulation approaches (text swap/attribute manipulation). Rich annotations are provided for detection and grounding, including binary labels, fine-grained manipulation types, manipulated image bounding boxes, and manipulated text tokens.Manipulated multi-modal media inevitably leaves traces of manipulation in manipulated image regions and text tokens, causing semantic inconsistency between the two modalities. Therefore, reasoning the semantic correlation between images and texts can provide insights for the detection and grounding of multi-modal manipulation. To address this, the paper proposes a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) that aligns image and text embeddings through manipulation-aware contrastive learning and aggregates multi-modal embeddings via modality-aware cross-attention.The main contributions of this paper include the introduction of the DGM4 research problem, the development of a large-scale DGM4 dataset, and the proposal of the HAMMER model for comprehensive manipulation detection and grounding. The superiority of HAMMER is demonstrated through extensive quantitative and qualitative experiments.