Gesturing is important for human speakers as it adds expressiveness and enhances persuasion and credibility. In the virtual world, high-quality 3D gesture animations can make talking characters more vivid. Automatic synthesis of co-speech gestures in computer animation is in high demand but remains challenging due to the complex relationship between speech and gestures. Traditional rule-based approaches are limited in diversity and semantics, while data-driven approaches sacrifice diversity and learn averaged gestures. Adversarial learning frameworks improve generalizability but fail to explore the relationship between speeches and gestures. To address these challenges, we propose a novel Reinforcement leArning framework with Contra-sitive prE-trained Rewards (RACER) for generating high-quality co-speech gestures. RACER consists of a vector quantized variational autoencoder (VQ-VAE) to extract meaningful gestures, a Q-value network based on GPT for coherence sequence generation, and a contrastive speech-gesture pre-training method to compute rewards that evaluate the quality of gestures as a sequence. Our contributions include formally modeling the co-speech gesture synthesis as a Markov decision process, introducing VQ-VAE to reduce the action space, proposing a contrastive pre-training method for deeper relation exploration, and demonstrating the superiority of RACER through extensive experimental results.