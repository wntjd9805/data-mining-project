Discretized surface semantic segmentation is a crucial task in 3D vision and computer graphics. While previous approaches have successfully applied Transformer models to process 3D point cloud input, adapting these models to mesh input poses challenges due to the irregular and unordered nature of meshes. Existing methods have not effectively addressed these challenges, resulting in limited segmentation accuracy for mesh input. In this work, we propose a novel self-attention operation called Heat Diffusion based Multi-head Self-Attention (HDMSA) to adaptively extract multi-scale information from local to global contexts in irregular meshes. We also introduce a Heat Kernel Signature based Structure Encoding (HKSSE) module to capture the geometric structural information of meshes. Our MeshFormer model integrates these techniques and achieves state-of-the-art results in mesh based semantic segmentation. To the best of our knowledge, this is the first mesh based Transformer model to incorporate heat diffusion methods for this task. Our contributions include the development of an enhanced self-attention operation for multi-scale feature extraction and a novel structure encoding module for structure-aware segmentation output. We demonstrate the feasibility of extending the Transformer model to 3D mesh input using heat diffusion methods.