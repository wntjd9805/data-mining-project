Novel-view synthesis (NVS) is a fundamental task in computer vision, aiming to generate unseen viewpoints of a scene based on a set of input images. The success of Neural Radiance Fields (NeRFs) has popularized NVS, as NeRFs effectively encode 3D scenes using a multi-layer perceptron (MLP) and synthesize high-quality images. However, NeRFs have limitations in real-world applications where the input data is sparse and camera poses are not accurate. In such scenarios, NeRFs suffer from overfitting and produce inconsistent or degenerate reconstructions. Existing approaches have attempted to improve NeRF performance in sparse-view settings but still rely on accurate camera poses, which are difficult to estimate with limited input views. To address these challenges, we propose Sparse Pose Adjusting Radiance Field (SPARF), a joint pose-NeRF training strategy. SPARF leverages multi-view geometry to enforce learning a global and geometrically accurate solution by inferring pixel correspondences and minimizing re-projection error. We also introduce a depth consistency loss to enhance rendering quality. Our evaluations on challenging datasets demonstrate that SPARF achieves state-of-the-art performance in novel-view synthesis.