This paper focuses on the problem of optical flow estimation, which involves estimating the per-pixel displacement vector between two frames. Optical flow estimation is widely used in real-world applications such as video frame interpolation, video inpainting, and action recognition. Current deep learning-based methods have achieved significant success in this domain but still struggle with certain challenges like small and fast-moving objects, occlusions, and textureless regions. In this paper, the authors propose a rethinking of the importance of Geometric Image Matching (GIM) in optical flow estimation. They suggest that deep models for optical flow should be trained using matching static scene pairs with consistent displacements, as GIM shares similarities with optical flow estimation in terms of displacement and appearance change challenges. The authors argue that training deep models on GIM data, which is easier to collect and label, can greatly improve the generalization of optical flow estimation. The authors also propose a novel optical flow estimation model called MatchFlow, which utilizes a Feature Matching Extractor module trained on GIM data to estimate optical flow. They conduct extensive experiments and ablation studies to demonstrate the effectiveness of their proposed model and show its superior performance compared to other optical flow estimation methods on various benchmark datasets. The contributions of this paper include the re-formulation of the optical flow pipeline by incorporating GIM as a preluding task, the introduction of the MatchFlow model that leverages matching-based pre-training and interleaving self/cross-attention modules, the utilization of real-world matching data for training the model, and the demonstration of the model's strong cross-dataset generalization and performance.