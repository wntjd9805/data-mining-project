Human Pose Estimation (HPE) and Human Mesh Reconstruction (HMR) from monocular images are challenging tasks in computer vision due to depth ambiguity, occlusion, and complex body articulation. Convolutional Neural Network (CNN) architectures have been widely used in HPE and HMR models, but they struggle to capture global dependencies between body parts. Recently, the transformer architecture from natural language processing has been successfully applied to computer vision tasks, showing improved performance in HPE and HMR. However, existing Vision Transformer architectures can only process flattened features, which is not ideal for preserving structural context. Additionally, the large embedding dimension in transformers makes them computationally expensive, limiting their real-time applicability. In response, we propose a Feature map-based transformER (FeatER) architecture that preserves the structural context of feature maps and reduces computational cost. FeatER performs self-attention on the original 2D feature maps using a dimensional decomposition strategy. We integrate FeatER into a framework for 2D HPE, 3D HPE, and HMR, with a feature map reconstruction module for more robust predictions. Extensive experiments on human representation tasks show that FeatER outperforms state-of-the-art methods with significant reduction in computation and memory costs.