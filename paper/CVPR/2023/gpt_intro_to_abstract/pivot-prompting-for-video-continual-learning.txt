Modern Deep Neural Networks (DNNs) have achieved remarkable performance in machine vision tasks, thanks to large-scale pre-training and feature reuse. However, fine-tuning pre-trained DNNs on new datasets often leads to catastrophic forgetting, where performance decreases on the original distribution. Continual Learning (CL) techniques have been developed to address this issue, with a focus on Class Incremental Learning (CIL) scenarios. While progress has been made in mitigating catastrophic forgetting in image domain CL, video domain CL presents additional challenges due to the need for temporal modeling. Current state-of-the-art methods for video CIL rely on temporal masking and feature distillation. In this paper, we propose a novel strategy called PIVOT for CIL in the video domain, inspired by advances in zero-shot image classification and learnable prompts for continual learning. We demonstrate that a zero-shot baseline pre-trained in the image domain outperforms existing CIL methods in action recognition. Furthermore, we show that incorporating temporal reasoning and a novel prompting strategy further improves the baseline, setting a new state-of-the-art in the challenging vCLIMB benchmark for video CIL. Our approach leverages the visual knowledge in the CLIP visual encoder, trained on paired static images and text, to enhance video understanding in continual learning. The contributions of our work include the effectiveness of a multi-modal classifier in mitigating catastrophic forgetting, the design of a prompt-based strategy for video CIL, and the superior performance of PIVOT compared to state-of-the-art methods in the vCLIMB benchmark. Experimental analysis demonstrates the significant performance improvements achieved by PIVOT in various video action recognition tasks.