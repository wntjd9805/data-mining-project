Image Aesthetic Assessment (IAA) plays a crucial role in various applications such as photo recommendation, selection, and editing. However, IAA is challenging due to its subjective nature and dependence on various factors. Previous learning-based methods for IAA have relied on human-labeled aesthetic ratings, which may lack context and additional information. In this paper, we propose a novel vision-language aesthetics learning framework called VILA, which utilizes image-comment pairs from aesthetic websites and forums. We leverage the abundance of aesthetic information expressed through natural language in these pairs to improve IAA performance. Our framework consists of a two-stage approach: pretraining and fine-tuning. In the pretraining stage, we learn an image-text model using contrastive and text sequence generation objectives to capture fine-grained aesthetic knowledge. In the fine-tuning stage, we use a rank-based adapter to adapt the pretrained model to downstream IAA tasks. Our proposed VILA framework achieves superior performance on aesthetic captioning, zero-shot aesthetic tasks, and style classification. Furthermore, it outperforms prior approaches on IAA correlation metrics and demonstrates zero-shot learning capabilities. Our work contributes to the development of a versatile and cost-effective method for image aesthetic assessment using vision-language models.