Semantic segmentation is a crucial task in various fields, including medical imaging and autonomous driving. Existing supervised approaches for semantic segmentation require expensive and time-consuming pixel-level annotations. This has led to the development of weakly-supervised and unsupervised semantic segmentation methods that can learn without pixel-level annotations. Unsupervised semantic segmentation is particularly challenging as it requires capturing pixel-level semantics from unlabeled data. Clustering-based approaches and representation learning have been proposed to tackle this challenge. However, these methods have limitations in terms of relying on a fixed backbone and overlooking the importance of semantic consistency along adjacent patches. In this paper, we propose a novel method that leverages contrastive learning based on hidden positives to ensure contextual and local consistency in semantic segmentation. We introduce global hidden positives, which are semantically similar patch pairs, and utilize task-specific features to enhance their contribution. We also develop a gradient propagation technique to learn local semantic consistency among nearby patches. Extensive experiments show that our approach outperforms existing state-of-the-art methods.