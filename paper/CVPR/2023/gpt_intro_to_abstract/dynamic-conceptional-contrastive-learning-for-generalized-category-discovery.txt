Learning recognition models from labeled data has been extensively studied in the field of machine learning and deep learning. However, these supervised learning techniques heavily rely on large annotated datasets, which are not suitable for open-world applications. To address this limitation, researchers have recently focused on learning with label-imperfect data, such as self-supervised learning, weakly-supervised learning, and learning with noisy labels. In this paper, we introduce a Dynamic Conceptional Contrastive Learning (DCCL) framework for generalized category discovery (GCD), which aims to jointly distinguish known and unknown classes and discover novel clusters without any annotations. Our framework includes two steps: Dynamic Conception Generation (DCG) and Dual-level Contrastive Learning (DCL). In DCG, we dynamically generate conceptions based on a clustering method with a proposed semi-supervised conceptional consolidation. In DCL, we optimize the model using conception-level and instance-level contrastive learning objectives, with a dynamic memory to ensure comparison with up-to-date conceptions.Our contributions include: proposing the DCCL framework to leverage the underlying relationships between unlabeled samples for learning discriminative representations in GCD; introducing a dynamic conception generation and update mechanism to ensure consistent conception learning and encourage more discriminative representation; and achieving superior performance over state-of-the-art GCD algorithms on both generic and fine-grained tasks.