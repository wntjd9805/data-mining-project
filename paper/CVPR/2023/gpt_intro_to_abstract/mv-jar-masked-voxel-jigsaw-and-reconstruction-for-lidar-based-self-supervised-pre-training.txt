Self-supervised pre-training has gained attention in the field of computer vision due to its impressive performance in visual representation learning. However, while existing methods have shown success in image-based modalities, developing effective self-supervised proxy tasks for LiDAR point clouds remains a challenge. This paper proposes a new method called Masked Voxel Jigsaw And Reconstruction (MV-JAR) for LiDAR-based self-supervised pre-training. MV-JAR takes into account the unique properties of LiDAR point clouds, such as their sparsity and irregular distribution, and utilizes voxel and point distributions to improve performance. The paper also highlights the limitations of current data-efÔ¨Åcient experiments in evaluating pre-training methods and proposes a new benchmark on the Waymo dataset to address these shortcomings. Experimental results demonstrate that MV-JAR significantly enhances the performance and convergence speed of 3D object detectors in downstream tasks, even with limited fine-tuning data. Furthermore, detectors pre-trained using MV-JAR show generalizability when transferred to other datasets, such as KITTI.