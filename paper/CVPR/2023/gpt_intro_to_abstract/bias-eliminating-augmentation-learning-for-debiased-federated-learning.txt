Deep neural networks have shown remarkable progress in various domains, but their success heavily relies on training data that accurately represents the underlying distribution of the data of interest. However, in real-world scenarios, biased data is often encountered during data collection. Biased datasets contain features that are highly correlated with class labels in the training dataset but do not adequately capture the underlying semantic meaning. Training models on such biased data leads to compromised generalization capability. To address this problem, several methods have been proposed for removing or alleviating data bias in centralized datasets. However, these techniques may fail to generalize when applied to distributed learning scenarios, particularly in federated learning (FL) where data collection and training are conducted at each client to preserve data privacy. In FL, the real-world applications are prone to suffer from data heterogeneity and potential data bias across clients. Existing FL methods focus on handling label distribution skew or domain discrepancy among clients, but not on addressing data bias. To mitigate local bias in FL, we propose a novel FL scheme called Bias-Eliminating Augmentation Learning (FedBEAL). In FedBEAL, we learn a Bias-Eliminating Augmenter (BEA) for each client to generate bias-conflicting samples that eliminate local data biases. Our approach uniquely utilizes the global server model and client models trained across iterations to identify and embed desirable semantic and bias features for augmentation purposes. We present the contributions of this work, including being among the first to tackle debiased federated learning, introducing FedBEAL for debiased FL, and utilizing the server and client models for learning the BEA and producing bias-conflicting samples.