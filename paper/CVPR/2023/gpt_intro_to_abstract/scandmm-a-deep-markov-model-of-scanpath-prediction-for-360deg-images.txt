Virtual reality (VR) images, also known as 360◦ images, have gained popularity in various applications due to their immersive experiences. However, there is limited understanding of how users explore virtual environments in 360◦ images. Scanpath prediction models, which aim to generate realistic gaze trajectories, have been of interest in understanding viewing behaviors and developing VR rendering, display, compression, and transmission. While scanpath prediction has been extensively explored in 2D images, 360◦ images pose unique challenges as they offer a larger space for interaction. This paper presents a probabilistic approach called ScanDMM, which uses a Deep Markov Model (DMM) to learn time-dependent attentional landscapes in 360◦ images. The proposed model incorporates visual working memory and scene semantics to model the nonlinear dynamics of gaze behavior. The authors also propose a strategy for initializing the visual state and demonstrate the model's effectiveness in generating variable-length scanpaths. Furthermore, the ScanDMM is applied to saliency detection and image quality assessment tasks, showcasing its potential for broader applications in computer vision.