Humans have the ability to recognize scenes and decompose them into hierarchical elements with dependencies. Classical image dependency parsing algorithms have been proposed to parse images into their constituent visual patterns. However, these methods often rely on human annotations or pre-trained object detection models, limiting their generalizability. In this paper, we propose DependencyViT, a visual dependency parser that can induce visual dependencies and build hierarchies from images without human annotations. We introduce a reversed self-attention mechanism to form a root-centric dependency parser and a message controller to determine how nodes send messages. We also introduce a soft head selector to generate a unique dependency graph for each layer. Experimental results demonstrate the effectiveness of DependencyViT in both part-level and object-level parsing. Additionally, we propose DependencyViT-Lite, a lightweight model that reduces computational cost through dynamic pooling and pruning. Extensive experiments on both self-supervised and weakly-supervised pretraining, as well as downstream tasks, validate the effectiveness of DependencyViT.