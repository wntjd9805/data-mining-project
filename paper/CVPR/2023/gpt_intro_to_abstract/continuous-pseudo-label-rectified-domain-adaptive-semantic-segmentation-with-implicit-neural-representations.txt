Semantic segmentation, which assigns semantic labels to pixels in images, is a fundamental problem in computer vision. The advancement of deep neural networks (DNNs) and the availability of large-scale datasets have greatly improved the state-of-the-art performance in this area. However, DNNs trained on one domain may not generalize well to another domain due to the distribution shift between the domains. The traditional approach of annotating images from the target domain and retraining the model is costly and labor-intensive. Unsupervised domain adaptation (UDA) has emerged as an alternative, where models are trained on labeled source domain data and unlabeled target domain data. Pseudo-labeling, or self-training, has shown promise as a simple and effective UDA approach. Pseudo-labels are generated on the target domain using the current model and used to fine-tune the model iteratively. However, some pseudo-labels may be incorrect due to the domain shift, necessitating rectification. Existing rectification methods often use heuristic functions, which assume strong correlations between the function and pseudo-label quality. Additionally, these methods typically model rectification in a discrete spatial grid, leading to inaccurate estimations near boundaries and restricted scalability. To address these issues, we propose a novel continuous rectification-aware mixture model (RMM). Our approach formulates the rectification function as an implicit rectification-representative function (IR2F), which learns pixel-wise rectification values as latent codes and decodes them at arbitrary continuous spatial coordinates. We evaluate our continuous RMM on various UDA benchmarks and demonstrate its superior performance compared to previous state-of-the-art methods. Continuous RMM shows significant potential for modeling pseudo-label rectification in a learnable and continuous manner, inspiring further research in this field.