Neural Radiance Fields (NeRFs) have seen numerous extensions since their initial publication. While they were originally used for novel view synthesis, there is growing interest in applying them to new tasks such as NeRF editing and live capture and training. One technical challenge that has emerged is how to seamlessly remove parts of the rendered scene. This can be useful for various applications, such as removing unappealing or personally identifiable objects from house scans or replacing objects in augmented reality applications. Existing approaches for editing NeRFs have limitations in terms of generative capabilities and the ability to inpaint missing regions. In this paper, we propose a new method that combines the multi-view consistency of NeRFs with the generative power of 2D inpainting models. We introduce a confidence-based view-selection scheme to address the issue of inconsistent inpaintings and demonstrate the effectiveness of our approach on a new dataset. Our contributions include the first approach for inpainting NeRFs using single image inpainting, a novel view-selection mechanism for removing inconsistent views, and a new dataset for evaluating object removal and inpainting in indoor and outdoor scenes.