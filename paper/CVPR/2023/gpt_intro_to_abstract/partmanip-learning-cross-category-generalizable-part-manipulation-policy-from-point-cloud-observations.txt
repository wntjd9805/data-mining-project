This paper addresses the need for generalizable object manipulation skills in intelligent robots. While recent advancements have led to the development of generalist agents, their manipulation skills are limited to known instances and do not generalize to novel object instances. Previous benchmarks and methods have provided some progress in category-level object manipulation, but they still fall short of human-level adaptability. The paper introduces a new benchmark, Part-Manip, built upon GAPartNet, which requires agents to learn skills across different object categories. This benchmark is more realistic and diverse, using partial point clouds as inputs without additional oracle information. The authors propose a two-stage training framework, training a state-based expert policy and distilling it to a vision-based student policy. They also introduce novel techniques to improve policy training and address the problem of overfitting and generalization. Through extensive experiments, the proposed approach outperforms previous methods, especially for unseen object categories. Real-world experiments also validate the effectiveness of the approach.