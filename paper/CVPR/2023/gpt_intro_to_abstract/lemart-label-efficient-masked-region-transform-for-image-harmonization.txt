The goal of image harmonization is to synthesize photo-realistic images by transferring foreground regions from one image to another. However, the appearance mismatch between the foreground and background poses a challenge due to differences in camera settings, lighting conditions, and post-processing. Image harmonization has various applications in image editing, video synthesis, and computer vision tasks. Traditional approaches focus on color transforms, but their generalization ability is questionable. Recent works have constructed datasets for training learning-based methods, but their scalability is limited. In this paper, we propose a self-supervised pre-training method called LEMaRT, which generates training data without annotations by perturbing foreground attributes. We also introduce an image harmonization model based on the Swin Transformer architecture called SwinIH, which addresses block boundary artifacts. Our experiments show that LEMaRT significantly improves the performance of models with different architectures. We achieve state-of-the-art results on the iHarmony4 dataset while consuming less training data. Our contributions include the introduction of LEMaRT, the design of SwinIH, and the improved performance on image harmonization tasks.