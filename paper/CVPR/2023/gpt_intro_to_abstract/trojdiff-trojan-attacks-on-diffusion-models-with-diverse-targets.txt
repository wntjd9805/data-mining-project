Diffusion models have recently emerged as powerful deep generative models capable of generating high-quality samples in various data modalities. These models utilize a diffusion process and a generative process to transform the data distribution into a standard Gaussian distribution and vice versa. Diffusion models offer advantages over other deep generative models, such as GANs and likelihood-based models, in terms of training stability and competitive log-likelihoods.However, the impressive performance of diffusion models relies heavily on large-scale training data, which is often collected from diverse open sources that may contain maliciously manipulated data. One significant threat to models trained on open source data is Trojan attacks, where an attacker inserts a Trojan trigger into a few training samples and relabels them as a specific target class. The trained model then falsely predicts instances containing the trigger as the adversarial target class. This poses a stealthy and serious threat to diffusion models.To investigate the vulnerability of diffusion models to Trojan attacks, this paper proposes the first Trojan attack on diffusion models, called TrojDiff. The authors study two generic diffusion models, DDPM and DDIM, and develop a Trojan diffusion process to bias the Gaussian distribution towards an adversarial target. They also propose a novel parameterization of the generative process to learn the reverse Trojan diffusion process. After training, the Trojaned diffusion models consistently output adversarial targets, demonstrating high attack performance on CIFAR-10 and CelebA datasets.The empirical results show that TrojDiff achieves high attack precision and success rates in various attack scenarios while maintaining the benign performance of the models. The paper's main contributions include revealing the vulnerabilities of diffusion models to data manipulation, proposing the Trojan diffusion and generative processes, and demonstrating the superior attack performance of TrojDiff while preserving benign performance on benchmark datasets.In conclusion, this paper introduces TrojDiff, the first Trojan attack on diffusion models, highlighting the vulnerabilities of these models to data manipulations. The proposed attack achieves high attack performance while maintaining the models' benign performance, indicating the need for robust defenses against Trojan attacks in deep generative models.