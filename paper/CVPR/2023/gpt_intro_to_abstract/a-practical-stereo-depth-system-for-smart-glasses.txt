Stereo disparity estimation is a fundamental problem in computer vision with applications in various fields. While neural networks have achieved high accuracy in benchmarks, there are practical challenges in using stereo in an end-to-end depth sensing system. This paper presents a productionized system for smart glasses equipped with stereo cameras, where computation occurs on a paired mobile phone. The system performs pre-processing, stereo rectification, and depth estimation, with fallback to monocular depth estimation if rectification fails. The output is fed into a rendering pipeline for creating 3D computational photographic effects. The goal of the system is to provide the best user experience while operating on a limited computational budget. The trained model demonstrates performance on par with state-of-the-art networks despite being significantly faster. The main contributions include the design choices and fallback plans of the end-to-end stereo system, a fast and robust online rectification algorithm, a strategy to align the output format of stereo and monocular depth networks, and the demonstration of competitive accuracy on a limited compute budget.