Abstract:Domain adaptation is a promising technique for reducing dataset bias and improving the transferability of vision models to sparsely labeled target domains. However, current methods and benchmark datasets for domain adaptation are limited to specific divergences between domains and do not consider the geographic origin of the data. In this paper, we address the problem of geographic bias in computer vision models by introducing a new large-scale dataset called GeoNet. GeoNet consists of three benchmarks: GeoPlaces for scene classification, GeoImNet for object recognition, and GeoUniDA for universal domain adaptation. The dataset includes images from the USA and Asia, which represent distinct geographical domains with various differences in culture, demographics, and climate. We also provide rich metadata associated with each image to support algorithms that leverage multimodal supervision. By analyzing GeoNet, we identify the challenges posed by geographic disparities, including context shift, design shift, and prior shift. We demonstrate how current unsupervised domain adaptation algorithms and modern architectures like vision transformers are limited in addressing these challenges. Our contributions include the GeoNet dataset, an analysis of domain shifts in geographic adaptation, extensive benchmarking of unsupervised adaptation algorithms, and a demonstration of the limitations of large-scale pretraining and vision transformers in addressing geographic disparities. These findings highlight the importance of considering geographic bias and motivate further research in this area.