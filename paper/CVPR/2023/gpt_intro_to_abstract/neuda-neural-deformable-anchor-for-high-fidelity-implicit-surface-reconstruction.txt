3D surface reconstruction from multi-view images is a fundamental problem in computer science. Current approaches involve cross-view feature matching, depth fusion, and surface reconstruction using methods like Poisson Surface Reconstruction. Some methods have explored the use of deep neural networks to improve the accuracy of sub-tasks in the reconstruction pipeline. Recent advancements have shown that neural implicit functions are promising for representing scene geometry and appearance. However, existing approaches have not fully explored the spatial context in 3D space, which can lead to difficulties in recovering fine-grain geometry in local areas such as boundaries and small structures. To address this, we propose Neural Deformable Anchor (NeuDA), a new neural implicit representation that leverages multi-level voxel grids. Rather than storing a regular embedding, we store the 3D position (anchor point) at each vertex and interpolate the features of adjacent anchors to obtain the input feature for a query point. The anchor points are optimized through backpropagation, allowing for flexible modeling of fine-grained geometric structures. We also introduce a hierarchical positional encoding policy that prioritizes high-frequency geometry and texture at finer grid levels. Experimental results demonstrate that NeuDA outperforms baselines and state-of-the-art methods in recovering high-quality geometry with fine-grained details. Despite using a shallower MLP, NeuDA achieves better surface reconstruction performance due to the promising scene representation capability of the hierarchical deformable anchor structure.