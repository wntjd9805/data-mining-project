Pansharpening is a crucial preprocessing step in remote sensing, where a high-resolution multispectral image (HRMS) is reconstructed from a low-resolution multispectral image (LRMS) with guidance from a panchromatic image (PAN). Previous methods have utilized techniques such as component substitution, multi-resolution analysis, and variational optimization. However, with the advancements in deep learning, deep learning-based methods have been proposed to address this problem. These methods typically involve upsampling the LRMS image followed by other super-resolution operations. However, existing upsampling methods used in pansharpening, such as bicubic interpolation and transposed convolution, are not specifically designed for this task and fail to exploit global information and channel specificity. To address these issues, we propose a novel probability-based global cross-modal upsampling method (PGCU) that utilizes probabilistic modeling to better adapt to the characteristics of pansharpening. The PGCU method establishes cross-modal feature vectors for each pixel in the upsampled HRMS image using global discrete distribution values sampled from the pixel value space, considering the distinctive properties of different spectral channels. Inspired by the Transformer architecture, the probability value for each pixel on its channel distribution is calculated using vector similarity. The pixel values of the upsampled image are then calculated by taking the expectation. Our proposed PGCU method consists of three blocks: information extraction (IE) module block, distribution and expectation estimation (DEE) block, and fine adjustment (FA) block. Experimental results demonstrate the effectiveness of the PGCU method, which can be integrated into existing state-of-the-art pansharpening networks to improve their performance. Additionally, the PGCU method is a universal upsampling method that has potential applications in other guided image super-resolution tasks.