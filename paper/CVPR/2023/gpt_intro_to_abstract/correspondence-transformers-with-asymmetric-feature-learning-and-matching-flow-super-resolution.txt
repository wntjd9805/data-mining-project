Robust semantic matching methods are essential for establishing dense visual correspondences between objects or scenes of the same category, even in the presence of significant variations in appearances and layouts. These methods have been widely used in various computer vision tasks, such as object recognition, cosegmentation, few-shot learning, and image editing. However, there are still two key issues that have not been fully addressed in state-of-the-art methods. Firstly, there is a need to learn feature representations that are suitable for semantic correspondence. Secondly, there is a need to enforce neighborhood consensus when dealing with high-resolution 4-D correlation tensors. In this paper, we propose a novel pipeline for semantic correspondence that addresses these issues. Our pipeline includes feature extraction using pre-trained feature backbones, asymmetric feature learning, and matching flow super-resolution. Unlike existing methods that calculate 4-D matching scores using refined generic backbone features, our approach focuses on finding a shared semantic space where local feature descriptors of images can be aligned with their corresponding features. The asymmetric feature learning module reconstructs source image features with target image features to reduce domain discrepancy, while the matching flow super-resolution enhances neighborhood consensus and improves matching accuracy. To reduce computational cost, we map the matching information from 4-D correlation matrices to 2-D matching flow maps using soft argmax. Experimental results on benchmark datasets demonstrate that our proposed method, called ACTRansformer, outperforms state-of-the-art methods by a significant margin. The qualitative results further illustrate the effectiveness of our approach.