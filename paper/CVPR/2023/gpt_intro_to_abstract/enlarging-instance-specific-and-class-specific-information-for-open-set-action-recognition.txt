Recent years have seen rapid development and remarkable performance in deep learning methods for video action recognition. However, these methods operate under a closed-set condition, meaning they can only classify videos into the classes encountered during training. This closed-set condition is not practical in real-world scenarios, as videos whose classes are beyond the training set range will be misclassified. To address this, open-set action recognition (OSAR) has been proposed, requiring the network to correctly classify in-distribution (InD) samples and identify out-of-distribution (OoD) samples. In this paper, we propose a novel approach to boost the open-set ability from the feature representation perspective. We first analyze the feature representation behavior in the open-set problem based on the information bottleneck theory, dividing the information into Instance-Specific (IS) and Class-Specific (CS) information. We find that the closed-set classification setting tends to eliminate IS information and cannot fully extract the minimum sufficient CS information for the task. To address this, we propose the Prototypical Similarity Learning (PSL) framework to enlarge the IS and CS information in learned feature representations for better OSAR performance. PSL encourages the retention of IS information and introduces the use of shuffled videos to extract distinct temporal information and enlarge CS information. Experimental results on multiple datasets and backbones demonstrate the superiority of PSL compared to other state-of-the-art counterparts in terms of OSAR performance.