Monocular 6D object pose estimation is a challenging task in computer vision that aims to estimate object poses from single images. Existing methods for monocular object pose estimation can be categorized as fully-supervised, utilizing annotated real images with ground-truth object poses, or self-supervised, utilizing synthetic images with object poses (sometimes in conjunction with un-annotated real images). Self-supervised methods have gained attention due to the time-consuming process of obtaining high-quality object poses as ground truth. However, the performance of self-supervised methods is lower compared to fully-supervised methods due to the domain gap between real and synthetic data.In this paper, we propose a novel Network for Self-supervised Monocular Object pose estimation (SMOC-Net) that addresses the domain gap and training costs. SMOC-Net utilizes un-annotated real images and predicted camera poses to estimate object poses. It consists of a teacher model and a student model trained via knowledge distillation. The teacher model incorporates a backbone pose estimation module and a geometric constraint on object poses derived from relative camera poses. A camera-pose-guided refiner is employed to refine the initial object pose. The student model learns from the teacher model by imposing the relative-pose constraint for accurate and fast object pose estimation. SMOC-Net's student model is used for predicting object poses in testing images.The contributions of this paper include the design of the relative-pose constraint to narrow the domain gap between synthetic and real data, the exploration of the camera-pose-guided refiner for effective refinement of low-accuracy object poses, and the proposal of SMOC-Net for monocular 6D object pose estimation. Experimental results demonstrate that SMOC-Net outperforms several state-of-the-art methods when trained with synthetic and un-annotated real images and performs better than fully-supervised methods on the public dataset LineMOD.