Gaze redirection is a task in computer science that involves manipulating an input image of a face to make it appear as though the face is looking in a specific direction, without altering the identity or other attributes of the subject. This technique has various applications, including video conferencing, image and movie editing, and human-computer interaction. It also has the potential to enhance the realism of avatars in virtual environments. Additionally, gaze-redirected images can be used to generate training data for gaze estimation tasks.Existing methods approach gaze redirection as a 2D image manipulation problem, using techniques such as image warping or deep generative models. However, these approaches have limitations. Image warping methods struggle to handle large changes due to their inability to generate new pixels. On the other hand, 2D generative models produce high-quality images but fail to consider the 3D nature of the task, leading to inconsistencies in spatial-temporal dynamics and identity.This paper introduces GazeNeRF, a novel approach that addresses these challenges by treating gaze redirection as a 3D task. GazeNeRF leverages recent advancements in image-based neural radiance fields (NeRF) to generate high-quality images. The method models the face and eyes as two separate 3D structures, using NeRF models to represent each structure. This allows for precise rotation of the eyes while maintaining the integrity of the face. GazeNeRF employs a two-stream multilayer-perceptron (MLP) structure to predict feature maps for the eyes and the rest of the face separately. The eye features are transformed using a desired 3D rotation matrix, and the regions are composited using differentiable volume rendering. Additional training losses and feature composition techniques are proposed to enhance the accuracy of gaze redirection.Experimental results demonstrate that GazeNeRF outperforms previous state-of-the-art methods in terms of gaze and head pose redirection accuracy and identity preservation across multiple datasets. This highlights the advantage of approaching gaze redirection as a 3D-aware problem.In summary, the contributions of this paper include the reformulation of gaze redirection as 3D-aware neural volume rendering, the disentanglement of face and eye features in GazeNeRF, and the achievement of state-of-the-art performance in gaze redirection accuracy and identity preservation.