The field of visual-textual presentation rendering on images, such as advertisement posters and magazines, relies heavily on layout design. However, using pre-defined templates limits the flexibility and diversity of presentations. To address this, an automated approach for generating visual-textual presentation layouts is proposed. Most existing approaches focus on the relationship between elements within a layer, neglecting the relationship between layers. This can lead to occlusion issues, where elements cover important content in the canvas. To overcome these limitations, a CNN-LSTM-based generative adversarial network (GAN) is proposed, which considers both graphic and content-aware metrics. CNN-LSTM has proven to be effective in time series forecasting and behavior analysis tasks, and is utilized to generate design sequences that imitate the design processes of human designers. Additionally, a new dataset and benchmark, PKU PosterLayout, consisting of diverse poster-layout pairs and images, is constructed and released. The proposed approach outperforms other methods in terms of generating proper layouts on diverse canvases. Overall, this paper contributes a new dataset, an algorithm for design sequence formation, and a CNN-LSTM-based GAN for generating content-aware visual-textual presentation layouts.