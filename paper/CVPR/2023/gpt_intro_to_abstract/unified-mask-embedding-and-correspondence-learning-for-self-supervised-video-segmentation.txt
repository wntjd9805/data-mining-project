This article focuses on the task of video object segmentation, specifically segmenting desired objects in a video sequence using pixel-wise masks. Existing solutions for this task rely on fully supervised learning techniques which require extensive labeling efforts. In contrast, this study aims to learn video object segmentation from unlabeled videos using a self-supervised approach. The proposed algorithm combines mask embedding and correspondence matching to enable mask-guided segmentation. Existing self-supervised solutions suffer from limitations such as not customizing the segmentation for target objects and using an outdated mask propagation strategy. To address these limitations, the proposed algorithm integrates mask embedding learning and dense correspondence modeling into a compact, end-to-end framework. The algorithm alternates between space-time pixel clustering and mask-embedded segmentation learning, utilizing pixel-level video partitions as pseudo ground-truths. The approach demonstrates the ability to conduct mask-guided sequential segmentation and outperforms state-of-the-art competitors in terms of mIoU gains on different datasets. By combining mask embedding learning with correspondence learning, this work establishes a tight coupling between self-supervised and fully supervised video object segmentation approaches. The authors anticipate that this work will foster collaboration between these two fields.