Advances in image editing and manipulation algorithms have enabled the creation of photo-realistic fake pictures, which poses a problem in terms of surveillance and crime prevention. Detecting manipulated regions is crucial, and low-level structures have been found to be beneficial in tampered region detection. For instance, resizing and copy-pasting destroy the JPEG compression levels between the tampered region and the host image, and the noise levels of the tampered region and the background differ. Additionally, low-level clues play an important role in segmenting blurred pixels, shadowed regions, and concealed objects. In this paper, we propose a unified method for four low-level structure segmentation tasks: camouflaged object detection, forgery detection, shadow detection, and defocus blur detection. Our approach leverages a pre-trained frozen transformer backbone that utilizes explicit extracted features, such as frozen embedded features and high-frequency components, to prompt knowledge. These tasks have proven to be beneficial in various computer vision tasks, including auto-refocus, image retargeting, and object tracking. Currently, these tasks are typically addressed with domain-specific solutions and carefully designed network architectures. The lack of large-scale datasets is also considered a limiting factor in achieving optimal performance. To address these challenges, we propose a solution that adopts a unified approach to the four tasks, inspired by recent advancements in prompting. Prompting involves efficiently adapting a frozen large foundation model to downstream tasks with minimum trainable parameters, resulting in better model generalization. Our main insight is to tune task-specific knowledge solely from the features of each individual image, as the pre-trained model already possesses sufficient knowledge for semantic understanding. We take into account the features from the frozen patch embedding and the high-frequency components of the input image. Through experiments on nine datasets for the four tasks, we validate the effectiveness of our approach. Our unified network achieves competitive performance, outperforming task-specific solutions without modification. In summary, our contributions include the design of a unified approach that produces state-of-the-art performances for multiple tasks, the proposal of explicit visual prompting that effectively improves tuning performance, and the simplification of low-level structure segmentation models while achieving comparable performance with existing methods.