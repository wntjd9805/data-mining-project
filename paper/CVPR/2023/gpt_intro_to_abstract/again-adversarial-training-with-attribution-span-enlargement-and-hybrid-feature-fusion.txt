This paper discusses the vulnerability of deep neural networks (DNNs) to adversarial attacks and the need for effective defenses against such attacks. Adversarial training (AT) has been identified as one of the most effective defenses, but it often shows a significant robust generalization gap. This work focuses on the attribution span, which is the range of features that the model focuses on during inference. It is found that adversarially trained DNNs have a smaller attribution span, resulting in limitations on test robustness. The authors propose a method called Attribution Span EnlarGement and Hybrid FeAture FusIoN (AGAIN) to boost AT and improve the generalization ability of the model. They expand the attribution span and use feature fusion to enhance the model's performance on clean data and adversarial examples. Extensive experiments demonstrate that AGAIN outperforms state-of-the-art AT methods in terms of accuracy on both clean data and adversarial examples. The method can also be easily combined with other techniques for further enhancement.