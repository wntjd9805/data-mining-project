Image segmentation involves grouping pixels into segments, either based on semantics or instances. Previous approaches have focused on these tasks separately, leading to specialized architectures. More recently, the concept of panoptic segmentation was introduced to unify semantic and instance segmentation. However, this approach still required specialized architectures and individual training for each task. In this paper, we propose OneFormer, a multi-task universal image segmentation framework that achieves high performance on all three segmentation tasks (semantic, instance, and panoptic) with a single training process on a panoptic dataset. Our approach introduces a task input token to guide the model and uses a transformer-based approach with query tokens to better capture inter-task and inter-class differences. We evaluate OneFormer on multiple benchmark datasets and show that it outperforms existing frameworks. Our contributions include demonstrating the effectiveness of OneFormer in achieving the original goal of unifying panoptic segmentation, presenting a task-conditioned joint training strategy, and establishing new state-of-the-art performance on all three segmentation tasks.