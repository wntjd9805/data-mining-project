Object localization is an essential task in computer vision that allows AI systems to understand and interact with objects in their environment. However, training models for object localization requires time-consuming and resource-intensive annotations such as object boxes, masks, and localized points. In this paper, we propose a method called Cut-and-LEaRn (CutLER) for unsupervised object detection and instance segmentation, which can be trained without any human labels. CutLER consists of three simple mechanisms: MaskCut, a method for generating initial coarse masks using self-supervised features; a loss dropping strategy for training detectors using these coarse masks; and multiple rounds of self-training to improve the quality of the masks and boxes produced by the detectors. Compared to previous methods, CutLER is data-agnostic and can be employed across various domains without requiring additional training data. We show that CutLER achieves state-of-the-art unsupervised zero-shot detection results on multiple benchmarks, outperforming prior work trained with in-domain data. Furthermore, CutLER exhibits robustness against domain shifts and can also serve as a pretrained model for supervised object detection and instance segmentation. Overall, our method offers simplicity, zero-shot detection capabilities, robustness, and the potential for improving performance on standard detection benchmarks.