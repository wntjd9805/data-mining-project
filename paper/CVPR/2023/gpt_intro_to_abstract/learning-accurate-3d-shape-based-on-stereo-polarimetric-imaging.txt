The problem of 3D shape recovery in computer vision has been extensively studied, but existing methods have limitations. Geometry-based methods have difficulty with texture-less regions and can only recover sparse point clouds, while photometric stereo methods require cumbersome calibration. Shape from polarization (SfP) offers a solution by using polarization cues of light, which can detect geometric details even on white walls and can be easily obtained with a quad-Bayer polarization camera. However, SfP methods still face challenges in terms of ambiguous polarization cues and assumptions of orthographic projection, leading to unsatisfactory accuracy. Some attempts have been made using deep learning, but they struggle with ambiguity due to monocular imaging. In this paper, we propose a method that combines stereo polarization information and deep learning to estimate both normal and disparity. Our approach integrates a convolutional neural network (CNN) with a Vision Transformer to extract features from stereo images. We address the ambiguity problem by designing a Shape Consistency-based Mask Prediction module to refine the feature map, and the orthographic projection problem by introducing a Viewing Direction-aided Positional Encoding strategy. We also establish a large real-world dataset for stereo SfP. Our approach outperforms existing methods in terms of accuracy and robustness to light variation.