This paper addresses the challenge of domain gap/discrepancy in deep learning by proposing a Clustering-based Optimal Transport (COT) algorithm for Unsupervised Domain Adaptation (UDA). Existing UDA approaches focus on global domain adaptation and ignore the fine-grained class structure information in the source and target domains. COT solves this issue by constructing a clustering-level mapping between the two domains, preserving the individual sub-domain information. The proposed COT algorithm mitigates the negative effects of class imbalance and reduces computation overhead compared to existing OT-based UDA approaches. The paper provides a theoretical analysis and experimental results to demonstrate the advantages of COT and its state-of-the-art performance on UDA benchmark datasets.