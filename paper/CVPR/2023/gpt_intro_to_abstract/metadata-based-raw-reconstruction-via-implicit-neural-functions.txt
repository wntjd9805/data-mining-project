Low-level computer vision tasks often benefit from using scene-referred RAW images, which have a linear relationship between pixel values and scene radiance and higher dynamic range compared to standard RGB images. However, RAW images take up more memory and are incompatible with most display and printing devices. Therefore, there is a need to map sRGB images back to their RAW counterparts, a process known as RAW reconstruction. Early methods focused on building models to reverse image signal processors (ISPs), but these approaches are only suitable for specific ISPs. Other methods have proposed embedding metadata into sRGB images to improve accuracy, but these approaches have limitations and fail to recover saturated regions. In this paper, we propose a two-way RAW reconstruction algorithm based on an implicit neural function (INF). We reformulate the problem as mapping the metadata coordinates to RAW values conditioned on the corresponding sRGB values. We decompose the reconstruction into two tasks and design an implicit neural network with two branches to address the challenges. Our algorithm outperforms existing methods in extensive experiments on different cameras.