In recent years, deep neural networks have achieved remarkable success in various domains, including visual understanding, natural language processing, and protein structure prediction. However, these models often suffer from over-parameterization and overfitting. To address these issues, regularization techniques such as weight decay and data augmentation are commonly used. Data augmentation, in particular, is a computationally inexpensive and effective approach to regularization. Typically, data augmentation involves applying invariant transforms to training samples, assuming that the identity of the sample remains the same after these transformations.The concept of visual invariance is supported by evidence from biological visual systems, emphasizing the robustness of human visual recognition. However, rather than achieving perfect invariance, human visual confidence decreases nonlinearly as the degree of transforms, such as occlusion, increases. This degradation in visual confidence is likely due to information loss. In this paper, we focus on understanding how human vision fails and propose a model to capture the information loss induced by transforms in learned image classifiers.Our contributions in this paper are as follows:1. We introduce Soft Augmentation, which is a generalization of data augmentation with invariant transforms. Soft Augmentation softens the learning target of transformed training samples and offers multiple softening strategies. We prescribe a robust non-linear softening formula based on empirical comparisons.2. By replacing standard crop augmentation with soft crop augmentation using a frozen softening strategy, we demonstrate that Soft Augmentation allows for more aggressive augmentation and leads to a significant boost in top-1 accuracy compared to RandAugment across various datasets.3. Additionally, Soft Augmentation improves the occlusion robustness of models, achieving a significant increase in top-1 accuracy on heavily occluded images.4. When combined with TrivialAugment, Soft Augmentation not only reduces top-1 error but also improves model calibration by reducing the expected calibration error by more than half. This outperforms ensemble methods.5. We demonstrate the generalizability of Soft Augmentation by showing its ability to enhance the performance of self-supervised models, beyond supervised image classification models.Overall, our study highlights the importance of modeling transform-induced information loss and presents Soft Augmentation as a powerful technique for improving the performance and robustness of deep learning models. Our experimental results across various datasets support the efficacy of Soft Augmentation in achieving better accuracy, occlusion robustness, and model calibration.