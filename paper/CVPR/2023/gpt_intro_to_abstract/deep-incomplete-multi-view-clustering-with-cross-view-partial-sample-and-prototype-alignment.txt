In modern society, data collected for real-world applications often comes from various domains, sensors, or feature extractors, leading to the emergence of multi-view learning. Multi-view clustering (MVC) is an important paradigm in multi-view learning that divides data by utilizing consistent and complementary information across multiple views. However, in practical applications, some views of instances may be only partially available, which can result in insufficient mining of complementary and consistent information. To address this issue, incomplete multi-view clustering algorithms (IMVC) have been proposed, but their performance heavily relies on the quality of raw features. Deep learning has shown promising results in learning high-level representations, leading researchers to explore the combination of deep neural networks and conventional IMVC methods to improve clustering performance, resulting in Deep Incomplete Multi-View Clustering (DIMVC) methods. However, most existing DIMVC methods focus on enforcing uniform representations across different views, potentially destroying the flexibility and variety of representations. The authors argue that the essence of IMVC lies in discovering structural correspondence between different views. Additionally, incomplete multi-view data can lead to biased distributions and the Prototype-Shifted Problem (PSP) where prototypes of each cluster shift and become biased. Existing contrastive-based DIMVC methods do not address these issues. To address these challenges, the authors propose a novel approach called Cross-view Partial Sample and Prototype Alignment Network (CPSPAN) for Deep Incomplete Multi-view Clustering. The proposed framework includes a cross-view instance alignment module and a prototype alignment module to establish view-to-view and prototype-to-prototype correspondences, respectively. Experimental results demonstrate the effectiveness of the proposed approach compared to conventional and deep state-of-the-art methods.