This paper introduces the concept of viewer-centered understanding in computer vision, going beyond objective image analysis to incorporate the emotional responses that an image can elicit from different viewers. The authors argue that emotions provide a fundamental link between the visual world and human experience. They propose a novel approach to affective analysis of real-world images by studying emotional responses induced by visual data in conjunction with human-provided explanations. The authors curate a large-scale dataset of explanations justifying emotions experienced at the sight of different real-world images and perform a linguistic and emotion-centric analysis of the dataset. They also develop deep neural listeners and speakers trained to comprehend or generate visually grounded explanations for emotional reactions to images. The authors explore variants of these affective neural captioning systems that allow control over the captured emotion and the level of factual visual details used in the explanation. The results show promising performance and demonstrate the potential of this research in achieving a more viewer-centered understanding of images.