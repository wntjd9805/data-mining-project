In this paper, we propose PVT-SSD, a 3D object detection method that combines the advantages of voxel and point representations while overcoming their limitations. We address the computational and memory challenges of self-attention by converting points to voxels through sparse convolutions and sampling non-empty voxels instead of points. Inside PVT-SSD, we fuse voxel and point features to preserve long-range context and accurate position information. Our method includes an input-dependent Query Initialization module, a Point-Voxel Transformer module, and a Virtual Range Image module to improve efficiency. Extensive experiments on various benchmarks demonstrate the effectiveness and efficiency of PVT-SSD.