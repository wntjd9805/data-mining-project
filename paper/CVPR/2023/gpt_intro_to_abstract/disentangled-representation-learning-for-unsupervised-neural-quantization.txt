Measuring distances among feature vectors is an essential task in various computer vision fields. Nearest neighbor search, which finds the closest data in a database from a query, is particularly challenging in high-dimensional and large-scale databases due to computation and memory requirements. Approximate Nearest Neighbor (ANN) search provides a solution by learning compact representations using Multi-Codebook Quantization (MCQ). MCQ offers an informative asymmetric distance estimator, and distances can be stored in a lookup table for efficiency. However, exhaustive search on large-scale datasets is still impractical. The Inverted File with Asymmetric Distance Computation (IVFADC) is proposed for non-exhaustive ANN search by splitting the database into smaller sets and restricting distance computations to those close to the query. Deep learning has significantly improved computer vision, and Unsupervised Neural Quantization (UNQ) introduced an encoder-decoder-based architecture for ANN search. However, UNQ's superiority is only validated for exhaustive search. In this paper, we focus on extending deep architectures for non-exhaustive search by learning a disentangled representation that combines deep quantization with the inverted index. Experimental results show that our proposed method outperforms state-of-the-art retrieval systems.