Reconstructing 3D objects from cross-sectional data is a challenging task with applications in various fields. Existing approaches often suffer from over-smoothed solutions and limited consideration of features due to simplistic regularization functions. Additionally, finding a cellular arrangement of planes is computationally intensive and impractical for large inputs. Recent mesh reconstruction methods are also not suitable for sparse and irregular data. To address these limitations, we propose a reconstruction approach called OReX based on neural networks. We leverage the inherent smoothness and self-similarities of neural networks, specifically Neural Fields, to estimate an entire shape from cross-sectional slices. Neural Fields are trained on 2D planar images and can complete the 3D scene based on multi-view renderings. We frame the reconstruction problem as a classification task and train the neural network to generate an indicator function that represents the shape's boundary. However, applying established training schemes leads to overly smoothed results and other artifacts due to spectral bias. To overcome this, we sample the data in regions with higher frequencies and encourage a low-to-high-frequency training progression. We also allow the network to iteratively refine the results, with later iterations focusing on finer, higher-frequency corrections. To address high-frequency artifacts at the shape boundary, we penalize strong spatial gradients to ensure a smoother transition between the inside and outside regions. Our method achieves state-of-the-art reconstructions for both man-made and organic shapes, as demonstrated through quantitative and qualitative experiments. It is arrangement-free, globally interpolates the data, avoids local artifacts, and handles large numbers of slices.