RGB-D registration and 3D SLAM are important tasks in computer vision that have enabled many applications in mixed reality, robotics, and content creation. Both traditional and learning-based camera pose estimation rely on establishing correspondences between points in input frames. However, correspondence estimation becomes challenging when there is little or no overlap between frames. Humans, on the other hand, can easily localize in such challenging scenarios by leveraging semantic knowledge and localizing at the object level. This paper proposes a new approach called ObjectMatch that combines canonical object correspondences with local keypoint correspondences to enhance camera pose estimation. ObjectMatch learns to semantically identify objects across frames and establish object correspondences through predicting normalized object coordinates. The paper formulates a joint camera and object pose optimization that constrains object correspondences indirectly, regardless of shared visibility. The proposed method outperforms strong baselines in both pairwise registration and registration of RGB-D frame sequences, achieving higher pose recall and reducing trajectory error in challenging scenes. The main contributions of this work are an object-centric camera pose estimator, a joint energy formulation, and improved registration performance in low-overlap and low-frame-rate scenarios.