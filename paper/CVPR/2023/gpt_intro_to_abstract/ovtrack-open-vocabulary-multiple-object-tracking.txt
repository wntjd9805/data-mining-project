This paper introduces the concept of open-vocabulary multiple object tracking (MOT), which aims to track objects beyond pre-defined categories. The traditional MOT methods are limited by the taxonomies of the benchmarks, resulting in difficulties in tracking unseen objects. To address this gap, previous works have explored open-world MOT and open-world tracking. However, these approaches face challenges related to object annotation and evaluation. To overcome these challenges, the proposed open-vocabulary MOT approach leverages vision-language models for training and testing. The paper also presents OVTrack, the first open-vocabulary multi-object tracker, which addresses the limitations of closed-set trackers. The tracker utilizes embedding head and CLIP feature distillation for improved classification and association, respectively. Additionally, a data hallucination strategy based on denoising diffusion probabilistic models (DDPMs) is proposed to address the data availability problem. The paper provides experimental results showing the effectiveness of OVTrack on the TAO benchmark, outperforming existing trackers and successfully tracking arbitrary object classes.