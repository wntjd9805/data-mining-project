Scene flow estimation is a crucial task in various computer vision applications such as 3D reconstruction, autonomous driving, and motion segmentation. Estimating scene flow from point clouds is particularly challenging due to their irregularity and sparsity. Many existing methods rely on dense ground truth scene flow annotations for model training, which is expensive and time-consuming to collect. To address this issue, weakly-supervised and self-supervised methods have been proposed, but they still rely on offline clustering algorithms with hand-crafted features to generate superpoints for scene flow estimation. However, these methods may cluster points with different flow patterns into the same superpoints, leading to false flow results. In this paper, we propose an iterative end-to-end superpoint guided scene flow estimation framework called "SPFlowNet." Our framework consists of an online superpoint generation module and a flow refinement module. It jointly optimizes flow-guided superpoint generation and superpoint-guided flow refinement to achieve more accurate flow prediction. We utilize farthest point sampling (FPS) to obtain initial superpoint centers and learn a soft point-to-superpoint association map to adaptively aggregate information for superpoint center updating. Based on the updated superpoint-wise flow values, we reconstruct the flow of each point and encode the consistency between pairwise point clouds. Finally, we refine the point-level flow using a gated recurrent unit. Experimental results on various benchmarks demonstrate that our approach outperforms state-of-the-art methods by a large margin. Our contributions include proposing a novel end-to-end self-supervised scene flow estimation framework, embedding online clustering into the model, introducing a superpoint guided flow refinement layer, and achieving state-of-the-art performance in scene flow estimation.