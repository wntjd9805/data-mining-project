In recent years, there has been significant progress in fully-supervised semantic segmentation for 3D point clouds. However, the reliance on large-scale human annotations for training deep neural networks poses a significant cost. To address this problem, some methods have started to use fewer labels or cheaper 2D image labels, but they still require manual efforts to annotate or align 3D points across images. In this paper, we propose an unsupervised approach for 3D semantic segmentation of real-world point clouds. We explore two strategies: adapting existing unsupervised 2D semantic segmentation techniques to the 3D domain, or applying self-supervised 3D pretraining techniques followed by classic clustering methods. However, existing methods fail to provide satisfactory results on 3D point clouds due to the lack of representative 3D datasets and the inability to capture categorical information. To address this, we introduce a pipeline called GrowSP that progressively grows the size of per-point neighborhoods to automatically discover per-point semantics without requiring human labels or pretrained models. Our approach consists of a per-point feature extractor, a superpoint constructor, and a semantic primitive clustering module. We demonstrate the effectiveness of our method through promising results on multiple large-scale datasets, surpassing baselines adapted from unsupervised 2D methods and self-supervised 3D pretraining methods. Our code is available at https://github.com/vLAR-group/GrowSP.