Semantic segmentation is an important computer vision task that has seen significant advancements with the emergence of deep learning. However, training segmentation models requires a large number of pixel-level annotations, which is time-consuming and laborious. To address this issue, semi-supervised learning has been introduced in semantic segmentation, aiming to design a label-efficient training scheme by leveraging additional unlabeled images. In this work, we propose a learning strategy called Density-Guided Contrastive Learning (DGCL) to mine effective supervision from the cluster structure of unlabeled data. We argue that the geometry of feature clusters can provide valuable supervision to complement label supervision. Specifically, we initialize categorical clusters based on labeled features and enrich them with confidently predicted unlabeled features. We then conduct sparsity hunting within each in-class feature cluster to locate low-density features as anchors and select features in dense regions to serve as positive keys. Through feature contrast, we aim to shrink sparse regions and enforce more compact clusters. The core of our method is feature density estimation, which is achieved by measuring the average distance between the target feature and its nearest neighbors. To improve estimation accuracy, we propose multi-scale nearest neighbor graphs that combine estimations from graphs of different sizes. We evaluate our proposed method on the PASCAL VOC 2012 and Cityscapes datasets and achieve state-of-the-art performances under various semi-supervised settings. Our contributions include the proposal of a density-guided contrastive learning strategy, a multi-scale density estimation module, and a unified learning framework that combines label-guided self-training and density-guided feature learning.