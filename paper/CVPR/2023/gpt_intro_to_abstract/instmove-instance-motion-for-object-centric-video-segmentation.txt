Segmenting and tracking object instances in videos is a crucial topic in computer vision with various applications. This paper focuses on three representative tasks: video object segmentation (VOS), video instance segmentation (VIS), and multi-object tracking and segmentation (MOTS). Despite significant progress in these tasks, state-of-the-art methods struggle with occlusion, rapid motion, and significant changes in objects, particularly in handling longer or more complex videos. One reason for this struggle is that most methods rely solely on appearance cues to localize and track objects, which makes them sensitive to intense appearance changes and struggle with multiple objects with similar appearances.In addition to appearance cues, object motion is another important piece of information provided by videos. Existing motion models fall into two categories: optical flow-based models and linear speed models. However, both approaches have limitations. Optical flow is inaccurate in scenarios with occlusion or fast motion, and linear speed models oversimplify the problem and provide limited benefits in other tasks.To address these limitations, this work proposes InstMove, a motion prediction plugin that combines the advantages of both optical flow and linear speed models. InstMove utilizes instance masks to indicate the position and shape of target objects and employs an RNN-based module with a memory network to extract motion features, store dynamic information, and predict the position and shape of the next frame based on motion cues. The proposed method improves robustness towards occlusion and fast motion while providing high-dimensional information for downstream tasks.To validate the effectiveness of InstMove, the paper integrates it into recent state-of-the-art methods in VOS, VIS, and MOTS tasks. Experimental results demonstrate that InstMove is more accurate and robust compared to optical flow methods, and its integration significantly boosts the performance of existing methods on various datasets.In summary, this paper introduces InstMove, a motion prediction plugin that combines pixel-level and instance-level dynamic information for object-centric video segmentation tasks. The proposed method improves robustness in complex scenarios and shows promising results when integrated into state-of-the-art methods.