Video action detection is a crucial problem in video understanding, with applications in various areas such as security and sports analysis. Recent advances in video representation learning, including video convolutional neural networks and video transformers, have led to significant progress in action detection. However, most current action detectors rely on the two-stage Faster R-CNN-like detection paradigm, which involves training a separate human detector and action classifier. This approach requires substantial computing resources and lacks flexibility in capturing context information. Sparse query-based object detectors have introduced a new perspective on detection tasks, and query-based sparse action detectors have been proposed. However, these methods still face challenges in feature sampling and decoding, resulting in inferior accuracy or slow convergence. To address these issues, we propose STMixer, a one-stage sparse action detector. STMixer incorporates two core designs: a query-guided adaptive feature sampling module that allows for flexible feature mining from the entire spatiotemporal domain, and a dual-branch feature mixing module to extract discriminative representations. With these designs, STMixer achieves state-of-the-art performance on three challenging action detection benchmarks (AVA, UCF101-24, and JHMDB). Our contributions include the introduction of the STMixer framework, the development of flexible feature sampling and mixing modules, and the achievement of superior performance on action detection benchmarks.