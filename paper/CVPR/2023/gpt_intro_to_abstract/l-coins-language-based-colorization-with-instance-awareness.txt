Image colorization is a widely used technique in image restoration, artistic creation, and image compression. The goal is to predict missing color information from grayscale images. Previous methods have focused on incorporating user interactions to determine a unique colorization solution. However, language descriptions have higher information density and can better represent high-level semantics. This motivates the development of language-based colorization techniques that produce visually pleasing and description-consistent results guided by user-provided captions. Cross-modality feature fusion modules have been used in previous methods, but they often fail to generate satisfactory results when there are fewer observed color-object correspondences and insufficient color descriptions. Recent approaches have shown improvements by introducing additionally annotated correspondences between object words and color words, but they still struggle with distinguishing instances corresponding to the same object words. In this paper, we propose a method called Language-based Colorization with Instance awareness (L-CoIns) that establishes correspondences between instance regions and color descriptions without using external priors. L-CoIns adopts a grouping mechanism to automatically aggregate similar image patches, enabling accurate identification of corresponding regions to be colorized and distinguishing instances corresponding to the same objects. Our model can assign colors for instances flexibly, even in cases where correspondences never occur during training. We introduce the luminance augmentation and counter-color loss to break down the statistical correlation between luminance and color words, resulting in colorization results that are more consistent with the given language description. Our contributions include the development of a grouping transformer for instance-aware language colorization without additional annotations or external priors, the introduction of luminance augmentation and counter-color loss to improve consistency with language descriptions, and the construction of a multi-instance dataset with diverse visual characteristics and detailed language descriptions. Overall, our proposed method offers a promising approach for language-based image colorization.