In recent years, transformers have gained significant attention in various domains such as natural language processing, vision, and graphs. However, their large model sizes and computational costs limit their deployment on resource-constrained devices. To address this issue, various compression and acceleration techniques have been proposed, with model pruning being a popular approach. Although there have been extensive studies on pruning convolutional neural networks (CNNs), research on pruning transformers is still in the early stage.Existing studies on pruning transformers can be categorized into criterion-based pruning, training-based pruning, and architecture-search pruning methods. However, two fundamental issues have not been fully addressed: determining the optimal layer-wise pruning ratio and measuring weight importance. For the first issue, some methods have proposed ways to determine the per-layer pruning rate, but they do not consider the inter-dependencies between weights. As for the second issue, previous methods use magnitude-based, gradient-based, or mask-based importance metrics, but these approaches have limitations in terms of stability, convergence, and suboptimality.In this paper, we propose a novel explainable structured pruning framework called X-Pruner for vision transformer models. We address the aforementioned issues by considering the explainability of the pruning criterion. Inspired by explainable AI (XAI) theories, we quantitate the importance of each weight in a class-wise manner using explainability-aware masks. These masks measure the contribution of each prunable unit to predicting every class and are fully differentiable. We use the ground-truth labels of each input to guide mask learning, ensuring that class-level information is fully utilized. We also introduce a differentiable pruning operation with a threshold regularizer, which allows thresholds to be learned through gradient-based optimization. This automatic and efficient pruning process retains discriminative units above the learned threshold.The major contributions of this paper are as follows: 1. We propose the X-Pruner framework, which is the first explainable pruning framework for vision transformers.2. We assign explainability-aware masks to prunable units, allowing their contribution to predicting each class to be quantified in an end-to-end manner.3. Based on the obtained masks, we propose a differentiable pruning operation to learn layer-wise pruning thresholds, making the pruning process explainable.4. Extensive simulations demonstrate that X-Pruner outperforms state-of-the-art approaches and provides superior explainability for the pruned model.