Quantization is a crucial step in deploying models on resource-constrained devices. It reduces model size by representing tensors with lower bit width and maintaining a dense format. Previous studies used quantization-aware training (QAT) to compress models, but this approach requires the entire training dataset and is time-consuming. Post-training quantization (PTQ) has gained attention as it can compress models within a few hours while achieving similar performance to QAT. Zero-shot quantization (ZSQ) is a research area that synthesizes data to compress models without real datasets. However, existing ZSQ methods have relied on QAT schemes, which require task-specific loss and are time-consuming. In this paper, we propose a framework called GENIE2 that combines PTQ with ZSQ. GENIE2 consists of two sub-modules: synthesizing data and quantizing models. We introduce a scheme for synthesizing datasets that combines generation and distillation approaches. We also suggest a method to replace stride-n convolution with swing convolution, allowing for the utilization of various spatial information during distillation. Additionally, we propose a new quantization scheme that jointly optimizes quantization parameters. Our contributions include the synthesis of datasets, the substitution of convolution, and the development of a new quantization scheme. GENIE2 bridges the gap between ZSQ and few-shot quantization, offering a unique state-of-the-art result in the field of quantization.