Semantic segmentation is an important vision task that allows networks to understand the world. Deep neural networks (DNNs) have shown promise in semantic segmentation, but they rely heavily on annotated datasets, which are costly and time-consuming to create. Semi-supervised learning (SSL) methods aim to address this issue by utilizing a small set of annotated data and a large set of unlabelled data. Pseudo-labelling and consistency regularization-based methods have been proposed, but they still suffer from limitations such as confirmation bias and sub-net collapse.In this paper, we propose a conflict-based cross-view consistency (CCVC) strategy for SSL in semantic segmentation. Our approach ensures that the two sub-nets in our model learn different features separately, allowing for reliable predictions from irrelevant views during co-training. We introduce a cross-view consistency (CVC) approach with a discrepancy loss to encourage the extraction of different features and prevent sub-net collapse. We also propose a conflict-based pseudo-labelling (CPL) method to enforce consistent predictions and reduce confirmation bias.Experimental results on benchmark datasets demonstrate that our CCVC method achieves state-of-the-art performance in semantic segmentation. Our approach is compatible with existing data augmentation methods and benefits from increased data diversity. The contributions of our work include the introduction of the CVC and CPL strategies, which enable reliable and consistent predictions, leading to a more stable training process.