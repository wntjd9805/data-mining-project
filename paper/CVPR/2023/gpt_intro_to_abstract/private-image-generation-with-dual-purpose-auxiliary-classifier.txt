Generative Adversarial Networks (GANs) have been successful in learning data distribution and generating high-fidelity synthetic data. They are particularly useful in domains where real data is scarce or sensitive, such as the medical domain. However, recent research has shown that GANs are vulnerable to privacy attacks. To address this, Differential Privacy (DP) has been incorporated into GAN training. Despite progress in privacy preservation, there are still gaps in the current literature. Firstly, the utility of generated data has mainly focused on transferability from fake to real data, neglecting the reverse direction. Secondly, privacy constraints have led to a trade-off between privacy and the quality/utility of generated outputs. This paper aims to bridge these gaps by proposing a method that considers both transferability directions and improves the convergence of the generator. The method incorporates a dual-purpose auxiliary classifier and adopts a sequential training procedure. Experiments on standard datasets demonstrate the effectiveness of the proposed method in terms of quality and utility. The contributions of this paper include the identification of "reversed utility" as an important aspect of private GAN design, the development of a dual-purpose auxiliary classifier, and the use of sequentialisation to accelerate generator convergence.