The goal of this paper is to address the fragmentation in video target segmentation tasks by proposing TarViS, a unified architecture that can perform multiple video segmentation tasks. The core idea is to use Transformer-based models to segment arbitrary targets in videos by encoding them as queries. This allows for the same model to be used across different tasks by specifying the segmentation target. The authors demonstrate the generalization capability of TarViS by tackling four different tasks: Video Instance Segmentation, Video Panoptic Segmentation, Video Object Segmentation, and Point Exemplar-guided Tracking. Existing methods lack generalization capability as they are built on task-specific assumptions, while TarViS decouples the network architecture from the task definition. Experimental results show that TarViS performs competitively and achieves state-of-the-art results for the mentioned tasks.