Latency is a crucial consideration in system design for various applications, including hardware design, network engineering, and satellite communications. However, it has not been given much attention in modern computer vision systems. Most vision system designs prioritize correctness over latency, and their evaluation is often done in an offline setting that neglects inference latency. This is problematic for real-time deployment scenarios where latency plays a significant role. In this paper, we propose a real-time evaluation setting that closely mimics real-world deployment for forecasting systems. We introduce RAFTformer, a real-time action forecasting transformer that outperforms prior works in both offline and real-time settings, with a forecasting speed of at least 25 frames per second. We also present a latency-aware evaluation setting that considers the trade-off between inference latency and forecasting performance. Through extensive experiments, we demonstrate that RAFTformer achieves significantly higher accuracy on various datasets compared to existing methods. Our work highlights the importance of considering latency in the design and evaluation of computer vision systems for real-time applications.