In recent years, the computer vision community has made significant advancements in 3D human pose and shape estimation. However, current methods lack robustness in out-of-distribution situations, such as occlusions or unusual poses. The main challenge in testing the robustness of these methods is the limited availability of test data. Synthetic datasets have been used to address this issue, but they only measure average performance and lack diversity. Inspired by adversarial machine learning, this paper introduces PoseExaminer, a learning-based algorithm that systematically explores the parameter space to diagnose the robustness of HPS methods. PoseExaminer utilizes a multi-agent reinforcement learning approach to efficiently search the high-dimensional continuous space of a simulator and identify failure modes. Experimental results on state-of-the-art HPS models demonstrate that PoseExaminer successfully discovers a variety of failure modes, provides insights into real-world performance, and improves the robustness of current methods. This work introduces new metrics for quantifying the robustness of HPS methods and highlights the potential of automated testing approaches in computer graphics rendering pipelines.