Semantic segmentation is a task in computer vision that assigns semantic class labels to each pixel in an image. Recent advancements in object detection, particularly the end-to-end De-tection Transfomer (DETR), have led to the adoption of DETR-like frameworks in semantic segmentation. These frameworks utilize queries to represent class prototypes or target segments, resulting in state-of-the-art performance.However, the accuracy of the positional priors in masked attention, a technique used in DETR-like frameworks, may be compromised due to two reasons. First, the positional queries, which provide information about the likely locations of target segments, are randomly initialized and tend to encode average statistics across the dataset. This limits their ability to capture segments with large location variances. Second, since each query only attends to foreground regions predicted by previous decoder blocks, inaccurate predictions can lead to error accumulation during early training stages.To address these issues, recent detectors have proposed encoding anchor points into positional queries to guide queries around anchor positions. While effective, this approach fails to capture fine-grained positional priors necessary for semantic segmentation, such as details, edges, and boundaries.In this paper, we introduce a novel query design called Dynamic Focus-aware Positional Queries (DFPQ) for semantic segmentation. DFPQ dynamically generates positional queries conditioned on cross-attention scores from preceding decoder blocks and positional encodings of image features. This enables accurate and fine-grained positional priors, facilitating the progressive localization and refinement of target segments. Additionally, we propose a method called High-Resolution Cross-Attention (HRCA) to mine details for segmenting small regions from high-resolution feature maps efficiently.Our main contributions include:1. The introduction of DFPQ, a simple yet effective query formulation that provides accurate and fine-grained positional priors for target segment localization.2. The proposal of HRCA, an efficient high-resolution cross-attention layer that enhances segmentation details while minimizing memory and computational requirements.3. Extensive experiments on ADE20K and Cityscapes datasets demonstrating the superior performance of our approach compared to state-of-the-art methods. For example, our FASeg outperforms SOTA methods by up to 1.3% single-scale mIoU on the ADE20K validation set with different backbone architectures.Overall, our approach improves the accuracy and efficiency of semantic segmentation, paving the way for further advancements in this field.