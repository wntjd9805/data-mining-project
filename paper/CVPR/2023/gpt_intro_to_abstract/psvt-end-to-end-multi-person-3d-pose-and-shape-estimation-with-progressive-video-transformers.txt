Multi-person 3D human pose and shape estimation from monocular video is a challenging task in computer vision with various applications. Existing methods use detection-based strategies or post-processing modules, but they have limitations in capturing spatio-temporal relations and global context. To address these challenges, we propose an end-to-end multi-person 3D pose and shape estimation framework called PSVT, which utilizes a video Transformer model. PSVT formulates the problem as a set prediction task and employs a spatio-temporal encoder and decoders to learn relations among feature tokens, human joints, and human meshes. We introduce a progressive decoding mechanism and a pose-guided attention mechanism to improve sequence decoding and shape estimation. Experimental results demonstrate that PSVT achieves state-of-the-art performance on four benchmarks.