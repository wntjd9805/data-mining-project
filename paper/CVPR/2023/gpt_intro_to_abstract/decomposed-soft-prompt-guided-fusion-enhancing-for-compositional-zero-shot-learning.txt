This paper introduces the concept of Compositional Zero-Shot Learning (CZSL) in the field of computer science. CZSL aims to equip models with the ability to recognize novel concepts that have not been seen during training. Previous algorithms have focused on identifying state and object separately, but they overlook the intrinsic relation between them. This paper proposes a novel approach based on vision-language models (VLMs) to address CZSL challenges. By decomposing state and object in language features and establishing the joint representation of them with images, the proposed method, Decomposed Fusion with Soft Prompt (DFSP), aims to learn the joint representation of primitive concepts and narrow the domain gap between seen and unseen compositions. Extensive experiments show that DFSP outperforms state-of-the-art CZSL approaches on both closed-world and open-world scenarios.