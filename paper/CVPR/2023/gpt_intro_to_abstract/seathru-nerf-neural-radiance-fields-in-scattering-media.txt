Neural Radiance Fields (NeRFs) have significantly advanced the field of Neural Rendering, but they assume that images are acquired in clear air without scattering or absorption of light. This paper introduces SeaThru-NeRF, a framework that incorporates a rendering model to account for scattering media. By assigning separate color and density parameters to the object and the medium within the NeRF framework, SeaThru-NeRF learns the correct representation of the entire 3D volume. Experimental results demonstrate that SeaThru-NeRF produces photorealistic novel view synthesis on scenes with scattering media, allowing color restoration, estimation of 3D scene structure, and estimation of wideband medium parameters.