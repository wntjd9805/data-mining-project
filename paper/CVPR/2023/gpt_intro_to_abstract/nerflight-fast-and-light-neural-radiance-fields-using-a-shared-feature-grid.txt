The paper introduces NeRFLight, a new approach for reducing the size of grid-based NeRF models while maintaining real-time view synthesis and rendering quality. The use of 3D objects reconstructed from real images is becoming popular in applications like virtual reality and online video games. Image-based reconstruction is a suitable alternative to manually designing these objects. Neural rendering methods, particularly NeRF, have shown great potential in modeling the plenoptic function using multi-layer perceptrons (MLPs). However, one major limitation of NeRF-based methods is their low rendering speed, which hinders their real-time application. Previous works have attempted to overcome this limitation but sacrifice the compactness of the representation. In this work, NeRFLight is introduced, which splits the density field volume into eight regions, each with a different decoder but sharing a common feature grid. This reduces the number of total features and increases rendering quality and model compactness. The proposed architecture achieves high rendering speeds and a large FPS/MB ratio compared to existing methods, while maintaining rendering quality. The main contributions of this work are: 1) the introduction of a NeRF architecture with multiple density fields and a shared feature grid for a light and fast representation, 2) an approach that enforces symmetry of neighboring voxels for seamless reconstruction, increased model accuracy, and reduced size, and 3) the highest frame rate vs. storage cost ratio compared to the current state of the art.