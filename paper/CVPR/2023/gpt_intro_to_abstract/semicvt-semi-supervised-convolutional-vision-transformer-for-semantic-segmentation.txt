Semantic segmentation is a fundamental problem in computer vision, but collecting pixel-level annotations is expensive and time-consuming. Semi-supervised learning provides an alternative by inferring labels from a small number of annotated images. Most semi-supervised learning methods rely on consistency regularization, pseudo labeling, entropy minimization, or bootstrapping. For semantic segmentation, Mean-Teacher models are commonly used, but they have limitations in capturing global representations and enforcing consistency regularization. In this paper, we propose a novel approach called SemiCVT that combines CNN and Transformer architectures to address these limitations. SemiCVT achieves better compactness, accurate localization, and improved segmentation performance compared to existing methods. The contributions of this work include the analysis of problems faced by existing Mean-Teacher methods, the introduction of an intra-model local-global interaction strategy, the proposal of an inter-model class-wise consistency, and the achievement of state-of-the-art performances on public datasets.