Generative Adversarial Networks (GANs) have been successful in generating high-quality images and modeling complex data distributions. In traditional class-conditional GANs, object categories are represented by discrete labels, but collecting sufficient labeled training data can be challenging. To address this limitation, semi-supervised generative learning methods have been developed, utilizing both labeled and unlabeled training samples. This paper introduces a novel approach called Learnable Cluster Prompt-based GAN (LCP-GAN) that focuses on semi-supervised class-conditional image generation. LCP-GAN learns intra-class cluster-specific prompts to guide the generation process and capture underlying variation factors. By incorporating an additional discriminator, LCP-GAN effectively captures the cluster label embeddings, enhancing the model's understanding of visual concepts. The proposed approach surpasses state-of-the-art GAN architectures, demonstrating the benefits of modeling intra-class variation with language-vision pre-training. The key contributions of this work include the association of intra-class cluster label embeddings with cluster semantics, the use of learnable prompts to represent clusters, and the integration of cluster prompts in the adversarial training process to guide the generator in capturing intra-class variation factors.