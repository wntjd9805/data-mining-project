Open-vocabulary object detection (OVD) is a task that aims to detect objects that were not present in the training phase of a traditional object detector. This limitation restricts the application of object detection in real-world scenarios with a wide range of potential object categories. In recent years, there has been a growing interest in OVD, and one common solution is the distillation-based approach, which involves distilling knowledge from pre-trained vision-language models (VLMs) that have learned aligned image and text representations on large-scale image-text pairs. However, existing approaches only align individual region embeddings with features extracted from the frozen VLMs. In this paper, we propose a new approach called BARON (BAg of RegiONs) to align the embedding of a bag of regions, thereby explicitly learning the compositional structure and co-existence of visual concepts in the scene. BARON is easy to implement and involves sampling contextually interrelated regions to form a bag, projecting regional features into the word embedding space, and encoding them using the text encoder of the frozen VLM. The spatial information of region boxes is retained by projecting the box shape and center position into embeddings before feeding them to the text encoder. We train BARON using a contrastive learning approach and evaluate its performance on two challenging benchmarks, OV-COCO and OV-LVIS. Our experiments show that BARON consistently outperforms existing state-of-the-art methods in various settings, achieving significant improvements in box AP50 and mask mAP of novel categories. Additionally, BARON can also distill knowledge from caption supervision, further enhancing its performance in identifying novel object categories.