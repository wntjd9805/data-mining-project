This paper introduces a novel Harmonious Feature Learning Network (HFL-Net) for joint hand-object pose estimation from single monocular RGB images. The main challenge in this task is occlusion, which leads to information loss and makes accurate estimation difficult. Previous solutions have used context to improve estimation by treating the hand and object as correlated entities. However, using a single backbone for feature extraction can result in competition between the hand and object pose estimation tasks. To overcome this, HFL-Net combines the advantages of single- and double-stream backbones. The low- and high-level convolutional layers of a common ResNet-50 model are shared, while the middle-level layers are unshared, allowing separate feature learning for the hand and object. This eliminates competition and enforces similar feature spaces. Efficient attention models are also employed to enhance the representation power of the hand and object features. Experiments on two benchmarks demonstrate that HFL-Net outperforms state-of-the-art methods in joint hand-object pose estimation and achieves superior performance in hand pose estimation alone. The mutual benefit between the hand and object pose estimation tasks in HFL-Net is highlighted.