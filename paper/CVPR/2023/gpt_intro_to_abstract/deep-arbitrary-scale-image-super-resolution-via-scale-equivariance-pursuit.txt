Arbitrary-scale image super-resolution (ASISR) has gained significant attention in low-level computer vision research due to its flexibility and practicality. However, existing ASISR methods often have lower super-resolution performance compared to fixed-scale models, limiting their practical applications. One major limitation is the lack of scale-equivariance in dealing with scale-varying image features. To address this, we propose two novel scale-equivariant modules within a transformer-style framework. The Adaptive Feature Extractor (AFE) module incorporates scale information to modulate the weights of subsequent convolutions, allowing for scale-adaptive representation learning. The Neural Kriging upsampler, on the other hand, encodes geometric information and feature similarity to achieve scale-encoded spatial feature fusion during the upsampling stage. We combine these modules to create EQSR, a model capable of handling different sampling rates. Experimental results on ASISR benchmarks demonstrate the superiority of our method, outperforming state-of-the-art methods in both in-distribution and out-of-distribution cases. Our model achieves significant improvements in average peak signal-to-noise ratios (PSNRs) and validates the effectiveness of our scale-equivariant operator.