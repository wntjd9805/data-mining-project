Semantic segmentation is crucial for environment perception in automated driving, enabling the recognition and understanding of images at the pixel level. However, traditional deep learning-based models for semantic segmentation are primarily trained and evaluated on data collected in clear weather conditions, assuming that the training domain matches the operational domain. This assumption is not valid in real-world autonomous driving systems that encounter constantly changing driving environments and variable input data distributions, including adverse weather conditions that can negatively impact segmentation model performance.To address this challenge, one potential solution is to incrementally fine-tune the model to new domains with labeled data. However, this approach often leads to catastrophic forgetting, where the model's performance on previously observed domains drops significantly. Existing methods mitigate this issue by replaying data from previous domains, re-estimating statistics, or transferring training images in the style of the novel domain. In our work, we focus on studying the effects of domain-incremental learning on the internal representations of semantic segmentation models and propose a method to mitigate forgetting without explicit replay of previous domains.Our main contributions include:1. We analyze the activation drift in a model's layers when adapting from good to adverse weather conditions by stitching them with the previous task's network. We identify that the main cause of forgetting is a shift in low-level representations in the first convolution layer, negatively affecting the population statistics of the subsequent BatchNorm Layer.2. By employing different augmentation strategies to match the target domains in color statistics or frequency domain, we demonstrate that learning color-invariant features stabilizes the representations in early layers, as they remain unchanged when the model is adapted to a new domain.3. Through a combination of pre-training, augmentations, and exchanged normalization layers, we achieve a significant reduction of forgetting, approximately 20% in terms of mean intersection over union (mIoU), compared to fine-tuning without any form of replay. Our findings highlight the effectiveness of pre-training and augmentations, which are often overlooked in continual learning.Overall, our work sheds light on the impact of domain-incremental learning on semantic segmentation models and provides insights into efficient feature reuse to mitigate catastrophic forgetting.