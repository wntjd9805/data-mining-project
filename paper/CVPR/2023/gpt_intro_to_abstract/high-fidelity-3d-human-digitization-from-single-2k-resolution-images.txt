Reconstructing photo-realistic 3D human models is a topic of interest in computer vision and graphics. Previous approaches have utilized multiple camera systems, but these are expensive and impractical for normal users. Recent advancements in deep learning have shown the potential to reconstruct 3D human models from a single image. However, current methods still have room for improvement in terms of model quality. Existing approaches fall into two categories: predicting a deep implicit volume or inferring multiple depth maps. These approaches either require significant memory or time. Previous work has focused on recovering geometric details and various postures. There is a need for suitable deep neural networks and high-quality training datasets to enhance the prediction quality of 3D human models. Existing approaches struggle to handle high-resolution images and lack large-scale datasets for 3D human digitization. This paper presents a practical approach to reconstruct high-quality human models from high-resolution images and a large-scale human scan dataset. The proposed framework is the first to predict high-resolution depth maps for 3D human reconstruction. The framework splits the human body into multiple parts and uses a 2D pose human detector for alignment. Surface normals are accurately predicted, even with pose variations. Predicted normal maps are merged into a single normal map and used for normal-to-depth prediction. Coarse depth maps are also incorporated for consistency across body parts. High-fidelity human meshes are generated using Marching cubes algorithm. The contributions of this paper include accuracy, efficiency, and the release of a large-scale 3D human dataset.