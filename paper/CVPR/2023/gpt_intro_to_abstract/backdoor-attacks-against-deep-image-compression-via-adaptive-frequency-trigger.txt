Image compression is a widely used technique in signal processing to efficiently store image data while maintaining quality. Traditional methods rely on hand-crafted modules for coding efficiency, but recent advances in deep learning have enabled the development of end-to-end trainable models. However, the use of deep neural networks in image compression raises concerns about AI security, particularly with regards to backdoor attacks. These attacks involve injecting a trigger into a model that can activate malicious behavior, compromising the system's reliability. In this paper, we investigate backdoor attacks in image compression models and propose a frequency-based trigger injection method in the discrete cosine transform domain. We comprehensively analyze the impact of attacks on compression quality and task-driven measures, and demonstrate the effectiveness of our approach in activating backdoors with multiple triggers. Our work contributes to the understanding of backdoor attacks in low-level computer vision research and provides insights into the security of learned image compression models.