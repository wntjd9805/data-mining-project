3D perception plays a critical role in autonomous driving systems, specifically in the detection and categorization of 3D objects. Recent advancements in 3D object detection have utilized sparse convolutional networks (Sparse CNNs) for efficient feature extraction. However, the traditional approach of using anchors or centers as intermediate representations for 3D objects is not well-suited for the sparsity and irregularity of 3D data. This approach leads to inefficient computations and complex detection pipelines, requiring post-processing steps like non-maximum suppression.In this paper, we propose VoxelNeXt, a simple and efficient 3D object detector that eliminates the need for anchor proxies, sparse-to-dense conversion, region proposal networks, and other complicated components. Our approach utilizes a voxel-to-object scheme and a fully sparse convolutional network to directly predict 3D objects from voxel features. This design not only improves inference efficiency but also allows for easy extension to 3D tracking.We compare VoxelNeXt to existing 3D object detectors, such as CenterPoint and FSD, and demonstrate its superior performance and efficiency on large-scale benchmark datasets like nuScenes, Waymo, and Argoverse2. Our approach achieves state-of-the-art results in both 3D object detection and tracking tasks without using additional techniques or modifications. By leveraging the sparsity of 3D data and eliminating unnecessary computations, VoxelNeXt offers a promising solution for efficient and accurate 3D perception in autonomous driving systems.