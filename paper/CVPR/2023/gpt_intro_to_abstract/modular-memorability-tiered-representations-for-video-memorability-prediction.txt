This paper introduces a new modular framework for predicting the memorability of visual content. The framework consists of four modules that extract low-level, mid-level, high-level, and contextual representations of the content. The authors argue that current deep neural network approaches do not leverage the underlying structure governing memorability and propose a tiered approach to capture different properties that influence memorability. The authors also perform an analysis of factors that influence memorability and show that their proposed framework produces competitive results on two benchmark datasets. The key contributions of this paper are the comprehensive analysis of factors influencing memorability, the proposed modular framework, and the insights gained from an in-depth ablation study of the model.