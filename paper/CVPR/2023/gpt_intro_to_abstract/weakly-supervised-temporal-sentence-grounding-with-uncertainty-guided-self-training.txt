In this paper, we address the task of temporally localizing the start and end times of a given sentence description, also known as temporal sentence grounding. This task has various applications in video understanding, such as video summarization, video action segmentation, and Human-computer interaction systems. While most existing works address this task in a supervised manner, annotating temporal labels for each sentence is laborious and hinders scalability. Therefore, recent research has focused on weakly supervised temporal sentence grounding, where video-language correspondence is provided only at the video-level.Previous weakly supervised methods adopt the multiple instance learning (MIL) approach, generating negative samples that describe other videos. However, these negative samples are often easy to distinguish and do not provide strong supervision signals. To overcome this limitation, recent works sample negative video segments within the same video, making it more challenging for the model to distinguish them. However, these methods rely heavily on negative samples and may not always generate high-quality positive proposals.To address this limitation, we propose a self-training technique for weakly supervised temporal sentence grounding. We leverage self-training to provide additional supervision signals to guide the grounding process. However, directly applying existing semi-supervised techniques leads to noisy teacher supervision signals and degraded performance. Therefore, we design a Bayesian teacher network and use weak-strong augmentation and cyclic mutual learning to update both the teacher and student networks efficiently.Our self-training technique can be applied to existing methods, and experiments on two standard datasets demonstrate its effectiveness in improving the performance of weakly supervised temporal sentence grounding. Our contributions include proposing a novel self-training method for this task, designing a Bayesian teacher network to address the issue of low-quality teacher supervision, and using mutual-learning based on data augmentation consistency to update the teacher and student networks.