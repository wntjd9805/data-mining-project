Surface normal estimation on point clouds is essential for various applications in computer science, including denoising, segmentation, registration, and surface reconstruction. However, raw-scanned point clouds are often incomplete, noisy, and non-uniform, making it challenging to accurately estimate surface normals amidst noise, density variations, and missing structures. Traditional methods aim to fit local geometrical surfaces around specific points to infer the normals, but they require careful parameter tuning and have limited generalization capabilities. Learning-based approaches have shown promising results, but they also struggle with real-world point clouds. Recent approaches have introduced the truncated Taylor expansion surface model to address these limitations, but they do not analyze the approximation error in surface fitting, leading to suboptimal results. In this paper, we propose two design principles to reduce the approximation error and improve the accuracy of surface fitting for normal estimation. We implement these principles using deep neural networks and present two methods: z-direction transformation and normal error estimation. Through comprehensive experiments, we demonstrate the effectiveness of our methods in improving surface normal estimation accuracy, pushing the boundaries of state-of-the-art performance.