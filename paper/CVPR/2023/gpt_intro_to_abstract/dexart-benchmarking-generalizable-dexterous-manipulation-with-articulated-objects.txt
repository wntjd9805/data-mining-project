This paper introduces a new benchmark called DexArt for dexterous manipulation with diverse articulated objects. The goal of this benchmark is to enable robots to manipulate various articulated objects using multi-finger hands. While previous research has made progress in using reinforcement learning for dexterous manipulation, most studies focus on manipulating a single rigid object. Manipulating diverse articulated objects poses additional challenges due to the increased degrees of freedom and the need for generalization to unseen objects. To address this, the DexArt benchmark incorporates 3D visual understanding and robot learning. The paper presents multiple tasks in which a dexterous hand manipulates articulated objects in a simulation and trains policies using a training set of diverse objects. The authors experiment with different methods and settings and provide key observations on the importance of training with more objects, the capacity of the encoder, the role of object parts reasoning, and the effectiveness of geometric representation learning. The paper concludes by highlighting the potential research opportunities that DexArt can provide in studying generalizable dexterous manipulation skills and improving visual perception for better decision-making.