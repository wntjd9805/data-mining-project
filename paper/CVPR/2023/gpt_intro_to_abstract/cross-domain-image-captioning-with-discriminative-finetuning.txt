In recent years, there has been significant progress in the field of automatically generating image descriptions using deep neural networks. Many existing methods aim to optimize the similarity between system-produced captions and human references through various cost functions or reward-based objectives. However, these approaches often neglect the purpose of image descriptions in concrete applications. One fundamental purpose is to accurately characterize an object in order to differentiate it from other contextual elements. This ability to discriminate between referents is crucial for effective communication and has played a key role in its evolution and acquisition.In this paper, we investigate the effects of fine-tuning the language components of an out-of-the-box image captioner with a discriminative objective using reinforcement learning. We propose a discrimination game where the captioner generates a caption for a target image, and an image retriever, whose weights are not updated, uses the caption to select the target from a set of candidates. This fine-tuning technique does not require annotated data and is agnostic to the underlying captioner and retriever components.We present two significant findings. Firstly, we demonstrate that captions that are fine-tuned in this manner lead to improved zero-shot cross-domain caption generation. Secondly, these fine-tuned captions are not only effective for neural text-based image retrieval, but they also outperform human-generated ground-truth captions in helping human annotators discriminate the target from distractors. We conclude the paper with an analysis of the fine-tuned captions, comparing them to human-generated and non-fine-tuned ones from the Conceptual Captions dataset. We find that discriminative fine-tuning results in a more practical and descriptive style, undoing the abstract language learned from ground-truth captions. Overall, our results indicate the potential of discriminative fine-tuning for improving the usefulness of image captions in practical applications.