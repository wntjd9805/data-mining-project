Federated learning is a machine learning technique that addresses data privacy protection and data security. In personalized federated learning, the challenge lies in designing a reliable and interpretable framework. Existing approaches have focused on using the global model for constraints on client's training processes or incorporating techniques such as clustering and knowledge distillation. However, these approaches often result in unreliable and uninterpretable client selection and training, leading to underutilization of collective intelligence. In this paper, we propose a reliable and interpretable federated learning framework, called RIPFL. We introduce the Dempster-Shafer evidence theory to quantify the uncertainty and performance of each client, enabling reliable client selection strategies. RIPFL ensures that all smart clients participate in the aggregation process while a small number of nonsmart individuals also participate, facilitating knowledge transfer from smart to nonsmart clients. Additionally, we propose a method to integrate social and personal information reliably. The framework is applicable to scenarios with a large number of clients and complex tasks. The contributions of this paper include proposing an interpretable personalized federated learning architecture, introducing evidence theory for reliable client selection and training, and introducing a Bayesian-rule-based evidence fusion method to retain the global model's knowledge in local training.