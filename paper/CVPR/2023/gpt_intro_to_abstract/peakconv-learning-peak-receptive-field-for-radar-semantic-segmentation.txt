The introduction of this computer science paper discusses the use of radar as a remote sensor for detecting objects of interest. Radar has several advantages over other active detection devices, such as LiDAR, as it is more robust in extreme weather conditions and not affected by dim light or sun glare. Radar sensors have been widely used in automotive security and defense applications.Conventional radar detection methods rely on peak detection algorithms following constant false alarm rate (CFAR) principles. These methods involve converting raw radar echoes into multi-domain frequency representations and applying a CFAR detector to determine the presence of moving objects. However, these methods require manual tuning of parameters and do not provide category information about the detected objects.Inspired by the success of deep learning techniques in computer vision, efforts have been made to improve automatic radar scene interpretation using machine learning methods. These methods utilize convolutional neural networks (CNNs) to make predictions on radar frequency representations and perform object detection and semantic segmentation tasks.In this paper, the authors propose a novel convolution computing paradigm for radar data processing. They redefine the receptive field of the convolution operator as a peak receptive field (PRF) that follows the guard-reference style used in conventional radar detection methods. They introduce two new convolution operations, called PeakConvs, that explicitly learn the peak response from the PRF. These operations maintain the computational compatibility of regular convolutions while also allowing for adaptive peak response with learnable weights and high-level semantic representation.The authors also present well-performed multi-view radar semantic segmentation frameworks based on PeakConvs. These frameworks leverage the advantages of radar localization and make predictions on both range-Doppler and range-angle frequency domains. Large-scale radar datasets were collected and created to support the training of these deep models.The introduction highlights the difference between radar and optical data processing, where convolution operations are more efficient in capturing semantic information from optical data due to the rich texture and color information. The authors propose that the selection of the receptive field sampling/selection manner plays a crucial role in convolution and suggest rethinking the internal relation between convolution and the conventional radar detection mechanism to improve radar scene understanding.In summary, this paper presents a novel convolution computing paradigm for radar data processing, introduces two new convolution operations (PeakConvs), and demonstrates the effectiveness of these operations in multi-view radar semantic segmentation frameworks. The proposed methods and frameworks leverage the advantages of radar sensors and deep learning techniques to improve automatic radar scene interpretation.