Object detection is a crucial technique in computer vision, particularly in applications such as self-driving and public safety. While deep neural networks have improved detection performance, the problem of domain shift significantly degrades the performance of detectors when deployed in new domains. To address this problem, researchers have proposed unsupervised domain adaptive object detection (UDA-OD) methods. Self-training based methods have shown promising results, but they are computationally expensive. Feature alignment-based methods, on the other hand, have been extensively studied and categorized into global-level, instance-level, and category-level alignment methods. Graph-based approaches have also been used to achieve feature alignment, but have limitations in terms of constructing the graph with the proper node set and exploring only the visual knowledge. This paper proposes the Cross-modality Graph Reasoning Adaptation (CIGAR) framework for category-level alignment via graph-based learning. The framework includes a Discriminative Feature Selector (DFS) for constructing the visual graph using only discriminative features, improving efficiency and robustness against noise. CIGAR also explores the linguistic modality and performs cross-modality graph reasoning between the linguistic and visual modalities. The proposed method achieves state-of-the-art performance in UDA-OD tasks, outperforming existing works.