Motion interpolation in character animation is often achieved through keyframes connected by interpolation algorithms. However, representing complex human motion solely using sparse keyframes is challenging. Learning-based motion interpolation methods have been proposed to automate this process, deriving details within keyframe transitions. While transformer-based approaches have shown promise, they are hindered by the use of conventional masked tokens that limit continuous attribute representation. This paper presents a novel transformer-based framework that models keyframe sequences into latent motion manifold representations for intermediate tokens, enabling smooth and continuous motion interpolation. The framework consists of three stages: keyframe encoding, intermediate token generation, and motion synthesis. This approach has the advantage of establishing temporal continuity in the latent representation space and aligning known and unknown tokens adaptively. Additionally, the paper introduces a sequence-level re-centering technique to effectively operate with real scalar attributes. Experimental results demonstrate the superiority of the proposed method over existing approaches.