Text recognition is a key research area in computer vision with numerous applications. Existing recognition methods for scene and handwritten text have improved accuracy but are limited by the availability of diverse and labeled data. Data synthesis and augmentation methods have been proposed to address this issue. In this paper, we propose a text image generation model inspired by the progress of diffusion models. Our model, called CTIG-DM, generates text images to enhance existing text recognizers. We introduce three conditions and four image generation modes to ensure validity, fidelity, and diversity of the generated images. CTIG-DM demonstrates high-quality image generation and improves the accuracy of previous text recognizers in experiments on scene and handwritten text. It also shows potential in OOV image generation and domain adaptation.