This paper addresses the problem of segmenting and tracking objects in videos through complex transformations, where appearance is no longer a reliable cue. Existing computer vision models for video object segmentation operate in an appearance-first paradigm, relying heavily on static appearance cues. However, object transformations, such as peeling a banana or cutting paper, can dramatically change the color, texture, and shape of an object, making appearance an unreliable cue. To study this problem, the authors collect a dataset called VOST (Video Object Segmentation under Transformations) that focuses on major object transformations. The dataset contains 713 clips covering 51 transformations over 155 object categories. The authors then analyze state-of-the-art VOS algorithms and observe that existing methods are ill-equipped to handle object transformations, with a large performance gap compared to traditional datasets. They conclude by highlighting the challenges of modeling object transformations and hope that this work will inspire further research in more robust video object representations. The dataset, source code, and models are made available for further exploration.