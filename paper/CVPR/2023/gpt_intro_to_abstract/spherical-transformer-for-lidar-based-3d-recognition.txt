LiDAR point clouds collected by LiDAR sensors are widely used in various industrial applications, but their varying-sparsity point distribution poses challenges for existing methods. Most existing work does not consider the sparsity of outdoor LiDAR point clouds, causing inferior results for sparse distant points. This is due to the limited receptive field, resulting in inconclusive features and information disconnection. While previous methods have proposed solutions to enlarge the receptive field, they do not address the specific LiDAR point distribution. In this paper, we propose the SphereFormer module to aggregate long-range information directly in a single operator, tailored to the varying-sparsity point distribution. We represent the 3D space using spherical coordinates and design radial windows to partition the scene. The SphereFormer module avoids the information disconnection issue and improves performance for distant points. Additionally, we propose exponential splitting for fine-grained position encoding and dynamic feature selection to further improve performance. Experimental results show that our method achieves state-of-the-art results in semantic segmentation and object detection tasks.