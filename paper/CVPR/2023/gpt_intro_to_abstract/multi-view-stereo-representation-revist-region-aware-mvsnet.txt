Multi-view stereo (MVS) is a method used to recover the geometry of an object or scene by using multiple images and their corresponding stereo correspondences. Conventional patch-based and PatchMatch-based methods require rich textures and restricted lighting conditions to achieve good reconstruction results. On the other hand, deep learning-based approaches use global scene semantic information to handle complex lighting conditions, but suffer from low estimation confidence in textureless areas and outliers near object boundaries. This is because these methods treat the surface as a set of uncorrelated sample points, limiting their ability to use surrounding surface information for inference. To address this, we propose a novel RA-MVSNet framework that expands the perception range by associating each hypothetical plane with a wider surface area through point-to-surface distance. This allows us to infer the surrounding surface information in textureless areas and object boundaries. Our network estimates both the probability and distance volumes using a cost volume, which are then combined to estimate the final depth map. The introduction of point-to-surface distance supervision improves performance in textureless and boundary areas, and allows us to predict a SDF-based implicit representation with correct topology and fine details. Our contribution includes introducing point-to-surface distance supervision, addressing the challenge of lacking ground-truth meshes, and achieving superior performance on challenging MVS datasets. Experimental results on indoor and outdoor datasets demonstrate the effectiveness of our proposed approach.