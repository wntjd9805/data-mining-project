Visual tracking is a fundamental problem in computer vision that has seen significant progress in recent years. However, challenges such as occlusion and extreme illumination still remain. The emergence of RGB-D sensors has led to the development of RGB-D tracking, as depth can provide additional 3D geometry cues. While existing RGB-D tracking datasets have benefitted the development of RGB-D trackers, they have limitations in terms of portability and lack of pixel-level mask labels. With the increasing availability of built-in depth sensors in mobile phones, it has become easier to capture depth data under diverse scenes. In this paper, we present ARKit-Track, a new RGB-D tracking dataset captured using iPhone's built-in LiDAR with the ARKit framework. This dataset overcomes the limitations of existing datasets by covering more diverse scenes and providing both box-level and pixel-level annotations. We also propose a baseline RGB-D tracker that integrates RGB features with bird's-eye-view representations to capture both appearance and 3D geometry information. Our contributions include the ARKit-Track dataset, a unified baseline method for RGB-D tracking, and in-depth evaluation and analysis of the dataset and the baseline method.