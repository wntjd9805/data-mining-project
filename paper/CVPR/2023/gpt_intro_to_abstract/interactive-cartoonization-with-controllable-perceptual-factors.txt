Cartoon creation has become increasingly popular, resulting in a higher number of cartoon creators. The typical process involves character drawing and composing them into a background scene, followed by post-processing techniques such as shading. While professional tools provide helpful plugins, cartoon creation remains challenging, even for skilled creators. One approach that has gained attention is image cartoonization, where real-world photographs are converted into cartoon styles to use as background scenes. Deep learning-based cartoonization methods have shown promise in producing high-quality cartoon-stylized outputs that can be used in real service production. However, previous methods lack control over the intermediate steps of the cartoon-making process, limiting the artist's ability to manipulate the outputs. In this paper, we propose an approach to embedding interactivity in cartoonization, focusing on texture and color control. We introduce a pipeline that allows creators to manipulate stroke thickness, abstractions, and color regions to achieve desired cartoonized results. Through separate texture and color decoders, we minimize interference and achieve high-quality stylization. Our framework is the first to offer interactivity in deep learning-based cartoonization, allowing users to create diverse cartoonized images based on their preferences. Experimental results demonstrate the superior perceptual quality and flexibility of our approach compared to previous methods.