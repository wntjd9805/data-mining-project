This paper discusses the importance of polarization in visual information encoding and its applications in various fields such as medicine, underwater exploration, and remote sensing. It introduces a novel neuromorphic vision sensor called Polarization Dynamic and Active pixel Vision Sensor (PDAVIS) inspired by the mantis shrimp visual system. The PDAVIS sensor can simultaneously capture high-frequency asynchronous polarization brightness change events under different polarization angles. However, the sparse and unstructured nature of the polarization events makes them challenging to interpret for human observation and traditional computer vision algorithms. To address this issue, the authors propose a solution to reconstruct polarization from polarization events using a deep neural network (DNN) model. They create a large-scale dataset called Events to Polarization Dataset (E2PD) that contains synthetic and real-world polarization events and corresponding video frames. The authors then design an E2P network using a Rich Polarization Pattern Perception (RPPP) module and a Cross-Modality Attention Enhancement (CMAE) module to reconstruct intensity, Angle of Linear Polarization (AoLP), and Degree of Linear Polarization (DoLP) directly from the raw polarization events. Extensive validation experiments show that the proposed method outperforms existing PDAVIS methods in terms of accuracy. The contributions of this work include the first attempt to solve the event-to-polarization problem using an end-to-end trained deep neural network, a unique large-scale event-to-polarization dataset, and a novel network that enhances polarization features through cross-modality attention mechanisms.