Abstract:The deployment of autonomous vehicles (AVs) on public roads is still facing significant challenges, particularly in navigating dense urban traffic scenes. Current solutions often result in incorrect decisions or unexpected behavior, leading to accidents or traffic infractions. This paper focuses on two major challenges in achieving autonomous competence: comprehensive scene understanding and high-fidelity prediction of future driving scenes, and dealing with rare adverse events in occluded regions. The proposed approach is a novel end-to-end driving framework called ReasonNet, which combines temporal reasoning on historic scene behaviors and global reasoning on interaction among objects and the environment. The framework aims to improve perception performance and driving quality by enhancing the understanding of driving scenes and the ability to anticipate potential dangers, especially under occlusion. The paper also introduces a new benchmark, the Driving in Occlusion Simulation (DOS) benchmark, to evaluate performance in occlusion events. Experimental results demonstrate the effectiveness of the ReasonNet framework, ranking it first on the sensor track of the CARLA autonomous driving leaderboard.