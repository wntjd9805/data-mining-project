Multi-frame denoising and novel view synthesis are two classical problems in computer vision and computer graphics, respectively. While these problems have traditionally been considered distinct, recent observations have shown that some novel view synthesis approaches can handle noisy inputs effectively and have a denoising effect in synthesized views. This opens up the possibility of solving multi-frame denoising as a special case of novel view synthesis, where the input views are noisy and the target views are clean. In this paper, we propose a novel approach called Multiplane Features Encoder-Renderer (MPFER) for multi-frame denoising. MPFER reimagines the traditional multiplane image (MPI) pipeline by moving the multiplane representation to feature space. By enforcing cross-depth consistency at the rendering stage using a learnable renderer, we overcome depth-discretization artifacts and significantly improve the overall performance of the framework. Our contributions include solving the cross-depth consistency problem for multi-plane representations, introducing the Multiplane Feature (MPF) representation with higher representational power, and repurposing the novel view synthesis framework for 3D-based multi-frame denoising. We validate our approach through experiments on three tasks and three datasets, demonstrating its superiority over existing 2D-based and 3D-based methods for multi-frame denoising.