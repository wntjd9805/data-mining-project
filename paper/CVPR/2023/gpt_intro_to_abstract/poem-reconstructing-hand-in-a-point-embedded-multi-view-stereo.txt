Hand mesh reconstruction is a crucial aspect of augmented and mixed reality applications, as it provides realistic experiences for users. However, existing methods for monocular 3D hand mesh reconstruction face several challenges, including depth ambiguity, unknown perspectives, and occlusion. To address these issues, our paper proposes a method called POEM (POint Embedded Multi-view Stereo), which focuses on reconstructing hands from multi-view images. By leveraging the geometrical consistency among different views, POEM aims to produce accurate and applicable results. The proposed method introduces a point-based feature fusion strategy and a cross-set point attention mechanism to enable interaction between the hand mesh vertices and the point cloud in camera frustum spaces. Experimental results on three multi-view datasets demonstrate the effectiveness of POEM, achieving state-of-the-art performance in hand mesh reconstruction. Our contributions include investigating the interaction between the target point set and basis point set, proposing an end-to-end learning framework for hand mesh reconstruction, and demonstrating significant improvements compared to previous methods. Overall, POEM offers a robust and accurate solution for reconstructing hand mesh from multi-view images in augmented and mixed reality applications.