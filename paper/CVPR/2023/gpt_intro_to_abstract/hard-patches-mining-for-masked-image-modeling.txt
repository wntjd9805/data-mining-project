Self-supervised learning without annotations has gained attention in computer vision. This paper proposes a new training paradigm, Hard Patches Mining (HPM), for masked image modeling (MIM). Instead of using manually-designed masks, HPM allows the model to generate demanding masks by learning challenging problems. The model is trained to predict masked patches while also being aware of the difficulty of the task. A novel auxiliary loss predictor is introduced to predict patch-wise losses and determine where to mask based on these predictions. Empirical results show significant improvements over supervised baselines and vanilla MIM pre-training. HPM achieves high accuracy on ImageNet-1K using ViT-B and ViT-L models. The paper emphasizes the importance of masking discriminative parts and its impact on downstream tasks.