Computer vision has made significant progress in synthesizing new views of objects and scenes. However, accurate camera pose estimation is crucial for high-quality reconstructions. Current methods require dense input imagery or specialized setups, making it challenging and expensive to capture a complete set of images. SparsePose is proposed as a solution to this problem, predicting camera rotation and translation parameters from sparse input views based on 3D consistency between projected image features. It leverages a prior learned over the geometry of common objects to estimate camera poses for sparse images and generalize to unseen object categories. The method consists of a two-step coarse-to-fine image registration process, including predicting initial camera locations and iterative pose refinement. SparsePose outperforms conventional and learning-based methods for camera pose estimation in sparse view settings. It enables real-life, sparse-view reconstruction with as few as five images, producing accurate camera poses and high-fidelity reconstructions compared to competing methods.