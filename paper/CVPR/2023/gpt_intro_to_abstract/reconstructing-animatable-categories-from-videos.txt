In this paper, we propose a method for building animatable 3D models for deformable object categories, specifically focusing on cats, dogs, and humans. Previous work has successfully built 3D models for specific object categories, but scaling these methods is challenging due to the need for 3D supervision and registration. We leverage test-time optimization through differentiable rendering to generate high-quality 3D models from monocular videos. However, these models are typically built independently for each object instance or scene. Our goal is to build category models that can generate different instances along with deformations, using causally-captured video collections. However, leveraging such data is challenging. One challenge is learning the morphological variation of instances within a category. For example, different dog breeds have different body shapes and appearances. Disentangling these variations from variations within a single instance is difficult without explicit supervision. Additionally, in-the-wild videos often have limited viewpoints and partially observable objects, making it challenging to accurately capture object structures. We aim to address these challenges by learning skeletons with constant bone lengths within a video, allowing for better disentanglement of between-instance morphology and within-instance articulation. We also regularize unobserved body parts to be coherent across instances while remaining faithful to the input views. Furthermore, we make use of a category-level background model to improve segmentation masks. Our approach outperforms prior art in terms of animatable 3D models for cats, dogs, and humans. We also demonstrate the ability to transfer motion across instances due to our models' registration with a canonical skeleton.