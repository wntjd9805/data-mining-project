Image and video denoising are important tasks in computational photography and computer vision. Deep neural networks have been successful in model-based denoising, achieving high reconstruction accuracy. However, there is often a trade-off between reconstruction accuracy and visual quality. Traditional denoising methods allow easy adjustment of denoising levels, but deep network methods typically only produce fixed outputs. Recent modulation methods have been proposed to generate continuous restoration effects, but they have limitations such as lack of explainability, lack of efficiency, and the need for explicit degradation levels during training. In this paper, we propose a new controllable denoising pipeline called RCD that supports real-time denoising control and larger control capacity without multiple training stages or auxiliary networks. RCD is the first method to support controllable denoising on real-world benchmarks. We also propose a general Noise Decorrelation technique to estimate editable noises. Our method achieves comparable or better results on widely-used denoising datasets with minimal additional computational cost.