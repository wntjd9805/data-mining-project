Object detection is a crucial task in computer vision, but achieving high precision for small object detection remains challenging. While deep learning has improved general object detection performance, it struggles to balance detection quality on small objects with computational costs. In this paper, we propose Scale-aware Knowledge Distillation (ScaleKD) to address this issue. Inspired by the success of knowledge distillation in image data, we explore distillation methods for small object detection. However, small object detection poses unique challenges, including noisy feature representations and low tolerance for noisy bounding boxes. To overcome these challenges, our proposed ScaleKD consists of two modules: a Scale-Decoupled Feature (SDF) distillation module and a Cross-Scale Assistant (CSA). The SDF module decouples feature representations of objects with varying scales into a multi-scale embedding, enhancing the student model's understanding of small objects' features. The CSA module resolves the adverse effect of noisy bounding box predictions by mapping representations from the teacher and student models into a single feature embedding using a multi-scale cross-attention module. We evaluate our approach on COCO object detection and VisDrone datasets using different types of detectors, and it consistently outperforms state-of-the-art knowledge distillation methods on both general object detection and small object detection. We also extend our method to instance-level detection tasks, demonstrating its superiority in dealing with small objects in various vision tasks. Our contributions include the introduction of ScaleKD, a cost-free knowledge distillation framework that improves object detection performance, and the demonstration of its effectiveness in small object detection and other instance-level detection tasks.