Image retrieval has been extensively studied in the field of computer science. High-performing image retrieval systems typically use a large model to embed both query and gallery images, known as symmetric image retrieval. However, in some real-world applications, such as mobile search, the query side has resource limitations and cannot support the deployment of a large model. This has led to the proposal of asymmetric image retrieval, which focuses on optimizing the gallery side instead of the query side. In this paper, we introduce a new paradigm called Asymmetric Feature Fusion (AFF) to enhance existing asymmetric retrieval systems. AFF leverages the complementarity among different features by deploying multiple powerful models on the gallery side to extract diverse features. These features are then aggregated using a dynamic mixer into a compact embedding, enabling efficient retrieval. On the query side, a single lightweight model is used for embedding queries. This paradigm achieves high retrieval efficiency and accuracy simultaneously, outperforming previous approaches. Experimental evaluation on landmark retrieval datasets demonstrates the effectiveness of our approach, leading to state-of-the-art results.