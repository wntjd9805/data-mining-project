The introduction of this computer science paper highlights the importance of accurate 3D modeling for immersive and realistic Augmented Reality (AR) applications. Various approaches have been proposed to address this issue, such as Visual SLAM, Depth Fusion, and Multi-View Stereo. Neural fields have also emerged as a promising technique for 3D reconstruction and novel view synthesis. However, benchmarking these algorithms is challenging due to the difficulty in building exact 3D models. Existing datasets often rely on high-end 3D scanners, which still result in artifacts and deviations from ground truth. This can lead to significant biases when evaluating high-fidelity object reconstruction. The paper introduces MobileBrick, a large-scale dataset of 153 diverse object shapes, focusing on detailed 3D object reconstruction using high-resolution RGB images and low-resolution depth maps captured on a mobile device. The dataset provides exact ground-truth 3D models and an efficient annotation pipeline to align the models to image sequences. The usefulness of the proposed dataset is demonstrated through training and evaluating various methods on tasks such as multi-view surface reconstruction, novel view synthesis, and color-guided depth enhancement.