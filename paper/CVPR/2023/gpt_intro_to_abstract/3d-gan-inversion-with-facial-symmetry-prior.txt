Recent advancements in 3D-aware generative adversarial networks (GANs) have shown significant progress in synthesizing view-consistent images. However, existing methods to increase generation resolution fall short in accurately representing 3D geometry. In this paper, we propose a novel 3D GAN inversion approach that utilizes facial symmetry as a prior to enhance the reconstruction of a human face given only one monocular image. By leveraging the mirrored image as additional supervision, we prevent geometry collapse and obtain a rough geometry. To improve texture quality and geometry in novel views, we employ depth-guided 3D warping and fine-tuning using both the original image and pseudo images generated from the mirrored image. We also introduce geometry regularization and adaptive constraints to extract meaningful information from the mirror image. Experimental results demonstrate the effectiveness of our method in achieving high-quality reconstruction with multi-view consistency in geometry and texture. We compare our method with state-of-the-art inversion methods and apply it to various downstream applications.