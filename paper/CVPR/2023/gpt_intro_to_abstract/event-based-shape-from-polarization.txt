This paper introduces a novel approach for shape-from-polarization (SfP) using event cameras. SfP methods leverage polarization cues to infer geometric properties of an object, and typically involve capturing images at different polarizer angles to estimate surface normals. However, existing methods, such as Division of Focal Plane (DoFP) and Division of Time (DoT), have limitations in terms of resolution, acquisition speed, and computational complexity. To address these challenges, the authors propose an approach that utilizes the high-speed and high-resolution capabilities of event cameras. They present two algorithms for surface normal estimation: one based on geometry and another based on a deep learning framework. The geometry-based method reconstructs relative intensities at multiple polarizer angles using the continuous event stream, resulting in improved surface normal estimation accuracy compared to traditional image-based approaches. The learning-based method uses a U-Net network to predict dense surface normals from events, addressing the issue of low fill-rate in real-world scenarios. The authors also introduce a large-scale dataset comprising events and images captured using a polarizer and the Lucid Polarisens camera. Overall, the proposed approach and algorithms improve the speed, resolution, and accuracy of surface normal estimation in SfP.