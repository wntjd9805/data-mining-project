The field of visual recognition has seen significant advancements in large-scale visual representation learning, thanks to research breakthroughs in previous decades. Pre-trained, large-scale vision models have become crucial in enabling various vision applications and feature learning. The performance of visual representation learning systems depends on three main factors: the chosen neural network architecture, the training method used, and the training data. Neural network architecture design has been instrumental in representation learning, with convolutional neural network architectures (ConvNets) revolutionizing computer vision research by allowing generic feature learning methods instead of manual feature engineering. The transformer architecture, initially developed for natural language processing, has also gained popularity due to its scalability with respect to model and dataset size. The ConvNeXt architecture has modernized traditional ConvNets and demonstrated scalability. Self-supervised pre-training with pretext objectives has also gained attention, particularly masked autoencoders (MAE), which have achieved success in masked language modeling for vision tasks. However, combining architecture design and self-supervised learning can present challenges, especially when using ConvNeXt with MAEs. The proposed approach is to co-design the network architecture and masked autoencoder to make mask-based self-supervised learning effective for ConvNeXt models. The masked autoencoder is designed to treat the masked input as sparse patches, utilizing sparse convolutions and converting weights to standard dense layers during fine-tuning. Feature collapse at the MLP layer during training on masked input is addressed by adding a Global Response Normalization layer. The introduction concludes by introducing ConvNeXt V2, which improves performance when used with masked autoencoders across various downstream tasks. Different models of varying complexity are available, achieving state-of-the-art accuracy in tasks such as ImageNet classification, COCO object detection, and ADE20K segmentation.