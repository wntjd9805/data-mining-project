This paper focuses on the demand for high-fidelity and personalized 3D hand modeling in various applications, such as 3D games, virtual reality, and the emerging Metaverse. Current methods for hand reconstruction and modeling lack the ability to enrich the details of the reconstructed shape and fail to generate consumer-friendly high-fidelity hands. By treating the hand mesh as graph signals and utilizing a frequency-based loss function, the authors propose a method that can generate high-fidelity hand meshes that adapt to different users and application scenarios. The authors also introduce a new hand model with nonparametric representation for residual adjustments, balancing personalized details and overall structure. The network architecture is designed in a coarse-to-fine manner to output hand meshes with increasing levels of resolution and personalized details. The contributions of this paper include the development of a high-fidelity 3D hand model, a frequency split network architecture for scalable mesh generation, and a new metric for evaluating mesh details. The proposed method outperforms existing baselines in terms of realism and accuracy. The evaluation is conducted on the InterHand2.6M dataset, and the effectiveness of the proposed metrics is validated through extensive experiments.