The development of remote photoplethysmography (rPPG) technology allows for the estimation of physiological metrics such as heart rate and respiratory rate from facial videos. Deep learning-based rPPG methods have been successful in overcoming intensity variations and noise in training samples. However, these models may not generalize well to unseen interferences in the test domain, such as lighting conditions and camera sensors, leading to distortions in estimated rPPG signals. To address this challenge, unsupervised domain adaptation (UDA) techniques have been proposed, but they may struggle to effectively reduce noise and align rPPG features from different domains. In this paper, we propose a dual-bridging noise modeling network that leverages ground-truth PPG signals and adversarial noise generation to improve the robustness of rPPG models to target domain noise. We also introduce a hard noise pattern mining mechanism to further explore target domain noise patterns. Our experimental evaluation demonstrates the effectiveness of our method in various cross-domain scenarios with different types of interferences.