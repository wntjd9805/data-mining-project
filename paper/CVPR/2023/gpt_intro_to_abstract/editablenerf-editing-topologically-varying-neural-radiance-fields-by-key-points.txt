Neural radiance fields (NeRF) have demonstrated impressive capabilities in novel-view synthesis and photo-realistic rendering. While recent advancements have extended NeRF to handle dynamic and topologically varying scenes, these approaches primarily focus on reconstruction and do not consider scene editing. Some frameworks have been proposed to enable editing of neural radiance fields, such as editing appearance, controlling object shapes and colors, or modifying scene parts, but the dynamics of moving objects and topological changes remain challenging to edit. One state-of-the-art framework attempts to address this issue using manual supervision but only supports limited and one-dimensional editing. In this paper, we propose EditableNeRF, a method that allows for intuitive multi-dimensional editing of topologically varying neural radiance fields without manual supervision. Our approach represents motions and topological changes using sparse surface key points, where each key point controls the dynamics of a moving part and other effects through the neural radiance fields. To achieve this, we employ scene analysis to detect and track key points, estimate spatially-varying weights for scene points, and optimize key point positions based on motion and geometry constraints. The trained network can reconstruct scenes from input image sequences, enable editing by controlling key point positions, and generate novel scenes. The contributions of this paper include the development of key-point-driven neural radiance fields for intuitive multi-dimensional editing, a weighted key points strategy for modeling topologically varying dynamics, and a scene analysis method for key point detection and initialization.