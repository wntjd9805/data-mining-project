Few-shot learning (FSL) is a technique in computer vision that aims to mimic the abilities of human vision by enabling machines to learn a new concept from just a single example. While supervised learning models excel in various computer vision tasks, they often fail when applied to novel tasks due to a lack of annotated data. The annotation process is often time-consuming and costly, making it challenging to obtain sufficient data for training supervised models. FSL addresses this limitation by leveraging metric learning, meta-learning, or transfer learning to enable machines to learn from limited data.In this paper, we focus on transductive inference for few-shot learning, which involves inferring class labels jointly for all unlabeled query samples at test time. We categorize transductive FSL into two paradigms: those that estimate prototypes using unlabeled data and those that build a graph and use label propagation to predict labels on query sets. However, both paradigms have their limitations. Prototype-based methods often assume a single prototype representation for each class and are sensitive to variations within and between classes. Graph-based methods depend on the construction of the graph, which can be affected by incorrect connections between samples.To overcome these limitations, we propose a method called prototype-based Label Propagation (protoLP) for transductive FSL. Our approach does not assume a uniform class distribution prior and significantly outperforms other methods that rely on this assumption. We show that protoLP achieves superior performance compared to state-of-the-art methods across different settings, datasets, and training models. Additionally, our transductive inference is highly efficient, with run-times comparable to inductive inference.In summary, our contributions include the identification of issues with existing prototype-based and graph-based FSL methods, the proposal of protoLP as a unified framework that combines both models, and the demonstration of its advantages over state-of-the-art methods through extensive experiments. Our approach improves the performance of few-shot learning in various scenarios, including unbalanced query sets and data augmentation.