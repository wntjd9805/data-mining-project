This paper focuses on the challenge of enabling real-time encoder inference for Codec Avatars on Augmented- and Virtual-Reality (AR/VR) devices. Codec Avatars are a state-of-the-art approach for photorealistic telepresence, which aims to create a sense of co-location among participants in a shared virtual space. However, the computational requirements of Codec Avatars, combined with the limited computing resources on AR/VR devices, pose a bottleneck for their practical adoption. While existing work has focused on reducing the computational cost of the decoder, efficient encoder designs for AR/VR devices have been less explored. In this paper, the authors propose a framework called Auto-CARD that enables efficient and robust real-time driving of Codec Avatars exclusively using on-device computing resources. Auto-CARD integrates a neural architecture search technique tailored for avatar encoding, as well as a mechanism called LATEX to reduce temporal redundancy. Experimental results show that Auto-CARD achieves a significant speed-up while maintaining comparable or even better accuracy compared to state-of-the-art encoder designs.