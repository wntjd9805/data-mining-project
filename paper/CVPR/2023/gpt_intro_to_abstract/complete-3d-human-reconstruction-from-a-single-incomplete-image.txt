This paper introduces a method for reconstructing a complete 3D human model from a single image with occlusions. While existing methods have shown promising results, they often fail to handle incomplete images, resulting in artifacts and missing data. The complete 3D model can be used in various applications such as film production and virtual teleportation. The recent progress in neural network-based implicit approaches indicates their potential for accurate detail reconstruction. However, these approaches are limited in reconstructing invisible body parts and maintaining global coherency. To overcome these limitations, we propose a 3D convolutional neural network that generates volumetric features, capturing the global ordinal relationship of a human body. These features are learned in conjunction with a 3D discriminator to generate a coarse yet complete 3D geometry. We also present techniques for enhancing surface normals and inpainting textures in a multiview-consistent manner. Our experiments demonstrate that our method outperforms previous approaches in reconstructing a complete 3D human model with plausible details from partial body images. The technical contributions of this work include the design of generative and coherent volumetric features, a novel multiview normal fusion approach, and an effective texture inpainting pipeline.