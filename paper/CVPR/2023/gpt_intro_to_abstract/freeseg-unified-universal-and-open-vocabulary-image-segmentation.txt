Image segmentation is a widely studied topic in computer vision, aiming to group and categorize object pixels in an image. However, current image segmentation tasks are limited to a small number of predefined categories, hindering the scalability and generalization of segmentation systems. To address this limitation, this paper proposes FreeSeg, a novel framework for unified, universal, and open-vocabulary image segmentation. FreeSeg utilizes large-scale visual-language pre-training models to calculate matching similarity between visual concepts and text corpus, allowing for custom specification of segmentation categories beyond the training dataset. The framework adopts a two-stage segmentation approach, where the first stage extracts universal mask proposals and the second stage performs zero-shot classification on these masks. Adaptive prompt learning is introduced to encode task-aware and category-sensitive concepts into the text abstraction, enabling FreeSeg to flexibly accomplish different segmentation tasks of arbitrary categories within a single model. Experimental results demonstrate that FreeSeg achieves state-of-the-art performance and generalization on various image segmentation tasks, outperforming specialized architectures and providing a more feasible solution for multi-task deployment. Overall, this paper contributes to the field of computer vision by proposing the first unified open-vocabulary segmentation framework.