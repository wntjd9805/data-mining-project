Hashing methods are widely used in large-scale image retrieval due to their efficiency in storage and retrieval. Deep-learning-based hashing methods have gained attention for image retrieval, using deep neural networks to learn hash functions that encode similar and dissimilar images to nearby and far-away binary codes, respectively. However, existing deep hashing methods have been found to have restrictions in performance due to low efficiency in obtaining global similarity, incomplete coverage of data distribution, and ineffectiveness on imbalanced similar and dissimilar data pairs. To address these issues, a novel deep hashing method is proposed that uses an optimization procedure to produce hash centers with a constraint on a given minimal distance d between any pair of hash centers. The value of d is derived using the Gilbert-Varshamov bound from coding theory. The proposed method utilizes a two-stage pipeline, with Stage 1 solving the optimization problem to produce clearly-separated hash centers using an alternating optimization procedure. In Stage 2, a deep hashing network is trained using the constructed hash centers and loss functions are defined to ensure the proximity of an image's hash code to its corresponding hash center, similarity between hash codes of images in the same class, and minimized quantization errors. The proposed method is evaluated on three datasets for image retrieval and outperforms state-of-the-art deep hashing methods, demonstrating the effectiveness of the approach.