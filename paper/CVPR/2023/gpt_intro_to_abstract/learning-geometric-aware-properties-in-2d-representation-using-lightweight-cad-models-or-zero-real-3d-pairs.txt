This paper introduces a novel approach to inducing geometric-aware properties in 2D representation using lightweight CAD models. The authors argue that previous methods in visual representation learning have shortcomings in tasks involving instance-level reasoning. To address this, they propose learning 3D geometric priors from CAD models and transferring them to 2D representations. The key concept is to share useful 3D priors with 2D representations to improve performance on downstream tasks. They explore learning an embedding space that maps images with the same or similar geometries together, using the Chamfer distance as a measure of similarity. The authors demonstrate the effectiveness of their approach in various 2D object understanding tasks and achieve competitive results compared to state-of-the-art methods that require 3D scene scans. The contributions of this paper include the proposed approach, training objectives for the embedding space, and enhanced performance on 2D object understanding tasks using real or pseudo-RGB-CAD datasets.