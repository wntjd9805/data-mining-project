In this paper, we address the issue of geographical inclusivity in Vision-Language Pre-trained Models (VLPs) that have shown impressive performance on various Vision-Language (V&L) tasks. While these models excel in solving V&L tasks, they often exhibit performance discrepancies when applied to images from different regions. To overcome this bias, we propose GIVL, a Geographically Inclusive Vision-and-Language Pre-trained model. We propose novel pre-training objectives, namely Image-Knowledge Matching (IKM) and Image Edit Checking (IEC), to encourage GIVL to learn geo-diverse knowledge during pre-training. These objectives focus on capturing the unique knowledge and visual characteristics of concepts from different regions and differentiating visually similar concepts that belong to unrelated categories. Our results show that GIVL outperforms similar-size VLPs on geo-diverse V&L tasks, achieving state-of-the-art and more balanced performance across different regions. Additionally, GIVL significantly outperforms VinVL on the geo-diverse zero-shot image classification task. Our proposed methods contribute to improving the geographical inclusivity of VLPs and enable effective transfer learning on images from diverse regions.