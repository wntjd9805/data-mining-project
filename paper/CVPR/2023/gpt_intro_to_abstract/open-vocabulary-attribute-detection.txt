Abstract:This paper introduces the Open-Vocabulary Attribute Detection (OVAD) task in computer vision, which aims to detect and recognize an open set of objects in an image along with an open set of attributes for each object. The task is defined by text queries during inference, without prior knowledge of the tested classes during training. To facilitate evaluation, the paper also presents the OVAD benchmark, a densely annotated dataset for open-vocabulary attribute detection based on the MS COCO dataset. The benchmark includes 80 object categories, 117 attribute categories, and provides negative attribute annotations for quantifying false positive predictions. A baseline method for the OVAD task is proposed, which outperforms existing open-vocabulary models. The paper further evaluates the performance of several vision-language models on attribute detection, demonstrating the generalizability of their success in object classification to attributes. The contributions of this paper include the introduction of the OVAD task, the development of the OVAD benchmark, the presentation of a baseline method, and the evaluation of foundation models for attribute detection.