This paper introduces the concept of enhancing existing hand-crafted and learning-based descriptors in computer vision tasks by using a lightweight network called FeatureBooster. The network takes the input of descriptors and geometric properties of keypoints within an image, and processes them using MLPs and an efficient Transformer to produce enhanced descriptors that are more robust and discriminative. The core idea is to integrate visual and geometric information into individual descriptors, mimicking how humans find correspondences between images. The paper evaluates the boosted descriptors on various tasks such as image matching, visual localization, and structure-from-motion, and demonstrates significant improvements in performance. The FeatureBooster method is highly efficient, with processing times of only 3.2ms on NVIDIA RTX 3090 and 27ms on NVIDIA Jetson Xavier NX, making it applicable to practical systems.