Image super-resolution (SR) is a process of reconstructing high-resolution images from low-resolution ones. While deep-learning methods have achieved good results in terms of fidelity and perceptual quality, they are not efficient and lightweight for mobile platforms. Mobile platforms have limitations such as restricted RAM, lower memory bandwidth, slower computational speed, and lack of support for common deep learning layers and operators. Recent SR models designed for mobile devices have attempted to address these limitations but still struggle with time-consuming components. In this paper, we propose Equivalent Transformation (ET), a method that substitutes time-consuming operators with time-friendly ones, without compromising reconstruction quality. ET can be directly applied to existing models, reducing inference latency without retraining. To fully utilize the redundant parameters introduced by ET, we design a dual stream network that makes the parameters partially learnable, enhancing feature extraction ability. Our proposed mobile image SR model, named ETDS, employs the dual stream network during training and transforms it into an equivalent plain network using ET during inference. ETDS achieves both high reconstruction quality and low inference speed.The contributions of this paper are as follows: 1) Introducing ET as a method to transform time-consuming operators and accelerate inference without compromising reconstruction quality. 2) Designing a dual stream network to address the redundancy introduced by ET by making parameters partially learnable. 3) Proposing an efficient and lightweight network, ETDS, for real-time SR on mobile devices based on ET and dual stream networks. Experimental results show that models equipped with ET achieve up to 80% improvement in inference latency, and ETDS achieves 34% inference latency improvement and 0.42dB PSNR performance improvement.