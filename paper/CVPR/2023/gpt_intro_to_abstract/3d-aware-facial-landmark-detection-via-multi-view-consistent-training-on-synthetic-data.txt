Facial landmark detection plays a crucial role in various computer vision and graphics applications. These applications require accurate and precise detection of facial landmarks, even under different facial appearances, expressions, and head poses. However, manually annotating landmarks accurately and consistently remains a challenge. To address this issue, we propose a method that enforces multi-view consistency during training. Instead of detecting landmarks in each individual facial image, our method locates landmarks in a holistic 3D-aware manner using multi-view images. We introduce self-projection consistency loss and multi-view landmark loss to enforce multi-view consistency. We also develop an annotation generation procedure that combines lab-controlled data and in-the-wild data. This allows us to learn facial landmark detection without relying on human annotations. We formulate our solution as a plug-in 3D aware module that can enhance the accuracy and multi-view consistency of any facial landmark detector. We validate the effectiveness of our approach through extensive experiments on synthetic and real datasets. Our contributions include the creation of a large-scale synthetic multi-view face dataset, the proposal of a novel 3D-aware optimization module, and the demonstration of performance improvements on multiple baseline methods.