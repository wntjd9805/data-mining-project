In this paper, we address the task of Temporal Action Localization (TAL) in long-form videos. TAL involves finding action instances in time and classifying their categories, which is crucial for video understanding tasks. However, the current pipeline for TAL suffers from a task discrepancy problem, where the pretrained snippet encoder fails to capture the temporal variations within the same action class, making it difficult to distinguish foreground actions from background frames. To overcome this challenge, we propose a Soft-Landing (SoLa) strategy that incorporates a light-weight neural network module between the pretrained encoder and the downstream head. The SoLa module acts as a middleware and mitigates the task discrepancy problem without the need for retraining the snippet encoder. Additionally, we introduce a novel unsupervised training scheme called Similarity Matching, which encourages temporally sensitive feature sequences. Our experimental results demonstrate significant performance improvements in downstream tasks compared to previous methods that involve snippet encoder retraining, while offering easier applicability and computational efficiency.