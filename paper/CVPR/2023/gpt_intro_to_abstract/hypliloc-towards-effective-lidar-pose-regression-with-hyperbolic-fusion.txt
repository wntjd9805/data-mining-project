Visual relocalization, which estimates the 6-degree of freedom (DoF) pose using perception sensors like LiDARs and cameras, is crucial for various applications such as robot navigation and scene recognition. While image-based relocalization methods have shown good performance, they are limited by environmental conditions. On the other hand, LiDARs are more robust against such changes and have gained importance in smart robots and autonomous vehicles. LiDAR-based relocalization methods, including LiDAR odometry and LiDAR-based retrieval, have been proposed, but they suffer from limitations such as error accumulation and high computation/storage cost. In this paper, we propose a novel LiDAR-based pose regression network called HypLiLoc, which directly regresses the global pose without relying on a pre-constructed candidate database or map. HypLiLoc uses a parallel feature extraction design, combining 3D features and 2D spherical projection features in two backbone branches. We leverage hyperbolic embeddings to enhance multi-modal feature interaction. Experimental results on outdoor and indoor datasets show that HypLiLoc outperforms existing pose regression methods and achieves state-of-the-art performance. Our contributions include the proposal of HypLiLoc, evaluation on various datasets, and extensive ablation studies to analyze the effectiveness of each design component.