Owning extraordinary representation learning ability, deep neural networks (DNNs) have achieved remarkable success on a variety of tasks when the training and test data are drawn from the same distribution. However, when faced with out-of-distribution data, DNNs have demonstrated poor generalization capability due to the violation of the i.i.d. assumption, which is common in real-world conditions. To address this issue, domain generalization (DG) has emerged as a solution, aiming to learn a robust model from multiple source domains that can generalize well to any unseen target domains with different statistics. One prevalent strategy in DG is domain augmentation, which exposes the model to more diverse domains via augmentation techniques.While it is commonly believed that more diverse training distributions lead to more generalizable models, the theoretical justification and formal analyses of the relation between domain diversity and model generalization are scarce. Moreover, the transfer of knowledge may even hurt the performance on target domains in some cases, referred to as negative transfer. Therefore, the relation between domain diversity and model generalization remains unclear.To explore this issue, the authors quantify domain diversity as the number of augmented domains and conduct an experiment using Fourier augmentation strategy as a representative instance. The results show that increasing domain diversity does not necessarily lead to improved model generalization, but can sometimes lead to a decrease in performance. This may be because the model fails to utilize the rich information of diverse domains or due to the presence of low-quality samples containing redundant or noisy information.In this work, the authors propose a convex game framework for DG to ensure a strictly positive correlation between model generalization and domain diversity. They design a novel regularization term based on the supermodularity of convex game, encouraging each diversified domain to contribute to improving model generalization. Additionally, a sample filter is constructed to remove low-quality samples that negatively impact generalization. The authors provide heuristic analyses and intuitive explanations for the mechanisms behind their proposed approach.The contributions of this work include exploring the relation between model generalization and source domain diversity, introducing a convex game framework for DG, and providing heuristic analysis and intuitive explanations. The effectiveness and superiority of the proposed approach are validated empirically across various real-world datasets.