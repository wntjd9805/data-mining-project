Re-identification (ReID) is a critical task in visual surveillance, aiming to associate person/vehicle images with the same identity across different cameras. With the advancements in deep neural networks, ReID tasks have seen progress in terms of feature extractors and losses. Metric losses, which quantify the similarity/distance between images, have been widely used to improve ranking precision in ReID. These losses focus on mapping raw signals into a low-dimensional space where instances of the same class are clustered and different classes are separated. Existing metric losses employ dense pairwise methods that treat each instance as an anchor and construct loss items using positive and negative pairs. However, this dense design introduces harmful positive pairs and leads to suboptimal solutions for metric learning. In this work, we propose a novel pairwise loss framework called Sparse Pairwise loss that leverages only a few informative positive/negative pairs for each class in a mini-batch. We also introduce a least-hard positive mining strategy to handle intra-class variations and develop an adaptive mechanism for different levels of intra-class variations. We evaluate our proposed AdaSP loss on various person/vehicle ReID datasets and show its superiority over existing dense pairwise losses across different benchmarks.