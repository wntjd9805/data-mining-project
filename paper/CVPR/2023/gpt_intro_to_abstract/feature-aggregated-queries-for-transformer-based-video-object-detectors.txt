The introduction of this computer science paper discusses the challenges and advancements in object detection, particularly in the context of deep learning. It categorizes existing object detectors into two-stage, one-stage, and query-based models, highlighting the trade-off between efficiency and performance. While two-stage models generate proposals and refine results, one-stage models directly predict object locations and categories, and query-based models generate predictions based on queries without complex post-processing. The paper then focuses on extending object detection to the video domain, where features can degrade due to motion. It discusses post-processing and feature-aggregation-based models as approaches to address this issue. The paper introduces Transformer-based models and their potential for video object detection. The authors propose a new approach that focuses on aggregating queries in Transformer-based object detectors to improve performance and adapt to the video domain. They introduce a vanilla query aggregation module and a dynamic version that enhances query representations and adjusts query weights based on input frames. The proposed method can be integrated into existing Transformer-based object detectors, achieving improved performance on video object detection tasks. The contributions of the paper include being the first to focus on query initialization and aggregation in Transformer-based video object detectors and proposing a plug-and-play module for integrating the method into state-of-the-art detectors, leading to improved performance. The paper concludes with experimental results demonstrating the effectiveness of the proposed modules on the ImageNet VID benchmark.