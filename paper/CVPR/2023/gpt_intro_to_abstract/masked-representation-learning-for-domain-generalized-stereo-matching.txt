Stereo matching is a challenging research topic in computer vision that involves obtaining the corresponding pixels between two rectified stereo images. It is crucial in various applications such as autonomous vehicles, augmented reality, and virtual reality. While mainstream deep stereo matching methods have made progress in terms of accuracy and efficiency, they often fail to achieve good generalization performance in unseen domains. To address this, researchers have explored solutions such as unsupervised matching, domain adaptation, and domain generalization. However, existing domain generalized matching methods do not address the issue of varying generalization performance among different training epochs. Furthermore, multi-task learning has been introduced in stereo matching to improve feature representation and learning. Inspired by these approaches, this paper proposes a masked representation learning approach for domain generalization in stereo matching. The proposed approach combines stereo matching with image reconstruction as a pseudo-multi-task learning framework, resulting in improved generalization accuracy and reduced volatility of generalization performance. Experimental results demonstrate the superiority of the approach over different training epochs, highlighting the importance of stability in cross-domain methods. The contributions of this paper include the introduction of the masked image modeling and stereo matching pseudo-multi-task learning framework, significant improvements in cross-domain accuracy, and the observation of varying accuracy in existing stereo matching domain generalization methods among different training epochs.