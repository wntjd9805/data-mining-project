3D point cloud analysis has made significant advancements in various industrial applications such as autonomous driving and augmented reality. However, the process of acquiring and labeling 3D point cloud data is expensive and time-consuming. In contrast to supervised learning, unsupervised learning aims to characterize feature distribution directly from the data itself. Previous research in unsupervised point cloud pre-training has focused on contrastive learning and reconstruction. This paper proposes a new approach called PointClustering, which leverages deep clustering and transformation invariance as a pretext task for unsupervised point cloud pre-training. The approach optimizes feature clusters and backbone iteratively, considering both point-level and instance-level feature invariance. Instance masks are obtained using a clustering algorithm, and geometric properties of points are characterized by clustering their features under different transformations. The instance-level feature of an object is computed by pooling all point features of that object, and feature consistency at the instance level is further optimized using InfoNCE loss. Experimental results show that PointClustering outperforms existing unsupervised pre-training models on multiple benchmarks and downstream tasks. This work contributes a new paradigm for unsupervised point cloud pre-training, highlighting the importance of transformation invariance in self-supervision and the indication of geometric properties and semantics of point cloud data.