Large-scale pre-trained vision-language models (VLMs) have revolutionized various vision tasks such as zero-shot classification, image/video generation, and language-guided question answering. However, these models lack the ability to search for specific instances, limiting their practicality. Prior approaches have proposed extending the vocabulary of the language encoder with tokens representing specific instances, but they require manual annotation and suffer from limited generalization. In this paper, we propose a method to automatically identify important personal instances in videos without explicit human annotations. We extract video transcripts and identify mentions of personal instances, building a dataset called This-Is-My. We then propose a novel model and training procedure to learn text tokens representing the named instances from few and noisy training examples. Our method uses pre-learned category-specific features shared across instances to improve generalization and utilizes meta-personalization to adapt these features. We evaluate our model on a fashion item retrieval benchmark and a new video instance retrieval dataset, demonstrating superior performance compared to baseline methods. Our contributions offer a promising approach to personalize VLMs for specific instance retrieval tasks.