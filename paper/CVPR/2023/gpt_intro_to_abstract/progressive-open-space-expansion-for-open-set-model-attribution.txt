In recent years, advanced generative modeling technology has led to significant changes in AI-enhanced design, arts, and the metaverse. However, the broadcasting of malicious content generated by open source generation models has had severe social impacts. Additionally, the protection of copyright ownership for digital generative models poses new challenges. Model attribution, which involves identifying the source model of generated content, has become an increasingly important area of research. Previous studies have found that GAN models leave fingerprints in generated images, similar to camera devices, and have demonstrated the feasibility of attributing fake images to known models. However, most of these works focus on a closed-set setup, where the number of known models is fixed. In this paper, we address the problem of Open-Set Model Attribution (OSMA), where the goal is to attribute images to both known and unknown source models. We propose a solution called Progressive Open Space Expansion (POSE) that simulates the potential open space of challenging unknown models by involving a set of augmentation models progressively. These lightweight augmentation models serve as "virtual" follow-up blocks of known models, modifying their fingerprints with reconstruction residuals to augment closed-set samples into open-set samples. To ensure the diversity of the simulated open space, we design a progressive training mechanism. We construct an OSMA benchmark dataset that simulates real-world scenarios with challenging unknown models, and the extensive experiments demonstrate that POSE outperforms existing GAN attribution methods and off-the-shelf open-set recognition methods. Overall, our contributions include tackling the open-set model attribution problem, proposing the POSE solution to reduce open space risk, and providing an OSMA benchmark for evaluating model attribution methods in open scenarios.