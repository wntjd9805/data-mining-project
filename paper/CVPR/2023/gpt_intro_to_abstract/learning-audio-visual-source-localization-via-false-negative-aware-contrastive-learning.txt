Humans have the ability to imagine the visual appearance of a sound source and locate it in a scene, demonstrating the importance of audio-visual correspondence for scene understanding. With the availability of paired audio-visual data, there is growing interest in developing multi-modal systems with audio-visual understanding abilities. This paper focuses on unsupervised visual sound source localization, aiming to localize sound-source objects in an image using its paired audio clip without manual annotations. Existing methods formulate this task as contrastive learning, where an audio clip and its corresponding image are treated as positive samples and all others as negative samples. However, the issue of false negatives, where semantically-matched samples are not considered positive pairs due to the lack of manual labeling, affects the representation learning. This paper assesses the impact of false negatives in real-world training and proposes a false-negative aware audio-visual contrastive learning framework (FNAC). The framework leverages intra-modal similarities as weak supervision and introduces strategies for false negative suppression and true negative enhancement. Experimental results demonstrate the effectiveness of the proposed method. The contributions of this paper include the investigation of the false negative issue, the exploitation of intra-modal similarities, and the introduction of strategies to suppress false negatives and enhance true negatives for sound source localization.