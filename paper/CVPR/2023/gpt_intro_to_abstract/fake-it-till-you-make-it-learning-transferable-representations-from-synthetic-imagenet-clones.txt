In recent decades, the field of computer vision has undergone significant changes with the emergence of shallow and deep machine learning. This shift has led to a greater focus on training data and its impact on research progress. The ImageNet dataset, particularly its subset ImageNet-1K, has had a profound influence on computer vision research. However, the process of curating and annotating such a dataset is expensive in terms of both money and labor. As a result, there has been a rise in the use of large-scale and generic models trained on less curated data. These models have proven to be applicable to various computer vision transfer tasks and have also demonstrated impressive image generation capabilities. They are often trained on billion-scale datasets composed of noisy image-text pairs from the internet. Given the success of these generative models, this paper explores the question of whether real images are still necessary when training image prediction models, using the ImageNet dataset as a case study. The authors investigate the extent to which synthetic images generated by the Stable Diffusion model can replace real images for learning deep models. They evaluate the performance of models trained on synthetic images on various datasets, including the standard ImageNet validation set, datasets testing resilience to domain shifts and adversarial examples, and transfer learning scenarios. The results show that the performance gap between models trained on synthetic and real images is narrow, indicating the potential for synthetic images to replace real images in training image classification models. The authors make three main contributions: generating synthetic ImageNet clones using Stable Diffusion, training classification models using these clones and achieving high accuracy, and assessing the generalization capacity of the models on various tasks.