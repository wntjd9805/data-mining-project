In this paper, we address the problem of 3D reconstruction and photo-realistic rendering in the fields of computer vision and graphics. With the advancements of deep learning, neural rendering has emerged as a solution to bridge the gap between these two problems. The Neural Radiance Field (NeRF) framework has been proposed to accurately reconstruct 3D structures and synthesize photo-realistic images from unseen viewpoints. However, while NeRF was originally designed for static scenes, there have been approaches to extend it to dynamic scenes, known as dynamic NeRFs.Previous works have attempted to solve the under-constrained problem of reconstructing dynamic scenes by estimating scene deformations or 3D scene flows for each frame. However, jointly optimizing the parameters of the deformation estimation modules with the NeRF network raises concerns about the accuracy of these estimations. Additionally, resolving ambiguities in dynamic scenes, such as whether a point is newly appeared, moved, or changed its color, remains challenging. It is desirable to train a single network that can separately solve these ambiguities and estimate deformations, but this is difficult in practice without prior knowledge of deformation.Grid representations in NeRF training have gained attention due to their fast training speed. However, incorporating grid representations into dynamic NeRFs requires additional neural networks, affecting both training and rendering speed.Motivated by these challenges, we propose a simple yet effective architecture for training dynamic NeRFs. Instead of using warping functions or 3D scene flows, we apply feature interpolation to the temporal domain. This approach enables us to train dynamic NeRFs without the need for deformation or flow estimation modules. We propose two multi-level feature interpolation methods depending on the feature representation, neural nets or hash grids. We also introduce a smoothness term to encourage feature similarity between adjacent frames, taking advantage of the smoothness of deformations in dynamic scenes. Our proposed method is validated through extensive experiments on synthetic and real-world datasets.The main contributions of our method are summarized as follows:1. We propose a feature extraction network that interpolates feature vectors along the temporal axis, outperforming existing methods without the need for a deformation or flow estimation module.2. We integrate temporal interpolation into hash-grid representation, significantly accelerating training speed compared to neural network models.3. We introduce a smoothness regularizer that effectively improves the overall performance of dynamic NeRFs.