Detecting objects and parsing them into semantic parts is a crucial skill of the human visual system. While computer vision research has primarily focused on object-level segmentation, the inclusion of intermediate part representations has shown to be beneficial for various tasks such as pose estimation, detection, and fine-grained recognition. In this paper, we propose a bottom-up strategy for jointly segmenting parts and objects in images. Our approach involves learning feature embeddings to represent parts and objects and formulating semantic segmentation as an optimization problem. We present a two-step algorithm, Compositor, that clusters image pixels to generate part proposals and then composes these proposals to segment the whole object. Our method not only creates a hierarchical segmentation model but also enhances the model's resistance to occlusion. We evaluate Compositor on PartImageNet and Pascal-Part datasets and demonstrate its effectiveness in generating high-quality semantic parts and improving object segmentation. We also assess Compositor's robustness against occlusion on Occluded-PartImageNet and show its superior performance compared to existing methods. Overall, our contributions include the proposal of a bottom-up segmentation strategy, extensive experimentation and validation, and the creation of a new dataset to assess robustness against occlusion.