Masked Image Modeling (MIM) has achieved great success in self-supervised visual representation learning. However, these models suffer from high computational burden and slow learning process. To address this issue, previous approaches have focused on accelerating the encoding process rather than the representation learning. In this paper, we propose LocalMIM, a novel model that conducts local reconstructions and utilizes multi-scale supervisions from the input. Our model is architecture-agnostic and can be used in both columnar and pyramid architectures. Experimental results demonstrate that LocalMIM outperforms existing MIM models in terms of efficiency and fine-tuning accuracy on ImageNet-1K, leading to better generalization on downstream tasks such as detection and segmentation. Overall, this work introduces the concept of local reconstructions and multi-scale supervisions in MIM, presenting a new approach to accelerate representation learning in self-supervised visual representation learning.