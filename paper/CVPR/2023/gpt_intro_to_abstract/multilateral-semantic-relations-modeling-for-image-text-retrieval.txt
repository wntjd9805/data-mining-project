This paper introduces the Multilateral Semantic Relations Modeling (MSRM) method to address the challenge of one-to-many correspondence in image-text retrieval. The existing approaches in this field focus on point-to-point mapping, which fails to capture the semantic richness of the data. MSRM incorporates semantic distribution learning for a query and multilateral relations modeling for retrieval. It uses a probabilistic embedding and Mahalanobis distance to learn the true semantic distribution of a query. Then, it models each candidate instance as a hyper-graph node and the query as a hyperedge, allowing the capturing of beyond pairwise semantic correlations. The contributions of this work include the introduction of MSRM, the Semantic Distribution Learning module to extract accurate multiple matches, and the use of hyperedge convolution to model high-order correlations.