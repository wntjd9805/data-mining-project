Camera-based vitals estimation is a rapidly growing field that enables non-contact health monitoring. This paper focuses on remote photoplethysmography (rPPG), which estimates the cardiac pulse using video data. While there have been successful approaches using supervised deep learning, the limited availability of benchmark video datasets with simultaneous vitals recordings poses a challenge. This paper proposes the use of non-contrastive unsupervised learning, specifically for regressing rPPG signals, to address the data scarcity problem. The authors demonstrate that weak assumptions of periodicity are enough to learn the visual features corresponding to the blood volume pulse from unlabelled face videos. The proposed approach is compared with supervised and contrastive unsupervised learning methods. The contributions of this work include a general framework for physiological signal estimation via non-contrastive unsupervised learning, the first method for camera-based vitals measurement using non-contrastive unsupervised learning, and experiments and results using non-rPPG-specific video data without ground truth vitals. The source code to replicate this work is provided.