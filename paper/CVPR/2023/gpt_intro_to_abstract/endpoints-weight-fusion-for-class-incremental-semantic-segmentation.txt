Semantic segmentation is a vital task in visual applications, but previous fully-supervised methods are limited to segmenting fixed classes defined in the training set. To overcome this limitation, we propose a class incremental semantic segmentation (CISS) approach that aims to maintain discrimination for old classes while learning knowledge of new classes. However, existing methods still suffer from catastrophic forgetting, where the model forgets previous classes when learning new ones. Additionally, the privacy of previous data and the labeling of old class regions as background further exacerbate the overfitting issue. To address these challenges, we introduce the Endpoints Weight Fusion (EWF) strategy for CISS, which utilizes weight fusion to find a balance between old and new knowledge without the need for further training or model re-parameterization. We also enhance the EWF strategy with a knowledge distillation scheme to increase the similarity of the models at different training points. Our method achieves state-of-the-art performance on both PASCAL VOC and ADE20K datasets and can be easily integrated with existing methods. It can significantly improve performance in CISS scenarios, particularly in long sequences.