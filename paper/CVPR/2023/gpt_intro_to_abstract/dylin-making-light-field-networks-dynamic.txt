Machine vision has seen significant advancements in reasoning about three-dimensional (3D) structures using two-dimensional (2D) observations. This progress is largely attributed to the emergence of coordinate networks, such as Neural Radiance Fields (NeRF) and its variants. While NeRFs have been successful in representing static scenes, there have been efforts to extend them to dynamic cases with moving and shape-evolving objects. However, the computational complexity of NeRF models limits their applicability. Various methods have been proposed to speed up static NeRFs, but the problem of accelerating dynamic NeRFs has received less attention.In this paper, we propose two schemes to extend Light Field Networks (LFNs) to dynamic scene deformations, topological changes, and controllability. First, we introduce DyLiN, which incorporates a deformation field and a hyperspace representation to handle non-rigid transformations in dynamic scenes. DyLiN leverages knowledge distillation from a pretrained dynamic NeRF model. Additionally, we propose CoDyLiN, which introduces controllable input attributes and is trained using synthetic data generated by a pretrained Controllable NeRF (CoNeRF) teacher model.We conducted empirical experiments on synthetic and real datasets to evaluate the efficiency of our proposed schemes. The results show that DyLiN achieves higher image quality and rendering speed, outperforming its original dynamic NeRF teacher model and the state-of-the-art TiNeuVox method. Similarly, CoDyLiN outperforms its CoNeRF teacher model. We also conducted ablation studies to analyze the effectiveness of different components in our models.In summary, our contributions in this paper are: 1) the proposal of DyLiN, an extension of LFNs that can handle dynamic scenes with topological changes, achieved through ray deformations, hyperspace lifting, and knowledge distillation; 2) the demonstration of state-of-the-art results and significant speed improvements compared to existing methods; 3) the introduction of CoDyLiN, which extends DyLiN to handle controllable input attributes. Our methods can be considered as accelerated versions of their respective teacher models, and we are not aware of any prior works attempting to speed up CoNeRF.