This paper addresses the problem of azimuth angle super-resolution for Frequency Modulated Continuous Wave (FMCW) Multiple Input Multiple Output (MIMO) radar in autonomous driving. Previous work has focused on super-resolution from low-resolution and high-resolution Range-Azimuth maps using Discrete Time Fourier Transform (FFT), but we aim to predict uncaptured signals before they are transformed into Range-Azimuth maps. MIMO radar is commonly used in autonomous vehicles due to its robustness in adverse weather conditions. While range and velocity resolution can be improved by adjusting bandwidth and frame times, azimuth resolution is limited by hardware constraints. Some prior work has proposed regularization approaches and deep models for azimuth super-resolution, but these methods have limitations when it comes to processing the transformed data after FFTs. To address this, we propose a light and efficient ADC super-resolution (ADC-SR) model that aims to predict uncaptured signals from hallucinated receivers. We collected a dataset called Pitt-Radar to evaluate and compare our approach with other baseline models, and our ADC-SR model achieves comparable performance with fewer network parameters compared to a RAD super-resolution (RAD-SR) model. We also propose a hybrid model named Hybrid-SR that combines ADC-SR and RAD-SR models, demonstrating improved performance. Additionally, we propose a theoretically grounded downsampling method for training. We evaluate the performance of existing object detectors trained along with our super-resolution models, showing the applicability of our approach to downstream tasks in autonomous driving. Overall, the contributions of this paper include the proposal of the ADC-SR model, the Hybrid-SR model, the Pitt-Radar dataset, and the improvement of existing object detectors.