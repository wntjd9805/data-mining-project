This paper proposes a method called LEGO-Net for learning the regular rearrangement of objects in rooms directly from data. Unlike existing methods that arrange new objects from scratch or require goal state specification, LEGO-Net focuses on rearranging existing objects without any additional input. The method utilizes a transformer-based architecture and learns human criteria for regular rearrangements from a dataset of professionally designed clean scenes. Prior to training, the regular scenes are perturbed to generate noisy configurations. During training, the transformer learns to predict the original, de-noised arrangement from the perturbed scene and its floor plan. During inference, an iterative denoising process is used to retain the flavor of the original room state while minimizing object movement during rearrangement. Extensive experiments show that LEGO-Net realistically rearranges noisy scene arrangements while respecting initial object positions and can generalize to previously unseen collections of objects in a wide variety of floor plans. The paper also introduces a new metric to evaluate the regularity of rearrangements based on integer relation algorithms. This work contributes a generalizable method for regular object rearrangement, an iterative approach to re-arrangement at inference time, an in-depth analysis of the denoising-based scene rearrangement, and a new metric for measuring the regularity of object arrangements.