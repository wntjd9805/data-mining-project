Recent advances in deep learning, particularly generative adversarial networks (GANs), have made it possible to generate highly realistic and diverse synthetic human faces that don't exist in reality. While these synthetic faces have positive applications in various industries, such as video games and computer-aided design, they also pose serious security and ethical concerns. Recent incidents have shown that GAN-generated fake faces can be used to create fake social media profiles and spread misinformation rapidly. Methods have been proposed to distinguish between real and fake GAN-generated faces using supervised deep learning-based classifiers, referred to as forensic classifiers. However, smart attackers can manipulate these fake images using adversarial machine learning techniques to bypass forensic classifiers while maintaining high visual quality. Existing work in adversarial attacks on forensic classifiers suffers from the limitation of being unable to control specific attributes of the generated adversarial faces. This attribute control is important for attackers to disseminate false propaganda via social media to targeted ethnic or age groups. In this paper, we propose a method to generate realistic adversarial fake faces that are misclassified by forensic face detectors. Our method leverages the highly disentangled latent space of the StyleGAN2 model to generate attribute-conditioned attacks. Specifically, we optimize attribute-specific latent variables in an adversarial manner to transfer desired attributes from a reference image or text description to the generated fake faces. Our contributions include a framework for generating attribute-conditioned adversarial fake faces, leveraging meta-learning optimization strategies for improved transferability, and demonstrating that the generated faces appear benign to humans while successfully fooling the target forensic classifier. We emphasize that our goal is not to circumvent face recognition systems, but to generate synthetic faces with specific attributes that can evade forensic classifiers. The reference image or text prompt guides the generation process towards the desired attributes, and we also show that it is possible to preserve the identity of the generated images without sacrificing their adversarial nature.