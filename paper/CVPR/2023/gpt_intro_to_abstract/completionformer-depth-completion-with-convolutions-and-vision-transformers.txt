Active depth sensing has become increasingly important in various applications, including autonomous driving and augmented reality. However, existing depth sensors often produce dense depth maps with significant noise and missing depth values, making depth completion methods crucial for reconstructing complete depth maps from sparse measurements and RGB images. One key aspect of depth completion is establishing depth affinity between neighboring pixels to propagate reliable depth labels. Current approaches, such as convolution neural networks and graph neural networks, can only capture local context and struggle to model global long-range relationships. While Transformer-based architectures enable global reasoning, they often overlook local feature details. Therefore, this paper proposes CompletionFormer, a pyramid architecture that combines CNN-based local features with Transformer-based global representations for enhanced depth completion. By integrating convolutional attention and Transformers in a multi-scale style, CompletionFormer achieves efficient and effective information exchange and fusion. The proposed network outperforms state-of-the-art methods in depth completion, particularly when dealing with sparse depth measurements commonly encountered in practical applications.