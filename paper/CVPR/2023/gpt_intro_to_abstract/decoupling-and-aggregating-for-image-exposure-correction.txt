Images captured under improper exposure conditions often suffer from under-exposure or over-exposure problems, resulting in contrast degradation and detail distortion. Existing methods primarily focus on contrast enhancement and struggle to efficiently restore high-frequency details. Some researchers propose decomposing images into lightness and structure components or using a coarse-to-fine strategy, but these approaches often lead to over-smoothing or artifacts. To address these issues, this paper introduces the Decoupling-and-Aggregating Convolution (DAConv) method, which decouples contrast enhancement and detail restoration during the convolution process. DAConv utilizes a Contrast Aware (CA) unit and a Detail Aware (DA) unit to guide the contrast and detail modeling explicitly. It also introduces dynamic coefficients to balance contrast enhancement and detail restoration. The proposed DAConv can effectively substitute the traditional convolution kernel in CNN-based exposure correction networks without introducing additional computational costs. The CA, DA, and dynamic coefficients are aggregated into a single kernel during the inference phase to further reduce computational costs. Evaluations on benchmark datasets and existing methods demonstrate the effectiveness of the proposed DAConv in improving contrast enhancement and detail restoration performance. The contribution of this paper includes the decoupling-and-aggregating scheme, the CA and DA units for feature extraction, and the improved performance without extra computational costs.