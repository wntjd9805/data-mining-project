In this paper, we address the problem of chronology reconstruction using Internet photos to build a 4D model of a scene. We revisit the previous work on Scene Chronology and propose a new approach that incorporates powerful neural scene representations inspired by methods such as NeRF in the Wild. However, existing neural reconstruction methods assume static scenes, which limits their effectiveness for scenes with ephemeral elements. We find that straightforward extension methods do not work well and introduce a novel encoding method for time inputs that can effectively model piece-wise constant scene content over time. Our proposed model disentangles transient changes from longer-term scene-level changes and allows for independent control of viewpoint, time, and illumination at render-time. We evaluate our method using a dataset of images from Flickr and show that it outperforms current state-of-the-art methods. Our work contributes to achieving photo-realistic chronology reconstruction and provides a benchmark dataset and code for further research in this area.