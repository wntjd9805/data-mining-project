3D object detection is a key technology for autonomous driving, allowing vehicles to better understand their surroundings and make critical decisions. LiDAR is an important sensing device in autonomous driving systems, collecting 3D measurements in the form of point clouds. However, the sparse and incomplete representation of point clouds poses challenges for 3D object detection. In this paper, we propose an efficient Motion-guided Sequential Fusion (MSF) method that leverages the continuity of object motion in sequences of point clouds to improve object detection. Instead of processing each frame individually, our method propagates proposals generated in the current frame to preceding frames based on object velocities, sampling reliable points-of-interest from the sequence. These points are transformed to proposal features and passed through a region-based network for refinement. We introduce a self-attention module to enhance interaction within proposals and a Bidirectional Feature Aggregation (BiFA) module to facilitate information exchange across frames. We optimize the point cloud pooling with a voxel sampling technique to improve efficiency. Our MSF method achieves leading accuracy on the Waymo Open Dataset with fast speed.