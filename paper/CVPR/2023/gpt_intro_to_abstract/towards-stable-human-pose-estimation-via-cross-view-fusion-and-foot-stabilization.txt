This paper focuses on the challenges of 3D pose estimation from a monocular RGB camera and presents a method for reducing the instability in estimation. The two main challenges identified are the inconsistency in pose performance from different perspectives and the inaccurate foot posture and foot-ground interaction. Most existing methods rely on holistic features extracted from the image, which do not explicitly model pose-related 3D features. In addition, predicting the SMPL parameters directly from these features is challenging due to the nonlinear mapping. The paper proposes a Cross-View Fusion module (CVF) that learns a fused 3D intermediate representation by supervision over three views: front, side, and top. This approach improves view consistency and outperforms other SMPL-based methods on 3D pose estimation. To address the challenge of foot stability, the paper introduces a multi-view optimization-based method to annotate foot-ground contact on public datasets. Additionally, a Reversible Kinematic Topology Decoder (RKTD) is proposed to adjust the predicted order of lower limb joints based on foot-ground contact. The proposed method achieves state-of-the-art performance on multiple 3D human pose estimation benchmarks and provides more stable and accurate pose estimations. The paper presents four main contributions: the Cross-View Fusion module for improved 3D pose estimation, the annotation of foot-ground contact on public datasets, the Reversible Kinematic Topology Decoder for dynamic joint prediction, and extensive experimental results demonstrating the effectiveness of the proposed method.