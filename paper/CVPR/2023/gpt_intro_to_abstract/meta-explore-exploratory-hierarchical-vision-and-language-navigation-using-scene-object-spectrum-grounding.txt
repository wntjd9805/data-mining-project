Visual navigation in indoor environments has been extensively studied, enabling agents to explore and navigate towards goals. With the development of vision-and-language navigation (VLN), robots can communicate with humans using natural language instructions. However, a challenging issue in VLN is when an agent makes a mistaken action, leading to incorrect paths. Existing methods address this issue through hierarchical exploration, but they often take a heuristic approach and do not fully utilize the constructed map. In this paper, we propose Meta-Explore, a hierarchical navigation method that allows the high-level planner to correct misled local movements and find unvisited states close to the global goal. Instead of backtracking, we introduce a more efficient exploitation method called local goal search. Additionally, we present a novel semantic representation of the scene called scene object spectrum (SOS), which provides meaningful clues for navigation. Experimental results on VLN benchmarks show that Meta-Explore improves success rates and SPL compared to baselines, demonstrating better generalization capabilities.