Camera calibration is a crucial component for various computer vision applications, particularly in 3D reconstruction and mapping, as well as spatial computing systems like autonomous driving and augmented reality. While camera extrinsics and pinhole model parameters can be easily optimized, other parameters, especially lenses, pose challenges. Camera lenses have a significant impact on image quality due to distortion and vignetting effects. Recent research suggests that end-to-end modeling and optimization of the image formation process leads to high-fidelity scene reproductions. However, modeling and optimizing lens parameters, especially in a differentiable manner, is difficult due to the diversity of lens types and optical effects. This paper aims to develop a flexible and differentiable lens model that approximates plausible distortions. The approach combines an invertible neural network (INN) with camera intrinsics and extrinsics to model ray distortion. The proposed lens model offers advantages such as integration into differentiable pipelines, scalability to different lens types, and compatibility with gradient-based methods for calibration. Additionally, a novel marker board and keypoint detector are suggested for pattern-based calibration, and a synthetic dataset called SynLens is introduced for large-scale lens benchmarking. The method is evaluated through qualitative and quantitative comparisons, demonstrating improved accuracy, robustness, and state-of-the-art performance in various calibration scenarios. The contributions of this research include the formulation and analysis of the INN-based lens distortion model, joint optimization of marker and keypoint detectors, the SynLens benchmark dataset, and integration into a neural rendering pipeline for photometric calibration.