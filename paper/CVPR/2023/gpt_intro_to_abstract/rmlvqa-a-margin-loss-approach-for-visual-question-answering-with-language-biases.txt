Our paper proposes a solution to address the language bias problem in Visual Question Answering (VQA) models. We introduce an instance-specific adaptive margin loss that allows for different margins based on the complexity of the samples, in addition to using frequency-based margins. To achieve this, we introduce a bias-injecting component that clusters samples based on the bias present in the dataset. We also propose ensembling the outputs of the bias-injecting component and the main model to overcome the in-domain/out-of-domain trade-off in margin-based losses. Additionally, we introduce a supervised contrastive loss to pull features of training samples with the same answers together, while pushing apart others. Through extensive experiments, we demonstrate that our approach achieves state-of-the-art results, especially on the out-of-domain VQA-CP v2 dataset, while maintaining competitive performance on the in-domain VQA v2 dataset. The code, hyperparameter analyses, and results on multiple datasets are provided as supplementary material.