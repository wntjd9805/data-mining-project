Neural Radiance Field (NeRF) has emerged as a powerful method for view synthesis in computer vision. While NeRF has shown great success in low- and middle-level vision tasks, its potential for high-level vision tasks remains unexplored. In this paper, we propose a neural semantic representation called Semantic Ray (S-Ray) that can learn and infer semantics across multiple scenes and viewpoints. Our approach utilizes a Cross-Reprojection Attention module to incorporate semantic information from multiple views efficiently. We decompose the attention into intra-view radial and cross-view sparse attentions to learn comprehensive relations. We evaluate our method on synthetic and real-world scenes and show that S-Ray outperforms existing baselines in learning semantic fields. Our work opens up possibilities for applying NeRF and its variants in high-level vision tasks with wide-ranging applications.