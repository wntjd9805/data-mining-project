This paper addresses the problem of Referring Expression Segmentation (RES), which aims to generate a segmentation mask for an object referred to in a language expression within an image. The authors recognize that the success of current methods in RES is due to the availability of large-scale training datasets with accurate pixel-level masks. However, labeling masks for a large number of images is costly and not feasible to scale up. Therefore, the authors propose a new partially supervised training paradigm for RES, called Partial-RES, where abundant bounding box annotations and only a few mask annotations are used. They explore the idea of training a Referring Expression Comprehension (REC) model and transferring it to the RES task through fine-tuning on a limited number of data with mask annotations. However, they observe that prevalent models designed for detection and segmentation tasks have issues in optimization when fine-tuned with a randomly initialized mask head using only a few mask annotations. To overcome these challenges, the authors propose a contour-based method called SeqTR, which uses a sequence model to generate contour points for the referred object. They show that SeqTR achieves better performance by unifying REC and RES tasks and optimizing them using a shared cross-entropy loss. Inspired by SeqTR, the authors introduce the Co-Content Teacher-Forcing (CCTF) training method, which combines ground truth point coordinates and spatial visual features for more accurate prediction. They also propose a Point-Modulated Cross-Attention mechanism to ensure that the decoder attends to the relevant regions while generating the point contour sequences. Additionally, the authors present a Resampling Pseudo Points (RPP) Strategy to fully utilize the data without mask annotations. The proposed approach is evaluated through extensive experiments, showing significant improvements compared to baseline methods on multiple benchmarks. The results indicate that the authors' method achieves high performance even with a small percentage of mask-labeled data, demonstrating its effectiveness and potential for practical applications in RES.