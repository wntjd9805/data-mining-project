Temporal Action Localization (TAL) is a critical task in video understanding, aiming to identify action instances and their categories in untrimmed videos. TAL has gained significant attention due to its wide range of applications. However, most existing methods for TAL require instance-level annotations, which limits their use in real-world scenarios. To overcome this limitation, Weakly-supervised Temporal Action Localization (WTAL) methods have been developed, which only rely on video-level labels. These WTAL methods often follow the Segment-based Multiple Instance Learning (S-MIL) framework, which has two main drawbacks: inconsistent objectives between training and testing stages, and difficulty in classifying individual segments. To address these issues, we propose a novel Proposal-based Multiple Instance Learning (P-MIL) framework. The P-MIL framework consists of a two-stage training pipeline that generates candidate proposals and classifies them into video-level scores. We also address three challenges within the P-MIL framework: focusing on discriminative short proposals, handling overcomplete candidate proposals, and learning robust relative scores. Our proposed framework outperforms existing methods in weakly-supervised temporal action localization, as demonstrated by extensive experiments on THUMOS14 and ActivityNet datasets.