Determining the relative camera pose between two images is a significant challenge in computer vision, with applications in various pipelines such as Structure-from-Motion, odometry, SLAM, and visual relocalization. While existing methods can often estimate an accurate fundamental matrix, failures still occur and their causes are not well understood. Traditional approaches rely on detecting and describing interest points, establishing correspondences, and using algorithms like RANSAC to rank and refine the hypotheses. However, these correspondence-based scoring methods are sensitive to the ratio of inliers, number of correspondences, and accuracy of keypoints, potentially leading to incorrect two-view geometry estimation. An alternative approach emerges, where neural networks are trained to directly regress two-view geometry. While promising, these approaches struggle with challenging scenarios such as wide-baseline or large illumination changes. In this paper, we propose the Fundamental Scoring Network (FSNet), which utilizes epipolar geometry to compare image features in a dense manner, without relying on correspondences for scoring in the RANSAC loop. FSNet leverages an attention layer to incorporate epipolar geometry and produce coherent fundamental matrix hypotheses. Our contributions include an analysis of scoring failures and insights into the traditional RANSAC approach, the development of FSNet to predict translation and rotation errors for a given image pair and fundamental matrix hypothesis, an image order-invariant design, and a solution that can be combined with state-of-the-art methods to address current failure cases.