This paper introduces a joint video multi-frame interpolation and deblurring method, called VIDUE, that addresses the challenge of unknown exposure time. The authors propose an adaptive computation approach, utilizing exposure-aware and motion-aware representations. They use supervised contrastive learning to extract the exposure-aware representation and train two U-Nets for intra-motion and inter-motion analysis. The U-Nets are adapted to the exposure-aware representation through gain tuning. A video reconstruction network with a U-Net-like structure is developed for exposure-adaptive convolution and motion refinement. Extensive experiments demonstrate that VIDUE produces high-quality deblurred and interpolated frames, outperforming state-of-the-art methods.