Semantic segmentation is a critical task in computer vision that has made significant progress with the advent of deep learning. However, models trained on one dataset often struggle to generalize to new datasets with novel classes, a phenomenon known as catastrophic forgetting. Incremental learning has been proposed as a solution to this problem, but existing methods for semantic segmentation require pixel-level annotations for new classes, which can be costly and time-consuming. In this paper, we introduce a novel framework called FMWISS (Foundation Model drives Weakly Incremental learning for Semantic Segmentation) that leverages pre-trained foundation models to improve the supervision given image-level labels. We propose pre-training based co-segmentation to generate dense masks by distilling category-aware and category-agnostic knowledge from pre-trained models. We utilize a teacher-student architecture with a dense contrastive loss to optimize the noisy pseudo labels obtained from the co-segmentation. Additionally, we propose memory-based copy-paste augmentation to address the forgetting problem of old classes. Our extensive experiments on Pascal VOC and COCO datasets demonstrate the effectiveness of FMWISS in achieving high-quality semantic segmentation results.