Lane detection is a crucial aspect of autonomous driving, as it provides valuable information for advanced navigation. This paper presents BEV-LaneDet, a real-time and efficient pipeline for 3D lane detection from a single image. Unlike previous methods that incorporate camera parameters into the network, BEV-LaneDet employs a Virtual Camera module that directly applies to the images, ensuring consistency of spatial relationships across different vehicles. The paper also introduces Key-Points Representation, a simple yet effective module for representing 3D lane structures. Additionally, a light-weight Spatial Transformation Pyramid based on MLP is proposed to transform front-view features to Bird's Eye View (BEV) features, enhancing the accuracy of 3D lane detection. Experimental results show that BEV-LaneDet outperforms state-of-the-art algorithms in terms of F-Score, with a significant improvement in speed. The contributions of this paper include the Virtual Camera module, the Key-Points Representation, and the Spatial Transformation Pyramid, which collectively enhance the performance and efficiency of 3D lane detection in autonomous driving.