Object detection is a crucial component of modern computer vision systems, particularly in applications such as robotics and self-driving cars. However, traditional object detection methods require large amounts of annotated data for training, which can be time-consuming and labor-intensive to collect. In the field of few-shot object detection (FSOD), which aims to learn to detect novel classes with limited data, researchers have attempted to leverage prior knowledge from abundant base data to rapidly learn new classes from small samples. While meta-learning and transfer learning approaches have shown success in FSOD, most methods focus on optimizing the detection performance of novel classes, potentially leading to catastrophic forgetting of the base classes and failures in real-life perception systems. To address this concern, generalized few-shot object detection (G-FSOD) has been introduced to jointly detect both base and novel classes. Previous approaches have attempted to balance the performance on base and novel classes, but relied on the availability of base data during the learning process. In this paper, we propose a new framework for G-FSOD that reduces forgetting without the need for base data storage. Our approach utilizes instance-level RoI head features to represent the distribution of base classes and trains a lightweight generator to synthesize class-wise base features for G-FSOD model training. Our contributions include the use of instance-level features instead of synthesizing images, the design of a standalone lightweight generator to capture feature distribution, the incorporation of class-aware heads for feature synthesis, and a significant reduction in memory footprint while achieving state-of-the-art detection performance on benchmark datasets.