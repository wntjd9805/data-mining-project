Optical flow estimation is a crucial task in computer vision for estimating per-pixel displacement between consecutive video frames. It provides valuable motion and correspondence information for various video applications, including video object detection, action recognition, and video restoration. The recent success of the transformer-based architecture in optical flow estimation, particularly in FlowFormer, suggests the potential of pretraining the cost-volume encoder to improve accuracy. In this paper, we propose a masked cost-volume autoencoding (MCVA) scheme to enhance the cost-volume encoding in FlowFormer. Inspired by the success of masked autoencoders in other domains, we address the challenges specific to optical flow estimation by introducing block-sharing masking and a novel pre-text reconstruction task. These designs encourage the cost-volume encoder to encode long-range information and reason about occluded information, resulting in more accurate flow estimation. Our experiments demonstrate the effectiveness of MCVA, as our proposed FlowFormer++ achieves state-of-the-art performance on public benchmarks, surpassing the performance of FlowFormer. Overall, this work contributes to advancements in optical flow estimation by improving the pretraining of the cost-volume encoder.