Human parsing is an important task in computer vision, contributing to various applications such as virtual try-on and human activity recognition. Previous methods have focused on developing powerful network architectures, but they often rely on specific labeling systems and do not effectively utilize data from multiple label domains. To address this issue, recent studies have proposed graph-based methods that learn semantic associations from different label domains. However, these methods have limitations in dynamically adding new label domains and have high inference costs. Therefore, there is a need for a more general, scalable, and simpler approach to leverage data from multiple label domains for human parsing. In this paper, we propose Scalable Semantic Transfer (SST), a novel training paradigm that embeds semantic associations from multiple label domains into a given parsing network. SST can be applied to both universal parsing, which learns homogeneous human representations from multiple domains, and dedicated parsing, which optimizes a network for a specific label domain. SST has several advantages, including generality, scalability, and simplicity. We introduce three plug-and-play modules in SST that incorporate prior knowledge of human body parts into the training process, and extensive experiments demonstrate the effectiveness of SST on both universal and dedicated parsing tasks.