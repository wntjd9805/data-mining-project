Object pose estimation is a fundamental challenge in computer vision and robotics, with various techniques proposed for different levels of pose estimation. Category-level object pose estimation is particularly important due to its broad applicability. Recent works have introduced methods for category-level pose estimation that are more efficient compared to instance-level methods, which rely on known 3D shape knowledge. However, fine-tuning models on target data for accurate pose estimation in real-world scenarios is expensive and impractical. To address this, unsupervised methods have been proposed, but they do not meet the requirements for online applications. In this paper, we propose Test-time Adaptation for Category-level Object Pose Estimation (TTA-COPE), a framework that automatically improves the network in an online manner without labeled target data. Our approach fine-tunes the network using unlabeled data and simultaneously performs pose estimation via inference. We do not use source data during test time, making our approach source-free. We compare our framework with existing unsupervised methods and demonstrate its effectiveness through extensive studies. Our TTA-COPE framework achieves state-of-the-art performance in category-level object pose estimation.