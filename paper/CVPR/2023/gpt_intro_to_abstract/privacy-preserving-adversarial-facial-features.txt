This paper presents a novel facial privacy-preserving method called AdvFace that aims to generate privacy-preserving adversarial features to defend against reconstruction attacks while maintaining face recognition accuracy. The method utilizes a shadow model to simulate the behavior of reconstruction attacks and generates adversarial features by obfuscating features with adversarial latent noise. The reconstruction loss is maximized during the generation process to disrupt the mapping from features to facial images. AdvFace requires no changes to the deployed face recognition model and can be integrated as a plug-in privacy-enhancing module. Experimental results show that AdvFace outperforms existing methods in terms of privacy protection performance with minimal face recognition accuracy loss. Additionally, AdvFace is capable of resisting different reconstruction networks.