Depth estimation from images is a crucial aspect of computer vision, enabling the acquisition of depth information for various applications. While active sensors like LiDAR can provide omnidirectional depth information, they are cost-prohibitive compared to passive sensors like RGB cameras. To address the limitations of traditional stereo cameras with pinhole lenses, fisheye lenses are often introduced to increase the field of view (FoV) in stereo vision setups. However, existing methods for depth estimation using fisheye cameras have their limitations, such as limited FoV or complexity in calibration. In this paper, we propose OmniVidar, a novel and simple multi-fisheye omnidirectional depth estimation system. We introduce a new camera model called Triple Sphere Camera Model (TSCM) that better approximates the imaging process and achieves higher accuracy. Additionally, we develop an epipolar rectification algorithm specifically designed for multi-fisheye camera systems, which solves the distortion issue and simplifies the depth estimation problem. Finally, we design a lightweight binocular depth estimation network based on RAFT and Transformer encoder, balancing accuracy and efficiency.We compare OmniVidar with existing methods on various datasets, and our results demonstrate that our approach outperforms others in terms of speed and accuracy, achieving state-of-the-art performance. This research contributes to the field of depth estimation using fisheye cameras and provides a more accessible and efficient solution for obtaining omnidirectional depth information.