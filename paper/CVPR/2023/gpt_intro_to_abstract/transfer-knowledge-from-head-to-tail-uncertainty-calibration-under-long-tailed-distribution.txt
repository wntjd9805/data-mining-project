In this paper, we address the problem of model calibration under a long-tailed distribution in image classification. Model calibration, or the ability of a model's confidence predictions to accurately reflect its performance, is crucial for safety-critical applications such as autonomous driving and medical diagnosis. However, most existing calibration techniques assume a balanced training data distribution, where each class has a similar number of instances, which may not hold true in real-world scenarios.We observe that when tested on balanced test data, classification models trained on long-tailed training data tend to be more over-confident towards head classes, which are the dominant classes in the dataset. Traditional calibration techniques struggle to achieve balanced calibration among head and tail classes, as the imbalanced training data distribution differs from the balanced test data. Even calibration methods like temperature scaling show overconfidence after calibration. Existing domain adaptation calibration methods, which rely on unlabeled target domain instances, or domain generalization calibration methods, which require extra instances, are also not applicable in the long-tailed calibration scenario.To tackle this problem, we propose a novel approach that utilizes importance weights to improve calibration for tail classes in a long-tailed distribution. The importance weight of each instance is calculated as the ratio between the target balanced probability density and the source imbalanced probability density. We explicitly model the distribution of each class as a Gaussian distribution and estimate the target probability density of each tail class by combining its own distribution and the transferred information from all head classes.Our main contributions are threefold: 1) We investigate the problem of calibration under long-tailed distribution, which has important practical implications but has been rarely studied. 2) We propose an importance weight estimation method that leverages the distributions of head classes as priors for tail classes to achieve balanced calibration. 3) We conduct extensive experiments on multiple datasets, including CIFAR-10-LT, CIFAR00-LT, MNIST-LT, and ImageNet-LT, to demonstrate the effectiveness of our method.Overall, our approach provides a reliable calibration method for deep neural networks trained on imbalanced datasets and shows promising results in improving model confidence estimates, especially for tail classes in a long-tailed distribution.