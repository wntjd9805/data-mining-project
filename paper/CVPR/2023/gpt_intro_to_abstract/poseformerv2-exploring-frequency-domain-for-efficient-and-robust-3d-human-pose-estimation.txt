This paper introduces the problem of 3D human pose estimation (HPE) using monocular videos or 2D human joint sequences. The use of 2D joint sequences for pose estimation has become dominant due to the availability of 2D human pose detectors and the memory-friendly nature of the 2D skeleton representation. Transformers, which have been successful in natural language processing and computer vision tasks, have also been applied to 3D HPE. However, there are practical concerns such as the computational cost of processing long joint sequences and the noise introduced by 2D joint detection. The paper raises two research questions: how to efficiently utilize long joint sequences and how to improve the robustness of the model against unreliable 2D pose detection. Previous works have addressed one of these questions, but not both simultaneously. The paper presents an initial attempt to address both questions by proposing a frequency-domain representation of input joint sequences, which removes the need for expensive all-frame self-attention and filters out high-frequency noise. The proposed approach, called PoseFormerV2, outperforms existing transformer-based methods in terms of speed-accuracy trade-off and robustness to 2D joint detection noise. Contributions include the utilization of frequency-domain representation, the design of a Time-Frequency Feature Fusion module, and achieving state-of-the-art results on benchmark datasets.