The rapid growth of visual data and the advancement of Deep Neural Network architectures have sparked renewed interest in unsupervised learning with visual data. Deep clustering, in particular, has seen significant progress in recent years. However, consensus clustering, which has been found to consistently improve performance over single clustering outcomes, remains underexplored in the context of deep clustering. Existing methods focus on producing a single clustering that matches the ground truth labels of the dataset, but fail to consider the benefits of ensemble clustering.Consensus clustering involves generating a set of base clusterings and applying a consensus algorithm to combine them. However, determining the properties that ensembles should have to produce better outcomes has been an open problem. Research has shown that inter-clustering diversity within the ensemble is desirable, along with individual clustering quality. Controlling diversity in ensembles is also crucial for studying its impact and determining the optimal level in each setting.While some methods exist to produce diverse clusterings, they either lack control over inter-clustering diversity or cannot be easily incorporated into Deep Learning frameworks. Additionally, existing methods often focus on orthogonal or independent attributes of simple visual data, which is not suitable for consensus clustering.To address these challenges, we propose DivClust, a method that efficiently generates multiple clusterings with diverse properties in deep clustering frameworks. DivClust incorporates a novel diversity loss component that controls inter-clustering similarity based on soft cluster assignments produced by the model. This approach ensures that the clusterings have the desired degree of diversity while minimizing computational cost and eliminating the need for hyperparameter tuning.Experiments on four datasets using three deep clustering methods demonstrate that DivClust effectively controls inter-clustering diversity without sacrificing the quality of the clusterings. Furthermore, the diverse base clusterings learned by DivClust outperform the base frameworks when combined using an off-the-shelf consensus clustering algorithm. Remarkably, DivClust maintains robust performance across various diversity levels and outperforms existing methods in most settings. This makes DivClust a valuable tool for improving the performance of deep clustering frameworks and studying the impact of diversity in deep clustering ensembles. In summary, DivClust offers a plug-and-play solution for controlling inter-clustering diversity in deep clustering frameworks with minimal computational cost.