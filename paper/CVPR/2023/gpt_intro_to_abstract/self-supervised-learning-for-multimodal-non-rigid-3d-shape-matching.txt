Matching 3D shapes is a challenging problem in computer vision and computer graphics. While deep learning approaches have shown promising results, they are often limited to specific types of 3D representations and require clean data. This paper proposes a self-supervised learning framework that can process both triangle meshes and point clouds for shape matching. The method utilizes the structural properties of functional maps for meshes and introduces a self-supervised contrastive loss for learning consistent feature representations for both modalities. The proposed method achieves accurate matchings for meshes and robustness for point clouds, outperforming existing unsupervised and supervised methods on benchmark datasets. The method also demonstrates cross-dataset generalization ability and extends the SURREAL dataset to include disconnected components in partial views.