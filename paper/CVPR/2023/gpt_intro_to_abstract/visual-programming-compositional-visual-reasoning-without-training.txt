This paper introduces VISPROG, a system that leverages large language models to tackle complex visual tasks by generating and executing visual programs from natural language instructions. VISPROG decomposes tasks into simpler steps that can be handled by specialized end-to-end trained models or other programs. It uses a range of modules, such as computer vision models, language models, and image processing subroutines, to perform each step. VISPROG improves upon previous methods by using a powerful language model and in-context examples to create complex programs without requiring extensive training. The system is highly interpretable, allowing users to verify program logic and inspect intermediate step outputs. The paper demonstrates the flexibility of VISPROG on four different tasks and highlights its impressive performance gains. Overall, the key contributions include the VISPROG system, its application to complex visual tasks, and the production of visual rationales for error analysis and instruction tuning.