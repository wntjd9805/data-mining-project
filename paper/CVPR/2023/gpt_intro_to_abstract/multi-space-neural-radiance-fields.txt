The introduction of the paper discusses the advancements and potential applications of Neural Radiance Fields (NeRF) and its variants in the field of neural rendering. NeRF represents scenes using continuous radiance fields stored by Multi-layer Perceptrons (MLPs) and renders novel views by integrating densities and radiance obtained from the MLPs. Various efforts have been made to enhance the NeRF method, including handling unbounded scenes, moving objects, and reconstructing from pictures in the wild. However, rendering scenes with mirrors remains a challenge for NeRF-like methods due to the lack of multi-view consistency caused by reflective surfaces. In this paper, the authors propose a novel multi-space NeRF-based method that automatically handles mirror-like objects in 360-degree high-fidelity scene rendering without the need for manual labeling. The approach treats the scene space as multiple virtual sub-spaces, and this multi-space decomposition allows for successful handling of complex reflections and refractions. The authors demonstrate the effectiveness of their approach using a newly constructed dataset and show significant improvements over existing baselines in terms of performance and compatibility. The main contributions of the paper include the proposal of a multi-space NeRF method, the design of a lightweight module for modeling reflection and refraction, and the creation of a dedicated evaluation dataset for scenes with complex reflections and refractions.