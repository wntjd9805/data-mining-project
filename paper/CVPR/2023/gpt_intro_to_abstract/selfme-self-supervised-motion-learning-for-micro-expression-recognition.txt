This paper introduces a novel framework for micro-expression recognition (MER) using self-supervised learning. Micro-expressions are subtle facial expressions that occur for less than 0.5 seconds and provide important cues for understanding human emotions. However, the small sample size of datasets poses challenges for MER, and existing methods often rely on hand-crafted features or traditional optical flow techniques. To overcome these limitations, the proposed framework, called SelfME, utilizes self-supervised learning to automatically extract facial motion for MER. The learned motion is visualized, and a symmetric contrastive vision transformer (SCViT) is developed to address the asymmetry in facial actions. Experimental results on benchmark datasets demonstrate that SelfME achieves state-of-the-art performance. The paper is organized as follows: Section 2 reviews related work, Section 3 describes the methodology, Section 4 presents experimental results, Section 5 discusses limitations and ethical concerns, and Section 6 concludes the paper.