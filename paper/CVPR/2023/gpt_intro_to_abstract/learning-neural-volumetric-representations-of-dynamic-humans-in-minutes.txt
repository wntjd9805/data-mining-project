Creating high-quality volumetric videos of human performers is valuable for various applications, such as immersive telepresence, video games, and movie production. However, existing methods for recovering these videos from sparse multi-view videos are time-consuming and computationally expensive, limiting their large-scale application. To address this issue, we propose a novel dynamic human representation that achieves a 100x speedup during optimization while maintaining competitive visual fidelity. Our representation utilizes a structured set of voxelized NeRF networks to efficiently depict the varying complexity of different parts of the human body. We also introduce a 2D motion parameterization technique to model non-rigid deformations, accelerating learning and reducing memory footprint. Experimental results demonstrate that our method significantly accelerates the optimization process while achieving high-quality rendering. Our contributions include the novel part-based voxelized human representation, the 2D motion parameterization scheme, and a 100x speedup in optimization compared to previous methods with competitive rendering quality.