Inverse rendering is a challenging problem in computer vision, aiming to decompose captured images into multiple intrinsic factors such as geometry, illumination, and material. This decomposition enables various applications like relighting, material editing, and object manipulation. In this paper, we focus on the inverse rendering of translucent objects, which are characterized by SubSurface Scattering (SSS). SSS involves the penetration of photons into the object and their multiple bounces before being absorbed or exiting at a different surface point, making inverse rendering extremely ill-posed. To address this complexity, we assume homogeneous subsurface scattering and aim to estimate the shape, spatially-varying reflectance, SSS parameters, and environment illumination of a translucent object. However, a well-known challenge in inverse rendering is the ambiguity problem, where the final appearance of an object is influenced by a combination of illumination, geometry, and material. We classify solutions to this problem into two groups: those that provide more information to the model and those that rely on assumptions and simplifications. Existing works often simplify the SSS or reflectance model, which limits their applicability to real-world translucent objects. In this paper, we propose a framework that considers both surface reflectance and SSS of translucent objects under an environment illumination. We employ a deep neural network for parameter estimation and use two differentiable renderers to re-render the scene based on estimated parameters. Additionally, we introduce an augmented loss to enhance the supervision of the neural renderer and adopt a two-shot setup to handle the unpredictable effects of saturated highlights. To train our model, we construct a large-scale synthetic dataset of translucent scenes. Overall, our contributions lie in addressing the simultaneous estimation of shape, reflectance, SSS, and illumination for translucent objects, incorporating a physically-based and a neural renderer, proposing an augmented loss, and creating a synthetic dataset for training.