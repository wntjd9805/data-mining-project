This paper aims to build a computer vision system that can group held objects, recognize contact, and group non-held objects, similar to human visual understanding. The system utilizes optical flow, 3D geometry, and per-pixel human masks to associate objects with hands. The researchers demonstrate that discriminative training on simple pseudo-labels generated by epipolar geometry produces strong feature representations that can be used to solve hand-held object-related tasks. The paper also discusses the importance of understanding hands and the objects they hold, as well as the limitations of existing methods that rely on extensive annotation efforts. The proposed approach predicts grouping and hand association properties using optical flow, epipolar geometry, and person masks, and achieves strong performance on egocentric data sets. Experimental results show significant improvements in object segmentation and distance estimation, as well as promising outcomes in upgrading bounding-box annotations to segments and instance segmentation.