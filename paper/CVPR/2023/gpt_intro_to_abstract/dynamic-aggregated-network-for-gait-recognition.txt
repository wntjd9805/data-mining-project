Abstract:Gait recognition is a challenging task in fine-grained label classification, with applications in social security, video surveillance, crime investigation, and more. This paper addresses the problem of learning robust features for gait recognition, considering the limitations of silhouette data and the impact of external factors. The proposed approach consists of two main components: the Local Conv-Mixing Block (LCMB) and the Global Motion Patterns Aggregator (GMPA). The LCMB extracts representative local motion patterns by encoding the features of each pixel into the complex domain and aggregating them in neighboring regions. The GMPA dynamically selects discriminative local motion patterns using a self-attentive mechanism and aggregates them to obtain a robust global representation. Experimental results on various datasets demonstrate the effectiveness of the proposed method, outperforming the state-of-the-art approaches. This work contributes by proposing novel components for gait recognition and exploring the potential of self-attention models in this task.