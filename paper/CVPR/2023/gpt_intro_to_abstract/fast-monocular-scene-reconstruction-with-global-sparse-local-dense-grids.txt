Reconstructing indoor spaces into 3D representations is crucial for various real-world applications, including robot navigation, virtual/augmented reality experiences, and architectural design. Monocular cameras, which are widely accessible, are particularly useful for this task. However, conventional monocular reconstruction methods are time-consuming and struggle to handle larger scenes. Recent advancements in neural radiance fields and neural implicit representations have improved surface reconstruction accuracy but still face challenges with large-scale scenes. In this paper, we propose a novel approach that utilizes an explicit signed distance function (SDF) voxel grid, which allows for efficient query and sampling. We address the challenges of implementing a differentiable data structure through a globally sparse and locally dense voxel grid. Additionally, we incorporate monocular depth and semantic priors to refine the reconstruction further. Our method achieves similar reconstruction results as state-of-the-art techniques but with significantly faster training and inference times. We present a fast monocular scene reconstruction system equipped with volume rendering and high-dimensional continuous Conditional Random Fields (CRFs) optimization. Our contributions include the development of a novel data structure, a calibration algorithm for geometric initialization, and a fast and accurate monocular scene reconstruction system.