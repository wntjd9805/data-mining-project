Artificial neural networks often suffer from catastrophic forgetting, where they struggle to retain previously learned knowledge when learning new information. Previous methods have attempted to address this issue, but they rarely consider the underlying geometry of the data. In many applications, data exhibits non-Euclidean geometric structures that cannot be effectively processed using Euclidean geometry. This paper aims to study the use of suitable non-Euclidean geometry to capture the intrinsic geometric structures of data during continual learning. The authors identify two challenges in achieving this goal: the increasing complexity of intrinsic geometric structures in a non-stationary data stream, and the inaccessibility of old data in continuous learning. To address these challenges, they propose a method that uses a mixed-curvature space to model the non-Euclidean geometry of the data. Two loss functions are introduced to preserve global and local structures in the data. The method is evaluated in various continual learning settings and experimental results demonstrate its effectiveness. Overall, this paper makes three contributions: it explores data geometry for continual learning, introduces an incremental search scheme to identify suitable geometry, and proposes angle-regularization and neighbor-robustness losses for preserving geometric structures in the mixed-curvature space.