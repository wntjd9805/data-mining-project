Deep neural networks have achieved remarkable success in various tasks, but they are still vulnerable to catastrophic forgetting, where the model's performance on old tasks deteriorates while learning new ones. This issue poses a significant challenge in continual learning scenarios, where models are trained on a sequence of tasks with limited access to old training data. Continuous learning without forgetting is crucial in real-world applications such as computer vision, intelligent robotics, and natural language processing. However, training on old data is often restricted due to storage limitations, scaling of training time, or privacy concerns.Various methods have been proposed to address the continual learning problem, including experience replay, parameter regularization, knowledge distillation, and architectural techniques. These methods aim to strike a balance between learning new knowledge and retaining old knowledge. In this paper, we focus on knowledge distillation in feature space and propose a continual learning algorithm that uses the old checkpoint of the model as a teacher to regularize network intermediate outputs and reduce forgetting.While existing knowledge distillation methods have been effective in reducing forgetting, they enforce a strict distance-based similarity constraint, making the learning process more rigid in retaining old knowledge but less flexible in adapting to new tasks. To overcome this limitation, we introduce the Backward Feature Projection (BFP) loss, which allows for feature consistency up to a learnable linear transformation instead of exact equality. This transformation aims to preserve the linear separability of features backward in time and enables the learning of new features to accommodate new classes.Our experiments on the Split-CIFAR10 and Split-CIFAR100 datasets demonstrate that integrating the BFP regularization loss into existing continual learning methods improves their performance by up to 6%-8%. Furthermore, linear probing experiments show that BFP creates a better feature space with improved class separability. In summary, our contributions include an analysis of feature space evolution during continual learning, the proposal of the BFP loss for preserving old class separability while allowing plasticity, and the demonstration of improved performance on challenging datasets when combined with experience replay baselines.