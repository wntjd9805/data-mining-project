The creation of virtual humans requires both accurate hand motion capture and realistic hand appearance. However, existing methods face a dilemma, as motion capture techniques using markers degrade hand appearance, while markerless appearance capture makes hand motion tracking difficult. In this paper, we propose a win-win solution to address this challenge. We introduce a semi-supervised framework that enables degraded images in marker-based motion capture to regain their bare appearance. Our framework consists of a powerful Vision Transformer (ViT) sketcher that disentangles the bare hand structure without relying on parametric models, and an adversarial scheme that effectively promotes the wrapping of degraded-to-bare appearance. We also present a novel dual adversarial discrimination (DAD) scheme that enables dual discrimination in the translation task. Our contributions include the development of a semi-supervised framework, a ViT sketcher, and an adversarial scheme for degraded-to-bare appearance wrapping. The codes for our framework will be made publicly available.