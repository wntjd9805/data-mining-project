Reconstructing 3D models of unknown objects from multi-view images is a popular problem in computer vision. This paper focuses on in-hand object scanning, which involves capturing multiple views of an object by either moving the camera around a static object or turning the object in front of the camera. Existing 3D reconstruction methods rely on neural representations, which provide accurate dense reconstructions even in non-Lambertian conditions and without prior knowledge of the object shape. However, these methods assume that camera poses are known, making them unsuitable for in-hand scanning. This paper proposes a method for in-hand object scanning from an RGB image sequence without knowledge of camera-object relative poses. The method utilizes a neural representation that captures both geometry and appearance, allowing for the reconstruction of poorly textured objects. Unlike previous methods, this paper simultaneously optimizes the object model and camera trajectory without assuming known camera poses. The proposed method uses an incremental optimization approach and experiments demonstrate its ability to reconstruct textured and texture-less objects. The method outperforms existing methods, including COLMAP and a single-image based reconstruction method. The real-world applicability of the method is also demonstrated by scanning an object with ARIA glasses.