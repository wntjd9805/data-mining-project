Talking head generation has become increasingly popular in various applications, such as live chat, virtual reality, and video games. In this paper, we focus on synthesizing a realistic talking head using only a single source image. While previous works have made progress in neural rendering techniques, preserving the identity of the person in the synthesized image remains a challenge. Existing methods mainly rely on learning a geometry-aware warping field, but they may not accurately capture the fine-grained facial geometry. To address these limitations, we propose two improvements. First, we argue that dense facial landmarks are more suitable for accurate warping field prediction. We adopt a landmark prediction model trained on synthetic data, which provides richer information on facial geometry. Additionally, we enhance the perceptual identity by attentively fusing the identity feature of the source portrait while retaining the pose and expression of the intermediate warping. Our one-shot model outperforms previous methods in terms of both image quality and perceptual identity preservation.However, synthesizing a talking head in a one-shot setting is inherently ill-posed, which may result in uncanny valley effects. To overcome this challenge, we propose to achieve fast personalization using meta-learning. By finding an easily adaptable initialization model and fine-tuning it with limited training iterations, we can train a personal model within 30 seconds, significantly faster than traditional methods that require several minutes of personalized training.Furthermore, we introduce a novel temporal super-resolution network to enhance the resolution and details of the generated talking head video. By leveraging generative priors and considering adjacent frames, we achieve temporally coherent video results with compelling facial details.In summary, our work improves the identity-preserving capability of one-shot talking head synthesis, explores the use of meta-learning for accelerated personalized training, and introduces a novel video super-resolution model without temporal flickering.