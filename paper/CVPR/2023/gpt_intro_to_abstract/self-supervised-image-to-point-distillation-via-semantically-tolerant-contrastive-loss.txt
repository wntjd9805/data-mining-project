Self-supervised learning (SSL) has been successful in learning representations from unlabeled images, but generating labels for 3D point clouds is more challenging. This paper introduces a novel approach to address the difficulties of self-supervised learning for 3D representations and imbalanced datasets in autonomous driving. The proposed approach includes a semantically-tolerant loss that considers the semantic distance between positive and negative samples and a class-agnostic balanced loss that weights the contribution of each 3D region based on aggregate semantic similarity. The experimental results demonstrate that the proposed approach improves the performance of 2D-to-3D representation learning frameworks on various tasks.