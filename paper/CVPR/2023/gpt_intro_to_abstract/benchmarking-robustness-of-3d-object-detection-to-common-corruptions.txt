The paper introduces the task of 3D object detection in autonomous driving, where the goal is to identify objects of interest in the surrounding environment. Two important sensors for object detection are LiDAR, which provides depth information as point clouds, and cameras, which capture semantic information as color images. The paper categorizes 3D object detection models into LiDAR-only, camera-only, and LiDAR-camera fusion models. The paper highlights the importance of assessing the robustness of these models under diverse circumstances before deployment in safety-critical autonomous driving scenarios.The existing models based on data-driven deep learning approaches often struggle to generalize to corrupted data caused by adverse weather conditions, sensor noises, and uncommon objects. To evaluate robustness, the paper discusses the construction of new datasets for road anomalies and extreme weather conditions, but notes that these datasets are small in size due to high collection costs. Other works synthesize corruptions on clean datasets, but they only consider simple corruptions, which may not be realistic for 3D object detection. Therefore, there is a need for a comprehensive framework to evaluate corruption robustness considering diverse driving scenarios.To address this gap, the paper systematically designs 27 types of common corruptions for both LiDAR and camera sensors. These corruptions are grouped into weather, sensor, motion, object, and alignment levels, covering real-world corruption cases. Each corruption has five severities, resulting in a total of 135 distinct corruptions. By applying these corruptions to popular autonomous driving datasets, the paper establishes corruption robustness benchmarks.The paper conducts large-scale experiments comparing the corruption robustness of existing 3D object detection models. The evaluation results show that corruption robustness is highly correlated with clean accuracy. Motion-level corruptions have the largest impact on model performance but have been rarely explored before. LiDAR-camera fusion models tend to be more resistant to corruptions, but there is a trade-off between robustness under image and point cloud corruptions. The paper also investigates data augmentation strategies but finds limited robustness gain. Overall, the enhancement of corruption robustness in 3D object detection remains an open problem for future research.