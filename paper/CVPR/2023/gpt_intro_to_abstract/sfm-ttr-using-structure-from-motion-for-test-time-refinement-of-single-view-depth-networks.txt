Obtaining accurate and dense depth maps from images is a challenging problem with wide-ranging applications in fields like robotics, augmented reality, endoscopy, and autonomous driving. Single-view depth estimation is particularly difficult due to its geometric ill-posed nature. However, recent research on deep models has shown promising results for this task. Initially, single-view depth learning was approached as a supervised learning problem, training deep networks using image collections annotated with ground truth depth. Research in this area continues to improve the accuracy of single-view depth estimates. In addition to improving the learning side of the problem, researchers are also incorporating single- and multi-view geometric concepts into depth learning, expanding its capabilities to handle more general setups. This integration naturally connects depth learning with classic research on Structure from Motion (SfM), visual odometry, and visual SLAM. Our work focuses on using SfM to refine single-view depth networks at test time, leveraging the accuracy of SfM reconstructions. While many existing approaches incorporate multiple views or photometric losses for refinement, our method solely relies on SfM reconstruction for test-time refinement (SfM-TTR). Our results demonstrate that SfM-TTR outperforms other state-of-the-art supervised and self-supervised baselines, providing state-of-the-art results for test-time refinement.