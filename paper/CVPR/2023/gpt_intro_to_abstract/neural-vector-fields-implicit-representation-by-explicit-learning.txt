The task of reconstructing continuous surfaces from unstructured, discrete, and sparse point clouds is challenging in robotics, vision, and graphics applications. Deep Neural Networks (DNNs) have shown promising results in surface reconstruction, with explicit and implicit representation methods being commonly used. Explicit representation methods provide precise surface location information but suffer from limitations in resolution and topology. Implicit representation methods, such as Occupancy and Signed Distance Functions (SDFs), can represent surfaces with complex topology but require pre-processing and suffer from gradient ambiguities. In this paper, we propose a novel 3D representation method called Neural Vector Fields (NVF), which combines the advantages of explicit and implicit approaches. NVF represents surfaces as vector fields and directly manipulates meshes while maintaining arbitrary resolution and topology. Our representation avoids complex inference processes, reduces ambiguity, and allows for the learning of a shape codebook for improved generalization and training efficiency. We evaluate NVF on benchmark datasets and demonstrate its superiority in terms of inference time, generalization, and reconstruction performance across different scenarios. Our contributions include the proposal of a novel 3D representation method and the introduction of a learned shape codebook using VQ strategy to enhance performance and generalization. Experimental results validate the effectiveness of our proposed method in various reconstruction tasks.