Motion blur artifacts can occur when the camera's shutter speed is slower than the object's motion. In this paper, we study the image capturing process, specifically the camera shutter opening to allow light to pass to the camera sensor. We present a formulation of this process and propose a method to tackle the order ambiguity issue in frame sequences. We map the frame sequences into a high-dimensional space to make them separable and define the order based on which side of the hyperplane they fall on. Image deblurring is a task aimed at removing blur artifacts and improving image quality. Existing methods often approach deblurring as an image-to-image mapping problem, seeking one sharp image for a given blurry input image. However, in many applications, a blurry image corresponds to a sequence of sharp images. We introduce the task of image-to-video deblurring, or blur2vid. This task requires learning a set of deblurring mapping functions to approximate the sharp images in the sequence. We propose a naive approach to minimize the squared difference between the predicted sharp image and the ground truth target. Additionally, we build a new dataset for image-to-video deblurring, covering street, face, and hand categories, which is the first large-scale dataset for this task. We also demonstrate two potential real-world applications of image-to-video deblurring.