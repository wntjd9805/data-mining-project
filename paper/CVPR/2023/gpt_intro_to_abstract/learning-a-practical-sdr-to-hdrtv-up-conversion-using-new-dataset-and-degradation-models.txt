The dynamic range of images, which refers to the difference between the maximum and minimum luminance values, plays a crucial role in enhancing the expressiveness of scenes. High dynamic range (HDR) technology, combined with advanced electro-optical transfer functions and wide color-gamut RGB primaries, has gained popularity in the media and film industry. However, the conversion of standard dynamic range (SDR) content to HDR is a challenging task due to the lack of available HDR footage and the imperfections introduced by old imaging systems and transmission. Existing learning-based methods for SDR-to-HDRTV up-conversion have shown limited success, producing dim and desaturated results when applied to real SDR images. This paper addresses the limitations of current methods by focusing on the impact of the training set on the performance of the network. The authors propose a new HDRTV4K dataset consisting of high-quality and diverse HDRTV frames as labels, along with three new HDR-to-SDR degradation models that preserve appropriate degradation capabilities. The task is tackled through a Luminance Segmented Network (LSN) that combines global mapping and recovery of the low and high luminance ranges. Additionally, the authors introduce fine-grained metrics and subjective experiments to assess the quality of the HDR reconstruction. The contributions of this work include highlighting the importance of the dataset in the SDR-to-HDRTV task, exploiting novel datasets and degradation models, and introducing a novel luminance segmented network approach.