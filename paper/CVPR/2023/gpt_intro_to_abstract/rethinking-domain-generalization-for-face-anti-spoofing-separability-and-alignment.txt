Face recognition (FR) has been widely used in mobile access control and electronic payments. However, FR systems are vulnerable to presentation attacks (PAs) such as print attacks, digital replay, and 3D masks. Anti-spoofing techniques have been developed to address this issue. Early methods focused on closed-world scenarios with limited variations. However, real-world applications, like mobile face unlock, involve wider angles, complex scenes, and different devices, leading to domain gaps between training and test data. Cross-domain face anti-spoofing (FAS) solutions aim to tackle these domain gaps. One approach is to learn domain-invariant representations, which has been applied in generic domain generalization. Adversarial training and metric learning are commonly used in these methods. However, these methods make unrealistic assumptions about perfect domain invariance and suffer from ambiguity when domains are mixed together. In this paper, we propose a new approach called FAS with separability and alignment (SA-FAS). Instead of removing the domain signal, we aim to maintain it and design the feature space based on separability and alignment. We use Supervised Contrastive Learning (SupCon) to encourage separability and a novel Projected Gradient optimization strategy based on Invariant Risk Minimization (PG-IRM) to achieve alignment. Our method achieves state-of-the-art performance on cross-domain FAS benchmarks and provides insights into the benefits of separability and alignment.