Federated learning (FL) is a distributed learning paradigm in large-scale machine learning where each client learns a model with its local data, and a centralized model is obtained by aggregating the updates from all clients, ensuring user privacy. However, federated learning faces challenges in handling data heterogeneity across clients and minimizing communication costs. The widely used FedAvg scheme tends to achieve subpar accuracy and convergence when the data is heterogeneous. To address this, we propose the FedPVR framework, which aligns the classification layers across clients using variance reduction. We experimentally show that FedPVR achieves comparable or better accuracy than existing methods while requiring fewer communication rounds. Furthermore, we prove convergence rates and demonstrate the algorithm's communication efficiency across various levels of data heterogeneity, datasets, and neural network architectures. In some cases, FedPVR even outperforms centralized learning.