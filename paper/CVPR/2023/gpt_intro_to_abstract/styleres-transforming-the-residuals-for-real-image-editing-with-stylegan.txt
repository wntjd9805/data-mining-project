Generative Adversarial Networks (GANs) have been successful in synthesizing high-quality images that are indistinguishable from real images. These networks also organize their latent space in a meaningful way, allowing for attribute manipulation through latent editing. While GANs have shown promise in image attribute editing for both generated and real images, finding the corresponding latent code for a given real image remains a challenge. Several GAN inversion methods have been proposed to address this issue, but there is still a trade-off between image reconstruction fidelity and image editing quality.This trade-off, known as the distortion-editability trade-off, is crucial for real image editing. Low-rate latent spaces have limited expressive power, resulting in lower fidelity reconstruction. Higher bit encodings and more expressive style spaces have been explored to improve reconstruction fidelity, but this often leads to a decrease in editing quality because the projected codes do not naturally align with the generator's latent manifold.In this paper, we present a framework that achieves high-fidelity input reconstruction and improved editability compared to existing methods. Our approach involves learning residual features in higher-rate latent codes that are missing in the reconstruction process. By reconstructing image details and background information using these residual features, which are difficult to capture with low rate encodings, we are able to preserve important details when editing low-rate latent codes.Our framework is a single-stage architecture that learns the residuals based on encoded features from the encoder and generated features from pretrained GANs. Additionally, we introduce a module that can transform the higher-latent codes when necessary, such as when low-rate codes are manipulated. To guide the network in learning correct transformations based on the generated features, we train the model using adversarial loss and cycle consistency constraint. During training, we simulate edits by randomly interpolating latent codes to ensure our method is not limited to predefined edits.We compare our approach to the state-of-the-art method, HFGI, and demonstrate superior editing quality in attribute manipulations, as shown in Figure 1. Our contributions include proposing a single-stage framework with a novel encoder architecture that achieves high-fidelity input embedding and editing, as well as employing cycle consistency and adversarial losses to guide image projection during editing. Through extensive experiments, we show the effectiveness of our framework and achieve significant improvements over existing methods for both image reconstruction and real image attribute manipulations.