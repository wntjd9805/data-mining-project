The computer vision and machine learning communities have long been pursuing human-centric perception. This includes various research tasks and applications such as person ReID, human parsing, pose estimation, and pedestrian detection. While significant progress has been made, most existing studies and pipelines are task-specific, resulting in high costs for representation/network design, pretraining, parameter tuning, and annotations. To address this, the authors propose the development of a general human-centric pre-training model that can be efficiently adapted to downstream tasks. They argue that such models are possible due to the correlations among different human-centric tasks and the flexibility of large-scale deep neural networks. However, there are two main obstacles to developing these models: the lack of a benchmark for comparing pretraining methods across multiple human-centric tasks, and the need to learn both global and fine-grained semantic features of human bodies simultaneously. To overcome these obstacles, the authors introduce a benchmark called HumanBench, which includes diverse images and evaluates pretraining models on six tasks. They also propose a projector-assisted hierarchical weight-sharing method called PATH for pretraining general human-centric representations. The authors demonstrate the effectiveness of their approach on the HumanBench dataset, achieving state-of-the-art results on multiple downstream tasks. They hope that their work will contribute to future research on pretraining human-centric representations.