This paper discusses the challenges faced in mapping and localization for autonomous robots in large-scale environments. While algorithms using sensors like cameras and lidar work well in small-scale environments, they become time and memory consuming when applied in larger and longer-term scenarios. The paper focuses on visual simultaneous localization and mapping (SLAM) using cameras, where redundant features are extracted from images and constructed as landmarks in a map. However, as more images are received, memory consumption increases and localization becomes more time-consuming. Not all landmarks are necessary for localization, and the paper explores the idea of compressing maps while maintaining comparable performance. Map compression can be achieved through descriptor compression or landmark sparsification, and this research focuses on the latter. A compact map is selected as an optimal subset of landmarks, minimizing their number while ensuring localization performance. The paper discusses the K-cover problem related to map sparsification and proposes a linear formulation for selecting uniformly distributed landmarks, considering their association with mapping images and their visibility in 3D space. The proposed methods are shown to be efficient and effective through experiments on different datasets.