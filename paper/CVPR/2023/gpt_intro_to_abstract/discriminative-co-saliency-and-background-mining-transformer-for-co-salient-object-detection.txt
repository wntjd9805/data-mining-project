Co-Salient Object Detection (CoSOD) is a task that aims to detect common salient objects across a group of relevant images, which presents challenges in terms of detecting both the foreground (co-salient objects) and the background accurately. Previous works have focused on mining foreground cues but neglected explicit exploration of the background, limiting their discriminative learning capability. In this paper, we propose a bivariate FG&BG modeling paradigm that explicitly models both foreground and background information. We introduce computationally economical multi-grained correlation modules to model inter-image and intra-image relations, allowing for more sophisticated relation modeling while reducing computational burdens. We also propose a Token-Guided Feature Refinement module to enhance the discriminability of segmentation features between co-saliency and background regions. Experimental results demonstrate that our approach achieves state-of-the-art performance on three benchmark datasets.