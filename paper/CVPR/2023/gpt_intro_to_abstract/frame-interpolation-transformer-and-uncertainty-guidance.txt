Video frame interpolation (VFI) is a fundamental problem in video processing that aims to generate intermediate frames in a given video sequence. Various practical applications, such as video editing, novel-view synthesis, video retiming, and slow motion generation, rely on temporal inbetweening. While recent advancements in VFI methods have enhanced interpolation quality, the presence of complex lighting effects and large motion in real-life videos still pose challenges and lead to artifacts in existing methods.To address these issues, we propose a transformer-based VFI architecture that operates on both source and target frames within a unified framework. This architecture incorporates optical flow estimation and cross-backward warping to accurately compensate for motion. Our model surpasses the current state-of-the-art in terms of interpolation quality, as demonstrated by extensive quantitative experiments and a user study.In addition to improved results, our model also predicts interpolation uncertainty, which is crucial for identifying problematic frames, particularly when working with long video sequences in a production context. The estimation of uncertainty aligns with approaches used in artifact detection and adaptive sampling. This uncertainty estimation is also beneficial for computer graphics (CG) applications, as it allows us to determine which frame patches lack sufficient quality and mark them for rendering. By leveraging our transformer-based model, we can seamlessly integrate the rendered patches into the same unified VFI framework, achieving high-quality results at a significantly reduced cost compared to rendering the entire intermediate frame. Our approach is more compatible with current production renderers, compared to CG specialized VFI works that necessitate the generation of specific G-buffers for keyframes and the intermediate frame.In summary, our contributions are threefold. Firstly, we introduce a novel motion-based VFI method that treats input and target frames uniformly through a transformer-based architecture with masks. Secondly, our model achieves state-of-the-art performance, as demonstrated by quantitative experiments and a user study. Finally, we address the subtask of uncertainty estimation, which is valuable for improving the quality of rendered content.