This paper introduces a novel Anchor-based Transformer architecture, called AnchorFormer, for point cloud completion. Point clouds, which describe various attributes of real-world objects, often suffer from geometric information loss and incompleteness. Previous works on point cloud completion have mainly relied on encoder-decoder architectures, which may lead to the loss of fine-grained details and limit the capability of global features. In contrast, AnchorFormer reconstructs object shape using discriminative nodes called anchors, which indicate the local geometry of different patterns in an object. Anchors are derived from the input partial observation using self-attention and can effectively infer key patterns and represent missing parts. The proposed architecture consists of downsampling, feature extraction, transformer encoding, anchor prediction, refinement, and morphing stages. The architecture is optimized based on the Chamfer Distance and compactness constraint. Extensive experiments demonstrate the effectiveness of AnchorFormer in reconstructing shape and improving point cloud completion.