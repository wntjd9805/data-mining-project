Segmenting internal structures from medical images is crucial for various clinical applications. Supervised learning techniques for medical image segmentation have been proposed, but they require a large amount of labeled data. However, manual contouring for labeling medical images is tedious and expensive. As a result, semi-supervised segmentation methods have gained attention in recent years. In semi-supervised medical image segmentation, there is often an empirical distribution mismatch between a small amount of labeled data and a large amount of unlabeled data. This mismatch makes it challenging to estimate the precise distribution of the entire dataset using only the labeled data. Existing methods attempt to train labeled and unlabeled data symmetrically, but they still struggle to address the distribution mismatch issue. This paper proposes a method called Bidirectional Copy-Paste (BCP) that aligns the empirical distributions of labeled and unlabeled features. BCP improves the performance of medical image segmentation by decreasing the performance gap between labeled and unlabeled data. Experimental results on three popular datasets demonstrate that BCP outperforms state-of-the-art methods by a significant margin, even with a small amount of labeled data. The proposed method is computationally efficient and does not introduce additional parameters for training.