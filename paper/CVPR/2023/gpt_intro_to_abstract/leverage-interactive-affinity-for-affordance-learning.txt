The objective of this paper is to propose a method for affordance learning, which involves perceiving and reasoning about an object's interactable regions for active interaction in intelligent systems. Previous approaches have focused on mapping appearances to labels for affordance learning, but they often ignore the multiple possibilities brought about by changes in the environment and actors. Reinforcement learning approaches have been used, but they are limited in their cost and lack generalization to unseen scenarios. Other methods use human demonstration, but they only provide a rough segmentation of the object/interaction regions. In this paper, the authors propose leveraging interactive affinity for affordance learning, specifically extracting interactive affinity from human-object interactions and transferring it to non-interactive objects. Interactive affinity refers to the contacts between different human body parts and objects' local regions, which can provide cues of interconnectivity. However, this approach faces challenges of interaction diversities and contact occlusions. Thus, the authors propose using the association between pose keypoints to overcome these difficulties. Additionally, the context between different body part contact regions is considered to explore associations between interactable regions in different images.To evaluate their proposed method, the authors construct a dataset called Contact-driven Affordance Learning (CAL) consisting of images from multiple affordance and object categories. Experimental results on the CAL dataset demonstrate the effectiveness of their method in addressing the multiple possibilities of affordance. The contributions of this paper include proposing the use of interactive affinity for affordance learning, introducing a pose-aided interactive affinity learning framework, and providing a CAL benchmark dataset for future research in affordance learning.