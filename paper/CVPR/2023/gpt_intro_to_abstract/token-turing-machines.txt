Processing long, sequential visual inputs in a causal manner is a fundamental challenge in robotics and computer vision applications, such as human activity recognition and robot action policy learning. Recurrent neural networks (RNNs) and Transformer models have been used to handle variable sequence lengths, but these models are not efficient for streaming or sequential inference problems. To address this, we propose Token Turing Machines (TTMs), an auto-regressive model with external memory and constant computational time complexity. Inspired by Neural Turing Machines (NTMs), our model leverages Transformers and a token summarization module to enable efficient fusion of past observations with current ones. Unlike the complex NTM, our TTM is simple to implement and train. We demonstrate the effectiveness of our approach in online temporal action detection and vision-based robot action policy learning, achieving significant improvements over strong baselines. Our model enables scalable, real-time, online inference with constant computational cost, making it suitable for practical applications.