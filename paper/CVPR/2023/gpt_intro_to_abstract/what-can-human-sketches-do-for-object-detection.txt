Sketches have been used throughout history as a means for humans to express and record ideas. Their level of expressiveness remains unmatched even in comparison to language. This paper aims to explore the potential of using sketches for the task of object detection. Specifically, the goal is to develop a sketch-enabled object detection framework that can detect objects based on the user's sketch, allowing for instance-aware and part-aware detection. Rather than creating a new model from scratch, the authors propose leveraging existing models and techniques, such as CLIP and sketch-based image retrieval (SBIR), to solve the problem. By adapting CLIP to build sketch and photo encoders and aligning the region embeddings of detected boxes with sketch and photo embeddings from SBIR, the authors are able to train the object detector to work without additional training photos. Additionally, the proposed method extends object detection to a zero-shot setup, where the model is trained using prototype learning and weakly supervised object detection techniques. The authors also introduce a simple yet effective data augmentation technique to bridge the gap between object and image-level features. The contributions of this paper include the cultivation of sketch expressiveness for object detection, the development of a sketch-based object detector that is instance-aware and part-aware, a novel prompt learning setup that combines CLIP and SBIR, and achieving superior results on zero-shot object detection compared to supervised and weakly supervised models.