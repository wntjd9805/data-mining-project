3D hand pose and shape reconstruction based on a single RGB camera is important for applications such as augmented and virtual reality (AR/VR), human-computer interaction, and 3D character animation. However, this task is challenging due to limited data, occlusion, and depth ambiguity. Previous methods have focused on reconstructing single hands, but fail to handle interactions between two hands. Recent research has shifted towards reconstructing two interacting hands, but these methods have limitations in handling imperfect hand interactions. In this paper, we propose a method called Attention Collaboration-based Regressor (ACR) that leverages center and part attention to mitigate interdependencies between hands and parts and eliminate prediction sensitivity to occluded or truncated parts. ACR consists of two components: Attention Encoder (AE) and Attention Collaboration-based Feature Aggregator (ACFA). AE learns hand-center and per-part attention maps, while ACFA uses these attention maps to extract global and local features for regressing each hand independently and enhancing interaction modeling. Our method is hand detector-free and achieves lower error rates compared to state-of-the-art methods on the InterHand2.6M dataset, demonstrating its effectiveness in handling interaction challenges. Additionally, our method shows promise for real-world applications with its powerful representation for arbitrary hands reconstruction. Our contributions include taking the first step towards reconstructing two hands in arbitrary scenarios, leveraging center and part-based representations to release input constraints, proposing a cross-hand prior reasoning module for interacting hand modeling, and outperforming existing methods on the InterHand2.6M benchmark. Overall, ACR is a practical and effective method for various in-the-wild application scenes.