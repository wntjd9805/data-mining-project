Semantic segmentation is a fundamental task in computer vision for various applications such as visual-based robot and autonomous driving. Deep learning techniques have achieved remarkable success in segmentation but suffer from a serious drawback known as domain shift, where models trained on one dataset perform poorly on another dataset with a different distribution. To address this problem, researchers have focused on domain generalization (DG) and domain adaptation (DA). However, both approaches have their limitations. DG is limited when there is a large gap between the source and target domains, as it does not leverage target data. DA assumes access to unlabeled target data, which is not always feasible in real-world scenarios. In this paper, we propose a test-time domain adaptation method called Dynamically Instance-Guided Adaptation (DIGA) for semantic segmentation. DIGA leverages each instance to dynamically adapt the model in a non-parametric manner, ensuring efficiency and avoiding error accumulation. Our approach incorporates distribution adaptation and semantic adaptation modules, providing a holistic solution. We demonstrate the effectiveness and efficiency of DIGA through experiments on multiple source and target domains, showing improved performance compared to existing methods. Additionally, we evaluate DIGA in the challenging task of continual test-time domain adaptation for semantic segmentation. Our method is easily implementable and can be integrated into existing models.