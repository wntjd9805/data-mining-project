Visual object recognition is a crucial aspect of human perception and survival. The human brain has the ability to quickly and accurately identify objects, regardless of variations in appearance and environmental factors. This recognition process primarily occurs along the ventral pathway, where visual perception progresses from local patterns to more complex features. Inspired by this biological process, convolutional neural architectures have been developed to mimic hierarchical learning in object recognition. However, recent research has shown that these architectures have a strong bias towards texture cues, which can negatively impact performance, especially when faced with domain shifts. To address this texture bias, various approaches have been proposed that incorporate adversarial texture cues into the learning pipeline. These approaches aim to minimize texture bias and shift towards shape bias, similar to human visual perception. However, existing algorithms that address texture bias lack consistent evaluation protocols and commonly used datasets and metrics. Moreover, model selection criteria are often overlooked or inconsistently applied. In this paper, we propose a comprehensive evaluation framework called Bias-Bed. This framework includes multiple datasets with different texture and shape biases, as well as fully implemented algorithms. We also introduce a robust evaluation pipeline that includes multiple runs, model selection methods, and rigorous statistical hypothesis testing. Through our experiments, we highlight the shortcomings of existing evaluation protocols and demonstrate that current algorithms on texture-bias datasets fail to outperform simple approaches. Our work aims to provide a more rigorous and comprehensive evaluation of algorithms addressing texture bias in object recognition.