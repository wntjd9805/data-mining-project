3D scene understanding is crucial for various computer vision tasks, such as robot grasping and autonomous navigation. However, current approaches heavily rely on large-scale annotated 3D data, which is time-consuming and laborious to collect. To address this issue, self-supervised learning (SSL) has emerged as a promising alternative, allowing for the learning of meaningful representations from unannotated data. One prevalent SSL approach is contrastive learning, which has achieved significant success in 2D visual recognition tasks. While contrastive learning has also been explored for point cloud representation learning, it often fails to capture the complexity and irregularity of 3D scenes. In this paper, we propose a novel approach called FAC (Foreground-Aware Feature Contrast) for large-scale 3D pre-training. FAC leverages scene foreground evidence and foreground-background distinction to construct more informative and discriminative contrast pairs for learning 3D representations. Our method incorporates regional correspondences and foreground-background point feature distinction to enhance foreground awareness and improve feature distinctions effectively. The proposed FAC framework is compatible with popular 3D segmentation and detection backbone networks and can be applied to both indoor dense RGB-D and outdoor sparse LiDAR point clouds. Extensive experiments on public benchmarks demonstrate that FAC outperforms state-of-the-art methods in self-supervised learning.