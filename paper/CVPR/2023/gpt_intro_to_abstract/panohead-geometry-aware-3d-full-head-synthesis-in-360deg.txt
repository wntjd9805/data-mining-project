Photo-realistic portrait image synthesis has gained significant attention in computer vision and graphics due to its applications in digital avatars, immersive gaming, and telepresence. While recent advancements in Generative Adversarial Networks (GANs) have achieved high-quality image synthesis, they lack 3D consistency and modeling of underlying scenes. Traditional approaches for generating 3D heads rely on parametric textured mesh models, but they suffer from limited perceptual quality and expressiveness. To address these limitations, conditional generative models based on differentiable rendering and neural implicit representation have been developed. However, these models require multi-view image or 3D scan supervision, which is challenging to acquire and has limited appearance distribution. The integration of implicit neural representation and GANs has led to rapid progress in 3D-aware generative models. However, most existing 3D GAN approaches are limited to near-frontal views. In this paper, we propose PanoHead, a novel 3D-aware GAN for high-quality full 3D head synthesis in 360 degrees. Our model can generate consistent 3D heads viewable from all angles, which is desirable for immersive interaction scenarios like digital avatars and telepresence. We introduce a foreground-aware tri-discriminator that decomposes the head in 3D space, a novel 3D tri-grid volume representation to handle projection ambiguity for 360-degree poses, and a two-stage alignment scheme to address the image alignment gap between frontal and back head images. Our framework substantially enhances the capabilities of 3D GANs to adapt to in-the-wild full head images from arbitrary views, enabling high-fidelity 360-degree RGB image synthesis and better quantitative metrics compared to state-of-the-art methods. We demonstrate compelling 3D full head reconstruction from a single monocular-view image, facilitating accessible 3D portrait creation. Our contributions include the first 3D GAN framework for view-consistent and high-fidelity full-head image synthesis, a novel tri-grid formulation for representing 360-degree head scenes, a foreground-aware tri-discriminator, and a two-stage image alignment scheme for training 3D GANs with wide camera pose distribution.