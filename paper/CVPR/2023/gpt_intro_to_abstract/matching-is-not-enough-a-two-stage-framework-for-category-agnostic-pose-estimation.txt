This paper introduces a two-stage framework for category-agnostic pose estimation, which aims to accurately localize instance keypoints for arbitrary categories given one or few support images with keypoint annotations. Unlike category-specific pose estimation models, the proposed framework, called CapeFormer, learns to represent and compare keypoints for open-world categories. The first stage of CapeFormer uses a transformer encoder to refine the matching results by generating similarity-aware position proposals. In the second stage, these proposals are updated using cross-attention in the transformer decoder. Experimental results on the MP-100 benchmark dataset show that CapeFormer outperforms the previous best approach by a large margin in terms of accuracy and efficiency. The contributions of this paper include the proposed two-stage framework, the instantiation of CapeFormer with specific designs, and the significant improvements achieved in accuracy and efficiency.