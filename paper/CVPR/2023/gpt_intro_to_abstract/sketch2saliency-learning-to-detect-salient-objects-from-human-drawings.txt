This paper introduces a novel approach to using sketches as a weak label for image saliency detection in computer vision. The paper highlights the inherent attention information present in sketches and explores the potential of utilizing this information to improve saliency detection. The paper proposes a framework that bridges the gap between sketch and photo domains through a photo-to-sketch generation process. This process uses an encoder-decoder model with a 2D attention mechanism to generate sequential sketches from RGB photos while focusing on visually salient regions. The generated attention maps indicate the importance of different regions in the photo. The paper also introduces an equivariance loss to handle perspective deformations and improve overall performance. Experimental results demonstrate the effectiveness of using sketches as a weak label and show significant performance gains over existing weakly-supervised methods. The paper concludes by validating the notion that "Sketch is Salient" and presents this work as the first to support this idea in the vision community.