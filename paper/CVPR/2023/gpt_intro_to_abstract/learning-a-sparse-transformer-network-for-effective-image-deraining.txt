Single image deraining is a challenging problem in low-level computer vision, where the goal is to recover a clean image from an observed rainy image. Traditional approaches impose handcrafted priors based on statistical properties of rain streaks and clear images, but these priors are not robust to complex and varying rainy scenarios. Learning-based methods using convolutional neural networks (CNNs) have achieved decent performance, but they struggle to eliminate long-range rain degradation perturbations. Transformers have been applied to image deraining to better capture non-local information, but they struggle to model local image details. To address these limitations, we propose a sparse Transformer network, called DRSformer, for image deraining. The key component of our framework is the sparse Transformer block (STB) which uses a top-k sparse attention mechanism to better aggregate features and a mixed-scale feed-forward network (MSFN) to explore multi-scale information. We also introduce a mixture of experts feature compensator (MEFC) to refine the features based on rain distribution. Our method offers advantages in robustness, locality and global feature exploitation, and co-exploration of data and content sparsity. Experimental results on various benchmarks demonstrate that our method outperforms state-of-the-art approaches in terms of deraining performance.