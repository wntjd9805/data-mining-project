The increasing popularity of virtual reality (VR) and light field displays has created a demand for capturing content that can provide an immersive virtual experience. However, specialized hardware for capturing this content is expensive and bulky, making it impractical for average users. In order to make content capture more widespread, there is a need to utilize standard capturing devices like cellphone cameras. Unfortunately, these devices typically have limited capabilities and are not able to capture high frame rate videos from multiple views. This necessitates the development of methods that can reconstruct high frame rate videos by interpolating across time and view using standard capturing devices. Existing approaches that are able to achieve this often violate practical criteria such as real-time processing, high storage overhead, and high memory cost. In this paper, we propose an approach that builds upon X-Fields, a coordinate-based network, to address these shortcomings. We analyze X-Fields and identify two major problems: struggles with interpolating disparities for cameras with large baselines and difficulties handling non-linear motions in natural videos. To address these problems, we propose multi-plane disparities to reduce spatial distances and a novel non-uniform time coordinate encoding method. We also introduce additional improvements such as regularization losses, learned blending, and positional encoding. Through extensive experiments, we demonstrate that our approach outperforms state-of-the-art methods in terms of interpolation capability. The code and supplementary materials for our approach are available on our project website.