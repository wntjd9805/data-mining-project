Automatically generating high-quality radiology reports is crucial in the medical field to assist radiologists in handling the overwhelming volume of radiology images. This paper proposes a novel framework called Knowledge-injected and U-Transformer (KiUT) to achieve the ability to understand radiology images and write reports. The model follows an encoder-decoder architecture with U-connection and introduces injected clinical knowledge in the final decoding stage. A symptom graph is constructed to represent clinical entities and their relationships, which are combined with visual and contextual information. The proposed framework outperforms existing methods on two public radiology report generation datasets. This model shows improvement in radiology report generation and natural image captioning tasks, and effectively captures relationships among image regions for extracting abnormal region features. The results demonstrate the effectiveness of incorporating clinical knowledge in generating high-quality radiology reports.