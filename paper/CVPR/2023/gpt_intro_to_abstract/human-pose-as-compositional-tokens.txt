Human pose estimation is a fundamental task in computer vision, but it remains challenging in scenarios with occlusion. Current pose estimators treat joints independently, leading to unrealistic estimates in the presence of occlusion. In this paper, we propose a new representation called pose as compositional tokens (PCT) to address this issue. PCT learns the dependency between joints without making any assumptions and represents poses as discrete indices. We introduce a two-stage process where we learn a compositional encoder to transform poses into token features and then quantize the tokens using a shared codebook. In the second stage, we cast pose estimation as a classification task to predict the categories of the tokens and recover the pose using a decoder network. PCT offers several advantages, including reduced chance of unrealistic pose estimates, no need for post-processing modules, and a unified representation for 2D and 3D poses. We extensively evaluate our approach on benchmark datasets and achieve better or comparable accuracy to state-of-the-art methods, particularly in occluded joint scenarios. We also demonstrate successful results in 3D pose estimation. Our findings highlight the wide applicability and improved performance of PCT in human pose estimation.