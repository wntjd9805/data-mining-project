In this paper, we examine the execution of different sub-behaviors, referred to as skills, in instruction-following agents. We focus on a popular paradigm called Vision-and-Language Navigation (VLN), where an agent navigates a previously unseen environment to reach a specified goal location based on a natural language instruction. Current evaluation metrics in VLN, such as success rate, SPL, and nDTW, provide a high-level assessment of agent performance but lack insights into fine-grained competencies and the grounding of sub-instructions. To address this, we propose an experimental paradigm that incorporates controlled interventions to analyze agent behaviors at a fine-grained level. We specifically investigate the agent's ability to execute both unconditional instructions (such as stopping and turning) and conditional instructions requiring visual grounding (such as moving towards specified objects and rooms). By utilizing annotations from the RxR dataset, we generate truncated trajectory-instruction pairs and augment them with skill-specific sub-instructions. These interventions allow us to evaluate the agent's proficiency in grounding language to appropriate actions.We conduct a case study using a contemporary VLN model and find that while the model can effectively ground some skill-specific language, it exhibits a systematic bias towards forward actions learned during training. For object- or room-seeking skills, we observe only modest relationships between instructions and agent actions. Furthermore, we derive skill-specific scores and compare them across different VLN models with varying overall task performance. We discover that higher skill-specific scores correlate with better task performance, but not all skills show equal improvement across weaker and stronger VLN models. This suggests that improvements in VLN may be driven by certain skills more than others.The contributions of this work include the development of an intervention-based behavioral analysis paradigm for evaluating VLN agents, a case study on a contemporary VLN agent to assess competencies and biases, and an exploration of the relationships between skill-specific metrics and overall VLN task performance.