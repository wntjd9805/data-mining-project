In this paper, we address the problem of enhancing the resolution of omnidirectional images (ODIs) using image super-resolution techniques. ODIs, also known as 360-degree images or panoramic images, have gained significant research interest in the computer vision community due to their potential for providing realistic visual experiences. However, capturing high-resolution ODIs is challenging due to the high industrial cost of camera sensors with high precision. Previous approaches have attempted to solve this problem by performing image super-resolution on equirectangular projection (ERP) images, which are the common storage format for ODIs. However, existing methods that use ERP downsampling for generating training pairs fail to capture the geometric properties of real ERP images, resulting in missing structures and blur textures in the super-resolved images. To address this, we propose a novel approach that applies uniform bicubic downsampling on fisheye images, which are the original format of ODIs, before converting them to ERP images. This fisheye downsampling process better represents the real-world imaging process and enables the exploration of the geometric properties of ODIs. Additionally, we introduce a distortion-aware Transformer model, called OSRT, which utilizes the geometric properties of ERP images to modulate distortions in a self-adaptive and continuous manner. Our proposed OSRT model outperforms previous methods in terms of peak signal-to-noise ratio (PSNR). Furthermore, we propose a data augmentation strategy that generates distorted ERP samples from plain images to reduce overfitting and boost the performance of the OSRT model. Our extensive experiments demonstrate the effectiveness and superiority of our proposed approach. Overall, our contributions include the introduction of fisheye downsampling, the design of a distortion-aware Transformer model, and a data augmentation strategy for ODI super-resolution.