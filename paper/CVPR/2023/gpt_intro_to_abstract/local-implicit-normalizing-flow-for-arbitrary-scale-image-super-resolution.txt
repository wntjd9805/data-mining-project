Arbitrary-scale image super-resolution (SR) has gained significant attention due to its vast application potential, but it faces two major challenges: the ill-posed nature of SR and the lack of flexibility in adjusting output resolutions. Previous deep learning-based SR approaches struggle with these challenges as they rely on pre-defined scale factors for upsampling, limiting their applicability. To overcome these issues, this paper introduces the Local Implicit Normalizing Flow (LINF) framework, which combines flow-based SR models with a local implicit module. LINF addresses the ill-posed nature of SR by learning the distribution of local texture patches and achieves arbitrary-scale SR by generating the local texture separately for each patch. Unlike previous methods, LINF produces high-resolution images with rich and realistic textures. The framework also offers control over generative artifacts through the sampling temperature. The effectiveness of LINF is validated through quantitative and qualitative evidence, demonstrating its superiority over previous SR approaches. This work presents LINF as the first framework that employs normalizing flow to generate photo-realistic HR images at arbitrary scales, offering a unified solution for the ill-posed and arbitrary-scale challenges in SR.