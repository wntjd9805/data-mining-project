This paper introduces Poly-PC, a framework for multi-task learning on point cloud. Unlike previous approaches, Poly-PC takes multiple dataset domains as input, allowing for more diverse and comprehensive training. To address the challenges of sharing a single backbone for different point cloud tasks and avoiding task interference, the authors propose the Res-SA layer, which adapts to various task requirements. They also utilize a weight-entanglement-based one-shot NAS technique to find optimal architectures for each task and shared parameters for efficient storage. Additionally, a task-prioritization-based gradient balance algorithm is introduced to overcome negative transfer and ensure that each task converges to the optimal solution. Experimental results demonstrate that Poly-PC outperforms baselines and achieves comparable performance to state-of-the-art methods. The framework also allows for incremental learning and avoids catastrophic forgetting when generalizing to new tasks, making it parameter-efficient and scalable for increasing numbers of tasks. The contributions of this work include the introduction of Poly-PC, Res-SA layer, weight-entanglement-based one-shot NAS technique, and task-prioritization-based gradient balance algorithm.