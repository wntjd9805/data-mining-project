Understanding hand-object interactions is crucial for various applications such as virtual reality, robotic manipulation, and human-computer interaction. While 3D estimation of sparse hand joints has been extensively studied, joint reconstruction of hands and object meshes provides richer information but has received less attention. Most existing methods for reconstructing high-quality meshes use multi-view image inputs, which are not practical or user-friendly. In this paper, we focus on the reconstruction of hand and object meshes from monocular RGB images, a more feasible scenario. Due to the ill-posed nature of the task, parametric mesh models are commonly employed to incorporate pose prior knowledge and improve 3D hand reconstruction. However, these models have limited resolution and are not optimal for capturing intricate hand-object interactions. To address this limitation, some recent works utilize signed distance functions (SDFs) for reconstructing detailed hand and object meshes. However, these methods do not explicitly associate 3D geometry with image cues and lack prior knowledge, leading to unrealistic meshes. To overcome these challenges, we propose a geometry-driven SDF (gSDF) method that encodes strong pose priors and improves reconstruction accuracy by disentangling pose and shape estimation. We predict sparse 3D hand joints from images and derive local pose transformations using inverse kinematics. We optimize SDFs with respect to poses of all hand joints, enabling a more fine-grained alignment between 3D shape and articulated hand poses. Additionally, we extract geometry-aligned visual features from projected 3D points and refine them using a transformer model to enhance robustness. Extensive experiments demonstrate the effectiveness of our approach, which outperforms state-of-the-art results on challenging benchmarks. Our contributions include embedding strong pose priors into SDFs, reducing misalignment induced by inaccurate pose estimations, and showing superior performance through comprehensive experiments.