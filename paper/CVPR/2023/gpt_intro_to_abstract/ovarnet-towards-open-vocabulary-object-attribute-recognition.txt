This paper addresses the problem of understanding visual scenes in computer vision beyond categorical object recognition. The authors propose a novel approach, OvarNet, which simultaneously detects objects and classifies their attributes in an open-vocabulary scenario. They first introduce CLIP-Attr, an architecture that performs open-vocabulary attribute recognition by comparing attribute word embeddings with visual embeddings of object proposals. They then present OvarNet, a unified framework that combines object detection and attribute recognition, leveraging datasets from both domains. Experimental results show that OvarNet outperforms previous state-of-the-art methods on various datasets, demonstrating its strong generalization ability for novel attributes and categories. This work contributes to a more comprehensive understanding of the visual world in computer vision.