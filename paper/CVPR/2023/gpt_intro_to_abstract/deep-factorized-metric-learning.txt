Learning good representations for images is crucial in computer vision, but measuring the similarity between these representations is equally important. Metric learning aims to learn a discriminative similarity metric that maximizes interclass distances and minimizes intra-class distances. This paper focuses on metric learning and introduces a deep factorized metric learning (DFML) method. Unlike existing ensemble-based methods that use a shared backbone network, DFML factorizes the backbone and learns a separate routine for each sample to enhance feature diversity. The proposed DFML framework is compatible with different loss functions and sampling strategies and can be applied to vision transformers (ViTs). Extensive experiments on popular image datasets demonstrate the superiority of DFML over existing methods, achieving better accuracy-computation trade-offs. The paper also provides a detailed analysis of the proposed framework's effectiveness.