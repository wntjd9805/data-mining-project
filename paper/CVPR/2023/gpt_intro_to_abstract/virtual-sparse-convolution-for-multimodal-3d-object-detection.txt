3D object detection is crucial for autonomous driving, with LiDAR sensors providing depth measurements in the form of point clouds. While LiDAR-based detection has advanced, it still struggles with distant objects due to sparse sampling density. Combining LiDAR with RGB image sensors can enhance detection performance. Early methods extended LiDAR features with image features but did not address sparsity. Virtual point-based methods create additional points around LiDAR points to enrich the sparse data, showing potential for high-performance detection. However, generating virtual points from images results in dense and computationally burdensome data. This paper proposes VirConv, an operator that encodes voxel features of virtual points using Sparse-to-Voxel Deconvolution (StVD) and Noisy Reduction Convolution (NRConv) to improve efficiency and noise reduction. Three multimodal detectors, VirConv-L, VirConv-T, and VirConv-S, are developed to demonstrate the effectiveness of VirConv. Extensive experiments on KITTI and nuScenes datasets confirm the superiority of the proposed approach, with VirConv-T and VirConv-S ranking highly on the KITTI leaderboard. The VirConv-L achieves competitive precision at a faster speed.