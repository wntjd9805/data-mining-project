Homography is a global projective mapping between two images captured from different perspectives that has been widely applied in various computer vision tasks. Deep homography estimation methods have been introduced to improve estimation accuracy, but feature inconsistency caused by homography deformation has often been neglected. Previous strategies to address this issue, such as group convolutions or pre-warping, are computationally expensive and redundant. In this paper, we propose a novel framework called RHWF that combines homography-guided image warping with a recurrent trainable network. We also introduce a transformer structure called FocusFormer that uses an attention focusing mechanism, which saves computation costs while improving estimation performance. Our RHWF framework outperforms previous methods on various datasets, including challenging cross-resolution and cross-modal scenes. We investigate the effectiveness and technique of using homography-guided image warping in the recurrent framework and propose FocusFormer as the fundamental block for recurrent homography estimation. Our contributions include the development of RHWF, which ranks top on multiple datasets, the investigation of homography-guided image warping, and the introduction of FocusFormer with a more efficient attention mechanism.