In this paper, we introduce a neural network-based approach to infer signed distance functions (SDFs) from single sparse point clouds, without relying on signed distance supervision, learned priors, or normals. We address the challenge of limited generalization ability and accuracy in inferring SDFs for unseen point clouds by learning surface parameterization and SDF inference in an end-to-end manner. Our method leverages the sparsity of the point clouds by treating parameterized surfaces as coarse surface samplers, generating multiple coarse surface estimations to statistically infer the SDF. We achieve this by representing the surface of a point cloud as a single patch on a 2D plane, mapping 2D samples to 3D points to estimate the coarse surface. Additionally, we use thin plate splines (TPS) in the feature space to infer smooth signed distance fields based on the estimated coarse surface. Our approach significantly outperforms the latest methods in surface reconstruction for sparse point clouds according to widely used benchmarks. The contributions of this work are: (i) the introduction of a neural network-based method to infer SDFs from sparse point clouds without using signed distance supervision, learned priors, or normals, (ii) the feasibility demonstration of learning surface parameterization and inferring SDFs from sparse point clouds in an end-to-end manner, providing a novel perspective for using surface parameterization to mine supervision, and (iii) the superior performance of our method compared to state-of-the-art methods in surface reconstruction for sparse point clouds.