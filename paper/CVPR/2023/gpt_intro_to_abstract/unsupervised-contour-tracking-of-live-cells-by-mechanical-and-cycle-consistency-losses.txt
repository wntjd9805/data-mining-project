Cellular morphodynamics, the dynamic change in the morphology of live cells, plays a crucial role in various biological processes. Quantifying cellular morphodynamics through contour tracking is an important first step to understand its functions. However, contour tracking of live cells presents two main difficulties: the visual features of the cellular contour are challenging to distinguish, and the expansion and contraction of the contour change the total number of tracking points. In this paper, we propose a deep learning-based contour tracker that overcomes these difficulties. Our tracker consists of a feature encoder, cross attentions, and a fully connected neural network for offset regression. We use unsupervised learning, including mechanical and cycle consistency losses, to train our tracker. Our proposed architecture achieves superior accuracy compared to existing methods. To evaluate the performance, we label tracking points in live cell videos and show qualitative results on a jellyfish dataset. Our contributions include the first deep learning-based contour tracker with dense point-to-point correspondences, an unsupervised learning strategy for contour tracking, and a thorough quantitative evaluation of cellular contour tracking.