Understanding the dynamics of surrounding environments is crucial for autonomous driving, and motion prediction plays a key role in path planning and navigation. Classical approaches achieve motion prediction through object detection, tracking, and trajectory forecasting, but they may fail when encountering unknown categories not included in the training data. To address this issue, many approaches propose to estimate class-agnostic motion from bird's eye view (BEV) maps of point clouds, which achieves a good trade-off between accuracy and computational cost. However, motion data is often scarce and expensive to obtain, and most existing real-world motion data are produced through semi-supervised learning methods. To overcome the dependence on motion annotations, a self-supervised motion learning method called PillarMotion has been developed, but there is still a performance gap compared to fully supervised methods.In this paper, we propose a novel weakly supervised paradigm that replaces expensive motion annotations with partially or fully annotated foreground/background (FG/BG) masks. We design a two-stage approach where a FG/BG segmentation network is trained in Stage 1 using partially annotated masks, and then a motion prediction network is trained in Stage 2. The segmentation network generates foreground points for training samples, enabling self-supervised motion learning. To address outliers in the point clouds, we introduce a Consistency-aware Chamfer Distance (CCD) loss that exploits supervision from multi-frame point clouds and suppresses potential outliers by assigning lower weights to uncertain points.Our main contributions include: 1) proposing a weakly supervised motion prediction paradigm using FG/BG masks as supervision, achieving a good compromise between annotation effort and performance, 2) presenting a two-stage approach that associates motion understanding with scene parsing, facilitating self-supervised motion learning, 3) introducing a novel CCD loss that leverages multi-frame information to suppress outliers for robust self-supervised motion learning, and 4) demonstrating that our weakly supervised models outperform self-supervised models and perform on par with some supervised ones. To the best of our knowledge, this is the first work on weakly supervised class-agnostic motion prediction.