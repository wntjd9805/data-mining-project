Estimating the relative pose between two images is a fundamental problem in computer vision, with applications in autonomous vehicles, robots, and augmented/virtual reality. This is typically achieved by solving a geometric problem and estimating the essential or fundamental matrix. However, existing algorithms do not consider the quality of feature correspondences, which can affect pose estimation accuracy. This paper addresses this issue by incorporating feature correspondence quality into relative pose estimation using deep learning and geometric modeling. The authors propose a method to learn the noise distributions of feature positions from data, allowing for more accurate modeling of uncertainty. They introduce a symmetric version of the probabilistic normal epipolar constraint and use a learning strategy to minimize relative pose error. Experimental results demonstrate the effectiveness of the proposed approach, which is able to generalize to different feature extraction algorithms and outperforms non-probabilistic relative pose estimation algorithms. The code and training setup are also provided for future research.