Recent studies in neural image compression have shown significant success using nonlinear transform coding (NTC) methods. Unlike traditional image codecs that utilize linear transforms like discrete cosine transform (DCT), NTC employs nonlinear transform layers and data-driven techniques using modern neural networks. Most NTC methods utilize scalar quantization (SQ) and additive uniform noise for quantization error approximation during training. However, it has been known that vector quantization (VQ) performs better in terms of rate-distortion (RD) performance. VQ maps continuous source distributions to discrete vectors and offers unique advantages such as space-filling and memory advantage. NTC methods rely on expensive nonlinear transform and context-based auto-regressive entropy models to reduce data distribution redundancies. In contrast, VQ exhibits superior decorrelation ability and optimal RD performance. In this paper, we propose a novel framework called nonlinear vector transform coding (NVTC) that leverages the space-filling and memory advantages of VQ for image compression. NVTC utilizes multi-stage product VQ, nonlinear vector transform, and entropy-constrained VQ to achieve high RD performance with low complexity. Our contributions include investigating the advantages of VQ over SQ with nonlinear transform, introducing NVTC as a VQ-based coding scheme, and demonstrating its superiority in terms of rate-distortion performance, decoding speed, and model size compared to previous neural image codecs.