This paper introduces the concept of position embeddings (PEs) in the context of Vision Transformer (ViT) models. While PEs have been extensively studied in language tasks, their effects and importance in vision tasks, such as image classification and object detection, have not been well explored. The authors visually demonstrate that PEs in ViTs effectively capture the spatial relationships between input image patches. However, the presence of PEs also poses privacy risks and can lead to inconsistencies when the input patches are transformed or shuffled. To address these issues, the authors propose a Masked Jigsaw Puzzle (MJP) position embedding method. MJP involves random selection and shuffling of input patches, the use of unknown position embeddings for shuffled patches, and a localization regressor to maintain the positional relationship of unshuffled patches. Experimental results show that MJP achieves a balance between accuracy, privacy preservation, and consistency in vision tasks. The proposed method improves accuracy on large-scale datasets and enhances robustness against adversarial attacks.