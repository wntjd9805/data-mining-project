Reconstructing high-fidelity controllable 3D faces from monocular videos poses a significant challenge in computer graphics and computer vision. Recently, the Neural Radiance Field (NeRF) technique has shown impressive quality for novel view synthesis. However, existing approaches do not support facial editing or face reenactment. The controllability of facial avatars is crucial for applications like talking head synthesis. Previous works have used 3D morphable face models (3DMM) as guidance in NeRF-based facial avatar reconstruction, but these approaches have limitations. To address these challenges, this paper proposes the use of a 3D generative prior, specifically a personalized 3D-aware generative prior, for reconstructing multi-view-consistent facial images. This personalized subspace is learned in the latent space of a 3D-GAN model, allowing for faithful maintenance of personalized characteristics. Experimental results demonstrate the effectiveness of the proposed method for facial avatar reconstruction and reenactment, surpassing state-of-the-art approaches in terms of 3D consistent reconstruction and faithful face reenactment. The contributions of this work include the utilization of a 3D-aware generative prior, the development of an efficient method to maintain personalized characteristics, and the enabling of 3DMM and audio-driven face reenactment through latent space navigation.