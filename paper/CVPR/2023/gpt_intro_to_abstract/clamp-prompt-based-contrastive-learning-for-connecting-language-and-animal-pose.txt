Animal pose estimation is a crucial task in animal behavior understanding, zoology, and wildlife conservation. However, it differs significantly from human pose estimation due to the involvement of multiple animal species and the scarcity of animal pose datasets. In this paper, we propose CLAMP, a novel prompt-based contrastive learning scheme that connects language and animal pose for improved estimation. We leverage the language information from texts to identify animal keypoints and adapt pre-trained language models using a spatial-aware and feature-aware process. This allows us to establish effective connections between language and visual animal poses, leading to better performance in animal pose estimation. Experimental results on challenging datasets validate the effectiveness of our CLAMP method.