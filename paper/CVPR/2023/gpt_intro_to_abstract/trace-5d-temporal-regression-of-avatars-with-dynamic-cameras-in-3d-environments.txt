The estimation of 3D human pose and shape (HPS) has made significant progress in recent years, but most methods are limited to reasoning about a single frame at a time and estimating humans in camera coordinates. This becomes problematic for applications that require capturing human movement in a global coordinate system. In this paper, we propose a new approach that treats the problem of estimating 3D HPS as a 5D problem, considering 3D space, time, and subject identity. We present TRACE, a unified one-stage method that uses a holistic 5D representation to infer multiple people's 3D pose, shape, identity, and global trajectory in dynamic camera videos (DC-videos). Our approach overcomes two main challenges: disentangling human motion from camera motion and dealing with occlusions in videos with multiple people. We address these challenges by incorporating three novel modules into the architecture of TRACE, allowing us to extract temporal image features, explicitly track human motions, and infer human trajectories in global coordinates. To evaluate our method, we introduce the DynaCam dataset, which includes in-the-wild DC-videos and pseudo-ground-truth 3D human annotations. Additionally, we evaluate TRACE on two benchmark datasets, where it outperforms existing methods in estimating human trajectories and tracking people under occlusions. Our contributions include the introduction of a 5D representation for holistic temporal reasoning, the development of novel modules for multi-subject association and global trajectory inference, achieving state-of-the-art results in global human motion estimation, and the release of the DynaCam dataset and code for research purposes.