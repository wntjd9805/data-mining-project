This paper addresses the challenge of detecting objects of vastly different scales in object detection. It introduces the concept of multi-scale features and their benefits for ConvNet-based object detectors like Faster R-CNN and FCOS. Additionally, it discusses the limitations of incorporating multi-scale features in Transformer-based detectors using FPN, which leads to high computational costs. To mitigate this issue, the paper proposes Iterative Multi-scale Feature Aggregation (IMFA), a technique that efficiently exploits multi-scale features in Transformer-based object detectors. IMFA consists of two novel designs: rearranging the encoder-decoder pipeline for iterative update of encoded image features, and sparsely sampling multi-scale features from informative regions guided by prior predictions. The paper presents IMFA as a generic paradigm that improves detection accuracy without significantly increasing computational overhead. The contributions of this work include a new detection pipeline, a sparse sampling strategy for multi-scale features, and the development of IMFA as an efficient approach for utilizing multi-scale features in Transformer-based object detectors. The proposed technique consistently enhances detection performance while remaining computationally efficient. This paper is the first to investigate such a generic approach for efficiently exploiting multi-scale features in Transformer-based object detectors.