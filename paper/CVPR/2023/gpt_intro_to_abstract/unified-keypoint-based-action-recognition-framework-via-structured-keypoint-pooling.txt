Recognizing human actions in videos is crucial for applications like robotics and surveillance cameras. There are two approaches to action recognition: appearance-based and skeleton-based. Appearance-based approaches use deep neural networks to directly analyze the video, but they are less robust to variations in appearance. Skeleton-based approaches, on the other hand, use keypoints detected in the video and are more robust to appearance changes. Various skeleton-based approaches using graph convolutional networks (GCNs) have been proposed, but they have limitations in terms of scalability, variety of targeted actions, and person-wise and frame-wise recognition. This paper proposes a unified action recognition framework called Structured Keypoint Pooling and a novel DNN architecture to address these limitations. Unlike previous methods, which use predefined graph structures, the proposed method treats keypoints as a point cloud and applies a point cloud deep-learning paradigm. This allows for a more flexible and tracking-free approach to feature aggregation among keypoints. The proposed architecture also incorporates nonhuman object keypoints, increasing the input information without relying on appearances. Additionally, the paper introduces a Pooling-Switching Trick for weakly supervised spatio-temporal action localization. The main contributions of this work are the Structured Keypoint Pooling method, the incorporation of object keypoints, and the achievement of weakly supervised action localization using the Pooling-Switching Trick.