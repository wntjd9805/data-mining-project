Federated Learning (FL) has gained popularity as a privacy-preserving method for collaborative learning on distributed data. Previous studies have mainly focused on improving convergence and performance of the source clients' data distribution. However, a more practical problem of making models trained on sites with different distributions generalize to target clients of unknown distributions, known as Federated Domain Generalization (FedDG), has been overlooked. FedDG specifically addresses domain shift among clients and treats each client as an individual domain. The challenge lies in the domain shift among training and testing clients. While FedDG shares a similar goal with standard Domain Generalization (DG), it prohibits direct data sharing among clients, making existing DG methods mostly inapplicable. Current methods for FedDG primarily focus on unbiased local training within isolated domains. Previous attempts include a meta-learning framework with Fourier-based augmentation and constraining local models' flatness. However, solely improving local training strategies does not guarantee the generalizability of the global model. In the FedAvg method, local models are aggregated into a global model using fixed weights, assuming equal contribution from each client. Subsequent improvements, such as FedNova, are designed for statistical heterogeneity within the same domain and do not consider each client as an individual domain. To address this limitation, we propose a new fairness objective for FedDG, measured by the variance of generalization gaps among source domains. However, the privacy issue in FL prevents direct optimization of this objective. To overcome this, we introduce a privacy-preserving method called Generalization Adjustment (GA). GA leverages the concept of domain flatness constraint to approximate the optimal domain weights and enhance generalization ability. We use a momentum mechanism to dynamically compute weights for each isolated domain based on the domain generalization gap. Theoretical analysis shows that GA achieves a tighter generalization bound by setting aggregation weights inversely proportional to the generalization gaps, reducing variance in generalization gaps. Our contributions include introducing a novel optimization objective for FedDG with a fairness regularizer, designing the FL-friendly method GA to tackle this objective, and demonstrating consistent improvements on benchmark datasets through extensive experiments combining GA with various federated learning algorithms.