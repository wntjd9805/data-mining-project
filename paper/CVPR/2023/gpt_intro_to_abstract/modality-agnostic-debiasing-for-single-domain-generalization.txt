This paper introduces a new approach called Modality-Agnostic Debiasing (MAD) for single domain generalization (single-DG) in deep neural networks (DNNs). The existing techniques for domain generalization are often modality-specific and cannot be directly applied to different modalities, such as 3D point clouds. MAD addresses this limitation by strengthening the classifier's ability to identify domain-specific features while also emphasizing the learning of domain-generalized features. This is achieved through a novel two-branch classifier structure, where one branch identifies domain-specific features and the other branch learns domain-generalized representations. MAD can be seamlessly incorporated into existing single-DG models with data augmentation. The proposed approach is evaluated in various single-DG scenarios with different modalities, including 2D images, 3D point clouds, 1D texts, and semantic segmentation on 2D images. Experimental results show that MAD improves the performance of existing single-DG techniques in different modalities, achieving higher accuracy in recognition on point cloud benchmark and better mean intersection over union (mIoU) in semantic segmentation on image benchmark. This demonstrates the versatility and effectiveness of MAD for single domain generalization in DNNs.