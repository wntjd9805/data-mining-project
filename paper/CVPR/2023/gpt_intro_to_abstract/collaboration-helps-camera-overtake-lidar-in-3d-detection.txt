Abstract:The field of computer vision requires precise localization of objects in the 3D physical space using real-time sensor inputs. 3D object detection is crucial in various applications like autonomous driving, surveillance systems, robotics, and unmanned aerial vehicles. Different technical solutions exist depending on the sensor setups, with high-end LiDAR sensors providing accurate 3D measurements but at a high cost, and camera-only setups offering cost-effectiveness but inferior performance. In this paper, we propose a novel approach to improve camera-only 3D detection by introducing multi-agent collaborations. Multiple agents equipped with cameras can share visual information, providing benefits such as resolving depth ambiguity, addressing occlusion and long-range issues, and potentially outperforming LiDAR-based detection. However, this approach also brings new challenges in terms of communication bandwidth constraints. We present a collaborative camera-only 3D detection framework, CoCa3D, which includes single-agent camera-only detection, collaborative depth estimation, and collaborative detection feature learning. We evaluate CoCa3D on real-world and simulation datasets, demonstrating its superior performance compared to previous methods. Our contributions include the proposal of CoCa3D, the development of communication-efficient collaboration techniques, and the expansion of collaborative datasets. Overall, CoCa3D significantly improves the detection ability of cameras with multi-agent collaboration, achieving more holistic 3D detection and bridging the gap between camera and LiDAR-based approaches.