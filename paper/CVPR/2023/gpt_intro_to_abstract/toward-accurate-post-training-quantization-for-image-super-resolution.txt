Image super resolution (SR) is a common computer vision task that aims to reconstruct high-resolution (HR) images from low-resolution (LR) images. SR has wide applications in fields such as medical imaging, surveillance, satellite imagery, and smartphone display. Deep learning-based SR models have achieved state-of-the-art performance on various datasets, but they require significant storage and computational resources, making deployment on mobile devices difficult. To improve inference efficiency, various techniques, including model quantization, have been proposed. However, existing SR quantization methods require quantization-aware training (QAT) and have high computational overhead. This paper introduces a post-training quantization (PTQ) method for accurate quantization of SR models without the need for training. The proposed method utilizes density-based dual clipping (DBDC) to narrow the distribution of feature maps, addressing the challenges posed by their long-tailed, asymmetric, and highly dynamic nature. Additionally, a pixel-aware calibration (PaC) technique is introduced to align the quantized network with the full-precision model. Experimental results demonstrate the effectiveness of the proposed method in achieving accurate quantization with only a few unlabeled calibration images. The method outperforms existing PTQ methods and achieves comparable performance with QAT in some settings. Furthermore, it can also enhance convergence and performance when combined with QAT methods.