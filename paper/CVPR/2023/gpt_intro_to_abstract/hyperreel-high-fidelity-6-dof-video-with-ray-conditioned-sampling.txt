Six-Degrees-of-Freedom (6-DoF) videos offer immersive experiences in AR/VR by allowing users to freely explore an environment with the ability to change head position and orientation. The underlying methodology behind 6-DoF videos is view synthesis, which involves rendering new, unobserved views of an environment from a set of posed images or videos. While recent advancements in volumetric scene representations have improved static scene view synthesis, creating a memory-efficient 6-DoF video format that achieves high quality, fast rendering, and a small memory footprint remains a challenge. Existing approaches are slow or require large storage capacities for dynamic scenes. Additionally, capturing view-dependent appearance, such as reflections and refractions, is difficult. This paper introduces HyperReel, a novel 6-DoF video representation that achieves state-of-the-art quality, real-time rendering, and memory efficiency. The approach includes a ray-conditioned sample prediction network that accelerates volume rendering and improves rendering quality, as well as a memory-efficient dynamic volume representation that utilizes spatio-temporal redundancy. HyperReel outperforms existing methods and provides high-quality renderings, even for scenes with challenging appearances. The contributions of this work include a novel sample prediction network, a memory-efficient dynamic volume representation, and the HyperReel 6-DoF video representation. The proposed system achieves a desirable trade-off between speed, quality, and memory usage while rendering in real time at high resolutions.