The usage of depth sensors, such as LiDARs, in applications like autonomous driving cars and robotics has increased. These sensors collect points in 3D space, forming a 3D representation called a point cloud. However, point clouds obtained from real-world sensors are often incomplete and sparse, leading to a loss of geometric information. Point cloud completion is a crucial task that infers completing geometric 3D shapes using partial point cloud observations. Previous data-driven methods have achieved decent performance but require ground-truth complete point clouds, which are difficult to obtain in real-world scenarios. Researchers have attempted to overcome this limitation by leveraging multi-view consistency and unpaired partial and complete point clouds. However, these methods have limitations in terms of applicability and data availability. To address these challenges, we propose ACL-SPC, the first self-supervised method for point cloud completion using only a single partial point cloud. Our method incorporates an adaptive closed-loop system and a novel loss function to generate complete point clouds from synthetic viewpoints without any supervision. Through experiments, we demonstrate the ability of our method to restore complete point clouds, improve quantitative performance, and perform comparably to other unsupervised methods in real-world scenarios. Our main contributions are the development of the ACL-SPC framework, the design of an effective self-supervised loss function, and the achievement of superior performance in real-world scenarios.