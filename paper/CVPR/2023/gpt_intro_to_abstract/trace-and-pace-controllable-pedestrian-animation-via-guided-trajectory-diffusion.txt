This paper introduces a controllable pedestrian animation system that synthesizes high-level human behavior in the form of 2D positional trajectories. The ability to control these trajectories is crucial for applications like autonomous vehicles, urban planning, and architectural design. While algorithmic models can generate controllable trajectories, they often appear unnatural. Learning-based approaches can improve naturalness by mimicking real-world data, but controlling these models is limited. This paper focuses on using controllable pedestrian trajectory models for character animation, specifically using a physics-based animation system for realistic motion. The authors propose a generative model called TRACE (TRAjectory Diffusion Model for Controllable PEdestrians) for trajectory generation. TRACE accounts for surrounding context and allows user-controlled sampling through test-time guidance. For character animation, the authors develop a Pedestrian Animation ControllER (PACER) that can drive physics-simulated humanoids with diverse body types to follow trajectories. PACER focuses on motion quality, terrain and social awareness, diverse body shapes, and compatibility with high-level planners. The proposed controllable pedestrian animation system integrates TRACE as a high-level planner for PACER, the low-level animator. The system operates in a closed loop and is guided by the value function learned during reinforcement learning training of PACER. The authors evaluate TRACE on synthetic and real-world pedestrian data and demonstrate its flexibility in synthesizing realistic motion with user-specified objectives. They also show the robustness and capability of the animation system across various tasks, terrains, and characters. Overall, this paper contributes a controllable pedestrian animation system that integrates a diffusion model for pedestrian trajectories and a general-purpose pedestrian animation controller to drive simulated characters in a controllable manner.