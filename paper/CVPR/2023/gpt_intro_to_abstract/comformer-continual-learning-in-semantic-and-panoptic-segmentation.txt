Image segmentation is a crucial task in computer vision, allowing machines to assign pixels in an image to different segments. Semantic segmentation groups pixels based on their classes, while panoptic segmentation assigns semantic classes to each pixel and separates different instances into separate segments. Panoptic segmentation has significant real-world applications in autonomous robots and vehicles. However, current approaches are typically trained on static datasets with a predefined set of classes. When new classes need to be added, the common solution is to train a new model from scratch on the combined old and new class data. This approach is computationally expensive and leads to a degradation of performance on the old classes. Continual learning, the problem of updating a model's knowledge over time, has been extensively studied in image classification but has received limited attention in the context of segmentation tasks. In this paper, we propose CoMFormer (Continual MaskFormer), the first method designed for both continual semantic and panoptic segmentation. CoMFormer is inspired by transformer architectures and treats segmentation as a mask classification problem. It predicts a set of binary masks associated with each class, effectively addressing both segmentation tasks without modifying the training architecture. CoMFormer introduces an adaptive distillation loss to mitigate forgetting and a mask-based pseudo-labeling technique to generate annotations for old classes. Experimental results on benchmark datasets demonstrate the superior performance of CoMFormer compared to existing methods in both continual segmentation tasks. The contributions of this work include the introduction of continual panoptic segmentation, the proposal of CoMFormer for tackling both continual panoptic and semantic segmentation, and extensive quantitative and qualitative benchmarks showcasing the state-of-the-art performance of CoMFormer.