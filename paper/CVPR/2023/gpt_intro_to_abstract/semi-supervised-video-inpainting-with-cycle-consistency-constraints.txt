Video inpainting is an important task in computer vision that aims to fill corrupted regions of a video with plausible contents. Existing methods for video inpainting typically require elaborate annotation of the corrupted regions in each frame of the video, which is labor-intensive and expensive. In this paper, we propose a new task called semi-supervised video inpainting, where only the corrupted regions of one frame are annotated to complete the entire video. We introduce a flexible and efficient framework consisting of a completion network and a mask prediction network to solve this task. We also propose a synthetic dataset tailored for semi-supervised video inpainting, which will be published to benefit other researchers. Experimental results demonstrate that our proposed method achieves comparable inpainting results as fully-supervised methods. This work contributes to the field by providing the first end-to-end semi-supervised approach for video inpainting.