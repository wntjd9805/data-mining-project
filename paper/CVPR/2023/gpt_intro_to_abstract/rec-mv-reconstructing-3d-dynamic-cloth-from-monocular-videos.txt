High-fidelity digitization of clothes is crucial for various vision applications such as virtual shopping, film, and gaming. In this paper, we address the problem of extracting dynamic 3D garments from monocular videos, which is a valuable but uncultivated area with many challenges. We review existing works in neural rendering methods and garment reconstruction and propose a new approach that combines dynamic surface modeling and explicit curve representation. Our method optimizes dynamic explicit feature curves and implicit garment surfaces from monocular videos to extract temporally consistent garment meshes with open boundaries. We introduce techniques such as intersection-free curve deformation, surface-aware curve visibility estimation, and progressive curve and surface evolution to ensure accurate and high-quality results. Our contributions include introducing the first method, REC-MV, for reconstructing dynamic and open loose garments from monocular videos, and proposing a novel joint optimization approach for explicit feature curves and implicit garment surfaces. Extensive evaluations demonstrate that our method outperforms existing methods.