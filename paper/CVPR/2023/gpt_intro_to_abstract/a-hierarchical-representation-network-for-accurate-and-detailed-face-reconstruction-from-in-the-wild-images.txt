High-fidelity 3D face reconstruction has numerous applications, including AR/VR, medical treatment, and film production. While specialized hardware like LightStage has achieved excellent reconstruction performance, reconstructing highly detailed face models from single or sparse-view images remains a challenge. Many works have attempted to reconstruct 3D faces using a statistical model learned from face scans, but they struggle to recover detailed facial geometry. Recent methods have focused on capturing high-frequency facial details but fail to model mid-frequency details. Trade-offs are difficult to achieve when handling mid- and high-frequency details simultaneously, and obtaining accurate shapes and detailed 3D facial priors considering various lighting and skin conditions is also a challenge. In response, this paper introduces a hierarchical representation network (HRN) for accurate and detailed face reconstruction. The HRN decouples facial geometry into low-frequency geometry, mid-frequency details, and high-frequency details. It employs image translation networks to estimate detail maps and generate detailed face models in a coarse-to-fine manner. Detail priors from fitting face scans using the hierarchical representation are introduced, and a de-retouching module refines the base texture. The HRN is extended to a multi-view fashion, enabling accurate face modeling from sparse-view images. Extensive experiments show that the proposed method outperforms existing methods in terms of detail capturing and accurate shape modeling. Additionally, a high-quality 3D face dataset named FaceHD-100 is introduced, containing detailed 3D face models and corresponding high-definition multi-view images to boost research in sparse-view and high-fidelity face reconstruction tasks. The main contributions of this work are the hierarchical modeling strategy, the HRN framework, the introduction of detail priors and a de-retouching module, and the extension of HRN to a multi-view fashion.