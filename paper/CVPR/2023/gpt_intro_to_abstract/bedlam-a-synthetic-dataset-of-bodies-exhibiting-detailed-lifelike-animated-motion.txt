The estimation of 3D human pose and shape from images has seen significant progress in recent years, with the introduction of the HMR neural network and subsequent improvements to accuracy by various methods. However, it remains unclear whether the architectural improvements or the training data improvements are the primary factors driving this progress. To address this question, we introduce a new synthetic dataset called BEDLAM, which provides realistic ground truth 3D body data for analysis of the current state of the art. BEDLAM offers many advantages over existing datasets, including perfect ground truth construction, diversity across skin tones and body shapes, and the ability to easily adapt to different cameras and scenes. Previous attempts at synthetic datasets have not been sufficient in terms of realism and diversity. In contrast, BEDLAM demonstrates that training only using synthetic data can produce methods that generalize well to real images, achieving state-of-the-art accuracy in 3D human pose and body shape estimation. The dataset includes diverse body shapes, skin textures, hair types, clothing, and motions, rendered in different scenes and HDRI panoramas. It is divided into training, validation, and test sets, with evaluation on multiple natural-image datasets. Surprisingly, even basic methods like HMR achieve state-of-the-art performance on real images when trained on BEDLAM. We also compare the performance on body shape regression tasks with other state-of-the-art methods, demonstrating the effectiveness of training on BEDLAM. Overall, BEDLAM provides a valuable resource for studying and advancing 3D human pose and shape estimation, as well as applications in 3D clothing modeling and action recognition. The dataset is available for research purposes, along with an evaluation server and the assets necessary for generating new datasets.