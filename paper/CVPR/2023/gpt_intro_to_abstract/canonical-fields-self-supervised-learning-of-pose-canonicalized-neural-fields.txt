Neural fields, a type of neural networks that represent signals in a coordinate-based manner, have become popular for modeling 3D shape, view-dependent appearance, and motion. Neural radiance fields (NeRFs), a specific type of neural fields, have been successfully applied in various computer vision tasks. However, building neural fields that can represent entire object categories remains challenging. Previous methods either overfit on a single instance or rely on supervised learning using datasets with manually canonicalized objects. Recent work has proposed self-supervised learning methods for canonicalization of 3D pose but do not apply to neural fields. In this paper, we introduce CaFi-Net, a self-supervised method for category-level canonicalization of objects represented as neural radiance fields. CaFi-Net extends the notion of equivariance to continuous vector fields and designs a Siamese network architecture that can operate directly on neural radiance fields. Our approach learns canonicalization without supervised labels using a dataset of pre-trained NeRF models. We propose self-supervision loss functions and evaluate our method against baselines and other approaches on standardized canonicalization metrics. Results show that our approach matches or exceeds the performance of 3D point cloud-based methods, enabling direct operation on neural fields. We contribute CaFi-Net, the Siamese network architecture, and a public dataset for evaluating canonicalization performance.