Referring expression segmentation (RES) has gained attention in recent years for its application in language-based human-robot interaction and interactive image editing. However, existing RES models struggle with handling novel compositions of learned concepts during testing, resulting in a significant performance drop. To address this issue, we propose a Meta Compositional Referring Expression Segmentation (MCRES) framework that trains the model to effectively capture the semantics and visual representations of individual concepts. The framework incorporates a meta optimization scheme that includes virtual training, virtual testing, and meta update steps. By constructing a virtual training set and multiple virtual testing sets with different levels of novel compositions, the framework enables the model to handle various levels of comprehension complexity. We demonstrate the effectiveness of our framework on multiple RES models, achieving consistent performance improvement on three RES benchmarks. Our contributions include the proposal of the MCRES framework, the ability to handle various levels of novel compositions, and consistent performance improvement on multiple models and benchmarks.