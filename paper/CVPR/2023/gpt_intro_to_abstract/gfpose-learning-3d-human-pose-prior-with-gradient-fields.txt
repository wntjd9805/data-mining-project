Modeling 3D human pose is a fundamental problem in various human-centered applications, such as augmented reality, virtual reality, and human-robot collaboration. Previous works have explored different ways to model human pose priors, including explicit joint-angle limits based on biomechanics and probabilistic models learned from data. However, these methods often require additional optimization processes and are limited to specific tasks. In this paper, we propose a novel approach called GFPose to learn a versatile 3D human pose prior model for general purposes. Instead of directly modeling the plausible pose distribution, we learn the score of a task conditional distribution, allowing us to jointly encode the human pose prior and task specifications. To enhance flexibility, we introduce a condition masking strategy, randomly masking task conditions to handle various pose-related tasks in a unified learning-based framework. We present GFPose, a general framework for pose-related tasks, that learns a time-dependent score network to approximate the pose distribution. We evaluate GFPose on various downstream tasks, including 3D pose estimation, denoising, completion, and generation, and demonstrate its superior performance compared to state-of-the-art methods. Our contributions include the introduction of GFPose, the design of a hierarchical condition masking strategy, and the demonstration of improved performance on multiple tasks under a unified framework.