This paper introduces a semantic controllable self-supervised learning framework called SOLIDER for human-centric visual analysis. The framework takes advantage of prior knowledge in human images to discover semantic information and produce pseudo semantic labels for every token. A token-level semantic classification pretext task is then introduced and supervised by these pseudo labels, enabling the training of representations with stronger semantic information. Additionally, a semantic controller is designed to adjust the ratio of semantic information in the representation, allowing for better performance in downstream tasks. The effectiveness of the SOLIDER representation is verified on six human-centric tasks, showcasing its potential to advance the field of computer vision.