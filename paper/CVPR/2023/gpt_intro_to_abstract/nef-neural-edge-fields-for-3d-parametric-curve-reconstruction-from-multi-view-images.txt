Feature curves play a crucial role in defining 3D shapes both geometrically and perceptually. However, traditional approaches to 3D curve extraction are limited by imperfect acquisition and reconstruction, leading to missed or broken edges. Recent learning-based methods have attempted to address these issues but with limited generality. In this paper, we propose a novel approach to 3D feature curve extraction using a neural implicit field representation called Neural Edge Field (NEF). Inspired by the success of Neural Radiance Field (NeRF), we optimize NEF using a view-based rendering loss that compares rendered 2D edge maps to ground-truth edge maps extracted from multi-view images. Our approach differs from NeRF in that our goal is to optimize NEF for extracting parametric 3D curves rather than novel view synthesis. We address the challenges of optimizing NEF density range and handling incompatible visibility by confining the edge density to the range [0, 1] and imposing consistency between density and color in NEF. We fit parametric curves to the 3D edge density volume using an iterative optimization strategy, and evaluate our method on a benchmark dataset consisting of 115 CAD models. Our experiments demonstrate that NEF outperforms existing state-of-the-art methods in 3D edge detection. Our contributions include a self-supervised approach to 3D edge detection, technical designs for range-limited and view-independent NEF, and a benchmark for evaluating edge/curve extraction methods.