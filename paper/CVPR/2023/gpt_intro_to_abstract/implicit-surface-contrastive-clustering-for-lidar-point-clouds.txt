Robust and reliable 3D LiDAR perception is crucial for autonomous driving systems. While LiDAR provides unambiguous measurements of the vehicle's 3D environment, training perception models for LiDAR-based tasks, such as object detection and semantic segmentation, requires a large amount of human annotated data, which is time-consuming and expensive to produce. Self-supervised learning has emerged as a potential solution to improve performance with limited annotated data in the image domain. However, self-supervised learning has shown limited impact for outdoor 3D point clouds due to the challenges in designing appropriate pretext tasks. This paper proposes ISCC (Implicit Surface Contrastive Clustering), a method for automatically learning semantically meaningful feature extraction without annotations for LiDAR point clouds. ISCC consists of two pretext tasks: semantic clustering using contrastive learning and implicit surface reconstruction. The proposed approach outperforms state-of-the-art self-supervised learning techniques in downstream finetuning performance for semantic segmentation and object detection tasks on real-world datasets such as KITTI and Waymo. The learned features also demonstrate semantic consistency and the ability to form semantic groups even without supervised fine-tuning.