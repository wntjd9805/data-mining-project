This paper discusses the importance of sign language understanding in overcoming communication barriers between the deaf or hard of hearing individuals and non-signers. The lack of available data limits the capability of sign language recognition and translation (SLRT). The paper focuses on developing a framework for sign language retrieval, which aims to retrieve the meanings expressed by signers from a closed-set. Sign language retrieval consists of two sub-tasks: text-to-sign-video (T2V) retrieval and sign-video-to-text (V2T) retrieval. The paper addresses the challenges of linguistic rules, data scarcity, and modeling long videos in sign language retrieval. It proposes a framework called CiCo (Cross-lingual Contrastive learning) that utilizes cross-lingual contrastive learning to map sign videos and texts into a joint embedding space. Transfer learning and domain-aware sign encoder techniques are used to fine-tune the framework. The CiCo framework outperforms existing methods on various datasets. It provides a solid baseline for future research in sign language retrieval.