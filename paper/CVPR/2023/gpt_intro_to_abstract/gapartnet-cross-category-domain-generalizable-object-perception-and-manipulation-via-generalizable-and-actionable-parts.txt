Generalizable object perception and manipulation are critical for building intelligent and multifunctional robots. While recent research has focused on category-level object perception and manipulation, there is a need to go beyond intra-category approaches and consider part-level perception and manipulation. In this paper, we propose the concept of Generalizable and Actionable Part (GAPart) classes, which are parts that share similar shapes and can be interacted with in similar ways. We present GAPart-Net, a large-scale dataset with annotated GAPart instances and poses, and use this dataset to explore cross-category tasks such as part segmentation, part pose estimation, and part-based object manipulation. To address the challenge of domain-generalizability, we propose learning domain-invariant representations using domain adversarial learning techniques. We integrate context invariance, multi-resolution, and focal loss techniques to improve the performance of the proposed method. Our method significantly outperforms previous 3D instance segmentation methods, achieving high accuracy on both seen and unseen object categories. Our contributions include the concept of GAPart, the GAPart-Net dataset, and a pipeline for domain-generalizable 3D part segmentation and pose estimation.