With the rise of deep learning methods, image content interpretation and semantic understanding have greatly improved. These models have a wide range of applications in areas such as autonomous driving, healthcare, and security. Semantic segmentation, which assigns pixel-level categories, is a fundamental part of visual interpretation. However, the performance of deep learning segmentation models is often limited by the availability of training data. Traditional segmentation approaches require a fixed set of predefined semantic categories and a large number of training examples per class, which makes it difficult to scale to new classes due to the time-consuming annotation process. Few-shot semantic segmentation (FSS) has emerged as an alternative to address this limitation. In FSS, models are trained on a large labeled dataset of base classes and only a few instances of novel classes are seen during the adaptation stage. However, there are two important limitations in existing FSS methods. First, they assume that the support samples contain the same categories as the query images, which can be costly to manually select. Second, these methods focus on leveraging support samples to extract effective target information but neglect the performance on known categories. Additionally, most FSS approaches are designed for binary classification, which is suboptimal for scenarios with multiple novel categories. To overcome these limitations, a Generalized Few-Shot Semantic Segmentation (GFSS) setting has been introduced. GFSS relaxes the assumption that support and query categories are the same and evaluates performance on both novel and base categories. However, there is still a gap between current experimental protocols and real-world applications. Existing works rely on prior knowledge of the novel classes during training and lack modularity in handling arbitrary tasks at test time. To address these limitations, a new GFSS framework called DIaM is proposed. DIaM is inspired by the InfoMax principle and maximizes the Mutual Information between learned feature representations and predictions. It introduces a Kullback-Leibler term to enforce consistency between base class predictions of the old and new model to reduce performance degradation on known categories. The performance of DIaM is demonstrated on existing GFSS benchmarks, outperforming state-of-the-art methods, particularly in the segmentation of novel classes. Furthermore, a more challenging scenario is presented where the number of base and novel classes is the same, highlighting the need for more modular and scalable methods in handling numerous novel classes.