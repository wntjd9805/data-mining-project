Standard digital photography sensors are limited in their ability to capture the wide range of illumination in natural scenes, resulting in Low Dynamic Range (LDR) images with over or underexposed regions. High Dynamic Range (HDR) imaging has been developed to address this limitation by combining multiple LDR images with different exposures to generate an HDR image. However, HDR imaging techniques can result in ghosting artifacts in dynamic scenes or handheld camera scenarios. Various techniques have been proposed to address these issues, including alignment-based, patch-based, and rejection-based methods. Deep Neural Networks (DNNs) have also been used to improve HDR deghosting, but these methods still have limitations due to the lack of a large amount of HDR-labeled data. In this paper, we propose a semi-supervised approach for HDR deghosting called SSHDR. This approach consists of two stages: a self-supervised learning network for content completion and a sample-quality-based iterative semi-supervised learning for deghosting. In the first stage, we pretrain a Saturated Mask AutoEncoder (SMAE) to generate saturated regions by self-supervised learning. In the second stage, we iteratively train the model with a few labeled samples and a large amount of HDR pseudo-labels from unlabeled data. We also propose an adaptive pseudo-labels selection strategy to pick high-quality HDR pseudo-labels and improve ghost removal. Experimental results demonstrate that our approach achieves state-of-the-art performance on individual and cross-public datasets, generating high-quality HDR images with few labeled samples.