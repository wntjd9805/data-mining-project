Point clouds obtained from 3D scanners are becoming increasingly popular and are essential in 3D geometry processing. However, due to the nature of the scanning process and object occlusion, point clouds are often incomplete, which poses challenges for downstream applications such as reconstruction. Previous works have focused on completing partial point clouds using supervised approaches with artificial complete point cloud data, but these methods are not practical due to the gap between artificial and real scene data. In this paper, we propose an unsupervised symmetric shape-preserving autoencoding network (USSPA) for completing real scene point clouds. Unlike previous domain-transforming methods, USSPA leverages the existing incomplete models and exploits the symmetry present in natural or man-made objects to preserve the shapes of the input. We also introduce a refinement autoencoder to learn detailed structures and an evaluation method using alignment information to accurately assess the completion of real scene objects. Experimental results on various datasets demonstrate the effectiveness and generalization of USSPA, achieving state-of-the-art performance in unsupervised completion of real scene objects. Our contributions include the development of USSPA, a novel symmetry learning module, a refinement autoencoder, and a new evaluation method for assessing completion results.