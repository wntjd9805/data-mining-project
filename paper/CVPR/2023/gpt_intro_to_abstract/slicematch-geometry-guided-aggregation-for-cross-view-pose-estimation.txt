Cross-view camera pose estimation is a technique used to estimate the 3-Degrees-of-Freedom (3-DoF) ground camera pose by comparing ground-level images to geo-referenced aerial images. This estimation can be obtained from a reference database using localization priors like GNSS or image retrieval, but these priors may not always be accurate. The cross-view formulation offers an alternative approach that eliminates the need for detailed 3D point cloud or semantic maps. Previous methods for cross-view camera pose estimation can be categorized as global image descriptor-based or dense pixel-level feature-based. However, these methods have limitations in terms of encoding spatial context and considering camera orientation. To address these gaps, we propose a novel method called SliceMatch. SliceMatch uses a cross-view attention module for ground-view guided feature selection and constructs pose-dependent aerial descriptors by exploiting the geometric relationship between the ground camera's frustum and the aerial image. Our method achieves accurate and efficient camera pose estimation and outperforms previous state-of-the-art methods.