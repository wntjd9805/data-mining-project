Semantic image editing, which involves modifying images by adding, altering, or removing objects, has gained popularity due to its various applications. Current methods have used Generative Adversarial Networks (GAN) to make significant advancements in simpler scenes like landscapes. However, these methods still struggle with complex scenes containing multiple objects and backgrounds. This paper focuses on improving editing performance in these real-world scenarios. Drawing inspiration from how human experts tackle complex tasks by decomposing them into smaller components, we propose a heterogeneous editing model that mimics this process. This model splits the compound content into two distinct components, enabling more effective editing in complex scenes.