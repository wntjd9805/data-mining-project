The accurate tracking and photo-realistic rendering of human-object interactions are crucial for applications such as telepresence, tele-education, and immersive experiences in virtual reality and augmented reality. However, finding a convenient solution for on-the-fly tracking and rendering from monocular input remains a significant challenge in the computer vision community. Early high-end solutions require dense cameras for high-fidelity reconstruction, while recent approaches are able to achieve similar results using fewer RGB or RGBD video inputs. However, these multi-view approaches are still not practical for consumer-level daily usage. Monocular methods with a single RGBD camera are more practical, but existing approaches fail to generate realistic appearance results. Recent advances in neural rendering techniques have enabled photo-realistic rendering with dense-view supervision. However, these methods rely on time-consuming scene-specific training and are not suitable for on-the-fly usage. In this paper, we propose Instant-NVR, an instant neural volumetric rendering system for human-object interactions using a single RGBD camera. Our system enables instant photo-realistic novel view synthesis by generating radiance fields in real-time for both rigid objects and dynamic humans. We employ a combination of non-rigid tracking and volumetric rendering techniques to achieve this. Our approach utilizes off-the-shelf instant segmentation to distinguish between the human and object, and a novel hybrid deformation module to efficiently model human motions. We also introduce an online key-frame selection scheme and a rendering-aware refinement strategy to improve the quality of the synthesized views. Our contributions include the development of the first instant neural rendering system for human-object interactions using an RGBD sensor, an on-the-fly reconstruction scheme for dynamic and static radiance fields, and an online key-frame selection and refinement strategy for real-time and photo-realistic novel-view synthesis.