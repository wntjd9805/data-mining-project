Single domain generalization is a challenging task in computer vision, where the goal is to generalize a model trained on one domain to multiple unseen test domains. Existing approaches have achieved success through data augmentation and adaptive data normalization, but they do not explicitly consider the domain shift between the source and target domains, limiting the model's generalization performance in real-world scenarios. In this paper, we propose a new learning paradigm called simulate-analyze-reduce, which enables the model to analyze the real domain shift and reduce it based on inferred causes. We build an auxiliary domain to simulate the domain shift and learn to analyze the causal factors of the shift. We then propose a meta-causal learning method that uses causal inference to infer the causes of the domain shift, which is applied to align the source and target domains during testing. We also introduce a factor-aware domain alignment technique that reduces the domain shift by learning and integrating multiple feature mappings. Our method achieves state-of-the-art results on image classification benchmarks, demonstrating its effectiveness in addressing single domain generalization.