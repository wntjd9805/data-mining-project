Despite the broad interest in meta-learning, the gener-alization problem remains one of the significant challenges in this field. Existing works focus on meta-generalization to unseen tasks at the meta-level by regularizing the meta-loss, while ignoring that adapted models may not general-ize to the task domains at the adaptation level. In this pa-per, we propose a new regularization mechanism for meta-learning â€“ Minimax-Meta Regularization, which employs inverted regularization at the inner loop and ordinary reg-ularization at the outer loop during training. In particular, the inner inverted regularization makes the adapted model more difficult to generalize to task domains; thus, optimiz-ing the outer-loop loss forces the meta-model to learn meta-knowledge with better generalization. Theoretically, we prove that inverted regularization improves the meta-testing performance by reducing generalization errors. We conduct extensive experiments on the representative scenarios, and the results show that our method consistently improves the performance of meta-learning algorithms. 