Self-supervised pretraining on large unlabeled datasets has shown tremendous success in improving the task per-formance of many 2D and small scale 3D computer vi-sion tasks. However, the popular pretraining approaches have not been impactfully applied to outdoor LiDAR point cloud perception due to the latterâ€™s scene complexity and wide range. We propose a new self-supervised pretrain-ing method ISCC with two novel pretext tasks for LiDAR point clouds. The first task uncovers semantic information by sorting local groups of points in the scene into a glob-ally consistent set of semantically meaningful clusters using contrastive learning, complemented by a second task which reasons about precise surfaces of various parts of the scene through implicit surface reconstruction to learn geomet-ric structures. We demonstrate their effectiveness through transfer learning on 3D object detection and semantic seg-mentation in real world LiDAR scenes. We further design an unsupervised semantic grouping task to show that our approach learns highly semantically meaningful features. 