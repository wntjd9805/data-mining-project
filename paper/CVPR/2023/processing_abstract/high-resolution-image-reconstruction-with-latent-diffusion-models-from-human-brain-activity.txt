Reconstructing visual experiences from human brain ac-tivity offers a unique way to understand how the brain rep-resents the world, and to interpret the connection between computer vision models and our visual system. While deep generative models have recently been employed for this task, reconstructing realistic images with high semantic ﬁ-delity is still a challenging problem. Here, we propose a new method based on a diffusion model (DM) to recon-struct images from human brain activity obtained via func-tional magnetic resonance imaging (fMRI). More speciﬁ-cally, we rely on a latent diffusion model (LDM) termedStable Diffusion. This model reduces the computational cost of DMs, while preserving their high generative perfor-mance. We also characterize the inner mechanisms of theLDM by studying how its different components (such as the latent vector of image Z, conditioning inputs C, and differ-ent elements of the denoising U-Net) relate to distinct brain functions. We show that our proposed method can recon-struct high-resolution images with high ﬁdelity in straight-* Corresponding author forward fashion, without the need for any additional train-ing and ﬁne-tuning of complex deep-learning models. We also provide a quantitative interpretation of different LDM components from a neuroscientiﬁc perspective. Overall, our study proposes a promising method for reconstructing im-ages from human brain activity, and provides a new frame-work for understanding DMs. Please check out our web-page at https://sites.google.com/view/stablediffusion-with-brain/. 