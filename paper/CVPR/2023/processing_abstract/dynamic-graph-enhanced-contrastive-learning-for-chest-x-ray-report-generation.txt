Automatic radiology reporting has great clinical poten-tial to relieve radiologists from heavy workloads and im-prove diagnosis interpretation. Recently, researchers have enhanced data-driven neural networks with medical knowl-edge graphs to eliminate the severe visual and textual bias in this task. The structures of such graphs are exploited by using the clinical dependencies formed by the disease topic tags via general knowledge and usually do not up-date during the training process. Consequently, the fixed graphs can not guarantee the most appropriate scope of knowledge and limit the effectiveness. To address the limi-tation, we propose a knowledge graph with Dynamic struc-ture and nodes to facilitate chest X-ray report generation with Contrastive Learning, named DCL. In detail, the fun-damental structure of our graph is pre-constructed from general knowledge. Then we explore specific knowledge ex-tracted from the retrieved reports to add additional nodes or redefine their relations in a bottom-up manner. Each im-age feature is integrated with its very own updated graph before being fed into the decoder module for report gen-eration. Finally, this paper introduces Image-Report Con-trastive and Image-Report Matching losses to better repre-sent visual features and textual information. Evaluated onIU-Xray and MIMIC-CXR datasets, our DCL outperforms previous state-of-the-art models on these two benchmarks. 