Novel view synthesis with sparse inputs is a challeng-ing problem for neural radiance ﬁelds (NeRF). Recent ef-forts alleviate this challenge by introducing external super-vision, such as pre-trained models and extra depth signals, or by using non-trivial patch-based rendering. In this pa-per, we present Frequency regularized NeRF (FreeNeRF), a surprisingly simple baseline that outperforms previous methods with minimal modiﬁcations to plain NeRF. We an-alyze the key challenges in few-shot neural rendering andﬁnd that frequency plays an important role in NeRF’s train-ing. Based on this analysis, we propose two regularization terms: one to regularize the frequency range of NeRF’s inputs, and the other to penalize the near-camera densityﬁelds. Both techniques are “free lunches” that come at no additional computational cost. We demonstrate that even with just one line of code change, the original NeRF can achieve similar performance to other complicated methods in the few-shot setting. FreeNeRF achieves state-of-the-art performance across diverse datasets, including Blender,DTU, and LLFF. We hope that this simple baseline will mo-tivate a rethinking of the fundamental role of frequency inNeRF’s training, under both the low-data regime and be-yond. This project is released at FreeNeRF. 