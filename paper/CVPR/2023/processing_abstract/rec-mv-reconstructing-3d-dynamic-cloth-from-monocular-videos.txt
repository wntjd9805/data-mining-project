Reconstructing dynamic 3D garment surfaces with open boundaries from monocular videos is an important problem as it provides a practical and low-cost solution for clothes digitization. Recent neural rendering methods achieve high-quality dynamic clothed human reconstruction results from monocular video, but these methods cannot separate the garment surface from the body. Moreover, despite ex-isting garment reconstruction methods based on feature curve representation demonstrating impressive results for garment reconstruction from a single image, they struggle to generate temporally consistent surfaces for the video in-put. To address the above limitations, in this paper, we for-mulate this task as an optimization problem of 3D garment feature curves and surface reconstruction from monocular video. We introduce a novel approach, called REC-MV, to jointly optimize the explicit feature curves and the implicit signed distance Ô¨Åeld (SDF) of the garments. Then the open garment meshes can be extracted via garment template reg-istration in the canonical space. Experiments on multiple casually captured datasets show that our approach outper-forms existing methods and can produce high-quality dy-namic garment surfaces. The source code is available at https://github.com/GAP-LAB-CUHK-SZ/REC-MV. 