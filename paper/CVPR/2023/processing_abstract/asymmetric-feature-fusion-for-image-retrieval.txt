In asymmetric retrieval systems, models with different capacities are deployed on platforms with different compu-tational and storage resources. Despite the great progress, existing approaches still suffer from a dilemma between retrieval efﬁciency and asymmetric accuracy due to the limited capacity of the lightweight query model.In this work, we propose an Asymmetric Feature Fusion (AFF) paradigm, which advances existing asymmetric retrieval systems by considering the complementarity among differ-ent features just at the gallery side. Speciﬁcally, it ﬁrst em-beds each gallery image into various features, e.g., local features and global features. Then, a dynamic mixer is in-troduced to aggregate these features into compact embed-ding for efﬁcient search. On the query side, only a sin-gle lightweight model is deployed for feature extraction.The query model and dynamic mixer are jointly trained by sharing a momentum-updated classiﬁer. Notably, the proposed paradigm boosts the accuracy of asymmetric re-trieval without introducing any extra overhead to the query side. Exhaustive experiments on various landmark retrieval datasets demonstrate the superiority of our paradigm. 