Semi-Supervised Object Detection (SSOD), aiming to ex-plore unlabeled data for boosting object detectors, has be-come an active task in recent years. However, existingSSOD approaches mainly focus on horizontal objects, leav-ing multi-oriented objects that are common in aerial images unexplored. This paper proposes a novel Semi-supervisedOriented Object Detection model, termed SOOD, built upon the mainstream pseudo-labeling framework. Towards ori-ented objects in aerial scenes, we design two loss func-tions to provide better supervision. Focusing on the orien-tations of objects, the first loss regularizes the consistency between each pseudo-label-prediction pair (includes a pre-diction and its corresponding pseudo label) with adaptive weights based on their orientation gap. Focusing on the layout of an image, the second loss regularizes the similar-ity and explicitly builds the many-to-many relation between the sets of pseudo-labels and predictions. Such a global consistency constraint can further boost semi-supervised learning. Our experiments show that when trained with the two proposed losses, SOOD surpasses the state-of-the-art SSOD methods under various settings on the DOTA-v1.5 benchmark. The code will be available at https://github.com/HamPerdredes/SOOD. 