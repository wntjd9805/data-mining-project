Real-world visual search systems involve deployments on multiple platforms with different computing and stor-age resources. Deploying a unified model that suits the minimal-constrain platforms leads to limited accuracy. It is expected to deploy models with different capacities adapt-ing to the resource constraints, which requires features ex-tracted by these models to be aligned in the metric space.The method to achieve feature alignments is called “com-patible learning”. Existing research mainly focuses on the one-to-one compatible paradigm, which is limited in learn-ing compatibility among multiple models. We propose aSwitchable representation learning Framework with Self-Compatibility (SFSC). SFSC generates a series of compati-ble sub-models with different capacities through one train-ing process. The optimization of sub-models faces gradients conflict, and we mitigate this problem from the perspective of the magnitude and direction. We adjust the priorities of sub-models dynamically through uncertainty estimation to co-optimize sub-models properly. Besides, the gradients with conflicting directions are projected to avoid mutual in-terference. SFSC achieves state-of-the-art performance on the evaluated datasets. 