Deep Neural Networks show superior performance in various tasks but are vulnerable to adversarial attacks.Most defense techniques are devoted to the adversarial training strategies, however, it is difficult to achieve satis-factory robust performance only with traditional adversar-ial training. We mainly attribute it to that aggressive per-turbations which lead to the loss increment can always be found via gradient ascent in white-box setting. Although some noises can be involved to prevent attacks from deriv-ing precise gradients on inputs, there exist trade-offs be-tween the defense capability and natural generalization.Taking advantage of the properties of random projection, we propose to replace part of convolutional filters with ran-dom projection filters, and theoretically explore the geomet-ric representation preservation of proposed synthesized fil-ters via Johnson-Lindenstrauss lemma. We conduct suffi-cient evaluation on multiple networks and datasets. The experimental results showcase the superiority of proposed random projection filters to state-of-the-art baselines. The code is available on GitHub. 