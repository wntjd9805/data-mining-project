We present GlassesGAN, a novel image editing frame-work for custom design of glasses, that sets a new stan-dard in terms of output-image quality, edit realism, and continuous multi-style edit capability. To facilitate the editing process with GlassesGAN, we propose a TargetedSubspace Modelling (TSM) procedure that, based on a novel mechanism for (synthetic) appearance discovery in the latent space of a pre-trained GAN generator, constructs an eyeglasses-specific (latent) subspace that the editing framework can utilize. Additionally, we also introduce an appearance-constrained subspace initialization (SI) tech-nique that centers the latent representation of the given in-put image in the well-defined part of the constructed sub-space to improve the reliability of the learned edits. We test GlassesGAN on two (diverse) high-resolution datasets (CelebA-HQ and SiblingsDB-HQf) and compare it to three state-of-the-art baselines, i.e., InterfaceGAN, GANSpace, and MaskGAN. The reported results show that GlassesGAN convincingly outperforms all competing techniques, while*Supported by ARRS J2-2501(A), the Fulbright Scholarship Fund, theCenter for Identification Technology Research, and the National ScienceFoundation under Grant No. 1650503. offering functionality (e.g., fine-grained multi-style editing) not available with any of the competitors. The source code for GlassesGAN is made publicly available. 