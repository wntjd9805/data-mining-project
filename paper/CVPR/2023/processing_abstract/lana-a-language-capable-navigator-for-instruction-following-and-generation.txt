Recently, visual-language navigation (VLN) – entailing robot agents to follow navigation instructions – has shown great advance. However, existing literature put most empha-sis on interpreting instructions into actions, only delivering“dumb” wayfinding agents. In this article, we devise LANA, a language-capable navigation agent which is able to not only execute human-written navigation commands, but also provide route descriptions to humans. This is achieved by si-multaneously learning instruction following and generation with only one single model. More specifically, two encoders, respectively for route and language encoding, are built and shared by two decoders, respectively for action prediction and instruction generation, so as to exploit cross-task know-ledge and capture task-specific characteristics. Throughout pretraining and fine-tuning, both instruction following and generation are set as optimization objectives. We empirically verify that, compared with recent advanced task-specific solutions, LANA attains better performances on both in-struction following and route description, with nearly half complexity. In addition, endowed with language generation capability, LANA can explain to human its behaviours and as-sist human’s wayfinding. This work is expected to foster fu-ture efforts towards building more trustworthy and socially-intelligent navigation robots. 