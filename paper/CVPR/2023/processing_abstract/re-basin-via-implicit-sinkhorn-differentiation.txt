The recent emergence of new algorithms for permuting models into functionally equivalent regions of the solution space has shed some light on the complexity of error sur-faces and some promising properties like mode connectivity.However, ﬁnding the permutation that minimizes some ob-jectives is challenging, and current optimization techniques are not differentiable, which makes it difﬁcult to integrate into a gradient-based optimization, and often leads to sub-optimal solutions. In this paper, we propose a Sinkhorn re-basin network with the ability to obtain the transportation plan that better suits a given objective. Unlike the cur-rent state-of-art, our method is differentiable and, there-fore, easy to adapt to any task within the deep learning do-main. Furthermore, we show the advantage of our re-basin method by proposing a new cost function that allows per-forming incremental learning by exploiting the linear mode connectivity property. The beneﬁt of our method is com-pared against similar approaches from the literature un-der several conditions for both optimal transport and linear mode connectivity. The effectiveness of our continual learn-ing method based on re-basin is also shown for several com-mon benchmark datasets, providing experimental results that are competitive with the state-of-art. The source code is provided at https://github.com/fagp/sinkhorn-rebasin. 