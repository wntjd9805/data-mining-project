Sarcasm indicates the literal meaning is contrary to the real attitude. Considering the popularity and complemen-tarity of image-text data, we investigate the task of multi-modal sarcasm detection. Diﬀerent from other multi-modal tasks, for the sarcastic data, there exists intrinsic incon-gruity between a pair of image and text as demonstrated in psychological theories. To tackle this issue, we pro-pose a Dual Incongruity Perceiving (DIP) network con-sisting of two branches to mine the sarcastic information from factual and aﬀective levels. For the factual aspect, we introduce a channel-wise reweighting strategy to ob-tain semantically discriminative embeddings, and leverage gaussian distribution to model the uncertain correlation caused by the incongruity. The distribution is generated from the latest data stored in the memory bank, which can adaptively model the diﬀerence of semantic similarity be-tween sarcastic and non-sarcastic data. For the aﬀective aspect, we utilize siamese layers with shared parameters to learn cross-modal sentiment information. Furthermore, we use the polarity value to construct a relation graph for the mini-batch, which forms the continuous contrastive loss to acquire aﬀective embeddings. Extensive experiments demonstrate that our proposed method performs favorably against state-of-the-art approaches. Our code is released on https://github.com/downdric/MSD. 