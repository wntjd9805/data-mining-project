Despite the tremendous progress on data-free knowledge distillation (DFKD) based on synthetic data generation, there are still limitations in diverse and efficient data syn-thesis. It is naive to expect that a simple combination of generative network-based data synthesis and data augmen-tation will solve these issues. Therefore, this paper proposes a novel data-free knowledge distillation method (Spaceship-Net) based on channel-wise feature exchange (CFE) and multi-scale spatial activation region consistency (mSARC) constraint. Specifically, CFE allows our generative net-work to better sample from the feature space and efficiently synthesize diverse images for learning the student network.However, using CFE alone can severely amplify the un-wanted noises in the synthesized images, which may result in failure to improve distillation learning and even have negative effects. Therefore, we propose mSARC to assure the student network can imitate not only the logit output but also the spatial activation region of the teacher network in order to alleviate the influence of unwanted noises in di-verse synthetic images on distillation learning. Extensive experiments on CIFAR-10, CIFAR-100, Tiny-ImageNet, Im-agenette, and ImageNet100 show that our method can work well with different backbone networks, and outperform the state-of-the-art DFKD methods. Code will be available at: https://github.com/skgyu/SpaceshipNet.*Equal contributionThis research was supported in part by the National Key R&D Pro-gram of China (grant 2018AAA0102500), and the National Natural Sci-ence Foundation of China (grant 62176249). 