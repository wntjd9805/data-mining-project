RENDERINGSCENE EDITINGIn this work, we present I2-SDF, a new method for in-trinsic indoor scene reconstruction and editing using dif-ferentiable Monte Carlo raytracing on neural signed dis-tance fields (SDFs). Our holistic neural SDF-based frame-work jointly recovers the underlying shapes, incident ra-diance and materials from multi-view images. We intro-duce a novel bubble loss for fine-grained small objects and error-guided adaptive sampling scheme to largely improve the reconstruction quality on large-scale indoor scenes.Further, we propose to decompose the neural radiance field into spatially-varying material of the scene as a neu-ral field through surface-based, differentiable Monte Carlo raytracing and emitter semantic segmentations, which en-ables physically based and photorealistic scene relighting and editing applications. Through a number of qualita-tive and quantitative experiments, we demonstrate the su-perior quality of our method on indoor scene reconstruc-tion, novel view synthesis, and scene editing compared to state-of-the-art baselines. Our project page is at https://jingsenzhu.github.io/i2-sdf. 