The cost of pathological examination makes virtual re-staining of pathological images meaningful. However, due to the ultra-high resolution of pathological images, tradi-tional virtual re-staining methods have to divide a WSI im-age into patches for model training and inference. Such a limitation leads to the lack of global information, result-ing in observable differences in color, brightness and con-trast when the re-stained patches are merged to generate an image of larger size. We summarize this issue as the square effect. Some existing methods try to solve this is-sue through overlapping between patches or simple post-processing. But the former one is not that effective, while the latter one requires carefully tuning. In order to elim-inate the square effect, we design a bi-directional feature fusion generative adversarial network (BFF-GAN) with aIt learns the inter-global branch and a local branch. patch connections through the fusion of global and local features plus patch-wise attention. We perform experiments on both the private dataset RCC and the public dataset AN-HIR. The results show that our model achieves competitive performance and is able to generate extremely real images that are deceptive even for experienced pathologists, which means it is of great clinical significance. 