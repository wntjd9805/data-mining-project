We develop a simple yet surprisingly effective implicit representing scheme called Multiplicative Fourier Level ofDetail (MFLOD) motivated by the recent success of mul-tiplicative filter network. Built on multi-resolution feature grid/volume (e.g., the sparse voxel octree), each level’s fea-ture is first modulated by a sinusoidal function and then element-wisely multiplied by a linear transformation of pre-vious layer’s representation in a layer-to-layer recursive manner, yielding the scale-aggregated encodings for a sub-sequent simple linear forward to get final output. In con-trast to previous hybrid representations relying on inter-leaved multilevel fusion and nonlinear activation-based de-coding, MFLOD could be elegantly characterized as a lin-ear combination of sine basis functions with varying am-plitude, frequency, and phase upon the learned multilevel features, thus offering great feasibility in Fourier analysis.Comprehensive experimental results on implicit neural rep-resentation learning tasks including image fitting, 3D shape representation, and neural radiance fields well demonstrate the superior quality and generalizability achieved by the proposed MFLOD scheme. 