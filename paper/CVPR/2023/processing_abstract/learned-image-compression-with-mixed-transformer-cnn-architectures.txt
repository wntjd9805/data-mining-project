Learned image compression (LIC) methods have exhib-ited promising progress and superior rate-distortion per-formance compared with classical image compression stan-dards. Most existing LIC methods are Convolutional NeuralNetworks-based (CNN-based) or Transformer-based, which have different advantages. Exploiting both advantages is a point worth exploring, which has two challenges: 1) how to effectively fuse the two methods? 2) how to achieve higher performance with a suitable complexity? In this pa-per, we propose an efficient parallel Transformer-CNN Mix-ture (TCM) block with a controllable complexity to incor-porate the local modeling ability of CNN and the non-local modeling ability of transformers to improve the overall ar-chitecture of image compression models. Besides, inspired by the recent progress of entropy estimation models and at-tention modules, we propose a channel-wise entropy model with parameter-efficient swin-transformer-based attention (SWAtten) modules by using channel squeezing. Experi-mental results demonstrate our proposed method achieves state-of-the-art rate-distortion performances on three dif-ferent resolution datasets (i.e., Kodak, Tecnick, CLIC Pro-fessional Validation) compared to existing LIC methods.The code is at https://github.com/jmliu206/LIC_TCM . 