Real-time efficient perception is critical for autonomous navigation and city scale sensing. Orthogonal to archi-tectural improvements, streaming perception approaches have exploited adaptive sampling improving real-time de-tection performance. In this work, we propose a learnable geometry-guided prior that incorporates rough geometry of the 3D scene (a ground plane and a plane above) to re-sample images for efficient object detection. This signifi-cantly improves small and far-away object detection per-formance while also being more efficient both in terms of latency and memory. For autonomous navigation, using the same detector and scale, our approach improves detection rate by +4.1 APS or +39% and in real-time performance by +5.3 sAPS or +63% for small objects over state-of-the-art (SOTA). For fixed traffic cameras, our approach detects small objects at image scales other methods cannot. At the same scale, our approach improves detection of small ob-jects by 195% (+12.5 APS) over naive-downsampling and 63% (+4.2 APS) over SOTA. 