Learning a generalizable and comprehensive similarity metric to depict the semantic discrepancies between images is the foundation of many computer vision tasks. While ex-isting methods approach this goal by learning an ensemble of embeddings with diverse objectives, the backbone net-work still receives a mix of all the training signals. Differ-ently, we propose a deep factorized metric learning (DFML) method to factorize the training signal and employ different samples to train various components of the backbone net-work. We factorize the network to different sub-blocks and devise a learnable router to adaptively allocate the training samples to each sub-block with the objective to capture the most information. The metric model trained by DFML cap-ture different characteristics with different sub-blocks and constitutes a generalizable metric when using all the sub-blocks. The proposed DFML achieves state-of-the-art per-formance on all three benchmarks for deep metric learn-ing including CUB-200-2011, Cars196, and Stanford On-line Products. We also generalize DFML to the image clas-sification task on ImageNet-1K and observe consistent im-provement in accuracy/computation trade-off. Specifically, we improve the performance of ViT-B on ImageNet (+0.2% accuracy) with less computation load (-24% FLOPs). 1 