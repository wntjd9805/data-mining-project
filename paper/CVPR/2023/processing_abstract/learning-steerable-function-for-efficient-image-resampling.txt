Image resampling is a basic technique that is widely employed in daily applications. Existing deep neural net-works (DNNs) have made impressive progress in resam-pling performance. Yet these methods are still not the per-fect substitute for interpolation, due to the issues of effi-ciency and continuous resampling. In this work, we propose a novel method of Learning Resampling Function (termedLeRF), which takes advantage of both the structural priors learned by DNNs and the locally continuous assumption of interpolation methods. Specifically, LeRF assigns spatially-varying steerable resampling functions to input image pix-els and learns to predict the hyper-parameters that deter-mine the orientations of these resampling functions with a neural network. To achieve highly efficient inference, we adopt look-up tables (LUTs) to accelerate the inference of the learned neural network. Furthermore, we design a directional ensemble strategy and edge-sensitive indexing patterns to better capture local structures. Extensive exper-iments show that our method runs as fast as interpolation, generalizes well to arbitrary transformations, and outper-forms interpolation significantly, e.g., up to 3dB PSNR gain over bicubic for Ã—2 upsampling on Manga109. 