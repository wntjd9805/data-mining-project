Video snapshot compressive imaging (SCI) uses a two-dimensional detector to capture consecutive video frames during a single exposure time. Following this, an effi-cient reconstruction algorithm needs to be designed to re-construct the desired video frames. Although recent deep learning-based state-of-the-art (SOTA) reconstruction al-gorithms have achieved good results in most tasks, they still face the following challenges due to excessive model complexity and GPU memory limitations: 1) these models need high computational cost, and 2) they are usually un-able to reconstruct large-scale video frames at high com-pression ratios. To address these issues, we develop an ef-ficient network for video SCI by using dense connections and space-time factorization mechanism within a single residual block, dubbed EfficientSCI. The EfficientSCI net-work can well establish spatial-temporal correlation by us-ing convolution in the spatial domain and Transformer in the temporal domain, respectively. We are the first time to show that an UHD color video with high compression ra-tio can be reconstructed from a snapshot 2D measurement using a single end-to-end deep learning model with PSNR above 32 dB. Extensive results on both simulation and real data show that our method significantly outperforms all pre-vious SOTA algorithms with better real-time performance.The code is at https://github.com/ucaswangls/EfficientSCI.git. 