Referring expression segmentation aims to segment an object described by a language expression from an image.Despite the recent progress on this task, existing models tackling this task may not be able to fully capture semantics and visual representations of individual concepts, which limits their generalization capability, especially when han-dling novel compositions of learned concepts. In this work, through the lens of meta learning, we propose a Meta Com-positional Referring Expression Segmentation (MCRES) framework to enhance model compositional generalization performance. Specifically, to handle various levels of novel compositions, our framework first uses training data to con-struct a virtual training set and multiple virtual testing sets, where data samples in each virtual testing set contain a level of novel compositions w.r.t. the virtual training set.Then, following a novel meta optimization scheme to opti-mize the model to obtain good testing performance on the virtual testing sets after training on the virtual training set, our framework can effectively drive the model to better cap-ture semantics and visual representations of individual con-cepts, and thus obtain robust generalization performance even when handling novel compositions. Extensive experi-ments on three benchmark datasets demonstrate the effec-tiveness of our framework. 