The deep neural networks (DNNs) trained by adversarial training (AT) usually suffered from significant robust gener-alization gap, i.e., DNNs achieve high training robustness but low test robustness. In this paper, we propose a generic method to boost the robust generalization of AT methods from the novel perspective of attribution span. To this end, compared with standard DNNs, we discover that the gen-eralization gap of adversarially trained DNNs is caused by the smaller attribution span on the input image. In other words, adversarially trained DNNs tend to focus on specific visual concepts on training images, causing its limitation on test robustness. In this way, to enhance the robustness, we propose an effective method to enlarge the learned at-tribution span. Besides, we use hybrid feature statistics for feature fusion to enrich the diversity of features. Extensive experiments show that our method can effectively improves robustness of adversarially trained DNNs, outperforming previous SOTA methods. Furthermore, we provide a the-oretical analysis of our method to prove its effectiveness.Figure 1. A visual illustration of attribution span under ResNet-18. (a) is the original image; (b) and (c) are attribution spans of the standard model and robust model in the inference phase, re-spectively. ASC is Attribution Span Coverage; (d) is the differ-ence between the standard model and the robust model in terms of attribution span; (e) is the result after partial feature erasure of the original image using (d). 