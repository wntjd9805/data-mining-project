Generating faithful visualizations of human faces re-quires capturing both coarse and ﬁne-level details of the face geometry and appearance. Existing methods are either data-driven, requiring an extensive corpus of data not pub-licly accessible to the research community, or fail to cap-ture ﬁne details because they rely on geometric face mod-els that cannot represent ﬁne-grained details in texture with a mesh discretization and linear deformation designed to model only a coarse face geometry. We introduce a method that bridges this gap by drawing inspiration from tradi-tional computer graphics techniques. Unseen expressions†Work done during an internship at Microsoft Research Cambridge.‡Work done at Simon Fraser University. are modeled by blending appearance from a sparse set of extreme poses. This blending is performed by measuring local volumetric changes in those expressions and locally reproducing their appearance whenever a similar expres-sion is performed at test time. We show that our method generalizes to unseen expressions, adding ﬁne-grained ef-fects on top of smooth volumetric deformations of a face, and demonstrate how it generalizes beyond faces. 