Recently, deep learning-based facial landmark detection has achieved signiﬁcant improvement. However, the se-mantic ambiguity problem degrades detection performance.Speciﬁcally, the semantic ambiguity causes inconsistent an-notation and negatively affects the model’s convergence, leading to worse accuracy and instability prediction. To solve this problem, we propose a Self-adapTive AmbiguityReduction (STAR) loss by exploiting the properties of se-mantic ambiguity. We ﬁnd that semantic ambiguity results in the anisotropic predicted distribution, which inspires us to use predicted distribution to represent semantic ambi-guity. Based on this, we design the STAR loss that mea-sures the anisotropism of the predicted distribution. Com-pared with the standard regression loss, STAR loss is en-couraged to be small when the predicted distribution is anisotropic and thus adaptively mitigates the impact of se-mantic ambiguity. Moreover, we propose two kinds of eigen-value restriction methods that could avoid both distribu-tion’s abnormal change and the model’s premature con-vergence. Finally, the comprehensive experiments demon-strate that STAR loss outperforms the state-of-the-art meth-ods on three benchmarks, i.e., COFW, 300W, and WFLW, with negligible computation overhead. Code is at https://github.com/ZhenglinZhou/STAR 