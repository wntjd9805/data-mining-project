We study the problem of reconstructing 3D feature curves of an object from a set of calibrated multi-view im-ages. To do so, we learn a neural implicit ﬁeld repre-senting the density distribution of 3D edges which we re-fer to as Neural Edge Field (NEF). Inspired by NeRF [20],NEF is optimized with a view-based rendering loss where a 2D edge map is rendered at a given view and is com-pared to the ground-truth edge map extracted from the im-age of that view. The rendering-based differentiable opti-mization of NEF fully exploits 2D edge detection, without needing a supervision of 3D edges, a 3D geometric oper-ator or cross-view edge correspondence. Several technical designs are devised to ensure learning a range-limited and view-independent NEF for robust edge extraction. The ﬁ-nal parametric 3D curves are extracted from NEF with an iterative optimization method. On our benchmark with syn-thetic data, we demonstrate that NEF outperforms exist-ing state-of-the-art methods on all metrics. Project page: https://yunfan1202.github.io/NEF/. 