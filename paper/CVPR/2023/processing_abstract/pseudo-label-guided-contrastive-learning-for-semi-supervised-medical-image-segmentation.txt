Although recent works in semi-supervised learning (SemiSL) have accomplished significant success in nat-ural image segmentation, the task of learning discrimi-native representations from limited annotations has been an open problem in medical images. Contrastive Learn-ing (CL) frameworks use the notion of similarity measure which is useful for classification problems, however, they fail to transfer these quality representations for accurate pixel-level segmentation. To this end, we propose a novel semi-supervised patch-based CL framework for medical im-age segmentation without using any explicit pretext task.We harness the power of both CL and SemiSL, where the pseudo-labels generated from SemiSL aid CL by providing additional guidance, whereas discriminative class informa-tion learned in CL leads to accurate multi-class segmen-tation. Additionally, we formulate a novel loss that syn-ergistically encourages inter-class separability and intra-class compactness among the learned representations. A new inter-patch semantic disparity mapping using aver-age patch entropy is employed for a guided sampling of positives and negatives in the proposed CL framework.Experimental analysis on three publicly available datasets of multiple modalities reveals the superiority of our pro-posed method as compared to the state-of-the-art methods.Code is available at: GitHub. 