Weakly-supervised temporal action localization aims to localize and recognize actions in untrimmed videos with only video-level category labels during training. Without instance-level annotations, most existing methods follow theSegment-based Multiple Instance Learning (S-MIL) frame-work, where the predictions of segments are supervised by the labels of videos. However, the objective for acquiring segment-level scores during training is not consistent with the target for acquiring proposal-level scores during test-ing, leading to suboptimal results. To deal with this prob-lem, we propose a novel Proposal-based Multiple InstanceLearning (P-MIL) framework that directly classiÔ¨Åes the candidate proposals in both the training and testing stages, which includes three key designs: 1) a surrounding con-trastive feature extraction module to suppress the discrimi-native short proposals by considering the surrounding con-trastive information, 2) a proposal completeness evaluation module to inhibit the low-quality proposals with the guid-ance of the completeness pseudo labels, and 3) an instance-level rank consistency loss to achieve robust detection by leveraging the complementarity of RGB and FLOW modal-ities. Extensive experimental results on two challenging benchmarks including THUMOS14 and ActivityNet demon-strate the superior performance of our method. Our code is available at github.com/RenHuan1999/CVPR2023 P-MIL. 