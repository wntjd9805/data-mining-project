We consider the challenging task of training models for image-to-video deblurring, which aims to recover a se-quence of sharp images corresponding to a given blurry image input. A critical issue disturbing the training of an image-to-video model is the ambiguity of the frame or-dering since both the forward and backward sequences are plausible solutions. This paper proposes an effective self-supervised ordering scheme that allows training high-quality image-to-video deblurring models. Unlike previous methods that rely on order-invariant losses, we assign an explicit order for each video sequence, thus avoiding the order-ambiguity issue. Specifically, we map each video se-quence to a vector in a latent high-dimensional space so that there exists a hyperplane such that for every video se-quence, the vectors extracted from it and its reversed se-quence are on different sides of the hyperplane. The side of the vectors will be used to define the order of the corre-sponding sequence. Last but not least, we propose a real-image dataset for the image-to-video deblurring problem that covers a variety of popular domains, including face, hand, and street. Extensive experimental results confirm the effectiveness of our method. Code and data are avail-able at https://github.com/VinAIResearch/HyperCUT.git 