Self-supervised learning in vision–language processing (VLP) exploits semantic alignment between imaging and text modalities. Prior work in biomedical VLP has mostly relied on the alignment of single image and report pairs even though clinical notes commonly refer to prior im-ages. This does not only introduce poor alignment be-tween the modalities but also a missed opportunity to ex-ploit rich self-supervision through existing temporal con-tent in the data.In this work, we explicitly account for prior images and reports when available during both train-ing and fine-tuning. Our approach, named BioViL-T, uses a CNN–Transformer hybrid multi-image encoder trained jointly with a text model.It is designed to be versatile to arising challenges such as pose variations and miss-ing input images across time. The resulting model excels on downstream tasks both in single- and multi-image se-tups, achieving state-of-the-art (SOTA) performance on (I) progression classification, (II) phrase grounding, and (III) report generation, whilst offering consistent improvements on disease classification and sentence-similarity tasks. We release a novel multi-modal temporal benchmark dataset,MS-CXR-T, to quantify the quality of vision–language rep-resentations in terms of temporal semantics. Our experi-mental results show the advantages of incorporating prior images and reports to make most use of the data.Figure 1. (a) Existing visual–language pre-training approaches[9, 32, 81] often use only a single image for contrastive learning (e.g., InfoNCE [49]). (b) In such settings, discarding the temporal connectivity of images limits the alignment of image–text pairs as shown with the affinity matrix, leading to suboptimal pre-training and missed opportunity to create additional model supervision for free. (c, d) Our approach exploits this domain knowledge by learn-ing to incorporate a series of images and correlate them to reports, leading to pre-trained models that can generalise to a wider range of downstream tasks whilst achieving SOTA performance. 