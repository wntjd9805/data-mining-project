Parameter regularization or allocation methods are ef-fective in overcoming catastrophic forgetting in lifelong learning. However, they solve all tasks in a sequence uni-formly and ignore the differences in the learning difficulty of different tasks. So parameter regularization methods face significant forgetting when learning a new task very dif-ferent from learned tasks, and parameter allocation meth-ods face unnecessary parameter overhead when learning simple tasks.In this paper, we propose the ParameterAllocation & Regularization (PAR), which adaptively select an appropriate strategy for each task from parameter allo-cation and regularization based on its learning difficulty.A task is easy for a model that has learned tasks related to it and vice versa. We propose a divergence estimation method based on the Nearest-Prototype distance to mea-sure the task relatedness using only features of the new task.Moreover, we propose a time-efficient relatedness-aware sampling-based architecture search strategy to reduce the parameter overhead for allocation. Experimental results on multiple benchmarks demonstrate that, compared withSOTAs, our method is scalable and significantly reduces the model’s redundancy while improving the model’s per-formance. Further qualitative analysis indicates that PAR obtains reasonable task-relatedness. 