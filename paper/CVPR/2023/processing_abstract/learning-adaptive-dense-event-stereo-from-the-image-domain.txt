Recently, event-based stereo matching has been studied due to its robustness in poor light conditions. However, existing event-based stereo networks suffer severe perfor-mance degradation when domains shift. Unsupervised do-main adaptation (UDA) aims at resolving this problem with-out using the target domain ground-truth. However, tradi-tional UDA still needs the input event data with ground-truth in the source domain, which is more challenging and costly to obtain than image data. To tackle this issue, we propose a novel unsupervised domain Adaptive DenseEvent Stereo (ADES), which resolves gaps between the dif-ferent domains and input modalities. The proposed ADES framework adapts event-based stereo networks from abun-dant image datasets with ground-truth on the source do-main to event datasets without ground-truth on the target domain, which is a more practical setup. First, we pro-pose a self-supervision module that trains the network on the target domain through image reconstruction, while an artifact prediction network trained on the source domain as-sists in removing intermittent artifacts in the reconstructed image. Secondly, we utilize the feature-level normalization scheme to align the extracted features along the epipolar line. Finally, we present the motion-invariant consistency module to impose the consistent output between the per-turbed motion. Our experiments demonstrate that our ap-proach achieves remarkable results in the adaptation ability of event-based stereo matching from the image domain. 