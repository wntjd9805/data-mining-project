Analyzing the dynamic changes of cellular morphol-ogy is important for understanding the various functions and characteristics of live cells, including stem cells and metastatic cancer cells. To this end, we need to track all points on the highly deformable cellular contour in every frame of live cell video. Local shapes and textures on the contour are not evident, and their motions are complex, of-ten with expansion and contraction of local contour fea-tures. The prior arts for optical ﬂow or deep point set tracking are unsuited due to the ﬂuidity of cells, and pre-vious deep contour tracking does not consider point cor-respondence. We propose the ﬁrst deep learning-based tracking of cellular (or more generally viscoelastic mate-rials) contours with point correspondence by fusing dense representation between two contours with cross attention.Since it is impractical to manually label dense tracking points on the contour, unsupervised learning comprised of the mechanical and cyclical consistency losses is proposed to train our contour tracker. The mechanical loss forcing the points to move perpendicular to the contour effectively helps out. For quantitative evaluation, we labeled sparse tracking points along the contour of live cells from two live cell datasets taken with phase contrast and confocalﬂuorescence microscopes. Our contour tracker quantita-tively outperforms compared methods and produces quali-tatively more favorable results. Our code and data are pub-licly available at https://github.com/JunbongJang/ contour-tracking/ 