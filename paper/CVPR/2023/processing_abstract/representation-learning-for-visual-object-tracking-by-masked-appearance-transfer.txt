Visual representation plays an important role in visual object tracking. However, few works study the tracking-specified representation learning method. Most trackers directly use ImageNet pre-trained representations. In this paper, we propose masked appearance transfer, a simple but effective representation learning method for tracking, based on an encoder-decoder architecture. First, we en-code the visual appearances of the template and search region jointly, and then we decode them separately. Dur-ing decoding, the original search region image is recon-structed. However, for the template, we make the decoder reconstruct the target appearance within the search region.By this target appearance transfer, the tracking-specified representations are learned. We randomly mask out the inputs, thereby making the learned representations more dis-criminative. For sufficient evaluation, we design a simple and lightweight tracker that can evaluate the representa-tion for both target localization and box regression. Exten-sive experiments show that the proposed method is effec-tive, and the learned representations can enable the simple tracker to obtain state-of-the-art performance on six datasets. https://github.com/difhnp/MAT 