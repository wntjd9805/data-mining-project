Recently, vision transformers have shown great success in a set of human reconstruction tasks such as 2D/3D hu-man pose estimation (2D/3D HPE) and human mesh recon-struction (HMR) tasks.In these tasks, feature map rep-resentations of the human structural information are of-ten extracted first from the image by a CNN (such as HR-Net), and then further processed by transformer to predict the heatmaps for HPE or HMR. However, existing trans-former architectures are not able to process these feature map inputs directly, forcing an unnatural flattening of the location-sensitive human structural information. Further-more, much of the performance benefit in recent HPE andHMR methods has come at the cost of ever-increasing com-putation and memory needs. Therefore, to simultaneously address these problems, we propose FeatER, a novel trans-former design that preserves the inherent structure of fea-ture map representations when modeling attention while re-ducing memory and computational costs. Taking advan-tage of FeatER, we build an efficient network for a set of human reconstruction tasks including 2D HPE, 3D HPE, and HMR. A feature map reconstruction module is applied to improve the performance of the estimated human pose and mesh. Extensive experiments demonstrate the effective-ness of FeatER on various human pose and mesh datasets.For instance, FeatER outperforms the SOTA method Mesh-Graphormer by requiring 5% of Params and 16% of MACs on Human3.6M and 3DPW datasets. The project webpage is https://zczcwh.github.io/feater_page/. 