Low-light image enhancement (LLIE) investigates how to improve illumination and produce normal-light images.The majority of existing methods improve low-light images via a global and uniform manner, without taking into ac-count the semantic information of different regions. With-out semantic priors, a network may easily deviate from a regionâ€™s original color. To address this issue, we propose a novel semantic-aware knowledge-guided framework (SKF) that can assist a low-light enhancement model in learning rich and diverse priors encapsulated in a semantic segmen-tation model. We concentrate on incorporating semantic knowledge from three key aspects: a semantic-aware em-bedding module that wisely integrates semantic priors in feature representation space, a semantic-guided color his-togram loss that preserves color consistency of various in-stances, and a semantic-guided adversarial loss that pro-duces more natural textures by semantic priors. Our SKF is appealing in acting as a general framework in LLIE task. Extensive experiments show that models equipped with the SKF significantly outperform the baselines on mul-tiple datasets and our SKF generalizes to different models and scenes well. The code is available at Semantic-Aware-Low-Light-Image-Enhancement 