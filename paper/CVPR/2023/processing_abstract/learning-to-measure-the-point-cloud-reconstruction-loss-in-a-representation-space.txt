For point cloud reconstruction-related tasks, the recon-struction losses to evaluate the shape differences between reconstructed results and the ground truths are typically used to train the task networks. Most existing works mea-sure the training loss with point-to-point distance, which may introduce extra defects as predeﬁned matching rules may deviate from the real shape differences. Although some learning-based works have been proposed to overcome the weaknesses of manually-deﬁned rules, they still measure the shape differences in 3D Euclidean space, which may limit their ability to capture defects in reconstructed shapes. In this work, we propose a learning-based Contrastive Adver-sarial Loss (CALoss) to measure the point cloud reconstruc-tion loss dynamically in a non-linear representation space by combining the contrastive constraint with the adversar-ial strategy. Speciﬁcally, we use the contrastive constraint to help CALoss learn a representation space with shape sim-ilarity, while we introduce the adversarial strategy to helpCALoss mine differences between reconstructed results and ground truths. According to experiments on reconstruction-related tasks, CALoss can help task networks improve re-construction performances and learn more representative representations.Figure 1. Sg and So denote ground truths and point clouds gen-erated by the task network. Sp is a positive sample with similar shapes as Sg acquired by perturbation [2]. Matching-based losses measure distances between points matched by different predeﬁned rules. PCLoss [6] learns to extract descriptors in 3D Euclidean space by linearly weighting coordinates according to their dis-tances to predicted center points, while our method dynamically measures the shape differences with distances between learned global representations in the constructed representation space. Lp and Lr denote representation distances between Sg, Sp and Sg,So, respectively. Ladv is an adversarial loss to maximize represen-r tation distances between Sg, So. Ladv and Lp are used to optimizeCALoss, while Lr is adopted to train the task network. r 