Recently, open-vocabulary learning has emerged to ac-complish segmentation for arbitrary categories of text-based descriptions, which popularizes the segmentation system to more general-purpose application scenarios.However, existing methods devote to designing specialized architectures or parameters for specific segmentation tasks.These customized design paradigms lead to fragmentation between various segmentation tasks, thus hindering the uni-formity of segmentation models. Hence in this paper, we propose FreeSeg, a generic framework to accomplish Uni-fied, Universal and Open-Vocabulary Image Segmentation.FreeSeg optimizes an all-in-one network via one-shot train-ing and employs the same architecture and parameters to handle diverse segmentation tasks seamlessly in the in-ference procedure. Additionally, adaptive prompt learn-ing facilitates the unified model to capture task-aware and category-sensitive concepts, improving model robustness in multi-task and varied scenarios. Extensive experimental re-sults demonstrate that FreeSeg establishes new state-of-the-art results in performance and generalization on three seg-⋆Equal contribution. †Corresponding author. This work was done while Jie Qin interned at ByteDance. mentation tasks, which outperforms the best task-specific architectures by a large margin: 5.5% mIoU on seman-tic segmentation, 17.6% mAP on instance segmentation, 20.1% PQ on panoptic segmentation for the unseen class on COCO. Project page: https://FreeSeg.github.io. 