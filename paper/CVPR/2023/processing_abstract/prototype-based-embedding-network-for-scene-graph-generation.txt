Current Scene Graph Generation (SGG) methods ex-plore contextual information to predict relationships among entity pairs. However, due to the diverse visual appearance of numerous possible subject-object combinations, there is a large intra-class variation within each predicate cat-egory, e.g., “man-eating-pizza, giraffe-eating-leaf”, and the severe inter-class similarity between different classes, e.g., “man-holding-plate, man-eating-pizza”, in model’s la-tent space. The above challenges prevent current SGG methods from acquiring robust features for reliable rela-tion prediction.In this paper, we claim that the predi-cate’s category-inherent semantics can serve as class-wise prototypes in the semantic space for relieving the chal-lenges. To the end, we propose the Prototype-based Embed-ding Network (PE-Net), which models entities/predicates with prototype-aligned compact and distinctive representa-tions and thereby establishes matching between entity pairs and predicates in a common embedding space for relation recognition. Moreover, Prototype-guided Learning (PL) is introduced to help PE-Net efficiently learn such entity-predicate matching, and Prototype Regularization (PR) is devised to relieve the ambiguous entity-predicate match-ing caused by the predicate’s semantic overlap. Exten-sive experiments demonstrate that our method gains su-perior relation recognition capability on SGG, achieving new state-of-the-art performances on both Visual Genome and Open Images datasets. The codes are available at https://github.com/VL-Group/PENET. 