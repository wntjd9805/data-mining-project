Motivated by the increasing popularity of transformers in computer vision, in recent times there has been a rapid development of novel architectures. While in-domain per-formance follows a constant, upward trend, properties like robustness or uncertainty estimation are less exploredâ€” leaving doubts about advances in model reliability. Studies along these axes exist, but they are mainly limited to classifi-cation models. In contrast, we carry out a study on semantic segmentation, a relevant task for many real-world applica-tions where model reliability is paramount. We analyze a broad variety of models, spanning from older ResNet-based architectures to novel transformers and assess their relia-bility based on four metrics: robustness, calibration, mis-classification detection and out-of-distribution (OOD) de-tection. We find that while recent models are significantly more robust, they are not overall more reliable in terms of uncertainty estimation. We further explore methods that can come to the rescue and show that improving calibration can also help with other uncertainty metrics such as misclassi-fication or OOD detection. This is the first study on modern segmentation models focused on both robustness and uncer-tainty estimation and we hope it will help practitioners and researchers interested in this fundamental vision task1. 