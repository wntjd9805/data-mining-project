importantPredicting human gaze is in Human-Computer Interaction (HCI). However, to practically serveHCI applications, gaze prediction models must be scalable, fast, and accurate in their spatial and temporal gaze pre-dictions. Recent scanpath prediction models focus on goal-directed attention (search). Such models are limited in their application due to a common approach relying on trained target detectors for all possible objects, and the availabil-ity of human gaze data for their training (both not scal-able). In response, we pose a new task called ZeroGaze, a new variant of zero-shot learning where gaze is pre-dicted for never-before-searched objects, and we develop a novel model, Gazeformer, to solve the ZeroGaze prob-lem.In contrast to existing methods using object detec-tor modules, Gazeformer encodes the target using a natu-ral language model, thus leveraging semantic similarities in scanpath prediction. We use a transformer-based encoder-decoder architecture because transformers are particularly useful for generating contextual representations. Gaze-former surpasses other models by a large margin (19%â€“ 70%) on the ZeroGaze setting. It also outperforms exist-ing target-detection models on standard gaze prediction for both target-present and target-absent search tasks. In ad-dition to its improved performance, Gazeformer is more than five times faster than the state-of-the-art target-present visual search model. Code can be found at https:// github.com/cvlab-stonybrook/Gazeformer/ 