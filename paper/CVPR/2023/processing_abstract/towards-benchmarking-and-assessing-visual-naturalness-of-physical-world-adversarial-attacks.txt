Physical world adversarial attack is a highly practical and threatening attack, which fools real world deep learn-ing systems by generating conspicuous and maliciously crafted real world artifacts. In physical world attacks, eval-uating naturalness is highly emphasized since human can easily detect and remove unnatural attacks. However, cur-rent studies evaluate naturalness in a case-by-case fash-ion, which suffers from errors, bias and inconsistencies.In this paper, we take the ﬁrst step to benchmark and as-sess visual naturalness of physical world attacks, taking autonomous driving scenario as the ﬁrst attempt. First, to benchmark attack naturalness, we contribute the ﬁrstPhysical Attack Naturalness (PAN) dataset with human rat-ing and gaze. PAN veriﬁes several insights for the ﬁrst time: naturalness is (disparately) affected by contextual features (i.e., environmental and semantic variations) and correlates with behavioral feature (i.e., gaze signal). Sec-ond, to automatically assess attack naturalness that aligns with human ratings, we further introduce Dual Prior Align-ment (DPA) network, which aims to embed human knowl-edge into model reasoning process. Speciﬁcally, DPA imi-tates human reasoning in naturalness assessment by rating prior alignment and mimics human gaze behavior by atten-tive prior alignment. We hope our work fosters researches to improve and automatically assess naturalness of physi-cal world attacks. Our code and dataset can be found at https://github.com/zhangsn-19/PAN. 