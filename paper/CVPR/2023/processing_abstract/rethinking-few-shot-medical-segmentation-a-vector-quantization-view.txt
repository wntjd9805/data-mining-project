The existing few-shot medical segmentation networks share the same practice that the more prototypes, the bet-ter performance. This phenomenon can be theoretically in-terpreted in Vector Quantization (VQ) view: the more pro-totypes, the more clusters are separated from pixel-wise feature points distributed over the full space. However, as we further think about few-shot segmentation with this perspective, it is found that the clusterization of feature points and the adaptation to unseen tasks have not received enough attention. Motivated by the observation, we propose a learning VQ mechanism consisting of grid-format VQ (GFVQ), self-organized VQ (SOVQ) and residual orientedVQ (ROVQ). To be specific, GFVQ generates the prototype matrix by averaging square grids over the spatial extent, which uniformly quantizes the local details; SOVQ adap-tively assigns the feature points to different local classes and creates a new representation space where the learn-able local prototypes are updated with a global view; ROVQ introduces residual information to fine-tune the aforemen-tioned learned local prototypes without re-training, which benefits the generalization performance for the irrelevance to the training task. We empirically show that our VQ framework yields the state-of-the-art performance over ab-domen, cardiac and prostate MRI datasets and expect this work will provoke a rethink of the current few-shot medical segmentation model design. Our code will soon be publicly available. 