To defend the inference attacks and mitigate the sensitive information leakages in Federated Learning (FL), client-level Differentially Private FL (DPFL) is the de-facto stan-dard for privacy protection by clipping local updates and adding random noise. However, existing DPFL methods tend to make a sharper loss landscape and have poorer weight perturbation robustness, resulting in severe per-formance degradation. To alleviate these issues, we pro-pose a novel DPFL algorithm named DP-FedSAM, which leverages gradient perturbation to mitigate the negative im-pact of DP. Specifically, DP-FedSAM integrates SharpnessAware Minimization (SAM) optimizer to generate local flat-ness models with better stability and weight perturbation robustness, which results in the small norm of local up-dates and robustness to DP noise, thereby improving the performance. From the theoretical perspective, we ana-lyze in detail how DP-FedSAM mitigates the performance degradation induced by DP. Meanwhile, we give rigorous privacy guarantees with RÂ´enyi DP and present the sensitiv-ity analysis of local updates. At last, we empirically confirm that our algorithm achieves state-of-the-art (SOTA) perfor-mance compared with existing SOTA baselines in DPFL. 