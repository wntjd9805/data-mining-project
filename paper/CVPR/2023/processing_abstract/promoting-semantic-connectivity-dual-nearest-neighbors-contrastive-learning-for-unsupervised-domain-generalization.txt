Domain Generalization (DG) has achieved great success in generalizing knowledge from source domains to unseen target domains. However, current DG methods rely heav-ily on labeled source data, which are usually costly and unavailable. Since unlabeled data are far more accessible, we study a more practical unsupervised domain generaliza-tion (UDG) problem. Learning invariant visual representa-tion from different views, i.e., contrastive learning, promises well semantic features for in-domain unsupervised learning.However, it fails in cross-domain scenarios. In this paper, we first delve into the failure of vanilla contrastive learn-ing and point out that semantic connectivity is the key toUDG. Specifically, suppressing the intra-domain connectiv-ity and encouraging the intra-class connectivity help to learn the domain-invariant semantic information. Then, we pro-pose a novel unsupervised domain generalization approach, namely Dual Nearest Neighbors contrastive learning with strong Augmentation (DN2A). Our DN2A leverages strong augmentations to suppress the intra-domain connectivity and proposes a novel dual nearest neighbors search strategy to find trustworthy cross domain neighbors along with in-domain neighbors to encourage the intra-class connectivity.Experimental results demonstrate that our DN2A outper-forms the state-of-the-art by a large margin, e.g., 12.01% and 13.11% accuracy gain with only 1% labels for linear evaluation on PACS and DomainNet, respectively. 