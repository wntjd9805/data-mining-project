Multi-view 3D object detection (MV3D-Det) in Bird-Eye-View (BEV) has drawn extensive attention due to its low cost and high efficiency. Although new algorithms for camera-only 3D object detection have been continu-ously proposed, most of them may risk drastic performance degradation when the domain of input images differs from that of training. In this paper, we first analyze the causes of the domain gap for the MV3D-Det task. Based on the covariate shift assumption, we find that the gap mainly at-tributes to the feature distribution of BEV, which is deter-mined by the quality of both depth estimation and 2D im-ageâ€™s feature representation. To acquire a robust depth pre-diction, we propose to decouple the depth estimation from the intrinsic parameters of the camera (i.e. the focal length) through converting the prediction of metric depth to that of scale-invariant depth and perform dynamic perspective augmentation to increase the diversity of the extrinsic pa-rameters (i.e. the camera poses) by utilizing homography.Moreover, we modify the focal length values to create mul-tiple pseudo-domains and construct an adversarial train-ing loss to encourage the feature representation to be more domain-agnostic. Without bells and whistles, our approach, namely DG-BEV, successfully alleviates the performance drop on the unseen target domain without impairing the accuracy of the source domain. Extensive experiments onWaymo, nuScenes, and Lyft, demonstrate the generalization and effectiveness of our approach. 