Existing Masked Image Modeling methods apply fixed mask patterns to guide the self-supervised training. As those patterns resort to different criteria to mask local re-gions, sticking to a fixed pattern leads to limited vision cues modeling capability. This paper proposes an evolved part-based masking to pursue more general visual cues model-ing in self-supervised learning. Our method is based on an adaptive part partition module, which leverages the vi-sion model being trained to construct a part graph, and partitions parts with graph cut. The accuracy of parti-tioned parts is on par with the capability of the pre-trained model, leading to evolved mask patterns at different training stages. It generates simple patterns at the initial training stage to learn low-level visual cues, which hence evolves to eliminate accurate object parts to reinforce the learn-ing of object semantics and contexts. Our method does not require extra pre-trained models or annotations, and effectively ensures the training efficiency by evolving the training difficulty. Experiment results show that it substan-tially boosts the performance on various tasks including im-age classification, object detection, and semantic segmenta-tion. For example, it outperforms the recent MAE by 0.69% on imageNet-1K classification and 1.61% on ADE20K seg-mentation with the same training epochs. 