Multi-modal image registration spatially aligns two im-ages with different distributions. One of its major challenges is that images acquired from different imaging machines have different imaging distributions, making it difficult to focus only on the spatial aspect of the images and ignore differences in distributions. In this study, we developed a self-supervised approach, Indescribable Multi-model SpatialEvaluator (IMSE), to address multi-modal image registration.IMSE creates an accurate multi-modal spatial evaluator to measure spatial differences between two images, and then op-timizes registration by minimizing the error predicted of the evaluator. To optimize IMSE performance, we also proposed a new style enhancement method called Shuffle Remap which randomizes the image distribution into multiple segments, and then randomly disorders and remaps these segments, so that the distribution of the original image is changed. ShuffleRemap can help IMSE to predict the difference in spatial location from unseen target distributions. Our results show that IMSE outperformed the existing methods for registration using T1-T2 and CT-MRI datasets. IMSE also can be easily integrated into the traditional registration process, and can provide a convenient way to evaluate and visualize registra-tion results. IMSE also has the potential to be used as a new paradigm for image-to-image translation. Our code is avail-able at https://github.com/Kid-Liet/IMSE.*Corresponding author.Figure 1. The GAN based methods can only ensure that the distri-bution of the X domain is mapped that of the Y domain. Ideally, we want to achieve instance registration in which moving and target images are one-to-one corresponded. 