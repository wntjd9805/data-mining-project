Semantic segmentation involves classifying each pixel into one of a pre-defined set of object/stuff classes. Such a fine-grained detection and localization of objects in the scene is challenging by itself. The complexity increases manifold in the presence of blur. With cameras becoming increasingly light-weight and compact, blur caused by mo-tion during capture time has become unavoidable. Most research has focused on improving segmentation perfor-mance for sharp clean images and the few works that deal with degradations, consider motion-blur as one of manyIn this work, we focus exclusively generic degradations. on motion-blur and attempt to achieve robustness for se-mantic segmentation in its presence. Based on the observa-tion that segmentation annotations can be used to generate synthetic space-variant blur, we propose a Class-CentricMotion-Blur Augmentation (CCMBA) strategy. Our ap-proach involves randomly selecting a subset of semantic classes present in the image and using the segmentation map annotations to blur only the corresponding regions.This enables the network to simultaneously learn seman-tic segmentation for clean images, images with egomotion blur, as well as images with dynamic scene blur. We demon-strate the effectiveness of our approach for both CNN andVision Transformer-based semantic segmentation networks on PASCAL VOC and Cityscapes datasets. We also illus-trate the improved generalizability of our method to com-plex real-world blur by evaluating on the commonly used deblurring datasets GoPro and REDS . 