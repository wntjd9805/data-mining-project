Robust and accurate geometric understanding against adverse weather conditions is one top prioritized condi-tions to achieve a high-level autonomy of self-driving cars.However, autonomous driving algorithms relying on the vis-ible spectrum band are easily impacted by weather and lighting conditions. A long-wave infrared camera, also known as a thermal imaging camera, is a potential res-cue to achieve high-level robustness. However, the miss-ing necessities are the well-established large-scale dataset and public benchmark results. To this end, in this pa-per, we first built a large-scale Multi-Spectral Stereo (MS2) dataset, including stereo RGB, stereo NIR, stereo thermal, and stereo LiDAR data along with GNSS/IMU informa-tion. The collected dataset provides about 195K synchro-nized data pairs taken from city, residential, road, campus, and suburban areas in the morning, daytime, and nighttime under clear-sky, cloudy, and rainy conditions. Secondly, we conduct an exhaustive validation process of monocu-lar and stereo depth estimation algorithms designed on visible spectrum bands to benchmark their performance in the thermal image domain. Lastly, we propose a uni-fied depth network that effectively bridges monocular depth and stereo depth tasks from a conditional random field approach perspective. Our dataset and source code are available at https://github.com/UkcheolShin/MS2-MultiSpectralStereoDataset. (a) Depth from thermal images via unified depth network (b) RGB (Reference) (c) Thermal image (d) Depth mapFigure 1. Depth from thermal images in various environments.Our proposed network can estimate both monocular and stereo depth maps regardless of given a single or stereo thermal image via unified network architecture. Furthermore, depth estimation results from thermal images show high-level reliability and robust-ness under day-light, low-light, and rainy conditions. 