Occluded and long-range objects are ubiquitous and challenging for 3D object detection. Point cloud sequence data provide unique opportunities to improve such cases, as an occluded or distant object can be observed from differ-ent viewpoints or gets better visibility over time. However, the efﬁciency and effectiveness in encoding long-term se-quence data can still be improved. In this work, we proposeMoDAR, using motion forecasting outputs as a type of vir-tual modality, to augment LiDAR point clouds. The MoDAR modality propagates object information from temporal con-texts to a target frame, represented as a set of virtual points, one for each object from a waypoint on a forecasted tra-jectory. A fused point cloud of both raw sensor points and the virtual points can then be fed to any off-the-shelf point-cloud based 3D object detector. Evaluated on the WaymoOpen Dataset, our method signiﬁcantly improves prior art detectors by using motion forecasting from extra-long se-quences (e.g. 18 seconds), achieving new state of the arts, while not adding much computation overhead. 