This paper proposes a regularizer called Implicit NeuralRepresentation Regularizer (INRR) to improve the general-ization ability of the Implicit Neural Representation (INR).The INR is a fully connected network that can represent sig-nals with details not restricted by grid resolution. However, its generalization ability could be improved, especially with non-uniformly sampled data. The proposed INRR is based on learned Dirichlet Energy (DE) that measures similarities between rows/columns of the matrix. The smoothness of theLaplacian matrix is further integrated by parameterizingDE with a tiny INR. INRR improves the generalization ofINR in signal representation by perfectly integrating the sig-nalâ€™s self-similarity with the smoothness of the Laplacian matrix. Through well-designed numerical experiments, the paper also reveals a series of properties derived from INRR, including momentum methods like convergence trajectory and multi-scale similarity. Moreover, the proposed method could improve the performance of other signal representa-tion methods. 