The inverted index is a widely used data structure toIt accelerates re-avoid the infeasible exhaustive search. trieval signiﬁcantly by splitting the database into multiple disjoint sets and restricts distance computation to a small fraction of the database. Moreover, it even improves search quality by allowing quantizers to exploit the compact distri-bution of residual vector space. However, we ﬁrstly point out a problem that an existing deep learning-based quan-tizer hardly beneﬁts from the residual vector space, unlike conventional shallow quantizers. To cope with this problem, we introduce a novel disentangled representation learning for unsupervised neural quantization. Similar to the con-cept of residual vector space, the proposed method enables more compact latent space by disentangling information of the inverted index from the vectors. Experimental results on large-scale datasets conﬁrm that our method outperforms the state-of-the-art retrieval systems by a large margin. 