In this work, we aim to enhance model-based face re-construction by avoiding fitting the model to outliers, i.e. regions that cannot be well-expressed by the model such as occluders or make-up. The core challenge for localizing outliers is that they are highly variable and difficult to anno-tate. To overcome this challenging problem, we introduce a joint Face-autoencoder and outlier segmentation approach (FOCUS). In particular, we exploit the fact that the outliers cannot be fitted well by the face model and hence can be localized well given a high-quality model fitting. The main challenge is that the model fitting and the outlier segmenta-tion are mutually dependent on each other, and need to be inferred jointly. We resolve this chicken-and-egg problem with an EM-type training strategy, where a face autoen-coder is trained jointly with an outlier segmentation net-work. This leads to a synergistic effect, in which the seg-mentation network prevents the face encoder from fitting to the outliers, enhancing the reconstruction quality. The im-proved 3D face reconstruction, in turn, enables the segmen-tation network to better predict the outliers. To resolve the ambiguity between outliers and regions that are difficult to fit, such as eyebrows, we build a statistical prior from syn-thetic data that measures the systematic bias in model fit-ting. Experiments on the NoW testset demonstrate that FO-CUS achieves SOTA 3D face reconstruction performance among all baselines trained without 3D annotation. More-over, our results on CelebA-HQ and AR database show that the segmentation network can localize occluders accuratelyâˆ— Denotes same contribution.Codes available at: github.com/unibas-gravis/Occlusion-Robust-MoFAC.Li is funded by the China Scholarship Council (CSC) from the Min-istry of Education of P.R. China. B.Egger was supported by a Post-Doc Mobility Grant, Swiss National Science Foundation P400P2 191110.A.Kortylewski acknowledges support via his Emmy Noether ResearchGroup funded by the German Science Foundation (DFG) under Grant No. 468670075. Sincere gratitude to Tatsuro Koizumi and William A. P. Smith who offered the MoFA re-implementation.Figure 1. FOCUS conducts face reconstruction and outlier seg-mentation jointly under weak supervision. Top to bottom: target images, our reconstruction images, and estimated outlier masks. despite being trained without any segmentation annotation. 