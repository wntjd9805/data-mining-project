Recent studies have shown that higher accuracy on Im-ageNet usually leads to better robustness against differ-ent corruptions. Therefore, in this paper, instead of fol-lowing the traditional research paradigm that investigates new out-of-distribution corruptions or perturbations deep models may encounter, we conduct model debugging in in-distribution data to explore which object attributes a model may be sensitive to. To achieve this goal, we create a toolkit for object editing with controls of backgrounds, sizes, po-sitions, and directions, and create a rigorous benchmark named ImageNet-E(diting) for evaluating the image clas-siﬁer robustness in terms of object attributes. With ourImageNet-E, we evaluate the performance of current deep learning models, including both convolutional neural net-works and vision transformers. We ﬁnd that most models are quite sensitive to attribute changes. A small change in the background can lead to an average of 9.23% dropCorresponding author.⇤This research is supported in part by the National Key Research andDevelopment Progrem of China under Grant No.2020AAA0140000. on top-1 accuracy. We also evaluate some robust models including both adversarially trained models and other ro-bust trained models and ﬁnd that some models show worse robustness against attribute changes than vanilla models.Based on these ﬁndings, we discover ways to enhance at-tribute robustness with preprocessing, architecture designs, and training strategies. We hope this work can provide some insights to the community and open up a new av-enue for research in robust computer vision. The code and dataset are available at https : / / github . com / alibaba/easyrobust. 