Neural radiance fields (NeRF) show great success in novel view synthesis. However, in real-world scenes, re-covering high-quality details from the source images is still challenging for the existing NeRF-based approaches, due to the potential imperfect calibration information and scene representation inaccuracy. Even with high-quality train-ing frames, the synthetic novel views produced by NeRF models still suffer from notable rendering artifacts, such as noise, blur, etc. Towards to improve the synthesis qual-ity of NeRF-based approaches, we propose NeRFLiX, a general NeRF-agnostic restorer paradigm by learning a degradation-driven inter-viewpoint mixer. Specially, we de-*Equal contributionâ€ Corresponding author sign a NeRF-style degradation modeling approach and con-struct large-scale training data, enabling the possibility of effectively removing NeRF-native rendering artifacts for ex-isting deep neural networks. Moreover, beyond the degra-dation removal, we propose an inter-viewpoint aggregation framework that is able to fuse highly related high-quality training images, pushing the performance of cutting-edgeNeRF models to entirely new levels and producing highly photo-realistic synthetic views. 