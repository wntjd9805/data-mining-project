In this paper, we propose a novel transfer-based tar-geted attack method that optimizes the adversarial pertur-bations without any extra training efforts for auxiliary net-works on training data. Our new attack method is pro-posed based on the observation that highly universal ad-versarial perturbations tend to be more transferable for targeted attacks. Therefore, we propose to make the per-turbation to be agnostic to different local regions within one image, which we called as self-universality.Instead of optimizing the perturbations on different images, opti-mizing on different regions to achieve self-universality can get rid of using extra data. Specifically, we introduce a feature similarity loss that encourages the learned pertur-bations to be universal by maximizing the feature similar-ity between adversarial perturbed global images and ran-domly cropped local regions. With the feature similarity loss, our method makes the features from adversarial per-turbations to be more dominant than that of benign im-ages, hence improving targeted transferability. We name the proposed attack method as Self-Universality (SU) attack.Extensive experiments demonstrate that SU can achieve high success rates for transfer-based targeted attacks. OnImageNet-compatible dataset, SU yields an improvement of 12% compared with existing state-of-the-art methods. Code is available at https://github.com/zhipeng-wei/Self-Universality. 