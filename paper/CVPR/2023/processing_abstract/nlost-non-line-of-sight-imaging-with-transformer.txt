(NLOS)Time-resolved non-line-of-sight imaging is based on the multi-bounce indirect reflections from the hid-den objects for 3D sensing. Reconstruction from NLOS measurements remains challenging especially for compli-cated scenes. To boost the performance, we present NLOST, the first transformer-based neural network for NLOS recon-struction. Specifically, after extracting the shallow features with the assistance of physics-based priors, we design two spatial-temporal self attention encoders to explore both lo-cal and global correlations within 3D NLOS data by split-ting or downsampling the features into different scales, re-spectively. Then, we design a spatial-temporal cross atten-tion decoder to integrate local and global features in the token space of transformer, resulting in deep features with high representation capabilities. Finally, deep and shallow features are fused to reconstruct the 3D volume of hidden scenes. Extensive experimental results demonstrate the su-perior performance of the proposed method over existing solutions on both synthetic data and real-world data cap-tured by different NLOS imaging systems. 