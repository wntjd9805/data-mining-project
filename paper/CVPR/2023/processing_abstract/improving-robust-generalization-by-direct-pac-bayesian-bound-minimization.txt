weights: (# weights: ($Recent research in robust optimization has shown an overﬁtting-like phenomenon in which models trained against adversarial attacks exhibit higher robustness on the training set compared to the test set. Although pre-vious work provided theoretical explanations for this phe-nomenon using a robust PAC-Bayesian bound over the ad-versarial test error, related algorithmic derivations are at best only loosely connected to this bound, which implies that there is still a gap between their empirical success and our understanding of adversarial robustness theory.To close this gap, in this paper we consider a different form of the robust PAC-Bayesian bound and directly min-imize it with respect to the model posterior. The derivation of the optimal solution connects PAC-Bayesian learning to the geometry of the robust loss surface through a Trace ofHessian (TrH) regularizer that measures the surface ﬂat-ness. In practice, we restrict the TrH regularizer to the top layer only, which results in an analytical solution to the bound whose computational cost does not depend on the network depth. Finally, we evaluate our TrH regulariza-tion approach over CIFAR-10/100 and ImageNet using Vi-sion Transformers (ViT) and compare against baseline ad-versarial robustness algorithms. Experimental results show that TrH regularization leads to improved ViT robustness that either matches or surpasses previous state-of-the-art approaches while at the same time requires less memory and computational cost. 