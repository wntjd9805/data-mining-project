← Perceptual QualityFidelity →Behavior of neural networks is irremediably determined by the specific loss and data used during training. How-ever it is often desirable to tune the model at inference time based on external factors such as preferences of the user or dynamic characteristics of the data. This is espe-cially important to balance the perception-distortion trade-off of ill-posed image-to-image translation tasks.In this work, we propose to optimize a parametric tunable con-volutional layer, which includes a number of different ker-nels, using a parametric multi-loss, which includes an equal number of objectives. Our key insight is to use a shared set of parameters to dynamically interpolate both the ob-jectives and the kernels. During training, these parame-ters are sampled at random to explicitly optimize all possi-ble combinations of objectives and consequently disentan-gle their effect into the corresponding kernels. During in-ference, these parameters become interactive inputs of the model hence enabling reliable and consistent control over the model behavior. Extensive experimental results demon-strate that our tunable convolutions effectively work as a drop-in replacement for traditional convolutions in existing neural networks at virtually no extra computational cost, outperforming state-of-the-art control strategies in a wide range of applications; including image denoising, deblur-ring, super-resolution, and style transfer. 