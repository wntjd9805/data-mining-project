We propose Universal Document Processing (UDOP), a foundation Document AI model which uniﬁes text, im-age, and layout modalities together with varied task for-mats, including document understanding and generation.UDOP leverages the spatial correlation between textual con-tent and document image to model image, text, and layout modalities with one uniform representation. With a novelVision-Text-Layout Transformer, UDOP uniﬁes pretraining and multi-domain downstream tasks into a prompt-based sequence generation scheme. UDOP is pretrained on both large-scale unlabeled document corpora using innovative self-supervised objectives and diverse labeled data. UDOP also learns to generate document images from text and lay-out modalities via masked image reconstruction. To the best of our knowledge, this is the ﬁrst time in the ﬁeld of document AI that one model simultaneously achieves high-quality neural document editing and content customization.Our method sets the state-of-the-art on 8 Document AI tasks, e.g., document understanding and QA, across diverse data domains like ﬁnance reports, academic papers, and web-sites. UDOP ranks ﬁrst on the leaderboard of the DocumentUnderstanding Benchmark.1 