Self-supervised monocular depth estimation that does not require ground truth for training has attracted attention in recent years. It is of high interest to design lightweight but effective models so that they can be deployed on edge devices. Many existing architectures beneﬁt from using heavier backbones at the expense of model sizes. This paper achieves comparable results with a lightweight architecture.Speciﬁcally, the efﬁcient combination of CNNs and Trans-formers is investigated, and a hybrid architecture calledLite-Mono is presented. A Consecutive Dilated Convolu-tions (CDC) module and a Local-Global Features Interac-tion (LGFI) module are proposed. The former is used to extract rich multi-scale local features, and the latter takes advantage of the self-attention mechanism to encode long-range global information into the features. Experiments demonstrate that Lite-Mono outperforms Monodepth2 by a large margin in accuracy, with about 80% fewer train-able parameters. Our codes and models are available at https://github.com/noahzn/Lite-Mono. 