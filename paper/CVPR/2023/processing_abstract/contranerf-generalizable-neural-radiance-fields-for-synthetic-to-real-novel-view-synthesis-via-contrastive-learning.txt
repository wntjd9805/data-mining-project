Although many recent works have investigated general-izable NeRF-based novel view synthesis for unseen scenes, they seldom consider the synthetic-to-real generalization, which is desired in many practical applications.In this work, we first investigate the effects of synthetic data in synthetic-to-real novel view synthesis and surprisingly ob-serve that models trained with synthetic data tend to pro-duce sharper but less accurate volume densities. For pix-els where the volume densities are correct, fine-grained de-tails will be obtained. Otherwise, severe artifacts will be produced. To maintain the advantages of using synthetic data while avoiding its negative effects, we propose to intro-duce geometry-aware contrastive learning to learn multi-view consistent features with geometric constraints. Mean-while, we adopt cross-view attention to further enhance the geometry perception of features by querying features across input views. Experiments demonstrate that under the synthetic-to-real setting, our method can render images with higher quality and better fine-grained details, outper-forming existing generalizable novel view synthesis meth-ods in terms of PSNR, SSIM, and LPIPS. When trained on real data, our method also achieves state-of-the-art results. https://haoy945.github.io/contranerf/ 