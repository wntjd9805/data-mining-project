Learning with large-scale unlabeled data has become a powerful tool for pre-training Visual Transformers (VTs).However, prior works tend to overlook that, in real-world scenarios, the input data may be corrupted and unreli-able. Pre-training VTs on such corrupted data can be chal-lenging, especially when we pre-train via the masked au-toencoding approach, where both the inputs and masked“ground truth” targets can potentially be unreliable in this case. To address this limitation, we introduce the To-ken Boosting Module (TBM) as a plug-and-play compo-nent for VTs that effectively allows the VT to learn to ex-tract clean and robust features during masked autoencod-ing pre-training. We provide theoretical analysis to show how TBM improves model pre-training with more robust and generalizable representations, thus benefiting down-stream tasks. We conduct extensive experiments to analyzeTBM’s effectiveness, and results on four corrupted datasets demonstrate that TBM consistently improves performance on downstream tasks. 