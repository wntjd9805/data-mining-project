Recent studies usually approach multi-label zero-shot learning (MLZSL) with visual-semantic mapping on spatial-class correlation, which can be computationally costly, and worse still, fails to capture fine-grained class-specific semantics. We observe that different channels may usually have different sensitivities on classes, which can correspond to specific semantics. Such an intrinsic channel-class correlation suggests a potential alternative for the more accurate and class-harmonious feature representa-tions. In this paper, our interest is to fully explore the power of channel-class correlation as the unique base for MLZSL.Specifically, we propose a light yet efficient Multi-LabelMulti-Layer Perceptron-based Encoder, dubbed (ML)2P-Encoder, to extract and preserve channel-wise semantics.We reorganize the generated feature maps into several groups, of which each of them can be trained independently with (ML)2P-Encoder. On top of that, a global group-wise attention module is further designed to build the multi-label specific class relationships among different classes, which eventually fulfills a novel Channel-Class CorrelationMLZSL framework (C3-MLZSL)1. Extensive experiments on large-scale MLZSL benchmarks including NUS-WIDE andOpen-Images-V4 demonstrate the superiority of our model against other representative state-of-the-art models. 