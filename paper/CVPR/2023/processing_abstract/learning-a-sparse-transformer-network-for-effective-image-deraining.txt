Transformers-based methods have achieved significant performance in image deraining as they can model the non-local information which is vital for high-quality im-age reconstruction.In this paper, we find that most ex-isting Transformers usually use all similarities of the to-kens from the query-key pairs for the feature aggrega-tion. However, if the tokens from the query are differ-ent from those of the key, the self-attention values esti-mated from these tokens also involve in feature aggregation, which accordingly interferes with the clear image restora-tion. To overcome this problem, we propose an effectiveDeRaining network, Sparse Transformer (DRSformer) that can adaptively keep the most useful self-attention values for feature aggregation so that the aggregated features bet-ter facilitate high-quality image reconstruction. Specifi-cally, we develop a learnable top-k selection operator to adaptively retain the most crucial attention scores from the keys for each query for better feature aggregation. Si-multaneously, as the naive feed-forward network in Trans-formers does not model the multi-scale information that is important for latent clear image restoration, we develop an effective mixed-scale feed-forward network to gener-ate better features for image deraining. To learn an en-riched set of hybrid features, which combines local con-text from CNN operators, we equip our model with mix-ture of experts feature compensator to present a coop-eration refinement deraining scheme. Extensive experi-mental results on the commonly used benchmarks demon-strate that the proposed method achieves favorable perfor-mance against state-of-the-art approaches. The source code and trained models are available at https://github. com/cschenxiang/DRSformer. 