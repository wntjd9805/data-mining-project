Transfer learning is fundamental for addressing prob-lems in settings with little training data. While several transfer learning approaches have been proposed in 3D, unfortunately, these solutions typically operate on an en-tire 3D object or even scene-level and thus, as we show, fail to generalize to new classes, such as deformable or-ganic shapes. In addition, there is currently a lack of un-derstanding of what makes pre-trained features transfer-able across significantly different 3D shape categories. In this paper, we make a step toward addressing these chal-lenges. First, we analyze the link between feature local-ity and transferability in tasks involving deformable 3D ob-jects, while also comparing different backbones and losses for local feature pre-training. We observe that with proper training, learned features can be useful in such tasks, but, crucially, only with an appropriate choice of the recep-tive field size. We then propose a differentiable method for optimizing the receptive field within 3D transfer learn-ing. Jointly, this leads to the first learnable features that can successfully generalize to unseen classes of 3D shapes such as humans and animals. Our extensive experiments show that this approach leads to state-of-the-art results on several downstream tasks such as segmentation, shape cor-respondence, and classification. Our code is available at https://github.com/pvnieo/vader. 