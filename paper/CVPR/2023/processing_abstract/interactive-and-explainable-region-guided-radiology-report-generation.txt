The automatic generation of radiology reports has the potential to assist radiologists in the time-consuming task of report writing. Existing methods generate the full re-port from image-level features, failing to explicitly focus on anatomical regions in the image. We propose a sim-ple yet effective region-guided report generation model that detects anatomical regions and then describes indi-vidual, salient regions to form the final report. While previous methods generate reports without the possibility of human intervention and with limited explainability, our method opens up novel clinical use cases through addi-tional interactive capabilities and introduces a high de-gree of transparency and explainability. Comprehensive ex-periments demonstrate our methodâ€™s effectiveness in report generation, outperforming previous state-of-the-art models, and highlight its interactive capabilities. The code and checkpoints are available at https://github.com/ ttanida/rgrg . 