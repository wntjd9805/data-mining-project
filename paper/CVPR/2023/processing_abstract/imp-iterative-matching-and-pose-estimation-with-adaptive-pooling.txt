Previous methods solve feature matching and pose esti-mation using a two-stage process by ﬁrst ﬁnding matches and then estimating the pose. As they ignore the geomet-ric relationships between the two tasks, they focus on ei-ther improving the quality of matches or ﬁltering poten-tial outliers, leading to limited efﬁciency or accuracy. In contrast, we propose an iterative matching and pose es-timation framework (IMP) leveraging the geometric con-nections between the two tasks: a few good matches are enough for a roughly accurate pose estimation; a roughly accurate pose can be used to guide the matching by pro-viding geometric constraints. To this end, we implement a geometry-aware recurrent attention-based module which jointly outputs sparse matches and camera poses. Specif-ically, for each iteration, we ﬁrst implicitly embed geo-metric information into the module via a pose-consistency loss, allowing it to predict geometry-aware matches pro-gressively. Second, we introduce an efﬁcient IMP, calledEIMP, to dynamically discard keypoints without potential matches, avoiding redundant updating and signiﬁcantly re-ducing the quadratic time complexity of attention computa-tion in transformers. Experiments on YFCC100m, Scannet, and Aachen Day-Night datasets demonstrate that the pro-posed method outperforms previous approaches in terms of accuracy and efﬁciency. Code is available at https://github.com/feixue94/imp-release 