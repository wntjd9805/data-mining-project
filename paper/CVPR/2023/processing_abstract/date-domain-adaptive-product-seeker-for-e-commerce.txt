Product Retrieval (PR) and Grounding (PG), aiming to seek image and object-level products respectively according to a textual query, have attracted great interest recently for better shopping experience. Owing to the lack of relevant datasets, we collect two large-scale benchmark datasets from Taobao Mall and Live domains with about 474k and 101k image-query pairs for PR, and manually annotate the object bounding boxes in each image for PG. As anno-tating boxes is expensive and time-consuming, we attempt to transfer knowledge from annotated domain to unanno-tated for PG to achieve un-supervised Domain Adaptation (PG-DA). We propose a Domain Adaptive Product Seeker (DATE) framework, regarding PR and PG as Product Seek-ing problem at different levels, to assist the query date the product. Concretely, we first design a semantics-aggregated feature extractor for each modality to obtain concentrated and comprehensive features for following efficient retrieval and fine-grained grounding tasks. Then, we present two cooperative seekers to simultaneously search the image for PR and localize the product for PG. Besides, we de-vise a domain aligner for PG-DA to alleviate uni-modal marginal and multi-modal conditional distribution shift be-tween source and target domains, and design a pseudo box generator to dynamically select reliable instances and gen-erate bounding boxes for further knowledge transfer. Exten-sive experiments show that our DATE achieves satisfactory performance in fully-supervised PR, PG and un-supervisedPG-DA. Our desensitized datasets will be publicly available here1. 