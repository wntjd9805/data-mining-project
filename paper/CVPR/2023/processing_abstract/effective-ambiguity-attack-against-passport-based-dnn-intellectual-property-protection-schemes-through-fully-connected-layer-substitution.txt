Since training a deep neural network (DNN) is costly, the well-trained deep models can be regarded as valuable intellectual property (IP) assets. The IP protection asso-ciated with deep models has been receiving increasing at-tentions in recent years. Passport-based method, which re-places normalization layers with passport layers, has been one of the few protection solutions that are claimed to be secure against advanced attacks. In this work, we tackle the issue of evaluating the security of passport-based IP protec-tion methods. We propose a novel and effective ambiguity attack against passport-based method, capable of success-fully forging multiple valid passports with a small train-ing dataset. This is accomplished by inserting a specially designed accessory block ahead of the passport parame-ters. Using less than 10% of training data, with the forged passport, the model exhibits almost indistinguishable per-formance difference (less than 2%) compared with that of the authorized passport. In addition, it is shown that our attack strategy can be readily generalized to attack other IP protection methods based on watermark embedding. Direc-tions for potential remedy solutions are also given. 