Recent advancements in deploying deep neural networks (DNNs) on resource-constrained devices have generated in-terest in input-adaptive dynamic neural networks (DyNNs).DyNNs offer more efﬁcient inferences and enable the de-ployment of DNNs on devices with limited resources, such as mobile devices. However, we have discovered a new vul-nerability in DyNNs that could potentially compromise their efﬁciency. Speciﬁcally, we investigate whether adversaries can manipulate DyNNs’ computational costs to create a false sense of efﬁciency. To address this question, we pro-pose EfficFrog, an adversarial attack that injects uni-versal efﬁciency backdoors in DyNNs. To inject a backdoor trigger into DyNNs, EfficFrog poisons only a minimal percentage of the DyNNs’ training data. During the infer-ence phase, EfficFrog can slow down the backdooredDyNNs and abuse the computational resources of systems running DyNNs by adding the trigger to any input. To eval-uate EfficFrog, we tested it on three DNN backbone ar-chitectures (based on VGG16, MobileNet, and ResNet56) using two popular datasets (CIFAR-10 and Tiny ImageNet).Our results demonstrate that EfficFrog reduces the efﬁ-ciency of DyNNs on triggered input samples while keeping the efﬁciency of clean samples almost the same. 