Thanks to the impressive progress of large-scale vision-language pretraining, recent recognition models can clas-sify arbitrary objects in a zero-shot and open-set manner, with a surprisingly high accuracy. However, translating this success to semantic segmentation is not trivial, because this dense prediction task requires not only accurate semantic understanding but also fine shape delineation and existing vision-language models are trained with image-level lan-guage descriptions. To bridge this gap, we pursue shape-aware zero-shot semantic segmentation in this study.In-spired by classical spectral methods in the image segmenta-tion literature, we propose to leverage the eigen vectors ofLaplacian matrices constructed with self-supervised pixel-wise features to promote shape-awareness. Despite that this simple and effective technique does not make use of the masks of seen classes at all, we demonstrate that it out-performs a state-of-the-art shape-aware formulation that aligns ground truth and predicted edges during training.We also delve into the performance gains achieved on dif-ferent datasets using different backbones and draw several interesting and conclusive observations: the benefits of pro-moting shape-awareness highly relates to mask compact-ness and language embedding locality. Finally, our method sets new state-of-the-art performance for zero-shot seman-tic segmentation on both Pascal and COCO, with significant margins. Code and models will be accessed at SAZS. 