In this paper, we investigate a new optimization frame-work for multi-view 3D shape reconstructions. Recent differentiable rendering approaches have provided break-through performances with implicit shape representations though they can still lack precision in the estimated geome-tries. On the other hand multi-view stereo methods can yield pixel wise geometric accuracy with local depth pre-dictions along viewing rays. Our approach bridges the gap between the two strategies with a novel volumetric shape representation that is implicit but parameterized with pixel depths to better materialize the shape surface with consis-tent signed distances along viewing rays. The approach re-tains pixel-accuracy while beneﬁting from volumetric inte-gration in the optimization. To this aim, depths are opti-mized by evaluating, at each 3D location within the vol-umetric discretization, the agreement between the depth prediction consistency and the photometric consistency for the corresponding pixels. The optimization is agnostic to the associated photo-consistency term which can vary from a median-based baseline to more elaborate criteria, e.g. learned functions. Our experiments demonstrate the ben-eﬁt of the volumetric integration with depth predictions.They also show that our approach outperforms existing ap-proaches over standard 3D benchmarks with better geome-try estimations. 