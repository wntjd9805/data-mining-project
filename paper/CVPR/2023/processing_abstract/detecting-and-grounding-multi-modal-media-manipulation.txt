Misinformation has become a pressing issue. Fake me-dia, in both visual and textual forms, is widespread on the web. While various deepfake detection and text fake news detection methods have been proposed, they are only de-signed for single-modality forgery based on binary classi-fication, let alone analyzing and reasoning subtle forgery traces across different modalities. In this paper, we high-light a new research problem for multi-modal fake me-dia, namely Detecting and Grounding Multi-Modal MediaManipulation (DGM4). DGM4 aims to not only detect the authenticity of multi-modal media, but also ground the ma-nipulated content (i.e., image bounding boxes and text to-kens), which requires deeper reasoning of multi-modal me-dia manipulation. To support a large-scale investigation, we construct the first DGM4 dataset, where image-text pairs are manipulated by various approaches, with rich anno-tation of diverse manipulations. Moreover, we propose a novel HierArchical Multi-modal Manipulation rEasoning tRansformer (HAMMER) to fully capture the fine-grained interaction between different modalities. HAMMER per-forms 1) manipulation-aware contrastive learning between two uni-modal encoders as shallow manipulation reason-ing, and 2) modality-aware cross-attention by multi-modal aggregator as deep manipulation reasoning. Dedicated ma-nipulation detection and grounding heads are integrated from shallow to deep levels based on the interacted multi-modal information. Finally, we build an extensive bench-mark and set up rigorous evaluation metrics for this new re-search problem. Comprehensive experiments demonstrate the superiority of our model; several valuable observations are also revealed to facilitate future research in multi-modal media manipulation. 