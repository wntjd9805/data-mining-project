Recent work on 4D point cloud sequences has attracted a lot of attention. However, obtaining exhaustively labeled 4D datasets is often very expensive and laborious, so it is especially important to investigate how to utilize raw unla-beled data. However, most existing self-supervised point cloud representation learning methods only consider ge-ometry from a static snapshot omitting the fact that se-quential observations of dynamic scenes could reveal more comprehensive geometric details. To overcome such is-sues, this paper proposes a new 4D self-supervised pre-training method called Complete-to-Partial 4D Distillation.Our key idea is to formulate 4D self-supervised represen-tation learning as a teacher-student knowledge distilla-tion framework and let the student learn useful 4D repre-sentations with the guidance of the teacher. Experiments show that this approach significantly outperforms previ-ous pre-training approaches on a wide range of 4D point cloud sequence understanding tasks. Code is available at: https://github.com/dongyh20/C2P. 