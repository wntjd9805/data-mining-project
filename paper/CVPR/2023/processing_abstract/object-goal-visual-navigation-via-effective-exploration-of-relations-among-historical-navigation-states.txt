Object-goal visual navigation aims at steering an agent toward an object via a series of moving steps. Previous works mainly focus on learning informative visual repre-sentations for navigation, but overlook the impacts of nav-igation states on the effectiveness and efficiency of nav-igation. We observe that high relevance among naviga-tion states will cause navigation inefficiency or failure forIn this paper, we present a History-existing methods. inspired Navigation Policy Learning (HiNL) framework to estimate navigation states effectively by exploring relation-ships among historical navigation states. In HiNL, we pro-pose a History-aware State Estimation (HaSE) module to alleviate the impacts of dominant historical states on the current state estimation. Meanwhile, HaSE also encour-ages an agent to be alert to the current observation changes, thus enabling the agent to make valid actions. Furthermore, we design a History-based State Regularization (HbSR) to explicitly suppress the correlation among navigation states in training. As a result, our agent can update states more ef-fectively while reducing the correlations among navigation states. Experiments on the artificial platform AI2-THOR (i.e., iTHOR and RoboTHOR) demonstrate that HiNL sig-nificantly outperforms state-of-the-art methods on both Suc-cess Rate and SPL in unseen testing environments. 