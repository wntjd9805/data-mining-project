Traditional video action detectors typically adopt the two-stage pipeline, where a person detector is first em-ployed to generate actor boxes and then 3D RoIAlign is used to extract actor-specific features for classification.This detection paradigm requires multi-stage training and inference, and cannot capture context information outside the bounding box. Recently, a few query-based action de-tectors are proposed to predict action instances in an end-to-end manner. However, they still lack adaptability in fea-ture sampling and decoding, thus suffering from the issues of inferior performance or slower convergence. In this pa-per, we propose a new one-stage sparse action detector, termed STMixer. STMixer is based on two core designs.First, we present a query-based adaptive feature sampling module, which endows our STMixer with the flexibility of mining a set of discriminative features from the entire spa-tiotemporal domain. Second, we devise a dual-branch fea-ture mixing module, which allows our STMixer to dynami-cally attend to and mix video features along the spatial and the temporal dimension respectively for better feature de-coding. Coupling these two designs with a video backbone yields an efficient end-to-end action detector. Without bells and whistles, our STMixer obtains the state-of-the-art re-sults on the datasets of AVA, UCF101-24, and JHMDB. 