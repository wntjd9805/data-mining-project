RGB-T tracking aims to leverage the mutual enhance-ment and complement ability of RGB and TIR modalities for improving the tracking process in various scenarios, where cross-modal interaction is the key component. Some previ-ous methods concatenate the RGB and TIR search region features directly to perform a coarse interaction process with redundant background noises introduced. Many other methods sample candidate boxes from search frames and conduct various fusion approaches on isolated pairs of RGB and TIR boxes, which limits the cross-modal interaction within local regions and brings about inadequate context modeling. To alleviate these limitations, we propose a novelTemplate-Bridged Search region Interaction (TBSI) module which exploits templates as the medium to bridge the cross-modal interaction between RGB and TIR search regions by gathering and distributing target-relevant object and envi-ronment contexts. Original templates are also updated with enriched multimodal contexts from the template medium.Our TBSI module is inserted into a ViT backbone for joint feature extraction, search-template matching, and cross-modal interaction. Extensive experiments on three popu-lar RGB-T tracking benchmarks demonstrate our method achieves new state-of-the-art performances. Code is avail-able at https://github.com/RyanHTR/TBSI.Figure 1. Comparison between our cross-modal interaction ap-proach and previous ones. (a) Features of RGB and TIR search frames are directly concatenated. (b) Candidate boxes (RoIs) are sampled from RGB and TIR search frames and fused in pairs with gating or attention mechanisms. (c) Our approach exploits tem-plate tokens as the medium to bridge the cross-modal interaction between RGB and TIR search region tokens. 