In clinical scenarios, multi-specialist consultation could significantly benefit the diagnosis, especially for intricate cases. This inspires us to explore a “multi-expert joint diagnosis” mechanism to upgrade the existing “single ex-pert” framework commonly seen in the current literature.To this end, we propose METransformer, a method to real-ize this idea with a transformer-based backbone. The key design of our method is the introduction of multiple learn-able “expert” tokens into both the transformer encoder and decoder. In the encoder, each expert token interacts with both vision tokens and other expert tokens to learn to attend different image regions for image representation. These ex-pert tokens are encouraged to capture complementary in-formation by an orthogonal loss that minimizes their over-lap. In the decoder, each attended expert token guides the cross-attention between input words and visual tokens, thus influencing the generated report. A metrics-based expert voting strategy is further developed to generate the final re-port. By the multi-experts concept, our model enjoys the merits of an ensemble-based approach but through a man-ner that is computationally more efficient and supports more sophisticated interactions among experts. Experimental re-sults demonstrate the promising performance of our pro-posed model on two widely used benchmarks. Last but not least, the framework-level innovation makes our work ready to incorporate advances on existing “single-expert” models to further improve its performance. 