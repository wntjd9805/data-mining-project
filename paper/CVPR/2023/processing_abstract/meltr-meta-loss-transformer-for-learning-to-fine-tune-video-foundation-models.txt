Foundation models have shown outstanding perfor-mance and generalization capabilities across domains.Since most studies on foundation models mainly focus on the pretraining phase, a naive strategy to minimize a sin-gle task-specific loss is adopted for fine-tuning. However, such fine-tuning methods do not fully leverage other losses that are potentially beneficial for the target task. There-fore, we propose MEta Loss TRansformer (MELTR), a plug-in module that automatically and non-linearly com-bines various loss functions to aid learning the target task via auxiliary learning. We formulate the auxiliary learn-ing as a bi-level optimization problem and present an ef-ficient optimization algorithm based on Approximate Im-plicit Differentiation (AID). For evaluation, we apply our framework to various video foundation models (UniVL,Violet and All-in-one), and show significant performance gain on all four downstream tasks: text-to-video retrieval, video question answering, video captioning, and multi-modal sentiment analysis. Our qualitative analyses demon-strate that MELTR adequately ‘transforms’ individual loss functions and ‘melts’ them into an effective unified loss.Code is available at https://github.com/mlvlab/MELTR. 