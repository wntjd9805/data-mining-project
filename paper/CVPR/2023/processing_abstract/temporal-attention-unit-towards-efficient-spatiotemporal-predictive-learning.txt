Spatiotemporal predictive learning aims to generate fu-ture frames by learning from historical frames. In this pa-per, we investigate existing methods and present a general framework of spatiotemporal predictive learning, in which the spatial encoder and decoder capture intra-frame fea-tures and the middle temporal module catches inter-frame correlations. While the mainstream methods employ recur-rent units to capture long-term temporal dependencies, they suffer from low computational efficiency due to their unpar-allelizable architectures. To parallelize the temporal mod-ule, we propose the Temporal Attention Unit (TAU), which decomposes temporal attention into intra-frame statical at-tention and inter-frame dynamical attention. Moreover, while the mean squared error loss focuses on intra-frame errors, we introduce a novel differential divergence regu-larization to take inter-frame variations into account. Ex-tensive experiments demonstrate that the proposed method enables the derived model to achieve competitive perfor-mance on various spatiotemporal prediction benchmarks. 