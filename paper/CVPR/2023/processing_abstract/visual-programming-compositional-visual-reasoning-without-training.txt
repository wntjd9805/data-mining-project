We present VISPROG, a neuro-symbolic approach to solving complex and compositional visual tasks given nat-ural language instructions. VISPROG avoids the need for any task-specific training. it uses the in-context learning ability of large language models to gener-ate python-like modular programs, which are then executed to get both the solution and a comprehensive and inter-pretable rationale. Each line of the generated program may invoke one of several off-the-shelf computer vision models,Instead, image processing subroutines, or python functions to pro-duce intermediate outputs that may be consumed by subse-quent parts of the program. We demonstrate the flexibility of VISPROG on 4 diverse tasks - compositional visual ques-tion answering, zero-shot reasoning on image pairs, factual knowledge object tagging, and language-guided image edit-ing. We believe neuro-symbolic approaches like VISPROG are an exciting avenue to easily and effectively expand the scope of AI systems to serve the long tail of complex tasks that people may wish to perform.