The traditional definition of co-salient object detection (CoSOD) task is to segment the common salient objects in a group of relevant images. Existing CoSOD models by-default adopt the group consensus assumption. This brings about model robustness defect under the condition of ir-relevant images in the testing image group, which hinders the use of CoSOD models in real-world applications. To address this issue, this paper presents a group exchange-masking (GEM) strategy for robust CoSOD model learn-ing. With two group of image containing different types of salient object as input, the GEM first selects a set of images from each group by the proposed learning based strategy, then these images are exchanged. The proposed feature ex-traction module considers both the uncertainty caused by the irrelevant images and group consensus in the remain-ing relevant images. We design a latent variable genera-tor branch which is made of conditional variational autoen-coder to generate uncertainly-based global stochastic fea-tures. A CoSOD transformer branch is devised to capture the correlation-based local features that contain the group consistency information. At last, the output of two branches are concatenated and fed into a transformer-based decoder, producing robust co-saliency prediction. Extensive evalua-tions on co-saliency detection with and without irrelevant images demonstrate the superiority of our method over a variety of state-of-the-art methods. 