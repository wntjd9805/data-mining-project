The remarkable breakthroughs in point cloud represen-tation learning have boosted their usage in real-world ap-plications such as self-driving cars and virtual reality. How-ever, these applications usually have a strict requirement for not only accurate but also efficient 3D object detec-tion. Recently, knowledge distillation has been proposed as an effective model compression technique, which trans-fers the knowledge from an over-parameterized teacher to a lightweight student and achieves consistent effectiveness in 2D vision. However, due to point clouds’ sparsity and irregularity, directly applying previous image-based knowl-edge distillation methods to point cloud detectors usually leads to unsatisfactory performance. To fill the gap, this paper proposes PointDistiller, a structured knowledge dis-tillation framework for point clouds-based 3D detection.Concretely, PointDistiller includes local distillation which extracts and distills the local geometric structure of point clouds with dynamic graph convolution and reweighted learning strategy, which highlights student learning on the crucial points or voxels to improve knowledge distillation efficiency. Extensive experiments on both voxels-based and raw points-based detectors have demonstrated the effective-ness of our method over seven previous knowledge distilla-tion methods. For instance, our 4× compressed PointPillars student achieves 2.8 and 3.4 mAP improvements on BEV and 3D object detection, outperforming its teacher by 0.9 and 1.8 mAP, respectively. Codes are available in https://github.com/RunpeiDong/PointDistiller. 