Motion capture is a long-standing research problem. Al-though it has been studied for decades, the majority of re-search focus on ground-based movements such as walking, sitting, dancing, etc. Off-grounded actions such as climb-ing are largely overlooked. As an important type of action in sports and firefighting field, the climbing movements is challenging to capture because of its complex back poses, intricate human-scene interactions, and difficult global lo-calization. The research community does not have an in-depth understanding of the climbing action due to the lack of specific datasets. To address this limitation, we collectCIMI4D, a large rock ClImbing MotIon dataset from 12 persons climbing 13 different climbing walls. The dataset consists of around 180,000 frames of pose inertial mea-surements, LiDAR point clouds, RGB videos, high-precision static point cloud scenes, and reconstructed scene meshes.Moreover, we frame-wise annotate touch rock holds to fa-∗ Equal contribution.† Corresponding author. cilitate a detailed exploration of human-scene interaction.The core of this dataset is a blending optimization pro-cess, which corrects for the pose as it drifts and is af-fected by the magnetic conditions. To evaluate the merit of CIMI4D, we perform four tasks which include human pose estimations (with/without scene constraints), pose pre-diction, and pose generation. The experimental results demonstrate that CIMI4D presents great challenges to ex-isting methods and enables extensive research opportuni-ties. We share the dataset with the research community in http://www.lidarhumanmotion.net/cimi4d/. 