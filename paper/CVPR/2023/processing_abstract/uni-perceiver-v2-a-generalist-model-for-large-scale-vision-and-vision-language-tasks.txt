Despite the remarkable success of foundation models, their task-speciﬁc ﬁne-tuning paradigm makes them incon-sistent with the goal of general perception modeling. The key to eliminating this inconsistency is to use generalist models for general task modeling. However, existing at-tempts at generalist models are inadequate in both ver-satility and performance.In this paper, we propose Uni-Perceiver v2, which is the ﬁrst generalist model capable of handling major large-scale vision and vision-language tasks with competitive performance. Speciﬁcally, images are encoded as general region proposals, while texts are encoded via a Transformer-based language model. The en-coded representations are transformed by a task-agnostic decoder. Different tasks are formulated as a uniﬁed max-imum likelihood estimation problem. We further propose an effective optimization technique named Task-BalancedGradient Normalization to ensure stable multi-task learn-ing with an unmixed sampling strategy, which is helpful for tasks requiring large batch-size training. After being jointly trained on various tasks, Uni-Perceiver v2 is capable of di-rectly handling downstream tasks without any task-speciﬁc adaptation. Results show that Uni-Perceiver v2 outper-forms all existing generalist models in both versatility and performance. Meanwhile, compared with the commonly-recognized strong baselines that require tasks-speciﬁc ﬁne-tuning, Uni-Perceiver v2 achieves competitive performance on a broad range of vision and vision-language tasks. 