Analogical reasoning enables agents to extract relevant information from scenes, and efficiently navigate them in familiar ways. While progressive-matrix problems (PMPs) are becoming popular for the development and evaluation of analogical reasoning in computer vision, we argue that the dominant methodology in this area struggles to expose the lack of meaningful generalisation in solvers, and rein-forces an objectivist stance on perception – that objects can only be seen one way – which we believe to be counter-productive. In this paper, we introduce the Unicode Analo-gies challenge, consisting of polysemic, character-basedPMPs to benchmark fluid conceptualisation ability in vision systems. Writing systems have evolved characters at mul-tiple levels of abstraction, from iconic through to symbolic representations, producing both visually interrelated yet ex-ceptionally diverse images when compared to those exhib-ited by existing PMP datasets. Our framework has been de-signed to challenge models by presenting tasks much harder to complete without robust feature extraction, while remain-ing largely solvable by human participants. We therefore argue that Unicode Analogies elegantly captures and tests for a facet of human visual reasoning that is severely lack-ing in current-generation AI. 