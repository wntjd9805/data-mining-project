How to generate the ground-truth (GT) image is a criti-cal issue for training realistic image super-resolution (Real-ISR) models. Existing methods mostly take a set of high-resolution (HR) images as GTs and apply various degra-dations to simulate their low-resolution (LR) counterparts.Though great progress has been achieved, such an LR-HR pair generation scheme has several limitations. First, the perceptual quality of HR images may not be high enough, limiting the quality of Real-ISR outputs. Second, existing schemes do not consider much human perception in GT generation, and the trained models tend to produce over-smoothed results or unpleasant artifacts. With the above considerations, we propose a human guided GT generation scheme. We first elaborately train multiple image enhance-ment models to improve the perceptual quality of HR im-ages, and enable one LR image having multiple HR coun-terparts. Human subjects are then involved to annotate the high quality regions among the enhanced HR images as GTs, and label the regions with unpleasant artifacts as negative samples. A human guided GT image dataset with both positive and negative samples is then constructed, and a loss function is proposed to train the Real-ISR mod-els. Experiments show that the Real-ISR models trained on our dataset can produce perceptually more realistic re-sults with less artifacts. Dataset and codes can be found at https://github.com/ChrisDud0257/HGGT. 