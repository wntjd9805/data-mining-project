A phrase grounding model receives an input image and a text phrase and outputs a suitable localization map. We present an effective way to refine a phrase ground model by considering self-similarity maps extracted from the la-tent representation of the modelâ€™s image encoder. Our main insights are that these maps resemble localization maps and that by combining such maps, one can obtain useful pseudo-labels for performing self-training. Our re-sults surpass, by a large margin, the state of the art in weakly supervised phrase grounding. A similar gap in per-formance is obtained for a recently proposed downstream task called WWbL, in which only the image is input, without any text. Our code is available at https://github. com/talshaharabany/Similarity-Maps-for-Self-Training-Weakly-Supervised-Phrase-Grounding. 