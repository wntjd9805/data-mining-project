For years, researchers have been devoted to general-izable object perception and manipulation, where cross-category generalizability is highly desired yet underex-plored.In this work, we propose to learn such cross-category skills via Generalizable and Actionable Parts (GAParts). By identifying and defining 9 GAPart classes (lids, handles, etc.) in 27 object categories, we construct a large-scale part-centric interactive dataset, GAPartNet, where we provide rich, part-level annotations (semantics, poses) for 8,489 part instances on 1,166 objects. Based onGAPartNet, we investigate three cross-category tasks: part segmentation, part pose estimation, and part-based object manipulation. Given the significant domain gaps between seen and unseen object categories, we propose a robust 3D segmentation method from the perspective of domain gen-eralization by integrating adversarial learning techniques.Our method outperforms all existing methods by a large*Equal contribution with the order determined by rolling dice.â€ Corresponding author: hewang@pku.edu.cn. margin, no matter on seen or unseen categories. Further-more, with part segmentation and pose estimation results, we leverage the GAPart pose definition to design part-based manipulation heuristics that can generalize well to unseen object categories in both the simulator and the real world. 