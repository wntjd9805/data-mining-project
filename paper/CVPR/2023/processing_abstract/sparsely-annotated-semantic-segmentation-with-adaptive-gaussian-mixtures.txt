Sparsely annotated semantic segmentation (SASS) aims to learn a segmentation model by images with sparse labels (i.e., points or scribbles). Existing methods mainly focus on introducing low-level affinity or generating pseudo la-bels to strengthen supervision, while largely ignoring the inherent relation between labeled and unlabeled pixels. In this paper, we observe that pixels that are close to each other in the feature space are more likely to share the same class.Inspired by this, we propose a novel SASS frame-work, which is equipped with an Adaptive Gaussian Mix-ture Model (AGMM). Our AGMM can effectively endow re-liable supervision for unlabeled pixels based on the distri-butions of labeled and unlabeled pixels. Specifically, we first build Gaussian mixtures using labeled pixels and their relatively similar unlabeled pixels, where the labeled pix-els act as centroids, for modeling the feature distribution of each class. Then, we leverage the reliable information from labeled pixels and adaptively generated GMM predic-tions to supervise the training of unlabeled pixels, achieving online, dynamic, and robust self-supervision. In addition, by capturing category-wise Gaussian mixtures, AGMM en-courages the model to learn discriminative class decision boundaries in an end-to-end contrastive learning manner.Experimental results conducted on the PASCAL VOC 2012 and Cityscapes datasets demonstrate that our AGMM can establish new state-of-the-art SASS performance. Code is available at https://github.com/Luffy03/AGMM-SASS.Figure 1. (a) Illustration of SASS task. (b) Different from existingSASS frameworks, our AGMM leverages the reliable information of labeled pixels and generates GMM predictions for dynamic on-line supervision. f denotes the model, P and G represent segmen-tation and GMM predictions, respectively. Solid and dashed lines represent model propagation and supervision, respectively. 