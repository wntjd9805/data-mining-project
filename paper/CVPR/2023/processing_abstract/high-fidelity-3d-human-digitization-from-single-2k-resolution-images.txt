High-quality 3D human body reconstruction requires high-Ô¨Ådelity and large-scale training data and appropriate network design that effectively exploits the high-resolution input images. To tackle these problems, we propose a sim-ple yet effective 3D human digitization method called 2K2K, which constructs a large-scale 2K human dataset and in-fers 3D human models from 2K resolution images. The proposed method separately recovers the global shape of a human and its details. The low-resolution depth network predicts the global structure from a low-resolution image, and the part-wise image-to-normal network predicts the de-tails of the 3D human body structure. The high-resolution depth network merges the global 3D shape and the detailed structures to infer the high-resolution front and back side depth maps. Finally, an off-the-shelf mesh generator recon-structs the full 3D human model, which are available at https://github.com/SangHunHan92/2K2K. In addition, we also provide 2,050 3D human models, including texture maps, 3D joints, and SMPL parameters for research purposes. In experiments, we demonstrate competitive per-formance over the recent works on various datasets. 