Recently, Visual Information Extraction (VIE) has been becoming increasingly important in both the academia and industry, due to the wide range of real-world applications.Previously, numerous works have been proposed to tackle this problem. However, the benchmarks used to assess these methods are relatively plain, i.e., scenarios with real-world complexity are not fully represented in these benchmarks.As the first contribution of this work, we curate and re-lease a new dataset for VIE, in which the document im-ages are much more challenging in that they are taken from real applications, and difficulties such as blur, partial oc-clusion, and printing shift are quite common. All these fac-tors may lead to failures in information extraction. There-fore, as the second contribution, we explore an alternative approach to precisely and robustly extract key information from document images under such tough conditions. Specif-ically, in contrast to previous methods, which usually ei-ther incorporate visual information into a multi-modal ar-chitecture or train text spotting and information extraction in an end-to-end fashion, we explicitly model entities as se-mantic points, i.e., center points of entities are enriched with semantic information describing the attributes and re-lationships of different entities, which could largely bene-fit entity labeling and linking. Extensive experiments on standard benchmarks in this field as well as the proposed*Equal Contribution.â€ Correspondence Author. dataset demonstrate that the proposed method can achieve significantly enhanced performance on entity labeling and linking, compared with previous state-of-the-art models.Dataset is available at https://www.modelscope. cn/datasets/damo/SIBR/summary. 