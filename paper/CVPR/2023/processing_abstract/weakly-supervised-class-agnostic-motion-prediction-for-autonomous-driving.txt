Understanding the motion behavior of dynamic environ-ments is vital for autonomous driving, leading to increas-ing attention in class-agnostic motion prediction in LiDAR point clouds. Outdoor scenes can often be decomposed into mobile foregrounds and static backgrounds, which enables us to associate motion understanding with scene parsing.Based on this observation, we study a novel weakly su-pervised motion prediction paradigm, where fully or par-tially (1%, 0.1%) annotated foreground/background binary masks are used for supervision, rather than using expen-sive motion annotations. To this end, we propose a two-stage weakly supervised approach, where the segmentation model trained with the incomplete binary masks in Stage1 will facilitate the self-supervised learning of the motion prediction network in Stage2 by estimating possible mov-ing foregrounds in advance. Furthermore, for robust self-supervised motion learning, we design a Consistency-awareChamfer Distance loss by exploiting multi-frame informa-tion and explicitly suppressing potential outliers. Compre-hensive experiments show that, with fully or partially bi-nary masks as supervision, our weakly supervised models surpass the self-supervised models by a large margin and perform on par with some supervised ones. This further demonstrates that our approach achieves a good compro-mise between annotation effort and performance. 