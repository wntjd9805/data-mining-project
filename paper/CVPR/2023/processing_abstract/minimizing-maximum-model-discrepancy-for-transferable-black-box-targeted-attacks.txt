In this work, we study the black-box targeted attack prob-lem from the model discrepancy perspective. On the the-oretical side, we present a generalization error bound for black-box targeted attacks, which gives a rigorous theoreti-cal analysis for guaranteeing the success of the attack. We reveal that the attack error on a target model mainly de-pends on empirical attack error on the substitute model and the maximum model discrepancy among substitute models.On the algorithmic side, we derive a new algorithm for black-box targeted attacks based on our theoretical analy-sis, in which we additionally minimize the maximum model discrepancy (M3D) of the substitute models when training the generator to generate adversarial examples. In this way, our model is capable of crafting highly transferable ad-versarial examples that are robust to the model variation, thus improving the success rate for attacking the black-box model. We conduct extensive experiments on the ImageNet dataset with different classification models, and our pro-posed approach outperforms existing state-of-the-art meth-ods by a significant margin. The code will be available at https://github.com/Asteriajojo/M3D. 