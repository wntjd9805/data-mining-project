3D content manipulation is an important computer vi-sion task with many real-world applications (e.g., prod-uct design, cartoon generation, and 3D Avatar edit-ing). Recently proposed 3D GANs can generate diverse photorealistic 3D-aware contents using Neural Radiance fields (NeRF). However, manipulation of NeRF still remains a challenging problem since the visual quality tends to degrade after manipulation and suboptimal control han-dles such as 2D semantic maps are used for manipula-tions. While text-guided manipulations have shown po-tential in 3D editing, such approaches often lack local-ity. To overcome these problems, we propose Local Edit-ing NeRF (LENeRF), which only requires text inputs for fine-grained and localized manipulation. Specifically, we present three add-on modules of LENeRF, the Latent Resid-ual Mapper, the Attention Field Network, and the Deforma-tion Network, which are jointly used for local manipulations of 3D features by estimating a 3D attention field. The 3D attention field is learned in an unsupervised way, by distill-ing the zero-shot mask generation capability of CLIP to the 3D space with multi-view guidance. We conduct diverse ex-periments and thorough evaluations both quantitatively and qualitatively.1 