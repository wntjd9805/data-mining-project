Controllable layout generation aims at synthesizing plausible arrangement of element bounding boxes with op-tional constraints, such as type or position of a specific el-ement. In this work, we try to solve a broad range of lay-out generation tasks in a single model that is based on dis-crete state-space diffusion models. Our model, named Lay-outDM, naturally handles the structured layout data in the discrete representation and learns to progressively infer a noiseless layout from the initial input, where we model the layout corruption process by modality-wise discrete diffu-sion. For conditional generation, we propose to inject lay-out constraints in the form of masking or logit adjustment during inference. We show in the experiments that our Lay-outDM successfully generates high-quality layouts and out-performs both task-specific and task-agnostic baselines on several layout tasks.1 