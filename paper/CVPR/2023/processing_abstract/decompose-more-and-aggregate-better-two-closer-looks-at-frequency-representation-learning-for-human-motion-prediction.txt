Encouraged by the effectiveness of encoding temporal dynamics within the frequency domain, recent human mo-tion prediction systems prefer to first convert the motion representation from the original pose space into the fre-quency space. In this paper, we introduce two closer looks at effective frequency representation learning for robust mo-tion prediction and summarize them as: decompose more and aggregate better. Motivated by these two insights, we develop two powerful units that factorize the frequency representation learning task with a novel decomposition-aggregation two-stage strategy: (1) frequency decompo-sition unit unweaves multi-view frequency representations from an input body motion by embedding its frequency fea-tures into multiple spaces; (2) feature aggregation unit de-ploys a series of intra-space and inter-space feature aggre-gation layers to collect comprehensive frequency represen-tations from these spaces for robust human motion predic-tion. As evaluated on large-scale datasets, we develop a strong baseline model for the human motion prediction task that outperforms state-of-the-art methods by large margins: 8%∼12% on Human3.6M, 3%∼7% on CMU MoCap, and 7%∼10% on 3DPW. 