Motion segmentation is one of the main tasks in com-puter vision and is relevant for many applications. The op-tical flow (OF) is the input generally used to segment every frame of a video sequence into regions of coherent motion.Temporal consistency is a key feature of motion segmenta-tion, but it is often neglected. In this paper, we propose an original unsupervised spatio-temporal framework for mo-tion segmentation from optical flow that fully investigates the temporal dimension of the problem. More specifically, we have defined a 3D network for multiple motion segmen-tation that takes as input a sub-volume of successive opti-cal flows and delivers accordingly a sub-volume of coher-ent segmentation maps. Our network is trained in a fully unsupervised way, and the loss function combines a flow reconstruction term involving spatio-temporal parametric motion models, and a regularization term enforcing tempo-ral consistency on the masks. We have specified an easy temporal linkage of the predicted segments. Besides, we have proposed a flexible and efficient way of coding U-nets.We report experiments on several VOS benchmarks with convincing quantitative results, while not using appearance and not training with any ground-truth data. We also high-light through visual results the distinctive contribution of the short- and long-term temporal consistency brought by our OF segmentation method. 