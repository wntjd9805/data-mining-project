Recent LSS-based multi-view 3D object detection has made tremendous progress, by processing the features inBrid-Eye-View (BEV) via the convolutional detector. How-ever, the typical convolution ignores the radial symmetry of the BEV features and increases the difficulty of the de-tector optimization. To preserve the inherent property of the BEV features and ease the optimization, we propose an azimuth-equivariant convolution (AeConv) and an azimuth-equivariant anchor. The sampling grid of AeConv is always in the radial direction, thus it can learn azimuth-invariantBEV features. The proposed anchor enables the detection head to learn predicting azimuth-irrelevant targets. In ad-dition, we introduce a camera-decoupled virtual depth to unify the depth prediction for the images with different cam-era intrinsic parameters. The resultant detector is dubbedAzimuth-equivariant Detector (AeDet). Extensive experi-ments are conducted on nuScenes, and AeDet achieves a 62.0% NDS, surpassing the recent multi-view 3D object de-tectors such as PETRv2 and BEVDepth by a large mar-gin. Project page: https://fcjian.github.io/ aedet. 