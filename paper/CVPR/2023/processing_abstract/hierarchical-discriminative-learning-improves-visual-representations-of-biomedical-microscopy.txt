Learning high-quality, self-supervised, visual represen-tations is essential to advance the role of computer vision in biomedical microscopy and clinical medicine. Previous work has focused on self-supervised representation learn-ing (SSL) methods developed for instance discrimination and applied them directly to image patches, or ﬁelds-of-view, sampled from gigapixel whole-slide images (WSIs) used for cancer diagnosis. However, this strategy is lim-ited because it (1) assumes patches from the same patient are independent, (2) neglects the patient-slide-patch hier-archy of clinical biomedical microscopy, and (3) requires strong data augmentations that can degrade downstream performance. Importantly, sampled patches from WSIs of a patient’s tumor are a diverse set of image examples that capture the same underlying cancer diagnosis. This moti-vated HiDisc, a data-driven method that leverages the in-herent patient-slide-patch hierarchy of clinical biomedical microscopy to deﬁne a hierarchical discriminative learning task that implicitly learns features of the underlying diag-nosis. HiDisc uses a self-supervised contrastive learning framework in which positive patch pairs are deﬁned based on a common ancestry in the data hierarchy, and a uniﬁed patch, slide, and patient discriminative learning objective is used for visual SSL. We benchmark HiDisc visual represen-tations on two vision tasks using two biomedical microscopy datasets, and demonstrate that (1) HiDisc pretraining out-performs current state-of-the-art self-supervised pretrain-ing methods for cancer diagnosis and genetic mutation pre-diction, and (2) HiDisc learns high-quality visual repre-sentations using natural patch diversity without strong data augmentations.Figure 1. Hierarchical self-supervised discriminative learn-ing for visual representations. Clinical biomedical microscopy has a hierarchical patch-slide-patient data structure. HiDisc com-bines patch, slide, and patient discrimination into a uniﬁed self-supervised learning task. 