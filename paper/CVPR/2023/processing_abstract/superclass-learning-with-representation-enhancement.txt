In many real scenarios, data are often divided into a handful of artificial super categories in terms of ex-pert knowledge rather than the representations of images.Concretely, a superclass may contain massive and vari-ous raw categories, such as refuse sorting. Due to the lack of common semantic features, the existing classifica-tion techniques are intractable to recognize superclass with-out raw class labels, thus they suffer severe performance damage or require huge annotation costs. To narrow this gap, this paper proposes a superclass learning framework, called SuperClass Learning with Representation Enhance-ment(SCLRE), to recognize super categories by leverag-ing enhanced representation. Specifically, by exploiting the self-attention technique across the batch, SCLRE col-lapses the boundaries of those raw categories and enhances the representation of each superclass. On the enhanced representation space, a superclass-aware decision bound-ary is then reconstructed. Theoretically, we prove that by leveraging attention techniques the generalization error ofSCLRE can be bounded under superclass scenarios. Exper-imentally, extensive results demonstrate that SCLRE outper-forms the baseline and other contrastive-based methods onCIFAR-100 datasets and four high-resolution datasets. 