The polarization event camera PDAVIS is a novel bio-inspired neuromorphic vision sensor that reports both con-ventional polarization frames and asynchronous, continu-ously per-pixel polarization brightness changes (polariza-tion events) with fast temporal resolution and large dy-namic range. A deep neural network method (Polariza-tion FireNet) was previously developed to reconstruct the polarization angle and degree from polarization events for bridging the gap between the polarization event camera and mainstream computer vision. However, PolarizationFireNet applies a network pre-trained for normal event-based frame reconstruction independently on each of four channels of polarization events from four linear polariza-tion angles, which ignores the correlations between chan-nels and inevitably introduces content inconsistency be-tween the four reconstructed frames, resulting in unsatisfac-tory polarization reconstruction performance. In this work, we strive to train an effective, yet efficient, DNN model that directly outputs polarization from the input raw polariza-tion events. To this end, we constructed the first large-scale event-to-polarization dataset, which we subsequently employed to train our events-to-polarization network E2P.E2P extracts rich polarization patterns from input polariza-tion events and enhances features through cross-modality context integration. We demonstrate that E2P outperformsPolarization FireNet by a significant margin with no addi-tional computing cost. Experimental results also show thatE2P produces more accurate measurement of polarization than the PDAVIS frames in challenging fast and high dy-namic range scenes. Code and data are publicly available at: https://github.com/SensorsINI/e2p. 