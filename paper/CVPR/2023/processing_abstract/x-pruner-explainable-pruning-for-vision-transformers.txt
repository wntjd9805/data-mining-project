Recently vision transformer models have become promi-nent models for a range of tasks. These models, how-ever, usually suffer from intensive computational costs and heavy memory requirements, making them impractical for deployment on edge platforms. Recent studies have pro-posed to prune transformers in an unexplainable manner, which overlook the relationship between internal units of the model and the target class, thereby leading to infe-rior performance. To alleviate this problem, we propose a novel explainable pruning framework dubbed X-Pruner, which is designed by considering the explainability of the pruning criterion. Speciﬁcally, to measure each prunable unit’s contribution to predicting each target class, a novel explainability-aware mask is proposed and learned in an end-to-end manner. Then, to preserve the most informative units and learn the layer-wise pruning rate, we adaptively search the layer-wise threshold that differentiates between unpruned and pruned units based on their explainability-aware mask values. To verify and evaluate our method, we apply the X-Pruner on representative transformer mod-els including the DeiT and Swin Transformer. Comprehen-sive simulation results demonstrate that the proposed X-Pruner outperforms the state-of-the-art black-box methods with signiﬁcantly reduced computational costs and slight performance degradation. Code is available at https://github.com/vickyyu90/XPruner. 