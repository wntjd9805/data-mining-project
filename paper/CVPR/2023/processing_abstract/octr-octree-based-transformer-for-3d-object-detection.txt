A key challenge for LiDAR-based 3D object detection is to capture sufﬁcient features from large scale 3D scenes es-pecially for distant or/and occluded objects. Albeit recent efforts made by Transformers with the long sequence mod-eling capability, they fail to properly balance the accuracy and efﬁciency, suffering from inadequate receptive ﬁelds or coarse-grained holistic correlations. In this paper, we pro-pose an Octree-based Transformer, named OcTr, to address this issue. It ﬁrst constructs a dynamic octree on the hier-archical feature pyramid through conducting self-attention on the top level and then recursively propagates to the level below restricted by the octants, which captures rich global context in a coarse-to-ﬁne manner while maintaining the computational complexity under control. Furthermore, for enhanced foreground perception, we propose a hybrid po-sitional embedding, composed of the semantic-aware po-sitional embedding and attention mask, to fully exploit se-mantic and geometry clues. Extensive experiments are con-ducted on the Waymo Open Dataset and KITTI Dataset, andOcTr reaches newly state-of-the-art results. 