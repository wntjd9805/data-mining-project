Most previous co-salient object detection works mainly focus on extracting co-salient cues via mining the con-sistency relations across images while ignore explicit ex-ploration of background regions.In this paper, we pro-pose a Discriminative co-saliency and background MiningTransformer framework (DMT) based on several econom-ical multi-grained correlation modules to explicitly mine both co-saliency and background information and effec-tively model their discrimination. Specifically, we first pro-pose a region-to-region correlation module for introduc-ing inter-image relations to pixel-wise segmentation fea-tures while maintaining computational efficiency. Then, we use two types of pre-defined tokens to mine co-saliency and background information via our proposed contrast-induced pixel-to-token correlation and co-saliency token-to-token correlation modules. We also design a token-guided fea-ture refinement module to enhance the discriminability of the segmentation features under the guidance of the learned tokens. We perform iterative mutual promotion for the seg-mentation feature extraction and token construction. Exper-imental results on three benchmark datasets demonstrate the effectiveness of our proposed method. The source code is available at: https://github.com/dragonlee258079/DMT. 