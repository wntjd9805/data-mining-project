ConVConVConVTargetEstimationMost current RGB-T trackers adopt a two-stream struc-ture to extract unimodal RGB and thermal features and complex fusion strategies to achieve multi-modal feature fusion, which require a huge number of parameters, thus hindering their real-life applications. On the other hand, a compact RGB-T tracker may be computationally efﬁ-cient but encounter non-negligible performance degrada-tion, due to the weakening of feature representation abil-ity. To remedy this situation, a cross-modality distillation framework is presented to bridge the performance gap be-tween a compact tracker and a powerful tracker. Speciﬁ-cally, a speciﬁc-common feature distillation module is pro-posed to transform the modality-common information as well as the modality-speciﬁc information from a deeper two-stream network to a shallower single-stream network. In addition, a multi-path selection distillation module is pro-posed to instruct a simple fusion module to learn more ac-curate multi-modal information from a well-designed fusion mechanism by using multiple paths. We validate the effec-tiveness of our method with extensive experiments on threeRGB-T benchmarks, which achieves state-of-the-art perfor-mance but consumes much less computational resources. 