Semi-Supervised Domain Adaptation (SSDA) involves learning to classify unseen target data with a few labeled and lots of unlabeled target data, along with many labeled source data from a related domain. Current SSDA ap-proaches usually aim at aligning the target data to the la-beled source data with feature space mapping and pseudo-label assignments. Nevertheless, such a source-oriented model can sometimes align the target data to source data of the wrong classes, degrading the classification per-formance. This paper presents a novel source-adaptive paradigm that adapts the source data to match the tar-get data. Our key idea is to view the source data as a noisily-labeled version of the ideal target data. Then, we propose an SSDA model that cleans up the label noise dy-namically with the help of a robust cleaner component de-signed from the target perspective. Since the paradigm is very different from the core ideas behind existing SSDA ap-proaches, our proposed model can be easily coupled with them to improve their performance. Empirical results on two state-of-the-art SSDA approaches demonstrate that the proposed model effectively cleans up the noise within the source labels and exhibits superior performance over those approaches across benchmark datasets. Our code is avail-able at https://github.com/chu0802/SLA. 