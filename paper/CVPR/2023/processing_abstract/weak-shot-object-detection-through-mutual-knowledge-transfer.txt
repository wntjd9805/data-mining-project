Weak-shot Object Detection methods exploit a fully-annotated source dataset to facilitate the detection perfor-mance on the target dataset which only contains image-level labels for novel categories. To bridge the gap be-tween these two datasets, we aim to transfer the object knowledge between the source (S) and target (T) datasets in a bi-directional manner. We propose a novel KnowledgeTransfer (KT) loss which simultaneously distills the knowl-edge of objectness and class entropy from a proposal gen-erator trained on the S dataset to optimize a multiple in-stance learning module on the T dataset. By jointly opti-mizing the classification loss and the proposed KT loss, the multiple instance learning module effectively learns to clas-sify object proposals into novel categories in the T dataset with the transferred knowledge from base categories in theS dataset. Noticing the predicted boxes on the T dataset can be regarded as an extension for the original annotations on the S dataset to refine the proposal generator in return, we further propose a novel Consistency Filtering (CF) method to reliably remove inaccurate pseudo labels by evaluating the stability of the multiple instance learning module upon noise injections. Via mutually transferring knowledge be-tween the S and T datasets in an iterative manner, the de-tection performance on the target dataset is significantly im-proved. Extensive experiments on public benchmarks vali-date that the proposed method performs favourably against the state-of-the-art methods without increasing the model parameters or inference computational complexity. 