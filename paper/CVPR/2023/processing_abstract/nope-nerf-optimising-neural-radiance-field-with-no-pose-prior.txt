Training a Neural Radiance Field (NeRF) without pre-computed camera poses is challenging. Recent advances in this direction demonstrate the possibility of jointly opti-mising a NeRF and camera poses in forward-facing scenes.However, these methods still face difficulties during dra-matic camera movement. We tackle this challenging prob-lem by incorporating undistorted monocular depth priors.These priors are generated by correcting scale and shift parameters during training, with which we are then able to constrain the relative poses between consecutive frames.This constraint is achieved using our proposed novel loss functions. Experiments on real-world indoor and outdoor scenes show that our method can handle challenging cam-era trajectories and outperforms existing methods in terms of novel view rendering quality and pose estimation ac-curacy. Our project page is https://nope- nerf. active.vision. 