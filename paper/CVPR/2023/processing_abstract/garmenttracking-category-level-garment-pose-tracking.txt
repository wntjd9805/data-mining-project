Garments are important to humans. A visual system that can estimate and track the complete garment pose can be useful for many downstream tasks and real-world applications.In this work, we present a complete pack-age to address the category-level garment pose tracking task: (1) A recording system VR-Garment, with which users can manipulate virtual garment models in simula-tion through a VR interface. (2) A large-scale dataset VR-Folding, with complex garment pose configurations in ma-nipulation like flattening and folding. (3) An end-to-end online tracking framework GarmentTracking, which pre-dicts complete garment pose both in canonical space and task space given a point cloud sequence. Extensive ex-periments demonstrate that the proposed GarmentTrack-ing achieves great performance even when the garment has large non-rigid deformation. It outperforms the base-line approach on both speed and accuracy. We hope our proposed solution can serve as a platform for future re-search. Codes and datasets are available in https:// garment-tracking.robotflow.ai. 