Novel View Synthesis (NVS) aims at synthesizing an im-age from an arbitrary viewpoint using multi-view images and camera poses. Among the methods for NVS, NeuralRadiance Fields (NeRF) is capable of NVS for an arbitrary resolution as it learns a continuous volumetric representa-tion. However, radiance fields rely heavily on the spectral characteristics of coordinate-based networks. Thus, there is a limit to improving the performance of high-resolution novel view synthesis (HRNVS). To solve this problem, we propose a novel framework using cross-guided optimiza-tion of the single-image super-resolution (SISR) and radi-ance fields. We perform multi-view image super-resolution (MVSR) on train-view images during the radiance fields op-timization process. It derives the updated SR result by fus-ing the feature map obtained from SISR and voxel-based un-certainty fields generated by integrated errors of train-view images. By repeating the updates during radiance fields op-timization, train-view images for radiance fields optimiza-tion have multi-view consistency and high-frequency de-tails simultaneously, ultimately improving the performance of HRNVS. Experiments of HRNVS and MVSR on various benchmark datasets show that the proposed method signifi-cantly surpasses existing methods. 