As a primitive 3D data representation, point clouds are prevailing in 3D sensing, yet short of intrinsic struc-tural information of the underlying objects. Such discrep-ancy poses great challenges in directly establishing corre-spondences between point clouds sampled from deformable shapes. In light of this, we propose Neural Intrinsic Embed-ding (NIE) to embed each vertex into a high-dimensional space in a way that respects the intrinsic structure. Based upon NIE, we further present a weakly-supervised learn-ing framework for non-rigid point cloud registration. Un-like the prior works, we do not require expansive and sen-sitive off-line basis construction (e.g., eigen-decomposition of Laplacians), nor do we require ground-truth correspon-dence labels for supervision. We empirically show that our framework performs on par with or even better than the state-of-the-art baselines, which generally require more su-pervision and/or more structural geometric input. 