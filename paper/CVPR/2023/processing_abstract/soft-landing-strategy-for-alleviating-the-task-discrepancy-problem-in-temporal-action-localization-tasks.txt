Temporal Action Localization (TAL) methods typically operate on top of feature sequences from a frozen snippet encoder that is pretrained with the Trimmed Action Classiﬁ-cation (TAC) tasks, resulting in a task discrepancy problem.While existing TAL methods mitigate this issue either by re-training the encoder with a pretext task or by end-to-end ﬁne-tuning, they commonly require an overload of high memory and computation. In this work, we introduce Soft-Landing (SoLa) strategy, an efﬁcient yet effective framework to bridge the transferability gap between the pretrained encoder and the downstream tasks by incorporating a light-weight neural network, i.e., a SoLa module, on top of the frozen encoder.We also propose an unsupervised training scheme for theSoLa module; it learns with inter-frame Similarity Match-ing that uses the frame interval as its supervisory signal, eliminating the need for temporal annotations. Experimen-tal evaluation on various benchmarks for downstream TAL tasks shows that our method effectively alleviates the task discrepancy problem with remarkable computational efﬁ-ciency. 