Language-based colorization produces plausible col-ors consistent with the language description provided by the user. Recent studies introduce additional annotation to prevent color-object coupling and mismatch issues, but they still have difÔ¨Åculty in distinguishing instances corre-sponding to the same object words. In this paper, we pro-pose a transformer-based framework to automatically ag-gregate similar image patches and achieve instance aware-ness without any additional knowledge. By applying our presented luminance augmentation and counter-color loss to break down the statistical correlation between luminance and color words, our model is driven to synthesize colors with better descriptive consistency. We further collect a dataset to provide distinctive visual characteristics and de-tailed language descriptions for multiple instances in the# Equal contributions. * Corresponding author. same image. Extensive experiments demonstrate our ad-vantages of synthesizing visually pleasing and description-consistent results of instance-aware colorization. 