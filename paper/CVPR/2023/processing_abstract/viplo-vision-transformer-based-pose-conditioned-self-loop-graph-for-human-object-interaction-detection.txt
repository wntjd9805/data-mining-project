Human-Object Interaction (HOI) detection, which lo-calizes and infers relationships between human and ob-jects, plays an important role in scene understanding. Al-though two-stage HOI detectors have advantages of high efficiency in training and inference, they suffer from lower performance than one-stage methods due to the old back-bone networks and the lack of considerations for theHOI perception process of humans in the interaction clas-sifiers.In this paper, we propose Vision Transformer based Pose-Conditioned Self-Loop Graph (ViPLO) to re-solve these problems. First, we propose a novel feature ex-traction method suitable for the Vision Transformer back-bone, called masking with overlapped area (MOA) module.The MOA module utilizes the overlapped area between each patch and the given region in the attention function, which addresses the quantization problem when using the VisionTransformer backbone. In addition, we design a graph with a pose-conditioned self-loop structure, which updates the human node encoding with local features of human joints.This allows the classifier to focus on specific human joints to effectively identify the type of interaction, which is mo-tivated by the human perception process for HOI. As a re-sult, ViPLO achieves the state-of-the-art results on two pub-lic benchmarks, especially obtaining a +2.07 mAP perfor-mance gain on the HICO-DET dataset. 