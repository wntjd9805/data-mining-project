Since light field simultaneously records spatial informa-tion and angular information of light rays, it is considered to be beneficial for many potential applications, and seman-tic segmentation is one of them. The regular variation of image information across views facilitates a comprehensive scene understanding. However, in the case of limited mem-ory, the high-dimensional property of light field makes the problem more intractable than generic semantic segmenta-tion, manifested in the difficulty of fully exploiting the re-lationships among views while maintaining contextual in-formation in single view. In this paper, we propose a novel network called LF-IENet for light field semantic segmenta-tion. It contains two different manners to mine complemen-tary information from surrounding views to segment cen-tral view. One is implicit feature integration that leverages attention mechanism to compute inter-view and intra-view similarity to modulate features of central view. The other is explicit feature propagation that directly warps features of other views to central view under the guidance of disparity.They complement each other and jointly realize complemen-tary information fusion across views in light field. The pro-posed method achieves outperforming performance on both real-world and synthetic light field datasets, demonstrating the effectiveness of this new architecture. 