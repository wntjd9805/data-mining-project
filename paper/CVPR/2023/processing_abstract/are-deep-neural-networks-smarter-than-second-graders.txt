Recent times have witnessed an increasing number of ap-plications of deep neural networks towards solving tasks that require superior cognitive abilities, e.g., playing Go, generating art, question answering (e.g., ChatGPT), etc.Such a dramatic progress raises the question: how general-izable are neural networks in solving problems that demand broad skills? To answer this question, we propose SMART: a Simple Multimodal Algorithmic Reasoning Task and the associated SMART-101 dataset1, for evaluating the abstrac-tion, deduction, and generalization abilities of neural net-works in solving visuo-linguistic puzzles designed specifi-cally for children in the 6–8 age group. Our dataset con-sists of 101 unique puzzles; each puzzle comprises a picture and a question, and their solution needs a mix of several elementary skills, including arithmetic, algebra, and spa-tial reasoning, among others. To scale our dataset towards training deep neural networks, we programmatically gen-erate entirely new instances for each puzzle while retaining their solution algorithm. To benchmark the performance on the SMART-101 dataset, we propose a vision-and-language meta-learning model that can incorporate varied state-of-the-art neural backbones. Our experiments reveal that while powerful deep models offer reasonable performances on puzzles in a supervised setting, they are not better than random accuracy when analyzed for generalization – filling this gap may demand new multimodal learning approaches. 