The high computational costs of video super-resolution (VSR) models hinder their deployment on resource-limited devices, e.g., smartphones and drones. Existing VSR mod-els contain considerable redundant filters, which drag down the inference efficiency. To prune these unimportant fil-ters, we develop a structured pruning scheme called Struc-tured Sparsity Learning (SSL) according to the properties of VSR. In SSL, we design pruning schemes for several key components in VSR models, including residual blocks, re-current networks, and upsampling networks. Specifically, we develop a Residual Sparsity Connection (RSC) scheme for residual blocks of recurrent networks to liberate prun-ing restrictions and preserve the restoration information.For upsampling networks, we design a pixel-shuffle prun-ing scheme to guarantee the accuracy of feature channel-space conversion.In addition, we observe that pruning error would be amplified as the hidden states propagate along with recurrent networks. To alleviate the issue, we design Temporal Finetuning (TF). Extensive experiments show that SSL can significantly outperform recent methods quantitatively and qualitatively. The code is available at https://github.com/Zj-BinXia/SSL. 