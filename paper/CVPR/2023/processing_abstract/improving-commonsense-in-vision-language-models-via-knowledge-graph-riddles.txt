This paper focuses on analyzing and improving the com-monsense ability of recent popular vision-language (VL) models. Despite the great success, we observe that existingVL-models still lack commonsense knowledge/reasoning ability (e.g., “Lemons are sour”), which is a vital com-ponent towards artificial general intelligence. Through our analysis, we find one important reason is that exist-ing large-scale VL datasets do not contain much common-sense knowledge, which motivates us to improve the com-monsense of VL-models from the data perspective. Rather than collecting a new VL training dataset, we propose a more scalable strategy, i.e., “Data Augmentation with kNowledge graph linearization for CommonsensE capabil-ity” (DANCE). It can be viewed as one type of data aug-mentation technique, which can inject commonsense knowl-edge into existing VL datasets on the fly during training.More specifically, we leverage the commonsense knowl-edge graph (e.g., ConceptNet) and create variants of text description in VL datasets via bidirectional sub-graph se-quentialization. For better commonsense evaluation, we further propose the first retrieval-based commonsense di-agnostic benchmark. By conducting extensive experiments on some representative VL-models, we demonstrate that our DANCE technique is able to significantly improve the commonsense ability while maintaining the performance on vanilla retrieval tasks. The code and data are available at https:// github.com/ pleaseconnectwifi/ DANCE. 