Training deep models for semantic scene completion (SSC) is challenging due to the sparse and incomplete in-put, a large quantity of objects of diverse scales as well as the inherent label noise for moving objects. To address the above-mentioned problems, we propose the following three solutions: 1) Redesigning the completion sub-network. We design a novel completion sub-network, which consists of several Multi-Path Blocks (MPBs) to aggregate multi-scale features and is free from the lossy downsampling opera-tions. 2) Distilling rich knowledge from the multi-frame model. We design a novel knowledge distillation objective, dubbed Dense-to-Sparse Knowledge Distillation (DSKD).It transfers the dense, relation-based semantic knowledge from the multi-frame teacher to the single-frame student, signiﬁcantly improving the representation learning of the single-frame model. 3) Completion label rectiﬁcation. We propose a simple yet effective label rectiﬁcation strategy, which uses off-the-shelf panoptic segmentation labels to re-move the traces of dynamic objects in completion labels, greatly improving the performance of deep models espe-cially for those moving objects. Extensive experiments are conducted in two public SSC benchmarks, i.e., Se-manticKITTI and SemanticPOSS. Our SCPNet ranks 1st onSemanticKITTI semantic scene completion challenge and surpasses the competitive S3CNet [3] by 7.2 mIoU. SCP-Net also outperforms previous completion algorithms on theSemanticPOSS dataset. Besides, our method also achieves competitive results on SemanticKITTI semantic segmenta-tion tasks, showing that knowledge learned in the scene completion is beneﬁcial to the segmentation task. 