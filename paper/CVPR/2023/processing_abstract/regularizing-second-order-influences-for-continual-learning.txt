Continual learning aims to learn on non-stationary data streams without catastrophically forgetting previous knowl-edge. Prevalent replay-based methods address this chal-lenge by rehearsing on a small buffer holding the seen data, for which a delicate sample selection strategy is required.However, existing selection schemes typically seek only to maximize the utility of the ongoing selection, overlooking the interference between successive rounds of selection.Motivated by this, we dissect the interaction of sequential selection steps within a framework built on influence func-tions. We manage to identify a new class of second-order influences that will gradually amplify incidental bias in the replay buffer and compromise the selection process. To reg-ularize the second-order effects, a novel selection objective is proposed, which also has clear connections to two widely adopted criteria. Furthermore, we present an efficient im-plementation for optimizing the proposed criterion. Exper-iments on multiple continual learning benchmarks demon-strate the advantage of our approach over state-of-the-art methods. Code is available at https://github.com/ feifeiobama/InfluenceCL. 