Discriminative representation is essential to keep a unique identiﬁer for each target in Multiple object tracking (MOT). Some recent MOT methods extract features of the bounding box region or the center point as identity embed-dings. However, when targets are occluded, these coarse-grained global representations become unreliable. To this end, we propose exploring diverse ﬁne-grained represen-tation, which describes appearance comprehensively from global and local perspectives. This ﬁne-grained represen-tation requires high feature resolution and precise semantic information. To effectively alleviate the semantic misalign-ment caused by indiscriminate contextual information ag-gregation, Flow Alignment FPN (FAFPN) is proposed for multi-scale feature alignment aggregation. It generates se-mantic ﬂow among feature maps from different resolutions to transform their pixel positions. Furthermore, we present a Multi-head Part Mask Generator (MPMG) to extract ﬁne-grained representation based on the aligned feature maps.Multiple parallel branches of MPMG allow it to focus on different parts of targets to generate local masks without label supervision. The diverse details in target masks fa-cilitate ﬁne-grained representation. Eventually, beneﬁting from a Shufﬂe-Group Sampling (SGS) training strategy with positive and negative samples balanced, we achieve state-of-the-art performance on MOT17 and MOT20 test sets.Even on DanceTrack, where the appearance of targets is ex-tremely similar, our method signiﬁcantly outperforms Byte-Track by 5.0% on HOTA and 5.6% on IDF1. Extensive ex-periments have proved that diverse ﬁne-grained representa-tion makes Re-ID great again in MOT. 