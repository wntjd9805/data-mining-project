We present HARP (HAnd Reconstruction and Personal-ization), a personalized hand avatar creation approach that takes a short monocular RGB video of a human hand as input and reconstructs a faithful hand avatar exhibiting a high-ﬁdelity appearance and geometry. In contrast to the major trend of neural implicit representations, HARP mod-els a hand with a mesh-based parametric hand model, a vertex displacement map, a normal map, and an albedo without any neural components. The explicit nature of our representation enables a truly scalable, robust, and efﬁcient approach to hand avatar creation as validated by our ex-periments. HARP is optimized via gradient descent from a short sequence captured by a hand-held mobile phone and can be directly used in AR/VR applications with real-time rendering capability. To enable this, we carefully de-sign and implement a shadow-aware differentiable render-ing scheme that is robust to high degree articulations and self-shadowing regularly present in hand motions, as well as challenging lighting conditions. It also generalizes to un-seen poses and novel viewpoints, producing photo-realistic renderings of hand animations. Furthermore, the learnedHARP representation can be used for improving 3D hand pose estimation quality in challenging viewpoints. The key advantages of HARP are validated by the in-depth analyses on appearance reconstruction, novel view and novel pose synthesis, and 3D hand pose reﬁnement. It is an AR/VR-ready personalized hand representation that shows superiorﬁdelity and scalability. 