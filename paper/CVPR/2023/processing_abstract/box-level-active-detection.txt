Active learning selects informative samples for annota-tion within budget, which has proven efficient recently on object detection. However, the widely used active detection benchmarks conduct image-level evaluation, which is un-realistic in human workload estimation and biased towards crowded images. Furthermore, existing methods still per-form image-level annotation, but equally scoring all targets within the same image incurs waste of budget and redun-dant labels. Having revealed above problems and limita-tions, we introduce a box-level active detection framework that controls a box-based budget per cycle, prioritizes infor-mative targets and avoids redundancy for fair comparison and efficient application.Under the proposed box-level setting, we devise a novel pipeline, namely Complementary Pseudo Active Strategy (ComPAS). It exploits both human annotations and the model intelligence in a complementary fashion: an efficient input-end committee queries labels for informative objects only; meantime well-learned targets are identified by the model and compensated with pseudo-labels. ComPAS con-sistently outperforms 10 competitors under 4 settings in a unified codebase. With supervision from labeled data only, it achieves 100% supervised performance of VOC0712 with merely 19% box annotations. On the COCO dataset, it yields up to 4.3% mAP improvement over the second-best method. ComPAS also supports training with the unlabeled pool, where it surpasses 90% COCO supervised perfor-mance with 85% label reduction. Our source code is pub-licly available at https://github.com/lyumengyao/blad. 