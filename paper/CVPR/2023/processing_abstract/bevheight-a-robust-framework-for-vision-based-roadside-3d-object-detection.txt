While most recent autonomous driving system focuses on developing perception methods on ego-vehicle sensors, people tend to overlook an alternative approach to lever-age intelligent roadside cameras to extend the perception ability beyond the visual range. We discover that the state-of-the-art vision-centric bird’s eye view detection methods have inferior performances on roadside cameras. This is because these methods mainly focus on recovering the depth regarding the camera center, where the depth difference be-*Work done during an internship at DAMO Academy, Alibaba Group.†Corresponding Author. tween the car and the ground quickly shrinks while the dis-tance increases.In this paper, we propose a simple yet effective approach, dubbed BEVHeight, to address this is-sue. In essence, instead of predicting the pixel-wise depth, we regress the height to the ground to achieve a distance-agnostic formulation to ease the optimization process of camera-only perception methods. On popular 3D detection benchmarks of roadside cameras, our method surpasses all previous vision-centric methods by a significant mar-gin. The code is available at https://github.com/ADLab-AutoDrive/BEVHeight.