Micro-expression recognition is one of the most chal-lenging topics in affective computing.It aims to recog-nize tiny facial movements difficult for humans to per-ceive in a brief period, i.e., 0.25 to 0.5 seconds. Re-cent advances in pre-training deep Bidirectional Trans-formers (BERT) have significantly improved self-supervised learning tasks in computer vision. However, the standardBERT in vision problems is designed to learn only from full images or videos, and the architecture cannot accu-rately detect details of facial micro-expressions. This pa-per presents Micron-BERT (µ-BERT), a novel approach to facial micro-expression recognition. The proposed method can automatically capture these movements in an unsu-pervised manner based on two key ideas. First, we em-ploy Diagonal Micro-Attention (DMA) to detect tiny dif-Second, we introduce a ferences between two frames. new Patch of Interest (PoI) module to localize and high-light micro-expression interest regions and simultaneously reduce noisy backgrounds and distractions. By incorpo-rating these components into an end-to-end deep network, the proposed µ-BERT significantly outperforms all previ-ous work in various micro-expression tasks. µ-BERT can be trained on a large-scale unlabeled dataset, i.e., up to 8 million images, and achieves high accuracy on new un-seen facial micro-expression datasets. Empirical experi-ments show µ-BERT consistently outperforms state-of-the-art performance on four micro-expression benchmarks, in-cluding SAMM, CASME II, SMIC, and CASME3, by sig-nificant margins. Code will be available at https:// github.com/uark-cviu/Micron-BERT 