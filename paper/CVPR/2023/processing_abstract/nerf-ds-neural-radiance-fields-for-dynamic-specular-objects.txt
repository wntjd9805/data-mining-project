Dynamic Neural Radiance Field (NeRF) is a powerful algorithm capable of rendering photo-realistic novel view images from a monocular RGB video of a dynamic scene.Although it warps moving points across frames from the observation spaces to a common canonical space for ren-dering, dynamic NeRF does not model the change of the reflected color during the warping. As a result, this ap-proach often fails drastically on challenging specular ob-jects in motion. We address this limitation by reformulat-ing the neural radiance field function to be conditioned on surface position and orientation in the observation space.This allows the specular surface at different poses to keep the different reflected colors when mapped to the common canonical space. Additionally, we add the mask of moving objects to guide the deformation field. As the specular sur-face changes color during motion, the mask mitigates the problem of failure to find temporal correspondences with only RGB supervision. We evaluate our model based on the novel view synthesis quality with a self-collected dataset of different moving specular objects in realistic environments.The experimental results demonstrate that our method sig-nificantly improves the reconstruction quality of moving specular objects from monocular RGB videos compared to the existing NeRF models. Our code and data are available at the project website 1. 