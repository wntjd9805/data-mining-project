Detecting mirrors from static images has received signif-icant research interest recently. However, detecting mirrors over dynamic scenes is still under-explored due to the lack of a high-quality dataset and an effective method for video mirror detection (VMD). To the best of our knowledge, this is the ﬁrst work to address the VMD problem from a deep-learning-based perspective. Our observation is that there are often correspondences between the contents inside (re-ﬂected) and outside (real) of a mirror, but such correspon-dences may not always appear in every frame, e.g., due to the change of camera pose. This inspires us to propose a video mirror detection method, named VMD-Net, that can tolerate spatially missing correspondences by considering the mirror correspondences at both the intra-frame level as well as inter-frame level via a dual correspondence mod-ule that looks over multiple frames spatially and tempo-rally for correlating correspondences. We further propose a ﬁrst large-scale dataset for VMD (named VMD-D), which contains 14,987 image frames from 269 videos with corre-sponding manually annotated masks. Experimental results show that the proposed method outperforms SOTA methods from relevant ﬁelds. To enable real-time VMD, our method efﬁciently utilizes the backbone features by removing the redundant multi-level module design and gets rid of post-processing of the output maps commonly used in existing methods, making it very efﬁcient and practical for real-time video-based applications. Code, dataset, and models are available at https:// jiaying.link/ cvpr2023-vmd/ 