The goal of this work is to understand the way actions are performed in videos. That is, given a video, we aim to predict an adverb indicating a modification applied to the action (e.g. cut “finely”). We cast this problem as a regres-sion task. We measure textual relationships between verbs and adverbs to generate a regression target representing the action change we aim to learn. We test our approach on a range of datasets and achieve state-of-the-art results on both adverb prediction and antonym classification. Fur-thermore, we outperform previous work when we lift two commonly assumed conditions: the availability of action la-bels during testing and the pairing of adverbs as antonyms.Existing datasets for adverb recognition are either noisy, which makes learning difficult, or contain actions whose ap-pearance is not influenced by adverbs, which makes evalu-ation less reliable. To address this, we collect a new high quality dataset: Adverbs in Recipes (AIR). We focus on in-structional recipes videos, curating a set of actions that exhibit meaningful visual changes when performed differ-ently. Videos in AIR are more tightly trimmed and were manually reviewed by multiple annotators to ensure high la-belling quality. Results show that models learn better fromAIR given its cleaner videos. At the same time, adverb pre-diction on AIR is challenging, demonstrating that there is considerable room for improvement. 