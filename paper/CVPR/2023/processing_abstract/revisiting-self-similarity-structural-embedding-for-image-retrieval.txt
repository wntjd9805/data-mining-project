Despite advances in global image representation, exist-ing image retrieval approaches rarely consider geometric structure during the global retrieval stage.In this work, we revisit the conventional self-similarity descriptor from a convolutional perspective, to encode both the visual and structural cues of the image to global image representation.Our proposed network, named Structural Embedding Net-work (SENet), captures the internal structure of the images and gradually compresses them into dense self-similarity descriptors while learning diverse structures from various images. These self-similarity descriptors and original im-age features are fused and then pooled into global embed-ding, so that global embedding can represent both geomet-ric and visual cues of the image. Along with this novel structural embedding, our proposed network sets new state-of-the-art performances on several image retrieval bench-marks, convincing its robustness to look-alike distractors.The code and models are available: https://github. com/sungonce/SENet. 