Model selection is essential for reducing the search cost of the best pre-trained model over a large-scale model zoo for a downstream task. After analyzing recent hand-designed model selection criteria with 400+ ImageNet pre-trained models and 40 downstream tasks, we ﬁnd that they can fail due to invalid assumptions and intrinsic limitations. The prior knowledge on model capacity and dataset also can not be easily integrated into the existing criteria. To address these issues, we propose to convert model selection as a recommendation problem and to learn from the past training history. Speciﬁcally, we characterize the meta information of datasets and models as features, and use their transfer learning performance as the guided score. With thousands of historical training jobs, a recommendation system can be learned to predict the model selection score given the features of the dataset and the model as input. Our approach enables integrating existing model selection scores as ad-ditional features and scales with more historical data. We evaluate the prediction accuracy with 22 pre-trained mod-els over 40 downstream tasks. With extensive evaluations, we show that the learned approach can outperform prior hand-designed model selection methods signiﬁcantly when relevant training history is available. 