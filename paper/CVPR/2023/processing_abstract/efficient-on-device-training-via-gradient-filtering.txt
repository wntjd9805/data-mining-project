Despite its importance for federated learning, continu-ous learning and many other applications, on-device train-ing remains an open problem for EdgeAI. The problem stems from the large number of operations (e.g., floating point multiplications and additions) and memory consump-tion required during training by the back-propagation al-gorithm. Consequently, in this paper, we propose a new gradient filtering approach which enables on-device CNN model training. More precisely, our approach creates a special structure with fewer unique elements in the gradi-ent map, thus significantly reducing the computational com-plexity and memory consumption of back propagation dur-ing training. Extensive experiments on image classification and semantic segmentation with multiple CNN models (e.g.,MobileNet, DeepLabV3, UPerNet) and devices (e.g., Rasp-berry Pi and Jetson Nano) demonstrate the effectiveness and wide applicability of our approach. For example, com-pared to SOTA, we achieve up to 19× speedup and 77.1% memory savings on ImageNet classification with only 0.1% accuracy loss. Finally, our method is easy to implement and deploy; over 20× speedup and 90% energy savings have been observed compared to highly optimized baselines inMKLDNN and CUDNN on NVIDIA Jetson Nano. Conse-quently, our approach opens up a new direction of research with a huge potential for on-device training.1 