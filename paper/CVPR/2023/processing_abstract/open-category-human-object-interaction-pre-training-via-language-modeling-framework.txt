Human-object interaction (HOI) has long been plagued by the conflict between limited supervised data and a vast number of possible interaction combinations in real life.Current methods trained from closed-set data predict HOIs as fixed-dimension logits, which restricts their scalability to open-set categories. To address this issue, we introduceOpenCat, a language modeling framework that reformu-lates HOI prediction as sequence generation. By convert-ing HOI triplets into a token sequence through a serial-ization scheme, our model is able to exploit the open-set vocabulary of the language modeling framework to pre-dict novel interaction classes with a high degree of free-dom. In addition, inspired by the great success of vision-language pre-training, we collect a large amount of weakly-supervised data related to HOI from image-caption pairs, and devise several auxiliary proxy tasks, including soft re-lational matching and human-object relation prediction, to pre-train our model. Extensive experiments show that ourOpenCat significantly boosts HOI performance, particu-larly on a broad range of rare and unseen categories. 