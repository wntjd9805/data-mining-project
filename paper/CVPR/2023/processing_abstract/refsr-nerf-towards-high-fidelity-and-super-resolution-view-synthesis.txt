We present Reference-guided Super-Resolution NeuralRadiance Field (RefSR-NeRF) that extends NeRF to super resolution and photorealistic novel view synthesis. DespiteNeRF’s extraordinary success in the neural rendering ﬁeld, it suffers from blur in high resolution rendering because its inherent multilayer perceptron struggles to learn high frequency details and incurs a computational explosion as resolution increases. Therefore, we propose RefSR-NeRF, an end-to-end framework that ﬁrst learns a low resolutionNeRF representation, and then reconstructs the high fre-quency details with the help of a high resolution reference image. We observe that simply introducing the pre-trained models from the literature tends to produce unsatisﬁed arti-facts due to the divergence in the degradation model. To this end, we design a novel lightweight RefSR model to learn the inverse degradation process from NeRF renderings to target HR ones. Extensive experiments on multiple bench-marks demonstrate that our method exhibits an impressive trade-off among rendering quality, speed, and memory us-age, outperforming or on par with NeRF and its variants while being 52× speedup with minor extra memory usage.Code will be available at: Mindspore and Pytorch 