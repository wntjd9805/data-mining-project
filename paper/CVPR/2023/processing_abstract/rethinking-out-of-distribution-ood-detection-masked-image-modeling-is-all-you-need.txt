The core of out-of-distribution (OOD) detection is to learn the in-distribution (ID) representation, which is dis-tinguishable from OOD samples. Previous work applied recognition-based methods to learn the ID features, which tend to learn shortcuts instead of comprehensive repre-sentations. In this work, we find surprisingly that simply using reconstruction-based methods could boost the per-formance of OOD detection significantly. We deeply ex-plore the main contributors of OOD detection and find that reconstruction-based pretext tasks have the potential to pro-vide a generally applicable and efficacious prior, which benefits the model in learning intrinsic data distributions of the ID dataset. Specifically, we take Masked Image Mod-eling as a pretext task for our OOD detection framework (MOOD). Without bells and whistles, MOOD outperforms previous SOTA of one-class OOD detection by 5.7%, multi-class OOD detection by 3.0%, and near-distribution OOD detection by 2.1%. It even defeats the 10-shot-per-class out-lier exposure OOD detection, although we do not include any OOD samples for our detection. Codes are available at https://github.com/lijingyao20010602/MOOD. 