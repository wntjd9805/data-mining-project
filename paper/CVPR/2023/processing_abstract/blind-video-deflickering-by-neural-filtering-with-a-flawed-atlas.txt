https://chenyanglei.github.io/deflicker.Many videos contain flickering artifacts; common causes of flicker include video processing algorithms, video gener-ation algorithms, and capturing videos under specific situ-ations. Prior work usually requires specific guidance such as the flickering frequency, manual annotations, or extraIn this work, we consistent videos to remove the flicker. propose a general flicker removal framework that only re-ceives a single flickering video as input without additional guidance. Since it is blind to a specific flickering type or guidance, we name this “blind deflickering.” The core of our approach is utilizing the neural atlas in cooperation with a neural filtering strategy. The neural atlas is a uni-fied representation for all frames in a video that provides temporal consistency guidance but is flawed in many cases.To this end, a neural network is trained to mimic a filter to learn the consistent features (e.g., color, brightness) and avoid introducing the artifacts in the atlas. To validate our method, we construct a dataset that contains diverse real-world flickering videos. Extensive experiments show that our method achieves satisfying deflickering performance and even outperforms baselines that use extra guidance on a public benchmark. The source code is publicly available at* Equal contribution.† Corresponding authors. 