Modern neural networks are over-parameterized and thus rely on strong regularization such as data augmenta-tion and weight decay to reduce overfitting and improve generalization. The dominant form of data augmentation applies invariant transforms, where the learning target of a sample is invariant to the transform applied to that sam-ple. We draw inspiration from human visual classifica-tion studies and propose generalizing augmentation with invariant transforms to soft augmentation where the learn-ing target softens non-linearly as a function of the de-gree of the transform applied to the sample: e.g., more ag-gressive image crop augmentations produce less confident learning targets. We demonstrate that soft targets allow for more aggressive data augmentation, offer more robust performance boosts, work with other augmentation poli-cies, and interestingly, produce better calibrated models (since they are trained to be less confident on aggressively cropped/occluded examples). Combined with existing ag-gressive augmentation strategies, soft targets 1) double the top-1 accuracy boost across Cifar-10, Cifar-100, ImageNet-1K, and ImageNet-V2, 2) improve model occlusion perfor-mance by up to 4Ã—, and 3) half the expected calibration error (ECE). Finally, we show that soft augmentation gen-eralizes to self-supervised classification tasks. Code avail-able at https://github.com/youngleox/soft_ augmentation 