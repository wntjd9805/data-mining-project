Current evaluations of Continual Learning (CL) meth-ods typically assume that there is no constraint on train-ing time and computation. This is an unrealistic assump-tion for any real-world setting, which motivates us to pro-pose: a practical real-time evaluation of continual learn-ing, in which the stream does not wait for the model to com-plete training before revealing the next data for predictions.To do this, we evaluate current CL methods with respect to their computational costs. We conduct extensive experi-ments on CLOC, a large-scale dataset containing 39 million time-stamped images with geolocation labels. We show that a simple baseline outperforms state-of-the-art CL methods under this evaluation, questioning the applicability of ex-isting methods in realistic settings. In addition, we explore various CL components commonly used in the literature, in-cluding memory sampling strategies and regularization ap-proaches. We find that all considered methods fail to be competitive against our simple baseline. This surprisingly suggests that the majority of existing CL literature is tai-lored to a specific class of streams that is not practical. We hope that the evaluation we provide will be the first step to-wards a paradigm shift to consider the computational cost in the development of online continual learning methods. 