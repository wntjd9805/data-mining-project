Whole-body mesh recovery aims to estimate the 3D hu-man body, face, and hands parameters from a single im-age.It is challenging to perform this task with a single network due to resolution issues, i.e., the face and hands are usually located in extremely small regions. Existing works usually detect hands and faces, enlarge their reso-lution to feed in a specific network to predict the parameter, and finally fuse the results. While this copy-paste pipeline can capture the fine-grained details of the face and hands, the connections between different parts cannot be easily re-covered in late fusion, leading to implausible 3D rotation and unnatural pose. In this work, we propose a one-stage pipeline for expressive whole-body mesh recovery, namedOSX, without separate networks for each part. Specifically, we design a Component Aware Transformer (CAT) com-posed of a global body encoder and a local face/hand de-coder. The encoder predicts the body parameters and pro-vides a high-quality feature map for the decoder, which per-forms a feature-level upsample-crop scheme to extract high-resolution part-specific features and adopt keypoint-guided deformable attention to estimate hand and face precisely.The whole pipeline is simple yet effective without any man-ual post-processing and naturally avoids implausible pre-diction. Comprehensive experiments demonstrate the effec-tiveness of OSX. Lastly, we build a large-scale Upper-Body dataset (UBody) with high-quality 2D and 3D whole-body annotations. It contains persons with partially visible bod-ies in diverse real-life scenarios to bridge the gap between the basic task and downstream applications. 