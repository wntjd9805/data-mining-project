Autonomous Driving Systems (ADS), vehicle self-control, localization, and map construction. 3D lane detection which plays a crucial role in vehicle routing, has recently been a rapidly developing topic in au-tonomous driving. Previous works struggle with practical-ity due to their complicated spatial transformations and in-ﬂexible representations of 3D lanes. Faced with the issues, our work proposes an efﬁcient and robust monocular 3D lane detection called BEV-LaneDet with three main contri-butions. First, we introduce the Virtual Camera that uniﬁes the in/extrinsic parameters of cameras mounted on differ-ent vehicles to guarantee the consistency of the spatial re-lationship among cameras. It can effectively promote the learning procedure due to the uniﬁed visual space. We sec-ondly propose a simple but efﬁcient 3D lane representation called Key-Points Representation. This module is more suit-able to represent the complicated and diverse 3D lane struc-tures. At last, we present a light-weight and chip-friendly spatial transformation module named Spatial Transforma-tion Pyramid to transform multiscale front-view features into BEV features. Experimental results demonstrate that our work outperforms the state-of-the-art approaches in terms of F-Score, being 10.6% higher on the OpenLane dataset and 4.0% higher on the Apollo 3D synthetic dataset, with a speed of 185 FPS. Code is released at https://github.com/gigo-team/bev_lane_det. 