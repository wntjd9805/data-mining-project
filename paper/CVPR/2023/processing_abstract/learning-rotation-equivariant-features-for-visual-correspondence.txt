Extracting discriminative local features that are invari-ant to imaging variations is an integral part of establish-ing correspondences between images.In this work, we introduce a self-supervised learning framework to extract discriminative rotation-invariant descriptors using group-equivariant CNNs. Thanks to employing group-equivariantCNNs, our method effectively learns to obtain rotation-equivariant features and their orientations explicitly, with-out having to perform sophisticated data augmentations.The resultant features and their orientations are further pro-cessed by group aligning, a novel invariant mapping tech-nique that shifts the group-equivariant features by their ori-entations along the group dimension. Our group align-ing technique achieves rotation-invariance without any col-lapse of the group dimension and thus eschews loss of dis-criminability. The proposed method is trained end-to-end in a self-supervised manner, where we use an orientation alignment loss for the orientation estimation and a con-trastive descriptor loss for robust local descriptors to ge-ometric/photometric variations. Our method demonstrates state-of-the-art matching accuracy among existing rotation-invariant descriptors under varying rotation and also shows competitive results when transferred to the task of keypoint matching and camera pose estimation. 