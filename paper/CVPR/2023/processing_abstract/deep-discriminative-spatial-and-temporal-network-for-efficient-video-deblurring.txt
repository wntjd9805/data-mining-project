How to effectively explore spatial and temporal informa-tion is important for video deblurring. In contrast to exist-ing methods that directly align adjacent frames without dis-crimination, we develop a deep discriminative spatial and temporal network to facilitate the spatial and temporal fea-ture exploration for better video deblurring. We Ô¨Årst de-velop a channel-wise gated dynamic network to adaptively explore the spatial information. As adjacent frames usually contain different contents, directly stacking features of ad-jacent frames without discrimination may affect the laten-t clear frame restoration. Therefore, we develop a simple yet effective discriminative temporal feature fusion module to obtain useful temporal features for latent frame restora-tion. Moreover, to utilize the information from long-range frames, we develop a wavelet-based feature propagation method that takes the discriminative temporal feature fu-sion module as the basic unit to effectively propagate main structures from long-range frames for better video deblur-ring. We show that the proposed method does not require additional alignment methods and performs favorably a-gainst state-of-the-art ones on benchmark datasets in terms of accuracy and model complexity. 