reconstructThe popular VQ-VAE models images through learning a discrete codebook but suffer from a sig-nificant issue in the rapid quality degradation of image re-construction as the compression rate rises. One major rea-son is that a higher compression rate induces more loss of visual signals on the higher frequency spectrum which re-flect the details on pixel space. In this paper, a FrequencyComplement Module (FCM) architecture is proposed to capture the missing frequency information for enhancing reconstruction quality. The FCM can be easily incorpo-rated into the VQ-VAE structure, and we refer to the new model as Frequancy Augmented VAE (FA-VAE). In ad-dition, a Dynamic Spectrum Loss (DSL) is introduced to guide the FCMs to balance between various frequencies dynamically for optimal reconstruction. FA-VAE is further extended to the text-to-image synthesis task, and a Cross-attention Autoregressive Transformer (CAT) is proposed to obtain more precise semantic attributes in texts. Extensive reconstruction experiments with different compression rates are conducted on several benchmark datasets, and the re-sults demonstrate that the proposed FA-VAE is able to re-store more faithfully the details compared to SOTA meth-ods. CAT also shows improved generation quality with bet-ter image-text semantic alignment. 