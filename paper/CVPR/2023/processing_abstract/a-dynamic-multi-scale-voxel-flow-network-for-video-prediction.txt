The performance of video prediction has been greatly boosted by advanced deep neural networks. However, most of the current methods suffer from large model sizes and require extra inputs, e.g., semantic/depth maps, for promis-ing performance. For efficiency consideration, in this pa-per, we propose a Dynamic Multi-scale Voxel Flow Net-work (DMVFN) to achieve better video prediction perfor-mance at lower computational costs with only RGB images, than previous methods. The core of our DMVFN is a dif-ferentiable routing module that can effectively perceive the motion scales of video frames. Once trained, our DMVFN selects adaptive sub-networks for different inputs at the in-ference stage. Experiments on several benchmarks demon-strate that our DMVFN is an order of magnitude faster thanDeep Voxel Flow [35] and surpasses the state-of-the-art iterative-based OPT [63] on generated image quality. 