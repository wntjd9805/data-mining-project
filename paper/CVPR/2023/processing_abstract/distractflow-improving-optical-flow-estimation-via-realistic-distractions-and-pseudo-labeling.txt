We propose a novel data augmentation approach, Dis-tractFlow, for training optical flow estimation models by introducing realistic distractions to the input frames. Based on a mixing ratio, we combine one of the frames in the pair with a distractor image depicting a similar domain, which allows for inducing visual perturbations congruent with natural objects and scenes. We refer to such pairs as distracted pairs. Our intuition is that using semantically meaningful distractors enables the model to learn related variations and attain robustness against challenging devia-tions, compared to conventional augmentation schemes fo-cusing only on low-level aspects and modifications. More specifically, in addition to the supervised loss computed between the estimated flow for the original pair and its ground-truth flow, we include a second supervised loss de-fined between the distracted pair’s flow and the original pair’s ground-truth flow, weighted with the same mixing ra-tio. Furthermore, when unlabeled data is available, we ex-tend our augmentation approach to self-supervised settings through pseudo-labeling and cross-consistency regulariza-tion. Given an original pair and its distracted version, we enforce the estimated flow on the distracted pair to agree with the flow of the original pair. Our approach allows increasing the number of available training pairs signifi-cantly without requiring additional annotations. It is agnos-tic to the model architecture and can be applied to training any optical flow estimation models. Our extensive evalua-tions on multiple benchmarks, including Sintel, KITTI, andSlowFlow, show that DistractFlow improves existing mod-els consistently, outperforming the latest state of the art. 