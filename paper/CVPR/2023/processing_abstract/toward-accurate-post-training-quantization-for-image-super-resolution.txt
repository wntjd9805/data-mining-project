Model quantization is a crucial step for deploying super resolution (SR) networks on mobile devices. However, exist-ing works focus on quantization-aware training, which re-quires complete dataset and expensive computational over-head.In this paper, we study post-training quantization (PTQ) for image super resolution using only a few unla-beled calibration images. As the SR model aims to maintain the texture and color information of input images, the distri-bution of activations are long-tailed, asymmetric and highly dynamic compared with classiﬁcation models. To this end, we introduce the density-based dual clipping to cut off the outliers based on analyzing the asymmetric bounds of acti-vations. Moreover, we present a novel pixel aware calibra-tion method with the supervision of the full-precision model to accommodate the highly dynamic range of different sam-ples. Extensive experiments demonstrate that the proposed method signiﬁcantly outperforms existing PTQ algorithms on various models and datasets. For instance, we get a 2.091 dB increase on Urban100 benchmark when quantiz-ing EDSR×4 to 4-bit with 100 unlabeled images. Our code is available at both PyTorch and MindSpore. 