Human body trajectories are a salient cue to identify actions in the video. Such body trajectories are mainly conveyed by hands and face across consecutive frames in sign language. However, current methods in continuous sign language recognition (CSLR) usually process frames independently, thus failing to capture cross-frame trajec-tories to effectively identify a sign. To handle this limita-tion, we propose correlation network (CorrNet) to explic-itly capture and leverage body trajectories across frames to identify signs. In specific, a correlation module is first pro-posed to dynamically compute correlation maps between the current frame and adjacent frames to identify trajec-tories of all spatial patches. An identification module is then presented to dynamically emphasize the body trajec-tories within these correlation maps. As a result, the gen-erated features are able to gain an overview of local tem-poral movements to identify a sign. Thanks to its spe-cial attention on body trajectories, CorrNet achieves new state-of-the-art accuracy on four large-scale datasets, i.e.,PHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. A com-prehensive comparison with previous spatial-temporal rea-soning methods verifies the effectiveness of CorrNet. Visu-alizations demonstrate the effects of CorrNet on emphasiz-ing human body trajectories across adjacent frames. 