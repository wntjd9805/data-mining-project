Endeavors have been recently made to leverage the vi-sion transformer (ViT) for the challenging unsupervised domain adaptation (UDA) task. They typically adopt the cross-attention in ViT for direct domain alignment. However, as the performance of cross-attention highly relies on the quality of pseudo labels for targeted samples, it becomes less effective when the domain gap becomes large. We solve this problem from a game theory’s perspective with the pro-posed model dubbed as PMTrans, which bridges source and target domains with an intermediate domain. Speciﬁcally, we propose a novel ViT-based module called PatchMix that effectively builds up the intermediate domain, i.e., proba-bility distribution, by learning to sample patches from both domains based on the game-theoretical models. This way, it learns to mix the patches from the source and target do-mains to maximize the cross entropy (CE), while exploiting two semi-supervised mixup losses in the feature and label spaces to minimize it. As such, we interpret the process ofUDA as a min-max CE game with three players, including the feature extractor, classiﬁer, and PatchMix, to ﬁnd theNash Equilibria. Moreover, we leverage attention maps fromViT to re-weight the label of each patch by its importance, making it possible to obtain more domain-discriminative feature representations. We conduct extensive experiments on four benchmark datasets, and the results show thatPMTrans signiﬁcantly surpasses the ViT-based and CNN-based SoTA methods by +3.6% on Ofﬁce-Home, +1.4% onOfﬁce-31, and +17.7% on DomainNet, respectively. https://vlis2022.github.io/cvpr23/PMTrans 