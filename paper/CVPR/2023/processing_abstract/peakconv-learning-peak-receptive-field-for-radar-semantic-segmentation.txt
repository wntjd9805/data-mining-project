The modern machine learning-based technologies have shown considerable potential in automatic radar scene un-derstanding. Among these efforts, radar semantic segmen-tation (RSS) can provide more refined and detailed infor-mation including the moving objects and background clut-ters within the effective receptive field of the radar. Moti-vated by the success of convolutional networks in various visual computing tasks, these networks have also been in-troduced to solve RSS task. However, neither the regular convolution operation nor the modified ones are specific to interpret radar signals. The receptive fields of existing convolutions are defined by the object presentation in opti-cal signals, but these two signals have different perception mechanisms. In classic radar signal processing, the object signature is detected according to a local peak response, i.e., CFAR detection. Inspired by this idea, we redefine the receptive field of the convolution operation as the peak re-ceptive field (PRF) and propose the peak convolution oper-ation (PeakConv) to learn the object signatures in an end-to-end network. By incorporating the proposed PeakConv layers into the encoders, our RSS network can achieve bet-ter segmentation results compared with other SoTA meth-ods on a multi-view real-measured dataset collected from an FMCW radar. Our code for PeakConv is available at https://github.com/zlw9161/PKC. 