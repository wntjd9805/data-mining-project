The goal of few-shot learning is to learn the general-ization from seen to unseen data with only a few samples.Most previous few-shot learning methods focus on learn-ing the generalization within particular domains. However, the more practical scenarios may also require the gener-In this paper, we study alization ability across domains. the problem of few-shot domain generalization (FSDG), which is a more challenging variant of few-shot classi-fication. FSDG requires additional generalization with larger gap from seen domains to unseen domains. We address FSDG problem by meta-learning two levels of meta-knowledge, where the lower-level meta-knowledge is domain-specific embedding spaces as subspaces of a base space for intra-domain generalization, and the upper-level meta-knowledge is the base space and a prior subspace over domain-specific spaces for inter-domain generaliza-tion. We formulate the two levels of meta-knowledge learn-ing problem with bi-level optimization, and further develop an optimization algorithm without higher-order derivative information to solve it. We demonstrate our method is sig-nificantly superior to the previous works by evaluating it on the widely used benchmark Meta-Dataset. 