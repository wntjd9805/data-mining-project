This paper studies how to keep a vision backbone ef-fective while removing token mixers in its basic building blocks. Token mixers, as self-attention for vision transform-ers (ViTs), are intended to perform information communica-tion between different spatial tokens but suffer from consid-erable computational cost and latency. However, directly removing them will lead to an incomplete model structure prior, and thus brings a significant accuracy drop. To this end, we first develop an RepIdentityFormer base on the re-parameterizing idea, to study the token mixer free model architecture. And we then explore the improved learn-ing paradigm to break the limitation of simple token mixer free backbone, and summarize the empirical practice into 5 guidelines. Equipped with the proposed optimization strat-egy, we are able to build an extremely simple vision back-bone with encouraging performance, while enjoying the high efficiency during inference. Extensive experiments and ablative analysis also demonstrate that the inductive bias of network architecture, can be incorporated into simple net-work structure with appropriate optimization strategy. We hope this work can serve as a starting point for the explo-ration of optimization-driven efficient network design. 