Neural radiance fields (NeRF) have demonstrated the potential of coordinate-based neural representation (neural fields or implicit neural representation) in neural rendering.However, using a multi-layer perceptron (MLP) to represent a 3D scene or object requires enormous computational re-sources and time. There have been recent studies on how to reduce these computational inefficiencies by using addi-tional data structures, such as grids or trees. Despite the promising performance, the explicit data structure neces-sitates a substantial amount of memory. In this work, we present a method to reduce the size without compromising the advantages of having additional data structures. In de-tail, we propose using the wavelet transform on grid-based neural fields. Grid-based neural fields are for fast con-vergence, and the wavelet transform, whose efficiency has been demonstrated in high-performance standard codecs, is to improve the parameter efficiency of grids. Further-more, in order to achieve a higher sparsity of grid coeffi-cients while maintaining reconstruction quality, we present a novel trainable masking approach. Experimental re-sults demonstrate that non-spatial grid coefficients, such as wavelet coefficients, are capable of attaining a higher level of sparsity than spatial grid coefficients, resulting in a more compact representation. With our proposed mask and com-pression pipeline, we achieved state-of-the-art performance within a memory budget of 2 MB. Our code is available at https://github.com/daniel03c1/masked wavelet nerf. 