In this paper, we define a new problem of recovering the 3D geometry of an object confined in a transparent en-closure. We also propose a novel method for solving this challenging problem. Transparent enclosures pose chal-lenges of multiple light reflections and refractions at the interface between different propagation media e.g. air or glass. These multiple reflections and refractions cause seri-ous image distortions which invalidate the single viewpoint assumption. Hence the 3D geometry of such objects can-not be reliably reconstructed using existing methods, such as traditional structure from motion or modern neural re-construction methods. We solve this problem by explicitly modeling the scene as two distinct sub-spaces, inside and outside the transparent enclosure. We use an existing neu-ral reconstruction method (NeuS) that implicitly represents the geometry and appearance of the inner subspace. In or-der to account for complex light interactions, we develop a hybrid rendering strategy that combines volume rendering with ray tracing. We then recover the underlying geome-try and appearance of the model by minimizing the differ-ence between the real and rendered images. We evaluate our method on both synthetic and real data. Experiment results show that our method outperforms the state-of-the-art (SOTA) methods. Codes and data will be available at https://github.com/hirotong/ReNeuS 