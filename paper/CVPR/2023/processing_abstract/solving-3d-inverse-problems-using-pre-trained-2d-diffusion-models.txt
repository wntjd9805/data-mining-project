Diffusion models have emerged as the new state-of-the-art generative model with high quality samples, with intriguing properties such as mode coverage and high flexibility.They have also been shown to be effective inverse problem solvers, acting as the prior of the distribution, while the information of the forward model can be granted at theThis work was supported by the Korea Medical Device Develop-ment Fund grant funded by the Korea government (the Ministry of Sci-ence and ICT, the Ministry of Trade, Industry and Energy, the Ministry of Health & Welfare, the Ministry of Food and Drug Safety) (ProjectNumber: 1711137899, KMDF PR 20200901 0015), by the National Re-search Foundation of Korea under Grant NRF-2020R1A2B5B03001980, by the KAIST Key Research Institute (Interdisciplinary Research Group)Project, and by the MSIT (Ministry of Science and ICT), Korea, under theITRC(Information Technology Research Center) support program(IITP-2022-2020-0-01461) supervised by the IITP(Institute for Information & communications Technology Planning & Evaluation). sampling stage. Nonetheless, as the generative process remains in the same high dimensional (i.e. identical to data dimension) space, the models have not been extended to 3D inverse problems due to the extremely high memory and computational cost.In this paper, we combine the ideas from the conventional model-based iterative recon-struction with the modern diffusion models, which leads to a highly effective method for solving 3D medical image reconstruction tasks such as sparse-view tomography, limited angle tomography, compressed sensing MRI fromIn essence, we propose pre-trained 2D diffusion models. to augment the 2D diffusion prior with a model-based prior in the remaining direction at test time, such that one can achieve coherent reconstructions across all di-mensions. Our method can be run in a single commodityGPU, and establishes the new state-of-the-art, showing the proposed method can perform reconstructions thatof high fidelity and accuracy even in the most extreme cases (e.g. 2-view 3D tomography). We further reveal that the generalization capacity of the proposed method is surprisingly high, and can be used to reconstruct volumes that are entirely different from the training dataset. Code available: https://github.com/HJ-harry/DiffusionMBIR 