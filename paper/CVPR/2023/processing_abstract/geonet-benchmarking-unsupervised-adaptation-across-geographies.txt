In recent years, several efforts have been aimed at im-proving the robustness of vision models to domains and environments unseen during training. An important practi-cal problem pertains to models deployed in a new geography that is under-represented in the training dataset, posing a direct challenge to fair and inclusive computer vision.In this paper, we study the problem of geographic robust-ness and make three main contributions. First, we intro-duce a large-scale dataset GeoNet for geographic adapta-tion containing benchmarks across diverse tasks like scene recognition (GeoPlaces), image classification (GeoImNet) and universal adaptation (GeoUniDA). Second, we inves-tigate the nature of distribution shifts typical to the prob-lem of geographic adaptation and hypothesize that the ma-jor source of domain shifts arise from significant varia-tions in scene context (context shift), object design (de-sign shift) and label distribution (prior shift) across ge-ographies. Third, we conduct an extensive evaluation of several state-of-the-art unsupervised domain adaptation al-gorithms and architectures on GeoNet, showing that they do not suffice for geographical adaptation, and that large-scale pre-training using large vision models also does not lead to geographic robustness. Our dataset is publicly available at https://tarun005.github.io/GeoNet. 