We propose Mask Auto-Labeler (MAL), a high-qualityTransformer-based mask auto-labeling framework for in-stance segmentation using only box annotations. MAL takes box-cropped images as inputs and conditionally generates their mask pseudo-labels. We show that Vision Transform-ers are good mask auto-labelers. Our method significantly reduces the gap between auto-labeling and human annota-tion regarding mask quality. Instance segmentation models trained using the MAL-generated masks can nearly match the performance of their fully-supervised counterparts, re-taining up to 97.4% performance of fully supervised mod-els. The best model achieves 44.1% mAP on COCO in-stance segmentation (test-dev 2017), outperforming state-of-the-art box-supervised methods by significant margins.Qualitative results indicate that masks produced by MAL are, in some cases, even better than human annotations. 