All instance perception tasks aim at finding certain ob-jects specified by some queries such as category names, lan-guage expressions, and target annotations, but this com-plete field has been split into multiple independent sub-tasks. In this work, we present a universal instance per-ception model of the next generation, termed UNINEXT.UNINEXT reformulates diverse instance perception tasks into a unified object discovery and retrieval paradigm and can flexibly perceive different types of objects by simply changing the input prompts. This unified formulation brings (1) enormous data from different the following benefits: tasks and label vocabularies can be exploited for jointly training general instance-level representations, which is es-pecially beneficial for tasks lacking in training data. (2) the unified model is parameter-efficient and can save re-dundant computation when handling multiple tasks simul-taneously. UNINEXT shows superior performance on 20 challenging benchmarks from 10 instance-level tasks in-cluding classical image-level tasks (object detection and instance segmentation), vision-and-language tasks (refer-ring expression comprehension and segmentation), and six video-level object tracking tasks. Code is available at https://github.com/MasterBin-IIAU/UNINEXT. 