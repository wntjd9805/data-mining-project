Virtually every object in the modern world was created, modified, analyzed and optimized using computer aided de-sign (CAD) tools. An active CAD research area is the use of data-driven machine learning methods to learn from the massive repositories of geometric and program represen-tations. However, the lack of labeled data in CADâ€™s na-tive format, i.e., the parametric boundary representation (B-Rep), poses an obstacle at present difficult to overcome.Several datasets of mechanical parts in B-Rep format have recently been released for machine learning research. How-ever, large-scale databases are mostly unlabeled, and la-beled datasets are small. Additionally, task-specific label sets are rare and costly to annotate. This work proposes to leverage unlabeled CAD geometry on supervised learn-ing tasks. We learn a novel, hybrid implicit/explicit surface representation for B-Rep geometry. Further, we show that this pre-training both significantly improves few-shot learn-ing performance and achieves state-of-the-art performance on several current B-Rep benchmarks. 