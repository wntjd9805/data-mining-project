Weakly-supervised temporal action localization (WTAL) learns to detect and classify action instances with only cat-egory labels. Most methods widely adopt the off-the-shelfClassification-Based Pre-training (CBP) to generate video features for action localization. However, the different opti-mization objectives between classification and localization, make temporally localized results suffer from the serious in-complete issue. To tackle this issue without additional anno-tations, this paper considers to distill free action knowledge from Vision-Language Pre-training (VLP), as we surpris-ingly observe that the localization results of vanilla VLP have an over-complete issue, which is just complementary to the CBP results. To fuse such complementarity, we pro-pose a novel distillation-collaboration framework with two branches acting as CBP and VLP respectively. The frame-work is optimized through a dual-branch alternate training strategy. Specifically, during the B step, we distill the confi-dent background pseudo-labels from the CBP branch; while during the F step, the confident foreground pseudo-labels are distilled from the VLP branch. As a result, the dual-branch complementarity is effectively fused to promote one strong alliance. Extensive experiments and ablation studies on THUMOS14 and ActivityNet1.2 reveal that our method significantly outperforms state-of-the-art methods. 