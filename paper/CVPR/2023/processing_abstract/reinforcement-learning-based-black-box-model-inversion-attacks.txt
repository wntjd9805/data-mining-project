Model inversion attacks are a type of privacy attack that reconstructs private data used to train a machine learning model, solely by accessing the model. Recently, white-box model inversion attacks leveraging Generative AdversarialNetworks (GANs) to distill knowledge from public datasets have been receiving great attention because of their excel-lent attack performance. On the other hand, current black-box model inversion attacks that utilize GANs suffer from issues such as being unable to guarantee the completion of the attack process within a predetermined number of query accesses or achieve the same level of performance as white-box attacks. To overcome these limitations, we propose a reinforcement learning-based black-box model inversion at-tack. We formulate the latent space search as a Markov De-cision Process (MDP) problem and solve it with reinforce-ment learning. Our method utilizes the confidence scores of the generated images to provide rewards to an agent. Fi-nally, the private data can be reconstructed using the latent vectors found by the agent trained in the MDP. The exper-iment results on various datasets and models demonstrate that our attack successfully recovers the private informa-tion of the target model by achieving state-of-the-art attack performance. We emphasize the importance of studies on privacy-preserving machine learning by proposing a more advanced black-box model inversion attack. 