We present Region-aware Open-vocabulary VisionTransformers (RO-ViT) – a contrastive image-text pretrain-ing recipe to bridge the gap between image-level pretrain-ing and open-vocabulary object detection. At the pretrain-ing phase, we propose to randomly crop and resize regions of positional embeddings instead of using the whole image positional embeddings. This better matches the use of posi-tional embeddings at region-level in the detection ﬁnetuning phase. In addition, we replace the common softmax cross entropy loss in contrastive learning with focal loss to bet-ter learn the informative yet difﬁcult examples. Finally, we leverage recent advances in novel object proposals to im-prove open-vocabulary detection ﬁnetuning. We evaluate our full model on the LVIS and COCO open-vocabulary de-tection benchmarks and zero-shot transfer. RO-ViT achieves a state-of-the-art 32.1 APr on LVIS, surpassing the best ex-isting approach by +5.8 points in addition to competitive zero-shot transfer detection. Surprisingly, RO-ViT improves the image-level representation as well and achieves the state of the art on 9 out of 12 metrics on COCO and Flickr image-text retrieval benchmarks, outperforming competitive ap-proaches with larger models. 