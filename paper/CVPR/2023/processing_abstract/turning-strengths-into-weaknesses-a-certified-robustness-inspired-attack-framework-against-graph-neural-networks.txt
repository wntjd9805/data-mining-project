Graph neural networks (GNNs) have achieved state-of-the-art performance in many graph learning tasks. How-ever, recent studies show that GNNs are vulnerable to both test-time evasion and training-time poisoning attacks that perturb the graph structure. While existing attack methods have shown promising attack performance, we would like to design an attack framework to further enhance the perfor-mance. In particular, our attack framework is inspired by certiﬁed robustness, which was originally used by defend-ers to defend against adversarial attacks. We are the ﬁrst, from the attacker perspective, to leverage its properties to better attack GNNs. Speciﬁcally, we ﬁrst derive nodes’ cer-tiﬁed perturbation sizes against graph evasion and poison-ing attacks based on randomized smoothing, respectively.A larger certiﬁed perturbation size of a node indicates this node is theoretically more robust to graph perturbations.Such a property motivates us to focus more on nodes with smaller certiﬁed perturbation sizes, as they are easier to be attacked after graph perturbations. Accordingly, we design a certiﬁed robustness inspired attack loss, when incorpo-rated into (any) existing attacks, produces our certiﬁed ro-bustness inspired attack counterpart. We apply our frame-work to the existing attacks and results show it can signiﬁ-cantly enhance the existing base attacks’ performance. 