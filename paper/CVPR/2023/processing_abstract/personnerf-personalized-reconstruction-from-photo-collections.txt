We present PersonNeRF, a method that takes a collec-tion of photos of a subject (e.g. Roger Federer) captured across multiple years with arbitrary body poses and ap-pearances, and enables rendering the subject with arbitrary novel combinations of viewpoint, body pose, and appear-ance. PersonNeRF builds a customized neural volumetric 3D model of the subject that is able to render an entire space spanned by camera viewpoint, body pose, and appearance.A central challenge in this task is dealing with sparse ob-servations; a given body pose is likely only observed by a single viewpoint with a single appearance, and a given appearance is only observed under a handful of different body poses. We address this issue by recovering a canon-ical T-pose neural volumetric representation of the subject that allows for changing appearance across different ob-servations, but uses a shared pose-dependent motion field across all observations. We demonstrate that this approach, along with regularization of the recovered volumetric ge-ometry to encourage smoothness, is able to recover a model that renders compelling images from novel combinations of viewpoint, pose, and appearance from these challenging un-structured photo collections, outperforming prior work for free-viewpoint human rendering.