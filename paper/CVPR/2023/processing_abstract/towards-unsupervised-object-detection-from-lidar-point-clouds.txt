In this paper, we study the problem of unsupervised ob-ject detection from 3D point clouds in self-driving scenes.We present a simple yet effective method that exploits (i) point clustering in near-range areas where the point clouds are dense, (ii) temporal consistency to ﬁlter out noisy unsu-pervised detections, (iii) translation equivariance of CNNs to extend the auto-labels to long range, and (iv) self-supervision for improving on its own. Our approach, OYS-TER (Object Discovery via Spatio-Temporal Reﬁnement), does not impose constraints on data collection (such as repeated traversals of the same location), is able to de-tect objects in a zero-shot manner without supervised ﬁne-tuning (even in sparse, distant regions), and continues to self-improve given more rounds of iterative self-training. To better measure model performance in self-driving scenar-ios, we propose a new planning-centric perception metric based on distance-to-collision. We demonstrate that our unsupervised object detector signiﬁcantly outperforms un-supervised baselines on PandaSet and Argoverse 2 Sen-sor dataset, showing promise that self-supervision com-bined with object priors can enable object discovery in the wild. For more information, visit the project website: https://waabi.ai/research/oyster. 