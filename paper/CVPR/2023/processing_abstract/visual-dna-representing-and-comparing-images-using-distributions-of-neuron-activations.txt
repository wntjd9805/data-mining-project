Selecting appropriate datasets is critical in modern com-puter vision. However, no general-purpose tools exist to evaluate the extent to which two datasets differ. For this, we propose representing images – and by extension datasets – using Distributions of Neuron Activations (DNAs). DNAs ﬁt distributions, such as histograms or Gaussians, to activa-tions of neurons in a pre-trained feature extractor through which we pass the image(s) to represent. This extractor is frozen for all datasets, and we rely on its generally expres-sive power in feature space. By comparing two DNAs, we can evaluate the extent to which two datasets differ with granular control over the comparison attributes of inter-est, providing the ability to customise the way distances are measured to suit the requirements of the task at hand.Furthermore, DNAs are compact, representing datasets of any size with less than 15 megabytes. We demonstrate the value of DNAs by evaluating their applicability on several tasks, including conditional dataset comparison, synthetic image evaluation, and transfer learning, and across diverse datasets, ranging from synthetic cat images to celebrity faces and urban driving scenes. 