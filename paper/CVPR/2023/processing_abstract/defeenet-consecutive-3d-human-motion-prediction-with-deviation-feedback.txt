Let us rethink the real-world scenarios that require hu-man motion prediction techniques, such as human-robot collaboration. Current works simplify the task of predicting human motions into a one-off process of forecasting a short future sequence (usually no longer than 1 second) based on a historical observed one. However, such simpliﬁcation may fail to meet practical needs due to the neglect of the fact that motion prediction in real applications is not an isolated“observe then predict” unit, but a consecutive process com-posed of many rounds of such unit, semi-overlapped along the entire sequence. As time goes on, the predicted part of previous round has its corresponding ground truth ob-servable in the new round, but their deviation in-between is neither exploited nor able to be captured by existing iso-lated learning fashion. In this paper, we propose DeFeeNet, a simple yet effective network that can be added on exist-ing one-off prediction models to realize deviation percep-tion and feedback when applied to consecutive motion pre-diction task. At each prediction round, the deviation gen-erated by previous unit is ﬁrst encoded by our DeFeeNet, and then incorporated into the existing predictor to enable a deviation-aware prediction manner, which, for the ﬁrst time, allows for information transmit across adjacent prediction units. We design two versions of DeFeeNet as MLP-based and GRU-based, respectively. On Human3.6M and more complicated BABEL, experimental results indicate that our proposed network improves consecutive human motion pre-diction performance regardless of the basic model. 