This paper, for the very first time, introduces human sketches to the landscape of XAI (Explainable Artificial In-telligence). We argue that sketch as a “human-centred” data form, represents a natural interface to study explainability.We focus on cultivating sketch-specific explainability designs.This starts by identifying strokes as a unique building block that offers a degree of flexibility in object construction and manipulation impossible in photos. Following this, we de-sign a simple explainability-friendly sketch encoder that accommodates the intrinsic properties of strokes: shape, lo-cation, and order. We then move on to define the first everXAI task for sketch, that of stroke location inversion (SLI).Just as we have heat maps for photos, and correlation ma-trices for text, SLI offers an explainability angle to sketch in terms of asking a network how well it can recover stroke locations of an unseen sketch. We offer qualitative results for readers to interpret as snapshots of the SLI process in the pa-per, and as GIFs on the project page. A minor but interesting note is that thanks to its sketch-specific design, our sketch en-coder also yields the best sketch recognition accuracy to date while having the smallest number of parameters. The code is available at https://sketchxai.github.io. 