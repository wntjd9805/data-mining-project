This paper introduces the Masked Voxel Jigsaw andReconstruction (MV-JAR) method for LiDAR-based self-supervised pre-training and a carefully designed data-efﬁcient 3D object detection benchmark on the Waymo dataset.Inspired by the scene-voxel-point hierarchy in downstream 3D object detectors, we design masking and re-construction strategies accounting for voxel distributions in the scene and local point distributions within the voxel. We employ a Reversed-Furthest-Voxel-Sampling strategy to ad-dress the uneven distribution of LiDAR points and proposeMV-JAR, which combines two techniques for modeling the aforementioned distributions, resulting in superior perfor-mance. Our experiments reveal limitations in previous data-efﬁcient experiments, which uniformly sample ﬁne-tuning splits with varying data proportions from each LiDAR se-quence, leading to similar data diversity across splits. To address this, we propose a new benchmark that samples scene sequences for diverse ﬁne-tuning splits, ensuring ad-equate model convergence and providing a more accu-rate evaluation of pre-training methods. Experiments on our Waymo benchmark and the KITTI dataset demonstrate that MV-JAR consistently and signiﬁcantly improves 3D detection performance across various data scales, achiev-ing up to a 6.3% increase in mAPH compared to training from scratch. Codes and the benchmark are available at https://github.com/SmartBot-PJLab/MV-JAR. 