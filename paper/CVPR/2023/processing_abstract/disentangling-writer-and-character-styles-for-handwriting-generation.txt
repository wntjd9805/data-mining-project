Training machines to synthesize diverse handwritings is an intriguing task. Recently, RNN-based methods have been proposed to generate stylized online Chinese charac-ters. However, these methods mainly focus on capturing a person’s overall writing style, neglecting subtle style in-consistencies between characters written by the same per-son. For example, while a person’s handwriting typically exhibits general uniformity (e.g., glyph slant and aspect ratios), there are still small style variations in finer de-In tails (e.g., stroke length and curvature) of characters. light of this, we propose to disentangle the style repre-sentations at both writer and character levels from indi-vidual handwritings to synthesize realistic stylized online handwritten characters. Specifically, we present the style-disentangled Transformer (SDT), which employs two com-plementary contrastive objectives to extract the style com-monalities of reference samples and capture the detailed style patterns of each sample, respectively. Extensive exper-iments on various language scripts demonstrate the effec-tiveness of SDT. Notably, our empirical findings reveal that the two learned style representations provide information at different frequency magnitudes, underscoring the impor-tance of separate style extraction. Our source code is public at: https://github.com/dailenson/SDT. 