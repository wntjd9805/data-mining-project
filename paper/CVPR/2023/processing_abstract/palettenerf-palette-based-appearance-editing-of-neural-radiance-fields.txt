Recent advances in neural radiance fields have enabled the high-fidelity 3D reconstruction of complex scenes for novel view synthesis. However, it remains underexplored how the appearance of such representations can be effi-ciently edited while maintaining photorealism. In this work, we present PaletteNeRF, a novel method for photorealis-tic appearance editing of neural radiance fields (NeRF) based on 3D color decomposition. Our method decom-poses the appearance of each 3D point into a linear com-bination of palette-based bases (i.e., 3D segmentations de-fined by a group of NeRF-type functions) that are shared across the scene. While our palette-based bases are view-independent, we also predict a view-dependent function to capture the color residual (e.g., specular shading). Dur-ing training, we jointly optimize the basis functions and the color palettes, and we also introduce novel regulariz-ers to encourage the spatial coherence of the decomposi-*Parts of this work were done when Zhengfei Kuang was an intern atAdobe Research. tion. Our method allows users to efficiently edit the appear-ance of the 3D scene by modifying the color palettes. We also extend our framework with compressed semantic fea-tures for semantic-aware appearance editing. We demon-strate that our technique is superior to baseline methods both quantitatively and qualitatively for appearance edit-ing of complex real-world scenes. Our project page is https://palettenerf.github.io. 