Video-based gait recognition has achieved impressive re-sults in constrained scenarios. However, visual cameras neglect human 3D structure information, which limits theIn-feasibility of gait recognition in the 3D wild world. stead of extracting gait features from images, this work explores precise 3D gait features from point clouds and proposes a simple yet efficient 3D gait recognition frame-work, termed LidarGait. Our proposed approach projects sparse point clouds into depth maps to learn the represen-tations with 3D geometry information, which outperforms existing point-wise and camera-based methods by a sig-nificant margin. Due to the lack of point cloud datasets, we build the first large-scale LiDAR-based gait recognition dataset, SUSTech1K, collected by a LiDAR sensor and anRGB camera. The dataset contains 25,239 sequences from 1,050 subjects and covers many variations, including vis-ibility, views, occlusions, clothing, carrying, and scenes.Extensive experiments show that (1) 3D structure informa-tion serves as a significant feature for gait recognition. (2)LidarGait outperforms existing point-based and silhouette-based methods by a significant margin, while it also offers stable cross-view results. (3) The LiDAR sensor is superior to the RGB camera for gait recognition in the outdoor en-vironment. The source code and dataset have been made available at https://lidargait.github.io. 