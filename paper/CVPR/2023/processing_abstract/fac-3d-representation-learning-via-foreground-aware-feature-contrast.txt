Contrastive learning has recently demonstrated great potential for unsupervised pre-training in 3D scene un-derstanding tasks. However, most existing work ran-domly selects point features as anchors while building con-trast, leading to a clear bias toward background points that often dominate in 3D scenes. Also, object aware-ness and foreground-to-background discrimination are ne-glected, making contrastive learning less effective.To tackle these issues, we propose a general foreground-aware feature contrast (FAC) framework to learn more effective point cloud representations in pre-training. FAC consists of two novel contrast designs to construct more effective and informative contrast pairs. The first is building positive pairs within the same foreground segment where points tend to have the same semantics. The second is that we prevent over-discrimination between 3D segments/objects and en-courage foreground-to-background distinctions at the seg-ment level with adaptive feature learning in a Siamese cor-respondence network, which adaptively learns feature cor-relations within and across point cloud views effectively.Visualization with point activation maps shows that our contrast pairs capture clear correspondences among fore-ground regions during pre-training. Quantitative exper-iments also show that FAC achieves superior knowledge transfer and data efficiency in various downstream 3D se-mantic segmentation and object detection tasks. All codes, data, and models are available. 