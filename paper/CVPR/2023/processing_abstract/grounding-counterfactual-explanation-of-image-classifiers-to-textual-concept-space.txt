Concept-based explanation aims to provide concise and human-understandable explanations of an image classifier.However, existing concept-based explanation methods typ-ically require a significant amount of manually collected concept-annotated images. This is costly and runs the risk of human biases being involved in the explanation.In this paper, we propose Counterfactual explanation with text-driven concepts (CounTEX), where the concepts are defined only from text by leveraging a pre-trained multi-modal joint embedding space without additional concept-annotated datasets. A conceptual counterfactual explana-tion is generated with text-driven concepts. To utilize the text-driven concepts defined in the joint embedding space to interpret target classifier outcome, we present a novel pro-jection scheme for mapping the two spaces with a simple yet effective implementation. We show that CounTEX generates faithful explanations that provide a semantic understanding of model decision rationale robust to human bias. 