Out-of-distribution (OOD) generalization is an impor-tant issue for Graph Neural Networks (GNNs). Recent works employ different graph editions to generate aug-mented environments and learn an invariant GNN for gen-eralization. However, the label shift usually occurs in aug-mentation since graph structural edition inevitably alters the graph label. This brings inconsistent predictive rela-tionships among augmented environments, which is harm-ful to generalization. To address this issue, we proposeLiSA, which generates label-invariant augmentations to fa-cilitate graph OOD generalization. Instead of resorting to graph editions, LiSA exploits Label-invariant Subgraphs of the training graphs to construct Augmented environments.Specifically, LiSA first designs the variational subgraph generators to extract locally predictive patterns and con-struct multiple label-invariant subgraphs efficiently. Then, the subgraphs produced by different generators are col-lected to build different augmented environments. To pro-mote diversity among augmented environments, LiSA fur-ther introduces a tractable energy-based regularization to enlarge pair-wise distances between the distributions of en-vironments.In this manner, LiSA generates diverse aug-mented environments with a consistent predictive relation-ship and facilitates learning an invariant GNN. Extensive experiments on node-level and graph-level OOD bench-marks show that LiSA achieves impressive generalization performance with different GNN backbones. Code is avail-able on https://github.com/Samyu0304/LiSA. 