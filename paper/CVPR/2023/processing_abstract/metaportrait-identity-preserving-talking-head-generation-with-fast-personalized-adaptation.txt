In this work, we propose an ID-preserving talking head generation framework, which advances previous methods in two aspects. First, as opposed to interpolating from sparseﬂow, we claim that dense landmarks are crucial to achiev-ing accurate geometry-aware ﬂow ﬁelds. Second, inspired by face-swapping methods, we adaptively fuse the source identity during synthesis, so that the network better pre-serves the key characteristics of the image portrait. Al-though the proposed model surpasses prior generation ﬁ-delity on established benchmarks, personalized ﬁne-tuning is still needed to further make the talking head generation qualiﬁed for real usage. However, this process is rather computationally demanding that is unaffordable to stan-dard users. To alleviate this, we propose a fast adaptation model using a meta-learning approach. The learned model can be adapted to a high-quality personalized model as fast as 30 seconds. Last but not least, a spatial-temporal en-hancement module is proposed to improve the ﬁne details while ensuring temporal coherency. Extensive experiments*Equal contribution, interns at Microsoft Research.†Joint corresponding authors. prove the signiﬁcant superiority of our approach over the state of the arts in both one-shot and personalized settings. 