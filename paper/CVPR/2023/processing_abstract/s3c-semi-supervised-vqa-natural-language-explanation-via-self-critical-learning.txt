VQA Natural Language Explanation (VQA-NLE) task aims to explain the decision-making process of VQA mod-els in natural language. Unlike traditional attention or gra-dient analysis, free-text rationales can be easier to under-stand and gain usersâ€™ trust. Existing methods mostly use post-hoc or self-rationalization models to obtain a plau-sible explanation. However, these frameworks are bottle-necked by the following challenges: 1) the reasoning pro-cess cannot be faithfully responded to and suffer from the problem of logical inconsistency. 2) Human-annotated ex-planations are expensive and time-consuming to collect. In this paper, we propose a new Semi-Supervised VQA-NLE via Self-Critical Learning (S3C), which evaluates the can-didate explanations by answering rewards to improve the logical consistency between answers and rationales. With a semi-supervised learning framework, the S3C can ben-efit from a tremendous amount of samples without human-annotated explanations. A large number of automatic mea-sures and human evaluations all show the effectiveness of our method. Meanwhile, the framework achieves a new state-of-the-art performance on the two VQA-NLE datasets. 