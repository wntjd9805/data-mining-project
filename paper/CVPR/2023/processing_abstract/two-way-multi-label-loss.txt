A natural image frequently contains multiple classiﬁ-cation targets, accordingly providing multiple class labels rather than a single label per image. While the single-label classiﬁcation is effectively addressed by applying a softmax cross-entropy loss, the multi-label task is tackled mainly in a binary cross-entropy (BCE) framework. In contrast to the softmax loss, the BCE loss involves issues regarding imbal-ance as multiple classes are decomposed into a bunch of binary classiﬁcations; recent works improve the BCE loss to cope with the issue by means of weighting. In this pa-per, we propose a multi-label loss by bridging a gap be-tween the softmax loss and the multi-label scenario. The proposed loss function is formulated on the basis of relative comparison among classes which also enables us to fur-ther improve discriminative power of features by enhanc-ing classiﬁcation margin. The loss function is so ﬂexible as to be applicable to a multi-label setting in two ways for discriminating classes as well as samples.In the exper-iments on multi-label classiﬁcation, the proposed method exhibits competitive performance to the other multi-label losses, and it also provides transferrable features on single-label ImageNet training. Codes are available at https://github.com/tk1980/TwowayMultiLabelLoss. 