Most existing point cloud upsampling methods have roughly three steps: feature extraction, feature expansion and 3D coordinate prediction. However, they usually suf-fer from two critical issues: (1) fixed upsampling rate after one-time training, since the feature expansion unit is cus-tomized for each upsampling rate; (2) outliers or shrink-age artifact caused by the difficulty of precisely predicting 3D coordinates or residuals of upsampled points. To adress them, we propose a new framework for accurate point cloud upsampling that supports arbitrary upsampling rates. Our method first interpolates the low-res point cloud according to a given upsampling rate. And then refine the positions of the interpolated points with an iterative optimization process, guided by a trained model estimating the differ-ence between the current point cloud and the high-res tar-get. Extensive quantitative and qualitative results on bench-marks and downstream tasks demonstrate that our method achieves the state-of-the-art accuracy and efficiency.Figure 1. The comparison between previous point cloud upsam-pling methods and ours, and N N denotes the deep neural net-work. Given the low-res input PL, previous methods directly pre-dict the 3D coordinates or residuals of high-res output PH . And most of them need retraining to satisfy various upsampling rates.Instead we first interpolate points in Euclidean space, which sep-arates point generation from network learning and thus achieves arbitrary upsampling rates. Then we formulate the refinement of interpolated points as an iterative process aiming to minimize the learned point-to-point distance function N N (PI ). 