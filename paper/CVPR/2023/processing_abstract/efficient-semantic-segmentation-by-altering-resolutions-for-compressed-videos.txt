Video semantic segmentation (VSS) is a computationally expensive task due to the per-frame prediction for videos of high frame rates.In recent work, compact models or adaptive network strategies have been proposed for efficientVSS. However, they did not consider a crucial factor that affects the computational cost from the input side: the in-put resolution. In this paper, we propose an altering res-olution framework called AR-Seg for compressed videos to achieve efficient VSS. AR-Seg aims to reduce the computa-tional cost by using low resolution for non-keyframes. To prevent the performance degradation caused by downsam-pling, we design a Cross Resolution Feature Fusion (CR-eFF) module, and supervise it with a novel Feature Similar-ity Training (FST) strategy. Specifically, CReFF first makes use of motion vectors stored in a compressed video to warp features from high-resolution keyframes to low-resolution non-keyframes for better spatial alignment, and then selec-tively aggregates the warped features with local attention mechanism. Furthermore, the proposed FST supervises the aggregated features with high-resolution features through an explicit similarity loss and an implicit constraint from the shared decoding layer. Extensive experiments on CamVid and Cityscapes show that AR-Seg achieves state-of-the-art performance and is compatible with different segmenta-tion backbones. On CamVid, AR-Seg saves 67% computa-tional cost (measured in GFLOPs) with the PSPNet18 back-bone while maintaining high segmentation accuracy. Code: https://github.com/THU-LYJ-Lab/AR-Seg. 