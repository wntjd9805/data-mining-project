Assessing the aesthetics of an image is challenging, as it is inﬂuenced by multiple factors including composition, color, style, and high-level semantics. Existing image aes-thetic assessment (IAA) methods primarily rely on human-labeled rating scores, which oversimplify the visual aes-thetic information that humans perceive. Conversely, user comments offer more comprehensive information and are a more natural way to express human opinions and prefer-ences regarding image aesthetics. In light of this, we pro-pose learning image aesthetics from user comments, and ex-ploring vision-language pretraining methods to learn mul-timodal aesthetic representations. Speciﬁcally, we pretrain an image-text encoder-decoder model with image-comment pairs, using contrastive and generative objectives to learn rich and generic aesthetic semantics without human labels.To efﬁciently adapt the pretrained model for downstreamIAA tasks, we further propose a lightweight rank-based adapter that employs text as an anchor to learn the aesthetic ranking concept. Our results show that our pretrained aes-thetic vision-language model outperforms prior works on image aesthetic captioning over the AVA-Captions dataset, and it has powerful zero-shot capability for aesthetic tasks such as zero-shot style classiﬁcation and zero-shot IAA, sur-passing many supervised baselines. With only minimal ﬁne-tuning parameters using the proposed adapter module, our model achieves state-of-the-art IAA performance over theAVA dataset. 1 