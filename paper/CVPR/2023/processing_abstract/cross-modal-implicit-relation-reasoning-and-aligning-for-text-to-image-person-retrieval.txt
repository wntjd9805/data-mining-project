Text-to-image person retrieval aims to identify the tar-get person based on a given textual description query. The primary challenge is to learn the mapping of visual and tex-tual modalities into a common latent space. Prior works have attempted to address this challenge by leveraging sep-arately pre-trained unimodal models to extract visual and textual features. However, these approaches lack the nec-essary underlying alignment capabilities required to match multimodal data effectively. Besides, these works use prior information to explore explicit part alignments, which may lead to the distortion of intra-modality information. To alle-viate these issues, we present IRRA: a cross-modal ImplicitRelation Reasoning and Aligning framework that learns re-lations between local visual-textual tokens and enhances global image-text matching without requiring additional prior supervision. Specifically, we first design an ImplicitRelation Reasoning module in a masked language model-ing paradigm. This achieves cross-modal interaction by integrating the visual cues into the textual tokens with a cross-modal multimodal interaction encoder. Secondly, to globally align the visual and textual embeddings, Similar-ity Distribution Matching is proposed to minimize the KL divergence between image-text similarity distributions and the normalized label matching distributions. The proposed method achieves new state-of-the-art results on all three public datasets, with a notable margin of about 3%-9% forRank-1 accuracy compared to prior methods. (a) Early global matching paradigm (b) Existing explicit local matching paradigm (c) Our implicit relation reasoning aided matching paradigmFigure 1. Evolution of text-to-image person retrieval paradigms. (a) Early global-matching method directly align global image and text embeddings. (b) Recent local-matching method, explicitly ex-tract and align local image and text embeddings. (c) Our implicit relation reasoning method, implicitly reasoning the relation among all local tokens to better align global image and text embeddings. 