Whilst the availability of 3D LiDAR point cloud data has significantly grown in recent years, annotation remains ex-pensive and time-consuming, leading to a demand for semi-supervised semantic segmentation methods with application domains such as autonomous driving. Existing work very often employs relatively large segmentation backbone net-works to improve segmentation accuracy, at the expense of computational costs. In addition, many use uniform sam-pling to reduce ground truth data requirements for learning needed, often resulting in sub-optimal performance. To ad-dress these issues, we propose a new pipeline that employs a smaller architecture, requiring fewer ground-truth annota-tions to achieve superior segmentation accuracy compared to contemporary approaches. This is facilitated via a novelSparse Depthwise Separable Convolution module that signif-icantly reduces the network parameter count while retaining overall task performance. To effectively sub-sample our training data, we propose a new Spatio-Temporal Redun-dant Frame Downsampling (ST-RFD) method that leverages knowledge of sensor motion within the environment to ex-tract a more diverse subset of training data frame samples.To leverage the use of limited annotated data samples, we further propose a soft pseudo-label method informed by Li-DAR reflectivity. Our method outperforms contemporary semi-supervised work in terms of mIoU, using less labeled data, on the SemanticKITTI (59.5@5%) and ScribbleKITTI (58.1@5%) benchmark datasets, based on a 2.3× reduction in model parameters and 641× fewer multiply-add oper-ations whilst also demonstrating significant performance improvement on limited training data (i.e., Less is More). 