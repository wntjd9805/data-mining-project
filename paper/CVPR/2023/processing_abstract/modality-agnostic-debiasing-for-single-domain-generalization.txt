Samples in Training Domain Data AugmentationOOD SamplesDeep neural networks (DNNs) usually fail to general-ize well to outside of distribution (OOD) data, especially in the extreme case of single domain generalization (single-DG) that transfers DNNs from single domain to multi-ple unseen domains. Existing single-DG techniques com-monly devise various data-augmentation algorithms, and remould the multi-source domain generalization methodol-ogy to learn domain-generalized (semantic) features. Nev-ertheless, these methods are typically modality-speciﬁc, thereby being only applicable to one single modality (e.g., image). In contrast, we target a versatile Modality-AgnosticDebiasing (MAD) framework for single-DG, that enables generalization for different modalities. Technically, MAD introduces a novel two-branch classiﬁer: a biased-branch encourages the classiﬁer to identify the domain-speciﬁc (su-perﬁcial) features, and a general-branch captures domain-generalized features based on the knowledge from biased-branch. Our MAD is appealing in view that it is pluggable to most single-DG models. We validate the superiority of our MAD in a variety of single-DG scenarios with different modalities, including recognition on 1D texts, 2D images, 3D point clouds, and semantic segmentation on 2D images.More remarkably, for recognition on 3D point clouds and semantic segmentation on 2D images, MAD improves DSU by 2.82% and 1.5% in accuracy and mIOU. 