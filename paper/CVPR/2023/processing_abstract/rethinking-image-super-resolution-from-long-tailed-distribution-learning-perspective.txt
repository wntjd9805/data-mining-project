Existing studies have empirically observed that the reso-lution of the low-frequency region is easier to enhance than that of the high-frequency one. Although plentiful works have been devoted to alleviating this problem, little under-standing is given to explain it. In this paper, we try to give a feasible answer from a machine learning perspective, i.e., the twin ﬁtting problem caused by the long-tailed pixel dis-tribution in natural images. With this explanation, we refor-mulate image super resolution (SR) as a long-tailed distri-bution learning problem and solve it by bridging the gaps of the problem between in low- and high-level vision tasks.As a result, we design a long-tailed distribution learning so-lution, that rebalances the gradients from the pixels in the low- and high-frequency region, by introducing a static and a learnable structure prior. The learned SR model achieves better balance on the ﬁtting of the low- and high-frequency region so that the overall performance is improved. In the experiments, we evaluate the solution on four CNN- and oneTransformer-based SR models w.r.t. six datasets and three tasks, and experimental results demonstrate its superiority. 