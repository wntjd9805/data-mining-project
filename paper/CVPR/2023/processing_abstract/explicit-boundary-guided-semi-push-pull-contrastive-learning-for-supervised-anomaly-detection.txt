Most anomaly detection (AD) models are learned using only normal samples in an unsupervised way, which may result in ambiguous decision boundary and insufﬁcient dis-criminability.In fact, a few anomaly samples are often available in real-world applications, the valuable knowl-edge of known anomalies should also be effectively ex-ploited. However, utilizing a few known anomalies dur-ing training may cause another issue that the model may be biased by those known anomalies and fail to generalize to unseen anomalies.In this paper, we tackle supervised anomaly detection, i.e., we learn AD models using a few available anomalies with the objective to detect both the seen and unseen anomalies. We propose a novel explicit boundary guided semi-push-pull contrastive learning mech-anism, which can enhance model’s discriminability while mitigating the bias issue. Our approach is based on two core designs: First, we ﬁnd an explicit and compact sepa-rating boundary as the guidance for further feature learn-ing. As the boundary only relies on the normal feature dis-tribution, the bias problem caused by a few known anoma-lies can be alleviated. Second, a boundary guided semi-push-pull loss is developed to only pull the normal fea-tures together while pushing the abnormal features apart from the separating boundary beyond a certain margin re-gion. In this way, our model can form a more explicit and discriminative decision boundary to distinguish known and also unseen anomalies from normal samples more effec-tively. Code will be available at https://github. com/xcyao00/BGAD. 