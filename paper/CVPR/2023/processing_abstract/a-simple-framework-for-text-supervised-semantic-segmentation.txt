Text-supervised semantic segmentation is a novel re-search topic that allows semantic segments to emerge with image-text contrasting. However, pioneering methods could be subject to speciÔ¨Åcally designed network architectures.This paper shows that a vanilla contrastive language-image pre-training (CLIP) model is an effective text-supervised se-mantic segmentor by itself. First, we reveal that a vanillaCLIP is inferior to localization and segmentation due to its optimization being driven by densely aligning visual and language representations.Second, we propose the locality-driven alignment (LoDA) to address the problem, where CLIP optimization is driven by sparsely aligning lo-cal representations. Third, we propose a simple segmenta-tion (SimSeg) framework. LoDA and SimSeg jointly amelio-rate a vanilla CLIP to produce impressive semantic segmen-tation results. Our method outperforms previous state-of-the-art methods on PASCAL VOC 2012, PASCAL Context and COCO datasets by large margins. Code and models are available at github.com/muyangyi/SimSeg. 