Neural implicit surface representation methods show impressive reconstruction results but struggle to handle texture-less planar regions that widely exist in indoor scenes. Existing approaches addressing this leverage image prior that requires assistive networks trained with large-scale annotated datasets.In this work, we introduce a self-supervised super-plane constraint by exploring the free geometry cues from the predicted surface, which can fur-ther regularize the reconstruction of plane regions without any other ground truth annotations. Specifically, we in-troduce an iterative training scheme, where (i) grouping of pixels to formulate a super-plane (analogous to super-pixels), and (ii) optimizing of the scene reconstruction net-work via a super-plane constraint, are progressively con-ducted. We demonstrate that the model trained with super-planes surprisingly outperforms the one using conventional annotated planes, as individual super-plane statistically oc-cupies a larger area and leads to more stable training. Ex-tensive experiments show that our self-supervised super-plane constraint significantly improves 3D reconstruction quality even better than using ground truth plane segmen-tation. Additionally, the plane reconstruction results from our model can be used for auto-labeling for other vision tasks. The code and models are available at https://github.com/botaoye/S3PRecon. 