Recently,Learning distinctive point-wise features is critical for low-overlap point cloud registration. it has achieved huge success in incorporating Transformer into point cloud feature representation, which usually adopts a self-attention module to learn intra-point-cloud features first, then utilizes a cross-attention module to perform fea-ture exchange between input point clouds. The advan-tage of Transformer models mainly benefits from the use of self-attention to capture the global correlations in fea-ture space. However, these global correlations may in-volve ambiguity for point cloud registration task, espe-cially in indoor low-overlap scenarios, because the corre-lations with an extensive range of non-overlapping points may degrade the feature distinctiveness. To address this is-sue, we present PEAL, a Prior-embedded Explicit AttentionLearning model. By incorporating prior knowledge into the learning process, the points are divided into two parts.One includes points lying in the putative overlapping region and the other includes points located in the putative non-overlapping region. Then PEAL explicitly learns one-way attention with the putative overlapping points. This simplis-tic design attains surprising performance, significantly re-lieving the aforementioned feature ambiguity. Our method improves the Registration Recall by 6+% on the challenging 3DLoMatch benchmark and achieves state-of-the-art per-formance on Feature Matching Recall, Inlier Ratio, andRegistration Recall on both 3DMatch and 3DLoMatch. 