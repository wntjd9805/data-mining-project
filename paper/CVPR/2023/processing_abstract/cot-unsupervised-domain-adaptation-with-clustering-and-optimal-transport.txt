Unsupervised domain adaptation (UDA) aims to trans-fer the knowledge from a labeled source domain to an unlabeled target domain. Typically, to guarantee desir-able knowledge transfer, aligning the distribution between source and target domain from a global perspective is widely adopted in UDA. Recent researchers further point out the importance of local-level alignment and propose to construct instance-pair alignment by leveraging on OptimalTransport (OT) theory. However, existing OT-based UDA approaches are limited to handling class imbalance chal-lenges and introduce a heavy computation overhead when considering a large-scale training situation. To cope with two aforementioned issues, we propose a Clustering-basedOptimal Transport (COT) algorithm, which formulates the alignment procedure as an Optimal Transport problem and constructs a mapping between clustering centers in the source and target domain via an end-to-end manner. With this alignment on clustering centers, our COT eliminates the negative effect caused by class imbalance and reduces the computation cost simultaneously. Empirically, our COT achieves state-of-the-art performance on several authorita-tive benchmark datasets. 