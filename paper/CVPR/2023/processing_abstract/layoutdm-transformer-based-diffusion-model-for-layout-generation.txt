Automatic layout generation that can synthesize high-quality layouts is an important tool for graphic design in many applications. Though existing methods based on gen-erative models such as Generative Adversarial Networks (GANs) and Variational Auto-Encoders (VAEs) have pro-gressed, they still leave much room for improving the qual-ity and diversity of the results. Inspired by the recent suc-cess of diffusion models in generating high-quality images, this paper explores their potential for conditional layout generation and proposes Transformer-based Layout Diffu-sion Model (LayoutDM) by instantiating the conditional de-noising diffusion probabilistic model (DDPM) with a purely transformer-based architecture.Instead of using convo-lutional neural networks, a transformer-based conditionalLayout Denoiser is proposed to learn the reverse diffu-sion process to generate samples from noised layout data.Benefitting from both transformer and DDPM, our Lay-outDM is of desired properties such as high-quality genera-tion, strong sample diversity, faithful distribution coverage, and stationary training in comparison to GANs and VAEs.Quantitative and qualitative experimental results show that our method outperforms state-of-the-art generative models in terms of quality and diversity. 