Existing Neural Radiance Fields (NeRF) methods suf-fer from the existence of reflective objects, often result-ing in blurry or distorted rendering.Instead of calculat-ing a single radiance field, we propose a multi-space neu-ral radiance field (MS-NeRF) that represents the scene us-ing a group of feature fields in parallel sub-spaces, which leads to a better understanding of the neural network to-ward the existence of reflective and refractive objects. Our multi-space scheme works as an enhancement to existingNeRF methods, with only small computational overheads needed for training and inferring the extra-space outputs.We demonstrate the superiority and compatibility of our ap-proach using three representative NeRF-based models, i.e.,NeRF, Mip-NeRF, and Mip-NeRF 360. Comparisons are performed on a novelly constructed dataset consisting of 25 synthetic scenes and 7 real captured scenes with complex reflection and refraction, all having 360-degree viewpoints.Extensive experiments show that our approach significantly outperforms the existing single-space NeRF methods for rendering high-quality scenes concerned with complex light paths through mirror-like objects. Our code and dataset will be publicly available at https://zx-yin.github.io/msnerf. 