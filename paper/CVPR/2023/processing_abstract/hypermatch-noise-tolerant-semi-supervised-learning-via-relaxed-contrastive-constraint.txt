(cid:54)(cid:91)(cid:82)(cid:82) (cid:54)(cid:91)(cid:89)(cid:78)Recent developments of the application of ContrastiveLearning in Semi-Supervised Learning (SSL) have demon-strated signiﬁcant advancements, as a result of its ex-ceptional ability to learn class-aware cluster representa-tions and the full exploitation of massive unlabeled data.However, mismatched instance pairs caused by inaccurate pseudo labels would assign an unlabeled instance to the incorrect class in feature space, hence exacerbating SSL’s renowned conﬁrmation bias. To address this issue, we intro-duced a novel SSL approach, HyperMatch, which is a plug-in to several SSL designs enabling noise-tolerant utilization of unlabeled data. In particular, conﬁdence predictions are combined with semantic similarities to generate a more ob-jective class distribution, followed by a Gaussian MixtureModel to divide pseudo labels into a ’conﬁdent’ and a ’less conﬁdent’ subset. Then, we introduce Relaxed ContrastiveLoss by assigning the ’less-conﬁdent’ samples to a hyper-class, i.e. the union of top-K nearest classes, which effec-tively regularizes the interference of incorrect pseudo la-bels and even increases the probability of pulling a ’less conﬁdent’ sample close to its true class. Experiments and in-depth studies demonstrate that HyperMatch delivers re-markable state-of-the-art performance, outperforming Fix-Match on CIFAR100 with 400 and 2500 labeled samples by 11.86% and 4.88%, respectively. 