A fully automated object reconstruction pipeline is cru-cial for digital content creation. While the area of 3D recon-struction has witnessed profound developments, the removal of background to obtain a clean object model still relies on different forms of manual labor, such as bounding box labeling, mask annotations, and mesh manipulations. In this paper, we propose a novel framework named AutoRe-con for the automated discovery and reconstruction of an object from multi-view images. We demonstrate that fore-ground objects can be robustly located and segmented fromSfM point clouds by leveraging self-supervised 2D vision transformer features. Then, we reconstruct decomposed neu-ral scene representations with dense supervision provided by the decomposed point clouds, resulting in accurate ob-ject reconstruction and segmentation. Experiments on theDTU, BlendedMVS and CO3D-V2 datasets demonstrate the effectiveness and robustness of AutoRecon. The code and supplementary material are available on the project page: https://zju3dv.github.io/autorecon/.Figure 1. Overview of our fully-automated pipeline and results.Given an object-centric video, we achieve coarse decomposition by segmenting the salient foreground object from a semi-dense SfM point cloud, with pointwise-aggregated 2D DINO features [3]. Then we train a decomposed neural scene representation from multi-view images with the help of coarse decomposition results to reconstruct foreground objects and render multi-view consistent high-quality foreground masks. 