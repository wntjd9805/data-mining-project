Neural scene representations have achieved great suc-cess in parameterizing and reconstructing images, but cur-rent state of the art models are not optimized with the preservation of physical quantities in mind. While current architectures can reconstruct color images correctly, they create artifacts when trying to fit maps of polar quanti-ties. We propose polarimetric coordinate networks (pCON), a new model architecture for neural scene representations aimed at preserving polarimetric information while accu-rately parameterizing the scene. Our model removes arti-facts created by current coordinate network architectures when reconstructing three polarimetric quantities of inter-est. All code and data can be found at this link: https://visual.ee.ucla.edu/pcon.htm. 