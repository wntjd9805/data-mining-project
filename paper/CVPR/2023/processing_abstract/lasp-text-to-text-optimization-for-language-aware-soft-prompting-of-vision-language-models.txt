Soft prompt learning has recently emerged as one of the methods of choice for adapting V&L models to a down-stream task using a few training examples. However, cur-rent methods significantly overfit the training data, suffer-ing from large accuracy degradation when tested on un-seen classes from the same domain. To this end, in this paper, we make the following 4 contributions: (1) To alle-viate base class overfitting, we propose a novel Language-Aware Soft Prompting (LASP) learning method by means of a text-to-text cross-entropy loss that maximizes the proba-bility of the learned prompts to be correctly classified with respect to pre-defined hand-crafted textual prompts. (2) To increase the representation capacity of the prompts, we pro-pose grouped LASP where each group of prompts is opti-mized with respect to a separate subset of textual prompts. (3) We identify a visual-language misalignment introduced by prompt learning and LASP, and more importantly, pro-pose a re-calibration mechanism to address it. (4) We show that LASP is inherently amenable to including, during train-ing, virtual classes, i.e. class names for which no visual samples are available, further increasing the robustness of the learned prompts. Through evaluations on 11 datasets, we show that our approach (a) significantly outperforms all prior works on soft prompting, and (b) matches and sur-passes, for the first time, the accuracy on novel classes ob-tained by hand-crafted prompts and CLIP for 8 out of 11 test datasets. Code will be made available here. 