Meta-learning and other approaches to few-shot learn-ing are widely studied for image recognition, and are in-creasingly applied to other vision tasks such as pose estima-tion and dense prediction. This naturally raises the question of whether there is any few-shot meta-learning algorithm capable of generalizing across these diverse task types? To support the community in answering this question, we intro-duce Meta Omnium, a dataset-of-datasets spanning multi-ple vision tasks including recognition, keypoint localization, semantic segmentation and regression. We experiment with popular few-shot meta-learning baselines and analyze their ability to generalize across tasks and to transfer knowledge between them. Meta Omnium enables meta-learning re-searchers to evaluate model generalization to a much wider array of tasks than previously possible, and provides a sin-gle framework for evaluating meta-learners across a wide suite of vision applications in a consistent manner. Code and dataset are available at https://github.com/ edi-meta-learning/meta-omnium. 