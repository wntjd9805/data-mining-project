Adversarial attacks can evaluate model robustness and have been of great concern in recent years. Among various attacks, targeted attacks aim at misleading victim models to output adversary-desired predictions, which are more chal-lenging and threatening than untargeted ones. Existing tar-geted attacks can be roughly divided into instance-specific and instance-agnostic attacks.Instance-specific attacks craft adversarial examples via iterative gradient updating on the specific instance. In contrast, instance-agnostic at-tacks learn a universal perturbation or a generative model on the global dataset to perform attacks. However, they rely too much on the classification boundary of substitute mod-els, ignoring the realistic distribution of the target class, which may result in limited targeted attack performance.And there is no attempt to simultaneously combine the in-formation of the specific instance and the global dataset. To deal with these limitations, we first conduct an analysis via a causal graph and propose to craft transferable targeted adversarial examples by injecting target patterns. Based on this analysis, we introduce a generative attack model com-posed of a cross-attention guided convolution module and a pattern injection module. Concretely, the former adopts a dynamic convolution kernel and a static convolution ker-nel for the specific instance and the global dataset, respec-tively, which can inherit the advantages of both instance-specific and instance-agnostic attacks. And the pattern in-jection module utilizes a pattern prototype to encode target patterns, which can guide the generation of targeted adver-sarial examples. Besides, we also provide rigorous theoret-ical analysis to guarantee the effectiveness of our method.Extensive experiments demonstrate that our method shows superior performance than 10 existing adversarial attacks against 13 models. 