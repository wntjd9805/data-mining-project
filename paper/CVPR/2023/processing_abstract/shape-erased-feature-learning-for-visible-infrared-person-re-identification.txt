Due to the modality gap between visible and infrared im-ages with high visual ambiguity, learning diverse modality-shared semantic concepts for visible-infrared person re-identification (VI-ReID) remains a challenging problem.Body shape is one of the significant modality-shared cues for VI-ReID. To dig more diverse modality-shared cues, we expect that erasing body-shape-related semantic concepts in the learned features can force the ReID model to ex-tract more and other modality-shared features for identifi-cation. To this end, we propose shape-erased feature learn-ing paradigm that decorrelates modality-shared features in two orthogonal subspaces. Jointly learning shape-related feature in one subspace and shape-erased features in the orthogonal complement achieves a conditional mutual in-formation maximization between shape-erased feature and identity discarding body shape information, thus enhancing the diversity of the learned representation explicitly. Ex-tensive experiments on SYSU-MM01, RegDB, and HITSZ-VCM datasets demonstrate the effectiveness of our method. 