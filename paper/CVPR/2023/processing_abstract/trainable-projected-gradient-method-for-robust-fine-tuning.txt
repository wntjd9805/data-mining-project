Recent studies on transfer learning have shown that se-lectively ﬁne-tuning a subset of layers or customizing dif-ferent learning rates for each layer can greatly improve ro-bustness to out-of-distribution (OOD) data and retain gen-eralization capability in the pre-trained models. However, most of these methods employ manually crafted heuristics or expensive hyper-parameter searches, which prevent them from scaling up to large datasets and neural networks. To solve this problem, we propose Trainable Projected Gradi-ent Method (TPGM) to automatically learn the constraint imposed for each layer for a ﬁne-grained ﬁne-tuning reg-ularization. This is motivated by formulating ﬁne-tuning as a bi-level constrained optimization problem. Speciﬁ-cally, TPGM maintains a set of projection radii, i.e., dis-tance constraints between the ﬁne-tuned model and the pre-trained model, for each layer, and enforces them through weight projections. To learn the constraints, we propose a bi-level optimization to automatically learn the best set of projection radii in an end-to-end manner. Theoretically, we show that the bi-level optimization formulation is the key to learning different constraints for each layer. Em-pirically, with little hyper-parameter search cost, TPGM outperforms existing ﬁne-tuning methods in OOD perfor-mance while matching the best in-distribution (ID) per-formance. For example, when ﬁne-tuned on DomainNet-Real and ImageNet, compared to vanilla ﬁne-tuning, TPGM shows 22% and 10% relative OOD improvement respec-tively on their sketch counterparts. Code is available at https://github.com/PotatoTian/TPGM . 