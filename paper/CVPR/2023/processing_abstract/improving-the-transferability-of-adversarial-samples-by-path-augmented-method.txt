Deep neural networks have achieved unprecedented suc-cess on diverse vision tasks. However, they are vulnerable to adversarial noise that is imperceptible to humans. This phe-nomenon negatively affects their deployment in real-world scenarios, especially security-related ones. To evaluate the robustness of a target model in practice, transfer-based at-tacks craft adversarial samples with a local model and have attracted increasing attention from researchers due to their high efficiency. The state-of-the-art transfer-based attacks are generally based on data augmentation, which typically augments multiple training images from a linear path when learning adversarial samples. However, such methods se-lected the image augmentation path heuristically and may augment images that are semantics-inconsistent with the target images, which harms the transferability of the gen-erated adversarial samples. To overcome the pitfall, we propose the Path-Augmented Method (PAM). Specifically,PAM first constructs a candidate augmentation path pool.It then settles the employed augmentation paths during ad-versarial sample generation with greedy search. Further-more, to avoid augmenting semantics-inconsistent images, we train a Semantics Predictor (SP) to constrain the length of the augmentation path. Extensive experiments confirm that PAM can achieve an improvement of over 4.8% on av-erage compared with the state-of-the-art baselines in terms of the attack success rates. 