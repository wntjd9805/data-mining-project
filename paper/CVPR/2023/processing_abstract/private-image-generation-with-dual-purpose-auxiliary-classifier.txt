Privacy-preserving image generation has been impor-tant for segments such as medical domains that have sen-sitive and limited data. The benefits of guaranteed privacy come at the costs of generated images’ quality and utility due to the privacy budget constraints. The utility is cur-rently measured by the gen2real accuracy (g2r%), i.e., the accuracy on real data of a downstream classifier trained using generated data. However, apart from this standard utility, we identify the “reversed utility” as another cru-cial aspect, which computes the accuracy on generated data of a classifier trained using real data, dubbed as real2gen accuracy (r2g%). Jointly considering these two views of utility, the standard and the reversed, could help the gen-eration model better improve transferability between fake and real data. Therefore, we propose a novel private image generation method that incorporates a dual-purpose auxil-iary classifier, which alternates between learning from real data and fake data, into the training of differentially privateGANs. Additionally, our deliberate training strategies such as sequential training contributes to accelerating the gen-erator’s convergence and further boosting the performance upon exhausting the privacy budget. Our results achieve new state-of-the-arts over all metrics on three benchmarks:MNIST, Fashion-MNIST, and CelebA. 