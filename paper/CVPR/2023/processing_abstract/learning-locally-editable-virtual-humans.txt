In this paper, we propose a novel hybrid representa-tion and end-to-end trainable network architecture to model fully editable and customizable neural avatars. At the core of our work lies a representation that combines the mod-eling power of neural fields with the ease of use and in-herent 3D consistency of skinned meshes. To this end, we construct a trainable feature codebook to store local geom-etry and texture features on the vertices of a deformable body model, thus exploiting its consistent topology under articulation. This representation is then employed in a generative auto-decoder architecture that admits fitting to unseen scans and sampling of realistic avatars with var-ied appearances and geometries. Furthermore, our repre-sentation allows local editing by swapping local features between 3D assets. To verify our method for avatar cre-ation and editing, we contribute a new high-quality dataset, dubbed CustomHumans, for training and evaluation. Our experiments quantitatively and qualitatively show that our method generates diverse detailed avatars and achieves bet-ter model fitting performance compared to state-of-the-art methods. Our code and dataset are available at https://ait.ethz.ch/custom-humans. 