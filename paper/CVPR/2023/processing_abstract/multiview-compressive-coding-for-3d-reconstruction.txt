A central goal of visual recognition is to understand ob-jects and scenes from a single image. 2D recognition has witnessed tremendous progress thanks to large-scale learn-ing and general-purpose representations. Comparatively, 3D poses new challenges stemming from occlusions not de-picted in the image. Prior works try to overcome these by inferring from multiple views or rely on scarce CAD models and category-specific priors which hinder scaling to novelIn this work, we explore single-view 3D recon-settings. struction by learning generalizable representations inspired by advances in self-supervised learning. We introduce a simple framework that operates on 3D points of single ob-jects or whole scenes coupled with category-agnostic large-scale training from diverse RGB-D videos. Our model, Mul-tiview Compressive Coding (MCC), learns to compress the input appearance and geometry to predict the 3D structure by querying a 3D-aware decoder. MCC’s generality and ef-ficiency allow it to learn from large-scale and diverse data sources with strong generalization to novel objects imag-ined by DALL·E 2 or captured in-the-wild with an iPhone. 