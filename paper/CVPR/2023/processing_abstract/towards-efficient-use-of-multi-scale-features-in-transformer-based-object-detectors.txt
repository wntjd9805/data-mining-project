Multi-scale features have been proven highly effective for object detection but often come with huge and even prohibitive extra computation costs, especially for the re-cent Transformer-based detectors.In this paper, we pro-pose Iterative Multi-scale Feature Aggregation (IMFA) â€“ a generic paradigm that enables efficient use of multi-scale features in Transformer-based object detectors. The core idea is to exploit sparse multi-scale features from just a few crucial locations, and it is achieved with two novel de-signs. First, IMFA rearranges the Transformer encoder-decoder pipeline so that the encoded features can be iter-atively updated based on the detection predictions. Second,IMFA sparsely samples scale-adaptive features for refined detection from just a few keypoint locations under the guid-ance of prior detection predictions. As a result, the sam-pled multi-scale features are sparse yet still highly ben-eficial for object detection. Extensive experiments show that the proposed IMFA boosts the performance of multipleTransformer-based object detectors significantly yet with only slight computational overhead. 