State-of-the-art solutions for Shape-from-Polarization (SfP) suffer from a speed-resolution tradeoff: they either sacrifice the number of polarization angles measured or necessitate lengthy acquisition times due to framerate con-straints, thus compromising either accuracy or latency. We tackle this tradeoff using event cameras. Event cameras operate at microseconds resolution with negligible motion blur, and output a continuous stream of events that precisely measures how light changes over time asynchronously. We propose a setup that consists of a linear polarizer rotating at high speeds in front of an event camera. Our method uses the continuous event stream caused by the rotation to reconstruct relative intensities at multiple polarizer an-gles. Experiments demonstrate that our method outper-forms physics-based baselines using frames, reducing theMAE by 25% in synthetic and real-world datasets. In the real world, we observe, however, that the challenging con-ditions (i.e., when few events are generated) harm the per-formance of physics-based solutions. To overcome this, we propose a learning-based approach that learns to esti-mate surface normals even at low event-rates, improving the physics-based approach by 52% on the real world dataset.The proposed system achieves an acquisition speed equiva-lent to 50 fps (>twice the framerate of the commercial po-larization sensor) while retaining the spatial resolution of 1MP. Our evaluation is based on the first large-scale dataset for event-based SfP.Code, dataset and video are available under: https://rpg.ifi.uzh.ch/esfp.html https://youtu.be/sF3Ue2Zkpec 