During training, supervised object detection tries to cor-rectly match the predicted bounding boxes and associated classification scores to the ground truth. This is essen-tial to determine which predictions are to be pushed to-wards which solutions, or to be discarded. Popular match-ing strategies include matching to the closest ground truth box (mostly used in combination with anchors), or match-ing via the Hungarian algorithm (mostly used in anchor-free methods). Each of these strategies comes with its own properties, underlying losses, and heuristics. We show howUnbalanced Optimal Transport unifies these different ap-proaches and opens a whole continuum of methods in be-tween. This allows for a finer selection of the desired prop-erties. Experimentally, we show that training an object de-tection model with Unbalanced Optimal Transport is able to reach the state-of-the-art both in terms of Average Preci-sion and Average Recall as well as to provide a faster initial convergence. The approach is well suited for GPU imple-mentation, which proves to be an advantage for large-scale models. 