We present 3D Highlighter, a technique for localizing se-mantic regions on a mesh using text as input. A key feature of our system is the ability to interpret “out-of-domain” localizations. Our system demonstrates the ability to rea-son about where to place non-obviously related concepts on an input 3D shape, such as adding clothing to a bare 3D animal model. Our method contextualizes the text de-scription using a neural ﬁeld and colors the correspond-ing region of the shape using a probability-weighted blend.Our neural optimization is guided by a pre-trained CLIP en-coder, which bypasses the need for any 3D datasets or 3D annotations. Thus, 3D Highlighter is highly ﬂexible, gen-eral, and capable of producing localizations on a myriad of input shapes. Our code is publicly available at https://github.com/threedle/3DHighlighter. 