Despite significant efforts, cutting-edge video segmenta-tion methods still remain sensitive to occlusion and rapid movement, due to their reliance on the appearance of ob-jects in the form of object embeddings, which are vul-nerable to these disturbances. A common solution is to use optical flow to provide motion information, but essen-tially it only considers pixel-level motion, which still re-lies on appearance similarity and hence is often inaccu-In this work, rate under occlusion and fast movement. we study the instance-level motion and present InstMove, which stands for Instance Motion for Object-centric VideoSegmentation.In comparison to pixel-wise motion, Inst-Move mainly relies on instance-level motion information that is free from image feature embeddings, and features physical interpretations, making it more accurate and ro-bust toward occlusion and fast-moving objects. To better fit in with the video segmentation tasks, InstMove uses in-stance masks to model the physical presence of an object and learns the dynamic model through a memory network to predict its position and shape in the next frame. With only a few lines of code, InstMove can be integrated into currentSOTA methods for three different video segmentation tasks and boost their performance. Specifically, we improve the previous arts by 1.5 AP on OVIS dataset, which features heavy occlusions, and 4.9 AP on YouTubeVIS-Long dataset, which mainly contains fast moving objects. These results suggest that instance-level motion is robust and accurate, and hence serving as a powerful solution in complex sce-narios for object-centric video segmentation. 