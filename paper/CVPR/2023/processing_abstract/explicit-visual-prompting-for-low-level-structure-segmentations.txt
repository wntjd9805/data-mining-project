We consider the generic problem of detecting low-level structures in images, which includes segmenting the ma-nipulated parts, identifying out-of-focus pixels, separating shadow regions, and detecting concealed objects. Whereas each such topic has been typically addressed with a domain-specific solution, we show that a unified approach performs well across all of them. We take inspiration from the widely-used pre-training and then prompt tuning protocols in NLP and propose a new visual prompting model, named ExplicitVisual Prompting (EVP). Different from the previous visual prompting which is typically a dataset-level implicit embed-ding, our key insight is to enforce the tunable parameters focusing on the explicit visual content from each individ-ual image, i.e., the features from frozen patch embeddings and the inputâ€™s high-frequency components. The proposedEVP significantly outperforms other parameter-efficient tun-ing protocols under the same amount of tunable parame-ters (5.7% extra trainable parameters of each task). EVP also achieves state-of-the-art performances on diverse low-level structure segmentation tasks compared to task-specific solutions. Our code is available at: https://github. com/NiFangBaAGe/Explicit-Visual-Prompt. 