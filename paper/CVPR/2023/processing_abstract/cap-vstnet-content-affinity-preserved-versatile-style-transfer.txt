Content affinity loss including feature and pixel affinity is a main problem which leads to artifacts in photorealis-tic and video style transfer. This paper proposes a new framework named CAP-VSTNet, which consists of a new re-versible residual network and an unbiased linear transform module, for versatile style transfer. This reversible resid-ual network can not only preserve content affinity but not introduce redundant information as traditional reversible networks, and hence facilitate better stylization. Empow-ered by Matting Laplacian training loss which can address the pixel affinity loss problem led by the linear transform, the proposed framework is applicable and effective on ver-satile style transfer. Extensive experiments show that CAP-VSTNet can produce better qualitative and quantitative re-sults in comparison with the state-of-the-art methods. 