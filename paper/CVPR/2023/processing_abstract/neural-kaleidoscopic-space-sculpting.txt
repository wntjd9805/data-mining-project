We introduce a method that recovers full-surround 3D reconstructions from a single kaleidoscopic image using a neural surface representation. Full-surround 3D recon-struction is critical for many applications, such as aug-mented and virtual reality. A kaleidoscope, which uses a single camera and multiple mirrors, is a convenient way of achieving full-surround coverage, as it redistributes light directions and thus captures multiple viewpoints in a single image. This enables single-shot and dynamic full-surround 3D reconstruction. However, using a kaleidoscopic im-age for multi-view stereo is challenging, as we need to de-compose the image into multi-view images by identifying which pixel corresponds to which virtual camera, a process we call labeling. To address this challenge, pur approach avoids the need to explicitly estimate labels, but instead“sculpts” a neural surface representation through the care-ful use of silhouette, background, foreground, and texture information present in the kaleidoscopic image. We demon-strate the advantages of our method in a range of simulated and real experiments, on both static and dynamic scenes. 