Existing methods of multi-person video 3D human Pose and Shape Estimation (PSE) typically adopt a two-stage strategy, which Ô¨Årst detects human instances in each frame and then performs single-person PSE with temporal model.However, the global spatio-temporal context among spa-tial instances can not be captured. In this paper, we pro-pose a new end-to-end multi-person 3D Pose and Shape estimation framework with progressive Video Transformer, termed PSVT. In PSVT, a spatio-temporal encoder (STE) captures the global feature dependencies among spatial ob-jects. Then, spatio-temporal pose decoder (STPD) and shape decoder (STSD) capture the global dependencies be-tween pose queries and feature tokens, shape queries and feature tokens, respectively. To handle the variances of ob-jects as time proceeds, a novel scheme of progressive de-coding is used to update pose and shape queries at each frame. Besides, we propose a novel pose-guided attention (PGA) for shape decoder to better predict shape parame-ters. The two components strengthen the decoder of PSVT to improve performance. Extensive experiments on the four datasets show that PSVT achieves stage-of-the-art results.Figure 1. Comparison of multi-stage and end-to-end framework. (a) Existing video-based methods [4, 16, 49, 50] perform single-person pose and shape estimation (SPSE) on the cropped areas by temporal modeling, such as Gated Recurrent Units (GRUs). (b)PSVT achieves end-to-end multi-person pose and shape estimation in video with spatial-temporal encoder (STE) and decoder (STD). 