Existing vector quantization (VQ) based autoregressive models follow a two-stage generation paradigm that first learns a codebook to encode images as discrete codes, and then completes generation based on the learned code-book. However, they encode fixed-size image regions into fixed-length codes and ignore their naturally different in-formation densities, which results in insufficiency in impor-tant regions and redundancy in unimportant ones, and fi-nally degrades the generation quality and speed. More-over, the fixed-length coding leads to an unnatural raster-scan autoregressive generation. To address the problem, we propose a novel two-stage framework: (1) Dynamic-Quantization VAE (DQ-VAE) which encodes image re-gions into variable-length codes based on their informa-tion densities for an accurate & compact code represen-tation. (2) DQ-Transformer which thereby generates im-ages autoregressively from coarse-grained (smooth regions with fewer codes) to fine-grained (details regions with more codes) by modeling the position and content of codes in each granularity alternately, through a novel stacked-transformer architecture and shared-content, non-shared position input layers designs. Comprehensive experiments on various generation tasks validate our superiorities in both effectiveness and efficiency. Code will be released at https : / / github . com / CrossmodalGroup /DynamicVectorQuantization.Figure 1. Illustration of our motivation. (a) Existing fixed-length coding ignores information densities, which results in insuffi-ciency in dense information regions like region ② and redundancy in sparse information regions like region ①, generating poor de-tails and inconsistent structure. Our information-density-based variable-length coding encodes accurately and produces rich de-tails and consistent structure. (b) Comparison of existing unnatu-ral raster-scan autoregressive generation order and our natural and more effective coarse-to-fine autoregressive generation order.Error map: l1 loss of each 322 region between original images and recon-structions, higher (redder) worse. Existing examples are taken from [13]. 