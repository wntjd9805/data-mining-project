Since experiencing domain shifts during test-time is in-evitable in practice, test-time adaption (TTA) continues to adapt the model after deployment. Recently, the area of continual and gradual test-time adaptation (TTA) emerged.In contrast to standard TTA, continual TTA considers not only a single domain shift, but a sequence of shifts. Grad-ual TTA further exploits the property that some shifts evolve gradually over time. Since in both settings long test se-quences are present, error accumulation needs to be ad-dressed for methods relying on self-training. In this work, we propose and show that in the setting of TTA, the sym-metric cross-entropy is better suited as a consistency loss for mean teachers compared to the commonly used cross-entropy. This is justified by our analysis with respect to the (symmetric) cross-entropy’s gradient properties. To pull the test feature space closer to the source domain, where the pre-trained model is well posed, contrastive learning is leveraged. Since applications differ in their require-ments, we address several settings, including having source data available and the more challenging source-free setting.We demonstrate the effectiveness of our proposed method“robust mean teacher“ (RMT) on the continual and grad-ual corruption benchmarks CIFAR10C, CIFAR100C, andImagenet-C. We further consider ImageNet-R and propose a new continual DomainNet-126 benchmark. State-of-the-art results are achieved on all benchmarks. 1 