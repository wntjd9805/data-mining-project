Existing image restoration methods mostly leverage the posterior distribution of natural images. However, they often assume known degradation and also require super-vised training, which restricts their adaptation to complex real applications. In this work, we propose the GenerativeDiffusion Prior (GDP) to effectively model the posterior distributions in an unsupervised sampling manner. GDP utilizes a pre-train denoising diffusion generative model (DDPM) for solving linear inverse, non-linear, or blind problems. Specifically, GDP systematically explores a pro-tocol of conditional guidance, which is verified more prac-tical than the commonly used guidance way. Furthermore,GDP is strength at optimizing the parameters of degrada-tion model during the denoising process, achieving blind image restoration. Besides, we devise hierarchical guid-ance and patch-based methods, enabling the GDP to gen-erate images of arbitrary resolutions. Experimentally, we demonstrate GDP ’s versatility on several image datasets for linear problems, such as super-resolution, deblurring, inpainting, and colorization, as well as non-linear and blind issues, such as low-light enhancement and HDR image re-∗Equal contribution, †Corresponding author. covery. GDP outperforms the current leading unsupervised methods on the diverse benchmarks in reconstruction qual-ity and perceptual quality. Moreover, GDP also general-izes well for natural images or synthesized images with ar-bitrary sizes from various tasks out of the distribution of the ImageNet training set. The project page is available at https://generativediffusionprior.github.io/ 