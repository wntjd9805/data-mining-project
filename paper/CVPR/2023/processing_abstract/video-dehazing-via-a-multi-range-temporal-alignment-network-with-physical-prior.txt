Video dehazing aims to recover haze-free frames with high visibility and contrast. This paper presents a novel framework to effectively explore the physical haze priors and aggregate temporal information. Specifically, we de-sign a memory-based physical prior guidance module to encode the prior-related features into long-range memory.Besides, we formulate a multi-range scene radiance recov-ery module to capture space-time dependencies in multiple space-time ranges, which helps to effectively aggregate tem-poral information from adjacent frames. Moreover, we con-struct the first large-scale outdoor video dehazing bench-mark dataset, which contains videos in various real-world scenarios. Experimental results on both synthetic and real conditions show the superiority of our proposed method. 