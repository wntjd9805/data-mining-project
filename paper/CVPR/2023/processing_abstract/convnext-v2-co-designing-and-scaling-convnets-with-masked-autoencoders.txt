Driven by improved architectures and better representa-tion learning frameworks, the field of visual recognition has enjoyed rapid modernization and performance boost in the early 2020s. For example, modern ConvNets, represented by ConvNeXt [33], have demonstrated strong performance in various scenarios. While these models were originally designed for supervised learning with ImageNet labels, they can also potentially benefit from self-supervised learn-ing techniques such as masked autoencoders (MAE) [14].However, we found that simply combining these two ap-proaches leads to subpar performance. In this paper, we propose a fully convolutional masked autoencoder frame-work and a new Global Response Normalization (GRN) layer that can be added to the ConvNeXt architecture to enhance inter-channel feature competition. This co-design of self-supervised learning techniques and architectural im-provement results in a new model family called ConvNeXtV2, which significantly improves the performance of pureConvNets on various recognition benchmarks, includingImageNet classification, COCO detection, and ADE20K segmentation. We also provide pre-trained ConvNeXt V2 models of various sizes, ranging from an efficient 3.7M-parameter Atto model with 76.7% top-1 accuracy on Im-ageNet, to a 650M Huge model that achieves a state-of-the-art 88.9% accuracy using only public training data. 