In this paper, we show that a binary latent space can be explored for compact yet expressive image representa-tions. We model the bi-directional mappings between an image and the corresponding latent binary representation by training an auto-encoder with a Bernoulli encoding dis-tribution. On the one hand, the binary latent space provides a compact discrete image representation of which the distri-bution can be modeled more efﬁciently than pixels or con-tinuous latent representations. On the other hand, we now represent each image patch as a binary vector instead of an index of a learned cookbook as in discrete image repre-sentations with vector quantization. In this way, we obtain binary latent representations that allow for better image quality and high-resolution image representations without any multi-stage hierarchy in the latent space. In this binary latent space, images can now be generated effectively us-ing a binary latent diffusion model tailored speciﬁcally for modeling the prior over the binary image representations.We present both conditional and unconditional image gen-eration experiments with multiple datasets, and show that the proposed method performs comparably to state-of-the-art methods while dramatically improving the sampling ef-ﬁciency to as few as 16 steps without using any test-time acceleration. The proposed framework can also be seam-1024 high-resolution image gener-lessly scaled to 1024 ation without resorting to latent hierarchy or multi-stage reﬁnements.⇥ 