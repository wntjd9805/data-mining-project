Confidence-based pseudo-labeling is among the domi-nant approaches in semi-supervised learning (SSL). It re-lies on including high-confidence predictions made on un-labeled data as additional targets to train the model. We propose PROTOCON, a novel SSL method aimed at the less-explored label-scarce SSL where such methods usually un-derperform. PROTOCON refines the pseudo-labels by lever-aging their nearest neighboursâ€™ information. The neigh-bours are identified as the training proceeds using an on-line clustering approach operating in an embedding space trained via a prototypical loss to encourage well-formed clusters. The online nature of PROTOCON allows it to utilise the label history of the entire dataset in one train-ing cycle to refine labels in the following cycle without the need to store image embeddings. Hence, it can seamlessly scale to larger datasets at a low cost. Finally, PROTOCON addresses the poor training signal in the initial phase of training (due to fewer confident predictions) by introduc-ing an auxiliary self-supervised loss. It delivers significant gains and faster convergence over state-of-the-art across 5 datasets, including CIFARs, ImageNet and DomainNet. 