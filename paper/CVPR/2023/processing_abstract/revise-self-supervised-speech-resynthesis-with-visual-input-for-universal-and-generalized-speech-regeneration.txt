Prior works on improving speech quality with visual in-put typically study each type of auditory distortion sepa-rately (e.g., separation, inpainting, video-to-speech) and present tailored algorithms. This paper proposes to unify these subjects and study Generalized Speech Regenera-tion, where the goal is not to reconstruct the exact refer-ence clean signal, but to focus on improving certain as-pects of speech while not necessarily preserving the restIn particular, this paper concerns intelli-such as voice. gibility, quality, and video synchronization. We cast the problem as audio-visual speech resynthesis, which is com-posed of two steps: pseudo audio-visual speech recognition (P-AVSR) and pseudo text-to-speech synthesis (P-TTS). P-AVSR and P-TTS are connected by discrete units derived from a self-supervised speech model. Moreover, we utilize self-supervised audio-visual speech model to initialize P-AVSR. The proposed model is coined ReVISE. ReVISE is the first high-quality model for in-the-wild video-to-speech synthesis and achieves superior performance on all LRS3 audio-visual regeneration tasks with a single model. To demonstrates its applicability in the real world, ReVISE is also evaluated on EasyCom, an audio-visual benchmark collected under challenging acoustic conditions with only 1.6 hours of training data. Similarly, ReVISE greatly sup-presses noise and improves quality. Project page: https://wnhsu.github.io/ReVISE/. 