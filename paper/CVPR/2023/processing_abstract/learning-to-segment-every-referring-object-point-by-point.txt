Referring Expression Segmentation (RES) can facili-tate pixel-level semantic alignment between vision and lan-guage. Most of the existing RES approaches require mas-sive pixel-level annotations, which are expensive and ex-haustive. In this paper, we propose a new partially super-vised training paradigm for RES, i.e., training using abun-dant referring bounding boxes and only a few (e.g., 1%) pixel-level referring masks. To maximize the transferabil-ity from the REC model, we construct our model based on the point-based sequence prediction model. We propose the co-content teacher-forcing to make the model explicitly associate the point coordinates (scale values) with the re-ferred spatial features, which alleviates the exposure bias caused by the limited segmentation masks. To make the most of referring bounding box annotations, we further pro-pose the resampling pseudo points strategy to select more accurate pseudo-points as supervision. Extensive experi-ments show that our model achieves 52.06% in terms of ac-curacy (versus 58.93% in fully supervised setting) on Re-fCOCO+@testA, when only using 1% of the mask anno-tations. Code is available at https://github.com/ qumengxue/Partial-RES.git. 