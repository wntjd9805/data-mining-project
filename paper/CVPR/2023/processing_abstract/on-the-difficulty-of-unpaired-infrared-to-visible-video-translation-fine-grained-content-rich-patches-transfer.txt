Explicit visible videos can provide sufficient visual in-formation and facilitate vision applications. Unfortunately, the image sensors of visible cameras are sensitive to light conditions like darkness or overexposure. To make up for this, recently, infrared sensors capable of stable imaging have received increasing attention in autonomous driving and monitoring. However, most prosperous vision mod-els are still trained on massive clear visible data, facing huge visual gaps when deploying to infrared imaging sce-narios. In such cases, transferring the infrared video to a distinct visible one with fine-grained semantic patterns is a worthwhile endeavor. Previous works improve the out-puts by equally optimizing each patch on the translated vis-ible results, which is unfair for enhancing the details on content-rich patches due to the long-tail effect of pixel dis-tribution. Here we propose a novel CPTrans framework to tackle the challenge via balancing gradients of different patches, achieving the fine-grained Content-rich PatchesTransferring. Specifically, the content-aware optimization module encourages model optimization along gradients of target patches, ensuring the improvement of visual details.Additionally, the content-aware temporal normalization module enforces the generator to be robust to the motions of target patches. Moreover, we extend the existing dataset In-fraredCity to more challenging adverse weather conditions (rain and snow), dubbed as InfraredCity-Adverse1. Exten-sive experiments show that the proposed CPTrans achieves state-of-the-art performance under diverse scenes while re-quiring less training time than competitive methods. 