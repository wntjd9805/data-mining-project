Human action recognition aims at classifying the cate-gory of human action from a segment of a video. Recently, people have dived into designing GCN-based models to ex-tract features from skeletons for performing this task, be-cause skeleton representations are much more efﬁcient and robust than other modalities such as RGB frames. However, when employing the skeleton data, some important clues like related items are also discarded.It results in some ambiguous actions that are hard to be distinguished and tend to be misclassiﬁed. To alleviate this problem, we pro-pose an auxiliary feature reﬁnement head (FR Head), which consists of spatial-temporal decoupling and contrastive fea-ture reﬁnement, to obtain discriminative representations of skeletons. Ambiguous samples are dynamically discovered and calibrated in the feature space. Furthermore, FR Head could be imposed on different stages of GCNs to build a multi-level reﬁnement for stronger supervision. Extensive experiments are conducted on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets. Our proposed models obtain competitive results from state-of-the-art methods and can help to discriminate those ambiguous samples. Codes are available at https://github.com/zhysora/FR-Head.Figure 1. There are some actions that are hard to recognize be-cause the skeleton representations lack important interactive ob-jects and contexts, which make them easily confused with each other. 