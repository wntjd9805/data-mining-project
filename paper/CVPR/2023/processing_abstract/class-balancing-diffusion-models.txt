Diffusion-based models have shown the merits of gener-ating high-quality visual data while preserving better diver-sity in recent studies. However, such observation is only jus-tified with curated data distribution, where the data samples are nicely pre-processed to be uniformly distributed in terms of their labels. In practice, a long-tailed data distribution appears more common and how diffusion models perform on such class-imbalanced data remains unknown. In this work, we first investigate this problem and observe signifi-cant degradation in both diversity and fidelity when the dif-fusion model is trained on datasets with class-imbalanced distributions. Especially in tail classes, the generations largely lose diversity and we observe severe mode-collapse issues. To tackle this problem, we set from the hypothesis that the data distribution is not class-balanced, and pro-pose Class-Balancing Diffusion Models (CBDM) that are trained with a distribution adjustment regularizer as a so-lution. Experiments show that images generated by CBDM exhibit higher diversity and quality in both quantitative and qualitative ways. Our method benchmarked the generation results on CIFAR100/CIFAR100LT dataset and shows out-standing performance on the downstream recognition task. 