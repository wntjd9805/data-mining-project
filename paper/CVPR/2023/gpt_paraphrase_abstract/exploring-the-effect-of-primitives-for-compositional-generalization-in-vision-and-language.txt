Compositional generalization, an important aspect of human cognition, has gained significant attention in the vision-and-language (V&L) community. Understanding the impact of different primitives, such as words, image regions, and video frames, is crucial for enhancing the capability of compositional generalization. This paper aims to investigate the influence of primitives on compositional generalization in V&L. To achieve this, a self-supervised learning framework is proposed, which integrates two key characteristics: semantic equivariance and semantic invariance. These characteristics enable the methods to comprehend primitives by observing how changes in primitives affect the semantics of samples and ground-truth. The effectiveness of the framework is demonstrated through experimental results on two tasks: temporal video grounding and visual question answering. The output of the framework is an abstraction that captures the essence of the answer format.