We present a unified approach to detecting various low-level structures in images, such as manipulated parts, out-of-focus pixels, shadow regions, and concealed objects. While these problems have traditionally been addressed separately, our research demonstrates that a single approach can effectively handle all of them. Drawing inspiration from pre-training and prompt tuning in natural language processing (NLP), we propose a new visual prompting model called Explicit Visual Prompting (EVP). Unlike previous visual prompting techniques that rely on implicit embedding at the dataset level, EVP focuses on explicit visual content within each individual image. This includes features from frozen patch embeddings and high-frequency components of the input. Our EVP model outperforms other parameter-efficient tuning protocols with the same number of tunable parameters, achieving state-of-the-art results in low-level structure segmentation tasks compared to task-specific solutions. The code for our model is available at: https://github.com/NiFangBaAGe/Explicit-Visual-Prompt.