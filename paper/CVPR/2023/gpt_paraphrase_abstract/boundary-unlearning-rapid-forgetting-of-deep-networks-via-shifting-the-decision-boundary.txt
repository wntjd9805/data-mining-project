Efficient machine unlearning techniques are needed to address the practical requirements of the "right to be forgotten" and removing poisoned data. These techniques allow machine learning models to forget or unlearn a portion of their training data and its lineage. Previous studies have focused on destroying the influence of forgotten data by scrubbing the model parameters, but this approach is costly due to the large parameter space. This paper proposes a different approach, called Boundary Unlearning, which focuses on the decision space of the deep neural network model. The main idea is to shift the decision boundary of the original model to mimic the decision behavior of a model retrained from scratch. Two novel boundary shift methods, namely Boundary Shrink and Boundary Expanding, are developed to achieve rapid and effective unlearning while maintaining utility and privacy guarantees. The proposed Boundary Unlearning technique is extensively evaluated on CIFAR-10 and Vggface2 datasets, showing its effectiveness in forgetting a specific class in image classification and face recognition tasks. Compared to retraining from scratch, Boundary Unlearning achieves an expected speed-up of 17× and 19× for image classification and face recognition, respectively.