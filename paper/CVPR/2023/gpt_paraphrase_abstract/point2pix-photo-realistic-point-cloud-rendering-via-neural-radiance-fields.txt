This paper introduces Point2Pix, a new method for synthesizing photo-realistic images from sparse point cloud representations. The challenge lies in the sparsity of the point cloud, but recent advancements in Neural Radiance Fields have shown promise in generating realistic images from 2D inputs. Point2Pix leverages the 3D information in the point cloud and the NeRF rendering pipeline to generate high-quality images, particularly for indoor scenes with colored point clouds. The method improves the efficiency of ray sampling through point-guided sampling, which focuses on valid samples. Additionally, Point Encoding is introduced to create Multi-scale Radiance Fields that offer discriminative 3D point features. Finally, Fusion Encoding is proposed for the efficient synthesis of high-quality images. The effectiveness and generalization of the method are demonstrated through extensive experiments on the ScanNet and ArkitScenes datasets.