We propose GazeNeRF, a method for gaze redirection that is aware of 3D information. Unlike existing methods that work on 2D images and struggle to produce consistent 3D results, our approach considers the face region and eyeballs as separate 3D structures that move independently but in a coordinated manner. To achieve this, we utilize the advancements in conditional image-based neural radiance fields and introduce a two-stream architecture. This architecture predicts volumetric features for the face and eye regions separately. By rigidly transforming the eye features using a 3D rotation matrix, we gain precise control over the desired gaze angle. The final redirected image is obtained through differentiable volume compositing. Our experiments demonstrate that our architecture surpasses both naive conditioned NeRF baselines and previous state-of-the-art 2D gaze redirection methods in terms of accuracy and preservation of identity. We will release the code and models for research purposes.