Object discovery, the process of distinguishing objects from the background without manual labels, is a significant challenge in computer vision. Existing methods primarily rely on clustering low-level cues, such as color and texture, either through manual crafting or learned techniques like auto-encoders. This study proposes an enhanced approach by incorporating motion-guidance and mid-level feature tokenization into the auto-encoder representation learning framework.While motion-guidance and mid-level feature tokenization have been explored separately before, this study introduces a novel transformer decoder that combines both elements. By utilizing motion-guided vector quantization, the benefits of these components are effectively compounded. The results demonstrate that our architecture outperforms state-of-the-art methods on synthetic and real datasets. Notably, our approach facilitates the emergence of interpretable mid-level features specific to each object, showcasing the advantages of motion-guidance (eliminating the need for labeling) and quantization (enhancing interpretability and memory efficiency).