Cell detection and counting in medical images is a crucial task for pathological diagnoses. However, manual counting is time-consuming and can result in variations among pathologists. Existing deep learning-based object detection and counting methods are not well-suited for detecting and counting cells in medical images due to limited data, overlapping objects, multiple cell types, class imbalance, and subtle differences in cell size and shape. To address these challenges, we propose guided posterior regularization (DEGPR), which helps an object detector by guiding it to exploit discriminative features among cells. These features can be provided by pathologists or inferred from visual data. We evaluate our model on three datasets, including two publicly available datasets (CoNSeP and MoNuSAC) and a novel dataset called MuCeD, consisting of 55 biopsy images of the human duodenum for predicting celiac disease. Our extensive experimentation with three object detection baselines on these datasets demonstrates that DEGPR is independent of the model used and consistently improves baseline performance, achieving gains of up to 9% in mean average precision (mAP).