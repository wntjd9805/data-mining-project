Previous methods for co-salient object detection have focused on extracting co-salient cues by analyzing consistency relations between images, but have neglected the explicit exploration of background regions. In this paper, we propose a framework called Discriminative co-saliency and background Mining Transformer (DMT), which utilizes multi-grained correlation modules to explicitly mine both co-saliency and background information and effectively model their discrimination. Our approach consists of several components. Firstly, we introduce an inter-image relation module that establishes correlations between regions to enhance pixel-wise segmentation features while maintaining computational efficiency. Next, we employ two types of pre-defined tokens to mine co-saliency and background information using our contrast-induced pixel-to-token correlation and co-saliency token-to-token correlation modules. Additionally, we incorporate a token-guided feature refinement module that improves the discriminability of segmentation features based on the learned tokens. The extraction of segmentation features and token construction are performed iteratively through mutual promotion. To evaluate the effectiveness of our proposed method, we conducted experiments on three benchmark datasets, and the results demonstrate its superior performance. The source code of our method is publicly available at the following GitHub repository: https://github.com/dragonlee258079/DMT.