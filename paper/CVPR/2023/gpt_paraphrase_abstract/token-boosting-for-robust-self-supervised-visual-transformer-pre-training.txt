Pre-training Visual Transformers (VTs) with large-scale unlabeled data has become popular. However, existing approaches often neglect the fact that real-world data can be corrupted and unreliable. This poses a challenge when pre-training VTs using the masked autoencoding method, where both the input and masked targets may be unreliable. To overcome this limitation, we introduce the Token Boosting Module (TBM) as an add-on component for VTs. TBM helps VTs learn to extract clean and robust features during masked autoencoding pre-training. We provide theoretical analysis to demonstrate how TBM improves pre-training by generating more robust and generalizable representations, ultimately benefiting downstream tasks. Through extensive experiments on four corrupted datasets, we show that TBM consistently enhances performance on downstream tasks.