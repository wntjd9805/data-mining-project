The aim of advancing AI is to create technologies that cater to the needs of all communities, regardless of their geographical location. However, regional differences in culture can lead to variations in knowledge and therefore hinder the performance of AI models in different regions, resulting in bias against marginalized groups. To address this issue, we introduce GIVL, a Geographically Inclusive Vision-and-Language Pre-trained model. GIVL leverages two attributes of geographically diverse visual concepts: unique knowledge and visual characteristics within similar categories, and similar visual features across different categories. Inspired by these attributes, we propose new pre-training objectives called Image-Knowledge Matching (IKM) and Image Edit Checking (IEC) to train GIVL. Compared to similar models trained on similar amounts of data, GIVL achieves state-of-the-art performance and demonstrates more balanced results on geographically diverse vision and language tasks. The code and data for GIVL are available at https://github.com/WadeYin9712/GIVL.