Unsupervised pretraining followed by supervised finetuning is a popular approach in computer vision tasks due to the large amount of data and high annotation costs. While previous research has focused on both stages of this paradigm, little attention has been given to optimizing the annotation budget during finetuning. To address this gap, we introduce the concept of active finetuning, which involves selecting a subset of data for annotation in the pretraining-finetuning process. We propose a novel method called ActiveFT, which optimizes a parametric model in the continuous space to select a diverse subset of data that is representative of the entire unlabeled pool. We demonstrate through experiments that ActiveFT outperforms baseline methods in image classification and semantic segmentation tasks, offering both superior performance and efficiency. Our code is publicly available at https://github.com/yichen928/ActiveFT.