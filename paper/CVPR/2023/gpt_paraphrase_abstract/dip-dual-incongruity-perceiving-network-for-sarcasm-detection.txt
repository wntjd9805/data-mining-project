We investigate the task of multi-modal sarcasm detection, where sarcasm is characterized by a contradiction between the literal meaning and the real attitude. To address the incongruity between image and text in sarcastic data, we propose a Dual Incongruity Perceiving (DIP) network. This network consists of two branches that mine sarcastic information from factual and affective levels. For the factual aspect, we introduce a channel-wise reweighting strategy to obtain semantically discriminative embeddings and utilize a Gaussian distribution to model the uncertain correlation caused by the incongruity. The distribution is generated from the memory bank, which adaptively models the difference in semantic similarity between sarcastic and non-sarcastic data. For the affective aspect, we use siamese layers with shared parameters to learn cross-modal sentiment information. Additionally, we construct a relation graph using polarity values in the mini-batch, which forms the continuous contrastive loss to acquire affective embeddings. Extensive experiments demonstrate the superiority of our proposed method compared to state-of-the-art approaches. Our code is available at https://github.com/downdric/MSD.