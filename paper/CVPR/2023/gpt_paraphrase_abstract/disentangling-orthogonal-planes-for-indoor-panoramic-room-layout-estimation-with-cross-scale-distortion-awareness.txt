Current indoor layout estimation schemes focus on recovering layouts from compressed 1D sequences, which leads to confusion between different planes and lower performance. To address this issue, we propose a method that segments orthogonal planes (vertical and horizontal) from complex scenes to capture geometric cues for layout estimation. We also introduce a soft-flipping fusion strategy to consider the symmetry between the floor and ceiling boundaries. Additionally, we present a feature assembling mechanism to effectively integrate shallow and deep features while considering distortion distribution. To compensate for potential errors in pre-segmentation, we use triple attention to reconstruct the disentangled sequences. Our experiments on popular benchmarks demonstrate our superiority over existing state-of-the-art solutions, particularly on the 3DIoU metric. The code for our method is available at https://github.com/zhijieshen-bjtu/DOPNet.