Recent techniques for single-image hand modeling have shown impressive performance, but they struggle to capture sufficient details of the 3D hand mesh. This limitation hinders their use in applications that require high-fidelity hand modeling, such as personalized hand modeling. To address this issue, we propose a frequency split network that generates the 3D hand mesh using different frequency bands in a coarse-to-fine manner. By transforming the mesh into the frequency domain, we can preserve high-frequency personalized details and supervise each frequency component using a novel frequency decomposition loss. Our approach is scalable and can be stopped at any resolution level to accommodate different hardware capabilities. To evaluate our method's performance in recovering personalized shape details, we introduce a new evaluation metric called Mean Signal-to-Noise Ratio (MSNR) that measures the signal-to-noise ratio of each mesh frequency component. Extensive experiments demonstrate that our approach produces fine-grained details for high-fidelity 3D hand reconstruction, and our evaluation metric is more effective than traditional metrics for measuring mesh details. The code for our method is available at https://github.com/tyluann/FreqHand.