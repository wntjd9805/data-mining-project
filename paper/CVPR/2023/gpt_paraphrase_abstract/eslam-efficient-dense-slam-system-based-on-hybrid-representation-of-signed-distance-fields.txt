We introduce ESLAM, a highly efficient method for Simultaneous Localization and Mapping (SLAM) using an implicit neural representation. ESLAM operates on RGB-D frames with unknown camera poses, reconstructing the scene representation and estimating the camera position in a sequential manner. By integrating the latest advancements in Neural Radiance Fields (NeRF), our SLAM system achieves both efficiency and accuracy in dense visual SLAM. Our scene representation comprises multi-scale axis-aligned feature planes and shallow decoders that translate interpolated features into Truncated Signed Distance Field (TSDF) and RGB values for each point in the continuous space. Through extensive experiments on standard datasets (Replica, ScanNet, and TUM RGB-D), we demonstrate that ESLAM enhances the accuracy of 3D reconstruction and camera localization compared to state-of-the-art dense visual SLAM methods by over 50%. Additionally, ESLAM operates up to ten times faster and does not require any pre-training. For more information, please visit our project page at https://www.idiap.ch/paper/eslam.