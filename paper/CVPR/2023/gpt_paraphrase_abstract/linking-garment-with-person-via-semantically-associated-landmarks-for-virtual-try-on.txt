This paper introduces a new algorithm called SAL-VTON that aims to improve the alignment between garments and individuals in virtual try-on scenarios. The algorithm achieves this by utilizing semantically associated landmarks, which are pairs of landmarks with similar local semantics in both the garment and try-on images. By effectively modeling the local semantic association between the garment and person, SAL-VTON compensates for misalignment in the overall deformation of the garment. The algorithm consists of three stages: first, the semantically associated landmarks are estimated using a landmark localization model; second, a warping model uses the landmarks to associate corresponding parts of the garment and person, refining the alignment in the global flow; finally, a generator utilizes the landmarks to capture local semantics and control the try-on results. Additionally, the paper introduces a new landmark dataset with a unified labeling rule for diverse styles of garments. Extensive experimental results on popular datasets demonstrate that SAL-VTON can handle misalignment and outperforms state-of-the-art methods both qualitatively and quantitatively. The dataset can be accessed at https://modelscope.cn/datasets/damo/SAL-HG/summary.