This paper introduces a new data augmentation technique called Bias-Adversarial augmentation (BiasAdv) to address the issue of bias in neural networks. Neural networks often struggle to generalize unbiased test criteria due to their bias towards spurious correlations in the dataset. The main challenge in resolving this issue is the lack of training data that contradicts the bias. BiasAdv aims to overcome this challenge by supplementing bias-conflicting samples with adversarial images. The key idea is that attacking a biased model, which relies on spurious correlations, can generate synthetic bias-conflicting samples that can be used as augmented training data for learning a debiased model. The authors propose an optimization problem to generate adversarial images that attack the predictions of the biased model without affecting the desired debiased model.Despite its simplicity, BiasAdv proves to be effective in generating useful synthetic bias-conflicting samples, enabling the debiased model to learn generalizable representations. Importantly, BiasAdv does not require any bias annotations or prior knowledge of the bias type, making it applicable to existing debiasing methods and improving their performance. Extensive experiments demonstrate the superiority of BiasAdv, as it achieves state-of-the-art performance on four popular benchmark datasets across various bias domains. Overall, BiasAdv presents a promising approach to mitigate bias in neural networks and enhance their generalization capabilities.