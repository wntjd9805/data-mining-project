Numerous attempts have been made to apply Neural Radiance Fields (NeRFs) to dynamic scenes for modeling and rendering. However, current techniques are limited to offline rendering or processing short sequences with minimal motion. This paper introduces a new technique called Residual Radiance Field (ReRF), which is a compact neural representation that enables real-time rendering of long-duration dynamic scenes for free-view videos (FVVs). ReRF explicitly models the residual information between adjacent timestamps in the spatial-temporal feature space using a global coordinate-based tiny MLP as the feature decoder. By employing a compact motion grid and a residual feature grid, ReRF can handle large motions without sacrificing quality. A sequential training scheme is also proposed to maintain the smoothness and sparsity of the motion/residual grids. Additionally, a special FVV codec is designed based on ReRF, achieving a significantly higher compression rate and providing a companion ReRF player for online streaming of long-duration FVVs of dynamic scenes. Extensive experiments demonstrate the effectiveness of ReRF in compactly representing dynamic radiance fields, offering an unprecedented free-viewpoint viewing experience in terms of speed and quality.