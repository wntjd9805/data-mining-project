Physical world adversarial attacks are a serious threat to deep learning systems in real-world scenarios. These attacks involve generating realistic and malicious artifacts that can deceive these systems. Evaluating the naturalness of these attacks is crucial, as humans are skilled at detecting and removing unnatural ones. However, current evaluation methods for naturalness are inconsistent and prone to errors and biases. In this paper, we aim to address this issue by creating a benchmark dataset called Physical Attack Naturalness (PAN), which includes human ratings and gaze data. PAN provides new insights into the impact of contextual features (such as environmental and semantic variations) on naturalness and its correlation with behavioral features (such as gaze signals). To automatically assess attack naturalness in line with human ratings, we introduce the Dual Prior Alignment (DPA) network. DPA incorporates human knowledge into the reasoning process by rating prior alignment and mimicking human gaze behavior through attentive prior alignment. Our hope is that this work will inspire further research on improving and automating the assessment of naturalness in physical world attacks. The PAN dataset and our code can be accessed at https://github.com/zhangsn-19/PAN.