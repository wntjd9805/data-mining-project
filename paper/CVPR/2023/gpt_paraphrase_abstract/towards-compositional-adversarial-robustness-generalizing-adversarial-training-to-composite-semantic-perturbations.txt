The robustness of models against single perturbation types, like the ℓp-norm, has been extensively studied. However, there is limited exploration of the generalization of this robustness to more realistic scenarios involving multiple semantic perturbations and their composition. This paper introduces a new method for generating composite adversarial examples. This method utilizes component-wise projected gradient descent and automatic attack-order scheduling to find the optimal attack composition. Additionally, the paper proposes generalized adversarial training (GAT) to extend model robustness from ℓp-ball to composite semantic perturbations, such as combinations of Hue, Saturation, Brightness, Contrast, and Rotation. Experimental results using the ImageNet and CIFAR-10 datasets demonstrate that GAT provides robustness not only against all tested types of single attacks but also against any combination of such attacks. GAT also outperforms baseline ℓ-norm bounded adversarial training approaches by a significant margin.