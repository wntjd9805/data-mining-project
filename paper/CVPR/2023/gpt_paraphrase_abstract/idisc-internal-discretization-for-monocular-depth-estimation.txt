Monocular depth estimation is a challenging task in 3D scene understanding and its applications. The lack of full geometric constraints makes it even more difficult, even with supervised learning. To address this issue, we propose iDisc, a method that learns high-level patterns using internal discretized representations. Our method implicitly divides the scene into different patterns and learns them without supervision through a continuous-discrete-continuous bottleneck module called Internal Discretization (ID). Unlike existing methods, our model does not impose explicit constraints or priors on the depth output. The entire network, including the ID module, can be trained end-to-end, facilitated by an attention-based bottleneck module. Our approach achieves state-of-the-art performance on NYU-Depth v2 and KITTI datasets, surpassing all previously published methods on the official KITTI benchmark. Additionally, iDisc also achieves impressive results on surface normal estimation. We also investigate the generalization capability of our model through zero-shot testing, particularly in outdoor scenarios. To promote diversification, we introduce splits of two autonomous driving datasets, DDAD and Argoverse. The code for our method is available at http://vis.xyz/pub/idisc.