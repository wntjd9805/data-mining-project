Open-vocabulary object detection is a task that involves training object detectors to recognize objects based on arbitrary text queries, rather than a fixed set of object categories. Existing approaches use knowledge distillation to transfer knowledge from Pretrained Vision-and-Language Models (PVLMs) to object detectors. However, these methods suffer from information destruction and inefficient knowledge transfer. To address these issues, we propose the Object-Aware Distillation Pyramid (OADP) framework, which consists of an Object-Aware Knowledge Extraction (OAKE) module and a Distillation Pyramid (DP) mechanism. The OAKE module adaptively transforms object proposals and uses object-aware mask attention to extract precise and complete knowledge of objects from PVLMs. The DP mechanism incorporates global and block distillation to enhance knowledge transfer and compensate for missing relation information. Our experiments demonstrate that our method outperforms existing approaches, achieving a significant improvement in performance. Specifically, on the MS-COCO dataset, our OADP framework achieves a mean average precision at 50 IoU threshold (mAP@50) of 35.6, surpassing the current state-of-the-art method by 3.3 mAP@50. The code for our method is available at https://github.com/LutingWang/OADP.