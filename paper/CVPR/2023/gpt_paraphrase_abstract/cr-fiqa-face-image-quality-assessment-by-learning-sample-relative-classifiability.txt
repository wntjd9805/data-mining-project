This abstract discusses a novel method called CR-FIQA for assessing the quality of face images. The method estimates the face image quality by predicting its relative classifiability, which is determined by the allocation of the training sample feature representation in angular space with respect to its class center and the nearest negative class center. The correlation between face image quality and sample relative classifiability is experimentally demonstrated. To overcome the limitation of this property being observable only for the training dataset, the authors propose learning this property by observing internal network observations during the training process and using it to predict the quality of unseen samples. The superiority of CR-FIQA over state-of-the-art FIQA algorithms is demonstrated through extensive evaluation experiments on eight benchmarks and four face recognition models.