This paper introduces F2-NeRF (Fast-Free-NeRF), a new grid-based NeRF model for synthesizing novel views. F2-NeRF allows for arbitrary camera trajectories and requires only a few minutes for training. Existing grid-based NeRF training frameworks, such as Instant-NGP, Plenoxels, DVGO, or TensoRF, are primarily designed for limited scenes and rely on space warping to handle unbounded scenes. However, current space-warping methods are only suitable for forward-facing or 360Â° object-centric trajectories and cannot handle arbitrary trajectories. In this paper, we investigate the mechanism of space warping for unbounded scenes and propose a novel method called perspective warping. This approach enables the grid-based NeRF framework to handle arbitrary camera trajectories. Extensive experiments demonstrate that F2-NeRF, using perspective warping, produces high-quality images on standard datasets and a newly collected free trajectory dataset. For more information, please visit the project page: totoro97.github.io/projects/f2-nerf.