The goal of concept-based explanation is to provide concise and understandable explanations for image classifiers. However, current methods often rely on manually annotated concept images, which can be expensive and introduce human biases. This paper introduces a new approach called CounTEX, which generates counterfactual explanations using concepts derived solely from text. By leveraging a pre-trained multi-modal joint embedding space, CounTEX eliminates the need for additional concept-annotated datasets. To interpret the classifier's outcomes using text-driven concepts, the paper proposes a projection scheme that effectively maps the two spaces together. The results show that CounTEX generates accurate explanations that offer a semantic understanding of the model's decision-making process, while also being robust to human biases. Overall, CounTEX provides a cost-effective and reliable method for concept-based explanation in image classification.