We propose a method for addressing the empirical mismatch problems that arise in semi-supervised medical image segmentation due to differences in labeled and unlabeled data distribution. Our approach involves copying and pasting labeled and unlabeled data bidirectionally in a Mean Teacher architecture. This method enables unlabeled data to learn comprehensive common semantics from the labeled data in both inward and outward directions, reducing the distribution gap. Specifically, we randomly crop a portion of a labeled image and place it onto an unlabeled image, and vice versa. These mixed images are then inputted into a Student network and supervised using pseudo-labels and ground-truth. Our experiments demonstrate significant improvements, such as a 21% increase in Dice score on the ACDC dataset with only 5% labeled data, compared to other state-of-the-art methods on various semi-supervised medical image segmentation datasets. The code for our method is available at https://github.com/DeepMed-Lab-ECNU/BCP.