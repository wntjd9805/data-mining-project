Creating high-quality 3D face models based on natural language descriptions is valuable for various applications such as avatar creation, virtual reality, and telepresence. However, there has been limited research in this area due to two main challenges. Firstly, there is a lack of high-quality 3D face data with descriptive text annotations. Secondly, there is a complex mapping relationship between descriptive language and the shape and appearance of the face.To address these challenges, we have developed the DESCRIBE3D dataset, which is the first large-scale dataset with detailed text descriptions for the task of generating 3D faces from text. We then propose a two-stage framework to accomplish this task. In the first stage, we generate a 3D face that matches the concrete descriptions provided. In the second stage, we optimize the parameters in the 3D shape and texture space using abstract descriptions to refine the 3D face model.Extensive experiments demonstrate that our method is capable of producing accurate and high-quality 3D faces that closely align with the input descriptions, surpassing the performance of previous methods. The code and DESCRIBE3D dataset are available for public use at https://github.com/zhuhao-nju/describe3d.