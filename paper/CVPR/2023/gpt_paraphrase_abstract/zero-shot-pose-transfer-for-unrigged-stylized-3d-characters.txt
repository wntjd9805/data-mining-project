This study addresses the challenge of transferring the pose of a reference avatar to stylized 3D characters of different shapes in computer graphics. Existing methods either require rigging of the stylized characters or use the desired pose as ground truth during training. However, this study proposes a zero-shot approach that only requires deformed non-stylized avatars for training and can deform stylized characters of various shapes during inference. While classical methods achieve strong generalization by deforming the mesh at the triangle level, this requires labeled correspondences. To overcome this limitation, the study introduces a semi-supervised shape-understanding module that eliminates the need for explicit correspondences during testing. Additionally, an implicit pose deformation module is introduced to deform individual surface points and match them with the target pose. To ensure realistic and accurate deformation of the stylized characters, an efficient volume-based test-time training procedure is introduced. This procedure does not require rigging or the deformed stylized character during training, enabling the model to generalize to categories with limited annotation, such as stylized quadrupeds. Extensive experiments demonstrate the effectiveness of the proposed method compared to state-of-the-art approaches trained with similar or more supervision. The project page for this study can be accessed at https://jiashunwang.github.io/ZPT/.