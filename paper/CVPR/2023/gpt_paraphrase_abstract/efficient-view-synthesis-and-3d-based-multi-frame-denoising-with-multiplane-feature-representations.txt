This abstract discusses a new method for multi-frame denoising using 3D-based techniques. Current methods use 2D alignment techniques to combine information from multiple input images, but recent advancements in novel view synthesis have led to the development of a new approach that relies on volumetric scene representations. The proposed method introduces a learnable encoder-renderer pair that manipulates multiplane representations in feature space. The encoder fuses information across views in a depth-wise manner, while the renderer fuses information across depths in a view-wise manner. These two modules are trained together and learn to separate depths in an unsupervised manner, resulting in MultiplaneFeature (MPF) representations. The effectiveness of the proposed method is validated through experiments on various datasets and scenarios, including view synthesis, multi-frame denoising, and view synthesis under noisy conditions.