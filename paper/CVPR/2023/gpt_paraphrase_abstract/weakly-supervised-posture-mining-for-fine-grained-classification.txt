Fine-grained classification has been a challenging task due to the subtle differences between sub-categories of visual categories like bird species. Previous works have focused on individual discriminative regions while neglecting the connection between different regions in an image. However, the relationship between these regions contains valuable posture information that can improve classification performance. In this study, we propose a novel framework called PMRC (posture mining and reverse cross-entropy) that effectively combines with different backbones. PMRC utilizes the Deep Navigator to generate discriminative regions and constructs a graph using these regions. We aggregate the graph through message passing to obtain classification results. To train PMRC to mine posture information, we introduce a new training paradigm that facilitates communication and joint training between the Deep Navigator and message passing. Additionally, we propose reverse cross-entropy (RCE) and demonstrate its superiority over cross-entropy (CE) in terms of promoting model accuracy and generalization to other fine-grained classification models. Experimental results on benchmark datasets validate the state-of-the-art performance achieved by PMRC.