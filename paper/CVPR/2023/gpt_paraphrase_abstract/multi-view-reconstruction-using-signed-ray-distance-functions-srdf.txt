This paper presents a new optimization framework for reconstructing 3D shapes from multiple views. While previous methods using differentiable rendering have shown promise, they often lack precision in estimating geometries. On the other hand, multi-view stereo methods can provide accurate pixel-wise geometry, but struggle with global shape estimation. To bridge this gap, we propose a novel volumetric shape representation that combines the benefits of both approaches. Our representation is implicit but parameterized with pixel depths, allowing for consistent surface reconstruction along viewing rays. We optimize the depths by evaluating the agreement between depth prediction consistency and photometric consistency at each 3D location. Our approach is flexible and can accommodate different photo-consistency terms. Experimental results demonstrate the advantages of our volumetric integration approach, showing improved geometry estimations compared to existing methods on standard 3D benchmarks.