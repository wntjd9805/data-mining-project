Current methods for Temporal Action Detection (TAD) typically involve a pre-processing step where a varying-length video is converted into a fixed-length representation sequence. However, this pre-processing step leads to a reduction in the temporal resolution of the video, resulting in a loss of detection performance. This issue is caused by a temporal quantization error introduced during downsampling and recovery. Existing methods tend to overlook this problem.   To tackle this issue, we propose a novel model-agnostic post-processing method called Gaussian Approximated Post-processing (GAP). This method does not require redesigning or retraining the model. GAP models the start and end points of action instances using a Gaussian distribution, allowing for temporal boundary inference at a sub-snippet level. We also introduce an efficient Taylor-expansion based approximation for GAP.  Extensive experiments show that our GAP method consistently improves the performance of various pre-trained TAD models on the challenging ActivityNet and THUMOS benchmarks. On average, GAP achieves a performance gain of 0.2% to 0.7% in mean Average Precision (mAP) for ActivityNet and 0.2% to 0.5% in mAP for THUMOS. These improvements are significant and comparable to those achieved by novel model designs. Additionally, GAP can be integrated with model training to further enhance performance.  An important advantage of GAP is that it enables lower temporal resolutions, making inference more efficient and suitable for low-resource applications. The code for GAP is available at https://github.com/sauradip/GAP.