We present Cut-and-LEaRn (CutLER), a straightforward method for training unsupervised models for object detection and segmentation. By utilizing the capability of self-supervised models to identify objects without human supervision, we enhance it to train a high-performing localization model without the need for labeled data. CutLER employs the MaskCut approach to generate rough masks for multiple objects in an image, and then trains a detector on these masks using a robust loss function. Additionally, we enhance the model's performance by self-training it on its own predictions.Compared to previous approaches, CutLER is simpler, compatible with various detection architectures, and capable of detecting multiple objects. It is also a zero-shot unsupervised detector and significantly improves detection performance (AP50) by more than 2.7 times on 11 benchmarks across domains such as video frames, paintings, and sketches. With fine-tuning, CutLER serves as a low-shot detector, outperforming MoCo-v2 by 7.3% in terms of APbox and 6.6% in terms of APmask on COCO dataset when trained with only 5% labeled data.