The field of indiscernible scene understanding has gained significant attention in the vision community. To further advance this field, we have focused on a new challenge called indiscernible object counting (IOC), which involves counting objects that are blended with their surroundings. To address the lack of appropriate datasets for IOC, we have created a large-scale dataset called IOCfish5K. This dataset includes 5,637 high-resolution images with 659,024 annotated center points. It primarily consists of indiscernible objects, specifically fish, in underwater scenes, making the annotation process more challenging. Compared to existing datasets, IOCfish5K stands out due to its larger scale, higher image resolutions, more annotations, and denser scenes, making it the most challenging dataset for IOC to date. To benchmark the performance of object counting methods, we have selected 14 mainstream methods and evaluated them on IOCfish5K. Additionally, we have introduced a new strong baseline called IOCFormer, which combines density and regression branches in a unified framework to effectively tackle object counting in concealed scenes. Experimental results demonstrate that IOCFormer achieves state-of-the-art performance on IOCfish5K. The resources, including the dataset and the proposed baseline method, are available at github.com/GuoleiSun/Indiscernible-Object-Counting.