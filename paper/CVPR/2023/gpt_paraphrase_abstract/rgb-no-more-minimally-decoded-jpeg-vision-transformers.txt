Most computer vision neural networks are designed to analyze RGB images, which are commonly encoded in JPEG format before being saved to disk. However, decoding these images creates a significant overhead for RGB networks. Instead, our research focuses on training Vision Transformers (ViT) directly from the encoded JPEG features. This approach allows us to avoid the majority of the decoding overhead, resulting in faster data loading. Previous studies have explored this concept, but they primarily focused on modifying Convolutional Neural Networks (CNNs) to handle the encoded features. In contrast, our work demonstrates that ViTs can handle the encoded features without requiring extensive architectural modifications. Additionally, we explore data augmentation techniques specifically tailored for these encoded features, an area that has not been extensively studied in this context. By combining the advantages of ViT and data augmentation, our ViT-Ti model achieves training speeds that are up to 39.2% faster and inference speeds that are 17.9% faster than the RGB counterpart, all without sacrificing accuracy.