This paper presents a generalized few-shot segmentation framework that is easy to train and optimize. The framework utilizes the InfoMax principle and maximizes the Mutual Information (MI) between feature representations and their corresponding predictions. To retain knowledge on base classes, a knowledge distillation term is incorporated. The proposed framework can be applied to any segmentation network trained on base classes with a simple training process. Experimental results on the PASCAL-5i and COCO-20i benchmarks demonstrate significant improvements in performance, particularly for novel classes. In the 1-shot and 5-shot scenarios, the improvement gains range from 7% to 26% and from 3% to 12%, respectively. The paper also introduces a more challenging setting, where performance gaps are further emphasized. The code for this framework is publicly available at https://github.com/sinahmr/DIaM.