Existing methods for Scene Graph Generation (SGG) use contextual information to predict relationships between entities. However, these methods face challenges due to the diverse visual appearance of subject-object combinations and the similarity between different classes. This results in intra-class variation within each predicate category and inter-class similarity in the model's latent space. Consequently, current SGG methods struggle to acquire robust features for reliable relation prediction.   To address these challenges, we propose the Prototype-based Embedding Network (PE-Net) in this paper. PE-Net leverages the inherent semantics of the predicate's category to serve as class-wise prototypes in the semantic space. This helps alleviate the aforementioned challenges. PE-Net achieves this by modeling entities and predicates with prototype-aligned compact and distinctive representations. It establishes matching between entity pairs and predicates in a common embedding space, facilitating relation recognition.   Furthermore, we introduce Prototype-guided Learning (PL) to assist PE-Net in efficiently learning the matching between entities and predicates. Additionally, Prototype Regularization (PR) is designed to alleviate the ambiguity in entity-predicate matching caused by semantic overlap among predicates.   We conduct extensive experiments to evaluate our method's performance on SGG. The results demonstrate that our approach achieves superior relation recognition capability, surpassing the state-of-the-art performances on both Visual Genome and Open Images datasets. The implementation codes for our method are publicly available at https://github.com/VL-Group/PENET.