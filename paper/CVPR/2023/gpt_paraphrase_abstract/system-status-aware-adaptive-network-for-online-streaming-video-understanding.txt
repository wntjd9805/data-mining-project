In recent years, there have been significant advancements in real-time applications using deep neural networks. However, most previous studies have not considered the general case where the device's state and available resources fluctuate over time. Additionally, none of these studies have examined the impact of varying computational resources on online video understanding tasks. To address these issues, this paper introduces the System-status-aware Adaptive Network (SAN), which takes into account the real-time state of the device to provide accurate predictions with minimal delay. By utilizing our agent's policy, SAN improves efficiency and resilience to fluctuations in the system's status. The SAN model achieves state-of-the-art performance on two widely used video understanding tasks while maintaining low processing delays. Training such an agent on different hardware configurations is challenging since labeled training data may not be available or computationally expensive. To overcome this challenge, we propose the Meta Self-supervised Adaptation (MSA) method, which allows the agent's policy to adapt to new hardware configurations during testing. This enables easy deployment of the model on unseen hardware platforms.