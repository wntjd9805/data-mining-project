Neural radiance fields (NeRF) are highly effective at generating new views of a static scene using multiple calibrated images. However, when the scene contains distractors such as moving objects, lighting variations, and shadows, artifacts called "floaters" can appear as view-dependent effects. In order to address this issue, we propose a robust estimation method for training NeRF models, which treats distractors as outliers in the optimization process. Our approach successfully removes these outliers, leading to improved results compared to baseline methods, both in synthetic and real-world scenes. Our technique is easy to integrate into existing NeRF frameworks and requires only a few hyper-parameters. It does not rely on prior knowledge of the distractor types and focuses on optimizing the problem rather than preprocessing or modeling transient objects. For additional results, please visit https://robustnerf.github.io/public.