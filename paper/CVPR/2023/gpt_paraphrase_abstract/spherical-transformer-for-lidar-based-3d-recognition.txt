This study focuses on LiDAR-based 3D point cloud recognition and addresses the limitations of current methods. These methods often fail to consider the distribution of LiDAR points, resulting in information disconnection and a limited receptive field, particularly for sparse distant points. To overcome these issues, the authors propose SphereFormer, a method that directly aggregates information from dense close points to sparse distant ones. This is achieved through the use of radial window self-attention, which partitions the space into multiple non-overlapping narrow and long windows. This approach effectively overcomes information disconnection and significantly enhances the performance of sparse distant points by enlarging the receptive field. To fit the narrow and long windows, the authors introduce exponential splitting for fine-grained position encoding and dynamic feature selection to improve model representation ability. The effectiveness of SphereFormer is demonstrated by achieving top rankings on both nuScenes and SemanticKITTI semantic segmentation benchmarks, with mIoU scores of 81.9% and 74.8%, respectively. Additionally, SphereFormer achieves the 3rd place on the nuScenes object detection benchmark, with NDS and mAP scores of 72.8% and 68.5%, respectively. The code for SphereFormer is available at https://github.com/dvlab-research/SphereFormer.git.