The VQA Natural Language Explanation (VQA-NLE) task aims to provide natural language explanations for the decision-making process of VQA models. Free-text rationales are used to enhance understanding and gain user trust, unlike traditional attention or gradient analysis. Existing methods rely on post-hoc or self-rationalization models to generate plausible explanations. However, these approaches face challenges, including a lack of faithful reasoning and logical inconsistency. Additionally, collecting human-annotated explanations is costly and time-consuming. This paper introduces a new approach called Semi-Supervised VQA-NLE via Self-Critical Learning (S3C). S3C evaluates candidate explanations using rewards and improves the logical consistency between answers and rationales. It utilizes a semi-supervised learning framework, allowing it to benefit from a large number of samples without the need for human-annotated explanations. The effectiveness of S3C is demonstrated through various automatic measures and human evaluations. Furthermore, the framework achieves state-of-the-art performance on two VQA-NLE datasets. The answer format exclusively presents the abstraction.