Weakly supervised semantic segmentation methods are often based on class activation maps, which highlight regions that are discriminative for each class. Despite efforts to improve the accuracy of locating class-specific regions, existing methods still produce error predictions that do not correspond to the label candidates. These errors can be easily identified by comparing them with the image-level class tags. In this study, we propose a plug-and-play mechanism called Out-of-Candidate Rectification (OCR) that addresses this issue. Our approach involves splitting the semantic categories into two groups: In-Candidate (IC) and Out-of-Candidate (OC), based on their prior annotation and posterior prediction correlations. We introduce a differentiable rectification loss that encourages OC pixels to shift to the IC group. By incorporating OCR with established baselines such as AffinityNet, SEAM, and MCTformer, we achieve significant performance improvements on the Pascal VOC and MS COCO datasets, with minimal additional training overhead. This demonstrates the effectiveness and versatility of OCR.