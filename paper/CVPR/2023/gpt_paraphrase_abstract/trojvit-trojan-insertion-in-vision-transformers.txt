Vision Transformers (ViTs) have achieved excellent performance in a range of vision-related tasks, prompting adversaries to launch backdoor attacks on these models. Although traditional Convolutional Neural Networks (CNNs) are known to be vulnerable to such attacks, the vulnerability of ViTs has received little attention. Unlike CNNs that capture local features through convolutions, ViTs extract global context information using patches and attention mechanisms. Simply applying CNN-specific backdoor attack techniques to ViTs leads to low accuracy on clean data and a low success rate for the attacks. This study introduces a stealthy and practical backdoor attack called TrojViT, specifically designed for ViTs. Instead of using an area-wise trigger like CNN-specific attacks, TrojViT generates a patch-wise trigger that creates a Trojan by manipulating vulnerable bits in the ViT's parameters stored in DRAM memory. This is achieved through patch salience ranking and attention-target loss. TrojViT also employs parameter distillation to reduce the number of Trojan bits. Once the attacker inserts the Trojan into the ViT by flipping the vulnerable bits, the model continues to produce accurate results on normal inputs. However, when the attacker embeds a trigger into an input, the ViT model is compelled to classify the input into a predefined target class. The study demonstrates that flipping just a few vulnerable bits identified by TrojViT using the well-known RowHammer technique can convert a ViT model into a backdoored one. Extensive experiments are conducted on multiple datasets and various ViT models. TrojViT achieves a classification accuracy of 99.64% on test images for the ImageNet dataset by flipping 345 bits in a ViT model.