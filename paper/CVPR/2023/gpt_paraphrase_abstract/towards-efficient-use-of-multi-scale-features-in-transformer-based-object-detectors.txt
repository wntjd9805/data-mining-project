This paper introduces Iterative Multi-scale Feature Aggregation (IMFA), a method that allows for efficient utilization of multi-scale features in Transformer-based object detectors. Traditionally, multi-scale features have been effective for object detection but require substantial computational resources, especially in recent Transformer-based detectors. IMFA addresses this issue by leveraging sparse multi-scale features extracted from a small number of important locations. This is achieved through two innovative designs. Firstly, the paper rearranges the Transformer encoder-decoder pipeline to enable iterative updates of the encoded features based on detection predictions. Secondly, IMFA samples scale-adaptive features from keypoint locations, guided by prior detection predictions, to refine the detection process. Consequently, the sampled multi-scale features are sparse yet highly beneficial for object detection. Extensive experiments demonstrate that IMFA significantly enhances the performance of various Transformer-based object detectors with only minimal computational overhead.