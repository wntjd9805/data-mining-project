The task of navigating towards specific objects in unfamiliar environments, known as Object goal navigation (ObjectNav), is a crucial aspect of Embodied AI. Previous approaches to ObjectNav have relied on 2D maps, scene graphs, or image sequences for policy learning. However, since this task occurs in a 3D space, an agent that is aware of its 3D surroundings can enhance its ObjectNav capabilities by learning from detailed spatial information. Nevertheless, incorporating 3D scene representation into policy learning for this floor-level task can be impractical due to low sample efficiency and high computational costs.   To address this challenge, we propose a framework for 3D-aware ObjectNav that consists of two simple sub-policies. These sub-policies, called the corner-guided exploration policy and the category-aware identification policy, work together using online fused 3D points as observations. Through extensive experiments, we demonstrate that our framework significantly improves ObjectNav performance by learning from 3D scene representation. In fact, our framework achieves the highest performance among all modular-based methods on the Matterport3D and Gibson datasets, while requiring up to 30 times less computational cost for training. We will release the code for this framework to benefit the research community.