Rotated bounding boxes are more effective than axis-aligned bounding boxes in reducing ambiguity for elongated objects. However, the laborious process of annotating rotated bounding boxes has led to their limited use in detection datasets. In this paper, we propose a framework that allows models to predict precise rotated boxes using cheaper axis-aligned annotations. We leverage the fact that neural networks can learn richer representations of the target domain to address this task. By combining task knowledge from an out-of-domain source dataset with stronger annotation and domain knowledge from the target dataset with weaker annotation, we enable co-training on both datasets. This approach allows the model to solve the more detailed task in the target domain without additional computation overhead during inference. We evaluate the method on various target datasets and find that it consistently performs on par with the fully supervised approach.