This paper introduces an integral pre-training framework called masked image modeling (MIM). The framework focuses on jointly pre-training the backbone and neck to minimize the gap between MIM and downstream recognition tasks. The authors propose two technical contributions. First, they integrate a feature pyramid into the pre-training stage to unify the reconstruction and recognition necks. Second, they incorporate masked feature modeling (MFM) alongside MIM to provide multi-stage supervision to the feature pyramid. The resulting pre-trained models, called integrally pre-trained transformer pyramid networks (iTPNs), serve as strong foundation models for visual recognition. The base/large-level iTPN achieves impressive top-1 accuracy on ImageNet-1K, box AP on COCO object detection, and mIoU on ADE20K semantic segmentation, setting new records in all three tasks. The authors encourage the community to explore the integration of upstream pre-training and downstream fine-tuning tasks. The code for this work is available on GitHub at github.com/sunsmarterjie/iTPN.