Recent deep matchers have achieved rotation invariance in point cloud matching through data augmentation, but this approach has limitations when facing rare rotations. In response, we propose RoITr, a Rotation-Invariant Transformer that addresses pose variations in point cloud matching. Our contributions include a local attention mechanism utilizing PointPair Feature-based coordinates to describe pose-invariant geometry and an attention-based encoder-decoder architecture. We also introduce a global transformer with rotation-invariant cross-frame spatial awareness, improving feature distinctiveness and robustness to low overlap. Experiments on rigid and non-rigid benchmarks demonstrate that RoITr outperforms state-of-the-art models, particularly in low-overlapping scenarios. On the challenging 3DLoMatch benchmark, RoITr achieves substantial improvements of at least 13 and 5 percentage points in Inlier Ratio and Registration Recall, respectively. Our code is publicly available.