This paper investigates the performance of vector quantization (VQ) compared to scalar quantization (SQ) in neural image compression. While recent methods focus on nonlinear transform coding with SQ, this study demonstrates that there is still a significant gap between SQ and VQ. To address this, the authors propose a new framework called Nonlinear Vector Transform Coding (NVTC) that solves the complexity issue of VQ through a multi-stage quantization strategy and nonlinear vector transforms. Additionally, entropy-constrained VQ is applied in the latent space to optimize rate-distortion. Compared to previous approaches, NVTC achieves superior rate-distortion performance, faster decoding speed, and smaller model size. The code for NVTC is available at https://github.com/USTC-IMCL/NVTC.