StyleRF is a novel 3D style transfer technique that addresses the challenges of accurate geometry reconstruction, high-quality stylization, and generalizability to new styles. It achieves this by performing style transformation within the feature space of a radiance field. StyleRF represents 3D scenes using a grid of high-level features, allowing for reliable geometry restoration through volume rendering. Additionally, it transforms the grid features based on a reference style, resulting in high-quality style transfer even for new styles. StyleRF includes two innovative designs: sampling-invariant content transformation, which ensures multi-view consistency by considering the holistic statistics of sampled 3D points, and deferred style transformation of 2D feature maps, which reduces memory usage without compromising multi-view consistency. Extensive experiments demonstrate that StyleRF produces superior 3D stylization with precise geometry reconstruction, and it can generalize to various new styles without prior training.