Learning representations for individual instances is a major challenge in multiple instance learning (MIL) when only bag-level labels are available. Recent studies have shown promising results using contrastive self-supervised learning (CSSL), which aims to distinguish representations of randomly-selected instances. However, real-world applications like medical image classification often suffer from class imbalance, where randomly-selected instances mostly belong to the same majority class. This hinders CSSL from effectively capturing inter-class differences. To tackle this problem, we propose a novel framework called Iterative Self-paced Supervised Contrastive Learning for MIL Representations (ItS2CLR). ItS2CLR enhances the learned representation by leveraging instance-level pseudo labels derived from the bag-level labels. The framework employs a unique self-paced sampling strategy to ensure the accuracy of these pseudo labels. We evaluate ItS2CLR on three medical datasets and demonstrate its ability to improve the quality of instance-level pseudo labels and representations. It outperforms existing MIL methods in terms of both bag and instance level accuracy.