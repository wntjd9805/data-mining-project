This study presents a novel inverse rendering model that can accurately estimate various properties of a translucent object, including 3D shape, reflectance, subsurface scattering parameters, and environmental illumination. The model utilizes a physically-based renderer and a neural renderer to reconstruct the scene and edit materials, and employs a reconstruction loss to address the ambiguity problem in inverse rendering. To improve the training of the neural renderer, an augmented loss is proposed. The model takes a pair of images, one with flash and one without, as input. A large-scale synthetic dataset of 117K scenes was created to train and evaluate the model. The results, both qualitative and quantitative, on synthetic and real-world datasets demonstrate the effectiveness of the proposed model. The code and data for this model are publicly available.