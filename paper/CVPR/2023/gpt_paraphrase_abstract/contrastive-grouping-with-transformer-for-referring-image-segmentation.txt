This paper introduces a new method called CGFormer for referring image segmentation, which aims to segment a specific object in an image based on a natural language expression. Existing methods focus on per-pixel classification, but they fail to capture important object-level information. CGFormer addresses this issue by using a mask classification framework that incorporates a Transformer network. It introduces learnable query tokens to represent objects and uses a querying and grouping strategy to capture object-level information. CGFormer also incorporates cross-level interaction by updating query tokens and decoding masks in consecutive layers. Additionally, it utilizes contrastive learning to improve the grouping strategy. Experimental results show that CGFormer outperforms existing methods in both segmentation and generalization settings. The code for CGFormer is available at https://github.com/Toneyaya/CGFormer.