This study aims to investigate the possibility of training a 3D-GAN on artistic datasets while maintaining multi-view consistency and texture quality. To achieve this, the researchers propose an adaptation framework that involves using a pre-trained 3D-GAN from a source domain and a 2D-GAN trained on artistic datasets as the target domain. The knowledge from the 2D generator is then distilled into the source 3D generator. To align the distributions of camera parameters between the domains, an optimization-based method is introduced. Additionally, regularizations are proposed to ensure high-quality texture learning and avoid degenerate geometric solutions, such as flat shapes. A deformation-based technique is also presented to model exaggerated geometry in artistic domains, allowing for personalized geometric editing. Furthermore, the researchers propose a novel inversion method for 3D-GANs that links the latent spaces of the source and target domains. This enables the generation, editing, and animation of personalized artistic 3D avatars on artistic datasets. The project page for more information can be found at https:/rameenabdal.github.io/3DAvatarGAN.