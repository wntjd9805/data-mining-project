This study aims to improve model-based face reconstruction by addressing the challenge of fitting the model to outliers, such as occluders or make-up, which cannot be accurately represented by the model. The difficulty lies in localizing these outliers, as they are highly variable and hard to annotate. To overcome this challenge, the authors propose a joint approach called FOCUS, which combines a Face-autoencoder and outlier segmentation. The idea is to leverage the fact that outliers cannot be well-fitted by the face model and can be localized effectively when a high-quality model fitting is achieved. However, the model fitting and outlier segmentation are interdependent and need to be inferred jointly. To solve this issue, an EM-type training strategy is employed, where a face autoencoder and an outlier segmentation network are trained simultaneously. This approach leads to a synergistic effect, where the segmentation network prevents the face encoder from fitting to the outliers, thereby improving the reconstruction quality. In turn, the improved 3D face reconstruction enables the segmentation network to accurately predict the outliers. To differentiate between outliers and challenging regions, such as eyebrows, a statistical prior is constructed using synthetic data to measure the systematic bias in model fitting. Experimental results demonstrate that FOCUS achieves state-of-the-art 3D face reconstruction performance without the need for 3D annotation. Additionally, the segmentation network accurately localizes occluders in datasets like CelebA-HQ and AR. The authors express gratitude to the contributors of the MoFA re-implementation and acknowledge the funding support provided by various institutions. The proposed FOCUS method conducts joint face reconstruction and outlier segmentation under weak supervision, yielding promising results as shown in Figure 1.