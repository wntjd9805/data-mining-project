In machine learning, accurately detecting out-of-distribution (OOD) samples is crucial for model deployment. Current training methods often produce high confidence scores for both in-distribution (ID) and OOD data, making it difficult to distinguish between the two. To address this issue, post-hoc scoring is employed, with MaxLogit being a commonly used scoring function that relies on the maximum logits as the OOD score. We propose a new perspective on logit-based scoring functions by reformulating the logit into cosine similarity and logit norm, leading to the introduction of MaxCosine and MaxNorm as alternative scoring methods. Through empirical analysis, we discover that MaxCosine significantly contributes to the effectiveness of MaxLogit, while MaxNorm hampers its performance. To overcome this limitation, we introduce Decoupling MaxLogit (DML), which offers flexibility in balancing MaxCosine and MaxNorm. Furthermore, we extend DML to DML+ by leveraging insights that suggest fewer hard samples and a compact feature space are crucial for enhancing the effectiveness of logit-based methods. Our proposed logit-based OOD detection methods, including DML and DML+, demonstrate superior performance on CIFAR-10, CIFAR-100, and ImageNet datasets, establishing them as state-of-the-art approaches.