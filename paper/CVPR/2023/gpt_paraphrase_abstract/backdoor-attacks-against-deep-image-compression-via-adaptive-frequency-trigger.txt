Recent advancements in deep-learning-based compression techniques have yielded impressive results compared to traditional methods. However, deep learning models are susceptible to backdoor attacks, where specific trigger patterns added to the input can cause malicious behavior in the models. This paper introduces a new backdoor attack that utilizes multiple triggers against learned image compression models. Building upon the widely used discrete cosine transform (DCT) in existing compression systems, the proposed attack injects triggers in the DCT domain using a frequency-based trigger injection model. Various attack objectives are designed, including compromising compression quality in terms of bit-rate and reconstruction quality, as well as affecting task-driven measures like face recognition and semantic segmentation. Additionally, a novel dynamic loss function is devised to dynamically balance the influence of different loss terms during training, enhancing its efficiency. Extensive experiments demonstrate the effectiveness of the proposed attack by successfully injecting multiple backdoors with corresponding triggers into a single image compression model through simple modifications of encoder parameters.