The field of motion synthesis has been revolutionized by the introduction of neural networks. However, there are still challenges in learning to generate motions unconditionally, especially when the motions are diverse. In this study, we introduce MoDi, a generative model trained in an unsupervised manner using a diverse and unstructured dataset. MoDi is capable of synthesizing high-quality and diverse motions during inference. Despite the lack of structure in the dataset, our model produces a well-structured latent space that can be semantically clustered. This latent space serves as a strong motion prior and enables applications such as semantic editing and crowd animation. We also propose an encoder that can convert real motions into MoDi's motion manifold, providing solutions to tasks like completion from a given prefix and spatial editing. Our experiments, both qualitative and quantitative, demonstrate that our approach achieves state-of-the-art results, surpassing recent techniques. The code and trained models are available at the following link: https://sigal-raab.github.io/MoDi.