We propose a new approach to image inversion that aims to achieve both high-fidelity reconstruction and high-quality attribute editing. Previous methods have struggled to find a balance between these two goals. Low-rate latent spaces limit the ability to reconstruct images accurately, while high-rate latent spaces degrade the quality of attribute editing. To address these challenges, we introduce residual features in higher latent codes that can preserve image details during reconstruction. Additionally, we learn how to transform these residual features to adapt to manipulations in latent codes, enabling high-quality editing. Our framework includes a novel architecture pipeline and cycle consistency losses to extract and transform the residual features. Through extensive experiments and comparisons with state-of-the-art methods, we demonstrate significant improvements in both qualitative metrics and visual comparisons. The code for our approach is available on GitHub.