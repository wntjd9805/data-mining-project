Training machines to generate diverse handwritten characters is an interesting task. Current methods focus on capturing the overall style of a person's handwriting, but they often neglect the subtle inconsistencies in style between characters written by the same person. We propose a new approach called the style-disentangled Transformer (SDT) that extracts style representations at both the writer and character levels to synthesize realistic stylized online handwritten characters. SDT uses two contrastive objectives to extract the common style elements from reference samples and capture the specific style patterns of each sample. Our experiments show that SDT is effective in generating stylized characters in various languages. We also discovered that the two learned style representations provide information at different frequencies, highlighting the importance of separate style extraction. The source code for SDT is publicly available at the provided GitHub link.