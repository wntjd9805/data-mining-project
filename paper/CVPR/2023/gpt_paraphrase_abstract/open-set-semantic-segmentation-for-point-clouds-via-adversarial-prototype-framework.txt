In recent years, there has been a growing interest in point cloud semantic segmentation in the field of computer vision. However, most existing studies assume that the training and testing point clouds contain the same object classes, which is not always the case in real-world scenarios. This limitation prevents the identification of 3D objects that belong to classes not seen in the training set. To overcome this problem, we propose a framework called Adversarial Prototype Framework (APF) for open-set 3D semantic segmentation.The goal of APF is to accurately identify unseen-class points while maintaining segmentation performance on seen-class points. The framework consists of three main modules: a feature extraction module, a prototypical constraint module, and a feature adversarial module.The feature extraction module is responsible for extracting point features from the input data. The prototypical constraint module is designed to learn prototypes for each seen class based on the extracted features. These prototypes serve as reference points for distinguishing between different classes. The feature adversarial module utilizes generative adversarial networks to estimate the distribution of features belonging to unseen classes. This module generates synthetic unseen-class features, which are then used to enhance the learning of effective point features and prototypes for discriminating unseen-class samples from seen-class samples.Experimental results on two publicly available datasets demonstrate the effectiveness of the proposed APF compared to other existing methods. In most cases, APF outperforms the comparative methods by a significant margin.Overall, our proposed Adversarial Prototype Framework addresses the challenge of open-set 3D semantic segmentation by effectively identifying unseen-class points while maintaining segmentation performance on seen-class points.