This paper introduces NoisyQuant, an enhancement technique for post-training activation quantization in vision transformers. Vision transformers have complex architecture and high training cost, making post-training quantization necessary. However, previous quantization methods have been ineffective due to the heavy-tailed distribution of transformer activations. Instead of adjusting the quantizer design, NoisyQuant proposes adding a fixed Uniform noisy bias to the values being quantized, which has been theoretically proven to reduce quantization error. This approach successfully alters the activation distribution to better fit a given quantizer. Experimental results demonstrate that NoisyQuant significantly improves post-training quantization performance in vision transformers with minimal computational overhead. For example, on linear uniform 6-bit activation quantization, NoisyQuant achieves up to 1.7%, 1.1%, and 0.5% improvement in top-1 accuracy on ImageNet for ViT, DeiT, and Swin Transformer, respectively, surpassing previous nonlinear and mixed-precision quantization methods.