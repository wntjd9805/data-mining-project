The main objective of visual recognition is to comprehend objects and scenes from a single image. While 2D recognition has made significant advancements through extensive learning and versatile representations, 3D recognition presents new challenges due to occlusions not visible in the image. Previous approaches have attempted to address this by inferring from multiple views or relying on limited CAD models and category-specific assumptions, limiting their applicability to novel scenarios. In this study, we investigate the reconstruction of 3D structures from a single viewpoint by leveraging generalizable representations inspired by self-supervised learning advancements. We propose a straightforward framework, called Multiview Compressive Coding (MCC), which operates on 3D points of individual objects or entire scenes, combined with category-agnostic large-scale training using diverse RGB-D videos. Our MCC model learns to compress the input appearance and geometry and predicts the 3D structure by utilizing a 3D-aware decoder. The versatility and efficiency of MCC enable it to learn from extensive and diverse data sources, with the ability to generalize well to novel objects generated by DALLÂ·E 2 or captured in real-world scenarios using an iPhone.