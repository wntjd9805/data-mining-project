Machine learning models have been found to learn unintended decision rules, known as shortcuts, which limit their ability to generalize and undermine their reliability. Previous studies have focused on addressing this issue assuming that only a single shortcut exists in the training data. However, real-world images contain multiple visual cues, such as background and texture, making it crucial to understand whether existing methods can handle multiple shortcuts or if mitigating one shortcut leads to increased reliance on others. To address this gap, we introduce two benchmarks: UrbanCars, a dataset with controlled spurious cues, and ImageNet-W, an evaluation set based on ImageNet that includes a shortcut we discovered called watermark, which affects most modern vision models. By incorporating texture, background, and ImageNet-W, we can study multiple shortcuts that emerge from training on natural images. Our findings reveal that computer vision models, including large foundation models, struggle when faced with multiple shortcuts, regardless of training set, architecture, or supervision. Even methods specifically designed to combat shortcuts struggle to overcome this Whac-A-Mole dilemma. To tackle this challenge, we propose the LastLayer Ensemble, a simple yet effective method for mitigating multiple shortcuts without exacerbating the Whac-A-Mole problem. Our results highlight the importance of addressing the overlooked challenge of multi-shortcut mitigation in order to enhance the reliability of vision systems. The datasets and code are available at https://github.com/facebookresearch/Whac-A-Mole.