This study focuses on developing a comprehensive model called FlexDM for creative workflows in generating graphical documents. These workflows involve various complex tasks, including aligning elements, selecting suitable fonts, and using harmonious colors. The FlexDM model treats vector graphic documents as a collection of multi-modal elements and learns to predict masked fields such as element type, position, styling attributes, image, or text using a unified architecture. By incorporating explicit multi-task learning and in-domain pre-training, the model effectively captures the relationships between different document fields. Experimental results demonstrate that FlexDM successfully handles diverse design tasks and achieves competitive performance compared to specialized and costly baselines.