Privacy-preserving image generation is crucial in domains like medicine where sensitive and limited data are involved. However, ensuring privacy often leads to a compromise in the quality and usefulness of the generated images due to budget constraints. Currently, the utility of these images is measured by the accuracy of a downstream classifier trained using real data, known as gen2real accuracy (g2r%). In addition to this standard utility, we propose considering the "reversed utility," which measures the accuracy of a classifier trained using real data on the generated images (real2gen accuracy or r2g%). By considering both views of utility, we aim to improve the transferability between fake and real data in the generation model. To achieve this, we introduce a novel method that incorporates a dual-purpose auxiliary classifier into the training of differentially private GANs. This classifier alternates between learning from real and fake data. Furthermore, our deliberate training strategies, including sequential training, help accelerate the convergence of the generator and enhance performance even after the privacy budget is exhausted. Our approach outperforms existing methods on three benchmark datasets: MNIST, Fashion-MNIST, and CelebA.