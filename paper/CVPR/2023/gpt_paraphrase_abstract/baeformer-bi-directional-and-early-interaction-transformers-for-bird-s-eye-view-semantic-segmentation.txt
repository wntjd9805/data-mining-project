BEV semantic segmentation is a crucial task in autonomous driving. However, current Transformer-based methods face challenges in transforming PV to BEV due to their one-way and posterior interaction mechanisms. To tackle this problem, we present a new framework called BAEFormer, which incorporates an early-interaction PV-BEV pipeline and a bi-directional cross-attention mechanism. Additionally, we discover that the resolution of image feature maps in the cross-attention module has a limited impact on the final performance. Based on this finding, we propose to increase the size of input images and downsample the multi-view image features for cross-interaction, resulting in improved accuracy while maintaining manageable computational requirements. Our BEV semantic segmentation method achieves state-of-the-art performance in real-time inference speed on the nuScenes dataset, with a mIoU of 38.9 at 45FPS on a single A100 GPU.