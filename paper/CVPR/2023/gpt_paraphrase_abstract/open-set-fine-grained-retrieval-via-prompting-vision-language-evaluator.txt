The challenge of open-set fine-grained retrieval involves the need to retrieve unknown sub-categories during evaluation. However, current approaches primarily focus on close-set visual concepts with pre-defined subcategories, making it difficult to capture knowledge from unknown subcategories and handle them in open-world scenarios. In this study, we introduce a new framework called PLEor (Prompting vision-Language Evaluator) based on the CLIP model for open-set fine-grained retrieval. PLEor utilizes the pre-trained CLIP model to identify and transfer category-specific discrepancies, which encompass both pre-defined and unknown subcategories, to the backbone network trained in close-set scenarios. To make the pre-trained CLIP model sensitive to category-specific discrepancies, we employ a dual prompt scheme that involves learning a vision prompt for specifying these discrepancies and transforming random vectors with category names into descriptions of category-specific discrepancies. Additionally, we propose a vision-language evaluator that semantically aligns the vision and text prompts using the CLIP model and reinforces their connection. Furthermore, we introduce an open-set knowledge transfer mechanism to transfer the category-specific discrepancies into the backbone network using knowledge distillation. Our PLEor framework achieves promising results on open-set fine-grained datasets, as demonstrated through both quantitative and qualitative experiments.