In recent years, there has been significant progress in multi-camera 3D object detection, with many advanced methods using bird's-eye-view representations. However, these methods often suffer from low efficiency. Model compression through knowledge distillation is a common technique, but it is challenging due to unclear 3D geometry reasoning and the presence of noisy and confusing areas in expert features. This study explores how to distill knowledge from imperfect experts in the field of 3D object detection. The proposed method, called FD3D, utilizes a set of queries to identify instance-level areas for generating masked features, thereby enhancing feature representation in these regions. Additionally, the queries identify representative fine-grained positions for refined distillation. The effectiveness of FD3D is demonstrated by applying it to two popular detection models, BEVFormer and DETR3D, and achieving improvements of 4.07 and 3.17 points, respectively, in terms of the NDS metric on the nuScenes benchmark. The code for FD3D is available at https://github.com/OpenPerceptionX/BEVPerception-Survey-Recipe.