We present a method called DGLSS that aims to improve the performance of LiDAR semantic segmentation models in both the source and unseen domains. We focus on generalizing from a dense source domain and address the domain shift caused by different LiDAR sensor configurations and scene distributions. To simulate the unseen domains, we augment the domain by randomly subsampling LiDAR scans. We introduce two constraints, namely sparsity invariant feature consistency (SIFC) and semantic correlation consistency (SCC), to ensure generalizable representation learning. SIFC aligns sparse internal features of the source domain with the augmented domain based on feature affinity, while SCC constrains the correlation between class prototypes for each LiDAR scan. We also establish a standardized training and evaluation setting for DGLSS. Our method outperforms other baselines in the unseen domains, even without access to the target domain. The code is available at https://github.com/gzgzys9887/DGLSS.