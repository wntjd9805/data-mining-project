Motion forecasting is a challenging task in autonomous driving systems due to the diverse sources of input, varied behavior of agents, and the need for fast onboard deployment. This paper presents a new approach to multimodal motion prediction that is centered around the agent and uses anchor-informed proposals for efficiency. A modality-agnostic strategy is employed to encode the complex input in a unified manner. Multiple proposals, combined with anchors that provide context about the goal-oriented scene, are generated to enable multimodal prediction of a wide range of future trajectories. The proposed network architecture is uniform and concise, making it suitable for real-world driving deployment. Experimental results demonstrate that our agent-centric network outperforms existing methods in terms of prediction accuracy, while maintaining inference latency at a scene-centric level.