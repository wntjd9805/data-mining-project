Vision-language models (VLMs) can be effectively applied to various vision tasks through prompt learning. However, adapting these models to multiple similar yet distinct tasks in real-world scenarios poses a challenge. Existing methods typically learn a specific prompt for each task, which limits the ability to leverage shared information from other tasks. Simply training a task-shared prompt using a combination of all tasks overlooks fine-grained task correlations and may result in negative transfers. To address this, we propose Hierarchical Prompt (HiPro) learning, a straightforward and efficient approach to jointly adapt pre-trained VLMs to multiple downstream tasks. Our method measures the inter-task affinity and constructs a hierarchical task tree accordingly. Task-shared prompts learned by internal nodes explore information within the corresponding task group, while task-individual prompts learned by leaf nodes capture fine-grained information specific to each task. The combination of hierarchical prompts provides high-quality content at different levels of granularity. We evaluate HiPro on four multi-task learning datasets and demonstrate its effectiveness in improving performance across tasks.