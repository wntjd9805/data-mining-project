Graph Neural Networks (GNNs) currently use a message-passing mechanism for node interaction, but this approach has limitations. Firstly, GNNs are not scalable for large-scale industrial applications due to the high computation and memory costs incurred when nodes interact with rapidly expanding neighbors. Secondly, the over-smoothing problem occurs when repeated node interactions cause node representations of different classes to become indistinguishable. To overcome these limitations, we propose a new hop interaction paradigm. Our approach involves converting the interaction target among nodes to pre-processed multi-hop features within each node. We introduce the HopGNN framework, which seamlessly integrates with existing GNNs to enable hop interaction. Additionally, we enhance HopGNN using a multi-task learning strategy with a self-supervised learning objective. We evaluate our methods on 12 benchmark datasets across various domains, scales, and graph smoothness levels. Experimental results demonstrate that our approach achieves superior performance while maintaining scalability and efficiency. The code for our approach is available at https://github.com/JC-202/HopGNN.