The increasing research on neural radiance fields (NeRFs) for generating new views has neglected the impact of underwater or foggy scenes where the medium affects object appearance. This study introduces a rendering model for NeRFs in scattering media, utilizing the SeaThru image formation model, and proposes an architecture for learning scene information and medium parameters. The effectiveness of this approach is demonstrated through simulations and real-world examples, accurately rendering realistic underwater views. Moreover, the method allows for the removal of the medium, revealing clear views of occluded far objects and reconstructing their appearance and depth. The project's website provides access to the code and unique datasets.