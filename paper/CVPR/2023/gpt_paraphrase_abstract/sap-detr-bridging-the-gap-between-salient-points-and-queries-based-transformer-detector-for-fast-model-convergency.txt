Recently, there has been a focus on using central-concept spatial priors in DETR-based approaches to improve the convergence of Transformer detectors. These methods refine reference points towards the center of target objects and incorporate updated central reference information into object queries for spatially conditional attention. However, centralizing reference points can negatively impact the saliency of queries and confuse detectors due to indiscriminative spatial priors. To address this issue, we propose a new approach called SAlientPoint-based DETR (SAP-DETR) that treats object detection as a transformation from salient points to instance objects. In SAP-DETR, we explicitly initialize a query-specific reference point for each object query, gradually aggregate them into an instance object, and then predict the distance from each side of the bounding box to these points. By quickly attending to query-specific reference regions and the conditional box edges, SAP-DETR effectively bridges the gap between salient points and the query-based Transformer detector, resulting in significantly faster convergence.In experimental evaluations, SAP-DETR achieves a convergence speed that is 1.4 times faster than existing methods, while still maintaining competitive performance. It also consistently improves the state-of-the-art approaches by approximately 1.0 AP. When implemented based on ResNet-DC-101, SAP-DETR achieves an AP of 46.9. The code for SAP-DETR will be made available at https://github.com/liuyang-ict/SAP-DETR.