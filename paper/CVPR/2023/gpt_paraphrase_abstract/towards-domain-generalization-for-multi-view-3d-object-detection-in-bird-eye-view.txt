Bird-Eye-View (BEV) multi-view 3D object detection (MV3D-Det) has gained significant attention due to its cost-effectiveness and efficiency. However, existing camera-only 3D object detection algorithms often suffer from performance degradation when faced with input images from different domains than the training set. In this study, we analyze the causes of this domain gap in MV3D-Det and identify the feature distribution of BEV as the main contributing factor, which is influenced by the quality of depth estimation and 2D image feature representation. To address this, we propose a robust depth prediction method by decoupling depth estimation from camera intrinsic parameters and introducing dynamic perspective augmentation using homography to increase the diversity of camera poses. Additionally, we modify the focal length values to create pseudo-domains and employ an adversarial training loss to encourage a more domain-agnostic feature representation. Our approach, DG-BEV, effectively mitigates the performance drop in unseen target domains while maintaining accuracy in the source domain. Extensive experiments conducted on Waymo, nuScenes, and Lyft datasets demonstrate the generalization and effectiveness of our approach.