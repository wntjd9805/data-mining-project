We propose a new method for learning spatial transformations in medical image registration. Unlike traditional optimization-based techniques and other learning-based methods, we prioritize transformation regularity instead of penalizing irregularities. Our approach involves using a neural network to predict maps between source and target images, as well as the maps when the source and target images are swapped. These maps are then combined, and we enforce regularity by minimizing deviations of the Jacobian of this composition from the identity matrix. We call this regularizer GradICON, which leads to better convergence during training compared to directly promoting inverse consistency of the composition of maps. Our method achieves state-of-the-art registration performance on various medical image datasets using a single set of hyperparameters and a standardized training protocol. The code is available at https://github.com/uncbiag/ICON.