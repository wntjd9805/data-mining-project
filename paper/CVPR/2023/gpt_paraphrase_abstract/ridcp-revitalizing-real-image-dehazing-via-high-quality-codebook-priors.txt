Current dehazing methods struggle to effectively process real-world hazy images due to the lack of paired real data and reliable priors. This study introduces a new approach to real image dehazing by focusing on synthesizing more realistic hazy data and incorporating robust priors into the network. The proposed method involves rethinking the degradation of real hazy images and developing a phenomenological pipeline that considers various degradation types. The authors present a Real Image Dehazing network called RIDCP, which utilizes high-quality Codebook Priors (HQPs) obtained from a pre-trained VQGAN model. By replacing the negative effects of haze with HQPs, the decoder, equipped with a novel normalized feature alignment module, effectively utilizes high-quality features to generate clean results. Although the proposed pipeline reduces the domain gap between synthetic and real data, it is still challenging to match HQPs in real-world scenarios. To address this, the authors introduce a controllable matching operation that recalculates the distance between the features and HQPs, facilitating the identification of better counterparts. The study also provides a recommendation for controlling the matching process based on an explainable solution, allowing users to adjust the enhancement degree according to their preference. Extensive experiments demonstrate the effectiveness of the data synthesis pipeline and the superior performance of RIDCP in real image dehazing. The code and data for this method are available at https://rq-wu.github.io/projects/RIDCP.