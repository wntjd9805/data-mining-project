In order to accurately estimate signed distance functions (SDFs) from 3D point clouds, it is important to overcome the limitations of current methods that rely on generalized priors learned from large-scale supervision. These priors do not perform well when faced with geometric variations that were not seen during training, particularly for extremely sparse point clouds. To address this issue, we propose a neural network that directly infers SDFs from single sparse point clouds without the need for signed distance supervision, learned priors, or even normals. Our approach involves learning surface parameterization and SDF inference simultaneously in an end-to-end manner. To compensate for the sparsity of the point clouds, we utilize parameterized surfaces as a coarse surface sampler, generating multiple coarse surface estimations during training iterations. Based on these estimations, we mine supervision and use our thin plate splines (TPS) based network to infer SDFs as smooth functions statistically. Our method significantly improves the generalization ability and accuracy when dealing with unseen point clouds. Experimental results demonstrate the superiority of our approach over state-of-the-art methods in surface reconstruction for sparse point clouds, both in synthetic datasets and real scans. The code for our method can be found at https://github.com/chenchao15/NeuralTPS.