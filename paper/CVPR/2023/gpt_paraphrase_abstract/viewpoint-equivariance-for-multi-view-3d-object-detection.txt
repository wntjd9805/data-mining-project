This study presents VEDet, a novel 3D object detection framework that utilizes 3D multi-view geometry to enhance localization through viewpoint awareness and equivariance. By incorporating a query-based transformer architecture, VEDet encodes the 3D scene by augmenting image features with positional encodings based on their 3D perspective geometry. View-conditioned queries at the output level allow for the generation of multiple virtual frames during training, enabling the learning of viewpoint equivariance through enforcing multi-view consistency. The injection of multi-view geometry as positional encodings at the input level, along with regularization at the loss level, provides valuable geometric cues for 3D object detection. Experimental results on the nuScenes benchmark demonstrate that VEDet achieves state-of-the-art performance. The code and model of VEDet are publicly available at https://github.com/TRI-ML/VEDet.