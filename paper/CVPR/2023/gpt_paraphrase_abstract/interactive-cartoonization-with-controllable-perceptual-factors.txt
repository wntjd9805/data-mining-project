The task of cartoonization involves transforming natural photos into cartoon styles. Previous methods focused on end-to-end translation, which limited the ability to make edits. In contrast, we propose a new approach that allows for texture and color editing based on the cartoon creation process. Our model architecture includes separate decoders for texture and color, allowing these attributes to be decoupled. Within the texture decoder, we introduce a texture controller that enables users to adjust stroke style and abstraction, resulting in diverse cartoon textures. Additionally, we incorporate HSV color augmentation to encourage the generation of varied and controllable color translations. To our knowledge, our work is the first deep learning method that enables control over cartoonization during the inference stage, while also demonstrating significant improvements in quality compared to existing baselines.