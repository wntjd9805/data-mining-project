Current point cloud upsampling methods typically involve three steps: feature extraction, feature expansion, and 3D coordinate prediction. However, these methods often face two main challenges: (1) the upsampling rate is fixed after a one-time training, as the feature expansion unit is customized for each specific rate, and (2) the difficulty in accurately predicting 3D coordinates or residuals of upsampled points leads to the presence of outliers or shrinkage artifacts. To address these issues, we propose a novel framework for precise point cloud upsampling that allows for arbitrary upsampling rates. Our approach initially interpolates the low-resolution point cloud based on a given rate and subsequently refines the positions of the interpolated points through an iterative optimization process, guided by a trained model that estimates the difference between the current point cloud and the high-resolution target. Through extensive quantitative and qualitative evaluations on benchmarks and downstream tasks, we demonstrate that our method achieves state-of-the-art accuracy and efficiency. Figure 1 illustrates the comparison between previous point cloud upsampling methods and our proposed approach, where "NN" denotes the deep neural network. In contrast to previous methods that directly predict the 3D coordinates or residuals of the high-resolution output based on the low-resolution input, requiring retraining for various upsampling rates, our method first performs point interpolation in Euclidean space. This separation of point generation from network learning enables us to achieve arbitrary upsampling rates. We then formulate the refinement of interpolated points as an iterative process aimed at minimizing the learned point-to-point distance function NN(PI).