We introduce a new type of map called the renderable neural radiance map (RNR-Map) for visual navigation in 3D environments. The RNR-Map is a grid-based map consisting of latent codes at each pixel, which are derived from image observations and can be converted to the neural radiance field for image rendering. The latent codes contain implicit visual information about the environment, making the RNR-Map visually descriptive and useful for visual localization and navigation. We develop localization and navigation frameworks that effectively utilize the RNR-Map. Experimental results demonstrate that our localization framework achieves fast and accurate target location retrieval compared to other approaches, even in different environments. Our navigation framework outperforms existing methods in challenging scenarios with noise, showing a significant improvement in success rate. More information can be found on our project page: https://rllab-snu.github.io/projects/RNR-Map/.