Deep learning models face challenges when there is a difference in distribution between the training and test data. Recent advancements have shown that large pre-trained models, trained on diverse data, are remarkably robust against various distribution shifts. However, fine-tuning these models often results in a trade-off between performance on in-distribution (ID) data and robustness on out-of-distribution (OOD) data. Current approaches to address this trade-off do not explicitly tackle the problem of OOD robustness. In this study, we propose a novel fine-tuning method based on causal analysis of these issues. Our method involves using masked images as counterfactual samples to enhance the robustness of the fine-tuned model. Specifically, we mask certain patches of the images, either related or unrelated to semantics, based on class activation maps to break spurious correlations. We then replace the masked patches with patches from other images. These resulting counterfactual samples are used in feature-based distillation with the pre-trained model. Extensive experiments confirm that incorporating the proposed masked images as a regularization technique in fine-tuning achieves a better trade-off between ID and OOD performance compared to previous methods, particularly improving OOD performance. The code for our method is available at https://github.com/Coxy7/robust-finetuning.