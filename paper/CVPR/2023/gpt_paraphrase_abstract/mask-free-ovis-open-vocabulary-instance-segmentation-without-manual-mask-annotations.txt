Current instance segmentation models rely on manual mask annotations for learning task-specific information. However, this approach is time-consuming and hinders scalability for annotating new categories. To address this issue, Open-Vocabulary (OV) methods utilize image-caption pairs and vision-language models to learn novel categories. These OV methods combine strong supervision from base annotations and weak supervision from image-caption pairs to learn task-specific and novel category information, respectively. However, this difference in supervision leads to overfitting on base categories and poor generalization to novel ones. To overcome these limitations, we propose a Mask-free OVIS pipeline that learns both base and novel categories in a weakly supervised manner. Our pipeline leverages a pre-trained vision-language model to automatically generate pseudo-mask annotations, eliminating the need for labor-intensive instance-level annotations and reducing overfitting. These generated pseudo-mask annotations then supervise an instance segmentation model.Through extensive experiments on the MS-COCO dataset and OpenImages dataset, we demonstrate that our method, trained solely with pseudo-masks, significantly improves mean Average Precision (mAP) scores compared to state-of-the-art methods trained with manual masks. We provide codes and models for our method on our website: https://vibashan.github.io/ovis-web/.