This study demonstrates the feasibility of concurrently performing multiple tasks on point cloud using a simple yet effective multi-task network called Poly-PC. The framework addresses challenges such as different model architectures due to task bias and conflicting gradients caused by multiple dataset domains. To overcome these obstacles, a residual set abstraction (Res-SA) layer is proposed to efficiently scale the network in both width and depth, accommodating the requirements of various tasks. Additionally, a weight-entanglement-based one-shot NAS technique is developed to find optimal architectures for all tasks, allowing for task-shared parameters for efficient storage deployment and task-specific parameters for learning task-related features. To enhance the training process of Poly-PC, a task-prioritization-based gradient balance algorithm is introduced, leveraging task prioritization to reconcile conflicting gradients and ensure high performance for all tasks. These techniques result in Poly-PC optimized models that have fewer total FLOPs and parameters while outperforming previous methods. Furthermore, Poly-PC enables incremental learning and prevents catastrophic forgetting when adapted to a new task.