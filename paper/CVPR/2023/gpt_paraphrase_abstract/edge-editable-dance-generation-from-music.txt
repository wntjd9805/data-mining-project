The study presents a new method called Editable Dance GEneration (EDGE) for creating realistic and physically-plausible dances that are synchronized with input music. EDGE combines a transformer-based diffusion model with Jukebox, a music feature extractor, to allow for powerful editing capabilities in dance creation, such as joint-wise conditioning and in-betweening. The researchers also introduce a new metric to evaluate the physical plausibility of the generated dances. The method is extensively evaluated using quantitative metrics and a large-scale user study, demonstrating a significant improvement over previous state-of-the-art methods. Qualitative samples can be accessed on the researchers' website.