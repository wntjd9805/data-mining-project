Video super-resolution (VSR) models are computationally expensive, making them unsuitable for resource-limited devices like smartphones and drones. The inefficiency is mainly due to redundant filters present in existing VSR models. To address this issue, we introduce a structured pruning scheme called Structured Sparsity Learning (SSL) specifically tailored for VSR. SSL includes pruning schemes for key components in VSR models, such as residual blocks, recurrent networks, and upsampling networks. We propose the Residual Sparsity Connection (RSC) scheme to remove pruning restrictions and retain restoration information in residual blocks of recurrent networks. For upsampling networks, we develop a pixel-shuffle pruning scheme to ensure accurate feature channel-space conversion. Additionally, we identify that pruning errors are amplified as hidden states propagate in recurrent networks. To mitigate this problem, we introduce Temporal Finetuning (TF). Through extensive experiments, we demonstrate that SSL outperforms recent methods both quantitatively and qualitatively. The code for SSL is available at https://github.com/Zj-BinXia/SSL.