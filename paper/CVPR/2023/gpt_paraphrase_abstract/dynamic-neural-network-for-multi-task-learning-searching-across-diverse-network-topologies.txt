This paper introduces a novel framework for multi-task learning (MTL) that focuses on finding optimized structures for diverse tasks using different graph topologies and sharing features among tasks. The framework includes a restricted directed acyclic graph (DAG)-based central network with read-in/read-out layers to create task-adaptive structures while controlling search space and time. Through a three-stage training process, a single optimized network is searched for, which can serve as multiple task adaptive sub-networks. To ensure a compact and discrete network, the paper proposes a flow-based reduction algorithm and a squeeze loss during training. The performance of the optimized network is evaluated on various public MTL datasets, demonstrating superior results compared to existing methods. Additionally, an extensive ablation study confirms the effectiveness of the sub-module and schemes within the proposed framework.