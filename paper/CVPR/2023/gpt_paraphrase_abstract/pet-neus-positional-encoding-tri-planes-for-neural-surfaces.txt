We enhance the existing neural surface reconstruction method, NeuS, by incorporating three new components. Firstly, we adopt the tri-plane representation from EG3D and combine it with MLPs to represent signed distance fields, resulting in a more expressive data structure that may introduce noise in the reconstructed surface. Secondly, we employ a novel positional encoding technique with learnable weights to address the noise issue during the reconstruction process. This involves dividing the tri-plane features into multiple frequency scales and modulating them using sine and cosine functions of varying frequencies. Lastly, we utilize learnable convolution operations on the tri-plane features through self-attention convolution to generate features with different frequency bands. Through experiments, we demonstrate that our method, PET-NeuS, achieves high-fidelity surface reconstruction on standard datasets. By comparing with the NeuS baseline using the Chamfer metric as a measure of surface reconstruction quality, we observe a 57% improvement on Nerf-synthetic (0.84 compared to 1.97) and a 15.5% improvement on DTU (0.71 compared to 0.84). Qualitative evaluation also showcases our method's ability to better control high-frequency noise interference.