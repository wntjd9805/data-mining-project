This study introduces a new architecture, called Omni-SR, to address the limitations of the lightweight ViT framework in image super-resolution. The ViT framework's uni-dimensional self-attention modeling and homogeneous aggregation scheme restrict its effective receptive field (ERF) in capturing comprehensive interactions from both spatial and channel dimensions. To overcome these drawbacks, two enhanced components are proposed in the Omni-SR architecture.The first component is the Omni Self-Attention (OSA) block, which is based on the dense interaction principle. This block allows for simultaneous modeling of pixel-interaction from both spatial and channel dimensions, enabling the exploration of potential correlations across the omni-axis. By combining OSA with mainstream window partitioning strategies, improved performance can be achieved within reasonable computational budgets.The second component is a multi-scale interaction scheme designed to mitigate sub-optimal ERF in shallow models. This scheme facilitates local propagation and meso-/global-scale interactions, resulting in an omni-scale aggregation building block.Extensive experiments demonstrate that the proposed Omni-SR architecture achieves record-high performance on lightweight super-resolution benchmarks, such as Urban100 Ã—4 with only 792K parameters, reaching a peak of 26.95dB. The code for Omni-SR is publicly available on GitHub at https://github.com/Francis0625/Omni-SR.