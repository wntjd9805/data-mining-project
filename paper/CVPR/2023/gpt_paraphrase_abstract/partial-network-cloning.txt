This paper introduces a new task called Partial Network Cloning (PNC) that allows for partial knowledge transfer from pre-trained models. Unlike previous methods that update all or some of the parameters in the target network during knowledge transfer, PNC conducts partial parametric "cloning" by transferring a module from a source network to the target network without modifying its parameters. This transferred module adds additional functionality to the target network, such as the ability to infer on new classes. If needed, the cloned module can be easily removed from the target network while preserving its original parameters and competence. The paper presents a novel learning scheme that identifies the component to be cloned from the source network and determines the optimal position for inserting it into the target network. Experimental results on multiple datasets demonstrate that our method achieves a significant improvement of 5% in accuracy and 50% in locality compared to parameter-tuning based methods. The code for our method is available at https://github.com/JngwenYe/PNCloning.