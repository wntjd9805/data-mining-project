This paper addresses the issue of low spatial resolution in direct time-of-flight (dToF) sensors used for on-device 3D sensing. Due to manufacturing limitations, the dToF data has a low resolution and requires a super-resolution step before use in downstream tasks. The authors propose a solution to this problem by fusing the low-resolution dToF data with high-resolution RGB guidance. Unlike conventional approaches, the fusion is done in a multi-frame manner to reduce spatial ambiguity. Additionally, the authors utilize depth histogram information provided by dToF sensors to further alleviate spatial ambiguity. To evaluate their models and provide a dataset, the authors introduce Dy-DToF, a synthetic RGB-dToF video dataset featuring dynamic objects and a realistic dToF simulator. They believe that their methods and dataset will benefit the broader community as dToF depth sensing becomes more popular on mobile devices. The code and data are publicly available at the given GitHub link.