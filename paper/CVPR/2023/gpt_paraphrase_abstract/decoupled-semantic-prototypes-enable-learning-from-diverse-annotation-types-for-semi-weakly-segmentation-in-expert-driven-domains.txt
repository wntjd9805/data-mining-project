The use of images and pixel-wise annotations has allowed us to develop scalable segmentation solutions for natural domains. However, applying these solutions to expert-driven domains such as microscopy or medical healthcare is challenging due to the limited availability of domain experts to provide pixel-wise annotations. To address this, we need training strategies that can handle diverse annotation types and do not rely solely on costly pixel-wise annotations. In this study, we evaluate existing training algorithms in the field of organelle segmentation and find that they are not effective in utilizing diverse annotation types. Based on our findings, we propose a new training method called Decoupled Semantic Prototypes (DSP) for semantic segmentation. DSP enables learning from various annotation types such as image-level, point, bounding box, and pixel-wise annotations, resulting in significant improvements in accuracy compared to existing semi-weakly supervised segmentation solutions.