This paper investigates the problem of adapting point cloud semantic segmentation from synthetic to real data. Synthetic data is clean and complete, while real-world point clouds often contain unexpected noise due to environmental factors. As a result, models trained on synthetic data may fail to perform well on real data. Previous adversarial training methods are less effective in dealing with this noise. To address this issue, we propose a novel approach called "Adversarial Masking" that learns to mask the source points during the adaptation process. Our method includes a learnable masking module that takes source features and 3D coordinates as inputs. We incorporate the Gumbel-Softmax operation into the masking module, allowing it to generate binary masks that can be trained end-to-end using gradient back-propagation. Through adversarial training, the masking module learns to generate source masks that mimic the pattern of irregular target noise, reducing the domain gap. The name "Adversarial Masking" signifies the interdependence and cooperation between adversarial training and the learnable masking module in mitigating the domain gap. Experimental results on two synthetic-to-real adaptation benchmarks demonstrate the effectiveness of our proposed method.