Retrieval augmented models have gained popularity in computer vision tasks, following their success in NLP problems. These models aim to improve recognition capabilities by retrieving similar examples from an external memory set. In this study, we propose an attention-based memory module that determines the importance of each retrieved example. Our method eliminates the influence of irrelevant examples and retains those that are helpful for the input query. We also explore different approaches to constructing the memory dataset. Through extensive experiments, we demonstrate the advantages of using a large-scale memory dataset consisting of 1 billion image-text pairs and evaluate the performance of different memory representations. Our method achieves state-of-the-art accuracies in ImageNet-LT, Places-LT, and Webvision datasets across three classification tasks: long-tailed recognition, learning with noisy labels, and fine-grained classification.