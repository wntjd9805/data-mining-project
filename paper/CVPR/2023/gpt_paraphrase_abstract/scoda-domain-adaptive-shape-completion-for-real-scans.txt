Completing 3D shapes from point clouds, especially from real-world scans, is a challenging task due to the lack of ground truth data. Existing methods primarily focus on benchmarking using synthetic data, such as computer-aided design models. However, the disparity between synthetic and real data limits the applicability of these methods. Therefore, we introduce a new task called SCoDA, which aims to adapt real scan shape completion using synthetic data. To facilitate this task, we contribute a dataset called ScanSalon, consisting of intricately designed 3D models based on scans. To tackle SCoDA, we propose a novel approach for knowledge transfer using cross-domain feature fusion, as well as a robust learning framework that ensures volume consistency through self-training. Extensive experiments demonstrate the effectiveness of our method, resulting in a 6% to 7% improvement in mean intersection over union (mIoU).