This paper focuses on post-training quantization (PTQ) for image super resolution, specifically for deploying SR networks on mobile devices. Existing works in model quantization often rely on quantization-aware training, which requires a complete dataset and expensive computational overhead. In contrast, this paper explores PTQ using only a small number of unlabeled calibration images. Since SR models aim to maintain texture and color information, the distribution of activations in these models is long-tailed, asymmetric, and highly dynamic compared to classification models. To address this, the paper introduces a density-based dual clipping method to remove outliers by analyzing the asymmetric bounds of activations. Additionally, a novel pixel-aware calibration method is presented, leveraging the supervision of the full-precision model to accommodate the highly dynamic range of different samples.Extensive experiments demonstrate that the proposed method outperforms existing PTQ algorithms on various models and datasets. For example, when quantizing EDSRÃ—4 to 4-bit with 100 unlabeled images, there is a significant 2.091 dB increase on the Urban100 benchmark. The code for this method is available in both PyTorch and MindSpore.