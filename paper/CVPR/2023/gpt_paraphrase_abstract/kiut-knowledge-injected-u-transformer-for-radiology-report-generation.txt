We propose a Knowledge-injected U-Transformer (KiUT) for radiology report generation. This method aims to generate accurate and coherent paragraphs from X-ray images, reducing the burden on radiologists. While previous image caption methods have been successful in natural images, medical image reports require knowledge of vision, language, and medical terminology. Our approach incorporates multi-level visual representation and adapts information using contextual and clinical knowledge for word prediction. We introduce a U-connection schema to model interactions between different modalities and use a symptom graph and injected knowledge distiller to assist report generation. Our experiments demonstrate that KiUT outperforms existing methods on benchmark datasets (IU-Xray and MIMIC-CXR) and highlight the advantages of our architecture and the complementary benefits of the injected knowledge.