Recent advancements in human motion prediction systems have shown the effectiveness of encoding temporal dynamics within the frequency domain. To achieve this, the motion representation is often converted from the original pose space to the frequency space. This paper introduces two approaches for effective frequency representation learning in order to improve the robustness of motion prediction. These approaches are summarized as "decompose more" and "aggregate better". Based on these insights, the paper proposes two powerful units that tackle the frequency representation learning task. The first unit, called the frequency decomposition unit, separates multi-view frequency representations from the input body motion by embedding its frequency features into multiple spaces. The second unit, known as the feature aggregation unit, utilizes intra-space and inter-space feature aggregation layers to gather comprehensive frequency representations from these spaces for accurate human motion prediction. The proposed model is evaluated on large-scale datasets and is found to outperform state-of-the-art methods by significant margins: 8%∼12% on Human3.6M, 3%∼7% on CMU MoCap, and 7%∼10% on 3DPW.