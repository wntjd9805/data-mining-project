The goal of weakly supervised temporal sentence grounding is to identify the specific moments in a video that correspond to a given language description. Existing approaches use negative video-language pairs as training samples and aim to generate positive proposals that are distinct from the negatives. However, this approach can lead to incorrect ground truth matches due to the complexity of video structures. To address this issue, we propose a self-training technique that utilizes uncertainty to guide the learning process. Our self-training method involves teacher-student mutual learning with weak-strong augmentation, which allows the teacher network to generate more reliable outputs for the student network to learn from. To prevent error accumulation, we incorporate two techniques: a Bayesian teacher network that uses uncertainty as a weight to suppress noisy signals, and cycle consistency through temporal data augmentation for mutual learning between the networks. Experimental results on Charades-STA and ActivityNet Captions datasets demonstrate the effectiveness of our method. Furthermore, we show that our self-training technique can improve the performance of various backbone methods.