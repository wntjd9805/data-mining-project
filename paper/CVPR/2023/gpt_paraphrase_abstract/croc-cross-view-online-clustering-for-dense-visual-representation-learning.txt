Learning dense visual representations without labels is a difficult task, especially when dealing with scene-centric data. To address this challenge, we propose a solution called CrOC, which combines a cross-view consistency objective with an online clustering mechanism. This approach allows us to discover and segment the semantics of different views without relying on hand-crafted priors or cumbersome pre-processing steps. The key innovation of CrOC is that it operates on the features of both views simultaneously, avoiding the problem of missing content in one view or ambiguous matching of objects between views. This leads to improved generalizability and performance on linear and unsupervised segmentation transfer tasks across various datasets, as well as video object segmentation.We have made our code and pre-trained models publicly available at https://github.com/stegmuel/CrOC.