This paper addresses the issue of federated semi-supervised learning (FSSL) in scenarios where only a few clients have labeled data (labeled clients) and the rest have unlabeled data (unlabeled clients). Existing methods have attempted to handle the challenges posed by non-independent and identically distributed data (Non-IID) settings, but they often rely on standard pseudo labeling or consistency regularization techniques on unlabeled clients, which can be affected by imbalanced class distribution. Consequently, problems in FSSL remain unresolved. To address this, we propose a solution called ClassBalanced Adaptive Pseudo Labeling (CBAFed) that approaches FSSL from the perspective of pseudo labeling. CBAFed incorporates two key elements. Firstly, it employs a fixed pseudo labeling strategy to mitigate the problem of catastrophic forgetting, ensuring that a fixed set of information from unlabeled data is retained at the start of each communication round during unlabeled client training. Secondly, CBAFed designs class balanced adaptive thresholds based on the empirical distribution of all training data in local clients, promoting a balanced training process. To further enhance the model's performance, we introduce a residual weight connection in local supervised training and global model aggregation. Extensive experiments conducted on five datasets demonstrate the effectiveness of CBAFed. The code for implementing CBAFed can be found at https://github.com/minglllli/CBAFed.