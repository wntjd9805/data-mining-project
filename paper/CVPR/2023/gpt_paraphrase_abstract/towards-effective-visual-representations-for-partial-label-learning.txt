Recently, contrastive learning has improved the performance of partial-label learning (PLL) in vision tasks. PLL involves having access to only a set of ambiguous candidate labels for each training instance, without knowing the true label. Positive points are predicted using noisy pseudo-labels, while negative points often require large batches or momentum encoders, leading to unreliable similarity information and high computational overhead. This paper reevaluates the PiCO method, a state-of-the-art contrastive PLL method, and proposes a new framework called PaPi (Partial-label learning with a guided Prototypical classifier). PaPi improves representation learning and label disambiguation by guiding the optimization of a prototypical classifier using a linear classifier that shares the same feature encoder. This encourages the representation to reflect visual similarity between categories. PaPi requires only a few components from PiCO but in the opposite direction of guidance, eliminating the noise and computational resources required by the contrastive learning module. Experimental results show that PaPi outperforms other PLL methods on various image classification tasks.