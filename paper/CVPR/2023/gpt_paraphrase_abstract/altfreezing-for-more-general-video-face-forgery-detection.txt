Current models for detecting face forgery focus on either spatial artifacts (such as generative artifacts and blending) or temporal artifacts (such as flickering and discontinuity). However, these models often struggle to perform well when faced with out-domain artifacts. To address this issue, this paper proposes a new approach that combines both spatial and temporal artifact detection in one model using a spatiotemporal model (3D ConvNet). However, it is found that this approach may favor one type of artifact over the other. To overcome this, a novel training strategy called AltFreezing is introduced. AltFreezing divides the weights of the spatiotemporal network into two groups: spatial-related and temporal-related. These groups of weights are alternately frozen during training to ensure the model learns to detect both spatial and temporal features for distinguishing real and fake videos. Additionally, various video-level data augmentation techniques are employed to enhance the model's ability to generalize to unseen manipulations and datasets. Extensive experiments demonstrate that this framework outperforms existing methods in terms of generalization.