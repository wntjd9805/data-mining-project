Test time adaptation (TTA) is a technique used to adapt deep neural networks when faced with out-of-distribution test domain samples. In this scenario, the model can only access online unlabeled test samples and pre-trained models on the training domains. Initially, TTA is approached as a feature revision problem due to the domain gap between the source and target domains. Two measurements, namely alignment and uniformity, are used to address the test time feature revision.To ensure test time feature uniformity, a test time self-distillation strategy is proposed. This strategy guarantees consistency in the uniformity between representations of the current batch and all previous batches. On the other hand, test time feature alignment is achieved using a memorized spatial local clustering strategy. This strategy aligns the representations among the neighborhood samples for the upcoming batch.To tackle the issue of noisy labels, the entropy and consistency filters are introduced. These filters are used to select and drop potential noisy labels. The scalability and effectiveness of the proposed method are demonstrated through experiments conducted on four domain generalization benchmarks and four medical image segmentation tasks with various backbones. The results of these experiments show that the proposed method not only consistently improves the baseline performance but also outperforms existing state-of-the-art test time adaptation methods.