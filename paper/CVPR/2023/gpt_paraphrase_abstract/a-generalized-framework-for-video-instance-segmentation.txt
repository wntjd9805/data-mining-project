The video instance segmentation (VIS) community is facing a new challenge in handling long videos with complex and occluded sequences. However, current methods have limitations in addressing this challenge due to the discrepancy between training and inference. To bridge this gap effectively, we propose a Generalized framework for VIS called GenVIS. GenVIS achieves state-of-the-art performance on challenging benchmarks without the need for complex architectures or additional post-processing. The key contribution of GenVIS is its learning strategy, which involves a query-based training pipeline for sequential learning with a novel target label assignment. We also introduce a memory that effectively captures information from previous states. By focusing on building relationships between separate frames or clips, GenVIS can be executed flexibly in both online and semi-online manner. We evaluate our approach on popular VIS benchmarks, achieving state-of-the-art results on YouTube-VIS 2019/2021/2022 and Occluded VIS (OVIS). Notably, we significantly outperform the state-of-the-art on the long VIS benchmark (OVIS), improving 5.6 AP with a ResNet-50 backbone. The code for GenVIS is available at https://github.com/miranheo/GenVIS.