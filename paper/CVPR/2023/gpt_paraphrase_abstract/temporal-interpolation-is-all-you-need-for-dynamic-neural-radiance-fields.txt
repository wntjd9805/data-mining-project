We present a new approach for training spatiotemporal neural radiance fields in dynamic scenes using temporal interpolation of feature vectors. We offer two methods for feature interpolation: one based on neural networks and the other on grids. In the neural representation, we extract features from space-time inputs using multiple neural network modules and interpolate them based on time frames. This approach effectively captures features across short-term and long-term time ranges. In the grid representation, we learn space-time features using four-dimensional hash grids, resulting in significantly reduced training time compared to previous neural-net-based methods. The grid representation achieves training speeds over 100 times faster while maintaining rendering quality. By combining static and dynamic features and incorporating a simple smoothness term, we further improve the performance of our models. Despite the simplicity of our model architectures, our method achieves state-of-the-art performance in both rendering quality (for the neural representation) and training speed (for the grid representation).