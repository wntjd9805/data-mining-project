In recent years, there have been efforts to improve the ability of vision models to adapt to new domains and environments that were not seen during training. This is especially important for ensuring fairness and inclusivity in computer vision. This paper focuses on the problem of geographic robustness and makes three main contributions. Firstly, a large-scale dataset called GeoNet is introduced, which includes benchmarks for scene recognition, image classification, and universal adaptation in different geographic locations. Secondly, the paper examines the distribution shifts that occur in geographic adaptation and suggests that these shifts primarily arise from variations in scene context, object design, and label distribution across different geographies. Lastly, the paper evaluates several unsupervised domain adaptation algorithms and architectures on GeoNet, finding that they are not sufficient for geographic adaptation. Additionally, it is discovered that large-scale pre-training using large vision models does not lead to geographic robustness. The GeoNet dataset is publicly available at https://tarun005.github.io/GeoNet.