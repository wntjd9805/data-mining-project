We present a novel method for generating a high-quality 3D head avatar from a single RGB video captured in real-world conditions. Our approach combines a parametric face model with a neural radiance field to achieve realistic facial expressions and head poses that can be controlled by the user. To enhance the synthesis of out-of-model expressions and prevent excessive smoothing, we propose predicting local features based on the geometry of the face model. These features are driven by the deformation of the face model and interpolated in 3D space to determine the volumetric radiance at specific points. We also demonstrate the importance of using a Convolutional Neural Network in the UV space to incorporate spatial context and generate representative local features. Extensive experiments show that our method produces high-quality avatars with accurate expression-dependent details, good generalization to unseen expressions, and superior renderings compared to existing approaches.