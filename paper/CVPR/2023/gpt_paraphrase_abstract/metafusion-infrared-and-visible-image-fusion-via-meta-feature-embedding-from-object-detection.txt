This paper proposes a method for fusing infrared and visible images using meta-feature embedding from object detection. The goal is to improve the texture details for object detection and enhance the fusion process by incorporating object semantic information. The feature gap between these two tasks is a challenge, but the proposed method addresses this by designing a meta-feature embedding model that generates object semantic features compatible with fusion features. This model is optimized through meta learning. Additionally, a mutual promotion learning approach is implemented to enhance the performance of both fusion and detection tasks. The effectiveness of the proposed method is demonstrated through comprehensive experiments on three public datasets. The code and model for this method are available at: https://github.com/wdzhao123/MetaFusion.