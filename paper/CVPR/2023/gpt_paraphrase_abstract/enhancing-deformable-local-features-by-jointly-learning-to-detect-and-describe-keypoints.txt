Local feature extraction is a widely used method in computer vision for tasks like image matching and retrieval. However, current methods often assume that images only undergo affine transformations and ignore more complex deformations. Even approaches tailored for non-rigid correspondence still rely on keypoint detectors designed for rigid transformations, limiting their effectiveness. To address this issue, we present DALF (Deformation-Aware Local Features), a novel network that jointly detects and describes keypoints while considering deformable surfaces. Our network incorporates feature fusion to ensure distinctiveness and invariance of descriptors. Through experiments on real deforming objects, we demonstrate that our method outperforms previous approaches, achieving an 8% improvement in matching scores. Additionally, our approach enhances the performance of deformable object retrieval and non-rigid 3D surface registration. Training, inference, and applications code for DALF are publicly available at verlab.dcc.ufmg.br/descriptors/dalf_cvpr23.