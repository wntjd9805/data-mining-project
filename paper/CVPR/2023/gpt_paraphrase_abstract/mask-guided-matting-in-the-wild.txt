Mask-guided matting has proven to be more practical than traditional trimap-based methods. Instead of relying on a trimap, the mask-guided approach utilizes a readily available coarse mask to generate a precise alpha matte. In order to expand the applicability of mask-guided matting to real-world scenarios, which involve complex contexts and a wide range of categories, we propose a straightforward yet effective learning framework. This framework is based on two key insights: 1) training a generalized matting model that can better comprehend the provided mask guidance, and 2) utilizing weak supervision datasets, such as instance segmentation datasets, to address the limited diversity and scale of existing matting datasets. Through extensive experiments on various benchmarks, including a newly proposed synthetic benchmark called Composition-Wild, as well as existing natural datasets, we demonstrate the superiority of our proposed method. Additionally, we showcase promising results in new practical applications, such as panoptic matting and mask-guided video matting, highlighting the versatility and potential of our model.