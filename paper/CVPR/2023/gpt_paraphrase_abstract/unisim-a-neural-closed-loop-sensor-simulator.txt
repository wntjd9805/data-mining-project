Testing self-driving vehicles to ensure their safety is crucial, but it can be challenging to generate enough diverse and rare scenarios to accurately evaluate their performance. While previously recorded driving logs can provide valuable data, they need to be modified to simulate closed-loop scenarios where the vehicle interacts with other actors in real-time. In this paper, we introduce UniSim, a neural sensor simulator that can convert a single recorded log into a realistic multi-sensor simulation. UniSim reconstructs the static background and dynamic actors in the scene, simulates LiDAR and camera data from new viewpoints, and incorporates learnable priors and convolutional networks to handle unseen regions. Our experiments demonstrate that UniSim can generate realistic sensor data with minimal domain gap for downstream tasks. With UniSim, we can now evaluate autonomy systems in closed-loop on safety-critical scenarios, bridging the gap between simulated and real-world testing.