There is currently a lack of general-purpose tools to evaluate the differences between datasets in computer vision. To address this, we propose using Distributions of Neuron Activations (DNAs) to represent images and datasets. DNAs fit distributions, such as histograms or Gaussians, to the activations of neurons in a pre-trained feature extractor. This feature extractor is consistent across all datasets, allowing for accurate representation. By comparing two DNAs, we can assess the extent of differences between datasets and customize the measurement of distances based on specific attributes of interest. Additionally, DNAs are compact, requiring less than 15 megabytes to represent datasets of any size. We demonstrate the effectiveness of DNAs through various tasks, including conditional dataset comparison, synthetic image evaluation, and transfer learning. These tasks span diverse datasets, such as synthetic cat images, celebrity faces, and urban driving scenes.