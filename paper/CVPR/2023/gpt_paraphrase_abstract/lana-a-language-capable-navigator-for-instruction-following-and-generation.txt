Recently, there have been significant advancements in visual-language navigation (VLN), where robots follow navigation instructions. However, existing research focuses mainly on interpreting instructions and creating basic navigation agents. In this article, we introduce LANA, a navigation agent capable of executing human-written commands and providing route descriptions to humans. LANA achieves this by learning instruction following and generation simultaneously using a single model. We use two encoders for route and language encoding, which are shared by two decoders for action prediction and instruction generation. This allows us to leverage knowledge from both tasks and capture task-specific characteristics. Through pretraining and fine-tuning, we optimize both instruction following and generation. Our empirical results show that LANA outperforms recent task-specific solutions in both instruction following and route description, with nearly half the complexity. Additionally, LANA can explain its behaviors and assist humans in wayfinding due to its language generation capability. This research aims to inspire the development of more reliable and socially intelligent navigation robots in the future.