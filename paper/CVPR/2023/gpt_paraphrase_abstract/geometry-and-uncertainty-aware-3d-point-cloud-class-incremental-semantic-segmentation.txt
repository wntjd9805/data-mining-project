Current methods for 3D point cloud semantic segmentation require training data for all classes at once and do not support scenarios where new categories are continuously discovered. Updating the model to accommodate new concepts requires significant memory storage and expensive re-training. To address these limitations, this paper proposes a class-incremental semantic segmentation approach for 3D point cloud data. Unlike 2D images, point clouds are disordered and unstructured, making it challenging to store and transfer knowledge without access to previous data. The paper tackles the issue of semantic shift, where previous and future classes are mistakenly treated as background, leading to a drop in performance on past classes. The proposed method includes a geometry-aware distillation module that transfers point-wise feature associations based on their geometric characteristics. Additionally, an uncertainty-aware pseudo-labeling scheme is developed to counter forgetting caused by semantic shift. This scheme eliminates noise in uncertain pseudo-labels by propagating labels within a local neighborhood. Extensive experiments on S3DIS and ScanNet datasets demonstrate impressive results comparable to the joint training strategy. The code for the proposed approach is available at the provided GitHub link.