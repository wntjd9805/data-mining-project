OrienterNet is a deep neural network that can accurately localize an image using 2D semantic maps, similar to how humans navigate using maps. Unlike existing algorithms that rely on complex and expensive 3D point clouds, OrienterNet matches a neural Bird's-Eye View with open and readily available maps from OpenStreetMap. It learns to perform semantic matching with various map elements, supervised only by camera poses. To facilitate this, a large dataset of images captured from different perspectives was created. OrienterNet demonstrates superior performance in both robotics and augmented reality scenarios and can be applied to new datasets. The code for OrienterNet is accessible on GitHub.