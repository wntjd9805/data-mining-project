Reconstructing visual experiences from brain activity is a valuable approach to comprehend how the brain perceives the world and establish connections between computer vision models and our visual system. Despite recent advancements in deep generative models for this purpose, achieving realistic and highly detailed image reconstruction remains challenging. To address this, we present a novel method called Stable Diffusion, which utilizes a latent diffusion model (LDM) to reconstruct images from functional magnetic resonance imaging (fMRI) data. The LDM, an efficient variant of diffusion models (DMs), maintains their strong generative performance while reducing computational costs. Additionally, we analyze the inner workings of the LDM by examining the roles of different components, such as the latent image vector Z, conditioning inputs C, and elements of the denoising U-Net, in relation to distinct brain functions. Our results demonstrate that our proposed method can reconstruct high-resolution images faithfully and efficiently, without the need for extensive training or fine-tuning of complex deep-learning models. From a neuroscientific perspective, we provide a quantitative understanding of the various components of the LDM. Overall, our study presents a promising approach for image reconstruction from brain activity and contributes to a better understanding of DMs. For more information, please visit our webpage at https://sites.google.com/view/stablediffusion-with-brain/.