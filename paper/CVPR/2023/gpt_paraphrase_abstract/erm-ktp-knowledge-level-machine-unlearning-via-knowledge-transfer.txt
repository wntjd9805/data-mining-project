Machine unlearning is a technique that enhances the privacy and security of machine learning applications. However, existing unlearning methods are either inefficient or unsuitable for complex Convolutional Neural Networks (CNNs). Additionally, approximate approaches pose security risks as they can produce the same contribution estimation for unrelated data points as the target data points. To address these issues, we propose a knowledge-level machine unlearning method called ERM-KTP. Our approach involves using an entanglement-reduced mask (ERM) structure to reduce knowledge entanglement during training. When unlearning is requested, we transfer knowledge from the original model for non-target data points to the unlearned model while preventing knowledge transfer for target data points using our knowledge transfer and prohibition (KTP) method. The result is an interpretable unlearned model where the ERM structure and crafted masks in KTP provide explicit explanations of the unlearning process. Extensive experiments demonstrate the effectiveness, efficiency, high fidelity, and scalability of the ERM-KTP method. The code for our proposed method is available at https://github.com/RUIYUN-ML/ERM-KTP.