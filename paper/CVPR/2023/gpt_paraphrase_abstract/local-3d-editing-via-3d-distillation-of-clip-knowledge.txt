The manipulation of 3D content is a significant task in computer vision, with various practical applications such as product design and cartoon generation. The use of Neural Radiance fields (NeRF) in 3D Generative Adversarial Networks (GANs) has allowed for the generation of photorealistic 3D-aware content. However, manipulating NeRF remains challenging due to issues such as degraded visual quality and the use of suboptimal control handles like 2D semantic maps.Text-guided manipulation has shown promise in 3D editing, but it often lacks precision in terms of localization. To address these problems, we propose a new approach called Local Editing NeRF (LENeRF), which enables fine-grained and localized manipulation using only text inputs. LENeRF incorporates three additional modules: the Latent Residual Mapper, the Attention Field Network, and the Deformation Network. These modules work together to manipulate 3D features by estimating a 3D attention field.The 3D attention field is learned in an unsupervised manner, leveraging the zero-shot mask generation capability of CLIP and applying it to the 3D space with multi-view guidance. We conducted diverse experiments and thorough evaluations, both quantitatively and qualitatively, to validate the effectiveness of LENeRF.In summary, our proposed LENeRF approach addresses the challenges of manipulating NeRF by enabling localized and fine-grained manipulation using only text inputs. Through the use of additional modules and an unsupervised learning approach, we achieve improved control and quality in 3D content manipulation.