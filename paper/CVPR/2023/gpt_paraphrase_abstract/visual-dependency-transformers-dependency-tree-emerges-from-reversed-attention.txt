Humans have the ability to extract structured representations from visual images, including identifying entities and their parts, as well as understanding the relationships between them. In order to replicate this capability, we introduce a model called DependencyViT, which can induce visual dependencies without the need for labeled data. We achieve this through a new neural operator called reversed attention, which captures long-range dependencies between image patches. This operator forms a dependency graph, where each child token attends to its parent tokens and sends information based on a normalized probability distribution. This design allows for the emergence of hierarchies and the progressive induction of a dependency tree. DependencyViT offers several advantages, including the ability to represent entities and their parts separately, dynamic visual pooling, and the ability to prune leaf nodes that contribute less to the model's performance. We also propose a lightweight version called DependencyViT-Lite to reduce computational and memory requirements. DependencyViT performs well in both self- and weakly-supervised pretraining on ImageNet, and demonstrates its effectiveness on various tasks such as part and saliency segmentation, recognition, and detection across multiple datasets.