Training a Neural Radiance Field (NeRF) without pre-computed camera poses is difficult. Recent advancements have shown that it is possible to optimize a NeRF and camera poses together in forward-facing scenes. However, these methods still struggle with significant camera movements. To address this challenge, we propose the incorporation of undistorted monocular depth priors. These priors are generated by adjusting scale and shift parameters during training, allowing us to constrain the relative poses between consecutive frames. Our approach utilizes novel loss functions to enforce this constraint. Experimental results on real-world indoor and outdoor scenes demonstrate that our method can handle challenging camera trajectories better than existing methods, offering improved quality in rendering novel views and more accurate pose estimation. For more information, please visit our project page at https://nope-nerf.active.vision.