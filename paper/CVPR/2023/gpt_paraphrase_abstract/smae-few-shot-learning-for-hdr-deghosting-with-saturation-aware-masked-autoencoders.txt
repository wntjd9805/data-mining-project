Generating high-quality High Dynamic Range (HDR) images from dynamic scenes has been extensively studied using Deep Neural Networks (DNNs). However, most existing DNN-based methods require a large amount of training data with ground truth, which is time-consuming and tedious to collect. To address this issue, few-shot HDR imaging aims to generate satisfactory images with limited data. However, current DNNs struggle with overfitting when trained on only a few images.In this study, we propose a novel semi-supervised approach called SSHDR, which consists of two stages of training. Unlike previous methods that directly recover content and remove ghosts simultaneously (a challenging optimization task), we first generate the content of saturated regions using a self-supervised mechanism. Then, we address the issue of ghosts through an iterative semi-supervised learning framework.Specifically, we treat saturated regions as mask-like Low Dynamic Range (LDR) input regions and introduce a Saturated Mask AutoEncoder (SMAE) to learn a robust feature representation and reconstruct a non-saturated HDR image. Additionally, we propose an adaptive pseudo-label selection strategy in the second stage to ensure the selection of high-quality HDR pseudo-labels and mitigate the impact of mislabeled samples.Experimental results demonstrate that our SSHDR approach outperforms state-of-the-art methods both quantitatively and qualitatively, across different datasets. It achieves appealing HDR visualization even with few labeled samples. Thus, our proposed method shows great potential in generating high-quality HDR images from dynamic scenes with limited training data.