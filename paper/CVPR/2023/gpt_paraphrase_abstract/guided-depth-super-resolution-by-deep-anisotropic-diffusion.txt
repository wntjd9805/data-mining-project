Super-resolution of depth images using guidance from RGB images is a problem of interest in various fields including robotics, medical imaging, and remote sensing. Although deep learning methods have shown promising results, recent studies have emphasized the importance of combining modern techniques with formal frameworks. In this study, we introduce a new approach that combines guided anisotropic diffusion with a deep convolutional network to advance the state-of-the-art in guided depth super-resolution. By leveraging the edge transfer and enhancement capabilities of diffusion along with the contextual reasoning abilities of modern networks, and incorporating a rigorous adjustment step to ensure fidelity to the source image, we achieve unprecedented results on three widely used benchmarks for guided depth super-resolution. Notably, our method outperforms other existing methods to the greatest extent at larger scales, such as Ã—32 scaling. We provide the source code to encourage reproducibility of our findings.