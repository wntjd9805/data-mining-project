The current state of vision-language pretraining (VLP) in the arts field achieves impressive results but is hindered by high training costs due to slow convergence and lengthy training time, particularly when working with large web datasets. The main challenge to training efficiency is the interdependence between the prediction rate (percentage of tokens for reconstruction) and corruption rate (percentage of corrupted tokens) in masked language modeling (MLM). In order to address this issue and expedite VLP convergence, we propose a new pre-training task called free language modeling (FLM). FLM allows for a 100% prediction rate with customizable corruption rates for each token, thereby eliminating the need to sacrifice a significant portion of output tokens for prediction loss. By enabling more flexible bidirectional contexts, FLM-trained models are able to learn better and faster within the same GPU time. Extensive experiments demonstrate that FLM achieves an impressive 2.5Ã— reduction in pretraining time compared to MLM-based methods, while maintaining competitive performance in both vision-language understanding and generation tasks. The code for FLM will be made publicly available at https://github.com/TencentARC/FLM.