Test-Time-Training (TTT) is an approach used to address the problem of out-of-distribution (OOD) data by adapting a pre-trained model to handle distribution shifts that occur during testing. In this study, we propose a method called Activation Matching (ActMAD) for performing this adaptation. ActMAD involves analyzing the activations of the model and aligning the activation statistics of the OOD test data with those of the training data. Unlike existing methods that focus on modeling the distribution of entire channels in the final layer of the feature extractor, ActMAD models the distribution of each feature in multiple layers across the network. This approach provides more detailed supervision and leads to superior performance on CIFAR-100C and Imagenet-C datasets. Furthermore, ActMAD is not limited to image classification tasks and can be applied to other architectures and tasks. For instance, when evaluating a KITTI-trained object detector on KITTI-Fog, ActMAD achieves a 15.4% improvement over previous approaches. Importantly, ActMAD demonstrates its applicability in realistic scenarios where online adaptation is required, and it achieves high performance even with limited data.