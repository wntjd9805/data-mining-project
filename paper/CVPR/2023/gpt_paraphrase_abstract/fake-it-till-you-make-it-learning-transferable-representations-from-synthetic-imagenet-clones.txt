Recent advancements in image generation models, such as Stable Diffusion, have demonstrated impressive capabilities in generating realistic images based on text prompts. This raises the question of whether these models could render real images unnecessary for training image prediction models. In this study, we aim to address a portion of this thought-provoking question by examining the necessity of real images in training models for ImageNet classification.Instead of using actual images, we solely rely on the class names used to construct the dataset. Our investigation focuses on the ability of Stable Diffusion to generate synthetic clones of ImageNet and evaluates their utility in training classification models from scratch. Through our research, we demonstrate that with minimal and class-agnostic prompt engineering, these ImageNet clones can significantly reduce the performance gap between models trained on synthetic images and those trained on real images. This holds true across various standard classification benchmarks considered in our study.Furthermore, we emphasize the strong generalization capabilities exhibited by models trained on synthetic images. They perform comparably to models trained on real data for transfer tasks, highlighting the potential of synthetic image training in achieving robust performance. For more information, please visit our project page at https://europe.naverlabs.com/imagenet-sd.