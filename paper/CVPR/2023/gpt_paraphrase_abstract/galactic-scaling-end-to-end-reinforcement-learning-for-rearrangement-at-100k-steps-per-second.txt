We introduce Galactic, a simulation and reinforcement learning framework for robotic mobile manipulation in indoor settings. Our framework focuses on the task of object rearrangement, where a Fetch robot is placed in a home environment and tasked with picking up objects, navigating to a target location, and placing the objects there. One key feature of Galactic is its speed. It achieves a simulation speed of over 421,000 steps-per-second (SPS) on an 8-GPU node, which is 54 times faster than Habitat 2.0. Additionally, Galactic optimizes the entire rendering, physics, and RL process to avoid any bottlenecks that could slow down training. In terms of simulation and RL speed, Galactic achieves over 108,000 SPS, which is 88 times faster than Habitat 2.0. These significant speed improvements not only reduce the training time for existing experiments but also enable a new scale of experiments. For example, Galactic can train a mobile pick skill with over 80% accuracy in under 16 minutes, while it takes over 24 hours in Habitat 2.0. Furthermore, we conducted the largest-scale experiment to date for rearrangement using Galactic, accumulating 5 billion steps of experience in just 46 hours, equivalent to 20 years of robot experience. This led to a single neural network achieving an 85% success rate in GeometricGoal rearrangement, compared to 0% success in Habitat 2.0 using the same approach.The code for Galactic is available on GitHub at github.com/facebookresearch/galactic.