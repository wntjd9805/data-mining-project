Recent advancements in two-dimensional convolutional neural networks (2D CNNs) have highlighted the importance of large kernels. However, when applying these large convolutional kernels directly to three-dimensional CNNs (3D CNNs), significant challenges arise. Module designs that have been successful in 2D networks, including the popular depth-wise convolution, surprisingly prove to be ineffective in 3D networks. To tackle this crucial challenge, we propose an alternative approach called spatial-wise partition convolution and its accompanying large-kernel module. This approach overcomes the optimization and efficiency issues faced by naive 3D large kernels. Our 3D CNN network, known as LargeKernel3D, demonstrates substantial improvements in 3D tasks such as semantic segmentation and object detection. In the ScanNetv2 semantic segmentation benchmark, LargeKernel3D achieves an impressive mean intersection over union (mIoU) score of 73.9%. Similarly, in the nuScenes object detection benchmark, it achieves a high score of 72.8% in the NDS category, securing the top rank on the nuScenes LIDAR leaderboard. By employing a simple multi-modal fusion technique, the performance of LargeKernel3D further improves to 74.2% NDS. Additionally, LargeKernel3D can be scaled up to a kernel size of 17x17x17 for Waymo 3D object detection. This is the first demonstration that large kernels are both feasible and essential for 3D visual tasks. Our code and models are available on GitHub at github.com/dvlab-research/LargeKernel3D.