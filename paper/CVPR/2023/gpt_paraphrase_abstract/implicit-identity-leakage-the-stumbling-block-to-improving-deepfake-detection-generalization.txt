The generalization ability of binary classifiers for deepfake detection is analyzed in this study. It is found that the hinderance to their generalization is caused by the unexpected learned identity representation on images. This phenomenon, called Implicit Identity Leakage, has been qualitatively and quantitatively verified across different deep neural networks (DNNs). Building on this understanding, a simple yet effective method called the ID-unaware Deepfake Detection Model is proposed to mitigate the influence of this phenomenon. Extensive experiments demonstrate that the proposed method surpasses the current state-of-the-art in both within-dataset and cross-dataset evaluations. The code for the method is accessible at https://github.com/megvii-research/CADDM.