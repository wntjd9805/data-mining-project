This study addresses the challenging problem of recovering motion from blur, also known as joint deblurring and interpolation or blur temporal super-resolution. The main challenges in this area are two-fold: firstly, existing methods have room for improvement in terms of visual quality even on synthetic datasets, and secondly, they struggle to generalize well to real-world data. To overcome these challenges, the authors propose a blur interpolation transformer (BiT) that effectively captures the underlying temporal correlation present in blur. The proposed BiT utilizes multi-scale residual Swin transformer blocks and incorporates dual-end temporal supervision and temporally symmetric ensembling strategies to generate accurate features for rendering time-varying motion. Furthermore, the authors collect a novel real-world dataset of one-to-many blur-sharp video pairs using a hybrid camera system. Experimental results demonstrate that BiT outperforms state-of-the-art methods on the public dataset Adobe240. Additionally, the authors show that the proposed real-world dataset significantly improves the model's ability to generalize to real blurry scenarios. The code and data for this study are available at https://github.com/zzh-tech/BiT.