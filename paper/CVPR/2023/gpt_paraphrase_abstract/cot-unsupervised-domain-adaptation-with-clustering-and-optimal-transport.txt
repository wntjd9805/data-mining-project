Unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain. Traditionally, UDA focuses on aligning the distribution between the source and target domains at a global level to ensure effective knowledge transfer. However, recent studies have highlighted the significance of local-level alignment and proposed using Optimal Transport (OT) theory to construct instance-pair alignment. Unfortunately, existing OT-based UDA approaches have limitations in handling class imbalance challenges and require heavy computation when dealing with large-scale training scenarios. To address these issues, we propose a novel algorithm called Clustering-based Optimal Transport (COT). COT formulates the alignment procedure as an Optimal Transport problem and creates a mapping between clustering centers in the source and target domains in an end-to-end manner. By aligning the clustering centers, COT effectively mitigates the negative impact of class imbalance while reducing computation costs. Empirical results demonstrate that COT achieves state-of-the-art performance on authoritative benchmark datasets.