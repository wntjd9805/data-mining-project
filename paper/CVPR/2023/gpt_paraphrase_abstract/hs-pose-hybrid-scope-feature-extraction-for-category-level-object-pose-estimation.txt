This paper addresses the challenge of estimating the pose of objects at the category level, which is difficult due to the variations in shape within categories. Existing methods that utilize 3D graph convolution (3D-GC) to extract local geometric features have limitations for complex shapes and are sensitive to noise. Additionally, the scale and translation invariance of 3D-GC restrict the perception of an object's size and translation information. To overcome these limitations, we propose a new network structure called the HS-layer. This layer extends 3D-GC to extract hybrid scope latent features from point cloud data, enabling the perception of both local-global geometric structure and global information, while being robust to noise and encoding size and translation information. Our experiments demonstrate that replacing the 3D-GC layer with the proposed HS-layer in the baseline method (GPV-Pose) leads to a significant improvement, with performance increases of 14.5% on the 5◦2cm metric and 10.3% on IoU75. Our method outperforms state-of-the-art methods by a large margin (8.3% on 5◦2cm, 6.9% on IoU75) on the REAL275 dataset, and it operates in real-time (50 FPS).