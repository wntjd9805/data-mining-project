This paper introduces a new approach to video compression called multi-mode video compression (MMVC). The goal of MMVC is to improve upon the limitations of existing learning-based video compression methods by adapting to different motion patterns and entropy models. The proposed framework utilizes multiple modes for feature domain prediction, including ConvLSTM-based prediction, optical flow conditioned prediction, and feature propagation. These modes are designed to handle a wide range of scenarios, from static scenes to dynamic scenes with a moving camera. Temporal prediction is performed on spatial block-based representations of the video, and both dense and sparse post-quantization residual blocks are considered for entropy coding. Optional run-length coding is applied to sparse residuals to further enhance compression rates. The method employs a dual-mode entropy coding scheme guided by a binary density map, which significantly reduces the compression rate without incurring substantial additional costs. The proposed scheme is evaluated using popular benchmarking datasets and compared to state-of-the-art compression methods and standard codecs. The results demonstrate that the MMVC method achieves better or competitive performance in terms of PSNR and MS-SSIM metrics.