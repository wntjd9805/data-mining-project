Existing methods for feature matching and pose estimation typically follow a two-stage process, first finding matches and then estimating the pose. However, these methods often overlook the geometric relationships between these two tasks, resulting in limited efficiency or accuracy. In contrast, our proposed approach, the iterative matching and pose estimation framework (IMP), takes advantage of the geometric connections between the tasks. We leverage a geometry-aware recurrent attention-based module that simultaneously outputs sparse matches and camera poses. In each iteration, we embed geometric information into the module using a pose-consistency loss, allowing it to progressively predict geometry-aware matches. Additionally, we introduce an efficient version of IMP, called EIMP, which dynamically discards keypoints without potential matches. This avoids redundant updating and significantly reduces the quadratic time complexity of attention computation in transformers. Experimental results on YFCC100m, Scannet, and Aachen Day-Night datasets demonstrate that our proposed method surpasses previous approaches in terms of accuracy and efficiency. The code for our method is available at https://github.com/feixue94/imp-release.