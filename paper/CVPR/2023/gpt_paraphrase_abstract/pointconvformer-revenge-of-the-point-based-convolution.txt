We present PointConvFormer, a new component for deep network architectures that operate on point cloud data. PointConvFormer combines the concepts of point convolution and Transformers, leveraging attention mechanisms to modify convolutional weights based on the differences in features between neighboring points. This approach maintains the invariances of point convolution while allowing for the selection of relevant points in the neighborhood. PointConvFormer is well-suited for tasks that require detailed point-level information, such as segmentation and scene flow estimation. We conducted experiments on various datasets and compared PointConvFormer to traditional convolutions, Transformers, and voxelized sparse convolution methods. Our results demonstrate that PointConvFormer achieves a favorable balance between accuracy and speed. Moreover, visualizations reveal that PointConvFormer performs similarly to convolution on flat areas and exhibits stronger neighborhood selection effects on object boundaries, combining the advantages of both approaches. The code for PointConvFormer will be made available.