We present a unique framework for localizing anomalies in videos, providing understandable explanations for the system's decisions. Our approach involves learning general object and motion representations using deep networks, which are then used to construct a location-dependent model for each scene. This model can effectively detect anomalies in new videos of the same scene. Importantly, our method offers explainability, as our high-level appearance and motion features can provide clear explanations for why specific parts of a video are classified as normal or anomalous. We conduct experiments on widely used video anomaly detection datasets and achieve significant improvements compared to the previous state-of-the-art methods. Additionally, we will make our code and additional datasets publicly accessible.