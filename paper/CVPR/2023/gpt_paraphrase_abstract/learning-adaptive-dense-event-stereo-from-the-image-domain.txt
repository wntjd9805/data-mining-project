Recently, researchers have been studying event-based stereo matching as it is known for its robustness in low light conditions. However, current event-based stereo networks face significant performance degradation when there is a shift in domains. Unsupervised domain adaptation (UDA) is a method that aims to solve this problem without relying on ground-truth data from the target domain. However, traditional UDA still requires the input event data with ground-truth from the source domain, which is more difficult and expensive to obtain compared to image data. To address this issue, we propose a new approach called Adaptive DenseEvent Stereo (ADES) that bridges the gap between different domains and input modalities. Our ADES framework adapts event-based stereo networks from abundant image datasets with ground-truth in the source domain to event datasets without ground-truth in the target domain, which is a more practical setup. Firstly, we introduce a self-supervision module that trains the network on the target domain through image reconstruction. Additionally, an artifact prediction network trained on the source domain helps remove intermittent artifacts in the reconstructed image. Secondly, we employ a feature-level normalization scheme to align the extracted features along the epipolar line. Lastly, we incorporate a motion-invariant consistency module to ensure consistent output despite perturbations in motion. Our experiments demonstrate that our approach achieves remarkable results in adapting event-based stereo matching from the image domain.