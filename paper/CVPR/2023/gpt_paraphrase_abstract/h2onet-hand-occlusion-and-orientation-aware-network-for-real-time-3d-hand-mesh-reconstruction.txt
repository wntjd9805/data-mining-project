Real-time reconstruction of a 3D hand mesh is difficult, particularly when the hand is holding an object. In this study, we introduce H2ONet, a method that effectively utilizes non-occluded information from multiple frames to enhance the quality of reconstruction. Our approach involves two branches: one focuses on capturing finger-level non-occluded information, while the other concentrates on global hand orientation. These branches have lightweight structures to ensure real-time performance. Additionally, we propose finger-level occlusion-aware feature fusion, which utilizes predicted finger-level occlusion information to combine finger-level information over time. We also introduce hand-level occlusion-aware feature fusion to extract non-occluded information from nearby frames. We evaluate our method on challenging datasets with hand-object occlusion scenarios and demonstrate that H2ONet achieves real-time performance and outperforms existing methods in terms of both hand mesh and pose precision. The code for our method will be made available on GitHub.