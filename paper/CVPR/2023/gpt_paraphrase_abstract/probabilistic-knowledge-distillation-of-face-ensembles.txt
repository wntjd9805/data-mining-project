Ensemble averaging, a widely used technique in machine learning, improves the performance of individual models. In this study, we introduce a formalized approach called feature alignment for ensemble in open-set face recognition and extend it to Bayesian Ensemble Averaging (BEA) using probabilistic modeling. This generalization offers two practical advantages that existing methods lack. Firstly, it allows for the evaluation of uncertainty in a face image, separating it into aleatoric uncertainty and epistemic uncertainty. The latter can be used to detect out-of-distribution face images. Secondly, the BEA statistic effectively reflects the aleatoric uncertainty and serves as a measure for face image quality, thereby enhancing recognition performance. To retain the uncertainty estimation capability of BEA without compromising inference efficiency, we propose BEA-KD, a student model that distills knowledge from BEA. BEA-KD emulates the behavior of ensemble members and consistently outperforms state-of-the-art knowledge distillation methods across various challenging benchmarks.