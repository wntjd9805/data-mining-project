Creating complex 3D movements using sparse keyframes is a difficult task due to the need for smoothness and precise skeletal details. While action features can be accurately derived from a complete set of keyframes, incorporating global context with transformers has shown promise as a data-driven embedding approach. However, existing methods often use interpolated intermediate frames for continuity, which leads to suboptimal results during training. In this study, we present a new framework that utilizes keyframe-based constraints to formulate latent motion manifolds. This approach considers the continuous nature of intermediate token representations. Our framework consists of two stages: keyframe encoding and intermediate token generation, followed by motion synthesis to extrapolate and combine motion data from the manifolds. Through extensive experiments on the LaFAN1 and CMU Mocap datasets, our proposed method demonstrates superior interpolation accuracy and high visual similarity to the ground truth motions.