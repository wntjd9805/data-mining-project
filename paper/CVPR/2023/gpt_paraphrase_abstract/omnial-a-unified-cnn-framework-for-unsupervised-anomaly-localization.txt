Unsupervised anomaly localization and detection are crucial in industrial manufacturing processes where anomalous samples are scarce. Recent advancements in unsupervised anomaly detection in industrial settings have achieved high performance by training separate models for multiple categories. However, this approach has drawbacks such as high storage and training time costs, as well as degradation of existing methods. This paper proposes a unified CNN framework called OmniAL for unsupervised anomaly localization. OmniAL addresses the aforementioned issues by improving anomaly synthesis, reconstruction, and localization. Instead of using normal data directly, the model is trained with panel-guided synthetic anomaly data to prevent learning identical reconstruction. To enhance anomaly reconstruction error for multi-class distribution, the network incorporates Dilated Channel and Spatial Attention (DCSA) blocks. Furthermore, OmniAL employs DiffNeck, a component between reconstruction and localization sub-networks, to explore multi-level differences and improve anomaly region localization. Experimental results on MVTecAD and VisA datasets with multiple classes demonstrate the superiority of OmniAL over state-of-the-art unified models. OmniAL achieves image-AUROC scores of 97.2 and 87.8, pixel-AUROC scores of 98.3 and 96.6, and pixel-AP scores of 73.4 and 41.7 for anomaly detection and localization respectively on 15-class MVTecAD and 12-class VisA datasets. Additionally, this paper conducts a comprehensive study on the robustness of unsupervised anomaly localization and detection methods against various levels of adversarial attacks, making it the first attempt in this area. The experimental results indicate that OmniAL holds great promise for practical applications due to its superior performance.