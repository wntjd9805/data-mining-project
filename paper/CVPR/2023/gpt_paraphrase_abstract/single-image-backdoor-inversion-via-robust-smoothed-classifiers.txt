The process of detecting and defending against backdoors in machine learning models involves finding a "trigger" that activates the backdoor. Previous methods for backdoor detection have focused on flipping a set of clean images to the target class through an optimization process. However, the size of this support set needed for successful recovery of the backdoor has not been extensively studied. In this study, we propose the SmoothInv method, which can reliably recover the backdoor trigger using just a single image. This method first constructs a robust smoothed version of the backdoored classifier and then performs guided image synthesis to reveal the backdoor pattern and target class. Unlike existing methods, SmoothInv does not require explicit modeling of the backdoor or complex regularization schemes. We conducted quantitative and qualitative studies on backdoored classifiers from previous attacks and demonstrated that SmoothInv outperforms existing methods by successfully recovering backdoors from single images while maintaining fidelity to the original backdoor. We also developed countermeasures to our approach and found that SmoothInv remains robust against adaptive attackers. Our code is available at https://github.com/locuslab/smoothinv.