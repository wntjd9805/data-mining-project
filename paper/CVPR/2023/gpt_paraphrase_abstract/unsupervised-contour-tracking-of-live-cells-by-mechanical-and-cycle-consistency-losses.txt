The analysis of changes in cellular morphology is crucial for understanding the functions and characteristics of live cells, such as stem cells and metastatic cancer cells. Tracking the deformable contour of cells in live cell videos is necessary to capture the local shapes and textures, which often involve complex motions including expansion and contraction. Existing methods like optical flow or deep point set tracking are not suitable for this task due to the fluidity of cells, and previous deep contour tracking approaches do not consider point correspondence. In this study, we propose a novel deep learning-based approach for tracking cellular contours, incorporating point correspondence by fusing dense representation using cross attention. Since manually labeling dense tracking points on the contour is impractical, we train our contour tracker using unsupervised learning with mechanical and cyclical consistency losses. The mechanical loss ensures that the points move perpendicular to the contour, aiding in effective tracking. We evaluated our method using labeled sparse tracking points on live cell datasets obtained from phase contrast and confocal fluorescence microscopes. Our contour tracker outperforms other methods quantitatively and produces more favorable results qualitatively. The code and data for our approach are publicly available at https://github.com/JunbongJang/contour-tracking/.