This study introduces a novel approach called AnchorFormer for point cloud completion, which aims to reconstruct the complete 3D shape of an object from partial observations. Existing methods encode observed points into a global feature vector and generate complete points based on this vector. However, this approach often fails to generate high-quality shapes due to the inability of the global feature vector to capture diverse patterns within an object. AnchorFormer addresses this limitation by utilizing pattern-aware discriminative nodes called anchors to capture regional information of objects. Anchors are learned based on the point features of the input partial observation and are scattered to both observed and unobserved locations by estimating specific offsets. These anchors, along with down-sampled points from the input observation, form sparse points. To reconstruct detailed object patterns, AnchorFormer employs a modulation scheme to morph a canonical 2D grid into a 3D structure at individual locations of the sparse points. The effectiveness of AnchorFormer is demonstrated through extensive experiments on various datasets, including PCN, ShapeNet-55/34, and KITTI. The results show that AnchorFormer outperforms existing point cloud completion approaches in terms of both quantitative and qualitative evaluations. The source code for AnchorFormer is available at https://github.com/chenzhik/AnchorFormer.