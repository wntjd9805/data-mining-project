We present SPARF, a method that addresses the limitations of Neural Radiance Field (NeRF) in synthesizing novel views using sparse input images with inaccurate camera poses. Our approach leverages multi-view geometry constraints to simultaneously learn NeRF and refine camera poses. By utilizing pixel matches between input views, our objective enforces the optimized scene and camera poses to converge to a global and accurate solution. Additionally, our depth consistency loss ensures scene consistency from any viewpoint. SPARF achieves state-of-the-art results on various challenging datasets in the sparse-view scenario.