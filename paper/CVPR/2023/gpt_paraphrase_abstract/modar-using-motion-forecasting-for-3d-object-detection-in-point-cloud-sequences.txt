We propose a method called MoDAR to improve 3D object detection in the presence of occluded and long-range objects. We utilize point cloud sequence data to observe objects from different viewpoints and improve visibility over time. However, the encoding of long-term sequence data can still be enhanced. MoDAR uses motion forecasting outputs as a virtual modality to augment LiDAR point clouds. It propagates object information from temporal contexts to a target frame by representing each object as a virtual point on a forecasted trajectory. The fused point cloud, consisting of raw sensor points and virtual points, can then be used with any off-the-shelf point-cloud based 3D object detector. We evaluated our method on the WaymoOpen Dataset and found that it significantly improves prior art detectors by utilizing motion forecasting from extra-long sequences (e.g. 18 seconds) without adding much computation overhead.