Data in real scenarios are often divided into artificial super categories based on expert knowledge rather than image representations. These super categories can contain a wide range of raw categories. However, existing classification techniques struggle to recognize super categories without raw class labels, leading to poor performance or requiring expensive annotations. To address this issue, this paper presents a framework called SuperClass Learning with Representation Enhancement (SCLRE) that leverages enhanced representation to recognize super categories. SCLRE utilizes self-attention techniques to collapse the boundaries between raw categories and enhance the representation of each superclass. This enhanced representation is then used to construct a superclass-aware decision boundary. The paper demonstrates theoretically that SCLRE can bound the generalization error under superclass scenarios by leveraging attention techniques. Experimental results on CIFAR-100 datasets and four high-resolution datasets show that SCLRE outperforms baseline methods and other contrastive-based approaches.