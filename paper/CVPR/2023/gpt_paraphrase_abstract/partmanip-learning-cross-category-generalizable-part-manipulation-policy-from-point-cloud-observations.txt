Creating a generalizable object manipulation policy is crucial for an embodied agent to effectively navigate complex real-world environments. Parts, which are shared components among various object categories, have the potential to enhance the policy's ability to generalize and achieve cross-category object manipulation. This study presents PartManip, a large-scale, part-based cross-category object manipulation benchmark. PartManip consists of 11 object categories, 494 objects, and 1432 tasks across 6 task classes. Compared to previous benchmarks, PartManip offers greater diversity and realism by including more objects and utilizing sparse-view point cloud input without oracle information like part segmentation. To address the challenges of learning vision-based policies, the researchers first train a state-based expert using part-based canonicalization and part-aware rewards, and then transfer the knowledge to a vision-based student. The researchers also identify the importance of an expressive backbone in handling the wide variety of objects. To achieve cross-category generalization, domain adversarial learning is introduced for domain-invariant feature extraction. Extensive simulations demonstrate that the learned policy outperforms other methods, particularly on unseen object categories. The researchers also successfully demonstrate the policy's ability to manipulate novel objects in the real world. The PartManip benchmark has been made publicly available at https://pku-epic.github.io/PartManip.