We introduce OmniAvatar, a new 3D head synthesis model that is trained on unstructured images and can generate a wide range of 3D heads with accurate control over various attributes such as camera poses, facial expressions, head shapes, and neck and jaw poses. To achieve this level of control, we propose a novel semantic signed distance function (SDF) based on head geometry (FLAME) that allows us to create a differentiable volumetric correspondence map. Using the 3D-aware GAN framework (EG3D), we generate detailed shape and appearance of 3D heads in a canonical space, which is then transformed back to the observation space using volume rendering guided by the correspondence map. To ensure control accuracy, we incorporate a geometry prior loss and a control loss. Additionally, we enhance temporal realism by including dynamic details based on expressions and joint poses. Our model outperforms existing methods in terms of generating identity-preserved 3D heads with realistic dynamic details. We validate our design choices through an ablation study.