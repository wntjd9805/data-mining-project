Soft prompt learning has become a popular method for adapting V&L models to downstream tasks with limited training data. However, current methods suffer from overfitting and experience a significant decrease in accuracy when tested on unseen classes from the same domain. In this paper, we propose four contributions to address these issues. Firstly, we introduce a novel approach called Language-Aware Soft Prompting (LASP) learning, which uses a text-to-text cross-entropy loss to maximize the probability of correctly classifying learned prompts based on predefined textual prompts. Secondly, we propose grouped LASP, which optimizes each group of prompts with respect to a separate subset of textual prompts to improve prompt representation capacity. Thirdly, we identify a visual-language misalignment caused by prompt learning and LASP and introduce a re-calibration mechanism to address it. Lastly, we demonstrate that LASP can include virtual classes during training, further enhancing the robustness of learned prompts. We evaluate our approach on 11 datasets and show that it outperforms previous works on soft prompting and achieves higher accuracy than hand-crafted prompts and CLIP on novel classes for 8 out of 11 test datasets. The code for our approach will be made available.