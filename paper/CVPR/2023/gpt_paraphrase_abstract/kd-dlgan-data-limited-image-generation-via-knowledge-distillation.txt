KD-DLGAN is a novel framework for improving the quality and diversity of image generation models trained with limited data. Generative Adversarial Networks (GANs) often suffer from overfitting when trained on small datasets, leading to subpar generation results. To address this issue, KD-DLGAN incorporates knowledge distillation techniques by leveraging pre-trained vision-language models.The framework introduces two key components to enhance the training process. The first component, called aggregated generative KD, tackles discriminator overfitting by exposing it to more challenging learning tasks. This approach helps the discriminator gain more generalizable knowledge from the pre-trained models. The second component, correlated generative KD, focuses on improving generation diversity. It achieves this by distilling and preserving the diverse image-text correlation present in the pre-trained models.Extensive experiments conducted on various benchmarks demonstrate that KD-DLGAN outperforms existing methods in generating high-quality images with limited training data. The framework consistently delivers substantial performance improvements, effectively complementing the state-of-the-art approaches. It is worth noting that the source code for KD-DLGAN will be made publicly available.