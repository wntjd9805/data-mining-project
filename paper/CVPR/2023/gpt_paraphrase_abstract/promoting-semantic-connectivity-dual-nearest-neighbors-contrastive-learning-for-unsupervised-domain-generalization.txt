Domain Generalization (DG) has been successful in transferring knowledge from known domains to unfamiliar ones. However, current DG methods heavily rely on labeled data from known domains, which are often expensive and hard to obtain. In contrast, there is an abundance of unlabeled data available. Therefore, we focus on the more practical problem of unsupervised domain generalization (UDG).   To tackle UDG, we explore the concept of contrastive learning, which involves learning invariant visual representations from different viewpoints. This approach has shown promise in unsupervised learning within the same domain. However, it fails to perform well in cross-domain scenarios.   In this paper, we investigate the limitations of traditional contrastive learning and identify that the key to successful UDG lies in semantic connectivity. Specifically, we find that suppressing connectivity within the same domain while encouraging connectivity within the same class helps in learning domain-invariant semantic information.   Based on this insight, we propose a novel approach called Dual Nearest Neighbors contrastive learning with strong Augmentation (DN2A) for unsupervised domain generalization. DN2A utilizes strong augmentations to suppress connectivity within the same domain and introduces a new dual nearest neighbors search strategy. This strategy allows us to identify reliable neighbors from both the target and source domains, promoting connectivity within the same class.   Our experimental results demonstrate that DN2A significantly outperforms existing state-of-the-art methods. For instance, with only 1% labeled data, we achieve an accuracy gain of 12.01% and 13.11% for linear evaluation on the PACS and DomainNet datasets, respectively.