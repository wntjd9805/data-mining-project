Images captured under improper exposure conditions often suffer from contrast degradation and detail distortion. This degradation and distortion limit the ability to model statistical and structural properties for exposure correction. To address this issue, this paper proposes a method to decouple contrast enhancement and detail restoration within each convolution process. By using addition and difference operations in local regions covered by convolution kernels, the low-frequency and high-frequency components can be separated. To facilitate statistical and structural regularities modeling, a Contrast Aware (CA) unit and a Detail Aware (DA) unit are designed and integrated into existing CNN-based exposure correction networks to replace the Traditional Convolution (TConv). To maintain computational costs, the two units are aggregated into a single TConv kernel using structural re-parameterization. Evaluation of nine methods and five benchmark datasets demonstrates that the proposed method significantly improves performance without introducing additional computational costs compared to the original networks. The codes for this method will be publicly available.