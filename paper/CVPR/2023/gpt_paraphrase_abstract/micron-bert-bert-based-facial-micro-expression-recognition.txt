Micro-expression recognition is a challenging task in affective computing, as it involves identifying subtle facial movements that are difficult for humans to perceive in a short amount of time. While pre-training deep Bidirectional Transformers (BERT) has improved self-supervised learning in computer vision, the standard BERT architecture is not suitable for accurately detecting facial micro-expressions. In this paper, we propose a new approach called Micron-BERT (µ-BERT) that can automatically capture these movements in an unsupervised manner. We introduce the Diagonal Micro-Attention (DMA) to detect small differences between frames, and a Patch of Interest (PoI) module to localize and highlight micro-expression regions while reducing background noise. By incorporating these components into an end-to-end deep network, µ-BERT outperforms previous methods in various micro-expression tasks. It can be trained on a large-scale unlabeled dataset and achieves high accuracy on new unseen micro-expression datasets. Experimental results demonstrate that µ-BERT consistently outperforms state-of-the-art performance on four micro-expression benchmarks. The code for µ-BERT is available at https://github.com/uark-cviu/Micron-BERT.