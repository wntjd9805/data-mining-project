Deep neural networks (DNNs) are highly effective in many applications, but they struggle with out-of-distribution (OOD) samples. Being able to identify new and unfamiliar inputs is crucial in critical areas like self-driving cars, unmanned aerial vehicles, and robots. Current methods treat DNNs as black boxes and assess the confidence of their predictions, but this approach often fails because DNNs are not trained to reduce their confidence for OOD inputs. In this study, we propose a novel method for OOD detection based on the analysis of neuron activation patterns (NAP) in ReLU-based architectures. Our method does not require significant computational resources as it utilizes binary representations of activation patterns from convolutional layers. Through extensive empirical evaluation on various DNN architectures and seven image datasets, we demonstrate its exceptional performance.