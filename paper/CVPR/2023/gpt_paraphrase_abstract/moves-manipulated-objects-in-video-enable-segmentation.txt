We have developed a method that utilizes video manipulation to gain insights into the interaction between held objects and hands. Our approach involves training a system that takes a single RGB image and generates a pixel-embedding, enabling it to address questions related to grouping (such as determining if two pixels belong together) and hand-object association (such as identifying if a hand is holding a specific pixel). Instead of manually annotating segmentation masks, we leverage realistic video data to observe human behavior. By combining epipolar geometry with modern optical flow, we generate effective pseudo-labels for grouping. Additionally, by using people segmentations, we can associate pixels with hands to understand contact. Our system achieves competitive performance in tasks involving hands and hand-held objects.