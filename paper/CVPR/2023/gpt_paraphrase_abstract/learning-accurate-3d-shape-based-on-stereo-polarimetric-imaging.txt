We propose a novel approach that combines deep learning and stereo polarization information to address the limitations of existing Shape from Polarization (SfP) methods. The first problem we tackle is the ambiguity of polarization cues, which often leads to false normal estimation. To overcome this, we introduce a Shape Consistency-based Mask Prediction (SCMP) module that utilizes the inherent consistency between surface normal and disparity. This module identifies areas with false normal estimation and replaces unreliable features with new features obtained through a global attention mechanism. The second problem we address is the assumption of orthographic projection, which is not always realistic. To handle non-orthographic projections, we introduce a Viewing Direction-aided Positional Encoding (VDPE) strategy that encodes pixel-viewing directions. This strategy enables our neural network to effectively handle different projection scenarios. To evaluate the performance of our approach, we create a real-world stereo SfP dataset that includes various object categories and illumination conditions. Experimental results demonstrate that our approach outperforms existing SfP methods in terms of accuracy. Additionally, our approach exhibits higher robustness to variations in light conditions.