Position Embeddings (PEs) are essential for Vision Transformers (ViTs) to enhance performance in various vision tasks. However, PEs pose a privacy risk as they expose spatial information of input patches. This raises questions about the impact of PEs on accuracy, privacy, and prediction consistency. To address these concerns, we propose a method called Masked Jigsaw Puzzle (MJP) for position embedding. MJP shuffles selected patches using a block-wise random jigsaw puzzle shuffle algorithm and occludes their corresponding PEs. Meanwhile, the PEs of non-occluded patches remain unchanged but their spatial relation is strengthened through a dense absolute localization regressor. Experimental results demonstrate that PEs encode the 2D spatial relationship and lead to privacy leakage under gradient inversion attacks. Training ViTs with naively shuffled patches can mitigate the issue, but it compromises accuracy. MJP, on the other hand, improves performance and robustness on large-scale datasets (ImageNet-1K, ImageNet-C, -A/O) and significantly enhances privacy preservation against typical gradient attacks. The source code and trained models can be found at https://github.com/yhlleo/MJP.