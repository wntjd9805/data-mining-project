Most current RGB-T trackers use a two-stream structure to extract RGB and thermal features and complex fusion strategies for multi-modal feature fusion. However, this approach requires a large number of parameters, making it impractical for real-life applications. On the other hand, compact RGB-T trackers are computationally efficient but suffer from performance degradation due to limited feature representation ability. To address this issue, we propose a cross-modality distillation framework that bridges the performance gap between compact and powerful trackers. Our framework includes a specific-common feature distillation module that transfers information from a deeper two-stream network to a shallower single-stream network. Additionally, a multi-path selection distillation module guides a fusion module to learn accurate multi-modal information using multiple paths. We demonstrate the effectiveness of our method through extensive experiments on three RGB-T benchmarks, achieving state-of-the-art performance while requiring fewer computational resources.