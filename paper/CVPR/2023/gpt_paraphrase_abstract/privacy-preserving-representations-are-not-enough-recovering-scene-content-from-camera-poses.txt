The increasing popularity of AR/VR/MR devices and cloud-based applications has raised concerns about privacy in visual localization, which involves estimating the camera pose from an image. Previous research on privacy-preserving localization focused on defending against attackers with access to cloud-based services. However, our study reveals that an attacker can gain information about a scene by querying a localization service, even without direct access. This attack exploits the robustness of modern localization algorithms to variations in appearance and geometry, causing them to localize objects similar to those in the scene. By querying the server with a large set of images, the attacker can learn about object placements from the camera poses returned by the service. We present a proof-of-concept version of this attack to demonstrate its practical feasibility. Importantly, this attack is not reliant on the specific localization algorithm used and is applicable to privacy-preserving representations as well. Thus, current efforts solely focused on privacy-preserving representations are inadequate.