The increasing use of deep learning models in real-world applications has created a need to model and understand the neural networks themselves. This allows us to estimate important attributes of these networks, such as accuracy and latency, without having to run the actual training or inference tasks. In this research, we propose a model called Neural Architecture Representation (NAR) that can provide a holistic estimation of these attributes. Our approach involves encoding both the operation and topology information of a neural network into a single sequence using a simple and effective tokenizer. We then utilize a multi-stage fusion transformer to create a compact vector representation from this sequence. To improve the efficiency of model training, we introduce an information flow consistency augmentation and an architecture consistency loss, which outperform previous random augmentation strategies with fewer augmentation samples. Our experimental results on various benchmark datasets demonstrate that our proposed framework can accurately predict the latency and accuracy attributes of both cell architectures and entire deep neural networks, yielding promising performance. The code for our framework is available at https://github.com/yuny220/NAR-Former.