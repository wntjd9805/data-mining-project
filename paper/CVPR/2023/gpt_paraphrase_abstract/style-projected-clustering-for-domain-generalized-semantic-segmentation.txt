Current methods for semantic segmentation aim to improve generalization by regularizing images to a standard feature space. However, this process weakens the representation. In contrast, our approach focuses on leveraging the differences between images to create a more effective representation space. We extract and store distinct style features as the basis of representation, allowing for generalization to unseen image styles by projecting features onto this known space. This projection is achieved through a weighted combination of stored bases, using similarity distances as weighting factors. Additionally, we extend this concept to the decision-making aspect of the model, promoting generalization in semantic prediction. Instead of deterministic prediction, we employ semantic clustering by measuring similarity distances to semantic bases (prototypes). Our proposed method outperforms state-of-the-art techniques, achieving an average improvement of up to 3.6% in mIoU on unseen scenarios. Code and models can be accessed at https://gitee.com/mindspore/models/tree/master/research/cv/SPC-Net.