This paper proposes a method for image restoration in various adverse weather conditions using a single set of network parameters. The authors observed that different weather conditions result in both general and specific image degradations. Based on this observation, they design a unified framework with a two-stage training strategy to capture both the general and specific features of each weather condition. In the first training stage, the model learns the general features by taking images from different weather conditions as inputs and producing coarsely restored results. In the second training stage, the model dynamically expands specific parameters for each weather type in the deep model, automatically learning the appropriate positions for expanding these weather-specific parameters. This approach allows for the creation of an efficient and unified model for image restoration under multiple adverse weather conditions. Additionally, the authors create a benchmark dataset with multiple real-world weather conditions to improve the performance of their method in real-world scenarios. Experimental results demonstrate that their approach outperforms existing methods on both synthetic and real-world benchmarks. The authors provide access to their codes and datasets for further research.