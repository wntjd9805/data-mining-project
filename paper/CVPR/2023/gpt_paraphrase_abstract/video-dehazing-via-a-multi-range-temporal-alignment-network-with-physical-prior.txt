This paper introduces a new approach to video dehazing, which aims to enhance the visibility and contrast of hazy frames. The approach involves utilizing physical haze priors and temporal information aggregation. A memory-based module is designed to incorporate prior-related features into long-range memory, while a multi-range scene radiance recovery module captures space-time dependencies in different ranges to effectively aggregate temporal information. Additionally, the authors have created a large-scale outdoor video dehazing benchmark dataset that includes videos from diverse real-world scenarios. Experimental results demonstrate the effectiveness of the proposed method in both synthetic and real conditions.