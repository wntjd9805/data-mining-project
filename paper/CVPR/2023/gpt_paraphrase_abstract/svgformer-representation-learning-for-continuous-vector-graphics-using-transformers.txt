Recent advancements in representation learning have yielded impressive results in comprehending and generating data across different domains. However, when it comes to modeling vector graphics data, solely relying on a data-driven approach often produces unsatisfactory outcomes in subsequent tasks. This is primarily because existing deep learning methods necessitate the quantization of SVG parameters and fail to effectively utilize the explicit geometric properties. To address this limitation, we introduce SVG-former, a transformer-based representation learning model that directly operates on continuous input values and effectively incorporates the geometric information of SVG to encode outline details and long-range dependencies. The versatility of SVG-former enables its application in a range of downstream tasks, including reconstruction, classification, interpolation, and retrieval. Through extensive experimentation on vector font and icon datasets, we demonstrate that our model can capture high-quality representation information and consistently outperform previous state-of-the-art approaches in various downstream tasks.