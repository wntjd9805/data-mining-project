This paper introduces a novel approach called TranSG for person re-identification (re-ID) using 3D skeleton data. Existing methods in this field typically focus on raw body joints or skeleton sequence representation, but they often fail to capture different body-component relations and do not explore the semantics of body joints in detail. To address these limitations, the authors propose a Transformer-based Skeleton Graph prototype contrastive learning approach. The approach consists of three main components: Skeleton Graph Transformer (SGT), Graph Prototype Contrastive learning (GPC), and graph Structure-Trajectory Prompted Reconstruction (STPR). The SGT is designed to learn both body and motion relations within skeleton graphs, enabling the aggregation of important node features into graph representations. The GPC component mines the most typical graph features (graph prototypes) for each identity and contrasts the similarity between graph representations and different prototypes at both the skeleton and sequence levels. This helps in learning discriminative graph representations. The STPR mechanism exploits the spatial and temporal contexts of graph nodes to prompt skeleton graph reconstruction, enabling the capture of valuable patterns and graph semantics for person re-ID.Empirical evaluations demonstrate that TranSG outperforms existing state-of-the-art methods in person re-ID tasks. The approach is also shown to be effective in different scenarios, such as different graph modeling, RGB-estimated skeletons, and unsupervised scenarios. The authors provide the code for TranSG on GitHub.Overall, TranSG offers a comprehensive approach for person re-ID using 3D skeleton data, capturing skeletal relations and valuable spatial-temporal semantics from skeleton graphs.