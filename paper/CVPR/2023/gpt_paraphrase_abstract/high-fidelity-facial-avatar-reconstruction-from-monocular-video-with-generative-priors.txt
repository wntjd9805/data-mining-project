Facial avatar reconstruction from a single video is a challenging task in computer graphics and computer vision. The Neural Radiance Field (NeRF) method has shown promising results in rendering novel views, but it struggles with the complexities of facial dynamics and the lack of 3D information in monocular videos. To address these challenges, we propose a new approach that incorporates a 3D-aware generative prior in NeRF-based facial avatar reconstruction. Unlike existing methods that rely on a conditional deformation field, we train a personalized generative prior that represents a local and low-dimensional subspace in the latent space of a 3D-GAN. We develop an efficient method to construct this personalized generative prior using a small set of facial images of an individual. Once learned, our approach enables photo-realistic rendering of novel views and face reenactment through navigation in the latent space. Our method can be applied to different driven signals, such as RGB images, 3DMM coefficients, and audio. Compared to existing approaches, our method achieves superior results in novel view synthesis and faithful face reenactment. The code for our method is available at the provided GitHub link.