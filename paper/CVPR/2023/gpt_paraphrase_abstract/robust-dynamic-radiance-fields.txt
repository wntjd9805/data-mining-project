Dynamic radiance field reconstruction methods aim to model the changing structure and appearance of a dynamic scene over time. However, current methods rely on accurate camera pose estimation from Structure from Motion (SfM) algorithms, which often fail or produce inaccurate poses in challenging videos with highly dynamic objects, poorly textured surfaces, and camera motion. To overcome this limitation, we propose a robust approach that simultaneously estimates the static and dynamic radiance fields, as well as the camera parameters (poses and focal length). Extensive quantitative and qualitative experiments demonstrate the effectiveness of our method, outperforming state-of-the-art dynamic view synthesis techniques.