Recent advancements in robust semi-supervised learning (SSL) have focused on filtering out-of-distribution (OOD) information at the sample level. However, a neglected issue in robust SSL is the corruption of semantic information, which hampers the progress of the field. This paper addresses this problem by introducing a unified framework called OOD Semantic Pruning (OSP) that aims to remove OOD semantics from in-distribution (ID) features. The framework consists of two components: an aliasing OOD matching module that pairs each ID sample with an OOD sample based on semantic overlap, and a soft orthogonality regularization that suppresses the semantic component collinear with the paired OOD sample in each ID feature. The regularization ensures consistency in predictions before and after soft orthogonality decomposition. Despite its simplicity, our method demonstrates strong performance in OOD detection and ID classification on challenging benchmarks. In fact, OSP outperforms the previous state-of-the-art by 13.7% in ID classification accuracy and 5.9% in AUROC for OOD detection on the TinyImageNet dataset. The source code for OSP is publicly available at https://github.com/rain305f/OSP.