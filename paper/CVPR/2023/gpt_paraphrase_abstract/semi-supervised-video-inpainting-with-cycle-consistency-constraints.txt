Deep learning-based video inpainting methods have shown promising results and gained attention from researchers. However, these methods assume that the masks for the corrupted regions in each frame are readily available, which is labor-intensive and expensive. To address this limitation, we propose a new semi-supervised inpainting approach where the networks can complete the corrupted regions of the entire video using the annotated mask of just one frame. Our framework includes a completion network and a mask prediction network, which generate corrupted contents of the current frame and determine the regions to be filled in the next frame, respectively. Additionally, we introduce a cycle consistency loss to optimize the training parameters of these networks, ensuring they constrain each other and maximize the overall model performance. Since existing video inpainting datasets don't suit the semi-supervised context, we create a new dataset by simulating real-world scenarios with corrupted videos. Extensive experiments demonstrate that our model outperforms other methods in video inpainting, achieving comparable performance to fully-supervised approaches.