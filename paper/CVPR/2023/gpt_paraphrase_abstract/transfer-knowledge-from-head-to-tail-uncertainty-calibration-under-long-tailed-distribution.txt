The problem of estimating uncertainty in a model is crucial, but current calibration techniques do not account for imbalanced training data. Real-world data often follows a long-tailed distribution, making existing calibration methods ineffective. Additionally, domain adaptation methods that rely on unlabeled target domain instances are not applicable. Models trained on long-tailed distributions tend to be overly confident in head classes. In this paper, we propose a novel calibration method that transfers knowledge from head classes to tail classes by estimating importance weights. We model the distribution of each class as a Gaussian and use the source statistics of head classes as a prior to calibrate the target distributions of tail classes. The importance weight is determined by the ratio of target probability density to source probability density. Our method is evaluated on various datasets and demonstrates its effectiveness.