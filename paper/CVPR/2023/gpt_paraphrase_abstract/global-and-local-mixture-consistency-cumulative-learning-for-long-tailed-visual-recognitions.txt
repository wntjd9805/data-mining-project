This paper aims to develop a simple learning approach for long-tail visual recognition. The approach focuses on enhancing the robustness of the feature extractor and reducing the bias towards head classes in the classifier, while also minimizing training complexity. The proposed method, Global and Local Mixture Consistency cumulative learning (GLMC), introduces two key ideas: (1) utilizing a global and local mixture consistency loss to improve the feature extractor's robustness. This involves generating two augmented batches using global MixUp and local CutMix techniques and minimizing the difference between them using cosine similarity. (2) Introducing a cumulative head-tail soft label reweighted loss to address the bias towards head classes. The mixed label of the head-tail class is reweighted based on empirical class frequencies for long-tailed data, and the conventional loss and the rebalanced loss are balanced using a coefficient accumulated over epochs. The GLMC approach achieves state-of-the-art accuracy on CIFAR10-LT, CIFAR100-LT, and ImageNet-LT datasets. Additional experiments on balanced ImageNet and CIFAR datasets demonstrate that GLMC significantly improves the generalization of backbones. The code for GLMC is publicly available at https://github.com/ynu-yangpeng/GLMC.