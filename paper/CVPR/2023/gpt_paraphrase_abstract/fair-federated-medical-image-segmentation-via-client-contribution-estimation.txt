Ensuring fairness is a crucial aspect of federated learning (FL). Previous studies have focused on either collaboration fairness, which involves rewarding clients based on their contribution, or performance fairness, which aims to achieve uniform performance across clients. However, we argue that it is essential to consider both types of fairness together in order to attract and motivate a diverse range of clients to participate in FL and produce high-quality global models. In this research, we propose a new method to optimize both collaboration fairness and performance fairness simultaneously. Our approach involves estimating client contribution in both gradient and data space. In gradient space, we analyze the differences in gradient direction between each client and others. In data space, we measure the prediction error on client data using an auxiliary model. Using this contribution estimation, we introduce a FL method called federated training via contribution estimation (FedCE), where estimation serves as the aggregation weights for the global model. We have conducted theoretical analysis and empirical evaluations on two real-world medical datasets to validate the effectiveness of our approach. The results demonstrate significant performance improvements, enhanced collaboration fairness, improved performance fairness, and comprehensive analytical studies. The code for our method is available at https://nvidia.github.io/NVFlare/research/fed-ce.