We introduce lookahead diffusion probabilistic models (LA-DPMs) to enhance the accuracy of estimating conditional Gaussian distributions in the backward process of diffusion probabilistic models (DPMs) by leveraging the correlation in the outputs of deep neural networks (DNNs) across consecutive timesteps. In a typical DPM, the original data sample x is estimated by inputting the most recent state zi and index i into the DNN model, and then the mean vector of the conditional Gaussian distribution for zi-1 is computed. Our approach improves this estimation by extrapolating the estimates of x obtained by inputting (zi+1, i+1) and (zi, i) into the DNN model. This extrapolation can be easily integrated into existing DPMs by adding an additional connection between two consecutive timesteps, without requiring fine-tuning. Extensive experiments demonstrate that incorporating this additional connection into various DPMs leads to a significant improvement in terms of the Fr√©chet inception distance (FID) score. Our implementation can be found at https://github.com/guoqiang-zhang-x/LA-DPM.