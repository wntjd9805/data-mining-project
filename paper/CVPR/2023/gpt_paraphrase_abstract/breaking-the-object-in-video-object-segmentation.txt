The fleeting nature of object appearance during transformation, such as the change in color, shape, and texture when objects like eggs or paper are broken or torn, is not adequately captured in existing video object segmentation benchmarks. To bridge this gap, we have created a new dataset called Video Object Segmentation under Transformations (VOST). This dataset comprises over 700 high-resolution videos captured in diverse environments, with an average length of 20 seconds, and densely labeled with instance masks. Our approach ensures that these videos focus on complex object transformations, capturing their complete temporal extent. We then extensively evaluate state-of-the-art video object segmentation methods and make significant discoveries. We find that existing methods struggle with this novel task due to their heavy reliance on static appearance cues. As a result, we propose modifications to the top-performing baseline, enhancing its ability to model spatio-temporal information. This study emphasizes the need for further research in developing more robust video object representations. In summary, our work demonstrates that while objects may transform and lose their original appearance, they still retain their identity, and this phenomenon should be addressed in video object segmentation research.