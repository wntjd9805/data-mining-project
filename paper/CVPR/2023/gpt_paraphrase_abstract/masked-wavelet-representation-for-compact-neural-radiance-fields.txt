Neural radiance fields (NeRF) have shown the potential of using neural fields or implicit neural representation in neural rendering. However, the computational resources and time required to represent a 3D scene or object using a multi-layer perceptron (MLP) are significant. Recent studies have explored the use of additional data structures like grids or trees to reduce computational inefficiencies, but these structures require a large amount of memory. This research proposes a method to reduce the size of the representation while maintaining the benefits of additional data structures. The approach involves applying the wavelet transform to grid-based neural fields. Grid-based neural fields enable fast convergence, and the wavelet transform, known for its efficiency in high-performance codecs, improves the parameter efficiency of grids. Additionally, a novel trainable masking approach is introduced to achieve higher sparsity of grid coefficients while preserving reconstruction quality. Experimental results demonstrate that non-spatial grid coefficients, specifically wavelet coefficients, can achieve higher levels of sparsity compared to spatial grid coefficients, resulting in a more compact representation. By implementing the proposed mask and compression pipeline, the research achieves state-of-the-art performance within a memory budget of 2 MB. The code for this work is available at https://github.com/daniel03c1/masked-wavelet-nerf.