Advancements in implementing deep neural networks (DNNs) on devices with limited resources have led to the development of input-adaptive dynamic neural networks (DyNNs). These DyNNs offer more efficient inferences and enable the deployment of DNNs on resource-constrained devices like mobile devices. However, a new vulnerability has been discovered in DyNNs that could potentially compromise their efficiency. The vulnerability involves the manipulation of DyNNs' computational costs by adversaries to create a false sense of efficiency. To address this concern, a new adversarial attack called EfficFrog has been proposed. EfficFrog injects universal efficiency backdoors into DyNNs by poisoning a minimal percentage of their training data. During the inference phase, EfficFrog can slow down the backdoored DyNNs and exploit the computational resources of systems running DyNNs by adding the trigger to any input. The effectiveness of EfficFrog was evaluated on three different DNN backbone architectures (VGG16, MobileNet, and ResNet56) using two popular datasets (CIFAR-10 and Tiny ImageNet). Results show that EfficFrog significantly reduces the efficiency of DyNNs on triggered input samples while maintaining similar efficiency for clean samples.