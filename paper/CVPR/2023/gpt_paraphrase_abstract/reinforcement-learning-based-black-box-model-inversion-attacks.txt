Model inversion attacks are privacy attacks that reconstruct private data used in training a machine learning model by accessing the model itself. Recently, there has been significant interest in white-box model inversion attacks that use Generative Adversarial Networks (GANs) to extract knowledge from public datasets, as they have shown excellent attack performance. However, existing black-box model inversion attacks that employ GANs face challenges such as inability to guarantee completion within a set number of queries or achieve the same performance as white-box attacks. To address these limitations, we propose a reinforcement learning-based black-box model inversion attack. We formulate the search for latent space as a Markov Decision Process (MDP) and solve it using reinforcement learning. Our approach utilizes confidence scores of generated images to provide rewards to an agent. Ultimately, the private data can be reconstructed using latent vectors discovered by the agent trained in the MDP. Experimental results on various datasets and models demonstrate that our attack successfully recovers private information from the target model, achieving state-of-the-art performance. We emphasize the significance of research on privacy-preserving machine learning by introducing a more advanced black-box model inversion attack.