Recently, there has been a lot of attention on supervised learning of skeleton sequence encoders for action recognition. However, learning these encoders without labels remains a difficult problem. Previous studies have shown promising results by using contrastive learning on pose sequences, but the quality of the learned representations is often dependent on the data augmentations used to create positive samples. Augmenting pose sequences is challenging because it requires enforcing geometric constraints among the skeleton joints to ensure realistic augmentations for each action.In this study, we propose a new approach to train models for skeleton-based action recognition without labels using contrastive learning. Our main contribution is the introduction of a simple module called HaLP (Hallucinate Latent Positives) for generating new positive samples. HaLP explores the latent space of poses in specific directions to create these synthetic positives. We develop a novel optimization formulation to solve for these synthetic positives, with explicit control over their difficulty. We propose approximations to the objective, enabling them to be solved in closed form with minimal computational overhead.Through experiments, we demonstrate that incorporating these generated positives into a standard contrastive learning framework consistently improves performance on various benchmarks, including NTU-60, NTU-120, and PKU-II. We evaluate the improvements on tasks such as linear evaluation, transfer learning, and kNN evaluation.To access our code, please visit https://github.com/anshulbshah/HaLP. Figure 1 illustrates the HaLP approach, which involves hallucinating latent positives for use within a contrastive learning pipeline. The process involves extracting prototypes that represent the data at a specific training step, randomly selecting a prototype from the set, and determining an optimal vector to add to the anchor to generate positives of varying difficulty. These generated positives are then utilized in a contrastive learning pipeline to train a model without labels.