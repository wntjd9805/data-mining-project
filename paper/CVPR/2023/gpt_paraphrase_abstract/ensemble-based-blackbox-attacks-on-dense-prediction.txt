We present a novel approach for adversarial attacks on dense prediction models, such as object detectors and segmentation models. Previous studies have shown that attacks generated by a single surrogate model do not effectively transfer to arbitrary victim models. Additionally, targeted attacks are more difficult to achieve than untargeted attacks. In this paper, we demonstrate that an ensemble of models can generate effective attacks against multiple victim models when carefully designed. We highlight the importance of normalizing the weights of individual models in the success of these attacks. Furthermore, we show that adjusting the weights of the ensemble according to the victim model can further enhance the attack performance. Our experiments on object detectors and segmentation models confirm the significance of our proposed methods, as our ensemble-based approach outperforms existing blackbox attack methods in these domains. Additionally, we demonstrate that our method can generate a single perturbation that can deceive multiple blackbox detection and segmentation models simultaneously. The code for our proposed method is available at https://github.com/CSIPlab/EBAD.