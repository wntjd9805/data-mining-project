The goal of referring expression segmentation is to separate an object described by a language expression from an image. However, existing models for this task may struggle to fully understand the meaning and visual representations of different concepts, which limits their ability to handle new combinations of learned concepts. To address this, we propose a Meta Compositional Referring Expression Segmentation (MCRES) framework that leverages meta learning to improve model generalization. Our framework constructs virtual training and testing sets using existing data, with each testing set containing novel combinations of concepts compared to the training set. By using a novel meta optimization scheme, we train the model to perform well on the virtual testing sets after training on the virtual training set. This approach helps the model better understand the semantics and visual representations of individual concepts, leading to robust generalization even when facing novel compositions. We conduct extensive experiments on three benchmark datasets, which demonstrate the effectiveness of our framework.