Learned image compression (LIC) methods have shown significant advancements and better rate-distortion performance compared to traditional image compression standards. Most LIC methods are either based on Convolutional Neural Networks (CNN) or Transformers, each having its own advantages. Combining the strengths of both methods is a promising area of research, but it poses two challenges: 1) how to effectively merge the two methods, and 2) how to achieve higher performance while maintaining a suitable complexity. This paper introduces an efficient parallel Transformer-CNN Mixture (TCM) block that addresses these challenges by incorporating the local modeling abilities of CNN and the non-local modeling abilities of transformers, thereby enhancing the overall architecture of image compression models. Additionally, inspired by recent advancements in entropy estimation models and attention modules, the paper proposes a channel-wise entropy model with parameter-efficient swin-transformer-based attention (SWAtten) modules using channel squeezing. Experimental results demonstrate that the proposed method achieves state-of-the-art rate-distortion performances on three different resolution datasets (Kodak, Tecnick, CLIC Professional Validation) when compared to existing LIC methods. The code for this method can be found at https://github.com/jmliu206/LIC_TCM.