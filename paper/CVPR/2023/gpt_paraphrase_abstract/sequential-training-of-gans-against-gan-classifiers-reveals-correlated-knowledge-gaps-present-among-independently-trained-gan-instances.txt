Modern Generative Adversarial Networks (GANs) excel at generating realistic images. However, these networks often exhibit "knowledge gaps," resulting in out-of-distribution artifacts in the generated samples. Previous research has introduced GAN-classifiers, which are separate from the discriminator and evaluate images produced by a fixed GAN. The existence of successful GAN-classifiers confirms the presence of knowledge gaps in GAN training.In this study, we explore the impact of iteratively training GAN-classifiers and GANs that deceive the classifiers to bridge these knowledge gaps. We examine the effects on the dynamics of GAN training, the quality of generated outputs, and the generalization of GAN-classifiers. We investigate two scenarios: a small DCGAN architecture trained on low-dimensional MNIST images and StyleGAN2, a state-of-the-art GAN architecture trained on high-dimensional FFHQ images.Our findings reveal that the DCGAN struggles to deceive a held-out GAN-classifier without compromising the quality of its output. On the other hand, StyleGAN2 successfully fools the held-out classifiers without any degradation in output quality. Moreover, this effect persists across multiple rounds of GAN/classifier training, indicating an ordering of optimal points in the generator parameter space. Additionally, we examine different classifier architectures and observe that the choice of GAN-classifier significantly influences the set of artifacts it learns.In summary, our study demonstrates the potential of iteratively training GAN-classifiers and GANs to address knowledge gaps in GAN training. The effectiveness of this approach varies depending on the GAN architecture, with StyleGAN2 showing superior performance. Furthermore, the choice of GAN-classifier architecture plays a crucial role in the artifacts it learns.