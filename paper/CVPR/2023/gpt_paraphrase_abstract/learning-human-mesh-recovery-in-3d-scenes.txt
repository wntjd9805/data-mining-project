We introduce a new approach to determine the precise position and shape of a person within a pre-scanned environment using only a single image. Unlike previous techniques that optimize mesh based on scene awareness, our method begins by estimating the absolute position and dense scene contacts using a sparse 3DCNN. We then enhance a pretrained human mesh recovery network by incorporating cross-attention with the derived 3D scene cues. By simultaneously learning from images and scene geometry, our method reduces ambiguity caused by depth and occlusion, resulting in more realistic overall poses and contacts. Additionally, encoding scene-aware cues within the network eliminates the need for optimization and enables real-time applications. Experimental results demonstrate that our network accurately and realistically recovers meshes in a single pass, outperforming existing methods in terms of both accuracy and speed. The code for our approach can be found on our project page: https://zju3dv.github.io/sahmr/.