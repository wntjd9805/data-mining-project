Advanced deep neural networks have greatly improved the performance of video prediction. However, current methods tend to have large model sizes and require additional inputs, such as semantic or depth maps, to achieve promising results. In order to address these issues, this paper introduces a novel approach called Dynamic Multi-scale Voxel Flow Network (DMVFN). Unlike previous methods, DMVFN achieves better video prediction performance with only RGB images while reducing computational costs. The key component of DMVFN is a differentiable routing module that effectively identifies the motion scales of video frames. During inference, DMVFN selects adaptive sub-networks based on the input. Experimental results on various benchmarks show that DMVFN is significantly faster than Deep Voxel Flow and outperforms the state-of-the-art iterative-based OPT in terms of generated image quality.