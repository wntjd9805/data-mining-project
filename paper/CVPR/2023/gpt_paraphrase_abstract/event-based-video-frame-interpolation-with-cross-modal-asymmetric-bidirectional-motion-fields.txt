This study focuses on Video Frame Interpolation (VFI) and its application in generating intermediate frames between consecutive input frames. The use of event cameras, which are bio-inspired sensors that encode brightness changes with high temporal resolution, has been proposed to enhance VFI performance. However, existing methods for estimating inter-frame motion fields using event cameras have limitations in handling complex motion in real-world scenarios. To address this issue, the authors propose a novel event-based VFI framework called EIF-BiOFNet. This framework utilizes both events and images to directly estimate inter-frame motion fields without any approximation methods. Additionally, they develop an interactive attention-based frame synthesis network that combines warping-based and synthesis-based features. To evaluate their proposed method, the authors create a large-scale event-based VFI dataset called ERF-X170FPS, which includes high frame rates, extreme motion, and dynamic textures. Experimental results demonstrate that their method outperforms state-of-the-art VFI methods on various datasets. To access further details and resources related to this study, visit their project page at https://github.com/intelpro/CBMNet.