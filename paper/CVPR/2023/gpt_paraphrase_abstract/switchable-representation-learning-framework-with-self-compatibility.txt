Real-world visual search systems are used on various platforms with different computing and storage resources. However, deploying a single model that works well on all platforms can lead to reduced accuracy. To overcome this challenge, it is necessary to deploy models with different capacities that can adapt to the resource constraints. This requires aligning the features extracted by these models in the metric space, which is known as "compatible learning". Existing research has mainly focused on the one-to-one compatible paradigm, which limits the ability to learn compatibility among multiple models.To address this limitation, we propose a new framework called Switchable representation learning Framework with Self-Compatibility (SFSC). SFSC enables the generation of a series of compatible sub-models with different capacities through a single training process. However, optimizing these sub-models can be challenging due to conflicts in the gradients. To mitigate this issue, we consider both the magnitude and direction of the gradients. We dynamically adjust the priorities of the sub-models based on uncertainty estimation to ensure proper co-optimization. Additionally, we project the gradients with conflicting directions to avoid mutual interference.The SFSC framework achieves state-of-the-art performance on the evaluated datasets.