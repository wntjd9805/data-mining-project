This paper introduces two modifications to the deep image prior (DIP) framework in order to improve its speed and practicality for image restoration tasks. The first modification involves optimizing the DIP seed while keeping the network weights randomly initialized, while the second modification reduces the network depth. Additionally, explicit priors, such as the sparse gradient prior encoded by total-variation regularization, are reintroduced to preserve the peak performance of DIP. The proposed method is evaluated on three image restoration tasks and compared to the original DIP framework, variants of DIP, and metaDIP, which utilizes meta-learning to learn good initializers with additional data. The results demonstrate that the proposed method achieves competitive restoration quality in a minimal amount of time, making it a clear winner. The code for the proposed method is available at https://github.com/sun-ummn/Deep-Random-Projector.