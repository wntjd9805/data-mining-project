Recent efforts have aimed to utilize the vision transformer (ViT) for unsupervised domain adaptation (UDA), a challenging task. These approaches typically employ cross-attention in ViT to directly align domains. However, the effectiveness of cross-attention diminishes when the domain gap is substantial due to the reliance on pseudo labels for targeted samples. To address this issue, we propose a game theory-based model called PMTrans, which establishes a connection between the source and target domains through an intermediate domain. Our approach introduces a novel ViT-based module called PatchMix, which constructs the intermediate domain by sampling patches from both domains using game-theoretical models. By doing so, it learns to combine patches from the source and target domains to maximize cross entropy while minimizing two semi-supervised mixup losses in the feature and label spaces. This formulation treats UDA as a min-max cross entropy game involving three players: the feature extractor, classifier, and PatchMix, aiming to find the Nash Equilibria. Additionally, we leverage attention maps from ViT to assign weights to each patch's label based on its importance, enabling the acquisition of more domain-discriminative feature representations. Extensive experiments on four benchmark datasets demonstrate that PMTrans outperforms state-of-the-art ViT-based and CNN-based methods by substantial margins: +3.6% on Office-Home, +1.4% on Office-31, and +17.7% on DomainNet. For more details, please refer to https://vlis2022.github.io/cvpr23/PMTrans.