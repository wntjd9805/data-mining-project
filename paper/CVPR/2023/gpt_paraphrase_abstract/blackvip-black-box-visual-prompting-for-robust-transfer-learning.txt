The rise of large-scale pre-trained models (PTMs) has led to the need for fine-tuning these models for various downstream tasks. However, current parameter efficient transfer learning (PETL) methods rely on assumptions that may not hold in real-world applications. These assumptions include having access to the entire parameter set of a PTM and having sufficient memory capacity for fine-tuning. In this study, we propose a method called black-box visual prompting (Black-VIP) that addresses these limitations. Black-VIP consists of two components: a Coordinator and simultaneous perturbation stochastic approximation with gradient correction (SPSA-GC). The Coordinator generates image-shaped visual prompts that are tailored to the input, improving few-shot adaptation and robustness to distribution and location shifts. SPSA-GC efficiently estimates the gradient of the target model to update the Coordinator. We conducted extensive experiments on 16 datasets, and the results show that BlackVIP enables robust adaptation to diverse domains without needing access to PTMs' parameters and with minimal memory requirements. The code for BlackVIP is available at https://github.com/changdaeoh/BlackVIP.