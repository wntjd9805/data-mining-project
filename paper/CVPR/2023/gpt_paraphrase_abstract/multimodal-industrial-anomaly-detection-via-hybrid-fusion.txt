Multimodal industrial anomaly detection based on 3D point clouds and RGB images is an area that has not been extensively explored. Current methods that attempt to detect anomalies in this context often concatenate the multimodal features, which results in interference between the features and negatively impacts the detection performance. In this paper, we propose a new approach called Multi-3D-Memory (M3DM) for multimodal anomaly detection. Our method incorporates a hybrid fusion scheme. Firstly, we introduce an unsupervised feature fusion technique using patch-wise contrastive learning to encourage interaction between different modal features. This helps improve the detection accuracy. Secondly, we utilize a decision layer fusion approach with multiple memory banks. This ensures that no information is lost and additional novelty classifiers are employed to make the final decision.To better align the point cloud and RGB features, we also introduce a point feature alignment operation. Through extensive experiments, we demonstrate that our multimodal industrial anomaly detection model outperforms the current state-of-the-art methods in terms of both detection and segmentation precision on the MVTec-3D AD dataset.The code for our proposed method is available on GitHub at github.com/nomewang/M3DM.