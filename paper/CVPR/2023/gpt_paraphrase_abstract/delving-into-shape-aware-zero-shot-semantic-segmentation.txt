Recent advancements in large-scale vision-language pretraining have allowed recognition models to classify objects in a zero-shot and open-set manner with high accuracy. However, applying this success to semantic segmentation, which requires accurate understanding of semantics and fine shape delineation, is challenging. Existing vision-language models are trained with image-level language descriptions, making it difficult to achieve precise segmentation. To address this issue, we propose a shape-aware zero-shot semantic segmentation method inspired by classical spectral methods in image segmentation. We leverage eigen vectors of Laplacian matrices constructed with self-supervised pixel-wise features to enhance shape-awareness. Remarkably, our technique outperforms a state-of-the-art shape-aware formulation that aligns ground truth and predicted edges during training, despite not using masks of seen classes. We conduct experiments on different datasets and with different backbones, yielding several interesting observations. The benefits of promoting shape-awareness are closely related to mask compactness and language embedding locality. Our method achieves new state-of-the-art performance in zero-shot semantic segmentation on both Pascal and COCO datasets, with significant improvements. The code and models for our method will be available at SAZS.