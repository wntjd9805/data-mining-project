Our objective is to develop a video representation that can be used for understanding instructional videos. However, the lack of labeled data makes it challenging to extract procedural knowledge from unlabeled videos. This procedural knowledge includes identifying the task being performed and its steps, as well as predicting potential next steps based on partial progress. We propose a solution by leveraging the repetitive nature of instructional video sequences and representing them as a Procedural Knowledge Graph (PKG). The PKG consists of discrete steps connected by edges that represent sequential occurrences in the instructional activities. We combine information from a text-based procedural knowledge database and an unlabeled instructional video corpus to build the PKG. Using this graph, we generate pseudo labels to train a video representation that captures the procedural knowledge in a more accessible form and can be applied to various procedure understanding tasks. We introduce four novel pre-training objectives in this PKG-based pre-training procedure, which we refer to as Paprika, Procedure-Aware PRe-training for Instructional Knowledge Acquisition. Paprika is evaluated on COIN and CrossTask datasets for tasks such as task recognition, step recognition, and step forecasting. The results show that Paprika outperforms existing models, achieving up to 11.23% improvement in accuracy across 12 evaluation settings. The implementation of Paprika is available at https://github.com/salesforce/paprika.