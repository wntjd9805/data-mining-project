Generating high-quality ground-truth (GT) images is crucial in training realistic image super-resolution (Real-ISR) models. Current methods often use a set of high-resolution (HR) images as GTs and artificially degrade them to create low-resolution (LR) counterparts. However, this approach has limitations. Firstly, the HR images may not have sufficient perceptual quality, which affects the quality of the Real-ISR outputs. Secondly, existing methods do not consider human perception much in GT generation, resulting in over-smoothed results or unwanted artifacts. To address these issues, we propose a human-guided GT generation scheme. We first train multiple image enhancement models to improve the perceptual quality of HR images and allow multiple HR counterparts for each LR image. Then, human subjects annotate the high-quality regions in the enhanced HR images as positive samples and identify regions with unpleasant artifacts as negative samples. This process creates a human-guided GT image dataset with both positive and negative samples. We also introduce a loss function to train the Real-ISR models. Experimental results demonstrate that our dataset enables Real-ISR models to generate more visually realistic results with fewer artifacts. The dataset and codes can be accessed at https://github.com/ChrisDud0257/HGGT.