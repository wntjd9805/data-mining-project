Neural Radiance Fields (NeRFs) have become popular for synthesizing novel views, but editing NeRF scenes remains a challenge. One important editing task is 3D inpainting, which involves removing unwanted objects from a 3D scene while maintaining visual plausibility and geometric validity. We propose a new 3D inpainting method that addresses these challenges. Our approach uses a small set of posed images and sparse annotations to quickly obtain a 3D segmentation mask for the target object. We then introduce a perceptual optimization-based approach that combines 2D image inpainters with 3D space, ensuring view consistency. To evaluate our method, we introduce a diverse benchmark dataset that contains challenging real-world scenes with and without a target object. We demonstrate the superiority of our approach compared to NeRF-based methods and 2D segmentation approaches in multiview segmentation. We also establish state-of-the-art performance in 3D inpainting compared to other NeRF manipulation algorithms and a strong 2D image inpainter baseline.