Deep learning methods have made significant progress in removing shadows from images. However, these methods still struggle with boundary artifacts and lack the ability to accurately model the shadow removal process. To address these issues, we propose a unified diffusion framework that incorporates both image and degradation priors for more effective shadow removal. Our approach, called ShandowDiffusion, introduces a shadow degradation model and a diffusive generative prior to progressively refine the desired output. This framework serves as a strong baseline for image restoration. Additionally, ShandowDiffusion improves the accuracy of shadow mask estimation by incorporating it as an auxiliary task of the diffusion generator. We evaluate our method on three popular datasets, ISTD, ISTD+, and SRD, and demonstrate its effectiveness. Compared to state-of-the-art methods, our model achieves a significant improvement in terms of PSNR, increasing from 31.69dB to 34.73dB on the SRD dataset.