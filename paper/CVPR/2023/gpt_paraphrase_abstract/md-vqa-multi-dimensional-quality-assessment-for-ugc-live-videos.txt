To improve the visual quality of user-generated content (UGC) live videos, which often suffer from distortions during capture, we propose a novel approach. We create a subjective UGC Live VQA database by collecting 418 source UGC videos in real live streaming scenarios and generating 3,762 compressed videos at different bit rates. Using this database, we develop a Multi-Dimensional VQA (MD-VQA) evaluator that assesses the visual quality of UGC live videos based on semantic, distortion, and motion aspects. Our extensive experimental results demonstrate that MD-VQA outperforms existing approaches on both our UGC Live VQA database and other compressed UGC VQA databases. This tool can play a crucial role in monitoring and optimizing the visual quality of live streaming videos during the distribution process.