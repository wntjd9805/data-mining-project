This study focuses on the deployment of vision transformers on GPU hardware, which is challenging due to the stacked self-attention and cross-attention blocks. To address this challenge, the researchers propose a compression scheme that maximizes the utilization of GPU-friendly 2:4 fine-grained structured sparsity and quantization. Firstly, a large model with dense weight parameters is pruned into a sparse model using 2:4 structured pruning, taking into account the GPU's acceleration capabilities with FP16 data type. Then, the sparse model is further quantized into a fixed-point model using sparse-distillation-aware quantization aware training, considering the GPU's ability to speed up sparse calculations with integer tensors. The compression scheme incorporates mixed-strategy knowledge distillation during the pruning and quantization processes and can be applied to both supervised and unsupervised learning styles. Experimental results demonstrate that the GPUSQ-ViT scheme achieves state-of-the-art compression, reducing model size by 6.4-12.7× and FLOPs by 30.3-62× while maintaining negligible accuracy degradation on various benchmarking tasks. Additionally, GPUSQ-ViT significantly improves deployment performance, achieving 1.39-1.79× and 3.22-3.43× latency and throughput improvement on A100 GPU, as well as 1.57-1.69× and 2.11-2.51× latency and throughput improvement on AGX Orin.