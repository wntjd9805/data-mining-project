We develop a method to extract information about the camera used to capture a photo by training a multimodal embedding model. This model combines image patches with the EXIF metadata present in image files. We convert the metadata into text and process it using a transformer. The features learned from this process outperform both self-supervised and supervised features in tasks related to image forensics and calibration. Notably, we achieve success in localizing spliced image regions without prior training by clustering the visual embeddings of patches within an image.