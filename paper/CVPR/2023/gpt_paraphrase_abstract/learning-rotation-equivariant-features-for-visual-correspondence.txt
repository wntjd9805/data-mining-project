This study introduces a self-supervised learning approach to extract rotation-invariant descriptors using group-equivariant CNNs. By employing these CNNs, the method learns to obtain rotation-equivariant features and their orientations explicitly, without the need for complex data augmentations. The features and orientations are processed using a novel technique called group aligning, which shifts the group-equivariant features by their orientations along the group dimension. This technique ensures rotation-invariance without compromising discriminability. The method is trained end-to-end in a self-supervised manner, using an orientation alignment loss and a contrastive descriptor loss to handle geometric and photometric variations. The proposed method achieves state-of-the-art matching accuracy for rotation-invariant descriptors, and performs well in keypoint matching and camera pose estimation tasks.