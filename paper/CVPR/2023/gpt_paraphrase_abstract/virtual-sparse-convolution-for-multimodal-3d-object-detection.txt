Recently, there has been a growing interest in virtual/pseudo-point-based 3D object detection, which combines RGB images and LiDAR data through depth completion. However, the virtual points generated from images are too dense, leading to excessive redundant computation during detection. Additionally, inaccurate depth completion introduces noise that significantly reduces detection precision. This study introduces a fast and effective backbone called Vir-ConvNet, based on a new operator called VirConv (Virtual SparseConvolution), for virtual-point-based 3D object detection. VirConv includes two key designs: StVD (Stochastic Voxel Discard) and NRConv (Noise-Resistant Sub-manifold Convolution). StVD addresses the computation problem by discarding redundant voxels in close proximity. NRConv tackles the noise problem by encoding voxel features in both 2D images and 3D LiDAR space. By incorporating VirConv, the researchers develop three pipelines: VirConv-L, VirConv-T, and VirConv-S. VirConv-L is an efficient pipeline based on early fusion design, achieving 85% AP on the KITTI car 3D detection test leaderboard with a fast running speed of 56ms. VirConv-T and VirConv-S are high-precision pipelines based on transformed refinement scheme and pseudo-label framework, achieving 86.3% and 87.2% AP respectively. Currently, VirConv-S ranks first on the leaderboard. The code for this study is available at https://github.com/hailanyi/VirConv.