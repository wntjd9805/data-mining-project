Neural networks struggle with catastrophic forgetting, where their performance on old tasks declines after being optimized for new tasks, unlike humans who can learn new tasks sequentially. To address this issue, the continual learning (CL) community has proposed solutions to enable neural networks to learn new tasks while maintaining accuracy on previous tasks. However, the trade-off between plasticity (ability to learn new tasks) and stability (accuracy on previous tasks) remains unresolved, and its underlying mechanism is not well understood. This study introduces a novel method called Auxiliary Network Continual Learning (ANCL) that incorporates an auxiliary network to enhance plasticity in a continually learned model focused on stability. The proposed framework includes a regularizer that balances plasticity and stability, outperforming existing methods in task incremental and class incremental scenarios. Through extensive analysis, the study uncovers key principles related to the plasticity-stability trade-off. The code implementation of ANCL is available at https://github.com/kim-sanghwan/ANCL.