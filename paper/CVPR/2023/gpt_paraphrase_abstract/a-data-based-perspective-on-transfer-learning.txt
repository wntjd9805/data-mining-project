The general belief is that including more pre-training data in transfer learning leads to better performance. However, recent evidence suggests that removing data from the source dataset can also be beneficial. In this study, we examine the impact of the composition of the source dataset on transfer learning and introduce a framework to investigate its effects on downstream performance. Our framework allows us to identify transfer learning brittleness and detect issues such as data-leakage and misleading examples in the source dataset. We demonstrate that removing problematic data points identified by our framework improves transfer learning performance from ImageNet on various target tasks.