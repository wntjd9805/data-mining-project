With the rapid proliferation of generative models, there is an increasing demand for a general-purpose solution to detect fake images. The current approach of training deep networks for real-vs-fake classification proves ineffective in detecting fake images generated by newer types of generative models, specifically GANs. Upon further examination, it is discovered that the resulting classifier is biased towards detecting patterns that indicate an image's fakeness. The real class becomes a catch-all category for anything that is not fake, including images generated by models that were not accessible during training. Building on this finding, we propose a novel method of real-vs-fake classification that does not rely on explicit training to distinguish between real and fake images. Instead, we utilize a feature space from a large pretrained vision-language model and employ nearest neighbor and linear probing techniques. Surprisingly, this simple approach demonstrates excellent generalization capabilities in detecting fake images from a wide range of generative models. When tested on unseen diffusion and autoregressive models, our method outperforms the current state-of-the-art by 15.07 mAP and 25.90% accuracy. Our code, models, and data are available at https://github.com/Yuheng-Li/UniversalFakeDetect.