Neural Radiance Fields (NeRF) have made significant advancements in generating realistic images from novel viewpoints. However, their practical application is limited by the need for accurate camera poses. Existing methods that combine analysis-by-synthesis techniques to learn 3D representations and register camera frames can produce suboptimal results if the initializations are poor. To overcome this limitation, we propose L2G-NeRF, a registration method that consists of two steps: local alignment and global alignment. The local alignment is performed at the pixel level and is learned in an unsupervised manner using a deep network. It aims to optimize photometric reconstruction errors. The global alignment, on the other hand, is performed at the frame level and utilizes differentiable parameter estimation solvers to find a global transformation based on the pixel correspondences. Our experiments on both synthetic and real-world data demonstrate that L2G-NeRF outperforms the current state-of-the-art methods in terms of reconstruction fidelity and handling large camera pose misalignments. Moreover, our method can be easily integrated as a plugin for various NeRF variants and other applications involving neural fields. The code and supplementary materials for L2G-NeRF are available at https://rover-xingyu.github.io/L2G-NeRF/.