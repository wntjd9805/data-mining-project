We have developed an improved method for enhancing a phrase grounding model, which takes an image and a text phrase as input and generates a suitable localization map. Our approach involves refining the model by utilizing self-similarity maps obtained from the latent representation of the model's image encoder. We have observed that these maps bear resemblance to localization maps and can be combined to create valuable pseudo-labels for self-training purposes. By employing this technique, we have achieved significantly better results compared to the current state-of-the-art methods in weakly supervised phrase grounding. We have also demonstrated the effectiveness of our approach in a related task called WWbL, where only the image is provided as input without any accompanying text. For further details and access to our code, please visit our GitHub repository at https://github. com/talshaharabany/Similarity-Maps-for-Self-Training-Weakly-Supervised-Phrase-Grounding.