This paper introduces Crowd3D, a novel framework for reconstructing the 3D poses, shapes, and locations of numerous individuals in wide-field large scenes from a single image. Existing methods face challenges in handling large scenes with hundreds of people, including the high number of individuals, variations in human scale, and complex spatial distribution. To address these issues, the authors propose converting the problem of crowd localization into pixel localization using a newly defined concept called Human-scene Virtual Interaction Point (HVIP). By pre-estimating a scene-level camera and a ground plane, a progressive reconstruction network based on HVIP is utilized to achieve global consistency in crowd reconstruction. Additionally, an adaptive human-centric cropping scheme is designed to handle the large number of individuals and different human sizes. The authors also provide a benchmark dataset called LargeCrowd for crowd reconstruction in large scenes. Experimental results demonstrate the effectiveness of the proposed method. The code and dataset are available for access at http://cic.tju.edu.cn/faculty/likun/projects/Crowd3D.