Deep neural networks have shown impressive performance in scene perception for automated vehicles but face challenges when encountering real-world conditions that differ from their training domain. Adverse weather conditions, in particular, can greatly impact model performance if not included in the training data. Furthermore, when a model is adapted to a new domain, it often suffers from catastrophic forgetting, resulting in a significant decrease in performance on previously seen domains. Although efforts have been made to mitigate catastrophic forgetting, the causes and effects of this phenomenon are not well understood. To address this gap, we investigate how semantic segmentation models are affected during domain-incremental learning in adverse weather conditions. Through experiments and analysis, we find that catastrophic forgetting is primarily caused by changes in low-level features during domain-incremental learning. We also observe that learning more general features on the source domain using pre-training and image augmentations enables efficient feature reuse in subsequent tasks, leading to a substantial reduction in catastrophic forgetting. These findings emphasize the importance of methods that promote generalized features for effective continual learning algorithms.