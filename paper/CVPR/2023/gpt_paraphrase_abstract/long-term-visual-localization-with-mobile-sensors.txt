Despite the challenges posed by changes in illumination, seasons, and structure that cause significant differences between query and reference images, this study proposes a solution for the problem of image-based camera localization in outdoor environments. The approach involves utilizing additional sensors on a mobile phone, such as GPS, compass, and gravity sensor, to provide initial poses and constraints that aid in reducing the search space for image matching and final pose estimation. The use of these sensors also enables the development of a direct 2D-3D matching network, which improves efficiency by establishing correspondences between 2D and 3D instead of relying on tedious 2D-2D matching. To facilitate the research, a new dataset was collected, containing various mobile sensor data and significant scene appearance variations. Ground-truth poses for query images were acquired to evaluate the proposed method against state-of-the-art baselines, demonstrating its effectiveness. The code and dataset for this project can be accessed on the project page: https://zju3dv.github.io/sensloc/.