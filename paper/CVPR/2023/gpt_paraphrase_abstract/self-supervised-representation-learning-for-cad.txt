CAD tools are widely used in the creation, modification, analysis, and optimization of objects in the modern world. One area of active research in CAD is the application of data-driven machine learning methods to learn from large repositories of geometric and program representations. However, the lack of labeled data in CAD's native format, known as the parametric boundary representation (B-Rep), is currently a significant obstacle. While some datasets of mechanical parts in B-Rep format have been released for machine learning research, they are mostly unlabeled, and the labeled datasets available are small. Moreover, task-specific label sets are rare and expensive to annotate. This study proposes a solution to this problem by utilizing unlabeled CAD geometry for supervised learning tasks. The researchers develop a new hybrid implicit/explicit surface representation for B-Rep geometry and demonstrate that pre-training with this representation significantly improves few-shot learning performance. The proposed method also achieves state-of-the-art performance on various B-Rep benchmarks.