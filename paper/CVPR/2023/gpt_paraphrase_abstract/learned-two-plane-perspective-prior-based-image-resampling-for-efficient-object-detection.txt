Real-time perception plays a crucial role in autonomous navigation and citywide sensing. Existing approaches in streaming perception have focused on adaptive sampling to enhance real-time object detection. In this study, we propose a learnable prior based on the rough geometry of the 3D scene, specifically the ground plane and a plane above it, to resample images for more efficient object detection. This approach significantly improves the detection performance of small and distant objects, while also being more efficient in terms of latency and memory usage. When applied to autonomous navigation, using the same detector and scale, our method achieves a 4.1 APS (39%) increase in detection rate and a 5.3 sAPS (63%) improvement in real-time performance for small objects compared to the state-of-the-art. Additionally, for fixed traffic cameras, our approach is able to detect small objects at image scales where other methods fail. At the same scale, our method achieves a 195% (12.5 APS) improvement in small object detection compared to naive-downsampling and a 63% (4.2 APS) improvement over the state-of-the-art.