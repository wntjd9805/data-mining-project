We present a new method called anchored radial observations (ARO) for learning the implicit field representation of 3D shapes. This method is able to handle significant shape variations and is not limited to specific categories. Our approach involves reasoning about shapes using partial observations from a set of viewpoints known as anchors. We use a fixed set of anchors generated through Fibonacci sampling and a coordinate-based deep neural network to predict the occupancy value of a given point in space. Unlike previous models that rely on global shape features, our shape encoder operates on query-specific features in a local context. To predict point occupancy, we encode and aggregate locally observed shape information from the anchors surrounding the query point using an attention module before performing implicit decoding. We demonstrate the effectiveness and versatility of our network, called ARO-Net, through experiments on surface reconstruction from sparse point clouds. We test our network on novel and unseen object categories, train it on a single shape, and compare its performance to state-of-the-art neural and classical methods for reconstruction and tessellation. Figure 1 shows the results of neural 3D reconstruction using ARO-Net on various objects, including airplanes, rifles, and animals, when the network was trained only on chairs. We also show the reconstruction of different shapes when the network was trained on multiple versions of one model, the Fertility. Further comparisons to other methods can be found in Section 4.