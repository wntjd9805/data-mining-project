This paper presents a solution to the problem of efficiently reconstructing volumetric videos of moving humans using sparse multi-view videos. Previous approaches have used neural radiance fields (NeRF) and motion fields to represent dynamic humans, but the optimization process was time-consuming. Other methods reduced optimization time by using learned priors but sacrificed visual fidelity. The proposed method introduces a novel part-based voxelized representation for humans and a 2D motion parameterization scheme to accelerate the learning process. Experimental results show that the model can be learned 100 times faster than previous methods, while maintaining competitive rendering quality. Training the model on a 512 Ã— 512 video with 100 frames takes approximately 5 minutes on a single RTX 3090 GPU. The code for the method is available on the project page: https://zju3dv.github.io/instantnvr.