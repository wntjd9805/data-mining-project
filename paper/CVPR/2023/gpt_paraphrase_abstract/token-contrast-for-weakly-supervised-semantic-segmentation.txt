In Weakly-Supervised Semantic Segmentation (WSSS), the use of image-level labels with Class Activation Map (CAM) to generate pseudo labels is common practice. However, CAM is limited in its ability to accurately identify complete object regions due to the local structure perception of Convolutional Neural Networks (CNNs). While Vision Transformer (ViT) has shown promise in addressing this limitation, it tends to introduce the problem of over-smoothing, resulting in uniform final patch tokens. To overcome this issue, we propose TokenContrast (ToCo) as a solution and explore the potential of ViT for WSSS.Our approach involves two main contributions. Firstly, we leverage the observation that intermediate layers in ViT retain semantic diversity. We introduce a Patch Token Contrast module (PTC) that supervises the final patch tokens using pseudo token relations derived from these intermediate layers. This alignment of semantic regions leads to more accurate CAM. Secondly, to differentiate low-confidence regions in CAM, we devise a Class TokenContrast module (CTC) inspired by the ability of class tokens in ViT to capture high-level semantics. CTC enhances representation consistency between uncertain local regions and global objects by contrasting their class tokens.We evaluate our proposed ToCo on the PASCAL VOC and MS COCO datasets and compare it with other single-stage competitors and state-of-the-art multi-stage methods. The results demonstrate that ToCo outperforms other methods in terms of performance and achieves comparable results to the best existing approaches. The code for ToCo is available at https://github.com/rulixiang/ToCo.