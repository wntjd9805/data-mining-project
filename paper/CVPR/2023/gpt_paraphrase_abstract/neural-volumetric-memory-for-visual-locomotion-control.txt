This study focuses on the use of legged robots for autonomous locomotion on challenging terrains using a single forward-facing depth camera. The problem lies in the partial observability of the terrain, requiring the robot to rely on past observations to infer the current terrain. To address this, the researchers propose Neural Volumetric Memory (NVM), a memory architecture that models the 3D geometry of the scene and considers the SE(3) equivariance of the 3D world. NVM aggregates feature volumes from multiple camera views by bringing them back to the robot's ego-centric frame. The visual-locomotion policy learned through this approach demonstrates superior performance compared to more simplistic methods. Ablation studies confirm that the representations stored in the neural volumetric memory contain enough geometric information to reconstruct the scene. The project page with accompanying videos can be found at https://rchalyang.github.io/NVM.