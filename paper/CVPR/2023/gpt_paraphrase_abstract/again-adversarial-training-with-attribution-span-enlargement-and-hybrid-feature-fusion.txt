In this study, we address the issue of robust generalization in deep neural networks trained with adversarial training (AT). Typically, AT methods achieve high training robustness but low test robustness. We propose a novel approach to improve the robust generalization of AT methods by focusing on the concept of attribution span. We observe that adversarially trained DNNs have a smaller attribution span on input images compared to standard DNNs. This limited attribution span causes a lack of test robustness as adversarially trained DNNs tend to focus on specific visual concepts from training images. To enhance robustness, we introduce a method to enlarge the learned attribution span. Additionally, we use hybrid feature statistics for feature fusion to increase the diversity of features. Through extensive experiments, we demonstrate that our method effectively improves the robustness of adversarially trained DNNs, surpassing previous state-of-the-art methods. Furthermore, we provide theoretical analysis to validate the effectiveness of our approach. The abstract is accompanied by a visual illustration depicting the attribution span under ResNet-18, showing the difference between the standard model and the robust model in terms of attribution span. Overall, our method offers a promising solution to enhance the robustness of DNNs trained with AT.