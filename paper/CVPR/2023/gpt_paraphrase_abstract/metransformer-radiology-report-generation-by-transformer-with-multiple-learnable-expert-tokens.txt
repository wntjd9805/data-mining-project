In clinical situations, the use of multi-specialist consultation has shown great potential in enhancing the accuracy of diagnoses, particularly for complex cases. This has motivated us to explore a new approach called "multi-expert joint diagnosis" as an upgrade to the current "single expert" framework commonly used in the literature. Our proposed method, called METransformer, utilizes a transformer-based backbone to achieve this goal. The key innovation of our approach is the incorporation of multiple learnable "expert" tokens within both the encoder and decoder of the transformer. In the encoder, each expert token interacts with both visual tokens and other expert tokens to learn how to attend to different regions of an image for representation purposes. An orthogonal loss is employed to ensure that these expert tokens capture complementary information and minimize overlap. In the decoder, each attended expert token guides the cross-attention between input words and visual tokens, thus influencing the generated report. Additionally, we have developed a metrics-based expert voting strategy to produce the final report. Our proposed model takes advantage of the benefits of an ensemble-based approach, but in a computationally efficient manner that allows for more sophisticated interactions among the experts. Experimental results on two widely used benchmarks demonstrate the promising performance of our model. Furthermore, the framework-level innovation of our approach enables the incorporation of advancements from existing "single expert" models, offering potential for further improvement in performance.