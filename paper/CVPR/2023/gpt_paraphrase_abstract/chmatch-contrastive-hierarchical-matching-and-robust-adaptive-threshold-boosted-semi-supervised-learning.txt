The FixMatch and FlexMatch methods have shown impressive results in semi-supervised learning. However, these methods have limitations. FixMatch uses a constant threshold for all classes, while FlexMatch uses an adaptive threshold for each category. Both methods suffer from unstable results and indiscriminative feature representation, especially when labeled samples are limited. In this paper, we propose a new method called CHMatch. CHMatch can learn adaptive thresholds for instance-level prediction matching and discriminative features through contrastive hierarchical matching. We introduce a memory-bank based strategy to learn robust thresholds by selecting highly confident samples. Additionally, we utilize the hierarchical labels to construct an accurate affinity graph for contrastive learning. CHMatch achieves stable and superior results on various benchmarks. For instance, on CIFAR-100 under WRN-28-2 with only 4 and 25 labeled samples per class, CHMatch reduces the error rate by 8.44% and 9.02% respectively compared to FlexMatch.