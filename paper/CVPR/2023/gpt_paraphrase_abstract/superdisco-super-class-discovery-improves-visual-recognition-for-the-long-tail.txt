Modern image classifiers perform well on classes that have a large number of instances, but struggle with classes that have only a few instances. In contrast, humans are able to handle the challenge of recognizing these "tail" classes effortlessly because they can learn to represent them at different levels of semantic abstraction, making the learned features more distinct. This observation inspired us to develop an algorithm called SuperDisco, which aims to discover super-class representations for long-tailed recognition using a graph model. Our approach involves learning to construct a super-class graph that guides the representation learning process to handle long-tailed distributions. By performing message passing on this graph, we rectify and refine image representations by focusing on the most relevant entities based on their semantic similarity within their super-classes. Additionally, we propose a meta-learning approach to train the super-class graph, using a prototype graph created from a small amount of imbalanced data as supervision. This enables us to obtain a more robust super-class graph that further enhances the performance of long-tailed recognition. We conducted extensive experiments on various datasets, including long-tailed CIFAR-100, ImageNet, Places, and iNaturalist, consistently achieving state-of-the-art results. These experiments demonstrate the effectiveness of the discovered super-class graph in addressing the challenges posed by long-tailed distributions.