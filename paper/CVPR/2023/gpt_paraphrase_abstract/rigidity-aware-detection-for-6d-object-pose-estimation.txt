Recent methods for estimating the pose of 6D objects typically start by using object detection to obtain 2D bounding boxes before determining the pose. However, these methods often struggle with cluttered scenes, leading to poor initialization for the pose network. To address this issue, we propose a rigidity-aware detection method that takes advantage of the fact that the target objects in 6D pose estimation are rigid. Our approach involves sampling positive object regions from the entire visible object area during training, rather than solely from the center of the bounding box where the object may be occluded. This allows every visible part of the object to contribute to the final bounding box prediction, resulting in improved detection robustness. A key component of our approach is the use of a visibility map, which is created by calculating the minimum barrier distance between each pixel within the bounding box and the box boundary. Our experimental results on seven challenging 6D pose estimation datasets demonstrate that our method significantly outperforms general detection frameworks. Additionally, when combined with a pose regression network, our method achieves state-of-the-art pose estimation results on the challenging BOP benchmark.