The detection of manipulated text in document images has become increasingly important for information security. However, detecting tampered text that appears visually consistent in photographed documents remains a major challenge. To address this issue, we propose a new framework called Document Tampering Detector (DTD). DTD includes a Frequency Perception Head (FPH) to compensate for the lack of noticeable visual features and a Multi-view Iterative Decoder (MID) to utilize information from features in different scales. Additionally, we introduce a new training method called Curriculum Learning for Tampering Detection (CLTD) to improve the robustness of image compression and the ability to generalize by addressing confusion during training. To support tampered text detection in document images, we create a large-scale dataset called DocTamper, consisting of 170,000 document images of various types. Experimental results demonstrate that our proposed DTD outperforms previous state-of-the-art methods by significant margins in terms of F-measure on the DocTamper testing set, as well as cross-domain testing sets. The code and dataset are available at https://github.com/qcf-568/DocTamper.