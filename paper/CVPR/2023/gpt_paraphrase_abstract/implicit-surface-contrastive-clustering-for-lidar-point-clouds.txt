We propose a new self-supervised pretraining method called ISCC for outdoor LiDAR point cloud perception. Existing pretraining approaches have not been effectively applied to this domain due to its scene complexity and wide range. Our method consists of two novel pretext tasks. The first task involves sorting local groups of points in the scene into semantically meaningful clusters using contrastive learning to uncover semantic information. The second task involves implicit surface reconstruction to reason about precise surfaces of different parts of the scene and learn geometric structures. We demonstrate the effectiveness of our method through transfer learning on 3D object detection and semantic segmentation in real-world LiDAR scenes. Additionally, we introduce an unsupervised semantic grouping task to show that our approach learns highly semantically meaningful features.