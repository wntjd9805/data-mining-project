To ensure success, agents in Vision-and-Language Navigation (VLN) need to accurately connect instructions to actions based on their surroundings. This study introduces a methodology to examine agent behavior in specific skills such as stopping, turning, and moving towards specified objects or rooms. By generating skill-specific interventions and measuring changes in agent predictions, we analyze the behavior of a recent agent and compare it to other agents in terms of skill-specific competency scores. The findings reveal that training biases have a lasting impact on agent behavior and that current models are capable of grounding simple referring expressions. Moreover, the study shows that skill-specific scores are correlated with improvements in overall VLN task performance.