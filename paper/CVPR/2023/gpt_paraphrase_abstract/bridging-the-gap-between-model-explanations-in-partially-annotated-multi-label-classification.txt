Partially annotated multi-label classification has emerged as a field in computer vision due to the high costs associated with collecting labels for multi-label classification datasets. One common approach to this task is to consider unobserved labels as negative labels, but this assumption introduces label noise in the form of false negatives. To understand the negative impact of false negative labels, we investigate how they affect the model's explanation. Our analysis reveals that two models, trained with full and partial labels respectively, highlight similar regions in their explanations, but with different scaling, where the model trained with partial labels tends to have lower attribution scores. Building on these findings, we propose a method to enhance the attribution scores of the model trained with partial labels, aiming to make its explanation resemble that of the model trained with full labels. This simple approach leads to a significant improvement in multi-label classification performance across three different datasets in a single positive label setting, as well as in a large-scale partial label setting. The code for our proposed method is available at https://github.com/youngwk/BridgeGapExplanationPAMC.