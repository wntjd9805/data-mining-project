This paper introduces a new problem of reconstructing the 3D geometry of an object inside a transparent enclosure. The challenges arise from the multiple reflections and refractions that occur at the interfaces between different media. These distortions make it difficult to accurately reconstruct the object's geometry using existing methods. To address this, the authors propose a novel approach that models the scene as two separate spaces - inside and outside the transparent enclosure. They utilize a neural reconstruction method called NeuS to represent the inner subspace's geometry and appearance. To handle complex light interactions, they combine volume rendering with ray tracing. By minimizing the difference between real and rendered images, they recover the model's underlying geometry and appearance. The proposed method is evaluated using both synthetic and real data and shows superior performance compared to state-of-the-art methods. The codes and data used in the experiments are available at a specified GitHub repository.