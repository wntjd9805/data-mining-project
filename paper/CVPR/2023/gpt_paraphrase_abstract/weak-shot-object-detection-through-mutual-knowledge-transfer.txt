This study focuses on weak-shot object detection, where a fully-annotated source dataset is used to improve detection performance on a target dataset that only has image-level labels for new categories. To bridge the gap between these datasets, the authors propose a bi-directional transfer of object knowledge. They introduce a novel Knowledge Transfer (KT) loss that distills objectness and class entropy from a proposal generator trained on the source dataset to optimize a multiple instance learning module on the target dataset. By jointly optimizing the classification loss and the KT loss, the module learns to classify object proposals into new categories using knowledge transferred from base categories in the source dataset. Additionally, the authors propose a Consistency Filtering (CF) method to remove inaccurate pseudo labels by assessing the stability of the multiple instance learning module when noise is introduced. Through iterative knowledge transfer between the source and target datasets, the proposed approach significantly improves detection performance on the target dataset. Experimental results on public benchmarks validate that the proposed method outperforms existing techniques without increasing model parameters or inference computational complexity.