The PointContrast method has been successful in unsupervised 3D representation learning using contrastive learning on raw RGB-D frames. However, the adoption of large-scale unsupervised learning in 3D has been hindered by two challenges: inefficient matching of RGB-D frames for contrastive views and the issue of mode collapse. To overcome these challenges, we propose an efficient and effective contrastive learning framework called Masked Scene Contrast (MSC). MSC generates contrastive views directly on scene-level point clouds using a carefully designed data augmentation pipeline and view mixing strategy. Additionally, we introduce reconstructive learning with contrastive cross masks to target the reconstruction of point color and surfel normal. The MSC framework significantly accelerates the pre-training process and achieves comparable performance to previous methods. Furthermore, MSC enables large-scale 3D pre-training across multiple datasets, leading to improved performance on various downstream tasks, such as achieving a 75.5% mIoU on the ScanNet semantic segmentation validation set.