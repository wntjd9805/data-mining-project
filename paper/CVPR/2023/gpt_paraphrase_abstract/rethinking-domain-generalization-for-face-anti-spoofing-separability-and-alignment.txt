This study focuses on the problem of generalization in face anti-spoofing (FAS) models when there are domain gaps, such as differences in image resolution, blurriness, and sensor variations. Previous approaches have treated domain-specific signals as detrimental and used metric learning or adversarial losses to remove them from the feature representation. However, we demonstrate that even when a domain-invariant feature space is learned from the training data, there is still a feature shift in unseen test domains, which hinders the generalizability of the classifier. Instead of aiming for a domain-invariant feature space, we propose a new approach called separability and alignment FAS (SA-FAS) where we encourage domain separability while ensuring that the trajectory from live to spoof is the same for all domains. We formulate SA-FAS as a problem of invariant risk minimization (IRM) and learn a domain-variant feature representation while maintaining a domain-invariant classifier. Our experiments on challenging cross-domain FAS datasets demonstrate the effectiveness of SA-FAS and show that it achieves state-of-the-art performance. The code for SA-FAS is available at https://github.com/sunyiyou/SAFAS.