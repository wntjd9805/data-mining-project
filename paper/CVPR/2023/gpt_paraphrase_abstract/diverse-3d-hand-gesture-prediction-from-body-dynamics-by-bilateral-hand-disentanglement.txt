This study focuses on the challenging task of predicting natural and diverse 3D hand gestures using upper body dynamics for virtual avatar creation. Previous approaches overlook the asymmetry between the hands, resulting in unnatural results. To address this, a novel two-stage method is proposed. In the first stage, natural hand gestures are generated by disentangling the motions of each hand using a Spatial-Residual Memory (SRM) module. This module models the spatial interaction between the body and each hand. To enhance coordination between the hands and body, a Temporal-Motion Memory (TMM) module is introduced to model the temporal association. The second stage aims to diversify the 3D hand predictions based on the initial output from stage one. A Prototypical-Memory Sampling Strategy (PSS) is proposed, which utilizes gradient-based Markov Chain Monte Carlo (MCMC) sampling to generate non-deterministic hand gestures. Extensive experiments demonstrate that the proposed method outperforms existing models on the B2H dataset and a newly collected TED Hands dataset. The code and dataset are available at the provided GitHub link.