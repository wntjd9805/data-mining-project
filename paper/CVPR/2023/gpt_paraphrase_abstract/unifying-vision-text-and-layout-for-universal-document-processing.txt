We introduce Universal Document Processing (UDOP), a foundational model for Document AI that integrates text, image, and layout modalities and supports various task formats including document understanding and generation. UDOP utilizes the spatial relationship between text and document images to create a unified representation for text, image, and layout. Through the use of a novel Vision-Text-Layout Transformer, UDOP combines pretraining and multi-domain downstream tasks into a prompt-based sequence generation approach. The model is pretrained on large-scale unlabeled document datasets using self-supervised objectives and labeled data. Additionally, UDOP is capable of generating document images from text and layout using masked image reconstruction. This is the first instance in the field of document AI where a single model achieves high-quality neural document editing and content customization. Our approach outperforms existing methods on 8 Document AI tasks, such as document understanding and question answering, across diverse data domains including finance reports, academic papers, and websites. UDOP ranks first on the Document Understanding Benchmark leaderboard.