We propose a method for efficiently representing 3D scenes using neural radiance fields called nerflets. These nerflets are local representations of the scene that maintain their own position, orientation, and size. They contribute to reconstructions of the scene's panoptic, density, and radiance properties. By using photometric and inferred panoptic image supervision, we can optimize the parameters of the nerflets to create a decomposed representation of the scene, where each object instance is represented by a group of nerflets. Our experiments with indoor and outdoor environments show that nerflets outperform traditional global NeRFs in terms of scene fitting and approximation. Additionally, nerflets allow for the generation of panoptic and photometric renderings from any viewpoint, and enable tasks like 3D panoptic segmentation and interactive editing that are not possible with NeRFs alone.