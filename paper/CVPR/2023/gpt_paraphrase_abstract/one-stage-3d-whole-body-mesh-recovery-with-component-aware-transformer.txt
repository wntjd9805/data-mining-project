We propose a one-stage pipeline called OSX for whole-body mesh recovery, which aims to estimate the 3D parameters of the human body, face, and hands from a single image. Existing methods use separate networks for each body part, but this copy-paste approach leads to difficulties in recovering the connections between different parts and results in unnatural poses. In OSX, we introduce a Component Aware Transformer (CAT) that consists of a global body encoder and a local face/hand decoder. The encoder predicts the body parameters and provides a high-quality feature map for the decoder, which uses a feature-level upsample-crop scheme and keypoint-guided deformable attention to accurately estimate the face and hands. Our pipeline is simple yet effective, avoiding the need for manual post-processing and preventing implausible predictions. We also introduce a new dataset called UBody, which contains high-quality 2D and 3D annotations of whole-body images in diverse real-life scenarios. Experimental results demonstrate the effectiveness of OSX in whole-body mesh recovery.