This paper introduces a group exchange-masking (GEM) strategy to improve the robustness of co-salient object detection (CoSOD) models. The traditional CoSOD task involves segmenting common salient objects in a group of relevant images. However, existing models assume group consensus and struggle when faced with irrelevant images in the testing group, limiting their real-world applicability. To overcome this issue, the GEM strategy selects images from two different groups using a learning-based approach and exchanges them. The proposed feature extraction module considers both the uncertainty caused by irrelevant images and the consensus among relevant images. It incorporates a latent variable generator branch, which uses a conditional variational autoencoder to generate uncertainly-based global stochastic features. Additionally, a CoSOD transformer branch captures correlation-based local features that contain group consistency information. The outputs of these branches are concatenated and passed through a transformer-based decoder to produce robust co-saliency predictions. Extensive evaluations comparing our method with state-of-the-art approaches demonstrate its superiority in co-saliency detection, particularly in scenarios with irrelevant images.