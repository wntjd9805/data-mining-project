Modern methods for incremental learning in semantic segmentation typically rely on dense annotations to learn new categories. However, this pixel-by-pixel labeling process is both costly and time-consuming. To address this issue, weakly incremental learning for semantic segmentation (WILSS) has emerged as a promising alternative, aiming to learn to segment new classes using image-level labels which are more cost-effective and widely available. Although WILSS has shown comparable results, the lack of detailed information provided by image-level labels limits its performance in accurately locating each segment. In this study, we propose a novel and data-efficient framework for WILSS called FMWISS. Our approach utilizes pre-training and co-segmentation to distill knowledge from complementary foundation models, allowing us to generate dense pseudo labels. We further improve the quality of these pseudo masks using a teacher-student architecture and a proposed dense contrastive loss. Additionally, we introduce memory-based copy-paste augmentation to mitigate the issue of catastrophic forgetting, which occurs when old classes are overlooked. Through extensive experiments on the Pascal VOC and COCO datasets, we demonstrate the superior performance of our framework. For instance, in the 15-5 VOC setting, FMWISS achieves 70.7% and 73.3% accuracy, surpassing the state-of-the-art method by 3.4% and 6.1%, respectively.