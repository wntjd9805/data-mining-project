The task of recognizing visible-infrared images is difficult due to the significant visual differences between heterogeneous images. Many existing methods achieve promising results by using transfer learning, such as pretraining on the ImageNet dataset, using advanced neural architectures like ResNet and ViT. However, these methods overlook the negative impact of pretrained color prior knowledge and their high computational requirements make them impractical for limited resource scenarios. To address these issues, this paper introduces a new task-oriented pretrained lightweight neural network called TOPLight for visible-infrared recognition. The TOPLight method incorporates a fake domain loss during the pretraining stage to simulate domain conflicts and sample variations, allowing the network to learn how to handle these challenges. This results in a more generalized feature representation for heterogeneous images. Additionally, the paper introduces an effective fine-grained dependency reconstruction module (FDR) that identifies significant pattern dependencies shared between two modalities. Extensive experiments conducted on visible-infrared person re-identification and face recognition datasets demonstrate the superiority of the proposed TOPLight method. It outperforms current state-of-the-art methods while demanding fewer computational resources.