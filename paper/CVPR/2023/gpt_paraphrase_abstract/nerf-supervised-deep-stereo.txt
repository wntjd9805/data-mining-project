A new approach is presented for training deep stereo networks without the need for ground-truth data. By using advanced neural rendering techniques, stereo training data is generated from image sequences captured with a handheld camera. A training procedure supervised by NeRF is then applied, utilizing rendered stereo triplets to address occlusions and depth maps as approximate labels. This approach enables the trained stereo networks to accurately predict detailed and clear disparity maps. Experimental results demonstrate that models trained using this method achieve a 30-40% improvement over existing self-supervised techniques on the challenging Middlebury dataset. Moreover, these models bridge the performance gap with supervised models and often surpass them in zero-shot generalization.