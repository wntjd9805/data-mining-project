We present a new method for rendering realistic and personalized hands in real-time under different lighting conditions. Our approach utilizes a teacher-student framework, where the teacher model learns the appearance of hands under a single point light in a controlled environment. This allows us to generate hand images under any lighting condition, but it requires significant computation. To overcome this, we train a more efficient student model using the images rendered by the teacher model as training data. The student model can directly predict the appearance of hands under natural lighting conditions in real-time. To ensure generalization, we condition the student model with physics-inspired illumination features such as visibility, diffuse shading, and specular reflections. These features are computed on a simplified geometry, resulting in minimal computational overhead. Our key insight is that these features have a strong correlation with global light transport effects, which makes them suitable for conditioning the neural relighting network. Additionally, unlike bottleneck illumination conditioning, these features are spatially aligned based on the underlying geometry, leading to better generalization to unseen lighting conditions and hand poses. In our experiments, we demonstrate the effectiveness of our illumination feature representations, outperforming baseline methods. We also showcase the ability of our approach to realistically relight two interacting hands. This work was conducted during an internship at Meta.