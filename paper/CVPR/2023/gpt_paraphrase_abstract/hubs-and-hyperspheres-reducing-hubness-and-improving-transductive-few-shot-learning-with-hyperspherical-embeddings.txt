Distance-based classification is commonly used in transductive few-shot learning (FSL) but is hindered by the hubness problem, where certain points occur frequently in multiple nearest neighbor lists. This can negatively impact classification performance when hubs from one class appear frequently among the nearest neighbors of points from another class. To address this issue, we demonstrate that hubness can be eliminated by uniformly distributing representations on the hypersphere. We propose two new approaches to embed representations on the hypersphere, striking a balance between uniformity and local similarity preservation. This reduces hubness while preserving the class structure. Experimental results indicate that our methods effectively reduce hubness and significantly enhance the accuracy of transductive FSL for a variety of classifiers.