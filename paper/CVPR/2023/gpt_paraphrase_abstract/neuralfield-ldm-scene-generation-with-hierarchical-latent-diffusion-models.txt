We propose a generative model called NeuralField-LDM for automatically creating realistic 3D scenes. By utilizing LatentDiffusion Models, which are effective in generating high-quality 2D content, we train a scene auto-encoder to represent image and pose pairs as a neural field. This neural field is represented by density and feature voxel grids that can be used to generate new views of the scene. To further compress this representation, we train a latent-autoencoder that maps the voxel grids to a set of latent representations. Finally, a hierarchical diffusion model is fitted to these latents to complete the scene generation process. Our model outperforms existing scene generation models and can be used for conditional scene generation, scene inpainting, and scene style manipulation in various 3D content creation applications.