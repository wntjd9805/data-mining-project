This paper addresses the question of whether a hybrid discriminative-generative model can be trained using a single network. The introduction of the Joint Energy-based Model (JEM) has provided a positive answer to this question, achieving high accuracy in classification and image generation. However, there are still two gaps in performance compared to other models: the accuracy gap to the standard softmax classifier and the generation quality gap to state-of-the-art generative models. This paper presents several training techniques to bridge these gaps. Firstly, the sharpness-aware minimization (SAM) framework is incorporated into the training of JEM to improve energy landscape smoothness and generalization. Secondly, data augmentation is excluded from the maximum likelihood estimate pipeline of JEM to mitigate its negative impact on image generation quality. Extensive experiments on multiple datasets demonstrate that the proposed SADA-JEM approach achieves state-of-the-art performance and outperforms JEM in various aspects such as image classification, image generation, calibration, out-of-distribution detection, and adversarial robustness. The code for SADA-JEM is available at https://github.com/sndnyang/SADAJEM.