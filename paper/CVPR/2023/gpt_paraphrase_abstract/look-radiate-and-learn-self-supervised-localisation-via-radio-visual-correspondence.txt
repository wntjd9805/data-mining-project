Next generation cellular networks will incorporate radio sensing functions in addition to regular communication, allowing for extensive outdoor sensing coverage worldwide. While deep learning has revolutionized computer vision, its application to radio perception tasks has been limited due to the lack of systematic datasets and benchmarks specifically designed for studying the performance and potential of radio sensing. To fill this gap, we introduce MaxRay, a synthetic radio-visual dataset and benchmark that enables accurate target localization in the radio domain. We propose a method to learn radio target localization without supervision by extracting self-coordinates from radio-visual correspondence. These self-supervised coordinates are then used to train a radio localizer network. Through comparisons with state-of-the-art baselines, we demonstrate the effectiveness of our approach. Our findings indicate that precise radio target localization can be automatically learned from paired radio-visual data without the need for labeled data, which is crucial for empirical analysis. This discovery paves the way for extensive data scalability and plays a significant role in achieving robust radio sensing on a unified communication-perception cellular infrastructure. The dataset will be hosted on IEEE DataPort.