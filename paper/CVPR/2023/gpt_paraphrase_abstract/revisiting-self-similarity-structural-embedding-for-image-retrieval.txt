Existing image retrieval approaches do not typically consider geometric structure in the global retrieval stage. In this study, we propose a new network called Structural Embedding Network (SENet) that incorporates both visual and structural cues of images into global image representation. SENet captures the internal structure of images and compresses them into dense self-similarity descriptors while learning diverse structures from different images. These descriptors, along with the original image features, are fused and pooled to create a global embedding that represents both geometric and visual cues. Our novel structural embedding approach outperforms existing methods on various image retrieval benchmarks, demonstrating its robustness against similar-looking distractors. The code and models for SENet can be accessed at https://github.com/sungonce/SENet.