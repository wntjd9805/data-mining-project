PanoHead is a novel 3D-aware generative model that allows for the synthesis and reconstruction of high-quality, view-consistent images of full human heads in 360 degrees. Unlike existing methods, PanoHead can handle diverse appearances and detailed geometry using only unstructured images for training. The model achieves this by leveraging the power of 3D generative adversarial networks (GANs) and addressing the alignment gap in training from in-the-wild images with different viewpoints. A two-stage self-adaptive image alignment technique is proposed to ensure robust training of the 3D GAN. Additionally, a tri-grid neural volume representation is introduced to handle the entanglement of front-face and back-head features. This representation incorporates prior knowledge of 2D image segmentation in the adversarial learning process, enabling the synthesis of composite heads in various backgrounds. The proposed method outperforms previous 3D GANs by generating high-quality 3D heads with accurate geometry and diverse appearances, including hairstyles such as long wavy and afro styles, that can be rendered from arbitrary poses. Furthermore, the system is capable of reconstructing full 3D heads from single input images, making it suitable for creating personalized realistic 3D avatars.