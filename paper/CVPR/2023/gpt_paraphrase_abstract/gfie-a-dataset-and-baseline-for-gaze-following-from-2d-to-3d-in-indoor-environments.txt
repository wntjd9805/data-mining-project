Gaze-following research involves automatically determining where a person is looking in a scene, specifically within the field of gaze estimation. This is important for understanding human intention, such as identifying objects or regions of interest. However, existing datasets used for gaze-following tasks have flaws in their collection of gaze point labels. Manual labeling introduces subjective bias and is time-consuming, while automatic labeling with an eye-tracking device alters the person's appearance. To address these issues, we present GFIE, a new dataset recorded using a gaze data collection system we developed. This system includes an Azure Kinect and a laser rangefinder, which generate a laser spot to direct the subject's attention while they perform in front of the camera. We have also developed an algorithm to locate the laser spots in images, allowing us to annotate 2D/3D gaze targets and remove ground truth introduced by the spots. This procedure enables us to obtain unbiased labels in unconstrained environments semi-automatically. Additionally, we propose a baseline method using stereo field-of-view perception to establish a 2D/3D gaze-following benchmark on the GFIE dataset. For more information, please visit our project page: https://sites.google.com/view/gfie.