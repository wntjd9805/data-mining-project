This study focuses on the importance of movie highlights in efficient browsing and their role on social media platforms. The researchers make two observations: (1) The labeling of highlights by different annotators is uncertain, leading to inaccurate and time-consuming annotations. (2) Existing video corpora, such as trailers, can be useful for highlight detection, but they are often noisy and incomplete. To address these challenges, the researchers propose a practical and promising approach called "learning with noisy labels." This approach leverages scene segmentation in movie trailers to obtain complete shots, which are considered as noisy labels. They then introduce a framework called Collaborative noisy Label Cleaner (CLC) that consists of two modules: augmented cross-propagation (ACP) and multi-modality cleaning (MMC). ACP aims to combine audio-visual signals to learn unified multi-modal representations, while MMC aims to achieve cleaner highlight labels by observing changes in losses across different modalities. To validate the effectiveness of CLC, the researchers collect a large-scale highlight dataset called MovieLights and conduct comprehensive experiments on this dataset as well as the YouTubeHighlights dataset. The results demonstrate the effectiveness of their approach. The code for their approach is available on GitHub.