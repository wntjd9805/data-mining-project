The Dynamic Neural Radiance Field (NeRF) algorithm is effective in generating realistic images from a single RGB video of a dynamic scene. However, it fails to accurately model changes in reflected color for moving specular objects. To address this issue, we propose a modified NeRF function that considers surface position and orientation in the observation space. This allows for the preservation of different reflected colors when mapping specular surfaces to a common canonical space. Additionally, we incorporate a mask of moving objects to guide the deformation field, mitigating the challenge of finding temporal correspondences with only RGB supervision. We evaluate our approach using a dataset of various moving specular objects in realistic environments and find that our method significantly improves the reconstruction quality compared to existing NeRF models. Our code and data can be found on the project website.