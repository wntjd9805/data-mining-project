This study explores the advantages of using tracking and 3D poses for action recognition. Rather than analyzing actions at a fixed point in space, the researchers adopt a Lagrangian view that considers actions over a trajectory of human motion. By utilizing tracklets of people, the researchers are able to predict their actions. The study demonstrates the benefits of using 3D pose to infer actions and examines person-person interactions. Additionally, the researchers propose a Lagrangian Action Recognition model that combines 3D pose and contextualized appearance over tracklets. The method achieves superior performance on the AVA v2.2 dataset in both pose-only settings and standard benchmark settings. When considering actions based solely on pose cues, the pose model achieves a significant mAP gain compared to the current state-of-the-art, while the fused model achieves a smaller mAP gain. The code and results of the study can be accessed at: https://brjathu.github.io/LART.