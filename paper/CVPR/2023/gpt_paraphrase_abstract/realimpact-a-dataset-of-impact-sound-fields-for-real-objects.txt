This abstract discusses the lack of a standard dataset for studying the impact sounds of real objects in audio-visual learning and simulation calibration. The authors introduce a dataset called REALIMPACT, which consists of 150,000 recordings of impact sounds from 50 everyday objects. The dataset includes detailed annotations such as impact locations, microphone locations, contact force profiles, material labels, and RGBD images. The authors also explore the use of this dataset as a reference for simulating object impact sounds that match the real world. Additionally, they demonstrate the dataset's usefulness for acoustic and audio-visual learning through the evaluation of listener location classification and visual acoustic matching tasks.