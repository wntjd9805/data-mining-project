This study focuses on dense geometric matching, which involves finding pixel-wise correspondence between two images representing the same 3D structure. Previous methods have used transformer blocks to correlate the features of these two images. However, existing pretraining tasks like image classification and masked image modeling (MIM) are not effective in pretraining the cross-frame module, leading to suboptimal performance. To address this issue, the authors propose a modification to MIM that involves reconstructing a pair of masked images instead of a single one, allowing for pretraining of the transformer module. They also introduce a decoder into the pretraining process to improve upsampling results. Additionally, they propose a new module called cross-frame global matching (CFGM) to handle textureless areas and use a homography loss to further enhance its learning. The combination of these techniques leads to state-of-the-art performance in geometric matching. The codes and models used in this study are available at the provided GitHub link.