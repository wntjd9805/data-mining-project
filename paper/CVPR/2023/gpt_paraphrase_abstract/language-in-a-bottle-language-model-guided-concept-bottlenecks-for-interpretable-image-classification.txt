Concept Bottleneck Models (CBM) are models that provide human-readable explanations for their decisions, making them valuable in high-stakes applications. However, CBMs have limitations, as they require manual specification of concepts and often perform worse than black box models. In this study, we propose a new approach called Language Guided Bottlenecks (LaBo) to construct high-performance CBMs without manual concept specification. LaBo utilizes a language model, GPT-3, to generate potential bottlenecks by producing factual sentences about categories relevant to a given problem domain. A submodular utility is used to efficiently search for informative and diverse bottlenecks. These bottlenecks, represented by GPT-3's sentential concepts, can be aligned with images using CLIP to form a bottleneck layer. Experimental results demonstrate that LaBo is an effective method for identifying important concepts in visual recognition. When evaluated on 11 diverse datasets, LaBo bottlenecks outperform black box linear probes in few-shot classification, achieving 11.7% higher accuracy with just 1 shot and comparable performance with more data. Overall, LaBo shows that interpretable models can be widely applied with similar or better performance than black box approaches.