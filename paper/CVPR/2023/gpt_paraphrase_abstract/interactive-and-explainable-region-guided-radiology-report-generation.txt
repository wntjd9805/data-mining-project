The automatic generation of radiology reports can help radiologists save time in writing reports. However, current methods do not focus on specific anatomical regions in the images. To address this, we propose a simple yet effective model that identifies anatomical regions and describes them individually in the final report. Our method introduces interactive capabilities and offers transparency and explainability, unlike previous methods that lack human intervention and limited explainability. Through extensive experiments, we demonstrate that our method outperforms previous models and showcases its interactive features. The code and checkpoints for our method can be found at https://github.com/ttanida/rgrg.