The issue of biases in Visual Question Answering (VQA) models is well-known, as these models tend to exploit biases in the dataset when making predictions. Previous methods to address this problem have used ensemble techniques, training an additional biased model to improve the performance of a target model. However, these methods determine bias based on label statistics or single modal branches. To better understand and address bias in a target VQA model, we propose a new method called GenB. GenB directly trains a bias model from the target model using a generative network. This is achieved by combining adversarial objectives and knowledge distillation. We then use GenB as a bias model to debias the target model. We conducted extensive experiments on various VQA bias datasets such as VQA-CP2, VQA-CP1, GQA-OOD, and VQA-CE. Our results, using the LXMERT architecture on VQA-CP2, demonstrate the effectiveness of our method, achieving state-of-the-art performance. The answer format focuses solely on the main idea of the abstract.