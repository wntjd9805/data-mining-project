Recent research suggests that deep neural networks (DNNs) used in computer vision tend to be overly confident in their predictions, leading to poor calibration. While existing methods have addressed calibration for classification tasks, there has been little to no exploration of calibration for object detection methods, which are crucial for vision-based security and safety. In this study, we propose a new technique for calibrating object detection methods during training. Our approach addresses both multiclass confidence and box localization by leveraging predictive uncertainties. Through extensive experiments on various detection benchmarks, we show that our method consistently outperforms baseline approaches in reducing calibration error for both in-domain and out-of-domain predictions. Our code and models can be found at https://github.com/bimsarapathiraja/MCCL.