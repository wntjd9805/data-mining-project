Despite advancements in generative technology, challenges related to intellectual property protection and the supervision of malicious content have emerged. Current efforts to manage synthetic images involve attributing them to a specific set of potential source models. However, this closed-set classification approach has limitations in real-world scenarios where arbitrary models generate content. In this study, we address the task of Open-Set Model Attribution (OSMA), which involves attributing images to known models while identifying those from unknown models. OSMA is more challenging than existing open-set recognition tasks as the distinction between images from known and unknown models may only exist in visually imperceptible traces. To tackle this, we propose a Progressive Open Space Expansion (POSE) solution. POSE simulates open-set samples that maintain the same semantics as closed-set samples but are embedded with different imperceptible traces. By applying a diversity constraint, the open space is progressively simulated using a set of lightweight augmentation models. We consider three real-world scenarios and create an OSMA benchmark dataset that includes unknown models trained with various random seeds, architectures, and datasets compared to the known models. Extensive experiments on the dataset demonstrate that POSE outperforms existing model attribution methods and off-the-shelf open-set recognition methods. The code for POSE can be found on Github: https://github.com/ICTMCG/POSE.