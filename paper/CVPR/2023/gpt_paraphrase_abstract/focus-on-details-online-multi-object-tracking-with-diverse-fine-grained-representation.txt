In Multiple Object Tracking (MOT), having a discriminative representation is crucial to maintain a unique identifier for each target. Current MOT methods rely on coarse-grained global representations extracted from the bounding box region or center point, which become unreliable when targets are occluded. To address this issue, we propose exploring diverse fine-grained representations that comprehensively describe appearance from both global and local perspectives. This requires high feature resolution and precise semantic information. To overcome the semantic misalignment caused by indiscriminate contextual information aggregation, we introduce the Flow Alignment FPN (FAFPN) for multi-scale feature alignment aggregation. FAFPN generates semantic flow among feature maps of different resolutions to transform their pixel positions. Additionally, we present the Multi-head Part Mask Generator (MPMG), which extracts fine-grained representation based on the aligned feature maps. The MPMG uses multiple parallel branches to focus on different parts of targets and generate local masks without label supervision. The inclusion of diverse details in the target masks enhances the fine-grained representation. Finally, by employing the Shufï¬‚e-Group Sampling (SGS) training strategy with balanced positive and negative samples, we achieve state-of-the-art performance on the MOT17 and MOT20 test sets. Even on DanceTrack, where target appearances are highly similar, our method outperforms Byte-Track by 5.0% on HOTA and 5.6% on IDF1. Extensive experiments demonstrate the effectiveness of diverse fine-grained representation in improving Re-ID in MOT.