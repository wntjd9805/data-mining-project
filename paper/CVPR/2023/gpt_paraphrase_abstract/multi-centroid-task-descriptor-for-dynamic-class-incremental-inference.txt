There are two main types of incremental learning: class-incremental learning and task-incremental learning. The key difference lies in whether the task ID is provided during evaluation. This study demonstrates that task information serves as a strong prior knowledge, leading to significant improvement over the class-incremental learning baseline. To leverage this observation, the authors propose a gate network to predict the task ID for class incremental inference. However, this task prediction is challenging because there is no explicit semantic relationship between categories within the concept of a task. To address this, the authors propose a multi-centroid task descriptor that assumes data within a task can form multiple clusters. The cluster centers are optimized by pulling relevant sample-centroid pairs closer while pushing others away, ensuring at least one centroid is close to a given sample. To select relevant pairs, class prototypes are used as proxies and a bipartite matching problem is solved, ensuring that the task descriptor is representative yet not degenerate to uni-modal. As a result, the dynamic inference network is trained independently of the baseline and provides a flexible and efficient solution for distinguishing between tasks. Extensive experiments demonstrate that this approach achieves state-of-the-art results, such as a 72.41% average accuracy on CIFAR100-B0S50, outperforming DER by 3.40%.