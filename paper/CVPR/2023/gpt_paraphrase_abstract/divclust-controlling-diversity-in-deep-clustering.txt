Deep Learning has been successful in the field of machine learning, particularly in the area of clustering. However, current deep clustering methods do not efficiently produce multiple diverse partitionings for a given dataset. This is important because having a diverse set of base clusterings improves the results compared to relying on a single clustering. To address this issue, we propose Div-Clust, a diversity controlling loss that can be integrated into existing deep clustering frameworks to generate multiple clusterings with the desired level of diversity. We conducted experiments using various datasets and deep clustering frameworks and found that our method effectively controls diversity with minimal computational cost. The clusterings learned by Div-Clust outperform single-clustering baselines, and when combined with an off-the-shelf consensus clustering algorithm, Div-Clust consistently outperforms single-clustering baselines, enhancing the performance of the base deep clustering framework. The code for Div-Clust is available at https://github.com/ManiadisG/DivClust.