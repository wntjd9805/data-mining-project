Automatic Perceptual Image Quality Assessment is a challenging problem that affects billions of internet and social media users on a daily basis. In order to advance research in this field, we propose a Mixture of Experts approach. This approach involves training two separate encoders in an unsupervised setting to learn high-level content and low-level image quality features. The unique aspect of our approach is its ability to generate low-level representations of image quality that complement the high-level features representing image content. We refer to the framework used to train the two encoders as Re-IQA.  To assess Image Quality in the Wild, we utilize the complementary low and high-level image representations obtained from the Re-IQA framework. These representations are used to train a linear regression model, which maps the image representations to ground truth quality scores. Figure 1 illustrates this process. Our method achieves state-of-the-art performance on large-scale image quality assessment databases that include both real and synthetic distortions. This demonstrates the effectiveness of training deep neural networks in an unsupervised setting to produce perceptually relevant representations.   Based on our experiments, we conclude that the low and high-level features obtained through our approach are indeed complementary, and they positively impact the performance of the linear regressor. To facilitate further research in this area, we will publicly release all the codes associated with this work on GitHub.