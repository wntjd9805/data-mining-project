Current methods for estimating 3D human pose and shape (HPS) have made significant progress, but they still struggle to accurately estimate the movements of humans in global coordinates, especially when the camera is also moving. This creates challenges in disentangling the motion of humans and the camera. To overcome these issues, we propose a novel 5D representation (space, time, and identity) that allows for comprehensive reasoning about people in scenes. Our method, called TRACE, introduces innovative architectural components including two "maps" that enable reasoning about the 3D trajectory of people over time in both camera and world coordinates. We also incorporate a memory unit that facilitates persistent tracking of people during occlusions. TRACE stands out as the first one-stage method that simultaneously recovers and tracks 3D humans in global coordinates from dynamic cameras. By training TRACE end-to-end and leveraging full image information, we achieve state-of-the-art performance on tracking and HPS benchmarks. We have made the code and dataset openly available for research purposes. It is important to note that this work was conducted during Yu Sun's internship at JD.com.