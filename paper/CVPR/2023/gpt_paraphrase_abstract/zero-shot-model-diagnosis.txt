This study focuses on the need for explainable behavior in deep vision models to ensure confidence in their reliability and fairness. Evaluating these models traditionally involves building a labeled test set and assessing their performance. However, creating a balanced test set can be time-consuming, expensive, and error-prone. This paper proposes a method called Zero-shot Model Diagnosis (ZOOM) that enables the evaluation of deep learning models' sensitivity to visual attributes without the need for a test set or labeling. The system relies on a generative model and CLIP, allowing users to select prompts relevant to the problem. The system then automatically searches for semantic counterfactual images, which are synthesized images that change the model's prediction in the case of a binary classifier. The methodology is evaluated across various visual tasks and domains, including classification, key-point detection, and segmentation. Extensive experiments demonstrate that the proposed method can generate counterfactual images and provide sensitivity analysis for model diagnosis without relying on a test set.