Recently, there has been significant progress in deep learning-based facial landmark detection. However, the issue of semantic ambiguity has hindered detection performance. This problem arises when inconsistent annotations are produced due to the ambiguity in the semantic meaning of facial landmarks. This inconsistency negatively impacts the convergence of the model, leading to reduced accuracy and unstable predictions. In order to address this problem, we propose a novel approach called Self-adapTive Ambiguity Reduction (STAR) loss.We observe that semantic ambiguity leads to an anisotropic predicted distribution. This insight inspires us to use the predicted distribution to represent semantic ambiguity. Building upon this observation, we introduce the STAR loss, which measures the anisotropy of the predicted distribution. Unlike the standard regression loss, the STAR loss is designed to be small when the predicted distribution is anisotropic. This adaptive nature of the STAR loss helps mitigate the impact of semantic ambiguity.Furthermore, we propose two eigen-value restriction methods to prevent abnormal changes in the distribution and premature convergence of the model. These methods ensure that the distribution remains stable and the model continues to learn effectively.Through comprehensive experiments, we demonstrate that our STAR loss outperforms state-of-the-art methods on three benchmark datasets: COFW, 300W, and WFLW. Importantly, our approach incurs minimal computation overhead. The code for our method is available at https://github.com/ZhenglinZhou/STAR.