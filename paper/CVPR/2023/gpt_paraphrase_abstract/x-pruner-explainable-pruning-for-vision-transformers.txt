Vision transformer models have gained popularity for various tasks, but their high computational costs and memory requirements make them impractical for edge platforms. Previous approaches to pruning transformers have overlooked the relationship between internal units and target classes, resulting in lower performance. To address this issue, we propose X-Pruner, a new explainable pruning framework that considers the explainability of the pruning criterion. We introduce an explainability-aware mask to measure the contribution of each prunable unit to predicting target classes, which is learned in an end-to-end manner. Additionally, we adaptively search for layer-wise thresholds to differentiate between pruned and unpruned units based on their explainability-aware mask values, preserving informative units and learning the pruning rate. We apply X-Pruner to popular transformer models like DeiT and Swin Transformer and evaluate its performance. Extensive simulations show that X-Pruner outperforms existing black-box methods, significantly reducing computational costs with only slight performance degradation. The code for X-Pruner is available at https://github.com/vickyyu90/XPruner.