Motion segmentation is a crucial task in computer vision with various applications. Optical flow is commonly used to segment video frames based on coherent motion. However, the temporal consistency aspect is often overlooked. This paper proposes an innovative unsupervised spatio-temporal framework for motion segmentation using optical flow. The framework utilizes a 3D network to segment multiple motions by taking a sub-volume of consecutive optical flows as input and generating a sub-volume of coherent segmentation maps. The network is trained in an unsupervised manner, with the loss function incorporating a flow reconstruction term involving spatio-temporal motion models and a regularization term to enforce temporal consistency on the masks. The proposed method also includes an easy temporal linkage of the predicted segments and a flexible and efficient way of coding U-nets. Experimental results on various VOS benchmarks demonstrate convincing quantitative results without using appearance information or training with ground-truth data. Visual results highlight the significant contribution of short- and long-term temporal consistency achieved by the proposed optical flow segmentation method.