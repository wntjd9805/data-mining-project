Semi-supervised semantic segmentation (SSS) has recently gained attention in research due to its ability to reduce the need for large amounts of fully annotated training data. However, current SSS methods face issues with confirmation bias from the pseudo-labeling process. To address this, a co-training framework has been used, but it relies on artificial perturbations that do not lead to optimal solutions. In this study, we propose a new method called conflict-based cross-view consistency (CCVC) for SSS. Our approach utilizes a two-branch co-training framework to enforce the learning of informative features from irrelevant views. We introduce a cross-view consistency (CVC) strategy that encourages the two sub-networks to learn distinct features while generating consistent prediction scores. This prevents collapsing of the sub-networks. Additionally, we propose a conflict-based pseudo-labeling (CPL) method to ensure the model learns from conflicting predictions, leading to a more stable training process. Our CCVC approach achieves state-of-the-art performance on SSS benchmark datasets. The code for our method is available at https://github.com/xiaoyao3302/CCVC.