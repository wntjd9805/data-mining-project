We introduce PersonNeRF, a technique that can generate realistic images of a person from a collection of photos taken at different times with various body poses and appearances. PersonNeRF utilizes a customized neural volumetric 3D model to render the subject from different viewpoints, body poses, and appearances. A major difficulty in this process is the limited observations available for each body pose and appearance. To overcome this, we create a canonical T-pose neural volumetric representation that allows for appearance variation while maintaining a shared pose-dependent motion field across all observations. Additionally, we incorporate regularization techniques to ensure smoothness in the recovered volumetric geometry. Our results show that PersonNeRF outperforms previous methods in generating high-quality images of people from unstructured photo collections, enabling free-viewpoint human rendering.