The Neural Radiance Field (NeRF) is a groundbreaking method for synthesizing novel views, but it suffers from performance degradation without a dense set of training images. Previous solutions relied on additional resources, contradicting the goal of efficient training for sparse-input novel-view synthesis. This study introduces MixNeRF, a training strategy that models a ray using a mixture density model. MixNeRF estimates the joint distribution of RGB colors along the ray by employing a mixture of distributions. Additionally, a new task of ray depth estimation is proposed as a training objective, which is closely related to 3D scene geometry. The colors are further improved by regenerating blending weights based on the estimated ray depth, enhancing robustness for colors and viewpoints. MixNeRF outperforms other methods in standard benchmarks and achieves superior efficiency in training and inference.