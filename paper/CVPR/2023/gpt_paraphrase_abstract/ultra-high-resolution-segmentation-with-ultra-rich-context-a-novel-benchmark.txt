The field of Ultra-High Resolution (UHR) segmentation requires a large-scale benchmark dataset to aid in its development. To address this need, the URUR dataset is introduced, which stands for Ultra-High Resolution dataset with Ultra-Rich Context. The URUR dataset consists of a significant number of high-resolution images (3,008 images of size 5,120Ã—5,120) captured in various complex scenes from 63 cities. It also includes rich contextual information with 1 million instances across 8 categories and fine-grained annotations with approximately 80 billion manually annotated pixels. Compared to existing UHR datasets like DeepGlobe, Inria Aerial, and UDD, the URUR dataset surpasses them in terms of quantity and quality. Additionally, a more efficient and effective framework called WSDNet is proposed for UHR segmentation, particularly with ultra-rich context. This framework incorporates a multi-level Discrete Wavelet Transform (DWT) to reduce computational burden while preserving spatial details. It also utilizes a Wavelet Smooth Loss (WSL) to reconstruct original structured context and texture with a smooth constraint. Experimental results on several UHR datasets demonstrate the state-of-the-art performance of WSDNet. The URUR dataset is publicly available at https://github.com/jankyee/URUR.