Deep functional maps have become a popular approach for non-rigid 3D shape correspondence tasks. One important aspect of this approach is learning feature functions that are used as constraints to solve for a functional map within the network. However, the exact nature of the information learned and stored in these features is not well understood. This paper explores whether these features can be used for purposes other than solving for functional maps. The authors find that, under certain conditions, the features learned in deep functional map approaches can be used as point-wise descriptors that can be directly compared across different shapes, without the need to solve for a functional map during testing. Based on their analysis, the authors propose modifications to the standard deep functional map pipeline that improve the structural properties of the learned features and enhance matching results. They also demonstrate that previous attempts to use extrinsic architectures for deep functional map feature extraction can be improved through simple architectural changes that align with the theoretical properties suggested by their analysis. By doing so, they bridge the gap between intrinsic and extrinsic surface-based learning and provide the necessary and sufficient conditions for successful shape matching. The code for their work is available at the provided link.