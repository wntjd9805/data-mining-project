This study focuses on the matching of 3D shapes, specifically those represented as surface meshes or point clouds. While point clouds are a common representation of raw 3D data, meshes provide more detailed topological information, although they require manual curation. Existing methods that rely solely on point clouds cannot achieve the same matching quality as mesh-based methods due to the lack of topological structure. To bridge this gap, the authors propose a self-supervised multimodal learning strategy that combines mesh-based functional map regularization with a contrastive loss that connects mesh and point cloud data. This approach allows for matching within and across different data modalities, including triangle meshes, complete point clouds, and partially observed point clouds. The method achieves state-of-the-art results on challenging benchmark datasets, even outperforming recent supervised methods. Furthermore, it demonstrates excellent generalization capabilities across different datasets. The code for this method is publicly available on GitHub.