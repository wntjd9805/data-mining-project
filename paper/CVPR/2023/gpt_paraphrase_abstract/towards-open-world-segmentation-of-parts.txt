Segmenting object parts, such as cup handles and animal bodies, is crucial in various real-world applications. However, this task requires significant annotation effort. Currently, the available dataset consists of only two hundred object categories, indicating the challenges in scaling up part segmentation to an unconstrained setting. To overcome this issue, we propose exploring a simplified yet effective and scalable task called class-agnostic part segmentation.In class-agnostic part segmentation, we disregard part class labels during training and consider all parts as a single class. We argue and demonstrate that models trained without part classes perform better in localizing and segmenting parts of unseen objects. Additionally, we introduce two enhancements to our approach.Firstly, we make the model object-aware by recognizing that parts are compositions that are bounded by the corresponding objects. Their appearances are not independent but rather bundled together. Leveraging this information improves the accuracy of part segmentation.Secondly, we present a novel approach to enhance part segmentation on unseen objects. We observed that pixel-wise features extracted by the model often reveal high-quality part segments for unseen objects. Inspired by this finding, we propose a self-supervised procedure that iterates between pixel clustering and supervised contrastive learning. This procedure helps in pulling pixels closer or pushing them away, leading to improved part segmentation.Through extensive experiments conducted on PartImageNet and Pascal-Part datasets, we demonstrate significant and consistent improvements achieved by our approach. This research is a critical step towards achieving open-world part segmentation.