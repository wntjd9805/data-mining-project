The assessment of an image's aesthetics is difficult due to the various factors that influence it, including composition, color, style, and high-level semantics. Current methods rely on human-labeled rating scores, which oversimplify the aesthetic information perceived by humans. User comments, on the other hand, provide more comprehensive and natural expressions of opinions and preferences regarding image aesthetics. In this study, we propose a method to learn image aesthetics from user comments and explore vision-language pretraining techniques to acquire multimodal aesthetic representations. We pretrained an image-text encoder-decoder model using image-comment pairs, employing contrastive and generative objectives to learn rich and generic aesthetic semantics without human labels. To effectively adapt the pretrained model for downstream image aesthetic assessment tasks, we also introduced a lightweight rank-based adapter that utilizes text as an anchor to learn the concept of aesthetic ranking. Our results demonstrate that our pretrained aesthetic vision-language model outperforms previous works in image aesthetic captioning using the AVA-Captions dataset. Furthermore, it exhibits powerful zero-shot capabilities in aesthetic tasks like zero-shot style classification and zero-shot image aesthetic assessment, surpassing many supervised baselines. By using the proposed adapter module with minimal fine-tuning parameters, our model achieves state-of-the-art performance in image aesthetic assessment on the AVA dataset.