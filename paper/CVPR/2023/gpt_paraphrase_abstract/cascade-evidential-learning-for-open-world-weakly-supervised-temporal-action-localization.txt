In recent years, Weakly-supervised Temporal Action Localization (WTAL) has made significant progress in recognizing and localizing action instances using only video-level labels during training. However, existing WTAL methods have a closed-set assumption, which is invalid in the dynamically changing open world where unknown actions constantly emerge. Open-world WTAL (OW-TAL) is a challenging task because annotations for unknown samples are unavailable, and the fine-grained annotations for known action instances can only be inferred ambiguously from video category labels. To address this problem, we propose the Cascade Evidential Learning framework, the first of its kind for OW-TAL. Our method utilizes multi-scale temporal contexts and knowledge-guided prototype information to progressively gather cascade and enhanced evidence for known action, unknown action, and background separation. We conducted extensive experiments on THUMOS-14 and ActivityNet-v1.3 datasets to validate the effectiveness of our approach. In addition to the classification metrics used by previous open-set recognition methods, we also evaluate our method using localization metrics, which are more suitable for OWTAL.