This paper proposes a method to improve the performance of Nerf-based Generative Adversarial Network (GAN) models in generating realistic face images of real subjects. While these models have been successful in generating fake identity images, generating accurate representations of real subjects has been challenging due to the "inversion issue". The proposed method involves fine-tuning the NeRF-GAN models using a single real image of a subject. By optimizing the latent code for the image, the method reduces the gap in identity between the generated image and the real subject. Additionally, 2D loss functions are used to improve the rendered image, and explicit and implicit 3D regularizations are applied to remove visual and geometrical artifacts. The effectiveness of the proposed method is confirmed through experiments on multiple NeRF-GAN models and datasets, demonstrating realistic, high-fidelity, and consistent 3D animation of real faces.