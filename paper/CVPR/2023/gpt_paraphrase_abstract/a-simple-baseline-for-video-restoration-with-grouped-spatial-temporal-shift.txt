Video restoration has important applications in restoring clear frames from degraded videos. Existing deep learning methods for video restoration often rely on complex network architectures, leading to high computational costs. In this study, we propose a simple yet effective framework based on grouped spatial-temporal shift. This lightweight technique captures inter-frame correspondences for multi-frame aggregation. By introducing grouped spatial shift, we achieve expansive effective receptive fields. Combined with basic 2D convolution, our framework effectively aggregates inter-frame information. Extensive experiments show that our framework outperforms the previous state-of-the-art method while using less computational cost. This suggests the potential of our approach to reduce computational overhead while maintaining high-quality results. The code for our framework is available at https://github.com/dasongli1/Shift-Net.