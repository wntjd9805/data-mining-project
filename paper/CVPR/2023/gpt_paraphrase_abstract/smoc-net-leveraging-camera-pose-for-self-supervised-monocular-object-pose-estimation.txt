Recently, there has been a growing interest in self-supervised 6D object pose estimation in computer vision. This approach involves training models using synthetic images with object poses, sometimes supplemented with un-annotated real images. However, existing methods face two main challenges. Firstly, their performance on real images is limited due to discrepancies between rendered and real images. Secondly, the training process is computationally expensive, primarily because of the use of a time-consuming differentiable renderer for object pose prediction.To address these challenges, we propose a novel approach called SMOC-Net (Network for Self-supervised Monocular Object pose estimation). SMOC-Net utilizes predicted camera poses from un-annotated real images to improve object pose estimation. Our approach is developed within a knowledge distillation framework, which consists of a teacher model and a student model. The teacher model initially estimates the object pose using a backbone estimation module and refines it with a geometric constraint derived from relative camera poses. The student model learns object pose estimation from the teacher model by imposing the relative-pose constraint. By leveraging the relative-pose constraint, SMOC-Net effectively reduces the domain gap between synthetic and real data and also reduces the training cost. Experimental results on two public datasets demonstrate that SMOC-Net significantly outperforms state-of-the-art methods while requiring much less training time compared to differentiable-renderer-based methods.