Federated Learning (FL) is a collaborative learning approach that trains object detection models using a distributed network of clients. However, FL is susceptible to model hijacking, where attackers manipulate the system by implanting Trojaned gradients through compromised clients. This paper proposes STDLens, a method to protect FL against such attacks. The paper explores existing mitigation techniques and identifies their shortcomings in analyzing Trojaned gradients. Based on this analysis, a three-tier forensic framework is introduced to detect and eliminate Trojaned gradients, thereby improving FL performance. The effectiveness of STDLens is demonstrated against various adaptive attacks, surpassing existing methods in accurately identifying and removing Trojaned gradients. The source code for STDLens is available at https://github.com/git-disl/STDLens.