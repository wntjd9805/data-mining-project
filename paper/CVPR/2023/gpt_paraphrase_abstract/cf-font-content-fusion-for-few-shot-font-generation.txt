To achieve few-shot font generation, it is beneficial to separate the content and style of font images. This allows for the transfer of style from a source domain to a target domain using only a few reference images. However, the content feature obtained from a representative font may not be optimal. To address this, we propose a content fusion module (CFM) that projects the content feature onto a linear space defined by the content features of basis fonts. This takes into account the variation in content features caused by different fonts. Additionally, our method includes a lightweight iterative style-vector refinement (ISR) strategy to optimize the style representation vector of reference images.   Furthermore, we treat the 1D projection of a character image as a probability distribution and utilize the distance between two distributions as the reconstruction loss (referred to as projected character loss, PCL). This distance metric focuses more on the overall shape of characters compared to L2 or L1 reconstruction loss.   We evaluated our method on a dataset of 300 fonts, each containing 6.5k characters. Experimental results demonstrate that our approach significantly outperforms existing state-of-the-art few-shot font generation methods. The source code for our method can be found at https://github.com/wangchi95/CF-Font.