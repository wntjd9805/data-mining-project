This paper introduces ViPLO, a novel approach for Human-Object Interaction (HOI) detection. HOI detection involves localizing and understanding the relationships between humans and objects in a scene. While two-stage HOI detectors are efficient in training and inference, they tend to have lower performance compared to one-stage methods due to outdated backbone networks and a lack of consideration for the human perception process in interaction classifiers. To address these issues, the authors propose ViPLO, which combines a Vision Transformer backbone with a Pose-Conditioned Self-Loop Graph. ViPLO introduces a new feature extraction method called masking with overlapped area (MOA) module. This module utilizes the overlapped area between each patch and the given region in the attention function, addressing the quantization problem associated with the Vision Transformer backbone. Additionally, ViPLO incorporates a graph with a pose-conditioned self-loop structure. This structure updates the human node encoding with local features of human joints, allowing the classifier to focus on specific joints to effectively identify the type of interaction. This design is motivated by the human perception process for HOI.Experimental results demonstrate that ViPLO achieves state-of-the-art performance on two public benchmarks, with a significant +2.07 mAP performance gain on the HICO-DET dataset. By leveraging the Vision Transformer backbone and the pose-conditioned self-loop graph, ViPLO overcomes the limitations of previous methods and enhances the accuracy of HOI detection.