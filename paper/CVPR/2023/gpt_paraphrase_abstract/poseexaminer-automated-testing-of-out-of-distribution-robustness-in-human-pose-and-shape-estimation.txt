The current benchmarks for testing human pose and shape (HPS) estimation methods are limited to scenarios similar to the training data, which can be problematic in real-world applications where the observed data may differ significantly. To address this issue, we have developed a simulator that allows for fine-grained control over human pose images, including variations in poses, shapes, and clothing. We have also created a learning-based testing method called PoseExaminer, which automatically diagnoses HPS algorithms by searching for failure modes within the parameter space of human pose images. Our approach uses a multi-agent reinforcement learning system to explore different parts of this high-dimensional parameter space. By using PoseExaminer, we have identified limitations in current state-of-the-art models that are relevant in real-world scenarios but overlooked by existing benchmarks. For example, we have discovered regions where realistic human poses are not accurately predicted, as well as reduced performance for individuals with skinny or corpulent body shapes. Furthermore, we have demonstrated that fine-tuning HPS methods based on the failure modes identified by PoseExaminer improves their robustness and performance on standard benchmarks. Researchers can access the code for PoseExaminer at https://github.com/qihao067/PoseExaminer.