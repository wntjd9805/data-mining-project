To address the demand for realistic and animatable digital avatars, we propose GANHead (Generative Animatable Neural Head Avatar). Existing methods struggle to meet all the necessary requirements, making this task challenging. GANHead utilizes fine-grained control over explicit expression parameters and realistic rendering results of implicit representations to generate complete and realistic head avatars. Our approach involves representing coarse geometry, fine-grained details, and texture through three networks in canonical space. This enables us to achieve flexible animation by defining the deformation field using standard linear blend skinning (LBS) with learned continuous pose and expression bases and LBS weights. GANHead allows for direct animation using FLAME parameters and generalizes well to unseen poses and expressions. Compared to state-of-the-art methods, GANHead outperforms in head avatar generation and raw scan fitting.