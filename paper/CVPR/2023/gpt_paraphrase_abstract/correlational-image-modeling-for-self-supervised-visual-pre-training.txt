We present a new and effective method called Correlational Image Modeling (CIM) for self-supervised visual pre-training. CIM involves a simple task where we randomly crop image regions from an input image and predict correlation maps between these regions and the rest of the image. Three important features make CIM a valuable self-supervisory task. Firstly, we use a variety of cropping techniques to generate useful pairs of image regions and contexts. Secondly, we utilize a bootstrap learning framework with online and target encoders to enhance the learning process. The online encoder processes the image regions while the target encoder handles the context. Lastly, we model the correlation maps using a cross-attention block, where the context acts as queries and the image regions serve as values and keys. Our experiments demonstrate that CIM performs equally well or better than state-of-the-art methods in self-supervised and transfer learning benchmarks. The code for CIM is available at https://github.com/weivision/Correlational-Image-Modeling.git.