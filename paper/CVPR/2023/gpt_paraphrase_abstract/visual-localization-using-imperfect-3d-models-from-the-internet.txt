Visual localization is a crucial aspect of various applications, such as augmented reality. Traditionally, localization algorithms rely on capturing and storing extensive data, followed by running Structure-from-Motion algorithms. However, an unexplored data source for building scene representations is readily available 3D models found on the Internet, such as hand-drawn CAD models or models generated from building footprints or aerial images. These models offer the advantage of immediate visual localization without the need for time-consuming data capturing and model building. Nevertheless, utilizing these models presents challenges due to their imperfections, such as lacking textures, simplistic scene geometry, or stretching. This paper investigates how these imperfections impact localization accuracy. To conduct this study, we introduce a new benchmark and provide a detailed experimental evaluation using multiple 3D models per scene. Our findings demonstrate that Internet-sourced 3D models hold potential as easily obtainable scene representations. However, there is ample room for improvement in visual localization pipelines. To encourage further research in this intriguing and challenging field, we make our benchmark available at v-pnk.github.io/cadloc.