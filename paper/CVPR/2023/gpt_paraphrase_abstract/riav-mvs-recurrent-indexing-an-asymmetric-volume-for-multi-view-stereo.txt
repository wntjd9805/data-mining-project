This paper introduces a learning-based approach for estimating depth from multiple views of posed images. The authors propose a "learning-to-optimize" method that uses a convolutional Gated Recurrent Unit (GRU) to regress the depth map by iteratively indexing a plane-sweeping cost volume. To enhance the construction of the cost volume, improvements are made at both the pixel and frame levels. At the pixel level, a transformer block is introduced to the reference image, breaking the symmetry of the Siamese network commonly used in multi-view stereo (MVS) to extract image features. This allows the network to extract global features from the reference image to predict its depth map. To account for potential inaccuracies in the poses between the reference and source images, a residual pose network is incorporated to correct the relative poses, rectifying the cost volume at the frame level. The proposed method is evaluated on real-world MVS datasets and achieves state-of-the-art performance in terms of both within-dataset evaluation and cross-dataset generalization.