Neural methods for representing implicit surfaces have achieved impressive results in reconstructing objects, but struggle when it comes to texture-less planar regions commonly found in indoor scenes. Current approaches address this issue by using image priors and assistive networks trained with large-scale annotated datasets.In this study, we propose a self-supervised super-plane constraint that utilizes the predicted surface's geometry cues to improve the reconstruction of plane regions without the need for ground truth annotations. Our approach involves an iterative training scheme that involves grouping pixels to create super-planes and optimizing the scene reconstruction network using the super-plane constraint.We found that our model trained with super-planes performs better than the traditional approach using annotated planes. This is because individual super-planes cover a larger area and contribute to more stable training. Extensive experiments demonstrate that our self-supervised super-plane constraint significantly improves the quality of 3D reconstruction, even surpassing the results obtained with ground truth plane segmentation. Moreover, the plane reconstruction results from our model can be used for auto-labeling in other vision tasks.The code and models used in this study are available at https://github.com/botaoye/S3PRecon.