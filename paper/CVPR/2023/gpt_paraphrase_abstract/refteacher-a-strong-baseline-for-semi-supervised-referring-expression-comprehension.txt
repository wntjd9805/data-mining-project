This paper introduces a novel approach called RefTeacher for semi-supervised learning in referring expression comprehension (REC). REC typically requires a large amount of instance-level annotations for fully supervised learning, which is time-consuming and costly. RefTeacher adopts a teacher-student learning paradigm, where the teacher REC network predicts pseudo-labels to optimize the student network. This allows REC models to utilize unlabeled data based on a small fraction of labeled data. The authors also address two key challenges in semi-supervised REC: sparse supervision signals and pseudo-label noise. They propose two novel designs, Attention-based Imitation Learning (AIL) and Adaptive Pseudo-label Weighting (APW), to overcome these challenges. AIL helps the student network imitate the teacher's recognition behaviors for better supervision, while APW enables adaptive adjustment of the contributions of pseudo-labels to avoid confirmation bias. The effectiveness of RefTeacher is validated through extensive experiments on three REC benchmark datasets. The results demonstrate significant improvements over fully supervised methods. Notably, with only 10% labeled data, the approach achieves nearly 100% fully supervised performance, such as only-2.78% on RefCOCO. The project website for RefTeacher is available at https://refteacher.github.io/.