In this study, we investigate the segmentation of objects in unlabeled videos. While humans can easily segment moving objects based on their motion, the Gestalt law of common fate, which suggests that objects moving at the same speed belong together, has been used as a basis for unsupervised object discovery through motion segmentation. However, common fate is not always a reliable indicator of objectness, as parts of an articulated or deformable object may not move at the same speed, and shadows or reflections of an object may move with it but are not part of it. To address this issue, we propose a two-step approach to bootstrap objectness. First, we learn image features from the relaxed notion of common fate, approximating optical flow with constant segment flow and small residual flow within segments. Then, we refine these features by grouping visually similar segments within the image itself and across multiple images statistically, taking into account appearance and figure-ground relevance.By applying our approach to unsupervised video object segmentation using only ResNet and convolutional heads, we achieve significant improvements over the state-of-the-art. Specifically, our model outperforms existing methods by absolute gains of 7%, 9%, and 5% on the DAVIS16, STv2, and FBMS59 datasets, respectively. This demonstrates the effectiveness of our ideas. The code for our model is publicly available.