Coordinate-based implicit neural networks, known as neural fields, have proven to be valuable in representing shape and appearance in 3D computer vision. However, constructing neural fields for object categories without datasets like ShapeNet, which provide aligned object instances, remains a challenge. In this study, we introduce a self-supervised approach called Canonical Field Network (CaFi-Net) to establish a canonical 3D pose for instances of an object category represented as neural fields, specifically neural radiance fields (NeRFs). CaFi-Net learns directly from continuous and noisy radiance fields using a Siamese network architecture that extracts equivariant field features for category-level canonicalization. During inference, our method utilizes pre-trained neural radiance fields of novel object instances at various 3D poses to estimate a canonical field with consistent 3D pose across the entire category. We conducted extensive experiments on a novel dataset comprising 1300 NeRF models across 13 object categories and found that our method performs as well as or better than 3D point cloud-based techniques.