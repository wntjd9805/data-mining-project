Semi-Supervised Object Detection (SSOD) has gained popularity as a method to enhance object detectors by utilizing unlabeled data. However, existing SSOD approaches primarily focus on horizontal objects, neglecting multi-oriented objects commonly found in aerial images. This study introduces a new model called Semi-supervised Oriented Object Detection (SOOD) that extends the mainstream pseudo-labeling framework to address this limitation. Our model incorporates two loss functions to improve supervision for oriented objects in aerial scenes. The first loss function emphasizes object orientations by regularizing the consistency between each pseudo-label-prediction pair, considering their orientation gap and using adaptive weights. The second loss function emphasizes the layout of an image by regularizing the similarity and establishing a many-to-many relation between sets of pseudo-labels and predictions. This global consistency constraint enhances semi-supervised learning. Experimental results demonstrate that SOOD outperforms state-of-the-art SSOD methods on the DOTA-v1.5 benchmark when trained with the proposed losses. The code for implementing SOOD is available at https://github.com/HamPerdredes/SOOD.