To protect sensitive information and defend against inference attacks in Federated Learning (FL), client-level Differentially Private FL (DPFL) is commonly used for privacy protection. However, existing DPFL methods often result in a sharper loss landscape and poorer weight perturbation robustness, leading to significant performance degradation. To address these issues, we propose a new DPFL algorithm called DP-FedSAM. DP-FedSAM utilizes gradient perturbation to mitigate the negative effects of DP. Specifically, it incorporates the Sharpness-Aware Minimization (SAM) optimizer to generate local flatness models that are more stable and robust to weight perturbations. This leads to smaller local update norms and improved performance even in the presence of DP noise. We provide a detailed theoretical analysis of how DP-FedSAM mitigates performance degradation caused by DP. Additionally, we offer rigorous privacy guarantees using RÂ´enyi DP and present sensitivity analysis of local updates. Empirical results demonstrate that our algorithm achieves state-of-the-art performance compared to existing baselines in DPFL.