Deep learning methods have become the leading approach for super-resolution, surpassing traditional methods. Previous models focused on fixed scaling factors, but recent efforts have explored blur kernels and non-integer scaling factors. However, these works do not offer a comprehensive framework to handle these issues together. This paper presents a framework for generic image resampling that addresses all these challenges and expands the range of possible transformations. The key to achieving this is accurately modeling image warping and changes in sampling rate during training data preparation. This enables a localized representation of image degradation, considering factors like reconstruction kernel, geometric distortion, and anti-aliasing kernel. By using this degradation map as a conditioning factor for the resampling model, both global transformations (e.g., upscaling, rotation) and locally varying transformations (e.g., lens distortion) can be addressed. Additionally, the paper introduces automatic estimation of the degradation map in more complex resampling scenarios, making it applicable for blind image resampling. Furthermore, the paper demonstrates that predicting kernels to apply on the input image instead of direct color prediction leads to state-of-the-art results. This makes the model suitable for various types of data, including those not encountered during training, such as normals.