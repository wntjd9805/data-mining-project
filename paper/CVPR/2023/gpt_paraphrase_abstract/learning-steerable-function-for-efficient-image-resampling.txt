We propose a novel method called LeRF for image resampling that combines the strengths of deep neural networks (DNNs) and interpolation methods. LeRF assigns spatially-varying resampling functions to image pixels and learns to predict the parameters that determine the orientations of these functions using a neural network. We use look-up tables to speed up inference and employ a directional ensemble strategy and edge-sensitive indexing patterns to capture local structures effectively. Our extensive experiments demonstrate that LeRF achieves efficient inference, generalizes well to different transformations, and outperforms interpolation methods, such as bicubic, with a significant improvement in peak signal-to-noise ratio (PSNR) of up to 3dB for Ã—2 upsampling on Manga109 dataset.