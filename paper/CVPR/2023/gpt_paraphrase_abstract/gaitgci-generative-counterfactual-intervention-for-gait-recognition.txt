Gait recognition is a promising biometric method for identifying individuals based on their walking patterns. However, current approaches are prone to errors due to various factors, resulting in a lack of focus on the key regions that represent effective walking patterns. To address this issue, we propose a framework called GaitGCI, which combines Counterfactual Intervention Learning (CIL) and Diversity-Constrained Dynamic Convolution (DCDC). CIL helps eliminate the impact of confounding factors by maximizing the difference in likelihood between factual and counterfactual attention. DCDC generates sample-wise factual and counterfactual attention to effectively capture the unique properties of each sample. Through matrix decomposition and diversity constraint, DCDC ensures that the model is both efficient and effective. Extensive experiments demonstrate that GaitGCI can effectively focus on the regions that are discriminative and interpretable for gait patterns. It is also compatible with existing models, allowing for improved performance at minimal additional cost. Furthermore, GaitGCI achieves state-of-the-art performance in various scenarios, including laboratory and real-world environments.