Action quality assessment (AQA) is an important topic with numerous applications. However, current methods and datasets focus on single-person short-sequence scenes, limiting the application of AQA in more complex situations. To address this limitation, we have created a new dataset called LOGO for action quality assessment in multi-person long-form videos. This dataset consists of 200 videos from 26 artistic swimming events, each with 8 athletes and an average duration of 204.2 seconds. LOGO includes detailed annotations on action procedures and formation labels to depict group information of multiple athletes. To effectively model relations among athletes and reason about temporal logic in long-form videos, we propose a simple yet effective method. We design a group-aware attention module that can be easily integrated into existing AQA methods, enhancing the clip-wise representations based on contextual group information. We evaluate several popular AQA and action segmentation methods on the LOGO dataset and demonstrate the challenges it presents. Our approach achieves state-of-the-art performance on the LOGO dataset. The dataset and code will be made available at https://github.com/shiyi-zh0408/LOGO.