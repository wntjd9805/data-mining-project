Contrastive visual language pretraining has become a powerful technique for training language-aware image encoders or enhancing pretrained models with visual recognition abilities. However, existing methods are designed for small to medium-sized images and rely on large datasets of image-text pairs, which is not suitable for computational pathology. In this study, we propose MI-Zero, a framework that leverages contrastively aligned image and text models to enable zero-shot transfer on gigapixel histopathology whole slide images. This allows pretrained encoders to perform diagnostic tasks without the need for additional labels. We address the computational challenge of inference on large images by formulating zero-shot transfer as multiple instance learning. Our text encoder is pretrained using over 550k pathology reports and other in-domain text corpora. Through effective utilization of pretrained encoders, our best model achieves an average median zero-shot accuracy of 70.2% on three real-world cancer subtyping tasks, using over 33k histopathology image-caption pairs for pretraining. The code for MI-Zero is available at: https://github.com/mahmoodlab/MI-Zero.