This research focuses on the analysis of facial expressions, specifically compound expressions, which are more diverse and accurately represent the complexity of daily affective displays. Limited research has been conducted in compound expression recognition (CER) due to the lack of databases and the controlled nature of existing ones. To address this, the authors present C-EXPR-DB, a large and diverse database consisting of 400 videos annotated with various expressions and emotion descriptors. They also propose C-EXPR-NET, a multi-task learning method for CER and AU detection. The authors incorporate semantic descriptions and visual information to enhance AU detection, and use a multi-label formulation and KL-divergence loss for CER. Additionally, they introduce a distribution matching loss to improve performance and avoid negative transfer. The authors conduct extensive experiments to demonstrate the effectiveness of C-EXPR-NET and its ability to generalize in new emotion recognition contexts. Overall, this research contributes to the understanding and recognition of compound facial expressions.