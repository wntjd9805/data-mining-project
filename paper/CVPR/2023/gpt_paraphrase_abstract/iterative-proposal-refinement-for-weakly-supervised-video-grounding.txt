Weakly-Supervised Video Grounding (WSVG) is a task that aims to identify specific events in untrimmed videos using only video-level annotations. Current state-of-the-art methods for WSVG follow a two-stage approach, where potential temporal proposals are first generated and then used for event localization. However, existing proposal generation methods have two limitations: they do not explicitly model correspondence between different elements, and they only partially cover complex events. To address these limitations, we propose a new network called IteRative prOposal refiNement (IRON) that gradually incorporates prior knowledge into each proposal and encourages proposals with more comprehensive coverage. The network includes two lightweight distillation branches that uncover cross-modal correspondence at both the semantic and conceptual levels. Additionally, we introduce an iterative Label Propagation (LP) strategy to prevent the network from focusing excessively on the most discriminative events and instead consider the entire content of the sentence. In each iteration, the proposal with the lowest distillation loss and its adjacent proposals are treated as positive samples, refining the confidence scores of proposals in a cascaded manner.We conducted extensive experiments and ablation studies on two challenging WSVG datasets to evaluate the effectiveness of our IRON network. The results demonstrate that our approach outperforms existing methods. The code for our network is publicly available at https://github.com/mengcaopku/IRON.