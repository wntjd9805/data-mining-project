In this study, we address the task of Vision-Language Navigation (VLN), which involves an embodied agent navigating to a global goal based on instructions. Previous methods for VLN use a single-step planning approach, where the agent directly performs navigation actions at each step. However, this approach is not suitable for the hierarchical nature of the navigation process, where a series of sub-goals need to be set and achieved.To overcome this limitation, we propose a new method called the Adaptive Zone-aware Hierarchical Planner (AZHP). The AZHP divides the navigation process into two phases: sub-goal setting and sub-goal executing. The sub-goal setting is performed using a Scene-aware adaptive Zone Partition (SZP) method, which dynamically divides the navigation area into different zones. Then, a Goal-oriented Zone Selection (GZS) method is used to select the appropriate zone for the current sub-goal. On the other hand, the sub-goal executing involves the agent navigating through the selected zone using a navigation-decision multi-step approach.To train the AZHP framework, we introduce a Hierarchical RL (HRL) strategy and auxiliary losses with curriculum learning. These techniques provide effective supervision signals at each stage of the navigation process. Experimental results on three VLN benchmarks (REVERIE, SOON, R2R) demonstrate that our proposed method outperforms existing approaches and achieves state-of-the-art performance.Overall, our study presents a novel approach to address the hierarchical nature of Vision-Language Navigation by introducing the AZHP framework, which effectively sets and achieves sub-goals in a dynamic and adaptive manner.