Fine-grained visual classification (FGVC) models are currently limited in their application because they require the identification of a coarse-grained label before selecting the appropriate FGVC model. In this study, we propose a comprehensive FGVC model that is trained using multiple datasets. This model can accurately predict the fine-grained label of an object across different label spaces. We discovered that positive and negative transfers occur simultaneously when training with different datasets, indicating that knowledge from other datasets is not always beneficial. To address this, we introduce a feature disentanglement module and a feature re-fusion module to minimize negative transfer and enhance positive transfer between datasets. The deep features are decoupled using dataset-specific feature extractors to reduce negative transfer, and then re-fused at the channel level to facilitate positive transfer. Additionally, we propose a dataset-agnostic spatial attention layer based on meta-learning to leverage the training data from multiple datasets, taking advantage of the dataset-agnostic nature of object localization. Experimental results using 11 mixed-datasets built on four FGVC datasets demonstrate the effectiveness of our approach. Moreover, our method can easily be combined with existing FGVC methods to achieve state-of-the-art results. The code for our proposed method is available at https://github.com/PRIS-CV/An-Erudite-FGVC-Model.