Current methods of predicting human-object interactions (HOI) have been limited by a lack of supervised data and the vast number of possible interaction combinations in real life. These methods use closed-set data to predict HOIs as fixed-dimension logits, which hinders their ability to handle open-set categories. To overcome this limitation, we propose OpenCat, a language modeling framework that transforms HOI prediction into sequence generation. By converting HOI triplets into a token sequence, our model can leverage the open-set vocabulary of the language modeling framework to predict novel interaction classes with a high level of flexibility. Additionally, we collect a large amount of weakly-supervised data related to HOI from image-caption pairs and employ auxiliary proxy tasks, such as soft relational matching and human-object relation prediction, to pre-train our model. Extensive experiments demonstrate that OpenCat significantly improves HOI performance, especially for rare and unseen categories.