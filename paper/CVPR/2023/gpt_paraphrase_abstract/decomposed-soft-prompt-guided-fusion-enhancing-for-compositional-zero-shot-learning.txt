Compositional Zero-Shot Learning (CZSL) is a task that involves recognizing new concepts created by known states and objects during training. Existing methods have limitations in effectively handling unseen compositions. Some methods combine state and object representations, making it difficult to generalize to unseen compositions. Others use separate classifiers for state and object identification without considering their intrinsic relationship. To address these limitations and create a more robust CZSL system, we propose a novel framework called Decomposed Fusion with Soft Prompt (DFSP). Our approach incorporates vision-language models (VLMs) for recognizing unseen compositions. DFSP combines learnable soft prompts with state and object to create a joint representation. Additionally, we design a cross-modal decomposed fusion module that separates state and object among language features instead of image features. By fusing the decomposed features with image features, our approach improves the expressiveness of image features in learning the relationship with states and objects. This leads to better recognition of unseen compositions and reduces the gap between seen and unseen sets. Experimental results on three challenging benchmarks demonstrate that our approach significantly outperforms other state-of-the-art methods.