Tuning foundation vision transformers (FViTs) on downstream tasks is in high demand, but it remains challenging to fully utilize FViTs' potential in data-limited scenarios such as few-shot tuning. Common data augmentation techniques are not effective in this context due to the limited features available in the few-shot tuning data. However, we have identified an opportunity to leverage the features learned by pretrained FViTs during parameter-efficient tuning. We propose a framework called Hint-based Data Augmentation (Hint-Aug) to enhance few-shot FViT tuning by augmenting over-fitted parts of tuning samples with the learned features of pretrained FViTs. Hint-Aug incorporates an Attentive Over-fitting Detector (AOD) to identify over-confident patches in foundation ViTs and a Confusion-based Feature Infusion (CFI) module to infuse easy-to-confuse features from pretrained FViTs with the over-confident patches, thereby enhancing feature diversity during tuning. Extensive experiments on multiple datasets consistently demonstrate the effectiveness of Hint-Aug, achieving higher accuracy compared to state-of-the-art data augmentation methods in various low-shot settings. For instance, on the Pet dataset, Hint-Aug achieves 2.22% higher accuracy with 50% less training data compared to SOTA data augmentation methods.