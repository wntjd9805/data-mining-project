Continual Learning (CL) has made significant progress recently, but determining the trustworthiness of CL models and fostering their trustworthiness remain largely unknown. This study focuses on evaluating and enhancing the resilience of existing CL models to data corruptions. Empirical evaluation shows that current state-of-the-art CL models are highly susceptible to various corruptions during testing. To ensure trustworthiness and robustness in safety-critical scenarios, a meta-learning framework called MetaMix is proposed. MetaMix learns to augment and mix data, automatically adapting to new task data or memory data. It optimizes generalization performance against data corruptions during training. To assess the corruption robustness of MetaMix, several CL corruption datasets with varying levels of severity are created. Comprehensive experiments are conducted on both task and class-continual learning. The results demonstrate the effectiveness of MetaMix compared to state-of-the-art baselines.