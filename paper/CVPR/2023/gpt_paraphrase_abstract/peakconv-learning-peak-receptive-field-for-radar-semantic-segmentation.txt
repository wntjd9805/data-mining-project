Modern machine learning technologies have shown great potential in automatically understanding radar scenes. One such technology is radar semantic segmentation (RSS), which can provide more detailed information about moving objects and background clutter within the radar's range. Convolutional networks, successful in visual computing tasks, have been introduced to solve the RSS problem. However, these networks are not specifically designed to interpret radar signals, as the receptive fields of existing convolutions are defined by the object presentation in optical signals. In radar signal processing, object signatures are detected using a local peak response, known as CFAR detection. Building on this idea, we redefine the receptive field as the peak receptive field (PRF) and propose the peak convolution operation (PeakConv) to learn object signatures in an end-to-end network. By incorporating PeakConv layers into the encoders, our RSS network achieves better segmentation results compared to other state-of-the-art methods. We validate our approach using a multi-view real-measured dataset collected from an FMCW radar. The code for PeakConv is available at https://github.com/zlw9161/PKC.