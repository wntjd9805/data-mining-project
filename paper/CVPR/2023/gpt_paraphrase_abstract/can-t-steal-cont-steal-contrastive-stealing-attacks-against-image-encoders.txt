Self-supervised representation learning methods have made significant progress in utilizing unlabeled images to generate powerful image features. However, these techniques are susceptible to model stealing attacks, where attackers can mimic the performance of well-trained encoders without the need for extensive computational resources or dedicated model designs. Previous attacks have primarily focused on supervised classifiers, leaving the vulnerability of unsupervised encoders unexplored. In this study, we investigate the vulnerability of encoders to model stealing attacks and demonstrate that they are more susceptible compared to downstream classifiers. To exploit the rich representation of encoders, we propose a contrastive-learning-based attack called Cont-Steal, which enhances the effectiveness of stealing encoders. Our experiments validate the improved stealing performance of Cont-Steal in various settings. We highlight the importance of protecting the intellectual property of representation learning techniques, particularly against encoder stealing attacks like ours.