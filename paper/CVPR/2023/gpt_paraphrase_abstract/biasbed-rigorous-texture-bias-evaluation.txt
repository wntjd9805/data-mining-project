This paper addresses the issue of texture bias in convolutional neural networks (CNNs) and the lack of standardized evaluation protocols for algorithms that aim to reduce this bias. The authors propose a testbed called BiasBed, which includes multiple datasets and existing algorithms for texture- and style-biased training. They also introduce an extensive evaluation protocol that incorporates rigorous hypothesis testing to determine the significance of results, despite the training instability of some style bias methods. Through their experiments, the authors highlight the importance of statistically founded evaluation protocols for style bias and reveal that certain algorithms proposed in the literature do not effectively mitigate the impact of texture bias. The release of BiasBed aims to establish a common understanding for consistent and meaningful comparisons, facilitating faster progress towards texture bias-free learning methods. The code for BiasBed is available on GitHub at https://github.com/D1noFuzi/BiasBed.