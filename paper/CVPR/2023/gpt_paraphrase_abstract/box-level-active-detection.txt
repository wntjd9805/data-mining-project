Active learning has become an efficient approach for object detection, but current benchmarks evaluate at the image level, which is unrealistic and biased. Additionally, existing methods annotate images at the same level, resulting in wasted resources and redundant labels. To address these issues, we propose a box-level active detection framework that allocates a budget per cycle and prioritizes informative targets. We introduce a novel pipeline called Complementary Pseudo Active Strategy (ComPAS) that combines human annotations and model intelligence. ComPAS consistently outperforms 10 competitors in various settings, achieving 100% supervised performance with only 19% box annotations on VOC0712 and improving mAP by up to 4.3% on the COCO dataset. It also supports training with unlabeled data, surpassing 90% COCO supervised performance with an 85% reduction in labels. Our source code is publicly available at https://github.com/lyumengyao/blad.