This paper introduces a new approach to editing neural radiance fields in 3D, allowing users to make edits using a single image while maintaining high fidelity and consistency across multiple views. The approach utilizes a prior-guided editing field to encode precise geometric and texture edits in 3D space. Several techniques are developed to assist the editing process, including cyclic constraints with a proxy mesh for geometric supervision, a color compositing mechanism for stable texture editing, and a feature-cluster-based regularization to preserve irrelevant content. The method is evaluated through extensive experiments and editing examples on real-world and synthetic data, demonstrating its ability to achieve photo-realistic 3D editing using just a single image. This approach pushes the boundaries of semantic-driven editing in 3D scenes.