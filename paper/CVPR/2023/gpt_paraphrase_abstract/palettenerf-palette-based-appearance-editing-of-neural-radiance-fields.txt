In recent years, there have been significant advancements in neural radiance fields (NeRF) for reconstructing complex 3D scenes and generating novel views. However, there is limited research on efficiently editing the appearance of these representations while maintaining photorealism. This paper introduces PaletteNeRF, a new method for photorealistic appearance editing of NeRF using 3D color decomposition.PaletteNeRF decomposes the appearance of each 3D point into a linear combination of palette-based bases, which are 3D segmentations defined by a group of NeRF-type functions shared across the scene. These bases are view-independent, but the method also predicts a view-dependent function to capture additional color information such as specular shading. During training, the basis functions and color palettes are jointly optimized, and novel regularizers are introduced to encourage spatial coherence in the decomposition.By modifying the color palettes, users can efficiently edit the appearance of the 3D scene using PaletteNeRF. Additionally, the framework is extended with compressed semantic features for semantic-aware appearance editing. The effectiveness of PaletteNeRF is demonstrated through quantitative and qualitative comparisons with baseline methods on complex real-world scenes.The project page for PaletteNeRF can be found at https://palettenerf.github.io.