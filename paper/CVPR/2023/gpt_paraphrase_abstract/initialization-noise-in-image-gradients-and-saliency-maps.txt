This paper investigates the impact of training randomness, specifically random initialization of networks, on the gradients of logits obtained from image classification convolutional neural networks (CNNs). The study extends to examining gradients of intermediate layers using methods like GradCAM, DeepLIFT, SHAP, LIME, Integrated Gradients, and SmoothGrad. Despite varying levels of empirical noise, all of these methods still provide different attributions to image features. This has implications for interpreting these attributions, especially when trying to understand the underlying phenomenon generating the data. The paper also demonstrates that these observed artifacts can be eliminated by integrating over the initialization distribution using stochastic integration.