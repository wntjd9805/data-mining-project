Despite recent advancements in implicit neural representations (INRs), it remains difficult for a coordinate-based multi-layer perceptron (MLP) of INRs to acquire a shared representation across data instances and apply it to unseen instances. In this study, we propose a straightforward yet effective framework for generalizable INRs that allows a coordinate-based MLP to represent intricate data instances by adjusting only a small set of weights in an early MLP layer, which acts as an instance pattern composer. The remaining MLP weights are responsible for learning pattern composition rules applicable to common representations across instances. Our generalizable INR framework is fully compatible with existing meta-learning and hypernetworks in the process of predicting the adjusted weight for unseen instances. Through extensive experiments, we demonstrate that our method achieves exceptional performance across a wide range of domains, including audio, image, and 3D objects. The ablation study further confirms the effectiveness of our weight modulation technique.