Modern neural networks rely on strong regularization techniques, such as data augmentation and weight decay, to reduce overfitting and improve generalization. In particular, data augmentation involves applying invariant transforms to samples, where the learning target remains the same regardless of the applied transform. Drawing inspiration from human visual classification studies, we propose a new approach called soft augmentation. Unlike invariant transforms, soft augmentation allows the learning target to soften non-linearly as the degree of transform applied to the sample increases. For example, more aggressive image crop augmentations result in less confident learning targets. We demonstrate that soft targets enable more aggressive data augmentation, leading to more robust performance improvements. Additionally, soft targets can be combined with existing augmentation policies and produce better calibrated models by reducing confidence on aggressively cropped or occluded examples. We conducted experiments on various datasets, including Cifar-10, Cifar-100, ImageNet-1K, and ImageNet-V2, and found that soft targets doubled the top-1 accuracy boost compared to traditional methods. They also improved model occlusion performance by up to four times and reduced the expected calibration error by half. Moreover, we show that soft augmentation can be generalized to self-supervised classification tasks. The code for implementing soft augmentation is available at https://github.com/youngleox/soft_augmentation.