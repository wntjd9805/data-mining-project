We present a novel learning-based approach for recovering surface properties from a single diffuse image of a material. Our method focuses on utilizing microgeometry appearance as the main cue. Unlike previous methods, which often produce over-smooth outputs with artifacts or operate at limited resolution, our approach leverages a generative network with attention and a U-Net discriminator to integrate global information effectively and reduce computational complexity. We demonstrate the effectiveness of our method using a real dataset of digitized textile materials and show that a regular flatbed scanner can provide the required diffuse illumination for our approach. To address potential challenges, such as the ill-posed nature of the problem or lack of representative training data, we propose a framework to quantify the model's confidence in its predictions during testing. This framework enhances the reliability of material digitization and enables intelligent strategies for dataset creation, as demonstrated through an active learning experiment. Our method is the first to tackle the issue of modeling uncertainty in material digitization, leading to increased trust in the process.