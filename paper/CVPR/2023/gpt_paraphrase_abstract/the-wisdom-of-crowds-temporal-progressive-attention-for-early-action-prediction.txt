Early action prediction involves inferring the ongoing action in videos that are only partially observed, typically at the beginning of the video. We introduce a new attention model called the bottleneck-based attention model, which captures the progression of the action by sampling at different scales, from fine to coarse. Our proposed model, called the Temporal Progressive (TemPr) model, consists of multiple attention towers, each focusing on a different scale. The predicted action label is determined by considering the agreement among these towers based on their confidences. Through extensive experiments on four video datasets, we demonstrate that our approach achieves state-of-the-art performance in early action prediction across various encoder architectures. We also conduct detailed ablations to show the effectiveness and consistency of the TemPr model.