Neuroscience relies heavily on tasks such as segmentation, reconstruction, and registration of neuroimages. These tasks often require robust deep learning strategies and architectures. However, when faced with a new task or dataset with different visual characteristics, researchers typically have to train a new model or fine-tune an existing one, which is a time-consuming process. This poses a significant barrier for neuroscientists and clinical researchers who may lack the necessary resources or expertise in machine learning. As a result, traditional frameworks are more commonly used in neuroscience, and deep learning is not widely adopted.To address this issue, we propose Neuralizer, a single model that can generalize to new neuroimaging tasks and modalities without the need for re-training or fine-tuning. This model does not require prior knowledge of the tasks and achieves generalization in a single forward pass during inference. It can effectively handle processing tasks across various image modalities, acquisition methods, and datasets, even for tasks and modalities it has not been trained on. Our experiments on coronal slices demonstrate that our multi-task network outperforms task-specific baselines, even with limited annotated subjects. This suggests that Neuralizer offers a promising solution for neuroimage processing tasks without the need for extensive training on each specific task.