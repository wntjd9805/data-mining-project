Current image captioning methods assume that the training and testing data come from the same domain or that the data from the target domain (where the testing data belong) are accessible. However, this assumption is not applicable in real-world scenarios where the target domain data cannot be accessed. This paper introduces a new setting called Domain Generalization for Image Captioning (DGIC), where the target domain data is unseen during the learning process. To facilitate research in DGIC, a benchmark dataset is constructed, allowing investigation of models' domain generalization ability on unseen domains. Additionally, a new framework called language-guided semantic metric learning (LSML) is proposed for the DGIC setting. Experimental results on multiple datasets demonstrate the challenge of the task and the effectiveness of the newly proposed benchmark and LSML framework.