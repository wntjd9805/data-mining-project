In recent times, there has been a surge in the use of deep neural networks for tasks that require advanced cognitive abilities such as playing Go, generating art, and question answering. This progress raises the question of how well neural networks can generalize in solving problems that require a wide range of skills. To address this question, we introduce SMART, a Simple Multimodal Algorithmic Reasoning Task, along with the SMART-101 dataset. This dataset is specifically designed for children aged 6-8 and consists of 101 unique puzzles that combine visual and linguistic elements. Solving these puzzles requires various elementary skills including arithmetic, algebra, and spatial reasoning. To train deep neural networks on this dataset, we programmatically generate new instances of each puzzle while maintaining their solution algorithm. To evaluate performance on the SMART-101 dataset, we propose a vision-and-language meta-learning model that can incorporate different state-of-the-art neural backbones. Our experiments show that while powerful deep models perform reasonably well on supervised puzzles, they perform no better than random accuracy when it comes to generalization. This suggests the need for new multimodal learning approaches to bridge this gap.