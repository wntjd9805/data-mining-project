Semantic segmentation often faces challenges due to an uneven distribution of data. This leads to features of less common categories being compressed into a small area in the feature space. To address this, we propose incorporating category-specific variation during training. Instead of projecting instances to a single feature point, we assign them to a small region based on their category. This perturbation depends on the scale of the category, with smaller variation for common categories and larger variation for less common ones. This approach helps to reduce the discrepancy between feature areas of different categories, resulting in a more balanced representation. Importantly, this introduced variation is disregarded during inference to ensure confident predictions. Despite its simplicity, our method demonstrates strong generalizability across datasets and task settings. Extensive experiments show that our approach can be easily integrated with state-of-the-art techniques, leading to improved performance.