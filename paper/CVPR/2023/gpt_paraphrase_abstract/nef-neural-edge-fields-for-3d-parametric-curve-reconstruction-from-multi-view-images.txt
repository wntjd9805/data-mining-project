We investigate the task of reconstructing 3D feature curves of an object using multiple calibrated images. Our approach involves training a neural implicit field called Neural Edge Field (NEF) to represent the density distribution of 3D edges. Similar to NeRF, NEF is optimized using a rendering loss, where a 2D edge map is rendered from a specific viewpoint and compared to the ground-truth edge map extracted from the corresponding image. This differentiable optimization method leverages 2D edge detection without requiring supervision of 3D edges, a 3D geometric operator, or cross-view edge correspondence. We introduce several technical designs to ensure that NEF is limited in range and view-independent, thereby enabling robust edge extraction. Finally, we extract parametric 3D curves from NEF using an iterative optimization technique. Our experiments with synthetic data demonstrate that NEF outperforms existing state-of-the-art methods across all evaluation metrics. More details can be found on our project page: https://yunfan1202.github.io/NEF/.