We propose a novel approach to address the issue of generating diverse training data for robust object detection in few-shot settings. Existing two-stage object detectors often generate object proposals that do not perfectly align with the objects in the images, resulting in varying levels of difficulty for classification. To overcome this, we introduce a variational autoencoder (VAE) based data generation model. By transforming the latent space, we can generate features with increased diversity in crop-related variations. We achieve this by rescaling the latent codes based on the norm, which correlates with the difficulty level of the crop. We train the VAE model on base classes, conditioned on the semantic code of each class, and then generate features for novel classes. Our experiments demonstrate that the generated features consistently improve the performance of state-of-the-art few-shot object detection methods on the PASCAL VOC and MS COCO datasets.