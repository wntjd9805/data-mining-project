Unsupervised person re-identification in visible-infrared images is a difficult task due to the significant differences between the two modalities and the lack of correspondences between them. Existing approaches have attempted to address this issue by focusing on local information, but they fail to fully utilize the global relationship across different identities, which results in low-quality correspondences. Additionally, the inconsistency in the number of clusters in each modality further affects the reliability of the correspondences.To overcome these challenges, we propose a Progressive Graph Matching (PGM) method that globally mines cross-modality correspondences, particularly under scenarios with imbalanced clusters. PGM formulates the correspondence mining as a graph matching process and takes into account the global information by minimizing the overall matching cost, which measures the dissimilarity between clusters. Furthermore, PGM utilizes a progressive strategy that involves multiple dynamic matching processes to address the imbalance issue.Building upon PGM, we introduce an Alternate Cross Contrastive Learning (ACCL) module to reduce the modality gap using the mined cross-modality correspondences. Additionally, we mitigate the impact of noise in the correspondences by employing an alternate scheme. Through extensive experiments, we demonstrate the reliability of the generated correspondences and the effectiveness of our approach.