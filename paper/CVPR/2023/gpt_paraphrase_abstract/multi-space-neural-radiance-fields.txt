The current methods of Neural Radiance Fields (NeRF) have limitations when it comes to rendering reflective objects, resulting in blurry or distorted images. To address this issue, we propose a new approach called multi-space neural radiance field (MS-NeRF). Instead of using a single radiance field, MS-NeRF represents the scene using multiple feature fields in parallel sub-spaces. This allows the neural network to better understand and handle reflective and refractive objects. Our approach is compatible with existing NeRF methods and requires only a small computational overhead for training and inferring the extra-space outputs. We evaluate our approach on three representative NeRF-based models and compare it to existing methods using a dataset of 25 synthetic scenes and 7 real captured scenes with complex reflection and refraction. The results of extensive experiments demonstrate that our approach significantly outperforms single-space NeRF methods in rendering high-quality scenes involving mirror-like objects and complex light paths. We will make our code and dataset publicly available at https://zx-yin.github.io/msnerf.