This paper introduces ARKitTrack, a novel RGB-D tracking dataset designed for static and dynamic scenes captured using consumer-grade LiDAR scanners on Apple's iPhone and iPad. The dataset consists of 300 RGB-D sequences, 455 targets, and a total of 229.7K video frames. In addition to bounding box annotations and frame-level attributes, the dataset also includes 123.9K pixel-level target masks. The camera intrinsic and camera pose information for each frame are provided for future developments. The paper presents a unified baseline approach for both box-level and pixel-level tracking, which combines RGB features with bird's-eye-view representations to exploit cross-modality 3D geometry. Empirical analysis confirms that the ARKitTrack dataset significantly enhances RGB-D tracking, and the proposed baseline method outperforms existing state-of-the-art methods. The code and dataset are publicly available at https://arkittrack.github.io.