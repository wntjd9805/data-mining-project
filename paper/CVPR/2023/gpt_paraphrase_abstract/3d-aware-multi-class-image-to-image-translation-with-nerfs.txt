Recent advancements in 3D-aware generative models (3D-aware GANs) combined with Neural Radiance Fields (NeRF) have shown impressive outcomes. However, there is a lack of research on using 3D-aware GANs for 3D consistent multi-class image-to-image (3D-aware I2I) translation. Utilizing traditional 2D-I2I translation methods leads to unrealistic changes in shape and identity. To address this, we divide the learning process into two steps: a multi-class 3D-aware GAN step and a 3D-aware I2I translation step. In the first step, we introduce two novel techniques: a new conditional architecture and an effective training strategy. In the second step, we construct a 3D-aware I2I translation system based on the well-trained multi-class 3D-aware GAN architecture, which maintains view-consistency. To further enhance view-consistency, we propose additional techniques including a U-net-like adaptor network design, a hierarchical representation constraint, and a relative regularization loss. Through extensive experiments on two datasets, both quantitative and qualitative results demonstrate the successful achievement of 3D-aware I2I translation with multi-view consistency. The code for our approach is available in 3DI2I.