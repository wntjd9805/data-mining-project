This study introduces a novel approach called Projection onto Orthogonal Prototypes (POP) for generalized few-shot semantic segmentation (GFSS). GFSS involves distinguishing pixels of base and novel classes from the background using limited examples from the novel class. Traditional GFSS approaches have two training phases: base class learning and novel class updating. However, the standalone updating process often compromises the well-learnt features and leads to a drop in performance on base classes. To address this issue, the authors propose POP, which updates features to identify novel classes without compromising base classes. POP constructs a set of orthogonal prototypes, where each prototype represents a semantic class, and predicts each class separately based on the features projected onto its prototype. The prototypes are first learned on base data and then extended to novel classes. The orthogonality constraint in POP encourages the prototypes to be orthogonal, minimizing the influence on base class features when generalizing to novel prototypes. Additionally, POP utilizes the residual of feature projection as the background representation, dynamically adjusting for semantic shifting (i.e., excluding pixels of novel classes from the background in the updating phase). Experimental results on two benchmarks demonstrate that POP achieves superior performance on novel classes while maintaining high accuracy on base classes. Notably, POP outperforms the state-of-the-art fine-tuning method by 3.93% overall mean Intersection over Union (mIoU) on PASCAL-5i in a 5-shot scenario.