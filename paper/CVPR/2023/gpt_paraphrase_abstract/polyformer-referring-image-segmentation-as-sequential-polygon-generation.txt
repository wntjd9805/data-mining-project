This study presents a new approach to image segmentation by formulating the problem as sequential polygon generation instead of direct pixel-level prediction. The proposed framework, called Polygon Transformer (PolyFormer), takes image patches and text query tokens as input and generates a sequence of polygon vertices. These predicted polygons can then be converted into segmentation masks. To improve geometric localization accuracy, a regression-based decoder is introduced, which predicts precise floating-point coordinates without quantization errors. Experimental results show that PolyFormer significantly outperforms previous methods, achieving absolute improvements of 5.40% and 4.52% on challenging datasets such as Re-fCOCO+ and RefCOCOg. Moreover, PolyFormer demonstrates strong generalization ability in referring video segmentation tasks without fine-tuning, achieving competitive results on the Ref-DAVIS17 dataset with a J & F score of 61.5%.