This study introduces Expressive Prompts with Residuals (EXPRES), a modified prompt learning method designed specifically for adapting vision transformers (ViT). EXPRES utilizes learnable "output" tokens and residual learnable tokens to construct downstream representations and steer the representation processing of the frozen transformer, respectively. The effectiveness of EXPRES is demonstrated through image classification and few-shot semantic segmentation tasks, achieving state-of-the-art prompt tuning on the VTAB benchmark. Additionally, EXPRES exhibits significantly improved prompt efficiency compared to existing visual prompting baselines. The computational advantages of EXPRES over weight space adaptation techniques like fine-tuning are analytically demonstrated. A series of ablation experiments further validate the architectural design of EXPRES.