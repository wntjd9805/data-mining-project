Transformer-based models have been successful in artistic style transfer due to their global receptive field and multi-head/layer attention operations. However, the large number of parameters in these models makes training burdensome. Additionally, the vanilla Transformer model used for style transfer can distort the content. In this paper, we propose a novel Transformer model called Master for style transfer. The proposed model reduces the number of parameters by sharing them among different layers, leading to more robust training and allowing for control of stylization during inference. We also introduce a learnable scaling operation to better preserve the original similarity between content features and ensure high-quality stylization. We further propose a meta learning scheme that enables the model to adapt to few-shot style transfer by fine-tuning the Transformer encoder layer for a specific style. We achieve text-guided few-shot style transfer using this framework. Extensive experiments demonstrate the superior performance of Master in both zero-shot and few-shot style transfer settings.