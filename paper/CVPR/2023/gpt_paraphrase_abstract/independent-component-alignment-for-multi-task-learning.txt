Multi-task learning (MTL) involves training a single model to handle multiple tasks simultaneously. However, MTL comes with challenges related to optimization, such as conflicting and dominating gradients. To address these issues, this study suggests utilizing the condition number of a linear system of gradients as a stability criterion for MTL optimization. The condition number is shown to reflect the optimization problems mentioned. Consequently, a novel MTL optimization approach called Aligned-MTL is introduced, which aligns the orthogonal components of the linear system of gradients to eliminate instability during training. While many existing MTL approaches ensure convergence to a minimum, they cannot specify task trade-offs beforehand. In contrast, Aligned-MTL guarantees convergence to an optimal point with predefined task-specific weights, providing more control over the optimization outcome. Experimental results demonstrate that the proposed method consistently enhances performance across various MTL benchmarks, including semantic and instance segmentation, depth estimation, surface normal estimation, and reinforcement learning. The source code for Aligned-MTL is publicly accessible at https://github.com/SamsungLabs/MTL.