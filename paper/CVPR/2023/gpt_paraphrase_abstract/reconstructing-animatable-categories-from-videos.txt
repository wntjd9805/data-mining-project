Creating animatable 3D models is a complex task that typically involves 3D scans, time-consuming registration processes, and rigging. However, recent advancements in differentiable rendering have opened up possibilities for generating high-quality 3D models from monocular videos. Unfortunately, existing methods are limited to rigid categories or individual instances. In this study, we propose a new approach called RAC that enables the construction of category-level 3D models from monocular videos, effectively disentangling variations across instances and motion over time.   To address this challenge, we introduce three key ideas. Firstly, we specialize a category-level skeleton to individual instances, allowing for more accurate modeling. Secondly, we develop a latent space regularization technique that encourages shared structure across the category while preserving instance-specific details. This ensures that the resulting models are both representative of the category and faithful to the individual instances. Lastly, we leverage 3D background models to separate objects from the background, facilitating the disentanglement of different elements in the scene.  We demonstrate the effectiveness of our method by constructing 3D models for humans, cats, and dogs using monocular videos. These models not only capture the unique characteristics of each instance but also generalize well across the entire category. More information about our project can be found on our project page: https://gengshan-y.github.io/rac-www/.