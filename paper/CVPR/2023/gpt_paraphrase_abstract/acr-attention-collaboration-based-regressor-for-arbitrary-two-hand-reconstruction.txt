Reconstructing two hands from single RGB images is a difficult task due to occlusion and confusion between the hands. Existing methods struggle with impaired interaction, such as truncated or separate hands, or external occlusion. This paper introduces ACR (Attention Collaboration-based Regressor), the first approach to reconstruct hands in any scenario. ACR addresses the issue by reducing interdependence between hands and their parts through center and part-based attention for feature extraction. However, reducing interdependence weakens the mutual reasoning for reconstructing interacting hands. Therefore, ACR also incorporates cross-hand prior knowledge based on center attention to improve reconstruction. The proposed method is evaluated on various hand reconstruction datasets and outperforms existing approaches on the InterHand2.6M dataset, while achieving comparable performance to state-of-the-art single-hand methods on the FreiHand dataset. Additional qualitative results on in-the-wild and hand-object interaction datasets, as well as web images/videos, demonstrate the effectiveness of the approach for arbitrary hand reconstruction. The code for ACR is available at the provided link.