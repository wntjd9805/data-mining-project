This paper explores the concept of continual learning, which involves efficiently learning from a non-stationary stream of data without forgetting previous knowledge. It addresses the limitation of using Euclidean space in practical applications where data follows non-Euclidean geometry, resulting in subpar results. The study proposes a novel approach that considers the geometric structures of the data in the non-stationary stream. By dynamically expanding the underlying space's geometry to accommodate new data-induced structures and preserving the geometric structures of old data, the method prevents forgetting. To achieve this, the paper introduces an incremental search scheme that encodes the growing geometric structures using a mixed curvature space. Additionally, the model is trained using an angular-regularization loss and a neighbor-robustness loss, which penalize changes in global and local geometric structures. Experimental results demonstrate that this method outperforms baseline methods designed for Euclidean space.