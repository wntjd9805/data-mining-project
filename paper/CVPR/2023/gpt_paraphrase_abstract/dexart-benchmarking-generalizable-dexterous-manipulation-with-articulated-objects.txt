In order for robots to perform tasks involving articulated objects, they need to be able to manipulate them in a similar way to humans. Currently, robot manipulation is limited by the use of parallel grippers, which restrict the types of objects the robot can handle. However, using a multi-finger robot hand would allow for more human-like behavior and the ability to manipulate a wider range of articulated objects. To address this, we propose a new benchmark called DexArt, which focuses on dexterous manipulation with articulated objects in a physical simulator. This benchmark includes various complex manipulation tasks that require the robot hand to manipulate different articulated objects. Our main objective is to evaluate the generalizability of the learned policy when applied to unseen articulated objects. This is a challenging task due to the numerous degrees of freedom involved in both the robot hand and the objects themselves. We employ reinforcement learning with 3D representation learning to achieve generalization. Through extensive research, we provide new insights into how 3D representation learning impacts decision-making in reinforcement learning with 3D point cloud inputs. For more detailed information, please visit https://www.chenbao.tech/dexart/.