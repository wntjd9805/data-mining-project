Raw images are advantageous due to their linearity and fine-grained quantization level, but they are not widely used by common users because of their large storage requirements. Recent approaches have attempted to compress raw images by designing sampling masks in the pixel space, but these methods result in suboptimal image representations and redundant metadata. In this study, we propose a new framework that learns a compact representation in the latent space, serving as metadata, in an end-to-end manner. Additionally, we introduce a novel sRGB-guided context model with improved entropy estimation techniques, resulting in better reconstruction quality, smaller metadata size, and faster processing speed. Our approach enables adaptive allocation of more bits to important image regions from a global perspective. Experimental results demonstrate that our method achieves superior raw image reconstruction using smaller metadata size for both uncompressed sRGB and JPEG images. The code for our approach will be made available at https://github.com/wyf0912/R2LCM.