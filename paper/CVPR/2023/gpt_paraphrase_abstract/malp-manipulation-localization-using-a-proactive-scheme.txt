Advancements in the quality of generated images by Generative Models (GMs) have highlighted the need for not only detecting manipulated images but also identifying the specific modified pixels within an image. However, previous methods for manipulation localization, categorized as passive, have shown limited effectiveness in generalizing to unseen GMs and attribute modifications. To address this issue, we propose a proactive approach called MaLP, which involves encrypting real images with a learned template. This template provides protection against manipulation and assists in both binary detection and identification of the modified pixels. The template is learned using a two-branch architecture that incorporates local and global-level features. Our experiments demonstrate that MaLP outperforms previous passive methods and exhibits strong generalizability by successfully detecting manipulation across 22 different GMs. This establishes MaLP as a benchmark for future research in manipulation localization. Additionally, we showcase that MaLP can be employed as a discriminator to enhance the generation quality of GMs. For further details and access to our models and codes, please visit www.github.com/vishal3477/pro_loc.