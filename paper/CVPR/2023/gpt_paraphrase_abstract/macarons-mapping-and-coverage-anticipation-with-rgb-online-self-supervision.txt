We present a novel method that can both explore and reconstruct large environments using only color images. This method addresses the NextBest View problem, which involves determining the optimal camera position to enhance scene coverage. Unlike existing methods that rely on depth sensors or require 3D supervision, our approach utilizes only a color camera and does not require any 3D supervision. It employs a self-supervised learning process to predict a "volume occupancy field" from color images and uses this field to determine the NextBest View. By not being biased towards any specific 3D training data, our method performs well on new scenes. We validate our approach on a diverse dataset of 3D scenes and demonstrate that it outperforms recent methods that rely on depth sensors, which are not practical for outdoor scenes captured by flying drones.