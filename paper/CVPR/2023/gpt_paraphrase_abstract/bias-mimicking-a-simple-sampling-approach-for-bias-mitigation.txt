Previous research has demonstrated that bias groups, such as females in the category of programmers, are often underrepresented in Visual Recognition datasets. This lack of representation can result in models learning false connections between class labels and bias groups like age, gender, or race. Existing methods to address this issue typically require significant changes to the model architecture or the addition of extra loss functions, which necessitates extensive hyper-parameter tuning. In contrast, simple data sampling techniques from the class imbalance literature, such as Undersampling and Upweighting, offer a more cost-effective and efficient solution. However, these methods have their limitations. Undersampling discards a significant portion of the input distribution per epoch, while Oversampling leads to overfitting by duplicating samples. To overcome these drawbacks, we introduce a new approach called Bias Mimicking. This method is founded on the observation that if we mimic the bias distribution of one class across all other classes, the class labels and bias groups become statistically independent. By utilizing this concept, Bias Mimicking ensures that the model is exposed to the complete distribution in each epoch without repetition. As a result, Bias Mimicking improves the accuracy of sampling methods for underrepresented groups by 3% across four benchmark datasets while maintaining or even enhancing performance compared to non-sampling methods. The code for Bias Mimicking is available at: https://github.com/mqraitem/Bias-Mimicking.