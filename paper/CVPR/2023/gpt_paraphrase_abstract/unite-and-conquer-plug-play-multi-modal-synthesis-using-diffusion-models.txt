Creating images that meet multiple constraints is valuable in the content creation industry. One challenge is the requirement for paired data that includes all constraints and their corresponding outputs. Additionally, existing methods need to be re-trained using paired data for each new condition. This paper proposes a solution using denoising diffusion probabilistic models (DDPMs). Diffusion models are chosen because of their flexible internal structure. By utilizing the Gaussian distribution in each sampling step of DDPM, we demonstrate that a closed-form solution exists for generating images with different constraints. Our approach can combine multiple diffusion models trained on different sub-tasks to tackle the overall task using a sampling strategy. We introduce a novel reliability parameter that allows the use of different pre-trained diffusion models from various datasets during sampling to guide the generation of images that satisfy multiple constraints. We conducted experiments on various multimodal tasks to showcase the effectiveness of our method. For more information, please visit: https://nithin-gk.github.io/projectpages/Multidiff.