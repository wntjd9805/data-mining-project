The aim of all instance perception tasks is to find specific objects based on queries such as category names, language expressions, and target annotations. However, these tasks have been divided into separate sub-tasks. This study introduces a new model called UNINEXT, which is a universal instance perception model. UNINEXT combines different instance perception tasks into a single object discovery and retrieval paradigm. By changing the input prompts, UNINEXT can perceive different types of objects. This unified approach offers several benefits. Firstly, it allows for the use of extensive data from various tasks and label vocabularies, enabling joint training of general instance-level representations. This is particularly advantageous for tasks with limited training data. Secondly, the unified model is efficient in terms of parameters and can save computational resources when handling multiple tasks simultaneously. UNINEXT demonstrates superior performance on 20 challenging benchmarks across 10 instance-level tasks, including image-level tasks, vision-and-language tasks, and video-level object tracking tasks. The code for UNINEXT is available at https://github.com/MasterBin-IIAU/UNINEXT.