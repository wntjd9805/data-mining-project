Test-time adaption (TTA) is necessary in practical applications due to domain shifts that occur during testing. A new approach called continual TTA has been developed, which takes into account not just a single domain shift, but a sequence of shifts. Gradual TTA is a further extension that recognizes that some shifts occur gradually over time. However, since long test sequences are present in both settings, error accumulation becomes a concern for self-training methods. This study proposes the use of symmetric cross-entropy as a consistency loss for mean teachers in TTA, as it is found to be more suitable compared to the commonly used cross-entropy. This choice is supported by an analysis of the gradient properties of symmetric cross-entropy. Additionally, contrastive learning is employed to bring the test feature space closer to the source domain, where the pre-trained model is well-established. The proposed method, called robust mean teacher (RMT), is evaluated on various benchmarks including CIFAR10C, CIFAR100C, Imagenet-C, and a new benchmark called continual DomainNet-126. The results demonstrate that RMT achieves state-of-the-art performance on all benchmarks.