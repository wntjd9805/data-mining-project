This paper presents a new method for cross-view geolocalization using vision-based metrics. The method matches camera images captured from a ground-based vehicle with an aerial image to determine the vehicle's geo-pose. The use of low-cost globally available aerial images offers a compromise between expensive high-definition prior maps and relying solely on sensor data during runtime. The proposed model is end-to-end differentiable and predicts a probability distribution of possible vehicle poses based on both ground and aerial images. Multiple vehicle datasets and aerial images are combined to demonstrate the feasibility of the method. To address inaccuracies in ground truth poses compared to aerial images, a pseudo-label approach is implemented to generate more accurate ground truth poses, which are made publicly available. Unlike previous works that require training data from the target region, our approach surpasses previous results even in the more challenging cross-area case. It achieves a significant improvement over the previous state-of-the-art, even without ground or aerial data from the test region, indicating its potential for global-scale application. The method's uncertainty-aware predictions are integrated into a tracking framework to determine the vehicle's trajectory over time. The mean position error on the KITTI-360 dataset is 0.78m.