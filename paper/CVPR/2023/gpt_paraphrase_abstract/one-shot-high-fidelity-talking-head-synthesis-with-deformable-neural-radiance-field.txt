The goal of talking head generation is to create realistic faces that maintain the identity information of the source image while imitating the motion of a driving image. Previous methods primarily use 2D representations, resulting in face distortion when dealing with large head rotations. Recent approaches utilize 3D structural representations or implicit neural rendering to improve performance under these conditions. However, the fidelity of identity and expression is still not ideal, especially for synthesizing novel views. In this paper, we propose a new method called HiDe-NeRF, which achieves high-fidelity and free-view talking-head synthesis. HiDe-NeRF builds upon the Deformable Neural Radiance Fields framework and represents the 3D dynamic scene using a canonical appearance field and an implicit deformation field. The canonical appearance field captures the source face, while the deformation field models the driving pose and expression. To improve fidelity, we introduce two key enhancements. First, we design a generalized appearance module that uses multi-scale volume features to preserve face shape and details, thereby enhancing identity expressiveness. Second, we propose a lightweight deformation module that explicitly separates pose and expression, allowing for precise expression modeling. Extensive experiments demonstrate that our approach outperforms previous methods in generating more realistic results. For more information, please visit our project page at https://www.waytron.net/hidenerf/.