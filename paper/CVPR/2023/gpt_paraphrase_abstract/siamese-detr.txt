We introduce Siamese DETR, a self-supervised pretraining method for the Transformer architecture in DETR. Unlike previous methods that focus on base models like ResNets, Siamese DETR is designed specifically for DETR and ViTs. Our approach aims to learn view-invariant and detection-oriented representations simultaneously by utilizing two complementary tasks: Multi-View Region Detection and Multi-View Semantic Discrimination. The former task trains the model to localize regions-of-interest between different views of the input, while the latter improves object-level discrimination for each region. Siamese DETR achieves state-of-the-art transfer performance on COCO and PASCAL VOC detection using various DETR variants. The code for Siamese DETR is available at https://github.com/Zx55/SiameseDETR.