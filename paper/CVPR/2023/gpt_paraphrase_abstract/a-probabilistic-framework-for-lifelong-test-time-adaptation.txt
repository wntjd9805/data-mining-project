Test-time adaptation (TTA) involves updating a pre-trained source model during inference using inputs from a different target domain. Most existing TTA methods assume a stationary target domain, where all test inputs come from a single domain. However, in practical scenarios, the test input distribution may continually shift over time. Additionally, current TTA methods lack the ability to provide reliable uncertainty estimates, which is important when distribution shifts occur between the source and target domains. To address these challenges, we propose PETAL (Probabilistic lifelong Test-time Adaptation with self-training prior), a probabilistic approach that solves lifelong TTA. PETAL utilizes a student-teacher framework, where the teacher model is an exponential moving average of the student model. It also regularizes model updates during inference using the source model as a regularizer. To prevent model drift in lifelong TTA, we introduce a data-driven parameter restoration technique that reduces error accumulation and preserves knowledge of recent domains by restoring only the irrelevant parameters. Through evaluations on benchmarks like CIFAR-10C, CIFAR-100C, ImageNetC, and ImageNet3DCC datasets, we demonstrate that our method outperforms the current state-of-the-art in terms of predictive error rate and uncertainty-based metrics such as Brier score and negative log-likelihood. The source code for PETAL is available at https://github.com/dhanajitb/petal.