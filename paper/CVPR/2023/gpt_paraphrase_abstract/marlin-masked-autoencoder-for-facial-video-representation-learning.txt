This paper introduces an approach called MARLIN for learning universal facial representations from videos in a self-supervised manner. MARLIN is a facial video masked autoencoder that learns robust and generic facial embeddings from non-annotated web crawled facial videos. The model reconstructs the spatio-temporal details of the face by focusing on masked facial regions such as eyes, nose, mouth, lips, and skin, capturing both local and global aspects for encoding transferable features. Experimental results demonstrate that MARLIN performs consistently well across various facial analysis tasks, including Facial Attribute Recognition, Facial Expression Recognition, DeepFake Detection, and Lip Synchronization. It outperforms supervised and unsupervised benchmarks in terms of accuracy and shows promising results even in low data scenarios. The code and pre-trained models are publicly available on GitHub at https://github.com/ControlNet/MARLIN.