This research focuses on automating industrial quality inspection through visual anomaly classification and segmentation. Previous studies have mainly relied on training custom models for each inspection task, which is limited by the need for task-specific images and annotations. To overcome this limitation, the authors propose a new approach called window-based CLIP (WinCLIP) that addresses zero-shot and few-normal-shot anomaly classification and segmentation. While CLIP, a vision-language model, has shown impressive performance in zero-/few-shot scenarios, it falls short in anomaly classification and segmentation tasks. The proposed WinCLIP overcomes this limitation by using a compositional ensemble on state words and prompt templates, as well as efficient extraction and aggregation of features aligned with text at the window/patch/image level. Additionally, an extension of WinCLIP called WinCLIP+ is introduced, which incorporates complementary information from normal images. Experimental results on the MVTec-AD and VisA datasets demonstrate the effectiveness of WinCLIP and WinCLIP+, achieving significantly higher AU-ROC scores in zero-shot and few-normal-shot scenarios compared to the state-of-the-art methods.