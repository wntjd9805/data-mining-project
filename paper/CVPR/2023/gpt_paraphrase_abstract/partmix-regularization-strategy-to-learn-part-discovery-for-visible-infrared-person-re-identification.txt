This study focuses on the development of a new data augmentation technique called PartMix for part-based Visible-Infrared person Re-IDentification (VI-ReID) models in computer vision applications. The purpose is to address the issue of overfitting to training data in these models. PartMix synthesizes augmented samples by mixing part descriptors across different modalities, improving the performance of VI-ReID models. The technique involves synthesizing positive and negative samples within and across different identities, and regularizing the backbone model through contrastive learning. Additionally, an entropy-based mining strategy is introduced to mitigate the impact of unreliable samples. The effectiveness of PartMix is demonstrated through experiments and ablation studies, consistently improving the performance of existing VI-ReID models.