Blind face restoration often involves combining degraded low-quality data with a predetermined degradation model for training. However, this approach falls short in real-world scenarios where more complex cases can occur, leading to artifacts in the output. Including every type of degradation in the training data is impractical and costly. To address this issue, we propose a solution called the Diffusion-based Robust Degradation Remover (DR2). DR2 first transforms the degraded image into a coarse, degradation-invariant prediction and then employs an enhancement module to restore the coarse prediction to a high-quality image. By utilizing a reliable de-noising diffusion probabilistic model, DR2 converts input images into a noisy state where various types of degradation are transformed into Gaussian noise. It then captures semantic information through iterative denoising steps. As a result, DR2 effectively handles common degradation types such as blur, resize, noise, and compression, and is compatible with different designs of enhancement modules. Experimental results on heavily degraded synthetic and real-world datasets demonstrate that our framework surpasses state-of-the-art methods.