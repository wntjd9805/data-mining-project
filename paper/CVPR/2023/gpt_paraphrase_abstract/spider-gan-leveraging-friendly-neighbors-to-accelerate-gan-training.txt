Training Generative adversarial networks (GANs) is a difficult task due to instability. GANs consist of a generator that transforms noise vectors into realistic data like images. This paper presents a new method for training GANs using images as inputs without imposing pairwise constraints. The idea is that images have more structure than noise, allowing the generator to learn a stronger transformation. The proposed approach, called Spider GAN, leverages closely related datasets or a "friendly neighborhood" of the target distribution to make the training process more efficient. To define friendly neighborhoods, a new measure called the signed inception distance (SID) is introduced, inspired by the polyharmonic kernel. The Spider GAN formulation leads to faster convergence by enabling the generator to discover correspondences even between seemingly unrelated datasets. For example, Spider GAN can find connections between Tiny-ImageNet and CelebA faces. Additionally, the paper introduces cascading Spider GAN, where the output distribution of a pre-trained GAN generator is used as the input for subsequent networks. This enables the transportation of one distribution to another in a cascaded manner, creating a new form of transfer learning. The efficacy of the Spider approach is demonstrated on various GAN architectures, including DCGAN, conditional GAN, PG-GAN, StyleGAN2, and StyleGAN3. The proposed approach achieves state-of-the-art Fr√©chet inception distance (FID) values with only one-fifth of the training iterations compared to baseline methods on high-resolution small datasets such as MetFaces, Ukiyo-E Faces, and AFHQ-Cats.