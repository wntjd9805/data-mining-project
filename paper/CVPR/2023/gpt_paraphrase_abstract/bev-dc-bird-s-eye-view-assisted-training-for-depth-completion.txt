The paper introduces BEV@DC, a more efficient and powerful multi-modal training scheme for image-guided depth completion in autonomous driving. The proposed model utilizes the rich geometric details from LiDARs during training and employs an enhanced depth completion method during inference using only images (RGB and depth) as inputs. This is achieved by projecting the LiDAR features onto a unified BEV space and combining them with RGB features for BEV completion. The model incorporates a point-voxel spatial propagation network (PV-SPN) as an auxiliary branch, which provides strong guidance to the image branches through 3D dense supervision and feature consistency. The baseline model shows significant improvements using only image inputs and achieves state-of-the-art performance on various benchmarks, including ranking Top-1 on the challenging KITTI depth completion benchmark.