Graph neural networks (GNNs) have achieved impressive results in graph learning tasks. However, recent studies have revealed that GNNs are susceptible to evasion and poisoning attacks that manipulate the graph structure. While current attack methods have shown promise, we propose an attack framework that improves their performance. Inspired by certified robustness, traditionally used by defenders to protect against adversarial attacks, we are the first to employ its properties to enhance attacks on GNNs. We determine the certified perturbation sizes of nodes against evasion and poisoning attacks using randomized smoothing. Larger certified perturbation sizes indicate higher theoretical robustness of nodes against graph manipulations. This motivates us to focus on nodes with smaller certified perturbation sizes, as they are more vulnerable to attack after graph perturbations. We design a certified robustness inspired attack loss, which, when incorporated into existing attacks, creates our certified robustness inspired attack counterpart. We apply our framework to existing attacks and observe a significant improvement in their performance.