This paper introduces a technique for enhancing the controllability of text-to-image (T2I) models by allowing precise specification of content in specific regions using free-form text descriptions. The proposed method involves augmenting T2I models' inputs with position tokens to represent spatial coordinates. Each region is defined by four position tokens denoting its corners, followed by a description in natural language. The pre-trained T2I model is then fine-tuned using this modified input interface, resulting in a model called ReCo (Region-Controlled T2I). ReCo enables region control for arbitrary objects described by open-ended regional texts, rather than limiting control to object labels from a predefined category set. Experimental results demonstrate that ReCo generates higher-quality images compared to the T2I model with positional words. The accuracy of object placement is also improved, with a 20.40% increase in region classification accuracy. Moreover, ReCo allows better control over object count, spatial relationships, and region attributes such as color/size using free-form regional descriptions. Human evaluation confirms that ReCo generates images with correct object count and spatial relationship more accurately than the T2I model. The code for ReCo is available at https://github.com/microsoft/ReCo.