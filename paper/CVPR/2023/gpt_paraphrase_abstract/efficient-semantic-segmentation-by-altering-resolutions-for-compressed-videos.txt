Video semantic segmentation (VSS) is a computationally demanding task due to per-frame prediction for videos with high frame rates. Previous studies have proposed compact models and adaptive network strategies to improve efficiency in VSS. However, they overlooked the impact of input resolution on computational cost. To address this, we introduce a modified resolution framework called AR-Seg for compressed videos, aiming to achieve efficient VSS. AR-Seg reduces computational cost by using low resolution for non-keyframes. To maintain performance despite downsampling, we develop a Cross Resolution Feature Fusion (CReFF) module, which leverages motion vectors from compressed videos to align high-resolution keyframe features with low-resolution non-keyframes. Additionally, we employ a novel Feature Similarity Training (FST) strategy to supervise the aggregated features. FST incorporates an explicit similarity loss and an implicit constraint from the shared decoding layer by comparing high-resolution features. Our experiments on CamVid and Cityscapes datasets demonstrate that AR-Seg achieves state-of-the-art performance and is compatible with various segmentation backbones. Specifically, AR-Seg reduces computational cost by 67% (measured in GFLOPs) with the PSPNet18 backbone on CamVid, while maintaining high segmentation accuracy. The code is available at https://github.com/THU-LYJ-Lab/AR-Seg.