Real-time eyeblink detection in real-world settings has various applications such as fatigue detection, face anti-spoofing, and emotion analysis. Previous research mainly focused on single-person cases in trimmed videos, neglecting the importance of multi-person scenarios in untrimmed videos. In this study, we address this gap by introducing a new research field that considers multi-person eyeblink detection in untrimmed videos. We make significant contributions in terms of dataset, theory, and practices. Our large-scale dataset consists of 686 untrimmed videos capturing 8748 eyeblink events under multi-person conditions, providing a realistic representation of "in the wild" characteristics. Additionally, we propose a real-time multi-person eyeblink detection method that differs from existing methods by running in a one-stage spatio-temporal manner with end-to-end learning capability. Our method simultaneously addresses face detection, face tracking, and human instance-level eyeblink detection, leveraging the global context of the face (e.g., head pose and illumination conditions) through joint optimization and interaction. This approach offers two main advantages: (1) it enhances eyeblink features by considering the face's global context, and (2) it saves significant time by addressing these sub-tasks in parallel, meeting the real-time running requirement. Experimental results on our dataset verify the challenges of real-time multi-person eyeblink detection in untrimmed videos, and our method outperforms existing approaches with high inference speed.