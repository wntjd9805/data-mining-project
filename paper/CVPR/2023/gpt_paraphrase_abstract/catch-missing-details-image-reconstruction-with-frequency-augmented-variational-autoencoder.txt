The current VQ-VAE models that use a discrete codebook to reconstruct images suffer from a significant problem of decreased image quality as the compression rate increases. This is mainly due to the loss of visual signals in the higher frequency spectrum, which contain important details in the pixel space. To address this issue, we propose a Frequency Complement Module (FCM) architecture that captures the missing frequency information to enhance reconstruction quality. The FCM can be easily integrated into the VQ-VAE structure, resulting in a new model called Frequency Augmented VAE (FA-VAE). Additionally, we introduce a Dynamic Spectrum Loss (DSL) to guide the FCMs in dynamically balancing various frequencies for optimal reconstruction. We further extend FA-VAE to the text-to-image synthesis task and propose a Cross-attention Autoregressive Transformer (CAT) to obtain more precise semantic attributes from texts. We conduct extensive reconstruction experiments on various benchmark datasets with different compression rates, and the results demonstrate that FA-VAE is able to restore details more accurately compared to state-of-the-art methods. CAT also exhibits improved generation quality with better image-text semantic alignment.