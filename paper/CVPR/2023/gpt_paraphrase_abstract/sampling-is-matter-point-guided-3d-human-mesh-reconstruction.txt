This paper introduces a straightforward yet effective approach for reconstructing a 3D human mesh from a single RGB image. Previous methods have made advancements in estimating non-local interactions and modeling relationships between body parts, but they struggle to directly infer the connection between 2D input image features and the 3D coordinates of each vertex. To address this issue, we propose a feature sampling scheme that samples features in the embedded space based on the guidance of points estimated from the 3D mesh vertices. This allows the model to focus more on vertex-related features in the 2D space, resulting in a more accurate reconstruction of the natural human pose. Additionally, we utilize progressive attention masking to accurately estimate local interactions between vertices, even in the presence of occlusions. Experimental results on benchmark datasets demonstrate that our proposed method significantly enhances the performance of 3D human mesh reconstruction. The code and model are publicly available at: https://github.com/DCVL-3D/PointHMR_release.