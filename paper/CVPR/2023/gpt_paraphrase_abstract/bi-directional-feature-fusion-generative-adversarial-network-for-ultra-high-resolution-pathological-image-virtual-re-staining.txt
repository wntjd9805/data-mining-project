Virtual re-staining of pathological images is a cost-effective alternative to traditional pathological examination. However, existing methods for virtual re-staining face limitations due to the high resolution of pathological images. These methods divide the whole slide image (WSI) into patches for training and inference, resulting in a lack of global information and visible differences in color, brightness, and contrast when the re-stained patches are merged. This issue is referred to as the square effect. Some current approaches attempt to address this problem through patch overlapping or post-processing, but they have limited effectiveness and require careful tuning. To overcome the square effect, we propose a bi-directional feature fusion generative adversarial network (BFF-GAN) that incorporates both global and local features, as well as patch-wise attention. We evaluate our model on both private and public datasets and demonstrate competitive performance. Our model is capable of generating highly realistic images that can deceive even experienced pathologists, indicating its significant clinical relevance.