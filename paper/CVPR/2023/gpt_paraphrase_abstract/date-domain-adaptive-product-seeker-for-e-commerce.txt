In recent times, there has been a growing interest in Product Retrieval (PR) and Grounding (PG) techniques, which aim to improve the shopping experience by enabling the search for image and object-level products based on textual queries. However, due to the lack of relevant datasets, we have collected two large-scale benchmark datasets from Taobao Mall and Live domains. These datasets consist of approximately 474k and 101k image-query pairs for PR, with manual annotation of object bounding boxes in each image for PG.Since annotating these boxes is a costly and time-consuming process, we have explored the idea of transferring knowledge from the annotated domain to the unannotated domain in order to achieve unsupervised Domain Adaptation (PG-DA). To accomplish this, we have developed a framework called Domain Adaptive Product Seeker (DATE), which treats PR and PG as two different levels of the product seeking problem. The DATE framework consists of several components.Firstly, we have designed a feature extractor that aggregates semantics from each modality, enabling us to obtain concentrated and comprehensive features for efficient retrieval and fine-grained grounding tasks. Then, we have introduced two cooperative seekers that work together to search the image for PR and localize the product for PG simultaneously.In addition, we have devised a domain aligner specifically for PG-DA, which helps to address the shift in uni-modal marginal and multi-modal conditional distributions between the source and target domains. Furthermore, we have developed a pseudo box generator that dynamically selects reliable instances and generates bounding boxes to facilitate the transfer of knowledge.Our extensive experiments demonstrate that the DATE framework achieves satisfactory performance in fully-supervised PR, PG, and unsupervised PG-DA. To facilitate further research in this field, we will make our desensitized datasets publicly available.