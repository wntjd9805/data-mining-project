Temporal video segmentation involves automatically analyzing videos by breaking them down into smaller components to facilitate further understanding. Previous research has focused on segmenting videos at different levels, such as shots, events, and scenes. While these segmentations allow for comparing semantics at specific scales, they lack a broader view of longer temporal spans, particularly in complex and structured videos. To address this, we propose two abstract levels of temporal segmentation and examine their hierarchy in relation to existing fine-grained levels. To support our research, we have created NewsNet, the largest news video dataset comprising 1,000 videos spanning over 900 hours. This dataset includes various tasks for hierarchical temporal video segmentation and features aligned audio, visual, and textual data, as well as extensive frame-wise annotations in four levels of granularity. We believe that studying NewsNet can enhance our understanding of complex structured videos and have practical applications in areas such as short-video creation, personalized advertisement, digital instruction, and education. Our dataset and code are publicly available at https://github.com/NewsNet-Benchmark/NewsNet.