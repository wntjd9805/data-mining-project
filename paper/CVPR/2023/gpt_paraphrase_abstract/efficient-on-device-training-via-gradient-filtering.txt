On-device training is a challenging task in EdgeAI due to the high computational complexity and memory consumption of the back-propagation algorithm. To address this problem, we propose a novel gradient filtering approach that reduces the number of unique elements in the gradient map. This approach significantly decreases the computational complexity and memory usage during training, enabling on-device training of convolutional neural network (CNN) models.We conducted extensive experiments using various CNN models and devices, such as MobileNet, DeepLabV3, UPerNet, Raspberry Pi, and Jetson Nano. The results demonstrate the effectiveness and wide applicability of our approach. For instance, compared to state-of-the-art methods, we achieved up to a 19× speedup and 77.1% memory savings in ImageNet classification while only experiencing a 0.1% accuracy loss.Moreover, our method is easy to implement and deploy. We observed over a 20× speedup and 90% energy savings compared to highly optimized baselines in MKLDNN and CUDNN on NVIDIA Jetson Nano. These findings highlight the potential of our approach for on-device training and open up new research directions in this field.