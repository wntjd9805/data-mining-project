We present a novel approach for training a neural radiance field (NeRF) that not only captures the appearance of a scene but also the semantic correlations between different elements within the scene. Unlike traditional methods that focus on photometric reconstruction, our method incorporates a regularization technique to align the Jacobians of highly correlated entities, maximizing the mutual information between them even under random scene perturbations. By considering this second-order information, our NeRF model can effectively express meaningful synergies when the network weights are changed. We demonstrate the effectiveness of our approach by leveraging the coordinated behavior of scene entities to perform label propagation for semantic and instance segmentation tasks. Our experiments show that our proposed JacobiNeRF outperforms NeRFs without mutual information shaping, particularly in scenarios with sparse labels, reducing the need for extensive annotation. Furthermore, our approach can also be used for entity selection and scene modifications. The code for our method is publicly available at https://github.com/xxm19/jacobinerf.