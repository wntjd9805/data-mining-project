In recent years, neural implicit rendering has emerged as a promising approach for multi-view reconstruction. Existing methods, such as NeuS and VolSDF, have been effective in generating meshes from multi-view images. However, these methods suffer from limited accuracy, particularly when the viewing direction is close to being tangent to the surface. In this paper, we propose a new rendering method that addresses this bias issue by scaling the Signed Distance Function (SDF) field with the angle between the viewing direction and the surface normal vector. Our experiments on simulated data demonstrate that this method reduces the bias in SDF-based volume rendering. Additionally, we find that there is still some bias present when the learnable standard deviation of SDF is large at an early stage, making it difficult to supervise the rendered depth using depth priors. As an alternative, we propose supervising the zero-level set with surface points obtained from a pre-trained Multi-View Stereo network. Evaluating our method on the DTU dataset, we show that it outperforms state-of-the-art neural implicit surface methods without the need for mask supervision.