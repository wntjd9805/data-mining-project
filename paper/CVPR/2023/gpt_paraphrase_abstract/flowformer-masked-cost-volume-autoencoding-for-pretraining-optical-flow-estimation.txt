FlowFormer is a state-of-the-art optical flow estimation model that incorporates a transformer architecture. The key element of FlowFormer is the transformer-based cost-volume encoder. Building on the success of masked autoencoding pretraining in enhancing the encoding capabilities of transformers for visual representation, we propose Masked Cost Volume Autoencoding (MCVA) to further improve FlowFormer. To prevent leakage of masked information, we introduce a block-sharing masking strategy, considering the high correlation between cost maps of neighboring source pixels. Additionally, we introduce a novel pretext reconstruction task that encourages the cost-volume encoder to aggregate long-range information and ensures consistency between pretraining and finetuning. We also modify the FlowFormer architecture to accommodate masks during pretraining.By pretraining FlowFormer with MCVA, we develop FlowFormer++, which achieves the highest performance among published methods on the Sintel and KITTI-2015 benchmarks. Specifically, FlowFormer++ achieves an average endpoint error (AEPE) of 1.07 and 1.94 on the clean and final pass of the Sintel benchmark, resulting in error reductions of 7.76% and 7.18% compared to FlowFormer. FlowFormer++ achieves a F1-all score of 4.52 on the KITTI-2015 test set, improving upon FlowFormer by 0.16.