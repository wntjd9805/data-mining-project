This research focuses on the development of a system that can estimate and track the pose of garments. The researchers have created a package consisting of a recording system called VR-Garment, a dataset named VR-Folding, and an online tracking framework called GarmentTracking. The VR-Garment system allows users to manipulate virtual garment models through a virtual reality interface. The VR-Folding dataset contains various complex garment pose configurations for manipulation tasks like flattening and folding. The GarmentTracking framework predicts the complete pose of a garment in both canonical space and task space using a sequence of point cloud data. The researchers conducted extensive experiments and found that GarmentTracking performs well even when the garment undergoes large non-rigid deformation. It surpasses the baseline approach in terms of both speed and accuracy. The researchers hope that their proposed solution can serve as a foundation for future research in this area. The codes and datasets related to this study can be accessed at https://garment-tracking.robotflow.ai.