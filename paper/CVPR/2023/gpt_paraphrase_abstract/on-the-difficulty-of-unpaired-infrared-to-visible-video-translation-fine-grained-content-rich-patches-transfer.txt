Explicit visible videos are useful for vision applications, but visible cameras are affected by light conditions. Infrared sensors have become popular for autonomous driving and monitoring due to their stable imaging capabilities. However, vision models trained on visible data face challenges when applied to infrared scenarios. Transferring infrared videos to visible ones with detailed semantic patterns is valuable. Previous approaches equalize the optimization of each patch in translated visible results, which is unfair for content-rich patches. We propose the CPTrans framework to address this challenge by balancing gradients of different patches and achieving fine-grained content-rich patch transferring. Our content-aware optimization module enhances model optimization along target patch gradients, improving visual details. The content-aware temporal normalization module ensures the generator's robustness to target patch motions. We expand the InfraredCity dataset to include adverse weather conditions. Experimental results demonstrate that CPTrans outperforms other methods in diverse scenes while requiring less training time.