We introduce VISPROG, a neuro-symbolic method for resolving intricate and compositional visual tasks using natural language instructions. VISPROG eliminates the necessity for task-specific training by utilizing the contextual learning capability of large language models. It generates modular programs resembling Python code and executes them to obtain both the solution and a comprehensive and interpretable justification. Each line of the generated program can employ various pre-existing computer vision models, image processing subroutines, or Python functions to produce intermediate outputs that can be utilized by subsequent parts of the program. We showcase the versatility of VISPROG by applying it to four diverse tasks: compositional visual question answering, zero-shot reasoning on image pairs, factual knowledge object tagging, and language-guided image editing. We strongly believe that neuro-symbolic approaches like VISPROG offer a promising opportunity to effortlessly and effectively broaden the capabilities of AI systems, enabling them to handle a wide range of complex tasks that individuals may desire to accomplish.