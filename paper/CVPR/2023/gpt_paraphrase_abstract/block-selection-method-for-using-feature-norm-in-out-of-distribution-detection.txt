Detecting out-of-distribution (OOD) inputs during inference is crucial for deploying neural networks in real-world scenarios. Previous methods have relied on highly activated feature maps as indicators for OOD detection. However, in this study, we have discovered that the norm of the feature map obtained from a block other than the last block of the network can serve as a more effective indicator.To leverage this insight, we propose a simple framework that consists of two metrics: FeatureNorm, which calculates the norm of the feature map, and NormRatio, which computes the ratio of FeatureNorm for in-distribution (ID) and OOD samples to evaluate OOD detection performance for each block. To identify the block that exhibits the largest difference between FeatureNorm of ID and FeatureNorm of OOD, we generate jigsaw puzzles as pseudo OOD samples from ID training samples and calculate NormRatio. The block with the highest NormRatio is selected.After identifying the suitable block, OOD detection using FeatureNorm surpasses other methods by reducing the false positive rate at 95% recall (FPR95) by up to 52.77% on the CIFAR10 benchmark and up to 48.53% on the ImageNet benchmark. We demonstrate the generalizability of our framework across various architectures and emphasize the importance of block selection, which can also enhance previous OOD detection methods.For further details and implementation, our code is available at https://github.com/gist-ailab/block-selection-for-OOD-detection.