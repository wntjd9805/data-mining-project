Dynamic Facial Expression Recognition (DFER) is an advancing field that focuses on detecting facial expressions in video format. Previous studies have considered non-target frames as noisy frames, however, we argue that they should be regarded as weakly supervised. Additionally, we have identified an imbalance in the temporal relationships of short and long-term durations in DFER. To address these issues, we propose the Multi-3D Dynamic Facial Expression Learning (M3DFEL) framework, which employs Multi-Instance Learning (MIL) to handle imprecise labels. M3DFEL generates 3D-instances to capture the strong short-term temporal relationship and uses 3DCNNs for feature extraction. To learn the long-term temporal relationships and effectively combine the instances, we introduce the Dynamic Long-term Instance Aggregation Module (DLIAM). Our experiments on DFEW and FERV39K datasets demonstrate that M3DFEL surpasses existing state-of-the-art methods using a vanilla R3D18 backbone. The source code for M3DFEL is available at https://github.com/faceeyes/M3DFEL.