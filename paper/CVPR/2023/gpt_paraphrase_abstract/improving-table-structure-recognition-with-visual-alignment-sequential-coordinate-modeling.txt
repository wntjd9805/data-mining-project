Table structure recognition aims to convert unstructured table images into a format that can be understood by machines. Existing methods use end-to-end image-to-text approaches where two decoders predict the logical and physical structures of the tables. However, these methods struggle with inaccurate bounding boxes because the logical representation lacks local visual information. To address this, we propose a sequential modeling framework called VAST for table structure recognition. VAST includes a novel coordinate sequence decoder that uses the representation of non-empty cells from the logical structure decoder. This decoder models the bounding box coordinates as a language sequence, decoding the left, top, right, and bottom coordinates sequentially to capture inter-coordinate dependency. Additionally, we introduce an auxiliary visual-alignment loss to encourage the logical representation of non-empty cells to include more local visual details, leading to improved bounding boxes for the cells. Extensive experiments demonstrate that our proposed method achieves state-of-the-art results in recognizing both the logical and physical structures of tables. Ablation studies confirm that the success of our method relies on the coordinate sequence decoder and the visual-alignment loss.