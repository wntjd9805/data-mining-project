This abstract discusses the significance of facial micro-expressions (MEs) in revealing genuine emotions and their applications in lie detection and criminal analysis. While deep learning methods have been successful in recognizing MEs, they often require pre-processing using optical flow-based methods to extract facial motions. To overcome this limitation, the authors propose a novel MER framework called SelfME that uses self-supervised learning to extract facial motion. This is the first work to utilize an automatically self-learned motion technique for MER. However, the self-supervised motion learning method may ignore symmetrical facial actions on the left and right sides of faces, leading to the development of a symmetric contrastive vision transformer (SCViT) to address this issue. Experimental results on two benchmark datasets demonstrate that the proposed method achieves state-of-the-art performance, and ablation studies confirm its effectiveness.