This paper introduces a new method called Closest Permutation Matching (CPM) for RGB-IR Group re-identification (G-ReID). While existing literature primarily focuses on RGB-based problems, the RGB-IR cross-modality matching problem has not been extensively studied. The proposed method models each group as a set of single-person features extracted by MPANet. It then utilizes the Closest Permutation Distance (CPD) metric to measure the similarity between two sets of features. CPD is designed to be invariant to changes in the order of group members, effectively solving the layout change problem in G-ReID. Additionally, the paper addresses the issue of G-ReID without person labels, introducing the Relation-aware Module (RAM) that exploits visual context and relations among group members to generate a modality-invariant order of features. This allows group member features within a set to be sorted and form a robust group representation against modality change. To facilitate the study of RGB-IR G-ReID, the authors construct a new large-scale dataset called CM-Group, which includes 15,440 RGB images and 15,506 infrared images of 427 groups and 1,013 identities. Extensive experiments conducted on this dataset demonstrate the effectiveness of the proposed models and the complexity of CM-Group. The code and dataset for this research are publicly available at the provided GitHub link.