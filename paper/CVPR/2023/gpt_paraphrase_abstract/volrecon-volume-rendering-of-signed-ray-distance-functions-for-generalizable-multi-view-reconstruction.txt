Neural Radiance Fields (NeRF) have been successful in synthesizing novel views, leading researchers to propose neural implicit scene reconstruction. However, existing methods in this area optimize per-scene parameters, limiting their generalizability to new scenes. To address this, we present VolRecon, a novel implicit reconstruction method with a Signed Ray Distance Function (SRDF). VolRecon combines projection features from multi-view features and volume features from a coarse global feature volume to reconstruct scenes with fine details and minimal noise. Using a ray transformer, we compute SRDF values of sampled points on a ray and render color and depth. In evaluations on the DTU dataset, VolRecon outperforms SparseNeuS by approximately 30% in sparse view reconstruction and achieves comparable accuracy to MVSNet in full view reconstruction. Additionally, VolRecon demonstrates strong generalization performance on the large-scale ETH3D benchmark. The code for VolRecon is available at https://github.com/IVRL/VolRecon/.