The Neural Radiance Field (NeRF) has shown impressive capabilities in reconstructing three-dimensional (3D) scenes using multiple views and calibrated camera parameters. However, previous NeRF-based systems have mainly been tested under controlled conditions and have not addressed real-world scenarios involving noise, such as exposure changes, illumination variations, and blur. While blur is commonly encountered in practical situations, there has been little research on NeRF's ability to handle blurred images. Existing studies on NeRF and blur have overlooked the importance of maintaining geometric and appearance consistency in 3D space, which is crucial for accurate reconstruction. As a result, there are inconsistencies and a decline in the perceived quality of the reconstructed scene. To address this issue, we propose a new framework called DP-NeRF, which is specifically designed for blurred images. DP-NeRF incorporates two physical priors that are derived from the actual blurring process during image acquisition by the camera. It utilizes a rigid blurring kernel to enforce 3D consistency based on these priors and employs adaptive weight proposals to enhance the color composition accuracy while considering the relationship between depth and blur. We conducted extensive experiments on both synthetic and real scenes, with two types of blur: camera motion blur and defocus blur. The results demonstrate that DP-NeRF significantly enhances the perceptual quality of the reconstructed NeRF, ensuring consistency in both 3D geometry and appearance. We further validate the effectiveness of our model through comprehensive ablation analysis.