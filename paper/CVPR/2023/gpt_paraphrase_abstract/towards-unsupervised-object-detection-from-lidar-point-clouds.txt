This paper focuses on the problem of detecting objects in self-driving scenes using unsupervised methods. The authors propose a method called OYS-TER that utilizes point clustering, temporal consistency, CNN translation equivariance, and self-supervision to improve object detection. Unlike other approaches, OYS-TER does not require repeated data collection or supervised fine-tuning, and it can detect objects even in sparse and distant regions. The model also continues to improve with more rounds of self-training. To evaluate model performance, a new perception metric based on distance-to-collision is introduced. Experimental results on PandaSet and Argoverse 2 Sensor dataset demonstrate that OYS-TER outperforms other unsupervised baselines, suggesting that self-supervision combined with object priors can facilitate object discovery in real-world scenarios. More details can be found on the project website: https://waabi.ai/research/oyster.