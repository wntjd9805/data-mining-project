This paper addresses two main challenges in human pose estimation from monocular images. Firstly, the inconsistent performance of different perspectives (front view, side view, and top view) due to depth ambiguity. Secondly, the significant role of foot posture in complex pose estimation scenarios such as dance and sports, as well as foot-ground interaction, which is often overlooked in existing approaches and datasets. To tackle these challenges, the authors propose the Cross-View Fusion (CVF) module, which utilizes a vision transformer encoder to improve the 3D intermediate representation and mitigate view inconsistency. Additionally, an optimization-based method is introduced to reconstruct foot pose and foot-ground contact using general multi-view datasets, including AIST++ and Human3.6M. Furthermore, the authors innovate a reversible kinematic topology strategy to incorporate contact information into the full-body pose estimation with a foot pose regressor. Extensive experiments on popular benchmarks demonstrate that the proposed method outperforms state-of-the-art approaches, achieving 40.1mm PA-MPJPE on the 3DPW test set and 43.8mm on the AIST++ test set.