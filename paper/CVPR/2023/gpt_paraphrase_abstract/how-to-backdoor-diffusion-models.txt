This paper presents the first study on the vulnerability of diffusion models to backdoor attacks and introduces a new attack framework called BadDiffusion. Diffusion models are deep learning generative models that are trained using forward and reverse diffusion processes. The proposed BadDiffusion framework engineers compromised diffusion processes during model training to implant backdoors. These backdoored diffusion models behave normally for regular inputs but generate specific targeted outcomes when triggered. This poses a significant risk for downstream tasks and applications that rely on these models. The experiments conducted demonstrate that BadDiffusion consistently compromises diffusion models with high utility and target specificity. Furthermore, it is shown that finetuning a clean pre-trained diffusion model can make the attack cost-effective. The paper also explores potential countermeasures for mitigating the risks associated with these attacks. The findings highlight the potential risks and misuse of diffusion models, emphasizing the need for attention to their security. The code for BadDiffusion is available on GitHub at https://github.com/IBM/BadDiffusion.