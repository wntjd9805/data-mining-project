Researchers have long been interested in reconstructing indoor scenes from single images in order to improve augmented reality and robotics applications. Recent advancements in neural field representations and monocular priors have produced impressive results in surface reconstruction at the scene level. However, the use of Multilayer Perceptrons (MLP) has imposed limitations on the speed of both training and rendering processes. To overcome these limitations, this study proposes the direct utilization of signed distance function (SDF) in sparse voxel block grids, enabling fast and accurate scene reconstruction without the need for MLPs. This data structure takes advantage of the spatial sparsity of surfaces, facilitating cache-friendly queries and accommodating multi-modal data like color and semantic labels. In the context of monocular scene reconstruction, the researchers develop a scale calibration algorithm for efficient geometric initialization based on monocular depth priors. They then employ differentiable volume rendering from this initialization to enhance details with fast convergence. Additionally, the study introduces high-dimensional Continuous Random Fields (CRFs) to effectively leverage the consistency between semantic labels and geometry of scene objects.Experimental results demonstrate that the proposed approach achieves faster rendering speeds while maintaining comparable accuracy to state-of-the-art neural implicit methods. It is also significantly faster in training, with a speed improvement of 100 times.