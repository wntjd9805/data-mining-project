The generalization problem is a major challenge in meta-learning, despite its widespread interest. While existing research focuses on meta-generalization to unseen tasks at the meta-level, it overlooks the fact that adapted models may not generalize well to the task domains at the adaptation level. In this paper, we propose a new regularization mechanism called Minimax-Meta Regularization. This approach utilizes inverted regularization at the inner loop and ordinary regularization at the outer loop during training. By employing inner inverted regularization, we make it harder for the adapted model to generalize to task domains. Consequently, optimizing the outer-loop loss compels the meta-model to learn meta-knowledge that exhibits better generalization. Theoretical analysis demonstrates that inverted regularization enhances meta-testing performance by reducing generalization errors. Through extensive experiments in various scenarios, we consistently observe improved performance of meta-learning algorithms when employing our method.