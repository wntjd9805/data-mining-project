We introduce ShearletX, a novel explanation method for image classifiers that is based on the shearlet transform, a multiscale directional image representation. Current methods for explaining image classifiers rely on smoothness constraints to regulate the masks, but this limits their ability to separate fine-detail patterns that are relevant for the classifier from nearby nuisance patterns that do not affect the classifier. ShearletX overcomes this limitation by using shearlet sparsity constraints instead of smoothness regularization. The resulting explanations consist of a few edges, textures, and smooth parts of the original image that are most relevant for the classifier's decision. We propose a mathematical definition for explanation artifacts and an information theoretic score to evaluate the quality of mask explanations. By using these new metrics, we demonstrate the superiority of ShearletX over previous mask-based explanation methods. We also provide examples where the ability to separate fine-detail patterns allows for the explanation of phenomena that were previously unexplainable.