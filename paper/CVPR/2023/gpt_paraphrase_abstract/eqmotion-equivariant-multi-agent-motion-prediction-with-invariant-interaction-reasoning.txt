Learning to predict the movements of agents while considering their relationships is crucial for various applications. Existing methods often overlook the importance of maintaining motion equivariance under geometric transformations and invariance of agent interactions. To address this gap, we propose Eq-Motion, an efficient model for motion prediction that incorporates equivariance and invariance principles. To achieve motion equivariance, we introduce an equivariant geometric feature learning module that learns a transformable feature using specialized equivariant operations. This enables the model to maintain consistency in motion predictions across different geometric transformations. To reason about agent interactions, we propose an invariant interaction reasoning module. This module ensures stable modeling of agent interactions by considering their invariance properties. Furthermore, we propose an invariant pattern feature learning module to enhance the comprehensiveness of motion features. This module cooperates with the equivariant geometric feature learning module to improve the expressiveness of the network. We evaluate our proposed model, Eq-Motion, on four distinct scenarios: particle dynamics, molecule dynamics, human skeleton motion prediction, and pedestrian trajectory prediction. Experimental results demonstrate that our method is not only generally applicable but also outperforms existing methods, achieving state-of-the-art prediction performances on all four tasks with improvements of 24.0%, 30.1%, 8.6%, and 9.2%, respectively. The code for our model is available at https://github.com/MediaBrain-SJTU/EqMotion.