This paper challenges the existing research on continual learning (CL) by highlighting another significant obstacle in class-incremental learning (CIL) known as cross-task class discrimination (CTCD). CTCD refers to the difficulty of establishing decision boundaries between new and old classes without access to sufficient old task data. While replay-based methods partially address CTCD by saving a small amount of previous task data (replay data) and training it with current task data, this paper argues that replay methods suffer from a dynamic training bias issue that hinders their effectiveness in solving the CTCD problem. To address this issue, the paper proposes a novel optimization objective and a gradient-based adaptive method to dynamically tackle the problem in the online CL process. Experimental results demonstrate that this new method significantly improves online CL performance.