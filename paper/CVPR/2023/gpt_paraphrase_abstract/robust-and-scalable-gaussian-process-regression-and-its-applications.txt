This paper presents a novel Gaussian process regression (GPR) model that is both robust and scalable. By using variational learning, the model can effectively handle large-scale real data that may contain outliers. The model utilizes a mixture likelihood approach, assuming that outliers are sampled from a uniform distribution. A variational formulation is derived to simultaneously infer the data mode (inlier or outlier) and hyperparameters by maximizing a lower bound of the true log marginal likelihood. Compared to previous robust GPR models, our formulation provides an approximation of the exact posterior distribution. Additionally, we introduce inducing variable approximation and stochastic variational inference techniques to extend our model to large-scale data. We validate our model on two challenging real-world applications: feature matching and dense gene expression imputation. Extensive experiments demonstrate the superior robustness and speed of our model. Notably, when matching 4k feature points, our model achieves millisecond inference time with almost no false matches. The code for our model can be found at github.com/YifanLu2000/Robust-Scalable-GPR.