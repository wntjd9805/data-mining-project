The study introduces the AttentionShift method to address the issue of semantic bias and false segmentation in pointly supervised instance segmentation (PSIS). PSIS learns to segment objects using a single point as supervision, but this approach is limited by the semantic variance between object parts. The proposed AttentionShift method aims to overcome this limitation by iteratively decomposing the instance attention map into parts and estimating fine-grained semantics for each part. It consists of two modules: token querying for generating pointly supervised attention maps and key-point shift for re-estimating part-based attention maps. These two steps are performed iteratively to optimize the part-based attention maps spatially and in the feature space, ensuring full coverage of the object extent. Experimental results on the PASCAL VOC and MS COCO 2017 datasets demonstrate that AttentionShift significantly improves the state-of-the-art performance of PSIS by 7.7% and 4.8% respectively in terms of mAP@0.5. A visual comparison with existing methods illustrates the effectiveness of AttentionShift in precisely localizing the full object extent.