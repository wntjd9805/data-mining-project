Self-supervised audio-visual source localization aims to locate sound-source objects in video frames without the need for additional annotations. Current methods often rely on contrastive learning, which considers audio and visual content from the same video as positive samples for each other. However, this approach can lead to false negative samples during real-world training scenarios. For instance, considering frames from the same audio class as negative samples for an audio sample can mislead the model and negatively impact the learned representations. To address this issue, we propose a new learning strategy called FalseNegative Aware Contrastive (FNAC). FNAC leverages intra-modal similarities to identify potentially similar samples and constructs adjacency matrices to guide contrastive learning. Additionally, we enhance the role of true negative samples by utilizing visual features of sound sources to improve the differentiation of authentic sound-source regions. Our FNAC method achieves state-of-the-art performance on Flickr-SoundNet, VGG-Sound, and AVSBench datasets, highlighting its effectiveness in mitigating the false negative problem. The code for our method is available at https://github.com/OpenNLPLab/FNAC_AVL.