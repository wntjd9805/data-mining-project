We introduce DejaVu, a new framework that enhances deep networks for dense prediction tasks like segmentation, depth estimation, and surface normal prediction. DejaVu utilizes conditional image regeneration as an additional form of supervision during training. The framework works by first applying redaction to the input image, which removes certain structural information through sparse sampling or selective frequency removal. Then, a conditional regenerator is used to reconstruct the original image by filling in the missing structural information, taking the redacted image and dense predictions as inputs. While boundaries are broken in the redacted image, the semantic context is mostly preserved. To make the regeneration possible, the conditional generator relies on the structure information from the dense predictions. By incorporating this conditional regeneration objective during training, DejaVu encourages the base network to learn accurate scene structure and produce more precise predictions with clearer boundaries and improved spatial consistency. Additionally, DejaVu can be extended to include an attention-based regeneration module within the dense prediction network, further enhancing accuracy when additional computation is available. Extensive experiments on various dense prediction benchmarks demonstrate the effectiveness of DejaVu during training, surpassing state-of-the-art methods without any additional computation cost.