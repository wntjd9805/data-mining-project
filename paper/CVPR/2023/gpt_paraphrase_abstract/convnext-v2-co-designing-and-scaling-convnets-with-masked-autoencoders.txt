The field of visual recognition has experienced significant advancements and performance improvements in recent years, thanks to improved architectures and representation learning frameworks. One notable architecture, ConvNeXt, has shown impressive performance in various scenarios. While ConvNeXt was initially designed for supervised learning with ImageNet labels, it has the potential to benefit from self-supervised learning techniques like masked autoencoders (MAE). However, combining these two approaches alone does not yield satisfactory results. To address this, we propose a fully convolutional masked autoencoder framework and a new Global Response Normalization (GRN) layer that can be incorporated into the ConvNeXt architecture. This co-design of self-supervised learning techniques and architectural improvements gives rise to a new model family called ConvNeXtV2. ConvNeXtV2 significantly enhances the performance of pure ConvNets on various recognition benchmarks, including ImageNet classification, COCO detection, and ADE20K segmentation. Additionally, we provide pre-trained ConvNeXtV2 models of different sizes, ranging from a compact 3.7M-parameter Atto model achieving 76.7% top-1 accuracy on ImageNet to a larger 650M Huge model attaining a state-of-the-art 88.9% accuracy using only publicly available training data.