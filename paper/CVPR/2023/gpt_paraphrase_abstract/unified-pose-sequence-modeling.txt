We propose a new approach called Unified Pose Sequence Modeling (UPS) to address the challenge of unifying different tasks related to human behavior understanding based on pose data. These tasks include action recognition, 3D pose estimation, and 3D early action prediction. The main issue is that these tasks require different output formats - action recognition and prediction tasks need class predictions as outputs, while 3D pose estimation requires human pose output. This limitation prevents the use of task-specific network architectures for each task.To overcome this challenge, we introduce the UPS model which unifies the output formats for the aforementioned tasks by treating text-based action labels and coordinate-based human poses as language sequences. By optimizing a single auto-regressive transformer, we can generate a unified output sequence that can handle all the tasks. Additionally, we propose a dynamic routing mechanism to address the heterogeneity between tasks and enable the UPS model to learn which parameters should be shared among different tasks.To evaluate the effectiveness of the UPS model, we conduct extensive experiments on four different tasks using four popular behavior understanding benchmarks. The results demonstrate the efficacy of our approach in unifying heterogeneous human behavior understanding tasks based on pose data.