The deployment of autonomous vehicles on a large scale is still pending, with one of the main challenges being dense urban traffic situations. Predicting the future development of the scene and the behavior of objects, as well as handling unexpected events like sudden appearance of hidden objects, remains difficult. This study introduces ReasonNet, an innovative framework for driving that utilizes both temporal and global information of the driving scene. By analyzing the temporal behavior of objects, our method effectively processes the interactions and relationships among features in different frames. Furthermore, considering the global information of the scene improves overall perception performance and aids in detecting adverse events, particularly in anticipating potential danger from hidden objects. To comprehensively evaluate occlusion events, a driving simulation benchmark called DriveOcclusionSim, consisting of various occlusion events, is also made publicly available. Extensive experiments on multiple CARLA benchmarks demonstrate that our model surpasses previous methods, securing the top position on the sensor track of the public CARLA Leaderboard [53].