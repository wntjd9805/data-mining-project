Deep metric learning (DML) focuses on learning compact image embeddings that capture semantic similarities between images and can be generalized to unseen test classes. However, existing approaches in DML overlook important information in individual images when computing similarity between pairs of images. To address this limitation, we propose a novel training strategy that conditions the embedding of an image on the image it is being compared to. Instead of using a simple pooling technique, we employ cross-attention to allow one image to identify relevant features in the other image. This attention mechanism establishes a hierarchy of conditional embeddings, gradually incorporating information about the image pair to guide the representation of each individual image. By bridging the gap between the original unconditional embedding and the final similarity, the cross-attention layers enable more direct updating of encodings through backpropagation, avoiding lossy pooling layers. During testing, we utilize the improved unconditional embeddings obtained from training, requiring no extra parameters or computational overhead. Experimental results on well-established DML benchmarks demonstrate that our cross-attention conditional embedding approach significantly enhances the standard DML pipeline, surpassing the state-of-the-art performance.