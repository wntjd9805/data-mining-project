Deep learning-based approaches have been successful in multi-view stereo due to their ability to extract strong visual features. However, these methods often require the construction of a large cost volume and a significant increase in receptive field size to handle large-scale textureless regions. This results in high memory usage, which is impractical. In order to address this issue, we propose a novel approach that combines the concept of deformable convolution from deep learning with the traditional PatchMatch-based method. Our method focuses on unreliable pixels, which are pixels with matching ambiguity, and adaptsively deforms the patch centered on these pixels to extend the receptive field. This deformation ensures that enough correlative reliable pixels, without matching ambiguity, are covered. By constraining the matching cost of unreliable pixels based on the anchor pixels, we guarantee that the correct depth is reached, thus significantly improving the robustness of multi-view stereo. To identify more anchor pixels for better adaptive patch deformation, we evaluate the matching ambiguity of a pixel by monitoring the convergence of the estimated depth during optimization. Our approach achieves state-of-the-art performance on ETH3D and Tanks and Temples datasets while maintaining low memory consumption.