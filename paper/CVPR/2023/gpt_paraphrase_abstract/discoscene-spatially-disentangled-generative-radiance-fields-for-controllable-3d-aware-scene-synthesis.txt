This work introduces DisCoScene, a 3D-aware generative model for synthesizing complex scenes. Existing approaches in 3D-aware image synthesis focus on generating a single object and struggle with composing scenes containing multiple objects. DisCoScene addresses this limitation by utilizing a simple yet informative object-level representation, 3D bounding boxes without semantic annotation, as the scene layout prior. This representation is easy to obtain and can describe various scene contents while enabling intuitive user control for scene editing. The proposed model disentangles the scene into object-centric generative radiance fields based on this prior, learning from 2D images with global-local discrimination. This approach allows for high-quality generation of individual objects and efficient composition of objects and the background into complete scenes. The model achieves state-of-the-art performance on various scene datasets, including the challenging Waymo outdoor dataset.