ResFormer is a framework developed to address the vulnerability of Vision Transformers (ViTs) in handling input resolutions that were not seen during training. ViTs have been successful, but their performance drops significantly when presented with unseen resolutions. ResFormer improves performance on a wide range of testing resolutions by using multi-resolution training. It operates on replicated images of different resolutions and enforces a scale consistency loss to incorporate information from different scales. To effectively handle varying resolutions during testing, ResFormer introduces a global-local positional embedding strategy that smoothly adjusts based on input sizes. Experimental results on ImageNet for image classification demonstrate that ResFormer has promising scaling abilities across resolutions. For example, ResFormer-B-MR achieves a Top-1 accuracy of 75.86% and 81.72% on low and high resolutions (96 and 640) respectively, outperforming DeiT-B by 48% and 7.49%. ResFormer is also flexible and can be extended to other tasks such as semantic segmentation, object detection, and video action recognition.