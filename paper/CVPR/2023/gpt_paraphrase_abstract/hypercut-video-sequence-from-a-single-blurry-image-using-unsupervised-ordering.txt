This study focuses on the training of image-to-video deblurring models, aiming to restore a sequence of sharp images from a blurry image input. The main challenge in training these models is the ambiguity in determining the correct order of frames, as both forward and backward sequences can be plausible solutions. To address this issue, the authors propose a self-supervised ordering scheme that enables the training of high-quality image-to-video deblurring models. Unlike previous methods that rely on order-invariant losses, this approach assigns an explicit order to each video sequence, eliminating the ambiguity. The authors achieve this by mapping each video sequence to a vector in a latent high-dimensional space, where a hyperplane is defined such that the vectors extracted from a sequence and its reverse are located on different sides. The side of the vectors is then used to determine the order of the corresponding sequence. Additionally, the authors introduce a real-image dataset covering various popular domains, such as face, hand, and street, to further enhance the image-to-video deblurring problem. Extensive experimental results validate the effectiveness of the proposed method. The code and data for the study are available at https://github.com/VinAIResearch/HyperCUT.git.