The task of seeing in the dark is a complex computer vision challenge with numerous practical applications. Current approaches can be categorized into two types: those that rely on degraded RGB inputs for information restoration, and those that translate images captured with near-infrared (NIR) illuminants into the RGB domain. The latter approach is appealing as it can operate in complete darkness and the illuminants are visually friendly. However, it suffers from instability due to inherent ambiguities. This paper aims to enhance the stability of NIR2RGB translation by designing an optimal spectrum of auxiliary illumination within the wide-band VIS-NIR range while maintaining visual friendliness. The authors propose quantifying the visibility constraint imposed by the human vision system and incorporating it into the design process. They model the image formation process in the VIS-NIR range and automatically design the optimal multiplexing of a wide range of LEDs in a differentiable manner, considering the visibility constraint. Additionally, they create a comprehensive VIS-NIR hyperspectral image dataset using a customized 50-band filter wheel for experimental purposes. The results demonstrate that the task can be significantly improved using the optimized wide-band illumination compared to NIR-only methods. The source code is available at https://github.com/MyNiuuu/VCSD.