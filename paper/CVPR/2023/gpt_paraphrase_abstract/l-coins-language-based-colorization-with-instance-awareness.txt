Our paper proposes a transformer-based framework for language-based colorization that addresses the issue of distinguishing instances corresponding to the same object words. Previous studies have introduced additional annotation to prevent color-object coupling and mismatch problems, but still struggle with this task. To overcome this challenge, we utilize luminance augmentation and counter-color loss to break down the statistical correlation between luminance and color words. This approach drives our model to synthesize colors that are more consistent with the provided language descriptions. Additionally, we create a dataset that includes distinctive visual characteristics and detailed language descriptions for multiple instances in the same image. Through extensive experiments, we demonstrate the effectiveness of our framework in producing visually appealing and description-consistent results for instance-aware colorization.