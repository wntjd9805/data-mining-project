The paper explores exemplar-guided image editing as a more precise form of control. The authors use self-supervised training to disentangle and re-organize the source image and the exemplar, but they also identify and address the issue of fusing artifacts that can occur with this approach. They propose a content bottleneck and strong augmentations to prevent simply copying and pasting the exemplar image. Additionally, they design an arbitrary shape mask for the exemplar image and use classifier-free guidance to increase similarity. The framework involves a single forward of the diffusion model without iterative optimization. The authors demonstrate that their method achieves impressive performance, allowing for controllable editing on real-world images with high fidelity. The code for their method is available online.