This abstract discusses the development of a novel 3D Generative Adversarial Network (GAN) framework for generating high-quality and 3D-consistent facial avatars from 2D images. Existing methods have limitations in handling topological changes and achieving fine-grained control over facial attributes. To overcome these limitations, the proposed framework utilizes a 3D representation called Generative Texture-RasterizedTri-planes, which combines fine-grained expression control with the flexibility of implicit volumetric representation. The framework also includes specific modules for modeling the mouth interior, which is not considered by existing models. Extensive experiments demonstrate that the proposed method achieves state-of-the-art synthesis quality and animation ability. Additionally, the animatable 3D representation can be used as a 3D prior for various applications, including one-shot facial avatars and 3D-aware stylization. The project page and code for the proposed framework are provided for further reference.