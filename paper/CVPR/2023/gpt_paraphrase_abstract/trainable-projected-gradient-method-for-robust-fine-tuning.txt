Recent research has demonstrated that selectively fine-tuning specific layers or adjusting learning rates for each layer can significantly enhance the ability of pre-trained models to handle out-of-distribution (OOD) data and maintain generalization capability. However, most existing methods rely on manual heuristics or computationally expensive hyper-parameter searches, limiting their scalability to large datasets and neural networks. To address this limitation, we propose the Trainable Projected Gradient Method (TPGM), which automatically learns constraints for fine-grained fine-tuning regularization. Our approach formulates fine-tuning as a bi-level constrained optimization problem. TPGM utilizes a set of projection radii, representing distance constraints between the fine-tuned model and the pre-trained model, for each layer. These constraints are enforced through weight projections. To learn the constraints, we introduce a bi-level optimization framework that automatically determines the best set of projection radii in an end-to-end manner. Theoretically, we demonstrate that this bi-level optimization formulation enables the learning of distinct constraints for each layer. Empirically, TPGM outperforms existing fine-tuning methods in terms of OOD performance while achieving comparable in-distribution (ID) performance, with minimal hyper-parameter search required. For instance, when fine-tuning on DomainNet-Real and ImageNet datasets, TPGM yields relative OOD performance improvements of 22% and 10%, respectively, compared to vanilla fine-tuning, specifically for their sketch counterparts. The code for TPGM is publicly available at https://github.com/PotatoTian/TPGM.