Existing skeletal action recognition models often use graph convolutional networks (GCNs) to represent the human body by connecting 3D body joints. However, these models typically only consider the immediate neighbors of each joint and overlook the dependencies between non-connected joints. To address this limitation, we propose the use of hypergraphs to model hyper-edges between graph nodes, allowing for the capture of higher-order motion patterns involving groups of body joints.To process action sequences, we divide them into temporal blocks. We introduce the Higher-order Transformer (HoT) to generate embeddings for each temporal block. These embeddings are based on the body joints, pairwise links between body joints, and higher-order hyper-edges of the skeleton body joints. To combine the HoT embeddings of hyper-edges of different orders, we introduce a novel Multi-order Multi-mode Transformer (3Mformer) with two modules. These modules enable coupled-mode attention on coupled-mode tokens, considering various pairings such as 'channel-temporal block', 'order-channel-body joint', 'channel-hyper-edge (any order)', and 'channel-only'. The first module, called Multi-order Pooling (MP), learns weighted aggregation along the hyper-edge mode. The second module, Temporal block Pooling (TP), aggregates along the temporal block mode.Our end-to-end trainable network achieves state-of-the-art results compared to GCN-, transformer-, and hypergraph-based models.