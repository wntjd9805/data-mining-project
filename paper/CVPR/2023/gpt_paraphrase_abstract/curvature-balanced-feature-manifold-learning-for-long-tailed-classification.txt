To tackle the challenges of long-tailed classification, researchers have proposed various methods to reduce model bias. However, these approaches often assume that classes with few samples are weak, overlooking the fact that tail classes can be easy to learn. Recent studies have shown that model bias can exist even in sample-balanced datasets, suggesting the presence of other factors affecting model performance. In this study, we systematically introduce a set of geometric measurements for perceptual manifolds in deep neural networks. We investigate how the geometric characteristics of these manifolds impact classification difficulty and how learning influences these characteristics. An unexpected discovery is that as training progresses, the correlation between class accuracy and the separation degree of perceptual manifolds gradually diminishes, while the negative correlation with curvature increases. This suggests that model bias is influenced by curvature imbalance. To address this, we propose a curvature regularization technique to encourage the learning of curvature-balanced and flatter perceptual manifolds. Our approach is evaluated on multiple long-tailed and non-long-tailed datasets, demonstrating excellent performance and broad applicability. We achieve significant improvements compared to current state-of-the-art techniques. This work introduces a geometric analysis perspective on model bias and highlights the importance of considering model bias in non-long-tailed and sample-balanced datasets. The code and model will be publicly available.