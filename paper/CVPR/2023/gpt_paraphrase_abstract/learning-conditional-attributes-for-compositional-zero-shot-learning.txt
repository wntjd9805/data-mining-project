Compositional Zero-Shot Learning (CZSL) is a task that involves training models to recognize new compositional concepts based on previously learned concepts, such as attribute-object combinations. One of the main challenges in CZSL is accurately modeling attributes that interact with different objects. For example, the attribute "wet" in "wet apple" and "wet cat" may have different meanings. To address this challenge, we propose an analysis that suggests attributes are dependent on the recognized object and input image. We introduce a framework for learning conditional attribute embeddings, consisting of an attribute hyper learner and an attribute base learner. By encoding conditional attributes, our model is able to generate flexible attribute embeddings, allowing for better generalization from seen to unseen compositions. Our experiments on CZSL benchmarks, including the challenging C-GQA dataset, show improved performance compared to other state-of-the-art approaches. These results validate the significance of learning conditional attributes in CZSL. The code for our proposed framework is available at https://github.com/wqshmzh/CANet-CZSL.