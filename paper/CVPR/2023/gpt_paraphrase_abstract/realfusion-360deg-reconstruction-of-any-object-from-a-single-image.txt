We explore the challenge of creating a complete 360â—¦ photographic model of an object using just one image. To address this problem, we utilize a neural radiance field and find it to be highly problematic due to its ill-posed nature. To overcome this, we employ a pre-existing conditional image generator that utilizes diffusion and devise a prompt that encourages it to generate new perspectives of the object. By incorporating the recently developed DreamFusion technique, we combine the original image, conditional prior, and other regularizers to achieve a consistent and final reconstruction. Our approach outperforms previous methods in terms of monocular 3D object reconstruction, as demonstrated by benchmark image comparisons. Our reconstructions accurately match the input view and provide a plausible extrapolation of the object's appearance and 3D shape, even for the unseen side.