The conversion of features from a 2D perspective to a 3D space is crucial for detecting 3D objects from multiple viewpoints. Current methods primarily focus on the design of view transformation, either by lifting perspective view features into 3D space based on estimated depth or by constructing bird's eye view features through 3D projection. However, the selection of which features to transform is also important but has received little attention. For example, the pixels representing a moving car contain more valuable information than those representing the sky. To make full use of the information in images, the view transformation should be able to adapt to different regions based on their contents. In this paper, we introduce a new framework called FrustumFormer, which prioritizes features in instance regions through adaptive instance-aware resampling. Our model identifies instance frustums in the bird's eye view using object proposals from the image view. It then learns an adaptive occupancy mask within the instance frustum to refine the location of the instance. Additionally, the intersection of temporal frustums further reduces the uncertainty in object localization. Extensive experiments on the nuScenes dataset demonstrate the effectiveness of FrustumFormer, achieving state-of-the-art performance on the benchmark. The code and models can be accessed at https://github.com/Robertwyq/Frustum.