Creating large datasets is essential for training deep models. However, the process of annotating the data often leads to the introduction of noisy labels, which presents challenges for deep learning algorithms. Previous attempts to address this issue have focused on identifying and removing noisy samples or correcting their labels based on statistical properties within the training set. In this study, we approach the problem from a different angle by investigating the deep feature maps. Through empirical analysis, we discover that models trained with both clean and mislabeled samples exhibit distinct activation feature distributions. Building on this observation, we propose a new robust training approach called adversarial noisy masking. This method involves regularizing deep features using a masking scheme guided by label quality. By adaptively modulating the input data and label simultaneously, the model is prevented from overfitting noisy samples. Additionally, we design an auxiliary task that reconstructs the input data, providing self-supervised signals that are free from noise and reinforcing the generalization ability of the models. Our proposed method is straightforward yet highly effective. We evaluate its performance on both synthetic and real-world noisy datasets, and significant improvements are achieved compared to previous approaches. The code for our method is publicly available at https://github.com/yuanpengtu/SANM.