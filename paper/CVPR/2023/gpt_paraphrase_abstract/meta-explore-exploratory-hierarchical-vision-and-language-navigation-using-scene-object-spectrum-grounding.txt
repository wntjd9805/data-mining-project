In the field of vision-and-language navigation (VLN), the primary challenge is how to interpret natural-language instructions in an unfamiliar environment. Conventional VLN algorithms have a major drawback: if the agent makes a mistake in its actions, it fails to follow the instructions or explores unnecessary areas, resulting in an irreversible path. To address this problem, we propose a hierarchical navigation method called Meta-Explore, which employs an exploitation policy to correct misguided recent actions. Our research demonstrates that an exploitation policy, which guides the agent towards a well-selected local goal among unexplored but observable states, outperforms a method that directs the agent to a previously visited state. We also emphasize the need for imagining regretful explorations with semantically meaningful clues. The key to our approach lies in understanding the arrangement of objects around the agent in the spectral-domain. We introduce a novel visual representation called scene object spectrum (SOS), which performs a category-wise 2D Fourier transform of detected objects. By combining the exploitation policy with SOS features, the agent can rectify its path by selecting a promising local goal. Our method is evaluated on three VLN benchmarks: R2R, SOON, and REVERIE. Meta-Explore surpasses other baseline approaches and exhibits significant generalization performance. Furthermore, the utilization of spectral-domain SOS features for local goal search leads to a notable improvement in success rate (17.1%) and SPL (20.6%) compared to the state-of-the-art method in the SOON benchmark. For more information, please visit our project page: https://rllab-snu.github.io/projects/Meta-Explore/doc.html.