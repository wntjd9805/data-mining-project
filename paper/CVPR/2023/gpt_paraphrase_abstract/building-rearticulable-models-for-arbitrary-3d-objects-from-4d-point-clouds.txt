We have developed a method to create flexible models of everyday man-made objects that consist of multiple parts connected through 1 degree-of-freedom joints. Using point cloud videos of these objects, our approach can identify the individual parts, determine how they are connected to each other, and analyze the properties of the joints between each pair of parts. This is achieved through a novel energy minimization framework that simultaneously optimizes part segmentation, transformation, and kinematics. The resulting animatable models can be easily adapted to different poses using sparse point correspondences. We evaluated our method on a dataset of articulating robots and the Sapiens dataset of common objects, showing superior performance compared to two previous approaches across various metrics.