Self-supervised learning models have demonstrated the ability to learn complex visual representations without the need for human annotations. However, in many real-life situations, only partial labels are available. This has led to the development of semi-supervised methods that incorporate self-supervised principles. In this study, we propose a straightforward yet effective approach to transform clustering-based self-supervised methods, such as SwAV or DINO, into semi-supervised learners. Our approach involves a multi-task framework that combines a supervised objective using ground-truth labels and a self-supervised objective based on clustering assignments, using a single cross-entropy loss. Essentially, this framework ensures that cluster centroids serve as class prototypes. Despite its simplicity, our approach has been empirically proven to be highly effective, achieving state-of-the-art performance on CI-FAR100 and ImageNet datasets.