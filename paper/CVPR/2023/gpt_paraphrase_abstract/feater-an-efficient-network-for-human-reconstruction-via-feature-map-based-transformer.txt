Vision transformers have been successful in human reconstruction tasks like 2D/3D human pose estimation (HPE) and human mesh reconstruction (HMR). These tasks typically involve extracting feature maps from images using a CNN and then using a transformer to predict heatmaps for HPE or HMR. However, existing transformer architectures cannot process these feature map inputs directly, resulting in the loss of important location-sensitive structural information. Additionally, recent HPE and HMR methods have become computationally expensive and memory-intensive. To address these issues, we propose FeatER, a novel transformer design that preserves the structure of feature map representations while reducing memory and computational costs. We utilize FeatER to build an efficient network for various human reconstruction tasks, including 2D HPE, 3D HPE, and HMR. We also incorporate a feature map reconstruction module to enhance the performance of estimated human pose and mesh. Extensive experiments demonstrate the effectiveness of FeatER on different human pose and mesh datasets. For example, FeatER outperforms the state-of-the-art method Mesh-Graphormer with significantly fewer parameters and computational requirements on Human3.6M and 3DPW datasets. More information can be found on the project webpage: https://zczcwh.github.io/feater_page/.