This paper presents a novel method called TeSLA (Test-time Self-Learning with automatic Adversarial augmentation) for adapting a pre-trained source model to unlabeled streaming test data. Unlike existing methods, TeSLA addresses the limitations of focusing only on classification tasks, using specialized network architectures, destroying model calibration, or relying on lightweight information from the source domain. TeSLA introduces a new test-time loss function that is connected to mutual information and online knowledge distillation, departing from conventional self-learning methods based on cross-entropy. Additionally, the paper proposes a learnable efficient adversarial augmentation module that enhances online knowledge distillation by generating high entropy augmented images. Experimental results demonstrate that TeSLA achieves state-of-the-art performance in classification and segmentation tasks across various benchmarks and types of domain shifts, particularly in challenging measurement shifts of medical images. Furthermore, TeSLA exhibits desirable properties such as calibration, uncertainty metrics, insensitivity to model architectures, and source training strategies, as supported by extensive ablations.The code and models for TeSLA are publicly available at https://github.com/devavratTomar/TeSLA.