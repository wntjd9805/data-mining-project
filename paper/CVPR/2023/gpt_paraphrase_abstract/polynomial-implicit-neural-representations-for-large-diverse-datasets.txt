Implicit neural representations (INR) are widely used for signal and image representation in various tasks. Most INR architectures rely on sinusoidal positional encoding, but this limits their representational power due to the finite encoding size. To overcome this limitation, we propose representing images with polynomial functions, eliminating the need for positional encodings. We achieve a higher degree of polynomial representation by performing element-wise multiplications between features and affine-transformed coordinate locations after each ReLU layer. We evaluate our method on large datasets like ImageNet and find that our Poly-INR model performs comparably to state-of-the-art generative models, even without convolution, normalization, or self-attention layers. Moreover, our approach requires fewer trainable parameters, making it more suitable for generative modeling tasks in complex domains. The code for our method is available at the given GitHub link.