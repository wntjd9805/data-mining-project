We introduce ObjectMatch1, a camera pose estimator designed specifically for RGB-D SLAM pipelines that focuses on semantic objects. Traditional camera pose estimators rely on direct correspondences between frames, which limits their ability to align frames with little or no overlap. To address this limitation, we propose leveraging indirect correspondences obtained through semantic object identification. By identifying objects seen from different perspectives in different frames, we can establish additional pose constraints through canonical object correspondences. We develop a neural network that predicts these correspondences on a per-pixel level, which we then incorporate into our energy formulation along with state-of-the-art keypoint matching solved using joint Gauss-Newton optimization. In pairwise comparisons, our method significantly improves the registration recall of feature matching techniques, increasing it from 24% to 45% in pairs with 10% or less inter-frame overlap. When registering RGB-D sequences, our method surpasses cutting-edge SLAM baselines in challenging scenarios with low frame rates, achieving a trajectory error reduction of over 35% in multiple scenes.