Current methods for generating 3D-aware images rely heavily on pre-estimated 3D pose distributions from the training set. However, inaccurate estimations can lead to the model learning incorrect geometry. This study introduces PoF3D, a method that eliminates the need for 3D pose priors in generative radiance fields. The proposed approach involves equipping the generator with a pose learner that can infer poses from latent codes to approximate the true pose distribution. The discriminator is then trained to learn the pose distribution under the guidance of the generator, distinguishing between real and synthesized images using the predicted pose as a condition. The pose-free generator and pose-aware discriminator are jointly trained adversarially. Extensive experiments on multiple datasets demonstrate that our approach achieves high-quality 3D-aware image synthesis in terms of both image and geometry quality. Notably, PoF3D is the first method to achieve this without relying on 3D pose priors. The project page can be accessed for more information.