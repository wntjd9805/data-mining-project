Few-shot object detection, which involves detecting new object categories with limited training data, is a growing area of interest in few-shot learning and object detection. Currently, there are two main categories of techniques: fine-tuning based approaches and meta-learning based approaches. Meta-learning approaches aim to develop specific meta-models that can map samples to models of novel classes, while fine-tuning approaches simplify the few-shot detection process by adjusting the detection model to novel classes through gradient-based optimization. Despite their simplicity, fine-tuning approaches often achieve competitive detection results. Building on this observation, our focus is on the role of loss functions and augmentations in driving the fine-tuning process. We propose a training scheme that uses meta-learning principles to tune the dynamics of these components. This approach enables the learning of inductive biases that enhance few-shot detection while retaining the advantages of fine-tuning approaches. Furthermore, our proposed approach results in interpretable loss functions, unlike the highly complex and parametric few-shot meta-models. Experimental results demonstrate the effectiveness of our scheme, showing significant improvements over strong fine-tuning based few-shot detection baselines on benchmark datasets such as Pascal VOC and MS-COCO. These improvements are observed in both standard and generalized few-shot performance metrics.