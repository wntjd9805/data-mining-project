Neural networks have been successful in representing detailed geometry using neural signed distance functions (SDFs). However, inferring SDFs from point clouds or multi-view images without signed distance supervision remains challenging. This paper argues that the parallelism of level sets, which indicates gradient consistency in the field, is crucial for accurate inference. To address this, the authors propose a level set alignment loss that evaluates the parallelism of level sets and can be minimized to achieve better gradient consistency. The novelty of their approach lies in aligning all level sets to the zero level set by constraining gradients at queries and their projections on the zero level set in an adaptive manner. By propagating the zero level set throughout the field through consistent gradients, they aim to eliminate uncertainty caused by the discreteness of 3D point clouds or the lack of observations from multi-view images. The proposed loss is a general term applicable to different methods for inferring SDFs from 3D point clouds and multi-view images. Numerical and visual comparisons demonstrate that this loss significantly improves the accuracy of SDFs inferred from point clouds or multi-view images across various benchmarks. The code and data for this research are available at https://github.com/mabaorui/TowardsBetterGradient.