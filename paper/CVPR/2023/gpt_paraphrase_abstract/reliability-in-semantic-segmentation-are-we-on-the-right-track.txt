Driven by the growing popularity of transformers in computer vision, there has been a rapid emergence of new architectures. While these models consistently improve in their performance within specific domains, the exploration of their robustness and uncertainty estimation remains limited, raising concerns about the reliability of these advancements. Although some studies have examined these aspects, they have mostly focused on classification models. In contrast, our study focuses on semantic segmentation, a crucial task in various real-world applications where model reliability is of utmost importance. We conduct a comprehensive analysis of a wide range of models, including both older ResNet-based architectures and newer transformers, evaluating their reliability based on four metrics: robustness, calibration, misclassification detection, and out-of-distribution (OOD) detection. Our findings indicate that while recent models exhibit greater robustness, they do not necessarily demonstrate overall improved reliability in terms of uncertainty estimation. To address this, we explore potential solutions and demonstrate that enhancing calibration can also enhance other uncertainty metrics such as misclassification and OOD detection. This study is the first of its kind to focus on modern segmentation models, examining both robustness and uncertainty estimation, and we anticipate that it will provide valuable insights for practitioners and researchers involved in this fundamental vision task.