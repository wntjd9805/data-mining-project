We tackle the challenging task of inferring the 3D shape and pose of dogs from images. Unlike humans, there is a lack of 3D training data for dogs, which makes this problem difficult. To overcome this, we approach the problem from multiple angles. First, we develop a dog-specific 3D parametric model called D-SMAL to establish a good 3D shape prior. This model helps us estimate the shape and pose accurately. Second, existing methods primarily focus on dogs in standing poses because sitting or lying down dogs have occluded legs and deformed bodies. However, without access to a good pose prior or 3D data, we adopt a different approach. We leverage the contact between the dog and the ground as a form of side information. We utilize a large dataset of dog images and label any 3D contact points with the ground. Exploiting this body-ground contact significantly improves our ability to estimate the dog's pose accurately. Third, we develop a novel neural network architecture that is designed to infer and exploit this contact information effectively. This architecture enhances the accuracy of our pose estimation. Fourth, in order to measure our progress, we need appropriate evaluation metrics. Current metrics rely on 2D features such as keypoints and silhouettes, which do not directly relate to 3D errors. To address this, we create a synthetic dataset containing rendered images of scanned 3D dogs. This allows us to evaluate our method in 3D and accurately assess the improvements. With these advancements, our method significantly outperforms the state-of-the-art techniques in terms of dog shape and pose estimation. We provide our code, model, and test dataset for research purposes. They are publicly available at https://bite.is.tue.mpg.de/.