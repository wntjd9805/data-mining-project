The neural radiance field (NRF) has greatly advanced the generation of new views from multi-view images. This paper introduces a new approach called the neural radiance feature field (NRFF) to further enhance the quality of view synthesis. The NRFF utilizes a multiscale tensor decomposition scheme to organize learnable features, resulting in improved scene shape and appearance reconstruction as well as faster convergence. Rather than encoding view directions, the rendering equation is encoded in the feature space using an anisotropic spherical Gaussian mixture obtained from the multiscale representation. The NRFF outperforms existing methods in terms of rendering quality, with an improvement of over 1 dB in PSNR on synthetic datasets and significant improvements on real-world datasets. The code for NRFF can be accessed at https://github.com/imkanghan/nrff.