The field of machine learning has seen the development of many algorithms that address the difference between the training and testing distributions. These algorithms aim to find a unified predictor or invariant feature representation. However, there has been limited investigation into directly mitigating the distribution shift in unseen testing sets due to the lack of availability of the testing distribution during training. This makes it impossible to train a distribution translator that maps between the training and testing distributions. In this paper, we propose a portable algorithm called Distribution Shift Inversion (DSI) that overcomes the need for the testing distribution in training a distribution translator. Our method involves combining the OoD testing samples with Gaussian noise and then transferring them back towards the training distribution using a diffusion model trained only on the source distribution. Theoretical analysis confirms the feasibility of our approach. Experimental results on multiple-domain and single-domain generalization datasets demonstrate that our method improves the performance of commonly used OoD algorithms. Our code is available at https://github.com/yu-rp/Distribution-Shift-Iverson.