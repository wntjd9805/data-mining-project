This paper introduces YOSO, a real-time panoptic segmentation framework. YOSO utilizes dynamic convolutions to predict masks by combining panoptic kernels and image feature maps, allowing for simultaneous instance and semantic segmentation. To minimize computational overhead, the framework includes a feature pyramid aggregator for feature map extraction and a separable dynamic decoder for panoptic kernel generation. The aggregator reparameterizes interpolation-first modules in a convolution-first manner, enhancing pipeline speed without additional costs. The decoder employs multi-head cross-attention through separable dynamic convolution to improve efficiency and accuracy. YOSO is the first real-time panoptic segmentation framework to achieve competitive performance compared to state-of-the-art models. Notably, YOSO achieves PQ scores of 46.4, 52.5, 38.0, and 34.1 on COCO, Cityscapes, ADE20K, and Mapillary Vistas datasets, respectively, with corresponding FPS rates of 45.6, 22.6, 35.4, and 7.1. The code for YOSO is available at https://github.com/hujiecpp/YOSO.