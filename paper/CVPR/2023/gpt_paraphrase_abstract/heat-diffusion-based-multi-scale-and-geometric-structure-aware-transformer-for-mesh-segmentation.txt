Triangle mesh segmentation is a crucial task in analyzing 3D shapes, particularly in digital humans and AR/VR applications. The Transformer model, known for its permutation invariance, is a suitable candidate for processing 3D meshes. However, there are two main challenges in adapting the Transformer to 3D meshes: extracting multi-scale information in an adaptive manner and capturing the geometric structures as discriminative characteristics. Existing point-based Transformer models are not able to address these challenges effectively, resulting in subpar performance for surface segmentation. To overcome these issues, this study proposes a novel Transformer model called MeshFormer. It incorporates a heat diffusion-based method to handle these challenges. MeshFormer integrates the Heat Diffusion method into the Multi-head Self-Attention operation (HDMSA) to capture features from local neighborhoods to global contexts adaptively. Additionally, it applies a novel Heat Kernel Signature based Structure Encoding (HKSSE) to embed the intrinsic geometric structures of mesh instances into the Transformer for structure-aware processing. Extensive experiments on triangle mesh segmentation demonstrate the effectiveness of the proposed MeshFormer model, showcasing significant improvements compared to current state-of-the-art methods.