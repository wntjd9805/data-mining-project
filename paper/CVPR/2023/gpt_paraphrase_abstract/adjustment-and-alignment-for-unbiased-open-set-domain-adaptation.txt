Open Set Domain Adaptation (OSDA) aims to transfer a model trained on a domain with labeled data to a new domain without labels, which contains samples from novel classes. However, existing OSDA methods overlook the abundant novel-class semantics present in the source domain, resulting in biased model learning and transfer. Although some studies have investigated causality to address this semantic-level bias, these approaches fail when novel-class samples are not available. To overcome this limitation, we propose a novel causality-driven solution based on the unexplored front-door adjustment theory. We implement this solution using a theoretically grounded framework called Adjustment and Alignment (ANNA), which enables unbiased OSDA. ANNA consists of two components: Front-Door Adjustment (FDA) and Decoupled Causal Alignment (DCA). FDA involves analyzing fine-grained visual blocks to identify novel-class regions hidden within the base-class image. It then corrects the biased model optimization through causal debiasing. On the other hand, DCA separates the base-class and novel-class regions using orthogonal masks and adapts the decoupled distribution to achieve an unbiased model transfer. Extensive experiments demonstrate that ANNA outperforms existing methods and achieves state-of-the-art results in OSDA. The code for ANNA is available at https://github.com/CityU-AIM-Group/Anna.