This paper introduces a novel approach called Local Implicit Transformer (LIT) for representing images with arbitrary resolutions. LIT combines the attention mechanism and frequency encoding technique to create a local implicit image function. The model includes a cross-scale local attention block that effectively aggregates local features and a local frequency encoding block that combines positional encoding with Fourier domain information to generate high-resolution images.To enhance the representation power, the paper proposes a Cascaded LIT (CLIT) that utilizes multi-scale features. Additionally, a cumulative training strategy is introduced, gradually increasing the upsampling scales during training. Extensive experiments are conducted to validate the effectiveness of these components and analyze various training strategies.Both qualitative and quantitative results demonstrate the superiority of LIT and CLIT over prior works in arbitrary super-resolution tasks. The proposed models achieve favorable results and outperform existing methods.