Ensuring reliable confidence estimation in deep neural classifiers is essential for high-stakes applications. However, contemporary deep neural networks often exhibit excessive confidence in erroneous predictions. This study aims to address this issue by utilizing outlier samples, specifically unlabeled samples from non-target classes, to detect misclassification errors. The commonly used Outlier Exposure technique, known for its effectiveness in identifying out-of-distribution (OOD) samples from unknown classes, does not contribute to the identification of misclassification errors. Building on this observation, a novel approach called OpenMix is proposed, which incorporates open-world knowledge by learning to reject uncertain pseudo-samples generated through outlier transformation. OpenMix significantly enhances confidence reliability in various scenarios, providing a comprehensive framework for detecting misclassified samples from known classes as well as OOD samples from unknown classes. The code for implementing OpenMix is publicly available at https://github.com/Impression2805/OpenMix.