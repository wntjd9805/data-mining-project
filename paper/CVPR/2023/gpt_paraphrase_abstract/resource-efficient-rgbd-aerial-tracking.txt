Aerial robots are now capable of flying in complex environments, and the use of drones to capture data for object tracking has gained significant attention. However, current research in aerial perception has primarily focused on limited categories such as pedestrians or vehicles, and most scenes are captured from a birds-eye view in urban environments. Recently, unmanned aerial vehicles (UAVs) equipped with depth cameras have been deployed for more complex applications, but the exploration of RGBD aerial tracking is still lacking. Incorporating depth information in addition to traditional RGB object tracking can effectively handle more challenging scenes with target and background interference. This paper aims to address this gap by exploring RGBD aerial tracking in an overhead space, which has the potential to significantly enhance drone-based visual perception. To facilitate further research in this field, a large-scale benchmark for RGBD aerial tracking is proposed, consisting of 1,000 drone-captured RGBD videos with dense annotations. Additionally, to meet the real-time processing requirements of drone-based applications with limited computational resources, an efficient RGBD tracker called EMT is introduced. The EMT tracker achieves impressive performance, running at over 100 fps on a GPU and 25 fps on the NVidia Jetson NX Xavier edge platform, thanks to its efficient multimodal fusion and feature matching techniques. Extensive experiments demonstrate the promising tracking capabilities of the EMT tracker. All the necessary resources for this research are available at the provided link: https://github.com/yjybuaa/RGBDAerialTracking.