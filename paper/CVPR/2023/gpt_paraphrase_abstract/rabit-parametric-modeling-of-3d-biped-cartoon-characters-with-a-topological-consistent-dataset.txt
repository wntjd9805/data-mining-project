Efficiently creating visually plausible 3D characters has long been a key focus in computer vision and computer graphics research. While recent learning-based approaches have made significant advancements in digitizing real human characters, there has been little attention given to modeling 3D biped cartoon characters, which are highly sought after in gaming and filming industries. This paper introduces 3DBiCar, the first large-scale dataset of 3D biped cartoon characters, along with RaBit, a corresponding parametric model. The dataset consists of 1,500 high-quality 3D textured models that have been manually crafted by professional artists. RaBit utilizes a SMPL-like linear blend shape model and a StyleGAN-based neural UV-texture generator to simultaneously represent the shape, pose, and texture of the characters. To showcase the practicality of 3DBiCar and RaBit, various applications including single-view reconstruction, sketch-based modeling, and 3D cartoon animation are explored. In the context of single-view reconstruction, it is observed that a direct mapping from input images to UV-based texture maps can result in loss of detail in local areas such as the nose and ears. To address this, a part-sensitive texture reasoner is employed to ensure accurate representation of all important local areas. Experimental results demonstrate the effectiveness of the proposed method both qualitatively and quantitatively. The 3DBiCar dataset and RaBit model are publicly available at gaplab.cuhk.edu.cn/projects/RaBit.