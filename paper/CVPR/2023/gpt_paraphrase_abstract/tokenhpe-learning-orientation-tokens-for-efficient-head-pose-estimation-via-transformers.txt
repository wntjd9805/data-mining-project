Current methods for head pose estimation (HPE) struggle with extreme head poses and occlusions. To address these challenges, we propose a novel method that leverages three cues from head images: neighborhood similarities, significant facial changes, and critical minority relationships. Our approach is based on the Transformer architecture, allowing us to learn facial part relationships. We introduce orientation tokens to encode basic orientation regions and a token guide multi-loss function to guide their learning process. We evaluate our method on three benchmark HPE datasets and demonstrate its superior performance compared to state-of-the-art methods. The code for our approach is publicly available at https://github.com/zc2023/TokenHPE.