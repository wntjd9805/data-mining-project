Existing NeRF-based approaches face challenges in recovering high-quality details from real-world scenes due to imperfect calibration information and scene representation inaccuracy. Even with high-quality training frames, synthetic novel views generated by NeRF models still exhibit rendering artifacts. To address this, we introduce NeRFLiX, a general NeRF-agnostic restorer paradigm that leverages a degradation-driven inter-viewpoint mixer. We propose a NeRF-style degradation modeling approach and create a large-scale training dataset to effectively remove NeRF-native rendering artifacts using deep neural networks. Additionally, we present an inter-viewpoint aggregation framework that combines highly related high-quality training images, enhancing the performance of cutting-edge NeRF models and producing highly realistic synthetic views.