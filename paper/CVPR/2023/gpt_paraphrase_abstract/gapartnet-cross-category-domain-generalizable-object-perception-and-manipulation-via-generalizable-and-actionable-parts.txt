Researchers have long been focused on developing object perception and manipulation skills that can be applied across different categories, but this area of study has not been thoroughly explored. In this study, we propose a method called Generalizable and Actionable Parts (GAParts) to learn these cross-category skills. We identify and define nine GAPart classes, such as lids and handles, within 27 object categories. To support our research, we create a large dataset called GAPartNet, which contains detailed annotations for 8,489 part instances on 1,166 objects. This dataset includes information on part semantics and poses.Using GAPartNet, we investigate three tasks related to cross-category skills: part segmentation, part pose estimation, and part-based object manipulation. Since there are significant differences between the object categories that are seen during training and those that are unseen during testing, we propose a robust 3D segmentation method that takes domain generalization into account. Our approach incorporates adversarial learning techniques and outperforms all existing methods, regardless of whether the object categories are seen or unseen.Furthermore, with the results of part segmentation and pose estimation, we utilize the GAPart pose definition to design heuristics for part-based manipulation. These heuristics are capable of generalizing well to unseen object categories in both simulated and real-world environments.