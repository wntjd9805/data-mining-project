This study addresses the difficulty of estimating depth from indoor panoramas, which is caused by the distortions inherent in equirectangular panoramas and inaccurate matching. To overcome these challenges, the authors propose a practical framework that utilizes Neural Radiance Field technology to enhance the accuracy and efficiency of depth estimation from multi-view indoor panoramic images. They develop two networks that learn the Signed Distance Function for depth measurements and the radiance field from panoramas. Additionally, a novel spherical position embedding scheme is introduced to achieve high accuracy. To improve convergence, an initialization method based on the Manhattan World Assumption is proposed for network weights. Moreover, a geometric consistency loss is devised, utilizing the surface normal, to further refine the depth estimation. Experimental results demonstrate that their method surpasses existing approaches significantly in both quantitative and qualitative evaluations. The source code for their method is available at https://github.com/WJ-Chang-42/IndoorPanoDepth.