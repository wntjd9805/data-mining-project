We propose a new approach called AdvFace for protecting the privacy of facial features in face recognition systems. Existing methods sacrifice accuracy for privacy, but AdvFace generates privacy-preserving adversarial features that disrupt the mapping from features to facial images, making it difficult to reconstruct the original face. We use a shadow model to simulate attackers and generate adversarial latent noise to disrupt the mapping. The server's database stores only the adversarial features, preventing leaked features from revealing facial information. AdvFace can be easily implemented as a plugin in existing face recognition systems without modifying the network. Our extensive experiments show that AdvFace outperforms other privacy-preserving methods in defending against reconstruction attacks while maintaining high face recognition accuracy.