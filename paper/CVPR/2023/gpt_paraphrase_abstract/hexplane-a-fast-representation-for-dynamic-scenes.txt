Modeling and re-rendering dynamic 3D scenes is a challenging task in the field of 3D vision. Previous approaches have relied on implicit representations, specifically NeRF, which involves multiple evaluations of multilayer perceptrons (MLPs), making it slow and impractical for real-world applications. In this study, we propose a novel solution called HexPlane, which represents dynamic 3D scenes explicitly using six planes of learned features. HexPlane efficiently computes features for points in spacetime by combining vectors extracted from each plane. By pairing HexPlane with a small MLP to predict output colors and training it through volume rendering, we achieve impressive results in synthesizing novel views of dynamic scenes. Our approach matches the image quality of previous methods while significantly reducing training time by over 100 times. Through extensive experimentation, we validate the effectiveness and robustness of HexPlane, demonstrating its adaptability to different feature fusion mechanisms, coordinate systems, and decoding mechanisms. We believe that HexPlane offers a simple yet powerful solution for representing 4D volumes and can greatly contribute to the modeling of spacetime in dynamic 3D scenes.