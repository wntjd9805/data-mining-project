We present MagicPony, a new method for predicting the 3D shape, articulation, viewpoint, texture, and lighting of an articulated animal like a horse using a single test image. Our approach learns this predictor from real-world single-view images of the object category, without relying heavily on assumptions about deformation topology. MagicPony combines neural fields and meshes to create an implicit-explicit representation of articulated shape and appearance, leveraging the strengths of both. To enhance the model's understanding of an object's shape and pose, we incorporate knowledge from a self-supervised vision transformer. We also introduce a novel viewpoint sampling scheme to overcome local optima in viewpoint estimation, without requiring additional training. MagicPony outperforms previous methods on this challenging task and shows excellent generalization in reconstructing art, despite being trained only on real images. The code for our method is available on our project page at https://3dmagicpony.github.io/.