This paper introduces NeRF-RPN, a groundbreaking object detection framework that operates directly on NeRF. NeRF-RPN aims to detect all object bounding boxes in a scene using a unique voxel representation that incorporates multi-scale 3D neural volumetric features. Unlike traditional methods, NeRF-RPN can regress the 3D bounding boxes of objects in NeRF without the need to render the NeRF from different viewpoints. Moreover, NeRF-RPN is a versatile framework that can be used to detect objects without class labels. The authors conducted experiments using various backbone architectures, RPN head designs, and loss functions, all of which can be trained end-to-end to achieve accurate 3D bounding box estimation. In order to support future research in object detection for NeRF, the authors created a benchmark dataset comprising synthetic and real-world data with meticulous labeling and cleaning. The code and dataset are publicly available at https://github.com/lyclyc52/NeRF_RPN.