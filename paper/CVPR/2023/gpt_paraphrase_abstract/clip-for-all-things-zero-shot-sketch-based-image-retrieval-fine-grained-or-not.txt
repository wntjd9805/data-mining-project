This paper explores the use of CLIP for zero-shot sketch-based image retrieval (ZS-SBIR). The authors are inspired by recent advancements in foundation models and their ability to generalize well, and they aim to apply this to the sketch community. They propose novel approaches for achieving this synergy in both the category and fine-grained settings. By incorporating sketch-specific prompts, they demonstrate a category-level ZS-SBIR system that outperforms previous methods by a significant margin (24.8%). However, addressing the fine-grained matching aspect requires additional strategies. They introduce an additional regularization loss to ensure consistent separation between sketches and photos across categories, and a patch shuffling technique to establish structural correspondences at the instance level. These designs result in a substantial performance improvement of 26.9% over the current state-of-the-art. The findings suggest that the combination of CLIP and prompt learning holds promise for addressing other sketch-related tasks with limited data availability.