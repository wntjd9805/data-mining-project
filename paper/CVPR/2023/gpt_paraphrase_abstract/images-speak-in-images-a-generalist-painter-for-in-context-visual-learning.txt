In the field of natural language processing (NLP), a new approach called in-context learning has emerged, allowing models to quickly adapt to different tasks with minimal prompts and examples. However, in the field of computer vision, in-context learning faces challenges due to the varying output representations of different tasks. This makes it difficult to define general-purpose task prompts that can be understood and transferred to out-of-domain tasks by vision models. To address these challenges, our work introduces a model called Painter, which takes an "image"-centric approach. We redefine the output of core vision tasks as images and specify task prompts as images as well. This simplifies the training process, as we can perform standard masked image modeling on pairs of input and output images. This allows the model to perform tasks based on visible image patches. During inference, we can use a pair of input and output images from the same task as the input condition to indicate which task the model should perform.Despite its simplicity, our generalist model, Painter, achieves competitive performance compared to task-specific models on seven representative vision tasks, ranging from high-level visual understanding to low-level image processing. Furthermore, Painter outperforms recent generalist models on challenging tasks. Overall, our approach of utilizing images as task prompts and redefining the output of core vision tasks as images enables the model to effectively adapt to various vision tasks and achieve impressive performance.