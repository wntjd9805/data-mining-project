StyleGANs are currently leading the way in the field of controllable image generation due to their ability to produce a latent space that allows for semantic disentanglement, making it suitable for image editing and manipulation. However, when trained using class-conditioning on large-scale long-tailed datasets, the performance of StyleGANs significantly decreases. We have identified that one of the reasons for this degradation is the collapse of latents for each class in the W latent space. To address this issue, we propose a solution called NoisyTwins. This approach involves introducing an effective and affordable augmentation strategy for class embeddings, which in turn decorrelates the latents based on self-supervision in the W space. By mitigating the collapse and ensuring intra-class diversity with class-consistency in image generation, our method demonstrates its effectiveness on real-world, large-scale, long-tailed datasets such as ImageNet-LT and iNaturalist 2019. In fact, our approach outperforms other methods by approximately 19% on FID, establishing a new state-of-the-art in this domain.