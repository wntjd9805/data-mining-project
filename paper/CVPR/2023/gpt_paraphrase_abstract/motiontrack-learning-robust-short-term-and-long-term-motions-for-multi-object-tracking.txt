This paper presents a new approach to Multi-Object Tracking (MOT) called MotionTrack. MOT is challenging due to dense crowds and occlusions, which can disrupt motion prediction and appearance recognition. MotionTrack addresses these issues by learning short-term and long-term motions in a unified framework. For dense crowds, an Interaction Module is designed to capture interaction-aware motions from short-term trajectories. This module estimates the complex movement of each target. For extreme occlusions, a Refind Module is built to learn reliable long-term motions from the target's history trajectory. This module links interrupted trajectories with their corresponding detections. Both the Interaction Module and Refind Module are integrated into the tracking-by-detection paradigm, resulting in superior performance. The effectiveness of MotionTrack is demonstrated through extensive experiments on MOT17 and MOT20 datasets, where it achieves state-of-the-art performances in challenging scenarios. The code for MotionTrack is available at https://github.com/qwomeng/MotionTrack.