Recent advancements in neural implicit functions have made significant progress in reconstructing high-quality 3D shapes from multiple images. However, these methods are currently limited to closed surfaces as they require the surface to be represented by a signed distance field. To address this limitation, we introduce NeAT, a novel neural rendering framework capable of learning implicit surfaces with arbitrary topologies from multi-view images. NeAT represents the 3D surface as a level set of a signed distance function (SDF) and includes a validity branch to estimate the probability of surface existence at query positions. Additionally, we propose a new neural volume rendering technique that utilizes the SDF and validity information to calculate volume opacity, ensuring that points with low validity are not rendered. NeAT also enables easy conversion from field to mesh using the renowned Marching Cubes algorithm. Through extensive experiments on various datasets, including DTU, MGN, and Deep Fashion 3D, our approach demonstrates faithful reconstruction of both watertight and non-watertight surfaces. Notably, NeAT surpasses state-of-the-art methods in the quantitative and qualitative evaluation of open surface reconstruction.