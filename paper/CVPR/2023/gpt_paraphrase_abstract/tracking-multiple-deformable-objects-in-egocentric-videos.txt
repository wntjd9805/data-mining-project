We introduce DogThruGlasses, a comprehensive dataset consisting of 150 videos and 73K annotated frames, specifically designed for tracking highly deformable objects using smart glasses. Existing multiple object tracking (MOT) methods relying solely on appearance features struggle in tracking such objects. Additionally, MOT methods utilizing motion clues face challenges when handling egocentric videos efficiently. To address these issues, we propose DETracker, a novel MOT approach that combines detection and tracking of deformable objects in egocentric videos. DETracker incorporates three innovative modules: the motion disentanglement network (MDN), the patch association network (PAN), and the patch memory network (PMN). These modules effectively handle severe ego motion and track fast morphing target objects. Furthermore, DETracker is end-to-end trainable and achieves near real-time speed. It outperforms existing state-of-the-art methods on both DogThruGlasses and YouTube-Hand datasets.