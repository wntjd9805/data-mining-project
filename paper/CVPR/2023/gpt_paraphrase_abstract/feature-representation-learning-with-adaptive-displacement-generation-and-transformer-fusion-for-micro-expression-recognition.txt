Micro-expressions are facial movements that cannot be faked or controlled, serving as important nonverbal communication cues. However, due to their fleeting nature and low intensity, recognizing micro-expressions is challenging. Previous deep learning methods for micro-expression recognition have focused on feature extraction and fusion, but there is still a need to study targeted feature learning and efficient fusion techniques that align with the characteristics of micro-expressions. To address these issues, we propose a new framework called Feature Representation Learning with adaptive Displacement Generation and Transformer fusion (FRL-DGT). This framework utilizes a self-supervised convolu-tional Displacement Generation Module (DGM) to extract dynamic features from onset/apex frames specifically for micro-expression recognition. Additionally, a well-designed Transformer Fusion mechanism, consisting of three Transformer-based fusion modules (local, global, and full-face fusion), is employed to extract informative multi-level features for the final prediction of micro-expressions. Extensive experiments, including solid leave-one-subject-out (LOSO) evaluation, have been conducted, demonstrating the superiority of our proposed FRL-DGT framework over existing methods.