This paper examines the problem of procedure planning in instructional videos, which involves creating goal-directed plans based on visual observations in real-life videos. Previous approaches have approached this as a sequence planning problem, relying on either detailed visual observations or natural language instructions for guidance. However, these methods are complex and require expensive annotation. In contrast, we propose treating this problem as a distribution fitting problem. We use a diffusion model (PDPP) to model the distribution of intermediate action sequences, transforming the planning problem into a sampling process from this distribution. We also simplify the supervision by using task labels from instructional videos instead of intermediate supervision. Our model is a U-Net based diffusion model that directly samples action sequences from the learned distribution using start and end observations. Additionally, we utilize an efficient projection method to provide accurate conditional guides during the learning and sampling process. Experimental results on three datasets demonstrate that our PDPP model achieves state-of-the-art performance on multiple metrics, even without task supervision. The code and trained models are available at https://github.com/MCG-NJU/PDPP.