We present a method for creating realistic pedestrian trajectories and full-body animations that can be controlled to meet specific user goals. By using guided diffusion modeling, we are able to achieve real-time control over trajectories, which is typically only possible with rule-based systems. Our model allows users to constrain trajectories by specifying target waypoints, speed, and social groups, while also considering the surrounding environment. We integrate this trajectory diffusion model with a new physics-based humanoid controller to create a complete pedestrian animation system that can simulate large crowds in various terrains. Additionally, we propose using the learned value function from reinforcement learning training of the animation controller to guide diffusion and generate trajectories suitable for specific scenarios such as avoiding collisions and navigating uneven terrain. You can find video results on our project page.