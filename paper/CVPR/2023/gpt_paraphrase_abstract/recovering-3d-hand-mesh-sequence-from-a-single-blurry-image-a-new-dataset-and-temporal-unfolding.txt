Previous methods for recovering 3D hand meshes have focused on sharp hand images and have not taken into account the blur caused by hand movements. This is due to the lack of datasets containing blurry hand images. In this study, we introduce the BlurHand dataset, which consists of blurry hand images with 3D groundtruths. We synthesized motion blur in the images to create a realistic representation of hand movements. Additionally, we propose a baseline network called BlurHandNet, which accurately recovers 3D hand meshes from blurry hand images. Unlike previous methods that generate a static single hand mesh, BlurHandNet utilizes temporal information in the blurry input image to create a sequence of 3D hand meshes. Our experiments demonstrate the effectiveness of BlurHand in recovering 3D hand meshes from blurry images. BlurHandNet produces more robust results on blurry images and performs well on real-world images. The training codes and BlurHand dataset are available at the following link: https://github.com/JaehaKim97/BlurHand_RELEASE.