Generative deep neural networks (DNNs) are effective in generating images, but their computational load is a limitation. Additionally, the quality of the generated images varies depending on the characteristics of the input. To address these challenges, we propose a method to reduce computations by incorporating early exit branches into the original DNN architecture. This allows for dynamic switching of the computational path based on the difficulty of rendering the output. We apply this method to two state-of-the-art models that perform generative tasks: generating images from a semantic map and cross-re-enactment of face expressions. Our method successfully generates images with custom lower-quality thresholds, reducing computations by up to 50% for a threshold of LPIPS â‰¤ 0.1. This is particularly advantageous for real-time applications like face synthesis, where quality loss must be minimized and most inputs require fewer computations than complex instances.