Image denoising is a crucial task in capturing and storing images, as devices inevitably introduce noise. Deep learning has become the dominant approach for image denoising, particularly with the emergence of Transformer-based models that have achieved impressive state-of-the-art results in various image tasks. However, deep learning methods often struggle with generalization, as models trained on Gaussian noise may perform poorly when confronted with other noise distributions. To tackle this problem, we propose a new technique called masked training to enhance the generalization performance of denoising networks. Our method involves randomly masking pixels in the input image and reconstructing the missing information during training. We also mask out features in the self-attention layers to mitigate the impact of training-testing inconsistencies. Our approach demonstrates superior generalization ability compared to other deep learning models and is directly applicable to real-world scenarios. Furthermore, our interpretability analysis confirms the effectiveness of our method.