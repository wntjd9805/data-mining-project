We propose Neural Vector Fields (NVF), a novel 3D representation method that combines explicit learning processes and the powerful representation ability of implicit functions. NVF manipulates meshes directly using explicit learning, while also leveraging the representation of unsigned distance functions (UDFs) to overcome resolution and topology limitations. Our method predicts displacements towards the surface and models shapes as Vector Fields, encoding both distance and direction fields to mitigate ambiguity at "ridge" points. Unlike existing UDF-based methods, our vector fields are differentiation-free, simplifying the calculation of direction fields. This allows us to learn a shape codebook via Vector Quantization, which encodes cross-object priors, accelerates training, and improves model generalization for cross-category reconstruction. Extensive experiments on surface reconstruction benchmarks demonstrate that our method outperforms state-of-the-art approaches in various evaluation scenarios, including watertight vs non-watertight shapes, category-specific vs category-agnostic reconstruction, category-unseen reconstruction, and cross-domain reconstruction. Our code is available at https://github.com/Wi-sc/NVF.