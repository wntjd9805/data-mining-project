Diffusion models have become the leading generative models for producing high-quality samples and have shown promising characteristics such as mode coverage and flexibility. These models have also demonstrated their effectiveness in solving inverse problems by acting as priors, while utilizing information from the forward model during the sampling stage. However, due to the high memory and computational requirements of working in high-dimensional spaces, these models have not been extended to 3D inverse problems.To address this limitation, our paper proposes a novel approach that combines conventional model-based iterative reconstruction with modern diffusion models. Specifically, we introduce pre-trained 2D diffusion models to enhance the diffusion prior with a model-based prior in the remaining direction during test time. This integration enables us to achieve coherent reconstructions across all dimensions in 3D medical image reconstruction tasks, such as sparse-view tomography, limited angle tomography, and compressed sensing MRI.Our method is highly efficient and can be executed on a single commodity GPU. It surpasses the current state-of-the-art and produces reconstructions of high fidelity and accuracy, even in challenging scenarios like 2-view 3D tomography. Surprisingly, our proposed method exhibits a remarkable generalization capacity and can reconstruct volumes that are entirely different from the training dataset.For further details and implementation, the code for our method is available at https://github.com/HJ-harry/DiffusionMBIR.