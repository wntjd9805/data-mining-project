Recent advancements in Neural Rendering Fields (NeRF) have demonstrated impressive outcomes in generating novel views by utilizing implicit neural representation for 3D scenes. However, the volumetric rendering process employed by NeRF leads to significantly slow inference speed, thus limiting its practicality on resource-constrained hardware like mobile devices. Various attempts have been made to reduce the latency of NeRF models, but most of them still rely on high-end GPUs or additional storage memory, which are not available on mobile devices. Another approach, known as neural light field (NeLF), has emerged as a means of accelerating NeRF by performing only one forward pass on a ray to predict pixel color. However, to achieve comparable rendering quality to NeRF, NeLF networks require intensive computation, making them unsuitable for mobile devices. In this study, we propose an efficient network architecture that can run in real-time on mobile devices for neural rendering. Our network is trained following the NeLF framework. Unlike existing methods, our novel network architecture is designed specifically for mobile devices, offering low latency and a compact size. It saves 15 times more storage compared to MobileNeRF. Our model can generate high-resolution images while maintaining real-time inference for both synthetic and real-world scenes on mobile devices, such as rendering a 1008x756 image of a real 3D scene in just 18.04ms (on iPhone 13). Additionally, our model achieves image quality similar to NeRF and superior to MobileNeRF, with a PSNR of 26.15 compared to 25.91 on a real-world forward-facing dataset.