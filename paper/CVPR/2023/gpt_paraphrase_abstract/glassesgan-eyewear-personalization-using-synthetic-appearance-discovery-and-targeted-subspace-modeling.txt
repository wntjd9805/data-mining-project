We introduce GlassesGAN, an innovative framework for editing images to design custom glasses. GlassesGAN sets a new benchmark in terms of image quality, realism in editing, and the ability to make continuous multi-style edits. To simplify the editing process, we propose Targeted Subspace Modelling (TSM), a procedure that constructs a glasses-specific latent subspace using a novel mechanism for discovering synthetic appearances in the latent space of a pre-trained GAN generator. We also introduce an appearance-constrained subspace initialization (SI) technique that improves the reliability of learned edits by centering the latent representation of the input image in a well-defined part of the constructed subspace. We evaluate GlassesGAN on two high-resolution datasets (CelebA-HQ and SiblingsDB-HQf) and compare it to three state-of-the-art baselines (InterfaceGAN, GANSpace, and MaskGAN). The results demonstrate that GlassesGAN outperforms all competing techniques and offers unique functionality, such as fine-grained multi-style editing. The source code for GlassesGAN is publicly available.