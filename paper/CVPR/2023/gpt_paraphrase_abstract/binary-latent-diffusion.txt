This paper demonstrates that a binary latent space can be used to create compact yet expressive image representations. The authors achieve this by training an auto-encoder with a Bernoulli encoding distribution to model the bi-directional mappings between images and their corresponding binary latent representations. The binary latent space offers a more efficient way to model the distribution of discrete image representations compared to pixel or continuous latent representations. Additionally, each image patch is represented as a binary vector instead of an index of a learned cookbook, resulting in binary latent representations that improve image quality and allow for high-resolution image representations without the need for a multi-stage hierarchy in the latent space. The authors develop a binary latent diffusion model specifically designed for generating images effectively in this binary latent space. They conduct experiments on multiple datasets to demonstrate both conditional and unconditional image generation and show that their proposed method performs comparably to state-of-the-art methods while significantly improving sampling efficiency, requiring as few as 16 steps without any test-time acceleration. The proposed framework can also be seamlessly scaled to generate 1024 high-resolution images without the need for latent hierarchy or multi-stage refinements.