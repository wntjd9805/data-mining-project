Image-to-image translation is a challenging problem in computer vision and image processing. Diffusion models have shown potential for high-quality image synthesis and have performed well in image-to-image translation. However, existing diffusion models often struggle with the gap between distinct domains. This paper presents a novel approach called the Brownian Bridge Diffusion Model (BBDM) for image-to-image translation. BBDM treats translation as a stochastic Brownian Bridge process and learns the translation between domains through a bidirectional diffusion process instead of conditional generation. This is the first work to propose the use of Brownian Bridge diffusion for image-to-image translation. Experimental results on various benchmarks show that BBDM achieves competitive performance in terms of both visual inspection and measurable metrics.