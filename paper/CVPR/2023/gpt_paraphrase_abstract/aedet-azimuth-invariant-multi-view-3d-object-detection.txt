The recent advancement in multi-view 3D object detection using the LSS technique has shown significant progress. However, the conventional convolutional detector used in this approach fails to consider the radial symmetry of the Brid-Eye-View (BEV) features, making the optimization of the detector more challenging. To address this issue and enhance optimization, we propose an azimuth-equivariant convolution (AeConv) and an azimuth-equivariant anchor. The AeConv ensures that the sampling grid is always in the radial direction, allowing it to learn BEV features that are invariant to azimuth. The proposed anchor enables the detection head to learn to predict targets that are irrelevant to azimuth. Additionally, we introduce a camera-decoupled virtual depth to unify depth prediction for images with different camera intrinsic parameters. Our resulting detector, called AeDet, achieves remarkable performance on nuScenes dataset, with an NDS score of 62.0%. AeDet outperforms recent multi-view 3D object detectors like PETRv2 and BEVDepth by a significant margin. For more information, please visit our project page: https://fcjian.github.io/aedet.