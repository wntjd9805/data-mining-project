The issue of misinformation is increasingly prevalent, with fake media being widespread on the internet. While methods for detecting deepfakes and fake news have been proposed, they are limited to single-modality forgery and do not analyze subtle forgery traces across different modalities. This paper introduces a new research problem called Detecting and Grounding Multi-Modal Media Manipulation (DGM4). DGM4 aims to detect the authenticity of multi-modal media and ground the manipulated content by analyzing image bounding boxes and text tokens. To facilitate this investigation, the first DGM4 dataset is constructed, containing manipulated image-text pairs with diverse annotations. Additionally, a novel model called Hierarchical Multi-modal Manipulation Reasoning Transformer (HAMMER) is proposed to capture the fine-grained interaction between modalities. HAMMER utilizes manipulation-aware contrastive learning and modality-aware cross-attention to reason about manipulations at different levels. The model includes manipulation detection and grounding heads that integrate multi-modal information. An extensive benchmark and rigorous evaluation metrics are also established for this research problem. Experimental results demonstrate the effectiveness of the proposed model and provide valuable insights for future research in multi-modal media manipulation.