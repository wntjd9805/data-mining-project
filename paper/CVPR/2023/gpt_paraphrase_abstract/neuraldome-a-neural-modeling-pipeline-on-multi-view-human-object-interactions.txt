In daily life, humans interact with objects, but it can be challenging to capture and analyze these interactions due to various factors such as occlusions, shape ambiguities, and motions. To address this issue, we have created a comprehensive dataset called HODome, which consists of approximately 71 million frames capturing 10 subjects interacting with 23 objects from multiple viewpoints. To process this dataset, we have developed NeuralDome, a neural processing pipeline specifically designed for multi-view video inputs. NeuralDome enables accurate tracking, geometry reconstruction, and free-view rendering for both human subjects and objects. Through extensive experiments using the HODome dataset, we have demonstrated the effectiveness of NeuralDome in various inference, modeling, and rendering tasks. We will make both the dataset and the NeuralDome tools available to the community for further development at https://juzezhang.github.io/NeuralDome.