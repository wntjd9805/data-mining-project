This paper presents a novel approach called neural texture learning for estimating the 6D pose of objects using synthetic data and a small number of unlabeled real images. The main contribution is a new learning scheme that overcomes the limitations of previous methods, which relied heavily on additional data or refinement steps for training. The proposed scheme involves two sub-optimization problems: one for learning object texture from real image collections and another for learning pose estimation from synthetic data. By combining these two capabilities, the approach can generate realistic novel views to supervise the pose estimator with accurate geometry. To address pose noise and segmentation imperfections during the texture learning phase, the authors propose a surfel-based adversarial training loss and texture regularization using synthetic data. Experimental results demonstrate that the proposed approach outperforms state-of-the-art methods even without ground-truth pose annotations, and it shows significant improvements in generalization to unseen scenes. Notably, the scheme improves the performance of the adopted pose estimators, even when they are initially poorly performing.