Current methods combining deep learning, artist-curated scans, and Implicit Functions (IF) have made it possible to generate detailed 3D human models from images. However, these methods have limitations in recovering accurate shapes for novel poses or clothing, often resulting in disjointed limbs or distorted shapes. To address this, existing approaches incorporate parametric body models to constrain surface reconstruction, but this restricts the recovery of free-form surfaces such as loose clothing. Our goal is to develop a method that combines the strengths of implicit representation and explicit body regularization. We make two important observations: (1) current networks excel in inferring detailed 2D maps rather than full 3D surfaces, and (2) a parametric model can act as a "canvas" for stitching together detailed surface patches. Based on these observations, we propose our method called ECON, which consists of three main steps: (1) inferring detailed 2D normal maps for the front and back of a clothed person, (2) recovering 2.5D front and back surfaces, referred to as d-BiNI, that are equally detailed but incomplete, and aligning them using a SMPL-X body mesh obtained from the image, and (3) filling in the missing geometry between the d-BiNI surfaces. If the face and hands are noisy, they can be optionally replaced with those from the SMPL-X model. As a result, ECON is able to generate high-quality 3D human models even in challenging poses and with loose clothing, surpassing previous methods as demonstrated by quantitative evaluations on the CAPE and Renderpeople datasets. Perceptual studies also confirm that ECON achieves significantly better perceived realism. The code and models for ECON are publicly available for research purposes at econ.is.tue.mpg.de.