The recent popularity of text-to-image synthesis has led to a shift in the preferred architecture for generative image models. While GANs like StyleGAN were previously the go-to choice, autoregressive and diffusion models have now become the standard with the introduction of DALLÂ·E 2. This raises the question of whether GANs can be scaled up to benefit from large datasets like LAION. However, increasing the capacity of StyleGAN architecture without modification leads to instability. To address this, we propose GigaGAN, a new GAN architecture that surpasses these limitations and proves to be a viable option for text-to-image synthesis. GigaGAN offers three key advantages: it is significantly faster, taking only 0.13 seconds to synthesize a 512px image; it can generate high-resolution images, such as 16-megapixel images in 3.66 seconds; and it supports various latent space editing applications like latent interpolation, style mixing, and vector arithmetic operations.