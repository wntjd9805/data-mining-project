Recent research indicates that computer vision models may not be fair, posing a risk to fairness. To address this issue, previous studies have proposed various methods, such as pre-processing, in-processing, and post-processing techniques. In this paper, we introduce a new approach to promoting fairness in computer vision using in-processing methods, inspired by the lottery ticket hypothesis (LTH). Our method involves randomly initializing a dense neural network and identifying suitable binary masks for the weights to create fair sparse subnetworks without any weight training. Notably, we are the first to discover that these fair subnetworks with inherent fairness exist in randomly initialized networks. Moreover, these Fair Scratch Tickets (FSTs) demonstrate a trade-off between accuracy and fairness comparable to that of dense neural networks trained with existing fairness-aware in-processing approaches. We also provide theoretical guarantees for the fairness and accuracy of FSTs. Through experiments, we explore the existence of FSTs on different datasets, target attributes, random initialization methods, sparsity patterns, and fairness surrogates. Additionally, we find that FSTs can transfer across datasets and investigate other characteristics of FSTs.