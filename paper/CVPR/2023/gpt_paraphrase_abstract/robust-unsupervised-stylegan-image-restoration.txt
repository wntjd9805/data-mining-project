This study focuses on GAN-based image restoration, which aims to repair images that have been corrupted by known degradations. Existing unsupervised methods require careful tuning for each specific task and level of degradation. However, this work introduces a robust approach to StyleGAN image restoration, where a single set of hyperparameters can be applied to a wide range of degradation levels. This eliminates the need for re-tuning when handling combinations of multiple degradations. The proposed method involves a 3-phase progressive latent space extension and a conservative optimizer, eliminating the requirement for additional regularization terms. Through extensive experiments, the approach demonstrates its robustness in tasks such as inpainting, upsampling, denoising, and deartifacting, outperforming other inversion techniques based on StyleGAN. Furthermore, the proposed approach produces more realistic inversion results compared to diffusion-based restoration. The code for this method is available at the provided URL.