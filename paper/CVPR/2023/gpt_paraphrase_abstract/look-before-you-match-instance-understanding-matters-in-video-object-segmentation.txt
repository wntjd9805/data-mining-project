Recent advancements in video object segmentation (VOS) have shown impressive results by utilizing memory-based methods for dense matching between current and past frames, enabling long-range context modeling. However, these approaches often struggle with large appearance variations and viewpoint changes caused by object and camera movement due to their lack of instance understanding ability. In this study, we emphasize the importance of instance understanding in VOS and propose a two-branch network that integrates instance segmentation (IS) with memory-based matching to leverage their synergistic effects. The IS branch focuses on capturing instance details in the current frame, while the VOS branch performs spatial-temporal matching using a memory bank. We incorporate well-learned object queries from the IS branch into the query key to inject instance-specific information, enabling instance-augmented matching. Additionally, we introduce a multi-path fusion block to effectively combine the memory readout with multi-scale features from the instance segmentation decoder. This fusion process incorporates high-resolution instance-aware features, resulting in accurate segmentation results. Our method achieves state-of-the-art performance on various benchmark datasets, including DAVIS 2016/2017 val (92.6% and 87.1%), DAVIS 2017 test-dev (82.8%), and YouTube-VOS 2018/2019 val (86.3% and 86.3%), outperforming alternative methods by significant margins.