This study addresses the issue of semi-supervised video object segmentation on devices with limited resources, such as mobile phones. We propose a solution in the form of small space-time-memory networks with finite memory, which can achieve comparable results to state-of-the-art methods but with significantly lower computational cost (32 milliseconds per frame on a Samsung Galaxy S22). Our approach combines knowledge distillation and supervised contrastive representation learning, providing a unified framework supported by theoretical foundations. These models benefit from both pixel-wise contrastive learning and distillation from a pre-trained teacher. We validate our approach by achieving competitive performance in terms of J & F scores on the standard DAVIS and YouTube benchmarks, while being up to 5 times faster and having 32 times fewer parameters than existing methods.