Trajectory prediction is essential for analyzing social behavior in various applications, such as autonomous driving, motion tracking, and robotic systems. The accurate forecasting of pedestrians' future locations relies on understanding videos, human social behaviors, and the observed trajectories and scenes. This prediction task involves capturing both spatial and temporal information, with spatial interactions playing a crucial role in determining future paths. However, spatial interactions can sometimes undermine temporal consistency and the original intentions based on temporal information. Current approaches have made progress in single-future trajectory prediction but fail to consider multiple destinations and plausible future trajectories. To address these challenges, we propose an encoder-decoder network that constructs a multi-scale graph to represent scene segmentation and trajectory features. We introduce a graph-based spatial transformer to model interactions between pedestrians and other objects in the scene. Additionally, we design a "Memory Replay" algorithm that utilizes a memory graph to accumulate and replay temporal information to ensure smooth trajectory predictions. We also propose a new evaluation metric, "Percentage of Trajectory Usage," to assess the comprehensiveness of multi-future predictions. Our experiments on the Forking Paths dataset demonstrate the effectiveness of our model, achieving state-of-the-art performance in multi-future trajectory prediction. Furthermore, our performance in single-future prediction matches that of existing state-of-the-art models on the VIRAT/ActEV dataset. Overall, our contributions include the graph-based spatial transformer, the trajectory smoothing algorithm, and the new evaluation metric.