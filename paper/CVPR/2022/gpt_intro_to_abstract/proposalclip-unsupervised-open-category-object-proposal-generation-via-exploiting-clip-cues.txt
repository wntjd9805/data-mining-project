Object proposal generation is a necessary step in various computer vision tasks, such as object detection, object segmentation, and image captioning. Traditional methods use low-level cues to select proposals, while recent deep learning-based methods utilize high-level semantics from CNNs or Transformers. However, these methods require a large number of annotated bounding boxes for training, limiting their applicability to a limited number of object categories. To address these challenges, this paper proposes an unsupervised and open-category object proposal generation method called ProposalCLIP. This method leverages the CLIP (contrastive language-image pre-training) model, which is trained on millions of image-language pairs, to generate diverse proposals without requiring expensive annotations. The paper analyzes CLIP features and develops an objectness score and a graph-based merging model to effectively combine proposals. Pseudo labels based on CLIP cues are also used to train a box regression model for further refinement. Experimental results on three datasets demonstrate the effectiveness of the proposed method, which can generate proposals for open categories without annotations. The paper's contributions include a novel method for annotation-free proposal generation, the analysis and exploitation of CLIP cues for proposal generation, and improvements on popular datasets with potential benefits for downstream tasks.