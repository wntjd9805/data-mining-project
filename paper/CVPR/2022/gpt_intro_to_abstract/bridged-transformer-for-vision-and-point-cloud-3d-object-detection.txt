3D object detection in computer vision has gained significant attention as a fundamental task in scene understanding. Previous approaches have utilized point cloud data, converting them into regular formats or using 3D specific operators for grouping strategies. Transformers have shown promise in 3D object detection and have been successful in various 2D tasks. Deep multimodal learning has also shown superiority in various applications. However, there is a lack of research on combining advantages from both point clouds and images in 3D object detection. This paper proposes a novel framework called Bridged Transformer (BrT) that bridges the learning processes of images and point clouds inside the Transformer. BrT leverages conditional object queries and point-to-patch projections to enhance the interaction between images and points. The proposed framework avoids grouping errors and captures long-range dependencies and global contextual information. Experimental results on benchmark datasets demonstrate the superiority of BrT over state-of-the-art methods, highlighting its potential in multi-view scenarios.