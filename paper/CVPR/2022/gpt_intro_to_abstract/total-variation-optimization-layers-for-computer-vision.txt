Optimization within deep-net layers has shown promise in designing building blocks for deep neural networks. This involves viewing optimization problems as differentiable functions and computing their derivatives through implicit differentiation. Designing effective layers is crucial for the success of deep learning, with specialized layers such as convolution, recurrence, normalization, and attention being fundamental building blocks in computer vision models. Recently, optimization layers have also found applications in reinforcement learning, logical reasoning, hyperparameter tuning, scene-flow estimation, and graph-matching. However, optimization as a layer has not been widely adopted in computer vision due to unanswered questions regarding the usefulness of optimization problems and the efficient solution of such problems for high-dimensional input.In this work, we propose and study Total Variation (TV) minimization as a layer within a deep-net for computer vision. TV has been successful in computer vision applications, incorporating the knowledge that images are piece-wise constant. It has been used as a regularizer in tasks such as image denoising, super-resolution, stylization, and blind deconvolution. We hypothesize that TV as a layer would be an effective building block, enforcing piece-wise properties in an end-to-end manner.Existing solutions that support TV as a deep-net layer are limited, with generic solvers lacking GPU support and specialized solvers lacking GPU and batching support. To overcome these limitations, we developed a fast GPU TV solver with custom CUDA kernels, enabling the use of TV as a layer across computer vision tasks. Our implementation is significantly faster than both generic and specialized solvers.With this fast implementation, we evaluate TV as a layer on five computer vision tasks: classification, object localization, edge detection, edge-aware smoothing, and image denoising. We incorporate TV layers into existing deep-nets, such as ResNet and VGGNet, and observe improvements in results.Our contributions include proposing TV as a layer for use in deep-nets for computer vision tasks, developing a fast GPU-based TV solver, and demonstrating the efficacy and practicality of TV layers through evaluations on five different computer vision tasks.