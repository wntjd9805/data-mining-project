Building on the success of supervised learning in visual tasks, there has been a recent focus on learning high-level representations without human annotations through self-supervised learning (SSL). SSL aims to learn representations that extract useful information for downstream tasks in an unsupervised manner. Existing SSL approaches encourage all random crops of an image to have similar representations, which can lead to the loss of valuable image information. In this paper, we propose a new multi-crop SSL strategy called LoGo that addresses this limitation by exploiting the relationships between local and global image patches. LoGo utilizes large crops for a global view and small crops for a higher variance in local regions. We design a loss function that pulls global representations of the same image together while allowing local representations to remain distant, accounting for differences between local patches. Additionally, we introduce a learnable similarity measure to evaluate patch representations in a high-dimensional feature space. Our approach shows improved performance over state-of-the-art SSL techniques on various datasets and enables self-supervised models to outperform supervised counterparts on dense prediction tasks with only a fraction of the training data.