This paper presents a novel approach for trajectory forecasting from LiDAR sensor data, which is a critical perception task for autonomous robot navigation. The traditional approach involves object detection and tracking in 3D LiDAR scans to obtain past trajectories, which are then used with forecasting methods to estimate future actions. However, existing approaches tend to predict only a single future trajectory for each object, neglecting future uncertainty. To overcome this limitation, the authors propose FutureDet, an approach that reframes forecasting as the task of future object detection. By repurposing existing detectors that predict heatmaps of possible object locations, FutureDet represents a distribution over multiple plausible future states. The approach encodes a sequence of past LiDAR scans using standard backbones for 3D LiDAR-based object detection and trains the network to detect objects multiple timesteps into the future and estimate trajectories for these future detections back to the current frame. The authors evaluate the proposed approach on the nuScenes dataset and demonstrate that FutureDet outperforms existing methods without requiring object tracks or HD-maps as inputs. They also discuss the limitation of current metrics for evaluating joint detection and forecasting and propose a novel forecasting mean average precision (mAP) metric that assesses forecasting and detection together. The contributions of this paper include repurposing object detectors for end-to-end trajectory forecasting, rethinking trajectory forecasting evaluation using the forecasting mAP metric, and thorough analysis of the proposed approach on the challenging nuScenes dataset.