The vanilla SMPL based parametric representations have been extensively studied and widely utilized for modeling 3D human shapes, but they lack the ability to capture temporal information. In this paper, we propose a novel neural representation called H4D for 4D human modeling. H4D combines the advantages of both prior-based and free-form solutions by encoding each dynamic human sequence with SMPL parameters for shape and initial pose, as well as a compact latent code for temporal motion. We use a decoder with a prior model extended from SMPL to reconstruct the input sequence, ensuring more complete and plausible outputs. To enhance the representation capability, we add an additional auxiliary latent code to compensate for inaccurate motion and enrich geometry details. Our representation is learned through an auto-encoding framework, and can support various applications such as motion retargeting, completion, and prediction. We design novel Gated Recurrent Unit (GRU) based architectures for the encoder and decoder to improve model performance. Experimental results demonstrate the effectiveness of our representation and GRU-based architecture in recovering accurate dynamic human sequences and performing well in various 4D human related applications.