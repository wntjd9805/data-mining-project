Group activity recognition (GAR) is a task in computer vision that involves classifying the activity being performed by a group of people in a video clip. It is a challenging task that requires the understanding of interactions between multiple actors and the precise modeling of their spatio-temporal relations. Most existing methods for GAR rely on ground-truth bounding boxes and action class labels for both training and testing, which can be impractical and restrict the applicability of these methods. In this paper, we propose a detector-free model for weakly supervised GAR (WSGAR) that does not depend on ground-truth bounding boxes or object detectors. Our model uses a Transformer encoder on top of a convolutional neural network backbone to capture partial contexts of the group activity. We introduce learnable tokens that localize key actors and other useful clues, allowing us to bypass the need for explicit object detection. We also incorporate motion information into our framework by learning to capture local correlations between adjacent frames. We evaluate our model on the Volleyball and NBA datasets and achieve state-of-the-art performance in the weakly supervised learning setting, outperforming existing WSGAR models and even competing with methods that rely on stronger supervision. Our contributions include the first detector-free method for WSGAR, a novel Transformer-based model for capturing group activity, and improved performance on benchmark datasets.