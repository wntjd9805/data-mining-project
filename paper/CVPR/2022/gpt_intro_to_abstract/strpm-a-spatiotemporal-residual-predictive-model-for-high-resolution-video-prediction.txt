Video prediction is a crucial aspect of representation learning in computer science, as it can model meaningful representations for natural videos. It has been applied to various video processing applications, such as video coding, precipitation nowcasting, robotic control, autonomous driving, and more. In recent years, deep learning technologies have been leveraged to develop learning-based methods for video prediction. These methods can be categorized into three types: recurrent neural networks (RNN)-based methods, deep stochastic models, and generative adversarial networks (GANs) with perceptual loss functions.Although these methods have achieved satisfactory results, they often struggle with high-resolution videos, limiting their practicality in real-world scenarios. The challenges mainly arise from the complex visual details and motion information present in high-resolution videos. To address these challenges, this paper introduces a Spatiotemporal Residual Predictive Model (STRPM). It employs a novel spatiotemporal encoding-decoding scheme to preserve more visual details by using independent encoders in both the spatial and temporal domains. Additionally, a Residual Predictive Memory (RPM) is designed to accurately model the complex motion information in high-resolution videos with fewer parameters and lower computation load. The RPM indirectly supervises the spatial encoder and the temporal encoder, enabling them to extract corresponding features.By combining the encoded spatiotemporal features and spatiotemporal residual features (STRF), the proposed model predicts more reliable spatiotemporal features for future frames. These features are then decoded back to the high-dimensional data space using spatiotemporal decoders. In the training stage, the model utilizes standard mean square error (MSE) loss, adversarial loss, and learned perceptual loss to enhance the visual quality of predictions. Experimental results demonstrate that the proposed model achieves state-of-the-art performance compared to other methods.