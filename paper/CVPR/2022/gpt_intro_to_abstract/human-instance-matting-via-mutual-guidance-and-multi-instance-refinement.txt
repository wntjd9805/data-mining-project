The rapid growth of the multimedia industry, particularly in the mobile internet technology and we-media platforms, has increased the demand for efficient image editing tools. Image matting, which is a technique used for image editing, has seen significant advancements with the adoption of deep neural networks. However, existing matting methods still face challenges in scenarios such as foreground extraction and instance-level editing. To address these issues, we propose a new task called human instance matting (HIM) that aims to automatically extract precise alpha matte for each human instance in an image. HIM combines the characteristics of existing tasks such as instance segmentation and soft segmentation while introducing new technical challenges. We introduce a novel instance matting framework called InstMatt, which utilizes a mutual guidance strategy and a multi-instance refinement module to decompose mingled compositing colors into separate instances. We also propose a new evaluation metric called instance matting quality (IMQ) to measure both instance recognition quality and alpha matte quality. To validate our techniques, we create a benchmark dataset called HIM2K consisting of 2,000 images with high-quality matte ground truths. Additionally, we demonstrate the potential of our contributions by showcasing preliminary results on matting multi-object instances beyond humans.