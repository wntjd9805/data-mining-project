The goal of this computer science paper is to conduct an empirical study on channel pruning, a technique used to reduce the computational complexity of convolutional neural networks (CNNs). Random pruning, where the pruning ratio of each layer is randomly selected and channels to be pruned are determined by some criterion, is frequently used as a baseline for comparing the improvements of state-of-the-art channel pruning methods. However, the power of random pruning is not fully understood. Through rigorous analysis, this paper presents several striking findings. Firstly, recent proposed channel pruning criteria perform just as well as the simple L1 and L2 norm-based pruning criteria. Secondly, compared to channel pruning algorithms that start with a pre-trained model, random pruning can achieve comparable or even superior performance. Thirdly, even compared to advanced pruning methods that optimize the overall network architecture, random pruning still narrows the performance gap. Lastly, the number of fine-tuning epochs strongly influences the performance of the pruned network. High-performing pruned networks usually require prolonged fine-tuning epochs. The paper also discusses the implications of these findings, such as the simplicity and effectiveness of L1 and L2 based pruning criteria, the potential for random pruning to serve as a neutral baseline for evaluating other pruning algorithms, and the importance of standardizing the fine-tuning protocol for fair comparisons. Overall, this paper contributes by presenting random pruning as a strong baseline for benchmarking channel pruning methods, analyzing the properties and performance of random pruning, and benchmarking various channel pruning methods.