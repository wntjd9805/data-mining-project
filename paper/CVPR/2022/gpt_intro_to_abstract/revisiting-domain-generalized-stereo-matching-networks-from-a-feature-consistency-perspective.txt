Estimating depth from images is a fundamental problem in computer vision. Stereo matching is a solution to this task, which finds the correspondence between stereo image pairs and recovers depth through triangulation. Recent advancements in end-to-end stereo matching networks have achieved state-of-the-art accuracy. However, these networks suffer from poor generalization performance on unseen domains, limiting their real-world applications. To address this challenge, some networks have attempted feature-level alignment to obtain domain-invariant features. In this paper, we propose a weaker constraint called stereo feature consistency for domain-generalized stereo networks. We argue that what a stereo network needs to generalize is the matching relationship, behaving as the feature consistency of paired points. We demonstrate that traditional methods compute matching costs directly on RGB images, and even though the image content varies across domains, the matching pixels have consistent expressions between stereo viewpoints. We verify this intuition by constructing a toy pipeline that combines a cost volume from RGB images with a common cost aggregation module, resulting in improved domain generalization performance. We also observe that the learned features lose consistency when constructing the cost volume, even within the training set. To overcome this, we propose the Stereo Contrastive Feature (SCF) loss to encourage feature consistency on the training set, and the Stereo Selective Whitening (SSW) loss to generalize this consistency across different domains. We apply these loss functions to various stereo matching backbones and demonstrate significant improvement in generalization performance. This paper contributes by highlighting the importance of stereo feature consistency and proposing loss functions to maintain it, leading to improved domain generalization in stereo matching networks.