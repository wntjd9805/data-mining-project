Convolutional neural networks (CNNs) have proven to be effective models in computer vision tasks, but they suffer from high computation costs and memory storage when deployed on resource-limited mobile devices. To address this, various model acceleration methods have been proposed, including pruning, quantization, and structure simplification. Quantization, in particular, has gained attention for its ability to reduce the bit widths of model weights and activations, leading to faster inference. However, existing quantization methods overlook the difference between training and testing data, which can result in a large quantization error.To tackle this issue, this paper introduces AlignQ, a novel quantization scheme that aligns non-i.i.d. training and testing data to minimize quantization error. The proposed method leverages the cumulative distribution function (CDF) as an alignment function, as it follows a uniform distribution. This uniform space is well-suited for uniform quantization and retains the data order. Moreover, the paper addresses the impact of changes in data correlations after quantization on quantization error. To preserve these correlations, the Alternating Direction Method of Multipliers (ADMM) optimization is employed.The proposed AlignQ is compared with state-of-the-art methods on benchmark datasets such as CIFAR-10, SVHN, and ImageNet, as well as domain shift benchmarks like digits and Office-31. Experimental results demonstrate that AlignQ achieves significant performance improvements, especially at low bit widths.The contributions of this paper include the design of AlignQ, a quantization scheme that aligns non-i.i.d. data to minimize quantization error, the use of ADMM to tackle multi-goal optimization problems, and the experimental validation of AlignQ's effectiveness on various benchmark datasets.