3D sensors are becoming more common in geometric perception tasks due to their miniaturization and mass production. These sensors capture scene geometry through a point cloud, which is an unordered and irregular data structure. While there have been advancements in static scene and object classification using point clouds, there is a need to consider the dynamic nature of the real 3D world. Previous works have focused on dynamic point cloud classification by treating it as a video-level categorization task. However, the utilization of scene flow, which captures the motion field of point clouds, has not been explored in this context. Scene flow estimation in point cloud sequences is challenging due to the irregular nature of the data, making it difficult to track point correspondences across frames. This paper proposes a novel approach called Kinet, which bypasses the direct estimation of scene flow by using the concept of space-time surfaces (ST-surfaces) and normal vectors. The proposed method encodes dynamic information through feature-level ST-surfaces without the need for explicit correspondence estimation. The solver for ST-normals is jointly trained with the static model in an end-to-end manner, leveraging intermediate features from the static network layers. The proposed framework is compared to existing methods on multiple datasets and tasks, showcasing its effectiveness, efficiency, and versatility. The results demonstrate improved performance in gesture recognition and action classification tasks, surpassing human-level accuracy in some cases. The code for the proposed method is publicly available for further exploration.