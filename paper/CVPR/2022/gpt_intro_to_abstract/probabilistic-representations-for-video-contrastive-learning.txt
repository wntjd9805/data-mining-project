Video content plays a vital role on the Internet, and understanding video content is crucial for modern AI agents. Self-supervised or unsupervised video representation learning has become a significant research topic in the computer vision community. The goal is to learn deep features that represent general visual content, which can improve performance on various tasks such as action recognition, action detection, video retrieval, and event recognition. However, self-supervised video representation learning is challenging due to the inherent difficulty caused by the nature of videos compared to static images.Recent breakthroughs in self-supervised video representation learning can be classified into two branches: pretext tasks related to video coherence and contrastive learning for instance discrimination. Pretext tasks model video coherence through different sub-properties of video contents, while contrastive learning aims to discriminate different instances without relying on specific properties of the data. Existing works in contrastive learning treat each video as an "instance" and embed video clips into deterministic points in the embedding space. Positive and negative pairs are then formed based on contrastive objectives. However, deterministic representations have limitations in capturing the complexity and uncertainty of video distribution, and improper sampling and transformation techniques can affect downstream task performance. Additionally, deterministic representations often neglect common components between semantically adjacent instances, leading to limited discrimination performance.To address these limitations, we propose ProViCo, a probabilistic representation for video contrastive learning. In ProViCo, video clips are represented as random variables in a stochastic embedding space. Clips from a video are represented as distinct normal distributions, and the distribution of the whole video is approximated using a Mixture of Gaussians. We construct positive and negative pairs based on the probabilistic distance between embeddings sampled from each video distribution. We also introduce an uncertainty-based stochastic contrastive loss that incorporates uncertainty into the soft contrastive loss. This allows us to reduce the impact of noisy samples and training pairs on self-supervised representation learning. Our contributions include: (1) the proposal of ProViCo, a novel approach that leverages probabilistic embeddings for self-supervised video representation learning, (2) the introduction of probabilistic distance-based positive mining and the stochastic contrastive loss to capture semantic relations between videos and mitigate the effects of unreliable instances, and (3) the demonstration of the effectiveness of the proposed probabilistic approach through uncertainty estimation and extensive experiments on action recognition and video retrieval tasks.