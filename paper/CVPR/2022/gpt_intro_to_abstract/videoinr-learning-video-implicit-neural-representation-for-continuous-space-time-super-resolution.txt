In this computer science paper, the authors address the problem of recovering low-resolution and low frame rate videos to high resolution and high frame rate. They propose a novel approach called Video Implicit Neural Representation (VideoINR) that allows for continuous video representation, enabling sampling and interpolation of video frames in arbitrary frame rates and spatial resolutions. The key idea is to learn an implicit neural representation that takes a space-time coordinate as input and outputs the corresponding RGB value. The VideoINR approach utilizes an encoder to generate a feature map, which is then decoded by VideoINR to achieve arbitrary spatial resolution and frame rate. Experimental results demonstrate that VideoINR achieves competitive performances with state-of-the-art Space-Time Video Super-Resolution (STVSR) methods and exhibits out-of-distribution generalization. The proposed approach offers an efficient solution for representing videos in arbitrary space and time resolutions using a single network.