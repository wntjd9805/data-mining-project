Continual Learning (CL) is the process of acquiring new knowledge from new data distributions without forgetting previous knowledge. In the classification setting, CL often leads to a phenomenon known as catastrophic forgetting, where the learner experiences a decrease in accuracy due to a loss of knowledge about previously seen data. Traditional approaches for evaluating forgetting may fail to distinguish between trivial changes in features and abrupt losses of useful representations. In this paper, we propose the use of Linear Probes (LP) to properly evaluate CL algorithms and their effectiveness. We revisit several CL settings and benchmarks and find that naive finetuning approaches exhibit minimal forgetting without losing critical task information. Our major contributions include insights obtained through extensive experimental analysis, such as the misleading nature of accuracy as a metric for studying forgetting, the advantageous properties of SupCon and SimCLR for continual learning, and the decreased forgetting observed for wider and deeper models using LP-based evaluation. Additionally, we propose a simple approach for facilitating fast remembering without the need for a large memory during training, relying instead on a small memory combined with SupCon-based finetuning.