Scene graph generation (SGG) is a crucial task in computer vision that involves generating structured representations of scenes in images. A scene graph is a directed graph that represents objects and their relationships in an image. SGG has been widely used in various downstream tasks such as image generation, visual question answering, image captioning, and semantic image retrieval.Although significant progress has been made in SGG, existing methods still struggle to capture the semantic similarity between different predicates. This is particularly evident in the long-tailed distribution of predicates in datasets, where head classes are more frequent than tail classes. Biased SGG models tend to prioritize high-frequency predicates, resulting in the neglect and misclassification of tail classes. Furthermore, the less semantic nature of head classes can degrade the overall performance of SGG in tasks that require richer semantics.To address these issues, this paper proposes a novel loss function called Predicate Probability Distribution based Loss (PPDL). Inspired by the Focal Loss for dense object detection, PPDL aims to weaken the model's suppression of tail classes by reweighting the loss of predicted predicates based on their estimated probability distribution. The paper introduces a Predicate Probability Distribution Matrix (PPDM) to represent the estimated probability distribution of each predicate class. By examining the similarity between the predicted and estimated predicate probability distributions, the model can determine if there is a bias in predicate classification and adjust the loss accordingly.To better estimate the probability distribution of each predicate class, the paper also proposes a dynamic updating method for PPDM during training. Instead of relying solely on co-occurrence statistics, the PPDM is adaptively updated by summing the probability distributions of unbiased predicted relationships in each mini-batch.The contributions of this paper are three-fold. Firstly, it presents PPDL as a model-agnostic training strategy to mitigate the impact of long-tailed data on SGG. Secondly, it proposes an adaptive updating method for PPDM to estimate a realistic probability distribution for each predicate during biased model training. Lastly, extensive experiments and qualitative analyses on the Visual Genome dataset demonstrate the effectiveness of PPDL in improving the performance of SGG, particularly for tail classes.Overall, this paper addresses the long-tailed distribution issue in SGG by integrating the predicate probability distribution into the training loss. The proposed approach significantly improves the performance of SGG, especially for tail classes, and has the potential to benefit a wide range of existing SGG models.