Human parsing, the process of segmenting human bodies into different parts, is a challenging task in scene parsing. It involves dealing with complex textures and styles of clothes, deformable human poses, and scale diversity of different parts. Human parsing provides fine-grained semantic segmentation, which is important for human understanding and applications. Previous studies have used fully convolutional networks (FCNs) to improve the performance of human parsing. However, human parsing is more difficult than conventional pixel-level segmentation tasks due to the symmetrical and structural nature of the human body. Several methods have attempted to leverage these characteristics to improve performance, but they often involve complex mechanisms that increase computational complexity. In this paper, we propose a novel Class Distribution Guided Network (CDGNet) that simplifies the representation of human structure by using horizontal and vertical position information. We build class distribution labels in these directions and teach the network using these supervision signals. Experimental results on benchmark datasets demonstrate the effectiveness of our method. Our contributions include simplifying the human parsing problem, proposing CDGNet to exploit human positional knowledge, and achieving significant performance improvements.