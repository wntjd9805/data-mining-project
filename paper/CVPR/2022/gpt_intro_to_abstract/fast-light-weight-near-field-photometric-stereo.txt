This paper introduces a fast and light-weight Photometric Stereo (PS) technique for near-field illumination. Photometric Stereo is a method used to reconstruct object geometry by capturing a sequence of images with varying light sources. Existing near-field PS approaches are slow and memory-intensive, limiting their practicality. By developing a fast and light-weight reconstruction technique, users can capture and process images on their laptops within seconds, allowing for multiple retakes. This technique is particularly useful for AR/VR applications. In addition, the proposed method can also be extended to uncalibrated real-world captures by introducing a calibration network.Near-field PS is preferred over far-field lighting-based PS for capturing large objects in confined spaces. Far-field approaches assume distant lighting, which is not suitable for 3D imaging in indoor spaces. Moreover, low-intensity LED lights on handheld devices may not be bright enough to illuminate objects from a distance. Near-field PS also eliminates the linear ambiguity present in far-field PS, providing more accurate reconstructions.The proposed method achieves fast and accurate results by using a recursive multi-scale algorithm. It consists of two recursive networks for predicting surface normals and depth maps. At each recursion step, the input image resolution is increased, and the lighting direction and attenuation factors are estimated for each pixel. The surface normals and depth maps are then inferred based on the input image, lighting information, and previous scale estimations. This approach significantly reduces memory requirements and inference time, while also improving robustness to noise and calibration errors.The method builds on existing near-field and far-field PS techniques, adapting the most effective ideas to improve performance. It incorporates the recursive architecture proposed in a far-field PS study, utilizing the concept of per-pixel lighting and introducing depth prediction from normals. A calibration network is also introduced to facilitate uncalibrated capture scenarios using handheld devices.The performance of the proposed method is evaluated on the LUCES dataset with both calibrated and uncalibrated lighting conditions. It outperforms state-of-the-art near-field PS approaches in terms of surface normal prediction accuracy and computational efficiency. The proposed method requires significantly less memory compared to existing methods and achieves faster inference times. Real-world object reconstructions using a commodity flashlight demonstrate the qualitative superiority of the proposed method over existing approaches.In summary, the contributions of this paper include a fast and light-weight near-field PS method with improved performance and reduced memory requirements. The method combines the benefits of per-pixel lighting, recursive depth prediction, and unstructured lighting flexibility.