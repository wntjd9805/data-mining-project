Self-supervised learning (SSL) aims to learn generalizable representations without expert annotation. The representation learning approaches in the SSL paradigm can be categorized into three main groups: discriminative learning, restorative learning, and adversarial learning. While discriminative learning has shown state-of-the-art performance in computer vision tasks, restorative learning has reached new heights in performance in medical imaging. This raises the question of why there is a preference for different methods in these domains and whether all three learning components can be integrated simultaneously.To address this gap, we propose a novel SSL framework called DiRA that combines discriminative, restorative, and adversarial learning to extract fine-grained semantic representations from unlabeled medical images. Our extensive experiments demonstrate that DiRA encourages collaborative learning among the three components, resulting in more generalizable representations across organs, diseases, and modalities. DiRA outperforms supervised ImageNet models, increases robustness in small data regimes, and learns fine-grained representations for accurate lesion localization with only image-level annotations. In addition, DiRA enhances state-of-the-art restorative approaches, establishing it as a general framework for united representation learning.Our contributions include insights into the synergy of discriminative, restorative, and adversarial learning in a ternary setup, introducing a new paradigm of collaborative learning for SSL. We also present the first self-supervised learning framework that seamlessly unites these three learning components, setting a new state-of-the-art for SSL in medical imaging. Through thorough experiments, we demonstrate not only DiRA's generalizability but also its potential to develop universal representations for medical imaging.