This paper introduces a novel method called Neural Kernel Fields (NKFs) for 3D surface reconstruction from point clouds. Surface reconstruction is a critical task in computer vision and graphics, with applications in various fields such as robotics, entertainment, and manufacturing. Existing techniques for surface reconstruction can be divided into implicit methods, which recover a volumetric function encoding the surface, and explicit methods, which directly generate a triangle mesh. While implicit approaches can handle arbitrary topologies, the need to store a dense volumetric field has led to a preference for explicit methods in the past. However, recent studies have shown that neural networks can effectively encode signed-distance and occupancy fields, making implicit approaches more appealing.The current state-of-the-art shape reconstruction methods can be categorized based on three factors: feed-forward vs. test-time optimization, leveraging data priors or not, and the scale at which data is processed. Feed-forward methods use shape priors to predict surfaces directly from input points, but they may perform more like retrieval than reconstruction. Test-time optimization via latent space traversal allows adaptation to the input but is slow and can converge to poor local minima. Data-free methods minimize residuals between the reconstructed surface and input points using fixed priors, while data-driven approaches can learn task-specific priors. Local-scale methods reduce complex structures to simpler geometric primitives, while global-scale methods lack the ability to complete larger missing regions.Motivated by the limitations of existing methods, this paper proposes the use of Neural Kernel Fields (NKFs). NKFs leverage a learned positive definite kernel conditioned on an input point cloud to predict an implicit shape by solving a simple linear system. The predicted kernels respect the input points and can be solved in closed form at test time, guaranteeing good minima. Additionally, the kernel acts as a global aggregator of spatially local features, allowing the method to work at various sampling densities without scale parameter tuning.The contributions of this paper are as follows: (1) the introduction of Neural Kernel Fields, a novel representation for 3D reconstruction that outputs highly detailed surfaces respecting the input points, (2) state-of-the-art performance on ShapeNet reconstruction, (3) demonstrating superior generalization performance on out-of-distribution shapes, scenes, and point densities. The experimental results showcase the effectiveness of the proposed method in achieving high-quality reconstruction on both in and out-of-distribution shapes.