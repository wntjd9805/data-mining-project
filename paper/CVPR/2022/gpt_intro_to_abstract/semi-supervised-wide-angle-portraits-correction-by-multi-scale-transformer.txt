Abstract:This paper addresses the issue of perspective distortion in wide-angle smartphone camera images. The traditional undistortion methods using perspective projection are effective in correcting background lines but lead to unnatural stretching of faces. Other projections, such as mercator and stereographic, preserve facial shape but distort linear structures in the background. We propose a semi-supervised strategy that leverages direction and range consistency (DRC) and regression consistency (RC), using a surrogate task of segmentation, to make use of both labeled and unlabeled data. Additionally, we introduce a novel network called Multi-Scale Swin-Unet (MS-Unet) based on the multi-scale swin transformer block (MSTB) for portraits correction. Experimental results demonstrate that our approach outperforms previous methods in correcting wide-angle portraits with superior performance and requires only a small amount of manually labeled data. This paper presents the first semi-supervised learning strategy for wide-angle portraits correction, offers a transformer-based network for better utilization of local-scale and long-range semantic information, and provides a high-quality unlabeled dataset for training future semi-supervised wide-angle portraits correction algorithms.