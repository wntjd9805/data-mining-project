This paper addresses the problem of rigid point cloud registration, which involves aligning two point clouds by finding the optimal rotation and translation parameters. Traditionally, this task involves detecting salient keypoints, computing feature descriptors, finding correspondences, and estimating the rigid transformation using RANSAC. In recent years, researchers have explored learning-based approaches for point cloud registration, focusing on learning feature descriptors and sometimes keypoint detection. However, these approaches still rely on nearest neighbor matching and RANSAC for obtaining the final transformation. This paper proposes a different approach that directly predicts a set of clean correspondences without relying on post-processing steps. The proposed method, called Registration Transformer (REGTR), utilizes transformer attention layers to output consistent point correspondences, enabling the direct estimation of the rigid transformation. REGTR employs a point convolutional backbone and transformer layers with multi-head self and cross attentions to aggregate global information while considering the point positions. The predicted correspondences are used to compute the rigid transformation, and overlap probability scores are also predicted to weigh the correspondences. Unlike traditional approaches, REGTR does not require interest points to be present at the same locations in both point clouds and can establish correspondences on grid subsampled points. Experimental results on the 3DMatch and ModelNet datasets demonstrate the state-of-the-art performance and fast run times of REGTR. Overall, this paper contributes a learning-based method that directly predicts consistent correspondences and achieves precise alignments with a small number of correspondences.