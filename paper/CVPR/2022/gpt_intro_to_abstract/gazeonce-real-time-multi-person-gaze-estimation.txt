Eye gaze is a valuable indicator of human intentions and has been utilized in various applications, including human-computer interaction, virtual/augmented reality, medical diagnostics, and surveillance systems. Previous systems for estimating gaze direction have faced challenges in achieving fast and accurate calculations in a wide range of environments. With the advancement of deep learning, appearance-based gaze estimation using face images has gained attention. However, existing methods often only support gaze estimation for a single person and require extensive pre-processing, resulting in longer computation times. In this paper, we propose a novel one-stage gaze estimation method called GazeOnce, which can estimate gaze directions for multiple individuals in real-time. Our method also predicts additional facial information such as bounding boxes and facial landmarks. To train and evaluate our method, we introduce a new high-quality dataset called MPSGaze, generated using a sophisticated gaze swapping technique. Our experimental results demonstrate that GazeOnce outperforms state-of-the-art methods in terms of estimation accuracy and computational efficiency, especially when dealing with a large number of faces. Overall, our contributions include the development of GazeOnce, the creation of the MPSGaze dataset, and the improvement of multi-person gaze estimation performance.