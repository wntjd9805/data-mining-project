Generative Adversarial Networks (GANs) and StyleGAN have revolutionized image synthesis and editing. However, editing real images using GANs remains a challenge. GAN inversion is a well-studied problem but still an open challenge. Recent works have shown a trade-off between distortion and editability in GAN inversion. Fine-tuning the generator has been proposed as a solution to achieve high-quality reconstructions with good editability. However, this approach is computationally expensive. Classical inversion approaches also face a time-accuracy trade-off. In this paper, we propose HyperStyle, an encoder-based approach that brings the generator-tuning technique to interactive applications. We introduce a hypernetwork that refines the generator weights based on a given input image. The hypernetwork consists of a feature extractor and a set of refinement blocks. We address the challenge of the large number of parameters in the hypernetwork by sharing offsets and network weights. We also propose an iterative refinement scheme to further improve reconstructions. HyperStyle achieves significant improvements over current encoders, rivaling optimization schemes while being much faster. It preserves the structure and semantics of the original latent space, allowing for off-the-shelf editing techniques. Furthermore, HyperStyle generalizes well to out-of-domain images, indicating its ability to refine the generator in a more general sense.