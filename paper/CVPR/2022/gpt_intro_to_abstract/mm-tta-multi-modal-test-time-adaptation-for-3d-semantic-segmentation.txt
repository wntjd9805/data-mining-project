3D semantic segmentation is a challenging task in computer vision that requires both geometric and semantic reasoning about a scene. It has applications in autonomous driving, virtual reality, and robotics. Multi-modal sensors, such as LiDAR and RGB cameras, are considered essential for accurately understanding the 3D semantic information. However, when there is a distribution shift in the multi-modal data during testing, a model needs to quickly adapt to new data for better performance. This is known as test-time adaptation.In this paper, the authors address the problem of multi-modal test-time adaptation for 3D semantic segmentation. They propose a framework called MM-TTA, which generates reliable and adaptive pseudo labels as self-training signals. The framework consists of two modules: Intra-modal Pseudo-label Generation (Intra-PG) and Inter-modal Pseudo-label Refinement (Inter-PR). The Intra-PG module generates pseudo labels for each modality separately to address the instability issue in test-time adaptation. It utilizes a slow-fast modeling strategy, where one batch normalization statistic is initialized from a pre-trained source model and slowly updated with a momentum from another fast-updated batch norm parameter. This allows the model to fuse predictions from both slow- and fast-updated statistics, leveraging their complementary benefits.The Inter-PR module adaptively selects reliable pseudo labels from the individual 2D and 3D branches. It measures the prediction consistencies of each modality separately and fuses predictions from slow-fast models to select the final cross-modal pseudo label as a self-training signal to update batch norm parameters.The authors evaluate their MM-TTA framework on various benchmark settings, including cross-dataset with different sensors, synthetic-to-real, and day-to-night scenarios. They compare it against state-of-the-art baselines and demonstrate its favorable performance. The proposed framework provides insights into test-time adaptation for multi-modal 3D semantic segmentation and offers a solution to generate reliable cross-modal pseudo labels as self-training signals.