Deep neural networks (DNNs) have significantly advanced computer vision tasks, but their performance on new domains is hindered by cross-domain mismatch. Unsupervised domain adaptation (UDA) aims to alleviate this issue by utilizing unlabelled target-domain samples. Previous unsupervised losses in UDA can be categorized into adversarial loss, image translation loss, and self-training loss. Unsupervised representation learning addresses a related problem of learning discriminative embeddings from unlabelled data. Instance contrastive learning has made significant advancements in unsupervised representation learning, where an encoder is trained to match an encoded query with a dictionary of encoded keys. In this paper, we propose Category Contrast (CaCo) for UDA, which builds a category-aware and domain-mixed dictionary using contrastive losses. CaCo effectively minimizes intra-category variation, maximizes inter-category distance, achieves inter-domain and intra-domain alignment, and mitigates data imbalance. Our experiments demonstrate that CaCo outperforms state-of-the-art UDA approaches and generalizes to other learning setups involving unlabeled data. Overall, our contributions include exploring instance contrast for UDA, proposing CaCo for category-aware UDA, and achieving superior UDA performance consistently.