This paper introduces a novel method for user-driven 3D object selection in neural volumetric 3D representations. The growth of 3D photography has increased the need for editing operations, like object selection, that are readily available for 2D photographs. The proposed method incorporates voxel feature embedding and multi-view feature embedding to segment and extract objects in the 3D scene representation. The method is evaluated on real-world datasets and outperforms existing interactive 3D segmentation methods. The paper also contributes a set of high-quality ground-truth annotations for evaluation. The results demonstrate the effectiveness of the proposed method in accurately selecting 3D objects and retaining fine details. This work addresses the lack of research on segmentation in novel 3D scene representations and provides valuable insights for augmented and virtual reality applications.