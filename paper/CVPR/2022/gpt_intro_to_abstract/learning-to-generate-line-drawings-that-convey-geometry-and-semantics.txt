This paper aims to automatically generate effective line drawings from photographs without the need for paired training data or human judgment of shape. The method treats line drawing generation as an unsupervised image translation problem, using deep learning methods to decode depth, semantics, and appearance from the drawings. The goal is for the extracted information to match the geometry and semantics of the input photographs. The paper presents an unsupervised method for automatic line generation that explicitly incorporates geometry and semantic information. Results in various styles of line drawings are provided along with analysis, visual comparisons, and an ablation study.