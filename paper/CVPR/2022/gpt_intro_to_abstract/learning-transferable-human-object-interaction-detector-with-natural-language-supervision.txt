Human-object interaction (HOI) detection is crucial in human-centric visual analysis, providing insights into human intentions and behaviors. However, creating a comprehensive data collection for all possible HOIs is impractical, especially as the action and object categories expand. Existing HOI detectors struggle with novel interactions that are not predefined, limiting their effectiveness. In this paper, we propose a transferable HOI detector that can handle unseen interactions. Unlike previous methods that rely on predetermined lists, we use compositional learning to decompose interactions and generate new combinations without prior knowledge. We also introduce a novel approach that transforms HOI labels into natural language supervision, enabling visual-to-text matching for unseen interactions. Our one-stage HOI detector incorporates a visual encoder and a text encoder, leveraging a unique sequence parser module and HOI Vision Transformer. The proposed method achieves state-of-the-art results on HOI detection, particularly for unseen interactions, as demonstrated through experiments on HICO-DET and SWIG-HOI datasets.