Object localization in computer vision aims to identify the area of a target object within an image. While fully supervised approaches require costly bounding box annotations, weakly supervised object localization (WSOL) has emerged as a more cost-effective alternative. The most commonly used approach for WSOL is the class activation map (CAM), which generates a map indicating the most activated areas in an image. However, CAM often fails to highlight the entire object area, resulting in poor localization performance.In this paper, we investigate why CAM fails to accurately highlight the entire object area. We propose a decomposition of CAM into two terms: activation in a feature map and cosine similarity between the feature vector at each spatial location and the class-specific weight in the fully connected (FC) layer. Our analysis reveals that the misalignment of feature directions to the class-specific weights prevents less discriminative parts of the object from being highly activated in CAM.While previous approaches have attempted to expand the activated region in CAM to cover the entire object area, none have addressed or mitigated the misalignment issue. To bridge the gap between classification and localization, we propose a method called feature direction alignment. This method enhances the alignment of feature directions in the entire object region to the directions of class-specific weights, while discouraging alignment in the background region. Additionally, we introduce consistency with attentive dropout to ensure uniformly high activation in the feature map for the target object region.We evaluate our proposed method on two benchmark datasets, CUB-200-2011 and ImageNet-1K, and demonstrate its state-of-the-art performance in object localization for weakly supervised learning. Our contributions include interpreting CAM in terms of feature direction alignment, proposing a method to bridge the gap between classification and localization, and achieving improved results compared to other WSOL methods.