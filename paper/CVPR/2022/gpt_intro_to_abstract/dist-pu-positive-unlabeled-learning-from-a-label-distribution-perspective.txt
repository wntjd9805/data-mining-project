Abstract:The growing importance of big data has led to increased interest in deep neural networks, which have shown impressive performance in various tasks. However, obtaining labeled data for supervision in real-world applications is often challenging, even for binary options. This issue is particularly relevant in recommendation systems, Alzheimer's disease recognition, malicious URL detection, and particle picking in cryo-electron micrographs, where labeled positives are scarce compared to unlabeled data. Hence, there is a need for learning from positive and unlabeled data, known as PU learning.In the past, researchers have developed cost-sensitive PU learning algorithms that assume prior class information and minimize the risk of classifying unlabeled data as negative instances. While these methods have achieved success, optimizing the risk of classifying unlabeled data as negatives often leads to overfitting and a negative-prediction preference in the classifier.To address this issue, we propose a label distribution alignment framework called Dist-PU for PU learning. Unlike cost-sensitive methods, Dist-PU aligns the expectation of the model's predicted labels with the ground-truth labels, rectifying the negative-prediction preference. We employ entropy minimization and Mixup techniques to mitigate the trivial solution issue and the confirmation bias caused by early predictions.We evaluate Dist-PU on Fashion-MNIST, CIFAR-10, and Alzheimer datasets, demonstrating its superiority over existing state-of-the-art models in most cases. Additionally, we provide a theoretical guarantee in the form of a generalization bound for label distribution alignment.In conclusion, Dist-PU offers a novel approach to PU learning by aligning label distributions, leading to improved performance compared to existing methods.