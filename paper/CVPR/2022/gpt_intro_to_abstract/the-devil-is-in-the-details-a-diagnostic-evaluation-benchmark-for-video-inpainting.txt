Video inpainting is a challenging task that involves filling in missing pixels in a video with plausible values. It is widely used in various applications such as watermark and foreground object removal. Compared to image inpainting, video inpainting is more complex due to the additional temporal dimension and the need for coherence in both spatial structure and motion. Although recent advancements in video inpainting have shown promising results, there is a lack of emphasis on content-informed diagnostic evaluation, which can help identify the strengths and weaknesses of existing methods. Existing evaluation schemes often underemphasize the importance of video contents and masks used for evaluation. This paper proposes the Diagnostic Evaluation of Video Inpainting on Landscapes (DEVIL) benchmark, which includes a dataset with labeled content attributes and a comprehensive evaluation scheme. The DEVIL dataset contains source videos labeled with camera and background scene motion attributes, and occlusion masks labeled with foreground displacement, pose motion, and size attributes. The DEVIL evaluation scheme constructs dataset slices with fixed content attributes and evaluates inpainting quality using metrics that capture reconstruction performance, realism, and temporal consistency. The benchmark is used to analyze seven state-of-the-art video inpainting methods, providing the most comprehensive and fine-grained evaluation to date. The results of the analysis highlight the importance of modeling time and optical flow and the sensitivity of performance rankings to metrics and content attributes. The benchmark serves as a valuable tool for video inpainting research, enabling insightful analysis and identifying systematic errors in existing methods.