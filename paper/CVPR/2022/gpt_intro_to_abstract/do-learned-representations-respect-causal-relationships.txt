This paper addresses the problem of determining whether attribute-specific learned representations in computer vision systems respect the underlying causal relationships between attributes. The authors propose a learning-based approach called Neural Causal Inference Net (NCINet) for observational causal discovery from high-dimensional representations. They also develop an experimental protocol to evaluate the causal relations between attributes using existing datasets that can be controllably resampled. The contributions of this work include the introduction of NCINet, which exhibits better causal inference generalization than existing approaches, and observations on the causal consistency of attribute-specific learned representations. The paper highlights the importance of identifying causal relations in representations to mitigate unintended consequences such as bias and privacy concerns in computer vision systems.