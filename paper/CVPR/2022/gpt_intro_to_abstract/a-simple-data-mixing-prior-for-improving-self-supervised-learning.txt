Data mixing is a widely used technique for improving recognition models. It involves training models on combinations of images and their labels. While data mixing has shown significant improvements in supervised learning, it has played a limited role in self-supervised learning. Existing efforts in data mixing have mainly focused on Convolutional Neural Networks (CNNs) and have not been able to improve Vision Transformers (ViTs). In this paper, we propose a generic training strategy called Simple Data Mixing Prior (SDMP) that aims to enhance self-supervised representation learning for both CNNs and ViTs. We observe that mixed images created with data mixing are inherently related in pairs, and this relationship can be used as additional positive samples for self-supervised learning. SDMP considers the relationships between the source images, the mixed counterparts, and the mixed samples, and further enhances the representation learning with semantically weighted loss. Our empirical results show that SDMP improves the accuracy and robustness of self-supervised learning frameworks on various visual benchmarks. Notably, SDMP is the first strategy that enables data mixing to improve self-supervised ViTs. We hope the insights and results presented in this work will be useful for future studies on data mixing in self-supervised learning.