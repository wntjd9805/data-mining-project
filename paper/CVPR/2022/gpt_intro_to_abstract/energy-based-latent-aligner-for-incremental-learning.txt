Learning experiences in the real-world often require models to incrementally learn new capabilities over time. Incremental Learning (or continual learning) is a paradigm that aims to train a model at each time step, such that it can solve a continuum of tasks introduced to it throughout its lifetime. However, traditional incremental learning approaches face challenges such as catastrophic forgetting, where the model's performance on previous tasks degrades when learning new tasks. To address this problem, existing approaches use regularization-based methods, exemplar replay-based methods, or dynamically expanding models. In this paper, we propose a novel approach called ELI (Energy-based Latent Aligner for Incremental Learning) that minimizes the representational shift in the latent space of an incremental model using a learned energy manifold. This energy modeling approach helps alleviate the issue of catastrophic forgetting.In our proposed methodology, after learning a new task, the features from the feature extractor of the previous task data drift in the latent space. To overcome this, we learn an energy manifold where the latent representations of the current task have higher energy, while the latents from the previous task have lower energy. This allows us to transform the previous task latents to alternate locations in the latent space, undoing the representational shift and alleviating forgetting.We demonstrate the effectiveness of our approach through experimental evaluation on large-scale classification datasets such as CIFAR-100, ImageNet subset, and ImageNet 1k, as well as the Pascal VOC object detection dataset. We compare our approach against three prominent class-incremental methods (iCaRL, LUCIR, and AANet) and the state-of-the-art incremental Object Detector (iOD). ELI consistently improves performance across all datasets and methods, achieving impressive gains in incremental object detection.In summary, our work introduces a novel methodology, ELI, that addresses the representational shift problem in the latent space of incremental learning models. It can be easily integrated into existing incremental classifiers and object detectors without requiring changes to their methodology. ELI demonstrates consistent improvements in large-scale incremental classification tasks and outperforms the state-of-the-art incremental object detector.