Local image descriptors, such as keypoints, play a vital role in various computer vision tasks. Traditionally, handcrafted keypoints like SIFT and ORB have been used, but learning-based approaches have shown superior results. However, these approaches rely on ground-truth pixel correspondences, which are obtained through Structure-from-Motion (SfM) reconstructions. This reliance on ground-truth data limits the scalability and applicability of these methods. In this paper, we explore the potential of unsupervised image pairs, where no ground-truth correspondences are available. We propose an unsupervised learning approach for local descriptors, based on two key matching priors: local consistency and uniqueness. We enforce these priors using a pyramidal non-parametric module, which extracts higher-level correspondences. We also introduce a new unsupervised loss, named PUMP, and train our approach on synthetic image pairs. Experimental results demonstrate the effectiveness of our method, outperforming state-of-the-art approaches on various tasks and benchmarks. Our contributions include revisiting the notion of matching priors, introducing the PUMP loss, and showing the superiority of our approach in terms of performance and amount of required supervision.