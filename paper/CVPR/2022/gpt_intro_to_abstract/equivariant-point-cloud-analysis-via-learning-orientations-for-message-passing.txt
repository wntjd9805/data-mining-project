This abstract introduces a new framework for equivariant point cloud analysis, which addresses the challenge of preserving invariance and equivariance for 3D point cloud data. The existing message passing networks for modeling point clouds lack equivariance to the rotation of point clouds. Two notable lines of methods have been proposed to address this problem: tensor field-based neural networks and vector-based neural networks. However, tensor field-based networks suffer from high space and time complexity, while vector-based networks are limited in modeling essential geometric relationships. To overcome these limitations, the authors propose a novel equivariant message passing model by learning the orientation of each point during the message passing process. This model decouples the relative position of two points from global rotations and integrates the projected relative position difference into neural messages. The authors demonstrate that their method is simpler and more flexible compared to previous equivariant models. The main contributions of this work include the proposal of the new framework for equivariant point cloud analysis, its generality by augmenting classical point cloud networks, and extensive experiments showcasing competitive performance in various point cloud tasks. This research has implications for computer vision and other science domains.