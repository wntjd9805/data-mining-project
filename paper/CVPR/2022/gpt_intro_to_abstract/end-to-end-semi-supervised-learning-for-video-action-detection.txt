In this paper, we address the challenge of video action detection, which involves spatio-temporal localization in videos. Annotating each frame is a time-consuming and costly task, making it difficult to obtain large-scale datasets for this problem. To tackle this issue, we propose a semi-supervised learning approach that utilizes a small set of annotated samples along with several unlabeled samples. This is the first work that focuses on semi-supervised learning for video action detection.Semi-supervised learning has been successful in image classification, and some recent works have explored it in object detection. We utilize two main approaches for semi-supervised learning: pseudo-labeling, which requires several iterations, and consistency regularization, which relies on single-step training. Due to the computational expense of training a video action detection model, we propose a consistency-based approach for an efficient solution.In our approach, we consider two different consistency constraints: classification consistency and spatio-temporal localization consistency. While classification consistency has been found effective, extending it to the video domain for spatio-temporal consistency is challenging. To address this, we propose a simple formulation for spatio-temporal consistency, computed for each pixel in the video. However, this approach fails to capture any temporal constraints. To overcome this, we explore temporal continuity of actions in videos and investigate two ways to capture motion continuity: temporal coherence and gradient smoothness.Our proposed method is trained end-to-end using both labeled and unlabeled samples and does not require any iterations, making it efficient. We evaluate the effectiveness of our approach on two different datasets, UCF101-24 and JHMDB-21, and demonstrate competitive performance compared to fully-supervised methods and outperforming weakly-supervised approaches. Additionally, we demonstrate the generalization capability of our method on Youtube-VOS for video object segmentation.In summary, our contributions in this work include proposing a simple end-to-end approach for semi-supervised video action detection, investigating two different consistency regularization approaches, and proposing two novel regularization constraints for spatio-temporal consistency. Our method shows promising results and opens avenues for further research in semi-supervised learning for video action detection.