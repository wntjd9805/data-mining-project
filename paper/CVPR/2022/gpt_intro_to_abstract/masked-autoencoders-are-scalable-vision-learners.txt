This paper introduces a simple and effective approach called Masked Autoencoder (MAE) for visual representation learning. The MAE masks random patches from an input image and reconstructs the missing patches in the pixel space using an asymmetric encoder-decoder design. The encoder operates only on visible patches, while the decoder is lightweight and reconstructs the input from the latent representation along with mask tokens. This design allows for a high masking ratio, optimizing accuracy while reducing overall pre-training time and memory consumption. The MAE achieves improved generalization performance on tasks such as object detection, instance segmentation, and semantic segmentation, outperforming supervised pre-training approaches. The paper also discusses the differences between autoencoding methods in natural language processing (NLP) and computer vision, addressing architectural differences, information density variations, and the role of the decoder in reconstructing text and images. The results demonstrate the effectiveness and scalability of the MAE in learning high-capacity models that generalize well. The paper concludes by highlighting the potential of self-supervised learning approaches in computer vision and their alignment with successful methods in NLP.