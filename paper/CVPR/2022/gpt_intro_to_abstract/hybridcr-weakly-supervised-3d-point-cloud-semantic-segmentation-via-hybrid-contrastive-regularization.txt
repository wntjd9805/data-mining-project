Learning the semantic meanings of large-scale point clouds is a crucial task for intelligent machines to understand complex 3D scenes. Existing deep learning methods for point cloud semantic segmentation heavily rely on labeled data, which is time-consuming and labor-intensive to annotate. To address this issue, we propose to explore weakly-supervised learning to enhance data efficiency and reduce annotation efforts. Several weakly-supervised semantic segmentation methods for 3D point clouds have emerged, including consistency regularization, pseudo labeling, and contrastive pre-training. However, these methods have certain limitations, such as not fully considering the semantic properties of neighboring points and global characteristics of 3D classes, sub-optimal learning due to fixed data augmentation, and the involvement of multiple training stages. To overcome these shortcomings, we propose a new paradigm called hybrid contrastive regularization (HybridCR) that leverages both consistency and contrastive properties in label space and feature space. We combine pseudo labeling and consistency regularization in an end-to-end training scheme for large-scale point clouds. Additionally, we redesign the positive and negative anchor point pairs to better use contrastive information. We introduce a dynamic point cloud augmentor to provide transformations for both consistency and contrastive regularization. Our proposed HybridCR framework achieves state-of-the-art performance on indoor and outdoor scene datasets, demonstrating the effectiveness of our approach. The contributions of this paper include the introduction of HybridCR, the use of local and global guidance contrastive regularization, the design of a dynamic point cloud augmentor, and the significant improvements in performance compared to existing weakly-supervised methods.