Visual geo-localization (VG) is a widely studied area in computer vision and robotics research. It involves recognizing the geographical location of a photo by comparing it to a database of geo-tagged images. However, current VG datasets are limited in their geographical coverage and sparsity, which hinders their representativeness for real-world large-scale applications. Additionally, training models on massive databases is challenging due to the computational cost of mining negative examples. In this paper, we introduce the San Francisco eXtra Large (SF-XL) dataset, which is significantly larger and denser than existing datasets. We propose a novel training approach called CosPlace, which uses a classification task to extract discriminative descriptors for retrieval without the need for mining negative examples. Experimental results demonstrate that CosPlace significantly reduces GPU memory usage and outperforms state-of-the-art methods, while using smaller embeddings and generalizing better to other datasets.