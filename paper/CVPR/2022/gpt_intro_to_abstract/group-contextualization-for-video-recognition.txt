Abstract:Video signals possess a 3D spatio-temporal nature that allows for flexible analysis from different perspectives. However, existing methods for feature contextualization in video recognition often lack versatility and can be computationally burdensome. In this paper, we propose a novel feature contextualization paradigm called group contextualization (GC) that addresses these limitations. The GC module decomposes video features into multiple groups and applies different contextualization operations on each group. This allows for the integration of feature dynamics from different perspectives and enables recognition of a wide variety of activities. Additionally, the use of group convolution reduces computational overload. We demonstrate the effectiveness of the GC module by applying it to various feedforward video networks and achieving significant performance improvements.