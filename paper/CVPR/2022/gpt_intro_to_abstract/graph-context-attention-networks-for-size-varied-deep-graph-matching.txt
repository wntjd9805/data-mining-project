Graph matching is a challenging problem in computer science with various real-world applications. Deep learning methods have shown superior performance in graph matching tasks compared to traditional approaches. These methods typically involve extracting node features using convolutional neural networks (CNNs) and utilizing graph embedding networks to capture intrinsic graph structure and improve node differentiation. Additionally, transformer-based models have gained attention for their ability to capture relationships between different elements. In this paper, we propose a novel Graph-context Attention Network that combines the advantages of graph convolutional neural networks and transformer models to capture both intra-graph and inter-graph node relationships. We also address the combinatorial problem of graph matching by formulating it as an Integer Linear Programming problem. We demonstrate the effectiveness of our approach in supervised and unsupervised settings, achieving higher accuracy than state-of-the-art methods. We evaluate our approach on various tasks, including keypoint matching with different graph sizes and a vessel graph matching task, and show its superiority.