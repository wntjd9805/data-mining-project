Deep neural networks (DNNs) have been found to be vulnerable to adversarial examples, and many attack algorithms have been proposed for various tasks. However, the security of DNNs applied to spherical images has been largely ignored. With an increasing number of computer vision problems involving spherical signals, such as omnidirectional RGB-D images and 360-degree videos, there is a need to investigate the vulnerability of DNNs used for spherical images. This paper proposes a black-box attack method, called 360-attack, that generates adversarial spherical images by disturbing their planar perspective-view representations. A novel distortion-aware iterative fast gradient sign method is proposed to obtain highly transferable adversarial images, considering the perturbation degradation caused by projection distortion. A spherical-spectrum-based saliency detection method and a saliency-aware fusion strategy are also introduced. Experimental results demonstrate the effectiveness of the proposed attack on DNNs designed for spherical images and confirm the transferability of adversarial perturbations from 2D to 3D.