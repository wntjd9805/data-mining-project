Creating rich, animated characters traditionally involves drawing each frame independently. To speed up this process, tools have been developed for rendering 2D characters in different poses by manipulating a rigged structure. Artists often create rigs by drawing various poses and configurations of the character in sprite sheets, manually segmenting common parts and stitching them together to form the final rig. These parts can also be used as assets to create new character rigs.Automatic rigging methods face unique challenges, as animated characters can have different limbs, accessories, and viewing angles, making a single template ineffective for all characters. Additionally, the lack of available examples for rigged characters complicates the process, especially since characters are often drawn and animated in different styles. Extracting articulated parts from poses shown in sprite sheets requires analyzing the motion demonstrated.This paper proposes a method for automatically constructing a 2D character rig from a sprite sheet with a few examples of the character in different poses. The rig is represented as deformable layers, each capturing an articulated part. The method involves learning a deep network to compute correspondences between sprites, using these correspondences to determine possible segmentations for each sprite, and reconstructing the other sprites in the sheet with minimal reconstruction error.The paper evaluates the proposed method using various test sprite sheets, demonstrating its ability to produce articulated parts and outperforming other co-part segmentation works. The contributions of this paper include a method for analyzing sprite sheets and creating articulated characters for animation, a neural architecture for predicting pixel motions and clustering pixels into articulated parts without relying on a known character template, and an optimization algorithm for selecting the character parts that best reconstruct the given sprite poses.