Deep learning algorithms have greatly advanced the field of semantic segmentation. However, training these algorithms requires a large number of accurately labeled pixels, which is time-consuming and resource-intensive. To address this issue, researchers have explored weakly supervised semantic segmentation methods, including those based on bounding boxes, scribbles, points, and image-level labels. Among these, image-level labels are more popular due to their ease of collection. In this paper, we focus on weakly supervised semantic segmentation based on image-level labels.One key component of weakly supervised semantic segmentation is the class activation map (CAM), which provides information on both the location and semantics of target objects. CAMs can be used as pseudo pixel-level annotations for training segmentation networks. To improve the quality of CAMs, various strategies have been proposed, including adversarial erasing, online attention accumulation, seed region expansion, and affinity learning. However, most existing methods use the entire input image as the sole input to the model. Empirical observation suggests that classification models can discover more discriminative regions when using local image patches as input, leading to potentially better attention maps.In this paper, we propose a method that leverages attention maps from local network views with rich details to train a global network. This approach allows the global network to learn rich local details from the local network online, leading to more comprehensive object attentions. Our experimental results demonstrate that incorporating local image patches can improve the quality of attention maps, thereby enhancing the performance of weakly supervised semantic segmentation.