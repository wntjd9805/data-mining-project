This paper introduces the task of video object segmentation referred by natural language expressions, known as Referring Video Object Segmentation (RVOS). RVOS is a challenging task that requires identifying target objects based on free-form expressions in video frames. This task has applications in language-based video editing, video summarization, and video question answering. The key challenges in RVOS are spatial-temporal interaction and cross-modal alignment. Current methods focus on cross-modal alignment but have limitations on spatial-temporal interaction due to the reliance on 3D Convolutional Neural Networks (ConvNets). Aggregating spatially misaligned features using 3D operators can lead to inaccurate segmentation results. To address this issue, the proposed Language-Bridged Duplex Transfer (LBDT) module establishes explicit interaction between spatial and temporal features in the encoding phase. The LBDT module utilizes the referring words as a medium to transfer language-relevant motion and appearance information between encoders. Additionally, a Bilateral Channel Activation (BCA) module is proposed to leverage hierarchical visual features and filter out language-irrelevant information in the decoding phase. The proposed method outperforms previous methods on RVOS benchmarks while consuming significantly less computational overhead. The contributions of this paper include the LBDT module for spatial-temporal interaction and the BCA module for language-based denoising of features.