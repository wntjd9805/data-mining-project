This paper addresses the challenges posed by the presence of hair in portrait images for digital hair design and 3D face reconstruction. Existing methods for hair design often result in problems due to mixing old and new hair or require error-prone techniques. Similarly, 3D face reconstruction methods struggle with the hair in front of the face, leading to noticeable artifacts in the reconstructed face. Image inpainting methods and exploration in StyleGAN's latent space have allowed for manipulation of facial attributes but fail to remove hair while preserving facial identity. The lack of a dataset of paired portraits with and without hair, difficulties in dataset preparation, and the complexity of hair removal further hinder progress. To overcome these challenges, this paper proposes a hair manipulation method that effectively removes hair from portraits while preserving facial semantics and quality. The authors present different pipelines for generating paired latent codes with and without hair for males and females, enabling hair removal while maintaining facial identity. The resulting method combines Poisson editing to blend the mapped portrait with the original portrait. The experiments demonstrate high-quality results for portraits of different ages and genders, and user studies indicate satisfaction with the outputs. The contributions of this paper include the automatic removal of hair from real portrait images while preserving facial identity, the development of a pipeline for generating bald female data in the StyleGAN latent space, and the creation of a dataset containing 6,000 high-quality portrait images with hair removed.