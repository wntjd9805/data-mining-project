Convolutional Neural Networks (CNNs) have shown remarkable progress in single image deraining. However, these CNN models come with high computational costs and bulky memory usage, limiting their applications in real scenarios, especially on devices with constrained computing capacity. To address this issue, various approaches have been proposed for compressing CNN models, such as quantization, pruning, and distillation. However, these approaches typically require access to the original training data, which is often not accessible due to storage, privacy, or transmission constraints. In this paper, we propose a novel data-free deraining model compression framework that leverages the statistical priors learned from pre-trained networks. Our method reconstructs diverse and in-distribution degraded images to provide sufficient supervision for the compressed model without the need for the original data. We employ two branches in the optimization process, one for reconstructing degraded images and the other for distilling the pruned model. We also propose an adaptive pruning scheme to determine the hierarchical sparsities and moderate the statistical drift of the pruned model before fine-tuning. Experimental results on various deraining datasets show that our method can compress about 40% FLOPs of state-of-the-art models while maintaining comparable performance without the original data.