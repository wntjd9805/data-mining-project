This paper introduces the JRDB-Act dataset, a large-scale dataset captured from a mobile robot platform, containing dense spatio-temporal individual action and social group annotation. The dataset provides new annotations for atomic human actions, social group labels, and social activity inference. It also includes difficulty level annotations to facilitate reliable evaluation. The sequences in JRDB-Act are captured from daily-life scenarios in an unconstrained environment, reflecting the highly unbalanced distribution of human actions in real-world scenarios. The dataset poses challenges due to the diverse levels of human population density and the robot motion. The paper proposes an end-to-end trainable pipeline for individual action and social group detection using the JRDB-Act dataset, incorporating novel features and loss functions. The proposed method also addresses the challenge of the unbalanced nature of action labels. Overall, JRDB-Act offers means to study new problems and challenges in human understanding for computer vision and robotics.