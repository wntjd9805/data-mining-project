Diffusion models have emerged as a promising family of generative models for image synthesis. These models offer advantages such as stable training, scalability, and good distribution coverage. While diffusion models have shown promise in class-conditional image generation, the unconditional generation of single models still has room for improvement and has not been explored extensively for high-resolution datasets. Diffusion models generate images by progressively removing noise, learning the reverse of a predefined diffusion process. Training involves optimizing denoising score matching losses for various noise levels to learn the recovery of clean images from corrupted ones. Previous works have used a weighted sum of losses as the objective function, which has proven effective in improving sample quality. However, the underlying reasons for the success of this weighting scheme are not well understood, and the design of a better weighting scheme to enhance sample quality has not been explored.This paper aims to explore a more appropriate weighting scheme for the objective function of diffusion models. However, designing a weighting scheme is challenging due to the large number of noise levels and the lack of clarity regarding the information learned by the model at each level. The authors investigate what a diffusion model learns at each noise level and propose a perception prioritized (P2) weighting scheme. This scheme assigns higher weights to levels where the model learns perceptually rich content and minimal weights to levels where the model learns imperceptible details.The effectiveness of the proposed P2 weighting scheme is validated through experiments on various datasets. Diffusion models trained with P2 weighting consistently outperform models trained with the previous standard objective. State-of-the-art performance is achieved on datasets such as CelebA-HQ and Oxford-flowers, and comparable performance is obtained on the FFHQ dataset. The authors also analyze the efficacy of P2 weighting for different model configurations and sampling steps.The contributions of this paper include the introduction of a simple and effective weighting scheme to promote the learning of rich visual concepts in diffusion models, an investigation into the learning of visual concepts at different noise levels, and consistent improvements in diffusion models across various datasets, model configurations, and sampling steps.