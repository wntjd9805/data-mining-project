Space-time video super-resolution (STVSR) is a task that aims to enhance the spatial and temporal resolutions of low-frame-rate and low-resolution videos. This task is essential in various multimedia applications such as video compression, video streaming, and video conferencing. However, existing STVSR approaches are not real-time and lack computational efficiency. This paper proposes a Real-time Spatial Temporal Transformer (RSTT) model that simultaneously increases spatial and temporal resolutions without explicitly separating the tasks. The RSTT model utilizes a cascaded UNet-style architecture that incorporates spatial and temporal information for synthesizing high-frame-rate and high-resolution videos. It also introduces a novel encoder-decoder design, where dictionaries are built at different resolutions to directly reconstruct high-resolution frames. The paper presents three RSTT models with varying sizes, demonstrating that RSTT achieves comparable performance to state-of-the-art STVSR methods while being significantly smaller and faster. In particular, RSTT-S achieves a frame rate of over 24 frames per second and outperforms existing methods with a significant speedup. Overall, this paper presents a novel approach for real-time STVSR that combines spatial and temporal transformations in a single model, achieving a balance between computational efficiency and visual quality.