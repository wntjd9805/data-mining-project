Few-shot learning (FSL) methods are essential for learning representations with limited training data, particularly in situations where obtaining large labeled datasets is challenging. This is particularly relevant in domains such as rare medical conditions, rare animal species, and failure cases in autonomous systems. FSL methods typically learn from a fixed set of base classes with ample labeled data and then adapt the learned model to novel classes with only a few training examples. Many FSL methods leverage a prototype-based classifier, which aims to find a prototype for each novel class that is close to the testing samples of the same class and far away from samples of other classes. However, estimating a representative prototype from few available support samples is challenging. To enhance the representativeness of the prototype, this paper proposes the use of textual semantic embeddings learned via natural language processing (NLP) models. These embeddings associate class names with class-representative semantic attributes, providing strong priors for category recognition. While current FSL methods focus on adaptively leveraging semantic information to complete the biased prototype estimated from few available samples, this paper proposes a novel FSL method to obtain class-representative prototypes. Inspired by zero-shot learning methods, the proposed method generates visual features using a variational autoencoder (VAE) model conditioned on the semantic embedding of each class. The VAE model learns to associate a distribution of features with a conditioned semantic code, allowing it to generate novel-class features that align with real unseen features. The generated features, combined with the few-shot samples, are used to construct class prototypes. The proposed method achieves state-of-the-art results on both miniImageNet and tieredImageNet datasets, particularly in 1-shot scenarios. To further enhance the representativeness of the prototype, the VAE is guided to generate more representative samples by selecting only representative data from the base classes during training. The trained VAE model outputs representative samples due to its training on a set of representative data. Experimental results demonstrate the effectiveness of this approach. Overall, the main contributions of this paper are the use of a VAE-based feature generation approach conditioned on class semantic embeddings and a novel sample selection method for collecting representative samples. The proposed methods achieve state-of-the-art performance on challenging datasets and are thoroughly evaluated through various analyses.