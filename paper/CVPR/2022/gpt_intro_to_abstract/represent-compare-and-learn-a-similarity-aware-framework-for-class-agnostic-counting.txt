This paper introduces a generic similarity-aware framework for class-agnostic counting (CAC) in computer vision. The goal of CAC is to count objects of arbitrary categories given only a few exemplars, without relying heavily on training data. Existing CAC methods work in an extract-and-match pipeline, but they often yield unsatisfactory matching results. To address this issue, the authors propose a novel framework that jointly learns feature representation and similarity metric in an end-to-end manner. The framework instantiates a bilinear matching network (BMNet) that extends the fixed inner product to a learnable bilinear similarity metric. This allows for flexible interactions among feature channels to capture similarity. They further extend BMNet to BMNet+ to improve the core aspects of the framework by representing instances via self-similarity, dynamically comparing similarity, and learning with explicit similarity-aware supervision. Experiments on the FSC147 benchmark dataset demonstrate that the proposed method outperforms state-of-the-art approaches, showing significant improvements in terms of mean absolute error. The authors also validate the effectiveness of BMNet+ through ablation studies and demonstrate the cross-dataset generality of their models on the CARPK car counting dataset.The contributions of this paper are twofold: (1) a generic CAC framework that incorporates existing pipeline methods while also generalizing it with joint representation learning and similarity learning, and (2) the instantiation of BMNet and BMNet+ models within the framework, which effectively capture packed similarity for object counting.