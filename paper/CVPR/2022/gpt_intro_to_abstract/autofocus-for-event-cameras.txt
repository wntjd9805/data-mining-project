This paper introduces a novel neuromorphic vision sensor called an event camera, which has gained significant attention in various applications due to its high dynamic range and low latency. The focus control (FC) of event cameras is crucial for reliable perception in robotics and computer vision. However, conventional autofocus (AF) methods designed for frame-based cameras are not applicable to event cameras due to the fundamental differences in data modality, noise, and temporal resolution. This paper addresses the challenges faced in developing AF methods specific to event cameras, including focus measure function, data modality, noise, and handling large data sizes in real-time. The paper proposes a novel event-based autofocus framework that utilizes a focus measure function based on the statistics of event rate (ER) and a robust event-based golden search (EGS) to find the optimal focal position. The contributions of this work include the proposal of the event-based focus measure (ER), a robust and efficient AF method for event cameras, and the creation of an event-based autofocus dataset (EAD) for evaluation and comparison. Extensive evaluations and comparisons on EAD and real-world scenarios demonstrate the effectiveness and efficiency of the proposed framework.