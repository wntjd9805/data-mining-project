This paper introduces a tracking system called PHALP (Predicting Human Appearance, Location and Pose for tracking) that focuses on 3D object tracking in computer vision. The system uses parameterized 3D models and deep learning techniques to lift 2D image observations to the 3D world. The paper discusses the challenges of tracking in 2D versus 3D and presents experimental evidence that performance is better with 3D representations. The authors develop a system that recursively updates the estimated state of a person, including appearance, location, and pose, based on observed RGB pixels in 2D. The system uses a dynamic model to predict future states and solves the association problem between detections and predictions in each frame. The paper highlights the importance of persistence in tracking even during periods of occlusion. The authors note that advancements in deep learning and big data enable the successful implementation of the proposed system in 2022. The PHALP system aggregates and predicts representations over time and associates them with detections using a probabilistic interpretation and the Hungarian algorithm. The final output is an identity label for each detected bounding box in the video. The system can also be applied to videos with shot changes with minor modifications. Overall, this paper presents a comprehensive approach to 3D object tracking in computer vision using deep learning and parameterized 3D models.