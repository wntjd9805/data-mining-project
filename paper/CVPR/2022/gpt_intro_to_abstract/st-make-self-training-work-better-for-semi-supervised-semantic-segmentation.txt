Fully-supervised semantic segmentation requires pixel-wise manual labeling of numerous images, which is costly and labor-intensive. To address this issue, semi-supervised semantic segmentation has been proposed, which learns from a few labeled images and a large amount of unlabeled images. Previous works in semi-supervised learning have utilized techniques such as entropy minimization and consistency regularization. However, in this paper, the authors present two simple and effective techniques to reintroduce the classical self-training method as a strong competitor. The first technique involves injecting strong data augmentations (SDA) on unlabeled images, which decouples predictions and reduces overfitting on noisy pseudo labels. The authors find that the SDA approach is compatible with off-the-shelf augmentation strategies in contrastive learning. The second technique, called ST++, addresses the issue of different reliability of pseudo labels by prioritizing more reliable images for re-training. This is done based on the stability of evolving pseudo masks during the training process. The authors demonstrate that their ST and ST++ frameworks outperform previous methods in semi-supervised semantic segmentation on the Pascal and Cityscapes datasets with few hyperparameters.