This paper introduces a novel approach called Comprehending and Ordering Semantics Networks (COS-Net) for image captioning. The task of image captioning aims to generate visually-grounded and linguistically coherent descriptions of visual content. Current image captioning techniques focus on enhancing vision-language alignment by capturing fine-grained semantics through pre-trained object detectors. However, these detectors have limited semantic comprehension capabilities and are not optimized for sentence decoding. To address these limitations, the authors propose a semantic comprehender and ranker that refines primary semantic cues and orders them linguistically. They also leverage a cross-modal retrieval model to retrieve relevant sentences and generate salient semantic words. A Transformer-style encoder-decoder structure is designed to jointly optimize the semantic comprehender and ranker for sentence decoding. Experimental results demonstrate the effectiveness of COS-Net in generating accurate and enriched image captions.