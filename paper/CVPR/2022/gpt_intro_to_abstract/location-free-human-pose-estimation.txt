Human pose estimation, also known as keypoint localization, is a challenging task in computer vision. Recent advancements in convolutional neural networks (CNNs) have led to significant progress in this area. However, collecting high-quality and fine-grained annotations for training data is labor-intensive and time-consuming. In this paper, we explore keypoint localization when only image-level category labels are given. We propose a novel approach called LOcation-FRee (LOFR) HPE, which is built upon the Class Activation Mapping (CAM) method. CAM discovers object regions from intermediate classifier activation using only image-level labels, but it struggles with localizing subtle joints. Our method overcomes this limitation by incorporating more contextual information and explicit spatial cues. We introduce a customized transformer-based architecture that captures global contextual information and precise spatial features. We also leverage the structural relations between joints to eliminate location confusions. Our experiments demonstrate that our location-free approach achieves comparable or even superior results compared to supervised methods when limited location labels are provided. Additionally, we introduce a multi-scale spatial-guided context encoder, a relation-guided pose decoder, and a part diversity constraint to enhance the performance and distinguish part-aware features. Overall, this paper makes significant contributions by developing a location-free HPE method, improving context encoding, and leveraging spatial relations between keypoints.