Deep learning has revolutionized computer vision tasks, particularly image classification. However, the success of deep learning models heavily relies on large-scale labeled training data, which is often expensive and time-consuming to obtain. To address this issue, the field of semi-supervised learning (SSL) has emerged, aiming to achieve good model generalization using limited labeled data and a large amount of unlabeled data that follows the same distribution. Current SSL methods commonly rely on deep models to learn feature representations that aid in subsequent classification. Techniques such as self-training and consistency regularization have been widely used and have shown promising results. However, these techniques are not optimal on their own, leading to a combination of different approaches. The prevailing strategy involves combining self-training and consistency regularization, enforcing both cluster and smoothness assumptions simultaneously to improve model performance. Despite these advances, existing SSL methods often employ confidence filtering to discard weakly predicted samples, assuming that only highly confident samples are useful. In this work, we propose a novel framework called Taylor expansion inspired filtration (TEIF) to address this limitation. TEIF utilizes the Taylor expansion of the loss function to select moderately confident samples based on their similarity to labeled and highly confident unlabeled samples in terms of features and gradients. We introduce two novel filters, gradient synchronization filter (GSF) and prototype proximity filter (PPF), which leverage gradient dynamics and feature prototypicality, respectively. Our methods are integrated into SSL frameworks with confidence filtering, and experimental results on commonly used SSL benchmarks demonstrate that our methods outperform existing approaches such as FixMatch. Our contributions include providing answers to previously raised questions regarding the usefulness of moderately confident samples and proposing a novel framework and filters that enhance SSL training and improve model performance.