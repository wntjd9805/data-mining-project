This paper addresses the issue of visual distortions, known as the rolling shutter effect, in CMOS cameras equipped with rolling shutter mode. These cameras are widely used in consumer photography, automotive sector, and motion picture industry. The rolling shutter mode exposes pixels in a sequential manner, leading to undesirable distortions in the presence of fast motion. To overcome this, video frame interpolation (VFI) techniques have been developed, but they assume a global shutter mechanism and fail to produce satisfying in-between frames with rolling shutter video.To address this problem, previous research has focused on correcting the rolling shutter effect using methods that recover intermediate frames from two consecutive rolling shutter frames. However, these methods have limitations in accurately reflecting camera motion and scene geometry, resulting in artifacts and ghosting effects. Recent deep learning-based solutions have shown promising results, but they can only recover one intermediate frame corresponding to a specific scanline.In this paper, the authors propose a method that aims to revive and relive all latent views of a scene as seen by a virtual global shutter camera. This involves joint handling of VFI and rolling shutter correction tasks to interpolate smooth and distortion-free video sequences. The authors introduce a novel approach based on contextual aggregation and motion enhancement using bilateral motion fields (BMF). Their proposed Context-aware Video Reconstruction (CVR) architecture consists of two stages: an initialization stage that estimates the initial bilateral motion field and a refinement stage that handles black holes and occlusions caused by complex motion patterns.The authors demonstrate that their method outperforms previous state-of-the-art methods in removing rolling shutter artifacts and generating high-fidelity global shutter videos. The main contributions of this paper are the proposed bilateral motion field approximation model for initialization, the development of a context-aware video reconstruction framework, and the demonstration of efficient network design.