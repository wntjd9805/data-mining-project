Instance segmentation is a challenging task in computer vision that involves the segmentation of all objects within an image. It has numerous applications in autonomous driving, surveillance systems, and medical imaging. Recent advancements in training high capacity models with large amounts of mask annotations have led to impressive results in segmentation. Most methods employ a two-stage object detection architecture, integrating a mask head to segment objects within box proposals. However, these approaches require costly mask annotations for every class, making it difficult to scale up to hundreds or thousands of classes. To address this limitation, this paper aims to reduce the amount of mask supervision needed by leveraging low-cost captioned images to segment novel classes. Partially supervised learning has been widely used to increase the number of segmentation classes by utilizing weak image-level or box-level supervision. While effective for certain classes, these methods are limited to the classes covered by the annotations and are not suitable for a wide range of novel classes. Zero-shot instance/semantic segmentation, on the other hand, focuses on segmenting novel classes without any training samples, using high-level semantic descriptions such as word embeddings. However, current zero-shot approaches suffer from low performance on novel classes due to the inability of word embeddings to effectively capture fine-grained shape information.To overcome these limitations, this paper proposes a cross-modal pseudo-labeling framework that aligns textual and visual modalities in captioned images to create caption-driven pseudo masks. The framework trains a teacher model on base classes and uses it to select object regions that are most compatible with the semantics of words in captions. These regions are then segmented into pseudo masks for the corresponding object words. The pseudo masks are further distilled into a robust student model, which jointly learns segmentation and estimates pseudo-mask noise levels to downweight incorrect teacher predictions. The effectiveness of the proposed method is evaluated on the MS-COCO and Open Images & Conceptual Captions datasets, demonstrating its ability to generalize to truly novel classes.The contributions of this paper include the proposal of a novel cross-modal pseudo-labeling framework that generates caption-driven pseudo masks without requiring instance mask annotations, the ability to work with novel classes by selecting regions compatible with their semantics, the explicit capture of pseudo mask reliability through a robust student model, and extensive experiments on benchmark datasets to demonstrate the effectiveness of the proposed method.