The introduction of this computer science paper highlights the evolution of cell-phones into handheld computational imaging platforms capable of acquiring high-quality images, pose, and depth. It discusses the recent advancements in passive depth imaging and the miniaturization of active depth systems, leading to their integration into modern smartphones. The paper emphasizes the demand for convenient systems to extract 3D information from the world, with smartphones being ideal due to their sensors and affordability. The use of image, pose, and depth data from mobile phones in various applications such as view synthesis, portrait relighting, and video interpolation is explored. The limitations of current mobile phones in providing accurate high-resolution depth from a single snapshot are addressed, and the need for improved depth estimation techniques is emphasized. The paper proposes a pipeline for recording LiDAR depth, image, and pose bundles and introduces an implicit neural representation approach to distill a high-fidelity depth estimate from hand tremor measurements. The contributions of the paper include a smartphone app for capturing synchronized RGB, LiDAR depth, and pose bundles, an implicit depth estimation method, and quantitative and qualitative evaluations showcasing its superiority over existing techniques. The paper concludes by providing access to the app, code, experimental data, and trained models for further exploration.