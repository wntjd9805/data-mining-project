Optical flow is a technique used to analyze motion between video frames and is applied in various real-life applications. Recent advancements in deep learning have improved optical flow estimation by focusing on feature similarities. However, the spatial relations, which reveal the underlying affinities during motion, have been overlooked. Traditional optical flow algorithms consider both feature similarities and spatial smoothness, but deep learning methods mainly rely on feature-matching similarities. In this paper, we propose a novel approach called Kernel Patch Attention (KPA) to explicitly capture local relations and motion affinities for optical flow estimation. Our method combines the advantages of non-local operations and kernel-based operators to effectively model local relations and update motion features. The KPA module is designed to work in a patch-wise manner, reducing computational complexity. We integrate the KPA module into a deep flow model called KPA-Flow and achieve top-ranked performance on benchmark datasets. Our contributions include a fully-differentiable approach for smooth constraint handling, a novel operator for comprehensive optical flow estimation, and state-of-the-art results on popular benchmarks.