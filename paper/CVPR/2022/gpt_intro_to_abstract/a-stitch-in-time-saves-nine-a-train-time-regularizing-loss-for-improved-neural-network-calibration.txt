Deep Neural Networks (DNNs) have shown promising results in pattern recognition tasks. However, these networks often output poorly calibrated confidence scores, leading to incorrect predictions and potential safety risks in critical applications. Previous post-hoc calibration techniques focus on the predicted label, leaving other labels uncalibrated. In this paper, we propose a train-time calibration approach using a novel auxiliary loss function called Multi-class Difference in Confidence and Accuracy (MDCA). Unlike post-hoc methods, our approach utilizes the learnable parameters of the DNN itself, allowing for flexible image and pixel-specific transformations. Experimental results demonstrate the effectiveness of our approach in maintaining calibration under domain shift and dataset imbalance. Our loss function serves as a powerful regularizer, improving model performance on various datasets and tasks including image classification and semantic segmentation. Overall, our approach provides a practical and accurate calibration method for DNNs.