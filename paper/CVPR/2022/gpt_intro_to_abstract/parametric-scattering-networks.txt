The scattering transform, proposed in [29], is a cascade of wavelets and complex modulus nonlinearities, which can be seen as a convolutional neural network (CNN) with fixed, predetermined filters. This construction can be used to build representations with geometric invariants and is shown to be stable to deformations. It has been demonstrated to yield impressive results on problems involving highly structured signals, outperforming a number of other classic signal processing techniques. Scattering transforms have also been studied as mathematical models for understanding the success of CNNs in image classification. Previous research has shown that first-order scattering coefficients are similar to SIFT descriptors, and higher-order scattering can provide insight into the information added with depth. Furthermore, studies on information encoded in scattering networks indicate that they often promote linear separability, leading to effective representations for downstream classification tasks. Scattering-based models have been shown to be useful in applications involving scarcely annotated or limited labeled data. While many breakthroughs in deep learning require large amounts of well-annotated data, there is increasing interest in small-sample learning tasks and deep-learning approaches for such tasks. Recent work has shown that hybrid networks utilizing the scattering transform as early layers followed by learned layers based on a wide residual network architecture achieve state-of-the-art results in image classification. In this paper, we propose using the scattering paradigm as not only fixed preprocessing layers in a concatenated architecture but also as a parametric prior for learning filters in a CNN. This allows us to investigate whether the standard wavelet construction is optimal for building filter banks from a mother wavelet for discriminative tasks. The scattering construction is based on complex wavelets generated from a mother wavelet via dilations and rotations, ensuring the resulting filter bank forms an efficient tight frame with energy preservation properties. However, it has been observed that the first layers of convolutional networks may not necessarily form a tight frame. We aim to relax the standard construction by considering an alternative where a small number of wavelet parameters used to create the wavelet filter banks are optimized for the task at hand.To the best of our knowledge, this is the first work that aims to learn the wavelet filters of scattering networks in 2D signals.