This paper introduces a self-supervised model for learning object states and state-modifying actions from uncurated videos obtained from a video search engine. The model uses the causal ordering in the videos to discover the changing states of objects and state-modifying actions. It supports large-scale learning using stochastic gradient descent and non-linear multi-layer models. To deal with noisy uncurated data, a noise adaptive weighting module is incorporated to filter out irrelevant videos. The module is supervised by still images depicting the object states. To validate the approach, a new dataset called "ChangeIt" is collected, containing over 2600 hours of video and 34 thousand changes of object states. Experimental results show substantial improvements in action and object state localization compared to prior work. The dataset, code, and trained model are publicly available.