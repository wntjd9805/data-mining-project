This paper focuses on the importance of e-commerce images in online shopping and the need for accurate saliency prediction on these images. The authors highlight that existing methods for saliency prediction mostly focus on natural images and are not suitable for e-commerce images, which often contain a combination of pictures and texts. The authors propose the use of a deep neural network called the SSWin-Transformer, which incorporates saliency information and non-local attention mechanisms to improve saliency prediction on e-commerce images. They also introduce the SalECI dataset, the first eye-tracking dataset of e-commerce images, to validate and analyze their proposed framework. The experimental results demonstrate the state-of-the-art performance of their approach, and they also showcase the application of their work in e-commerce image compression. The contributions of this paper include the establishment of the SalECI dataset, thorough analysis of the dataset, and the proposal of a novel multi-task learning framework for saliency prediction on e-commerce images.