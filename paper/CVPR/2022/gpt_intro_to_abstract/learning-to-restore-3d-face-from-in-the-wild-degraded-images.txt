The field of 3D human face reconstruction has seen significant advancements in the past two decades, with applications ranging from human digitalization to animation and biometrics. The 3D Morphable Model (3DMM) was the first major breakthrough in this area, providing a framework for modeling facial geometry. However, 3DMM-based approaches still have limitations, including a limited number of subjects, difficulties in capturing skin details and muscular structures, and large variations in identity.To address these drawbacks, non-parametric modeling techniques have been explored, which directly regress face normals or depths from input images without relying on the assumptions of 3DMM. While these methods capture more detailed facial structures, they often suffer from degradation of appearance due to limited facial clues provided by the input images. This degradation significantly reduces the accuracy of reconstruction.In this paper, we propose a novel Learning to Restore (L2R) 3D face framework that aims to improve 3D face modeling from degraded images. The L2R framework leverages 2D facial priors mined from pretrained Generative Adversarial Networks (GANs) to propagate 3D texture and geometry clues. It encodes input images and albedo proxies to StyleGAN, which provides style codes and spatial prior, respectively. This approach enables L2R to predict diverse clues for modeling realistic 3D albedo and enhance facial details without predefined topology. Additionally, L2R learns high-resolution facial shapes and displacement maps to complement 3D textures and further improve modeling accuracy.Experimental results demonstrate that L2R outperforms state-of-the-art and 2D pre-processed methods in modeling superior texture and geometry from low-resolution images. It achieves competitive results compared to models without degradation. The contributions of this paper include the proposal of the L2R framework for modeling high-quality 3D faces from degraded images in an unsupervised manner. This framework enhances inherent 3D clues on texture and geometry reconstruction by leveraging 2D generative facial priors. Furthermore, a novel albedo restoration network and a geometry refining network are introduced to complement the lack of facial clues and model detailed facial depth, respectively.In summary, this paper presents a novel approach for 3D face modeling that overcomes the limitations of degraded input images. The proposed L2R framework demonstrates promising results in modeling high-quality 3D faces and enhancing texture and geometry reconstruction.