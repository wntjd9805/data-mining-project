Human-Object Interaction (HOI) detection is a crucial task in computer vision, with applications in surveillance event detection and robot imitation learning. Conventional HOI detectors have approached the problem indirectly, formalizing it as regression and classification tasks. This approach requires post-processing and cannot be trained end-to-end, resulting in suboptimal solutions. Recent state-of-the-art HOI detectors have adopted the Transformer-based detector of DETR to directly predict HOI sets in an end-to-end manner. However, these detectors start from randomly initialized embeddings, hindering the exploration of prior knowledge and relational reasoning among interactions.To address these limitations, we propose a novel HOI detection scheme called Structure-aware Transformer over Interaction Proposals (STIP). STIP decomposes the set prediction into two phases: generating interaction proposals and performing HOI set prediction based on these proposals. By using the interaction proposals as non-parametric queries, STIP enables more reasonable interaction queries and improves the correspondence between queries and HOIs.Additionally, the predicted interaction proposals allow for the construction of a structured understanding of interactions, both within individual proposals and across proposals. We design a structure-aware Transformer to encode the inter-interaction and intra-interaction structures, enhancing HOI predictions.Our contributions include: (1) Demonstrating the effectiveness of the two-phase implementation of the Transformer-style HOI detector, which seamlessly incorporates potential interactions among proposals; (2) Introducing the structure-aware Transformer, which leverages inter-interaction and intra-interaction structures to enhance the performance of the vanilla Transformer; (3) Validating the proposed approach through extensive experiments on the V-COCO and HICO-DET datasets, showing its ability to achieve desirable HOI detection results and solve the limitations of one-stage approaches.