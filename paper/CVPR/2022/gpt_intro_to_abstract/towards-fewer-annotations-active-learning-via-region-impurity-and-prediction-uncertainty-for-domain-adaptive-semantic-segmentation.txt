Semantic segmentation is a critical task in computer vision with applications in various fields such as autonomous driving, robotics, and medical analysis. However, training segmentation models requires large amounts of labeled data, which is expensive and time-consuming to obtain. Additionally, ensuring good generalization to diverse testing situations remains a challenge.One promising approach to address these issues is domain adaptation, specifically self-training with pseudo labels. This method re-trains the network using pseudo labels generated from confident predictions on the target domain. However, this approach often suffers from class imbalance, where certain classes appear more frequently than others, leading to biased performance.To overcome this challenge and improve segmentation performance, we propose a simple and effective active learning strategy for adaptive semantic segmentation called Region Impurity and Prediction Uncertainty (RIPU). RIPU selects the most diverse and uncertain image regions to annotate, enhancing the segmentation performance.We introduce two labeling mechanisms, namely Region-based Annotating (RA) and Pixel-based Annotating (PA). RA annotates every pixel in selected regions, while PA focuses on labeling the center pixel within the region to improve labeling efficiency. We also incorporate local stability and negative learning loss to enforce prediction consistency and enhance representation learning.Our experiments using standard segmentation models demonstrate that RIPU significantly improves performance on two domain adaptation benchmarks: GTAV → Cityscapes and SYNTHIA → Cityscapes.In summary, our contributions include benchmarking prior active domain adaptation methods, proposing the RIPU acquisition strategy for adaptive semantic segmentation, and demonstrating significant performance gains in domain adaptation benchmarks.