Inferring structural properties of a scene, such as the relationship between entities, is a fundamental task in computer vision. The visual relationship between two entities can be represented by a triple, and a scene can be modeled as a graph structure called the scene graph. Scene graphs provide a compact representation of the structural information in a visual scene, which is useful for various vision tasks.Scene graph generation (SGG) is the task of effectively and efficiently modeling the relationships between entities in a visual scene. Traditional approaches for SGG have focused on two design patterns: bottom-up two-stage and point-based one-stage. However, these approaches have limitations in terms of computational cost and restrictive assumptions about interaction regions.In this paper, we propose a novel approach called Scene graph Generation TRansformer (SGTR) to address these limitations. Our model formulates SGG as a bipartite graph construction problem, where each relationship triplet is represented as two types of nodes connected by directed edges. We introduce a new transformer-based model that consists of three modules: entity node generator, predicate node generator, and graph assembling module.The entity node generator and the predicate node generator produce entity and predicate nodes using CNN+Transformer sub-networks. To enhance the representations of the predicates, we design a structural predicate generator that incorporates information from entity proposals. We then use a differentiable graph assembling module to infer the directed edges of the bipartite graph, taking into account the entity indicators.We evaluate our method on two SGG benchmarks, Visual Genome and OpenImages-V6 datasets, and compare it with previous state-of-the-art methods. The experimental results demonstrate that our method achieves superior or comparable performance while maintaining high efficiency during inference.The main contributions of our work are three-fold. Firstly, we propose a transformer-based end-to-end SGG model using a bipartite graph construction process, combining the advantages of two-stage and one-stage methods. Secondly, we develop an entity-aware structure that leverages the compositional properties of visual relationships. Finally, our method outperforms or achieves comparable performance to prior SGG methods while being more efficient in inference.