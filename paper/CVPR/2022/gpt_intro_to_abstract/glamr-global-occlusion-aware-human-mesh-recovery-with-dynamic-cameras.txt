Recovering fine-grained 3D human meshes from monocular videos captured by dynamic cameras is a challenging task with many potential applications in virtual or augmented reality, assistive living, and autonomous driving. Existing methods for human mesh recovery often estimate meshes in camera or root-relative coordinates, requiring additional SLAM techniques for global coordinate estimation. However, SLAM can fail in dynamic environments, and severe occlusions in videos further complicate human mesh recovery. In this paper, we propose Global Occlusion-Aware Human Mesh Recovery (GLAMR), which addresses the challenges of severe occlusions and consistent global coordinate estimation. GLAMR utilizes off-the-shelf methods to estimate shape and pose sequences of visible people, and a deep generative motion inﬁller to inﬁll missing motions caused by occlusions. A global trajectory predictor is also introduced to generate global human trajectories based on local body motions. Finally, a global optimization framework is proposed to jointly optimize the global motions and camera poses using video evidence. The contributions of this paper include a novel approach to address long-term occlusions and estimate global 3D human pose and shape, a Transformer-based motion inﬁller outperforming state-of-the-art methods, a method to generate global human trajectories, and extensive experiments demonstrating superior performance in occlusion handling and global human mesh estimation.