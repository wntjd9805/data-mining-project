Scene flow estimation is a crucial task in computer vision, aiming to predict the 3D motion field from consecutive frames. It has various applications, such as robotic navigation and autonomous driving. In the past, scene flow has been estimated from stereo or RGB-D images. However, recent advancements in 3D sensing have allowed for learning scene flow directly from point clouds. Obtaining training data for scene flow estimation is challenging because it requires annotating 3D motion vectors for each point in the scene. One solution is to use synthetic data for training, but this approach faces two major challenges when applied to real-world data: the lack of appropriate synthetic datasets that capture real-world dynamics and the domain gap between synthetic and real data. While there have been studies on unsupervised domain adaptation (UDA) for 2D tasks, little attention has been given to UDA for point clouds and scene flow estimation. This paper addresses these challenges by proposing a synthetic point cloud scene flow dataset and a UDA framework specifically designed for scene flow estimation. The proposed dataset, called GTA-V Scene Flow (GTA-SF), leverages the GTA-V engine to simulate LiDAR scanning and autonomously annotate scene flow. Compared to existing synthetic datasets, GTA-SF offers more realistic scenes and point cloud representation. To bridge the synthetic-to-real domain gap, the paper introduces a mean-teacher domain adaptation framework that focuses on addressing shape deformations and correspondence deviation. Specifically, a teacher model is constrained with rigid shapes, and a deformation-aware student model is trained to learn desirable scene flow. Additionally, object surface relationships are leveraged to address correspondence deviation in real data. Extensive experiments demonstrate the effectiveness of the proposed dataset and framework, showing remarkable generalization to real-world data and outperforming common UDA methods across multiple datasets. This work contributes to bridging the domain gap in synthetic-to-real scene flow estimation for point clouds and provides valuable insights and tools for future research in this field.