Three-dimensional (3D) object detection has gained significant attention due to its applications in areas such as autonomous driving, augmented/virtual reality, and indoor robotics. However, most existing 3D object detectors require fully supervised learning, which involves annotating each 3D object in a scene. This annotation process is time-consuming and labor-intensive. To address this issue, some recent works have explored weakly-supervised and semi-supervised learning strategies, but they still require additional annotations or suffer from ineffective information transfer. In this paper, we propose a novel method for sparsely annotated 3D object detection, called SS3D, which only requires annotating one 3D object per scene. We introduce two modules to mine reliable positive instances and background, respectively, to ensure the 3D detector can be trained with confident supervision data. Experimental results show that our method achieves comparable performance to fully-supervised methods while significantly reducing annotation effort. This work is the first to explore the sparsely annotated strategy for 3D object detection and outperforms state-of-the-art weakly-supervised and semi-supervised methods.