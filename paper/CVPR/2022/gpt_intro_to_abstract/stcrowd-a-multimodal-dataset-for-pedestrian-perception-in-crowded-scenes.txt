This paper focuses on accurate pedestrian perception in 3D space, which is essential for thorough scene understanding and various applications such as surveillance, serving robots, and autonomous driving. However, pedestrian perception is challenging due to the non-rigid nature of pedestrians, their relatively small size compared to other agents, and the tendency for pedestrians to congregate and cause occlusion in crowded scenarios. To accelerate research in this field, several datasets have been collected, but they mainly provide 2D bounding box annotations, which are insufficient for accurate 3D position inference. The urgent need for precise pedestrian perception in 3D space has led to the development of 3D annotated datasets, but these datasets primarily focus on sparse traffic scenes, limiting the exploration and evaluation of learning-based perception methods in crowded scenarios. To address this gap, the authors introduce a large-scale multimodal dataset called STCrowd, which includes manually labeled 3D annotations for both images and point clouds. STCrowd contains a significant number of pedestrian instances in crowded scenes, making it ideal for exploring more effective methods and testing their robustness. The dataset includes data captured in different scenes with varying weather, light conditions, and road conditions, making it applicable for different tasks such as LiDAR-only, image-only, and sensor-fusion based detection, tracking, and trajectory prediction. Additionally, the authors propose a novel method called Density-aware Hierarchical heatmap Aggregation (DHA) to enhance pedestrian perception, particularly in crowded scenes. DHA consists of a spatial attention module and a hierarchical heatmap aggregation module, which improve the network's focus on relevant foreground regions and distinguish individuals in density-varying scenes. The authors evaluate their method on the STCrowd dataset and achieve state-of-the-art performance. Overall, this paper contributes a large-scale multimodal dataset for crowded scenarios, provides baselines and metrics for various tasks, and presents a novel method for enhancing LiDAR-based pedestrian perception.