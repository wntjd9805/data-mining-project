Deep neural networks (DNNs) have achieved great success in academia and industry. However, they are vulnerable to adversarial examples (AEs), which are generated by adding indistinguishable perturbations to benign images. Many studies have focused on generating AEs, and it has been proven that DNNs used in real-world applications are susceptible to AEs. Adversarial training (AT) is considered as one of the most effective defense methods to improve adversarial robustness. Existing AT methods often use a hand-crafted attack strategy to generate AEs, which limits the generalization performance and lacks flexibility. Additionally, most methods use only one attack strategy, which limits the robustness improvement. In this paper, we propose a novel adversarial training framework called LAS-AT (Learnable Attack Strategy-Adversarial Training) that introduces the concept of "learnable attack strategy." LAS-AT learns to automatically produce sample-dependent attack strategies for AE generation. It consists of a target network and a strategy network, where the target network is trained using AEs to improve robustness, and the strategy network generates attack strategies to control the generation of AEs. The two networks engage in a gaming mechanism where they learn from each other. LAS-AT does not rely on manually designed metrics or strategies, but instead uses the strategy network to automatically produce attack strategies based on the given sample. We propose two loss terms to guide the learning of the strategy network, which evaluate the robustness of the target model and the accuracy of clean samples. Our experiments and analyses on three databases demonstrate the effectiveness of the proposed LAS-AT framework. The proposed framework can be combined with other state-of-the-art methods as a plug-and-play component.