Generative Adversarial Networks (GANs) have made significant advancements in image generation tasks, producing realistic images that are almost indistinguishable from real-world images. However, current approaches have primarily focused on generating single-object images, such as human faces, while real-world scene images often contain diverse objects in various regions. This raises the question of whether GANs can generate high-quality scene images with diverse objects. In scene image generation, GANs tend to prioritize the synthesis of big and frequently occurring object classes, leading to a visual quality imbalance issue for non-dominant objects, which have smaller scales or lower frequencies. To address this problem, we propose a Local Attention Pyramid (LAP) module tailored for scene generation. The LAP module spreads attention over the entire image and enhances local attentions in different scales, ensuring balanced quality across diverse object classes. This is achieved by determining coarse locations of each object class using depthwise convolution layers and dividing feature maps into patches, which are normalized and fed into the sigmoid function to amplify local activation scores. Multiple attention maps with various patch sizes are inferred based on the feature map pyramid to handle object scale diversity.Our contributions include highlighting the class-wise quality imbalance problem in GAN-based scene synthesis, introducing the LAP module to address this issue, and demonstrating its effectiveness in improving image quality across various GAN architectures, loss functions, and training strategies. Experimental results on large-scale benchmarks show significant and consistent improvements in image quality with minimal additional learnable parameters.Keywords: Generative Adversarial Networks, scene image generation, visual quality imbalance, Local Attention Pyramid module, attention mechanism, object scale diversity.