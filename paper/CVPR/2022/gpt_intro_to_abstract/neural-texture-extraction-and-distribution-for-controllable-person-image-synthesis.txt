Synthesizing person images with explicit control over body pose and appearance is a crucial task with various applications in industries such as electronic commerce, virtual reality, and communication. However, existing Convolutional Neural Networks (CNNs) lack the ability to efficiently perform spatial transformation, leading to challenges in accurately deforming reference images. Flow-based methods have been proposed to address this issue but suffer from noticeable artifacts in complex deformations and occlusions. Attention mechanisms have emerged as an effective approach for capturing long-term dependencies but face limitations in this task, including the need for sparse attention correction matrices and quadratic memory footprint. To overcome these limitations, this paper introduces an efficient spatial transformation operation called the Neural Texture Extraction and Distribution (NTED) operation. This operation is motivated by the idea that person images can be manipulated by extracting and reassembling semantic entities. The proposed NTED operation consists of an extraction operation to gather features from reference images and a distribution operation to soft select extracted neural textures for each target position based on learned semantic distribution. By designing a generative neural network using NTED operations at different scales, the model can render input skeletons by predicting conditional semantic distributions and reassembling extracted neural textures.Experimental evaluations demonstrate the photo-realistic results at a high resolution of 512 Ã— 352, and comparison experiments show the superiority of the proposed model. Furthermore, the model enables explicit appearance control by manipulating interested semantics through exchanging corresponding neural textures of different references. An optimization method is proposed to automatically search for interpolation coefficients to fuse the extracted neural textures, resulting in coherent and realistic results. The main contributions of this paper include providing an intuitive idea for image deformation through the extraction and distribution of semantic entities, implementing the idea with a lightweight and computationally efficient NTED operation, and achieving explicit appearance control through interpolation between neural textures of different references.