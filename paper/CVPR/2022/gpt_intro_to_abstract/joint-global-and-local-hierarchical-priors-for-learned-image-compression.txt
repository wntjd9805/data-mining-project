This paper discusses the increasing demand for improved compression efficiency in learned image compression due to the large volume of photos being taken each year. Existing approaches follow a transform coding framework, where an image is transformed into a quantized latent representation and then entropy encoded. Deep neural networks are utilized for the transformation and entropy model. The accuracy of the entropy model is crucial for compression efficiency, and traditional approaches assume independence among elements, which limits compression efficiency in practical cases. To address this, CNN-based entropy models have been used to capture dependencies from the latent representation. However, these models have limitations in capturing global and long-range dependencies. To overcome these limitations, the paper proposes an Information Transformer (Informer) that captures both global and local dependencies using the attention mechanism. By introducing global and local hyperpriors, Informer improves the rate-distortion performance of learned image compression methods while avoiding the computational complexity problem. The paper's contributions include the proposal of joint global and local hyperpriors and demonstrating the improved performance of Informer in rate-distortion performance.