Generative Adversarial Networks (GANs) have made significant advancements in recent years, particularly with the introduction of StyleGAN, which can synthesize high-resolution images with moderate quality. As a result, utilizing pretrained StyleGAN models for downstream tasks, such as image-to-image translation, has become a popular research topic. However, inverting or editing images for StyleGAN remains challenging due to several reasons. Firstly, there are multiple candidate latent embeddings, and different choices can greatly impact the results. Secondly, the distribution of latent codes in StyleGAN is complex, making independent editing difficult.In this paper, we propose a novel approach to improve encoder-based image inversion and editing for StyleGAN simultaneously. Inspired by the success of transformers in other computer vision tasks, we utilize a multi-stage style transformer in the latent space of StyleGAN for accurate image inversion and editing. This transformer leverages cross-attention and self-attention mechanisms to update latent codes in an iterative manner, incorporating image features at different spatial positions as keys and values. Additionally, our model employs a two-pyramid encoder to capture multi-scale features and enhance the regularization on latent codes.Furthermore, we explore two types of image editing in StyleGAN: label-based editing and reference-based editing. For label-based editing, we use a pre-trained non-linear latent classifier to determine the editing direction based on the target label. For reference-based editing, we perform cross-attention between the inverted code from the source image and the code obtained from a reference image. This allows us to determine the exact editing vector from the reference, resulting in diverse and high-quality editing results.The contributions of this paper include the proposal of a novel multi-stage style transformer for accurate image inversion, the characterization of label-based and reference-based image editing in StyleGAN, and the use of a non-linear classifier to generate the editing vector. Our approach achieves diverse and faithful editing results while maintaining the quality of the images.