Deep learning techniques have achieved great success in various visual recognition tasks. However, they often require large amounts of annotated training data, which can be laborious and time-consuming to collect. One alternative is to leverage labeled data from related source domains. However, models trained with source-domain data often experience a performance drop when applied to target domains with different data distributions.Unsupervised domain adaptation (UDA) has been explored to mitigate the discrepancy between source and target domains. One approach is image-to-image translation with generative adversarial networks (GANs), but this method requires learning a large number of parameters and impairs the end-to-end feature of UDA.To address these challenges, we propose Spectral UDA (SUDA), which learns domain-invariant spectral features efficiently and effectively. SUDA consists of a spectrum transformer (ST) that reduces inter-domain discrepancies by enhancing domain-invariant frequency components (FCs) and suppressing domain-variant FCs. We introduce adversarial spectrum attention (ASA) to accurately identify domain-variant and domain-invariant FCs. Additionally, we design multi-view spectral learning (MSL) to learn diverse target representations by maximizing mutual information among multiple ST-generated spectral views.SUDA has three desirable features: it is generalizable across different visual tasks, it is an online and learnable technique, and it can be incorporated with existing UDA methods for improved performance without significant extra computation.The contributions of this work include the design of SUDA, the online learnable spectrum transformer, ASA for accurate identification of FCs, and MSL for effective learning of target representations. Overall, SUDA provides a promising approach for tackling UDA challenges and improving the performance of deep learning models in target domains.