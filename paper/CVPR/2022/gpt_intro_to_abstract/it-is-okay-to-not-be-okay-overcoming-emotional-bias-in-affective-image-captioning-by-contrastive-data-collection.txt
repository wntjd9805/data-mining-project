This paper introduces the importance of studying emotional experiences and their expression in understanding human behavior. It emphasizes the need for affective datasets that capture different modalities to better comprehend emotions and enhance the acceptance of AI applications. The authors discuss existing affective datasets and highlight their limitations, particularly in attributing emotional experiences to a single stimulus.The paper also discusses the significance of multi-modal datasets in advancing AI capabilities and introduces the ArtEmis dataset, which connects emotions, visual art, and language explanations. However, it raises concerns about dataset biases and biases introduced by human labelers, which can have negative implications for ethical judgment and human interaction applications.The authors reference a bias identified in the VQA dataset and its impact on deep learning models. This bias affected the models' reliance on the visual modality and demonstrated the need to detect and address biases in affective datasets. They further identify a discrepancy in the ArtEmis dataset, wherein a naive nearest neighbor model performs unusually well due to an unbalanced distribution of emotions and generic captions.To address this issue, the authors propose a complementary dataset collection method using the contrastive data collection technique. They demonstrate the effectiveness of this method compared to simply expanding the size of the ArtEmis dataset. The combined dataset achieves a more balanced distribution of emotional labels and provides a representation of fine-grained emotions.The contributions of the paper include highlighting the problems in the ArtEmis dataset, introducing the contrastive data collection method, and demonstrating its superiority in training neural speakers. The results of the experiments conducted support the effectiveness of the proposed method in improving the quality of trained speakers.Overall, this paper addresses the importance of affective datasets, discusses biases in such datasets, and presents a novel approach to tackle these issues. The findings and methodology presented contribute to advancing the understanding of emotions in AI applications and fostering the development of more balanced and reliable models.