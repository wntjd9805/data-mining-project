Camera localization is a fundamental task in computer vision, robotics, and AR/VR, aiming to estimate the spatial relationship between an input image and an environmental representation. Different problem instances arise based on factors such as the pose geometric model, input query imagery, and environmental geometric reference. This paper focuses on camera localization of a query panorama/perspective image with respect to a 2D floor map, using the Monte Carlo Localization (MCL) framework. Conventional MCL methods often require depth sensors and have limited robustness to environmental variability. Supervised learning approaches have shown promise but are computationally burdensome. To address these challenges, the proposed framework adopts a geometrically-structured metric learning framework, performing latent-space rendering while prioritizing applicability to unseen environments, computational efficiency, estimation accuracy, and robustness. The framework leverages a rendering codebook and circular features to provide fine-grained structured descriptors for geometry and semantics. Experimental results demonstrate that the proposed framework significantly outperforms state-of-the-art methods in terms of accuracy and speed. The main technical contributions include a map-aware 2D visual localization framework, a latent space rendering approach based on a codebook scheme, and a geometrically-structured metric learning approach utilizing rotationally-covariant circular features.