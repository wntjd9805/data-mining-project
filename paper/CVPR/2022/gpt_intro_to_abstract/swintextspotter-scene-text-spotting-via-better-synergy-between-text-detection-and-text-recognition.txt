Scene text spotting, the task of detecting and recognizing text in natural images, has gained significant attention for its applications in autonomous driving, intelligent navigation, and key entities recognition. Traditional methods treat detection and recognition as separate tasks, leading to limitations such as error accumulation and low efficiency. To address these issues, researchers have proposed end-to-end systems that optimize detection and recognition jointly. However, existing end-to-end systems have limitations in accurately detecting text in the presence of background noise and lack sufficient interaction between detection and recognition. In this paper, we propose SwinTextSpotter, an end-to-end Transformer-based framework that improves synergy between text detection and recognition. We introduce a two-level self-attention mechanism to stimulate interactions between text instances. We also propose Recognition Conversion (RC), which guides the recognition head by incorporating detection features, leading to joint optimization of the detector and recognizer. Our experiments on multiple benchmarks demonstrate the superior performance of SwinTextSpotter in both detection and recognition tasks. The main contributions of this work include the effectiveness of Transformer in end-to-end scene text spotting, the synergy of text detection and recognition achieved through Recognition Conversion, a concise framework that does not require character-level annotation or rectification, and state-of-the-art performance on multiple scene text benchmarks.