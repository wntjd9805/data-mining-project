This paper introduces the novel task of unweaving video into its constituent activity threads. It presents a new interpretation of video as a weaving of activities, which allows for the distinction between instances of an activity when it is paused and later resumed. The proposed task is related to event boundary detection and unsupervised activity segmentation, but it focuses on finding transitions between activities and supports the association between paused-and-resumed activities. The paper proposes a model called UnweaveNet, which learns to unweave video by manipulating a thread bank with a neural controller. It also introduces a self-supervised pretraining approach that leverages within-thread temporal-order consistency. The model is evaluated using the EPIC-KITCHENS-100 dataset. The contributions of the paper include the novel task of unweaving video, a new video representation, a self-supervised pretraining approach, labelled annotations of activity threads from the EPIC-KITCHENS dataset, and an empirical evaluation and ablation study of UnweaveNet.