With the advancements in 3D scanning technology, deep learning on 3D point clouds has made significant progress in various tasks. However, most existing methods in this field neglect pose information, leading to ambiguous representations and limitations in real-world scenarios. In this paper, we address the inherent pose information loss problem by proposing a Pose-aware Rotation Invariant Convolution (PaRI-Conv) operator. The PaRI-Conv operator restores the lost pose information by dynamically adjusting convolution kernels based on relative poses. We introduce an Augmented Point Pair Feature (APPF) to represent the relative pose information, which is rotation-invariant and facilitates dynamic kernel adjustment. To reduce computational complexity, we propose a factorized dynamic kernel that decomposes the kernel weight into a shared basis matrix and a pose-aware diagonal matrix. By fully preserving geometric relationships and incorporating pose information, our method acquires global context without the need for redundant blocks or complex representations. Experimental results demonstrate the superiority of our approach in shape classification and part segmentation tasks, surpassing state-of-the-art rotation-invariant methods while approaching or surpassing rotation-sensitive methods on aligned data. The main contributions of our work include addressing the pose information loss problem, proposing the PaRI-Conv operator, and introducing the APPF and factorized dynamic kernel for efficient and powerful rotation-invariant learning.