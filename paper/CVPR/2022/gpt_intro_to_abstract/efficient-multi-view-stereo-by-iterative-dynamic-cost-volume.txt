Multi-view stereo (MVS) is a computer vision technique that reconstructs a dense 3D model using a series of images and camera parameters. The most common approach in MVS is to predict depth maps and fuse them into a point cloud model. Deep learning-based MVS methods have seen rapid development in recent years, outperforming traditional methods in reconstruction accuracy. However, these methods are limited by high GPU memory usage and processing time. Existing approaches can only handle low-resolution images due to the resource requirements of the regularization step.In addition to improving reconstruction quality, it is important to reduce running time and GPU memory consumption to make learning-based MVS methods adaptable to resource-restricted devices. Previous works have attempted to improve efficiency, but it remains challenging to simultaneously improve accuracy and reduce resource consumption. In this work, we aim to improve the computation speed and memory consumption of high-resolution MVS while maintaining reconstruction quality.Our method proposes a lightweight and dynamic cost volume that can be processed iteratively. This approach reduces peak memory usage during inference and ensures a large search space for improved accuracy. The dynamic cost volume converges in a few iterative steps, making our method highly efficient. We draw inspiration from previous works on adaptive cost volume and optical estimation, but our approach introduces novel modifications to address memory limitations and accelerate convergence.Our contributions can be summarized as follows: 1) We propose a lightweight and dynamic cost volume processed iteratively using a 2D convolution-based gated recurrent unit (GRU). This approach avoids the memory and time-consuming problem of large static cost volumes.2) We present a cascade and hierarchical refinement architecture that leverages multi-scale information to speed up convergence. A lightweight 3D CNN provides a reliable initialization for GRUs, which is critical for fast convergence and overall performance.3) Our method achieves state-of-the-art performance in terms of accuracy, inference speed, and GPU memory consumption. It outperforms other methods on important MVS benchmarks, such as DTU and Tanks & Temples, with decreased memory usage and a significant two-fold increase in speed compared to the runner-up.