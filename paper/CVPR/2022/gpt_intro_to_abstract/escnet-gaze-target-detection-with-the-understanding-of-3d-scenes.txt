Gaze target detection plays a crucial role in understanding human intention and has various applications in human-computer interfaces and social awareness tracking. While wearable eye trackers can perform gaze estimation, they have limitations such as location and calibration requirements. A more general approach involves using third person view images and aims to determine where a person is looking in a 2D image. Conventional methods rely on 2D visual cues and estimated gaze orientation, while recent approaches incorporate 3D gaze estimation and depth cues. However, these approaches require additional human annotations and lack the ability to handle complex scenarios with multiple salient objects. In this paper, we propose an approach to gaze target detection that explicitly models the 3D geometry of scenes using only 2D gaze annotations. We address the challenges of the task, including the lack of 3D information in existing datasets and the representation of such information. We introduce two key insights: the reconstruction of 3D geometry using depth and camera parameters and the modeling of occlusion to determine the front-most points in 3D space.To implement our approach, we propose a novel model called ESCNet, which consists of gEometry and SCene parsing modules. The gEometry module leverages geometric cues, such as 3D gaze direction and 3D geometry, to generate an initial heatmap representing the probability of each front-most point being looked at. The SCene parsing module incorporates scene contextual cues, such as RGB image saliency, to generate final heatmap predictions.We evaluate our method on the GazeFollow and VideoAttentionTarget datasets and achieve state-of-the-art performance. Our approach not only provides visually and conceptually meaningful intermediate representations but also allows for deep supervision, leading to improved performance. Interestingly, our method even outperforms human performance on the AUC metric.In summary, our contributions include a novel method that explicitly models full 3D geometry, especially occlusion, in 2D gaze target detection. We also propose the ESCNet model, which explores 3D geometry, 2D/3D gaze, and scene contextual cues using only 2D gaze annotations. Our approach achieves state-of-the-art results on publicly available datasets and surpasses human performance.