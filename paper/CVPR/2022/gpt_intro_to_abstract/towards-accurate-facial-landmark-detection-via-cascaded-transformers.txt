Facial landmark detection is an important task for various facial analysis applications. In recent years, significant progress has been made in this field, with approaches falling into two main categories: coordinate regression-based methods and heatmap-based methods. While heatmap-based methods have higher detection accuracy, they suffer from issues such as non-differentiable post-processing steps, lower resolution of heatmaps compared to input images, and vulnerability to appearance variations. Coordinate regression-based methods have advantages in terms of end-to-end training, but they lack spatial structure preservation. In this paper, we propose a coordinate regression-based model called Deformable Transformer Landmark Detector (DTLD) that addresses the limitations of heatmap-based methods and improves localization accuracy. Our approach leverages multi-level feature maps and deformable attention to extract relevant features and refine coordinates. Inspired by the success of DETR in object detection, we formulate landmark detection as a refined N-coordinate prediction task and utilize self-attention and deformable attention mechanisms. We also introduce a parallel decoder to further enhance detection performance.The main contributions of this work are as follows: 1) We propose DTLD, a cascaded deformable transformer-based model, which effectively captures structural relationships and visual contextual information for accurate landmark detection.2) We introduce a parallel decoder that improves detection accuracy with minimal increase in model parameters.3) We conduct extensive experiments and achieve state-of-the-art accuracy on multiple landmark detection benchmarks, demonstrating the effectiveness and generalizability of our approach.Overall, our proposed method shows promise in tackling facial landmark detection under various scenarios and provides a significant advancement in this field.