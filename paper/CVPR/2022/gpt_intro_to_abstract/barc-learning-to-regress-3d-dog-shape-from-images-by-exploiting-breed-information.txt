Learning to infer 3D models of articulated and non-rigid objects from 2D images is a challenging task, especially for animal species. In the case of humans, parametric models like SMPL have been successful, but such models cannot be replicated for most animals due to limited training data. In this paper, we focus on dogs as a representative test case and aim to estimate their 3D shape and pose from monocular images. We train a regression network with 2D supervision using keypoints and silhouettes as training data, but the problem remains under-constrained. To address this, we leverage the prior knowledge that a dog's breed influences its shape and incorporate breed labels as additional information. Dogs offer a diverse range of breeds with distinct body shapes, making them an interesting case to explore the role of breeds. We propose a novel neural network called BARC, which uses breed labels to regress 3D dog shape from 2D images. We extend the SMAL animal model to enhance its suitability for learning about dog shape. Our contributions include a novel neural network architecture, leveraging breed information to impose regularization, and learning a breed-aware latent shape space. We evaluate our approach on a dataset of 120 different dog breeds and demonstrate that our model learns a latent shape space in which closely related dogs are closer together. We also conduct ablation studies to evaluate the impact of different types of breed information and show significant improvements in shape accuracy. Comparisons with prior art and a perceptual study demonstrate the effectiveness and realism of our approach for estimating 3D dog shape from in-the-wild images.