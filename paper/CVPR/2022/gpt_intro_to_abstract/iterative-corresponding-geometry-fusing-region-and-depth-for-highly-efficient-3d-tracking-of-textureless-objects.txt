This paper explores the problem of estimating the six degrees of freedom (6DoF) pose of objects in robotic manipulation and augmented reality applications. To achieve high-frequency pose estimation, 3D object tracking is used, where the object's position and orientation are estimated from consecutive image frames. However, real-world scenarios present challenges such as occlusions, motion blur, background clutter, textureless surfaces, object symmetries, and real-time requirements.Previous approaches to 3D object tracking have utilized keypoints, edges, direct optimization, deep learning, object regions, and depth images. Keypoint-based and direct optimization methods are not suitable for textureless objects, while edge-based techniques struggle with background clutter and object texture. To overcome these issues, data-driven techniques such as convolutional neural networks (CNNs) have been proposed, requiring significant computational resources and a detailed 3D model. Region-based techniques have gained popularity for tracking textureless objects in cluttered environments, and the use of consumer depth sensors has enabled additional trackers that do not rely on texture. Additionally, combining different techniques has demonstrated improved results in object tracking.This paper focuses on the combination of region-based correspondence lines and depth-based correspondence points for efficient and accurate tracking of textureless objects. The proposed method, ICG, utilizes geometric information from both region-based and depth-based correspondences. The performance of ICG is evaluated on three different datasets and compared against classical and deep learning-based techniques, demonstrating state-of-the-art results. The comparative analysis provides new insights into the current state of deep learning-based object tracking and pose estimation, which has been underexplored in previous studies.