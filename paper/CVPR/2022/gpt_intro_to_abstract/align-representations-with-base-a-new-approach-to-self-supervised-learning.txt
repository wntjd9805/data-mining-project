The scarcity of labeled data has been a major bottleneck in deep learning, leading to increased focus on unsupervised and self-supervised learning approaches. These approaches can be broadly categorized into generative, pretext-tasks-based, and contrastive methods. While generative methods predominantly use pixel-level reconstruction, discriminative approaches have gained attention for training encoders using pretext tasks.Contrastive-based methods have become the mainstream in current research, as views of the same images generated by random augmentation retain similar semantic information. However, directly aligning the embeddings of these views often leads to degenerate solutions, where different samples are mapped to the same points in feature space. This is due to the lack of proper objective functions or architectures.To address this issue, this paper introduces a novel method called ARB. ARB maximizes the mutual information between an immediate variable generated from one view and the representations of the other view. This approach effectively avoids degenerate solutions in contrastive learning. The paper proposes shuffling the feature and dividing the output space into groups on the feature dimension to further reduce complexity.The highlights of this paper are summarized as follows: 1) ARB is a straightforward, comprehensible, and efficient method for avoiding collapses in contrastive learning. It only requires linear order complexity of objectives.2) The paper provides a theoretical analysis of the relationship between ARB and previous feature-wise methods, as well as an explanation of how ARB avoids degenerate solutions.3) Experimental results on CIFAR-10, CIFAR-100, and ImageNet demonstrate that ARB achieves higher or comparable performance to previous methods. Additionally, ARB is more robust to dimension size compared to other feature-wise contrastive methods like Barlow Twins.In conclusion, this paper introduces ARB as a novel method to address degenerate solutions in contrastive learning. The theoretical analysis and experimental results highlight the effectiveness and robustness of ARB in various datasets.