Lossy image compression is an essential task in image processing, aiming to reduce the bitrate required for storage or transmission while preserving visual image content. This problem has been extensively studied and is actively researched in both traditional hand-crafted approaches and newer learned methods. Traditional image codecs typically involve partitioning the image into small blocks for separate processing, linear transforms to decorrelate image values, intra block prediction, residual coding, quantization, and entropy coding. In contrast, modern learned compression methods process the image as a whole using models based on variational autoencoders, where the latent representation is quantized and entropy coded. Stereo image compression shares the primary objective of reducing bitrate while preserving visual content, with the additional potential to leverage mutual information between left and right images. Traditional methods accomplish this through inter-frame or motion prediction, but incorporating stereo compression into learned methods is more challenging. Existing deep learning methods for stereo compression, such as DSIC and HESIC, are complex and require additional modules for joint entropy modeling and image enhancement. In contrast, our proposed model is lightweight and conceptually simple, achieving comparable performance without sacrificing simplicity or requiring special training procedures.The backbone of our method is an adaptation of an existing single image compression encoder-decoder model. The left image is encoded normally, while the right image is processed by the encoder, and optimal horizontal shifts of each channel of its latent representation are found to align with the corresponding channel of the left image latent. By subtracting the two shifted channels, only the residual is encoded for the right latent. This approach is motivated by the observation that the dominant rigid transformation between rectified stereo images is a horizontal shift, and working in the latent space allows for a larger effective disparity range. To account for smaller local displacements caused by depth variation, a stereo attention module is used to connect the two image representations.In summary, our proposed method for stereo image compression has several key features. It mimics techniques used in traditional codecs while remaining fully end-to-end learnable. The method outperforms existing state-of-the-art stereo image compression methods on standard test datasets. It is lightweight, easy to train, and its code is publicly available. The rest of the paper will provide a literature review, a detailed description of the method, and the presentation and discussion of experimental results.