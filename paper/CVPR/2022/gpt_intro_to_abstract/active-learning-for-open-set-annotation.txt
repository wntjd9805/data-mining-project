The success of deep learning relies on large datasets with human-labeled annotations. However, labeling such data is costly and time-consuming, leading to the challenge of learning with limited labeled data. Active learning (AL) is a popular approach to address this issue by selecting the most informative examples from unlabeled data to query for labels. Existing AL methods operate in a closed-set setting where labeled and unlabeled data are from the same class distribution. In real-world scenarios, unlabeled data often includes large amounts of examples from unknown classes. This paper presents a novel active learning framework called Learning from Open-Set Annotation (LfOSA) to handle the open-set annotation (OSA) problem. The goal of OSA is to filter out examples from unknown classes and select a query set consisting of examples from known classes. LfOSA includes two networks for detection and classification. The detector models the per-example max activation value distribution to separate the unlabeled open-set into known and unknown sets. Examples with higher certainty from the known set are selected for annotation. The classification model is updated with the newly labeled examples from known classes. Invalid examples from unknown classes are also used as negative training examples to improve the detector's ability to identify known-class examples. Experimental results show that LfOSA outperforms state-of-the-art active learning methods in terms of selection quality and classification accuracy while reducing annotation costs. The paper concludes with a discussion of related work, the proposed method, experimental results, and future work.