This paper focuses on the task of semantic segmentation, which aims to assign each pixel in an input image a unique category label. Deep fully convolutional network methods have achieved remarkable results in this task, but they often rely on large models with a high number of parameters. In order to maintain efficient inference speed and high accuracy with high-resolution images, the paper explores the use of knowledge distillation, a technique introduced by Hinton et al. that has received attention in the semantic segmentation community.Previous works in knowledge distillation for semantic segmentation have focused on high-level contextual knowledge or final response knowledge, which capture global context and long-range dependencies but may result in coarse and inaccurate segmentation. This paper proposes to exploit texture knowledge from a teacher model to enrich the low-level information of a student model. Texture, as a region descriptor, provides measures for both local structural properties and global statistical properties of an image.The proposed framework, called Structural and Statistical Texture Knowledge Distillation (SSTKD), effectively distills two kinds of texture knowledge from the teacher model to the student model. The framework includes a Contourlet Decomposition Module (CDM) that decomposes low-level features to extract structural texture knowledge, and a Denoised Texture Intensity Equalization Module (DTIEM) that adaptively extracts and enhances statistical knowledge. The DTIEM utilizes an adaptive importance sampler and a denoised operation for efficient and accurate characterization.To the authors' knowledge, this is the first work to introduce both structural and statistical texture knowledge to knowledge distillation for semantic segmentation. The proposed framework achieves state-of-the-art performance on three benchmark datasets, regardless of the choice of student backbones.