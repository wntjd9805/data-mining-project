Referring video object segmentation (RVOS) is the task of predicting the most relevant visual target in a video given a natural language expression. It has various applications in fields such as video editing, virtual reality, and human-robot interaction. Unlike traditional unsupervised or semi-supervised video object segmentation methods, RVOS requires cross-modal understanding between the language query and video content. Current approaches in RVOS mainly rely on frame-level visual representations, which have limitations in capturing long-temporal information and attending to salient spatial objects. This leads to misalignment between modalities and inaccurate segmentation results. To address these limitations, we propose a novel multi-level learning framework for RVOS. Our framework includes a fine-grained analysis of video content at the video, frame, and object granularity, as well as a dynamic semantic alignment technique that effectively incorporates linguistic features with the different levels of visual representation. We also introduce a boundary-aware segmentation method to guide mask prediction. Our proposed framework achieves compelling performance on challenging benchmarks and outperforms existing methods in terms of accuracy and inference speed.