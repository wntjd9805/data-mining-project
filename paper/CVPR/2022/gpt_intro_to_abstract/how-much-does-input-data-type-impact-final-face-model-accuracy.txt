Three-dimensional face models are extensively used in various applications such as biometric identification, 3D avatars, social media filters, and photo editing. The accuracy requirements for these applications vary, ranging from realistic movie rendering to fun mobile apps with cartoon features. Raw input data, including laser scans and 2D RGB photographs, often require a model to constrain or clean up the data. This model can take different forms, such as explicit priors or neural network architectures. However, system designers must select appropriate input data sources, models, and fitting methods to obtain a usable 3D face model. While previous research focused on improving raw data or reconstruction methods, this paper aims to address the question of how accurate the input data needs to be for a specific application domain. Can a 3D model be predicted from a photograph? Can missing facial features be approximated based on the rest of the face? To answer these questions, the paper utilizes an existing ground truth dataset with 3D face scans and corresponding 2D images. The paper compares the accuracy of different raw data types, including 2D feature points, photographs, low quality 3D, 3D feature points, high-quality 3D with missing data, and complete high-quality 3D. Synthetic experiments are conducted to mimic different input data types, and real experiments are conducted using only RGB photographs. The paper does not aim to determine the absolute accuracy achievable but rather provides a comparison of error magnitudes when starting from different raw inputs. The chosen model, Morphable Face Model, is widely used, well-established, and easily interpretable. The contribution of this paper is a comprehensive analysis of 3D facial reconstruction accuracy based on input data completeness.