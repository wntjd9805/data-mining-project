Monocular 3D object detection is a challenging problem in computer vision, as it involves localizing and estimating 3D bounding boxes of objects using only a single image. Existing methods typically rely on expensive LiDAR sensors or stereo cameras to obtain depth information, but these solutions increase costs. In contrast, monocular cameras are more cost-effective. However, most existing methods treat each object as an individual sample without considering the relationships between neighboring objects. This can limit the ability to refine and correct the estimated position of a single object. Some approaches use projection loss to constrain the optimization of 3D boxes with the supervision of 2D ground truth boxes, but the localization of a single object remains independent of others. MonoPair addresses this by leveraging object relationships and building scene graphs, but it can only connect objects with their nearest neighbors. Additionally, existing methods struggle to handle occluded or smaller objects that are far away from the camera. A promising approach to improve 3D detection is to leverage foreground objects or 2D detection results to correct the results. However, most approaches are limited to training the network for individual samples. To address these limitations, we propose a novel homography loss that builds connections between all objects and globally optimizes their 3D positions. We also associate Bird's Eye View (BEV) with the image view, using 2D detection results as guidance for improving 3D localization in BEV. Our proposed method achieves state-of-the-art performance on the KITTI 3D detection benchmark and surpasses other monocular 3D detectors. The main contributions of our work are the novel homography loss, the superior performance achieved on the benchmark, and the adaptability of our method to various monocular 3D detectors. Our loss function can be easily integrated into existing detectors, making the training process more stable and improving accuracy and performance without additional inference costs.