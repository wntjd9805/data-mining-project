Abstract:This paper addresses the task of feature matching in computer vision applications such as SLAM, SfM, and camera pose estimation. Classical methods rely on point-to-point feature matching using nearest neighbor search and outlier rejection. However, these methods overlook geometric information and the global receptive field. Recent works have introduced graph neural networks (GNNs) for feature matching, but learning complete graphs with attention suffers from computational and memory complexity. To mitigate this issue, we propose a coarse-to-fine cluster-based GNN approach that reduces redundancy and computational complexity. We divide keypoints into clusters and establish local graphs, where each point interacts only with points in the same cluster. We evaluate our method on various tasks and achieve state-of-the-art accuracy with significantly improved efficiency in runtime and memory consumption. Our contributions include the presentation of a learnable clustering method for feature matching, the introduction of the ClusterGNN architecture, and the achievement of state-of-the-art results with reduced runtime and memory consumption compared to existing methods.