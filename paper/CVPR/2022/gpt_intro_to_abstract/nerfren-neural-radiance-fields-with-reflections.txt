Photorealistic novel view synthesis (NVS) from unstructured image collections is essential for creating immersive virtual experiences. While significant progress has been made in controlled settings, challenges remain in handling light transport in different materials, particularly reflections caused by glass or mirrors. These reflections pose difficulties for novel view synthesis due to their severe view-dependent effects. Neural Radiance Fields (NeRF) is an emerging technique that has achieved impressive view synthesis quality by utilizing volumetric representations with coordinate-based neural networks. However, when modeling scenes with complex reflections, NeRF encounters two problems: inaccurate depth estimation in reflective regions and inaccurate rendering when multi-view consistency is violated. To address these issues, we propose NeRFReN, which enhances NeRF to handle scenes with reflections by modeling the transmitted and reflected parts of the scene with separate neural radiance fields. We introduce specific network architectures, exploit geometric priors, and employ a carefully-designed warm-up training strategy to achieve physically sound decomposition results. Our approach achieves competitive novel view synthesis quality compared to vanilla NeRF on several real-world scenes, including those with mirrors. Additionally, we explore further applications such as depth estimation and scene editing based on the decomposed results. Our contributions include analyzing NeRF's behavior and limitations in modeling reflective regions, proposing the use of separate transmitted and reflected neural radiance fields, and demonstrating the effectiveness of our approach through experiments on real-world scenes.