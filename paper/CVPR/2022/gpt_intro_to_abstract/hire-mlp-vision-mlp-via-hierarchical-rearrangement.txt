Attention mechanism based transformers have shown significant improvements in natural language processing tasks. However, the heavy computational burdens caused by self-attention modules hinder the models from achieving a better trade-off between accuracy and latency. Recently, MLP-based models have emerged as a new trend in the vision community, offering comparable results to CNNs while discarding the heavy self-attention module. However, existing MLP-based models have limitations when it comes to being generalized to different input resolutions and exploring local information. To address these challenges, we propose Hire-MLP, which utilizes hierarchical rearrangement operations to encode both local and global information while being compatible with flexible input resolutions. The hierarchical rearrangement operation allows our model to capture local and global information in both height and width directions. Experimental results show that Hire-MLP outperforms existing MLP-based models in various computer vision tasks, including image classification, object detection, instance segmentation, and semantic segmentation. Hire-MLP achieves higher accuracy and better latency trade-off, making it a versatile backbone for computer vision tasks.