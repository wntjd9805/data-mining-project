Recent advancements in action recognition have led to various real-world applications, such as video surveillance and smart shopping systems. However, these applications often require extensive computation and necessitate sharing video data with cloud computation servers, resulting in the exposure of private visual information. This creates a need for solutions to privacy-preserving action recognition. One solution is to use low-resolution videos, but this compromises the trade-off between action recognition performance and privacy preservation. Another approach involves using pretrained object-detectors to detect privacy regions and modify or remove them. However, these methods require bounding-box level annotations for privacy attributes and may result in a drop in action recognition performance. An adversarial training framework has also been proposed to learn an anonymization function, but it requires privacy labels, which are challenging and time-consuming to annotate. Additionally, the learned anonymization function may not generalize well to novel privacy attributes. In this paper, we propose a novel self-supervised learning (SSL) method for privacy-preserving action recognition. Our method aims to remove semantic information from input videos while maintaining information relevant to the action recognition task. We demonstrate that our proposed framework, called Self-supervised Privacy-preserving Action recognition (SPAct), can anonymize videos without the need for privacy annotations in training. To evaluate the generalization ability of the anonymization function, we introduce new protocols that consider domain shift in action and privacy classes. We also address the importance of preserving privacy attributes beyond humans, such as scenes and objects. To evaluate this, we propose a new dataset subset, P-HVU, which allows for robust evaluation of privacy-preserving action recognition. Our contributions include the introduction of a novel SSL framework for privacy-preserving action recognition that does not require privacy attribute labels. We achieve competitive performance compared to state-of-the-art supervised methods on existing evaluation protocols. We also propose new evaluation protocols that demonstrate the superior generalization capability of our method. Finally, we introduce the P-HVU dataset to address the limitations of existing evaluation sets and extend privacy evaluation to non-human attributes.