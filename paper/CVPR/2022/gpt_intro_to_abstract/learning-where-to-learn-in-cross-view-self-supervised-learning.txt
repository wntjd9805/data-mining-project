Self-supervised learning (SSL) has gained significant attention in recent years for its ability to learn representations from unlabeled data. Instance discrimination approaches, which encourage representation learning with image-level invariance to random data transformations, have shown superior performance in various downstream tasks. However, two main issues remain unresolved, specifically the introduction of irrelevant information and spatial misalignment from rigorous invariance to random cropping. Previous solutions have involved localization priors from downstream tasks, but these methods suffer from limitations and fail to generalize to other tasks. In this paper, we propose a new self-supervised learning approach called Learning Where to Learn (LEWEL). LEWEL learns local representations spontaneously by manipulating alignment maps to control where to learn. Experimental results on classification, segmentation, and object detection tasks demonstrate the effectiveness of LEWEL in improving the performance of existing baselines. LEWEL outperforms MoCov2 and BYOL by significant margins on various benchmarks. The results highlight the potential of LEWEL in enhancing self-supervised representation learning.