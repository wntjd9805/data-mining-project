Autonomous navigation in intelligent embodied agents is a key capability that requires the understanding and execution of human instructions. Vision-and-Language Navigation (VLN) has emerged as a challenging problem, where agents must navigate in unfamiliar environments based on language instructions. Previous VLN approaches have used fine-grained instructions or goal-oriented instructions, but both have limitations. Fine-grained instructions offer detailed guidance but lack practicality, while goal-oriented instructions pose challenges in grounding rooms and objects. In order to efficiently explore new areas and keep track of instructions, memory mechanisms are implemented using recurrent architectures in existing approaches. However, this implicit memory mechanism may not effectively store and utilize previous experiences. Recent approaches have proposed explicit memory storage and modeling of long-range dependencies using transformers. Nevertheless, these models only allow for local actions, requiring the agent to backtrack N steps by running the navigation model N times. To address these limitations, this paper proposes a dual-scale graph transformer (DUET) with topological maps. The model consists of two modules: topological mapping and global action planning. The topological mapping module constructs a map over time by adding new locations and updating visual representations of nodes. The global action planning module predicts the next location or a stop action. To balance fine-grained language grounding and reasoning over large graphs, action predictions are dynamically fused from dual scales. Transformers are used to capture vision-and-language relations and improve map encoding. The model is pretrained with behavior cloning and auxiliary tasks, and a pseudo interactive demonstrator is proposed to enhance policy learning. DUET outperforms state-of-the-art methods on goal-oriented VLN benchmarks, achieving significant improvements in success rate. It also improves performance on fine-grained VLN benchmarks. The contributions of this work are the proposal of DUET with topological maps, the use of graph transformers for encoding and cross-modal relations, and achieving state-of-the-art results on VLN benchmarks.