Content-Based Image Retrieval (CBIR) plays a crucial role in computer vision and multimedia research. It is applicable to various domains including landmarks, medical images, cultural heritage, and e-commerce, such as fashion and interior design. CBIR systems retrieve images from a database by comparing the visual features of the query image with the stored features. However, the challenge lies in bridging the semantic gap between low-level visual features and the high-level meaning of images. To tackle this, variations of CBIR have been proposed, including relevance feedback and the integration of natural language processing to incorporate user intent and context. This work focuses on conditioned retrieval for the fashion domain and composed retrieval for general images. The proposed system utilizes a network that combines visual and textual features derived from the OpenAI CLIP network. Despite its simplicity, the system achieves state-of-the-art results on standard datasets in both fashion and general content domains. The system has potential applications in interactive e-commerce sites, chatbots, and image search engine performance improvement.