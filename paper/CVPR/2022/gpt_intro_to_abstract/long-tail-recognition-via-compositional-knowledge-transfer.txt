Standard classification models often assume that all classes are equally represented in training datasets. However, in real-life datasets, there is often a long-tail distribution where a few classes have a large amount of training data and the remaining classes have only a few samples. This imbalance results in trained models that perform well on common classes but poorly on rare classes. Addressing this imbalance challenge has been studied extensively, but the limited availability of data for rare classes has received limited attention. Existing approaches rarely incorporate mechanisms to account for the limited data in the tail of the distribution. In contrast, few-shot learning (FSL) has been extensively studied in settings with strong assumptions, making it challenging to directly apply existing solutions to the long-tail problem. This paper introduces a novel classification strategy for long-tail recognition that addresses the few-shot problem using a knowledge transfer mechanism. The proposed approach transfers knowledge from data-rich common classes to semantically similar but data-hungry rare classes to obtain richer representations. Class prototypes and learned cosine classifiers are used to compose learned features, and an attention mechanism is employed for the transfer. Importantly, the information is only transferred from common to rare classes, addressing the limited reliability of classifiers trained in few-shot settings and allowing for the introduction of new, unseen classes. The proposed approach is model-agnostic and leverages a pre-trained model, allowing for easy adaptation to new classes and tailored classifiers for specific class groups. The paper also provides an analysis of the impact of cosine classifiers on pre-trained backbones and the impact of sampling strategies on prototype quality, along with recommendations for optimizing the feature and classifier learning stage. The contributions of this work include a novel knowledge transfer mechanism that improves the performance of rare classes without additional training requirements, a flexible solution for continual adaptation to new classes, and an analysis of training strategies with optimization recommendations.