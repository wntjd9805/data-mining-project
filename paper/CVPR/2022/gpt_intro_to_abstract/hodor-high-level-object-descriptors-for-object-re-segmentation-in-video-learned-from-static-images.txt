Video Object Segmentation (VOS) methods have achieved impressive results by learning pixel-to-pixel correspondences between image frames in a video. However, these methods rely on large amounts of densely annotated video data for training, which is labor-intensive and redundant. In contrast, single image datasets with hundreds of thousands of annotated images are available. This paper explores the possibility of learning VOS with only single-image annotations.To address this, the authors propose HODOR: High-level Object Descriptors for Object Re-segmentation, a novel VOS framework. HODOR extracts robust, high-level descriptors for objects and background in an image and uses them to re-segment objects in another video frame, even if the object moves or changes appearance. This approach differs from traditional methods that learn low-level, pixel-to-pixel correspondences. HODOR leverages the idea that high-level object descriptors can be learned without sequential video data, focusing on object appearance rather than motion.The key aspect of HODOR is the incorporation of a concise descriptor, an information bottleneck, which prevents the trivial summarization of object mask shape and location. The network learns to encode object appearance concisely and match the descriptor to pixels for re-segmentation.HODOR can be trained using single annotated images without requiring video motion augmentation and still be applied to video. This is not possible with traditional methods, as learning correspondences necessitates comparing multiple frames. Augmenting single image training with sequential augmentation increases HODOR's robustness, outperforming existing methods on benchmark datasets.Another advantage of HODOR is its ability to be trained with cycle consistency on video using only a single annotated frame. The network propagates masks through unlabeled frames and applies the loss in reverse back to the labeled frame using a fully differentiable formulation. This enables the network to tolerate appearance changes occurring in natural video.HODOR has additional advantages, including the ability to model interactions between an arbitrary number of objects and incorporate temporal history during inference. The proposed framework achieves state-of-the-art results on benchmark datasets, surpassing methods trained without video annotation.In summary, this paper introduces HODOR, a novel VOS framework that uses high-level descriptors to propagate objects across video. It allows training with single images, with or without additional unlabeled video frames, and can process multiple objects simultaneously while incorporating temporal context during inference. The proposed framework achieves superior performance compared to existing methods trained without video annotation.