Understanding human actions and behaviors is crucial for various computer vision applications. Significant progress has been made in 2D and 3D human pose and shape estimation from single images. However, existing methods often neglect the interaction between humans and scenes, leading to physically implausible results. Most methods simplify the scene or body assumptions, which limits their accuracy and generalizability. Moreover, none of these methods utilize image evidence when predicting human-scene contact. Although some methods estimate human object interaction from images, they only consider 2D image regions and do not relate them to the 3D body. To address these limitations, we propose a framework that directly estimates 3D contact on the body from a single image. Our framework utilizes a new dataset, called RICH, that captures human-scene contact by extending a markerless motion capture method to markerless contact capture. The dataset provides high-resolution multiview images, dense full-body scene-contact labels, 3D scene scans, and 3D human shapes and poses. We develop a novel network architecture, BSTRO, based on the transformer model, which enables learning non-local relationships and leveraging scene information to infer unseen contact. We evaluate our method on RICH and demonstrate its superior performance compared to existing approaches. Additionally, we assess the performance of state-of-the-art human pose and shape estimation methods on RICH and analyze their performance with respect to scene-contact. Our findings highlight the importance of considering scene contact in accurate human pose and shape estimation.