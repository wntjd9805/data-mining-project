Deep neural networks (DNNs) have made significant progress in computer vision tasks, but their success relies heavily on large amounts of annotated data, which is time-consuming and expensive to obtain. Unsupervised domain adaptation (UDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain in the presence of a domain shift. Existing UDA methods typically focus on learning domain-invariant feature representations using moment matching or adversarial learning techniques. Adversarial learning has shown promise in UDA, but current methods suffer from ambiguous predictions or mode collapse issues. In this paper, we propose a novel adversarial paradigm for UDA that leverages the original task-specific classifier as a discriminator. We introduce a new discrepancy measure, called Nuclear-norm Wasserstein discrepancy (NWD), which uses the advantages of both Nuclear norm and 1-Wasserstein distance to encourage prediction determinacy and diversity. Our proposed method, called Discriminator-Free Adversarial Learning Network (DALN), achieves UDA classification without an explicit domain discriminator. DALN outperforms existing state-of-the-art methods and the NWD can be used as a regularizer to improve the performance of other methods. Our contributions include a new UDA paradigm, a new discrepancy measure, and a simple and efficient UDA method. Experimental results on various datasets demonstrate the effectiveness of our proposed approach.