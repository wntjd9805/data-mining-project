Image stitching algorithms aim to generate wide Field of View (FoV) images by aligning and stitching together multiple images with overlapping regions. However, these methods often result in irregular boundaries in the non-overlapping regions, which can be visually unpleasant. Traditional approaches to address this issue involve cropping the stitched image, but this reduces the FoV, contradicting the purpose of image stitching. Another solution is image completion, but current methods are insufficient and may introduce unrealistic content. In this paper, we propose a novel one-stage learning baseline approach for image rectangling, which aims to warp the stitched image to a rectangle while preserving content fidelity. Our approach utilizes a fully convolutional network to predict an initial mesh that is content-aware, and a comprehensive objective function is designed to encourage boundary rectangularity, mesh shape preservation, and content perceptual naturalness. Unlike existing methods, our approach can preserve both linear and non-linear structures, and it is more robust and generalizable. We also introduce a deep image rectangling dataset (DIR-D) for training and evaluate our approach quantitatively and qualitatively, demonstrating its effectiveness and efficiency in generating content-preserving rectangular images.