Semantic segmentation is a fundamental topic in computer vision and has been widely used in various downstream tasks. Most existing approaches for semantic segmentation are designed to train on daytime images with favorable illumination, which limits their performance in challenging outdoor scenes, such as nighttime. This paper focuses on semantic segmentation at nighttime, where the low exposure of captured images and the lack of ground truth pose significant challenges. To address this problem, domain adaptation methods have been proposed to adapt daytime-trained models to nighttime without requiring ground truth labels in the nighttime domain. Some previous methods utilize image transfer networks or twilight as intermediate target domains, but they fail to fully utilize the semantic embedding of the segmentation task and introduce additional complexity or increase inference time. In this work, we propose an end-to-end multi-source multi-target domain adaptation framework for nighttime semantic segmentation. We leverage the differences in illumination and datasets as the domain shift and propose a cross-domain correlation distillation approach to improve the performance of nighttime segmentation. Our approach does not require extra data or style transfer networks, thus maintaining the inference time of the segmentation network. Experimental results on Dark Zurich and ACDC datasets demonstrate that our approach achieves state-of-the-art performance in nighttime semantic segmentation.