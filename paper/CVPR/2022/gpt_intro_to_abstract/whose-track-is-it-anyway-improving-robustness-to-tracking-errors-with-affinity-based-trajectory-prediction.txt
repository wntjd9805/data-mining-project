Tightly integrating multi-object tracking and trajectory prediction in an autonomy stack poses a challenge due to the isolated development of these methods in prior works. The direct use of tracking outputs as prediction inputs can lead to a significant drop in accuracy, primarily caused by tracking errors such as identity switches and fragments. In this paper, we propose an affinity-based prediction (Affinipred) framework that eliminates the need for data association and utilizes raw detections and affinity matrices as prediction inputs. Our key insight is to preserve the soft affinity information by skipping the data association step, which can improve accuracy in cases of ambiguous matching and potential data association errors. We introduce a transformer architecture that models joint attention between detections across frames and an affinity-based attention mechanism that incorporates full object affinity information. Additionally, Affinipred incorporates advancements from prior work, including a conditional variational autoencoder for multi-modal predictions, joint interaction modeling for scene-consistent predictions, and the use of maps to capture environmental information.