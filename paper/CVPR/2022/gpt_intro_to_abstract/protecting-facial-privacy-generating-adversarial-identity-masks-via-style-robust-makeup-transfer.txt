In recent years, face recognition systems based on deep neural networks (DNNs) have experienced rapid development. However, these powerful systems also pose a significant threat to personal privacy. Excessive surveillance on users through large-scale photo analysis and identification of social media profiles has raised concerns regarding unauthorized face recognition. To address this issue, data poisoning attacks and adversarial examples have been proposed as potential solutions for protecting facial privacy. However, existing approaches have limitations in terms of accessibility to target models, poor visual quality of adversarial face images, and weak transferability in real-world scenarios. In this paper, we propose a new framework called adversarial makeup transfer GAN (AMT-GAN) to generate adversarial face images with natural appearance and stronger black-box attack strength. We leverage the concept of makeup to arrange perturbations in a reasonable way, ensuring that they appear natural and comfortable while maintaining a high attack ability. AMT-GAN utilizes generative adversarial networks to construct adversarial examples that inherit makeup styles from a reference image. We introduce a regularization module to reconcile conflicts between adversarial noises and cycle consistency loss in makeup transfer. Additionally, we incorporate a joint training strategy that combines traditional GAN training, the regularization module, and transferability enhancement processes to encourage the generator to effectively transfer common adversarial features between different models. Our proposed AMT-GAN framework is the first to address the collapse phenomenon of cycle consistency and domain mappings when using image-to-image translation GANs to craft adversarial examples. Experimental results on multiple benchmark datasets demonstrate the effectiveness of AMT-GAN in attacking various deep face recognition models, outperforming state-of-the-art methods by 4% to 60%. Overall, our work provides a practical approach for protecting face images against unauthorized face recognition systems by generating adversarial examples with outstanding black-box attack performance and natural appearance. The proposed AMT-GAN framework has the potential to be applied in other security-sensitive fields involving GANs, such as Deepfake.