Image matting is a fundamental computer vision task that aims to obtain the high-quality alpha matte of a foreground object given an input image. Despite recent advancements in deep learning-based methods, the robustness of these methods is still underexplored due to limited training/test data. This paper addresses two important challenges in image matting: robustness to trimap and domain generalization. Existing matting methods are sensitive to the shape/size of the trimap, which is commonly used as prior input by users. This sensitivity requires users to spend more time accurately brushing the trimap. To enhance robustness, the paper proposes optimizing the trimap to be more detailed by leveraging a multi-task learning approach. However, the context modeling of the trimap in this method remains limited, hindering its robustness in real-world applications. The second challenge addressed in the paper is the domain gap between deep matting models trained on synthetic data and real-world domains. While synthetic datasets are more readily available for training, they may not generalize well to real-world images. Some existing works attempt to narrow this domain gap through extra data augmentation, but significant performance degradation on synthetic benchmarks occurs simultaneously. Therefore, the paper aims to develop a model that can generalize to broader scenes without sacrificing performance on benchmark data.To tackle these challenges, the paper presents a more robust matting method (RMat) that achieves higher robustness to diverse trimap precision and better generalization to various domains. The proposed method consists of two steps: building a strong baseline model with multilevel context assembling and incorporating strong data augmentation strategies specifically tailored for matting. The paper conducts experiments and visualizations to verify the robustness and generalization capability of the proposed method, showcasing state-of-the-art results on benchmarks and improved performance in terms of trimap precision and generalization to real-world images.In summary, the contributions of this paper include: 1) a strong matting framework with multilevel context assembling, 2) strong augmentation strategies targeting matting, 3) designs of experiments and visualizations to verify the generalization capability of matting models, and 4) state-of-the-art results on benchmarks, higher robustness to varying trimap precision, and better generalization to real-world images.