Federated learning (FL) allows clients to collaboratively train machine learning models while preserving data privacy. However, the heterogeneity of data among clients poses challenges for optimization. Existing solutions aim to mitigate data heterogeneity by introducing proximal terms to restrain local updates. However, these methods limit local convergence potential and require extensive communication rounds. Moreover, they overlook resource constraints and incur significant overhead on client devices. In this paper, we propose a new approach to address data heterogeneity by focusing on local learning generality rather than proximal restriction. We analyze the effectiveness of various regularization methods and identify indicators for successful FL optimization. We then introduce FedAlign, a distillation-based regularization method that promotes local learning generality while maintaining resource efficiency. By regularizing the last block of the network, FedAlign achieves state-of-the-art accuracy with less computation and memory overhead compared to other methods. Our contributions include a novel perspective on data heterogeneity, empirical analysis of regularization methods, theoretical indicators for optimal FL methods, and the development of FedAlign to improve FL performance.