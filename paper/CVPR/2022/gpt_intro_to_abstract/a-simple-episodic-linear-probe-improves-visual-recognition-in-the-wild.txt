Deep neural networks have shown impressive performance in visual recognition tasks, thanks to their ability to learn compact and discriminative visual representations. However, the theoretical understanding of how these networks generalize remains largely unsolved. To investigate this, various analytical tools have been used, including visualization techniques and geometric probes. One effective strategy is to employ linear probes, which quantitatively evaluate the quality of learned features. Linear probes have been used to analyze the dynamics of intermediate layers and evaluate feature generalization in self-supervised visual representation learning. In this paper, we propose an Effective Linear Probe (ELP) that measures linear separability of learned features and applies a regularization term to mitigate model bias. By adaptively modulating the cross-entropy loss, ELP-SR improves the discriminability of learned features and achieves significant improvements in various visual recognition tasks, including fine-grained, long-tailed, and generic recognition datasets. Experimental results on six standard datasets validate the effectiveness of our approach in enhancing deep networks' generalization performance.