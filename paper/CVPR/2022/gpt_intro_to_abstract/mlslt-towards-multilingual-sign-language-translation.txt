Sign languages are the main form of communication for millions of deaf or hard-of-hearing individuals worldwide. However, the differences between sign language and spoken language can create communication barriers between deaf individuals and hearing individuals, impacting their daily lives. Most previous studies in sign language translation have focused on building bilingual sign language translation (BSLT) models for specific language pairs, such as American Sign Language to English. However, there are over 300 sign languages in the world, and creating individual models for each language pair is not practical. In this paper, we propose a single model for translating between multiple sign languages and spoken languages, known as the multilingual sign language translation (MSLT) model. We highlight the advantages of the MSLT model over the BSLT model and discuss the challenges in building such a model, such as the lack of MSLT corpus and language divergence. To address these challenges, we construct the Spreadthesign-Ten (SP-10) dataset, a large-scale parallel multilingual sign language understanding dataset. This dataset contains videos and spoken translations in ten sign languages, making it suitable for various tasks like multilingual sign language translation and sign language generation. We propose the MLSLT model, an end-to-end MSLT model based on the Transformer architecture, with two novel data-driven routing mechanisms: inter-layer language-specific routing (InterLSR) and intra-layer language-specific routing (IntraLSR). These mechanisms help control parameter sharing between different languages, reducing language conflicts and representation bottlenecks. Experimental results on the SP-10 dataset show that our proposed MLSLT model achieves higher BLEU and ROUGE scores compared to the MSLT baseline and BSLT baseline models, while using fewer parameters. We also explore zero-shot translation in sign language and find that our model performs comparably to supervised BSLT models on some language pairs, demonstrating the potential of our approach.Our main contributions include the creation of a large-scale multilingual sign language understanding dataset, the exploration of the MSLT problem, and the development of the MLSLT model with novel dynamic routing mechanisms. Our experimental results provide new baselines and insights for future research in the field of sign language translation.