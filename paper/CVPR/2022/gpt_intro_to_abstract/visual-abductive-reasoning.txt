This paper introduces the concept of Visual Abductive Reasoning (VAR), which explores the application of abductive reasoning in computer vision tasks. The authors propose a novel task and dataset for investigating the abductive reasoning ability of AI systems in daily visual situations. VAR requires the AI systems to describe incomplete visual observations and generate hypotheses to best explain the observations. The paper discusses the characteristics that make VAR challenging, including the need for imagination, discovering causal structures, and dealing with incomplete information. The authors also present their dataset, which contains 9K examples from videos, and introduce a new model called REASONER, which is built upon a Transformer architecture. Extensive experimental results show that REASONER outperforms existing models in the VAR task but is still far behind human performance. The paper concludes by mentioning a related study on image-based abductive reasoning and asserts the importance of exploring vision-based abductive reasoning.