Event cameras are neuromorphic sensors that offer distinct advantages over conventional frame-based cameras in challenging environments. They provide high dynamic range and microsecond-scale temporal resolution, making them suitable for conditions where standard cameras struggle, such as extreme motion or low lighting. However, the noisy and feature-lacking nature of event data obtained in these conditions poses challenges for event-based object recognition algorithms. This paper proposes Ev-TTA, a test-time adaptation algorithm for event-based object recognition. Ev-TTA aims to adapt a pre-trained event classifier to new environments with large domain shifts without requiring labeled data from the target domain. The algorithm leverages the distinctive characteristics of event data in the space-time domain. It enforces the consistency of predictions for temporally adjacent streams and removes events that lack neighboring events in the opposite polarity. By intervening with the input event and output probability distribution, Ev-TTA is versatile and applicable to various event representations, datasets, and tasks. Experimental evaluations demonstrate significant performance gains in event-based object recognition using Ev-TTA across different event representations and external conditions. Additionally, Ev-TTA can be extended to event-based regression tasks, highlighting its broad applicability in event-based vision algorithms. The contributions of this paper include a novel test-time adaptation objective, a noise removal mechanism for low-light conditions, comprehensive evaluation of Ev-TTA, and the extension to event-based regression tasks. Overall, Ev-TTA successfully adapts event-based vision algorithms to a wide range of external conditions.