Achieving free-viewpoint navigation of 3D objects or scenes from a set of calibrated images has become an important task in computer science. Neural Radiance Fields (NeRFs) have recently emerged as powerful representations for this task, providing state-of-the-art quality. However, NeRFs suffer from lengthy training times and inefficient rendering of new views, making them impractical for many applications. While some follow-up methods have shown speed improvements during testing, they do not significantly reduce training times or maintain quality. This paper proposes a method that utilizes a dense voxel grid to directly model the 3D geometry, resulting in super-fast convergence during training. The key to this approach is optimizing the volume density within the voxel grid directly, which avoids the need for conversion steps or cross-scene pretraining. The paper introduces two priors to address suboptimal geometry solutions and proposes post-activation voxel-grid interpolation to achieve sharp boundary modeling at lower grid resolutions. The proposed method achieves convergence speeds that are two orders of magnitude faster than NeRF, reducing training time from hours to minutes. It also achieves comparable visual quality to NeRF at a rendering speed that is 45 times faster. Importantly, the proposed method does not require cross-scene pretraining and achieves high-quality results with a lower grid resolution compared to previous work. Overall, this paper presents a novel and efficient approach for free-viewpoint navigation using dense voxel grids, offering significant improvements in training time and rendering speed without compromising on quality.