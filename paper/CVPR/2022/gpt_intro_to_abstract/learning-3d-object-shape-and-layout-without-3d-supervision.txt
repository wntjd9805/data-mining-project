Understanding the 3D structure of a scene is crucial for various applications in computer vision. However, directly measuring or perceiving 3D structure is often impractical, leading to the need for inferring 3D shape and layout from 2D images. While deep learning methods have improved 3D understanding from single images, they typically rely on ground truth 3D shape and layout for training, limiting scalability. Some recent approaches without any 3D supervision face challenges scaling to the complexities of the real world. Another approach is to use multiple views, but classical techniques lack semantic prediction and are not learned from data. Recent advancements in differentiable rendering have shown promise as they learn from multi-view images and 2D supervision. However, these methods have only been applied to simple images with a single object. In this paper, we propose an unsupervised approach, called USL, for predicting 3D object shapes and layout in complex scenes from a single image. Our method does not rely on ground truth shapes or layouts during training and learns from object silhouettes in multi-view images. We augment an existing method, Mesh R-CNN, with a layout network and use differentiable rendering and distance transform loss to predict layout. We demonstrate the effectiveness of our approach on three datasets, including complex real-world scenes, showing its scalability and utility.