Semantic segmentation is a widely studied problem in computer vision that has seen significant advancements with the rise of deep learning and the availability of large-scale annotated datasets. However, existing pre-trained models have limitations in terms of incremental updates and their knowledge is often restricted to a fixed set of classes. The naive solution of training new models from scratch with augmented datasets is impractical due to time and energy consumption concerns. This paper proposes a solution to incrementally update pre-existing models by adding new classes using weak supervision in the form of image-level labels. The proposed framework, called Weakly-Supervised Incremental Learning for Semantic Segmentation (WILSS), combines the benefits of incremental learning and the use of cheap and easily available annotations. Existing weakly-supervised methods for segmentation require pixel-wise supervision, which is expensive and time-consuming to collect. This paper introduces WILSON, a Weakly Incremental Learning framework for semantic Segmentation, that incrementally trains a segmentation model using online pseudo-supervision generated from image-level annotations. WILSON utilizes a localizer on the encoder to extract pseudo-supervision and improves its quality through regularization. Unlike previous works, soft-labels are used instead of hard labels to address noise in the pseudo-supervision. Experimental results on benchmark datasets demonstrate the superiority of the proposed approach over offline weakly-supervised methods and its comparability with fully supervised incremental learning methods.