Generative Adversarial Nets (GANs) have been successful in generating photo-realistic images but lack control over the synthesized content. This limitation hinders their usefulness in applications such as autonomous driving and reinforcement learning. Previous approaches introduced supervision in the form of class labels, requiring annotated data and intricate engineering. In this paper, we propose a method to add control to any pretrained GAN without the need for labels or supervision. Our approach leverages clusters formed in the intermediate representation space of the generator. We assume that these clusters correspond to different semantic attributes, allowing us to control image generation by conditioning on the cluster assignment. We employ Implicit Maximum Likelihood Estimation (IMLE) for latent sampling from these clusters. By benchmarking against clustering-based GANs and interpretable direction methods, we demonstrate the effectiveness of our approach in consistently generating images with desired attributes. Our proposed framework is outlined, depicting the training and testing phases. Overall, our method provides a solution for controllable generation in GANs without the need for annotation or extensive engineering.