Exponential behavior is commonly observed in machine learning models, but it can lead to undesired outcomes. This paper examines the negative effects of exponential behavior, such as overconfident predictions in the tails of distributions and vulnerability to adversarial attacks. The authors propose a partial remedy by shifting to models with polynomial behavior, which promotes conservativeness and uncertainty in predictions. Specifically, a polynomial form of softmax estimation, called softRmax, is introduced as a substitute for the standard softmax activation in logistic regression and deep learning models. The authors demonstrate that softRmax improves robustness against adversarial attacks by maintaining performance and minimizing prediction changes. This robustness is attributed to the conservativeness of softRmax and inherent gradient regularization. The benefits of conservativeness are discussed in the context of covariate shift, and empirical experiments on toy and public datasets validate the robustness of the proposed polynomial substitutes. The paper also introduces a semi-black-box attack, known as an average-sample attack, to further confirm the robustness of softRmax. Additionally, a scale-invariant metric called the magnitude-margin ratio is introduced to compare the robustness of different models under the same level of attack.