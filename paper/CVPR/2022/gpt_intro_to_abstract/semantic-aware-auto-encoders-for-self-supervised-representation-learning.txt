Learning representations without human annotations is a longstanding vision in the field of computer science. Recently, there has been a resurgence of interest in unsupervised learning, thanks to the remarkable progress in self-supervised learning (SSL). SSL can be divided into two groups: generative models (G models) and discriminative models (D models). In computer vision, the mainstream SSL algorithms belong to D models, which learn representations through agent tasks such as patch ordering, solving jigsaw puzzles, and rotation prediction.However, D models have several disadvantages, including the need for careful design, special regularizations, unusual optimizations, and non-trivial architectures. Additionally, recent studies have suggested that G models might be more effective than D models in certain aspects, such as generalization and interpretability. G models can be particularly useful in pretraining foundation models for fine-tuning or downstream tasks.In this paper, we propose a switch from D models to G models using classical auto-encoders (AEs). Previous works have rarely used G models due to their perceived inefficiency compared to D models. However, we address the issue of semantic agnosticism in G models by designing a novel semantic-aware AE that learns representations through cross-view image reconstruction. This approach allows the model to focus on visual concepts rather than semantic-agnostic information compression.To overcome the challenges of optimizing G models, we also propose a semantic alignment technique that aligns the hidden AE codes with the reconstruction target using geometric transformation knowledge. These techniques significantly improve the representation learning ability of AE and make SSL with G models feasible in computer vision.Our contributions can be summarized as follows:1. We explore the possibility of replacing D models with G models in SSL in computer vision and propose a novel semantic-aware AE inspired by perceptual learning.2. We introduce a semantic alignment technique that improves the optimization capabilities of semantic-aware AE.3. Extensive experiments demonstrate the state-of-the-art performance of our method on various benchmarks and tasks, highlighting the effectiveness of our approach in feature learning, generalizability, and interpretability.Overall, our research opens up new possibilities for unsupervised learning in computer vision and showcases the potential of G models in representation learning.