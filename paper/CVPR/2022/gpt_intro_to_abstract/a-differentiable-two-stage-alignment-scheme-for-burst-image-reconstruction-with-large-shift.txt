Color demosaicking and denoising are crucial steps in reconstructing high-quality full-color images from raw sensor data in digital camera imaging pipelines. These tasks are often performed jointly in joint denoising and demosaicking (JDD) algorithms. With the rise of smartphone cameras, restoring images with low signal-to-noise ratios has become increasingly important, leading to the emergence of burst image processing, which involves capturing a sequence of low-quality frames and fusing them to produce a higher-quality photograph. The main challenge in burst image restoration lies in compensating for shifts between frames. Previous approaches have relied on optical flow estimation and spatially variant kernels, but accurately estimating these factors is difficult due to noise. Implicit alignment in the feature domain has shown promise in video super-resolution and denoising, but it is less effective for image sequences with large shifts. Additionally, precise pixel-wise alignment on full-size images with large motion is computationally expensive. To address these issues, we propose a differentiable two-stage alignment framework for joint denoising and demosaicking of burst images. This framework divides the alignment problem into coarse and refined alignment stages to handle large shifts more effectively. We introduce a differentiable progressive block matching method for coarse alignment, which reduces computational complexity, and use deformable convolution for refined alignment to achieve accurate image restoration. Our experiments demonstrate that our two-stage alignment method outperforms existing approaches, achieving impressive improvements in burst image restoration.