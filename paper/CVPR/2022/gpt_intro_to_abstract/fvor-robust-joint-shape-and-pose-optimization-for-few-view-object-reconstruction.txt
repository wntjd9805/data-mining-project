Reconstructing 3D shapes from un-registered RGB inputs is a longstanding problem in computer vision. One popular approach is to integrate Structure-from-Motion (SfM) and Multi-view Stereo (MVS), relying on dense image coverage to obtain accurate camera poses and correspondences. Recent works have focused on learning monocular 3D reconstruction, using shape priors to infer complete geometry from partial observations. However, acquiring dense input views is tedious and not user-friendly. This paper presents a novel approach for few-view reconstruction, where the input views cover most of the object and only a small portion needs to be filled in. Few-view reconstruction is challenging as accurate image poses are difficult to estimate from the input images themselves. The proposed approach jointly optimizes shape reconstruction and camera poses, using a pose initialization module, a shape module, and a pose refinement module. The pose initialization module reduces outlier predictions, while the shape and pose refinement modules improve the accuracy of the reconstruction. The approach outperforms existing techniques on ShapeNet and is significantly faster than optimization-based approaches.