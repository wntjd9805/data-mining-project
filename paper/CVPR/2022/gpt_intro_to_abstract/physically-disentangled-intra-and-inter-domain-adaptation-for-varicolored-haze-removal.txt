Haze is a weather phenomenon that causes poor visual quality and hampers high-level vision tasks. Image dehazing methods have been extensively studied, with previous approaches focusing either on intra-domain (varicolored haze spaces) or inter-domain (synthetic and real image) gaps. However, there is a lack of methods that consider both gaps simultaneously. In this paper, we propose a physically disentangled joint intra- and inter-domain adaptation (PDI2A) framework for semi-supervised varicolored image dehazing. Our framework addresses varicolored haze removal by decomposing the problem into two sub-problems: intra-domain color alignment and inter-domain synthetic-to-real haze removal. We utilize physical and learning-based reconstructions to exchange knowledge between synthetic and real data. Our approach also employs self-consistency and adversarial loss for better information preservation and translation. Experimental results on real and synthetic data demonstrate the effectiveness of our method in varicolored image dehazing. Our approach offers a novel and practical solution, addressing both intra-domain and inter-domain gaps simultaneously, and significantly improving image dehazing performance.