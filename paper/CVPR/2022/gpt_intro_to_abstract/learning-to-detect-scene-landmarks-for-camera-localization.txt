Camera localization is a fundamental task in enabling VR/AR systems that allow users to interact with 3D scenes. However, existing localization methods that use retrieval and feature matching may raise privacy concerns, and their long-term storage requirements can become impractical. Learned localization approaches have addressed these issues by encoding scene information in the parameters of a convolutional neural network (CNN), but their performance still lags behind traditional methods. In this paper, we propose a new learned method that preserves privacy, requires low storage, and outperforms existing storage-free pose regression methods. We achieve this by recognizing scene-specific 3D points called scene landmarks from a query image, establishing 2D-3D correspondences, and using them to estimate the camera pose. This landmark recognition approach is privacy-preserving and doesn't require storing visual features. We train a scene-specific CNN architecture to detect the landmarks, and introduce a Neural Bearing Estimator (NBE) that directly regresses the 3D bearing vectors for the scene landmarks. Our method has comparable performance to existing methods on established datasets and outperforms them on a new dataset with challenging scenarios. We also demonstrate that our method can complement other localization methods. Our contributions include a new formulation for privacy-preserving landmark localization, a dataset for evaluating camera localization performance, and superior results with low storage requirements compared to existing methods.