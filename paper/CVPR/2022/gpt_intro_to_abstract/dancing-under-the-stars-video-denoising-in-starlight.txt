This paper addresses the challenge of capturing high-quality images and videos in extremely low-light conditions. While some animals exhibit the ability to navigate in near complete darkness, most CMOS cameras require a certain level of illumination to capture moving objects at night. Long exposure times can be used to collect more light, but this sacrifices temporal resolution and is not suitable for capturing moving scenes. Alternatively, increasing the gain of the camera can enhance sensitivity to light, but it also introduces significant noise.Denoising algorithms have been developed to improve image quality in noisy images, but most of these methods are based on simplistic noise models that do not apply in extremely low-light settings. The noise in such conditions is often non-Gaussian, non-linear, sensor-specific, and difficult to characterize. Recently, deep learning-based approaches have shown promising results in low light, but they require a large number of training image pairs, which are camera-dependent and impractical to obtain for moving scenes.To address these challenges, the proposed method combines a high-gain camera optimized for low-light imaging, a physics-inspired noise generator, and synthetic clean/noisy video pairs to train a video denoiser. The noise generator is trained using a limited dataset of still clean/noisy bursts, eliminating the need for experimental motion-aligned video clips. The denoising network achieves remarkable performance in low-light conditions, generating photorealistic video denoising in submillilux levels of illumination for the first time.Experimental results demonstrate the effectiveness of the proposed approach in capturing challenging scenes with extensive motion, where subjects are illuminated only by the light of the Milky Way and a meteor shower. This method enables the capture of high-quality videos in extremely low-light settings, expanding the possibilities for low-light imaging applications.