Unsupervised image-to-image translation (UNIT) aims to translate images from one domain to another without paired data. However, existing UNIT methods that rely on cycle-consistency and assume a bijection between domains often struggle with translations involving large cross-domain shape and appearance differences. Translating across such domains requires establishing translations at a higher semantic level. This paper introduces a GP-UNIT framework that expands the application scenarios of previous UNIT methods by capturing coarse-level correspondences across various heterogeneous and asymmetric domains. The framework also learns fine-level correspondences adaptively and retains essential content features, avoiding artifacts commonly observed in cycle reconstruction. The contributions of this work include the proposal of the GP-UNIT framework, an effective way of learning robust correspondences, and a novel coarse-to-fine scheme for learning cross-domain correspondences at different semantic levels.