This paper introduces a set of distribution shifts designed to test the robustness of computer vision models. Unlike previous shifts that only perform 2D modifications, these shifts incorporate 3D information to generate corruptions that are consistent with real-world scene geometry. The resulting set includes 20 corruptions, each representing a distribution shift from training data, denoted as 3D Common Corruptions (3DCC). These corruptions address various aspects of the real world, such as camera motion, weather, occlusions, depth of field, and lighting. Compared to 2D-only approaches, the corruptions in 3DCC are more diverse and realistic. The paper demonstrates that methods aiming to improve robustness, including those with diverse data augmentation, perform poorly under 3DCC. Additionally, the paper shows that the robustness issues exposed by 3DCC correlate well with corruptions generated via photorealistic synthesis. The proposed corruptions are programmatically generated and can be finely analyzed by adjusting parameters. They are computationally efficient and can be applied as data augmentation during training. The corruptions are also extendable and can be applied to standard vision datasets that do not have 3D labels. Overall, this work provides an important testbed for real-world corruptions, particularly those dependent on scene geometry. It also introduces new 3D data augmentations that significantly enhance model robustness against realistic corruptions that cannot be addressed by 2D augmentations.