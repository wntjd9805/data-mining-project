The field of computer vision has seen rapid development in convolutional neural network (CNN) based techniques for various tasks such as instance segmentation and semantic segmentation. However, collecting labeled data for these tasks is time-consuming and labor-intensive. In contrast, humans are able to recognize new concepts with only a few examples, which has led to the proposal of few-shot learning (FSL) in computer vision. This paper focuses on few-shot segmentation (FSS), where the model uses only a few labeled training data to segment specific semantic categories. Most existing FSS approaches rely on meta-learning frameworks, but they are biased towards seen classes and struggle with hard query samples. To address this, the authors propose a scheme called BAM (base and meta) that introduces an additional base learner to explicitly predict base class regions in query images. The coarse predictions from the base and meta learners are then integrated to achieve accurate segmentation. The authors also propose using evaluation results of scene differences between query-support image pairs to adjust the meta learner's predictions. The proposed scheme achieves state-of-the-art results on FSS benchmarks and is extended to the more challenging generalized FSS setting, where both base and novel class targets need to be determined. Overall, the contributions of this paper include addressing the bias problem, utilizing scene differences for prediction adjustments, achieving state-of-the-art results, and extending the approach to the generalized FSS setting.