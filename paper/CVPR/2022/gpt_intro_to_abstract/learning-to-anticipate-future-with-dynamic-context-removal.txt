Anticipating human action is crucial for intelligent systems in various applications, such as autonomous driving and human-robot interaction. With advancements in deep learning, there has been growing interest in understanding and analyzing human action videos. Traditional recognition approaches leverage spatiotemporal modeling to recognize spatial and temporal patterns in videos. However, action anticipation, which requires predicting future actions based on current observations, is more challenging due to the temporal misalignment between visual observation and target action semantics.Previous methods have proposed neural architectures to learn temporal logic from past observations, but they still face performance limitations. In this paper, we propose an action anticipation model inspired by the curriculum learning process in Sudoku. Our model leverages auxiliary frames in training and dynamically schedules their visibility to gradually strengthen the reasoning ability of the model. We introduce the Dynamic Context Removal (DCR) learning scheme, which combines the principles of curriculum learning and gradually removing redundant context for better adaptation to the anticipation task.To demonstrate the effectiveness of our approach, we conduct experiments on four widely-used action anticipation benchmarks. Our training scheme is flexible and can be applied to different temporal reasoning architectures, such as transformer and LSTM. Experimental results show that our approach achieves state-of-the-art performance on all four benchmarks.In summary, our contributions include proposing a novel learning scheme, DCR, which improves the effectiveness and efficiency of practical temporal modeling architectures. We also introduce an order-aware pre-training method for transformer architecture and achieve state-of-the-art performance on action anticipation benchmarks. We believe that our subtractive and adaptive paradigm can be applied to other complex and challenging temporal predictive tasks.