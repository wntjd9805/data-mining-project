Most consumer cameras use CMOS sensors for imaging, which offer advantages such as low power consumption, compact design, and fast imaging. However, CMOS sensors often have rolling shutter (RS) effects, where images are captured row by row, leading to distortions when there are relative movements between the camera and objects. These distortions significantly impact image and video quality, as well as the performance of downstream tasks like 3D reconstruction and depth prediction. To mitigate the performance gap between RS and global shutter (GS) images, there are two approaches: adapting algorithms to RS distorted images or correcting the RS distortions to obtain visually-friendly GS images. Correcting RS images has gained significant research attention recently. Existing RS effect removal methods can be categorized into single-image-based and multi-frame-based approaches. Single-image-based methods rely on external constraints or priors to restore GS images from RS images. Multi-frame-based methods, using convolutional neural networks (CNNs) and motion information, aim to remove RS distortions by warping operations. However, current methods still face challenges such as inaccurate motion modeling, non-learnable warping operations, difficulties in generating unseen areas, and limitations of synthesized datasets. To address these limitations, we propose a novel adaptive warping module and a real-world dataset for rolling shutter correction. Our model takes three consecutive frames as input and utilizes an adaptive warping module to improve accuracy and handle various motions. We also contribute the BS-RSC dataset, the first real-world dataset for RS correction with diverse motions. Experimental results show the superior performance of our proposed method compared to state-of-the-art methods on both real-world and synthetic datasets.