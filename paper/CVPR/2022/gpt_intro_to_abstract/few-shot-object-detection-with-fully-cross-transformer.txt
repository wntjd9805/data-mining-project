Few-shot object detection (FSOD) is a challenging task that aims to detect objects using only a few training examples. Current deep-learning based methods require thousands of training examples and are prone to overfitting in data-scarce scenarios. To address this, current FSOD methods follow a two-stage learning paradigm, either using single-branch based methods or two-branch based methods. However, these methods have limitations in terms of overfitting and limited generalization ability.To overcome these limitations, we propose a novel Fully Cross-Transformer based model (FCT) for FSOD. Our model is based on the two-stage detection model Faster R-CNN but does not rely on deep convolutional networks. Instead, we use a multi-layer deep cross-transformer to jointly extract features from both the query and support branches. By aligning features at all network layers, we can capture the common features and improve the final similarity learning.In our proposed model, we introduce asymmetric-batched cross-attention to aggregate information from the two branches with different batch sizes. This allows us to align the features from both branches in each cross-transformer layer. Furthermore, we incorporate the cross-transformer in both the feature backbone and ROI feature extractor, promoting multi-level interactions between the query and support inputs.We emphasize the differences between our model and a closely related work, ViLT. While both models use transformers for joint feature extraction, our model focuses on FSOD and incorporates the cross-transformer into both the feature backbone and detection head. We also use visual images as input and explore multi-level interactions between the branches.Our contributions include being the first to propose a vision transformer based FSOD model, the development of a fully cross-transformer for multi-level interactions, and the incorporation of asymmetric-batched cross-attention. We evaluate our model on two widely-used FSOD benchmarks and achieve state-of-the-art performance.