Massive amounts of image data and manual annotations are typically needed to train deep neural networks for various computer vision tasks. However, obtaining bounding box or pixel-level annotations can be time-consuming and labor-intensive. To address this, weaker forms of supervision, such as image-level labels, have been introduced in weakly supervised object localization (WSOL) and semantic segmentation (WSSS). These methods rely on class activation maps (CAM) to estimate the location of the target object.While image-level labels enable CAM to indicate the correct location of target objects, they also limit the focus of CAM. In addition, pairs of foreground-foreground or background-background with less similar semantics can negatively affect the learning of the network. To address these challenges, we propose a feature similarity-based rank weighting method that automatically reduces the influence of dissimilar positive pairs.We initialize the activation head randomly, resulting in random class-agnostic activation maps at the beginning. By applying contrastive loss, we can pull close the representations of positive pairs and push apart the representations of negative pairs, gradually separating the regions of the foreground object and background in the image.Extensive experiments conducted on WSOL and WSSS tasks demonstrate that our proposed method, called C2AM, can replace or refine CAM for better performance. Specifically, in WSOL, our method can be used for class-agnostic object localization and object classification, allowing extraction of class-agnostic object bounding boxes for localization.