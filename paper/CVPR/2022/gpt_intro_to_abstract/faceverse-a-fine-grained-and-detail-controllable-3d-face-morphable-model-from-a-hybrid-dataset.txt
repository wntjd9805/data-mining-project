3D human face modeling is a popular research topic in the fields of computer vision and computer graphics, with applications in film, video games, mixed reality, and more. The 3D Morphable Model (3DMM) has been a powerful tool in face-related research since its introduction in 1999, offering effective control over facial shape, expression, and texture. However, recent research has presented challenges to 3DMM in terms of accuracy, photo-realistic details, and editability. Data acquisition difficulties limit the performance of 3DMMs, and previous methods have been unable to change detailed facial geometry and texture. To address these issues, we propose a hybrid dataset that combines high generalization ability and fidelity. Our approach includes a coarse-to-fine structure that allows for detailed adjustment of facial features and enables parameter-changeable facial geometry and texture details. Existing 3D face datasets have limitations in terms of scale or fidelity, with capture systems falling into sparse camera arrays or consumer depth sensors categories. The former requires elaborate setups and has a time-consuming data collection process, limiting the dataset scale. The latter offers off-the-shelf solutions but suffers from low resolution and precision. To overcome these limitations, we propose the creation of a hybrid dataset. Additionally, existing formulation of 3DMMs fails to represent parameter-changeable facial details. While PCA-based, multi-linear, and non-linear methods offer effective ways to capture shape and expression changes, none are able to fully represent the facial details such as fine-grained facial features. Our proposed approach, called FaceVerse, overcomes these limitations by combining a hybrid dataset with a coarse-to-fine structure and a conditional StyleGAN architecture. The hybrid dataset consists of a large-scale dataset captured by consumer depth sensors and a high-fidelity dataset captured by a multi-camera system. Our conditional StyleGAN architecture allows for changeable facial details while preserving basic facial attributes. We also introduce a single-image fitting pipeline based on differentiable rendering that follows the coarse-to-fine concept. FaceVerse outperforms previous 3DMM methods in terms of both qualitative and quantitative results. Our contributions include the development of a hybrid dataset and a coarse-to-fine scheme that maximizes dataset utilization and enhances model generalization and fidelity. We also introduce a novel conditional StyleGAN architecture with normal discriminators, allowing for changeable facial details, and provide a pre-trained model and detailed dataset for further research.