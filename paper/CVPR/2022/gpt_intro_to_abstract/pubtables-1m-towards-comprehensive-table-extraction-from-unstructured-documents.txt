This paper introduces the concept of table extraction (TE) and its three subtasks: table detection (TD), table structure recognition (TSR), and functional analysis (FA). Traditional rule-based methods for TE are being replaced by data-driven methods based on deep learning (DL), which can handle a wider variety of table presentation formats. However, manually annotating tables for TSR is time-consuming, leading researchers to use crowd-sourcing to construct larger datasets. Although crowd-sourced annotations solve the problem of dataset size, they present challenges in terms of completeness, consistency, quality, and explicitness of information. Additionally, oversegmentation in markup annotations can lead to incorrect interpretations of a table's logical structure. To address these challenges, the authors present a new large-scale dataset called PubTables-1M, which contains nearly one million tables from scientific articles. PubTables-1M addresses all three tasks of TE and includes richer annotation information compared to prior datasets. The authors also introduce a novel canonicalization procedure to correct oversegmentation and ensure each table has a unique, unambiguous structure interpretation. Quality verification and control steps are implemented to reduce errors, and the authors demonstrate improved performance for TSR using PubTables-1M. Additionally, the paper applies the Detection Transformer (DETR) for TD, TSR, and FA, showing how all three tasks can be addressed using a transformer-based object detection framework without customization.