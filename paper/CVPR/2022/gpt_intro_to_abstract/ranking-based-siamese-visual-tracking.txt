Visual object tracking is a challenging task in computer vision, aiming to estimate the location of a target in each frame of a video sequence. Deep learning has been widely utilized in visual tracking, with Siamese networks being one of the most popular paradigms. However, Siamese-based trackers still suffer from limitations, including the difficulty in distinguishing background distractors and the mismatch between classification and localization tasks. In this paper, we propose a ranking-based optimization (RBO) approach to address these limitations. RBO consists of both classification and IoU-guided ranking losses, which explicitly model the relationship between positive and hard negative samples and align the classification scores with the corresponding IoU values, respectively. We evaluate the effectiveness of RBO on anchor-based and anchor-free Siamese networks, and our results show significant improvement in tracking performance on diverse benchmarks without sacrificing inference speed. The proposed RBO approach provides a promising solution to enhance the discrimination capability and improve the localization accuracy of visual object trackers.