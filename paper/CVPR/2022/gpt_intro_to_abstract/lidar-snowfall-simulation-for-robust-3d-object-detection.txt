A light detection and ranging (LiDAR) sensor is a useful active range sensor for various applications. It is particularly favored for tasks that require 3D reasoning such as 3D object detection. With decreasing costs, the integration of LiDAR sensors into autonomous cars is becoming more feasible. However, previous tests have shown that LiDAR systems are vulnerable in scattering weather conditions such as rain, fog, and snow. These conditions lead to decreases in perception distances and degradation of measurement quality, impacting the performance of high-level tasks like 3D object detection. Achieving robust perception in adverse weather is crucial, as fatality rates for human drivers are higher in such conditions. Due to the challenges of collecting adverse-weather data, previous works have explored simulation methods to close the domain gap for camera and LiDAR data in fog and rain. In this paper, we introduce a physically based method to simulate snowfall on clear-weather LiDAR point clouds. Our simulation model considers the transmission of LiDAR pulses and their interaction with snow particles, taking into account factors such as particle size and potential occlusions. Additionally, we incorporate an optical model to simulate the increase in reflection from wet surfaces. The generated partially synthetic point clouds are then used as training data for optimizing state-of-the-art 3D object detection methods, aiming to improve robustness under snowfall conditions. Our benchmarking results show significant performance gains over baseline models trained on clear weather and other simulation methods.