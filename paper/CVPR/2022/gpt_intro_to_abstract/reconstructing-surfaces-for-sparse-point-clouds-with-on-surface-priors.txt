Reconstructing surfaces from 3D point clouds is a vital task in 3D computer vision. Previous geometric approaches have required extensive human interaction to set parameters for different point clouds, resulting in poor generalization ability. To address this, recent methods have leveraged a data-driven strategy to learn signed distance functions (SDFs) from 3D point clouds. However, existing methods either require ground truth supervision during training or assume dense point clouds, which may not be feasible in real-world applications.In this paper, we propose a novel approach to learn SDFs from single sparse point clouds with an on-surface prior. Our method aims to perceive the surrounding signed distance field of a surface represented by a sparse point cloud by projecting an arbitrary query location onto the surface. We introduce two constraints on these projections: each projection should lie on the surface and be the nearest to the query. We incorporate these constraints into our neural network training, resulting in two losses: one from the on-surface prior and the other encouraging minimum projection distance to the surface.Our method does not require ground truth signed distances or point normals for learning SDFs, enabling accurate surface reconstruction from sparse point clouds. We train our neural network using a data-driven strategy to capture the on-surface prior and leverage the trained network as a differentiable function for SDF learning. We evaluate our method against state-of-the-art approaches on widely used benchmarks, demonstrating superior performance in terms of surface reconstruction accuracy.Overall, our contributions include: 1) proposing a method to learn SDFs from sparse point clouds without ground truth supervision, 2) introducing an on-surface prior to determine the relationship between a point and a sparse point cloud, and 3) achieving significantly improved surface reconstruction accuracy compared to existing methods on large-scale benchmarks.