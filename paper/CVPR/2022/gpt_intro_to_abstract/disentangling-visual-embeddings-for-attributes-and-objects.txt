This paper introduces a novel approach called Object Attribute Disentanglement (OADis), which aims to disentangle attribute and object visual features in the context of compositional learning. Unlike previous works that rely on linguistic embeddings, OADis focuses on visual cues to separate attributes and objects in the shared embedding space. The proposed method leverages disentangled visual embeddings to compose new attribute-object pairs, even for unseen combinations. The paper also discusses the importance of decomposing before composing, drawing inspiration from human imagination. Experimental results demonstrate the effectiveness of OADis in the Compositional Zero-shot Learning (CZSL) setup, outperforming existing baselines on standard datasets. Additionally, a new benchmark dataset for CZSL is introduced using the VAW dataset, further validating the superiority of OADis. Overall, this work presents a promising direction for improving compositional learning in computer vision tasks by leveraging disentangled visual features.