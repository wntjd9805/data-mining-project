The use of deep convolutional neural networks has revolutionized object detection, with one-stage and two-stage detectors like YOLO and Faster R-CNN gaining popularity. However, when applied to new scenarios, pre-trained detectors often experience performance drops due to domain shift. Source-Free Object Detection (SFOD) has emerged as a promising topic, assuming only the availability of a pre-trained model on the source domain. Research on SFOD is scarce compared to Source-Free Domain Adaptation (SFDA), which focuses on sample generation and self-training pseudo labeling. Several SFOD methods based on pseudo-labeling or sample generation have been proposed, but the reliability and quality of these approaches limit their performance. To address the domain shift, we propose a new domain adaptation method called Learning to Overlook Domain Style (LODS). LODS enhances the target domain style while maintaining the original style of target images, allowing the object detector to learn to overlook target domain style. Our method consists of a style enhancement module and an overlooking style module, employing the Mean-Teacher framework. We introduce graph alignment constraints to ensure the consistency of object instance and image patch feature relationships, resulting in feature extraction that overlooks the target domain style. Our contributions include a novel learning strategy that reduces domain sensitivity, a style enhancement method that adds target domain style, and a new Mean-Teacher framework variant. Unlike existing methods, our approach achieves two-way knowledge distillation without relying on source data. The proposed LODS method shows promise for improving object detection in scenarios with domain shifts.