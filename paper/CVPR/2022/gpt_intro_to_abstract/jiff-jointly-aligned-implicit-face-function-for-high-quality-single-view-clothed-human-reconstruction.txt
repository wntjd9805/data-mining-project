The COVID-19 pandemic and social distancing measures have made video conferencing the primary mode of communication. With the increasing popularity of 3D hardware such as AR goggles, 3D telepresence is expected to become the next generation communication standard. However, high-quality 3D human reconstruction, a crucial component of this technology, has limitations such as expensive equipment and calibration procedures. This hinders its application in AR/VR settings. Recent advancements in deep learning have introduced methods that achieve impressive results using just a single image. These methods can be categorized as model-based or model-free. While model-based methods struggle with capturing high-frequency details like clothing and hair, model-free methods predict the occupancy of a discretized volume space. However, these methods often lack fine face details, which is a drawback in ultra-high-definition rendering standards. To address this, a new approach called Jointly-aligned Implicit Face Function (JIFF) is proposed. JIFF combines the benefits of the implicit function-based and model-based approaches by employing the 3D morphable face model (3DMM) as a shape prior and computing space-aligned 3D features to capture detailed face geometry and texture information. By jointly considering pixel-aligned 2D features and space-aligned 3D features, JIFF predicts an implicit face function for high-quality face reconstruction. Experiments on public benchmarks demonstrate that JIFF outperforms current state-of-the-art methods significantly.