This paper introduces a novel framework called DT-Net for 3D mesh reconstruction and generation. DT-Net enables the reconstruction of high-quality 3D meshes with diverse topologies, well-adapting to input such as images or voxels. The framework facilitates controllability in the generative process by implicitly learning a disentangled latent representation for topology and shape. The paper decouples the mesh reconstruction into topology formation and shape deformation, leading to improved reconstruction quality and the ability to generate meshes with diverse topologies. The authors propose an end-to-end framework with a topology-learning module and use invertible maps to maintain the topology between the neural template and the final reconstructed object. By directly learning the topology-aware neural template without intermediate topology annotations, DT-Net achieves high-quality mesh reconstruction and supports various generative applications with disentangled controls. Quantitative and qualitative results demonstrate the effectiveness of DT-Net in producing high-quality meshes with diverse topologies, outperforming existing methods.