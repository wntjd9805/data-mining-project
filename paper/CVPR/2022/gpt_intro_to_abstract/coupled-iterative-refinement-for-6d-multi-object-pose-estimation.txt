This paper focuses on the task of 6D multi-object pose estimation, which involves detecting and estimating the position and orientation of each object instance in an RGB or RGB-D image containing known 3D shapes. Accurate pose estimation is important for applications such as robotics tasks and augmented reality involving shape manipulation. Previous approaches to 6D pose estimation relied on estimating correspondences between 3D models and the image, followed by using solvers or iterative algorithms to obtain the object pose. However, obtaining accurate correspondences can be challenging, especially for poorly textured objects or in scenarios with occlusion, object symmetry, and lighting variations. These issues make classical systems brittle and less robust for many real-world use cases. Recent advancements in deep learning have partially addressed these challenges. Some approaches train deep networks to directly regress 6D poses, while others combine deep learning with projective geometry by detecting keypoints or imposing geometric knowledge. However, these approaches are limited in their sensitivity to outliers and errors in correspondences due to their "one-shot" nature.To overcome these limitations, this paper proposes an end-to-end differentiable architecture that incorporates geometric knowledge and employs a "coupled iterative refinement" approach. The architecture is built upon the RAFT framework, originally developed for optical flow estimation. It estimates flow between the input image and rendered images of the known 3D object, generating 2D-3D correspondences used for pose estimation. Unlike previous approaches, the proposed method iteratively refines both pose and correspondence in a tightly coupled manner, dynamically removing outliers to improve accuracy.To update the object pose, a novel differentiable layer called "Bidirectional Depth-Augmented PnP (BD-PnP)" is introduced. This layer solves for a single pose update by minimizing reprojection error on both the input image and rendered image correspondences. Additionally, the optimization objective includes the reprojection error on inverse depth, which enhances accuracy.Experimental results demonstrate that the proposed method achieves state-of-the-art accuracy on various multi-object pose benchmarks, such as YCB-V, T-LESS, and Linemod (Occluded), outperforming prior approaches. A variant of the method can also handle RGB-only input, achieving performance comparable to the current state-of-the-art.