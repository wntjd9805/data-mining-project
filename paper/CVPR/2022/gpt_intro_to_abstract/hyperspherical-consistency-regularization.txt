The advent of deep learning in computer vision has brought about significant advancements in image classification, object detection, and semantic segmentation. However, the collection and annotation of large-scale labeled datasets are time-consuming and costly. As a result, there has been growing interest in semi-supervised learning (SSL), which involves learning from a limited number of labeled data along with a large volume of unlabeled data. Contrastive learning, a recent SSL algorithm, combines self-supervised learning with supervised learning by incorporating a branch network as a projection head. Despite the improvements in feature learning, the classifier still tends to be biased due to the semi-supervision or weak supervision. Previous studies have shown that simply adjusting the classifier with balanced sampling can mitigate this bias. This implies that while quality representations are important for robust learning, regularizing the classifier is crucial for improved performance. Many existing contrastive learning methods project feature embeddings onto a hypersphere through â„“2 normalization. This restricts the output space to a unit hypersphere, ensuring training stability and linear separability of well-clustered features. Leveraging on this, we propose hyperspherical consistency regularization (HCR) to constrain the latent hyperspherical space in order to improve the generalization ability of SSL and weakly-supervised learning. Our experiments demonstrate that HCR greatly enhances performance in these areas.