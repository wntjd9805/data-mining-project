Deep learning models have shown success in computer vision tasks, but training deep models that generalize well on unseen data requires massive training data. In the medical image segmentation task, there is usually insufficient data in a single institution due to the expensive process of collecting labeled data. One solution is to gather data from multiple institutions, but this raises concerns for data privacy and security.Traditional distributed training methods have limitations in terms of communication complexity and security. Federated learning (FL) has been proposed to tackle these issues. In medical applications, cross-silo federated learning is of particular interest, where there are a limited number of participating clients. However, a challenge in FL is the non-iid data distribution on different clients, leading to client drift and compromised training performance.In this paper, we propose a novel training framework called Federated Super Model (FedSM) for FL medical image segmentation tasks. FedSM avoids the client drift issue by producing personalized models that fit different data distributions well. We also introduce a novel model selector to determine the closest model/data distribution for any test data.Our contributions include:1. Introducing FedSM as a training framework to address the client drift issue and close the generalization gap between FL and centralized training for medical segmentation tasks.2. Presenting a novel formulation for personalized FL optimization and a method called Soft-Pull to solve it in FedSM. We provide a rigorous convergence analysis for the proposed method.3. Conducting experiments on real-world FL medical image segmentation tasks to validate the effectiveness of our framework and methods compared to existing FL baselines.Overall, our work aims to improve the performance and efficiency of FL in medical image segmentation tasks, bridging the gap between FL and centralized training.