Hyper-Parameter Optimization (HPO) is a crucial subfield in Automatic Machine Learning (AutoML). With the rise of deep learning, the training of large-scale neural networks requires significant computing resources and manual tuning of hyper-parameters has become expensive. However, improper hyper-parameters can lead to training failure. The challenge of HPO varies across different subfields of machine learning, especially in computer vision where hyper-parameters are more sensitive. Mainstream HPO algorithms consist of trial schedulers and configuration searchers. The scheduler allocates computing resources and determines when to start, suspend, or terminate trials. The searcher proposes new hyper-parameter configurations. Random search is simple but unstable, while Bayesian Optimization is limited by assumptions and low-dimensional search spaces. Evolutionary Algorithms are not suitable for non-inheritable hyper-parameters. To address these limitations, this paper proposes a new configuration searcher based on Deep Reinforcement Learning (DRL) and Transformer, called Attention and Memory Enhancement (AME). AME enhances the ability to capture relationships between configurations and is combined with the parallel trial scheduler ASHA. AME actively encourages high-performance configurations and penalizes underperforming ones. The contributions of this work include a transformer-structured configuration searcher under reinforcement learning, the proposal of the AME model capable of optimizing all types of hyper-parameters, and experiments demonstrating its efficiency in image classification, object detection, and semantic segmentation tasks.