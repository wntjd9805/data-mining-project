Deep neural networks (DNNs) have shown impressive performance in computer vision tasks. However, recent research has revealed that DNNs are highly vulnerable to adversarial examples, which are crafted by adding imperceptible perturbations. Adversarial examples are transferable, meaning they can deceive other black-box models. Adversarial attacks, which generate these examples, have gained significant attention as they can evaluate model robustness and improve it through adversarial training. Various attack methods have been proposed, achieving high success rates in the white-box setting but low rates in the black-box setting. In recent years, methods to enhance transferability and attack success rates in the black-box setting have been explored, including gradient optimization attacks, input transformation attacks, and model ensemble attacks. However, model ensemble attacks have received less attention compared to the other methods. This paper proposes a novel method called the stochastic variance reduced ensemble (SVRE) attack to enhance the transferability of ensemble attacks. Inspired by the stochastic variance reduced gradient (SVRG) method, SVRE utilizes an outer loop to calculate the average gradient and an inner loop to update the adversarial example using the gradients from randomly chosen models. This approach improves gradient updates, enabling better escape from poor local optima and leading to crafted adversarial examples with higher transferability. Experimental results on the ImageNet dataset demonstrate that SVRE consistently outperforms vanilla ensemble model attacks in the black-box setting. This work is the first to investigate the limitation of existing ensemble attacks through the lens of gradient variance on multiple models.