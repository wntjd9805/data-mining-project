Glaucoma, a leading cause of irreversible blindness, is diagnosed and classified based on Anterior Chamber Angle (ACA) structure evaluations. However, the limited availability of expert ophthalmologists hinders efficient ACA evaluation. Deep Neural Networks (DNNs) have shown success in glaucoma-related medical image analysis, but their direct application for ACA classification faces challenges. These challenges include distinguishing important structural information from noise, recognizing and learning representations of adjacent and blurred ACA structures, and capturing inter-class similarities and intra-class variations. To overcome these challenges, we propose a deep neural network with weakly-supervised metric learning and interactive module communications. Our proposed network, CMANet, is able to classify ACA images by augmenting them with pixel-level annotations, fusing features from multiple granularity levels, and capturing both semantic and pixel-level information. We collect and label an ACA evaluation image dataset and conduct experiments on three real-world datasets to validate the effectiveness of our framework compared to deep learning baselines. This work is the first to classify ACA images using deep learning techniques with three sub-modules.