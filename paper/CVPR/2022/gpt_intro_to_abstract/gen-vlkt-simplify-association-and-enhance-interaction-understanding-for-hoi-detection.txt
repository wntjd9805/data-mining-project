Human-Object Interaction (HOI) detection is a crucial task in computer vision for understanding human activities in images. This paper introduces a unified and superior HOI detection framework called GEN-VLKT. The core problems of HOI detection are associating interactive human and object pairs and understanding their interactions. Traditional methods use bottom-up or top-down approaches for association, but query-based methods have shown better performance. However, these methods still face challenges in designing effective matching rules and handling complex post-processing. To address these challenges, the paper proposes GEN, a query-based HOI detector with two-branch decoders. GEN incorporates a guided embedding association mechanism to simplify the association process. Additionally, a training strategy called VLKT is introduced to transfer visual-linguistic knowledge from the CLIP pre-trained model to enhance interaction understanding. VLKT includes a text-driven classifier for prior knowledge integration and zero-shot HOI discovery, as well as a knowledge distillation method to guide visual features. The proposed GEN-VLKT framework achieves improved performance on two benchmark datasets, HICO-Det and V-COCO, and outperforms existing state-of-the-art methods in terms of mean average precision (mAP) and zero-shot settings.