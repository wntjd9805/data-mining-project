The widespread adoption of IoT devices has led to an increasing need for on-device AI capabilities, including training and transfer learning. On-device transfer learning eliminates the need for communication between edge devices and the cloud, as well as data privacy concerns. However, the memory-hungry training process poses a significant challenge for memory-constrained IoT/edge devices. While fine-tuning pre-trained models can improve performance, it can also lead to high memory consumption. Existing transfer learning methods have limitations in terms of memory consumption and transfer capacity. This paper introduces Reprogramming Network (Rep-Net), a lightweight side-network that reprograms intermediate features of a pre-trained backbone model using a memory-efficient additive operation. Rep-Net is trained directly from the new task input data and performs feature exchange with the backbone model. Experimental results demonstrate the superiority of Rep-Net over current state-of-the-art transfer learning approaches.