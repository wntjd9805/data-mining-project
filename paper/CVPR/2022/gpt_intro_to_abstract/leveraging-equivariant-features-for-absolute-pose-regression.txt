Camera pose estimation and object pose estimation are important tasks in computer vision. Traditional approaches rely on 3D geometry and feature correspondences to recover camera pose. However, recent advancements in deep learning have introduced direct Absolute Pose Regression (APR) methods that achieve end-to-end pose estimation using Convolutional Neural Networks (CNNs). While these methods offer advantages such as fully differentiable results and predictable performance, they still fall short in accuracy compared to 3D structure-based approaches. This paper hypothesizes that the lack of exploitation of geometric properties of data in APR methods is the cause of this accuracy gap. The authors propose the use of equivariant features, which are representations that are sensitive to rigid motions like rotations and translations, to improve APR performance. They introduce a lightweight equivariant pose regression model called E-PoseNet and validate its performance on standard datasets. This work contributes to the exploration of deep equivariant features for APR and highlights the potential of leveraging geometric properties for improved pose estimation accuracy. The paper is organized in sections that provide an overview of state-of-the-art APR methods, define equivariance, present the theoretical justification and formulation of SE(2)-equivariant features, introduce the E-PoseNet model, and provide extensive experimental validation.