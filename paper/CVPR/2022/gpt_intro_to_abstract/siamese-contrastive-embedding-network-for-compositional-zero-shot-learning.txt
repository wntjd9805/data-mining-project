Humans have the ability to generalize their knowledge of known entities to comprehend new concepts. They can combine known states and objects, such as "green horse," even if they have never seen such a combination before. Compositional Zero-Shot Learning (CZSL) aims to equip AI systems with a similar ability to recognize unseen compositions composed of known states and objects. In CZSL, each composition consists of a state and an object, and the compositions in the train and test sets are disjoint. The challenge lies in understanding the meaning of states and objects when presented in different combinations, as the interaction degree between them cannot be quantified. Existing methods focus on supervised recognition tasks or embedding spaces to address this problem but neglect the domain gap between training and testing compositions. To address these limitations, this paper proposes a Siamese Contrastive Embedding Network (SCEN) that excavates discriminative prototypes of states and objects. SCEN projects visual features into state/object-based contrastive spaces and uses specific databases as positive and negative samples to guide the learning process. Additionally, a State Transition Module (STM) generates virtual samples to mitigate the domain gap between seen and unseen compositions. Experimental results on benchmark datasets demonstrate the effectiveness of the proposed approach, outperforming existing CZSL methods.