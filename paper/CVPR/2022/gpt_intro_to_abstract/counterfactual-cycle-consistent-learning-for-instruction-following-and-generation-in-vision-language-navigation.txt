Recent advancements in vision-language navigation (VLN) have focused on developing agents that can navigate realistic environments based on human instructions. However, the task of learning a speaker that can generate clear and informative navigation instructions has received much less attention. Instruction generation is a crucial ability for AI agents to effectively collaborate with humans in various scenarios, such as search and rescue missions. In these scenarios, the ability of the robot to generate linguistic explanations can help human users resolve ambiguity and establish trust. Additionally, the robot can assist the human in navigating unfamiliar areas by providing clear instructions. This paper explores the intrinsic correlation between instruction following and generation and proposes a novel cycle-consistent learning framework that jointly trains the speaker and follower. The proposed framework leverages the dependencies between the input and output spaces of the speaker and follower agents, which were previously overlooked in existing VLN methods. The training process involves mapping visual observations and navigable directions to action sequences using the follower agent, and then translating the action sequences to trustable instructions using the speaker agent. The dissimilarity between the generated instructions and the ground truth instructions is used as a feedback signal to guide the training process. The proposed framework is more elegant and effective compared to existing VLN training protocols, which often suffer from data quality issues when using synthetic instructions. Furthermore, the paper introduces a creator agent that enables counterfactual environment synthesis, enhancing the robustness of the training process. Experimental results on the R2R dataset demonstrate the efficacy of the proposed framework in both instruction following and generation tasks.