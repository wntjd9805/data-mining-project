IntroductionThe field of video analysis has seen significant growth in recent years. Understanding human actions is crucial for analyzing large amounts of video data and has numerous applications such as video retrieval, video captioning, and video summarization. Among the various sub-topics in action analysis, action recognition is of particular importance and has made significant progress with the development of various models. However, current research trends in video analysis are shifting towards understanding longer and more complex videos, particularly instructional videos with semantically rich content. Unlike conventional action recognition approaches that focus on classifying single actions in short video clips, instructional video analysis requires studying a series of actions and their contextual relations. Existing graph-based models have studied the mutual information between correlated actions in instructional videos, but they are limited in their ability to handle unknown actions and lack the ability to depict contextual relations between ordinal actions. In this paper, we propose a text-based learning method called Bridge-Prompt for instructional video analysis. Inspired by prompt-based learning approaches in natural language processing and visual recognition, we introduce a three-plus-one-level design of text prompts to analyze video clips with ordinal actions. Our approach combines video and text encoders through a specially designed video-text fusion module, allowing for a comprehensive understanding of instructional videos by exploiting both out-of-context and contextual action information. Experimental results on benchmark datasets demonstrate the effectiveness of the Bridge-Prompt-based approach, achieving promising performance and outperforming state-of-the-art methods in several benchmarks. Overall, our work explores the potential of prompt-based learning approaches in ordinal action understanding and instructional video analysis.