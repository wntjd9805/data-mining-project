Recent advancements in machine learning have greatly improved the performance of automatic photo enhancement methods. These methods aim to replace the complex operations in the camera imaging pipeline for enhanced visual quality. However, these methods often suffer from heavy computational burdens due to complicated optimization processes or neural architecture designs.In this paper, we revisit the commonly-used enhancement operations and propose a 3D color transform function that maps input color points to output color points. To address the computational complexity of this transform, we introduce the use of a 3D lookup table (LUT). The LUT efficiently maps input values to output values by sparsely sampling a range of input values and storing the corresponding output values in a 3D lattice.Previous works have attempted to learn image-adaptive LUTs but have not considered the adaptation of sampling point density to image contents. This results in a sub-optimal sampling point allocation and limits the expressiveness of the LUTs for modeling local non-linearities. To overcome this limitation, we propose a deep learning-based approach called AdaInt, which dynamically learns the non-uniform sampling intervals of the 3D lattice. This allows for more sampling points to be allocated to color ranges that require highly non-linear transforms, while reducing redundant sampling points for strongly linear ranges.We incorporate AdaInt into a lightweight convolutional neural network (CNN) to simultaneously predict the non-uniform sampling coordinates and the corresponding output color values. These predictions are combined to compose an image-adaptive 3D LUT. To facilitate learning, we introduce a novel differentiable operator called AiLUT-Transform, which enables the location of input colors in a non-uniform 3D lattice through a low-complexity binary search. Our method provides high efficiency and can be easily integrated as a plug-and-play module for 3D LUTs.The main contributions of this paper are three-fold: first, we highlight the importance of the sampling strategy for learning 3D LUTs with higher non-linear capability; second, we propose the AdaInt module and the AiLUT-Transform operator to enable adaptive learning of a 3D LUT with a non-uniform layout; and third, we demonstrate the effectiveness and efficiency of our method on two large-scale publicly available datasets.