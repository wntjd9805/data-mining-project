This paper introduces a novel method for constructing event-based graph representation that effectively utilizes informative features from voxelized event streams while maintaining the sparse and non-redundant advantage of event data. The proposed representation encodes locally coherent 2D semantics by describing the regional events contained in each voxel. A lightweight graph-based learning architecture, EV-VGCNN, is also introduced, which utilizes graph pooling operations and a classifier to perform object classification. The architecture includes a multi-scale feature relational layer (MFRL) that extracts semantic and motion cues from each vertex in the event-based graph. The proposed model achieves state-of-the-art accuracy while maintaining low model complexity. The contributions of this paper include the introduction of the novel event-based graph representation, the MFRL module for learning spatial semantics and motion cues, and extensive experiments showing the effectiveness of the proposed model with low model complexity.