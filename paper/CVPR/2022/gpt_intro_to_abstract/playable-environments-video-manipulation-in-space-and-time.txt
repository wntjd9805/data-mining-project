This paper introduces a framework for creating playable environments (PE) by reconstructing the geometry and style of the observed environment in 3D. The authors propose a method that allows users to interactively generate different videos by controlling players, manipulating camera trajectory, and indicating object styles. The PE representation enables various creative applications, such as 3D- and action-aware video editing, camera trajectory manipulation, and changing object styles. The proposed method supports interactive manipulations and is trained on a dataset of monocular videos. It presents six core characteristics, including playability, camera control, modeling of multiple objects, handling deformable objects, handling appearance changes, and robustness to calibration and localization errors. The authors evaluate the method using two large-scale datasets and demonstrate its superiority in terms of playability, camera control, and video quality over existing baseline methods. The contributions of this paper include the framework for creating PEs, a compositional NeRF for handling deformable objects, an action module for generating actions, and the introduction of challenging datasets for training and evaluation.