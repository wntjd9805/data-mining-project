High-resolution CT volume data is valuable for computer-aided diagnosis, but its between-slice resolution is often insufficient for detailed imaging. To address this problem, the task of medical slice synthesis has emerged. Previous approaches have used pixel-wise interpolation to improve resolution but require large ground-truth training data. In this paper, we introduce a self-supervised learning framework that formulates slice synthesis as a slice-wise interpolation problem, allowing intermediate slices to be inferred from adjacent slices in the axial view. We propose a cross-view knowledge distillation framework that combines pixel-wise and slice-wise interpolation models to collectively address the medical slice synthesis problem. Our proposed incremental cross-view mutual distillation pipeline involves modeling components for slice-wise interpolation in the axial view, as well as pixel-wise interpolation in the coronal and sagittal views. By using a U-shape network and image super-resolution network, we learn deep models in a two-stage learning framework. We demonstrate the effectiveness of our approach using extensive experiments on a CT collection, showing that our method achieves state-of-the-art performance. Our contributions include the implementation of self-supervised CT slice synthesis, the establishment of a novel self-supervised learning framework, and the demonstration of improved performance compared to existing methods.