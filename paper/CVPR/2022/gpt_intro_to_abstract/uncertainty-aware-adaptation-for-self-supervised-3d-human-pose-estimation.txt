The introduction of this computer science paper discusses the importance of 3D human pose estimation in various human-centric technologies. Most existing 3D pose estimation approaches require large-scale datasets with paired 3D pose annotations, which can be challenging to acquire. Some recent works propose weakly supervised techniques that bypass the need for 3D pose annotations by leveraging 2D pose datasets or off-the-shelf image-to-2D pose estimation networks. However, these methods lack cross-dataset generalization. To address the need for 3D human pose estimation in new application environments, the paper proposes a novel unsupervised adaptation framework called MRP-Net. This framework utilizes a multi-representation pose network with two output heads, one for heat-map based joint localization and the other for model-based parametric regression. The paper also introduces measures to quantify prediction uncertainties at both pose and joint levels. Training is performed on a labeled source dataset and a dataset of negative samples (backgrounds and occlusions) to improve the effectiveness of uncertainty estimation. The proposed framework is evaluated on various source-to-target settings, showing improved performance compared to prior methods on datasets such as Human3.6M. The framework also demonstrates state-of-the-art results for adapting to in-the-wild samples with partial body visibility.