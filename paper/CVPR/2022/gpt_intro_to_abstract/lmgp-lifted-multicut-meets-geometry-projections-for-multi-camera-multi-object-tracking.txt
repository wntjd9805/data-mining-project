Multiple object tracking (MOT) is crucial for understanding information in videos. The tracking-by-assignment approach is commonly used, where detection boxes are computed for objects in each frame, and data association links detections of the same objects. However, tracking in crowded scenes still faces challenges, especially in the data association step due to partial visibility and object indistinguishability. One approach to improve performance is to use multiple cameras facing the same scene, where objects may be occluded in one camera but fully observed by another. Recent research has explored single view-based and centralized representation methods to leverage multi-camera setups. While both approaches have their advantages and limitations, we propose a method that integrates concepts from both approaches. Our method includes a pre-clustering step that eliminates tracklet errors and provides accurate affinity costs. We also introduce a novel spatial-temporal optimization model for data association, considering both short- and long-range temporal interactions and spatial interactions between cameras. Experimental results show that our method achieves nearly optimal performance for multi-camera object tracking. Our main contributions include a new pre-clustering algorithm based on 3D geometry projections and a spatial-temporal lifted multicut formulation that jointly optimizes intra- and inter-camera interactions. We demonstrate superior performance on various datasets compared to state-of-the-art methods.