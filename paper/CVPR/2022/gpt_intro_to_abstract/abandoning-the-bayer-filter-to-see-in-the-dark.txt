This paper presents a novel approach for enhancing low-light images by leveraging a fully end-to-end convolutional neural network model. The proposed model consists of two modules: a De-Bayer-Filter (DBF) module and a Dual Branch Low-light Enhancement (DBLE) module. The DBF module is designed to restore monochrome raw images from color camera raw data, simulating the capability of a monochrome sensor. The DBLE module then fuses the colored raw and synthesized monochrome raw data to generate enhanced RGB images. To train and evaluate the model, a dataset containing monochrome and colored raw image pairs captured by identical sensors is introduced. The dataset covers various scenes and ensures consistent exposure settings between the two sensor types. The contributions of this work include the development of the DBF model to simulate a virtual monochrome camera, the design of the DBLE model to bridge the gap between colored and monochrome domains, and the creation of the MCR dataset for community utilization. Experimental results demonstrate that the proposed approach achieves state-of-the-art performance in low-light image enhancement. The MCR dataset will be publicly available to support further research in this domain.