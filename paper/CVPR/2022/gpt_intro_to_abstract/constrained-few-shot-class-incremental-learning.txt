This paper proposes a new approach called C-FSCIL (Class-incremental Few-Shot Convolutional Neural Networks with Concentrative Quasi-orthogonal Prototypes) for addressing the challenges of learning novel classes in a online data stream with limited resources in computer vision tasks. The authors focus on the problem of catastrophic interference, where new learning can overwrite previously learned knowledge, causing classification accuracy to deteriorate. To overcome this problem, the authors combine memory-augmented neural networks (MANNs) and hyperdimensional computing. MANNs separate information processing from memory storage, while hyperdimensional computing allows representation of novel classes with quasi-orthogonal vectors that minimize interference. The proposed C-FSCIL architecture consists of a frozen feature extractor, a fixed-size fully connected layer, and a dynamically growing explicit memory (EM) that stores class prototypes. Three update modes are introduced in C-FSCIL to balance accuracy and computational costs. Experimental results on various datasets demonstrate that C-FSCIL outperforms existing approaches in terms of accuracy, compute-memory efficiency, and scalability. The authors conclude that C-FSCIL is a promising solution for learning novel classes in resource-constrained environments.