The introduction of the paper discusses the growing use of 3D point clouds in applications such as autonomous driving, robotics, and augmented reality. However, processing 3D data is challenging due to the irregular arrangement of points. The paper highlights the need for advanced methods specifically tailored for 3D point cloud data.The paper mentions that several methods have focused on 3D point cloud segmentation but have primarily concentrated on aggregating local features, neglecting the importance of capturing long-range dependencies. The authors mention the Transformer model as a promising approach for capturing long-range information but note that limited attempts have been made to apply Transformer to 3D point clouds.The authors propose a new segmentation network called Stratified Transformer, which efficiently captures long-range contexts using multi-head self-attention while preserving position information. They introduce a stratified strategy that samples both nearby and distant points as keys, significantly expanding the effective receptive field. The authors illustrate the importance of modeling long-range contexts through visualization.The paper also addresses challenges posed by irregular point arrangements in designing 3D Transformers. They present a point embedding approach and effective contextual position encoding to handle the irregularity while ensuring faster convergence and stronger performance. Additionally, they propose a memory-efficient implementation to reduce unnecessary memory consumption.The contributions of the paper are threefold: the introduction of Stratified Transformer that samples distant points to build a direct long-range dependency; the design of point embedding and effective positional encoding for handling irregular point arrangements; and achieving state-of-the-art results on large-scale segmentation datasets through experiments, with extensive ablation studies validating the effectiveness of each component.