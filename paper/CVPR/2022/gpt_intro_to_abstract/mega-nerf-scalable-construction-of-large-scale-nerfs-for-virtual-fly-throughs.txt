Recent advancements in neural rendering have significantly improved the synthesis of photo-realistic novel views, which is crucial for various applications in virtual reality (VR) and augmented reality (AR). A key technique in this field is Neural Radiance Fields (NeRFs), which has inspired numerous follow-up works to enhance different aspects of the original methodology. However, most existing methods focus on single-object scenes, often captured indoors or generated synthetically. This paper explores the scalability of NeRFs, specifically targeting urban-scale environments captured from drone footage.The motivation behind scaling NeRFs to urban scenes stems from the potential applications in search-and-rescue scenarios. Drones can conduct rapid surveys, enabling the prioritization of limited resources for ground team deployment. Typically, the captured footage is reconstructed into 2D maps for post-hoc analysis. However, the authors envision a future where neural rendering enables 3D analysis, allowing response teams to inspect the field as if they were flying a real-time drone with detailed views far beyond what traditional Structure-from-Motion (SfM) techniques can provide.This endeavor poses several challenges, including the time-sensitivity of search-and-rescue scenarios, the increased training time required for larger datasets, and the need for interactive real-time rendering. To address these challenges, the authors propose Mega-NeRF, a framework that supports large-scale 3D scenes for interactive fly-throughs. Mega-NeRF utilizes a sparse network structure, where different regions of the scene are specialized by separate NeRF submodules, trained in parallel. Spatial locality is exploited during rendering, enabling just-in-time visualization for interactive exploration.The approach of utilizing multiple NeRF submodules is inspired by prior works such as DeRF and KiloNeRF, which accelerate inference for pre-trained NeRFs. However, obtaining pre-trained NeRFs for such large-scale scenes is currently not feasible. Therefore, the authors emphasize the importance of modularity in training, combined with an intelligent data sharding strategy based on geometric clustering.The contributions of this paper include a reformation of the NeRF architecture that introduces sparsity in layer connections, resulting in efficiency improvements during training and rendering. The training process is adapted to exploit spatial locality and allow fully parallelizable training of subweights, leading to a threefold increase in training speed while surpassing the reconstruction quality of existing approaches. The authors also evaluate fast rendering methods and propose a novel technique that leverages temporal coherence to achieve high visual fidelity with minimal preprocessing.