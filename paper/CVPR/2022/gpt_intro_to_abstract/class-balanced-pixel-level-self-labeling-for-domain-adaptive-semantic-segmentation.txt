Semantic segmentation is a crucial task in computer vision, with applications in autonomous driving, human-machine interaction, and augmented reality. Deep Convolutional Neural Networks (CNNs) have significantly improved semantic segmentation accuracy and efficiency. However, deep models trained on one domain often perform poorly on unseen domains, such as autonomous driving in changing weather conditions. Collecting data from various scenarios to improve model generalization is expensive and labor-intensive. Unsupervised Domain Adaptation (UDA) offers a solution by transferring knowledge from labeled source domains to unlabeled target domains. Previous UDA approaches align data distributions at the image, feature, or output levels, but they suffer from increased model complexity, training instability, and lack of reproducibility and robustness. Self-training is another approach where pseudo labels are generated in an iterative manner, but it can lead to biased labels and limited supervision information for training. This paper proposes an online pixel-level self-labeling method using clustering in the target domain and soft cluster assignments to correct pseudo labels. Additionally, a distribution alignment technique is introduced to align the class distribution of cluster assignments with pseudo labels, especially beneficial for long-tailed class predictions. The proposed Class-balanced Pixel-level Self-Labeling (CPSL) module can be seamlessly integrated into existing UDA frameworks. Extensive experiments demonstrate the superiority of the CPSL module over state-of-the-art methods, particularly for long-tailed classes.