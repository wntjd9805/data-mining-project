This paper addresses the security issue of realistic image generation with generative adversarial networks (GANs), specifically focusing on the substitution of human portraits and the potential threats to subject identifications. The authors highlight the emerging investigation on deepfake detectors to identify face forgeries as a way to mitigate these risks. They emphasize the discrepancy between training and testing data, which poses challenges for practical use of deepfake detectors. Previous attempts to improve generalization have been made through data augmentation and mining intrinsic forgery attributes, but limitations exist due to the lack of variety in augmentations and the sensitivity of attribute representations to post-processing steps. In this paper, the authors propose a heuristic principle, which suggests that a generalizable representation should be sensitive to various types of forgeries. They introduce a method that enriches the diversity of forgeries by synthesizing forgery images from a large pool of configurations. Their detector network is trained to not only judge if an image is a forgery or not, but also predict the forgery configurations, enhancing the sensitivity to forgeries. They adopt an adversarial training strategy to dynamically construct the most challenging augment based on the performance of the discriminator. Through experimental studies, the authors demonstrate the effectiveness of their method, showing significant improvement over baseline approaches and competitive performance against other state-of-the-art detectors.