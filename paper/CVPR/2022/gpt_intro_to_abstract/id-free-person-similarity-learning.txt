This paper explores the task of detecting and re-identifying people in images and videos using a single model. Existing approaches rely on annotated training sets, which are costly and limited in size. The authors propose a method that leverages large-scale training sets for person detection by using person bounding boxes as the only supervision. They adopt instance discrimination tasks to learn a person embedding model that can handle appearance changes. To address variations in pose and viewpoint, unlabeled videos are used to provide examples of natural appearance changes. The model is fine-tuned using a density-based clustering technique. Experimental results show that the proposed approach achieves high performance on the person search task and comparable results on the multi-person tracking task, even without manual identity annotation or frames from the target dataset during training. By using only a subset of identity annotations, the model outperforms the state-of-the-art approach. Overall, the proposed method offers a more efficient and cost-effective solution for person detection and re-identification.