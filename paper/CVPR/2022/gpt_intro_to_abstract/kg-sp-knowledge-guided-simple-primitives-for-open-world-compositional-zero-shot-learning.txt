Humans interact with objects based on their state, and autonomous agents need algorithms that can recognize objects and their states to exhibit similar interaction capabilities. This problem, known as Compositional Zero-shot Learning (CZSL), involves training models on images of objects in a subset of their states and testing their ability to recognize compositions of objects and states unseen during training. CZSL requires modeling how objects and states interact with each other and extrapolating this knowledge to unseen compositions. Previous works have approached CZSL using compositional classifiers or shared embedding spaces. However, these methods suffer from performance degradation in the open-world CZSL (OW-CZSL) setting where there are no priors on unseen compositions.In this paper, a different approach is proposed. A new architecture is designed that independently predicts object and state labels, disregarding the compositional nature of the problem. This is motivated by the idea that recognizing primitives (objects and states) in isolation is easier than discriminating between compositions. The proposed model, called Knowledge-Guided Simple Primitives (KG-SP), uses two independent classifiers for object and state prediction, trained with different non-linear feature extractors. To refine the predictions, external knowledge from ConceptNet is utilized to estimate the feasibility of compositions, allowing the removal of less feasible compositions from the output space at test time.Furthermore, the paper explores the problem of CZSL under partial supervision (pCZSL), where training samples have either object or state annotation, but not both. KG-SP leverages prior knowledge on feasible compositions to aid pseudo-labeling during training in the pCZSL setting. Experimental results demonstrate that KG-SP either competes with or surpasses the state-of-the-art methods in OW-CZSL, and outperforms recent CZSL approaches in the pCZSL setting. The paper concludes by summarizing the contributions of the proposed model: independent prediction of state and object labels, removal of less feasible compositions based on external contextual information, and exploration of pCZSL with successful adaptation of recent baselines.