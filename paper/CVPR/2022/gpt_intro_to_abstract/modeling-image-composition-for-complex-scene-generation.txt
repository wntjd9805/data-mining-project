Generating photo-realistic images is a long-standing goal in computer vision. While significant progress has been made in image generation for simple scenarios and single objects, generating complex scenes with multiple objects of various categories remains a challenging problem. In this paper, we focus on the task of layout to image generation (L2I), which involves generating complex scenes based on specified layouts. Compared to other conditions for complex scene generation, layouts are more user-friendly, controllable, and flexible. Additionally, we propose a new few-shot L2I task, which aims to generate complex scenes with a novel object category after providing only a few images containing the novel objects.The core challenge in complex scene generation, including few-shot L2I tasks, is synthesizing photo-realistic images with reasonable object-level relationships, clear patch-level instance structures, and refined pixel-level textures. Previous attempts at the L2I task can be categorized into CNN-based methods and Transformer-based methods. CNN-based methods use an encoder-decoder generator to capture object relationships in the encoder and model instance structures and textures in the decoder. Transformer-based methods tokenize the layout into object and patch tokens and employ a pre-trained compression model to quantize the image into discrete patch tokens. While these methods have shown promising results, they struggle to capture inherent instance structures and often result in blurry or crumpled objects.In this paper, we propose a Transformer with Focal Attention (TwFA) to address the limitations of existing methods. TwFA separately models image compositions on the object-level and patch-level by distinguishing between object and patch tokens. Our focal attention mechanism constrains each token to only attend to its related tokens based on the spatial layout, capturing global information for object relationships and modeling instance structures with increased data efficiency during training. The TwFA enables fast learning of novel object categories with only a few images.We evaluate the effectiveness of TwFA on COCO-stuff and Visual Genome datasets and demonstrate its superiority over state-of-the-art methods in terms of FID score and performance on the few-shot L2I task. TwFA achieves a significant improvement in FID score and produces impressive visualizations. Our results validate the efficacy of the proposed approach in generating high-quality complex scene images.