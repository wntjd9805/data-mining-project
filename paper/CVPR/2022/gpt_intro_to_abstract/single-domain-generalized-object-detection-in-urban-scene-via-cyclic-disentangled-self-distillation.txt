Recent advancements in deep learning have greatly improved object detection in computer vision. However, these techniques assume that the training and test data are drawn from the same domain. In real-world scenarios, when object detectors trained on a source domain are applied to unseen target domains, they often suffer from poor generalization due to domain shift. To address this issue, researchers have focused on domain adaptation and domain generalization. Domain adaptation aims to align the data distribution of annotated source domains with target domains, while domain generalization aims to generalize a model to an unseen target domain by learning from multiple source domains. However, existing methods in both domains have limitations. Aligned methods in domain adaptation require access to both source and target domain data during training and struggle to adapt to unseen target domains. Furthermore, when a target domain consists of multiple different data distributions, the generalization ability of aligned methods tends to be weak. Additionally, most domain generalization methods heavily rely on a large number of source domains, which is impractical in real-world scenarios where collecting multiple high-quality datasets can be time-consuming and labor-intensive. In this paper, we propose a novel approach called cyclic-disentangled self-distillation for single-domain generalized object detection (Single-DGOD). Single-DGOD aims to train a detector on one source domain dataset and generalize well to multiple unseen target domains without access to target domain data during training. Our method disentangles domain-invariant representations without the reliance on domain-related annotations, such as domain labels. We evaluate our approach on a diverse-weather dataset consisting of five scenes with different weather conditions and demonstrate its superior performance compared to baseline methods. The contributions of our work include introducing the Single-DGOD task, proposing a method of cyclic-disentangled self-distillation for domain-invariant representation learning, and providing a benchmark dataset for urban-scene object detection. The results show the effectiveness of our approach in improving the generalization ability of object detectors.