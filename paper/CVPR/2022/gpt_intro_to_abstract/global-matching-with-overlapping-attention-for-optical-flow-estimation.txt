Optical flow estimation plays a crucial role in various computer vision applications such as video interpolation, deblurring, video segmentation, and action recognition. Previous methods for optical flow estimation have mainly relied on either energy-based optimization or direct regression approaches. However, energy-based optimization methods struggle to handle large displacements, while direct regression methods struggle with capturing long-term motion correspondences. In this paper, we propose a novel framework called Global Matching Flow Network (GMFlowNet) that combines the advantages of both approaches. GMFlowNet incorporates a matching step before the direct regression to explicitly handle large displacements. It introduces efficient and accurate global matching using argmax applied to the cost volume. Moreover, a Patch-based OverLapping Attention (POLA) block is introduced to address local ambiguities in matching. By mimicking the learning-based optimization approach of direct regression methods, GMFlowNet achieves state-of-the-art performance on standard datasets for optical flow estimation. Experimental results show that GMFlowNet outperforms optimization-only models, especially in areas with large motion and textureless regions. Our contributions include the introduction of a global matching step, the proposal of the POLA block for addressing local ambiguities, and the development of the GMFlowNet framework, which achieves superior performance in optical flow estimation.