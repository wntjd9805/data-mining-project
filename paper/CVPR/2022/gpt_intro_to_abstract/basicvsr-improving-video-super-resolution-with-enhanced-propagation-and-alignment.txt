Video super-resolution (VSR) is a challenging task in computer vision, as it requires gathering complementary information from mis-aligned video frames to enhance the resolution. The sliding-window framework is a prevalent approach, where each frame is restored using neighboring frames within a short temporal window. However, this framework fails to exploit long-term dependencies. Recurrent frameworks attempt to address this by propagating latent features across frames, resulting in a more compact model. However, transmitting long-term information and aligning features remain challenging in recurrent models.In this paper, we focus on improving BasicVSR, a state-of-the-art VSR model that utilizes bidirectional propagation and optical flow for feature alignment. We aim to explore more effective methods for aggregating temporal information in video restoration, particularly in dealing with occluded and complex regions. We propose two novel components: second-order grid propagation and flow-guided deformable alignment.The proposed second-order grid propagation improves the bidirectional propagation by arranging it in a grid-like manner, allowing for more aggressive and robust information flow. Additionally, it relaxes the assumption of the first-order Markov property and incorporates a second-order connection to aggregate information from different spatiotemporal locations. The flow-guided deformable alignment module addresses the problem of inaccurate flow estimation by using optical flow as base offsets refined by flow field residue, resulting in more stable training.With these design improvements, our model, BasicVSR++, surpasses existing state-of-the-art methods in terms of restoration performance while maintaining efficiency. Compared to its predecessor, BasicVSR, BasicVSR++ achieves a significant gain of 0.82 dB in peak signal-to-noise ratio (PSNR) on the REDS4 dataset. Moreover, the proposed components also benefit other video restoration tasks, such as compressed video enhancement and real-world VSR.In conclusion, our research contributes to the advancement of VSR models by exploring more effective ways to aggregate temporal information and improve feature alignment. The results demonstrate the superiority of BasicVSR++ over existing methods, highlighting the potential for further advancements in video restoration tasks.