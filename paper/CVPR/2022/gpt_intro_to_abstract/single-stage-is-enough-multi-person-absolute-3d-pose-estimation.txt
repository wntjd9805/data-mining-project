Estimating 3D human pose from a monocular RGB camera is a significant task in computer vision and artificial intelligence, with applications in robotics, action recognition, animation, and more. The problem setting of multi-person 3D pose estimation has attracted increasing attention in recent years. Existing methods for this task can be categorized as top-down or bottom-up approaches, each with their own limitations. While single-stage methods for 2D pose estimation have gained popularity, a single-stage pipeline for multi-person 3D pose estimation is still unexplored. In this paper, we propose a single-stage pipeline called Decoupled Regression Model (DRM), which combines the end-to-end 2D pose regression with person depth estimation. DRM introduces a decoupled formulation that represents 2D pose and depth information through a center point and root point for each 3D human instance. We perform 2D keypoint regression and keypoint depth estimation in parallel, effectively unifying the 2D pose regression with person depth estimation for joint 3D pose regression. To address the ambiguous depth estimation from a single image, DRM introduces a Pose-guided Depth Query Module (PDQM) to extract features from the 2D pose regression branch. Additionally, we propose a Decoupled Absolute Pose Loss (DAPL) to supervise the human absolute 3D pose estimation. Experimental results on challenging benchmarks demonstrate the superiority of DRM compared to existing methods. Our contributions include the development of DRM as the first single-stage solution for multi-person absolute 3D pose estimation, the introduction of PDQM to enhance depth regression, and the use of DAPL to improve absolute depth prediction. DRM achieves comparable performance with top-down methods and outperforms the state-of-the-art bottom-up method on benchmark datasets.