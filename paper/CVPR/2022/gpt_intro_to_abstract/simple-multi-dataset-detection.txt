Computer vision has made significant progress in object detection and instance segmentation, but these advancements are fragmented across various datasets. This fragmentation limits the development of general-purpose recognition systems and hinders the ability to create models that can perform well in diverse domains. In this paper, the authors propose a method to unify disparate detection datasets and train a single object detector that can generalize across domains. They demonstrate the feasibility of training a single detector with separate outputs for each dataset and applying dataset-specific supervision during training. To integrate the datasets into a common taxonomy, they introduce a fully automatic approach that leverages visual data to unify the output space of a multi-dataset detection system. This method optimizes for a common taxonomy, mapping from this taxonomy to each respective dataset, and a detector over the unified taxonomy. The authors evaluate their unified object detector on three large and diverse datasets and show that it performs as well as dataset-specific models on each individual dataset. Furthermore, they demonstrate that models trained on diverse training sets can generalize to new domains without the need for further retraining. Overall, this work presents a promising approach for overcoming the limitations caused by dataset fragmentation and improving the generalization capabilities of object detection models.