The rise of autonomous driving has led to increased interest in the semantic segmentation of point cloud data in computer science research. While early methods focused on projecting 3D points onto regular structures for convolutional operations, the Point-Net model introduced a method to directly apply deep learning on sparse 3D points using multi-layer perceptrons. Subsequent work in this area typically includes point-wise transformation, local aggregation, and point sampling. Most state-of-the-art point cloud segmentation methods adopt the encoder-decoder U-shape architecture, similar to the design in image segmentation. However, little attention has been given to the network architecture itself in point cloud segmentation, in contrast to the advancements made in image segmentation architectures. This paper introduces a pyramid architecture for point cloud segmentation, inspired by recent advances in image segmentation. The pyramid architecture incorporates lateral stages, upward/downward links, and a novel Cross-scaLe Attention fusIon Module (CLAIM) for multi-scale feature aggregation. The proposed architecture shows significant improvements in accuracy without a higher computational demand when applied to the popular KPConv and RandLANet baseline networks. The results demonstrate the effectiveness of the pyramid architecture in enhancing point cloud segmentation tasks on various benchmarks, including achieving state-of-the-art results on NPM3D and S3DIS datasets. Additionally, the pyramid architecture is generic and can be used to improve any encoder-decoder network.