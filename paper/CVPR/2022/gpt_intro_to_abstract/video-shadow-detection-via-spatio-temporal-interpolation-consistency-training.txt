Shadow detection is a crucial problem in computer vision and graphics tasks, with applications in object recognition, virtual reality, light position estimation, and object shape perception. Recent progress in shadow detection has been achieved through the development of deep Convolutional Neural Networks (CNNs) on image benchmark datasets. However, the lack of large-scale annotated datasets hinders the application of deep learning-based methods in video shadow detection (VSD). This paper proposes a Spatio-Temporal Interpolation Consistency Training (STICT) framework for image-to-video shadow knowledge transfer. The framework utilizes a Scale-Aware shadow detection Network (SANet) for end-to-end training by rationally combining unlabeled video frames and labeled images. The proposed approach incorporates spatial interpolation consistency, temporal interpolation consistency, and scale consistency constraints to improve generalization, produce temporally smooth, and scale-consistent results. Additionally, the paper introduces the Spatial ICT, which encourages consistent predictions between two unlabeled images in the feature space, and the Temporal ICT, which tracks pixel predictions in consecutive frames using optical flow-based temporal interpolation. The proposed STICT framework simplifies the inference process by conducting spatial and temporal interpolations during training. To address the scale variations of shadows in videos, the paper introduces a Scale-Aware Network (SANet) that features an encoder-decoder-refiner architecture with a feature fusion module and a detail attentive module. A scale consistency constraint is also proposed to minimize prediction discrepancies across different scales. The contributions of this paper include the STICT framework for image-to-video shadow detection, the novel Spatial and Temporal ICT interpolation schemes, and the SANet architecture for multi-scale shadow feature learning. Experimental results on benchmark datasets demonstrate the superiority of the proposed approach over existing supervised, semi-supervised, and unsupervised image and video methods.