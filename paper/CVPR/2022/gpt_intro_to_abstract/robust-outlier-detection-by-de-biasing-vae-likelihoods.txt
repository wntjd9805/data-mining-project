Deep neural networks are widely used in computer vision applications, but they often generate over-confident predictions when tested with images that are different from the training data. Therefore, developing robust outlier detection methods is crucial for real-world implications. In this paper, we focus on outlier detection using variational autoencoders (VAEs), which are simple deep generative models. VAEs consist of a generative model and an inference model, both parameterized by deep neural networks. Unlike other generative models, VAEs optimize the evidence lower bound (ELBO) as a proxy for maximizing the marginal likelihood. However, previous studies have shown that likelihoods computed by VAEs are unreliable for outlier detection due to biases introduced by low-level image statistics. Some existing solutions have been proposed, but they have computational limitations or do not perform well with limited sample sizes. In this work, we propose lightweight analytical and algorithmic remedies, such as bias correction and contrast stretching, to debias VAE likelihoods and achieve robust outlier detection. Our approach aims to address the limitations of previous methods and provide efficient and effective outlier detection in real-world computer vision applications.