Facial Action Units (AUs) play a crucial role in describing facial activities and have numerous applications in computer vision. While the majority of existing facial AU recognition works are supervised, requiring labeled images for training, they often overlook the correlation between AUs and specific facial areas, limiting their performance. Recent approaches have aimed to address this issue by learning AU-specific patterns using facial landmarks and muscles. However, obtaining AU labels from experts is time-consuming and existing labeled databases are too limited for these supervised methods. Some semi-supervised methods summarize label distributions from ground-truth AU labels, but they may not accurately capture the true distribution due to limited data. Other self-supervised methods utilize large amounts of unlabeled data to learn representations but do not fully leverage task-related domain knowledge. In this paper, we propose a novel knowledge-driven self-supervised representation learning framework for AU recognition that alleviates the need for AU labels by utilizing domain knowledge derived from Facial Action Coding System (FACS) rules. We divide the facial areas based on appearance changes associated with AUs and train a representation learning framework using contrastive learning and inter-area correlation predictors. Our method outperforms state-of-the-art self-supervised, semi-supervised, and supervised methods in two benchmark databases, demonstrating the effectiveness of learning AU-related local representations from large amounts of unlabeled data while leveraging task-related domain knowledge.