Template-based 3D object tracking is an important task in computer vision, used in various applications such as augmented reality and robotic grasping. While single-frame 6DOF pose estimation methods have seen rapid development, video analysis requires more accurate and efficient 3D tracking. However, accurately annotating the 3D pose of moving objects in real videos is challenging. Existing datasets have limitations, including synthetic or low-precision annotations, limited object and camera movement, and marker restrictions. To address these limitations, we propose a markerless multi-view approach for high-precision 3D pose estimation of video objects. Our method utilizes shape-based techniques and joint optimization of multiple views. We also introduce a new benchmark, the BCOT (BinoCular Object Tracking) benchmark, which includes accurately annotated real videos with freely moving cameras and objects. The benchmark achieves a maximum annotation error of 2mm, providing high-precision ground truth for evaluation. Our contributions include the proposed multi-view approach, the BCOT benchmark, and a comprehensive evaluation of state-of-the-art 3D object tracking methods on the benchmark.