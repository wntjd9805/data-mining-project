In this computer science paper, the authors address the problem of optimization difficulties that arise when increasing the depth of convolutional neural networks. They propose the use of auxiliary classifiers connected directly to intermediate layers to provide extra gradients and alleviate the vanishing gradient problem in image classification. The authors highlight the use of auxiliary classifiers in variations of the Inception architecture and ResNet to directly provide useful gradients to intermediate layers. Similar attempts have been made in the field of semantic segmentation, where auxiliary heads are used in ResNet-101 to resize the resolution of intermediate feature maps. However, the authors argue that this approach is flawed as it does not consider the various-order features of each layer. To overcome this limitation, the authors introduce Class Probability Preserving (CPP) pooling, which keeps the class information within a receptive field as a probability to prevent information loss. The authors conduct comprehensive experiments on various datasets and demonstrate that CPP pooling is effective in improving the training process of semantic segmentation models. Additionally, the authors propose SeeThroughNet, a model with an improved multi-scale attention-coupled decoder structure, to maximize the effect of CPP pooling. SeeThroughNet achieves state-of-the-art results in semantic understanding of high-resolution urban street scenes. The contributions of this paper include the introduction of CPP pooling, the demonstration of its effect on popular semantic segmentation models, and the proposal of SeeThroughNet.