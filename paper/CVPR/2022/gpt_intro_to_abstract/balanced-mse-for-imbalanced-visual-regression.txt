Visual regression is a fundamental task in machine learning, but data imbalance can significantly affect the model's performance and fairness. Imbalanced regression, which focuses on predicting continuous labels, is an underexplored area compared to imbalanced classification. Previous works have explored sample synthesis and loss reweighting techniques, but they have shown limited effectiveness. To address this gap, we propose a statistically principled loss function called Balanced MSE for imbalanced regression. We leverage the training label distribution prior to restore a balanced prediction and provide flexible implementation options. The advantages of Balanced MSE are demonstrated through theoretical analysis and practical experiments on synthetic and real-world benchmarks. We also introduce a new multi-dimensional benchmark for imbalanced regression and show that Balanced MSE achieves state-of-the-art performance. Overall, this work contributes to improving the performance and effectiveness of imbalanced regression tasks in the modern deep learning context.