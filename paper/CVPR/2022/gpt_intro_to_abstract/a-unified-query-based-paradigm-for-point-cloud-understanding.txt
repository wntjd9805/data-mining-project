This paper introduces the concept of the Embedding-Querying (EQ) paradigm for 3D point cloud understanding tasks. The EQ paradigm allows for feature generation for any position in the 3D scene, unlike the traditional Encoder-Decoder (ED) paradigm that only extracts features for fixed positions. The EQ paradigm consists of three stages: an Embedding stage, a Querying stage, and a task-specific head. Any feature extraction architecture can be used for the Embedding stage, including voxel- and point-based networks. The Querying stage takes a set of query positions and generates their intermediate representation, called Q-representation, based on the support features. A novel querying stage network called Q-Net is introduced to effectively extract the Q-representation. The EQ paradigm is a unified query-based paradigm that can easily combine any state-of-the-art 3D backbone networks with different task heads. This provides flexibility in the head design and improves the model's performance across object detection, semantic segmentation, and shape classification tasks. The primary contributions of this paper are the introduction of the EQ paradigm, the development of Q-Net, and the integration of EQ-Paradigm and Q-Net into various state-of-the-art 3D networks, resulting in consistent performance improvement.