In recent years, supervised learning has achieved great success in computer vision tasks. However, these methods heavily rely on expensive and labor-intensive annotations, which can lead to generalization problems. Self-supervised representation learning has emerged as a promising alternative, benefiting subsequent supervised tasks. While representation learning has advanced in single object recognition, scene text recognition presents additional challenges. Existing non-sequential contrastive learning schemes do not perform well on sequence-like characters, highlighting the need for a specific representation learning scheme. This paper explores the unique properties of scene text and proposes a generative representation learning scheme. The proposed scheme incorporates a Similarity-Aware Normalization (SimAN) module to align corresponding styles. The SimAN module estimates the similarity of representations between augmented and neighboring image patches. By ensuring distinguishability of representations, different patterns can be identified and correctly aligned with styles. The proposed approach achieves promising representation performance and demonstrates capabilities in data synthesis, text image editing, and font interpolation. Overall, this work contributes to the development of better representations for sequential data like scene text images, opening up practical applications in the field.