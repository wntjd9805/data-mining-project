Abstract:This paper investigates the importance of the initial phase in Class Incremental Learning (CIL) and proposes a novel regularization technique called Class-wise Decorrelation (CwD) to improve CIL performance. Previous works focused on reducing forgetting in later phases, neglecting the impact of the initial phase on subsequent learning. The authors argue that the initial phase plays a critical role in CIL and propose a method to mimic the oracle model's representations at this phase. Experimental results show that this additional regularization significantly improves CIL performance in subsequent phases. The authors also analyze the difference in representations between the naively-trained initial-phase model and the oracle model, finding that representations in the latter scatter more uniformly. Motivated by this finding, they propose the CwD regularizer to enforce uniformly scattered representations in the initial phase. Extensive experiments on benchmark datasets demonstrate consistent performance gains with the proposed CwD regularizer. The contributions of this paper include the empirical discovery of the benefits of mimicking the oracle model in the initial phase, the observation of more uniformly scattered representations in the oracle model, and the proposal and evaluation of the CwD regularization technique.