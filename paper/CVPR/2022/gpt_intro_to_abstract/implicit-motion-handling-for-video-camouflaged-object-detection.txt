Video Camouflaged Object Detection (VCOD) is a challenging task in computer vision that involves identifying objects in videos that blend seamlessly with the background. Despite its wide range of applications, such as surveillance, autonomous driving, and medical image segmentation, VCOD has not received as much attention as other related problems in computer vision. In traditional computer vision tasks, objects are assumed to have clear boundaries, which makes the detection process easier. However, camouflaged objects lack clear boundaries and often have repetitive textures similar to the background, making it difficult to distinguish them. Additionally, the motion information used for detection is often noisy and inaccurate. Existing approaches, such as video object detection (VOD), video salient object detection (VSOD), and video motion segmentation (VMS), fail to effectively tackle the VCOD problem. In this paper, we propose SLT-Net, a new method for VCOD that leverages short-term dynamics and long-term temporal consistency. SLT-Net incorporates a short-term dynamic module to capture motion implicitly using a correlation pyramid strategy instead of relying on optical flow. To address accumulated inaccuracies in the short-term module, we introduce a long-term refinement module. Our approach combines transformer and CNN components to encode features and construct the correlation pyramid, benefiting from the global contextual information and long-range dependencies captured by the transformer. To evaluate SLT-Net and promote further research in VCOD, we curate a large-scale dataset called MoCA-Mask, consisting of 87 video sequences with pixel-wise ground truth masks. The dataset encompasses various challenges, including complex backgrounds and well-camouflaged objects. We provide annotations, bounding boxes, and dense segmentation masks for every five frames, along with a comprehensive benchmark for existing VCOD methods. Our contributions include the new VCOD framework, the MoCA-Mask dataset, and setting a new state-of-the-art performance on the VCOD task.By effectively modeling short-term dynamics and long-term temporal consistency, our proposed SLT-Net framework improves the detection of camouflaged objects in videos. The MoCA-Mask dataset and benchmark facilitate further advancements in VCOD research. Our experiments demonstrate that SLT-Net outperforms the previous state-of-the-art method by 9.88%.