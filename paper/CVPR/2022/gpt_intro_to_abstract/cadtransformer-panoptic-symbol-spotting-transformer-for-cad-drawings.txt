Symbol spotting is a crucial task in document image analysis and architecture industries. However, traditional methods struggle with the variability in graphical notations and the complexity of CAD drawings. Recent learning-based approaches using convolutional neural networks (CNNs) treat CAD drawings as pixel images, leading to inaccurate predictions. This paper proposes CADTransformer, a transformer-based framework, to address the challenges of symbol spotting in CAD drawings. CADTransformer tokenizes graphical primitives directly from CAD drawings and introduces improvements to the standard transformer backbone, such as neighborhood awareness, hierarchical feature aggregation, and a novel data augmentation approach. The proposed framework is evaluated on the FloorPlanCAD dataset, and it outperforms previous state-of-the-art methods, significantly improving panoptic quality. A comprehensive set of ablation studies is also conducted to demonstrate the effectiveness of each design component.