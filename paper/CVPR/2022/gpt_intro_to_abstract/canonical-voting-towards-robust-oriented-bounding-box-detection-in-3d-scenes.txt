This paper introduces a method for 3D object detection using depth cameras and Lidar sensors. The method, called VoteNet, shows remarkable improvement over previous methods on 3D oriented bounding box detection. However, it is found that the accuracy of predicted offsets and box orientations is not better than random guess in many cases. To address this issue, the paper proposes disentangling the direct offset towards object centers into Local Canonical Coordinates (LCC), box scales, and box orientations. Experimental results show that the LCC predictions are far more accurate than direct offset predictions. The paper also presents a canonical voting algorithm to find possible object orientations and centers, and introduces a back projection validation module to eliminate false positives. The proposed method achieves state-of-the-art performance on various 3D detection benchmarks and is more robust in detecting occluded objects. The contributions of this work are bypassing orientation regression difficulties through LCC and canonical voting, and devising a back projection validation module for eliminating false positives.