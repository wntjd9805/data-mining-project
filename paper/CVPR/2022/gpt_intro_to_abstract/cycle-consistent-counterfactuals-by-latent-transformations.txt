This paper explores the generation of counterfactual (CF) explanations in the visual domain, aiming to provide humans with examples that are visually similar to the original image but classified differently by convolutional neural networks (CNNs). Prior work has focused on generating CF examples through optimization or generative models, but these approaches often suffer from being time-consuming, adversarial, or off the natural image manifold. To address these limitations, the authors propose a novel approach that optimizes for a nonlinear transformation in the latent space of a pretrained generative model. This approach allows for the generation of realistic CF examples at high resolutions and can easily adapt to current and future generative algorithms. The paper also introduces a set of quantitative evaluation metrics to assess properties such as validity, proximity, sparsity, realism, and speed of CF explanations. Extensive evaluations demonstrate the effectiveness and capabilities of the proposed method in generating high-resolution CF images.