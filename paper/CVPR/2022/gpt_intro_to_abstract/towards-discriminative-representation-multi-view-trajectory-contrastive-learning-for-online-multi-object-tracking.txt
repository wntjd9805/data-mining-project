Multiple object tracking (MOT) is a crucial task in computer vision with applications in various fields such as autonomous driving, video analysis, and intelligent robots. Most existing MOT methods follow the tracking-by-detection paradigm, which involves detection and association. However, these methods face challenges when targets are missing for several frames, making it difficult to reconnect them to the correct trajectories. To address this issue, appearance-based strategies have been employed, but their effectiveness is still limited. Therefore, the need for more effective representation learning methods in MOT is evident.In this paper, we propose a novel multi-view tracker (MTrack) that incorporates several techniques to enhance the association accuracy in MOT. First, we introduce a multi-frame representation learning approach that utilizes the features from the entire trajectory instead of just a single or neighboring frames. This allows for a more comprehensive understanding of the objects' characteristics and improves the discriminative power of the learned representation. Additionally, we propose a feature aggregation method that effectively handles poor features caused by occlusion or blurriness. By aggregating features based on historical similarity, the influence of these poor features on the trajectory representation is mitigated.We evaluate the performance of MTrack on four popular MOT benchmarks, including MOT15, MOT16, MOT17, and MOT20. The experimental results demonstrate the effectiveness of our proposed strategies, with MTrack significantly outperforming previous state-of-the-art methods. For example, on the MOT20 dataset, MTrack achieves an IDF1 score of 69.2% and an MOTA score of 63.5%. These results highlight the advantage of our approach in improving the quality and accuracy of object association in MOT tasks.