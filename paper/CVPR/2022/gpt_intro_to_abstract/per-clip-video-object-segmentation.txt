Semi-supervised video object segmentation (VOS) aims to segment foreground objects in every frame of a video using a ground truth object mask in the first frame. The Space-Time Memory network (STM) introduced a memory-based approach that encodes past frames and corresponding masks as memory, allowing for mask prediction in the current frame. This memory-based approach has dominated the field of semi-supervised VOS, with various improvements such as advanced memory read processes and efficient memory storage. The STCN model improved memory matching using siamese key encoders and demonstrated that memory updates may not be needed at every frame, leading to significant speedup without sacrificing accuracy.Building on these advancements, this paper explores a per-clip inference scheme for memory-based VOS. By updating the memory periodically with an interval, the input video frames can be grouped into consecutive frames (clips), and mask prediction can be performed clip-by-clip instead of frame-by-frame. This non-causal system enables the exchange of information among frames within a clip, allowing for optimized predictions. Additionally, increasing the memory update interval offers linear speedup and the potential for accuracy-speed tradeoff.Based on this motivation, the paper proposes a new method called PCVOS tailored for per-clip inference. Several changes are introduced, including an intra-clip refinement module that optimizes features using spatial-temporal neighborhood information and a progressive memory matching mechanism that enhances memory readout accuracy. The paper also presents a new training scheme that utilizes multiple clips and clip-level supervision.Experimental results demonstrate that PCVOS achieves state-of-the-art performance on multiple benchmarks, with efficient variants offering a balance between accuracy and speed. For example, the Ours-L15 model outperforms STCN1 while running almost three times faster. Additionally, by varying the memory update intervals, different models with varying accuracy and efficiency tradeoffs can be achieved. The proposed per-clip inference scheme provides an alternative to the dominant per-frame inference perspective, and PCVOS offers improved performance and flexibility. Overall, the contributions of this paper include the reformulation of semi-supervised VOS from a per-clip perspective, the introduction of the PCVOS model tailored for per-clip inference, and the achievement of state-of-the-art performance with efficient variants.