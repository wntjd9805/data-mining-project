The upright orientation of objects plays a crucial role in their functionality, stability, and semantic meaning. In computer graphics and computer vision, registering objects in an upright orientation is a common practice for various tasks. However, learning features that are invariant or equivariant with respect to geometric transformations in unaligned point cloud data remains a challenge. Previous methods have attempted to estimate the upright orientation of 3D models based on hand-crafted features or by using divide-and-conquer schemes. However, these approaches have limitations in terms of bias, conflict among features, and convergence of solutions. In this paper, we propose a data-driven deep learning method called Upright-Net to address these challenges. Our approach formulates the continuous orientation problem as a discrete classification problem and utilizes deep learning to automatically extract comprehensive features. By encoding criteria that define the natural base and learning orientation-aware features, we achieve superior performance in orientation estimation. The experimental results demonstrate the effectiveness, generalization ability, and transfer capability of Upright-Net compared to previous approaches.