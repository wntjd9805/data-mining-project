A foundational goal of machine learning is to develop models that are robust across various data distributions. While current algorithms struggle to enhance robustness on certain distribution shifts, large pre-trained models have shown unprecedented robustness. However, these robustness improvements are strongest when the models perform inference without fine-tuning. Fine-tuning on specific data can improve performance on the target distribution but often comes at the cost of reduced robustness. This raises the question of whether zero-shot models can be fine-tuned without compromising accuracy under distribution shift. Fine-tuning pre-trained models is crucial in machine learning, and robust fine-tuning has been identified as an open problem. In this paper, we empirically investigate the fine-tuning of zero-shot models from a distributional robustness perspective. We measure the impact of different fine-tuning approaches on accuracy under distribution shift and identify two key issues: the sensitivity of fine-tuned models to hyperparameter changes and the trade-off between target distribution accuracy and distribution shift robustness. To address these challenges, we propose a robust fine-tuning method called Weight-space ensembles for fine-tuning (WiSE-FT), which combines the original zero-shot and fine-tuned models by linearly interpolating their weights. We demonstrate that WiSE-FT substantially improves accuracy under distribution shift on ImageNet and other natural distribution shifts, while maintaining or improving accuracy on the target distribution. These robustness gains incur no additional computational cost during fine-tuning or inference. Our investigation focuses on CLIP but demonstrates similar trends for other zero-shot models. We also explore the robustness gains of WiSE-FT on additional distribution shifts and show improvements in accuracy compared to standard fine-tuning on various datasets. Overall, WiSE-FT is a simple and universally applicable method that can be easily implemented for fine-tuning zero-shot models.