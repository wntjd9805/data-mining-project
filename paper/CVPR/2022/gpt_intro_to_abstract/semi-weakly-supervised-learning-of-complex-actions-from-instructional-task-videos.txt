Learning procedural tasks from instructional videos has become increasingly important, with applications ranging from teaching intelligent agents to constructing knowledge bases and evaluating task performance. However, annotating videos with detailed actions is time-consuming and complex, posing challenges for scaling learning to a large number of tasks and videos. While some fully-supervised methods have been explored, most existing works focus on utilizing weak supervision, such as video transcripts or action sets. Weakly-supervised methods reduce annotation costs but still require watching entire videos, while unsupervised methods leverage unlabeled videos but suffer from limited similarity constraints. To address these issues, we propose a Semi-Weakly-Supervised Learning (SWSL) approach that combines weakly-labeled training videos and unannotated videos with only task labels. Our method simultaneously learns a video segmentation model and an action classifier by regularizing learning from a small number of weakly-labeled videos with unlabeled videos. We introduce a differentiable Soft Restricted Edit (SRE) loss to predict transcripts for unlabeled videos that are close to ground-truth transcripts of weakly-labeled videos from the same task. To compute the SRE loss, we develop a flexible transcript prediction (FTP) method that uses the output of the action classifier to determine the length and sequence of actions in an unlabeled video. Our learning scheme alternates between minimizing the proposed loss on both types of videos and adding confident unlabeled videos and their pseudo-transcripts to the weakly labeled set. Experimental results on benchmark datasets demonstrate the effectiveness of our approach.