This paper introduces the concept of monocular 3D object detection, which aims to obtain the locations, sizes, and orientations of objects using only a single 2D image and camera calibration information. This method is gaining attention due to its simplicity and cost advantages, especially in the field of autonomous driving. However, obtaining 3D information from a 2D image is challenging due to the ill-posed mapping from 2D to 3D, the correlation of depth with object height, and the sparsity of depth supervision in existing methods. To overcome these challenges, the paper proposes the use of a learnable ground plane prior that is based on the assumption that objects should lie on the ground. This ground plane prior helps to solve the ill-posed mapping problem, remove the correlation between depth and height, and provide dense depth supervision. The paper also introduces depth-align training and a two-stage depth inference method to effectively learn and predict dense grounded depth. Experimental results on the KITTI dataset demonstrate the effectiveness of the proposed method, which achieves state-of-the-art performance with real-time processing speed.