This paper addresses the drawback of the Neural Radiance Fields (NeRF) method, which requires training from scratch for every scene separately. Various approaches, such as pixelNeRF, GRF, MINE, SRF, IBRNet, MVSNeRF, and NeRFormer, have attempted to generalize the NeRF rendering technique to unseen scenes by conditioning the renderer with features from nearby views. However, these methods still have limited understanding of scene geometry and occlusions, leading to undesired artifacts in the rendered outputs. In this work, the authors propose improvements to the MVSNeRF method by introducing a geometry reasoner in the form of cascaded cost volumes and training it in a semi-supervised fashion to obtain fine and high-resolution priors for conditioning the renderer. They also combine an attention-based model with an auto-encoder network to handle information from different source views and leverage the strong Euclidean and ordering structure along a ray. The authors further detect and exclude occluded views for each point in space to improve the rendering process. Additionally, they propose an alternate model that utilizes RGBD images to enhance the perception of geometry. The paper references concurrent works such as RGBD-Net, NeuralMVS, and NeuRay, which also aim to create a generalizable NeRF method. Overall, this research contributes to the improvement of scene understanding and rendering quality in the field of computer vision and computer graphics.