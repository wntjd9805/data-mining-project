Crowd counting is an important task in various applications such as congestion estimation, video surveillance, and crowd management. With the outbreak of COVID-19, real-time crowd detection and counting have gained significant attention. Existing counting methods typically use Convolutional Neural Networks (CNNs) to predict the total crowd count by regressing density maps. However, traditional CNNs struggle to handle large-scale variations in crowd images due to the wide viewing angle of cameras and 2D perspective projection. To address this limitation, recent methods have introduced multi-scale mechanisms that adapt to the size of objects. Transformer models, which utilize global self-attention, have shown promising results in natural language processing tasks. However, their application in crowd counting is still in its early stages and faces challenges in incorporating local inductive bias in crowded scenes. This paper proposes a novel Multifaceted Attention Network (MAN) for crowd counting using vision transformers. MAN improves the structure and training scheme of vision transformers by introducing learnable region attention (LRA) to emphasize local context and handle large-scale variations. It also incorporates a local attention regularization (LAR) method to optimize the distribution of attention and an instance attention module to focus on important instances dynamically during training. Experimental results on popular datasets demonstrate the effectiveness of MAN in achieving significant improvements in crowd counting performance.