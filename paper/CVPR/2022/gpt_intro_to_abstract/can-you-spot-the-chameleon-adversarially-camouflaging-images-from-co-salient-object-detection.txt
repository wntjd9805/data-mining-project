Co-saliency detection is a challenging problem in computer vision, aiming to identify common and salient foreground regions across a group of images. While there have been several methods proposed to solve this problem, they also raise concerns regarding the potential extraction of sensitive content. In this work, we propose a novel approach called adversarial co-saliency attack to evade co-saliency detection methods and conceal personal content. Our method, called Jadena, jointly adjusts exposure and perturbations in the image using a contrast-sensitive loss function. Unlike white-box attacks, Jadena does not require knowledge of existing CoSOD methods and achieves significant performance degradation on various datasets. This has practical value for protecting personal multimedia contents shared on the internet. The code for our method is available on GitHub.