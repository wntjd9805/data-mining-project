Image restoration is a challenging task that involves reconstructing a high-quality image by removing degradations such as noise, blur, and raindrops. Convolutional neural networks (CNNs) have emerged as a preferred choice for image restoration due to their ability to learn effective image priors from large-scale data. However, CNNs are limited by their fixed weights during inference and their inability to model long-range pixel dependencies. In this paper, we propose an efficient Transformer model for image restoration that can capture global connectivity and is applicable to large images. Our model introduces a multi-Dconv head transposed attention (MDTA) module that applies self-attention across feature dimensions rather than spatial dimensions, allowing for linear complexity and modeling of cross-channel interactions. We also reformulate the first linear transformation layer of the regular feed-forward network (FN) with a gating mechanism to improve information flow. Additionally, we present a progressive learning strategy for training our Restormer model, which involves training on small patches and gradually increasing image patch sizes. Experimental results demonstrate that our Restormer achieves state-of-the-art performance on various image restoration tasks, including deraining, deblurring, and denoising. Our proposed architectural designs and experimental choices are also shown to be effective through extensive ablations. Overall, this work contributes to the field of image restoration by providing an efficient Transformer model that can capture global interactions and produce high-quality outputs on high-resolution images.