Abstract:The rapid development of 3D technologies has created a digital replica of the real world, opening up new possibilities for interaction and communication. However, there is currently no solution for automatically populating the digital world with realistic virtual humans. This paper presents a method called GAMMA (Generative Motion primitive via body surface MArkers) that enables virtual humans to navigate a 3D environment realistically. The virtual humans follow randomized routes, pass individual waypoints, and reach their destination while maintaining realistic body shape, pose, and contact with the environment. This technology has potential applications in enhancing AR/VR user experiences and providing architects with a blueprint for design foresight. The paper addresses the limitations of existing character animation methods, which are unable to handle a massive number of characters with different behaviors. GAMMA utilizes large-scale motion capture datasets and a generative motion model to produce diverse and realistic motions for a variety of human shapes. The paper also tackles the challenge of allowing virtual humans to move naturally within 3D scenes while considering geometric constraints. A novel motion synthesis pipeline with control is proposed, consisting of a policy network and a tree-based search mechanism. Experimental results demonstrate the realism and controllability of the method, outperforming state-of-the-art approaches. Overall, GAMMA provides a fully automated solution for populating 3D scenes with virtual humans and enriching user experiences. The code and model are made available for research purposes.