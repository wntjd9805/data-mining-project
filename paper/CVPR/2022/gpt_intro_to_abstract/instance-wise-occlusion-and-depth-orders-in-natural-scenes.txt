In computer vision, understanding the content of an image is a fundamental problem. Deep learning-based approaches have shown great success in various tasks such as object detection, semantic and instance segmentation, and depth estimation. Recent research has also focused on inferring high-level information like amodal segmentation, physics, and 3D-property recognition. Understanding relationships between objects, particularly in cluttered scenes, is crucial for learning high-level context. To facilitate research in geometric scene understanding, we introduce a new large-scale dataset called INSTAORDER. This dataset provides extensive annotations on the geometric ordering between class-labeled instances in natural scenes. INSTAORDER includes two types of orders: occlusion order, which indicates objects that occlude others, and depth order, which describes the relative distance of objects from the camera. These two types of relations can be represented using directed graphs. The occlusion order and depth order are complementary to each other, and neither alone can fully depict the geometric relationship in a cluttered scene. INSTAORDER is the only dataset that provides instance segmentation masks, instance class labels, occlusion order, and depth order annotations together. The dataset is built on the COCO 2017 dataset and has annotations from 3,659 crowd-workers for 100,623 images, resulting in 2,859,919 depth and occlusion orderings. The annotations in INSTAORDER cover a wide range of complex and ambiguous cases that were not addressed in prior datasets. We also propose two new networks, InstaOrderNet and InstaDepthNet, for geometric order prediction and depth estimation, respectively. These networks achieve superior accuracy compared to state-of-the-art approaches. The INSTAORDER dataset, pre-trained models, and toolbox are publicly available for further research and development.