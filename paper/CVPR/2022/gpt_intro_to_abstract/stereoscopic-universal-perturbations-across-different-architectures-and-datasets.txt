Deep neural networks have shown vulnerability to adversarial perturbations, where small changes in input images can lead to significant inference errors. Such perturbations have been observed to disrupt not only the classification label but also the depth or disparity estimates in stereo networks. Universal adversarial perturbations have been crafted to disrupt inference for all images in a dataset with high probability. In this paper, we introduce the concept of stereoscopic universal perturbations (SUPs) that can disrupt the depth or disparity estimate of different stereo networks trained on different datasets, architectures, and domains. Unlike previous perturbations, SUPs are not specific to individual inputs and can generalize across domains and datasets. We demonstrate the existence of SUPs and their effectiveness in disrupting stereo networks even without knowledge of the trained model. Our main methodological innovation is the design of SUPs that are approximately space equivariant. We observe that SUPs induce more errors in disparity for certain object classes, potentially due to their homogeneous regions prone to disparity ambiguity. Through empirical analysis, we find that SUPs affect the features of registered points in a stereo pair, fooling the network into estimating incorrect correspondences. Additionally, we investigate the role of architectural elements, such as deformable convolutions and explicit feature matching, in mitigating the effects of SUPs. Our results show that these architectural choices can reduce the impact of adversarial attacks and improve robustness against common image perturbations. Overall, our contributions include the design and analysis of SUPs, uncovering the mechanisms of their impact on stereo networks, and proposing architectural designs to mitigate their effects.