Marker-less human motion capture has experienced rapid development in the past decade, particularly for applications in virtual reality/augmented reality and interactive entertainment. However, capturing long-range 3D human motions in a large space remains a challenge, especially for activities like sports and human behavior analysis. While vision-based motion capture solutions dominate the field, they often require expensive equipment or markers, making them impractical for consumer-level usage. Monocular capture methods using learning-based techniques have become more popular but struggle with capturing clear images of performers far away from the cameras. In contrast, motion capture using body-worn sensors like Inertial Measurement Units (IMUs) is widely adopted but limited to capturing motions of people wearing specific attire. Additionally, IMU-based methods suffer from global drifting artifacts in long-range settings. Consumer-level RGBD sensors are also not suitable for long-range capture in large scenes. To address these challenges, this paper proposes the use of a consumer-level LiDAR sensor for marker-less, long-range, and data-driven motion capture. The LiDAR sensor provides accurate depth information over a large effective range, making it suitable for capturing 3D human motions in general lighting conditions without degraded visual artifacts. However, capturing long-range 3D human motions using a single LiDAR sensor poses its own set of challenges, including the sparse and noisy nature of observed point clouds and the lack of a large-scale LiDAR-based dataset with accurate 3D human motion annotations. To overcome these challenges, the paper introduces LiDARCap, a marker-less, long-range, and data-driven motion capture method using a single LiDAR sensor. The paper also presents the LiDARHuman26M benchmark dataset, which includes synchronous LiDAR point clouds, RGB images, and ground-truth 3D human motions obtained from professional IMU-based mocap devices. The dataset covers various daily motions and performers, facilitating the development of data-driven LiDAR-based motion capture techniques. The paper concludes with a thorough evaluation of LiDARCap and state-of-the-art image-based motion capture methods using the LiDARHuman26M dataset, highlighting the advantages of LiDAR-based methods in the long-range setting. The contributions of this paper include the proposal of the first monocular LiDAR-based approach for marker-less, long-range 3D human motion capture, a three-stage motion capture pipeline, and the provision of a large-scale benchmark dataset for LiDAR-based motion capture.