Visual object tracking (VOT) is a crucial problem in computer vision research with applications in video surveillance, autonomous vehicles, and human-machine interaction. Most popular trackers utilize Siamese network structures and similarity metric of cross-correlation. However, the single-level linear computational process in these trackers loses semantic information. Transformer-based approaches have recently achieved state-of-the-art performance in various computer vision tasks. In this paper, we propose a novel multi-scale cyclic shifting window transformer for visual object tracking. Our method lifts pixel-level attention to window-level attention, preserving location information and integrity of the object. We introduce a multi-head multi-scale attention scheme with cyclic shifting strategy and design a spatially regularized attention mask for accurate attention results. We also present computation optimization strategies to reduce redundancy. Experimental results show that our tracker outperforms existing algorithms. Our contributions include the novel transformer architecture, window-level attention, spatially regularized attention mask, and computational optimization strategies.