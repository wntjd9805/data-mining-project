RGB-D scan registration is crucial for 3D reconstruction and modeling. Existing methods typically require a large overlap between scans, which is not always achievable in practical scenarios. This paper introduces a method for directly registering less-overlap RGB-D scans by leveraging global information. Unlike previous approaches that rely on local feature points for matching, our method utilizes scene layout and object surroundings to guide the registration process. This approach addresses the challenge of blurred and texture-less regions, which pose problems for conventional methods. The registration is performed in a jigsaw-like manner, preserving global consistency of both geometric and photometric alignments. However, utilizing global information is challenging due to noise introduced by unaligned scans and unreliable completion. To overcome this challenge, we propose a reinforcement learning-based method that jointly reduces noise and improves alignments. By aligning RGB-D scans with the scene based on current and future global information, we refine the alignment process iteratively. We also introduce a scene inference network to generate a panorama representation of the global information, which is then refined using global constraints of photometry and geometry. Experimental evaluation on SUNCG, Matterport, and ScanNet datasets demonstrates the superiority of our method compared to existing state-of-the-art approaches for less-overlap scan registration.