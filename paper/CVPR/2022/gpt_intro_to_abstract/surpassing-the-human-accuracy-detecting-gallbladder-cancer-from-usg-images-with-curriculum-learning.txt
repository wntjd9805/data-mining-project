Gallbladder cancer (GBC) is a deadly disease with a low survival rate, making the early detection of utmost importance. While machine learning models based on convolutional neural networks (CNNs) have shown significant progress in medical diagnosis for various diseases, their application in GBC detection is lacking. In this paper, we address the challenge of automated GBC detection from ultrasound (USG) images. USG is a popular diagnostic tool due to its non-ionizing radiation, low cost, portability, and accessibility. However, accurately characterizing GBC from USG images is challenging. Existing CNN classifiers fail to localize the gallbladder region accurately, and the presence of shadows and other artifacts further complicates the analysis. To overcome these challenges, we propose GBCNet, a deep neural network that extracts candidate regions of interest (ROIs) from USG images to mitigate the effects of shadows and employs a multi-scale, second-order pooling-based (MS-SoP) classifier for malignancy detection. We also introduce a training curriculum inspired by human visual acuity to address texture bias in GBCNet. Additionally, we present a new dataset, the Gallbladder Cancer Ultrasound (GBCU) dataset, consisting of 1255 annotated abdominal USG images. Our proposed approach shows improvement in GBC detection compared to state-of-the-art models, providing a stepping stone for future research in this field.