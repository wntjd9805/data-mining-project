Object rearrangement is a crucial skill for robots to assist people with everyday tasks. Previous approaches rely on strict assumptions about known objects and accurate pose estimation. Recent efforts have used deep learning to relax these constraints, but are limited to 2D translations and no change in object orientation. In this paper, we propose a new approach, IFOR, which handles unknown objects with translation and planar rotations. Our method reformulates object rearrangement as an iterative minimization of optical flow, leveraging state-of-the-art flow estimation models. Using this estimated flow, along with depth input and object segmentation models, we obtain dense 3D correspondences for each object, allowing for desired transformation via optimization. Our approach is trained on simulation data and transfers to the real world in a zero-shot manner. Experimental results demonstrate the effectiveness of IFOR in rearranging novel objects in cluttered scenes with a real robot.