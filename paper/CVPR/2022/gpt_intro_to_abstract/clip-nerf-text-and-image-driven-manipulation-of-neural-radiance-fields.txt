Abstract:The demand for manipulating 3D content has increased with the growth of 3D assets. While most existing 3D editing methods operate on explicit representations, recent advances in implicit volumetric representations have motivated research in benefiting manipulation from such representations. Neural Radiance Fields (NeRF) utilize volume rendering to render neural implicit representations for high-quality novel view synthesis, providing an ideal representation for 3D content. However, editing NeRF, such as deforming shape or changing appearance, is challenging due to the implicit nature of NeRF and the multi-view dependency. This paper presents a novel framework for individually manipulating the shape and appearance of NeRF based on a text prompt or a reference image. The framework is built on a disentangled conditional NeRF architecture controlled by shape and appearance codes. The shape code guides the deformation of the volume, while the appearance code controls the emitted color. By using Contrastive Language-Image Pre-training (CLIP), text prompts or exemplar images are used to extract features and map them to the latent space for editing the shape and appearance codes. A CLIP-based loss enforces consistency between input constraints and output renderings, enabling high-resolution NeRF manipulation. Additionally, an optimization-based method is proposed for editing real images by inversely optimizing their shape and appearance codes. This paper makes contributions in the form of the first text-and-image-driven manipulation method for NeRF, a disentangled conditional NeRF architecture, feedforward code mappers for fast inference, and an inversion method for shape and appearance editing of existing data.