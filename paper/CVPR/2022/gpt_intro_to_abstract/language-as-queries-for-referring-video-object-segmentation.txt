Referring video object segmentation (R-VOS) is a challenging task that aims to segment the target object in a video given a natural language description. This paper introduces a simple and unified framework called ReferFormer to solve the R-VOS task. The framework utilizes language expressions as queries to focus on the referred object, reducing the query number and improving performance. Additionally, a cross-modal feature pyramid network is designed for multi-scale vision-language fusion, enhancing the discriminativeness of mask features for accurate segmentation. Extensive experiments on multiple benchmarks demonstrate that ReferFormer outperforms previous methods by a significant margin, achieving impressive results. The proposed framework can serve as a strong baseline for the R-VOS task.