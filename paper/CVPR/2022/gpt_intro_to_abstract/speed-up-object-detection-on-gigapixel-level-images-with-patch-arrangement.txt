This paper addresses the challenge of efficiently analyzing super high-resolution images, particularly at the gigapixel level. It introduces a novel framework called Patch Arrangement Network (PAN) for object detection in gigapixel-level images. PAN arranges patches into compact canvases to significantly speed up the detection process. The framework comprises a multi-grained patch tree, a Patch Filter Module (PFM), and a Patch Packing Module (PPM). The multi-grained patch tree explores the relationship among patches using an LSTM-based tree structure encoder. PFM learns an adaptive patch selection between two granularities, while PPM determines how to pack patches into a compact layout. The entire framework is trained using policy-based reinforcement learning. Experimental results demonstrate that PAN can improve the inference speed of detection by 5x while maintaining high performance. The contributions of this work include the development of an efficient framework for object detection in gigapixel-level images, the introduction of a multi-grained patch tree, and the proposal of the PFM and PPM modules. PAN expands the frontiers of high-resolution image analysis and addresses the challenge of speeding up object detection in large images.