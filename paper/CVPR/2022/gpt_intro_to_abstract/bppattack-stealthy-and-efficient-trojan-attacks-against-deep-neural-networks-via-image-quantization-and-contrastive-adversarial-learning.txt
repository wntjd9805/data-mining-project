Deep Neural Networks (DNNs) have shown impressive performance in computer vision tasks. However, they are vulnerable to various adversarial attacks, including Trojan attacks. In Trojan attacks, a secret Trojan behavior is embedded during training and activated at runtime using a Trojan trigger. Existing Trojan attacks often rely on easily detectable triggers, making them vulnerable to detection and defense methods. In this paper, we propose a new Trojan attack called BPPATTACK that leverages vulnerabilities in human visual systems. By reducing the bit-per-pixel (BPP) and performing input-dependent image transformations, our attack achieves imperceptibility and bypasses existing defenses. We employ contrastive learning and adversarial training for efficient and dynamic injection of triggers. Experimental results demonstrate the effectiveness of our attack on multiple datasets and network architectures, with a high attack success rate and the ability to bypass state-of-the-art defenses. Our work contributes to the understanding of human visual systems and highlights the need for robust defense mechanisms against Trojan attacks in DNN-based computer vision models.