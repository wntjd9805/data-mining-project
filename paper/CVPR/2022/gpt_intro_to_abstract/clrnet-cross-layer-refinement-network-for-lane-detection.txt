Lane detection is a critical task in computer vision with applications in autonomous driving and Advanced Driver Assistance Systems (ADAS). While Convolutional Neural Networks (CNNs) have shown promise in lane detection, accurately predicting lanes remains a challenge. Lanes have high-level semantics and specific local patterns, requiring the utilization of both low-level and high-level features in a CNN. Existing approaches either focus on local geometry or global features, resulting in inaccurate detection performance. Additionally, visual evidence for the presence of lanes can be lacking in certain scenarios, such as when lanes are occupied by cars or affected by extreme lighting conditions. In this paper, we propose a novel framework called Cross Layer Refinement Network (CLRNet) that fully utilizes low-level and high-level features for accurate lane detection. Our approach involves performing detection in high semantic features to localize lanes and refining the locations using fine-detail features. We introduce ROIGather to capture more global context and address the issue of non-visual evidence of lanes. Furthermore, we define the Line IoU (LIoU) loss to regress lanes as a whole unit and significantly improve detection performance. Experimental results on three benchmark datasets demonstrate the effectiveness of our method, achieving state-of-the-art accuracy. Our contributions include the demonstration of the complementarity of low-level and high-level features, the proposal of ROIGather to enhance lane feature representation, the introduction of the LIoU loss, and the improvement in localization accuracy using the mF1 metric.