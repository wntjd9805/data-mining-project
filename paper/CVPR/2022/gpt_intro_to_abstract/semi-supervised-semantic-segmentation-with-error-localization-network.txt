Recent advances in semantic segmentation have been attributed to supervised learning of deep neural networks on large-scale datasets. However, collecting training data for semantic segmentation is labor-intensive and time-consuming, resulting in limited annotated data and class diversity. To address this issue, label efficient learning techniques such as semi-supervised learning, unsupervised learning, weakly supervised learning, and synthetic-to-real domain adaptation have been proposed. This paper focuses on semi-supervised learning of semantic segmentation, where only a subset of training images are assigned segmentation labels. Self-training and contrastive learning are commonly used techniques for utilizing unlabeled images, but they suffer from the drawback of confirmation bias towards errors in predictions. To address this, recent approaches have introduced an error correction network (ECN) to correct errors in pseudo labels. However, ECN's generalization capability is limited due to challenges in training. In this paper, we propose a novel method that better generalizes to errors in arbitrary unlabeled images. Our method incorporates an error localization network (ELN) that identifies pixels with erroneous pseudo labels. By disregarding these invalid pseudo labels, our method alleviates confirmation bias and learns accurate segmentation models. We also design a novel training strategy for ELN that improves its generalization by simulating the segmentation network at different training stages. The trained ELN is then used for semi-supervised learning of semantic segmentation. Experimental results on the PASCAL VOC 2012 and Cityscapes datasets demonstrate the superiority of our method in terms of performance. Our contributions are three-fold: proposing error localization as an effective approach for handling errors on pseudo labels, developing a new strategy for generating diverse and plausible prediction errors during the training of ELN, and achieving state-of-the-art results on benchmark datasets.