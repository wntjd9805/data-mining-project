Abstract: Depth sensors are widely used for providing 3D spatial information in various applications such as augmented reality and 3D reconstruction. However, most existing depth sensors cannot generate precise depth maps, resulting in invalid depth pixels and hole regions. This affects the performance of downstream tasks. Depth completion, which reconstructs the whole depth map from the raw depth map, has been studied extensively. Convolutional neural networks (CNNs) have shown significant progress in depth completion tasks. However, existing methods often produce blurry completed depth maps or require depth completeness without missing regions. In this paper, we propose a novel two-branch end-to-end network called RDF-GAN for indoor depth completion. Inspired by GANs, our network fuses an RGB image and a depth map to generate a completed dense depth map. We also introduce a constraint network to restrict the depth values and a conÔ¨Ådence fusion head for the final depth map completion. Additionally, we propose a method of training with pseudo depth maps that are more realistic and improve the model's depth completion performance, especially in indoor environments. Our method achieves state-of-the-art performance on NYU-Depth V2 and SUN RGB-D datasets and improves downstream task performance such as object detection.