In this paper, we propose a novel Fourier PlenOctree (FPO) technique for neural dynamic scene representation, which enables efficient modeling and real-time rendering of unseen dynamic objects. Our approach combines the generalized Neural Radiance Field (NeRF), PlenOctree representation, volumetric fusion, and Fourier transform. We introduce a coarse-to-fine fusion scheme that leverages the NeRF technique to generate the PlenOctree with fast plenoptic functions inference. To handle dynamic scenes, we tailor the implicit network to model the Fourier coefficients of time-varying density and plenoptic functions of the dynamic PlenOctree. By discarding high-frequency bases, our representation achieves high storage efficiency while preserving perceptual details. Finally, we construct the FPO and train the Fourier coefficients directly on the leaves of a union PlenOctree structure. Our experiments demonstrate that the FPO is significantly faster than the original NeRF implementation and outperforms state-of-the-art techniques for dynamic scene modeling and rendering. Overall, our contributions include the introduction of a FPO representation for real-time rendering of dynamic scenes and a coarse-to-fine scheme for efficient PlenOctree generation and FPO construction.