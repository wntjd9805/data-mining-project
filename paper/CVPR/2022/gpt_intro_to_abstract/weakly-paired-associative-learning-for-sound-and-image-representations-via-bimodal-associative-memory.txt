Data representation learning without labels has gained significant attention in various industries and research fields due to the time-consuming and labor-intensive nature of manual data annotation. Representation learning methods have been applied in computer vision, natural language processing, and sound signal processing. Specifically, bimodal representation learning methods have been proposed to learn feature representation by exploiting the correspondence between auditory and visual data.Existing bimodal representation learning methods require a large number of data samples with corresponding pairs, making it challenging to ensure their effectiveness in weakly paired conditions where paired bimodal data is lacking. Neurobiological studies have shown that cognitive functions related to a certain modality can be enhanced by receiving stimuli from other modalities. Humans memorize and associate multisensory modalities, leading to the enhancement of bimodal cognitive functions.Considering the weakly paired condition, this paper introduces a new problem: how to boost a certain modality's representation using other unpaired modal data. The focus is on sound-image data representations, as it is relatively easier to obtain images compared to sound data. The authors propose a bimodal associative memory (BMA-Memory) that learns sound and image representations by storing bimodal features and associating them through a key-value switching scheme. BMA-Memory enables the association of modalities even from single modal input and addresses the weakly paired condition by boosting the representation of a certain modality using unpaired modal data.The proposed approach introduces weakly paired associative learning, which constructs pseudo bimodal pairs from unpaired data to enhance bidirectional association. This allows for the enhancement of certain modality representations using other unpaired modal data. The concept of the proposed framework is illustrated in Figure 1.The main contributions of this paper are twofold. Firstly, the introduction of BMA-Memory with key-value switching enables the learning of sound and image representations and the acquisition of abundant representations including both input and associated modalities. Secondly, the introduction of weakly paired associative learning effectively addresses the weakly paired condition, allowing for the enhancement of certain modality representations using other unpaired modal data.