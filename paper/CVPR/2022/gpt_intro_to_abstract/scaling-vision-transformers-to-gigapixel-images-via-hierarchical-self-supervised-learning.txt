Tissue phenotyping is a critical component of computational pathology for cancer diagnosis and prognosis. However, analyzing gigapixel whole-slide images (WSIs) presents significant challenges due to their large size and complex features. This paper focuses on a three-stage, weakly-supervised framework for image analysis in WSIs. However, this framework has limitations in capturing both fine-grained and coarse-grained features and learning long-range dependencies between phenotypes. To address these issues, the authors propose the Hierarchical Image Pyramid Transformer (HIPT), a Transformer-based architecture for slide-level representation learning in WSIs. HIPT leverages the hierarchical structure of WSIs and applies self-supervised learning to improve slide-level representations. Experimental results demonstrate that HIPT outperforms conventional approaches, particularly in tasks requiring larger context awareness. Additionally, HIPT achieves superior slide-level classification results and demonstrates the ability to learn fine-grained and coarse-grained visual concepts in histopathology tissue. The code for HIPT is made publicly available.