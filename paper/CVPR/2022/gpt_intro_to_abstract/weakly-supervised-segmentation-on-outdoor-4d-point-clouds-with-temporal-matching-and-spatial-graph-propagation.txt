Recently, outdoor 3D semantic segmentation has gained research attention due to the availability of large datasets such as SemanticKITTI and SemanticPOSS. However, the manual annotation process for these datasets is time-consuming and expensive. In this paper, we propose a novel weakly supervised framework for outdoor point cloud segmentation that aims to reduce the annotation cost. We exploit the temporal information among point cloud sequences and only annotate a small percentage of points in one frame per 100-frame sequence. To generate more supervision, we apply efficient super-voxel segmentation on the dataset and assign labels to their corresponding super-voxels. We design two modules, temporal matching and spatial graph propagation, to propagate the annotations to the whole dataset. We also propose a two-stage training strategy that includes a seed point propagation stage and a dense scene propagation stage. Experimental results on SemanticKITTI and SemanticPOSS datasets show that our weakly supervised approach achieves comparable performance with fully supervised methods while utilizing only a small fraction of annotations. Our method demonstrates the importance of exploiting spatial and temporal information in weakly supervised segmentation tasks.