In recent years, object detection has significantly progressed due to advancements in network architectures and dataset construction. However, training advanced object detectors typically relies on a large number of accurately annotated images, which can be challenging and expensive to obtain. To mitigate the burden of manual labeling, previous studies have proposed weakly and semi-supervised methods for object detection, using partially annotated or unlabeled images. One such approach, weakly semi-supervised object detection (WS-SOD), combines weakly-labeled images with semi-supervised detection to strike a balance between labeling costs and model performance. In this study, we further enhance WS-SOD by introducing point annotations, which provide category and location information with minimal labeling cost. We propose a pipeline that utilizes a point-to-box regressor, trained on images with only bounding box annotations, to convert point annotations into pseudo bounding box annotations. Subsequently, any object detector can be trained using a combination of well-labeled and pseudo-labeled images. We argue against the claim that CNN models perform poorly as point-to-box regressors, and present an in-depth analysis to support our argument. To address the limitations of previous approaches, we propose an instance-aware representation learning framework called Group R-CNN. This framework leverages instance-aware feature enhancement and instance-aware parameter generation to improve model convergence. Compared to the state-of-the-art method Point DETR, our proposed Group R-CNN demonstrates several advantages, including the ability to utilize the feature pyramid network for multi-scale proposal generation and faster convergence. We conduct extensive experiments on the MS-COCO dataset, demonstrating that Group R-CNN outperforms Point DETR by a large margin, even with a significantly smaller training budget. Overall, Group R-CNN achieves superior performance and faster convergence in weakly semi-supervised object detection tasks.