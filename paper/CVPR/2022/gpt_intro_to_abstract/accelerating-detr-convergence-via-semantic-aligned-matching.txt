Object detection is a fundamental task in computer vision that has made significant progress with the development of deep learning. However, traditional object detectors rely on complex pipelines and handcrafted components, resulting in suboptimal performance. The recently proposed DEtection TRansformer (DETR) addresses this issue by establishing an end-to-end framework for object detection without the need for hand-designed components. Despite its promising results, one major drawback of DETR is its slow convergence during training, requiring 500 epochs to converge on the COCO benchmark. This slow convergence increases training cost and limits its broader applications.To mitigate this issue, we propose the Semantic-Aligned-Matching DETR (SAM-DETR) framework, which significantly accelerates the convergence of DETR. SAM-DETR interprets the cross-attention module of DETR as a "matching and distillation" process and aligns object queries with encoded image features to facilitate matching. Additionally, SAM-DETR explicitly searches for objects' salient points with discriminative features and incorporates them into the cross-attention module for semantic-aligned matching, further improving detection accuracy and convergence speed.Experiments demonstrate that SAM-DETR achieves significantly faster convergence compared to the original DETR. Furthermore, our approach can be easily integrated with existing solutions that modify the attention mechanism, leading to a comparable convergence speed with Faster R-CNN in as few as 12 epochs. This plug-and-play module nature of SAM-DETR allows for seamless integration with other convergence-enhancing techniques, expanding its potential applications.