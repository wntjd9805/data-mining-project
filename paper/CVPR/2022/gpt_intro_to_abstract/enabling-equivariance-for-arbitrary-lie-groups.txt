Symmetry plays a crucial role in machine learning, particularly in computer vision. Achieving invariance with respect to symmetries is desirable, and current approaches involve training models on symmetry-perturbed data. However, architectural approaches such as CapsNets provide an alternative for achieving invariance. Despite the lack of theoretical guarantees, CapsNets have shown promise. CNNs, on the other hand, have provable architectural invariance to translational symmetries and are widely used in computer vision. Recently, group convolutions, derived from mathematics, have demonstrated better performance than conventional convolutions in image classification tasks. However, the potential for mild out-of-distribution generalization with group-convolutional neural networks has received less attention. The lack of a sufficient general theoretical framework has hindered progress in this area. This paper introduces a rigorous mathematical framework for implementing convolutional networks over arbitrary finite-dimensional Lie groups, allowing for the implementation of group convolutions for natural warps. Additionally, tools from differential geometry and Lie theory enable efficient Monte Carlo sampling from Haar measure for arbitrary Lie groups, facilitating fast approximation of group convolutions. The authors validate the framework by testing it on affine-invariant and homography-invariant image classification tasks, outperforming existing benchmarks. This work opens up new possibilities for applying group convolutions in computer vision, reducing the reliance on data augmentation and large parameter sets. The paper acknowledges the contributions of the reviewers in improving the quality of the research.