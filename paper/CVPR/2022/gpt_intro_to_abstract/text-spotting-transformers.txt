Text spotting, the detection and recognition of text in natural scenes, is an important task in computer vision with applications in mapping, autonomous driving, and image retrieval. Despite recent progress, text spotting remains challenging due to various factors such as font variations, occlusion, and non-rectangular text boxes. Traditional methods often perform text detection and recognition separately, requiring heuristics and post-processing steps. Inspired by the success of Transformers in natural language processing and computer vision, we propose TESTR, a Transformer-based text spotting method that performs detection and recognition in a unified framework. TESTR utilizes a single-encoder dual-decoder architecture to handle curved text instances and eliminates the need for heuristics and intermediate stages. Our method achieves state-of-the-art performance on challenging datasets and introduces a box-to-polygon process for improved detection accuracy. The canonical representation of control points allows for both polygonal and Bezier curve annotations. Overall, TESTR provides a holistic and efficient solution to the text spotting problem.