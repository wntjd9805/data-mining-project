Real-world video super-resolution (VSR) aims to enhance the resolution of videos with unknown degradations, which presents challenges in designing benchmarks and training settings. Previous works have focused on synthetic or camera-specific degradations, but these simplified scenarios cannot generalize well to complex real-world degradations. In this paper, we address the problems and tradeoffs in real-world VSR and propose solutions based on our experiences.We begin by discussing the tradeoff between enhancing details and suppressing artifacts in real-world VSR. Long-term information has been shown to be beneficial but can also lead to exaggerated artifacts due to error accumulation during propagation. To address this tradeoff, we introduce an image cleaning module that removes degradations in the input images before propagation. This simple solution avoids artifact amplification, resulting in improved output quality while maintaining simplicity. We also develop a dynamic refinement scheme that repeatedly applies the cleaning module to remove excessive degradations, allowing a flexible tradeoff between smoothness and detailedness.Training real-world VSR models with diverse degradations requires larger batch sizes, which increases training time and computational resources. We examine two tradeoffs to improve training efficiency. First, we propose a stochastic degradation scheme that reduces the I/O bottleneck without sacrificing output quality, resulting in up to 40% reduction in training time compared to conventional schemes. Second, we investigate the tradeoff between batch size and sequence length, finding that networks trained with longer sequences effectively utilize long-term information, improving stability.We also introduce a new benchmark dataset, VideoLQ, for real-world VSR. Existing benchmarks do not accurately reflect the generalizability of models on real-world videos. VideoLQ consists of diverse low-resolution videos with various contents, resolutions, and degradations, serving as a common benchmark for future methods. We evaluate existing methods on VideoLQ and provide quantitative and qualitative results, as well as releasing our dataset for future research.In conclusion, this paper addresses the challenges and tradeoffs in real-world VSR and presents solutions based on our experiences. Our proposed methods effectively balance the tradeoff between enhancing details and suppressing artifacts, improve training efficiency, and introduce a new benchmark dataset for evaluating real-world VSR methods.