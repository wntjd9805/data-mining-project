In this paper, we present a novel approach for acquiring dynamic light fields, which consist of multiple viewpoints aligned on a 2D grid with tiny viewpoint intervals. Dynamic light fields are challenging to acquire due to the huge data rate associated with both the number of views and frame rate. We summarize existing approaches for light field acquisition, such as camera arrays and lens-array cameras, but these methods have limitations in terms of hardware requirements and spatial or temporal resolution. We propose a compressive approach, using a single camera equipped with a coded mask and pixel-wise exposure coding, to acquire a dynamic light field with full-sensor spatial resolution and a faster frame rate than the camera itself. We design an imaging model that embeds the original information of the dynamic light field into a single coded image. We then use a convolutional neural network (CNN) trained with the camera-side coding patterns to reconstruct the light field from the coded image. We also develop a hardware prototype to capture real 3D scenes moving over time. Through experiments, we are able to acquire a dynamic light field with 5x5 viewpoints over 4 temporal sub-frames (100 views in total) from a single coded image, achieving a finer temporal resolution than the camera itself. To the best of our knowledge, our method is the first to achieve such high temporal resolution in compressive light field acquisition. Our proposed approach has potential applications in various fields such as 3D display, view synthesis, depth estimation, synthetic refocusing, and object recognition.