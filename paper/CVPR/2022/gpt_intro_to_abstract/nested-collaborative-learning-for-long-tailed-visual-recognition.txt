Deep neural networks have achieved remarkable success in various visual tasks, such as face analysis and action recognition. However, these successes are heavily reliant on large datasets with balanced class distributions, which are not representative of real-world datasets that often exhibit long-tailed data distributions. In long-tailed visual recognition, the model's accuracy is significantly lower for tail classes compared to head classes. To address this challenge, previous works have focused on class re-balancing strategies and decoupled learning. More recent efforts have explored the use of multiple experts, where each expert specializes in a different aspect of the data. However, existing multi-expert methods lack collaboration among the experts. This paper introduces Nested Collaborative Learning (NCL) for long-tailed visual recognition. NCL consists of two components: Nested Individual Learning (NIL) and Nested Balanced Online Distillation (NBOD). NIL aims to enhance the discriminative capability of each network, while NBOD facilitates the transfer of knowledge among the experts. NCL and NBOD are performed from both a full perspective on all categories and a focused perspective on important categories. Hard Category Mining (HCM) is proposed to select the hard categories, which are defined as categories with high predicted scores that result in misclassification. The learning approaches from different perspectives are nested, related, and complementary, enabling thorough representation learning. Additionally, self-supervised learning techniques are employed to enhance feature learning. Experimental results show that NCL outperforms state-of-the-art methods on popular datasets, including CIFAR-10/100-LT, Places-LT, ImageNet-LT, and iNaturalist 2018. Overall, this paper offers a novel approach to address the challenges of long-tailed visual recognition and achieves significant performance improvements.