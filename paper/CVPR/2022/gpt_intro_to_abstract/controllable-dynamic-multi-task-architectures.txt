Multi-task learning (MTL) is a technique that solves multiple tasks using a single model, which can lead to faster inference and improved generalization. However, optimizing all tasks simultaneously can be challenging due to task conflicts and limited model capacity. This requires a trade-off between tasks and precise balancing of task losses during optimization. Existing dynamic network methods for MTL enable a single model to learn the trade-off curve and allow users to control the trade-off during inference. However, these methods assume a fixed model architecture, leading to over-sharing of parameters between tasks and a lack of flexibility in adapting to changing task preferences or compute budgets. To address these shortcomings, we propose a tree-structured dynamic multi-task network that can adapt its architecture and weights at test-time. We design a controller using hypernetworks that predicts architectures and weights based on user preferences, allowing for resource allocation and enhanced task accuracy. We develop a two-stage training scheme using an anchor net and branching regularized loss to encourage resource allocation for dominant tasks. We also introduce a secondary hypernetwork for cross-task adaptation. Our framework is evaluated on three MTL datasets and achieves comparable performance to state-of-the-art methods while providing controllability over task performance and network capacity. The contributions of our work include a controllable multi-task framework, a dynamic network controller, a joint learning objective, and experimental validation on various benchmarks.