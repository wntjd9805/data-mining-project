This paper introduces a multi-task framework that combines 3D panoptic segmentation and 3D object detection to improve the recognition and localization of 3D objects. The framework leverages semantic and instance-level information to guide the detection process. In addition, the framework can be easily integrated into existing Bird's-Eye-View (BEV) based object detection methods. The effectiveness of the proposed method is validated through experiments conducted on the nuScenes dataset. Ablation studies are also conducted to examine the contribution of each component in improving performance. This work contributes to the advancement of autonomous vehicles vision systems by enhancing the accuracy and robustness of 3D object detection.