Face anti-spoofing (FAS) is a critical technique for preventing security attacks on face recognition systems. While previous methods have focused on learning-based approaches using deep neural networks, they have been limited by small-scale and low-variation datasets, leading to overfitting and vulnerability in unseen testing scenarios. To address these limitations, some FAS works have utilized auxiliary pixel-wise supervision and generative adversarial networks (GANs) to improve generalization ability. However, the underlying cues learned by these networks remain unclear. In this paper, we propose PatchNet, a framework that learns discriminative features based on fine-grained patches of face images. By focusing on patch-level inputs and using an angular margin-based softmax loss, we aim to classify different patch types related to capturing devices and presenting materials. We also propose an asymmetric angular margin loss and a self-supervised similarity loss to optimize network training and enforce location and rotation invariance. Through extensive experiments on various benchmark datasets, we demonstrate that PatchNet achieves state-of-the-art performance in intra-dataset, cross-dataset, and domain generalization scenarios. Our contributions include a novel framework for fine-grained patch recognition, as well as new loss functions that improve the generalization and invariance of the learned features. The learned patch embedding space also enables applications such as Few-Shot reference FAS and patch type retrieval.