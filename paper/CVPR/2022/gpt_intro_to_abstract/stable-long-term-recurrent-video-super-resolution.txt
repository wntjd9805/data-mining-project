Video super-resolution (VSR) is an important problem in computer vision that aims to reconstruct a sequence of high-resolution (HR) images from their corresponding low-resolution (LR) counterparts. Unlike single-image super-resolution (SISR), VSR requires the fusion of multiple LR images to generate an HR image. Traditional VSR methods based on iterative algorithms are relatively slow and not suitable for real-world applications. Recently, deep learning (DL) methods have shown promising results in VSR by efficiently learning spatio-temporal statistics from a training dataset of natural videos. There are two main classes of deep VSR methods: sliding-window based models and recurrent models. Sliding-window based models fuse a batch of LR frames to reconstruct an HR frame, limiting the temporal receptive field to a small number of LR frames. Recurrent models, on the other hand, use hidden states and/or outputs from previous time steps to super-resolve a frame at the current time step, allowing information propagation through a larger number of frames. Recurrent VSR models are usually trained on sequences of 7 to 12 images due to computational limitations, but their performance on longer sequences is unknown. In this study, we investigate the instability issue of recurrent VSR networks on long sequences with low motion and propose a new framework, called MRVSR, to address this problem. We evaluate the stability and performance of existing recurrent VSR models and demonstrate the superior performance of the proposed network on a newly created long sequence dataset. The article is structured as follows: a review of related studies on VSR and recurrent network instabilities, the proposed stable framework for recurrent VSR, the introduction of MRVSR, an empirical analysis of existing recurrent VSR models, and the conclusion of the study with the availability of the dataset for future research.