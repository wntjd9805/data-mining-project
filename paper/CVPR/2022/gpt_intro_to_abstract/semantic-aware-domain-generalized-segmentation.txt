Semantic segmentation is a crucial task in computer vision with various applications such as robotic navigation, autonomous vehicles, and scene parsing. However, current deep learning-based segmentation methods suffer from a significant drop in performance when evaluated on unseen out-of-domain data. To address this limitation, domain adaptation techniques have been proposed, but they rely on the availability of target domain data for training, which is impractical in many real-world applications. In this paper, we focus on Domain Generalized Semantic Segmentation (DGSS), where no target domain data is available during training. Existing methods for DGSS use domain randomization or normalization and whitening techniques, but they fail to adequately handle different scenarios and enforce consistency in local feature distribution. To overcome these limitations, we propose two modules, Semantic-Aware Normalization (SAN) and Semantic-Aware Whitening (SAW), which align category-level distributions to enhance feature discriminability. Our approach combines semantic-aware center alignment and distributed alignment, significantly improving generalization to out-of-domain data without sacrificing performance on the source domain. Extensive evaluations on benchmark datasets demonstrate the superiority of our approach over previous DGSS methods and even state-of-the-art domain adaptation methods. Our contributions include effective feature alignment strategies, easily integratable semantic-aware alignment modules, and improved generalization performance compared to existing methods.