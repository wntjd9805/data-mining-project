Action recognition is a fundamental task in video understanding, and object-based action recognition has gained attention for its ability to consider object interactions. However, current object-based methods often fail to explicitly model fine-grained relationship transitions between objects. These transitions play a crucial role in distinguishing similar action categories. This paper introduces the Object-Relation Reasoning Graph (OR2G) to model the fine-grained transition of objects and relationships in a video. OR2G includes an actor-centric object-level graph (OG) for modeling object attribute transitions and a relation-level graph (RG) for modeling relationship transitions. A graph aggregating module (GAM) enhances the coupling between the two graphs. OR2G explains actions through attribute and relationship transitions, creating interpretable representations. Experimental results on a public action recognition dataset demonstrate the effectiveness of the proposed method. The paper concludes with an overview of related work and implementation details.