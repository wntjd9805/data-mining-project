Semantic segmentation is a crucial task in computer vision, and recent advancements in deep neural networks have significantly improved its performance. However, existing supervised approaches for semantic segmentation require large amounts of annotated data, which can be expensive and time-consuming to acquire. To address this issue, several semi-supervised methods have been proposed, aiming to learn a segmentation model using a limited number of labeled samples and a large set of unlabeled data. One common approach is to assign pseudo-labels to pixels in unlabeled images by leveraging predictions from a model trained on labeled data. However, relying solely on reliable predictions may result in some pixels never being learned throughout the training process. This paper presents an alternative approach called U2PL (Using Unreliable Pseudo-Labels) to make full use of the unlabeled data. U2PL identifies unreliable predictions by measuring per-pixel entropy and treats them as negative samples to categories to which they are unlikely to belong. Reliable predictions are used to derive positive pseudo-labels, while the unreliable ones are stored in a memory bank as negative samples, ensuring balanced representation across all classes. The proposed U2PL method outperforms state-of-the-art competitors on benchmark datasets such as PASCAL VOC 2012 and Cityscapes. Additionally, U2PL exhibits better performance in ambiguous regions, thanks to its effective utilization of unreliable pseudo-labels.