Video deblurring is a challenging task in computer vision, aiming to restore sharpness in blurry videos. Blurring in videos can result from various sources such as object motion, camera shake, and depth of field. Unlike image deblurring, video deblurring requires effective utilization of information from the entire sequence of frames. Existing methods either rely on window-based models or recurrent models, but they cannot effectively utilize information from all frames and neighboring frames are often used in simplistic manners. Moreover, an underexplored aspect in video deblurring is that blurring occurs from non-uniform blur kernels, leading to different blurry artifacts in different frames and regions. To address these challenges, this paper proposes a novel memory-based architecture that combines the principles of memory networks with video deblurring. The memory network stores blurry and sharp spatio-temporal patterns and computes a spatio-temporal attention between memory features and query frame regions to extract corresponding sharp information. Unlike previous works using memory networks, this paper uses memory to supplement information to the deblurring backbone, while still allowing the core deblurring branch to recover low-level details. Additionally, a bidirectional and multi-scale structure is proposed to enrich the features in the memory bank, facilitating cross-scale matching and effective handling of large motions. Experimental results demonstrate that the proposed model achieves superior results compared to state-of-the-art methods under comparable computational budgets. This work contributes to the advancement of video deblurring techniques and demonstrates the potential of memory networks in enhancing video quality.