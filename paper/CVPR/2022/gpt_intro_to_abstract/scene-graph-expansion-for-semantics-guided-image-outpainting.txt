This paper addresses the task of semantics-guided image outpainting, which involves generating complete images based on incomplete or partial inputs. Existing approaches mainly focus on extending textures or completing fractional objects, resulting in extrapolated regions with repeating patterns. In order to introduce novel semantics with reasonable relationships, the authors propose a three-stage approach using a scene graph representation. The first stage expands the scene graph using a Scene Graph Transformer (SGT) with node and edge-level attention mechanisms. The second stage transforms the expanded scene graph into a complete layout, and the final stage generates the final image output. The contributions of this work include the approach to semantics-guided image outpainting, the proposed SGT module for modeling structural information, and the exploitation of converse relationships between objects in the scene graph.