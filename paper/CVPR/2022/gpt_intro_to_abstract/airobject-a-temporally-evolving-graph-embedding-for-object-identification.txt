Abstract:Object encoding and identification play a crucial role in various robotic tasks such as autonomous exploration, semantic scene understanding, and simultaneous localization and mapping (SLAM). Existing approaches have limitations in terms of robustness to occlusion, viewpoint changes, and perceptual aliasing. To address these limitations, we propose a novel temporal encoding method called AirObject. Our method utilizes deep learned keypoint features to construct sequences of object-wise topological graph neural networks (GNNs), which generate temporal 3D object descriptors. We employ a graph attention-based sparse encoding method to capture the structural information of objects. These graph features are then aggregated across multiple frames using a single-layer temporal convolutional network, resulting in robust object descriptors that are invariant to various transformations. Our contributions include constructing topological object graphs using Delaunay triangulation, introducing a simple yet effective temporal object encoding method, and achieving state-of-the-art performance in video object identification on four large-scale datasets. Experimental results demonstrate the superiority of AirObject in terms of accuracy and robustness.