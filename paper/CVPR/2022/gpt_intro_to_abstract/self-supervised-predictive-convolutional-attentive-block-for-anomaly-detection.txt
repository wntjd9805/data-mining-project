Anomaly detection is a crucial task with various applications, such as industrial inspection and public security. Existing methods typically frame anomaly detection as a one-class classification problem, where familiarity models are learned from normal training samples and unfamiliar examples are labeled as anomalies at inference time. However, supervised learning methods cannot be directly applied to anomaly detection since abnormal samples are only available during testing. To address this challenge, alternative approaches such as reconstruction-based methods, dictionary learning methods, distance-based models, change detection frameworks, and probabilistic models have been explored.In this paper, we propose a novel approach that integrates the capability of reconstructing masked information into a neural block. Unlike existing methods that mask the input and use deep neural networks for prediction, our approach allows masking information at any layer in a neural network and can be applied to a wide range of neural architectures. Specifically, we design a self-supervised predictive block consisting of a dilated convolutional layer and a channel attention mechanism. The dilated filters are based on a custom receptive field, where the center area of the kernel is masked. The resulting convolutional activation maps are then passed through a channel attention module to ensure the block learns to reconstruct the masked region based on contextual information.Our self-supervised predictive convolutional attentive block (SSPCAB) can be integrated into state-of-the-art anomaly detection frameworks. We evaluate our approach on the MVTec AD, Avenue, and ShanghaiTech datasets and show significant performance improvements compared to baseline methods. For example, with the addition of SSPCAB, the region-based detection criterion (RBDC) on Avenue increases from 41% to 62%. We also report new state-of-the-art performance levels on Avenue and ShanghaiTech. Furthermore, we demonstrate that the masked convolutional layer alone can improve performance levels on the Avenue dataset.In summary, our contributions are twofold: (1) introducing a novel self-supervised predictive convolutional attentive block for anomaly detection and (2) integrating the block into state-of-the-art neural models, leading to significant performance improvements across multiple models and benchmarks.