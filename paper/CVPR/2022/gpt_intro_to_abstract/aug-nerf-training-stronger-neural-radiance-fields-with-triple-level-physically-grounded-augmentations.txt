Neural radiance fields (NeRF) and its variants have made significant advancements in representing 3D objects and scenes for photo-realistic novel view synthesis. However, NeRF suffers from inconsistent and non-smooth geometries due to the vanilla MLP lacking geometry-awareness. To address this limitation, we propose Augmented NeRF (Aug-NeRF), a training framework that injects worst-case perturbations to implicitly regularize the NeRF pipeline with physical foundations. Aug-NeRF considers three levels of regularization: input coordinates, intermediate features, and pre-rendering output. Our experiments demonstrate that Aug-NeRF achieves smoother and more consistent reconstructed geometry and improved unseen view synthesis compared to NeRF. Additionally, Aug-NeRF shows resilience towards severely corrupted supervision images. The contributions of this paper include revealing the non-smooth geometries in NeRF, proposing Aug-NeRF as a solution, and validating its effectiveness through extensive experiments.