This paper introduces a method to enhance the performance of formula-driven supervised learning (FDSL) in the context of pre-training Vision Transformers (ViTs) for image recognition tasks. The traditional approach of supervised learning (SL) and the emerging self-supervised learning (SSL) methods have limitations related to the dataset labeling, privacy concerns, and ethical biases. To overcome these issues, FDSL utilizes synthetic images generated by mathematical formulas instead of real images. The authors investigate the factors that influence the generation of synthetic images and propose guidelines to improve FDSL methods. They also test two hypotheses related to object contours and the number of parameters in FDSL pre-training. The results show that FDSL pre-trained ViTs achieve comparable or higher accuracy compared to models pre-trained on real-image datasets like ImageNet-21k. The paper provides insights into the impact of fractal images and the complexity of mathematically generated images on FDSL performance. The findings suggest that FDSL with ViTs can be a viable alternative to SL and SSL for image recognition tasks, addressing ethical concerns associated with real-image datasets.