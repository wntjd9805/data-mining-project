Image quality assessment aims to develop computational models that can predict image quality consistent with human perception. While significant progress has been made in developing full reference image quality assessment metrics, such as peak signal-to-noise ratio and structural similarity index, there is a need to reduce the reliance on extensive human judgments for training. In this paper, we propose a joint semi-supervised and positive-unlabeled learning method for image quality assessment. This method leverages both labeled and unlabeled data to train deep image quality assessment models, while also mitigating the adverse effects of outliers in the unlabeled data. We also introduce a novel image quality assessment network that emphasizes informative regions and handles misalignment between distorted and pristine images. Experimental results on benchmark datasets demonstrate the effectiveness of our method compared to existing approaches. Our contributions include the development of the joint semi-supervised and positive-unlabeled learning method and the incorporation of spatial attention and local sliced Wasserstein distance in the image quality assessment network.