Person Re-identification (ReID) is a task that involves matching individuals with the same identification (ID) across different camera views. Deep convolutional neural networks (CNNs) have significantly improved the performance of supervised ReID and unsupervised domain adaptation (UDA). However, both methods require target domain data for training, which is not available in real-world applications where the ReID system must search for individuals in unseen domains. This has led to a research focus on domain generalization (DG) ReID, where only labeled source datasets are used for training. Existing DG methods typically aim to learn domain invariant features through multiple source domains, but they do not explore distribution alignment between source and target domains.In this paper, we propose a novel Meta Distribution Alignment (MDA) method for DG ReID, which aligns the distributions of features across source and target domains. We use a known prior distribution as the aligned goal and encode the high-dimensional ID features into a low-dimensional latent space that is constrained to the prior distribution. By decoding the latent embeddings, we can align the distributions of source and target domains to the same prior distribution during training and testing. We use Wasserstein distance to measure the distance between distributions, as it satisfies the triangle inequality.To further enhance model generalization on unseen domains, we introduce a meta-learning strategy that simulates the train-test process. We dynamically divide the source domain into a meta-train and meta-test domain in each batch, where the meta-train process trains the source domain and the meta-test simulates testing on an unseen domain. We perform inner updates on the meta-train domain to improve generalization, and second-order updates on the original parameters during the meta-test stage. These processes are performed alternately to improve the model's ability to generalize to various unseen domains. During testing, we use a test-train strategy at the batch level to pull in latent embedding distributions across source and target domains.Our contributions include the proposal of MDA, a pioneering method for aligning distributions across source and target domains in DG ReID. We also design a meta-learning strategy to simulate the real train-test process and improve model generalization. Furthermore, we introduce a test-time adaptive updating strategy to efficiently adapt the model to unseen domains with limited samples. Our extensive experiments demonstrate state-of-the-art performance on large-scale DG ReID and single-source DG ReID datasets.