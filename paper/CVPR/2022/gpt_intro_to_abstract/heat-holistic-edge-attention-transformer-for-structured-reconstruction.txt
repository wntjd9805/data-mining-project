This paper introduces a novel approach for structured reconstruction in computer vision, with a focus on inferring outdoor building architecture or indoor floorplans from raster sensor data. While deep neural networks have shown success in low-level primitive detection tasks, such as corners and edges, holistic structure reasoning remains a challenge. The authors propose a Transformer-based architecture that effectively learns structural regularities by creating nodes for edge candidates and utilizing positional encoding and deformable attention mechanisms to fuse image features. Two weight-sharing Transformer decoders are used to learn structural patterns of edges, and a masked learning strategy enables end-to-end training and iterative inference. The proposed approach is evaluated on outdoor building reconstruction and indoor floorplan reconstruction benchmarks, demonstrating superior performance compared to competing methods. For the indoor reconstruction task, the approach is on par with domain specific solutions while being significantly faster. Overall, this work pushes the frontier of end-to-end neural architecture for structured reconstruction and has broad applications in visual effects, construction, manufacturing, and robotics.