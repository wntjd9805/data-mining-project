Local visual descriptors are widely used in computer vision applications such as SLAM, SfM, tracking, and image retrieval. These descriptors represent local regions of images and are typically high-dimensional vectors. However, recent advances in deep learning have made it possible to reconstruct input images from these descriptors, raising privacy concerns for sensitive data. To address this, several methods have been proposed to obfuscate the descriptors. In this paper, we explore the idea of mitigating privacy concerns at the descriptor level by training a content-concealing visual descriptor using an adversarial approach. We optimize the descriptor encoding network with an adversarial loss that competes with an image reconstruction network to conceal the image content while maintaining feature correspondence matching. We introduce an auxiliary encoder network called NinjaNet that can transform existing descriptors into content-concealing descriptors. Experimental results show that our approach significantly reduces reconstruction similarity without a significant drop in matching accuracy. We demonstrate the generalizability of our method by using different descriptors, reconstruction network architectures, and scene categories. Our innovations include a novel adversarial learning framework for visual descriptors, effective control of the trade-off between utility and privacy, and empirical validation through benchmark datasets.