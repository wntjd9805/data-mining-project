Generative adversarial networks (GANs) have demonstrated impressive image synthesis quality and a semantic understanding of modeled images. Previous GANs, such as StyleGAN, have been successfully applied in various applications, such as image editing, style transfer, and image-to-image translation. However, these GAN models are typically trained on images from individual domains, limiting their ability to generate aligned samples from related domains.In this paper, we propose Polymorphic-GAN (PMGAN), a novel approach that enables training a generative model with a shared backbone to produce aligned samples from multiple related domains. By aligning images across domains in terms of attributes and conditions like pose and lighting, PMGAN offers computational advantages and enables a wide range of applications. Additionally, editing one domain automatically produces corresponding edits in other domains.The main challenge in synthesizing outputs from different domains lies in the geometric variations among semantically aligned domains, such as human faces, animal faces, or face paintings. Existing approaches, like fine-tuning pre-trained GANs, fail to generate samples from the parent domain or multiple domains simultaneously. Although transfer and multi-task learning have explored shared representations between domains, little progress has been made in generative models.To overcome these challenges, PMGAN leverages a shared generator network combined with novel morph maps to adapt the synthesis network's feature maps according to the geometries of different domains. The morph maps, predicted by a MorphNet, apply geometric deformations to the generator's features to ensure both stylistic and geometric alignment across multiple domains. This allows PMGAN to retain the impressive semantic properties of StyleGAN's latent space while accurately reflecting geometric differences.We extensively analyze and validate PMGAN through various tasks, including expressive image editing, image-to-image translation, zero-shot semantic segmentation transfer, and learning from domains with limited training data. Our experimental results demonstrate the effectiveness of PMGAN and its superiority over previous methods in addressing the challenges posed by geometric variations among aligned domains.In summary, PMGAN is the first generative model that enables the synthesis of aligned samples from multiple semantically-related domains simultaneously. This capability opens up new opportunities for novel and promising applications in computer vision and image synthesis.