This paper addresses the problem of video demoiréing, which refers to the removal of moiré patterns that occur when photographing a video on a screen. While significant progress has been made in removing moiré patterns in single images, video demoiréing remains a relatively unexplored research problem. This paper proposes a video demoiréing model that leverages multiple video frames and introduces a novel relation-based consistency loss to improve temporal consistency without sacrificing frame-level quality. The model is built upon a baseline model that effectively utilizes nearby frames for demoiréing. Deep supervision and a selective aggregation scheme are employed to optimize the model. Additionally, a new video demoiréing dataset is introduced to facilitate further research in learning-based approaches. Experimental results demonstrate the superior performance of the proposed method compared to existing approaches in terms of visual quality and fidelity. The method achieves significant improvements in LIPIS (levels of image pixel intensity similarity) and is preferred by a majority of users in a user study.