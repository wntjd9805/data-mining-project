Single image super-resolution (SISR) is a challenging problem in computer vision, which aims to recover high-resolution details from low-resolution images. The degradation model, which describes the process of generating a low-resolution image from a high-resolution one, is often unknown and complicated, making blind SISR even more difficult. Previous methods have addressed this problem by either treating SISR as an interpolation task or by considering image degradation. These methods can be further categorized as model-based or learning-based approaches.Model-based methods build a generative model based on the image degradation and then estimate the blur kernel and the high-resolution image using a maximum a posteriori (MAP) framework. These methods tend to achieve better generalization for unknown degradations. Learning-based methods, on the other hand, aim to learn a unified super-resolver based on a large amount of low-resolution and high-resolution image pairs. Some recent works attempt to improve generalization by learning the degradation model from real image data. However, these methods heavily rely on collected training data, which can lead to performance drop when faced with unseen degradations in testing.This paper proposes a model-based approach for blind SISR and introduces a probabilistic method that considers noise and kernel modeling. A patch-based non-i.i.d. Gaussian noise assumption is employed to better model real noise, allowing for more accurate noise handling. Additionally, an explicit kernel prior (EKP) is constructed for the anisotropic Gaussian kernel commonly used in SISR, which can be easily integrated into deep learning-based blind SISR methods. The contributions of this work include the use of a patch-based non-i.i.d. noise distribution, the development of the EKP for more stable kernel estimation, and the design of a Monte Carlo EM algorithm to solve the proposed model.