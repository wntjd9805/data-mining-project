Deep learning has achieved remarkable success in computer vision tasks, but large-scale labeled data is not always readily available. This has led to a research effort in designing models that can learn to solve tasks using a limited number of labeled examples. Few-shot learning aims to classify unlabeled query samples using limited labeled support examples. Recent approaches leverage meta-learning to improve generalization. However, current methods still face challenges in learning to generalize with a limited number of labeled samples. In this paper, we propose an end-to-end meta-learning strategy that uses self-attention to co-attend to both support and query features. We introduce a single shared attention module that computes attention scores per task and re-weights the initial features based on these scores. We show that this approach improves embedding adaptation and achieves competitive results on benchmark datasets. Our contributions include the cross-attention of support and query embeddings, the implicit re-weighting of features with prototypes, and the minimal overhead in learnable parameters. Extensive evaluation confirms the effectiveness of our method.