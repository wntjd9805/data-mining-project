Saliency detection is an important task in computer vision, with previous works focusing on tasks such as salient object detection and gaze prediction. However, a new task called saliency ranking has been proposed, which aims to detect salient instances and infer their ranks simultaneously. This task is beneficial for various visual tasks, including image manipulation, scene understanding, and person identification. Previous methods for saliency ranking have been limited in their ability to accurately predict object-level saliency ranks, often favoring objects with strong semantics such as people. In this paper, we propose a novel approach to saliency ranking that combines spatial attention and object-based attention, inspired by how humans change their attention across scenes. We introduce a Selective Object Saliency (SOS) module to model object-based attention by inferring and enriching the semantic representations of salient objects based on their local contexts. We also propose an Object-Context-Object Relation (OCOR) module to capture the spatial attention mechanism by reasoning in a bi-directional object-context and context-object manner. We use a multi-head attention mechanism to model interactions between objects and their respective contexts.Our approach outperforms state-of-the-art methods in producing more accurate saliency ranks. For example, our method can accurately detect and rank objects with visual distinctiveness, such as a green screen or a horse. Our method can also detect and rank objects based on their interactions with other objects, as shown in our results with a skateboard and a person.In summary, our work makes three main contributions: 1) we propose a novel approach that combines spatial and object-based attention for saliency ranking, inspired by psychological studies; 2) we introduce a Selective Object Saliency (SOS) module and an Object-Context-Object Relation (OCOR) module to model object-based and spatial attention, respectively; 3) we demonstrate the superior performance of our approach through extensive experiments compared to state-of-the-art methods.