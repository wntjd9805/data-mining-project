Scene flow, a 3D motion field, is widely used in various applications such as robotics and autonomous driving for dynamic scene understanding. However, collecting scene flow data is challenging, leading to a scarcity of real-world training samples for supervised learning. To address this issue, self-supervised scene flow learning has been proposed as a promising solution. In this work, we focus on approximating scene flow labels given unlabeled point cloud data to enable deep network training under the self-supervised setting. Previous approaches have used point matching between consecutive point clouds to establish point correspondences and estimated the 3D coordinate difference as the pseudo scene flow label. However, these approaches often fail to capture structured motions of points, resulting in inconsistent labels. To overcome this limitation, we propose a method called RigidFlow that generates pseudo scene flows using piecewise rigid motion estimations. Our method decomposes the point cloud into super-voxels and treats these regions as rigid during pseudo label generation. By independently estimating the rigid transformation for each super-voxel, we obtain rigid alignments and generate locally rigid pseudo scene flow labels. Our approach achieves state-of-the-art performance in self-supervised scene flow learning, outperforming even some supervised methods.