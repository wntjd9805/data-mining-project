In this paper, we present an approach to reconstruct physically plausible articulated 3D human motion from monocular video. We aim to improve upon existing methods that achieve accurate 3D pose estimation results but often produce visually unnatural reconstructions. Our approach incorporates the laws of physics into the pose estimation process, allowing us to impose desirable properties on the estimated motion such as temporal consistency and balance in the presence of gravity. One of the key challenges in using physics for pose estimation is adequately modeling the diverse physical phenomena that arise from interactions between people and the scene. Previous literature commonly simplifies the physics model to enable efficient inference, but we propose a more sophisticated approach that generates technical insights. We demonstrate excellent alignment of estimated physical motion with 2D input images by automatically adapting the 3D model to the person in the image and employing appropriate 2D alignment losses. This sets our work apart from related research that often neglects reporting 2D alignment error and may not achieve good alignment of the physical model with the image. Additionally, we contribute to the understanding of residual root force control, a mechanism hypothesized to bridge the simulation-to-reality gap and compensate for inaccuracies in the physical model. Through experimentation, we show that physically unrealistic residual force control may not be necessary, even for complex and dynamic motions. Overall, our approach offers a promising solution for reconstructing physically plausible articulated 3D human motion from monocular video, with potential applications in various domains such as animation, motion capture, and virtual reality.