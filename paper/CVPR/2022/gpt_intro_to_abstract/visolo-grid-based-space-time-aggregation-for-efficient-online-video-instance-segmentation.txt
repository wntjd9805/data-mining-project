This paper introduces a novel framework called VISOLO for online video instance segmentation (VIS). VIS is a technique that locates and classifies objects in a video by generating spatio-temporal pixel masks for each object. Existing offline methods for VIS are effective but not suitable for real-time applications as they require processing the entire video before making predictions. In this paper, the authors address the challenges of online VIS, where video frames are processed sequentially. They propose a framework that utilizes information from previous frames for tracking, classification, and segmentation in order to improve overall VIS performance. The framework is built upon the grid-structured representation of the single-stage image instance segmentation method SOLO, which allows for real-time processing. The authors also introduce modules for memory matching, temporal aggregation, and score reweighting to enhance the classification and segmentation performance by leveraging the features from previous frames. Experimental results on the YouTube-VIS 2019 and 2021 datasets show that VISOLO achieves state-of-the-art accuracy and runs in real-time.