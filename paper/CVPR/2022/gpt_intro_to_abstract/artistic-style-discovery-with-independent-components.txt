The target of artistic style transfer is to transform the style of one image into another while preserving its content. This field has experienced rapid development in both academia and industry, with convolutional neural networks (CNNs) being frequently utilized, particularly VGG-net. However, generating satisfying and convincing artworks remains a challenge.Recent works in neural style transfer (NST) aim to generate high-quality stylized images through iterative optimization or feed-forward networks. While these methods have achieved impressive results, they often neglect the significance of the latent space in the stylization process. Existing methods focus on style extraction and content reconstruction, overlooking the rich latent information contained in the image space. This results in limited style controllability and diversity.To address this issue, we propose a generally applicable approach called ArtIns (Artistic Ingredients/Components Separation). Our method discovers a large number of artistic styles through mathematical computation, independent of any form of training. By examining the relationship between latent style features and image variation, we find that versatile styles can be divided into multiple independent style components. By isolating these components, our method enables the production of diverse artistic stylizations.We validate the effectiveness and flexibility of our algorithm through extensive experiments using popular pre-trained style transfer models. The main contributions of our work are: (1) the introduction of a novel unsupervised algorithm for discovering various styles, enhancing controllability in stylization; (2) the identification of independent style components, leading to multiple artistic stylizations and reduced computational costs; (3) the general applicability of our method without the need for training, demonstrated through experiments on state-of-the-art style transfer models.