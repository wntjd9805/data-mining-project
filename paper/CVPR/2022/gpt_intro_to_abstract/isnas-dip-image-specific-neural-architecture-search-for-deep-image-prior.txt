Convolutional neural networks (CNNs) have become widely used in computer vision, particularly in image restoration tasks. These tasks involve recovering the original image from a corrupted version. While CNNs have been successful in supervised settings with access to ground truth labels, there is a need for unsupervised approaches when ground truth labels are unavailable. Recent research has shown that the architecture of CNNs has inherent knowledge that can be used in image restoration tasks. One such approach is the Deep Image Prior (DIP) framework, which works solely with the degraded image and does not require a supervised training phase. The success of DIP has been attributed to the spectral bias of neural networks towards low frequencies. However, the architectural design of the network greatly impacts its performance in the DIP framework. Previous works have attempted to automate the search process for network architecture using Neural Architecture Search (NAS). However, current NAS approaches are computationally expensive and can only determine the optimum architecture for a dataset of images, rather than on an image-by-image basis. In this paper, the authors propose novel image-dependent metrics to determine optimal network architectures in the DIP framework with minimal training. These metrics measure the similarity between the power spectral density of the generated initial output and that of the corrupted image. The authors demonstrate the necessity of finding image-specific architectures and present selection procedures for identifying optimal architectures in an unsupervised fashion. Their experiments on various image restoration tasks validate the effectiveness of their approach, outperforming existing state-of-the-art methods. The contributions of this work include empirical evidence for image-specific models in DIP, novel metrics for NAS in DIP, selection procedures for optimal architectures, a NAS Dataset for DIP with 522 optimized models, and extensive experimental validation.