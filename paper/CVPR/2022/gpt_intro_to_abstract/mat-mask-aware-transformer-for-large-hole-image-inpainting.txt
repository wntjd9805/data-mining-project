Image completion, also known as inpainting, is a key problem in computer vision with numerous applications in various fields. The objective is to fill missing portions of an image with plausible content. Previous works have focused on modeling contextual information, particularly for large masks that cover significant portions of the image. However, fully convolutional neural networks (CNNs) struggle to capture semantic correspondences between distant areas in images with complex structures. To address this limitation, recent approaches have proposed the use of attention modules in CNN-based generators. However, these modules have been restricted to small-scale feature maps due to computational complexity, limiting their effectiveness in modeling long-range dependencies.In contrast, transformer architectures, which are built on attention mechanisms, naturally handle non-local modeling. Some recent studies have applied transformer structures to inpainting problems, but primarily for inferring low-resolution predictions, resulting in coarse image structures for large masks. In this paper, we introduce a new inpainting transformer that generates high-resolution completed results for large mask inpainting. We customize the vanilla Transformer block by removing layer normalization and utilizing fusion learning with feature concatenation to improve optimization stability and performance. To address heavy interactions between tokens in the high-resolution input, we propose a new variant of multi-head self-attention called multi-head contextual attention (MCA). This attention mechanism computes non-local relations using partial valid tokens, determined by a dynamic mask initialized by the input mask and updated with spatial constraints and long-range interactions. We also incorporate a style manipulation module that enables pluralistic generation.Our proposed framework, named MAT, is the first transformer-based inpainting system capable of directly processing high-resolution images. We extensively evaluate MAT on benchmark datasets and demonstrate its superiority over existing approaches, achieving state-of-the-art performance on datasets such as Places and CelebA-HQ. Furthermore, our framework enables the generation of diverse inpainting results. Overall, our contributions include the development of MAT, the meticulous design of its components including MCA and the modified transformer block, and the achievement of new performance benchmarks in inpainting.