Part-based object representations play a crucial role in various computer vision tasks such as object recognition, pose estimation, action detection, and scene understanding. While current approaches often use sparse keypoints to represent objects, part segmentations provide a more detailed and comprehensive description. However, part segmentation requires significant annotation effort and existing datasets have limitations in terms of size and diversity. To address this, we propose to learn part segmentation for general objects through unsupervised domain adaptation (UDA) using synthetic data. We introduce a new dataset called UDA-Part, consisting of 21 3D CAD models from 5 vehicle categories, with fine-grained part annotations. We render a large-scale synthetic image dataset with automatically generated part segmentation ground-truth based on these CAD models. Additionally, we label parts on 200 real images to evaluate model performance on real data. To enhance UDA for part segmentation, we propose a new algorithm called Geometric-Matching Guided domain adaptation (GMG). GMG leverages cross-domain geometric matching to preserve spatial relations between parts and transfers synthetic labels to real images. In our experiments, GMG outperforms other UDA baselines on both UDA-Part test images and the PascalPart dataset. Our contributions include proposing UDA for part segmentation, introducing the UDA-Part dataset as a benchmark, and developing the GMG algorithm for superior adaptation results.