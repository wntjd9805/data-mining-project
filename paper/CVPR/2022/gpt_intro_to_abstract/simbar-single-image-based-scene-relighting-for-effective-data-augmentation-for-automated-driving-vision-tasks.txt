The lack of diversity in lighting conditions is a known issue in manually collected real-world autonomous driving datasets. Existing datasets have limited variations in lighting and shadows, which hinders the successful deployment of perception models for automated driving applications. Previous methods for scene relighting rely on multiple camera views or generative adversarial networks (GANs), which have limitations in training difficulty, controllability, and physical consistency. This paper presents a novel Single IMage-BAsed scene Relighting pipeline (SIMBAR) that can relight a single input image for a wide variety of sun positions and sky zeniths. SIMBAR achieves realistic and geometrically consistent relit images, even with limited views. To evaluate the effectiveness of scene relighting, experiments are conducted using a state-of-the-art object detection and tracking network, CenterTrack. The results show that CenterTrack models augmented with SIMBAR relit images outperform the baseline models, achieving significant improvements in tracking and detection accuracy. The contributions of this paper include the development of SIMBAR for single-image relighting, single image-based geometry estimation, an improved version of MVR for realistic relit images in road driving scenes, qualitative evaluation and comparison of scene relighting methods, and quantitative evaluation of the effectiveness of augmenting the KITTI dataset using SIMBAR.