Semantic segmentation and instance segmentation are two important vision tasks in computer science. Recently, there has been a trend towards unifying these tasks into a single task called panoptic segmentation. Panoptic segmentation divides image contents into two categories: things, which are countable instances with unique IDs, and stuff, which are uncountable regions without instance IDs. Previous works have attempted to use transformer-based models for panoptic segmentation, such as DETR, but these approaches have limitations such as lengthy training processes and limited feature resolution. In this paper, we propose Panoptic SegFormer, a framework for panoptic segmentation that overcomes these limitations. Our approach includes a deeply-supervised mask decoder, a query decoupling strategy, and an improved post-processing method. We conduct experiments on the COCO dataset and show that our method outperforms previous approaches in terms of both accuracy and parameter efficiency. Additionally, our approach achieves competitive performance on the instance segmentation task.