Image-based rendering (IBR) is a widely used approach for synthesizing novel views from real views in various applications such as virtual navigation, video stabilization, and augmented reality/virtual reality. The quality of the synthesized view depends on the accuracy and completeness of the scene geometry information and the effectiveness of blending methods. Existing IBR methods rely on dense input views to reconstruct dense proxy geometry, which is time-consuming and not easily available in practical scenarios with sparse input views. In this paper, we propose SIBRNet, a two-stage model for robust IBR on sparse scene geometry. The first stage, called geometry recovery (GR), utilizes a learning-based depth completion network to predict a complete depth map from a sparse one. The second stage, called light blending (LB), aggregates different source views using the complete depth maps to synthesize a novel view. Our method can achieve better or comparable results to existing IBR methods even with sparse geometry input. We also introduce a bias-corrected module (BCM) to rectify projection biases caused by inaccurate depth values during the warping process. Additionally, we propose a new dataset called Surround for evaluating IBR methods in a surround setting. Our experiments on three datasets demonstrate the robustness of our method on different depth sparsity levels and its ability to generate realistic results, particularly in areas with missing depth information. The code and dataset for our method will be made publicly available. In summary, the contributions of this paper include the introduction of SIBRNet for robust IBR on sparse scene geometry, the development of a bias-corrected module, and the creation of the Surround dataset for evaluating IBR methods in a surround setting.