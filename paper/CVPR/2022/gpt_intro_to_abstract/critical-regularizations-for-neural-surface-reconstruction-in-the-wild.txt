Reconstructing surfaces from multiple calibrated views is a crucial task in 3D computer vision. Traditionally, this involves estimating a point cloud from images using multi-view stereo (MVS) and then extracting a triangular mesh from the point cloud. However, recent advancements in neural implicit surface reconstruction have shown promising results, particularly for texture-less and non-Lambertian surfaces. These methods utilize multi-layer perceptrons (MLP) to map space coordinates to different geometry properties such as density, occupancy, or signed distance to the nearest surface point. MLPs can be fit into explicit geometry representations or optimized with scene appearance through differentiable rendering. Nevertheless, surface reconstruction in real-world scenarios remains challenging due to textureless or non-Lambertian surfaces and unstructured camera trajectories. Traditional mesh reconstruction pipelines using MVS suffer from missing or noisy geometries in the reconstructed point cloud. Neural surface methods, while capable of generating surfaces directly from multi-view images, are time-consuming and designed for object-centric captures. In this paper, we present RegSDF, a neural framework for surface reconstruction from multi-view images in a wide range of scenes. We use a signed distance field (SDF) as the geometry representation and a surface light field as the appearance model for generating rendered images for network training. To leverage MVS pipelines, we incorporate an oriented point cloud as input, with the SDF fitted to observed data points and normal directions. We propose two critical regularizations: the Hessian regularization to achieve smooth diffusion of the signed distance value throughout the field and the minimal surface constraint for compact interpolation of holes and extrapolation of missing parts. Experimental results on various datasets demonstrate that these regularizations, coupled with point cloud supervision, produce high-quality and robust reconstruction results. Our method outperforms other neural implicit surface reconstruction systems in terms of surface accuracy, generalization ability to complex scenes, and training time. Additionally, compared to traditional meshing methods, our framework is more robust against point cloud noise and can generate realistic rendered images.