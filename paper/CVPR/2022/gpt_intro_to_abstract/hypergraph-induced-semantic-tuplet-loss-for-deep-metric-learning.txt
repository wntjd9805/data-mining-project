Abstract:Deep metric learning algorithms aim to train deep embedding networks that can generate discriminative features for visual tasks such as image retrieval, face recognition, person re-identification, and few-shot learning. Traditionally, pair-based loss functions have been used, but they often suffer from convergence issues and require complex sample mining. Proxy-based and classification-based losses offer faster convergence but cannot leverage relationships between data samples. To address these limitations, recent approaches have proposed graph-based losses that utilize graph modeling to capture relationships between samples. However, these graph-based losses have inherent limitations and do not consider class semantic relations. In this paper, we propose a novel loss function called Hypergraph-Induced Semantic Tuplet (HIST) loss, which leverages multilateral semantic relations between every sample and every class using hypergraph modeling. We introduce semantic tuplets represented by a learnable semantic relation matrix, and adopt a hypergraph neural network (HGNN) to model these relations. The HIST loss outperforms state-of-the-art methods on three benchmark datasets for deep metric learningâ€”CUB-200-2011, CARS-196, and Stanford Online Products. Our experiments demonstrate the effectiveness of the proposed approach in attending to meaningful object regions, improving generalization performance, and enhancing model robustness against input corruptions.