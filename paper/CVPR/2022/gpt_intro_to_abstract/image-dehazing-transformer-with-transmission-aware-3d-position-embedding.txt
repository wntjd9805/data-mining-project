Single image dehazing is a challenging problem in computer vision, aiming to restore clear and haze-free images from hazy counterparts with reduced contrast and dull colors. Previous methods have relied on priors or convolutional neural networks (CNNs) to estimate haze parameters or learn haze-free representations. However, these approaches are limited by the local nature of convolutions and the lack of global context and spatially variant operations. To address these limitations, this paper proposes the integration of Transformer, a powerful global modeling technique, with CNNs for image dehazing. The proposed method combines the global modeling capability of Transformer with the local representation capability of CNNs. Specifically, a transmission-aware 3D position embedding module is introduced to provide relative position and haze density information to improve dehazing performance. Additionally, a feature modulation module is proposed to integrate the features from Transformer and CNNs, solving the feature inconsistency issue. The modulated features are then passed to a CNN decoder module to enhance image resolution and capture local details. Experimental results on benchmark datasets demonstrate the superiority of the proposed method over state-of-the-art dehazing methods. This work not only introduces the power of Transformer in image dehazing but also provides insights into integrating prior information and optimizing feature modulations in Transformer-based image reconstruction.