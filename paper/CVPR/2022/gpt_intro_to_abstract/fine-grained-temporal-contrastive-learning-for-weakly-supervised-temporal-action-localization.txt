In the field of computer vision, action localization is a crucial task that involves identifying the start and end timestamps of different actions in a video. While significant progress has been made in this area using fully supervised approaches, the collection and annotation of precise frame-level data can be a challenge. To address this, weakly-supervised action localization (WSAL) techniques have been explored, where only video-level category labels are available.Current approaches in WSAL predominantly employ a localization-by-classification paradigm. This approach involves dividing the input video into fixed-size non-overlapping snippets and generating temporal Class Activation Sequences (CAS) by optimizing a video-level classification loss. Multiple instance learning (MIL) formulations and attention mechanisms are often used to train models that assign snippets with different class activations. The resulting action localization results are obtained by thresholding and merging these activations.Existing WSAL methods have introduced various strategies to improve the accuracy of learned CAS, such as uncertainty modeling, collaborative learning, action unit memory, and causal analysis. These strategies have demonstrated promising performance in enhancing the localization capabilities of WSAL models.Despite the progress made, current learning pipelines for WSAL still face challenges in localization ambiguity and distinguishing between different action instances and action-background distinctions. Addressing these challenges and further improving the accuracy and scalability of WSAL frameworks in real-world scenarios remains an open area of research.