This paper introduces a novel contrastive learning framework called Hierarchical Contrastive Selective Coding (HCSC) to address the limitations of existing contrastive methods in representing hierarchical semantic structures in large-scale image datasets. HCSC utilizes hierarchical prototypes to capture the hierarchical semantic structures underlying the data and dynamically updates them during training. It improves instance-wise and prototypical contrastive learning by selecting high-quality positive and negative pairs that are semantically correct. The proposed HCSC approach consistently outperforms state-of-the-art contrastive learning algorithms on various downstream tasks and is validated through extensive ablation and visualization analysis.