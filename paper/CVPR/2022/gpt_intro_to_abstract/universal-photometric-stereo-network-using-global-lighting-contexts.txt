Photometric stereo is a problem in computer vision that involves recovering the surface normal map of an object from its appearances under varying lighting conditions. Traditional techniques for photometric stereo rely on physics-based modeling, but recent advances in deep learning have allowed for methods that can handle complex optical phenomena. However, existing photometric stereo algorithms are limited to specific lighting models, which greatly restricts their usability. In this paper, we propose a new task called universal photometric stereo (UniPS), which aims to address this limitation by allowing for arbitrary lighting conditions without prior assumptions about the lighting model. We present a method for UniPS that extract global lighting contexts from individual images, allowing for the recovery of surface normals without the need for explicit lighting parameter estimation. We also create a dataset for training and evaluation by rendering objects with a variety of shapes, materials, and lighting conditions. Our method is evaluated qualitatively and demonstrates its efficacy in handling challenging lighting conditions.