Object detection has made significant advancements thanks to deep neural networks. However, the challenges of realistic applications such as autonomous driving and mobile robots remain, as these scenarios often involve large data variations caused by weather conditions, illumination, and object appearance. Cross-domain object detection, in particular, faces two major difficulties: domain shift and label deficiency. Current approaches that address these challenges are limited in their effectiveness. Domain adaptation methods reduce domain shift but have limited discrimination ability. Self-training methods generate pseudo object supervision but struggle with complex domain shifts. To address these limitations, we propose a novel Target-perceived Dual-branch Distillation (TDD) framework for cross-domain object detection. The framework consists of a source-adaptive branch and a target-like branch, both designed to be target-oriented for reducing domain shift. The source-adaptive branch incorporates a Target Proposal Perceiver module, which uses iterative cross-attention to discover target-domain contexts for each proposal. This enhances the source branch's ability to perceive objects in the target domain. The target-like branch transfers source images into target-like images and learns discriminative object knowledge for the target domain. Network training is achieved through a Dual Branch Self Distillation strategy, which generates pseudo annotations from both branches. This process progressively integrates complementary object knowledge from different domains to improve cross-domain object detection.Our proposed TDD framework offers several contributions. First, it addresses domain shift and label deficiency simultaneously in a teacher-student learning manner. Second, the Target Proposal Perceiver module enables adaptive guidance for perceiving target domain objects. Finally, extensive experiments on popular benchmarks demonstrate that TDD outperforms state-of-the-art methods by a significant margin.