This paper introduces the topic of automated facial expression perception in computer vision research. The authors highlight the importance of facial expression in human communication and the need to replicate this ability in machines. They discuss the challenges of training and benchmarking facial analysis models and raise important questions about annotation methods, measurement reproducibility, and appropriate evaluation metrics. The authors propose a novel approach to collecting and modeling facial expression annotations using crowdsourcing, along with a benchmark dataset and metric for algorithmic accuracy. Their main contributions include an efficient method for collecting and modeling multi-dimensional facial expression annotations and a benchmark for facial expression prediction algorithms. Overall, this paper aims to contribute to the development of machines that can interact effectively and gracefully with humans through automated facial expression perception.