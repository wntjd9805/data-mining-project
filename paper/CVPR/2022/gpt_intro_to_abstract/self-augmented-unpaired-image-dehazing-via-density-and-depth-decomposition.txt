Haze is a natural phenomenon that reduces visual clarity, posing challenges for both human observers and computer vision systems. Dehazing methods aim to remove haze from real-world images, improving visual quality and benefiting computer vision tasks. These methods often rely on deep neural networks trained on synthetic hazy-clean image pairs in a supervised manner. However, there is a significant domain gap between synthetic and real-world hazy images, leading to poor generalization of supervised models. To address this issue, recent approaches have explored unpaired deep learning methods. This paper proposes a novel framework called D4 (Dehazing via Decomposing transmission map into Density and Depth) for unpaired haze synthesis and removal. The framework explicitly models the scattering coefficient and depth map of the target scene, allowing for accurate estimation of transmission maps and clean content. The proposed framework surpasses state-of-the-art methods in terms of dehazing performance, while requiring fewer parameters and computational resources. Experimental results on both synthetic and real images demonstrate the effectiveness and generalization ability of the D4 framework.