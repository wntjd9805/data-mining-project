Semantic segmentation is a fundamental and active area of research in computer vision, aiming to assign a semantic label to each pixel in a natural image. While significant progress has been made in image semantic segmentation using deep neural networks and large-scale image datasets, video semantic segmentation (VSS) has not witnessed the same level of advancement due to the lack of large-scale video datasets. This paper proposes a Coarse-to-Fine Feature Mining (CFFM) technique for video context learning, which aims to jointly learn static and motional contexts for VSS. The contextual information in videos is twofold: static contexts and motional contexts. Static contexts refer to the contexts within the same video frame or the contexts of unchanged content across different frames, while motional contexts capture temporal information and are responsible for better parsing moving objects and capturing effective scene representations. Previous research has extensively studied static and motional contexts in isolation, but their joint learning has received less attention. The authors argue that static and motional contexts are highly correlated and should be learned simultaneously to achieve a unified representation. The proposed CFFM technique consists of two parts: coarse-to-fine feature assembling and cross-frame feature mining. The feature assembling operation organizes features in a multi-scale manner, considering the temporal consistency and temporal inconsistency of content. This operation prepares data for learning static contexts and enables a large perception region for remote frames, suitable for learning motional contexts. The cross-frame feature mining technique iteratively mines useful information from neighboring frames for the target frame, enhancing the output features for final prediction. The advantages of the CFFM technique include its ability to learn a unified representation of static and motional contexts, its low computational complexity, and its state-of-the-art results in VSS benchmarks. The authors also highlight the potential use of CFFM in other video recognition tasks that require powerful video contexts.