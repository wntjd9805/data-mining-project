Object pose estimation is a crucial task in robotics and computer vision applications. Previous methods for 6D object pose estimation rely on given 3D CAD model information, making it difficult to estimate the pose of unknown objects. Category-level object pose estimation approaches have proven to be more efficient, but current research relies on expensive and unreliable supervised learning with synthetic datasets. To address the data scarcity problem in real-world applications, we propose an unsupervised domain adaptation method called UDA-COPE. Our method transfers task knowledge from a synthetic domain to a real domain through a multi-modal self-supervised learning scheme using pseudo labels. We introduce bidirectional point filtering to improve the quality of pseudo labels and reduce the domain gap between synthetic and real datasets. Experimental results demonstrate the effectiveness of our method, outperforming previous supervised approaches. The contributions of our method include the UDA-COPE framework, the bidirectional point filtering, and improved performance in category-level object pose estimation.