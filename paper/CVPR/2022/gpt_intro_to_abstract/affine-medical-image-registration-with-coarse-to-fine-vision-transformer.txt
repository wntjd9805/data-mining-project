Medical imaging studies heavily rely on rigid and affine registration techniques to accurately align image pairs. The pre-alignment of target images using rigid or affine transformations plays a crucial role in eliminating linear and spatial misalignments before applying deformable registration. While solid structures like bones can be aligned effectively using these methods, inaccurate pre-alignment can lead to suboptimal solutions and hinder registration accuracy. Recent advances in learning-based deformable registration have shown promising results with the use of accurate affine initialization. However, the computational time required for high-resolution 3D image volumes remains a challenge.To address these limitations, some studies have proposed joint affine and non-parametric registration using convolutional neural networks (CNNs) to achieve real-time automated image registration. Nevertheless, the individual performance of the CNN-based affine subnetwork compared to conventional affine registration algorithms has not been thoroughly explored. Furthermore, CNN architectures are not ideal for encoding spatial orientation and absolute position due to their inherent biases.In this paper, we analyze the limitations of CNN-based affine registration methods, specifically their inability to handle initial misalignment and unseen image pairs. Inspired by the success of vision transformer models, we propose a novel approach called coarse-to-fine vision transformer (C2FViT) for 3D medical affine registration. This is the first learning-based affine registration approach that considers non-local dependencies between input images during the learning process.The main contributions of this work include a quantitative investigation of the performance, robustness, and generalizability of existing learning-based and conventional affine registration methods in 3D brain registration. We introduce C2FViT, a convolutional vision transformer with a multi-resolution strategy that outperforms recent CNN-based approaches while demonstrating superior robustness and generalizability across datasets. Furthermore, our proposed learning paradigm and objective functions can be easily adapted to different parametric registration approaches.We evaluate our method on template-matching normalization to MNI152 space and 3D brain atlas registration in native space. The results illustrate that our approach not only outperforms existing CNN-based methods in terms of registration performance but also demonstrates strong generalization capabilities beyond the training dataset, matching the performance of conventional affine registration methods.In summary, this paper presents a comprehensive study on affine registration techniques in medical imaging and introduces a novel learning-based approach, C2FViT, that overcomes the limitations of existing methods.