Imbalanced data distributions pose significant challenges for standard deep learning methods in computer science. While there have been many approaches proposed for long-tailed recognition in the presence of class imbalance, existing solutions from long-tailed recognition and semi-supervised learning (SSL) do not generalize well to the challenging and realistic setting of imbalanced SSL where both labeled and unlabeled data are imbalanced. This paper addresses the problem of imbalanced SSL by introducing CoSSL, a novel co-learning framework that leverages strong SSL algorithms and decouples representation and classifier learning. CoSSL consists of three modules: semi-supervised representation learning, classifier learning, and pseudo-label generation. The framework allows for the exchange of information between the representation learning module and the classifier learning module, enabling improved feature extraction and the generation of better pseudo-labels. The paper also proposes Tail-class Feature Enhancement (TFE) as a method to enhance classifier learning by utilizing unlabeled data to increase the data diversity of tail classes. To evaluate the proposed framework, the paper introduces new evaluation criteria for imbalanced SSL, including a shifted evaluation protocol that considers varying test data distributions. The paper demonstrates the superiority of CoSSL through comprehensive evaluations on multiple benchmarks, achieving state-of-the-art results in various imbalanced SSL settings.