Object detection is a crucial task in computer vision that involves locating and recognizing objects in images. In recent years, deep learning has revolutionized the field of object detection, with the development of powerful detectors using deep convolutional neural networks. However, modern detectors often produce redundant results and require Non-Maximum Suppression (NMS) to reduce redundancy. In contrast, Detection with Transformer (DETR) is a fully end-to-end detector that avoids the need for NMS by applying a Transformer, a powerful attention-based encoder-decoder pipeline. Despite its benefits, DETR faces a difficult training problem, requiring long training epochs to achieve promising performance. This is mainly due to the lack of effective locality modeling in the attention modeling of DETR. To address this issue, previous works have proposed advanced multi-scale feature encoding and object embedding designs to improve locality modeling. In this paper, we propose a novel RoI-based refinement module called the recurrent glimpse-based decoder (REGO) to enhance the attention modeling in DETR. The REGO module performs multi-stage processing by extracting glimpse features from local areas surrounding detected bounding boxes and using a Transformer decoder to translate these features into refined attention modeling outputs and detection results. By incorporating rich contextual information and focusing on relevant regions, REGO improves the training efficiency of DETR and significantly boosts its detection performance. Our experiments demonstrate that using REGO, DETR achieves promising performance with only 36 training epochs, which is 13 times faster than the original DETR method. Furthermore, REGO consistently improves the performance of different DETR methods by up to 7% relative gain using the same number of training epochs. Overall, the proposed REGO module offers an effective solution to the difficult training problem in attention modeling and enhances the performance of DETR-based object detection systems.