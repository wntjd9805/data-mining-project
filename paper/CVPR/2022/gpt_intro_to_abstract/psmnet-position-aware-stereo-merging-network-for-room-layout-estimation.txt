Image-based room layout estimation is a crucial task for various applications in home interior modeling, such as virtual tours and floor plan generation. Current techniques perform well on simple room layouts, but struggle with large and complex rooms. This paper addresses the challenge of estimating room layouts from two 360-degree panoramas, taking into account the relative camera pose. The proposed system, called Position-aware Stereo Merging Network (PSMNet), consists of a transformer-based Stereo Pose Estimation (SP2) network and a pose-aware Cross-Perspective Projection (CP2) module. The CP2 module uses an attention-based merging model to generate the final layout by weighting regions based on certainty. The network is trained end-to-end and achieves state-of-the-art performance on a challenging dataset of stereo panoramas. The contributions of this work include the first end-to-end joint layout-pose deep architecture for large and complex room layout estimation, a new CP2 module for layout generation, and an integrated SP2 network for refining input pose.