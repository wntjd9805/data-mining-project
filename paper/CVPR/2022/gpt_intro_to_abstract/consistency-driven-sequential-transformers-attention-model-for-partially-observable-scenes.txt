High-performing image classification models such as EfficientNet, ResNet, and Vision Transformers assume that a complete scene or image is available for recognition. However, in practical scenarios, a complete image may not be available at once, such as when an autonomous agent acquires an image through a series of narrow observations. This may be due to a small field of view, high acquisition cost, limited time for acquisition, or limited bandwidth. Models trained on complete images prove inefficient for recognizing incomplete images. Therefore, there is a need for autonomous agents that can perform classification based on partial observations.Existing approaches glance at an entire scene to locate informative sub-regions, but this is not always feasible in practice. To address this, we propose an autonomous agent called Sequential Transformers Attention Model (STAM) that predicts the locations of the most informative regions, called glimpses, without observing the entire scene initially. STAM is based on transformer architecture, known for efficiently modeling long-range dependencies. At any given time, the agent predicts the optimal location for the next glimpse and the class-label of the image based on the glimpses collected so far. Since glimpse acquisition is a discrete and non-differentiable process, we train the agent using reinforcement learning.We also propose a consistency-based training objective, where the agent must predict a class distribution consistent with the complete image using only partial observations. This objective is achieved by employing a teacher transformers model to predict the class distribution from a complete image, and our agent (a student model) tries to reproduce this distribution using partial observations. Experimental results on ImageNet and fMoW datasets show that our proposed objective yields significant gains in accuracy.In conclusion, our contributions include the development of STAM, a transformers-based RL agent that actively senses glimpses from a scene and predicts class-labels based on partial observations. We also propose a consistency-based training objective that improves accuracy even with a small percentage of the total image area observed. Our agent outperforms previous methods that initially glance at an entire image to locate informative glimpses, achieving better results with fewer observed pixels.