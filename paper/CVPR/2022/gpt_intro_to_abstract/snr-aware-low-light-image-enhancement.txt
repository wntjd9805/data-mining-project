Low-light imaging is essential for various tasks in computer vision, but low-light images typically suffer from poor visibility. Current methods for enhancing low-light images often rely on neural networks that manipulate color, tone, and contrast. However, these approaches do not consider the different characteristics of lightness, noise, and visibility in different regions of the image. In this paper, we propose an adaptive approach to low-light image enhancement by studying the relationship between signal and noise in image space. We explore the use of Signal-to-Noise Ratio (SNR) to achieve spatial-varying enhancement. We observe that regions with lower SNR are typically unclear and therefore require non-local image information, while regions with higher SNR have higher visibility and less noise, making local image information sufficient. To address this, we propose a solution that combines long-range operations to capture non-local information and short-range operations to capture local information. We dynamically determine the contribution of local and non-local information based on the pixel's SNR. We also introduce an SNR-aware transformer structure that considers only tokens with sufficient SNR values to avoid noise influence from very-low-SNR regions. Our framework is evaluated on seven representative datasets and consistently outperforms state-of-the-art methods. We also conduct a user study to validate the effectiveness of our approach. Overall, our contributions include a new signal-to-noise-aware framework, an SNR-aware transformer, and extensive experimental results demonstrating the superiority of our method.