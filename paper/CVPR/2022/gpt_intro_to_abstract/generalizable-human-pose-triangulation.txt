Human pose estimation, the task of detecting key-points representing human joints, is a competitive field, especially with the advancements in deep learning. It has significant applications in medicine, fashion, anthropometry, and entertainment. This paper focuses on 3D human pose estimation from multiple views in a single time frame.The usual approach to multi-view pose estimation involves detecting 2D keypoints in each view using pretrained pose detectors and then triangulating them. However, this naive approach can result in erroneous detections and self-occlusions. To address this issue, a stochastic framework for human pose triangulation is proposed.The proposed framework generates a pool of random hypotheses, where each hypothesis represents a 3D pose obtained by triangulating a random subset of views for each joint separately. These hypotheses are then passed through a scoring neural network, and the loss function is an expectation of the triangulation error. By minimizing the error expectation, the model learns the distribution of hypotheses, enabling evaluation of 3D pose hypotheses without considering the spatial camera arrangement used for triangulation.The proposed approach demonstrates consistent generalization performance across different camera arrangements, as shown on two public datasets - Human3.6M and Panoptic Studio. Additionally, the model learns human pose prior and defines a novel metric for pose prior evaluation. Furthermore, the same stochastic approach is applied to the problem of fundamental matrix estimation from noisy 2D detections, showing its applicability to other computer vision problems.Overall, the proposed framework addresses the limitations of previous methods by providing generalizability, performance, and the ability to evaluate pose hypotheses without considering camera arrangement. It has practical advantages and potential for applications beyond human pose triangulation.