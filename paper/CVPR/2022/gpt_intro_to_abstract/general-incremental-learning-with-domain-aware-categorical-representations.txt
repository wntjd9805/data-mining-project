This paper introduces a new offline general incremental learning problem where both class distribution and intra-class domain distribution continuously change over time. It addresses the stability-plasticity dilemma and imbalance issue at both inter- and intra-class levels. The authors propose a method based on von Mises-Fisher (vMF) mixture models to learn a domain-aware representation and develop a bi-level balanced memory strategy to mitigate both the inter- and intra-class data imbalance issue. Extensive experiments on three benchmarks show that their strategy consistently outperforms existing methods.