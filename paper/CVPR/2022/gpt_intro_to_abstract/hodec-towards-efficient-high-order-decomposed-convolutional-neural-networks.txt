Deep neural networks (DNNs) have been widely used in computer vision tasks, but their large size poses challenges in terms of computational and storage costs. To address this, model compression approaches such as pruning and quantization have been proposed. However, another approach, tensor decomposition, which explores the low-rankness of DNN models, has also shown promise in reducing network sizes. Specifically, techniques like tensor train (TT) and tensor ring (TR) can achieve high compression ratios. However, these approaches suffer from computation inefficiency, especially for convolutional neural networks (CNNs). While the number of weight parameters is reduced, the computational cost does not decrease proportionally. This inefficiency hinders the widespread deployment of tensor decomposition approaches in time-sensitive applications. In this paper, we propose an efficient High-Order tensor DEcomposed Convolution (HODEC) to address this challenge. We analyze the inefficiency of the classical TT-format convolution and develop strategies to mitigate it. We also propose a new decomposition and execution scheme that significantly reduces computational costs and memory consumption. Experimental evaluations on different datasets demonstrate that HODEC outperforms existing approaches in terms of model parameters, FLOPs, and accuracy. Overall, HODEC offers a solution to the computation inefficiency problem in tensor decomposed CNNs, making them more practical for real-time processing in various computer vision applications.