Efficiently searching large digital archives has become increasingly important as the price-performance of hardware improves. Natural language queries, where users describe their search targets in human terms, are a promising approach to this problem. Cross modal retrieval, which involves searching a gallery of samples in one modality given a query in another, has received significant attention in recent years. Deep neural networks are commonly used to project modality-specific samples into a high-dimensional vector space for comparison. However, these methods often suffer from the "hubness problem," where certain samples appear as nearest neighbors to many other samples, leading to poor retrieval results. Existing approaches to address this problem have limitations, such as requiring concurrent access to multiple test queries and sensitivity to querybank selection. In this paper, we propose Querybank Normalisation (QB-NORM), a framework that utilizes a querybank of samples during inference to reduce the influence of hubs. QB-NORM does not require concurrent access to test queries and introduces a new normalization method called Dynamic Inverted Softmax (DIS) that is more robust than prior approaches. Our contributions include demonstrating the significance of the hubness problem, proposing the QB-NORM framework, showing its effectiveness without concurrent access to test queries, introducing DIS as a novel normalization method, and demonstrating the efficacy of QB-NORM across various tasks, models, and benchmarks.