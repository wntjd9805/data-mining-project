In this paper, we introduce the concept of open-world tracking in computer vision and propose a new benchmark called TAO-OW (Tracking Any Object in an Open World) for evaluating detection and tracking performance in this setting. Traditional tracking methods perform well on objects with abundant training data, but struggle when presented with previously unseen scenarios. To address this limitation, our benchmark focuses on tracking both known objects (from a pre-defined set) and unknown objects (not present in the training data). We utilize the TAO dataset, which contains diverse videos from various scenarios, to ensure a wide range of unknown object categories. We use the COCO dataset's 80 known object classes and leave over 700 categories for evaluating algorithms on unknown objects. Our benchmark features a long-tailed distribution of object categories and provides a basis for comparing against previous closed-world tracking benchmarks. Open-world evaluation poses challenges in terms of exhaustive annotation and we propose a new evaluation metric called Open-World Tracking Accuracy (OWTA) to address this. With our benchmark and evaluation methodology, we conduct a comprehensive analysis of existing methods and propose an open-world tracking approach that performs well on both our benchmark and previous closed-world benchmarks. Our work expands the scope of vision-based multi-object tracking and highlights the continued difficulty of tracking unknown objects.