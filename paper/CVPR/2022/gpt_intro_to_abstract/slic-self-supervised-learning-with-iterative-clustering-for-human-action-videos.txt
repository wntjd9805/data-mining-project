Self-supervision tasks have gained popularity as effective pretraining methods for image classification and retrieval. However, the assumption of instance discrimination becomes more challenging in the case of video representations due to the need to account for both motion-based and appearance-based similarities. In this paper, we propose SLIC, a self-supervised learning method for videos, which combines iterative clustering with multi-view encoding and a temporal discrimination loss. Our main contributions include showing the significant improvement of iterative clustering over traditional instance discrimination in self-supervised learning for video representation, as well as integrating iterative clustering with multi-view encoding and temporal discrimination to sample harder positives and negatives during pretraining. Our experiments demonstrate that SLIC achieves state-of-the-art results in video retrieval and action classification when pre-trained on UCF101. Furthermore, we show that the combination of iterative clustering, multi-view encoding, and temporal discrimination results in larger performance improvements compared to individual components.