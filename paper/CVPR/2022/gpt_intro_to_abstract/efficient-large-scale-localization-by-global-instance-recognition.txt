Visual localization is a critical technique for various applications such as autonomous driving and robotics. Different methods have been developed, including image-based, scene coordinate-based, and structure-based approaches. Image-based methods provide approximate poses, while scene coordinate-based models struggle in large-scale scenes. Structure-based systems, which consist of coarse and fine localization steps, are preferred in real applications. However, previous methods often suffer from computational slowness and low accuracy due to exhaustive comparisons and spurious wrong candidates. Some works have used semantics to improve localization, but they often ignore the fact that coarse localization should provide valid areas for establishing correspondences in fine localization. In this paper, we propose an efficient and accurate large-scale localization system that models coarse and fine localization as a coherent process. We leverage the discriminative and robust nature of buildings to bridge the gap between the two processes. Our system assigns each building instance a global ID and performs pixel-wise recognition to find reference images from areas observing recognized instances. We also use recognition masks for local feature detection and matching, which increases the number of inliers. The uniqueness of buildings and their robustness to appearance changes allow our model to recognize more building instances even under challenging conditions. We employ a progressive search strategy to efficiently find candidates for coarse localization and a robust instance-wise detection and matching technique for fine localization. Our model divides the pose estimation process into two steps to explore potential locations at low cost and produce accurate poses in a slower refinement step. Experimental results on large-scale datasets demonstrate the superior efficiency and accuracy of our model compared to previous approaches. The rest of the paper is organized as follows: Section 2 discusses related works, Section 3 presents our framework, Section 4 presents extensive experiments, and Sections 5 and 6 discuss limitations and conclusions, respectively.