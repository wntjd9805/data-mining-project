Deep neural networks (DNNs) have shown vulnerabilities to adversarial examples, where imperceptible perturbations can deceive the networks. Various defense methods have been proposed, but they can be easily broken by advanced attack methods. Therefore, there is a need for a practical evaluation method to judge the adversarial robustness of different defense strategies. This paper proposes an Adaptive Direction Initialization (ADI) strategy to generate better starting points for adversarial attacks, based on statistics that show the regularities in the direction of diversification to a specific defense model. Additionally, an online statistics-based discarding strategy is introduced to improve the reliability of existing methods by identifying and abandoning hard-to-attack images. By incorporating these two strategies, the proposed evaluation method, Adaptive Auto Attack (A3), achieves lower robust accuracy and faster evaluation for nearly 50 defense models. Experimental results demonstrate the effectiveness and reliability of the proposed method.