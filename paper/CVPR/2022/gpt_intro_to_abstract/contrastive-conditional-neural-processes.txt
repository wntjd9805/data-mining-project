Supervised generative models are widely used in computer science to estimate parameters by reconstructing joint distributions. Meta-learning, which leverages knowledge from previous tasks to adapt to novel tasks, can be naturally integrated with these models. Conditional Neural Processes (CNPs) combine both supervised generative models and meta-learning. CNPs learn to reconstruct observations given contextual representations and query indices. They are designed to handle non-i.i.d function instantiations by implicitly adapting the reconstruction process. CNPs offer several advantages, including the ability to quantify uncertainties and model distributions over functions. These properties make CNPs suitable for applications such as traffic forecasting and activity recognition, where observations can be corrupted or come from different data-generation functions.Despite their benefits, CNPs have some limitations. Correlations between observations are not explicitly modeled, which can affect the coherence of predictions. CNPs also struggle with high-dimensional observations, as they focus on reconstructing low-level details rather than capturing high-level abstractions. Additionally, supervisory collapse can occur in meta-learning scenarios when prediction and transfer tasks are intertwined.To address these limitations, this paper proposes a generative-contrastive meta-learning model based on CNPs. The model aims to decouple model adaptation from generative reconstruction, improving the transferability of meta-representations. The contributions of this work include the presentation of the end-to-end generative-contrastive meta-learning model, the exploration of appropriate contrastive objectives for CNPs, and an empirical evaluation that demonstrates the superiority of the proposed model in terms of function distribution reconstruction and parameter identification across diverse tasks.The paper concludes by highlighting the potential of incorporating contrastive objectives into generative CNPs, suggesting new research directions for this field.