Single image restoration is a crucial task in computer vision, aiming to reconstruct a high-quality image from a degraded version, such as a noisy, rainy, or hazy image. While several methods have been developed to address specific degradation types, such as denoising, deblurring, deraining, and dehazing, they often suffer from limitations in practice. One major challenge is the requirement of prior knowledge about the specific corruption type to select an appropriate model. If the corruption type or level changes, the performance of the model can be compromised. Additionally, real-world environments are often complex, with multiple degradations present simultaneously. To address these challenges, we propose an All-in-one Image Restoration Network (AirNet) composed of two modules: Contrastive-Based Degraded Encoder (CBDE) and Degradation-Guided Restoration Network (DGRN). CBDE learns the representation of degradations by leveraging the consistency within the same degradation type and the inconsistency between different degradation types. DGRN then uses the learned degradation representations to restore images with various degradations. AirNet offers two key advantages: (i) it provides a unified solution for recovering images with different corruption types and ratios, without requiring prior information about the specific corruption, and (ii) it can handle multiple degradations simultaneously, making it more flexible and efficient. Our contributions include being one of the first methods to address the challenge of all-in-one image restoration and proposing a dual-model approach that leverages contrastive learning to capture the characteristics of multi-degradations. Extensive experimental evaluations on denoising, deraining, and dehazing tasks demonstrate the effectiveness of AirNet compared to 17 baseline methods.