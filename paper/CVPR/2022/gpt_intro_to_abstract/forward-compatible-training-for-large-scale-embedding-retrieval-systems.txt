This paper introduces the concept of forward-compatible training (FCT) in the context of representation learning for computer vision. FCT aims to prepare models for future updates by incorporating side-information, auxiliary features learned alongside the original model, which can aid in transferring to new models. The paper demonstrates that FCT outperforms backward-compatible training (BCT) in terms of retrieval accuracy for various datasets. Unlike previous methods, FCT allows for independent training of new and old models, ensuring that the accuracy of the new model is not compromised for compatibility purposes. Experimental results show significant improvements in retrieval accuracy compared to BCT. The paper also discusses the computational cost trade-offs of FCT and highlights its effectiveness in on-device computing scenarios. Overall, the contributions of this paper include the proposal of FCT as a learning paradigm and the introduction of side-information for representation learning.