Deep convolutional neural networks have achieved remarkable success in visual face recognition, achieving over 99% accuracy on multiple benchmarks. However, in low-visibility scenarios such as low-light or night-time, it is often difficult to obtain clear visible (VIS) images, leading to a need for heterogeneous face recognition (HFR). HFR matches images from Thermal (TH) modality to their VIS counterparts and has applications in surveillance, monitoring, and security. Existing face recognition algorithms trained on VIS images often perform poorly on TH datasets due to large domain discrepancies. Previous efforts to address HFR have focused on learning domain-invariant features or finding a common subspace. Recently, HFR has been reformulated as a face synthesis/translation problem using Generative Adversarial Networks (GANs). However, existing synthesis-based approaches still produce unsatisfactory VIS images with distorted facial structures. The limited size and quality of TH datasets make collecting and annotating them difficult. Additionally, most existing methods can only process images at resolutions no larger than 128x128, limiting their applicability in downstream tasks. In this paper, we propose a unified hallucination framework for HFR that can synthesize high-resolution VIS faces from low-resolution heterogeneous data. Our approach leverages pre-trained GANs as facial decoders and uses a novel Multi-scale Contexts Aggregation (MSCA) mechanism for better fine-grained generation control and preserving identity information. We also introduce Federated Learning (FL) to improve HFR by allowing collaborative model training without explicit data exchange. We address the challenge of heterogeneous data distributions across institutions using a Model Proximity Regularization (MPR) approach. Our approach, called VPFL, generates high-resolution VIS faces with superior realness and accuracy. We validate its effectiveness through extensive experiments.