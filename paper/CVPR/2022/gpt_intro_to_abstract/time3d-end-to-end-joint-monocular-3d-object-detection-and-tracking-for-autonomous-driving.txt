The introduction of this computer science paper discusses the challenges of 3D object detection using monocular cameras in autonomous driving. Monocular cameras are favored for their cost-effectiveness and flexibility, but they lack depth information, making it difficult to accurately estimate the state of 3D objects. The paper proposes a solution called Time3D, which combines monocular 3D object detection and 3D multi-object tracking in a unified architecture with end-to-end training. The proposed method aims to predict 2D and 3D bounding boxes, object categories, and Re-ID features using only monocular images. It also encodes compatible feature representations for different cues and learns a differential association to generate trajectories by combining heterogeneous cues across time. The paper introduces modifications to the KM3D 3D detector to learn detection and Re-ID embedding jointly. It also proposes a Transformer architecture, inspired by the query-key mechanism, for data association. A temporal-consistency loss is proposed to make the trajectories smoother. Experimental results on the nuScenes 3D tracking benchmark show that the proposed method achieves superior tracking accuracy compared to other competitors while running in real-time.