In recent research, implicit, coordinate-based neural networks have been utilized as a 3D representation for optimizing 3D volumes from 2D image super-vision. Neural Radiance Fields (NeRF) demonstrated impressive photorealistic novel viewpoint synthesis by capturing scene geometry and view-dependent effects. However, these high-quality results require significant computation time for both training and rendering, limiting their practical application. Although subsequent papers have reduced rendering costs, training time still remains a bottleneck.This paper presents a method to train a radiance field from scratch without neural networks, while maintaining NeRF quality and significantly reducing optimization time. The authors provide a custom CUDA implementation that capitalizes on the simplicity of the model, achieving substantial speedups. The optimization time on a single GPU is only 11 minutes for bounded scenes (compared to roughly 1 day for NeRF) and 27 minutes for unbounded scenes (compared to approximately 4 days for NeRF++). Additionally, the authors demonstrate the ability to render novel viewpoints at interactive rates, and propose the conversion of the optimized Plenoxel model into a PlenOctree for even faster rendering.The proposed method utilizes an explicit volumetric representation based on a view-dependent sparse voxel grid, without the use of neural networks. Photorealistic novel viewpoints can be rendered and the model can be optimized from calibrated 2D photographs using a differentiable rendering loss and total variation regularizer. The model, called Plenoxel, consists of a sparse voxel grid where each voxel stores density and spherical harmonic coefficients to model view dependence. To achieve high resolution on a single GPU, empty voxels are pruned and a coarse to fine optimization strategy is employed. The authors also demonstrate the modeling of unbounded scenes using normalized device coordinates or multisphere images for 360-degree scenes.The proposed method highlights that photorealistic volumetric reconstruction can be achieved using standard tools from inverse problems. The research shows that each component of the method, including data representation, forward model, regularization function, and optimizer, can be simple yet yield state-of-the-art results. Additionally, the experiments suggest that the differentiable volumetric renderer is the key element of Neural Radiance Fields, rather than the neural network itself.