This paper introduces the concept of pose estimation for multi-body articulations, focusing on the composited hand and object poses during their interaction. The authors highlight the challenge of obtaining diverse training data for this task, as traditional recording and annotation methods hinder pose diversity. To address this issue, the authors propose ArtiBoost, an online data enhancement method that boosts articulated hand-object pose estimation through exploration and synthesis steps. In the exploration step, ArtiBoost samples different hand-object-viewpoint triplets from a three-dimensional discrete space called the Composited hand-object Configuration and Viewpoint space (CCV-space). In the synthesis step, valid and diverse hand-object poses are constructed using a fitting-based grasp synthesis method that considers contact constraints between hand and object vertices. These synthesized poses are then mixed with real-world source images to train the HOPE model. The training losses are fed back to the exploration step, allowing ArtiBoost to adaptively adjust its sampling weights for selecting more challenging data. The authors demonstrate the effectiveness of ArtiBoost by plugging it into classification-based and regression-based pose estimation models and evaluating their performance on challenging HOPE benchmarks. The results show that even without complex techniques, the baseline models using ArtiBoost outperform previous state-of-the-art methods. Overall, this paper presents a comprehensive approach to enhancing the performance of HOPE tasks by improving the diversity of training data.