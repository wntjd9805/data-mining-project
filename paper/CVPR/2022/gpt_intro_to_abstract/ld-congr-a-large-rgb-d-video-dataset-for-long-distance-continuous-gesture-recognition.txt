Gesture is a crucial means of information transmission, enabling communication with the deaf, traffic control, and natural interaction with machines. While existing gesture recognition datasets and research largely focus on close-range interactions, there is a need for datasets and methods that cater to long-distance gesture recognition in scenarios like meetings and home automation. To address this gap, we introduce LD-ConGR, a large high-quality RGB-D video dataset specifically designed for long-distance continuous gesture recognition. Unlike existing datasets, LD-ConGR captures gestures at distances ranging from 1m to 4m, presenting new challenges for recognition. The dataset provides fine-grained annotations for continuous gesture recognition, including gesture categories, start and end frames, and hand positions. LD-ConGR videos are of high quality, captured using the Kinect V4 with synchronized color and depth streams. Experimental exploration using LD-ConGR demonstrates the effectiveness of different models and techniques for long-distance gesture recognition, including a multimodal model that combines RGB and depth information, and a strategy for estimating the gesture region based on hand location. Key frame sampling is also utilized to address the difficulties posed by varying gesture durations. In summary, this paper contributes LD-ConGR, the first dataset for long-distance continuous gesture recognition, and provides insights and directions for future research in this domain.