This paper introduces a system for online photorealistic reconstruction of 3D scenes. The goal is to capture accurate geometry and appearance of scenes in real-time applications. The paper compares two paradigms for achieving this goal: visual simultaneous localization and mapping (SLAM) systems and neural volumetric rendering approaches. While SLAM systems are efficient, they can only reconstruct solid surfaces and make simplified assumptions about scene appearance. On the other hand, neural volumetric rendering approaches capture scenes in a photorealistic manner but require a long per-scene training time. To address these limitations, the paper proposes two novel components. The first component is a tree-based scene representation called nVDB, which improves memory efficiency by storing information only near occupied areas. This representation speeds up rendering and optimization. The second component is a volumetric bundle adjustment (VBA) approach that optimizes the pose and volume parameters to achieve photometric consistency. VBA utilizes a Levenberg-Marquadt type approach, which enables faster convergence by leveraging the curvature of the objective function.By combining the nVDB scene representation and the VBA optimizer, the proposed system achieves more accurate results than RGB-D systems. The main contribution of the paper is a system for online photorealistic reconstruction, facilitated by the novel components: the nVDB tree-based representation and the VBA optimization method. These components enable efficient representation and optimization of 3D scenes, allowing for real-time performance.