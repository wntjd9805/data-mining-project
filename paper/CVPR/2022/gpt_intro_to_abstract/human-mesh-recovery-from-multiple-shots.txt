Movies provide a diverse and rich source of human behavior episodes, making them ideal for training systems for video understanding and acquiring common sense knowledge. However, a challenge arises from the grammar of film and the existence of shots, which introduce temporal discontinuities and independent scenes. Additionally, shot changes often depict close-up shots of actors, which current human mesh recovery models struggle to handle. In this paper, we propose a multi-shot optimization method that addresses these challenges by leveraging shot changes as a multi-view signal of the underlying dynamic scene. This enables the recovery of consistent 3D human motion sequences and improves the performance of regression models for human mesh recovery. We demonstrate the effectiveness of our approach on the AVA dataset and highlight the importance of multi-shot reasoning in training accurate and longer pseudo-ground truth. Furthermore, we propose a transformer-based architecture for temporal encoding, which enhances the applicability of regression models on movie data. Our work makes significant contributions by introducing the problem of human mesh recovery from multiple shots, presenting an optimization approach, validating its effectiveness on movie data, and proposing a temporal model with a transformer-based encoder.