Anomaly detection from videos presents challenges due to the rarity, complexity, and unbounded nature of abnormal activities. The lack of segment or frame labels also complicates the detection task, requiring models to rely on weak video-level labels. Existing research approaches anomaly detection either as unsupervised learning or multiple instance learning (MIL). Unsupervised learning models abnormal events as significant deviations from a predefined set of normal events but may have high false alarm rates for novel normal events. MIL models each video as a bag and its segments as instances, aiming to predict frame-level anomalies based on video-level labels. The Maximum Score based MIL (MMIL) model outperforms unsupervised approaches but has limitations. It can be sensitive to noisy outliers in abnormal and normal videos, impacting overall performance. It may also struggle to detect multiple types of abnormal events in a single video, known as multi-modal anomaly. Top-k ranking loss has been used to address these issues, but it is sensitive to the selected k value and may suffer from outlier and multimodal scenarios. To overcome these limitations, we propose a novel Bayesian non-parametric construction of a submodular set function integrated with MIL for robust video anomaly detection. The proposed approach maximizes diversity in the selected instances and exposes the model to all potentially abnormal segments for more effective training. We construct the submodular set function using an infinite Hidden Markov Model with a Hierarchical Dirichlet prior (HDP-HMM) and a non-parametric mixture model to accommodate the dynamic and noisy nature of surveillance videos. We also introduce a submodularity diversified MIL loss function and develop a greedy algorithm for efficient model training. The proposed approach achieves state-of-the-art robust anomaly detection performance in real-world surveillance videos with noisy and multimodal scenarios.