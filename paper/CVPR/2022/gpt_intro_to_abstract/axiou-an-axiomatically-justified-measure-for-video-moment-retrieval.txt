Video Moment Retrieval (VMR) is an important task in computer vision that aims to find relevant sections, or video moments, within videos based on a user's textual query. Existing VMR systems typically approach this problem as a ranking task, evaluating the effectiveness of ranked lists using the R@K, θ metric, which measures the intersection between predicted video moments and ground truth instances.However, R@K, θ has two limitations. Firstly, it is insensitive to the ranking of video moments, treating them as a set without considering their specific ranks. Secondly, it is insensitive to the localization quality of video moments, as it binarizes the intersection over union (IoU) measurement. These limitations make R@K, θ inadequate for reliable evaluation, as it fails to differentiate between ranked lists of different quality and can lead to instability and conflicting results.In this paper, we propose an alternative evaluation metric called Average Max IoU (Ax-IoU) for VMR systems. Ax-IoU addresses the limitations of R@K, θ by considering both the ranking and localization quality of video moments. We introduce two important axioms that an effective evaluation measure for VMR must satisfy and show that R@K, θ only satisfies the first axiom. We also empirically investigate the properties of Ax-IoU, including its agreement with conventional R@K, θ and its stability with respect to dataset size and label ambiguity.By addressing the limitations of existing evaluation metrics, Ax-IoU provides a more comprehensive and reliable measure for assessing the performance of VMR systems. Its effectiveness is demonstrated through empirical evaluations, highlighting its potential to improve the evaluation and comparison of different VMR methods.