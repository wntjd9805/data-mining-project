Semantic segmentation is a crucial problem in computer vision, with applications in various fields including autonomous driving. Recent advancements in semantic segmentation have been driven by large-scale annotated datasets. However, collecting such annotations can be costly and time-consuming, making it unrealistic to obtain a sufficient number of well-annotated images for new environments. To address this issue, synthetic images with accurate annotations can be rendered using computer-generated models. However, models trained on synthetic images often suffer from performance degradation when tested on real-world images, as these domains have different distributions. This phenomenon is commonly observed in cross-domain semantic segmentation tasks, and numerous unsupervised domain adaptation models have been proposed to mitigate this problem by transferring knowledge from a labeled source domain to an unlabeled target domain.Existing cross-domain semantic segmentation methods focus on learning domain-invariant representations through adversarial training. However, these methods overlook the label shift problem, which frequently occurs in cross-domain semantic segmentation tasks due to differences in label distributions between domains. This paper presents a novel approach to address the label shift problem in cross-domain semantic segmentation. It begins with an in-depth analysis that reveals the critical role of classifier bias in the poor generalization ability of learned models on the target domain when label shift is present. The classifier tends to be biased towards the source domain, given that the supervision signal comes solely from it. The paper also demonstrates that aligning the conditional distribution of data and correcting the posterior probability can overcome the negative impact of label shift.To achieve this, the proposed approach incorporates class-level feature alignment for conditional distribution alignment. Two simple yet effective methods are introduced to rectify the classifier bias from the source to the target domain. The conditional distribution alignment is followed by adjusting the classifier's predictions using the label distributions from the source and target domains, either during the training or inference stage.In summary, this paper presents a novel approach to address the label shift problem in cross-domain semantic segmentation. By analyzing classifier bias and aligning conditional distributions, the proposed approach mitigates the negative effects of label shift, improving the performance of models on the target domain. The effectiveness of the approach is demonstrated through experiments and comparisons with existing methods.