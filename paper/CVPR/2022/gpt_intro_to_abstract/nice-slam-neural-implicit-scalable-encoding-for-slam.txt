Dense visual Simultaneous Localization and Mapping (SLAM) is a crucial problem in 3D computer vision with applications in autonomous driving, indoor robotics, mixed reality, etc. In order to create a practical SLAM system for real-world use, it must possess certain properties. It should be real-time, have the ability to make predictions for unobserved regions, scale up to large scenes, and be robust to noisy or missing observations. While there have been several methods introduced for RGB-D cameras in the past years, traditional systems fulfill real-time and large-scale requirements but struggle with making plausible geometry estimations for unobserved regions. On the other hand, learning-based SLAM approaches show promise in making predictions and handling noise, but are limited to small scenes. Recent advancements have demonstrated the benefits of hierarchical scene representations and neural implicit representations for dense RGB-D SLAM. In this work, we present NICE-SLAM, a real-time, scalable, predictive, and robust dense RGB-D SLAM system that combines hierarchical feature grids with neural implicit decoders. By using these representations, we can optimize the features grids within the viewing frustum and achieve competitive performance in mapping and tracking.