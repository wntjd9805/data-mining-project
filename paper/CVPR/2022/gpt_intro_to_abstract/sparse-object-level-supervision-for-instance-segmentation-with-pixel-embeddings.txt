Instance segmentation is a crucial problem in the field of computer vision, with applications ranging from astronomy to robotics. It plays a vital role in the analysis of individual object appearance and is particularly relevant in biological imaging, where it is used for tasks such as phenotyping and cellular ultrastructure analysis. However, instance segmentation in microscopy presents unique challenges due to crowded 3D environments or their 2D projections with multiple overlapping objects and the lack of large, publicly accessible training datasets. Most microscopy segmentation networks are trained from scratch, relying on annotations produced by domain experts, which can be time-consuming. To alleviate the annotation burden, weakly supervised segmentation approaches have been introduced, leveraging image-level labels as a form of supervision. However, these approaches are not suitable for microscopy due to the absence of appropriate collections. This paper introduces a different kind of weak supervision for instance segmentation, termed "positive unlabeled" setting. In this setting, a subset of instances in the image is annotated with mask annotations, while the rest of the pixels remain unlabeled. This approach has been explored in image classification and semantic segmentation but not for instance segmentation.The proposed method addresses the dense annotation bottleneck by utilizing sparse object mask annotations combined with an instance-level consistency loss in the unlabeled areas of the image. The instance selection step is made differentiable, allowing for the application of loss directly to individual instances. This approach enables training with weak positive unlabeled supervision and improves segmentation accuracy across various datasets.The paper presents an evaluation of the approach on natural images and microscopy datasets, including 2D and 3D microscopy images from light and electron microscopy. The results demonstrate the state-of-the-art performance on the CVPPP dataset and consistently outperform strong baselines in microscopy segmentation. Notably, significant performance improvements are observed with the annotation of only a fraction of training objects. The proposed method also allows for efficient domain adaptation using a few object masks as supervision in the target domain.In summary, this paper introduces a CNN-based approach for instance segmentation using pixel embeddings. It presents the first approach to enable training with weak positive unlabeled supervision, leveraging sparse object mask annotations. The paper also introduces a differentiable instance selection step and a consistency loss term for training on unlabeled image regions. The approach is evaluated on various datasets, demonstrating its effectiveness and outperforming baselines in microscopy segmentation.