This paper focuses on the important task of face analysis in computer vision and discusses the limitations of existing supervised models that require expensive and difficult-to-acquire annotated data. The authors propose a framework called FaRL to learn facial representation in a visual-linguistic manner, leveraging pre-training techniques. They create a dataset called LAION-FACE by filtering a large openly available image-text-pair dataset. The authors adopt contrastive loss to improve the semantic meaning of the learned embeddings. Additionally, they explore low-level information through masked image modeling. The pre-trained model is evaluated on various downstream face tasks, demonstrating superior performance compared to other pre-trained models and surpassing the state-of-the-art methods in face parsing and face alignment. The contributions of the paper include an extensive study on transferable visual models in face analysis tasks and the introduction of a new framework that combines low-level and high-level information for better representation.