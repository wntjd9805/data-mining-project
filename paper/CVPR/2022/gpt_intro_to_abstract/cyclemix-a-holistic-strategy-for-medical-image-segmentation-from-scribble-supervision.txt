Large fully-annotated datasets are crucial for the gener-a-lization of deep neural networks. However, manually labeling medical images is expensive and time-consuming. To address this issue, previous works have utilized weakly labeled and unlabeled training data for model training, such as semi-supervised learning (SSL) and weakly-supervised learning (WSL). SSL requires accurate annotations in the dataset, while WSL approaches, like scribble annotations, have shown potential for medical image segmentation. However, learning shape priors from scribble supervision is challenging due to the lack of precise annotations.Existing scribble learning approaches either expand scribble annotations using a priori assumptions or learn adversarial shape priors with fully-annotated masks. Augmentation strategies like mixup have been proposed but mainly for image classification, which may change the shape priors of objects and result in unrealistic segmentation. When only scribble supervision is available, segmentation performance with mixup augmentation can be unstable.To overcome these challenges, we propose CycleMix, a weakly-supervised segmentation framework for scribble supervision. CycleMix maximizes the supervision of scribbles through mix augmentation and random occlusion, and regularizes model training using consistency losses. We introduce a two-step mix augmentation strategy to increase and reduce scribbles, and develop two-level consistency regularization at the global and local levels. The global consistency loss penalizes inconsistent segmentation in original and mixed images, while the local consistency loss minimizes the distance between predictions and their largest connected component.The contributions of this paper include the CycleMix framework, the introduction of mixup strategies for weakly-supervised segmentation, consistency losses for regularization, and a new scribble annotated cardiac segmentation dataset called MSCMRseg. CycleMix is the first framework to achieve both increments and decrements of scribbles from mixed training images. Evaluation on ACDC and MSCMR datasets demonstrates promising performance, with comparable or even better segmentation accuracy than fully-supervised approaches.