Deep learning models have achieved remarkable success in cellular nuclei segmentation from histopathologic images. However, collecting a large amount of annotated data can be time-consuming and expensive. In this paper, we focus on training deep models with only a few annotated data, using a semi-supervised learning approach. Previous works in this direction include semi-supervised and weakly-supervised learning techniques. We specifically study the semi-supervised learning problem in which a few pixel-wise annotated data are available, while learning from a large amount of unlabeled data. We propose a cross-patch dense contrastive learning framework that extracts structural information from unlabeled data. This framework leverages the similarity and disparity between different features to learn high-level semantic structures across images. Our approach involves sampling positive and negative pairs of features and enforcing intra-class compactness and inter-class separability at both patch-level and pixel-level. We also utilize mean teacher architecture, consistency regularization, and entropy minimization to improve the quality of predictions and pseudo-labels. Experimental results on two publicly available datasets demonstrate the effectiveness of our method, outperforming state-of-the-art techniques. Our contributions include proposing an effective cross-patch dense contrastive learning framework and developing an efficient semi-supervised nuclei image segmentation algorithm.