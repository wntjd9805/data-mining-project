This paper introduces MeMOT, a Transformer-based tracking model for online multi-object tracking (MOT). Traditional methods for MOT involve separate stages for object detection and data association. However, combining these stages often results in the oversimplification of the association module. MeMOT addresses this issue by proposing a large spatio-temporal memory that stores past observations of tracked objects. This memory is actively encoded in each time step and provides more accurate states for the association task. The proposed model consists of three main components: a hypothesis generation module, a memory encoding module, and a memory decoding module. These components work together to perform object detection and data association simultaneously. MeMOT achieves state-of-the-art performance in pedestrian tracking benchmarks and outperforms other Transformer-based methods in both object detection and data association tasks. Extensive ablation studies validate the effectiveness of MeMOT.