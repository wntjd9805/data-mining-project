3D representations play a crucial role in various applications such as robotics, self-driving, virtual/augmented reality, and online marketplaces. As the number of diverse tasks relying on effective 3D representations increases, the need for specialized data and individual systems for each task becomes more demanding in terms of compute and data resources. However, seemingly different tasks like shape completion or image-conditioned prediction share a common requirement of a distribution over plausible 3D structures based on the corresponding input. In this paper, we propose the utilization of a generic shape prior that can be applied across different inference tasks. We demonstrate that this prior can be learned from abundant raw 3D data and used to enhance the performance of task-specific conditional distributions, especially when acquiring paired training data is challenging. Since learning a prior directly over the continuous and high-dimensional space of 3D shapes is computationally intractable, we adopt discrete representation learning to transform 3D shapes into low-dimensional representations. This approach not only makes the training of autoregressive models feasible but also enables the learning of a non-sequential autoregressive prior capable of using random subsets as conditioning. To leverage the learned prior for conditional generation tasks, we propose an approximation of the complex conditional distribution as a product of the prior and task-specific "naive" conditionals. This unified approach, combined with the expressive shape prior, outperforms task-specific state-of-the-art methods. Our framework provides a simple and effective solution for leveraging a learned shape prior in various 3D inference tasks.