Generative Adversarial Networks (GANs) have proven successful in synthesizing high-quality images and learning interpretable directions in the latent space. While GANs implicitly learn which pixels or regions correspond to each other, establishing dense correspondence between semantically-similar regions with varying appearance remains a challenge. Most existing approaches rely on supervised or unsupervised methods but few have explored learning dense correspondence from GANs. In this paper, we propose a method for learning explicit correspondence maps from GANs by representing dense correspondence as a pixel-level semantic label map. This task is relevant to disentangling structure and texture in GANs. Inspired by UV maps of 3D meshes, we introduce a novel coordinate space for obtaining pixel-level correspondence and design a Coordinate GAN (CoordGAN) that controls structure and texture independently. Several objectives are used to ensure accurate correspondence, including texture swapping and warping constraints. We also demonstrate that CoordGAN can be equipped with an encoder to produce correspondence maps for real images. Our contributions include the introduction of a novel coordinate space for dense correspondence, the development of CoordGAN for generating correspondence maps and high-quality images, and the introduction of an encoder network for explicit structure representation. Experimental results show that CoordGAN generates accurate correspondence maps and high-quality editable images for various categories.