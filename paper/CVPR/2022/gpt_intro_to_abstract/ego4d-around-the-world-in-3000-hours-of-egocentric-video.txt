Computer vision systems have made significant progress in object and activity recognition in Internet photos and videos. However, these datasets and models have limitations in terms of representing visual perception. Current datasets capture isolated moments from a third-person view, while robotics and augmented reality require a first-person or egocentric perspective. Additionally, Internet photos are curated by human photographers, whereas egocentric camera footage lacks active curation. First-person perception entails understanding the camera wearer's environment, interpreting objects and actions in a human context, and considering human-object interactions and social behaviors. To address these challenges, the Ego4D dataset and benchmark suite is introduced. This dataset is a massive collection of ego-videos captured by 931 participants from 74 locations worldwide, totaling 3,670 hours of footage. The dataset provides diverse and unscripted daily life activities, captured by individuals of varying backgrounds, occupations, genders, and ages. It offers long-form video content that showcases complex interactions with the environment, objects, and other people. The dataset also includes additional data modalities such as audio, 3D meshes, gaze, stereo, and multi-camera views. The Ego4D dataset builds upon prior egocentric video data efforts but introduces advancements in scale, diversity, and realism. In addition to the dataset, a suite of five benchmark tasks is provided, covering indexing past experiences, analyzing present interactions, and anticipating future activity. These benchmarks are accompanied by millions of rich annotations created through extensive annotator effort. The Ego4D project involved collaboration among 14 institutions and aims to catalyze research not only in computer vision but also in areas such as robotics, augmented reality, 3D sensing, multimodal learning, speech, and language. The project kickstarts with a benchmark challenge at CVPR 2022, and the dataset is made publicly available to foster further research in the field.