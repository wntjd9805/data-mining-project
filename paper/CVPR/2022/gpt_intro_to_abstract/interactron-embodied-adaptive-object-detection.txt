Object detection is a fundamental problem in computer vision, and various methods have been proposed over the years to tackle this problem. However, existing approaches have two main limitations: they assume a fixed training set and a test set, and the model is frozen after the training stage without further updates. These limitations hinder the performance and adaptability of object detection in real-world applications where new observations continuously emerge. In this paper, we propose INTERACTRON, a novel method for object detection that addresses these limitations. Our approach allows the detection model to be adaptively updated during inference without explicit supervision. We hypothesize that interacting with the environment during inference enables the model to capture better observations and improve its adaptation and performance. Unlike traditional object detection frameworks, our model learns to take actions and adapt without a distinct boundary between training and inference phases. We evaluate our adaptive object detection model using the AI2-THOR framework and demonstrate significant improvements over strong non-adaptive baselines. Furthermore, our model achieves comparable results to a fully supervised model on the Habitat framework, which involves scenes with different appearance characteristics. Our approach presents an embodied adaptive object detection approach that leverages interaction with the environment for model updates, leading to improved performance and generalization.