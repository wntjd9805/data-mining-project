Abstract:This paper addresses the problem of sparse and missing labels in deep learning by proposing a solution using Zero Shot Learning (ZSL) techniques. Specifically, the focus is on the Generalized ZSL (GZSL) task, where predictions are made on both seen and unseen classes simultaneously. The current approach of synthesizing pseudo samples for unseen classes has limitations related to feature confounding and distribution uncertainty. To overcome these challenges, this paper introduces a non-generative approach called Task-correlated Disentanglement and Controllable Samples Synthesis (TDCSS). TDCSS includes a Task-correlated Feature Disentanglement Module that separates task-correlated features from task-independent features, and a Controllable Pseudo Samples Synthesis Module that synthesizes pseudo samples based on these task-correlated features. The proposed method is evaluated on the GZSL task and a new task called Few-shot Seen class and Zero-shot Unseen class learning (FSZU). The results demonstrate the competitiveness of the TDCSS approach compared to similar methods on four different datasets. Overall, this paper presents a novel approach for addressing the challenges associated with sparse labels and provides insights into the role of pseudo samples in knowledge transfer in ZSL tasks.