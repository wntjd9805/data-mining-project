Monocular 3D object detection, which aims to detect objects and recover their position in 3D space from a single input image, has gained increasing attention in various applications such as autonomous driving and robot navigation. Unlike stereo or lidar sensors, monocular cameras are more cost-effective for perceiving the surrounding environment. However, they suffer from unreliable depth recovery, resulting in suboptimal performance. In this paper, we explore the geometric robustness of existing detectors and propose augmentation techniques to enhance their consistency under geometric shifts. We conduct experiments to investigate if detectors utilize visual cues, such as object size and vertical position, for depth estimation. We find that detectors are unable to capture consistent relationships between depth and these visual cues, even though they can identify variations. To address this issue, we introduce geometry-aware data augmentation techniques at both the image and instance levels. These augmentation methods preserve the pictorial visual cues during manipulation, leading to significant performance improvements in state-of-the-art detectors. We also demonstrate the effectiveness of consistency regularization techniques in cross-domain scenarios and semi-supervised training. Our contributions include identifying the instability problem in depth recovery, proposing geometry-aware augmentation techniques, and achieving state-of-the-art performance on benchmark datasets.