Video frame interpolation (VFI) is an important task in computer vision that involves predicting intermediate frames given a sequence of frames. Existing VFI works typically follow a two-step process of estimating motion between frames and synthesizing intermediate frames. However, these methods are primarily designed for sequences with high frame rates, and their performance degrades significantly when the frame rate of the input sequence decreases. This limitation has received less attention in the past literature, likely due to the challenges posed by accurately estimating motion for large temporal gaps. In this paper, we propose a new VFI framework that addresses the problem of long-term video interpolation for relatively low frame rates. Instead of estimating motion, we propagate from one side of the input frames to a reliable extent of time, using the other input as a reference. By doing so, we reduce the temporal gap between frames and enable existing interpolation approaches to be applied. Our approach incorporates a propagation network (PNet) that leverages optical flow to guide the propagation of features and enforce temporal consistency. We also introduce a frame synthesis network to reconstruct frames from the propagated features. Experimental results demonstrate that our proposed method improves the robustness of existing state-of-the-art VFI approaches when there is a considerable temporal gap between input frames. We evaluate our method on multiple datasets and conduct ablation experiments to analyze the network design and loss function choices. Overall, our approach shows promising results in addressing the challenges of long-term video interpolation for low frame rates.