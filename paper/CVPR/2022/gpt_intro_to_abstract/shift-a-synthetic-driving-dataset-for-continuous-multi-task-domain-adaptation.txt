Recent progress in perception systems for autonomous driving has led to the collection and release of large-scale driving datasets by industry and academia. These datasets have played a crucial role in the development of perception algorithms, but their generalization to unforeseen environmental conditions has been limited. One major challenge is domain shift, which refers to changes in weather, lighting conditions, scenery, and other factors that can impact the performance of learning algorithms. While techniques such as domain generalization, domain adaptation, uncertainty estimation, and out-of-distribution detection have been developed to address domain shift, their effectiveness has mostly been tested on toy datasets or synthetically corrupted datasets. Current solutions cannot be adequately evaluated in real-world autonomous driving scenarios without risking car crashes.Existing driving datasets primarily consist of short sequences captured under approximately stationary conditions, with discrete shifts observed between sets of sequences representing different homogeneous conditions. However, continuous shifts - the transitions from one domain to another within a sequence - are prevalent in the real world. For example, a sunny day can quickly turn into a rainy one, or a quiet road can suddenly become crowded. Continuous distributional shift poses a critical challenge for current learning systems.To address these limitations, we introduce SHIFT, a new synthetic dataset that captures the continuously evolving nature of the real world through realistic discrete and continuous shifts. SHIFT includes a comprehensive sensor suite and covers 13 perception tasks for multi-task driving systems, such as semantic/instance segmentation, object detection, multiple object tracking, optical flow estimation, and more. It consists of over 4,800 sequences captured from a multi-view sensor suite in 8 different locations, providing a rich and diverse dataset for research.With SHIFT, we aim to foster research in various under-explored fields related to the generality and reliability of perception systems for autonomous driving, including domain generalization, domain adaptation, and uncertainty estimation. We also hope to contribute to the field of continual learning for autonomous driving, which has primarily been studied on discrete levels of synthetic corruptions of traditional image classification datasets. Moreover, by including sequences with realistic continuous domain shifts, SHIFT enables research on continuous test-time learning and adaptation.The main contributions of this work are the introduction of SHIFT, the largest synthetic dataset for autonomous driving with a comprehensive set of annotations and conditions, and the analysis of discrete and continuous domain shifts using SHIFT to demonstrate new findings on adaptation and uncertainty estimation methods. SHIFT provides a valuable resource for advancing the development of perception systems for autonomous driving and addressing the challenges posed by domain shift.