Learning a shape space involves finding a latent representation that can effectively generalize to unseen shapes. This is commonly achieved through autoencoder frameworks, which employ an encoder to map input shapes to a latent space and a decoder to map latent representations back to shapes. Many shape collections exhibit symmetries, such as Euclidean motions or articulated body poses. Incorporating these symmetries into shape space learning requires the encoder and decoder to be equivariant, meaning that applying a symmetry to an input shape results in the same symmetry applied to the latent code, and reconstructing a shape from a transformed latent code produces a transformed shape. However, building equivariant neural networks that are both expressive and efficient remains challenging. Existing architectures are either computationally intensive or lack universality. In this paper, we propose a flexible, efficient, and maximally expressive framework for building equivariant encoders and decoders. Our framework incorporates the recent Frame Averaging (FA) approach to shape space learning, enabling the construction of powerful shape autoencoders. Additionally, we introduce an autoencoder architecture that is fully equivariant to piecewise Euclidean transformations of shape parts. We evaluate our framework on different shape learning tasks, including real-life point cloud-based shape learning and mesh deformation learning for human and animal shapes. Our method achieves state-of-the-art results with significant performance improvements over baselines, highlighting the effectiveness of the inductive bias introduced by frame-averaging and equivariance.