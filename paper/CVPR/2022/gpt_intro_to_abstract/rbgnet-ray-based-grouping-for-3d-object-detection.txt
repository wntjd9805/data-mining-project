3D object detection in computer vision has gained significant attention as a fundamental technique for understanding 3D scenes. This technique plays a crucial role in various applications such as autonomous driving, augmented reality, and domestic robots. Unlike 2D image problems, 3D scenes are represented by unordered and irregular point clouds captured by depth sensors, making it distinct from traditional input data. Existing approaches for 3D detection can be classified into grid-based methods and point-based methods. Grid-based methods transform irregular points into regular data structures, while point-based methods directly extract features from the irregular points. However, these point-based methods have not fully explored the fine-grained surface geometry of objects to improve detection performance. This paper proposes a new 3D detection framework called RBGNet, which incorporates ray-based feature grouping and foreground biased sampling strategies to enhance feature representation and allocation of foreground object points. The ray-based feature grouping module captures object surface points using rays emitted from cluster centers, with anchor points densely sampled on each ray. The features of these anchor points are utilized to learn the object's surface geometry shape and aggregated to predict 3D bounding boxes. The foreground biased sampling module focuses sampling on object surface points by using a segmentation head to separate foreground and background points. By incorporating these modules, RBGNet outperforms state-of-the-art methods in terms of 3D object detection accuracy. This research contributes to the advancement of 3D object detection in computer vision.