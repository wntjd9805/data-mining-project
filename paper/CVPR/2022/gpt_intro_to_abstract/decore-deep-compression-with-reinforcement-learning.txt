Deep neural networks (DNNs) have revolutionized image recognition tasks, but their large size poses challenges for deployment in embedded systems or mobile devices. To address this issue, researchers have focused on reducing the inference time and memory consumption of large models. One approach is network compression, which can be achieved through non-structured or structured pruning. While existing methods have made progress, they often require manual design and lack automation. This paper introduces DECORE, a multi-agent reinforcement learning framework for network compression. DECORE assigns agents to each channel in the network, allowing them to learn which channels are important and should be retained. Agents optimize their policies using the REINFORCE algorithm to maximize compression without significantly impacting accuracy. The proposed approach achieves high compression and FLOPs reduction rates while improving accuracy compared to existing methods. Experimental results on CIFAR-10 and ImageNet datasets demonstrate the effectiveness of DECORE in finding important channels and achieving better compression and acceleration rates.