Humans have the ability to quickly learn new tasks based on prior knowledge. Meta-learning algorithms aim to learn relevant knowledge from various tasks and generalize to unseen tasks with few samples. Two popular meta-learning algorithms, MAML-based models and Neural Processes (NPs), have shown promising results in domains such as few-shot classification and hyperparameter optimization. However, there has been limited research on meta-learning for vision regression tasks, particularly in high-dimensional input tasks. This paper proposes an improvement to NPs by employing contrastive learning at the functional space (FCL) and introduces two application datasets for object discovery and pose estimation. The performance of the proposed algorithmic improvements on the Distractor and pose estimation tasks is evaluated, demonstrating enhanced task expressivity and successful prediction of poses of unknown objects. The paper also analyzes the effect of different techniques commonly used in meta-learning algorithms on the proposed datasets, finding that overfitting is a challenge regardless of dataset size. The study shows that Conditional Neural Processes (CNPs) are more flexible and efficient than MAML in pose regression tasks and that MAML suffers from underfitting on large-scale datasets. The contributions of this work include investigating meta-learning algorithms on vision regression tasks, proposing functional contrastive learning for CNPs, and providing insights and recommendations for designing and implementing meta-learning algorithms for vision regression tasks.