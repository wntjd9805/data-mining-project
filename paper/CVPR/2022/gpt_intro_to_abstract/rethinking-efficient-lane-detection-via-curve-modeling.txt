Lane detection is a crucial task in autonomous driving systems, aiding in decisions related to lane-keeping, centering, and changing. Previous methods have relied on expensive sensors such as LIDAR, but recent advancements in deep learning have led to the development of lane detection methods using RGB inputs from front-mounted cameras. These methods can be categorized into segmentation-based, point detection-based, and curve-based approaches. While segmentation-based and point detection-based methods have achieved state-of-the-art performance, they often rely on indirect representations of lane lines, requiring heavy computations or large numbers of heuristic anchors. On the other hand, curve-based methods that model lane lines as holistic curves have struggled to match the performance of other techniques. In this paper, we propose a state-of-the-art curve-based lane detector by leveraging classic cubic B´ezier curves, which offer sufficient freedom in parameterization while maintaining low computational complexity and high stability. We optimize the model by learning on-image B´ezier control points using the bipartite matching loss, eliminating the need for post-processing steps or hand-crafted heuristics. To capture the global structure of driving scenes, we introduce a feature flip fusion module that exploits the symmetry of lane lines observed from front-view cameras. Extensive experiments demonstrate the effectiveness, speed, and accuracy of our method on popular benchmark datasets, surpassing existing methods. Our contributions include the novel B´ezier curve-based deep lane detector, the deformable convolution-based feature flip fusion module, and the superior performance on the LLAMAS benchmark using the light-weight ResNet-34 backbone.