Visual gait recognition, which focuses on identifying individuals based on their walking patterns in videos, has been extensively studied for over two decades. Existing approaches and datasets primarily use 2D representations of gait such as silhouette sequences and Gait Energy Images. However, the human body is a 3D non-rigid object, and projecting it onto a 2D space results in the loss of valuable information regarding shapes, viewpoints, and dynamics, leading to ambiguity in gait recognition. This paper addresses the neglected area of 3D gait recognition, which retains the shapes and viewpoints of the human body in the 3D space. Deep learning-based methods have achieved state-of-the-art performance on 2D gait recognition benchmarks, but they struggle in complex real-world scenarios with diverse 3D viewpoints and environmental interference factors. While some works have utilized 3D models, such as 3D cylinders or skeletons, these models also discard essential information. Fortunately, recent advancements in parameterized human body models and 3D human mesh recovery allow for the estimation of precise 3D meshes and viewpoints in video frames. This paper proposes a novel 3D gait recognition framework called SMPLGait, based on the Skinned Multi-Person Linear (SMPL) model. The framework consists of two branches, one utilizing silhouette sequences for appearance features and the other employing a 3D Spatial-Transformation Network (3D-STN) to learn 3D knowledge of viewpoint and shape from the 3D human mesh. The proposed framework effectively addresses the challenge of extreme viewpoint changes in real-world scenarios. To facilitate research in this area, the authors create the first large-scale 3D mesh-based gait recognition dataset, named Gait3D, containing 4,000 subjects with over 25,000 sequences captured from 39 cameras in an unconstrained indoor scene. Gait3D provides precise 3D human meshes, along with conventional 2D silhouettes and keypoints, enabling exploration of gait recognition using multi-modal data. The paper presents comprehensive experiments that evaluate existing 2D approaches and demonstrate the effectiveness of the proposed SMPLGait method, highlighting the potential of 3D representations for gait recognition. Additionally, the combination of 3D and 2D representations further enhances performance, emphasizing the complementarity of multi-modal representations.