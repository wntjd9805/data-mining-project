Convolutional neural networks (CNNs) have become the leading method for image understanding tasks in computer vision. However, as CNNs have grown in complexity with hundreds of convolutional layers, they require a large number of floating point operations (FLOPs) and are not optimized for real-time applications on mobile devices. In recent years, researchers have developed various methods to reduce the computational cost of CNNs, but there is still a need for further improvement.One approach that has shown promise is exploiting the temporal similarity found in video inputs from surveillance cameras or webcams. By reusing results from previous frames in unchanged regions, the computational cost of CNNs can be greatly reduced. Additionally, small updates can be truncated to maintain sparsity in activation throughout the network without sacrificing accuracy. However, leveraging data sparsity efficiently with actual hardware remains a challenge, as specialized inference hardware and GPUs are less efficient for processing sparse activations.In this paper, we introduce DeltaCNN, the first fully sparse CNN optimized for GPUs. DeltaCNN achieves real speedups in practice and outperforms the state-of-the-art dense inference method cuDNN by up to 7x. We propose a novel kernel design involving masks and caches to address memory bandwidth and control flow issues in sparse neural networks. We also provide the first GPU implementation of CNN operators for sparse input and output, which we make open source.Our evaluations on three GPU architectures demonstrate that DeltaCNN is efficiently implemented, matching the speed of cuDNN without sparsity. In sparse mode, we achieve significant speedups up to 7x over cuDNN. This work contributes a new approach to reducing the computational cost of CNNs by leveraging data sparsity and demonstrates the potential for real-time applications on mobile devices.