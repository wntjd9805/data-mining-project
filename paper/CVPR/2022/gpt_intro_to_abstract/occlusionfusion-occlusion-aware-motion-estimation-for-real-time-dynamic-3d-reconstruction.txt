Dynamic 3D reconstruction has become increasingly popular with advancements in sensing and computing technologies. It allows for the reconstruction of shape, motion, and appearance of recorded objects, enabling various applications such as 3D design, video games, virtual reality, and augmented reality. Fusion-based methods have emerged as a new technological trend, offering the ability to handle different targets without requiring geometry templates or class-specific motion priors. These techniques can be achieved in real time using a single consumer sensor.However, there is a quality gap between online and offline methods in single view-based solutions. Online methods lack reliable temporal correspondences, leading to limited accuracy in motion estimation and difficulties in tracking long sequences or challenging motions. On the other hand, offline methods deliver more accurate results but come with higher computational complexity.To address this gap, we propose OcclusionFusion, a real-time dynamic 3D reconstruction system that achieves state-of-the-art accuracy comparable to offline methods. This is accomplished by efficiently exploiting spatial and temporal motion priors. We introduce a neural network trained to estimate full 3D motions of objects, including occluded surfaces, using the motion of visible regions and historical information. By obtaining the full object motion between consecutive frames without extensive correspondence computation or long-range correspondences, we improve real-time performance.To estimate the motion of occluded regions, we utilize a light-weight graph neural network that integrates motion information of visible regions and historical data through a long short-term memory (LSTM) module. Unlike previous approaches, our method avoids heavy computation and memory costs associated with 3D convolution-based networks. Additionally, we model per graph node motion using a Gaussian distribution, improving motion prediction accuracy and providing confidence for the reconstruction module.In summary, our contributions include the development of a robust real-time dynamic 3D reconstruction system with a light-weight graph neural network for full 3D motion estimation. Our method outperforms state-of-the-art offline methods and leverages spatial and temporal information through an LSTM structure. We also introduce per node motion confidence estimation using a Gaussian distribution, enhancing reconstruction system robustness.