The rapid advancement of generative adversarial networks (GAN) in computer vision has enabled the generation of realistic facial images. However, this technology can be misused for malicious purposes such as creating fake news or falsifying evidence. As a result, there is a growing need for deepfake detection techniques. While previous detection methods have performed well in detecting forgeries they were trained on, their performance significantly drops when faced with cross-dataset scenarios where fake samples are forged using unknown manipulations.One effective solution to address this issue is to train models with synthetic data, which enables them to learn more generic representations for deepfake detection. Existing methods have used techniques such as blurring facial regions or generating blended images to reproduce relevant artifacts. However, these methods have limitations, as the quality of deepfakes has improved over time, rendering some of these techniques ineffective. Additionally, low-quality videos in challenging datasets further hinder accurate detection.In this paper, we propose a novel approach, called self-blended images (SBIs), as synthetic training data for deepfake detection. Our method leverages the generation of face forgery traces to encourage models to learn more general and robust representations. We analyze forged faces and define four typical artifacts, including landmark mismatch, blending boundary, color mismatch, and frequency inconsistency. To synthesize these artifacts, we develop a source-target generator (STG) and a mask generator (MG). STG generates pseudo source and target images from pristine images, while MG generates blending masks from facial landmarks. By blending the source and target images with the masks, we create SBIs. Notably, our method improves computational efficiency by avoiding the computational cost associated with landmark nearest search used in previous works.We evaluate our approach on multiple datasets using two evaluation protocols: cross-dataset evaluation and cross-manipulation evaluation. In the cross-dataset evaluation, our method outperforms or is at least comparable to state-of-the-art methods on all test sets, including those with domain gaps between training and test sets. In the cross-manipulation evaluation, our approach achieves high AUC scores on various unseen manipulation methods, demonstrating its generality.Overall, our proposed method of using SBIs for deepfake detection shows promising results in terms of accuracy and efficiency, making it a valuable contribution to the field.