The success of deep learning depends on abundant training data and computational capability. When computational resources are limited, distributed learning can be used, where data is distributed across multiple clients and part of the learning process is performed within each client. In such environments, the details of the localized data are often hidden to enhance data privacy and security, and the server aggregates only encapsulated information communicated from clients. This paper focuses on distributed gradient descent-based optimization as an example of such learning problems. The objective is to minimize a differentiable energy function by aggregating local gradients calculated by each client. However, some clients may exhibit abnormal behavior, resulting in unreliable local gradients and suboptimal learning. Existing approaches for robust distributed learning require additional training sets, information on the number of affected clients, or access to local data.To address this issue, we propose a new approach that combines local gradients in the presence of adversarial perturbation. Our algorithm uses the na¨ıve uniform average of gradients as a noisy observation and iteratively improves it during the gradient descent steps. We represent the combined gradient as a convex combination of all local gradients, with combination weights that are uniformly initialized. As the optimization proceeds, the genuine local gradients are automatically identified by adjusting the combination weights through simulating the diffusion of the combined gradient. Our approach does not require a separate training set, and it refines the gradient combination without knowing the number and identities of affected clients or the nature of perturbations.In experiments with benchmark datasets and different client perturbations, our approach outperformed the standard uniform gradient averaging algorithm and existing robust gradient combination approaches. This demonstrates the effectiveness and efficiency of our proposed method.