Semantic segmentation is a critical task in computer vision research that involves assigning a class label to each pixel in an image. Deep neural networks have shown great potential in achieving accurate segmentation models when large amounts of labeled training images are available. However, collecting these labeled images is a laborious and time-consuming process, which hampers further progress in semantic segmentation research. As a result, there has been increasing interest in semi-supervised semantic segmentation, which aims to learn from a combination of labeled and unlabeled images to address the image annotation challenge.Existing studies in semi-supervised semantic segmentation have primarily focused on applying consistency-training or self-training techniques to the unlabeled data. However, these approaches often suffer from limited segmentation accuracy due to the class imbalance present in the labeled data. This class imbalance leads to biased segmentation of the unlabeled data, negatively impacting the overall learning process. While some studies have attempted to address this issue by generating more pseudo labels for minority classes during self-training, these labels are often noisy due to the class-biased segmentation.This paper proposes an unbiased subclass regularization network (USRN) to tackle the class imbalance problem and produce class-unbiased segmentation by introducing an auxiliary segmentation task. The USRN leverages the segmentation backbone learned from the original class distribution and uses a set of class-balanced clusters as supervision to generate unbiased segmentations on the unlabeled data. These class-balanced clusters are obtained by clustering pixels of each original class into multiple subclasses of similar size. The USRN trained on these clusters achieves significantly more class-unbiased segmentation on the unlabeled data. Additionally, the paper addresses the issue of interference between the segmentation with original classes and generated subclasses by designing an entropy-based gate mechanism. This mechanism stops the learning process for the subclasses when their predictions are less confident than those of the original classes.Extensive experiments conducted on multiple public benchmarks demonstrate the effectiveness of the proposed network. The contributions of this work are threefold: 1) the introduction of the unbiased subclass regularization network to mitigate class imbalance in semi-supervised semantic segmentation, 2) the design of an entropy-based gate mechanism to coordinate the learning from original classes and generated subclasses, and 3) the empirical validation of the superiority of the proposed network over state-of-the-art approaches.