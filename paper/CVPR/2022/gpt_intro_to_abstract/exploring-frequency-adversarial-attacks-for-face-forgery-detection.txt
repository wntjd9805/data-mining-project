The study focuses on the growing problem of face forgery generation, which has both positive applications, such as virtual makeup and face editing in the film industry, and negative implications, particularly in terms of security and privacy. While various face forgery detection methods have been proposed, they are vulnerable to adversarial examples, which can trick the detectors into making incorrect decisions. Existing works have explored the robustness of detection methods but often fail to fool both humans and detectors simultaneously. Additionally, the frequency diversity between real and fake faces has been identified as an essential clue for detection. In response, the authors propose a frequency adversarial attack method that adds imperceptible perturbations in the frequency domain. By utilizing the discrete cosine transform (DCT) and inverse DCT, the proposed method avoids visual degradation of the images while achieving effective adversarial attacks. Furthermore, a hybrid adversarial attack that combines spatial and frequency attacks is proposed to enhance attack transferability. The proposed method is evaluated on both spatial-based and frequency-based face forgery detectors, demonstrating its effectiveness under different settings. The contributions of this study include the introduction of the frequency domain for adversarial attacks in face forgery detection, the exploration of a hybrid approach, and the validation of the proposed method through extensive experiments.