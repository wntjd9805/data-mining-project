This paper addresses the problem of category-level 9D pose estimation in the wild, which involves estimating the 3D position, orientation, and scale of novel objects. Existing methods for pose estimation have limitations, such as requiring exact object models and sizes beforehand or tedious real-world pose annotations. In this paper, the authors propose a novel voting scheme called Category-level PPF (CPPF) for 9D pose estimation. CPPF leverages point pair features (PPFs) and formulates the problem as a voting process, where each point pair generates offsets or relative angles towards ground-truth poses. The pose with the most votes is cast as the final prediction. CPPF is faster and able to generalize to unseen objects compared to traditional instance-level PPFs. To address orientation voting challenges, an auxiliary binary classification task is introduced. The authors also leverage an instance segmentation model to segment the point cloud of the target object and propose a two-stage coarse-to-fine voting method to robustly estimate the object pose. The proposed method is evaluated on a publicly available real-world dataset and outperforms sim-to-real state-of-the-art methods. Results also show that the method can give decent 9D pose predictions even with only bounding box detections. The generalization ability of the method is evaluated on the SUN RGB-D dataset with zero-shot transfer, where it outperforms baselines significantly. Overall, the contributions of this work include the proposed category-level voting scheme, a sim-to-real pipeline for generalizable pose estimation, and robustness to segmentation errors and limited annotations.