Time-of-Flight (ToF) imaging is widely used in various applications such as autonomous driving, face recognition, 3D sensing, and augmented/virtual reality. ToF imaging can be categorized into direct ToF (dToF) and indirect ToF (iToF) based on the working principle. iToF imaging, which encodes depth information in the phase of continuously modulated light, offers higher spatial resolution and lower cost compared to dToF imaging. However, existing iToF imaging suffers from low signal-to-noise ratio (SNR) in measurements, particularly in scenarios with strong ambient light or large distance attenuations. Previous research has proposed methods to improve SNR, such as using higher energy light sources or capturing more measurements, but these approaches come at the expense of increased power consumption or acquisition time. Recently, a ToF reconstruction network was proposed to enhance robustness to noise through post-processing, but without considering the influence of coding schemes. Other studies have designed coding functions that outperform commonly used ones, but their performance in low SNR scenarios is still limited. In this paper, we propose an information theory guided framework to jointly optimize the coding functions and the reconstruction neural network of iToF imaging. The framework incorporates a discriminative Fisher loss and a differential physical imaging model with learnable coding functions. By training the iToF imaging system using this approach, we achieve state-of-the-art performance, especially in low SNR scenarios. Our contributions include introducing a Fisher-information guided learning framework, modeling the physical constraints of iToF imaging, constraining coding functions with a discriminative Fisher loss, and building a prototype iToF imaging system with optimized coding functions. Through simulation and experimental comparisons, we demonstrate the superiority of our learned iToF imaging method.