The Generative Adversarial Network (GAN) is a popular generative model used for high-resolution image generation. However, it has drawbacks such as difficulty in capturing long-range dependencies and understanding global structure. In this paper, we propose Styleformer, a generator that utilizes style vectors based on the Transformer structure. Unlike CNNs, Styleformer uses self-attention operation to efficiently capture long-range dependencies and understand global structure. We introduce three models: Styleformer, Styleformer-L, and Styleformer-C. Styleformer enhances the multi-head attention in the original Transformer and introduces novel attention style injection modules. Styleformer-L addresses scalability limitations by applying Linformer, enabling the generation of high-resolution images with linear computational costs. Styleformer-C combines Styleformer and StyleGAN2, resulting in compositional scene generation. Our experiments show that Styleformer achieves comparable performance to state-of-the-art models and excels in multi-object image generation. Additionally, Styleformer-C outperforms pure StyleGAN2 in terms of performance metrics.