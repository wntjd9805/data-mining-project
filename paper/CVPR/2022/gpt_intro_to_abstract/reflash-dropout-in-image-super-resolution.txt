Image super-resolution (SR) is a task that aims to restore a high-resolution image from a low-resolution input. Deep SR networks have achieved impressive results in a synthetic environment, but their success in real-world images is limited. Blind SR methods have been developed to handle unknown downsampling kernels or degradations. While recent advances have improved data diversity and model capacity, the training strategy has not been optimized. This paper proposes the use of dropout, originally designed to prevent overfitting in high-level vision tasks, to improve the performance of SR models. The conflict between dropout and SR is addressed by studying its usage in conventional non-blind settings. Detailed guidance for using dropout in SR is provided, along with experimental results showing significant performance improvements. Addition of dropout code incurs no extra computation cost. The paper also introduces channel saliency map and deep degradation representation as novel interpretation tools to analyze the behavior of dropout. The results support the effectiveness of dropout in improving the generalization ability of SR networks and can inspire better training strategies in the future.