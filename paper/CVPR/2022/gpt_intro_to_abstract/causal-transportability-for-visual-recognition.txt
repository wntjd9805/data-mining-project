Visual recognition systems heavily rely on visual representations, which are learned from large image datasets using convolutional networks. These representations have greatly improved image classification tasks. However, a major challenge is the ability to generalize to new visual distributions at inference time. The most common technique is to fine-tune the backbone model or fit a linear model on the target classification task. Although effective on in-distribution benchmarks, this approach inherits biases from the target dataset, as every realistic image dataset contains spurious features that impact the generalization of computer vision systems. In this paper, we explore object recognition visual representations through the lens of causality. We propose a causal-transportability language to formally model and analyze confounding and structural invariances shared across different environments. We demonstrate how different environments select distinct robust and non-robust features when constructing input datasets. Standard classifiers tend to use spurious correlations, leading to poor generalization performance. We show that the association between image and label is not generally transferable across domains, but the causal effect remains invariant with respect to the features' distributions. This motivates us to leverage causal effects in image classification to provide stability and enable successful extrapolation under changing conditions. Extracting robust features from observational data is challenging due to unobserved confounding factors, but with mild assumptions, we can use causal and deep representations as proxies for identifying the causal effect. Our experimental results using supervised and self-supervised representations demonstrate improved performance when generalizing to new domains. Our approach is compatible with existing representations and does not require re-training, making it practical for deployment. Compared to standard techniques, our causally motivated approach achieves significant gains on various datasets. Our work emphasizes the importance of causal quantities in out-of-distribution image classification and presents an effective method for learning a domain-robust classifier. The code for our approach is available online.