Stereo matching is a crucial task in computer vision, used in applications such as augmented reality, robotics, and autonomous driving. Convolutional Neural Networks (CNNs) have shown impressive results for stereo matching, particularly on benchmark datasets. However, these networks typically require a large amount of labeled data for training. To address this challenge, many networks are initially trained on synthetic data but struggle to generalize to real-world scenarios. Fine-tuning using labeled data from the target domain can improve performance, but collecting such data can be difficult and expensive. The lack of generalization is due to networks relying on superficial shortcut features present in synthetic data. Previous approaches to remove shortcuts have relied on manually designed methods or assumptions about their identification. In this paper, we propose an information-theoretic approach to automatically restrict shortcut-related information from being encoded in the network's feature representations. We optimize an objective function based on the information bottleneck principle, combining the task loss with Fisher information to learn a generalizable stereo matching model. To efficiently approximate the optimization of the Fisher information loss, we introduce a novel loss term and perturbation technique called ITSA. Our empirical results demonstrate that stereo matching networks trained on synthetic data with ITSA can generalize well to realistic data without fine-tuning. The proposed framework is computationally efficient, model-agnostic, and can also be applied to other vision problems like semantic segmentation. Overall, our contributions include enhancing domain generalization and robustness in stereo matching networks, introducing a novel loss function, and demonstrating the application of the framework beyond stereo matching. The paper concludes with a discussion of related work, experimental results, and future directions.