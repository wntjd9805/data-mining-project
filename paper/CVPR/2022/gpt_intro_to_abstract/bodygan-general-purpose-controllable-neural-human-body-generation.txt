Realistic human body image generation is a challenging problem in computer science. Existing methods for image synthesis often produce poor results with unnatural texture patterns, loss of details, and color distortions on human body parts. Some methods focus on generating face skin or faces based on contour sketches, but they are not suitable for generating human body images due to the flexible articulated structure of the body.Recent GAN-based methods have attempted to disentangle pose and appearance in human body image synthesis, but they often require paired training images and lack robustness in handling images with various poses and appearances. To address these limitations, this paper proposes BodyGAN, a highly controllable framework for human image synthesis. BodyGAN focuses on generating pure human body images with explicit control over poses, body shapes, and skin colors, which can be modified to meet downstream tasks such as virtual try-on.BodyGAN utilizes a pose encoding branch and an appearance encoding branch to generate condition maps for image synthesis. The pose encoding branch includes subnet-works that obtain semantic segmentation, 3D surface information, and key points of the human body. The appearance encoding branch generates condition maps for different body parts. By disentangling pose and appearance based on these condition maps, BodyGAN achieves finer control over image synthesis compared to existing methods.The generated condition maps are then fed into a generator model that is optimized through adversarial learning. Unlike existing methods, BodyGAN does not require paired training images, making it applicable to various image datasets. Experimental results demonstrate that BodyGAN can generate realistic and visually-pleasant human body images, even with difficult poses. The paper also presents downstream applications of BodyGAN in image manipulation, such as virtual try-on and digital humans.Overall, BodyGAN provides a novel approach to human body image generation with explicit control over multiple factors. Its effectiveness is validated through extensive experiments and its potential applications in computer animation.