Object perception often involves the decomposition of an object into its parts and their relationships. This structural abstraction can be reflected in natural language descriptions of objects. In this paper, we explore the interplay between language and geometry and how it can guide the learning of shape structure and parts. Previous work has shown that neural networks can learn to depend on part-related words and corresponding visual parts of objects, even without direct part information during training. Motivated by this observation, we investigate how well a neural network can connect part names in language utterances to specific regions in the geometry of 3D shapes. We demonstrate that semantic part segments can be discovered on the geometry solely using referential language data. We propose a framework based on a variant of the neural listener pipeline, employing a Transformer-based attention module to learn the region corresponding to each part described in the utterance. Our experimental results show that the architecture components significantly improve part segmentation performance. We also show that additional information on part names can be leveraged for better part detection and segmentation. Furthermore, we demonstrate that our network can generalize to out-of-distribution categories of shapes. This work suggests a new potential way to collect data for object part segmentation by utilizing language descriptions, which could be a more cost-effective and natural alternative to manual annotations.