Lidars and cameras are two complementary sensors widely used in autonomous driving for 3D object detection. While lidars provide low-resolution shape and depth information, cameras offer high-resolution shape and texture information. Most current state-of-the-art 3D object detectors solely rely on lidar input, indicating that effectively fusing the signals from both sensors remains a challenge. In this paper, we aim to provide a generic and effective solution to this problem. Existing approaches in the literature for fusing lidars and cameras adopt either early-stage fusion or mid-level fusion. However, a major challenge in both approaches is establishing the correspondence between lidar and camera features. To address this issue, we propose two methods: InverseAug and LearnableAlign. InverseAug reverses geometric-related data augmentations and associates the two modalities using original camera and lidar parameters. LearnableAlign utilizes cross-attention to dynamically learn the correlation between lidar and camera features. These techniques are simple, generic, and efficient. We develop a family of multi-modal 3D detection models called DeepFusions, which can be trained end-to-end and are compatible with existing voxel-based 3D detection methods. DeepFusion can be easily integrated into popular 3D point cloud detection frameworks. In extensive experiments on the Waymo Open Dataset, we demonstrate that effective deep feature alignment is crucial for multi-modal 3D object detection. DeepFusion, with improved alignment using InverseAug and LearnableAlign, significantly enhances detection accuracy and robustness against input corruptions and out-of-distribution data. DeepFusion outperforms several prevalent 3D detection models, achieving state-of-the-art results and showing significant improvements in recognition and localization for long-range objects. Our contributions include a systematic study on the influence of deep feature alignment for 3D multi-modality detectors, the proposal of InverseAug and LearnableAlign for accurate and robust deep-feature-level alignment, and the development of DeepFusions models that achieve state-of-the-art performance on the Waymo Open Dataset.