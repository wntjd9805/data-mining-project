Estimating 3D poses of multiple persons from a single RGB image is a challenging task in computer vision with numerous applications in AR/VR, gaming, and human-computer interaction. Prior works have addressed this task using two-stage strategies, either adopting a top-down scheme or a bottom-up scheme. However, these methods suffer from redundant computation and complex postprocessing due to the sequential management of person position and body joint localization. To address these issues, we propose a Distribution-Aware Single-stage (DAS) model for multi-person 3D pose estimation. DAS represents the 3D pose with a 2.5D human center and 3D center-relative joint offsets, enabling direct depth prediction and unifying the localization of person position and body joints. DAS also learns the true distribution of body joints using a recursive update strategy to improve regression-based performance. In experiments, DAS outperforms two-stage models in efficiency and achieves superior accuracy compared to state-of-the-art methods. Our contributions include presenting a single-stage model for multi-person 3D pose estimation, introducing a distribution-aware approach for body joint regression, and setting new state-of-the-art results on benchmark datasets.