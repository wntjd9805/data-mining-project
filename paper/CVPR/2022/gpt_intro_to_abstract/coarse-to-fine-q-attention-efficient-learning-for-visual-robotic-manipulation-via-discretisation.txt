This paper introduces a novel approach for real-world manipulation tasks using a small number of demonstrations and sparsely-rewarded exploration data. The two paradigms of imitation learning (IL) and reinforcement learning (RL) are explored, with IL suffering from compounding error and RL requiring long training times. The ARM system, which utilizes Q-attention, is shown to bypass these flaws in RL. However, the next-best pose agent in ARM follows an unstable actor-critic paradigm, particularly for learning from sparsely-rewarded and image-based tasks. In this paper, a more stable discrete action Q-learning approach is proposed, and the challenge of effectively discretizing 6D poses is addressed through a coarse-to-fine Q-attention method. The resulting Coarse-to-Fine Attention-driven Robotic Manipulation (C2F-ARM) system is benchmarked against other robot learning algorithms, demonstrating its sample efficiency and stability. Moreover, C2F-ARM is capable of learning diverse sets of real-world tasks from just 3 demonstrations. This paper presents three contributions: a novel way to discretize the translation space, the C2F-ARM manipulation system, and the first use of a voxel representation for vision-based reinforcement learning in 6D robot manipulation. Supplementary material including code and videos can be found online.