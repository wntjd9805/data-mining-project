Visual object tracking is a fundamental task in computer vision, with applications in human-computer interaction and visual surveillance. Designing a simple yet effective end-to-end tracker is challenging due to scale variations, object deformations, occlusion, and confusion from similar objects. Current trackers have a multi-stage pipeline, but traditional integration methods have limitations in incorporating target information. This paper proposes MixFormer, a compact tracking framework that combines feature extraction and target integration using a transformer-based architecture. The proposed Mixed Attention Modules (MAM) perform both feature extraction and mutual interaction of target template and search area simultaneously. The MixFormer backbone is constructed using Patch Embedding and MAM layers, with a simple localization head. The framework achieves state-of-the-art performance on multiple benchmarks, demonstrating its effectiveness and efficiency in tracking tasks. The contributions include the introduction of MixFormer, the customized asymmetric attention for template update, and the improved performance on challenging benchmarks.