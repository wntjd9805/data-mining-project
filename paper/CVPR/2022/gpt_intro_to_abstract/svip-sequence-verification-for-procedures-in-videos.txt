In recent years, the widespread dissemination of short-form videos on social media has enabled the research on video understanding. Many daily activities are accomplished through sequential steps, forming a procedure with key steps that exhibit intrinsic consistency. However, different participants may accomplish the same activity using different procedures, resulting in step-level divergence. In this paper, we propose a novel action task called sequence verification, which aims to verify whether the procedures in two videos are step-level consistent. This task has various potential applications, such as instructional training and performance scoring. We introduce specific terms to define the components of this task, including steps, procedures, tasks, and videos. Traditional action tasks in computer vision, such as action recognition and action segmentation, have limitations in predefined categories and the need for intensive step annotations. In contrast, our proposed sequence verification task overcomes these limitations by verifying video pairs based on their distance in the embedding space, thus enabling an open-set setting. We emphasize that sequence verification focuses on action step association rather than background distinction. To perform this task effectively, an appropriate dataset is essential. Existing video datasets for action recognition or action segmentation do not specifically collect videos that perform similar or identical procedures. Therefore, we rearrange existing datasets and introduce a new scripted filming dataset to address this gap. Additionally, we propose a new evaluation metric called Weighted Distance Ratio to ensure fairness in evaluating negative pairs with different step-level differences. Although off-the-shelf action detectors can be used for sequence verification, their performance on existing datasets is not satisfactory for step-level detection. Hence, we propose a baseline model called CosAlignment Transformer (CAT) that leverages 2D convolution and a transformer encoder to align steps via cosine similarities. Experimental results demonstrate that our proposed method outperforms other action recognition methods in the sequence verification task. The contributions of this paper include the proposal of the sequence verification task, the rearrangement of datasets to support this task, the introduction of a new evaluation metric, and the development of an effective baseline model.