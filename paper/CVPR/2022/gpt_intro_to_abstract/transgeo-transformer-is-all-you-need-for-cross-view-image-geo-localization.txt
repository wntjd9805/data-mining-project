Image-based geo-localization is a crucial task in computer vision, with applications in GPS correction and navigation in crowded cities. Existing methods for cross-view geo-localization, which use aerial images as reference, suffer from the domain gap between street and aerial views. To address this, recent works have applied a polar transform on aerial images to align them with street-view query images. However, this approach relies on prior knowledge of the geometry and may fail in certain scenarios. In this paper, we argue that vision transformers are better suited for cross-view geo-localization due to their ability to encode position information, model global long-range correlations, and allow for non-uniform cropping. We propose TransGeo, the first pure transformer-based method for cross-view geo-localization, which incorporates Adaptive Sharpness-Aware Minimization (ASAM) to improve model generalization. We also introduce an attention-guided non-uniform cropping strategy that removes uninformative patches in reference images and reallocates computation to informative regions. Our method achieves state-of-the-art performance with lower computation cost and GPU memory consumption compared to CNN-based methods.