Convolutional neural networks (CNNs) have significantly improved visual object detection in the past decade, but they suffer from performance loss when applied to unseen scenes due to domain shift. Domain adaptive object detection (DAOD) has gained attention as a solution to this problem, aiming to transfer knowledge from a source domain to a target domain without labeled data. Existing methods address DAOD through adversarial feature alignment or semi-supervised learning. However, multi-source domain adaptation (MSDA) is a more practical scenario, and it has been less explored in detection. This paper proposes a novel target-relevant knowledge preservation (TRKP) approach for multi-source DAOD. The approach utilizes a teacher-student network, where a multi-head teacher network extracts knowledge from labeled source domains and mentors the student network on building detectors in the unlabeled target domain. To preserve source domain-specific knowledge, an adversarial multi-source disentanglement (AMSD) module is introduced. In addition, a holistic target-relevant mining (HTRM) scheme is developed to enhance the acquisition of target-relevant knowledge from different sources. Experimental results demonstrate that the proposed TRKP approach outperforms existing methods on public benchmarks and achieves a good baseline on a harder scenario with more sources. The contributions of this study include the introduction of a teacher-student network for multi-source DAOD, a target-relevant mining procedure to measure source-target relevance, and significant performance improvement in comparison to existing methods.