Video anomaly detection (VAD) has been a valuable topic in computer vision, with applications in fields like public security and city management. However, VAD remains a challenge due to the rarity and novelty of anomalies, making them hard to predict or enumerate. Classic VAD follows a semi-supervised setup, where a normality model is trained using only normal videos and anomalies are detected as events that do not fit this model. However, labeling a training set with pure normal events can be tedious and labor-intensive. To address this issue, unsupervised VAD (UVAD) aims to discover anomalies directly from unlabeled videos. Existing UVAD methods suffer from limitations, including reliance on shallow models and hand-crafted feature descriptors, as well as inferior performance compared to classic VAD methods. In this paper, we propose a novel deep neural network (DNN) based solution for highly effective and fully end-to-end UVAD. We introduce the concept of deep reconstruction and unveil the property of "normality advantage." We design a localization based reconstruction (LBR) method as a baseline for our solution. We also introduce a self-paced refinement (SPR) scheme to consolidate normality advantage and enable more proactive UVAD. Additionally, we design a motion enhanced solution that considers motion cues for improved detection capability. Experimental results demonstrate the superiority of our solution compared to existing UVAD methods and achieve comparable performance to recent classic VAD methods on mainstream benchmarks.