In this paper, we address the challenges in gait recognition by focusing on the motion information of pedestrians' walking patterns. While existing appearance-based methods rely on visual appearance, we argue that distinguishing individuals based solely on appearance is difficult, particularly when the view angle is close. Therefore, we propose the use of second-order motion features, in addition to first-order motion features, to represent gait.We introduce a novel motion-assisted gait recognition method that incorporates Lagrange's Equation to model human walking. This analysis helps us conclude that second-order motion features are necessary to effectively represent gait. We propose a second-order Motion Extraction Module to extract these features from high-level feature maps.To address the impact of viewpoint differences, we also introduce a view-aware embedding method. This method reduces the negative effects of changes in view by considering the intrinsic motion and appearance of silhouette sequences. Our proposed multi-branch framework combines view, appearance, and intrinsic motion information.We conduct experiments on the CASIA-B and OU-MVLP datasets to validate the effectiveness of our proposed method. The results show that our model effectively narrows the intra-class distance caused by view variance. Additionally, we provide visualizations to further support the validity of our approach.Overall, the contributions of this paper include the modeling of human walking using Lagrange's Equation, the proposal of a second-order Motion Extraction Module, the introduction of a view-aware embedding method, and the verification of our method's effectiveness through experiments on popular datasets.