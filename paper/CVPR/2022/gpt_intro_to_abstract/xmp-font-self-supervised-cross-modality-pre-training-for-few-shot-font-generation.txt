The few-shot font generation (FFG) task aims to create a new font library with minimal reference glyphs, without fine-tuning the model during testing. This is particularly useful for designing font libraries for glyph-rich scripts such as Chinese, where manual font design is time-consuming. Previous methods disentangle font-specific style and content information from reference glyphs to synthesize new glyphs. However, universal style representations have limited capabilities, and learning component-wise styles is insufficient for component-rich glyphs like Chinese characters. To address these challenges, we propose using stroke labels instead of component labels to represent character structure and introduce a cross-modality transformer-based encoder conditioned on glyph images and stroke labels. Additionally, we propose a style-content decoupling network and an LSTM-based stroke loss to enhance the reliability of the model. Experimental results show that our method outperforms previous FFG methods, achieving successful font style transfer with only one reference glyph. Our contributions include introducing cross-modality transformer-based encoder and cross-modality pre-training, a style-content decoupling network, and a novel stroke loss based on LSTM. The model demonstrates powerful generalizability to unseen font domains and successful generation of novel glyphs based on minimal reference examples.