In this paper, we investigate the use of directed distance fields (DDFs) as a representation for three-dimensional shapes in computer vision and machine learning systems. DDFs capture detailed geometry information, including higher-order differentials and internal geometry, and can be efficiently rendered using differentiable techniques. Unlike other implicit shape or radiance-based approaches, DDFs can be trained with depth data and easily composed. They also allow for the extraction of classical unsigned distance fields. We define DDFs as a mapping from position and orientation to visibility and distance, and propose a probabilistic variant for modeling surface and occlusion discontinuities. We demonstrate the usefulness of DDFs in shape fitting, single-image reconstruction, and generative modeling tasks. Our method enables fast differentiable rendering while preserving high-fidelity geometric information, making it suitable for a variety of downstream applications. We provide proofs of several geometric properties of DDFs and showcase their versatility and effectiveness in our experiments.