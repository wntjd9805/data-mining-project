Garment transfer is a challenging problem in human-centric image generation, with significant commercial potential. Existing methods for garment transfer have limitations in handling in-the-wild scenarios, arbitrary garments, and complex poses. This paper proposes a novel approach called wFlow that combines the advantages of 2D pixel flow and 3D vertex flow. A robust garment transfer network is developed using a self-supervised training scheme based on easily obtainable dance videos. The wFlow model can generalize well to transfer garments between different persons by adding protected body parts to guide the network. The proposed method leverages conditional segmentation, pixel flow estimation, and 3D vertex flow to generate warped garments. Additionally, an inpainting network is used to fuse the warped garment with the query background. The proposed method can handle arbitrary garments and challenging posed query persons. The paper presents three main contributions: exploring in-the-wild garment transfer using self-supervised training, introducing the wFlow method for arbitrary garment transfer under complex poses, and constructing a large-scale video dataset called Dance50k for human-centric image/video processing.