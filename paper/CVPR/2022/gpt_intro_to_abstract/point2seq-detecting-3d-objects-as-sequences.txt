This paper introduces Point2Seq, a flexible and streamlined framework for 3D object detection from point clouds in self-driving systems. Traditional methods for 3D object detection rely on complex hand-crafted procedures and suffer from misalignment between object locations and pixel features. Point2Seq addresses these challenges by representing each object as a sequence of words and using a scene-to-sequence decoder to progressively predict each attribute of 3D objects. The decoder is compatible with existing 3D detection pipelines and can generate sequences for all objects in parallel. To optimize the detector, a similarity-based sequence matching scheme is proposed for automatic assignment of predicted sequences to ground truths. Experimental results demonstrate that Point2Seq outperforms anchor-based and center-based 3D detectors, achieving high mean average precision on the ONCE dataset and vehicle L1 mAP on the Waymo Open Dataset. The framework provides a more accurate and efficient approach for 3D object detection in self-driving systems.