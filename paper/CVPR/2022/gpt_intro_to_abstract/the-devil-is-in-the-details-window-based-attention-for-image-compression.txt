Image compression is an essential area of research in image processing, particularly with the increasing need for efficient storage of images and videos. While classic compression standards like JPEG and JPEG2000 have been widely used, they rely on manual rules and may not provide optimal solutions. In recent years, learned image compression methods based on variational auto-encoders (VAE) have shown promising results in terms of rate-distortion performance.The general pipeline of VAE-based methods involves encoding the images using a parametric analysis transform to map them to a latent code space. After quantization, entropy estimation modules predict the distributions of latents, and lossless compression techniques are used to compress the latents into a bit stream. On the decoding side, the bit stream is decompressed, and the reconstructed images are obtained by mapping the decompressed latents to the image space. Post-processing networks can also be incorporated to enhance the quality of reconstruction.One limitation of current convolutional neural network (CNN) based models is their focus on high-level global feature distillation rather than low-level local detail restoration. However, attention mechanisms, inspired by their success in natural language processing and computer vision tasks, have been used to guide the adaptive processing of latent features and improve rate-distortion performance. Transformer-based networks, which have shown competitive performance in vision tasks, have also been explored in image compression. While global attention can capture global dependency, it may not be as effective in image compression compared to spatially neighboring elements.This paper addresses the problem of detail missing in image compression by studying the combination of neural networks and attention mechanisms for designing local-aware architectures. Comparative experiments on global attention and local attention mechanisms confirm that local attention is more suitable for local texture reconstruction. The paper then introduces a flexible attention module called window-attention, which captures correlations among neighboring elements and can enhance CNN and Transformer models.Furthermore, the paper proposes a novel Symmetrical Transformer (STF) framework with absolute transformer blocks in both the encoding and decoding stages. This framework overcomes challenges such as the lack of up-sampling units and fixed attention models in transformer-based image compression. Extensive experiments demonstrate that the proposed methods outperform state-of-the-art image compression methods in essential metrics.In summary, this paper contributes to the advancement of image compression by studying local-aware attention mechanisms, introducing a flexible window-based attention module, and proposing a novel Symmetrical Transformer framework. The experimental results demonstrate the effectiveness of the proposed methods in improving rate-distortion performance.