Hand tracking is a crucial task in various applications, including gesture recognition, activity recognition, contact tracing, and skill evaluation. Traditional approaches consider hand tracking as part of human body tracking, relying on the tracked human pose. However, pose detection and tracking alone can be unreliable, particularly when dealing with partially occluded or out-of-view hands. Alternatively, off-the-shelf tracking methods have been explored for hand tracking. Unfortunately, single-object trackers are unsuitable for tracking multiple hands, while existing multiple-object tracking methods have not shown satisfactory performance for hands, despite their success in tracking pedestrians and vehicles.Hand tracking presents unique challenges due to the intricate articulation of hands and their frequent interactions with other objects. Hands are non-rigid objects, as their size, shape, location, and visibility can change dramatically and frequently within a few frames. Many existing multiple-object trackers adopt a detection and association paradigm, but hand detection is hindered by motion blur and occlusion, while linking hands across time is complicated as hands may undergo drastic changes in size, location, pose, and appearance. Furthermore, distinguishing between different hand instances is challenging, even for sophisticated re-identification modules trained specifically for hands.To address these challenges, this paper proposes a novel convolutional architecture called HandLer, short for Hand Linker, for detecting and tracking hands in unconstrained videos. HandLer takes two consecutive video frames at times t-1 and t as input and outputs the detected hands in frame t along with their corresponding locations in frame t-1. The proposed architecture consists of three stages: Forward Propagation, Detection and Association, and Re-identification. The Forward Propagation stage propagates features from frame t-1 to frame t based on the locations of previously detected hands and their estimated movements. The Detection and Association stage utilizes this propagated information to detect hands in frame t and associate them with their corresponding locations in frame t-1. Finally, the Re-identification stage handles the challenges of distinguishing between different hand instances.Experimental evaluations demonstrate the effectiveness of HandLer in detecting and tracking hands in unconstrained videos, overcoming the limitations of existing methods. This work contributes to the field of hand tracking by providing an advanced detection and association algorithm specifically designed for multiple hands and their complex dynamics in real-world scenarios.