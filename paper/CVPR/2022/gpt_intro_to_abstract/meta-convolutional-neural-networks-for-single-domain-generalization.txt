Deep learning models have become widely popular for vision tasks, assuming that training and testing data come from similar distributions. However, when applied to unseen or out-of-distribution (OOD) test domains, the performance of these models can be significantly degraded. Domain shift, caused by changes in illuminations, object appearances, or backgrounds, is a common problem. To address this issue, various domain adaptation and domain generalization methods have been proposed. This paper focuses on the problem of single domain generalization, where only one domain is available for training and the model needs to perform well on multiple unseen domains. Previous approaches to single domain generalization include data augmentation and regularization techniques. Data augmentation generates more diversified data from "fictitious" domains, while regularization methods develop losses for feature consistency between source and augmented data.This paper proposes a new convolutional model called Meta CNN to solve the single domain generalization problem. The model is inspired by stacked capsule autoencoders (SCAE), which segment images into parts and reconstruct them using general part templates. Similarly, the convolutional features of input images can be decomposed into universal and elemental visual features. These elemental features are used as "templates" to compose general representations of images in the trained domain. By addressing the domain gap using metadata normalization, the effect of domain shift in the input features is eliminated. This is achieved by feeding the composed meta features into the following convolutional operations.The challenge of applying compositional operations of meta features within a CNN building block lies in four main areas: local feature extraction, local feature addressing, meta feature composition, and meta feature learning. To overcome these challenges, the paper proposes a sliding window approach for local feature extraction, mapping local features to a combination of meta features, representing local patch features using a linear interpolation of meta features, and updating the meta features using regression analysis with maximum likelihood estimation.Extensive experiments on multiple benchmark datasets demonstrate the superiority of the proposed Meta CNN model in tackling single domain generalization problems. Furthermore, the results suggest the potential of convolutional meta features for general image representations.