The paper introduces a novel approach for rendering a sparse light field in order to synthesize novel views with photo-realistic modeling of non-Lambertian effects. The existing NeRF model has limitations in capturing these effects due to its neural architecture design. To address this, the proposed method leverages a multi-view geometric constraint, specifically the epipolar geometry, and a transformer-based ray fusion. The resulting model achieves higher fidelity renderings for both forward-facing and 360Â° captures, outperforming state-of-the-art techniques in challenging scenes. Additionally, the proposed method allows for obtaining dense correspondences and depth without modifications and provides transparent visualization of the rendering process. Ablation studies are conducted to demonstrate the significance of the design choices made.