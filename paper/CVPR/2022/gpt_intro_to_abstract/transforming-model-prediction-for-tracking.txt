Generic visual object tracking is a fundamental problem in computer vision, involving the estimation of the state of a target object in each frame of a video sequence. Discriminative Correlation Filters (DCF) have been successful in object tracking, learning a target model to localize the target by minimizing a discriminative objective function. However, DCFs have limitations in terms of flexibility and integrating learned priors. Transformers have shown strong global reasoning capabilities in multiple frame tracking. This paper proposes a novel tracking framework that combines the compactness of DCF with the power of Transformer-based model prediction. The proposed approach, called ToMP, achieves significant improvements in tracking performance compared to both DCF-based methods and recent Transformer-based trackers. The main contributions of this work include the development of a novel Transformer-based model prediction module, the extension of the model predictor for bounding box regression, the introduction of two novel encodings for target location and extent, and the proposal of a parallel two-stage tracking procedure for robust and accurate target detection. A comprehensive set of ablation experiments is conducted, and ToMP sets a new state-of-the-art performance on three tracking benchmarks, including LaSOT, where it achieves an AUC of 68.5%. Additionally, ToMP outperforms other Transformer-based trackers in every attribute of LaSOT.