Energy-based models (EBMs) are powerful generative models used in machine learning, which define a distribution by normalizing exponential negative energy. They have been successfully applied to visual tasks such as image synthesis, classification, out-of-distribution (OOD) detection, and semi-supervised learning. However, the effectiveness of energy-based latent variable models (EBLVMs) in solving computer vision problems is limited due to the doubly intractable model problem. Previous approaches leverage gradient-based Markov Chain Monte Carlo (MCMC) but require many steps and suffer from the high-dimensional image problem. To address these challenges, this paper introduces a Bi-level Doubly Variational Learning (BiDVL) framework. BiDVL formulates the problem as a bi-level optimization and utilizes tractable variational distributions to estimate gradients for maximum likelihood estimation (MLE). Theoretical analysis shows that BiDVL is equivalent to the original MLE objective under the nonparametric assumption. An efficient alternative optimization scheme is proposed for practical optimization. Additionally, a decoupled EBLVM and a symmetric KL divergence are used to improve stability in deep learning settings. Experimental results demonstrate remarkable performance in image generation, image reconstruction, and OOD detection.