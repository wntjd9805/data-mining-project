Efficiently searching for semantically similar images in massive image datasets is a challenging task. Hashing, which involves learning binary encodings of images for efficient discovery, has been widely applied in various domains. Supervised hashing methods, which leverage annotated similarity, have shown superior performance compared to unsupervised methods. However, existing supervised hashing methods still suffer from quantization error and coding imbalance, resulting in sub-optimal hash codes. This paper proposes a faster and more performant quantization approach for deep supervised hashing methods. The proposed approach minimizes the distributional distance between the learned hash distribution and a uniform discrete distribution, achieving low quantization error and coding balance simultaneously. The paper also introduces a low computation-and sample-complexity Sliced-Wasserstein-based distributional distance. The effectiveness of the proposed quantization technique is demonstrated through experiments on various real-world datasets using both quantitative and qualitative performance analysis. The rest of the paper discusses related work, presents empirical analysis, details the proposed methodology, evaluates the approach's effectiveness, and concludes with remarks. Further experimental settings, results, and proofs are provided in the supplementary material.