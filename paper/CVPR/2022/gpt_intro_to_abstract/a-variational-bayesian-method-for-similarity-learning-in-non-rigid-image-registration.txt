Image registration is a crucial step in various computer science applications, such as statistical analysis of clinical imaging data, computer-aided diagnosis, and computer-assisted intervention. Traditional image registration methods minimize an energy function to calculate the necessary transformation. However, deep learning approaches for medical image registration have been difficult due to the lack of ground truth transformations. DLIR and VoxelMorph (VXM) utilize neural networks to learn a function that estimates a deformation field between input images, resulting in faster processing with comparable accuracy. It was previously believed that deep learning models for image registration were limited to self- and unsupervised learning, but recent work has shown the possibility of training generative models on synthetic images and segmentations. In this paper, a new model for atlas-based diffeomorphic non-rigid image registration is proposed. The model employs a neural network as a similarity metric, which is refined within a Bayesian framework. This Bayesian approach allows for learning a data-specific similarity metric with limited data, improves robustness, and enables quantification of output uncertainty. The contributions of this work include: 1) the introduction of a novel variational Bayesian method for unsupervised similarity learning in medical image registration, 2) demonstration of improved performance compared to traditional similarity metrics, 3) evidence of generalization ability, and 4) the estimation of voxel-wise uncertainty associated with the transformation.