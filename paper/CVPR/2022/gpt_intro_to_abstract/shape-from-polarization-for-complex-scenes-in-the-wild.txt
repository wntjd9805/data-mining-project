Accurate surface normal estimation is an important task in computer vision, with applications in segmentation, 3D reconstruction, and other areas. While various techniques exist for estimating surface normals, such as photometric stereo and active depth sensors, there are limitations in terms of range, noise, and complexity of scenes. In this paper, we focus on estimating surface normals from single polarization images for complex scenes in the wild. We leverage the changes in polarization of light to provide dense surface orientation cues. Unlike active sensors and object-level normal estimation techniques, polarization cameras are passive sensors and not constrained to a specific depth range, making them promising for accurate normal estimation in real-world scenarios. However, estimating normals from polarization images for complex scenes is challenging due to ambiguities, lack of scene-level training data, and the influence of viewing direction. To address these challenges, we construct a new real-world scene-level SfP dataset and propose novel designs in our model, including multi-head self-attention in a convolutional neural network, per-pixel viewing encoding, and a novel polarization representation. Our approach outperforms state-of-the-art methods in generating high-quality normal maps from single polarization images and generalizes well beyond the training data's depth range. Our contributions include the dataset, the best-performing approach for normal estimation from polarization in complex scenes, and the novel designs in our model.