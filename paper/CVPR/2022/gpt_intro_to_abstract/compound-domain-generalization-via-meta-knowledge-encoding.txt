The success of computer vision algorithms often relies on the assumption of independent and identically distributed (i.i.d.) training and test data. However, in practice, this assumption is frequently violated due to changes in environments, imaging devices, and selection biases. This has led to a body of research on Domain Adaptation (DA) and Domain Generalization (DG) to address the problem of generalizing models to out-of-distribution domains. Unlike DA, DG considers the challenge of generalizing a model trained on a source domain to an unseen target domain with different data statistics, without access to target domain data for retraining or fine-tuning.Most existing DG methods assume that the domain label of each source sample is known, which is not practical in many applications where multiple source domains need to be automatically divided and modeled. In this paper, the authors investigate the problem of compound domain generalization, where domain labels are unavailable for training. They propose a novel framework called COmpound domain generalization via Meta-knowledge ENcoding (COMEN) to address this challenge. COMEN aims to identify latent domain structure and model semantic correlations across domains.The authors introduce two stages of the COMEN framework. In the first stage, they propose a Style-induced Domain-specific Normalization (SDNorm) technique to reveal latent domains and learn domain assignment probabilities for each source sample. SDNorm is trainable and can be easily integrated into deep neural networks. In the second stage, based on the discovered latent domains, the authors use prototypes to model the relations among different semantic categories. They introduce two parallel modules, Prototypical Graph Reasoning (ProtoGR) and Prototypical Category-aware Contrastive Learning (ProtoCCL), to capture the topological structure of the semantic space and enhance the discriminability of different categories.The contributions of this work include introducing a practical compound DG setting without prior knowledge of domain labels, proposing the COMEN framework to jointly discover and model latent domains, and presenting two modules, ProtoGR and ProtoCCL, to encode semantic structures in the embedding space. Experimental results on four standard DG benchmarks demonstrate that COMEN outperforms state-of-the-art methods without the need for domain supervision.