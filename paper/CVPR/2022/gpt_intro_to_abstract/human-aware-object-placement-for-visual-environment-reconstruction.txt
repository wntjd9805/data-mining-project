Abstract: This paper focuses on the 3D reconstruction of both human bodies and scenes to facilitate behavior analysis and various computer graphics applications. Previous research has made progress in reconstructing 3D human bodies and scenes individually, but fails to consider the occlusion and interaction between humans and scenes. Recent work on human-scene interaction (HSI) attempts to estimate humans and scenes together, but requires a 3D scan of the full scene, which is often unrealistic and cumbersome. To address these challenges, the paper presents MOVER, a method that leverages HSI frames to estimate a plausible 3D scene and a moving human that interacts with the scene. MOVER takes multiple HSI frames, a 3D human mesh for each frame, and a 3D shape for each object detected in the scene as input. It produces a refined 3D scene by repositioning objects to be consistent with the estimated 3D human, while satisfying expected contacts and preventing inter-penetration. MOVER uses a novel optimization scheme that considers camera pose, ground-plane pose, and the size and position of objects, while taking into account various HSI constraints. These constraints include depth ordering, the movement of humans in free space, and contact between humans and objects. A comparison with existing methods shows that MOVER produces more accurate and realistic 3D scene layouts that satisfy the expected contacts while minimizing penetrations. Additionally, the paper finds that MOVER's estimated 3D scene can be used to refine human poses. Overall, the results suggest that estimating 3D scenes and humans from a single camera is challenging but synergistic, benefiting each other in the reconstruction process.