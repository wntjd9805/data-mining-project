This paper introduces a novel approach for automatic 3D scene painting, aiming to create realistic 3D scenes for virtual realism. The existing methods for 3D scene painting often rely on human labor or manual capture of real scenes, making it a challenging task. To address this issue, the proposed approach utilizes a 3D scene painting network that takes a 2D semantic map and a 3D coordinate map as input and generates a 2D image with realistic RGB colors. Training the network requires colored 3D scenes with semantic labels, which are difficult to acquire. To overcome this, the approach leverages techniques developed for 2D image synthesis. By rendering 2D maps of 3D coordinates and semantic labels and applying image synthesis, pseudo-ground-truth labels are generated for training the network. The proposed method offers several advantages, including the ability to generate high-quality textures, change the style of a scene, and provide detailed control over scene layouts and viewpoints. Furthermore, the approach opens a new research direction for cases where 3D scenes are provided. Experimental results demonstrate the success and controllability of the approach in producing high-quality colored scenes and images. The contributions of this work include the proposal of a novel 3D scene painting network, the ability to learn 3D scene painting without ground-truth colored 3D scenes, and the provision of detailed scene control.