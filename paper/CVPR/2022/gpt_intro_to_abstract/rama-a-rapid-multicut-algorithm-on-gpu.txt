Decomposing a graph into clusters is a fundamental problem in combinatorial optimization. The multicut problem, also known as correlation clustering, is a popular approach for dividing a graph into clusters based on node affinities. Multicut and its extensions have found applications in various fields such as machine learning, computer vision, image analysis, and data mining. However, solving these problems is NP-hard, and even powerful approximative algorithms require significant running times for large instances. To address this, parallelization on GPUs is desirable. The GPU's parallelism is challenging to exploit due to irregular data structures and the sequential nature of combinatorial optimization algorithms. This paper introduces a new primal-dual method that can be massively parallelized and run on GPUs, resulting in faster runtimes compared to previous solvers while producing similar or better solutions. The method is based on solving a principled polyhedral relaxation and provides both primal solutions and dual lower bounds. The algorithm incorporates edge contraction and Lagrange relaxation with message passing, achieving significant speed improvements compared to previous schemes. The experimental results demonstrate the effectiveness of the proposed algorithm, producing quality solutions in a fraction of the execution time for instance segmentation problems in scene understanding and connectomics containing millions to billions of variables.