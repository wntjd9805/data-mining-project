Deep generative models have made significant advancements in generating high-quality samples in various domains such as images, speech, and natural language. In the context of image generation, these models can be categorized into two main branches: generative adversarial networks (GANs) and log-likelihood-based methods like variational autoencoders (VAEs), autoregressive models, and normalizing flows. While log-likelihood models have a simpler objective and easier optimization, GANs have historically outperformed them in terms of generation quality.However, a new log-likelihood model called the Denoising Diffusion Probabilistic Model (DDPM) has emerged, surpassing GANs in terms of image quality while being stable and easy to train. DDPMs leverage iterative denoising, gradually predicting less noisy images from noisy ones. This process, repeated over hundreds or thousands of iterations, results in high-quality and diverse image generation, even from random noise. DDPMs find applications in computer vision tasks such as super-resolution and image translation, as well as non-visual domains.DDPM incorporates a probabilistic denoising process that relies on estimating the mean component µt−1. Initially, the estimation was performed by predicting either the noise (cid:15)θ(xt, t) or the original image xθ(xt, t), with the former yielding better empirical results. However, no further comparisons between noise and the original image have been conducted.In this paper, the authors revisit the original implementation of DDPM and find that the preference of (cid:15)θ over xθ depends on hyperparameters and datasets. They also discover that the denoising process performs better when predicting noise in some timesteps and the original image in others. Based on this observation, the authors propose a modified model that predicts both values and adaptively selects the more reliable output at each sampling iteration. This adaptation introduces minimal additional parameters and complexity to the model.Through experiments on various DDPM models, the authors demonstrate a notable improvement in image quality, as measured by FID score, on multiple benchmark datasets. This modification to the DDPM framework is independent of existing advancements and particularly beneficial for generating high-quality samples when restricted to fewer iterations.