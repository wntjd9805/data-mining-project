Animating 3D characters is a labor-intensive process that requires extensive training and expertise. Traditionally, animators manually create a mesh model and define the skeleton topology, followed by the time-consuming task of painting skinning weights. This paper presents a novel approach called SkinningNet, a Two-Stream Graph Convolutional Network that automates the skin binding and skinning weight computation for each vertex of the mesh. Unlike previous methods that rely on handcrafted features, SkinningNet automatically extracts the most relevant features to establish the relationship between the mesh and skeleton and predict the corresponding skinning weights. The paper introduces several key contributions: a) the Two-Stream Graph Neural architecture that effectively extracts features from meshes and skeletons with diverse topologies, b) the Multi-aggregator Graph Convolution (MAGC) layer that enhances the Message-Passing scheme by using a multiple aggregation approach that improves generalization for unfamiliar graph topologies, c) a novel skin binding method that employs a skeleton joint representation instead of a bone representation, and d) the Mesh-Skeleton Graph Convolution Network, which leverages the skeleton joint representation to determine the optimal relationship between the input mesh and the skeleton. Experimental results demonstrate that the proposed method surpasses existing state-of-the-art techniques, achieving over 20% improvement in mesh deformation error. These results also highlight the ability of the approach to generalize effectively across various complex mesh and skeleton structures from different domains.