This paper introduces a novel end-to-end one-step transformer-based framework for person search, named PSTR. Person search is the task of detecting and identifying a target person from a gallery of uncropped images. Existing approaches for person search can be categorized into two-step and one-step methods. Two-step methods separate the tasks of person detection and re-identification, while one-step methods perform both tasks simultaneously using a shared network. However, these approaches often rely on hand-designed mechanisms, such as non-maximum suppression (NMS), and struggle to achieve satisfactory results. In this work, the authors investigate the use of transformers, a recently successful architecture in computer vision tasks, for person search. They propose PSTR, which uses an end-to-end one-step transformer-based architecture with a person-search specialized module to jointly perform detection and re-identification without requiring an NMS post-processing step. PSTR aims to improve re-identification feature discriminability and encode multi-scale information for re-identification. Experimental results on benchmark datasets demonstrate that PSTR achieves state-of-the-art performance in terms of both accuracy and speed. Overall, this paper contributes a new approach for person search using transformers, showing promising results in the field.