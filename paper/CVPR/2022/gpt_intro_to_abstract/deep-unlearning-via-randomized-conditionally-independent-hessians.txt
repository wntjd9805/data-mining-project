In this paper, we address the challenge of updating machine learning models to ensure the deletion of personal data without the need for full retraining. With the increasing focus on the right to be forgotten and the unauthorized use of personal images, there is a need for efficient and effective methods to remove data from models.We propose a statistical approach called L-CODEC, which computes conditional independence to identify the parameters that need to be updated in order to minimize the impact of a sample on the model predictions. This approach enables unlearning in deep models, even those with hundreds of millions of parameters, which was previously infeasible.We demonstrate the effectiveness of our approach by unlearning samples and entire classes on various types of deep learning models, including convolutional neural networks (CNNs), ResNets, and transformers. We specifically focus on face recognition and person re-identification models, showing that our approach can successfully remove sensitive data from these models.Our approach aims to provide a practical solution to the challenge of updating ML models to ensure data deletion without the need for extensive retraining. By identifying the specific parameters that need to be updated, we can achieve efficient unlearning without compromising the performance of the models. This has significant implications for privacy and data protection, as it allows for the removal of personal data from ML models in a scalable and cost-effective manner.