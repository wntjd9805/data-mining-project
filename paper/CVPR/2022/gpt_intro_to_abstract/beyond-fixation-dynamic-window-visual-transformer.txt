In this computer science paper, we introduce the concept of Dynamic Window Vision Transformer (DW-ViT) and its potential impact on computer vision tasks. We start by discussing the limitations of existing methods, such as ViT and Swin, in terms of their self-attention complexity and fixed window size. We then pose several questions regarding the optimal window size and the advantages of a multi-scale window approach. To address these questions, we design a multi-scale window multi-head self-attention (MSW-MSA) mechanism for the window-based ViT. However, simply introducing the MSW mechanism does not effectively improve performance, suggesting the need for protecting ViT with MSW from suboptimal window settings. To achieve this, we propose the DW-ViT method, which utilizes dynamic multi-scale windows and the dynamic fusion of information through weight assignment. DW-ViT demonstrates superior performance compared to other ViTs using the same single-scale window. Our contributions include challenging the limitations of window-based ViTs, proposing a plug-and-play module for dynamic multi-scale window self-attention, and achieving state-of-the-art performance on various computer vision tasks. Overall, DW-ViT provides a promising approach for improving the performance of computer vision models.