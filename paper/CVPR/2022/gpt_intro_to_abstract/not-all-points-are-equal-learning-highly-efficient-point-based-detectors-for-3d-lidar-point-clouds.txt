Accurate recognition and localization of specific 3D objects in point cloud data is a challenging problem in computer vision. In this paper, we focus on the task of 3D object detection in LiDAR point clouds, which involves predicting 3D bounding boxes with 7 degrees of freedom. Existing approaches typically convert the point clouds into regular representations or operate directly on the raw point cloud data. However, these methods suffer from quantization errors, high computational/memory costs, and limited detection performance. To address these limitations, we propose a task-oriented instance-aware downsampling framework that selectively preserves foreground points while reducing memory/computational costs. We introduce two sampling strategies, namely class-aware and centroid-aware, and incorporate a contextual instance centroid perception to exploit meaningful context information. Our proposed IA-SSD (Instance-Aware Single-Shot Detector) achieves high efficiency with a fast inference speed and accurate detection performance on the KITTI benchmark. Furthermore, the high instance recall ratio of our sampling strategy allows for training the model on multiple object categories, eliminating the need for separate models for each category. The contributions of this paper include: the identification of the sampling issue in existing point-based detectors, the introduction of efficient instance-aware downsampling strategies, the development of the IA-SSD model capable of detecting multi-class objects in LiDAR point clouds, and extensive experiments demonstrating the superior efficiency and accurate detection performance of our proposed method.