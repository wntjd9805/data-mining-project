Face alignment, the process of locating facial landmarks in images, has become a critical task in various face-related applications. Deep learning-based face alignment methods have gained attention recently, but still face challenges in handling occlusion, profile view, and illumination variation. This paper proposes a Sparse Local Patch Transformer (SLPT) to address these challenges. Unlike heatmap regression methods that focus locally and ignore the inherent relation between facial landmarks, SLPT utilizes a series of landmark queries to aggregate representations and learns an adaptive adjacency matrix using transformer-based cross-attention. The proposed method also introduces a coarse-to-fine framework that optimizes a group of initial landmarks to target landmarks through multiple stages. Experiments conducted on popular benchmarks demonstrate that the proposed method outperforms other state-of-the-art methods in terms of performance and computational complexity. The contributions of this work include the introduction of SLPT as a novel transformer for exploring the inherent relation between facial landmarks, the incorporation of a coarse-to-fine framework for fine-grained feature representation, and the validation of the proposed method through extensive experiments on multiple benchmarks.