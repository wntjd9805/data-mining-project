Semi-supervised video object segmentation (VOS) has garnered considerable attention in recent years. This task involves segmenting objects of interest from the background in a video, with only the first frame's mask annotation provided during testing. Early methods focused on online fine-tuning using the first annotated frame but suffered from model degradation due to target appearance changes over time. Propagation-based methods relied on masks computed in previous frames, but they struggled with occlusions and rapid motion. Matching-based VOS methods have achieved impressive results by constructing target templates from previous frames and calculating pixel-level correlations for segmentation. However, these methods have limitations, such as memory issues and inefficiencies due to inter-frame redundancy. In this paper, we propose a method called Sequential Weighted Expectation-Maximization (SWEM) that addresses both inter-frame and intra-frame redundancy simultaneously. SWEM constructs a set of low-rank bases for memory features using Expectation-Maximization (EM) iterations, significantly reducing intra-frame redundancy. Additionally, we introduce adaptive weights calculation and a sequential updating process to further reduce inter-frame redundancy. Our contributions include the development of SWEM, a fast and robust matching-based VOS method that achieves state-of-the-art performance while maintaining an impressive inference speed of 36 FPS.