Action understanding in untrimmed instructional videos is crucial for agents learning complex tasks by observing others. However, fully-supervised training of these videos is challenging and time-consuming due to the need for manual annotation of action labels and temporal boundaries. Weakly-supervised action segmentation addresses these limitations by utilizing only the ordered sequence of action labels per video during training. Additionally, the demand for processing videos online in real-time applications has not been addressed in existing weakly-supervised segmentation methods. This paper presents a framework for weakly-supervised online action segmentation using Dynamic Programming (DP), which outperforms previous approaches using greedy sliding window methods. The paper also introduces the Online-Ofﬂine Discrepancy Loss (OODL) to improve segmentation accuracy by penalizing the difference between online and ofﬂine segmentation results. Furthermore, the paper incorporates frame-wise multi-view correspondence during training to generate more accurate action pseudo-ground truth in weakly-labeled videos. The effectiveness of the proposed approach is demonstrated through experiments on benchmark multi-view datasets in cooking and assembly domains. The results show consistent improvements over baseline methods both quantitatively and qualitatively. Overall, this work addresses the challenges of weakly-supervised action segmentation and online processing, offering significant contributions to the field.