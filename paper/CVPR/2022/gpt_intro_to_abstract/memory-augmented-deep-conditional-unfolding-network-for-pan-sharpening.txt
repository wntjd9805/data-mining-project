This paper addresses the problem of Pan-sharpening, which involves fusing multispectral (MS) and panchromatic (PAN) satellite images to obtain high-resolution images with both spatial and spectral information. Traditional approaches to Pan-sharpening rely on hand-crafted priors, which limit their performance on complex scenes. In recent years, deep learning (DL)-based methods have shown promise due to their superior feature representation and generalization capabilities. However, these DL-based methods often lack interpretability and ignore the different characteristics of each band of MS images, leading to copy artifacts. This paper proposes an interpretable deep unfolding network called Memory-augmented Deep Conditional Unfolding Network (MDCUN) to address these issues. MDCUN formulates Pan-sharpening as a variational model and introduces denoising-based and non-local auto-regression priors to improve long-range coherence. It incorporates advantages of both model-based and data-driven DL methods. Additionally, a band-aware PAN-guided high-frequency information extraction module is introduced to fully exploit the potentials of different bands of MS images. The proposed method is evaluated on various satellite datasets and outperforms state-of-the-art algorithms with fewer parameters. Overall, this paper provides a novel and interpretable approach to Pan-sharpening, improving performance in terms of both interpretability and artifact reduction.