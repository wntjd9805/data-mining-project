Graph Neural Networks (GNNs) have become popular for learning and analyzing graph representations. However, training GNNs on large-scale datasets often leads to overfitting, especially when dealing with out-of-distribution test nodes. Data augmentation has been successful in reducing overfitting in computer vision tasks, but extending this concept to GNNs remains a challenge. Existing data augmentation methods for GNNs focus primarily on modifying the graph structure. This paper proposes a novel method called FLAG (Free Large-scale Adversarial Augmentation on Graphs) that applies adversarial perturbations to the node features of graphs to combat overfitting. FLAG leverages "free" adversarial training methods and multi-scale augmentations to improve the model's generalization in the input feature space. Extensive experiments on large-scale graph datasets show that FLAG outperforms existing adversarial augmentation methods and brings significant improvements to the accuracy of GNN models. The paper also provides analysis and insights into the effects of adversarial augmentation on model accuracy. Overall, FLAG is a simple, general, and efficient method for feature-based data augmentation in graph data.