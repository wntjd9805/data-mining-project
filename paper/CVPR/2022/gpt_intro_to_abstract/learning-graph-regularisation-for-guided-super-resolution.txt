Guided super-resolution is an important task in computer vision with practical applications in fields such as medical and satellite imaging. Traditional methods formulate the problem as an optimization task, aiming to create a high-resolution target image that matches the low-resolution source while adhering to a desired image characteristic. On the other hand, deep learning methods learn a mapping from the source and guide images to the target using a dataset of triplets. These methods excel in capturing complex image features but may struggle with limited training data or domain shifts. In this paper, we propose combining these two approaches by learning a graph representation of an optimization-based super-resolution scheme. We train a convolutional network to map the source and guide images to the edge potentials of an affinity graph, which serves as a regularizer for reconstructing the high-resolution target. Our method outperforms traditional and deep learning-based methods on guided depth super-resolution datasets, showing robustness to distribution shifts and generalizability across datasets. The contributions of our work include a novel formulation of guided super-resolution, a differentiable optimizer for graph regularization, and the combination of deep feature extractors and graph-based optimization in an end-to-end trainable framework. The resulting images are crisp and natural-looking, adhering to the underlying image formation model.