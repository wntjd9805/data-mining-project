Automatic face manipulation methods have gained significant attention due to their ability to realistically alter a person's appearance or expression. However, the potential social harm associated with this technology has led to extensive research efforts in detecting forged content. While deep learning-based detectors have shown high accuracy on familiar manipulation methods, their performance often declines when faced with videos created using novel manipulation techniques. In this paper, we propose a two-stage detection approach that leverages large-scale natural talking faces to achieve strong generalization and robustness. In the first stage, we introduce a non-contrastive self-supervised framework that learns temporally dense representations. We demonstrate the effectiveness of our approach through ablations. Additionally, we achieve state-of-the-art performance in cross-manipulation generalization experiments and showcase robustness against common corruption factors. Our contributions pave the way for future forgery detection methods to explore the vast repository of real videos available online.