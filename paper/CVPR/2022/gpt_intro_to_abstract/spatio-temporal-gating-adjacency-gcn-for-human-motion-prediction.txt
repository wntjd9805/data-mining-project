Human motion prediction is a crucial computer vision task with numerous potential applications, such as autonomous driving, human-robotics interaction, target tracking, and motion planning. The prediction of skeleton-based human body motion involves capturing complex spatio-temporal relationships, as the movement of a single joint is influenced by the coupling of spatial connections with other joints and the temporal trajectory tendency. This paper proposes the Spatio-Temporal Gating-Adjacency GCN (GAGCN) to learn these complex dependencies across diverse action types. The GAGCN employs an enhancing strategy and a balancing and fusing strategy to address the challenges of long-term sequence prediction and modeling spatio-temporal relationships. The enhancing strategy utilizes a gating network to blend candidate adjacency matrices, enhancing the generalization of the model on multi-action motions. The balancing and fusing strategy scales the number of candidate matrices to balance the weight of spatial and temporal modeling and fuses the spatio-temporal features to capture the hidden cross-dependency of the relationships. Experiments conducted on Human3.6M, AMASS, and 3DPW datasets demonstrate that the proposed method outperforms state-of-the-art approaches in both short-term and long-term motion predictions. The contributions of this work include the use of a gating network to enhance the generalization of GCN, the capturing of cross-dependency of space and time through balancing and fusing joint dependencies and temporal correlations, and extensive quantitative and qualitative evaluations demonstrating the superiority of the proposed method.