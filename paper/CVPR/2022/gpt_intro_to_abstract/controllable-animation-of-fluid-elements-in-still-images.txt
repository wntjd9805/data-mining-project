Animations have become increasingly popular and effective in capturing human imagination and engagement. Video-based ads and explainers have shown to generate more trust and boost sales compared to other modalities. However, while still images are readily available, animations and videos are less easily accessible. Therefore, it is desirable to provide practitioners with tools to convert still images into user-controlled videos, known as 'cinemagraphs'. This paper focuses on animating images containing fluid elements, such as water, smoke, and fire, that have repeating textures and continuous fluid motion. Previous work has explored generating animations from still images, but most methods either lack user control or suffer from limitations. This paper proposes a two-step approach to estimate a flow map from user-provided movement directions and speeds, which is then refined using a GAN-based network. The estimated flow map and input image are fed into an image generator to generate future frames. The paper's contributions include the proposed interactive control approach, the novel estimation of a constant flow map, superior performance compared to previous methods, and generalizability to arbitrary user directions. Experimental results demonstrate the effectiveness and versatility of the proposed method.