Object detection is a crucial technology for various real-world vision systems, including robotics, autonomous driving, and manufacturing. However, the performance of current object detectors is limited by the high cost of annotating training data. This limitation becomes more apparent when using transfer learning. Previous approaches like active learning, semi-supervised learning, and weakly-supervised learning have had limited success in overcoming this barrier. In this paper, we focus on the problem of object discovery in natural images without human annotations. Current approaches for this problem are computationally expensive and do not scale well to larger datasets. We propose TokenCut, a graph-based approach for unsupervised object discovery. We utilize a self-supervised vision transformer trained with DINO as our backbone feature encoder and construct a graph based on the token features. We use graph-cut to group self-similar regions and delimit foreground objects. Our approach significantly outperforms previous state-of-the-art methods in unsupervised object discovery, weakly-supervised object detection, and unsupervised saliency detection.