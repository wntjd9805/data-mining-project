Visual tracking is essential for various video applications, such as autonomous driving and video recognition. Deep learning-based trackers are currently dominant in visual object tracking, but they require a large amount of labeled data which may limit their ability to track previously unseen objects. Unsupervised tracking methods aim to learn from unlabeled videos, either through spatial or temporal self-supervision signals. While spatial self-supervision methods focus on constructing template-search pairs using still frames, they struggle to learn temporal correspondence over long periods of time. This paper focuses on methods that exploit the temporal self-supervision signal in videos to address the appearance variations that occur during online tracking.Previous unsupervised methods have not effectively utilized a box-regression branch, which is important for capturing objects with large scale variation along the temporal dimension. This paper introduces a better tracker by learning temporal correspondence on both the classification and regression branches. However, three critical challenges are identified. First, existing methods do not explore how to effectively utilize the self-supervision signal in the temporal dimension for training a tracker equipped with a box-estimation branch. Second, there is misalignment in cycle training where inaccurate tracking results lead to noisy template kernels, causing an ill-posed penalty. Third, the pseudo labels used in unsupervised tracking frameworks are often noisy, degrading tracking performance.To address these challenges, a novel unsupervised tracking framework called ULAST is proposed. ULAST consists of three components: consistency propagation transformation, region mask operation, and mask-guided loss re-weighting. The consistency propagation transformation generates reliable template kernels by utilizing long-term and short-term information from previous frames, preventing the training pipeline from breaking down. The region mask operation selects features and implicitly penalizes tracking errors on intermediate frames. The mask-guided loss re-weighting strategy assigns weights to samples based on the quality of their pseudo labels, mitigating the negative impact of noise on training.The trained tracker is evaluated on five benchmark datasets, showing favorable performance compared to state-of-the-art methods and demonstrating the effectiveness of ULAST. The main contributions of this work include the proposal of ULAST, which learns temporal correspondence on both classification and regression branches, the introduction of a consistency propagation transformation, a differentiable region mask operation, and a mask-guided loss re-weighting strategy to overcome the challenges in unsupervised tracking.