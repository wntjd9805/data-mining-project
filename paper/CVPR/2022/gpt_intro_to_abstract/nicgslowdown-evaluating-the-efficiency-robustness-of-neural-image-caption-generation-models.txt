Neural Image Caption Generation (NICG) models have gained significant attention in recent years for their ability to combine computer vision and natural language processing for image understanding and textual description generation. The design of NICG models poses challenges but can have a significant impact in real-world applications, such as assisting people with visual impairment or improving image search engines. However, the responsiveness of NICG models in real-time feedback scenarios is crucial, and it remains an open question whether these models can maintain efficiency under adversarial pressure. This paper aims to investigate the efficiency robustness of NICG models by examining the factors that affect their efficiency. The non-deterministic nature of the NICG model's output generation process, which follows a Markov process, implies that the computational consumption of these models is also non-deterministic. This natural property reveals a potential vulnerability where adversaries can design specific inputs to significantly increase the computational cost of NICG models. Such efficiency vulnerabilities can have severe consequences in real-world scenarios, such as draining device battery or extending response latency. The paper addresses the following questions: Can unnoticeable modifications to image inputs significantly increase the computational consumption of NICG models and degrade efficiency? If so, how severe can this degradation be? Existing work on adversarial machine learning does not address these questions, as they primarily focus on deterministic models and accuracy-based attacks. Moreover, evaluating efficiency robustness requires a fundamentally different optimization function than accuracy-based techniques.To evaluate the efficiency-oriented adversarial inputs, the paper proposes a new methodology called NICGSlowDown, which introduces minimal perturbations to inputs to delay the appearance of the End Of Sentence token and increase computational resource consumption. The effectiveness of NICGSlowDown is evaluated on four subject models using two datasets, and it is compared against six baseline techniques. The evaluation results demonstrate that NICGSlowDown outperforms all baselines, significantly increasing the loop numbers and CPU/GPU latency of NICG models.The contributions of this paper are twofold. Firstly, it identifies a new vulnerability in NICG models, where adversaries can decrease efficiency by increasing computational resource consumption. Secondly, it proposes NICGSlowDown as a novel technique for evaluating the efficiency robustness of NICG models, being the first of its kind.