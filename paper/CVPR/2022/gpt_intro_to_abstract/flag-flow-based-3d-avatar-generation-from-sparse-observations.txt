Mixed reality technology offers new opportunities for interaction in various domains such as remote collaboration, virtual gatherings, gaming, and education. To enhance the user experience, it is crucial to generate realistic representations of humans with high fidelity. While external sensors and cameras have shown effectiveness, generating realistic human representations solely with head-mounted devices (HMDs) remains a challenging problem. Current HMDs, like Microsoft HoloLens and Oculus Quest, provide limited data on the location and orientation of the head and hands, obtained through hand tracking or motion controllers. This limited data is insufficient for capturing the pose and motion of the full human body.Prior research has proposed human pose priors based on richer data sources, including images, 2D joints/keypoints, and markers. However, there have been limited attempts to generate full-body pose representations from extremely sparse observations, such as head and hand position and orientation. One approach by Dittadi et al. used a variational autoencoder to compress the head and hand inputs into a latent space, allowing for full-body pose generation through sampling.In this paper, we propose a new approach called a flow-based avatar generative model (FLAG) for generating full-body poses from sparse inputs. Specifically, we use a flow-based model to learn the conditional distribution of the full body pose based on the given head and hand data. This flow-based model enables an invertible mapping between the 3D pose distribution and a base distribution. The invertibility of our model allows us to go further and learn a probabilistic mapping from the given condition to the high-likelihood region in the base distribution.The strengths of our approach lie in the ability to compute exact pose likelihoods, in contrast to approximate likelihoods seen in previous VAE-based pose priors. The invertibility of our generative model also allows us to compute the oracle latent code, which serves as ground truth during training and enables a representative mapping from the observed head and hands to the latent space. This makes our approach a strong predictive model. Additionally, our model's pose prior provides a superior initialization in the latent space, making optimization efficient when optimizing in either pose space or latent space.Overall, our proposed FLAG approach addresses the challenge of generating realistic full-body poses from sparse HMD inputs, enhancing the realism and user experience in mixed reality applications.