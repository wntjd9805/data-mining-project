Depth prediction is a critical task in computer vision with applications in 3D reconstruction, autonomous driving, and robotics. However, traditional methods are limited in their ability to accurately estimate depth from a single color image. Recent works have used deep networks to directly regress depth maps, but these approaches lack the ability to exploit geometric constraints of multi-view. In this paper, we propose a novel approach that combines fully-connected Conditional Random Fields (FC-CRFs) with a vision transformer and multi-head attention mechanism to estimate depth. We segment the input image into windows and optimize the FC-CRFs energy within each window, reducing computation complexity. The multi-head attention mechanism captures pairwise relationships in the FC-CRFs, improving depth estimation. Experimental results on outdoor and indoor datasets show significant improvements in depth prediction accuracy compared to previous methods. Additionally, our approach achieves state-of-the-art performance on panorama datasets, demonstrating its effectiveness in handling monocular depth prediction tasks in different scenarios. Our contributions include the introduction of window-based FC-CRFs optimization, the use of multi-head attention for pairwise relationships, and the development of a bottom-up-top-down network for depth estimation.