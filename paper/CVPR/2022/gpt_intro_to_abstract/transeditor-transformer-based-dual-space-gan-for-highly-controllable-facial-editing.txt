High-fidelity generative modeling has advanced significantly with the introduction of Generative Adversarial Networks (GANs), leading to advancements in facial editing. However, achieving highly controllable facial attribute editing remains a challenge. The main challenge lies in the clean disentanglement of attributes in the latent space. Existing approaches have explored single latent spaces and local-region editing, but still suffer from latent entanglement. Recent studies have presented attempts using dual latent spaces, but they may not fully exploit the potential of a dual-space GAN. This paper introduces TransEditor, a novel Transformer-based dual-space GAN that strengthens the interaction between the latent spaces. The proposed Transformer-Based Cross-Space Interaction module enhances the interaction between the two spaces, allowing for highly controllable facial editing while maintaining semantic disentanglement. The P-space controls the structural information, while the Z-space determines the texture representation. A novel Dual-Space Editing strategy is devised to leverage the controllability of TransEditor. Additionally, existing inversion techniques are extended to fit the proposed dual-space design for real image editing. The contributions of this work include the introduction of TransEditor, a flexible dual-space GAN for highly controllable facial attribute editing, and a novel editing and inversion strategy. Extensive experiments demonstrate the effectiveness of TransEditor, outperforming state-of-the-art approaches, especially for complicated attributes.