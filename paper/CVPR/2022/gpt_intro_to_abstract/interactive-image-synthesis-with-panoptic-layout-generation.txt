Conditional image synthesis has seen significant advancements in recent years, with various input formats such as categories, source images, text descriptions, scene graphs, and semantic layouts being explored. However, interactive image synthesis using conditional generative models remains a contemporary challenge. This paper introduces Panoptic Layout Generative Adversarial Network (PLGAN), which addresses the region missing problem encountered by current instance layout-based approaches. PLGAN utilizes the panoptic segmentation theory to distinguish between stuff and thing objects, and incorporates a panoptic layout generation module that constructs stuff and instance layouts separately. These layouts are then combined into a panoptic layout using an Instance- and Stuff-Aware Normalization module, resulting in a synthesis process that eliminates missing regions and is more robust to perturbations in object locations. Experimental results on various datasets demonstrate the effectiveness of PLGAN compared to state-of-the-art layout-based approaches.