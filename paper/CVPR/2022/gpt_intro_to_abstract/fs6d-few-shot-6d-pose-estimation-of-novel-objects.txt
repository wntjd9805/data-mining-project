This paper focuses on the problem of 6D object pose estimation, which involves predicting the transformation between the object coordinate system and the camera coordinate system. While deep learning has shown significant improvement in this field, the current approaches have limitations due to strict restrictions and the need for high-fidelity CAD models and large-scale datasets. The authors propose a new open-set problem called few-shot 6D object pose estimation, where the goal is to estimate the pose of unknown objects with only a few views and without extra training. They introduce a dense RGBD prototypes matching framework that leverages both appearance and geometric information. Additionally, they present a large-scale dataset (ShapeNet6D) with diverse shapes and appearances for prior learning, as well as an online texture blending augmentation to bridge the domain gap between rendered RGB images and real-world scenes. The contributions of this work include establishing a benchmark for few-shot 6D object pose estimation, formulating the problem, and introducing datasets and augmentation techniques to improve network performance. This research has applications in various fields, such as robotic manipulation and home robots.