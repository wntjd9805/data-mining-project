This paper addresses the challenge of modeling and rendering a realistic human portrait with complete control over 3D viewpoint, facial expressions, and head pose in natural scenes. The authors propose a system called RigNeRF that leverages 3D Morphable Face Models (3DMMs) to generate a deformation field for controlling head pose and facial expressions in a neural radiance field (NeRF) framework. They refine the coarse deformation field using corrective residuals predicted by a multilayer perceptron (MLP) to account for non-rigid dynamics, hair, and accessories. The 3DMM serves as an inductive bias, allowing the network to generalize to novel head poses and expressions. The model is trained on short videos captured using a mobile device and enables explicit control of head pose, facial expression, and camera viewpoint. Experimental results demonstrate high fidelity reanimation of videos, capturing rich details of the scene and human head. The paper's contributions include proposing a neural radiance field for full control of the human head and the 3D scene, addressing the issue of rigidity loss in dynamic neural radiance fields, and introducing a deformation prior to improve the quality of reanimation.