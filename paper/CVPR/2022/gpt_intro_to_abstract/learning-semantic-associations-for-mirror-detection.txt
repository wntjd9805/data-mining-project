Mirrors are common in our daily lives and their appearances vary depending on their surroundings. The presence of mirrors can have an impact on various vision tasks and can be a potential hazard for computer vision tasks. Therefore, it is important to detect mirrors accurately. Existing mirror detection methods primarily focus on learning contextual contrasts or corresponding relations between mirror and non-mirror regions. However, these approaches can easily fail in real-world scenarios where there are many objects that possess similar properties to mirrors. In this paper, we propose a novel mirror detection approach that takes into account the semantic associations between mirrors and their surrounding objects. We observe that humans typically place mirrors in specific relationships with certain objects for functional purposes. Based on this observation, we develop a model that learns the semantic knowledge of mirrors and their surrounding objects and explores the semantic associations between them. Our model includes two novel modules: an Associations Exploration (AE) Module to infer scene object associations and a Quadruple-Graph (QG) Module to facilitate the diffusion and aggregation of semantic association knowledge. Both modules are built with graph convolutions, enabling efficient long-range semantic context aggregation. We conduct extensive experiments and demonstrate that our approach outperforms existing state-of-the-art methods on two mirror detection benchmarks. Our contributions include the presentation of a novel mirror detection approach that incorporates semantic associations for reliable mirror detection, the proposal of an AE Module and QG Module that effectively infer and aggregate semantic association knowledge, and the achievement of superior performance compared to existing methods on mirror detection benchmarks.