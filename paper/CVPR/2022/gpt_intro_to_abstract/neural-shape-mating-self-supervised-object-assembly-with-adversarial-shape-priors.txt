Abstract:This paper introduces the problem of pairwise shape mating without known models, which is an important aspect of multi-part geometric assembly in areas like robotics and AR/VR. Previous approaches in application-specific domains relied heavily on semantic information and ground-truth annotations, making them difficult to scale and generalize. In this paper, we propose Neural Shape Mating (NSM), a geometric approach to shape mating that doesn't rely on semantic information or pre-defined target shapes. NSM uses point cloud data and a Transformer-based module to predict plausible mating configurations based on geometric cues. An adversarial learning scheme is also used to learn shape priors for evaluating the generated mating configurations. To account for imperfect data, NSM is trained with an implicit shape reconstruction task. A self-supervised data collection pipeline is proposed to generate a large-scale dataset for training and evaluation. Extensive experiments demonstrate the effectiveness of NSM compared to other methods. This paper contributes a new task, a dataset, and an algorithm that improve shape mating techniques.