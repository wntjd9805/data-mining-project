Deep neural networks have achieved impressive performance in various machine learning tasks, but they require a large amount of labeled training data. Unsupervised Domain Adaptation (UDA) addresses this issue by transferring knowledge from a labeled source domain to an unlabeled target domain. Adversarial adaptation is a prevailing paradigm in UDA, which learns domain-invariant feature representation using adversarial learning. While deep UDA methods with pretrained Convolutional Neural Network (CNN) backbones have shown impressive results on medium-sized classification benchmarks, they struggle on large-scale datasets like DomainNet.To address this, we propose a novel UDA solution called SSRT (Safe Self-Refinement for Transformer-based domain adaptation). We focus on two challenging aspects: representation and domain adaptation. From the representation aspect, we integrate the vision transformer, which processes images as sequences of tokens and uses global self-attention to refine the representation. By combining the vision transformer ViT-B/16 with adversarial adaptation, we achieve better results on DomainNet compared to using the ResNet-101 backbone.From the domain adaptation aspect, we propose a reliable strategy to protect the learning process from collapse due to large domain gaps. As strong backbones like the vision transformer increase the risk of overfitting to source domain data, we introduce a regularization mechanism using predictions on perturbed target domain data. We add random offsets to the latent token sequences and minimize the discrepancy of model predictions between the original and perturbed versions using the Kullback Leibler divergence. This regularization applies to the transformer layers and is backed by multi-layer perturbation and bi-directional supervision.Furthermore, to prevent model collapse, we introduce a Safe Training mechanism that automatically adjusts the learning configuration. We monitor the whole training process and adaptively adjust the configuration based on a diversity measure of model predictions on the target domain data. This ensures that our SSRT does not suffer significant performance deterioration on adaptation tasks with large domain gaps.In summary, our contributions include the development of SSRT, a UDA solution that integrates a vision transformer backbone and utilizes predictions on perturbed target domain data for model refinement. We also propose a safe training strategy to protect the learning process from collapse. SSRT achieves promising results on large-scale datasets like DomainNet, outperforming previous methods. Extensive experiments on widely tested benchmarks demonstrate the effectiveness of our approach.