This paper introduces a novel approach to photorealistic style transfer, which involves rendering an image in the style of a reference image to create a photorealistic result. The challenge lies in achieving a good balance between stylization strength and content preservation while optimizing for speed. The current state-of-the-art models use autoencoders, but their performance is limited by the size of the VGG-19 backbone. To address this, the authors propose a method that employs coarse-to-fine feature transformations and knowledge distillation. Their approach achieves superior stylization quality and content preservation compared to existing models, while also being faster. This is the first knowledge distillation algorithm for photorealistic style transfer, offering a new direction for future research in this domain.