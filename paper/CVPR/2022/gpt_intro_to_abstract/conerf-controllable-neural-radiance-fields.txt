Neural radiance field (NeRF) methods have gained popularity due to their ability to render photorealistic images from various viewpoints. However, these methods currently only allow limited control over materials, color, and object placement. Fine-grained control, such as manipulating individual attributes of an object, remains a challenge. This paper proposes a learning framework called CoNeRF that enables direct and intuitive control over NeRF representations with minimal user intervention. The framework utilizes sparse 2D mask annotations to specify which regions of the image an attribute controls. By treating attributes as latent variables, the annotations can be automatically propagated to the entire input video. CoNeRF allows for the synthesis of expressions that were not seen during training. The contributions of this paper include providing fine-grained control over NeRF representations, achieving this through few-shot supervision, and offering a domain-agnostic technique inspired by facial animation research.