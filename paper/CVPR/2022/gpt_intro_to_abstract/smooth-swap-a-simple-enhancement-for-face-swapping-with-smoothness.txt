Face swapping is a popular task that involves switching the identity of a given face image while preserving other attributes like facial expressions and head poses. This task has various real-world applications, such as privacy protection and entertainment industry character creation. Current face-swapping models have made significant progress in generating high-quality swapped images using a single source identity. However, these models often rely on complex architectures and multiple loss functions to change the shape of the face. The challenge lies in changing the face shape without access to ground-truth swapped images. Previous studies have employed handcrafted components like mask-based mixing or 3D face-shape modeling, which introduce complexity in terms of hyperparameters and loss function tuning.In this research, we propose a new approach to face swapping that focuses on improving the smoothness of identity embeddings. We argue that handcrafted components are not the optimal solution to overcome the challenges of face swapping. Instead, we develop a new identity embedding model, Smooth-Swap, which provides improved smoothness. The identity embedding model plays a crucial role in training the swapping model, as it guides the generator to change the identity. By using a supervised contrastive loss, we demonstrate that Smooth-Swap achieves a smoother space compared to existing models that use the ArcFace embedder. This smoother space enables faster and more stable training.Smooth-Swap eliminates the need for handcrafted components by utilizing a simple U-Net-based generator. Only three basic loss functions are employed for training: identity change, target preservation, and adversarial loss. Despite its simpler architecture, we show that Smooth-Swap achieves comparable or superior performance by leveraging a data-driven approach and minimizing inductive bias.The advantages of Smooth-Swap can be summarized as follows: (1) Simple architecture: Smooth-Swap uses a straightforward U-Net-based generator without any handcrafted components. (2) Simple loss functions: The generator can be trained using minimal loss functions specifically designed for face swapping. (3) Fast training: The smooth identity embedder enables faster training by providing more stable gradient information.