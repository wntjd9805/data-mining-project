Generative Adversarial Networks (GANs) have been at the forefront of deep learning research, revolutionizing generative tasks and downstream discriminative objectives. However, previous attempts to generate or augment training data using GANs have had limited success. In this paper, we propose an alternative approach by focusing on extracting information from the latent space of StyleGAN, which is known for its semantic and disentangled properties. We leverage the distances along semantic hyperplanes in the latent space as discriminative features for regression tasks. These distances have globally consistent relationships with corresponding attributes, allow for lower dimensional functions, and exhibit a monotone relationship with attribute strength. By fitting a simple linear function, we can regress complex semantic attributes in images using only two parameters. Our method is compatible with various GAN inversion encoders, and we demonstrate its effectiveness on few-shot learning tasks such as pose and age estimation. We show that our model can achieve state-of-the-art results without direct supervision and can even outperform fully-supervised methods trained on large datasets. In cases where no supervision is available, our model produces meaningful scores for tasks like ordinal regression and sorting images by semantic property strength. Overall, our contributions include the discovery of highly semantic latent-space distances, a scheme for constructing a few-shot regressive model, and a new approach to analyzing layer importance and mapping semantic distances in GAN latent spaces.