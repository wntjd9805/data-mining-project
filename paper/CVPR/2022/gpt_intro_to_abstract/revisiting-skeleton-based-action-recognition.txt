Action recognition in videos is an important task in the field of computer vision. There are various modalities that have been explored for representing video features, such as RGB frames, optical flows, audio waves, and human skeletons. Skeleton-based action recognition has gained attention due to its ability to focus on actions and its compactness.In this paper, we propose a novel framework called PoseConv3D as an alternative to graph convolutional network (GCN) approaches for skeleton-based action recognition. PoseConv3D takes 2D poses as input, represented by stacks of heatmaps of skeleton joints. These heatmaps are stacked along the temporal dimension to form a 3D heatmap volume, which is then processed by a 3D convolutional neural network for action recognition.Compared to GCN-based approaches, PoseConv3D addresses several limitations. First, it is more robust to variations in pose estimation methods. It generalizes well across different input skeletons obtained from different approaches. Second, PoseConv3D can easily integrate with other modalities, such as RGB frames, optical flows, or audio waves, into multi-stream convolutional networks. This opens up opportunities for further improvements in recognition performance. Lastly, PoseConv3D can handle varying numbers of persons without increasing computational overhead.We conducted comprehensive studies on several datasets, including FineGYM, NTURGB-D, UCF101, HMDB51, Kinetics400, and Volleyball. Our results show that PoseConv3D achieves state-of-the-art performance compared to GCN-based approaches. These findings highlight the efficiency and effectiveness of PoseConv3D in skeleton-based action recognition tasks.