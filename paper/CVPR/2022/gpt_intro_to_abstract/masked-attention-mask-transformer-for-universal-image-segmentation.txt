Image segmentation is a fundamental task in computer vision, involving the grouping of pixels based on various semantics. Different types of segmentation tasks, such as panoptic, instance, and semantic segmentation, have emerged based on different semantics for grouping pixels. However, current methods typically develop specialized architectures for each task, leading to duplicate research and optimization efforts. Recent work has attempted to address this issue by designing universal architectures capable of handling all segmentation tasks with the same architecture. These architectures, based on end-to-end set prediction objectives, have shown promising results on semantic and panoptic segmentation. However, they still lag behind specialized architectures in terms of performance and are harder to train. In this paper, we propose a universal image segmentation architecture called Mask2Former that outperforms specialized architectures across different segmentation tasks while being easy to train. We introduce key improvements such as masked attention, multi-scale high-resolution features, optimization enhancements, and memory-saving techniques. We evaluate Mask2Former on three segmentation tasks and four popular datasets, showing that our architecture achieves state-of-the-art performance in all benchmarks. Specifically, Mask2Former achieves 57.8 PQ on COCO panoptic segmentation, 50.1 AP on COCO instance segmentation, and 57.7 mIoU on ADE20K semantic segmentation. Our results demonstrate the effectiveness and accessibility of universal architectures in image segmentation.