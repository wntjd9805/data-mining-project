Transformers have gained significant attention in natural language processing (NLP) studies due to their ability to model long-range dependencies using self-attention. Recently, transformers have been applied to computer vision tasks, but they require large amounts of training data due to the lack of certain inductive biases. Convolutional neural networks (CNNs), on the other hand, naturally possess strong inductive biases and are sample and parameter-efficient. Researchers have proposed combining convolution operations with transformers to introduce inductive biases, but this approach may compromise the intrinsic properties of transformers. Another approach is the use of knowledge distillation (KD) to transfer inductive biases from CNNs to transformers, but existing methods have limitations. In this paper, we propose a two-stage learning framework called DearKD for training vision transformers in a data-efficient manner. DearKD distills knowledge from both the classification logits and intermediate layers of the CNN, providing explicit learning signals for the early transformer layers to capture inductive biases. We introduce a Multi-Head Convolutional-Attention (MHCA) layer to mimic convolutional layers without compromising the expressive capacity of self-attention. We also propose an aligner module to solve feature misalignment between CNN features and transformer tokens. The distillation process only occurs in the first stage of DearKD training, allowing transformers to learn their own inductive biases in the second stage. We evaluate DearKD in different scenarios with varying amounts of training data and show that it achieves state-of-the-art performance on image classification with similar or less computation. Additionally, our data-free DearKD approach achieves promising results with only a small decrease in performance compared to full-ImageNet training. Our contributions include the introduction of the DearKD framework, investigation of DearKD in various settings, and the proposal of an intra-divergence loss based on DeepInversion to improve performance in the data-free situation.