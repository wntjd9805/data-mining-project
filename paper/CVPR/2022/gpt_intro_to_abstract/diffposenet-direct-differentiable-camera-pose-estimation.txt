The localization ability is crucial for mobile robotics applications, with vision-based solutions being preferred due to their size, weight, power constraints, and robust localization methods. However, these methods often struggle with challenging conditions in-the-wild, such as changing lighting, textureless regions, and dynamic objects. Traditional approaches for localization rely on sparse feature correspondences or dense motion fields, but optical flow estimation is biased due to noise. Learning-based approaches have attempted to improve optical flow estimation, but this bias persists. This paper introduces the concept of normal flow, which projects optical flow on the image gradient direction and is more resilient to bias. Previous methods to estimate normal flow have not been robust enough for deployment in real-world scenarios, so optical flow has remained the go-to representation for ego-motion estimation. To address this, the paper proposes NFlowNet, the first normal flow network, to improve the robustness of camera pose estimation. Direct approaches that utilize normal flow for pose estimation face challenges as normal flow is 1D and depth cannot be eliminated from the equations relating it to scene geometry and 3D motion. By utilizing the depth positivity constraint, which states that the scene must be in front of the camera and thus has positive depth, the paper reformulates the cheirality optimization into a differentiable layer for pose estimation. The differentiable programming paradigm with implicit differentiation is employed to train the pose network in an end-to-end fashion. The contributions of this work include the introduction of NFlowNet for normal flow estimation, the formulation of pose estimation using the cheirality constraint, and extensive experimental results showcasing the robustness and generalizability of the proposed approach.