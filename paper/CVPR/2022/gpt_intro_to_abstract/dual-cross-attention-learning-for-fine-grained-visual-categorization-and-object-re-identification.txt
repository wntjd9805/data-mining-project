This paper introduces the concept of self-attention, an attention mechanism that allows for relating different positions within a single sequence and drawing global dependencies. Originally applied in natural language processing, self-attention has shown outstanding performance in various tasks. In recent years, self-attention has also been explored in the field of computer vision as an alternative to convolutional neural networks (CNNs), particularly for image classification and object detection. The goal of this work is to investigate the extension of self-attention modules to better learn subtle feature embeddings for fine-grained object recognition. Fine-grained recognition is more challenging than general image classification due to the subtle visual variations between different sub-classes. Existing approaches often utilize CNNs for predicting class probabilities or measuring feature distances, but to address the subtle appearance variations, this work proposes a different approach using the vision Transformer and local information.To incorporate local information, the authors propose a global-local cross-attention (GLCA) mechanism, which enhances interactions between global images and local high-response regions. By computing cross-attention between selected query vectors and the entire set of key-value vectors, GLCA helps reinforce spatial-wise discriminative clues for fine-grained object recognition.Additionally, the authors explore pair-wise learning as another solution to distinguish subtle visual differences. Pair-wise learning involves comparing image pairs to identify these differences. The authors introduce pair-wise cross-attention (PWCA) to regularize attention learning, treating another image as a distractor. By diffusing attention scores to another image, PWCA increases the difficulty of attention learning, allowing the network to discover more discriminative regions and alleviate overfitting.The proposed GLCA and PWCA mechanisms are easy to implement and compatible with self-attention learning. The paper presents extensive evaluations on fine-grained visual categorization (FGVC) and object re-identification (Re-ID) tasks. Experimental results show that the methods consistently improve multiple self-attention baselines and achieve competitive performance with state-of-the-art methods.In summary, the main contributions of this paper are: (1) the proposal of global-local cross-attention to enhance interactions between global and local regions for reinforcing spatial-wise discriminative clues, and (2) the introduction of pair-wise cross-attention to establish interactions between image pairs by regularizing attention learning. The dual cross-attention learning approach complements self-attention learning and consistently improves performance on various FGVC and Re-ID benchmarks.