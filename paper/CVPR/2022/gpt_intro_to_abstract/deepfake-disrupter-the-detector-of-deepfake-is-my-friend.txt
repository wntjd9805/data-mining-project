Face manipulation techniques, such as DeepFakes, have raised concerns due to their potential to create highly realistic fake images and videos. This has led to social and security problems, including reputational damage and financial fraud. In response, various defense methods have been proposed, including detection models to distinguish between real and DeepFake data, and disruption methods that distort the output of DeepFake models. However, existing disruption methods still have limitations, as visually distorted samples can still fool DeepFake detectors. Additionally, these methods rely on time-consuming iterative algorithms to generate perturbations. To address these issues, we propose a novel framework called DeepFake Disrupter, which uses a perturbation generator to produce human-imperceptible perturbations that can be recognized as fake by DeepFake detectors and human eyes. Simultaneously, the original real inputs with perturbations can still be identified as real by DeepFake detectors. Experimental results on CelebA and VoxCeleb1 datasets demonstrate the effectiveness of our proposed method in protecting original real images/videos from being used to create DeepFake data.