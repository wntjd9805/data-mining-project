Human hand (or body) pose estimation is a crucial task with various applications in augmented reality, sign language translation, and human-robot interaction. Although deep learning methods have shown success in this field, they require large amounts of annotated data, which is often expensive and time-consuming to obtain. Active learning, which selects the most informative unlabeled images for annotation, offers a potential solution to this problem. However, existing active learning-based pose estimation frameworks suffer from overconfidence and suboptimal image selection strategies. Additionally, they struggle in the batch setting, where multiple images are selected for annotation at once. Traditional methods either disregard redundancies or use less effective clustering algorithms in high-dimensional spaces. To address these issues, we propose a Meta Agent Teaming Active Learning (MATAL) model for human hand (or body) pose estimation. MATAL leverages an agent team to learn a teaming sampling policy from data and formulates the active learning procedure as a Markov Decision Process (MDP) solved with Reinforcement Learning (RL). The agent team collaboratively selects a batch of informative and diverse images for annotation, based on the topological information of the pose encoded using Kinetic Chain Space (KCS). Meta-learning is used to train the model for fast adaptation to an iteratively enlarged labeled dataset.The main contributions of our work are: 1) Formulating the pose estimation active learning procedure as an MDP and developing an RL-based framework for effective sample selection.2) Proposing a state-action representation to characterize the informativeness and representativeness of samples.3) Validating the efficacy of the proposed MATAL framework on human hand and body pose benchmarks.