Generative Adversarial Networks (GANs) have become powerful models for various tasks such as image generation, sound generation, image stylization, super-resolution, and feature generation. However, GANs often suffer from training instability, mode collapse, and discriminator overfitting. In this paper, we propose a solution to reduce discriminator overfitting by introducing a data-driven feature manifold-learning step intertwined with layers of the discriminator. This allows the discriminator to learn the feature manifold at different levels of object abstraction, limiting the complexity of the parameter space and separating the signal from noise. Our contributions include integrating locality-constrained and subspace-based feature encoding and dictionary learning with the GAN discriminator, employing a balancing term to facilitate manifold learning, and demonstrating the effectiveness of locality-constrained soft assignment coding as a flexible denoiser. We evaluate our method using various coding techniques and demonstrate its effectiveness in reducing discriminator overfitting. Overall, our approach enhances the stability and performance of GANs.