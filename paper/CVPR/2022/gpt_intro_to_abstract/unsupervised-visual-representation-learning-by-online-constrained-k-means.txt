Recent research efforts have focused on unsupervised representation learning, which utilizes unlabeled data to obtain applicable models. One key challenge in unsupervised representation learning is designing an appropriate pretext task. Various pretext tasks have been proposed, including instance discrimination and cluster discrimination. Instance discrimination is popular due to its straightforward objective, but it can be intractable on large-scale datasets. To mitigate this challenge, contrastive learning with a memory bank or large mini-batch training has been introduced. Cluster discrimination, on the other hand, partitions data into a predefined number of groups, making the classification task more feasible for large-scale data. However, the clustering phase often requires multiple iterations over the entire dataset, which is computationally expensive. To improve efficiency, online clustering methods have been adopted. However, these methods face the challenge of the collapsing problem. In this paper, we investigate clustering-based representation learning from the perspective of distance metric learning. By decoupling the variables appropriately, we propose an alternating optimization approach that includes clustering and discrimination phases. In the clustering phase, we propose a novel online algorithm for constrained k-means that lower-bounds the size of each cluster. This approach is more flexible than balanced clustering methods and can better model inherent data structure. In the discrimination phase, we use a standard normalized Softmax loss with labels and centers recorded from the last epoch to learn representations. Our proposed method, called CoKe, can effectively learn representations with a single view from each instance and can be optimized with a small batch size. We also propose two variance reduction strategies to enhance the robustness of the clustering. Experimental results demonstrate that CoKe outperforms existing methods, achieving state-of-the-art performance on downstream tasks and clustering.