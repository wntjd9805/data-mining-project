This paper introduces the problem of semantic understanding in videos and highlights the need for capturing not just visual aspects, but also the intended concepts and interpretations by the creators and viewers. To address this, the authors present a novel dataset called 3MASSIV, built from short videos posted on the Moj platform, which includes annotations for concept labels, affective states, audio types, video types, and languages. The dataset overcomes various challenges present in existing datasets, such as taxonomy limitations, lack of coverage for novel video formats, sparse and noisy hashtags, and limited linguistic diversity. The authors also discuss the potential applications of 3MASSIV for tasks like multilingual modeling, creator modeling, and temporal analysis. With 900 hours of video data and baseline results demonstrating its uniqueness and difficulty, 3MASSIV offers an opportunity for comprehensive understanding of social media content.