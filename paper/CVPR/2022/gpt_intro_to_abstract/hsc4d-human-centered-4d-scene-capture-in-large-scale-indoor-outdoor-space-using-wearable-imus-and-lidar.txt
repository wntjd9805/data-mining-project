The development of digital society has led to the emergence of technologies such as augmented reality, virtual reality, smart cities, robots, and autonomous driving, which enrich people's lives. However, current research works often separate dynamic human motions and static environments, neglecting the potential improvements that can be achieved by considering their interactions. This paper proposes a method that captures the entire scene, including consecutive human activities, by combining inertial measurement unit (IMU) sensors and light detection and ranging (LiDAR) technology. IMUs, when mounted on different parts of the human body, can capture accurate short-term motions but suffer from drift over time. To address this, some methods use external RGB or RGBD cameras, but this limits capture space, human activities, and interactions. The proposed method, Human-centered 4D Scene Capture (HSC4D), integrates IMU-based motion capture with LiDAR-based localization and scene capture to accurately and efficiently create a dynamic digital world with consecutive human motions. HSC4D uses only body-mounted sensors, making it space-free and pose-free, and it also allows for interaction between humans and the environment. Compared to camera-based localization, LiDAR provides more precise global localization, reducing drift and avoiding the need for pre-built maps. Through joint optimization, the proposed method improves motion estimation and human-scene mapping by considering physical constraints. The paper also presents a dataset comprising large scenes with accurate human motions and locations to facilitate further research and applications. The dataset includes diverse scenarios and challenging human activities, showcasing the effectiveness and generalization capabilities of HSC4D. Overall, this paper contributes by introducing HSC4D, proposing a joint optimization method, and providing a dataset for future research and applications.