Most modern visual-recognition systems are based on machine-learning models that are pretrained on different tasks than the downstream task they aim to solve. This pretraining allows the system to leverage larger annotated image or video datasets. Supervised image classification is a popular pretraining task, but self-supervised and weakly supervised tasks have also been explored. There are trade-offs between these pretraining types, with fully supervised pretraining benefiting from strong semantic learning signals but not scaling well, self-supervised pretraining lacking semantic information but scaling easily, and weakly supervised pretraining falling in between with noisy semantic signals but large-scale availability.This paper examines weakly-supervised pretraining using hashtag supervision. Modern image-recognition models are pretrained on a dataset of images and associated hashtags, and their performance is evaluated in transfer learning experiments. The models are transferred to various image-classification tasks, including zero-shot transfer and few-shot transfer settings. The goal is to compare and understand the trade-offs between fully supervised, self-supervised, and weakly supervised pretraining. The results indicate that the weakly-supervised approach is competitive and achieves state-of-the-art performance despite its relatively simple training pipeline.One potential downside of weakly-supervised pretraining is the possibility of inheriting or amplifying harmful associations from the supervisory signal. Experiments are conducted to assess this risk, though conclusive answers are not provided. However, the results suggest that the risks may not be as significant as in language modeling. Overall, this study presents a compelling argument for the weakly-supervised pretraining of visual-recognition systems.