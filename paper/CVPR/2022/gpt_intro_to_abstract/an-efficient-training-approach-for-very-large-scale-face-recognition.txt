Deep Neural Networks (DNNs) have achieved remarkable results in computer vision tasks, particularly in the field of face recognition. The training process of face recognition aims to learn an embedding space that reduces intra-class distances and enlarges inter-class distances. To achieve better performance, researchers have collected large-scale datasets with millions of face identities. However, training on these ultra-large-scale datasets poses challenges in terms of training time and hardware resource occupancy. In this paper, we propose an efficient training approach called Faster Face Classification (F2C) for ultra-large-scale face datasets. F2C utilizes twin backbones, Gallery Net (G-Net) and Probe Net (P-Net), to generate identity centers and extract face features, respectively. Additionally, we introduce Dynamic Class Pool (DCP) as a substitute for the fully connected (FC) layer, significantly reducing the time and resource cost in training. We also design a dual data loader to improve the update efficiency of DCP parameters. Experimental results on various face benchmarks demonstrate that F2C achieves comparable results to state-of-the-art FC-based methods while reducing the training time and hardware costs. Our contributions include the proposal of F2C as an efficient training approach, the introduction of DCP as an alternative to the FC layer, and the design of a dual data loader to enhance update efficiency.