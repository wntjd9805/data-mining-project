Photo-realistic image synthesis is a significant problem in computer vision and graphics, with a particular focus on generating high-fidelity and editable portrait images. Existing methods can be classified into two main categories: 2D GAN image generation and 3D-aware image synthesis techniques. However, 2D GAN methods neglect the important projection or rendering process of the underlying 3D scene, leading to view inconsistency and artifacts in the generated images. On the other hand, 3D-aware methods based on Neural Radiance Fields (NeRF) have been explored, but they often produce blurry results and lack interactivity for local editing. To address these limitations, we propose a generator that produces strictly view-consistent portraits while supporting interactive local editing. Our generator adopts a noise-to-volume scheme, taking decoupled shape and texture latent codes as input and generating a 3D volume that preserves facial semantics and texture in a spatially-aligned manner. We address the challenge of learning this 3D volume representation by utilizing paired monocular images with semantic masks as training data, leveraging color and semantic discriminators to supervise the training of the generator. The color discriminator enhances image fidelity, while the semantic discriminator enforces alignment between the image and semantic map in the 3D volume. This spatial alignment enables local and flexible editing of the 3D volume using GAN inversion. Additionally, joint learning of semantic and texture representations improves the generation of accurate 3D geometry. Experimental evaluations on the CelebAMask-HQ and FFHQ datasets demonstrate the effectiveness of our FENeRF generator, outperforming state-of-the-art methods and supporting various downstream tasks. Our contributions include the development of the first locally editable and strictly view-consistent portrait image generator, training with paired monocular images and semantic maps without the need for multi-view or 3D data, and the observation that joint learning of semantic and texture volumes improves 3D geometry generation.