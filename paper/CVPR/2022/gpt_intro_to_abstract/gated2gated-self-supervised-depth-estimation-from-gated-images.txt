This paper introduces a novel self-supervised method for depth estimation using gated cameras. Gated imaging has shown promise in overcoming the limitations of traditional depth sensors such as LiDAR and RGB cameras. Gated cameras combine low-cost CMOS sensors with analog gated readout and active flash illumination to capture depth cues not present in RGB cameras. However, existing methods for gated depth estimation require calibrated and synchronized LiDAR data for training, which limits their practicality. In this work, the authors propose a self-supervised method that takes gated slices as input and predicts scene albedo, depth, and ambient illumination. The method utilizes calibrated gated profiles to enforce measurement cycle consistency and warping from nearby slices for temporal consistency. By exploiting these training signals, the proposed model is able to accurately estimate metric depth. The authors validate the effectiveness of their method, showing that it outperforms both self-supervised and supervised depth estimation using monocular and stereo RGB images, as well as supervised gated depth estimation methods. The models and code used in this work have been released for reproducibility.