This paper introduces a novel framework called CLIMS (Cross Language Image Matching framework for Weakly Supervised Semantic Segmentation) to tackle the challenges of false-activation of irrelevant background and underestimation of object contents in weakly supervised semantic segmentation (WSSS). Existing WSSS approaches rely on image-level labels and follow a three-stage learning process involving initial class activation maps (CAMs) generation, refinement of CAMs, and segmentation network training. However, these approaches suffer from the inclusion of class-related background pixels and limitations in estimating object contents. The proposed CLIMS framework leverages the power of Contrastive Language-Image Pre-training (CLIP) model to overcome these issues. CLIP is pre-trained on a large dataset of image-text pairs and can associate a wide range of visual concepts with their textual labels in an open-world setting. CLIMS utilizes CLIP to generate high-quality initial activation maps for each object category without irrelevant background. The framework includes a backbone network and a text-driven evaluator with three CLIP-based loss functions. Experimental results demonstrate the efficacy of CLIMS in improving the quality of semantic segmentation models trained using only image-level labels.