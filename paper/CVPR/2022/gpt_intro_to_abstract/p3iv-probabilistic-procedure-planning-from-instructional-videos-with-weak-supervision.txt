Procedure planning is a challenging task for artificial agents that involves predicting a sequence of actions to achieve a desired goal. Solving this task is crucial for developing advanced artificial intelligence systems that can analyze and mimic human behavior. Traditionally, procedure planning has been studied in structured environments, but recent work has focused on addressing this problem in the context of instructional videos. However, current approaches for procedure planning from instructional videos rely on expensive annotations for supervision. In this paper, we propose a weakly supervised approach that leverages language representations to reduce the labeling effort. We remove the need for intermediate visual states during training and instead use their linguistic representation for supervision. Our approach employs a single branch non-autoregressive model, implemented as a transformer, to generate all intermediate steps in parallel. We also address the modeling of uncertainty in procedure planning by introducing a generative module that can produce multiple feasible plans. We evaluate our approach on three instructional video datasets and demonstrate state-of-the-art performance, even with weaker supervision. Our work contributes to the development of more efficient and probabilistic procedure planning models.