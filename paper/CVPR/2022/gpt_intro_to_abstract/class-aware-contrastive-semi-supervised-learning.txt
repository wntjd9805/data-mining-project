Raw data utilization has gained significant attention in computer science research due to its high accessibility and affordability. Raw data refers to a combination of in-distribution data with known classes and balanced distribution, and out-of-distribution data with unknown classes or unbalanced distribution. Semi-supervised learning (SSL) has achieved remarkable performance by using pseudo labeling techniques on in-distribution datasets. However, the assumption that the distribution of labeled data is similar to the unlabeled data and that the unlabeled dataset does not contain any novel categories often does not hold true in real-world applications with extensive out-of-distribution data. The use of pseudo labels on out-of-distribution data introduces significant noise, leading to poor performance of SSL due to confirmation bias induced by the noisy pseudo labels. Various techniques have been proposed to address this confirmation bias, including self-correction, narrowing the distribution gap, and using prior or posterior information. However, these methods still suffer from confirmation bias and may not perform well on real-world data with unbalanced distribution or unknown classes. To alleviate this issue, this paper introduces a class-aware contrastive semi-supervised learning (CCSSL) method, which integrates contrastive information to mitigate confirmation bias in the feature space. The CCSSL method consists of a semi-supervised module and a class-aware contrastive module, allowing it to enhance any end-to-end pseudo-label-based SSL method. Unlike self-correcting methods that rely on the model's output, CCSSL regularizes the training process by incorporating information in the feature space. It uses class-aware clustering on in-distribution data for maintaining SSL's clustering ability and image-level contrasting on out-of-distribution data for noise alleviation. Furthermore, a target re-weighting module is incorporated to reduce the impact of uncertain noisy samples and emphasize learning on highly probable in-distribution samples. Experimental results demonstrate that CCSSL improves the performance of state-of-the-art SSL methods on both in-distribution and real-world data. This paper contributes by proposing an effective SSL method that combines SSL and self-supervised learning techniques, providing a drop-in helper for existing pseudo-label-based SSL methods, and analyzing the impact of CCSSL on various SSL methods.