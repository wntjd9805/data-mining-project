Object detection is a crucial task in computer vision, enabling the prediction of object categories and bounding-box coordinates in images. It has applications in various domains, including instance segmentation and face detection. Two main approaches used in modern object detectors are two-stage and one-stage detectors. One-stage detectors, also known as dense object detectors, are popular due to their speed and relevance in real-world applications. However, they often face an imbalance problem, with a large number of background patches overwhelming the foreground patches. To address this issue, the Average Precision (AP) Loss converts the classification task into a ranking task by explicitly modeling sample relationships. Although AP loss performs well, its underlying mechanism is still not fully understood. In this paper, we analyze AP loss from a pairwise ranking perspective and focus on the pairwise error between positive and negative samples. We improve AP loss by adjusting the approach to ranking pair selection, which leads to significant performance gains in object detection. Our approach involves reformulating the AP loss into three components: distance function, balance constant, and ranking pair selection. Through detailed experiments, we verify the effects of these components and highlight the importance of proper ranking pair selection for accurate detection results. We also identify existing issues with ranking pair selection strategies and propose an Adaptive Ranking Pair Selection (ARPS) approach to address them. ARPS provides complete and accurate ranking pairs for calculating pairwise error, resulting in improved training and higher accuracy in ranking tasks. Our contributions include experimental validation of AP loss from a pairwise perspective, the introduction of ARPS for automatic ranking pair selection, and competitive performance compared to existing classification and ranking methods.