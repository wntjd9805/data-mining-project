This paper introduces the task of forecasting characteristic 3D poses in future human behavior, which is crucial for achieving higher-level perception in machine interactions with humans. The goal is to predict a person's future pose at action-defining moments, rather than fixed time intervals, in order to understand the objectives underlying a future action separately from the speed at which they occur. The proposed approach uses an attention-driven, probabilistic method to generate diverse hypotheses for the future pose, capturing the multi-modality of characteristic poses. Autoregressive predictions are made for the end effectors of the actions to model the joint distribution of the human pose joints. A benchmark dataset is introduced for characteristic 3D pose prediction, and experiments show that the proposed approach outperforms state-of-the-art methods by 26% on average. Overall, this work contributes to goal-oriented understanding of pose forecasting and provides insights for various applications in human-robot interaction, surveillance, and content creation.