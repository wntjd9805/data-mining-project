Object tracking is a crucial task in computer vision, especially in applications such as surveillance and self-driving. While there have been significant advancements in tracking algorithms, the performance of state-of-the-art trackers deteriorates in real-world scenarios with a large vocabulary of objects. Current tracking benchmarks and trackers primarily focus on a small set of objects, limiting their applicability in general environments with a diverse range of objects. To address this limitation, a new benchmark called TAO, containing over 800 object categories, has been introduced. The analysis of this benchmark has indicated that large-vocabulary tracking requires improvements in both tracking and classification accuracy.In this paper, we propose a set classifier that leverages multiple viewpoints of a tracklet to accurately classify objects from a large vocabulary. Unlike existing methods that rely on per-frame classification results, our set classifier considers the spatio-temporal features of the entire tracklet, making it robust against appearance changes and temporal shifts. We design the set classifier as a stack of transformer layers that attend to relevant information for classifying the large vocabulary.Due to the limited annotation budget for videos, we present augmentation methods for generating tracklets with video characteristics, such as multiple viewpoints of an object. This enables the set classifier to be trained with a diverse range of tracklets, including rare classes. We also introduce a training procedure that facilitates the supervision of the set classifier using augmented tracklets and propose auxiliary losses for further accuracy improvements.Experimental results on the TAO benchmark show that our set classifier achieves state-of-the-art performance, significantly improving tracking accuracy in long-tailed scenarios. We also demonstrate the effectiveness of our method on the YouTube-VIS 2019 video instance segmentation dataset. In summary, our contributions include the proposal of the set classifier, augmentation methods for generating diverse tracklets, a new training procedure, and achieving state-of-the-art results on challenging benchmarks.