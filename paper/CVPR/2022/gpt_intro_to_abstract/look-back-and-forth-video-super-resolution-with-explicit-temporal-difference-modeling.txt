Super-resolution (SR) aims to recover high-resolution (HR) images from low-resolution (LR) observations. Single image super-resolution (SISR) methods rely on learned image priors or self-similarity within images, while video super-resolution (VSR) methods aim to extract valuable details from neighboring frames. Both tasks have made progress with the development of deep learning techniques. Some methods attempt to model temporal information across frames through explicit or implicit motion compensation, but these approaches have limitations such as increased model complexity or errors in motion estimation. Other methods explore temporal information in a recurrent fashion, either unidirectionally or bidirectionally, but they suffer from unbalanced historical accumulation or large memory usage. The idea of explicit temporal difference modeling has been explored in video-related tasks and has shown promising results. In this paper, we propose a framework that explicitly models temporal differences in LR and HR space for VSR. We use a uni-directional recurrent approach to ensure efficiency and avoid large memory caching. Instead of feeding consecutive frames into the model, we compute the temporal difference between a reference frame and neighboring frames. We divide the neighboring frames into subsets based on their level of difference and process them separately with different receptive fields. We combine the outputs of these branches and use them to reconstruct the initial SR results. We also use separate heads to model temporal differences in HR space at future and past time steps. By allowing the model to look back and forth at intermediate estimations, we achieve further enhancement in HR space. Additionally, we cache the temporal difference between spatial residual features at different time steps to propagate information from further time steps to the current step. Our proposed method achieves favorable performance compared to state-of-the-art methods on benchmark datasets for VSR. Our contributions include a framework to explicitly explore temporal differences in LR and HR, a novel refinement strategy, and improved performance on VSR benchmarks.