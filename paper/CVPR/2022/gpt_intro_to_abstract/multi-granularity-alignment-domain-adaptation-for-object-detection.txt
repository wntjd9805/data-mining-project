Recent progress in deep learning has led to significant advancements in modern object detection methods, particularly due to the use of large-scale annotated datasets. However, these models, which are trained on domain-constrained datasets, often struggle to perform effectively in new environments where labeled training data is not available. To address this challenge, one feasible solution is to reduce the disparity between the label-rich source domain and the label-agnostic target domain through unsupervised domain adaptation using an adversarial approach. Specifically, an introduced domain discriminator aims to identify whether an image belongs to the source or target domain, while an object detector learns domain-invariant features to confuse the discriminator. However, traditional domain adaptation frameworks have limited performance due to scale variations in cluttered backgrounds, making it difficult to accurately capture object features of various scales and aspect ratios. Additionally, existing approaches only pay attention to the consistency between image-level and instance-level predictions. To overcome these limitations, this paper proposes a unified multi-granularity alignment based object detection framework using unsupervised domain adaptation. The framework encodes dependencies across different granularity perspectives, including pixel-level, instance-level, and category-level, to align the source and target domains. The proposed approach does not simply combine previous single-granularity alignment techniques, but rather utilizes omni-scale gated fusion to select the most plausible convolutions from both low-resolution and high-resolution streams, adapting to various instances. Coarse detections are estimated based on pixel-level backbone feature maps, and parallel convolutions are activated to aggregate discriminative representations of instances with similar scales and aspect ratios. Additionally, a category-level discriminator is introduced to consider both instance discriminability in different categories and category consistency between the source and target domains. The category-level discriminator is supervised by assigning pseudo labels to important instances with high confidence from object detection. Experimental evaluations on different domain adaptation scenarios demonstrate the effectiveness of the proposed approach, achieving state-of-the-art performance on various datasets. The multi-granularity alignment framework can be applied to different object detectors, the omni-scale gated fusion module facilitates the extraction of discriminative representations for objects with different scales and aspect ratios, and the category-level discriminator models both instance discriminability and category consistency. Overall, the proposed method significantly improves domain adaptation performance in object detection tasks.