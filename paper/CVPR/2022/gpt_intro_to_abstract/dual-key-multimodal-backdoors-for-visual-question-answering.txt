This paper focuses on backdoor (trojan) attacks in multimodal machine learning models, which combine information from multiple modalities such as images and natural language. The authors introduce a novel attack technique called Dual-Key Multimodal Backdoors, where the network is trained to activate the backdoor only when specific triggers are present in all input modalities. This approach enhances the stealthiness of the backdoor, reducing the risk of accidental discovery. The authors conduct an in-depth study of these backdoors on the Visual Question Answering (VQA) dataset and highlight the potential risks they pose in real-world applications. They address the challenges of embedding backdoors in VQA models and propose a trigger optimization strategy to achieve high attack success rates. Additionally, the authors provide a large dataset of clean and trojan VQA models to encourage research in defense mechanisms against multimodal backdoors. Overall, this paper presents the first study of backdoors in multimodal models and provides valuable insights into their behavior and potential defenses.