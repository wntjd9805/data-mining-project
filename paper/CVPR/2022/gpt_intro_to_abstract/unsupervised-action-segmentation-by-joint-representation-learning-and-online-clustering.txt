This paper introduces a novel method for unsupervised activity segmentation in videos. The goal is to assign each frame of a long video capturing a complex activity to one of the action or sub-activity classes. Previous approaches have relied on fully-supervised or weakly-supervised training, which require expensive frame-level annotations or time-consuming weak labels. To address these limitations, the proposed method jointly performs representation learning and online clustering. By leveraging video frame clustering as a pretext task, the method directly optimizes for unsupervised activity segmentation. Additionally, a temporal optimal transport module is introduced to exploit temporal cues in videos, preserving the temporal order of activities in the computed pseudo-label cluster assignments. This approach achieves comparable or better results than state-of-the-art methods on public datasets and a newly collected dataset, while being more memory efficient. The paper also includes the release of the Desktop Assembly dataset, which is labeled and publicly available.