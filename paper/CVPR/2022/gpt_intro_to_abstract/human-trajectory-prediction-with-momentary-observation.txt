This paper focuses on the task of momentary trajectory prediction, which involves predicting future movements of traffic agents based on only two frames of observation. While existing methods perform well using historical observations over several seconds, accurately tracking trajectories over long periods of time is difficult, especially in congested traffic scenarios. The paper highlights the importance of momentary predictions in emergency situations where immediate and precise trajectory predictions are crucial for avoiding collisions. The authors propose a unified input formulation that integrates three types of information between adjacent frames: velocity of agents, social context, and scene context. These types of information provide valuable clues for predicting short-term behaviors and long-term trends of movements. A momentary observation feature extractor (MOE) is introduced to extract a joint historical representation from the input and improve the performance of momentary trajectory prediction frameworks. Unlike previous approaches that require feature alignment between social and scene context, the proposed method avoids this burden by integrating the information at the data level and encoding the input in a unified manner. This approach also addresses the challenge of fitting prediction models to reduced observation spaces by introducing a soft pre-training mechanism for the MOE. The soft pre-training involves several sub-tasks related to trajectory prediction that are easier to learn, effectively improving the MOE's ability to map the reduced observation space to the original prediction space.Experiments conducted on ETH/UCY and Stanford Drone Dataset demonstrate the performance of existing state-of-the-art approaches in the momentary prediction setting. The adoption of the MOE into multiple prediction frameworks also yields significant improvements in trajectory prediction.