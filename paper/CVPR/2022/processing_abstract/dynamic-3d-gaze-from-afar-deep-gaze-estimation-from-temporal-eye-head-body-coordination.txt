We introduce a novel method and dataset for 3D gaze estimation of a freely moving person from a distance, typi-cally in surveillance views. Eyes cannot be clearly seen in such cases due to occlusion and lacking resolution. Exist-ing gaze estimation methods suffer or fall back to approxi-mating gaze with head pose as they primarily rely on clear, close-up views of the eyes. Our key idea is to instead lever-age the intrinsic gaze, head, and body coordination of peo-ple. Our method formulates gaze estimation as Bayesian prediction given temporal estimates of head and body ori-entations which can be reliably estimated from a far. We model the head and body orientation likelihoods and the conditional prior of gaze direction on those with separate neural networks which are then cascaded to output the 3D gaze direction. We introduce an extensive new dataset that consists of surveillance videos annotated with 3D gaze di-rections captured in 5 indoor and outdoor scenes. Experi-mental results on this and other datasets validate the accu-racy of our method and demonstrate that gaze can be accu-rately estimated from a typical surveillance distance even when the personâ€™s face is not visible to the camera. 