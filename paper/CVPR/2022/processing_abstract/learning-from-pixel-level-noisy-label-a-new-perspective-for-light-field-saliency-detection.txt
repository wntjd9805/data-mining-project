Saliency detection with light field images is becoming at-tractive given the abundant cues available, however, this comes at the expense of large-scale pixel level annotatedIn this paper, we data which is expensive to generate. propose to learn light field saliency from pixel-level noisy labels obtained from unsupervised hand crafted featured-based saliency methods. Given this goal, a natural question is: can we efficiently incorporate the relationships among light field cues while identifying clean labels in a unified framework? We address this question by formulating the learning as a joint optimization of intra light field features fusion stream and inter scenes correlation stream to gen-erate the predictions. Specially, we first introduce a pixel forgetting guided fusion module to mutually enhance the light field features and exploit pixel consistency across it-erations to identify noisy pixels. Next, we introduce a cross scene noise penalty loss for better reflecting latent struc-tures of training data and enabling the learning to be in-variant to noise. Extensive experiments on multiple bench-mark datasets demonstrate the superiority of our framework showing that it learns saliency prediction comparable to state-of-the-art fully supervised light field saliency meth-ods. Our code is available at https://github.com/OLobbCode/NoiseLF. 