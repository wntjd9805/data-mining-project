Recently, the semantics of scene text has been proven to be essential in fine-grained image classification. However, the existing methods mainly exploit the literal meaning of scene text for fine-grained recognition, which might be irrel-evant when it is not significantly related to objects/scenes.We propose an end-to-end trainable network that mines im-plicit contextual knowledge behind scene text image and en-hance the semantics and correlation to fine-tune the image representation. Unlike the existing methods, our model in-tegrates three modalities: visual feature extraction, text se-mantics extraction, and correlating background knowledge to fine-grained image classification. Specifically, we em-ploy KnowBert to retrieve relevant knowledge for seman-tic representation and combine it with image features for fine-grained classification. Experiments on two benchmark datasets, Con-Text, and Drink Bottle, show that our method outperforms the state-of-the-art by 3.72% mAP and 5.39% mAP, respectively. To further validate the effectiveness of the proposed method, we create a new dataset on crowd ac-tivity recognition for the evaluation. The source code and new dataset of this work are available at this repository1. 