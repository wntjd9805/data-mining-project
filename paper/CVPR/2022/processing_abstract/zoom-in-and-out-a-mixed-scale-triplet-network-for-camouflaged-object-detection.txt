The recently proposed camouflaged object detection (COD) attempts to segment objects that are visually blended into their surroundings, which is extremely complex and dif-ficult in real-world scenarios. Apart from high intrinsic similarity between the camouflaged objects and their back-ground, the objects are usually diverse in scale, fuzzy in appearance, and even severely occluded. To deal with these problems, we propose a mixed-scale triplet network, Zoom-Net, which mimics the behavior of humans when observing vague images, i.e., zooming in and out. Specifically, ourZoomNet employs the zoom strategy to learn the discrim-inative mixed-scale semantics by the designed scale inte-gration unit and hierarchical mixed-scale unit, which fully explores imperceptible clues between the candidate objects and background surroundings. Moreover, considering the uncertainty and ambiguity derived from indistinguishable textures, we construct a simple yet effective regularization constraint, uncertainty-aware loss, to promote the model to accurately produce predictions with higher confidence in candidate regions. Without bells and whistles, our pro-posed highly task-friendly model consistently surpasses the existing 23 state-of-the-art methods on four public datasets.Besides, the superior performance over the recent cutting-edge models on the SOD task also verifies the effectiveness and generality of our model. The code will be available at https://github.com/lartpang/ZoomNet. 