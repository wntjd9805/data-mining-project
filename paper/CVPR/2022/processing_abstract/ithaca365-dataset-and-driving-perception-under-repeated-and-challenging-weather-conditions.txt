Advances in perception for self-driving cars have accel-erated in recent years due to the availability of large-scale datasets, typically collected at speciﬁc locations and under nice weather conditions. Yet, to achieve the high safety re-quirement, these perceptual systems must operate robustly under a wide variety of weather conditions including snow and rain. In this paper, we present a new dataset to enable robust autonomous driving via a novel data collection pro-cess — data is repeatedly recorded along a 15 km route un-der diverse scene (urban, highway, rural, campus), weather (snow, rain, sun), time (day/night), and trafﬁc conditions (pedestrians, cyclists and cars). The dataset includes im-ages and point clouds from cameras and LiDAR sensors, along with high-precision GPS/INS to establish correspon-dence across routes. The dataset includes road and object annotations using amodal masks to capture partial occlu-sions and 3D bounding boxes. We demonstrate the unique-ness of this dataset by analyzing the performance of base-lines in amodal segmentation of road and objects, depth estimation, and 3D object detection. The repeated routes opens new research directions in object discovery, contin-ual learning, and anomaly detection. Link to Ithaca365: https://ithaca365.mae.cornell.edu/ 