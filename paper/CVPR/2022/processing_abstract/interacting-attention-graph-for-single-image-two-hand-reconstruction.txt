Graph convolutional network (GCN) has achieved great success in single hand reconstruction task, while interact-ing two-hand reconstruction by GCN remains unexplored.In this paper, we present Interacting Attention Graph Hand the first graph convolution based network (IntagHand), that reconstructs two interacting hands from a single RGB image. To solve occlusion and interaction challenges of two-hand reconstruction, we introduce two novel attention based modules in each upsampling step of the originalGCN. The first module is the pyramid image feature at-tention (PIFA) module, which utilizes multiresolution fea-tures to implicitly obtain vertex-to-image alignment. The second module is the cross hand attention (CHA) module that encodes the coherence of interacting hands by build-ing dense cross-attention between two hand vertices. As a result, our model outperforms all existing two-hand re-construction methods by a large margin on InterHand2.6M benchmark. Moreover, ablation studies verify the effec-tiveness of both PIFA and CHA modules for improving the reconstruction accuracy. Results on in-the-wild im-ages and live video streams further demonstrate the gen-eralization ability of our network. Our code is available at https://github.com/Dw1010/IntagHand. 