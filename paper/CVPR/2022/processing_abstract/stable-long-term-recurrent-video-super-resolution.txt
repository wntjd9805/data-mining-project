Recurrent models have gained popularity in deep learn-ing (DL) based video super-resolution (VSR), due to their increased computational efficiency, temporal receptive field and temporal consistency compared to sliding-window based models. However, when inferring on long video se-quences presenting low motion (i.e. in which some parts of the scene barely move), recurrent models diverge through recurrent processing, generating high frequency artifacts.To the best of our knowledge, no study about VSR pointed out this instability problem, which can be critical for some real-world applications. Video surveillance is a typical ex-ample where such artifacts would occur, as both the camera and the scene stay static for a long time.In this work, we expose instabilities of existing recur-rent VSR networks on long sequences with low motion. We demonstrate it on a new long sequence dataset Quasi-StaticVideo Set, that we have created. Finally, we introduce a new framework of recurrent VSR networks that is both sta-ble and competitive, based on Lipschitz stability theory. We propose a new recurrent VSR network, coined Middle Re-current Video Super-Resolution (MRVSR), based on this framework. We empirically show its competitive perfor-mance on long sequences with low motion. 