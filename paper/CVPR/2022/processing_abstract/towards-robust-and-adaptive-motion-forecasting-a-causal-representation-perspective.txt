Learning behavioral patterns from observational data has been a de-facto approach to motion forecasting. Yet, the current paradigm suffers from two shortcomings: brittle under distribution shifts and inefficient for knowledge trans-fer. In this work, we propose to address these challenges from a causal representation perspective. We first introduce a causal formalism of motion forecasting, which casts the problem as a dynamic process with three groups of latent variables, namely invariant variables, style confounders, and spurious features. We then introduce a learning frame-work that treats each group separately: (i) unlike the com-mon practice mixing datasets collected from different loca-tions, we exploit their subtle distinctions by means of an invariance loss encouraging the model to suppress spuri-ous correlations; (ii) we devise a modular architecture that factorizes the representations of invariant mechanisms and style confounders to approximate a sparse causal graph; (iii) we introduce a style contrastive loss that not only en-forces the structure of style representations but also serves as a self-supervisory signal for test-time refinement on the fly. Experiments on synthetic and real datasets show that our proposed method improves the robustness and reusabil-ity of learned motion representations, significantly outper-forming prior state-of-the-art motion forecasting models for out-of-distribution generalization and low-shot transfer. 