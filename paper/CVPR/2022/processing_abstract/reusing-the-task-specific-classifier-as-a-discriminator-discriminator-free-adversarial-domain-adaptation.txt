Adversarial learning has achieved remarkable perfor-mances for unsupervised domain adaptation (UDA). Exist-ing adversarial UDA methods typically adopt an additional discriminator to play the min-max game with a feature ex-tractor. However, most of these methods failed to effectively leverage the predicted discriminative information, and thus cause mode collapse for generator. In this work, we ad-dress this problem from a different perspective and design a simple yet effective adversarial paradigm in the form of a discriminator-free adversarial learning network (DALN), wherein the category classifier is reused as a discrimina-tor, which achieves explicit domain alignment and category distinguishment through a unified objective, enabling theDALN to leverage the predicted discriminative information for sufficient feature alignment. Basically, we introduce aNuclear-norm Wasserstein discrepancy (NWD) that has defi-nite guidance meaning for performing discrimination. SuchNWD can be coupled with the classifier to serve as a discrim-inator satisfying the K-Lipschitz constraint without the re-quirements of additional weight clipping or gradient penalty strategy. Without bells and whistles, DALN compares favor-ably against the existing state-of-the-art (SOTA) methods on a variety of public datasets. Moreover, as a plug-and-play technique, NWD can be directly used as a generic regular-izer to benefit existing UDA algorithms. Code is available at https://github.com/xiaoachen98/DALN . 