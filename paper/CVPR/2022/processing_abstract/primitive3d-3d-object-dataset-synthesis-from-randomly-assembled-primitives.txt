Numerous advancements in deep learning can be at-tributed to the access to large-scale and well-annotated datasets. However, such a dataset is prohibitively expensive in 3D computer vision due to the substantial collection cost.To alleviate this issue, we propose a cost-effective method for automatically generating a large amount of 3D objects with annotations. In particular, we synthesize objects sim-ply by assembling multiple random primitives. These ob-jects are thus auto-annotated with part labels originating from primitives. This allows us to perform multi-task learn-ing by combining the supervised segmentation with unsu-pervised reconstruction. Considering the large overhead of learning on the generated dataset, we further propose a dataset distillation strategy to remove redundant samples regarding a target dataset. We conduct extensive experi-ments for the downstream tasks of 3D object classification.The results indicate that our dataset, together with multi-task pretraining on its annotations, achieves the best perfor-mance compared to other commonly used datasets. Further study suggests that our strategy can improve the model per-formance by pretraining and fine-tuning scheme, especially for the dataset with a small scale. In addition, pretraining with the proposed dataset distillation method can save 86% of the pretraining time with negligible performance degra-dation. We expect that our attempt provides a new data-centric perspective for training 3D deep models. 