Monocular depth estimation is vital for scene under-standing and downstream tasks. We focus on the super-vised setup, in which ground-truth depth is available only at training time. Based on knowledge about the high reg-ularity of real 3D scenes, we propose a method that learns to selectively leverage information from coplanar pixels to improve the predicted depth. In particular, we introduce a piecewise planarity prior which states that for each pixel, there is a seed pixel which shares the same planar 3D sur-face with the former. Motivated by this prior, we design a network with two heads. The ﬁrst head outputs pixel-level plane coefﬁcients, while the second one outputs a dense off-set vector ﬁeld that identiﬁes the positions of seed pixels.The plane coefﬁcients of seed pixels are then used to predict depth at each position. The resulting prediction is adap-tively fused with the initial prediction from the ﬁrst head via a learned conﬁdence to account for potential devia-tions from precise local planarity. The entire architecture is trained end-to-end thanks to the differentiability of the pro-posed modules and it learns to predict regular depth maps, with sharp edges at occlusion boundaries. An extensive evaluation of our method shows that we set the new state of the art in supervised monocular depth estimation, surpass-ing prior methods on NYU Depth-v2 and on the Garg split of KITTI. Our method delivers depth maps that yield plau-sible 3D reconstructions of the input scenes. Code is avail-able at: https://github.com/SysCV/P3Depth 