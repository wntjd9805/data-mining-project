Weakly supervised temporal action localization aims to localize temporal boundaries of actions and simultaneously identify their categories with only video-level category la-bels. Many existing methods seek to generate pseudo la-bels for bridging the discrepancy between classification and localization, but usually only make use of limited contex-tual information for pseudo label generation. To alleviate this problem, we propose a representative snippet summa-rization and propagation framework. Our method seeks to mine the representative snippets in each video for propagat-ing information between video snippets to generate better pseudo labels. For each video, its own representative snip-pets and the representative snippets from a memory bank are propagated to update the input features in an intra-and inter-video manner. The pseudo labels are generated from the temporal class activation maps of the updated fea-tures to rectify the predictions of the main branch. Our method obtains superior performance in comparison to the existing methods on two benchmarks, THUMOS14 and Ac-tivityNet1.3, achieving gains as high as 1.2% in terms of average mAP on THUMOS14. Our code is available at https://github.com/LeonHLJ/RSKP. 