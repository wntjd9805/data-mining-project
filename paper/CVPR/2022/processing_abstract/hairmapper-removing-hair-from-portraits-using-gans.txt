Removing hair from portrait images is challenging due to the complex occlusions between hair and face, as well as the lack of paired portrait data with/without hair. To this end, we present a dataset and a baseline method for removing hair from portrait images using generative adver-sarial networks (GANs). Our core idea is to train a fully connected network HairM apper to find the direction of hair removal in the latent space of StyleGAN for the train-ing stage. We develop a new separation boundary and dif-fuse method to generate paired training data for males, and a novel “female-male-bald” pipeline for paired data of fe-males. Experiments show that our method can naturally deal with portrait images with variations on gender, age, etc. We validate the superior performance of our method*Corresponding author. by comparing it to state-of-the-art methods through exten-sive experiments and user studies. We also demonstrate its applications in hair design and 3D face reconstruction. 