Both accuracy and efficiency are crucial for image cap-tioning in real-world scenarios. Although Transformer-based models have gained significant improved captioning performance, their computational cost is very high. A fea-sible way to reduce the time complexity is to exit the predic-tion early in internal decoding layers without passing the entire model. However, it is not straightforward to devise early exiting into image captioning due to the following is-sues. On one hand, the representation in shallow layers lacks high-level semantic and sufficient cross-modal fusion information for accurate prediction. On the other hand, the exiting decisions made by internal classifiers are unreli-able sometimes. To solve these issues, we propose DeeCap framework for efficient image captioning, which dynami-cally selects proper-sized decoding layers from a global perspective to exit early. The key to successful early exiting lies in the specially designed imitation learning mechanism, which predicts the deep layer activation with shallow layer features. By deliberately merging the imitation learning into the whole image captioning architecture, the imitated deep layer representation can mitigate the loss brought by the missing of actual deep layers when early exiting is un-dertaken, resulting in significant reduction in calculation cost with small sacrifice of accuracy. Experiments on theMS COCO and Flickr30k datasets demonstrate the DeeCap can achieve competitive performances with 4Ã— speed-up.Code is available at: https://github.com/feizc/DeeCap. 