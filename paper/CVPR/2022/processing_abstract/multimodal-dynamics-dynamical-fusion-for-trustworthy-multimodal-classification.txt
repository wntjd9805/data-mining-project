Integration of heterogeneous and high-dimensional data (e.g., multiomics) is becoming increasingly important. Ex-isting multimodal classification algorithms mainly focus on improving performance by exploiting the complemen-tarity from different modalities. However, conventional approaches are basically weak in providing trustworthy multimodal fusion, especially for safety-critical applica-tions (e.g., medical diagnosis). For this issue, we pro-pose a novel trustworthy multimodal classification algo-rithm termed Multimodal Dynamics, which dynamically evaluates both the feature-level and modality-level infor-mativeness for different samples and thus trustworthily in-tegrates multiple modalities. Specifically, a sparse gat-ing is introduced to capture the information variation of each within-modality feature and the true class probability is employed to assess the classification confidence of each modality. Then a transparent fusion algorithm based on the dynamical informativeness estimation strategy is induced.To the best of our knowledge, this is the first work to jointly model both feature and modality variation for different sam-ples to provide trustworthy fusion in multi-modal classifica-tion. Extensive experiments are conducted on multimodal medical classification datasets. In these experiments, supe-rior performance and trustworthiness of our algorithm are clearly validated compared to the state-of-the-art methods. 