Label-to-image translation models generate images from semantic label maps. Existing models depend on large vol-umes of pixel-level annotated samples. When given new training samples annotated with novel semantic classes, the models should be trained from scratch with both learned and new classes. This hinders their practical applications and motivates us to introduce an incremental learning strat-egy to the label-to-image translation scenario. In this pa-per, we introduce a few-shot incremental learning method for label-to-image translation.It learns new classes one by one from a few samples of each class. We propose to adopt semantically-adaptive convolution ﬁlters and nor-malization. When incrementally trained on a novel seman-tic class, the model only learns a few extra parameters of class-speciﬁc modulation. Such design avoids catastrophic forgetting of already-learned semantic classes and enables label-to-image translation of scenes with increasingly rich content. Furthermore, to facilitate few-shot learning, we propose a modulation transfer strategy for better initializa-tion. Extensive experiments show that our method outper-forms existing related methods in most cases and achieves zero forgetting. 