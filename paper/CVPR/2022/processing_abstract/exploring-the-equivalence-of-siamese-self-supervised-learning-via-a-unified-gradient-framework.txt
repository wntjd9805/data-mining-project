Self-supervised learning has shown its great potential to extract powerful visual representations without human an-notations. Various works are proposed to deal with self-supervised learning from different perspectives: (1) con-trastive learning methods (e.g., MoCo, SimCLR) utilize both positive and negative samples to guide the training direc-tion; (2) asymmetric network methods (e.g., BYOL, Sim-Siam) get rid of negative samples via the introduction of a predictor network and the stop-gradient operation; (3) fea-ture decorrelation methods (e.g., Barlow Twins, VICReg) instead aim to reduce the redundancy between feature di-mensions. These methods appear to be quite different in the designed loss functions from various motivations. The ﬁ-nal accuracy numbers also vary, where different networks and tricks are utilized in different works. In this work, we demonstrate that these methods can be uniﬁed into the same form. Instead of comparing their loss functions, we derive a uniﬁed formula through gradient analysis. Furthermore, we conduct fair and detailed experiments to compare their performances. It turns out that there is little gap between these methods, and the use of momentum encoder is the key factor to boost performance.From this uniﬁed framework, we propose UniGrad, a simple but effective gradient form for self-supervised learn-ing.It does not require a memory bank or a predictor network, but can still achieve state-of-the-art performance and easily adopt other training strategies. Extensive experi-ments on linear evaluation and many downstream tasks also show its effectiveness. Code shall be released.∗Equal contribution.†This work is done when Chenxin Tao,Honghui Wang, and Jiahua Dong are interns at SenseTime Research.BCorresponding author.Figure 1. Overview of three typical types of self-supervised learn-ing methods and our proposed UniGrad. u1 and u2 are two aug-mented views of the same image. v denote views of other images.We ﬁnd these methods have a similar gradient structure composed of the positive and negative gradients, which can be analogous to positive and negative samples in contrastive learning. Because some methods do not explicitly utilize negative samples, we high-light the source of negative gradient in each method. 