Instance contrast for unsupervised representation learn-In this ing has achieved great success in recent years. work, we explore the idea of instance contrastive learn-ing in unsupervised domain adaptation (UDA) and pro-pose a novel Category Contrast technique (CaCo) that in-troduces semantic priors on top of instance discrimination for visual UDA tasks. By considering instance contrastive learning as a dictionary look-up operation, we construct a semantics-aware dictionary with samples from both source and target domains where each target sample is assigned a (pseudo) category label based on the category priors of source samples. This allows category contrastive learn-ing (between target queries and the category-level dictio-nary) for category-discriminative yet domain-invariant fea-ture representations: samples of the same category (from ei-ther source or target domain) are pulled closer while those of different categories are pushed apart simultaneously. Ex-tensive UDA experiments in multiple visual tasks (e.g., seg-mentation, classiÔ¨Åcation and detection) show that CaCo achieves superior performance as compared with state-of-the-art methods. The experiments also demonstrate thatCaCo is complementary to existing UDA methods and gen-eralizable to other learning setups such as unsupervised model adaptation, open-/partial-set adaptation etc. 