(cid:3)(cid:18)(cid:19)(cid:24)(cid:18)(cid:1)(cid:2)(cid:12)(cid:23)(cid:15)(cid:19)(cid:18)(cid:22) (cid:8)(cid:18)(cid:16)(cid:18)(cid:19)(cid:24)(cid:18)(cid:1)(cid:2)(cid:12)(cid:23)(cid:15)(cid:19)(cid:18)(cid:22) (cid:4)(cid:16)(cid:15)(cid:10)(cid:3)(cid:19)(cid:14)(cid:17) (cid:2)(cid:12)(cid:10)(cid:11)(cid:3)(cid:19)(cid:14)(cid:17) (cid:2)(cid:6)(cid:14)(cid:14)(cid:9)(cid:18)(cid:5)(cid:11)(cid:18)(cid:16)(cid:20)Temporal Action Localization (TAL) has experienced re-markable success under the supervised learning paradigm.However, existing TAL methods are rooted in the closed set assumption, which cannot handle the inevitable unknown actions in open-world scenarios. In this paper, we, for theﬁrst time, step toward the Open Set TAL (OSTAL) problem and propose a general framework OpenTAL based on Ev-idential Deep Learning (EDL). Speciﬁcally, the OpenTAL consists of uncertainty-aware action classiﬁcation, action-ness prediction, and temporal location regression. With the proposed importance-balanced EDL method, classiﬁ-cation uncertainty is learned by collecting categorical ev-idence majorly from important samples. To distinguish the unknown actions from background video frames, the ac-tionness is learned by the positive-unlabeled learning. The classiﬁcation uncertainty is further calibrated by leverag-ing the guidance from the temporal localization quality. TheOpenTAL is general to enable existing TAL models for open set scenarios, and experimental results on THUMOS14 andActivityNet1.3 benchmarks show the effectiveness of our method. The code and pre-trained models are released at https://www.rit.edu/actionlab/opental. 