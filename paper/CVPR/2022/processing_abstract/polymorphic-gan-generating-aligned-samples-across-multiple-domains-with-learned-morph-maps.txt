Modern image generative models show remarkable sam-ple quality when trained on a single domain or class of objects. In this work, we introduce a generative adversar-ial network that can simultaneously generate aligned im-age samples from multiple related domains. We leverage the fact that a variety of object classes share common at-tributes, with certain geometric differences. We proposePolymorphic-GAN which learns shared features across all domains and a per-domain morph layer to morph shared features according to each domain.In contrast to previ-ous works, our framework allows simultaneous modelling of images with highly varying geometries, such as images of human faces, painted and artistic faces, as well as mul-tiple different animal faces. We demonstrate that our model produces aligned samples for all domains and show how it can be used for applications such as segmentation trans-fer and cross-domain image editing, as well as training in low-data regimes. Additionally, we apply our Polymorphic-GAN on image-to-image translation tasks and show that we can greatly surpass previous approaches in cases where the geometric differences between domains are large. 