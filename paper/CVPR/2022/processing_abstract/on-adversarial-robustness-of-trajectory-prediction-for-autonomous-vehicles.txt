Trajectory prediction is a critical component for au-tonomous vehicles (AVs) to perform safe planning and navi-gation. However, few studies have analyzed the adversarial robustness of trajectory prediction or investigated whether the worst-case prediction can still lead to safe planning. To bridge this gap, we study the adversarial robustness of tra-jectory prediction models by proposing a new adversarial attack that perturbs normal vehicle trajectories to maxi-mize the prediction error. Our experiments on three models and three datasets show that the adversarial prediction in-creases the prediction error by more than 150%. Our case studies show that if an adversary drives a vehicle close to the target AV following the adversarial trajectory, the AV may make an inaccurate prediction and even make unsafe driving decisions. We also explore possible mitigation tech-niques via data augmentation and trajectory smoothing. 