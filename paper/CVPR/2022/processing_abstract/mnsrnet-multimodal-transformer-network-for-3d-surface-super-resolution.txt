With the rapid development of display technology, it has become an urgent need to obtain realistic 3D surfaces with as high-quality as possible. Due to the unstructured and irregular nature of 3D object data, it is usually difficult to obtain high-quality surface details and geometry tex-tures at a low cost.In this article, we propose an effec-tive multimodal-driven deep neural network to perform 3D surface super-resolution in 2D normal domain, which is simple, accurate, and robust to the above difficulty. To leverage the multimodal information from different perspec-tives, we jointly consider the texture, depth, and normal modalities to simultaneously restore fine-grained surface details as well as preserve geometry structures. To better utilize the cross-modality information, we explore a two-bridge normal method with a transformer structure for fea-ture alignment, and investigate an affine transform mod-ule for fusing multimodal features. Extensive experimen-tal results on public and our newly constructed photometric stereo dataset demonstrate that the proposed method deliv-ers promising surface geometry details compared with nine competitive schemes. 