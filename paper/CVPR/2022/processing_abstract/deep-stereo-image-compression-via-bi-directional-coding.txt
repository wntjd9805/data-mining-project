Existing learning-based stereo compression methods usually adopt a unidirectional approach to encoding one image independently and the other image conditioned uponThis paper proposes a novel bi-directional the ﬁrst. coding-based end-to-end stereo image compression net-work (BCSIC-Net). BCSIC-Net consists of a novel bi-directional contextual transform module which performs nonlinear transform conditioned upon the inter-view con-text in a latent space to reduce inter-view redundancy, and a bi-directional conditional entropy model that employs inter-view correspondence as a conditional prior to improve cod-ing efﬁciency. Experimental results on the InStereo2K andKITTI datasets demonstrate that the proposed BCSIC-Net can effectively reduce the inter-view redundancy and out-performs state-of-the-art methods. 