page is at https://github.com/hitachinsk/ISVI.Physical objects have inertia, which resists changes in the velocity and motion direction. Inspired by this, we in-troduce inertia prior that optical flow, which reflects ob-ject motion in a local temporal window, keeps unchanged in the adjacent preceding or subsequent frame. We pro-pose a flow completion network to align and aggregate flow features from the consecutive flow sequences based on the inertia prior. The corrupted flows are completed un-der the supervision of customized losses on reconstruction, flow smoothness, and consistent ternary census transform.The completed flows with high fidelity give rise to signifi-cant improvement on the video inpainting quality. Never-theless, the existing flow-guided cross-frame warping meth-ods fail to consider the lightening and sharpness variation across video frames, which leads to spatial incoherence af-ter warping from other frames. To alleviate such prob-lem, we propose the Adaptive Style Fusion Network (ASFN), which utilizes the style information extracted from the valid regions to guide the gradient refinement in the warped re-gions. Moreover, we design a data simulation pipeline to re-duce the training difficulty of ASFN. Extensive experiments show the superiority of our method against the state-of-the-art methods quantitatively and qualitatively. The projectThis work is supported by the Natural Science Foundation of China under Grant 62036005 and Grant 62022075, and by the Fundamental Re-search Funds for the Central Universities under Grant WK3490000006. K.Zhang performed this work at Microsoft Research Asia. 