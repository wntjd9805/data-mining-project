Blind face restoration is to recover a high-quality face image from unknown degradations. As face image contains abundant contextual information, we propose a method,RestoreFormer, which explores fully-spatial attentions to model contextual information and surpasses existing works that use local operators. RestoreFormer has several ben-efits compared to prior arts. First, unlike the conven-tional multi-head self-attention in previous Vision Trans-formers (ViTs), RestoreFormer incorporates a multi-head cross-attention layer to learn fully-spatial interactions be-tween corrupted queries and high-quality key-value pairs.Second, the key-value pairs in ResotreFormer are sam-pled from a reconstruction-oriented high-quality dictionary, whose elements are rich in high-quality facial features specifically aimed for face reconstruction, leading to su-*This work is supported by the General Research Fund of HKNo.27208720 and 17212120. perior restoration results. Third, RestoreFormer outper-forms advanced state-of-the-art methods on one synthetic dataset and three real-world datasets, as well as produces images with better visual quality. Code is available at https://github.com/wzhouxiff/RestoreFormer.git. 