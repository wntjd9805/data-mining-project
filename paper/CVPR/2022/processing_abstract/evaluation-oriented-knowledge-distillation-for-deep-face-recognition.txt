Knowledge distillation (KD) is a widely-used technique that utilizes large networks to improve the performance of compact models. Previous KD approaches usually aim to guide the student to mimic the teacherâ€™s behavior com-pletely in the representation space. However, such one-to-one corresponding constraints may lead to inflexible knowl-edge transfer from the teacher to the student, especially those with low model capacities.Inspired by the ulti-mate goal of KD methods, we propose a novel Evaluation-oriented KD method (EKD) for deep face recognition to di-rectly reduce the performance gap between the teacher and student models during training. Specifically, we adopt the commonly used evaluation metrics in face recognition, i.e.,False Positive Rate (FPR) and True Positive Rate (TPR) as the performance indicator. According to the evalua-tion protocol, the critical pair relations that cause the TPR and FPR difference between the teacher and student models are selected. Then, the critical relations in the student are constrained to approximate the corresponding ones in the teacher by a novel rank-based loss function, giving more flexibility to the student with low capacity. Extensive ex-perimental results on popular benchmarks demonstrate the superiority of our EKD over state-of-the-art competitors.Figure 1.Illustration of critical relations of samples. Different colors indicate different models (Teacher T in blue and StudentS in green). Different shapes indicate samples of different sub-jects. The numbers denote the cosine similarities of samples. The relation of the 1st and the 3rd samples is the only one whose sim-ilarities fall on the different side of the threshold in teacher and student models (i.e., 0.6 > 0.55 in teacher while 0.5 < 0.55 in student), and thus leads to the TPR difference. Therefore, in order to pursue the same TPR of the teacher, the student which has lim-ited model capability should pay more attention on the relation (in red) of the 1st and the 3rd samples which is the critical relation.Similarly, for the negative pairs, the relation of 1st and 5th samples leads to the FPR difference and should be paid more attention. 