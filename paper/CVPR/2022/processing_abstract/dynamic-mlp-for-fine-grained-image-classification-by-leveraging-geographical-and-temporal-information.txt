Fine-grained image classiﬁcation is a challenging com-puter vision task where various species share similar vi-sual appearances, resulting in misclassiﬁcation if merely based on visual clues. Therefore, it is helpful to leverage additional information, e.g., the locations and dates for data shooting, which can be easily accessible but rarely exploited.In this paper, we ﬁrst demonstrate that exist-ing multimodal methods fuse multiple features only on a single dimension, which essentially has insufﬁcient help in feature discrimination. To fully explore the potential of multimodal information, we propose a dynamic MLP on top of the image representation, which interacts with mul-timodal features at a higher and broader dimension. The dynamic MLP is an efﬁcient structure parameterized by the learned embeddings of variable locations and dates. It can be regarded as an adaptive nonlinear projection for gener-ating more discriminative image representations in visual tasks. To our best knowledge, it is the ﬁrst attempt to ex-plore the idea of dynamic networks to exploit multimodal information in ﬁne-grained image classiﬁcation tasks. Ex-tensive experiments demonstrate the effectiveness of our method. The t-SNE algorithm visually indicates that our technique improves the recognizability of image representa-tions that are visually similar but with different categories.Furthermore, among published works across multiple ﬁne-grained datasets, dynamic MLP consistently achieves SOTA results1 and takes third place in the iNaturalist challenge atFGVC82. Code is available at https://github.com/megvii-research/DynamicMLPForFinegrained.*Corresponding author. †Works is done as interns in Megvii Research.Lingfeng Yang, Xiang Li, Juntian Tao, and Jian Yang are from PCA Lab,Key Lab of Intelligent Perception and Systems for High-Dimensional In-formation of Ministry of Education, and Jiangsu Key Lab of Image andVideo Understanding for Social Security, School of Computer Science andEngineering, Nanjing University of Science and Technology. 1https://paperswithcode.com/dataset/inaturalist 2https://www.kaggle.com/c/inaturalist-2021/leaderboard (a) (b) (c) (d) (e)Figure 1. Visualization of t-SNE [44] representations under well trained models. Various similar species from the genus Turdus in the iNaturalist 2021 dataset are depicted in different colors. (a):The visualization of an image-only model. (b): Concatenating the image, location, and date features before the classiﬁcation head is a typical strategy of utilizing additional information to help clas-siﬁcation. The concatenated representation is more discrimina-tive than the original. The concatenation strategy can be regarded as a baseline for all methods that involve additional information. (c): Intuitively, our proposed dynamic MLP expands the diversity among different ﬁne-grained species compared to the image-only or concatenation framework. (d): The 3-d visualization of image representation from the concatenation strategy. (e): The 3-d visu-alization of our dynamic MLP. 