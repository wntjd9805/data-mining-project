We propose the task of forecasting characteristic 3d from a short sequence observation of a person, poses: predict a future 3d pose of that person in a likely action-defining, characteristic pose â€“ for instance, from observing a person picking up an apple, predict the pose of the per-son eating the apple. Prior work on human motion predic-tion estimates future poses at fixed time intervals. Although easy to define, this frame-by-frame formulation confounds temporal and intentional aspects of human action. Instead, we define a semantically meaningful pose prediction task that decouples the predicted pose from time, taking inspira-tion from goal-directed behavior. To predict characteristic poses, we propose a probabilistic approach that models the possible multi-modality in the distribution of likely char-acteristic poses. We then sample future pose hypotheses from the predicted distribution in an autoregressive fash-ion to model dependencies between joints. To evaluate our method, we construct a dataset of manually annotated char-acteristic 3d poses. Our experiments with this dataset sug-gest that our proposed probabilistic approach outperforms state-of-the-art methods by 26% on average. 