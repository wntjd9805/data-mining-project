Consistency learning using input image, feature, or net-work perturbations has shown remarkable results in semi-supervised semantic segmentation, but this approach can be seriously affected by inaccurate predictions of unlabelled training images. There are two consequences of these in-accurate predictions: 1) the training based on the “strict” cross-entropy (CE) loss can easily overfit prediction mis-takes, leading to confirmation bias; and 2) the perturba-tions applied to these inaccurate predictions will use poten-tially erroneous predictions as training signals, degrading consistency learning. In this paper, we address the predic-tion accuracy problem of consistency learning methods with novel extensions of the mean-teacher (MT) model, which include a new auxiliary teacher, and the replacement ofMT’s mean square error (MSE) by a stricter confidence-weighted cross-entropy (Conf-CE) loss. The accurate pre-diction by this model allows us to use a challenging com-bination of network, input data and feature perturbations to improve the consistency learning generalisation, where the feature perturbations consist of a new adversarial per-turbation. Results on public benchmarks show that our ap-proach achieves remarkable improvements over the previ-ous SOTA methods in the field.1 Our code is available at https://github.com/yyliu01/PS-MT. 