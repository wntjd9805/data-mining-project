User-level differential privacy (DP) provides certifiable privacy guarantees to the information that is specific to any userâ€™s data in federated learning. Existing methods that ensure user-level DP come at the cost of severe accu-racy decrease. In this paper, we study the cause of model performance degradation in federated learning with user-level DP guarantee. We find the key to solving this issue is to naturally restrict the norm of local updates before ex-ecuting operations that guarantee DP. To this end, we pro-pose two techniques, Bounded Local Update Regularization and Local Update Sparsification, to increase model quality without sacrificing privacy. We provide theoretical analy-sis on the convergence of our framework and give rigorous privacy guarantees. Extensive experiments show that our framework significantly improves the privacy-utility trade-off over the state-of-the-arts for federated learning with user-level DP guarantee. 