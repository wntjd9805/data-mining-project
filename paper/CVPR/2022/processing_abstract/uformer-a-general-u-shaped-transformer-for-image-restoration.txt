In this paper, we present Uformer, an effective and efﬁ-cient Transformer-based architecture for image restoration, in which we build a hierarchical encoder-decoder networkIn Uformer, there are two using the Transformer block. core designs. First, we introduce a novel locally-enhanced window (LeWin) Transformer block, which performs non-overlapping window-based self-attention instead of global self-attention.It signiﬁcantly reduces the computational complexity on high resolution feature map while capturing local context. Second, we propose a learnable multi-scale restoration modulator in the form of a multi-scale spatial bias to adjust features in multiple layers of the Uformer decoder. Our modulator demonstrates superior capabil-ity for restoring details for various image restoration tasks while introducing marginal extra parameters and compu-tational cost. Powered by these two designs, Uformer en-joys a high capability for capturing both local and global dependencies for image restoration. To evaluate our ap-proach, extensive experiments are conducted on several im-age restoration tasks, including image denoising, motion deblurring, defocus deblurring and deraining. Without bells and whistles, our Uformer achieves superior or compara-ble performance compared with the state-of-the-art algo-rithms. The code and models are available at https://github.com/ZhendongWang6/Uformer. 