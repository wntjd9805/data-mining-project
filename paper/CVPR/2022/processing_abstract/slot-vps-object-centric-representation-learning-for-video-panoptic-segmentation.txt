Video Panoptic Segmentation (VPS) aims at assigning a class label to each pixel, uniquely segmenting and identify-ing all object instances consistently across all frames. Clas-sic solutions usually decompose the VPS task into several sub-tasks and utilize multiple surrogates (e.g. boxes and masks, centers and offsets) to represent objects. However, this divide-and-conquer strategy requires complex post-processing in both spatial and temporal domains and is vul-nerable to failures from surrogate tasks. In this paper, in-spired by object-centric learning which learns compact and robust object representations, we present Slot-VPS, the first end-to-end framework for this task. We encode all panoptic entities in a video, including both foreground instances and background semantics, with a unified representation called panoptic slots. The coherent spatio-temporal objectâ€™s in-formation is retrieved and encoded into the panoptic slots by the proposed Video Panoptic Retriever, enabling to local-ize, segment, differentiate, and associate objects in a unified manner. Finally, the output panoptic slots can be directly converted into the class, mask, and object ID of panoptic objects in the video. We conduct extensive ablation stud-ies and demonstrate the effectiveness of our approach on two benchmark datasets, Cityscapes-VPS (val and test sets) and VIPER (val set), achieving new state-of-the-art perfor-mance of 63.7, 63.3 and 56.2 VPQ, respectively. 