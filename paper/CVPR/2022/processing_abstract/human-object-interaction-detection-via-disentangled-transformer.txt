Human-Object Interaction Detection tackles the problem of joint localization and classiﬁcation of human object in-teractions. Existing HOI transformers either adopt a sin-gle decoder for triplet prediction, or utilize two parallel de-coders to detect individual objects and interactions sepa-rately, and compose triplets by a matching process. In con-trast, we decouple the triplet prediction into human-object pair detection and interaction classiﬁcation. Our main mo-tivation is that detecting the human-object instances and classifying interactions accurately needs to learn represen-tations that focus on different regions. To this end, we present Disentangled Transformer, where both encoder and decoder are disentangled to facilitate learning of two sub-tasks. To associate the predictions of disentangled de-coders, we ﬁrst generate a uniﬁed representation for HOI triplets with a base decoder, and then utilize it as input fea-ture of each disentangled decoder. Extensive experiments show that our method outperforms prior work on two pub-lic HOI benchmarks by a sizeable margin. Code will be available. 