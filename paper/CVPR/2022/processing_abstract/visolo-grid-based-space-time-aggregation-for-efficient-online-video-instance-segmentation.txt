For online video instance segmentation (VIS), fully uti-lizing the information from previous frames in an efficient manner is essential for real-time applications. Most previ-ous methods follow a two-stage approach requiring addi-tional computations such as RPN and RoIAlign, and do not fully exploit the available information in the video for all subtasks in VIS. In this paper, we propose a novel single-stage framework for online VIS built based on the grid structured feature representation. The grid-based features allow us to employ fully convolutional networks for real-time processing, and also to easily reuse and share fea-tures within different components. We also introduce co-operatively operating modules that aggregate information from available frames, in order to enrich the features for all subtasks in VIS. Our design fully takes advantage of pre-vious information in a grid form for all tasks in VIS in an efficient way, and we achieved the new state-of-the-art ac-curacy (38.6 AP and 36.9 AP) and speed (40.0 FPS) onYouTube-VIS 2019 and 2021 datasets among online VIS methods. The code is available at https://github. com/SuHoHan95/VISOLO. 