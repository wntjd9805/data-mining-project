Few-Shot Image Classiﬁcation (FSIC) aims to recognize novel image classes with limited data, which is signiﬁcant in practice. In this paper, we consider the FSIC problem in the case of adversarial examples. This is an extremely challenging issue because current deep learning methods are still vulnerable when handling adversarial examples, even with massive labeled training samples. For this prob-lem, existing works focus on training a network in the meta-learning fashion that depends on numerous sampled few-shot tasks. In comparison, we propose a simple but effec-tive baseline through directly learning generalizable repre-sentations without tedious task sampling, which is robust to unforeseen adversarial FSIC tasks. Speciﬁcally, we intro-duce an adversarial-aware mechanism to establish auxil-iary supervision via feature-level differences between legit-imate and adversarial examples. Furthermore, we design a novel adversarial-reweighted training manner to alleviate the imbalance among adversarial examples. The feature puriﬁer is also employed as post-processing for adversarial features. Moreover, our method can obtain generalizable representations to remain superior transferability, even fac-ing cross-domain adversarial examples. Extensive exper-iments show that our method can signiﬁcantly outperform state-of-the-art adversarially robust FSIC methods on two standard benchmarks. 