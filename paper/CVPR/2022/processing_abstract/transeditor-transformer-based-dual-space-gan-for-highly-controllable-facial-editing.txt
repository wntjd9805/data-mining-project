Recent advances like StyleGAN have promoted the growth of controllable facial editing. To address its core challenge of attribute decoupling in a single latent space, attempts have been made to adopt dual-space GAN for bet-ter disentanglement of style and content representations.Nonetheless, these methods are still incompetent to ob-tain plausible editing results with high controllability, es-pecially for complicated attributes. In this study, we high-light the importance of interaction in a dual-space GAN for more controllable editing. We propose TransEditor, a novelTransformer-based framework to enhance such interaction.Besides, we develop a new dual-space editing and inversion strategy to provide additional editing flexibility. Extensive experiments demonstrate the superiority of the proposed framework in image quality and editing capability, suggest-ing the effectiveness of TransEditor for highly controllable facial editing. Code and models are publicly available at https://github.com/BillyXYB/TransEditor.âˆ— Two authors have equal contributions, ordered alphabetically. This work was done during an internship at Shanghai AI Laboratory.