Few-shot font generation (FFG), which aims to generate a new font with a few examples, is gaining increasing at-tention due to the significant reduction in labor cost. A typ-ical FFG pipeline considers characters in a standard font library as content glyphs and transfers them to a new tar-get font by extracting style information from the reference glyphs. Most existing solutions explicitly disentangle con-tent and style of reference glyphs globally or component-wisely. However, the style of glyphs mainly lies in the local details, i.e. the styles of radicals, components, and strokes together depict the style of a glyph. Therefore, even a sin-gle character can contain different styles distributed over spatial locations. In this paper, we propose a new font gen-eration approach by learning 1) the fine-grained local styles from references, and 2) the spatial correspondence between the content and reference glyphs. Therefore, each spatial location in the content glyph can be assigned with the right fine-grained style. To this end, we adopt cross-attention over the representation of the content glyphs as the queries and the representations of the reference glyphs as the keys and values.Instead of explicitly disentangling global or component-wise modeling, the cross-attention mechanism can attend to the right local styles in the reference glyphs and aggregate the reference styles into a fine-grained style representation for the given content glyphs. The experi-ments show that the proposed method outperforms the state-of-the-art methods in FFG. In particular, the user studies also demonstrate the style consistency of our approach sig-nificantly outperforms previous methods. 