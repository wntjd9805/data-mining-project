The wavelet scattering transform creates geometric in-variants and deformation stability. In multiple signal do-mains, it has been shown to yield more discriminative rep-resentations compared to other non-learned representations and to outperform learned representations in certain tasks, particularly on limited labeled data and highly structured signals. The wavelet ﬁlters used in the scattering trans-form are typically selected to create a tight frame via a pa-rameterized mother wavelet. In this work, we investigate whether this standard wavelet ﬁlterbank construction is op-timal. Focusing on Morlet wavelets, we propose to learn the scales, orientations, and aspect ratios of the ﬁlters to produce problem-speciﬁc parameterizations of the scatter-ing transform. We show that our learned versions of the scattering transform yield signiﬁcant performance gains in small-sample classiﬁcation settings over the standard scat-tering transform. Moreover, our empirical results suggest that traditional ﬁlterbank constructions may not always be necessary for scattering transforms to extract effective rep-resentations. 