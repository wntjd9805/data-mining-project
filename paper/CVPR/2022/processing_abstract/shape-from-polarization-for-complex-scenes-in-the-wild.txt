We present a new data-driven approach with physics-based priors to scene-level normal estimation from a single polarization image. Existing shape from polarization (SfP) works mainly focus on estimating the normal of a single ob-ject rather than complex scenes in the wild. A key barrier to high-quality scene-level SfP is the lack of real-world SfP data in complex scenes. Hence, we contribute the first real-world scene-level SfP dataset with paired input polarization images and ground-truth normal maps. Then we propose a learning-based framework with a multi-head self-attention module and viewing encoding, which is designed to handle increasing polarization ambiguities caused by complex ma-terials and non-orthographic projection in scene-level SfP.Our trained model can be generalized to far-field outdoor scenes as the relationship between polarized light and sur-face normals is not affected by distance. Experimental re-sults demonstrate that our approach significantly outper-forms existing SfP models on two datasets. Our dataset and source code will be publicly available at https://github.com/ChenyangLEI/sfp-wild.Input IunInput ϕWithout pol.With pol.Figure 1. Our method can estimate dense scene-level surface nor-mals from a single polarization image. Polarization can provide effective cues for obtaining more accurate results. In the first row, polarization provides geometry cues for our model so that it is not fooled by objects in the printed image on a wall. In the second and third rows, polarization provides guidance for planes with dif-ferent surface normals even when their materials are quite similar.Iun: unpolarized image; ϕ: angle of polarization. 