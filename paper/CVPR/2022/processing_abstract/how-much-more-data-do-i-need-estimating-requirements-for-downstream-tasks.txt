Given a small training data set and a learning algo-rithm, how much more data is necessary to reach a target validation or test performance? This question is of criti-cal importance in applications such as autonomous driving or medical imaging where collecting data is expensive and time-consuming. Overestimating or underestimating data requirements incurs substantial costs that could be avoided with an adequate budget. Prior work on neural scaling laws suggest that the power-law function can ﬁt the valida-tion performance curve and extrapolate it to larger data set sizes. We ﬁnd that this does not immediately translate to the more difﬁcult downstream task of estimating the required data set size to meet a target performance. In this work, we consider a broad class of computer vision tasks and system-atically investigate a family of functions that generalize the power-law function to allow for better estimation of data requirements. Finally, we show that incorporating a tuned correction factor and collecting over multiple rounds sig-niﬁcantly improves the performance of the data estimators.Using our guidelines, practitioners can accurately estimate data requirements of machine learning systems to gain sav-ings in both development time and data acquisition costs. 