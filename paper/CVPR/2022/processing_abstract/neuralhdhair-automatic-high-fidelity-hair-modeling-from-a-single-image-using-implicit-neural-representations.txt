Undoubtedly, high-ﬁdelity 3D hair plays an indispens-able role in digital humans. However, existing monocular hair modeling methods are either tricky to deploy in digital systems (e.g., due to their dependence on complex user in-teractions or large databases) or can produce only a coarse geometry. In this paper, we introduce NeuralHDHair, a ﬂex-ible, fully automatic system for modeling high-ﬁdelity hair from a single image. The key enablers of our system are two carefully designed neural networks: an IRHairNet (Im-plicit representation for hair using neural network) for in-ferring high-ﬁdelity 3D hair geometric features (3D orien-tation ﬁeld and 3D occupancy ﬁeld) hierarchically and aGrowingNet (Growing hair strands using neural network) to efﬁciently generate 3D hair strands in parallel. Specif-ically, we perform a coarse-to-ﬁne manner and propose a novel voxel-aligned implicit function (VIFu) to represent the global hair feature, which is further enhanced by the local details extracted from a hair luminance map. To improve the efﬁciency of a traditional hair growth algorithm, we adopt a local neural implicit function to grow strands based on the estimated 3D hair geometric features. Extensive ex-periments show that our method is capable of construct-ing a high-ﬁdelity 3D hair model from a single image, both efﬁciently and effectively, and achieves the-state-of-the-art performance. 