As acquiring pixel-wise annotations of real-world im-ages for semantic segmentation is a costly process, a model can instead be trained with more accessible synthetic data and adapted to real images without requiring their annota-tions. This process is studied in unsupervised domain adap-tation (UDA). Even though a large number of methods pro-pose new adaptation strategies, they are mostly based on outdated network architectures. As the inﬂuence of recent network architectures has not been systematically studied, we ﬁrst benchmark different network architectures for UDA and newly reveal the potential of Transformers for UDA se-mantic segmentation. Based on the ﬁndings, we propose a novel UDA method, DAFormer. The network architecture ofDAFormer consists of a Transformer encoder and a multi-It is enabled level context-aware feature fusion decoder. by three simple but crucial training strategies to stabilize the training and to avoid overﬁtting to the source domain:While (1) Rare Class Sampling on the source domain im-proves the quality of the pseudo-labels by mitigating the conﬁrmation bias of self-training toward common classes, (2) a Thing-Class ImageNet Feature Distance and (3) a learning rate warmup promote feature transfer from Ima-geNet pretraining. DAFormer represents a major advance in UDA. It improves the state of the art by 10.8 mIoU forGTA→Cityscapes and 5.4 mIoU for Synthia→Cityscapes and enables learning even difﬁcult classes such as train, bus, and truck well. The implementation is available at https://github.com/lhoyer/DAFormer. 