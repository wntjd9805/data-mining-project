Neural implicit functions have recently shown promis-ing results on surface reconstructions from multiple views.However, current methods still suffer from excessive time complexity and poor robustness when reconstructing un-bounded or complex scenes.In this paper, we presentRegSDF, which shows that proper point cloud supervi-sions and geometry regularizations are sufficient to pro-duce high-quality and robust reconstruction results. Specif-ically, RegSDF takes an additional oriented point cloud as input, and optimizes a signed distance field and a sur-face light field within a differentiable rendering framework.We also introduce the two critical regularizations for this optimization. The first one is the Hessian regularization that smoothly diffuses the signed distance values to the en-tire distance field given noisy and incomplete input. And the second one is the minimal surface regularization that compactly interpolates and extrapolates the missing geome-try. Extensive experiments are conducted on DTU, Blended-MVS, and Tanks and Temples datasets. Compared with re-cent neural surface reconstruction approaches, RegSDF is able to reconstruct surfaces with fine details even for open scenes with complex topologies and unstructured camera trajectories. 