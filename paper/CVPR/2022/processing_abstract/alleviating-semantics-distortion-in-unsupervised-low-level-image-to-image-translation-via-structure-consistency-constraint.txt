Unsupervised image-to-image (I2I) translation aims to learn a domain mapping function that can preserve the se-mantics of the input images without paired data. However, because the underlying semantics distributions in the source and target domains are often mismatched, current distri-bution matching-based methods may distort the semantics when matching distributions, resulting in the inconsistency between the input and translated images, which is known as the semantics distortion problem. In this paper, we focus on the low-level I2I translation, where the structure of images is highly related to their semantics. To alleviate semantic distortions in such translation tasks without paired supervi-sion, we propose a novel I2I translation constraint, calledStructure Consistency Constraint (SCC), to promote the con-sistency of image structures by reducing the randomness of color transformation in the translation process. To facilitate estimation and maximization of SCC, we propose an approx-imate representation of mutual information called relativeSquared-loss Mutual Information (rSMI) that enjoys efﬁcient analytic solutions. Our SCC can be easily incorporated into most existing translation models. Quantitative and quali-tative comparisons on a range of low-level I2I translation tasks show that translation models with SCC outperform the original models by a signiﬁcant margin with little additional computational and memory costs. 