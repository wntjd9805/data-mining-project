Graph Neural Networks (GNNs) with attention have been successfully applied for learning visual feature match-ing. However, current methods learn with complete graphs, resulting in a quadratic complexity in the number of fea-tures. Motivated by a prior observation that self- and cross- attention matrices converge to a sparse represen-tation, we propose ClusterGNN, an attentional GNN ar-chitecture which operates on clusters for learning the fea-ture matching task. Using a progressive clustering mod-ule we adaptively divide keypoints into different subgraphs to reduce redundant connectivity, and employ a coarse-to-fine paradigm for mitigating miss-classification within im-ages. Our approach yields a 59.7% reduction in runtime and 58.4% reduction in memory consumption for dense de-tection, compared to current state-of-the-art GNN-based matching, while achieving a competitive performance on various computer vision tasks. 