: Visual features: Class seed embedding: Linguistic features: Inner productPatch-level predictionReferring image segmentation is an advanced semantic segmentation task where target is not a predeﬁned class but is described in natural language. Most of existing meth-ods for this task rely heavily on convolutional neural net-works, which however have trouble capturing long-range dependencies between entities in the language expression and are not ﬂexible enough for modeling interactions be-tween the two different modalities. To address these issues, we present the ﬁrst convolution-free model for referring im-age segmentation using transformers, dubbed ReSTR. Since it extracts features of both modalities through transformer encoders, it can capture long-range dependencies between entities within each modality. Also, ReSTR fuses features of the two modalities by a self-attention encoder, which en-ables ﬂexible and adaptive interactions between the two modalities in the fusion process. The fused features are fed to a segmentation module, which works adaptively accord-ing to the image and language expression in hand. ReSTR is evaluated and compared with previous work on all public benchmarks, where it outperforms all existing models. 