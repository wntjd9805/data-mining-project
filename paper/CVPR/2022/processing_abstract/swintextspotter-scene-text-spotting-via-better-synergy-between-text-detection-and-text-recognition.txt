End-to-end scene text spotting has attracted great at-tention in recent years due to the success of excavat-ing the intrinsic synergy of the scene text detection and recognition. However, recent state-of-the-art methods usu-ally incorporate detection and recognition simply by shar-ing the backbone, which does not directly take advan-tage of the feature interaction between the two tasks.In this paper, we propose a new end-to-end scene text spot-ting framework termed SwinTextSpotter. Using a trans-former encoder with dynamic head as the detector, we unify the two tasks with a novel Recognition Conversion mechanism to explicitly guide text localization through recognition loss. The straightforward design results in a concise framework that requires neither additional rec-tiﬁcation module nor character-level annotation for the arbitrarily-shaped text. Qualitative and quantitative experi-ments on multi-oriented datasets RoIC13 and ICDAR 2015, arbitrarily-shaped datasets Total-Text and CTW1500, and multi-lingual datasets ReCTS (Chinese) and VinText (Viet-namese) demonstrate SwinTextSpotter signiﬁcantly outper-forms existing methods. Code is available at https://github.com/mxin262/SwinTextSpotter. 