Generalized zero-shot learning (GZSL) requires a clas-siﬁer trained on seen classes that can recognize objects from both seen and unseen classes. Due to the absence the classiﬁer tends to bias of unseen training samples, towards seen classes. To mitigate this problem, feature generation based models are proposed to synthesize visu-al features for unseen classes. However, these features are generated in the visual feature space which lacks of discriminative ability. Therefore, some methods turn toﬁnd a better embedding space for the classiﬁer training.They emphasize the inter-class relationships of seen classes, leading the embedding space overﬁtted to seen classes and unfriendly to unseen classes.Instead, in this paper, we propose an Intra-Class Compactness Enhancement method (ICCE) for GZSL. Our ICCE promotes intra-class com-pactness with inter-class separability on both seen and unseen classes in the embedding space and visual feature space. By promoting the intra-class relationships but the inter-class structures, we can distinguish different classes with better generalization. Speciﬁcally, we propose a Self-Distillation Embedding (SDE) module and a Semantic-Visual Contrastive Generation (SVCG) module. The former promotes intra-class compactness in the embedding space, while the latter accomplishes it in the visual feature space.The experiments demonstrate that our ICCE outperforms the state-of-the-art methods on four datasets and achieves competitive results on the remaining dataset. 