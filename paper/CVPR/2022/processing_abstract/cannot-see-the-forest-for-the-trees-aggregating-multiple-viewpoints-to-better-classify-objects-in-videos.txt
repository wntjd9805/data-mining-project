Recently, both long-tailed recognition and object track-ing have made great advances individually. TAO bench-mark presented a mixture of the two, long-tailed object tracking, in order to further reﬂect the aspect of the real-world. To date, existing solutions have adopted detectors showing robustness in long-tailed distributions, which de-rive per-frame results. Then, they used tracking algorithms that combine the temporally independent detections to ﬁnal-ize tracklets. However, as the approaches did not take tem-poral changes in scenes into account, inconsistent classiﬁ-cation results in videos led to low overall performance. In this paper, we present a set classiﬁer that improves accuracy of classifying tracklets by aggregating information from multiple viewpoints contained in a tracklet. To cope with sparse annotations in videos, we further propose augmen-tation of tracklets that can maximize data efﬁciency. The set classiﬁer is plug-and-playable to existing object track-ers, and highly improves the performance of long-tailed ob-ject tracking. By simply attaching our method to QDTrack on top of ResNet-101, we achieve the new state-of-the-art, 19.9% and 15.7% TrackAP50 on TAO validation and test sets, respectively. Our code is available at this link1. 