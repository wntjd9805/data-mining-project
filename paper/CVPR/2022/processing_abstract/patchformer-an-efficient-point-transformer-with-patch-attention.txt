The point cloud learning community witnesses a mod-eling shift from CNNs to Transformers, where pure Trans-former architectures have achieved top accuracy on the ma-jor learning benchmarks. However, existing point Trans-formers are computationally expensive since they need to generate a large attention map, which has quadratic com-plexity (both in space and time) with respect to input size. To solve this shortcoming, we introduce Patch ATtention (PAT) to adaptively learn a much smaller set of bases upon which the attention maps are computed. By a weighted summation upon these bases, PAT not only captures the global shape context but also achieves linear complexity to input size. In addition, we propose a lightweight Multi-Scale aTtention (MST) block to build attentions among features of differ-ent scales, providing the model with multi-scale features.Equipped with the PAT and MST, we construct our neural architecture called PatchFormer that integrates both mod-ules into a joint framework for point cloud learning. Ex-tensive experiments demonstrate that our network achieves comparable accuracy on general point cloud learning tasks with 9.2Ã— speed-up than previous point Transformers. 