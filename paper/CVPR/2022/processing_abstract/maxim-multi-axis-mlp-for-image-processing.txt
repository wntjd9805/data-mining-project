Recent progress on Transformers and multi-layer per-ceptron (MLP) models provide new network architectural designs for computer vision tasks. Although these models proved to be effective in many vision tasks such as image recognition, there remain challenges in adapting them for low-level vision. The inﬂexibility to support high-resolution images and limitations of local attention are perhaps the main bottlenecks. In this work, we present a multi-axis MLP based architecture called MAXIM, that can serve as an ef-ﬁcient and ﬂexible general-purpose vision backbone for im-age processing tasks. MAXIM uses a UNet-shaped hierar-chical structure and supports long-range interactions en-abled by spatially-gated MLPs. Speciﬁcally, MAXIM con-tains two MLP-based building blocks: a multi-axis gatedMLP that allows for efﬁcient and scalable spatial mixing of local and global visual cues, and a cross-gating block, an alternative to cross-attention, which accounts for cross-feature conditioning. Both these modules are exclusively based on MLPs, but also beneﬁt from being both global and ‘fully-convolutional’, two properties that are desirable for image processing. Our extensive experimental results show that the proposed MAXIM model achieves state-of-the-art performance on more than ten benchmarks across a range of image processing tasks, including denoising, de-blurring, deraining, dehazing, and enhancement while re-quiring fewer or comparable numbers of parameters andFLOPs than competitive models. The source code and trained models will be available at https://github. com/google-research/maxim. 