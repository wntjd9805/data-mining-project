Various approaches have been proposed for out-of-distribution (OOD) detection by augmenting models, input examples, training sets, and optimization objectives. Devi-ating from existing work, we have a simple hypothesis that standard off-the-shelf models may already contain sufﬁcient information about the training set distribution which can be leveraged for reliable OOD detection. Our empirical study on validating this hypothesis, which measures the model activation’s mean for OOD and in-distribution (ID) mini-batches, surprisingly ﬁnds that activation means of OOD mini-batches consistently deviate more from those of the training data. In addition, training data’s activation means can be computed ofﬂine efﬁciently or retrieved from batch normalization layers as a ‘free lunch’. Based upon this ob-servation, we propose a novel metric called Neural MeanDiscrepancy (NMD), which compares neural means of the input examples and training data. Leveraging the simplicity of NMD, we propose an efﬁcient OOD detector that com-putes neural means by a standard forward pass followed by a lightweight classiﬁer. Extensive experiments show thatNMD outperforms state-of-the-art OOD approaches across multiple datasets and model architectures in terms of both detection accuracy and computational cost. 