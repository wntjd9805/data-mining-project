Self-supervised learning (SSL) holds promise in lever-aging large amounts of unlabeled data. However, the suc-cess of popular SSL methods has limited on single-centric-object images like those in ImageNet and ignores the cor-relation among the scene and instances, as well as the se-mantic difference of instances in the scene. To address the above problems, we propose a Unified Self-supervised Vi-sual Pre-training (UniVIP), a novel self-supervised frame-work to learn versatile visual representations on either single-centric-object or non-iconic dataset. The frame-work takes into account the representation learning at three levels: 1) the similarity of scene-scene, 2) the correla-tion of scene-instance, 3) the discrimination of instance-instance. During the learning, we adopt the optimal trans-port algorithm to automatically measure the discrimina-tion of instances. Massive experiments show that Uni-VIP pre-trained on non-iconic COCO achieves state-of-the-art transfer performance on a variety of downstream tasks, such as image classification, semi-supervised learn-ing, object detection and segmentation. Furthermore, our method can also exploit single-centric-object dataset such as ImageNet and outperforms BYOL by 2.5% with the same pre-training epochs in linear probing, and surpass current self-supervised object detection methods on COCO dataset, demonstrating its universality and potential. 