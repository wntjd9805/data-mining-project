Automatic generation of ophthalmic reports using data-driven neural networks has great potential in clinical prac-tice. When writing a report, ophthalmologists make infer-ences with prior clinical knowledge. This knowledge has been neglected in prior medical report generation meth-ods. To endow models with the capability of incorporat-ing expert knowledge, we propose a Cross-modal clinicalGraph Transformer (CGT) for ophthalmic report genera-tion (ORG), in which clinical relation triples are injected into the visual features as prior knowledge to drive the de-coding procedure. However, two major common Knowl-edge Noise (KN) issues may affect modelsâ€™ effectiveness. 1) Existing general biomedical knowledge bases such as theUMLS may not align meaningfully to the specific context and language of the report, limiting their utility for knowl-edge injection. 2) Incorporating too much knowledge may divert the visual features from their correct meaning. To overcome these limitations, we design an automatic infor-mation extraction scheme based on natural language pro-cessing to obtain clinical entities and relations directly from in-domain training reports. Given a set of ophthalmic im-ages, our CGT first restores a sub-graph from the clini-cal graph and injects the restored triples into visual fea-tures. Then visible matrix is employed during the encod-ing procedure to limit the impact of knowledge. Finally, reports are predicted by the encoded cross-modal features via a Transformer decoder. Extensive experiments on the large-scale FFA-IR benchmark demonstrate that the pro-posed CGT is able to outperform previous benchmark meth-ods and achieve state-of-the-art performances. 