Surface reconstruction from point clouds is vital for 3D computer vision. State-of-the-art methods leverage large datasets to ﬁrst learn local context priors that are repre-sented as neural network-based signed distance functions (SDFs) with some parameters encoding the local contexts.To reconstruct a surface at a speciﬁc query location at in-ference time, these methods then match the local recon-struction target by searching for the best match in the lo-cal prior space (by optimizing the parameters encoding the local context) at the given query location. However, this re-quires the local context prior to generalize to a wide variety of unseen target regions, which is hard to achieve. To re-solve this issue, we introduce Predictive Context Priors by learning Predictive Queries for each speciﬁc point cloud at inference time. Speciﬁcally, we ﬁrst train a local context prior using a large point cloud dataset similar to previous techniques. For surface reconstruction at inference time, however, we specialize the local context prior into our Pre-dictive Context Prior by learning Predictive Queries, which predict adjusted spatial query locations as displacements of the original locations. This leads to a global SDF thatﬁts the speciﬁc point cloud the best. Intuitively, the query prediction enables us to ﬂexibly search the learned local context prior over the entire prior space, rather than being restricted to the ﬁxed query locations, and this improves the generalizability. Our method does not require ground truth signed distances, normals, or any additional procedure of signed distance fusion across overlapping regions. Our experimental results in surface reconstruction for single shapes or complex scenes show signiﬁcant improvements over the state-of-the-art under widely used benchmark-∗The corresponding author is Yu-Shen Liu. This work was sup-ported by National Key R&D Program of China (2018YFB0505400, 2020YFF0304100), the National Natural Science Foundation of China (62072268), the National Natural Science Foundation (1813583) and in part by Tsinghua-Kuaishou Institute of Future Media Data. s. Code and data are available at https://github. com/mabaorui/PredictableContextPrior. 