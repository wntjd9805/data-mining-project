Person image generation aims to perform non-rigid de-formation on source images, which generally requires un-aligned data pairs for training. Recently, self-supervised methods express great prospects in this task by merging the disentangled representations for self-reconstruction. How-ever, such methods fail to exploit the spatial correlation between the disentangled features. In this paper, we pro-pose a Self-supervised Correlation Mining Network (SCM-Net) to rearrange the source images in the feature space, in which two collaborative modules are integrated, Decom-posed Style Encoder (DSE) and Correlation Mining Module (CMM). Specifically, the DSE first creates unaligned pairs at the feature level. Then, the CMM establishes the spa-tial correlation field for feature rearrangement. Eventually, a translation module transforms the rearranged features to realistic results. Meanwhile, for improving the fidelity of cross-scale pose transformation, we propose a graph basedBody Structure Retaining Loss (BSR Loss) to preserve rea-sonable body structures on half body to full body gener-ation. Extensive experiments conducted on DeepFashion dataset demonstrate the superiority of our method com-â€ Corresponding author. pared with other supervised and unsupervised approaches.Furthermore, satisfactory results on face generation show the versatility of our method in other deformation tasks. 