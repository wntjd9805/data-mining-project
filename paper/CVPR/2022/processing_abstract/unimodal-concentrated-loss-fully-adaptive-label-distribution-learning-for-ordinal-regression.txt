Learning from a label distribution has achieved promis-ing results on ordinal regression tasks such as facial age and head pose estimation wherein, the concept of adaptive label distribution learning (ALDL) has drawn lots of atten-tion recently for its superiority in theory. However, com-pared with the methods assuming fixed form label distribu-tion, ALDL methods have not achieved better performance.We argue that existing ALDL algorithms do not fully ex-ploit the intrinsic properties of ordinal regression. In this paper, we emphatically summarize that learning an adap-tive label distribution on ordinal regression tasks should follow three principles. First, the probability correspond-ing to the ground-truth should be the highest in label dis-tribution. Second, the probabilities of neighboring labels should decrease with the increase of distance away from the ground-truth, i.e., the distribution is unimodal. Third, the label distribution should vary with samples changing, and even be distinct for different instances with the same label, due to the different levels of difficulty and ambiguity.Under the premise of these principles, we propose a novel loss function for fully adaptive label distribution learning, namely unimodal-concentrated loss. Specifically, the uni-modal loss derived from the learning to rank strategy con-strains the distribution to be unimodal. Furthermore, the estimation error and the variance of the predicted distribu-tion for a specific sample are integrated into the proposed concentrated loss to make the predicted distribution maxi-mize at the ground-truth and vary according to the predict-ing uncertainty. Extensive experimental results on typical ordinal regression tasks including age and head pose es-timation, show the superiority of our proposed unimodal-concentrated loss compared with existing loss functions.∗Authors contribute equally to this work.†Shiliang Pu is the corresponding author.Figure 1. Distributions predicted by Mean-Variance method [22] and ours. Our predictions are optimized to be unimodal and learned according to specific instances adaptively. On the contrary, predictions of Mean-Variance are optimized to be concentrated for all instances and do not ensure unimodal distributions explicitly. 