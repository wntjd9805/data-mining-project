In spite of the dominant performances of deep neural networks, recent works have shown that they are poorly calibrated, resulting in over-confident predictions. Miscal-ibration can be exacerbated by overfitting due to the mini-mization of the cross-entropy during training, as it promotes the predicted softmax probabilities to match the one-hot la-bel assignments. This yields a pre-softmax activation of the correct class that is significantly larger than the remaining activations. Recent evidence from the literature suggests that loss functions that embed implicit or explicit maximiza-tion of the entropy of predictions yield state-of-the-art cal-ibration performances. We provide a unifying constrained-optimization perspective of current state-of-the-art calibra-tion losses. Specifically, these losses could be viewed as approximations of a linear penalty (or a Lagrangian term) imposing equality constraints on logit distances. This points to an important limitation of such underlying equality con-straints, whose ensuing gradients constantly push towards a non-informative solution, which might prevent from reach-ing the best compromise between the discriminative perfor-mance and calibration of the model during gradient-based optimization. Following our observations, we propose a simple and flexible generalization based on inequality con-straints, which imposes a controllable margin on logit dis-tances. Comprehensive experiments on a variety of image classification, semantic segmentation and NLP benchmarks demonstrate that our method sets novel state-of-the-art re-sults on these tasks in terms of network calibration, without affecting the discriminative performance. The code is avail-able at https://github.com/by-liu/MbLS . 