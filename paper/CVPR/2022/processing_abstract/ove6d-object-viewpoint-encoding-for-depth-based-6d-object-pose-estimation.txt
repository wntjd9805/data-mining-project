This paper proposes a universal framework, calledOVE6D, for model-based 6D object pose estimation from a single depth image and a target object mask. Our model is trained using purely synthetic data rendered from ShapeNet, and, unlike most of the existing methods, it generalizes well on new real-world objects without any fine-tuning. We achieve this by decomposing the 6D pose into viewpoint, in-plane rotation around the camera optical axis and transla-tion, and introducing novel lightweight modules for estimat-ing each component in a cascaded manner. The resulting network contains less than 4M parameters while demon-strating excellent performance on the challenging T-LESS and Occluded LINEMOD datasets without any dataset-specific training. We show that OVE6D outperforms some contemporary deep learning-based pose estimation meth-ods specifically trained for individual objects or datasets with real-world training data. The implementation is avail-able at https://github.com/dingdingcai/OVE6D-pose. 