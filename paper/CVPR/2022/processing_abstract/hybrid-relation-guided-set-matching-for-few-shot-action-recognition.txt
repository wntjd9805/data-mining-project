Current few-shot action recognition methods reach im-pressive performance by learning discriminative features for each video via episodic training and designing various temporal alignment strategies. Nevertheless, they are lim-ited in that (a) learning individual features without consid-ering the entire task may lose the most relevant informa-tion in the current episode, and (b) these alignment strate-gies may fail in misaligned instances. To overcome the two limitations, we propose a novel Hybrid Relation guidedSet Matching (HyRSM) approach that incorporates two key components: hybrid relation module and set matching met-ric. The purpose of the hybrid relation module is to learn task-specific embeddings by fully exploiting associated re-lations within and cross videos in an episode. Built upon the task-specific features, we reformulate distance measure be-tween query and support videos as a set matching problem and further design a bidirectional Mean Hausdorff Metric to improve the resilience to misaligned instances. By this means, the proposed HyRSM can be highly informative and flexible to predict query categories under the few-shot set-tings. We evaluate HyRSM on six challenging benchmarks, and the experimental results show its superiority over the state-of-the-art methods by a convincing margin. Project page: https://hyrsm-cvpr2022.github.io/. 