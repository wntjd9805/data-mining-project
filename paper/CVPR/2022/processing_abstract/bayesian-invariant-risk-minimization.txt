Generalization under distributional shift is an open chal-lenge for machine learning.Invariant Risk Minimization (IRM) is a promising framework to tackle this issue by ex-tracting invariant features. However, despite the potential and popularity of IRM, recent works have reported nega-tive results of it on deep models. We argue that the fail-ure can be primarily attributed to deep modelsâ€™ tendency to overfit the data. Specifically, our theoretical analysis shows that IRM degenerates to empirical risk minimization (ERM) when overfitting occurs. Our empirical evidence also provides supports: IRM methods that work well in typ-ical settings significantly deteriorate even if we slightly en-large the model size or lessen the training data. To alle-viate this issue, we propose Bayesian Invariant Risk Min-imization (BIRM) by introducing Bayesian inference into the IRM. The key motivation is to estimate the penalty ofIRM based on the posterior distribution of classifiers (as opposed to a single classifier), which is much less prone to overfitting. Extensive experimental results on four datasets demonstrate that BIRM consistently outperforms the exist-ing IRM baselines significantly. 