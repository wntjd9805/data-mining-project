To learn camera-view invariant features for person Re-IDentification (Re-ID), the cross-camera image pairs of each person play an important role. However, such cross-view training samples could be unavailable under the ISo-lated Camera Supervised (ISCS) setting, e.g., a surveillance system deployed across distant scenes. To handle this chal-lenging problem, a new pipeline is introduced by synthesiz-ing the cross-camera samples in the feature space for model training. Specifically, the feature encoder and generator are end-to-end optimized under a novel method, Camera-Conditioned Stable Feature Generation (CCSFG). Its joint learning procedure raises concern on the stability of gen-erative model training. Therefore, a new feature genera-tor, σ-Regularized Conditional Variational Autoencoder (σ-Reg. CVAE), is proposed with theoretical and experimental analysis on its robustness. Extensive experiments on twoISCS person Re-ID datasets demonstrate the superiority of our CCSFG to the competitors. 1Figure 1.Illustrations of the training samples under different person Re-ID settings. The light-blue areas indicate the feature space. Different shapes corresponding to identities. Different col-ors mean under different cameras. (a) Cross-camera person images are available under the conventional settings. (b) No cross-camera image pairs under the ISCS setting for model training. 