Human skeleton-based action recognition offers a valu-able means to understand the intricacies of human behav-ior because it can handle the complex relationships be-tween physical constraints and intention. Although several studies have focused on encoding a skeleton, less atten-tion has been paid to embed this information into the la-tent representations of human action.InfoGCN proposes a learning framework for action recognition combining a novel learning objective and an encoding method. First, we design an information bottleneck-based learning objec-tive to guide the model to learn informative but compact latent representations. To provide discriminative informa-tion for classifying action, we introduce attention-based graph convolution that captures the context-dependent in-trinsic topology of human action. In addition, we present a multi-modal representation of the skeleton using the rel-ative position of joints, designed to provide complemen-InfoGCN1 surpasses tary spatial information for joints. the known state-of-the-art on multiple skeleton-based ac-tion recognition benchmarks with the accuracy of 93.0% on NTU RGB+D 60 cross-subject split, 89.8% on NTURGB+D 120 cross-subject split, and 97.0% on NW-UCLA. 