In this work, we focus on scene flow learning on point clouds in a self-supervised manner. A real-world scene can be well modeled as a collection of rigidly moving parts, therefore its scene flow can be represented as a combina-tion of rigid motion of each part. Inspired by this obser-vation, we propose to generate pseudo scene flow for self-supervised learning based on piecewise rigid motion es-timation, in which the source point cloud is decomposed into a set of local regions and each region is treated as rigid. By rigidly aligning each region with its potential counterpart in the target point cloud, we obtain a region-specific rigid transformation to represent the flow, which together constitutes the pseudo scene flow labels of the en-tire scene to enable network training. Compared with most existing approaches relying on point-wise similarities for scene flow approximation, our method explicitly enforces region-wise rigid alignments, yielding locally rigid pseudo scene flow labels. We demonstrate the effectiveness of our self-supervised learning method on FlyingThings3D andKITTI datasets. Comprehensive experiments show that our method achieves new state-of-the-art performance in self-supervised scene flow learning, without any ground truth scene flow for supervision, even outperforming some super-vised counterparts.Figure 1. Comparison of the pseudo scene flow labels produced by nearest neighbor search and our proposed method. (a) Input point clouds from two consecutive frames; (b) Pseudo labels generated by the point matching with per-point nearness as a measure; (c)Pseudo labels generated by our proposed method. Green line rep-resents the correct pseudo label with absolute error less than 0.1m or relative error less than 10%. Red line represents the incorrect pseudo label. 