Recent advances in deep learning have relied on large, labelled datasets to train high-capacity models. However, collecting large datasets in a time- and cost-efÔ¨Åcient man-ner often results in label noise. We present a method for learning from noisy labels that leverages similarities be-tween training examples in feature space, encouraging the prediction of each example to be similar to its nearest neigh-bours. Compared to training algorithms that use multiple models or distinct stages, our approach takes the form of a simple, additional regularization term.It can be inter-preted as an inductive version of the classical, transduc-tive label propagation algorithm. We thoroughly evaluate our method on datasets evaluating both synthetic (CIFAR-10, CIFAR-100) and realistic (mini-WebVision, WebVision,Clothing1M, mini-ImageNet-Red) noise, and achieve com-petitive or state-of-the-art accuracies across all of them. 