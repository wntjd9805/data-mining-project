Modern handheld devices can acquire burst image se-quence in a quick succession. However, the individual ac-quired frames suffer from multiple degradations and are misaligned due to camera shake and object motions. The goal of Burst Image Restoration is to effectively combine complimentary cues across multiple burst frames to gen-erate high-quality outputs. Towards this goal, we develop a novel approach by solely focusing on the effective in-formation exchange between burst frames, such that the degradations get filtered out while the actual scene de-tails are preserved and enhanced. Our central idea is to create a set of pseudo-burst features that combine com-plimentary information from all the input burst frames to seamlessly exchange information. However, the pseudo-burst cannot be successfully created unless the individ-ual burst frames are properly aligned to discount inter-frame movements. Therefore, our approach initially ex-tracts pre-processed features from each burst frame and matches them using an edge-boosting burst alignment mod-ule. The pseudo-burst features are then created and en-riched using multi-scale contextual information. Our fi-nal step is to adaptively aggregate information from the pseudo-burst features to progressively increase resolution in multiple stages while merging the pseudo-burst features.In comparison to existing works that usually follow a late fusion scheme with single-stage upsampling, our approach performs favorably, delivering state-of-the-art performance on burst super-resolution, burst low-light image enhance-ment and burst denoising tasks. The source code and pre-trained models are available at https://github. com/akshaydudhane16/BIPNet. 