In this paper, we propose a weakly-supervised approach for 3D object detection, which makes it possible to train a strong 3D detector with position-level annotations (i.e. an-notations of object centers). In order to remedy the infor-mation loss from box annotations to centers, our method, namely Back to Reality (BR), makes use of synthetic 3D shapes to convert the weak labels into fully-annotated vir-tual scenes as stronger supervision, and in turn utilizes the perfect virtual labels to complement and reﬁne the real labels.Speciﬁcally, we ﬁrst assemble 3D shapes into physically reasonable virtual scenes according to the coarse scene layout extracted from position-level annota-tions. Then we go back to reality by applying a virtual-to-real domain adaptation method, which reﬁne the weak labels and additionally supervise the training of detector with the virtual scenes. Furthermore, we propose a more challenging benckmark for indoor 3D object detection with more diversity in object sizes for better evaluation. With less than 5% of the labeling labor, we achieve comparable de-tection performance with some popular fully-supervised ap-proaches on the widely used ScanNet dataset. Code is avail-able at: https://github.com/wyf-ACCEPT/BackToReality. 