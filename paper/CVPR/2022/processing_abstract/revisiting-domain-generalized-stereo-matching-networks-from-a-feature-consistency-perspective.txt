Despite recent stereo matching networks achieving im-pressive performance given sufficient training data, they suffer from domain shifts and generalize poorly to unseen domains. We argue that maintaining feature consistency between matching pixels is a vital factor for promoting the generalization capability of stereo matching networks, which has not been adequately considered. Here we ad-dress this issue by proposing a simple pixel-wise contrastive learning across the viewpoints. The stereo contrastive fea-ture loss function explicitly constrains the consistency be-tween learned features of matching pixel pairs which are observations of the same 3D points. A stereo selective whitening loss is further introduced to better preserve the stereo feature consistency across domains, which decorre-lates stereo features from stereo viewpoint-specific style in-formation. Counter-intuitively, the generalization of fea-ture consistency between two viewpoints in the same scene translates to the generalization of stereo matching perfor-mance to unseen domains. Our method is generic in nature as it can be easily embedded into existing stereo networks and does not require access to the samples in the target do-main. When trained on synthetic data and generalized to four real-world testing sets, our method achieves superior performance over several state-of-the-art networks. The code is available online1. 