In real-world applications of machine learning, reliable and safe systems must consider measures of performance beyond standard test set accuracy. These other goals in-clude out-of-distribution (OOD) robustness, prediction con-sistency, resilience to adversaries, calibrated uncertainty estimates, and the ability to detect anomalous inputs. How-ever, improving performance towards these goals is often a balancing act that today’s methods cannot achieve without sacriﬁcing performance on other safety axes. For instance, adversarial training improves adversarial robustness but sharply degrades other classiﬁer performance metrics. Sim-ilarly, strong data augmentation and regularization tech-niques often improve OOD robustness but harm anomaly detection, raising the question of whether a Pareto improve-ment on all existing safety measures is possible. To meet this challenge, we design a new data augmentation strategy utilizing the natural structural complexity of pictures such as fractals, which outperforms numerous baselines, is nearPareto-optimal, and roundly improves safety measures. 