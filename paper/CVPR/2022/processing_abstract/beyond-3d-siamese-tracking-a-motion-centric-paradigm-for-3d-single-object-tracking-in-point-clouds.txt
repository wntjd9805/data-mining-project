3D single object tracking (3D SOT) in LiDAR point clouds plays a crucial role in autonomous driving. Cur-rent approaches all follow the Siamese paradigm based on appearance matching. However, LiDAR point clouds are usually textureless and incomplete, which hinders ef-fective appearance matching. Besides, previous meth-ods greatly overlook the critical motion clues among tar-In this work, beyond 3D Siamese tracking, we in-gets. troduce a motion-centric paradigm to handle 3D SOT from a new perspective. Following this paradigm, we pro-pose a matching-free two-stage tracker M2-Track. At the 1st-stage, M 2-Track localizes the target within successive frames via motion transformation. Then it refines the tar-get box through motion-assisted shape completion at the 2nd-stage. Extensive experiments confirm that M 2-Track significantly outperforms previous state-of-the-arts on three large-scale datasets while running at 57FPS (∼ 8%, ∼ 17% and ∼ 22% precision gains on KITTI, NuScenes, andWaymo Open Dataset respectively). Further analysis veri-fies each component’s effectiveness and shows the motion-centric paradigm’s promising potential when combined with appearance matching. Code will be made available at https://github.com/Ghostish/Open3DSOT. 