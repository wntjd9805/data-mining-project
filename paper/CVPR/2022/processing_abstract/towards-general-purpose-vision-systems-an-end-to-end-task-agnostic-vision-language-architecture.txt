Computer vision systems today are primarily N-purpose systems, designed and trained for a predefined set of tasks.Adapting such systems to new tasks is challenging and of-ten requires non-trivial modifications to the network archi-tecture (e.g. adding new output heads) or training process (e.g. adding new losses). To reduce the time and exper-tise required to develop new applications, we would like to create general purpose vision systems that can learn and perform a range of tasks without any modification to the ar-chitecture or learning process. In this paper, we proposeGPV-1, a task-agnostic vision-language architecture that can learn and perform tasks that involve receiving an image and producing text and/or bounding boxes, including clas-sification, localization, visual question answering, caption-ing, and more. We also propose evaluations of generality of architecture, skill-concept1 transfer, and learning efficiency that may inform future work on general purpose vision. Our experiments indicate GPV-1 is effective at multiple tasks, reuses some concept knowledge across tasks, can perform the Referring Expressions task zero-shot, and further im-proves upon the zero-shot performance using a few training samples. 