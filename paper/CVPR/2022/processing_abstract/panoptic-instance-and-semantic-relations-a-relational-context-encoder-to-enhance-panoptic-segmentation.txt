This paper presents a novel framework to integrate both semantic and instance contexts for panoptic segmentation.In existing works, it is common to use a shared backbone to extract features for both things (countable classes such as vehicles) and stuff (uncountable classes such as roads).This, however, fails to capture the rich relations among them, which can be utilized to enhance visual understand-ing and segmentation performance. To address this short-coming, we propose a novel Panoptic, Instance, and Seman-tic Relations (PISR) module to exploit such contexts. First, we generate panoptic encodings to summarize key features of the semantic classes and predicted instances. A Panop-tic Relational Attention (PRA) module is then applied to the encodings and the global feature map from the back-bone. It produces a feature map that captures 1) the rela-tions across semantic classes and instances and 2) the re-lations between these panoptic categories and spatial fea-tures. PISR also automatically learns to focus on the more important instances, making it robust to the number of in-stances used in the relational attention module. Moreover,PISR is a general module that can be applied to any ex-isting panoptic segmentation architecture. Through exten-sive evaluations on panoptic segmentation benchmarks likeCityscapes, COCO, and ADE20K, we show that PISR at-tains considerable improvements over existing approaches. 