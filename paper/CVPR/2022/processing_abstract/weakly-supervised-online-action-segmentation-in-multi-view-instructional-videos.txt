This paper addresses a new problem of weakly-supervised online action segmentation in instructional videos. We present a framework to segment streaming videos online at test time using Dynamic Programming and show its advantages over greedy sliding window ap-proach. We improve our framework by introducing theOnline-Ofﬂine Discrepancy Loss (OODL) to encourage the segmentation results to have a higher temporal consis-tency. Furthermore, only during training, we exploit frame-wise correspondence between multiple views as supervision for training weakly-labeled instructional videos.In par-ticular, we investigate three different multi-view inference techniques to generate more accurate frame-wise pseudo ground-truth with no additional annotation cost. We present results and ablation studies on two benchmark multi-view datasets, Breakfast and IKEA ASM. Experimental results show efﬁcacy of the proposed methods both qualitatively and quantitatively in two domains of cooking and assem-bly. 