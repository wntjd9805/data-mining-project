We introduce DiffPhy, a differentiable physics-based model for articulated 3d human motion reconstruction from video. Applications of physics-based reasoning in human motion analysis have so far been limited, both by the com-plexity of constructing adequate physical models of artic-ulated human motion, and by the formidable challenges of performing stable and efficient inference with physics in the loop. We jointly address such modeling and infer-ence challenges by proposing an approach that combines a physically plausible body representation with anatomi-cal joint limits, a differentiable physics simulator, and opti-mization techniques that ensure good performance and ro-bustness to suboptimal local optima.In contrast to sev-eral recent methods [39, 42, 55], our approach readily sup-ports full-body contact including interactions with objects in the scene. Most importantly, our model connects end-to-end with images, thus supporting direct gradient-based physics optimization by means of image-based loss func-tions. We validate the model by demonstrating that it can accurately reconstruct physically plausible 3d human mo-tion from monocular video, both on public benchmarks with available 3d ground-truth, and on videos from the internet. 