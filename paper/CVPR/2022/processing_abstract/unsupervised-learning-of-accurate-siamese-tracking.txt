Unsupervised learning has been popular in various com-puter vision tasks, including visual object tracking. How-ever, prior unsupervised tracking approaches rely heavily on spatial supervision from template-search pairs and are still unable to track objects with strong variation over a long time span. As unlimited self-supervision signals can be ob-tained by tracking a video along a cycle in time, we investi-gate evolving a Siamese tracker by tracking videos forward-backward. We present a novel unsupervised tracking frame-work, in which we can learn temporal correspondence both on the classification branch and regression branch. Specif-ically, to propagate reliable template feature in the forward propagation process so that the tracker can be trained in the cycle, we first propose a consistency propagation trans-formation. We then identify an ill-posed penalty problem in conventional cycle training in backward propagation pro-cess. Thus, a differentiable region mask is proposed to se-lect features as well as to implicitly penalize tracking errors on intermediate frames. Moreover, since noisy labels may degrade training, we propose a mask-guided loss reweight-ing strategy to assign dynamic weights based on the qual-ity of pseudo labels. In extensive experiments, our tracker outperforms preceding unsupervised methods by a substan-tial margin, performing on par with supervised methods on large-scale datasets such as TrackingNet and LaSOT. Code is available at https://github.com/FlorinShum/ULAST. 