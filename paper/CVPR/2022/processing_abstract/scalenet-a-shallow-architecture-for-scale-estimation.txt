In this paper, we address the problem of estimating scale factors between images. We formulate the scale es-timation problem as a prediction of a probability distri-bution over scale factors. We design a new architecture,ScaleNet, that exploits dilated convolutions as well as self-and cross-correlation layers to predict the scale between images. We demonstrate that rectifying images with es-timated scales leads to significant performance improve-ments for various tasks and methods.Specifically, we show how ScaleNet can be combined with sparse local fea-tures and dense correspondence networks to improve cam-era pose estimation, 3D reconstruction, or dense geomet-ric matching in different benchmarks and datasets. We pro-vide an extensive evaluation on several tasks, and analyze the computational overhead of ScaleNet. The code, evalua-tion protocols, and trained models are publicly available at https://github.com/axelBarroso/ScaleNet. 