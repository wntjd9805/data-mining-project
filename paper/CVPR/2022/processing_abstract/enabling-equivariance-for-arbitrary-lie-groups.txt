Although provably robust to translational perturbations, convolutional neural networks (CNNs) are known to suffer from extreme performance degradation when presented at test time with more general geometric transformations of inputs. Recently, this limitation has motivated a shift in fo-cus from CNNs to Capsule Networks (CapsNets). However,CapsNets suffer from admitting relatively few theoretical guarantees of invariance. We introduce a rigourous math-ematical framework to permit invariance to any Lie group of warps, exclusively using convolutions (over Lie groups), without the need for capsules. Previous work on group con-volutions has been hampered by strong assumptions about the group, which precludes the application of such tech-niques to common warps in computer vision such as afﬁne and homographic. Our framework enables the implemen-tation of group convolutions over any ﬁnite-dimensionalLie group. We empirically validate our approach on the benchmark afﬁne-invariant classiﬁcation task, where we achieve ∼30% improvement in accuracy against conven-tional CNNs while outperforming most CapsNets. As fur-ther illustration of the generality of our framework, we train a homography-convolutional model which achieves supe-rior robustness on a homography-perturbed dataset, whereCapsNet results degrade. 