We endeavor on a rarely explored task named Insubstan-tial Object Detection (IOD), which aims to localize the ob-ject with following characteristics: (1) amorphous shape with indistinct boundary; (2) similarity to surroundings; (3) absence in color. Accordingly, it is far more challenging to distinguish insubstantial objects in a single static frame and the collaborative representation of spatial and tempo-ral information is crucial. Thus, we construct an IOD-Video dataset comprised of 600 videos (141,017 frames) covering various distances, sizes, visibility, and scenes captured by different spectral ranges. In addition, we develop a spatio-temporal aggregation framework for IOD, in which differ-ent backbones are deployed and a spatio-temporal aggrega-tion loss (STAloss) is elaborately designed to leverage the consistency along the time axis. Experiments conducted onIOD-Video dataset demonstrate that spatio-temporal aggre-gation can significantly improve the performance of IOD.We hope our work will attract further researches into this valuable yet challenging task. The code will be available at: https://github.com/CalayZhou/IOD-Video. 