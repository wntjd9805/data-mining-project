Predicting future motion based on historical motion sequence is a fundamental problem in computer vision, and it has wide applications in autonomous driving and robotics. Some recent works have shown that Graph Convo-lutional Networks(GCN) are instrumental in modeling the relationship between different joints. However, consider-ing the variants and diverse action types in human mo-tion data, the cross-dependency of the spatio-temporal re-lationships will be difficult to depict due to the decoupled modeling strategy, which may also exacerbate the problem of insufficient generalization. Therefore, we propose theSpatio-Temporal Gating-Adjacency GCN(GAGCN) to learn the complex spatio-temporal dependencies over diverse ac-tion types. Specifically, we adopt gating networks to en-hance the generalization of GCN via the trainable adap-tive adjacency matrix obtained by blending the candidate spatio-temporal adjacency matrices. Moreover, GAGCN addresses the cross-dependency of space and time by bal-ancing the weights of spatio-temporal modeling and fusing the decoupled spatio-temporal features. Extensive exper-iments on Human 3.6M, AMASS, and 3DPW demonstrate that GAGCN achieves state-of-the-art performance in both short-term and long-term predictions. 