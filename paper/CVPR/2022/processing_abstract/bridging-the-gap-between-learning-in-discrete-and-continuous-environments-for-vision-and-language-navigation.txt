Most existing works in vision-and-language naviga-tion (VLN) focus on either discrete or continuous environ-ments, training agents that cannot generalize across the two. Although learning to navigate in continuous spaces is closer to the real-world, training such an agent is sig-niﬁcantly more difﬁcult than training an agent in discrete spaces. However, recent advances in discrete VLN are chal-lenging to translate to continuous VLN due to the domain gap. The fundamental difference between the two setups is that discrete navigation assumes prior knowledge of the connectivity graph of the environment, so that the agent can effectively transfer the problem of navigation with low-level controls to jumping from node to node with high-level ac-tions by grounding to an image of a navigable direction.To bridge the discrete-to-continuous gap, we propose a predictor to generate a set of candidate waypoints during navigation, so that agents designed with high-level actions can be transferred to and trained in continuous environ-ments. We reﬁne the connectivity graph of Matterport3D to ﬁt the continuous Habitat-Matterport3D, and train the waypoints predictor with the reﬁned graphs to produce ac-cessible waypoints at each time step. Moreover, we demon-strate that the predicted waypoints can be augmented dur-ing training to diversify the views and paths, and therefore enhance agent’s generalization ability.Through extensive experiments we show that agents nav-igating in continuous environments with predicted way-points perform signiﬁcantly better than agents using low-level actions, which reduces the absolute discrete-to-continuous gap by 11.76% Success Weighted by PathLength (SPL) for the Cross-Modal Matching Agent and 18.24% SPL for the VLNœBERT. Our agents, trained with a simple imitation learning objective, outperform previous methods by a large margin, achieving new state-of-the-art results on the testing environments of the R2R-CE and theRxR-CE datasets.* Authors contributed equally