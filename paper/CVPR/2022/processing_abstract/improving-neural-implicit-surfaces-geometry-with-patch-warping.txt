Neural implicit surfaces have become an important tech-nique for multi-view 3D reconstruction but their accuracy remains limited. In this paper, we argue that this comes from the difÔ¨Åculty to learn and render high frequency textures with neural networks. We thus propose to add to the standard neural rendering optimization a direct photo-consistency term across the different views. Intuitively, we optimize the implicit geometry so that it warps views on each other in a consistent way. We demonstrate that two elements are key to the success of such an approach: (i) warping en-tire patches, using the predicted occupancy and normals of the 3D points along each ray, and measuring their sim-ilarity with a robust structural similarity (SSIM); (ii) han-dling visibility and occlusion in such a way that incorrect warps are not given too much importance while encour-aging a reconstruction as complete as possible. We eval-uate our approach, dubbed NeuralWarp, on the standardDTU and EPFL benchmarks and show it outperforms state of the art unsupervised implicit surfaces reconstructions by over 20% on both datasets. Our code is available at https://github.com/fdarmon/NeuralWarp 