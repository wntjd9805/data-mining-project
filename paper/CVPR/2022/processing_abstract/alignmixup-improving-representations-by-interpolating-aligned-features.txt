Mixup is a powerful data augmentation method that in-terpolates between two or more examples in the input or feature space and between the corresponding target labels.However, how to best interpolate images is not well de-ﬁned. Recent mixup methods overlay or cut-and-paste two or more objects into one image, which needs care in se-lecting regions. Mixup has also been connected to autoen-coders, because often autoencoders generate an image that continuously deforms into another. However, such images are typically of low quality.In this work, we revisit mixup from the deformation perspective and introduce AlignMixup, where we geomet-rically align two images in the feature space. The cor-respondences allow us to interpolate between two sets of features, while keeping the locations of one set. Interest-ingly, this retains mostly the geometry or pose of one im-age and the appearance or texture of the other. We also show that an autoencoder can still improve representa-tion learning under mixup, without the classiﬁer ever see-ing decoded images. AlignMixup outperforms state-of-the-art mixup methods on ﬁve different benchmarks. Code available at https://github.com/shashankvkt/AlignMixup_CVPR22.git 