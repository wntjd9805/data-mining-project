Despite single image dehazing has been made promis-ing progress with Convolutional Neural Networks (CNNs), the inherent equivariance and locality of convolution still bottleneck dehazing performance. Though Transformer has occupied various computer vision tasks, directly leveragingTransformer for image dehazing is challenging: 1) it tends to result in ambiguous and coarse details that are undesired for image reconstruction; 2) previous position embedding of Transformer is provided in logic or spatial position order that neglects the variational haze densities, which results in the sub-optimal dehazing performance.The key insight of this study is to investigate how to combine CNN and Transformer for image dehazing. To solve the feature inconsistency issue between Transformer and CNN, we propose to modulate CNN features via learn-ing modulation matrices (i.e., coefficient matrix and bias matrix) conditioned on Transformer features instead of sim-ple feature addition or concatenation. The feature modula-tion naturally inherits the global context modeling capabil-ity of Transformer and the local representation capability of CNN. We bring a haze density-related prior into Trans-former via a novel transmission-aware 3D position embed-ding module, which not only provides the relative position but also suggests the haze density of different spatial re-gions. Extensive experiments demonstrate that our method,DeHamer, attains state-of-the-art performance on several image dehazing benchmarks. 