Existing state-of-the-art methods for Video Object Seg-mentation (VOS) learn low-level pixel-to-pixel correspon-dences between frames to propagate object masks across video. This requires a large amount of densely annotated video data, which is costly to annotate, and largely redun-dant since frames within a video are highly correlated. In light of this, we propose HODOR: a novel method that tack-les VOS by effectively leveraging annotated static images for understanding object appearance and scene context. We encode object instances and scene information from an im-age frame into robust high-level descriptors which can then be used to re-segment those objects in different frames. As a result, HODOR achieves state-of-the-art performance on the DAVIS and YouTube-VOS benchmarks compared to ex-isting methods trained without video annotations. With-out any architectural modification, HODOR can also learn from video context around single annotated video frames by utilizing cyclic consistency, whereas other methods rely on dense, temporally consistent annotations. Source code: https://github.com/Ali2500/HODOR 