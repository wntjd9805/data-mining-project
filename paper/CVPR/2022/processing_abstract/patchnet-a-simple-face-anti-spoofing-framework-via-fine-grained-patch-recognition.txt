Face anti-spoofing (FAS) plays a critical role in securing face recognition systems from different presentation attacks.Previous works leverage auxiliary pixel-level supervision and domain generalization approaches to address unseen spoof types. However, the local characteristics of image captures, i.e., capturing devices and presenting materials, are ignored in existing works and we argue that such infor-mation is required for networks to discriminate between live and spoof images. In this work, we propose PatchNet which reformulates face anti-spoofing as a fine-grained patch-type recognition problem. To be specific, our framework recog-nizes the combination of capturing devices and presenting materials based on the patches cropped from non-distorted face images. This reformulation can largely improve the data variation and enforce the network to learn discrim-inative feature from local capture patterns.In addition, to further improve the generalization ability of the spoof feature, we propose the novel Asymmetric Margin-basedClassification Loss and Self-supervised Similarity Loss to regularize the patch embedding space. Our experimen-tal results verify our assumption and show that the model is capable of recognizing unseen spoof types robustly by only looking at local regions. Moreover, the fine-grained and patch-level reformulation of FAS outperforms the ex-isting approaches on intra-dataset, cross-dataset, and do-main generalization benchmarks. Furthermore, our Patch-Net framework can enable practical applications like Few-Shot Reference-based FAS and facilitate future exploration of spoof-related intrinsic cues. 