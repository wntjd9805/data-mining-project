Standard visual localization methods build a priori 3D model of a scene which is used to establish correspon-dences against the 2D keypoints in a query image. Stor-ing these pre-built 3D scene models can be prohibitively expensive for large-scale environments, especially on mo-bile devices with limited storage and communication band-width. We design a novel framework that compresses a scene while still maintaining localization accuracy. The scene is compressed in three stages: first, the database frames are clustered using pairwise co-visibility informa-tion. Then, a learned point selection module prunes the points in each cluster taking into account the final pose es-In the final stage, the features of the timation accuracy. selected points are further compressed using learned quan-tization. Query image registration is done using only the compressed scene points. To the best of our knowledge, we are the first to propose learned scene compression for visual localization. We also demonstrate the effectiveness and ef-ficiency of our method on various outdoor datasets where it can perform accurate localization with low memory con-sumption. 