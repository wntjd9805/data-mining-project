We present a novel high-fidelity generative adversar-ial network (GAN) inversion framework that enables at-tribute editing with image-specific details well-preserved (e.g., background, appearance, and illumination). We first analyze the challenges of high-fidelity GAN inversion from the perspective of lossy data compression. With a low bit-rate latent code, previous works have difficulties in preserv-ing high-fidelity details in reconstructed and edited images.Increasing the size of a latent code can improve the accu-racy of GAN inversion but at the cost of inferior editability.To improve image fidelity without compromising editabil-ity, we propose a distortion consultation approach that em-ploys a distortion map as a reference for high-fidelity recon-struction.In the distortion consultation inversion (DCI), the distortion map is first projected to a high-rate latent map, which then complements the basic low-rate latent code with more details via consultation fusion. To achieve high-fidelity editing, we propose an adaptive distortion align-ment (ADA) module with a self-supervised training scheme, which bridges the gap between the edited and inversion images. Extensive experiments in the face and car do-mains show a clear improvement in both inversion and edit-ing quality. The project page is https://tengfei-wang.github.io/HFGI/. 