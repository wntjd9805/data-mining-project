3D object detection has attracted much attention thanks to the advances in sensors and deep learning methods for point clouds. Current state-of-the-art methods like VoteNet regress direct offset towards object centers and box orientations with an additional Multi-Layer-Perceptron network. Both their offset and orientation predictions are not accurate due to the fundamental difﬁculty in rotation classiﬁcation. In the work, we disentangle the direct offset into Local CanonicalCoordinates (LCC), box scales and box orientations. OnlyLCC and box scales are regressed, while box orientations are generated by a canonical voting scheme. Finally, anLCC-aware back-projection checking algorithm iteratively cuts out bounding boxes from the generated vote maps, with the elimination of false positives. Our model achieves state-of-the-art performance on three standard real-world bench-marks: ScanNet, SceneNN and SUN RGB-D. Our code is available on https://github.com/qq456cvb/CanonicalVoting. 