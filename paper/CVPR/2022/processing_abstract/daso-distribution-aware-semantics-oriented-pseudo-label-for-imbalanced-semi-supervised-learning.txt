The capability of the traditional semi-supervised learn-ing (SSL) methods is far from real-world application due to severely biased pseudo-labels caused by (1) class imbal-ance and (2) class distribution mismatch between labeled and unlabeled data. This paper addresses such a rela-tively under-explored problem. First, we propose a general pseudo-labeling framework that class-adaptively blends the semantic pseudo-label from a similarity-based classifier to the linear one from the linear classifier, after making the observation that both types of pseudo-labels have comple-mentary properties in terms of bias. We further introduce a novel semantic alignment loss to establish balanced fea-ture representation to reduce the biased predictions from the classifier. We term the whole framework as Distribution-Aware Semantics-Oriented (DASO) Pseudo-label. We con-duct extensive experiments in a wide range of imbalanced benchmarks: CIFAR10/100-LT, STL10-LT, and large-scale long-tailed Semi-Aves with open-set class, and demonstrate that, the proposed DASO framework reliably improves SSL learners with unlabeled data especially when both (1) class imbalance and (2) distribution mismatch dominate. 