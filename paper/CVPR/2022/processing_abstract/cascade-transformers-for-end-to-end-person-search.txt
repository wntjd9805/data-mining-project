The goal of person search is to localize a target per-son from a gallery set of scene images, which is extremely challenging due to large scale variations, pose/viewpoint changes, and occlusions. In this paper, we propose the Cas-cade Occluded Attention Transformer (COAT) for end-to-end person search. Our three-stage cascade design focuses on detecting people in the first stage, while later stages si-multaneously and progressively refine the representation for person detection and re-identification. At each stage the occluded attention transformer applies tighter intersection over union thresholds, forcing the network to learn coarse-to-fine pose/scale invariant features. Meanwhile, we cal-culate each detection’s occluded attention to differentiate a person’s tokens from other people or the background.In this way, we simulate the effect of other objects occlud-ing a person of interest at the token-level. Through com-prehensive experiments, we demonstrate the benefits of our method by achieving state-of-the-art performance on two benchmark datasets. 