Domain adaptive object detection is challenging due to distinctive data distribution between source domain and target domain. In this paper, we propose a unified multi-granularity alignment based object detection framework to-wards domain-invariant feature learning. To this end, we encode the dependencies across different granularity per-spectives including pixel-, instance-, and category-levels si-multaneously to align two domains. Based on pixel-level feature maps from the backbone network, we first develop the omni-scale gated fusion module to aggregate discrimi-native representations of instances by scale-aware convolu-tions, leading to robust multi-scale object detection. Mean-while, the multi-granularity discriminators are proposed to identify which domain different granularities of samples (i.e., pixels, instances, and categories) come from. Notably, we leverage not only the instance discriminability in dif-ferent categories but also the category consistency between two domains. Extensive experiments are carried out on mul-tiple domain adaptation scenarios, demonstrating the effec-tiveness of our framework over state-of-the-art algorithms on top of anchor-free FCOS and anchor-based Faster R-CNN detectors with different backbones. 