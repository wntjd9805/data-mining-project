Algorithmic fairness is frequently motivated in terms of a trade-off in which overall performance is decreased so as to improve performance on disadvantaged groups where the algorithm would otherwise be less accurate. Contrary to this, we find that applying existing fairness approaches to computer vision improve fairness by degrading the per-formance of classifiers across all groups (with increased degradation on the best performing groups).Extending the bias-variance decomposition for classifi-cation to fairness, we theoretically explain why the major-ity of fairness methods designed for low capacity models should not be used in settings involving high-capacity mod-els, a scenario common to computer vision. We corrobo-rate this analysis with extensive experimental support that shows that many of the fairness heuristics used in computer vision also degrade performance on the most disadvantaged groups. Building on these insights, we propose an adaptive augmentation strategy that, uniquely, of all methods tested, improves performance for the disadvantaged groups. 