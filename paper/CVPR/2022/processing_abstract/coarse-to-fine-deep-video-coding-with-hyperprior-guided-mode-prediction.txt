The previous deep video compression approaches only use the single scale motion compensation strategy and rarely adopt the mode prediction technique from the tra-ditional standards like H.264/H.265 for both motion and residual compression.In this work, we first propose a coarse-to-fine (C2F) deep video compression framework for better motion compensation, in which we perform mo-tion estimation, compression and compensation twice in a coarse to fine manner. Our C2F framework can achieve better motion compensation results without significantly in-creasing bit costs. Observing hyperprior information (i.e., the mean and variance values) from the hyperprior net-works contains discriminant statistical information of dif-ferent patches, we also propose two efficient hyperprior-guided mode prediction methods. Specifically, using hyper-prior information as the input, we propose two mode pre-diction networks to respectively predict the optimal block resolutions for better motion coding and decide whether to skip residual information from each block for better resid-ual coding without introducing additional bit cost while bringing negligible extra computation cost. Comprehensive experimental results demonstrate our proposed C2F video compression framework equipped with the new hyperprior-guided mode prediction methods achieves the state-of-the-art performance on HEVC, UVG and MCL-JCV datasets. 