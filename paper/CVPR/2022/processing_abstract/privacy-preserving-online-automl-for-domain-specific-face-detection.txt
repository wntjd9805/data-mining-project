Despite the impressive progress of general face detec-tion, the tuning of hyper-parameters and architectures is still critical for the performance of a domain-speciﬁc face detector. Though existing AutoML works can speedup such process, they either require tuning from scratch for a new scenario or do not consider data privacy. To scale up, we derive a new AutoML setting from a platform perspective.In such setting, new datasets sequentially arrive at the plat-form, where an architecture and hyper-parameter conﬁg-uration is recommended to train the optimal face detector for each dataset. This, however, brings two major chal-lenges: (1) how to predict the best conﬁguration for any given dataset without touching their raw images due to the privacy concern? and (2) how to continuously improve theAutoML algorithm from previous tasks and offer a better warm-up for future ones? We introduce “HyperFD”, a new privacy-preserving online AutoML framework for face de-tection. At its core part, a novel meta-feature representation of a dataset as well as its learning paradigm is proposed.Thanks to HyperFD, each local task (client) is able to effec-tively leverage the learning “experience” of previous tasks without uploading raw images to the platform; meanwhile, the meta-feature extractor is continuously learned to bet-ter trade off the bias and variance. Extensive experiments demonstrate the effectiveness and efﬁciency of our design. 