Abductive reasoning seeks the likeliest possible expla-nation for partial observations. Although abduction is fre-quently employed in human daily reasoning, it is rarely ex-plored in computer vision literature. In this paper, we pro-pose a new task and dataset, Visual Abductive Reasoning (VAR), for examining abductive reasoning ability of ma-chine intelligence in everyday visual situations. Given an in-complete set of visual events, AI systems are required to not only describe what is observed, but also infer the hypothe-sis that can best explain the visual premise. Based on our large-scale VAR dataset, we devise a strong baseline model,REASONER (causal-and-cascaded reasoning Transformer).First, to capture the causal structure of the observations, a contextualized directional position embedding strategy is adopted in the encoder, that yields discriminative represen-tations for the premise and hypothesis. Then, multiple de-coders are cascaded to generate and progressively refine the premise and hypothesis sentences. The prediction scores of the sentences are used to guide cross-sentence information flow in the cascaded reasoning procedure. Our VAR bench-marking results show that REASONER surpasses many fa-mous video-language models, while still being far behind human performance. This work is expected to foster future efforts in the reasoning-beyond-observation paradigm. 