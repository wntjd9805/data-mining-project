Domain Adaptive Object Detection (DAOD) models a joint distribution of images and labels from an annotated source domain and learns a domain-invariant transforma-tion to estimate the target labels with the given target do-main images. Existing methods assume that the source do-main labels are completely clean, yet large-scale datasets often contain error-prone annotations due to instance am-biguity, which may lead to a biased source distribution and severely degrade the performance of the domain adaptive detector de facto. In this paper, we represent the first ef-fort to formulate noisy DAOD and propose a Noise LatentTransferability Exploration (NLTE) framework to address this issue.It is featured with 1) Potential Instance Min-ing (PIM), which leverages eligible proposals to recapture the miss-annotated instances from the background; 2) Mor-phable Graph Relation Module (MGRM), which models the adaptation feasibility and transition probability of noisy samples with relation matrices; 3) Entropy-Aware Gradi-ent Reconcilement (EAGR), which incorporates the seman-tic information into the discrimination process and enforces the gradients provided by noisy and clean samples to be consistent towards learning domain-invariant representa-tions. A thorough evaluation on benchmark DAOD datasets with noisy source annotations validates the effectiveness ofNLTE. In particular, NLTE improves the mAP by 8.4% un-der 60% corrupted annotations and even approaches the ideal upper bound of training on a clean source dataset. 1 