Recent works attempt to integrate the non-local opera-tion with CNNs or Transformer, achieving remarkable per-formance in image restoration tasks. The global similar-ity, however, has the problems of the lack of locality and the high computational complexity that is quadratic to an input resolution. The local attention mechanism alleviates these issues by introducing the inductive bias of the local-ity with convolution-like operators. However, by focusing only on adjacent positions, the local attention suffers from an insufﬁcient receptive ﬁeld for image restoration. In this paper, we propose a new attention mechanism for image restoration, called k-NN Image Transformer (KiT), that rec-tiﬁes the above mentioned limitations. Speciﬁcally, the KiT groups k-nearest neighbor patches with locality sensitive hashing (LSH), and the grouped patches are aggregated into each query patch by performing a pair-wise local atten-tion. In this way, the pair-wise operation establishes non-local connectivity while maintaining the desired properties of the local attention, i.e., inductive bias of locality and lin-ear complexity to input resolution. The proposed method outperforms state-of-the-art restoration approaches on im-age denoising, deblurring and deraining benchmarks. The code will be available soon. 