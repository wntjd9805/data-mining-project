We propose a method for compressively acquiring a dynamic light ﬁeld (a 5-D volume) through a single-shot coded image (a 2-D measurement). We designed an imag-ing model that synchronously applies aperture coding and pixel-wise exposure coding within a single exposure time.This coding scheme enables us to effectively embed the orig-inal information into a single observed image. The ob-served image is then fed to a convolutional neural network (CNN) for light-ﬁeld reconstruction, which is jointly trained with the camera-side coding patterns. We also developed a hardware prototype to capture a real 3-D scene moving over time. We succeeded in acquiring a dynamic light ﬁeld with 5×5 viewpoints over 4 temporal sub-frames (100 views in total) from a single observed image. Repeating capture and reconstruction processes over time, we can acquire a dy-namic light ﬁeld at 4× the frame rate of the camera. To our knowledge, our method is the ﬁrst to achieve a ﬁner temporal resolution than the camera itself in compressive light-ﬁeld acquisition. Our software is available from our project webpage.1 