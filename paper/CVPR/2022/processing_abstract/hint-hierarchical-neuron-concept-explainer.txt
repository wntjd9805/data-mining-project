To interpret deep networks, one main approach is to associate neurons with human-understandable concepts.However, existing methods often ignore the inherent con-nections of different concepts (e.g., dog and cat both belong to animals), and thus lose the chance to explain neurons re-sponsible for higher-level concepts (e.g., animal). In this paper, we study hierarchical concepts inspired by the hier-archical cognition process of human beings. To this end, we propose HIerarchical Neuron concepT explainer (HINT) to effectively build bidirectional associations between neurons and hierarchical concepts in a low-cost and scalable man-ner. HINT enables us to systematically and quantitatively study whether and how the implicit hierarchical relation-ships of concepts are embedded into neurons. Specifically,HINT identifies collaborative neurons responsible for one concept and multimodal neurons pertinent to different con-cepts, at different semantic levels from concrete concepts (e.g., dog) to more abstract ones (e.g., animal). Finally, we verify the faithfulness of the associations using Weakly Su-pervised Object Localization, and demonstrate its applica-bility in various tasks, such as discovering saliency regions and explaining adversarial attacks. Code is available on https://github.com/AntonotnaWang/HINT. 