Videos typically record the streaming and continuous vi-sual data as discrete consecutive frames. Since the stor-age cost is expensive for videos of high ﬁdelity, most of them are stored in a relatively low resolution and frame rate. Recent works of Space-Time Video Super-Resolution (STVSR) are developed to incorporate temporal interpo-lation and spatial super-resolution in a uniﬁed frame-work. However, most of them only support a ﬁxed up-sampling scale, which limits their ﬂexibility and appli-cations.In this work, instead of following the discrete representations, we propose Video Implicit Neural Repre-sentation (VideoINR), and we show its applications forSTVSR. The learned implicit neural representation can be decoded to videos of arbitrary spatial resolution and frame rate. We show that VideoINR achieves competi-tive performances with state-of-the-art STVSR methods on common up-sampling scales and signiﬁcantly outperforms prior works on continuous and out-of-training-distribution scales. Our project page is at here and code is avail-able at https://github.com/Picsart-AI-Research/VideoINR-Continuous-Space-Time-Super-Resolution. 