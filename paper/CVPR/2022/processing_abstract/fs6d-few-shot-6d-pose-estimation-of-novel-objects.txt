6D object pose estimation networks are limited in their capability to scale to large numbers of object instances due to the close-set assumption and their reliance on high-fidelity object CAD models. In this work, we study a new open set problem; the few-shot 6D object poses estimation: estimating the 6D pose of an unknown object by a few sup-port views without extra training. To tackle the problem, we point out the importance of fully exploring the appear-ance and geometric relationship between the given support views and query scene patches and propose a dense pro-totypes matching framework by extracting and matching dense RGBD prototypes with transformers. Moreover, we show that the priors from diverse appearances and shapes are crucial to the generalization capability under the prob-lem setting and thus propose a large-scale RGBD photore-alistic dataset (ShapeNet6D) for network pre-training. A simple and effective online texture blending approach is also introduced to eliminate the domain gap from the syn-thesis dataset, which enriches appearance diversity at a low cost. Finally, we discuss possible solutions to this problem and establish benchmarks on popular datasets to facilitate future research. [project page]Figure 1. The few-shot 6D pose estimation problem. Given a few RGBD views of a novel objects with pose labels. The few-shot pose estimation network aims to estimate 6D pose of that object in a novel query scene without extra training. No precise CAD models are required as well. 