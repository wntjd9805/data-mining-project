Given a source image and a driving video depicting the same object type, the motion transfer task aims to generate a video by learning the motion from the driving video while preserving the appearance from the source image. In this paper, we propose a novel structure-aware motion model-ing approach, the deformable anchor model (DAM), which can automatically discover the motion structure of arbitrary objects without leveraging their prior structure information.Specifically, inspired by the known deformable part model (DPM), our DAM introduces two types of anchors or key-points: i) a number of motion anchors that capture both appearance and motion information from the source image and driving video; ii) a latent root anchor, which is linked to the motion anchors to facilitate better learning of the representations of the object structure information. More-over, DAM can be further extended to a hierarchical ver-*Work done during an internship at Alibaba Group†The corresponding author‡Codes will be available at https://github.com/JialeTao/DAM.git sion through the introduction of additional latent anchors to model more complicated structures. By regularizing mo-tion anchors with latent anchor(s), DAM enforces the corre-spondences between them to ensure the structural informa-tion is well captured and preserved. Moreover, DAM can be learned effectively in an unsupervised manner. We validate our proposed DAM for motion transfer on different bench-mark datasets. Extensive experiments clearly demonstrate that DAM achieves superior performance relative to exist-ing state-of-the-art methods. 