Pseudo-LiDAR 3D detectors have made remarkable progress in monocular 3D detection by enhancing the ca-pability of perceiving depth with depth estimation networks, and using LiDAR-based 3D detection architectures. The ad-vanced stereo 3D detectors can also accurately localize 3D objects. The gap in image-to-image generation for stereo views is much smaller than that in image-to-LiDAR gener-ation. Motivated by this, we propose a Pseudo-Stereo 3D detection framework with three novel virtual view gener-ation methods, including image-level generation, feature-level generation, and feature-clone, for detecting 3D objects from a single image. Our analysis of depth-aware learning shows that the depth loss is effective in only feature-level virtual view generation and the estimated depth map is ef-fective in both image-level and feature-level in our frame-work. We propose a disparity-wise dynamic convolution with dynamic kernels sampled from the disparity feature map to filter the features adaptively from a single image for generating virtual image features, which eases the feature degradation caused by the depth estimation errors. Till sub-mission (November 18, 2021), our Pseudo-Stereo 3D de-tection framework ranks 1st on car, pedestrian, and cyclist among the monocular 3D detectors with publications on theKITTI-3D benchmark. The code is released at https://github.com/revisitq/Pseudo-Stereo-3D. 