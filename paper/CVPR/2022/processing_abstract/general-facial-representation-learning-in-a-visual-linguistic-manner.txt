How to learn a universal facial representation that boosts all face analysis tasks? This paper takes one step toward this goal. In this paper, we study the transfer perfor-mance of pre-trained models on face analysis tasks and in-troduce a framework, called FaRL, for general facial repre-sentation learning. On one hand, the framework involves a contrastive loss to learn high-level semantic meaning from image-text pairs. On the other hand, we propose exploring low-level information simultaneously to further enhance the face representation by adding a masked image modeling.We perform pre-training on LAION-FACE, a dataset con-taining a large amount of face image-text pairs, and eval-uate the representation capability on multiple downstream tasks. We show that FaRL achieves better transfer perfor-mance compared with previous pre-trained models. We also verify its superiority in the low-data regime. More impor-tantly, our model surpasses the state-of-the-art methods on face analysis tasks including face parsing and face align-ment. 