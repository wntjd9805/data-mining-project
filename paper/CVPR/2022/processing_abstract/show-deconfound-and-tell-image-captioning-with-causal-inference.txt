The transformer-based encoder-decoder framework has shown remarkable performance in image captioning. How-ever, most transformer-based captioning methods ever over-look two kinds of elusive confounders: the visual con-founder and the linguistic confounder, which generally lead to harmful bias, induce the spurious correlations during training, and degrade the model generalization.In this paper, we first use Structural Causal Models (SCMs) to show how two confounders damage the image caption-ing. Then we apply the backdoor adjustment to propose a novel causal inference based image captioning (CIIC) framework, which consists of an interventional object de-tector (IOD) and an interventional transformer decoder (ITD) to jointly confront both confounders. In the encod-ing stage, the IOD is able to disentangle the region-based visual features by deconfounding the visual confounder. In the decoding stage, the ITD introduces causal interven-tion into the transformer decoder and deconfounds the vi-sual and linguistic confounders simultaneously. Two mod-ules collaborate with each other to alleviate the spurious correlations caused by the unobserved confounders. When tested on MSCOCO, our proposal significantly outperforms the state-of-the-art encoder-decoder models on Karpathy split and online test split. Code is published in https://github.com/CUMTGG/CIIC. 