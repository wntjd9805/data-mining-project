High-order decomposition is a widely used model com-pression approach towards compact convolutional neural networks (CNNs). However, many of the existing solutions, though can efficiently reduce CNN model sizes, are very dif-ficult to bring considerable saving for computational costs, especially when the compression ratio is not huge, thereby causing the severe computation inefficiency problem. To overcome this challenge, in this paper we propose efficientHigh-Order DEcomposed Convolution (HODEC). By per-forming systematic explorations on the underlying reason and mitigation strategy for the computation inefficiency, we develop a new decomposition and computation-efficient ex-ecution scheme, enabling simultaneous reductions in com-putational and storage costs.To demonstrate the effectiveness of HODEC, we per-form empirical evaluations for various CNN models on dif-ferent datasets. HODEC shows consistently outstanding compression and acceleration performance. For compress-ing ResNet-56 on CIFAR-10 dataset, HODEC brings 67% fewer parameters and 62% fewer FLOPs with 1.17% ac-curacy increase than the baseline model. For compress-ing ResNet-50 on ImageNet dataset, HODEC achieves 63%FLOPs reduction with 0.31% accuracy increase than the uncompressed model. 