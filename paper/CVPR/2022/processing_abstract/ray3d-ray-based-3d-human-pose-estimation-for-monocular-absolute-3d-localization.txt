In this paper, we propose a novel monocular ray-based 3D (Ray3D) absolute human pose estimation with cali-brated camera. Accurate and generalizable absolute 3D human pose estimation from monocular 2D pose input is an ill-posed problem. To address this challenge, we con-vert the input from pixel space to 3D normalized rays.This conversion makes our approach robust to camera in-trinsic parameter changes. To deal with the in-the-wild camera extrinsic parameter variations, Ray3D explicitly takes the camera extrinsic parameters as an input and jointly models the distribution between the 3D pose rays and camera extrinsic parameters. This novel network de-sign is the key to the outstanding generalizability of Ray3D approach.To have a comprehensive understanding of how the camera intrinsic and extrinsic parameter varia-tions affect the accuracy of absolute 3D key-point local-ization, we conduct in-depth systematic experiments on three single person 3D benchmarks as well as one syn-thetic benchmark. These experiments demonstrate that our method signiÔ¨Åcantly outperforms existing state-of-the-art models. Our code and the synthetic dataset are available at https://github.com/YxZhxn/Ray3D. 