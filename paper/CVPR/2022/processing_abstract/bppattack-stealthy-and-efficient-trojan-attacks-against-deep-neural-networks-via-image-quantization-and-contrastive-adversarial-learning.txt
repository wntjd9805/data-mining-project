Deep neural networks are vulnerable to Trojan attacks.Existing attacks use visible patterns (e.g., a patch or im-age transformations) as triggers, which are vulnerable to human inspection. In this paper, we propose stealthy and efﬁcient Trojan attacks, BPPATTACK. Based on existing bi-ology literature on human visual systems, we propose to use image quantization and dithering as the Trojan trig-ger, making imperceptible changes.It is a stealthy and efﬁcient attack without training auxiliary models. Due to the small changes made to images, it is hard to inject such triggers during training. To alleviate this problem, we pro-pose a contrastive learning based approach that leverages adversarial attacks to generate negative sample pairs so that the learned trigger is precise and accurate. The pro-posed method achieves high attack success rates on four benchmark datasets, including MNIST, CIFAR-10, GTSRB, and CelebA. It also effectively bypasses existing Trojan de-fenses and human inspection. Our code can be found in https://github.com/RU- System- Software-and-Security/BppAttack. 