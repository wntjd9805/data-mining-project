Robustness and discrimination power are two fundamen-tal requirements in visual object tracking. In most tracking paradigms, we find that the features extracted by the pop-ular Siamese-like networks cannot fully discriminatively model the tracked targets and distractor objects, hinder-ing them from simultaneously meeting these two require-ments. While most methods focus on designing robust cor-relation operations, we propose a novel target-dependent feature network inspired by the self-/cross-attention scheme.In contrast to the Siamese-like feature extraction, our net-work deeply embeds cross-image feature correlation in mul-tiple layers of the feature network. By extensively matching the features of the two images through multiple layers, it is able to suppress non-target features, resulting in instance-varying feature extraction. The output features of the search image can be directly used for predicting target locations without extra correlation step. Moreover, our model can be flexibly pre-trained on abundant unpaired images, lead-ing to notably faster convergence than the existing methods.Extensive experiments show our method achieves the state-of-the-art results while running at real-time. Our feature networks also can be applied to existing tracking pipelines seamlessly to raise the tracking performance. 