We present Point-BERT, a new paradigm for learningTransformers to generalize the concept of BERT [8] to 3D point cloud. Inspired by BERT, we devise a Masked PointModeling (MPM) task to pre-train point cloud Transform-ers. Specifically, we first divide a point cloud into several local point patches, and a point cloud Tokenizer with a dis-crete Variational AutoEncoder (dVAE) is designed to gen-erate discrete point tokens containing meaningful local in-formation. Then, we randomly mask out some patches of input point clouds and feed them into the backbone Trans-formers. The pre-training objective is to recover the orig-inal point tokens at the masked locations under the super-vision of point tokens obtained by the Tokenizer. Extensive experiments demonstrate that the proposed BERT-style pre-training strategy significantly improves the performance of standard point cloud Transformers. Equipped with our pre-training strategy, we show that a pure Transformer archi-tecture attains 93.8% accuracy on ModelNet40 and 83.1% accuracy on the hardest setting of ScanObjectNN, surpass-ing carefully designed point cloud models with much fewer hand-made designs. We also demonstrate that the rep-resentations learned by Point-BERT transfer well to new tasks and domains, where our models largely advance the state-of-the-art of few-shot point cloud classification task.The code and pre-trained models are available at https://github.com/lulutang0608/Point-BERT. 