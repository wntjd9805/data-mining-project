There is a growing discrepancy in computer vision be-tween large-scale models that achieve state-of-the-art per-formance and models that are affordable in practical appli-cations. In this paper we address this issue and signiﬁcantly bridge the gap between these two types of models. Through-out our empirical investigation we do not aim to necessarily propose a new method, but strive to identify a robust and ef-fective recipe for making state-of-the-art large scale models affordable in practice. We demonstrate that, when performed correctly, knowledge distillation can be a powerful tool for reducing the size of large models without compromising their performance. In particular, we uncover that there are cer-tain implicit design choices, which may drastically affect the effectiveness of distillation. Our key contribution is the explicit identiﬁcation of these design choices, which were not previously articulated in the literature. We back up ourﬁndings by a comprehensive empirical study, demonstrate compelling results on a wide range of vision datasets and, in particular, obtain a state-of-the-art ResNet-50 model forImageNet, which achieves 82.8% top-1 accuracy. 