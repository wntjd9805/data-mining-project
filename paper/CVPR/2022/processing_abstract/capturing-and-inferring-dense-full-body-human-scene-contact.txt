Inferring human-scene contact (HSC) is the ﬁrst step to-ward understanding how humans interact with their sur-roundings. While detecting 2D human-object interaction (HOI) and reconstructing 3D human pose and shape (HPS) have enjoyed signiﬁcant progress, reasoning about 3D human-scene contact from a single image is still challeng-ing. Existing HSC detection methods consider only a few types of predeﬁned contact, often reduce the body and scene to a small number of primitives, and even overlook image evidence. To predict human-scene contact from a single image, we address the limitations above from both data and algorithmic perspectives. We capture a new dataset called RICH for “Real scenes, Interaction, Contact andHumans.” RICH contains multiview outdoor/indoor video sequences at 4K resolution, ground-truth 3D human bod-ies captured using markerless motion capture, 3D body scans, and high resolution 3D scene scans. A key feature of RICH is that it also contains accurate vertex-level con-tact labels on the body. Using RICH, we train a network that predicts dense body-scene contacts from a single RGB image. Our key insight is that regions in contact are al-ways occluded so the network needs the ability to explore the whole image for evidence. We use a transformer to learn such non-local relationships and propose a new Body-Scene contact TRansfOrmer (BSTRO). Very few methods explore 3D contact; those that do focus on the feet only, detect foot contact as a post-processing step, or infer con-tact from body pose without looking at the scene. To our knowledge, BSTRO is the ﬁrst method to directly estimate 3D body-scene contact from a single image. We demon-strate that BSTRO signiﬁcantly outperforms the prior art.Our code and dataset are available for research purposes at: https://rich.is.tue.mpg.de 