Recent progress in introducing rotation invariance (RI) to 3D deep learning methods is mainly made by designingRI features to replace 3D coordinates as input. The key to this strategy lies in how to restore the global informa-tion that is lost by the input RI features. Most state-of-the-arts achieve this by incurring additional blocks or complex global representations, which is time-consuming and inef-fective. In this paper, we real that the global information loss stems from an unexplored pose information loss prob-lem, i.e., common convolution layers cannot capture the rel-ative poses between RI features, thus hindering the global information to be hierarchically aggregated in the deep net-works. To address this problem, we develop a Pose-awareRotation Invariant Convolution (i.e., PaRI-Conv), which dynamically adapts its kernels based on the relative poses.Specifically, in each PaRI-Conv layer, a lightweight Aug-mented Point Pair Feature (APPF) is designed to fully en-code the RI relative pose information. Then, we propose to synthesize a factorized dynamic kernel, which reduces the computational cost and memory burden by decomposing it into a shared basis matrix and a pose-aware diagonal ma-trix that can be learned from the APPF. Extensive experi-ments on shape classification and part segmentation tasks show that our PaRI-Conv surpasses the state-of-the-art RI methods while being more compact and efficient. 