Asymmetric image retrieval, which typically uses small model for query side and large model for database server, is an effective solution for resource-constrained scenarios.However, existing approaches either fail to achieve feature coherence or make strong assumptions, e.g., requiring la-beled datasets or classiﬁers from large model, etc., which limits their practical application. To this end, we propose a ﬂexible contextual similarity distillation framework to en-hance the small query model and keep its output feature compatible with that of the large gallery model, which is crucial with asymmetric retrieval.In our approach, we learn the small model with a new contextual similarity con-sistency constraint without any data label. During the small model learning, it preserves the contextual similarity among each training image and its neighbors with the features ex-tracted by the large model. Note that this simple constraint is consistent with simultaneous ﬁrst-order feature vector preserving and second-order ranking list preserving. Ex-tensive experiments show that the proposed method outper-forms the state-of-the-art methods on the Revisited Oxford and Paris datasets. 