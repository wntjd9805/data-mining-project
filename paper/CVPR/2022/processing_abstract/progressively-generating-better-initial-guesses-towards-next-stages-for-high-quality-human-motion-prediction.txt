This paper presents a high-quality human motion pre-diction method that accurately predicts future human poses given observed ones. Our method is based on the observa-tion that a good “initial guess” of the future poses is very helpful in improving the forecasting accuracy. This mo-tivates us to propose a novel two-stage prediction frame-work, including an init-prediction network that just com-putes the good guess and then a formal-prediction network that predicts the target future poses based on the guess.More importantly, we extend this idea further and design a multi-stage prediction framework where each stage pre-dicts initial guess for the next stage, which brings more performance gain. To fulﬁll the prediction task at each stage, we propose a network comprising Spatial DenseGraph Convolutional Networks (S-DGCN) and TemporalDense Graph Convolutional Networks (T-DGCN). Alterna-tively executing the two networks helps extract spatiotem-poral features over the global receptive ﬁeld of the whole pose sequence. All the above design choices cooperating together make our method outperform previous approaches by large margins: 6%-7% on Human3.6M, 5%-10% onCMU-MoCap, and 13%-16% on 3DPW. Code is available at https://github.com/705062791/PGBIG. 