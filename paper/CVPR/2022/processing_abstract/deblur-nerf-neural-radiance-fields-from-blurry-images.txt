Neural Radiance Field (NeRF) has gained considerable attention recently for 3D scene reconstruction and novel view synthesis due to its remarkable synthesis quality. How-ever, image blurriness caused by defocus or motion, which often occurs when capturing scenes in the wild, signifi-cantly degrades its reconstruction quality. To address this problem, We propose Deblur-NeRF, the first method that can recover a sharp NeRF from blurry input. We adopt an analysis-by-synthesis approach that reconstructs blurry views by simulating the blurring process, thus making NeRF robust to blurry inputs. The core of this simulation is a novel Deformable Sparse Kernel (DSK) module that mod-els spatially-varying blur kernels by deforming a canoni-cal sparse kernel at each spatial location. The ray ori-gin of each kernel point is jointly optimized, inspired by the physical blurring process. This module is parameter-ized as an MLP that has the ability to be generalized to various blur types. Jointly optimizing the NeRF and theDSK module allows us to restore a sharp NeRF. We demon-*Author did this work during the internship at Tencent AI Lab. strate that our method can be used on both camera mo-tion blur and defocus blur: the two most common types of blur in real scenes. Evaluation results on both syn-thetic and real-world data show that our method outper-forms several baselines. The synthetic and real datasets along with the source code is publicly available at https://limacv.github.io/deblurnerf/. 