Currently, many theoretical as well as practically rele-vant questions towards the transferability and robustness ofConvolutional Neural Networks (CNNs) remain unsolved.While ongoing research efforts are engaging these problems from various angles, in most computer vision related cases these approaches can be generalized to investigations of the effects of distribution shifts in image data.In this context, we propose to study the shifts in the learned weights of trained CNN models. Here we focus on the prop-erties of the distributions of dominantly used 3 Ã— 3 convo-lution filter kernels. We collected and publicly provide a dataset with over 1.4 billion filters from hundreds of trainedCNNs, using a wide range of datasets, architectures, and vi-sion tasks. In a first use case of the proposed dataset, we can show highly relevant properties of many publicly available pre-trained models for practical applications: I) We ana-lyze distribution shifts (or the lack thereof) between trained filters along different axes of meta-parameters, like visual category of the dataset, task, architecture, or layer depth.Based on these results, we conclude that model pre-training can succeed on arbitrary datasets if they meet size and vari-ance conditions. II) We show that many pre-trained models contain degenerated filters which make them less robust and less suitable for fine-tuning on target applications.Data & Project website: https://github.com/ paulgavrikov/cnn-filter-db 