Video highlight detection can greatly simplify video browsing, potentially paving the way for a wide range of ap-plications. Existing efforts are mostly fully-supervised, re-quiring humans to manually identify and label the interest-ing moments (called highlights) in a video. Recent weakly supervised methods forgo the use of highlight annotations, but typically require extensive efforts in collecting external data such as web-crawled videos for model learning. This observation has inspired us to consider unsupervised high-light detection where neither frame-level nor video-level an-notations are available in training. We propose a simple contrastive learning framework for unsupervised highlight detection. Our framework encodes a video into a vector rep-resentation by learning to pick video clips that help to dis-tinguish it from other videos via a contrastive objective us-ing dropout noise. This inherently allows our framework to identify video clips corresponding to highlight of the video.Extensive empirical evaluations on three highlight detec-tion benchmarks demonstrate the superior performance of our approach. 