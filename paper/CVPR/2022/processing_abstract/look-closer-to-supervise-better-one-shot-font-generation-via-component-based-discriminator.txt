Automatic font generation remains a challenging re-search issue due to the large amounts of characters with complicated structures. Typically, only a few samples can serve as the style/content reference (termed few-shot learn-ing), which further increases the difﬁculty to preserve local style patterns or detailed glyph structures. We investigate the drawbacks of previous studies and ﬁnd that a coarse-grained discriminator is insufﬁcient for supervising a font generator. To this end, we propose a novel Component-Aware Module (CAM), which supervises the generator to decouple content and style at a more ﬁne-grained level, i.e., the component level. Different from previous studies strug-gling to increase the complexity of generators, we aim to perform more effective supervision for a relatively simple generator to achieve its full potential, which is a brand new perspective for font generation. The whole frame-work achieves remarkable results by coupling component-level supervision with adversarial learning, hence we call itComponent-Guided GAN, shortly CG-GAN. Extensive ex-periments show that our approach outperforms state-of-the-art one-shot font generation methods. Furthermore, it can be applied to handwritten word synthesis and scene text im-age editing, suggesting the generalization of our approach. 