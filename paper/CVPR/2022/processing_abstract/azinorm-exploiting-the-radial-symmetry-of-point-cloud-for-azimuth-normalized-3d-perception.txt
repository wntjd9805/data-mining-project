Studying the inherent symmetry of data is of great im-portance in machine learning. Point cloud, the most impor-tant data format for 3D environmental perception, is natu-rally endowed with strong radial symmetry. In this work, we exploit this radial symmetry via a divide-and-conquer strategy to boost 3D perception performance and ease op-timization. We propose Azimuth Normalization (AziNorm), which normalizes the point clouds along the radial direc-tion and eliminates the variability brought by the differ-ence of azimuth. AziNorm can be ﬂexibly incorporated into most LiDAR-based perception methods. To validate its effectiveness and generalization ability, we apply Azi-Norm in both object detection and semantic segmentation.For detection, we integrate AziNorm into two representa-tive detection methods, the one-stage SECOND detector and the state-of-the-art two-stage PV-RCNN detector. Ex-periments on Waymo Open Dataset demonstrate that Azi-Norm improves SECOND and PV-RCNN by 7.03 mAPH and 3.01 mAPH respectively. For segmentation, we in-tegrate AziNorm into KPConv. On SemanticKitti dataset,AziNorm improves KPConv by 1.6/1.1 mIoU on val/test set. Besides, AziNorm remarkably improves data efﬁciency and accelerates convergence, reducing the requirement of data amounts or training epochs by an order of magni-tude. SECOND w/ AziNorm can signiﬁcantly outperform fully trained vanilla SECOND, even trained with only 10% data or 10% epochs. Code and models are available at https://github.com/hustvl/AziNorm. 