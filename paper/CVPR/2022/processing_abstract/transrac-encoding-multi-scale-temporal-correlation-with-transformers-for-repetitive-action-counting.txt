Counting repetitive actions are widely seen in human ac-tivities such as physical exercise. Existing methods focus on performing repetitive action counting in short videos, which is tough for dealing with longer videos in more re-alistic scenarios. In the data-driven era, the degradation of such generalization capability is mainly attributed to the lack of long video datasets. To complement this margin, we introduce a new large-scale repetitive action counting dataset covering a wide variety of video lengths, along with more realistic situations where action interruption or action inconsistencies occur in the video. Besides, we also pro-vide a fine-grained annotation of the action cycles instead of just counting annotation along with a numerical value.Such a dataset contains 1,451 videos with about 20,000 an-notations, which is more challenging. For repetitive action counting towards more realistic scenarios, we further pro-pose encoding multi-scale temporal correlation with trans-formers that can take into account both performance and ef-ficiency. Furthermore, with the help of fine-grained annota-tion of action cycles, we propose a density map regression-based method to predict the action period, which yields bet-ter performance with sufficient interpretability. Our pro-posed method outperforms state-of-the-art methods on all datasets and also achieves better performance on the un-seen dataset without fine-tuning. The dataset and code are available 1. 