We study the problem of extracting accurate correspon-dences for point cloud registration. Recent keypoint-free methods bypass the detection of repeatable keypoints which is difﬁcult in low-overlap scenarios, showing great poten-tial in registration. They seek correspondences over down-sampled superpoints, which are then propagated to dense points. Superpoints are matched based on whether their neighboring patches overlap. Such sparse and loose match-ing requires contextual features capturing the geometric structure of the point clouds. We propose Geometric Trans-former to learn geometric feature for robust superpoint matching. It encodes pair-wise distances and triplet-wise angles, making it robust in low-overlap cases and invari-ant to rigid transformation. The simplistic design attains surprisingly high matching accuracy such that no RANSAC is required in the estimation of alignment transformation, leading to 100 times acceleration. Our method improves the inlier ratio by 17∼30 percentage points and the registra-tion recall by over 7 points on the challenging 3DLoMatch benchmark. Our code and models are available at https://github.com/qinzheng93/GeoTransformer. 