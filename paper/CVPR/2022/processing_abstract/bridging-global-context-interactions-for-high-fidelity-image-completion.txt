is available at https://github.com/lyndonzheng/TFill.Bridging global context interactions correctly is impor-tant for high-fidelity image completion with large masks.Previous methods attempting this via deep or large recep-tive field (RF) convolutions cannot escape from the dom-inance of nearby interactions, which may be inferior.In this paper, we propose to treat image completion as a di-rectionless sequence-to-sequence prediction task, and de-ploy a transformer to directly capture long-range depen-dence. Crucially, we employ a restrictive CNN with small and non-overlapping RF for weighted token representation, which allows the transformer to explicitly model the long-range visible context relations with equal importance in all layers, without implicitly confounding neighboring to-kens when larger RFs are used. To improve appearance consistency between visible and generated regions, a novel attention-aware layer (AAL) is introduced to better exploit distantly related high-frequency features. Overall, exten-sive experiments demonstrate superior performance com-pared to state-of-the-art methods on several datasets. Code 