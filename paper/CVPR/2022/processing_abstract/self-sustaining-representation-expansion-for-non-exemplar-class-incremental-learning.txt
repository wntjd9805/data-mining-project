Non-exemplar class-incremental learning is to recog-nize both the old and new classes when old class sam-ples cannot be saved.It is a challenging task since rep-resentation optimization and feature retention can only be achieved under supervision from new classes. To address this problem, we propose a novel self-sustaining representa-tion expansion scheme. Our scheme consists of a structure reorganization strategy that fuses main-branch expansion and side-branch updating to maintain the old features, and a main-branch distillation scheme to transfer the invari-ant knowledge. Furthermore, a prototype selection mecha-nism is proposed to enhance the discrimination between the old and new classes by selectively incorporating new sam-ples into the distillation process. Extensive experiments on three benchmarks demonstrate significant incremental per-formance, outperforming the state-of-the-art methods by a margin of 3%, 3% and 6%, respectively. 