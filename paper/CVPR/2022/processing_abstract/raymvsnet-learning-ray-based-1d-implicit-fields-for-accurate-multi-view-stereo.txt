Camera rayFeature aggregation 0 mm 5 mmLearning-based multi-view stereo (MVS) has by far cen-tered around 3D convolution on cost volumes. Due to the high computation and memory consumption of 3D CNN, the resolution of output depth is often considerably limited.Different from most existing works dedicated to adaptive re-ﬁnement of cost volumes, we opt to directly optimize the depth value along each camera ray, mimicking the range (depth) ﬁnding of a laser scanner. This reduces the MVS problem to ray-based depth optimization which is much more light-weight than full cost volume optimization.In particular, we propose RayMVSNet which learns sequen-tial prediction of a 1D implicit ﬁeld along each camera ray with the zero-crossing point indicating scene depth. This sequential modeling, conducted based on transformer fea-tures, essentially learns the epipolar line search in tradi-tional multi-view stereo. We also devise a multi-task learn-ing for better optimization convergence and depth accuracy.Our method ranks top on both the DTU and the Tanks &Temples datasets over all previous learning-based methods, achieving overall reconstruction score of 0.33mm on DTU and f-score of 59.48% on Tanks & Temples. 