Neural Radiance Fields (NeRF) is a technique for high quality novel view synthesis from a collection of posed in-put images. Like most view synthesis methods, NeRF uses tonemapped low dynamic range (LDR) as input; these im-ages have been processed by a lossy camera pipeline that smooths detail, clips highlights, and distorts the simple noise distribution of raw sensor data. We modify NeRF to instead train directly on linear raw images, preserving the scene’s full dynamic range. By rendering raw output im-ages from the resulting NeRF, we can perform novel high dynamic range (HDR) view synthesis tasks. In addition to changing the camera viewpoint, we can manipulate focus, exposure, and tonemapping after the fact. Although a single raw image appears signiﬁcantly more noisy than a postpro-cessed one, we show that NeRF is highly robust to the zero-mean distribution of raw noise. When optimized over many noisy raw inputs (25-200), NeRF produces a scene repre-sentation so accurate that its rendered novel views outper-form dedicated single and multi-image deep raw denoisers run on the same wide baseline input images. As a result, our method, which we call RawNeRF, can reconstruct scenes from extremely noisy images captured in near-darkness. 