Transfer learning for GANs successfully improves gen-eration performance under low-shot regimes. However, ex-isting studies show that the pretrained model using a sin-gle benchmark dataset is not generalized to various target datasets. More importantly, the pretrained model can be vulnerable to copyright or privacy risks as membership in-ference attack advances. To resolve both issues, we pro-pose an effective and unbiased data synthesizer, namelyPrimitives-PS, inspired by the generic characteristics of natural images. Specifically, we utilize 1) the generic statistics on the frequency magnitude spectrum, 2) the el-ementary shape (i.e., image composition via elementary shapes) for representing the structure information, and 3) the existence of saliency as prior. Since our synthesizer only considers the generic properties of natural images, the single model pretrained on our dataset can be consistently transferred to various target datasets, and even outperforms the previous methods pretrained with the natural images in terms of FrÂ´echet inception distance. Extensive analysis, ab-lation study, and evaluations demonstrate that each com-ponent of our data synthesizer is effective, and provide in-sights on the desirable nature of the pretrained model for the transferability of GANs. 