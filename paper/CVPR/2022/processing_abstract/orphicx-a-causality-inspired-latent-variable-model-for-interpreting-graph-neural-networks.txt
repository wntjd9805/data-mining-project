This paper proposes a new eXplanation framework, called OrphicX, for generating causal explanations for any graph neural networks (GNNs) based on learned la-tent causal factors. Speciﬁcally, we construct a distinct generative model and design an objective function that en-courages the generative model to produce causal, compact, and faithful explanations. This is achieved by isolating the causal factors in the latent space of graphs by maximizing the information ﬂow measurements. We theoretically analyze the cause-effect relationships in the proposed causal graph, identify node attributes as confounders between graphs andGNN predictions, and circumvent such confounder effect by leveraging the backdoor adjustment formula. Our frame-work is compatible with any GNNs, and it does not require access to the process by which the target GNN produces its predictions. In addition, it does not rely on the linear-independence assumption of the explained features, nor re-quire prior knowledge on the graph learning tasks. We show a proof-of-concept of OrphicX on canonical classiﬁ-cation problems on graph data. In particular, we analyze the explanatory subgraphs obtained from explanations for molecular graphs (i.e., Mutag) and quantitatively evaluate the explanation performance with frequently occurring sub-graph patterns. Empirically, we show that OrphicX can ef-fectively identify the causal semantics for generating causal explanations, signiﬁcantly outperforming its alternatives1. 