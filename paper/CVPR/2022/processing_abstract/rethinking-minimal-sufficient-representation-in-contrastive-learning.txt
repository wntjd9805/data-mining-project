Contrastive learning between different views of the data achieves outstanding success in the field of self-supervised representation learning and the learned representations are useful in broad downstream tasks. Since all supervision information for one view comes from the other view, con-trastive learning approximately obtains the minimal suf-ficient representation which contains the shared informa-tion and eliminates the non-shared information between views. Considering the diversity of the downstream tasks, it cannot be guaranteed that all task-relevant information is shared between views. Therefore, we assume the non-shared task-relevant information cannot be ignored and theoretically prove that the minimal sufficient representa-tion in contrastive learning is not sufficient for the down-stream tasks, which causes performance degradation. This reveals a new problem that the contrastive learning mod-els have the risk of over-fitting to the shared information between views. To alleviate this problem, we propose to increase the mutual information between the representa-tion and input as regularization to approximately intro-duce more task-relevant information, since we cannot uti-lize any downstream task information during training. Ex-tensive experiments verify the rationality of our analysis and the effectiveness of our method.It significantly im-proves the performance of several classic contrastive learn-ing models in downstream tasks. Our code is available at https://github.com/Haoqing-Wang/InfoCL. 