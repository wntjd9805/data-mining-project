We propose a new video camouflaged object detection (VCOD) framework that can exploit both short-term dy-namics and long-term temporal consistency to detect cam-ouflaged objects from video frames. An essential property of camouflaged objects is that they usually exhibit patterns similar to the background and thus make them hard to iden-tify from still images. Therefore, effectively handling tem-poral dynamics in videos becomes the key for the VCOD task as the camouflaged objects will be noticeable when they move. However, current VCOD methods often leverage homography or optical flows to represent motions, where the detection error may accumulate from both the motion estimation error and the segmentation error. On the other hand, our method unifies motion estimation and object seg-mentation within a single optimization framework. Specifi-cally, we build a dense correlation volume to implicitly cap-ture motions between neighbouring frames and utilize the final segmentation supervision to optimize the implicit mo-tion estimation and segmentation jointly. Furthermore, to enforce temporal consistency within a video sequence, we jointly utilize a spatio-temporal transformer to refine the short-term predictions. Extensive experiments on VCOD benchmarks demonstrate the architectural effectiveness of our approach. We also provide a large-scale VCOD dataset* Indicates equal contribution; â€  Corresponding author (dengp-fan@gmail.com). Work was done while Xuelian Cheng was an MBZUAI visiting scholar mentored by Deng-Ping Fan. named MoCA-Mask with pixel-level handcrafted ground-truth masks and construct a comprehensive VCOD bench-mark with previous methods to facilitate research in this direction. Dataset Link: https://xueliancheng. github.io/SLT-Net-project. 