Text logo design heavily relies on the creativity and ex-pertise of professional designers, in which arranging ele-ment layouts is one of the most important procedures. How-ever, few attention has been paid to this task which needs to take many factors (e.g., fonts, linguistics, topics, etc.) into consideration.In this paper, we propose a content-aware layout generation network which takes glyph images and their corresponding text as input and synthesizes aes-thetic layouts for them automatically. Specifically, we de-velop a dual-discriminator module, including a sequence discriminator and an image discriminator, to evaluate both the character placing trajectories and rendered shapes of synthesized text logos, respectively. Furthermore, we fuse the information of linguistics from texts and visual seman-tics from glyphs to guide layout prediction, which both play important roles in professional layout design. To train and evaluate our approach, we construct a dataset named asTextLogo3K, consisting of about 3,500 text logo images and their pixel-level annotations. Experimental studies on this dataset demonstrate the effectiveness of our approach for synthesizing visually-pleasing text logos and verify its su-periority against the state of the art. 