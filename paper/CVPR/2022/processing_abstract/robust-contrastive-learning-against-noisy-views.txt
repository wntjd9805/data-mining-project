Noisy ViewContrastive learning relies on an assumption that posi-tive pairs contain related views that share certain underly-ing information about an instance, e.g., patches of an im-age or co-occurring multimodal signals of a video. What if this assumption is violated? The literature suggests that contrastive learning produces suboptimal representations in the presence of noisy views, e.g., false positive pairs with no apparent shared information. In this work, we pro-pose a new contrastive loss function that is robust against noisy views. We provide rigorous theoretical justiﬁcations by showing connections to robust symmetric losses for noisy binary classiﬁcation and by establishing a new contrastive bound for mutual information maximization based on theWasserstein distance measure. The proposed loss is com-pletely modality-agnostic and a simple drop-in replacement for the InfoNCE loss, which makes it easy to apply to ex-isting contrastive frameworks. We show that our approach provides consistent improvements over the state-of-the-art on image, video, and graph contrastive learning bench-marks that exhibit a variety of real-world noise patterns. 