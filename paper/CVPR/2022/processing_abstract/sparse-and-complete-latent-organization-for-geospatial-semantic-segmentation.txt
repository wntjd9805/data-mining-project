Geospatial semantic segmentation on remote sensing im-ages suffers from large intra-class variance in both fore-ground and background classes. First, foreground objects are tiny in the remote sensing images and are represented by only a few pixels, which leads to large foreground intra-class variance and undermines the discrimination between foreground classes (issue ﬁrstly considered in this work).Second, background class contains complex context, which results in false alarms due to large background intra-class variance. To alleviate these two issues, we construct a sparse and complete latent structure via prototypes. In par-ticular, to enhance the sparsity of the latent space, we de-sign a prototypical contrastive learning to have prototypes of the same category clustering together and prototypes of different categories to be far away from each other. Also, we strengthen the completeness of the latent space by modeling all foreground categories and hardest (nearest) background objects. We further design a patch shufﬂe augmentation for remote sensing images with complicated contexts. Our aug-mentation encourages the semantic information of an ob-ject to be correlated only to the limited context within the patch that is speciﬁc to its category, which further reduces large intra-class variance. We conduct extensive evalua-tions on a large scale remote sensing dataset, showing our approach signiﬁcantly outperforms state-of-the-art methods by a large margin. 