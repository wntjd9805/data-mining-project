We propose an analysis-by-synthesis method for fast multi-view 3D reconstruction of opaque objects with ar-bitrary materials and illumination. State-of-the-art meth-ods use both neural surface representations and neural ren-dering. While flexible, neural surface representations are a significant bottleneck in optimization runtime.Instead, we represent surfaces as triangle meshes and build a dif-ferentiable rendering pipeline around triangle rasterization and neural shading. The renderer is used in a gradient de-scent optimization where both a triangle mesh and a neural shader are jointly optimized to reproduce the multi-view im-ages. We evaluate our method on a public 3D reconstruc-tion dataset and show that it can match the reconstruction accuracy of traditional baselines and neural approaches while surpassing them in optimization runtime. Addition-ally, we investigate the shader and find that it learns an interpretable representation of appearance, enabling appli-cations such as 3D material editing. 