Most of the existing Out-Of-Distribution (OOD) detec-tion algorithms depend on single input source: the feature, the logit, or the softmax probability. However, the immense diversity of the OOD examples makes such methods frag-ile. There are OOD samples that are easy to identify in the feature space while hard to distinguish in the logit space and vice versa. Motivated by this observation, we propose a novel OOD scoring method named Virtual-logit Match-ing (ViM), which combines the class-agnostic score from feature space and the In-Distribution (ID) class-dependent logits. Speciﬁcally, an additional logit representing the vir-tual OOD class is generated from the residual of the fea-ture against the principal space, and then matched with the original logits by a constant scaling. The probability of this virtual logit after softmax is the indicator of OOD-ness.To facilitate the evaluation of large-scale OOD detection in academia, we create a new OOD dataset for ImageNet-1K, which is human-annotated and is 8.8× the size of ex-isting datasets. We conducted extensive experiments, in-cluding CNNs and vision transformers, to demonstrate the effectiveness of the proposed ViM score. In particular, us-ing the BiT-S model, our method gets an average AUROC 90.91% on four difﬁcult OOD benchmarks, which is 4% ahead of the best baseline. Code and dataset are available at https://github.com/haoqiwang/vim. 