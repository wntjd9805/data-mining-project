Digitizing physical objects into the virtual world has the potential to unlock new research and applications in em-bodied AI and mixed reality. This work focuses on recre-ating interactive digital twins of real-world articulated ob-jects, which can be directly imported into virtual environ-ments. We introduce Ditto to learn articulation model es-timation and 3D geometry reconstruction of an articulated object through interactive perception. Given a pair of vi-sual observations of an articulated object before and af-ter interaction, Ditto reconstructs part-level geometry and estimates the articulation model of the object. We em-ploy implicit neural representations for joint geometry and articulation modeling. Our experiments show that Ditto effectively builds digital twins of articulated objects in a category-agnostic way. We also apply Ditto to real-world objects and deploy the recreated digital twins in physical simulation. Code and additional results are available at https://ut-austin-rpl.github.io/Ditto/ 