In generative adversarial networks, improving discrimi-nators is one of the key components for generation perfor-mance. As image classifiers are biased toward texture and debiasing improves accuracy, we investigate 1) if the dis-criminators are biased, and 2) if debiasing the discrimina-tors will improve generation performance. Indeed, we find empirical evidence that the discriminators are sensitive to the style (e.g., texture and color) of images. As a remedy, we propose feature statistics mixing regularization (FSMR) that encourages the discriminator’s prediction to be invari-ant to the styles of input images. Specifically, we generate a mixed feature of an original and a reference image in the discriminator’s feature space and we apply regulariza-tion so that the prediction for the mixed feature is consis-tent with the prediction for the original image. We conduct extensive experiments to demonstrate that our regulariza-tion leads to reduced sensitivity to style and consistently improves the performance of various GAN architectures on nine datasets. In addition, adding FSMR to recently-proposed augmentation-based GAN methods further im-proves image quality. Our code is available at https://github.com/naver-ai/FSMR. 