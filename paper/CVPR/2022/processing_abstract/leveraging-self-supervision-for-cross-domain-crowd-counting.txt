State-of-the-art methods for counting people in crowded scenes rely on deep networks to estimate crowd density.While effective, these data-driven approaches rely on large amount of data annotation to achieve good performance, which stops these models from being deployed in emergen-cies during which data annotation is either too costly or cannot be obtained fast enough.One popular solution is to use synthetic data for train-ing. Unfortunately, due to domain shift, the resulting mod-els generalize poorly on real imagery. We remedy this shortcoming by training with both synthetic images, along with their associated labels, and unlabeled real images. To this end, we force our network to learn perspective-aware features by training it to recognize upside-down real im-ages from regular ones and incorporate into it the abil-ity to predict its own uncertainty so that it can gener-ate useful pseudo labels for fine-tuning purposes. This yields an algorithm that consistently outperforms state-of-the-art cross-domain crowd counting ones without any extra computation at inference time. Code is publicly available at https : / / github . com / weizheliu / Cross -Domain-Crowd-Counting. 