Semi-supervised learning (SSL) is a method to make bet-ter models using a large number of easily accessible un-labeled data along with a small number of labeled data obtained at a high cost. Most of existing SSL studies fo-cus on the cases where sufficient amount of labeled sam-ples are available, tens to hundreds labeled samples for each class, which still requires a lot of labeling cost.In this paper, we focus on SSL environment with extremely scarce labeled samples, only 1 or 2 labeled samples per class, where most of existing methods fail to learn. We pro-pose a propagation regularizer which can achieve efficient and effective learning with extremely scarce labeled sam-ples by suppressing confirmation bias. In addition, for the realistic model selection in the absence of the validation dataset, we also propose a model selection method based on our propagation regularizer. The proposed methods show 70.9%, 30.3%, and 78.9% accuracy on CIFAR-10, CIFAR-100, SVHN dataset with just one labeled sample per class, which are improved by 8.9% to 120.2% compared to the ex-isting approaches. And our proposed methods also show good performance on a higher resolution dataset, STL-10. 