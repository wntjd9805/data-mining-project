Detecting abnormal events in video is commonly framed as a one-class classiﬁcation task, where training videos contain only normal events, while test videos encompassIn this scenario, both normal and abnormal events. anomaly detection is an open-set problem. However, some studies assimilate anomaly detection to action recognition.This is a closed-set scenario that fails to test the capabil-ity of systems at detecting new anomaly types. To this end, we propose UBnormal, a new supervised open-set bench-mark composed of multiple virtual scenes for video anomaly detection. Unlike existing data sets, we introduce abnor-mal events annotated at the pixel level at training time, for the ﬁrst time enabling the use of fully-supervised learn-ing methods for abnormal event detection. To preserve the typical open-set formulation, we make sure to include dis-joint sets of anomaly types in our training and test collec-tions of videos. To our knowledge, UBnormal is the ﬁrst video anomaly detection benchmark to allow a fair head-to-head comparison between one-class open-set models and supervised closed-set models, as shown in our experiments.Moreover, we provide empirical evidence showing that UB-normal can enhance the performance of a state-of-the-art anomaly detection framework on two prominent data sets, Avenue and ShanghaiTech. Our benchmark is freely available at https://github.com/lilygeorgescu/UBnormal. 