Cloth-Changing person re-identification (CC-ReID) aims at matching the same person across different loca-tions over a long-duration, e.g., over days, and therefore inevitably has cases of changing clothing. In this paper, we focus on handling well the CC-ReID problem under a more challenging setting, i.e., just from a single image, which en-ables an efficient and latency-free person identity matching for surveillance. Specifically, we introduce Gait recogni-tion as an auxiliary task to drive the Image ReID model to learn cloth-agnostic representations by leveraging per-sonal unique and cloth-independent gait information, we name this framework as GI-ReID. GI-ReID adopts a two-stream architecture that consists of an image ReID-Stream and an auxiliary gait recognition stream (Gait-Stream). TheGait-Stream, that is discarded in the inference for high ef-ficiency, acts as a regulator to encourage the ReID-Stream to capture cloth-invariant biometric motion features during the training. To get temporal continuous motion cues from a single image, we design a Gait Sequence Prediction (GSP) module for Gait-Stream to enrich gait information. Finally, a semantics consistency constraint over two streams is en-forced for effective knowledge regularization. Extensive ex-periments on multiple image-based Cloth-Changing ReID benchmarks, e.g., LTCC, PRCC, Real28, and VC-Clothes, demonstrate that GI-ReID performs favorably against the state-of-the-art methods. 