In single domain generalization, models trained with data from only one domain are required to perform well on many unseen domains. In this paper, we propose a new model, termed meta convolutional neural network, to solve the single domain generalization problem in image recog-nition. The key idea is to decompose the convolutional features of images into meta features. Acting as “visual words”, meta features are defined as universal and basic visual elements for image representations (like words for documents in language). Taking meta features as reference, we propose compositional operations to eliminate irrele-vant features of local convolutional features by an address-ing process and then to reformulate the convolutional fea-ture maps as a composition of related meta features. In this way, images are universally coded without biased informa-tion from the unseen domain, which can be processed by following modules trained in the source domain. The com-positional operations adopt a regression analysis technique to learn the meta features in an online batch learning man-ner. Extensive experiments on multiple benchmark datasets verify the superiority of the proposed model in improving single domain generalization ability. 