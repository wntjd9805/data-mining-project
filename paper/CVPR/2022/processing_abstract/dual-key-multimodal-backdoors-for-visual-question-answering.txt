The success of deep learning has enabled advances in multimodal tasks that require non-trivial fusion of mul-tiple input domains. Although multimodal models have shown potential in many problems, their increased complex-ity makes them more vulnerable to attacks. A Backdoor (orTrojan) attack is a class of security vulnerability wherein an attacker embeds a malicious secret behavior into a net-work (e.g. targeted misclassiﬁcation) that is activated when an attacker-speciﬁed trigger is added to an input.In this work, we show that multimodal networks are vul-nerable to a novel type of attack that we refer to as Dual-Key Multimodal Backdoors. This attack exploits the com-plex fusion mechanisms used by state-of-the-art networks to embed backdoors that are both effective and stealthy. In-stead of using a single trigger, the proposed attack embeds a trigger in each of the input modalities and activates the ma-licious behavior only when both the triggers are present. We present an extensive study of multimodal backdoors on theVisual Question Answering (VQA) task with multiple archi-tectures and visual feature backbones. A major challenge in embedding backdoors in VQA models is that most models use visual features extracted from a ﬁxed pretrained object detector. This is challenging for the attacker as the detector can distort or ignore the visual trigger entirely, which leads to models where backdoors are over-reliant on the language trigger. We tackle this problem by proposing a visual trigger optimization strategy designed for pretrained object detec-tors. Through this method, we create Dual-Key Backdoors with over a 98% attack success rate while only poisoning 1% of the training data. Finally, we release TrojVQA, a large collection of clean and trojan VQA models to enable research in defending against multimodal backdoors. 