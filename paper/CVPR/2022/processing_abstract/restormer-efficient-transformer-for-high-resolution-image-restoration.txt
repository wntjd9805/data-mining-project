Since convolutional neural networks (CNNs) perform well at learning generalizable image priors from large-scale data, these models have been extensively applied to image restoration and related tasks. Recently, another class of neural architectures, Transformers, have shown signifi-cant performance gains on natural language and high-level vision tasks. While the Transformer model mitigates the shortcomings of CNNs (i.e., limited receptive field and in-adaptability to input content), its computational complex-ity grows quadratically with the spatial resolution, there-fore making it infeasible to apply to most image restora-tion tasks involving high-resolution images. In this work, we propose an efficient Transformer model by making sev-eral key designs in the building blocks (multi-head atten-tion and feed-forward network) such that it can capture long-range pixel interactions, while still remaining appli-cable to large images. Our model, named RestorationTransformer (Restormer), achieves state-of-the-art results on several image restoration tasks, including image derain-ing, single-image motion deblurring, defocus deblurring (single-image and dual-pixel data), and image denoising (Gaussian grayscale/color denoising, and real image de-noising). The source code and pre-trained models are avail-able at https://github.com/swz30/Restormer. 