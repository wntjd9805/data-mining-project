Optimization based tracking methods have been widely successful by integrating a target model prediction mod-ule, providing effective global reasoning by minimizing an objective function. While this inductive bias integrates valuable domain knowledge, it limits the expressivity of the tracking network.In this work, we therefore pro-pose a tracker architecture employing a Transformer-based model prediction module. Transformers capture global relations with little inductive bias, allowing it to learn the prediction of more powerful target models. We fur-ther extend the model predictor to estimate a second set of weights that are applied for accurate bounding box regression. The resulting tracker ToMP relies on train-ing and on test frame information in order to predict all weights transductively. We train the proposed tracker end-to-end and validate its performance by conducting compre-hensive experiments on multiple tracking datasets. ToMP sets a new state of the art on three benchmarks, achiev-ing an AUC of 68.5% on the challenging LaSOT [14] dataset. The code and trained models are available at https://github.com/visionml/pytracking 