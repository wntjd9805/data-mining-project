In this paper, we propose a novel and practical mecha-nism to enable the service provider to verify whether a sus-pect model is stolen from the victim model via model ex-traction attacks. Our key insight is that the proﬁle of a DNN model’s decision boundary can be uniquely characterized by its Universal Adversarial Perturbations (UAPs). UAPs belong to a low-dimensional subspace and piracy models’ subspaces are more consistent with victim model’s subspace compared with non-piracy model. Based on this, we pro-pose a UAP ﬁngerprinting method for DNN models and train an encoder via contrastive learning that takes ﬁnger-prints as inputs, outputs a similarity score. Extensive stud-ies show that our framework can detect model IntellectualProperty (IP) breaches with conﬁdence > 99.99 % within only 20 ﬁngerprints of the suspect model. It also has good generalizability across different model architectures and is robust against post-modiﬁcations on stolen models. 