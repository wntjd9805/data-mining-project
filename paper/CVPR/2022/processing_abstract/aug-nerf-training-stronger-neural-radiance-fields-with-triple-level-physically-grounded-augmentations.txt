Neural Radiance Field (NeRF) regresses a neural param-eterized scene by differentially rendering multi-view images with ground-truth supervision. However, when interpolat-ing novel views, NeRF often yields inconsistent and visually non-smooth geometric results, which we consider as a gen-eralization gap between seen and unseen views. Recent ad-vances in convolutional neural networks have demonstrated the promise of advanced robust data augmentations, either random or learned, in enhancing both in-distribution and out-of-distribution generalization. Inspired by that, we pro-pose Augmented NeRF (Aug-NeRF), which for the first time brings the power of robust data augmentations into regular-izing the NeRF training. Particularly, our proposal learns to seamlessly blend worst-case perturbations into three dis-tinct levels of the NeRF pipeline with physical grounds, including (1) the input coordinates, to simulate imprecise camera parameters at image capture; (2) intermediate fea-tures, to smoothen the intrinsic feature manifold; and (3) pre-rendering output, to account for the potential degra-dation factors in the multi-view image supervision. Exten-sive results demonstrate that Aug-NeRF effectively boostsNeRF performance in both novel view synthesis (up to 1.5dBPSNR gain) and underlying geometry reconstruction. Fur-thermore, thanks to the implicit smooth prior injected by the triple-level augmentations, Aug-NeRF can even recover scenes from heavily corrupted images, a highly challeng-ing setting untackled before. Our codes are available in https://github.com/VITA-Group/Aug-NeRF. 