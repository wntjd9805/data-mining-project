Guided depth super-resolution (GDSR) is an essential topic in multi-modal image processing, which reconstructs high-resolution (HR) depth maps from low-resolution ones collected with suboptimal conditions with the help of HRRGB images of the same scene. To solve the challenges in interpreting the working mechanism, extracting cross-modal features and RGB texture over-transferred, we propose a novel Discrete Cosine Transform Network (DCTNet) to alle-viate the problems from three aspects. First, the Discrete Co-sine Transform (DCT) module reconstructs the multi-channelHR depth features by using DCT to solve the channel-wise optimization problem derived from the image domain. Sec-ond, we introduce a semi-coupled feature extraction module that uses shared convolutional kernels to extract common information and private kernels to extract modality-specific information. Third, we employ an edge attention mechanism to highlight the contours informative for guided upsampling.Extensive quantitative and qualitative evaluations demon-strate the effectiveness of our DCTNet, which outperforms previous state-of-the-art methods with a relatively small number of parameters. The code is available at https:// github.com/Zhaozixiang1228/GDSR-DCTNet. 