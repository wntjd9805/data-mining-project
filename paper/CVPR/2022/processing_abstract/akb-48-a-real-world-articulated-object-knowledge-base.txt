Human life is populated with articulated objects. A com-prehensive understanding of articulated objects, namely appearance, structure, physical property, and semantics, will benefit many research communities. As current artic-ulated object understanding solutions are usually based on synthetic object dataset with CAD models without physics properties, which prevent satisfied generalization from sim-ulation to real-world applications in visual and robotics tasks. To bridge the gap, we present AKB-48: a large-scale Articulated object Knowledge Base which consists of 2,037 real-world 3D articulated object models of 48 cat-egories. Each object is described by a knowledge graphArtiKG. To build the AKB-48, we present a fast articula-tion knowledge modeling (FArM) pipeline, which can fulfill the ArtiKG for an articulated object within 10-15 minutes, and largely reduce the cost for object modeling in the realâ€ Cewu Lu is the corresponding author. He is the member of Qing YuanResearch Institute and MoE Key Lab of Artificial Intelligence, AI Institute,Shanghai Jiao Tong University, and Shanghai Qi Zhi Institute, China. world. Using our dataset, we propose AKBNet, an integral pipeline for Category-level Visual Articulation Manipula-tion (C-VAM) task, in which we benchmark three sub-tasks, namely pose estimation, object reconstruction and manipu-lation. Dataset, codes, and models are publicly available at https://liuliu66.github.io/AKB-48. 