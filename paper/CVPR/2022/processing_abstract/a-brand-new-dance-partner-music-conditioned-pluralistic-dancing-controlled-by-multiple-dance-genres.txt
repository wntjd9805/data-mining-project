When coming up with phrases of movement, choreogra-phers all have their habits as they are used to their skilled dance genres. Therefore, they tend to return certain pat-terns of the dance genres that they are familiar with. What if artificial intelligence could be used to help choreogra-phers blend dance genres by suggesting various dances, and one that matches their choreographic style? Numer-ous task-specific variants of autoregressive networks have been developed for dance generation. Yet, a serious limita-tion remains that all existing algorithms can return repeated patterns for a given initial pose sequence, which may be in-ferior. To mitigate this issue, we propose MNET, a novel and scalable approach that can perform music-conditioned pluralistic dance generation synthesized by multiple dance genres using only a single model. Here, we learn a dance-genre aware latent representation by training a conditional generative adversarial network leveraging Transformer ar-chitecture. We conduct extensive experiments on AIST++ along with user studies. Compared to the state-of-the-art methods, our method synthesizes plausible and diverse out-puts according to multiple dance genres as well as gen-erates outperforming dance sequences qualitatively and quantitatively. 