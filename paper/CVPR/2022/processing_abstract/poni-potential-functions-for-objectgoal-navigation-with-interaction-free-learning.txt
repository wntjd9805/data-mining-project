State-of-the-art approaches to ObjectGoal navigation (ObjectNav) rely on reinforcement learning and typically require significant computational resources and time for learning. We propose Potential functions for ObjectGoalNavigation with Interaction-free learning (PONI), a modu-lar approach that disentangles the skills of ‘where to look?’ for an object and ‘how to navigate to (x, y)?’. Our key in-sight is that ‘where to look?’ can be treated purely as a perception problem, and learned without environment in-teractions. To address this, we propose a network that pre-dicts two complementary potential functions conditioned on a semantic map and uses them to decide where to look for an unseen object. We train the potential function network using supervised learning on a passive dataset of top-down semantic maps, and integrate it into a modular framework to perform ObjectNav. Experiments on Gibson and Mat-terport3D demonstrate that our method achieves the state-of-the-art for ObjectNav while incurring up to 1,600× less computational cost for training. Code and pre-trained mod-els are available.1 