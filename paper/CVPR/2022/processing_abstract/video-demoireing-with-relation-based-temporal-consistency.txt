Moir´e patterns, appearing as color distortions, severely degrade image and video qualities when ﬁlming a screen with digital cameras. Considering the increasing demands for capturing videos, we study how to remove such undesir-able moir´e patterns in videos, namely video demoir´eing. To this end, we introduce the ﬁrst hand-held video demoir´eing dataset with a dedicated data collection pipeline to ensure spatial and temporal alignments of captured data. Further, a baseline video demoir´eing model with implicit feature space alignment and selective feature aggregation is devel-oped to leverage complementary information from nearby frames to improve frame-level video demoir´eing. More im-portantly, we propose a relation-based temporal consis-tency loss to encourage the model to learn temporal con-sistency priors directly from ground-truth reference videos, which facilitates producing temporally consistent predic-tions and effectively maintains frame-level qualities. Ex-tensive experiments manifest the superiority of our model.Code is available at https://daipengwa.github. io/VDmoire_ProjectPage/. 