The goal of open-world compositional zero-shot learn-ing (OW-CZSL) is to recognize compositions of state and objects in images, given only a subset of them during train-ing and no prior on the unseen compositions. In this set-ting, models operate on a huge output space, containing all possible state-object compositions. While previous works tackle the problem by learning embeddings for the com-positions jointly, here we revisit a simple CZSL baseline and predict the primitives, i.e. states and objects, indepen-dently. To ensure that the model develops primitive-specific features, we equip the state and object classifiers with sepa-rate, non-linear feature extractors. Moreover, we estimate the feasibility of each composition through external knowl-edge, using this prior to remove unfeasible compositions from the output space. Finally, we propose a new setting, i.e. CZSL under partial supervision (pCZSL), where either only objects or state labels are available during training, and we can use our prior to estimate the missing labels.Our model, Knowledge-Guided Simple Primitives (KG-SP), achieves state of the art in both OW-CZSL and pCZSL, sur-passing most recent competitors even when coupled with semi-supervised learning techniques. Code available at: https:// github.com/ ExplainableML/ KG-SP. 