We introduce AdaMix, an adaptive differentially private algorithm for training deep neural network classiﬁers using both private and public image data. While pre-training lan-guage models on large public datasets has enabled strong differential privacy (DP) guarantees with minor loss of ac-curacy, a similar practice yields punishing trade-offs in vi-sion tasks. A few-shot or even zero-shot learning baseline that ignores private data can outperform ﬁne-tuning on a large private dataset. AdaMix incorporates few-shot train-ing, or cross-modal zero-shot learning, on public data prior to private ﬁne-tuning, to improve the trade-off. AdaMix re-duces the error increase from the non-private upper bound from the 167-311% of the baseline, on average across 6 datasets, to 68-92% depending on the desired privacy level selected by the user. AdaMix tackles the trade-off aris-ing in visual classiﬁcation, whereby the most privacy sen-sitive data, corresponding to isolated points in representa-tion space, are also critical for high classiﬁcation accuracy.In addition, AdaMix comes with strong theoretical privacy guarantees and convergence analysis. 