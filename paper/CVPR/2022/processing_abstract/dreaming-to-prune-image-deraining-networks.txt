Convolutional image deraining networks have achieved great success while suffering from tremendous computa-tional and memory costs. Most model compression methods require original data for iterative fine-tuning, which is lim-ited in real-world applications due to storage, privacy, and transmission constraints. We note that it is overstretched to fine-tune the compressed model using self-collected data, as it exhibits poor generalization over images with different degradation characteristics. To address this problem, we propose a novel data-free compression framework for de-raining networks. It is based on our observation that deep degradation representations can be clustered by degrada-tion characteristics (types of rain) while independent of im-age content. Therefore, in our framework, we “dream” di-verse in-distribution degraded images using a deep inver-sion paradigm, thus leveraging them to distill the pruned model. Specifically, we preserve the performance of the pruned model in a dual-branch way.In one branch, we invert the pre-trained model (teacher) to reconstruct the de-graded inputs that resemble the original distribution and employ the orthogonal regularization for deep features to yield degradation diversity. In the other branch, the pruned model (student) is distilled to fit the teacher’s original sta-tistical modeling on these dreamed inputs. Further, an adaptive pruning scheme is proposed to determine the hi-erarchical sparsity, which alleviates the regression drift of the initial pruned model. Experiments on various derain-ing datasets demonstrate that our method can reduce about 40% FLOPs of the state-of-the-art models while maintain-ing comparable performance without original data. 