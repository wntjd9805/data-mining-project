With diverse presentation attacks emerging continually, generalizable face anti-spoofing (FAS) has drawn growing attention. Most existing methods implement domain gener-alization (DG) on the complete representations. However, different image statistics may have unique properties for theFAS tasks. In this work, we separate the complete represen-tation into content and style ones. A novel Shuffled StyleAssembly Network (SSAN) is proposed to extract and re-assemble different content and style features for a stylized feature space. Then, to obtain a generalized representa-tion, a contrastive learning strategy is developed to empha-size liveness-related style information while suppress the domain-specific one. Finally, the representations of the cor-rect assemblies are used to distinguish between living and spoofing during the inferring. On the other hand, despite the decent performance, there still exists a gap between academia and industry, due to the difference in data quan-tity and distribution. Thus, a new large-scale benchmark for FAS is built up to further evaluate the performance of algorithms in reality. Both qualitative and quantitative re-sults on existing and proposed benchmarks demonstrate the effectiveness of our methods. The codes will be available at https://github.com/wangzhuo2019/SSAN. 