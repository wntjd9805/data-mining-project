Contrastive learning (or its variants) has recently be-come a promising direction in the self-supervised learn-ing domain, achieving similar performance as supervised learning with minimum ﬁne-tuning. Despite the labeling ef-ﬁciency, wide and large networks are required to achieve high accuracy, which incurs a high amount of computation and hinders the pragmatic merit of self-supervised learn-ing. To effectively reduce the computation of insigniﬁcant features or channels, recent dynamic pruning algorithms for supervised learning employed auxiliary salience pre-dictors. However, we found that such salience predictors cannot be easily trained when they are na¨ıvely applied to contrastive learning from scratch. To address this issue, we propose contrastive dual gating (CDG), a novel dy-namic pruning algorithm that skips the uninformative fea-tures during contrastive learning without hurting the train-ability of the networks. We demonstrate the superiority of CDG with ResNet models for CIFAR-10, CIFAR-100, and ImageNet-100 datasets. Compared to our implemen-tations of state-of-the-art dynamic pruning algorithms for self-supervised learning, CDG achieves up to 15% accu-racy improvement for CIFAR-10 dataset with higher com-putation reduction. 