Self-explaining deep models are designed to learn the la-tent concept-based explanations implicitly during training, which eliminates the requirement of any post-hoc explana-tion generation technique.In this work, we propose one such model that appends an explanation generation mod-ule on top of any basic network and jointly trains the whole module that shows high predictive performance and gen-erates meaningful explanations in terms of concepts. Our training strategy is suitable for unsupervised concept learn-ing with much lesser parameter space requirements com-pared to baseline methods. Our proposed model also has provision for leveraging self-supervision on concepts to ex-tract better explanations. However, with full concept su-pervision, we achieve the best predictive performance com-pared to recently proposed concept-based explainable mod-els. We report both qualitative and quantitative results with our method, which shows better performance than recently proposed concept-based explainability methods. We re-ported exhaustive results with two datasets without ground truth concepts, i.e., CIFAR10, ImageNet, and two datasets with ground truth concepts, i.e., AwA2, CUB-200, to show the effectiveness of our method for both cases. To the best of our knowledge, we are the first ante-hoc explanation gener-ation method to show results with a large-scale dataset such as ImageNet. 