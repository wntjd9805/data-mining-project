We target at the task of weakly-supervised action lo-calization (WSAL), where only video-level action labels are available during model training. Despite the recent progress, existing methods mainly embrace a localization-by-classiﬁcation paradigm and overlook the fruitful ﬁne-grained temporal distinctions between video sequences, thus suffering from severe ambiguity in classiﬁcation learn-ing and classiﬁcation-to-localization adaption. This paper argues that learning by contextually comparing sequence-to-sequence distinctions offers an essential inductive bias inWSAL and helps identify coherent action instances. Specif-ically, under a differentiable dynamic programming formu-lation, two complementary contrastive objectives are de-signed, including Fine-grained Sequence Distance (FSD) contrasting and Longest Common Subsequence (LCS) con-trasting, where the ﬁrst one considers the relations of var-ious action/background proposals by using match, insert, and delete operators and the second one mines the longest common subsequences between two videos. Both contrast-ing modules can enhance each other and jointly enjoy the merits of discriminative action-background separation and alleviated task gap between classiﬁcation and localiza-tion. Extensive experiments show that our method achieves state-of-the-art performance on two popular benchmarks.Our code is available at https : / / github . com /MengyuanChen21/CVPR2022-FTCL. 