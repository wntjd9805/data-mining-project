Model pre-training is a cornerstone of modern visual recognition systems. Although fully supervised pre-training on datasets like ImageNet is still the de-facto standard, re-cent studies suggest that large-scale weakly supervised pre-training can outperform fully supervised approaches. This paper revisits weakly-supervised pre-training of models us-ing hashtag supervision with modern versions of residual networks and the largest-ever dataset of images and corre-sponding hashtags. We study the performance of the result-ing models in various transfer-learning settings including zero-shot transfer. We also compare our models with those obtained via large-scale self-supervised learning. We find our weakly-supervised models to be very competitive across all settings, and find they substantially outperform their self-supervised counterparts. We also include an investi-gation into whether our models learned potentially trou-bling associations or stereotypes. Overall, our results pro-vide a compelling argument for the use of weakly supervised learning in the development of visual recognition systems.Our models, Supervised Weakly through hashtAGs (SWAG), are available publicly. 