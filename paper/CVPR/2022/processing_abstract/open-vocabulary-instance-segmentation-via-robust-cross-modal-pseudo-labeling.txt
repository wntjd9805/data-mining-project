Open-vocabulary instance segmentation aims at seg-menting novel classes without mask annotations. It is an im-portant step toward reducing laborious human supervision.Most existing works ﬁrst pretrain a model on captioned images covering many novel classes and then ﬁnetune it on limited base classes with mask annotations. However, the high-level textual information learned from caption pre-training alone cannot effectively encode the details required for pixel-wise segmentation. To address this, we propose a cross-modal pseudo-labeling framework, which generates training pseudo masks by aligning word semantics in cap-tions with visual features of object masks in images. Thus, our framework is capable of labeling novel classes in cap-tions via their word semantics to self-train a student model.To account for noises in pseudo masks, we design a robust student model that selectively distills mask knowledge by estimating the mask noise levels, hence mitigating the ad-verse impact of noisy pseudo masks. By extensive experi-ments, we show the effectiveness of our framework, where we signiﬁcantly improve mAP score by 4.5% on MS-COCO and 5.1% on the large-scale Open Images & ConceptualCaptions datasets compared to the state-of-the-art.1 