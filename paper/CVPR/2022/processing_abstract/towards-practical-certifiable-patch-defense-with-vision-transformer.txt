Patch attacks, one of the most threatening forms of phys-ical attack in adversarial examples, can lead networks to induce misclassification by modifying pixels arbitrarily in a continuous region. Certifiable patch defense can guaran-tee robustness that the classifier is not affected by patch at-tacks. Existing certifiable patch defenses sacrifice the clean accuracy of classifiers and only obtain a low certified accu-racy on toy datasets. Furthermore, the clean and certified accuracy of these methods is still significantly lower than the accuracy of normal classification networks, which lim-its their application in practice. To move towards a prac-tical certifiable patch defense, we introduce Vision Trans-former (ViT) into the framework of Derandomized Smooth-ing (DS). Specifically, we propose a progressive smoothed image modeling task to train Vision Transformer, which can capture the more discriminable local context of an image while preserving the global semantic information. For effi-cient inference and deployment in the real world, we inno-vatively reconstruct the global self-attention structure of the original ViT into isolated band unit self-attention. On Ima-geNet, under 2% area patch attacks our method achieves 41.70% certified accuracy, a nearly 1-fold increase over the previous best method (26.00%). Simultaneously, our method achieves 78.58% clean accuracy, which is quite close to the normal ResNet-101 accuracy. Extensive exper-iments show that our method obtains state-of-the-art clean and certified accuracy with inferring efficiently on CIFAR-10 and ImageNet. 