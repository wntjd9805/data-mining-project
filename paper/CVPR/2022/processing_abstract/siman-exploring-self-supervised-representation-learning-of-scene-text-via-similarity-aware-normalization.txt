Recently self-supervised representation learning has drawn considerable attention from the scene text recogni-tion community. Different from previous studies using con-trastive learning, we tackle the issue from an alternative perspective, i.e., by formulating the representation learning scheme in a generative manner. Typically, the neighbor-ing image patches among one text line tend to have simi-lar styles, including the strokes, textures, colors, etc. Moti-vated by this common sense, we augment one image patch and use its neighboring patch as guidance to recover itself.Specifically, we propose a Similarity-Aware Normalization (SimAN) module to identify the different patterns and align the corresponding styles from the guiding patch.In this way, the network gains representation capability for distin-guishing complex patterns such as messy strokes and clut-tered backgrounds. Experiments show that the proposedSimAN significantly improves the representation quality and achieves promising performance. Moreover, we surpris-ingly find that our self-supervised generative network has impressive potential for data synthesis, text image editing, and font interpolation, which suggests that the proposedSimAN has a wide range of practical applications. 