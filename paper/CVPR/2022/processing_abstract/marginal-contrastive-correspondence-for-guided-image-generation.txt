Exemplar-based image translation establishes dense correspondences between a conditional input and an exem-plar (from two different domains) for leveraging detailed exemplar styles to achieve realistic image translation. Ex-isting work builds the cross-domain correspondences im-plicitly by minimizing feature-wise distances across the two domains. Without explicit exploitation of domain-invariant features, this approach may not reduce the domain gap effectively which often leads to sub-optimal correspon-dences and image translation. We design a Marginal Con-trastive Learning Network (MCL-Net) that explores con-trastive learning to learn domain-invariant features for re-alistic exemplar-based image translation. Specifically, we design an innovative marginal contrastive loss that guides to establish dense correspondences explicitly. Nevertheless, building correspondence with domain-invariant semantics alone may impair the texture patterns and lead to degraded texture generation. We thus design a Self-Correlation Map (SCM) that incorporates scene structures as auxiliary infor-mation which improves the built correspondences substan-tially. Quantitative and qualitative experiments on multifar-ious image translation tasks show that the proposed method outperforms the state-of-the-art consistently. 