Recent transformer-based solutions have been intro-duced to estimate 3D human pose from 2D keypoint se-quence by considering body joints among all frames glob-ally to learn spatio-temporal correlation. We observe that the motions of different joints differ significantly. How-ever, the previous methods cannot efficiently model the solid inter-frame correspondence of each joint, leading to insuf-ficient learning of spatial-temporal correlation. We pro-pose MixSTE (Mixed Spatio-Temporal Encoder), which has a temporal transformer block to separately model the tem-poral motion of each joint and a spatial transformer block to learn inter-joint spatial correlation. These two blocks are utilized alternately to obtain better spatio-temporal fea-ture encoding. In addition, the network output is extended from the central frame to entire frames of the input video, thereby improving the coherence between the input and out-put sequences. Extensive experiments are conducted on three benchmarks (i.e. Human3.6M, MPI-INF-3DHP, andHumanEva). The results show that our model outperforms the state-of-the-art approach by 10.9% P-MPJPE and 7.6%MPJPE. The code is available at https://github. com/JinluZhang1126/MixSTE. 