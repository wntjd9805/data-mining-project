Certiﬁed patch defenses can guarantee robustness of an image classiﬁer to arbitrary changes within a bounded con-tiguous region. But, currently, this robustness comes at a cost of degraded standard accuracies and slower inference times. We demonstrate how using vision transformers en-ables signiﬁcantly better certiﬁed patch robustness that is also more computationally efﬁcient and does not incur a substantial drop in standard accuracy. These improvements stem from the inherent ability of the vision transformer to gracefully handle largely masked images.1 