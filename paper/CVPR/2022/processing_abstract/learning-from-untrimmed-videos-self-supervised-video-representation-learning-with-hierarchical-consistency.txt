Natural videos provide rich visual contents for self-Yet most existing approaches for supervised learning. learning spatio-temporal representations rely on manually trimmed videos, leading to limited diversity in visual pat-terns and limited performance gain. In this work, we aim to learn representations by leveraging more abundant in-formation in untrimmed videos. To this end, we propose to learn a hierarchy of consistencies in videos, i.e., visual consistency and topical consistency, corresponding respec-tively to clip pairs that tend to be visually similar when separated by a short time span and share similar topics when separated by a long time span. Specifically, a hi-erarchical consistency learning framework HiCo is pre-sented, where the visually consistent pairs are encouraged to have the same representation through contrastive learn-ing, while the topically consistent pairs are coupled through a topical classifier that distinguishes whether they are topic-related. Further, we impose a gradual sampling algorithm for proposed hierarchical consistency learning, and demon-strate its theoretical superiority. Empirically, we show that not only HiCo can generate stronger representations on untrimmed videos, it also improves the representation qual-ity when applied to trimmed videos. This is in contrast to standard contrastive learning that fails to learn appropri-ate representations from untrimmed videos. 