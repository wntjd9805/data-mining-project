Efficient photorealistic scene capture is a challenging task. Current online reconstruction systems can operate very efficiently, but images generated from the models cap-tured by these systems are often not photorealistic. Recent approaches based on neural volume rendering can render novel views at high fidelity, but they often require a long time to train, making them impractical for applications that require real-time scene capture. In this paper, we propose a system that can reconstruct photorealistic models of com-plex scenes in an efficient manner. Our system processes images online, i.e. it can obtain a good quality estimate of both the scene geometry and appearance at roughly the same rate the video is captured. To achieve the efficiency, we propose a hierarchical feature volume using VDB grids.This representation is memory efficient and allows for fast querying of the scene information. Secondly, we introduce a novel optimization technique that improves the efficiency of the bundle adjustment which allows our system to converge to the target camera poses and scene geometry much faster.Experiments on real-world scenes show that our method outperforms existing systems in terms of efficiency and cap-ture quality. To the best of our knowledge, this is the first method that can achieve online photorealistic scene cap-ture.Figure 1. Our method in operation. We present an approach for online scene capture from a stream of monocular RGB im-ages. The scene is represented using a neural volumetric dynamicB+Tree (nVDB) which stores a hierarchy of spatial features. The dynamic topology of the tree allows it to grow as the camera ex-plores the scene. The camera and the volume parameters are opti-mized online using a novel volumetric bundle adjustment method (VBA). This allows our method to efficiently capture scene ap-pearance and geometry. See the supplementary video for an online demo. 