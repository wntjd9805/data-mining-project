One major challenge for semantic segmentation in real-world scenarios is only limited pixel-level labels available due to high expense of human labor though a vast volume of video data is provided. Existing semi-supervised meth-ods attempt to exploit unlabeled data in model training, but they just regard video as a set of independent images. To better explore semi-supervised segmentation problem with video data, we formulate a semi-supervised video semantic segmentation task in this paper. For this task, we observe that the overﬁtting is surprisingly severe between labeled and unlabeled frames within a training video although they are very similar in style and contents. This is called inner-video overﬁtting, and it would actually lead to inferior per-formance. To tackle this issue, we propose a novel inter-frame feature reconstruction (IFR) technique to leverage the ground-truth labels to supervise the model training onIFR is essentially to utilize the inter-unlabeled frames. nal relevance of different frames within a video. During training, IFR would enforce the feature distributions be-tween labeled and unlabeled frames to be narrowed. Con-sequently, the inner-video overﬁtting issue can be effectively alleviated. We conduct extensive experiments on Cityscapes and CamVid, and the results demonstrate the superiority of our proposed method to previous state-of-the-art meth-ods. The code is available at https://github.com/ jfzhuang/IFR. 