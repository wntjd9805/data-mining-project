Few-shot learning (FSL) aims to learn new categories with a few visual samples per class. Few-shot class repre-sentations are often biased due to data scarcity. To mit-igate this issue, we propose to generate visual samples based on semantic embeddings using a conditional vari-ational autoencoder (CVAE) model. We train this CVAE model on base classes and use it to generate features for novel classes. More importantly, we guide this VAE to strictly generate representative samples by removing non-representative samples from the base training set when training the CVAE model. We show that this training scheme enhances the representativeness of the generated samples and therefore, improves the few-shot classifica-tion results. Experimental results show that our method improves three FSL baseline methods by substantial mar-gins, achieving state-of-the-art few-shot classification per-formance on miniImageNet and tieredImageNet datasets for both 1-shot and 5-shot settings. Code is available at: https://github.com/cvlab-stonybrook/ fsl-rsvae. 