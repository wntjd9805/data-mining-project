Previous advances in object tracking mostly reported on favorable illumination circumstances while neglecting per-formance at nighttime, which signiﬁcantly impeded the de-velopment of related aerial robot applications. This work instead develops a novel unsupervised domain adaptation framework for nighttime aerial tracking (named UDAT).Speciﬁcally, a unique object discovery approach is provided to generate training patches from raw nighttime tracking videos. To tackle the domain discrepancy, we employ aTransformer-based bridging layer post to the feature ex-tractor to align image features from both domains. With the day-a Transformer day/night feature discriminator, time tracking model is adversarially trained to track at night. Moreover, we construct a pioneering benchmark namely NAT2021 for unsupervised domain adaptive night-time tracking, which comprises a test set of 180 manually annotated tracking sequences and a train set of over 276k unlabelled nighttime tracking frames. Exhaustive experi-ments demonstrate the robustness and domain adaptabil-ity of the proposed framework in nighttime aerial track-ing. The code and benchmark are available at https://github.com/vision4robotics/UDAT. 