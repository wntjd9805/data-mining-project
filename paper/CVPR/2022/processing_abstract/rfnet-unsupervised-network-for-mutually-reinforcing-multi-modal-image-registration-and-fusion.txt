In this paper, we propose a novel method to realize multi-modal image registration and fusion in a mutually reinforcing framework, termed as RFNet. We handle the registration in a coarse-to-ﬁne fashion. For the ﬁrst time, we exploit the feedback of image fusion to promote the registration accuracy rather than treating them as two separate issues. The ﬁne-registered results also improve the fusion performance. Speciﬁcally, for image registration, we solve the bottlenecks of deﬁning registration metrics applicable for multi-modal images and facilitating the network convergence. The metrics are deﬁned based on image translation and image fusion respectively in the coarse and ﬁne stages. The convergence is facilitated by the designed metrics and a deformable convolution-based network. For image fusion, we focus on texture preser-vation, which not only increases the information amount and quality of fusion results but also improves the feedback of fusion results. The proposed method is evaluated on multi-modal images with large global parallaxes, images with local misalignments and aligned images to validate the performances of registration and fusion. The results in these cases demonstrate the effectiveness of our method. 