In this paper, we address the task of semantics-guided image outpainting, which is to complete an image by gen-erating semantically practical content. Different from most existing image outpainting works, we approach the above task by understanding and completing image semantics atIn particular, we propose a novel the scene graph level. network of Scene Graph Transformer (SGT), which is de-signed to take node and edge features as inputs for model-ing the associated structural information. To better under-stand and process graph-based inputs, our SGT uniquely performs feature attention at both node and edge levels.While the former views edges as relationship regularization, the latter observes the co-occurrence of nodes for guiding the attention process. We demonstrate that, given a partial input image with its layout and scene graph, our SGT can be applied for scene graph expansion and its conversion to a complete layout. Following state-of-the-art layout-to-image conversions works, the task of image outpainting can be completed with sufficient and practical semantics intro-duced. Extensive experiments are conducted on the datasets of MS-COCO and Visual Genome, which quantitatively and qualitatively confirm the effectiveness of our proposed SGT and outpainting frameworks. 