Free-form inpainting is the task of adding new content to an image in the regions specified by an arbitrary bi-nary mask. Most existing approaches train for a certain distribution of masks, which limits their generalization ca-pabilities to unseen mask types. Furthermore, training with pixel-wise and perceptual losses often leads to simple tex-tural extensions towards the missing areas instead of se-mantically meaningful generation.In this work, we pro-pose RePaint: A Denoising Diffusion Probabilistic Model (DDPM) based inpainting approach that is applicable to even extreme masks. We employ a pretrained unconditionalDDPM as the generative prior. To condition the genera-tion process, we only alter the reverse diffusion iterations by sampling the unmasked regions using the given image infor-mation. Since this technique does not modify or condition the original DDPM network itself, the model produces high-quality and diverse output images for any inpainting form.We validate our method for both faces and general-purpose image inpainting using standard and extreme masks. Re-Paint outperforms state-of-the-art Autoregressive, and GAN approaches for at least five out of six mask distributions.Github Repository: git.io/RePaint 