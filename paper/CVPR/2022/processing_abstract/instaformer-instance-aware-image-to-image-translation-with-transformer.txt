We present a novel Transformer-based network architec-ture for instance-aware image-to-image translation, dubbedInstaFormer, to effectively integrate global- and instance-level information. By considering extracted content fea-tures from an image as tokens, our networks discover global consensus of content features by considering context infor-mation through a self-attention module in Transformers.By augmenting such tokens with an instance-level feature extracted from the content feature with respect to bound-ing box information, our framework is capable of learn-ing an interaction between object instances and the global image, thus boosting the instance-awareness. We replace layer normalization (LayerNorm) in standard Transformers with adaptive instance normalization (AdaIN) to enable a multi-modal translation with style codes.In addition, to improve the instance-awareness and translation quality at object regions, we present an instance-level content con-trastive loss defined between input and translated image.We conduct experiments to demonstrate the effectiveness of our InstaFormer over the latest methods and provide exten-sive ablation studies. 