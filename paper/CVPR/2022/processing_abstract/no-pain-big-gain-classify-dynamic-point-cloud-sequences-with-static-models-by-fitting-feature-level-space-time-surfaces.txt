Scene ﬂow is a powerful tool for capturing the motionﬁeld of 3D point clouds. However, it is difﬁcult to directly apply ﬂow-based models to dynamic point cloud classiﬁ-cation since the unstructured points make it hard or even impossible to efﬁciently and effectively trace point-wise correspondences. To capture 3D motions without explic-itly tracking correspondences, we propose a kinematics-inspired neural network (Kinet) by generalizing the kine-matic concept of ST-surfaces to the feature space. By unrolling the normal solver of ST-surfaces in the fea-ture space, Kinet implicitly encodes feature-level dynam-ics and gains advantages from the use of mature back-bones for static point cloud processing. With only minor changes in network structures and low computing over-head, it is painless to jointly train and deploy our frame-work with a given static model. Experiments on NvGes-ture, SHREC’17, MSRAction-3D, and NTU-RGBD demon-strate its efﬁcacy in performance, efﬁciency in both the num-ber of parameters and computational complexity, as well as its versatility to various static backbones. Noticeably,Kinet achieves the accuracy of 93.27% on MSRAction-3D with only 3.20M parameters and 10.35G FLOPS. The code is available at https://github.com/jx-zhong-for-academic-purpose/Kinet. 