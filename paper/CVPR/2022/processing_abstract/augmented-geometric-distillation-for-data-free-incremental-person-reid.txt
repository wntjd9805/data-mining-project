Incremental learning (IL) remains an open issue for Per-son Re-identification (ReID), where a ReID system is ex-pected to preserve preceding knowledge while learning in-crementally. However, due to the strict privacy licenses and the open-set retrieval setting, it is intractable to adapt ex-isting class IL methods to ReID. In this work, we propose an Augmented Geometric Distillation (AGD) framework to tackle these issues. First, a general data-free incremental framework with dreaming memory is constructed to avoid privacy disclosure. On this basis, we reveal a “noisy distil-lation” problem stemming from the noise in dreaming mem-ory, and further propose to augment distillation in a pair-wise and cross-wise pattern over different views of mem-ory to mitigate it. Second, for the open-set retrieval prop-erty, we propose to maintain feature space structure during evolving via a novel geometric way and preserve relation-ships between exemplars when representations drift. Exten-sive experiments demonstrate the superiority of our AGD to baseline with a margin of 6.0% mAP / 7.9% R@1 and it could be generalized to class IL. Code is available here†. 