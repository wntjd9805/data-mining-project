The industry practice for night video surveillance is to use auxiliary near-infrared (NIR) LEDs, usually centered at 850nm or 940nm, for scene illumination. NIR LEDs are used to save power consumption while hiding the surveil-lance coverage area from naked human eyes. The captured images are almost monochromatic, and visual color and texture tend to disappear, which hinders human and ma-chine perception. A few existing studies have tried to con-vert such NIR images to RGB images through deep learn-ing, which can not provide satisfying results, nor generalize well beyond the training dataset. In this paper, we aim to break the fundamental restrictions on reliable NIR-to-RGB (NIR2RGB) translation by examining the imaging mecha-nism of single-chip silicon-based RGB cameras under NIR illuminations, and propose to retrieve the optimal LED mul-tiplexing via deep learning. Experimental results show that this translation task can be significantly improved by prop-erly multiplexing NIR LEDs close to the visible spectral range than using 850nm and 940nm LEDs. 