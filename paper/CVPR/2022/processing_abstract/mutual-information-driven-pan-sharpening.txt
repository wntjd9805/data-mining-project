Pan-sharpening aims to integrate the complementary in-formation of texture-rich PAN images and multi-spectral (MS) images to produce the texture-rich MS images. De-spite the remarkable progress, existing state-of-the-art Pan-sharpening methods donâ€™t explicitly enforce the comple-mentary information learning between two modalities ofPAN and MS images. This leads to information redun-dancy not being handled well, which further limits the per-formance of these methods. To address the above issue, we propose a novel mutual information-driven Pan-sharpening framework in this paper. To be specific, we first project thePAN and MS image into modality-aware feature space in-dependently, and then impose the mutual information min-imization over them to explicitly encourage the comple-mentary information learning. Such operation is capable of reducing the information redundancy and improving the model performance. Extensive experimental results over multiple satellite datasets demonstrate that the proposed al-gorithm outperforms other state-of-the-art methods qualita-tively and quantitatively with great generalization ability to real-world scenes. 