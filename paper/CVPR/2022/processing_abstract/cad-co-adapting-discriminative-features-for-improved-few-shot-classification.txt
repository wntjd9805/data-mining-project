Few-shot classification is a challenging problem that aims to learn a model that can adapt to unseen classes given a few labeled samples. Recent approaches pre-train a feature extractor, and then fine-tune for episodic meta-learning. Other methods leverage spatial features to learn pixel-level correspondence while jointly training a classi-fier. However, results using such approaches show marginal improvements.In this paper, inspired by the transformer style self-attention mechanism, we propose a strategy to cross-attend and re-weight discriminative features for few-shot classification. Given a base representation of support and query images after global pooling, we introduce a sin-gle shared module that projects features and cross-attends in two aspects: (i) query to support, and (ii) support to query. The module computes attention scores between fea-tures to produce an attention pooled representation of fea-tures in the same class that is later added to the original representation followed by a projection head. This effec-tively re-weights features in both aspects (i & ii) to produce features that better facilitate improved metric-based meta-learning. Extensive experiments on public benchmarks show our approach outperforms state-of-the-art methods by 3%âˆ¼5%. 