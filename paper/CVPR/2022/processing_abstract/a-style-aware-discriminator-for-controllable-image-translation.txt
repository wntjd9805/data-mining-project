Current image-to-image translations do not control the output domain beyond the classes used during training, nor do they interpolate between different domains well, lead-ing to implausible results. This limitation largely arises be-cause labels do not consider the semantic distance. To miti-gate such problems, we propose a style-aware discriminator that acts as a critic as well as a style encoder to provide conditions. The style-aware discriminator learns a con-trollable style space using prototype-based self-supervised learning and simultaneously guides the generator. Experi-ments on multiple datasets verify that the proposed model outperforms current state-of-the-art image-to-image trans-lation methods. In contrast with current methods, the pro-posed approach supports various applications, including style interpolation, content transplantation, and local im-age translation. The code is available at github.com/ kunheek/style-aware-discriminator. 