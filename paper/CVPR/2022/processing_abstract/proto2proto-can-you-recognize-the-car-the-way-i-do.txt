Prototypical methods have recently gained a lot of at-tention due to their intrinsic interpretable nature, which is obtained through the prototypes. With growing use cases of model reuse and distillation, there is a need to also study transfer of interpretability from one model to an-other. We present Proto2Proto, a novel method to trans-fer interpretability of one prototypical part network to an-other via knowledge distillation. Our approach aims to add interpretability to the “dark” knowledge transferred from the teacher to the shallower student model. We propose two novel losses: “Global Explanation” loss and “Patch-Prototype Correspondence” loss to facilitate such a trans-fer. Global Explanation loss forces the student prototypes to be close to teacher prototypes, and Patch-Prototype Cor-respondence loss enforces the local representations of the student to be similar to that of the teacher. Further, we pro-pose three novel metrics to evaluate the student’s proxim-ity to the teacher as measures of interpretability transfer in our settings. We qualitatively and quantitatively demon-strate the effectiveness of our method on CUB-200-2011 and Stanford Cars datasets. Our experiments show that the proposed method indeed achieves interpretability trans-fer from teacher to student while simultaneously exhibiting competitive performance. The code is available at https://github.com/archmaester/proto2proto 