Determining the motion behavior of inexhaustible cate-gories of traffic participants is critical for autonomous driv-ing.In recent years, there has been a rising concern in performing class-agnostic motion prediction directly from the captured sensor data, like LiDAR point clouds or the combination of point clouds and images. Current motion prediction frameworks tend to perform joint semantic seg-mentation and motion prediction and face the trade-off be-In this pa-tween the performance of these two tasks. per, we propose a novel Spatial-Temporal Integrated net-work with Bidirectional Enhancement, BE-STI, to improve the temporal motion prediction performance by spatial se-mantic features, which points out an efficient way to com-bine semantic segmentation and motion prediction. Specif-ically, we propose to enhance the spatial features of each individual point cloud with the similarity among tempo-ral neighboring frames and enhance the global temporal features with the spatial difference among non-adjacent frames in a coarse-to-fine fashion. Extensive experiments on nuScenes and Waymo Open Dataset show that our pro-posed framework outperforms all state-of-the-art LiDAR-based and RGB+LiDAR-based methods with remarkable margins by using only point clouds as input.1 