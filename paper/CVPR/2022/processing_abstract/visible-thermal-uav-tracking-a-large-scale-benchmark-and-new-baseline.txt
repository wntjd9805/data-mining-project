With the popularity of multi-modal sensors, visible-thermal (RGB-T) object tracking is to achieve robust perfor-mance and wider application scenarios with the guidance of objects’ temperature information. However, the lack of paired training samples is the main bottleneck for unlock-ing the power of RGB-T tracking. Since it is laborious to collect high-quality RGB-T sequences, recent benchmarks only provide test sequences.In this paper, we construct a large-scale benchmark with high diversity for visible-thermal UAV tracking (VTUAV), including 500 sequences with 1.7 million high-resolution (1920 ∗ 1080 pixels) frame pairs. In addition, comprehensive applications (short-term tracking, long-term tracking and segmentation mask predic-tion) with diverse categories and scenes are considered for exhaustive evaluation. Moreover, we provide a coarse-to-fine attribute annotation, where frame-level attributes are provided to exploit the potential of challenge-specific track-ers. In addition, we design a new RGB-T baseline, namedHierarchical Multi-modal Fusion Tracker (HMFT), which fuses RGB-T data in various levels. Numerous experiments on several datasets are conducted to reveal the effectiveness of HMFT and the complement of different fusion types. The project is available at here.Figure 1. Sample frames in our dataset. Scenes - super class (se-quence length) are shown on the top. Sequence-level attributes are shown at bottom, including camera movement (C), deforma-tion (D), extreme illumination (E), partial occlusion (P), full oc-clusion (F), scale variation (S), thermal clustering (H), fast mov-ing (M), out-of-view (O), and low resolution (L). 