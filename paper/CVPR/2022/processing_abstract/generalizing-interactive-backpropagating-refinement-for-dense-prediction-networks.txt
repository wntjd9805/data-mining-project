As deep neural networks become the state-of-the-art ap-proach in the field of computer vision for dense prediction tasks, many methods have been developed for automatic es-timation of the target outputs given the visual inputs. Al-though the estimation accuracy of the proposed automatic methods continues to improve, interactive refinement is of-tentimes necessary for further correction. Recently, fea-ture backpropagating refinement scheme [25] (f-BRS) has been proposed for the task of interactive segmentation, which enables efficient optimization of a small set of aux-iliary variables inserted into the pretrained network to pro-duce object segmentation that better aligns with user in-puts. However, the proposed auxiliary variables only con-tain channel-wise scale and bias, limiting the optimization to global refinement only. In this work, in order to general-ize backpropagating refinement for a wide range of dense prediction tasks, we introduce a set of G-BRS (General-ized Backpropagating Refinement Scheme) layers that en-able both global and localized refinement for the following tasks: interactive segmentation, semantic segmentation, im-age matting and monocular depth estimation. Experiments on SBD, Cityscapes, Mapillary Vista, Composition-1k andNYU-Depth-V2 show that our method can successfully gen-eralize and significantly improve performance of existing pretrained state-of-the-art models with only a few clicks. 