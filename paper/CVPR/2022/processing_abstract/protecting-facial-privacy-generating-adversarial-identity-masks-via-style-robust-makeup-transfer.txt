While deep face recognition (FR) systems have shown amazing performance in identification and verification, they also arouse privacy concerns for their excessive surveil-lance on users, especially for public face images widely spread on social networks. Recently, some studies adopt adversarial examples to protect photos from being identified by unauthorized face recognition systems. However, exist-ing methods of generating adversarial face images suffer from many limitations, such as awkward visual, white-box setting, weak transferability, making them difficult to be ap-plied to protect face privacy in reality.In this paper, we propose adversarial makeup transferGAN (AMT-GAN)1, a novel face protection method aim-ing at constructing adversarial face images that preserve stronger black-box transferability and better visual quality simultaneously. AMT-GAN leverages generative adversar-ial networks (GAN) to synthesize adversarial face images with makeup transferred from reference images. In particu-lar, we introduce a new regularization module along with a joint training strategy to reconcile the conflicts between the adversarial noises and the cycle consistence loss in makeup transfer, achieving a desirable balance between the attack strength and visual changes. Extensive experiments verify that compared with state of the arts, AMT-GAN can not only preserve a comfortable visual quality, but also achieve a higher attack success rate over commercial FR APIs, in-1https://github.com/CGCL-codes/AMT-GANFigure 1. Comparison with existing adversarial attacks on FR sys-tems in the black-box setting. The images in (a) are directly ex-tracted from their papers. The numbers listed below images are the verification confidence of the target identity given by commercialFR APIs, and a higher score represent a stronger attack ability. The blue is from Face++, the green is from Aliyun, and the red is fromMicrosoft Azure (The same color code will be used hereinafter). cluding Face++, Aliyun, and Microsoft. 