Motion style transfer is a common method for enriching character animation. Motion style transfer algorithms are often designed for offline settings where motions are pro-cessed in segments. However, for online animation applica-tions, such as real-time avatar animation from motion cap-ture, motions need to be processed as a stream with mini-mal latency. In this work, we realize a flexible, high-quality motion style transfer method for this setting. We propose a novel style transfer model, Style-ERD, to stylize motions in an online manner with an Encoder-Recurrent-Decoder structure, along with a novel discriminator that combines feature attention and temporal attention. Our method styl-izes motions into multiple target styles with a unified model.Although our method targets online settings, it outperforms previous offline methods in motion realism and style expres-siveness and provides significant gains in runtime efficiency. 