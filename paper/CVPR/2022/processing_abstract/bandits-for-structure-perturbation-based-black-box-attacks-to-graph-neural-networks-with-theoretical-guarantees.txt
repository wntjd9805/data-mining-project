Graph neural networks (GNNs) have achieved state-of-the-art performance in many graph-based tasks such as node classification and graph classification. However, many re-cent works have demonstrated that an attacker can misleadGNN models by slightly perturbing the graph structure. Ex-isting attacks to GNNs are either under the less practical threat model where the attacker is assumed to access theGNN model parameters, or under the practical black-box threat model but consider perturbing node features that are shown to be not enough effective. In this paper, we aim to bridge this gap and consider black-box attacks to GNNs with structure perturbation as well as with theoretical guaran-tees. We propose to address this challenge through bandit techniques. Specifically, we formulate our attack as an on-line optimization with bandit feedback. This original prob-lem is essentially NP-hard due to the fact that perturbing the graph structure is a binary optimization problem. We then propose an online attack based on bandit optimization which is proven to be sublinear to the query number T , i.e.,N T 3/4) where N is the number of nodes in the graph.O(Finally, we evaluate our proposed attack by conducting ex-periments over multiple datasets and GNN models. The experimental results on various citation graphs and image graphs show that our attack is both effective and efficient.âˆš 