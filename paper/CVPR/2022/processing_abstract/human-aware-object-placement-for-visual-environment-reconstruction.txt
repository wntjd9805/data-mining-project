Humans are in constant contact with the world as they move through it and interact with it. This contact is a vi-tal source of information for understanding 3D humans, 3D scenes, and the interactions between them. In fact, we demonstrate that these human-scene interactions (HSIs) can be leveraged to improve the 3D reconstruction of a scene from a monocular RGB video. Our key idea is that, as a person moves through a scene and interacts with it, we ac-cumulate HSIs across multiple input images, and use these in optimizing the 3D scene to reconstruct a consistent, phys-ically plausible, 3D scene layout. Our optimization-based approach exploits three types of HSI constraints: (1) hu-mans who move in a scene are occluded by, or occlude, objects, thus constraining the depth ordering of the objects, (2) humans move through free space and do not interpene-trate objects, (3) when humans and objects are in contact, the contact surfaces occupy the same place in space. Us-ing these constraints in an optimization formulation across all observations, we signiﬁcantly improve 3D scene layout reconstruction. Furthermore, we show that our scene re-construction can be used to reﬁne the initial 3D human pose and shape (HPS) estimation. We evaluate the 3D scene layout reconstruction and HPS estimates qualitatively and quantitatively using the PROX and PiGraphs datasets.The code and data are available for research purposes at https://mover.is.tue.mpg.de. 