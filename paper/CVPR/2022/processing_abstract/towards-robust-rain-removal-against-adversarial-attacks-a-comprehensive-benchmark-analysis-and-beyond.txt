Rain removal aims to remove rain streaks from im-ages/videos and reduce the disruptive effects caused by rain. It not only enhances image/video visibility but also allows many computer vision algorithms to function prop-erly. This paper makes the first attempt to conduct a com-prehensive study on the robustness of deep learning-based rain removal methods against adversarial attacks. Our study shows that, when the image/video is highly degraded, rain removal methods are more vulnerable to the adversar-ial attacks as small distortions/perturbations become less noticeable or detectable. In this paper, we first present a comprehensive empirical evaluation of various methods at different levels of attacks and with various losses/targets to generate the perturbations from the perspective of hu-man perception and machine analysis tasks. A system-atic evaluation of key modules in existing methods is per-formed in terms of their robustness against adversarial at-tacks. From the insights of our analysis, we construct a more robust deraining method by integrating these effec-tive modules. Finally, we examine various types of adver-sarial attacks that are specific to deraining problems and their effects on both human and machine vision tasks, in-cluding 1) rain region attacks, adding perturbations only in the rain regions to make the perturbations in the at-tacked rain images less visible; 2) object-sensitive attacks, adding perturbations only in regions near the given objects.Code is available at https://github.com/yuyi-sd/Robust_Rain_Removal. 