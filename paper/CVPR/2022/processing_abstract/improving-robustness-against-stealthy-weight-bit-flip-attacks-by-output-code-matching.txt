Deep neural networks (DNNs) have been shown to be vulnerable against adversarial weight bit-ﬂip attacks through hardware-induced fault-injection methods on the memory systems where network parameters are stored. Re-cent attacks pose the further concerning threat of ﬁnding minimal targeted and stealthy weight bit-ﬂips that preserve expected behavior for untargeted test samples. This renders the attack undetectable from a DNN operation perspective.We propose a DNN defense mechanism to improve robust-ness in such realistic stealthy weight bit-ﬂip attack scenar-ios. Our output code matching networks use an output cod-ing scheme where the usual one-hot encoding of classes is replaced by partially overlapping bit strings. We show that this encoding signiﬁcantly reduces attack stealthiness. Im-portantly, our approach is compatible with existing defenses and DNN architectures. It can be efﬁciently implemented on pre-trained models by simply re-deﬁning the output classiﬁ-cation layer and ﬁnetuning. Experimental benchmark eval-uations show that output code matching is superior to exist-ing regularized weight quantization based defenses, and an effective defense against stealthy weight bit-ﬂip attacks. 