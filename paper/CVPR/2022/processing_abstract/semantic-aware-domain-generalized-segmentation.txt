Deep models trained on source domain lack generaliza-tion when evaluated on unseen target domains with different data distributions. The problem becomes even more pro-nounced when we have no access to target domain samplesIn this paper, we address domain gener-for adaptation. alized semantic segmentation, where a segmentation model is trained to be domain-invariant without using any target domain data. Existing approaches to tackle this problem standardize data into a unified distribution. We argue that while such a standardization promotes global normaliza-tion, the resulting features are not discriminative enough to get clear segmentation boundaries. To enhance sepa-ration between categories while simultaneously promoting domain invariance, we propose a framework including twoâˆ—Corresponding Author: Yinjie Lei (yinjie@scu.edu.cn) novel modules: Semantic-Aware Normalization (SAN) andSemantic-Aware Whitening (SAW). Specifically, SAN fo-cuses on category-level center alignment between features from different image styles, while SAW enforces distributed alignment for the already center-aligned features. With the help of SAN and SAW, we encourage both intra-category compactness and inter-category separability. We validate our approach through extensive experiments on widely-used datasets (i.e. GTAV, SYNTHIA, Cityscapes, Mapillary andBDDS). Our approach shows significant improvements over existing state-of-the-art on various backbone networks.Code is available at https://github.com/leolyj/SAN-SAW 