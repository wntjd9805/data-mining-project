Imposing consistency through proxy tasks has been shown to enhance data-driven learning and enable self-supervision in various tasks. This paper introduces novel and effective consistency strategies for optical ﬂow esti-mation, a problem where labels from real-world data are very challenging to derive. More speciﬁcally, we propose occlusion consistency and zero forcing in the forms of self-supervised learning and transformation consistency in the form of semi-supervised learning. We apply these consis-tency techniques in a way that the network model learns to describe pixel-level motions better while requiring no ad-ditional annotations. We demonstrate that our consistency strategies applied to a strong baseline network model using the original datasets and labels provide further improve-ments, attaining the state-of-the-art results on the KITTI-2015 scene ﬂow benchmark in the non-stereo category. Our method achieves the best foreground accuracy (4.33% inFl-all) over both the stereo and non-stereo categories, even though using only monocular image inputs. 