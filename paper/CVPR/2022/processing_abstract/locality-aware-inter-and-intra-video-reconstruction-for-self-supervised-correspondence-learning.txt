Our target is to learn visual correspondence from unla-beled videos. We develop LIIR, a locality-aware inter-and intra-video reconstruction method that ﬁlls in three miss-ing pieces, i.e., instance discrimination, location awareness, and spatial compactness, of self-supervised correspondence learning puzzle. First, instead of most existing efforts focu-sing on intra-video self-supervision only, we exploit cross-video afﬁnities as extra negative samples within a uniﬁed, inter-and intra-video reconstruction scheme.This enables in-stance discriminative representation learning by contrasting desired intra-video pixel association against negative inter-video correspondence. Second, we merge position informa-tion into correspondence matching, and design a position shifting strategy to remove the side-effect of position encod-ing during inter-video afﬁnity computation, making our LIIR location-sensitive. Third, to make full use of the spatial conti-nuity nature of video data, we impose a compactness-based constraint on correspondence matching, yielding more spar-se and reliable solutions. The learned representation sur-passes self-supervised state-of-the-arts on label propaga-tion tasks including objects, semantic parts, and keypoints. 