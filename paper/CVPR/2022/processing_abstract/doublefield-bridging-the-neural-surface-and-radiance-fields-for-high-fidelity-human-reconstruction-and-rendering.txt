We introduce DoubleField, a novel framework combin-ing the merits of both surface ﬁeld and radiance ﬁeld for high-ﬁdelity human reconstruction and rendering. WithinDoubleField, the surface ﬁeld and radiance ﬁeld are as-sociated together by a shared feature embedding and a surface-guided sampling strategy. Moreover, a view-to-view transformer is introduced to fuse multi-view features and learn view-dependent features directly from high-resolution inputs. With the modeling power of DoubleField and the view-to-view transformer, our method signiﬁcantly im-proves the reconstruction quality of both geometry and ap-pearance, while supporting direct inference, scene-speciﬁc high-resolution ﬁnetuning, and fast rendering. The efﬁcacy of DoubleField is validated by the quantitative evaluations on several datasets and the qualitative results in a real-world sparse multi-view system, showing its superior ca-pability for high-quality human model reconstruction and photo-realistic free-viewpoint human rendering. Data and source code will be made public for the research purpose. 