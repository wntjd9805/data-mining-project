We propose Styleformer, a generator that synthesizes im-age using style vectors based on the Transformer structure.In this paper, we effectively apply the modified Transformer structure (e.g., Increased multi-head attention and Pre-layer normalization) and introduce novel Attention StyleInjection module which is style modulation and demodu-lation method for self-attention operation. The new gen-erator components have strengths in CNNâ€™s shortcomings, handling long-range dependency and understanding global structure of objects. We present two methods to generate high-resolution images using Styleformer. First, we applyLinformer in the field of visual synthesis (Styleformer-L), enabling Styleformer to generate higher resolution images and result in improvements in terms of computation cost and performance. This is the first case using Linformer to im-age generation. Second, we combine Styleformer and Style-GAN2 (Styleformer-C) to generate high-resolution compo-sitional scene efficiently, which Styleformer captures long-range dependencies between components. With these adap-tations, Styleformer achieves comparable performances to state-of-the-art in both single and multi-object datasets.Furthermore, groundbreaking results from style mixing and attention map visualization demonstrate the advantages and efficiency of our model. 