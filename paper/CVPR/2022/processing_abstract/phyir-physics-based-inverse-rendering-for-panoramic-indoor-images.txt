Inverse rendering of complex material such as glossy, metal and mirror material is a long-standing ill-posed prob-lem in this area, which has not been well solved. Pre-vious approaches cannot tackle them well due to simpli-fied BRDF and unsuitable illumination representations. In this paper, we present PhyIR, a neural inverse render-ing method with a more completed SVBRDF representa-tion and a physics-based in-network rendering layer, which can handle complex material and incorporate physical con-straints by re-rendering realistic and detailed specular re-flectance. Our framework estimates geometry, material andSpatially-Coherent (SC) illumination from a single indoor panorama. Due to the lack of panoramic datasets with com-pleted SVBRDF and full-spherical light probes, we intro-duce an artist-designed dataset named FutureHouse with high-quality geometry, SVBRDF and per-pixel Spatially-Varying (SV) lighting. To ensure the coherence of SV light-ing, a novel SC loss is proposed. Extensive experiments on both synthetic and real-world data show that the proposed method outperforms the state-of-the-arts quantitatively and qualitatively, and is able to produce photorealistic results for a number of applications such as dynamic virtual object insertion. 