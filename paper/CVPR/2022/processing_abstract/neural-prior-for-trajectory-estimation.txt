Neural priors are a promising direction to capture low-level vision statistics without relying on handcrafted regu-larizers. Recent works have successfully shown the use of neural architecture biases to implicitly regularize image de-noising, super-resolution, inpainting, synthesis, scene ﬂow, among others. They do not rely on large-scale datasets to capture prior statistics and thus generalize well to out-of-Inspired by such advances, we in-the-distribution data. vestigate neural priors for trajectory representation. Tra-ditionally, trajectories have been represented by a set of handcrafted bases that have limited expressibility. Here, we propose a neural trajectory prior to capture continu-ous spatio-temporal information without the need for ofﬂine data. We demonstrate how our proposed objective is opti-mized during runtime to estimate trajectories for two impor-tant tasks: Non-Rigid Structure from Motion (NRSfM) and lidar scene ﬂow integration for self-driving scenes. Our re-sults are competitive to many state-of-the-art methods for both tasks. 