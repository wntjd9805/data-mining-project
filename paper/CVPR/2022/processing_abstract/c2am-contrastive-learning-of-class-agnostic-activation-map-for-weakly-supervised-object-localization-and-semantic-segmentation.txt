While class activation map (CAM) generated by image classiﬁcation network has been widely used for weakly su-pervised object localization (WSOL) and semantic segmen-tation (WSSS), such classiﬁers usually focus on discrimina-tive object regions. In this paper, we propose Contrastive learning for Class-agnostic Activation Map (C2AM) gen-eration only using unlabeled image data, without the in-volvement of image-level supervision. The core idea comes from the observation that i) semantic information of fore-ground objects usually differs from their backgrounds; ii) foreground objects with similar appearance or background with similar color/texture have similar representations in the feature space. We form the positive and negative pairs based on the above relations and force the network to dis-entangle foreground and background with a class-agnostic activation map using a novel contrastive loss. As the net-work is guided to discriminate cross-image foreground-background, the class-agnostic activation maps learned by our approach generate more complete object regions.We successfully extracted from C2AM class-agnostic object bounding boxes for object localization and background cues to reﬁne CAM generated by classiﬁcation network for se-mantic segmentation. Extensive experiments on CUB-200-2011, ImageNet-1K, and PASCAL VOC2012 datasets show that both WSOL and WSSS can beneﬁt from the proposedC2AM. Code will be available at https://github.com/CVI-SZU/CCAM. 