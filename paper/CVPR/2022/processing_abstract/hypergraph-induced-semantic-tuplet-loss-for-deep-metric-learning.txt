In this paper, we propose Hypergraph-Induced Seman-tic Tuplet (HIST) loss for deep metric learning that lever-ages the multilateral semantic relations of multiple samples to multiple classes via hypergraph modeling. We formulate deep metric learning as a hypergraph node classification problem in which each sample in a mini-batch is regarded as a node and each hyperedge models class-specific seman-tic relations represented by a semantic tuplet. Unlike pre-vious graph-based losses that only use a bundle of pair-wise relations, our HIST loss takes advantage of the mul-tilateral semantic relations provided by the semantic tuplets through hypergraph modeling. Notably, by leveraging the rich multilateral semantic relations, HIST loss guides the embedding model to learn class-discriminative visual se-mantics, contributing to better generalization performance and model robustness against input corruptions. Extensive experiments and ablations provide a strong motivation for the proposed method and show that our HIST loss leads to improved feature learning, achieving state-of-the-art re-sults on three widely used benchmarks. Code is available at https://github.com/ljin0429/HIST.Figure 1. Our HIST loss utilizes multilateral semantic relations between every sample and class (marked by color) for a given mini-batch. A semantic tuplet is defined for a class (e.g., green) and represents the sample’s semantic relations to the class. Inside the semantic tuplet, positive samples have definite relation values (= 1), and negative samples have soft relation values (≤ 1) based on their likelihood of belonging to the class. Each semantic tuplet is then modeled as a hyperedge. In this hypergraph, we formulate a node classification objective. By leveraging multilateral seman-tic relations, HIST loss enables the embedding network to capture important visual semantics suitable for deep metric learning. 