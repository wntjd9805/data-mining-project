As clean ImageNet accuracy nears its ceiling, the re-search community is increasingly more concerned about ro-bust accuracy under distributional shifts. While a variety of methods have been proposed to robustify neural networks, these techniques often target models trained on ImageNet classiﬁcation. At the same time, it is a common practice to use ImageNet pretrained backbones for downstream tasks such as object detection, semantic segmentation, and image classiﬁcation from different domains. This raises a ques-tion: Can these robust image classiﬁers transfer robustness to downstream tasks? For object detection and semantic segmentation, we ﬁnd that a vanilla Swin Transformer, a variant of Vision Transformer tailored for dense prediction tasks, transfers robustness better than Convolutional Neu-ral Networks that are trained to be robust to the corrupted version of ImageNet. For CIFAR10 classiﬁcation, we ﬁnd that models that are robustiﬁed for ImageNet do not re-tain robustness when fully ﬁne-tuned. These ﬁndings sug-gest that current robustiﬁcation techniques tend to empha-size ImageNet evaluations. Moreover, network architecture is a strong source of robustness when we consider transfer learning. 