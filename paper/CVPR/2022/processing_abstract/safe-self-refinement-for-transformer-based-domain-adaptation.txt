Unsupervised Domain Adaptation (UDA) aims to lever-age a label-rich source domain to solve tasks on a related unlabeled target domain. It is a challenging problem espe-cially when a large domain gap lies between the source and target domains. In this paper we propose a novel solution named SSRT (Safe Self-Refinement for Transformer-based domain adaptation), which brings improvement from two aspects. First, encouraged by the success of vision trans-formers in various vision tasks, we arm SSRT with a trans-former backbone. We find that the combination of vision transformer with simple adversarial adaptation surpasses best reported Convolutional Neural Network (CNN)-based results on the challenging DomainNet benchmark, show-ing its strong transferable feature representation. Second, to reduce the risk of model collapse and improve the effec-tiveness of knowledge transfer between domains with large gaps, we propose a Safe Self-Refinement strategy. Specifi-cally, SSRT utilizes predictions of perturbed target domain data to refine the model. Since the model capacity of vi-sion transformer is large and predictions in such challeng-ing tasks can be noisy, a safe training mechanism is de-signed to adaptively adjust learning configuration. Ex-tensive evaluations are conducted on several widely testedUDA benchmarks and SSRT achieves consistently the best performances, including 85.43% on Office-Home, 88.76% on VisDA-2017 and 45.2% on DomainNet. 