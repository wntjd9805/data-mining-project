With the ubiquity of rolling shutter (RS) cameras, it is be-coming increasingly attractive to recover the latent global shutter (GS) video from two consecutive RS frames, which also places a higher demand on realism. Existing solu-tions, using deep neural networks or optimization, achieve promising performance. However, these methods generate intermediate GS frames through image warping based on the RS model, which inevitably result in black holes and no-ticeable motion artifacts. In this paper, we alleviate these issues by proposing a context-aware GS video reconstruc-tion architecture. It facilitates the advantages such as oc-clusion reasoning, motion compensation, and temporal ab-straction. Speciﬁcally, we ﬁrst estimate the bilateral motionﬁeld so that the pixels of the two RS frames are warped to a common GS frame accordingly. Then, a reﬁnement scheme is proposed to guide the GS frame synthesis along with bi-lateral occlusion masks to produce high-ﬁdelity GS video frames at arbitrary times. Furthermore, we derive an ap-proximated bilateral motion ﬁeld model, which can serve as an alternative to provide a simple but effective GS frame ini-tialization for related tasks. Experiments on synthetic and real data show that our approach achieves superior perfor-mance over state-of-the-art methods in terms of objective metrics and subjective visual quality. Code is available at https://github.com/GitCVfb/CVR. 