In this paper, we study the problem of jointly estimat-ing the optical ﬂow and scene ﬂow from synchronized 2D and 3D data. Previous methods either employ a complex pipeline that splits the joint task into independent stages, or fuse 2D and 3D information in an “early-fusion” or “late-fusion” manner. Such one-size-ﬁts-all approaches suffer from a dilemma of failing to fully utilize the characteris-tic of each modality or to maximize the inter-modality com-plementarity. To address the problem, we propose a novel end-to-end framework, called CamLiFlow.It consists of 2D and 3D branches with multiple bidirectional connec-tions between them in speciﬁc layers. Different from pre-vious work, we apply a point-based 3D branch to better ex-tract the geometric features and design a symmetric learn-able operator to fuse dense image features and sparse point features. Experiments show that CamLiFlow achieves bet-ter performance with fewer parameters. Our method ranks 1st on the KITTI Scene Flow benchmark, outperforming the previous art with 1/7 parameters. Code is available at https://github.com/MCG-NJU/CamLiFlow. 