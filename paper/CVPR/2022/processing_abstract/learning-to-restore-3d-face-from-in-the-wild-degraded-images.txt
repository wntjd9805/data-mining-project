+45(cid:28733)-45(cid:28733) 0(cid:28733)In-the-wild 3D face modelling is a challenging problem as the predicted facial geometry and texture suffer from a lack of reliable clues or priors, when the input images are degraded. To address such a problem, in this paper we pro-pose a novel Learning to Restore (L2R) 3D face framework for unsupervised high-quality face reconstruction from low-resolution images. Rather than directly reﬁning 2D image appearance, L2R learns to recover ﬁne-grained 3D details on the proxy against degradation via extracting generative facial priors. Concretely, L2R proposes a novel albedo restoration network to model high-quality 3D facial texture, in which the diverse guidance from the pre-trained Gener-ative Adversarial Networks (GANs) is leveraged to comple-ment the lack of input facial clues. With the ﬁner details of the restored 3D texture, L2R then learns displacement maps from scratch to enhance the signiﬁcant facial structure and geometry. Both of the procedures are mutually optimized with a novel 3D-aware adversarial loss, which further im-proves the modelling performance and suppresses the po-tential uncertainty. Extensive experiments on benchmarks show that L2R outperforms state-of-the-art methods under the condition of low-quality inputs, and obtains superior performances than 2D pre-processed modelling approaches with limited 3D proxy. 