Recent salient object detection (SOD) methods based on deep neural network have achieved remarkable perfor-mance. However, most of existing SOD models designed for low-resolution input perform poorly on high-resolution im-ages due to the contradiction between the sampling depth and the receptive ﬁeld size. Aiming at resolving this con-tradiction, we propose a novel one-stage framework calledPyramid Grafting Network (PGNet), using transformer andCNN backbone to extract features from different resolu-tion images independently and then graft the features from transformer branch to CNN branch. An attention-basedCross-Model Grafting Module (CMGM) is proposed to en-able CNN branch to combine broken detailed information more holistically, guided by different source feature dur-ing decoding process. Moreover, we design an AttentionGuided Loss (AGL) to explicitly supervise the attention ma-trix generated by CMGM to help the network better inter-act with the attention from different models. We contribute a new Ultra-High-Resolution Saliency Detection datasetUHRSD, containing 5,920 images at 4K-8K resolutions. To our knowledge, it is the largest dataset in both quantity and resolution for high-resolution SOD task, which can be used for training and testing in future research. Sufﬁcient exper-iments on UHRSD and widely-used SOD datasets demon-strate that our method achieves superior performance com-pared to the state-of-the-art methods. 