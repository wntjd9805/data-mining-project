In this paper, we present TransMVSNet, based on our exploration of feature matching in multi-view stereo (MVS).We analogize MVS back to its nature of a feature match-ing task and therefore propose a powerful Feature Match-ing Transformer (FMT) to leverage intra- (self-) and inter-(cross-) attention to aggregate long-range context informa-tion within and across images. To facilitate a better adap-tation of the FMT, we leverage an Adaptive Receptive Field (ARF) module to ensure a smooth transit in scopes of fea-tures and bridge different stages with a feature pathway to pass transformed features and gradients across differ-ent scales. In addition, we apply pair-wise feature corre-lation to measure similarity between features, and adopt ambiguity-reducing focal loss to strengthen the supervi-sion. To the best of our knowledge, TransMVSNet is the first attempt to leverage Transformer into the task of MVS.As a result, our method achieves state-of-the-art perfor-mance on DTU dataset, Tanks and Temples benchmark, and BlendedMVS dataset. Code is available at https://github.com/MegviiRobot/TransMVSNet. 