Learned image compression methods have exhibited su-perior rate-distortion performance than classical image compression standards. Most existing learned image com-pression models are based on Convolutional Neural Net-works (CNNs). Despite great contributions, a main draw-back of CNN based model is that its structure is not de-signed for capturing local redundancy, especially the non-repetitive textures, which severely affects the reconstruction quality. Therefore, how to make full use of both global structure and local texture becomes the core problem for learning-based image compression. Inspired by recent pro-gresses of Vision Transformer (ViT) and Swin Transformer, we found that combining the local-aware attention mech-anism with the global-related feature learning could meet the expectation in image compression.In this paper, we first extensively study the effects of multiple kinds of atten-tion mechanisms for local features learning, then introduce a more straightforward yet effective window-based local at-tention block. The proposed window-based attention is very flexible which could work as a plug-and-play component to enhance CNN and Transformer models. Moreover, we pro-pose a novel Symmetrical TransFormer (STF) framework with absolute transformer blocks in the down-sampling en-coder and up-sampling decoder. Extensive experimental evaluations have shown that the proposed method is ef-fective and outperforms the state-of-the-art methods. The code is publicly available at https://github.com/Googolxx/STF. 