Conventional point cloud semantic segmentation meth-ods usually employ an encoder-decoder architecture, where mid-level features are locally aggregated to extract geomet-ric information. However, the over-reliance on these class-agnostic local geometric representations may raise confu-sion between local parts from different categories that are similar in appearance or spatially adjacent. To address this issue, we argue that mid-level features can be further en-hanced with semantic information, and propose semantic-affine transformation that transforms features of mid-level points belonging to different categories with class-specific affine parameters. Based on this technique, we propose Se-mAffiNet for point cloud semantic segmentation, which uti-lizes the attention mechanism in the Transformer module to implicitly and explicitly capture global structural knowl-edge within local parts for overall comprehension of each category. We conduct extensive experiments on the Scan-NetV2 and NYUv2 datasets, and evaluate semantic-affine transformation on various 3D point cloud and 2D image segmentation baselines, where both qualitative and quan-titative results demonstrate the superiority and generaliza-tion ability of our proposed approach. Code is available at https://github.com/wangzy22/SemAffiNet. 