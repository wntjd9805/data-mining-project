To overcome the overfitting issue of dehazing models trained on synthetic hazy-clean image pairs, many recent methods attempted to improve modelsâ€™ generalization abil-ity by training on unpaired data. Most of them simply for-mulate dehazing and rehazing cycles, yet ignore the physi-cal properties of the real-world hazy environment, i.e. the haze varies with density and depth. In this paper, we pro-pose a self-augmented image dehazing framework, termedD4 (Dehazing via Decomposing transmission map intoDensity and Depth) for haze generation and removal. In-stead of merely estimating transmission maps or clean con-tent, the proposed framework focuses on exploring scatter-ing coefficient and depth information contained in hazy and clean images. With estimated scene depth, our method is capable of re-rendering hazy images with different thick-nesses which further benefits the training of the dehazing network.It is worth noting that the whole training pro-cess needs only unpaired hazy and clean images, yet suc-ceeded in recovering the scattering coefficient, depth map and clean content from a single hazy image. Comprehensive experiments demonstrate our method outperforms state-of-the-art unpaired dehazing methods with much fewer pa-rameters and FLOPs. Our code is available at https://github.com/YaN9-Y/D4. 