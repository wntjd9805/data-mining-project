Domain Generalizable (DG) person ReID is a challeng-ing task which trains a model on source domains yet gen-eralizes well on target domains. Existing methods use source domains to learn domain-invariant features, and assume those features are also irrelevant with target do-mains. However, they do not consider the target domain information which is unavailable in the training phrase ofDG. To address this issue, we propose a novel Meta Dis-tribution Alignment (MDA) method to enable them to share similar distribution in a test-time-training fashion. Specif-ically, since high-dimensional features are difficult to con-strain with a known simple distribution, we first introduce an intermediate latent space constrained to a known prior distribution. The source domain data is mapped to this la-tent space and then reconstructed back. A meta-learning strategy is introduced to facilitate generalization and sup-port fast adaption. To reduce their discrepancy, we fur-ther propose a test-time adaptive updating strategy based on the latent space which efficiently adapts model to un-seen domains with a few samples. Extensive experimental results show that our model outperforms the state-of-the-art methods by up to 5.2% R-1 on average on the large-scale and 4.7% R-1 on the single-source domain general-ization ReID benchmark. Source code is publicly available at https://github.com/haoni0812/MDA.git. 