Deep learning (DL) models trained to minimize empir-ical risk on a single domain often fail to generalize when applied to other domains. Model failures due to poor gen-eralizability are quite common in practice and may prove quite perilous in mission-critical applications, e.g., diag-nostic imaging where real-world data often exhibits pro-nounced variability. Such limitations have led to increased interest in domain generalization (DG) approaches that im-prove the ability of models learned from a single or multiple source domains to generalize to out-of-distribution (OOD) test domains. In this work, we propose BoosterNet, a lean add-on network that can be simply appended to any arbi-trary core network to improve its generalization capability without requiring any changes in its architecture or train-ing procedure. Specifically, using a novel measure of fea-ture culpability, BoosterNet is trained episodically on the most and least culpable data features extracted from crit-ical units in the core network based on their contribution towards class-specific prediction errors, which have shown to improve generalization. At inference time, correspond-ing test image features are extracted from the closest class-specific units, determined by smart gating via a Siamese network, and fed to BoosterNet for improved generaliza-tion. We evaluate the performance of BoosterNet within two very different classification problems, digits and skin lesions, and demonstrate a marked improvement in model generalization to OOD test domains compared to SOTA. 