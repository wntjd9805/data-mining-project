Videos from edited media like movies are a useful, yet under-explored source of information, with rich variety of appearance and interactions between humans depicted over a large temporal context. However, the richness of data comes at the expense of fundamental challenges such as abrupt shot changes and close up shots of actors with heavy truncation, which limits the applicability of existing 3D hu-man understanding methods. In this paper, we address these limitations with the insight that while shot changes of the same scene incur a discontinuity between frames, the 3D structure of the scene still changes smoothly. This allows us to handle frames before and after the shot change as multi-view signal that provide strong cues to recover the 3D state of the actors. We propose a multi-shot optimization framework that realizes this insight, leading to improved 3D reconstruction and mining of sequences with pseudo-ground truth 3D human mesh. We treat this data as valuable supervision for models that enable human mesh recovery from movies; both from single image and from video, where we propose a transformer-based temporal encoder that can naturally handle missing observations due to shot changes in the input frames. We demonstrate the importance of our insight and proposed models through extensive experiments.The tools we develop open the door to processing and an-alyzing in 3D content from a large library of edited me-dia, which could be helpful for many downstream applica-tions. Code, models and data are available at: https://geopavlakos.github.io/multishot/Figure 2. Multi-shot reasoning. Frames before and after the shot change depict the same 3D scene and provide a multi-view signal which helps reconstruct the underlying 3D pose of humans, particularly in cases of close-up, heavily truncated images of people. Blue triangles correspond to estimated camera locations in the scene. Each person is reconstructed independently. 