Defocus deblurring is a challenging task due to the spa-tially varying nature of defocus blur. While deep learning approach shows great promise in solving image restoration problems, defocus deblurring demands accurate training data that consists of all-in-focus and defocus image pairs, which is difficult to collect. Naive two-shot capturing can-not achieve pixel-wise correspondence between the defo-cused and all-in-focus image pairs. Synthetic aperture of light fields is suggested to be a more reliable way to gener-ate accurate image pairs. However, the defocus blur gen-erated from light field data is different from that of the im-ages captured with a traditional digital camera. In this pa-per, we propose a novel deep defocus deblurring network that leverages the strength and overcomes the shortcoming of light fields. We first train the network on a light field-generated dataset for its highly accurate image correspon-dence. Then, we fine-tune the network using feature loss on another dataset collected by the two-shot method to allevi-ate the differences between the defocus blur exists in the two domains. This strategy is proved to be highly effective and able to achieve the state-of-the-art performance both quan-titatively and qualitatively on multiple test sets. Extensive ablation studies have been conducted to analyze the effect of each network module to the final performance. 