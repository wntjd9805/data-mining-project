The performance of nighttime semantic segmentation is restricted by the poor illumination and a lack of pixel-wise annotation, which severely limit its application in au-tonomous driving. Existing works, e.g., using the twilight as the intermediate target domain to perform the adapta-tion from daytime to nighttime, may fail to cope with the inherent difference between datasets caused by the camera equipment and the urban style. Faced with these two types of domain shifts, i.e., the illumination and the inherent dif-ference of the datasets, we propose a novel domain adap-tation framework via cross-domain correlation distillation, called CCDistill. The invariance of illumination or inher-ent difference between two images is fully explored so as to make up for the lack of labels for nighttime images. Specifi-cally, we extract the content and style knowledge contained in features, calculate the degree of inherent or illumination difference between two images. The domain adaptation is achieved using the invariance of the same kind of difference.Extensive experiments on Dark Zurich and ACDC demon-strate that CCDistill achieves the state-of-the-art perfor-mance for nighttime semantic segmentation. Notably, our method is a one-stage domain adaptation network which can avoid affecting the inference time. Our implementa-tion is available at https://github.com/ghuan99/CCDistill. 