Action recognition is a difficult task due to the constantly changing attributes and relationships of objects in videos. Current methods use object-level or scene graphs to represent object dynamics and relationships, but they do not directly model the fine-grained transitions in relationships. To address this, we propose an Object-Relation Reasoning Graph (OR2G) that combines an object-level graph and a relation-level graph. The OR2G captures attribute transitions of objects and reasons about relationship transitions between objects simultaneously. We also introduce a graph aggregating module (GAM) that uses a multi-head edge-to-node message passing operation. GAM enhances the coupling between the object-level and relation-level graphs by feeding back information from relation nodes to object nodes. Experimental results in video action recognition demonstrate the effectiveness of our approach compared to state-of-the-art methods.