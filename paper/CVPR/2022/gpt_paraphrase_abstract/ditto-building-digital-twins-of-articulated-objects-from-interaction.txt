The potential of digitizing physical objects into the virtual world is explored in this research, with a focus on creating interactive digital twins of real-world articulated objects. These digital twins can be directly imported into virtual environments. The authors introduce a system called Ditto, which uses interactive perception to learn the articulation model estimation and 3D geometry reconstruction of an articulated object. By analyzing visual observations of the object before and after interaction, Ditto is able to reconstruct the geometry at the part-level and estimate the object's articulation model. Implicit neural representations are employed for joint geometry and articulation modeling. The experiments demonstrate that Ditto is successful in building digital twins of articulated objects in a category-agnostic manner. The system is also applied to real-world objects and the recreated digital twins are deployed in physical simulation. The code and additional results can be found at the provided URL: https://ut-austin-rpl.github.io/Ditto/.