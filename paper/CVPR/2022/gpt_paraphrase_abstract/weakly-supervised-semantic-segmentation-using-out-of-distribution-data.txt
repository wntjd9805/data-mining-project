Weakly supervised semantic segmentation methods often rely on pixel-level localization maps obtained from a classifier. However, classifiers trained solely on class labels suffer from the problem of spurious correlation between foreground and background cues, limiting the performance of weakly supervised semantic segmentation. Previous attempts to address this issue have involved additional supervision. In this study, we propose a new source of information to distinguish foreground from background: Out-of-Distribution (OoD) data, which refers to images without foreground object classes. Specifically, we utilize hard OoDs that the classifier is likely to incorrectly predict as positive. These hard OoDs typically contain visual features on the background that are often confused as foreground by the classifier. By incorporating these cues, the classifier can effectively suppress spurious background cues. Acquiring hard OoDs does not require extensive annotation efforts and only involves a few additional image-level labeling costs on top of the original collection of class labels. We introduce a method called W-OoD to utilize the hard OoDs, which achieves state-of-the-art performance on the Pascal VOC 2012 dataset. The code for W-OoD is available at the following GitHub repository: https://github.com/naver-ai/w-ood.