Learning new classes without forgetting previous knowledge is a challenging problem. We propose C-FSCIL, which consists of a frozen feature extractor, a trainable fixed-size fully connected layer, and a growing memory. C-FSCIL has three update modes that balance accuracy and compute-memory cost. It uses hyperdimensional embedding to represent more classes in a limited vector space. The quality of class representations is improved by aligning them quasi-orthogonally. Experiments on various datasets show that C-FSCIL outperforms baselines in accuracy and compression. It can also handle a large number of classes with minimal accuracy drop. The code is available at https://github.com/IBM/constrained-FSCIL.