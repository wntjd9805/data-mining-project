PU learning is a challenging task that involves learning binary classifiers from a limited number of labeled positive examples and a large number of unlabeled ones. Unlike semi-supervised learning, PU learning does not have any known negative labels, making it more difficult. Current cost-sensitive-based methods for PU learning have achieved good results, but they may have a preference for negative predictions. To address this issue, we propose a label distribution perspective for PU learning. We observe that the label distribution of unlabeled data remains constant when the class prior is known, and we can use this as a learning supervision for the model. We aim to ensure consistency between the predicted and ground-truth label distributions by aligning their expectations. Additionally, we incorporate entropy minimization and Mixup regularization to prevent trivial solutions and reduce confirmation bias. Experimental results on three benchmark datasets demonstrate the effectiveness of our proposed method.