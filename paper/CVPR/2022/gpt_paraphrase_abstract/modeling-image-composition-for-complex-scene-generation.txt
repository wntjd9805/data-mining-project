We present a method that achieves state-of-the-art results on challenging layout-to-image generation tasks. Our approach accurately models textures, structures, and relationships in complex scenes. We compress RGB images into patch tokens and propose the Transformer with Focal Attention (TwFA) to explore dependencies between objects, patches, and pixels. Unlike existing models that entangle modeling at different levels, our focal attention predicts the current patch token by focusing on highly-related tokens specified by the spatial layout, leading to disambiguation during training. Additionally, TwFA improves data efficiency, allowing us to propose the first few-shot complex scene generation strategy based on the well-trained TwFA. Extensive experiments demonstrate the superiority of our method in terms of quantitative metrics and qualitative visual realism compared to state-of-the-art CNN-based and transformer-based approaches. The code for our method is available at https://github.com/JohnDreamer/TwFA.