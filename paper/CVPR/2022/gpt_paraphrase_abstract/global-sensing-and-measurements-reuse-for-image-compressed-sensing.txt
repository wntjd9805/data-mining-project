Recently, deep network-based methods for compressing and reconstructing images have shown promising results, offering improved reconstruction quality and reduced computational requirements compared to traditional approaches. However, existing methods only utilize partial features from the network and employ them once for image reconstruction. This overlooks the fact that low, mid, and high-level features are all crucial for achieving high-quality reconstructions. Additionally, using measurements only once may not capture enough information from the data. To address these limitations, we propose a novel approach called Measurements Reuse Convolutional Compressed Sensing Network (MR-CCSNet). Our method incorporates a Global Sensing Module (GSM) to gather features at all levels, enabling efficient sensing, and a Measurements Reuse Block (MRB) to reuse measurements multiple times at different scales. Through experiments conducted on three benchmark datasets, we demonstrate that our model significantly outperforms state-of-the-art methods in terms of reconstruction accuracy. For easy access, the code for our proposed MR-CCSNet is available at: https://github.com/fze0012/MR-CCSNet.