This paper introduces a novel approach for making region-based edits to natural images using natural language descriptions and ROI masks. The method combines a pretrained language-image model (CLIP) with a de-noising diffusion probabilistic model (DDPM) to generate realistic results. To seamlessly blend the edited region with the rest of the image, the method applies spatial blending of noised versions of the input image with the local text-guided diffusion latent. The addition of augmentations to the diffusion process helps mitigate adversarial outcomes. The proposed method is compared against various baselines and related techniques, demonstrating superior performance in terms of overall realism, preserving the background, and matching the text. The paper also showcases several text-driven editing applications, such as adding new objects, removing/replacing/altering existing objects, background replacement, and image extrapolation.