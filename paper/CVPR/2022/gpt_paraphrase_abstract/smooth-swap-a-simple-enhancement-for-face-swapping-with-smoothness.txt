We present a new face-swapping model called 'Smooth-Swap' that offers high-quality generation while simplifying the architecture and training process. Unlike previous models, which require complex designs and careful tuning, Smooth-Swap utilizes a smooth identity embedding that ensures stable gradients for identity change. This embedding is trained using a supervised contrastive loss, resulting in a smoother space. Our model consists of a U-Net-based generator and three basic loss functions, making it much simpler compared to previous models. Extensive experiments on face-swapping benchmarks and face images in the wild demonstrate that our model is quantitatively and qualitatively comparable or even superior to existing methods.