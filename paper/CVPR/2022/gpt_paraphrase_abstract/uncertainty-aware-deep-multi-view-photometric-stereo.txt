This paper introduces a solution to the long-standing problem of multi-view photometric stereo (MVPS) by combining the strengths of photometric stereo (PS) and multi-view stereo (MVS) while considering the uncertainty of their estimates. The proposed approach utilizes an uncertainty-aware deep-PS network and deep-MVS network to estimate per-pixel surface normals and depth. By modeling uncertainty, the approach selects reliable estimates at each pixel, which represent the dense surface geometry. The deep-PS and deep-MVS predictions are selectively used based on their prediction uncertainty measure. To achieve detailed and precise inference of the object's surface profile, the approach employs a multilayer perceptron (MLP) to learn the implicit neural shape representation. By leveraging confident predictions from the deep-PS and deep-MVS networks, the MLP converges to a natural zero-level set surface, resulting in superior dense surface reconstruction. Experimental results on the DiLiGenT-MV benchmark dataset demonstrate that the proposed method offers high-quality shape recovery with a lower memory requirement compared to existing approaches.