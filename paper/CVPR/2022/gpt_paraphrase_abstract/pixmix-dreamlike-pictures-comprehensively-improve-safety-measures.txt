In practical applications of machine learning, it is important to consider various performance measures beyond just test set accuracy. These measures include robustness to out-of-distribution inputs, consistency in predictions, resilience against adversarial attacks, accurate uncertainty estimation, and the ability to detect anomalies. However, improving performance in these areas often comes at the expense of performance in other safety aspects. For example, training models to be robust against adversarial attacks can negatively impact other classifier performance metrics. Similarly, strong data augmentation techniques that improve robustness to out-of-distribution inputs may hinder anomaly detection. This raises the question of whether it is possible to achieve a Pareto improvement across all safety measures. To address this challenge, we propose a novel data augmentation strategy that leverages the inherent structural complexity of images, such as fractals. Our approach surpasses several baseline methods, comes close to being Pareto-optimal, and significantly enhances safety measures.