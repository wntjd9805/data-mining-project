Multi-camera multi-object tracking is gaining attention in the field of computer vision due to its superior performance in real-world applications such as video surveillance in crowded scenes or wide spaces. In this study, we propose an elegant mathematical approach for multi-camera tracking. Our model utilizes tracklets generated by single-camera trackers as proposals, but refines them to eliminate ID-Switch errors using a novel pre-clustering technique based on 3D geometry projections. This results in a more accurate tracking graph and affinity costs for data association. We then match the tracklets to multi-camera trajectories by solving a global lifted multicut formulation that incorporates both short and long-range temporal interactions within the same camera and across different cameras. Our experimental results on the WildTrack dataset show near-perfect performance, outperforming state-of-the-art trackers on the Campus dataset and achieving comparable results on the PETS-09 dataset. We will make our implementations available at the following link: https://github.com/nhmduy/LMGP.