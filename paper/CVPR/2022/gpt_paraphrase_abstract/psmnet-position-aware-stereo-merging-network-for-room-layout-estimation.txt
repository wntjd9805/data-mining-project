This paper presents a novel deep learning approach, named Position-aware Stereo Merging Network (PSMNet), for accurately estimating the layout of a room using a pair of 360-degree panoramas. PSMNet is an end-to-end system that combines both layout and pose estimation. It consists of two main components: the Stereo Pano Pose (SP2) transformer and the Cross-Perspective Projection (CP2) layer. The SP2 transformer infers correspondences between views, allowing it to handle noisy poses. The CP2 layer, on the other hand, transfers features from the adjacent view to the reference view, enabling view fusion and accurate estimation of the visible layout. Experimental results demonstrate that our method outperforms existing layout estimators, particularly in large and complex room spaces.