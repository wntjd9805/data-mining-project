Saliency detection with light field images is gaining popularity due to the numerous cues available. However, obtaining pixel-level annotated data for training is expensive. In this study, we propose a method to learn light field saliency using pixel-level noisy labels obtained from unsupervised feature-based saliency methods. Our approach aims to efficiently incorporate the relationships among light field cues while identifying clean labels. To achieve this, we formulate the learning process as a joint optimization of intra light field features fusion stream and inter scenes correlation stream. We introduce a pixel forgetting guided fusion module to enhance the light field features and identify noisy pixels through pixel consistency. Additionally, we introduce a cross scene noise penalty loss to better capture the underlying structures of the training data and make the learning process invariant to noise. Through extensive experiments on multiple benchmark datasets, we demonstrate the effectiveness of our framework, which achieves saliency prediction comparable to state-of-the-art fully supervised light field saliency methods. Our code is available at https://github.com/OLobbCode/NoiseLF.