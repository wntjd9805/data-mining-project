Current state-of-the-art techniques for Video Object Segmentation (VOS) require a significant amount of densely annotated video data to establish pixel-to-pixel correspondences between frames and propagate object masks. This annotation process is expensive and redundant since frames within a video are highly correlated. To address this issue, we introduce HODOR, a novel approach that effectively utilizes annotated static images to comprehend object appearance and scene context for VOS. HODOR encodes object instances and scene information from an image frame into robust high-level descriptors, enabling the re-segmentation of objects in different frames. Our method outperforms existing techniques trained without video annotations on the DAVIS and YouTube-VOS benchmarks. Importantly, HODOR does not require any architectural modification and can also learn from video context around single annotated video frames by utilizing cyclic consistency. This is in contrast to other methods that rely on dense, temporally consistent annotations. The source code for HODOR can be found at: https://github.com/Ali2500/HODOR.