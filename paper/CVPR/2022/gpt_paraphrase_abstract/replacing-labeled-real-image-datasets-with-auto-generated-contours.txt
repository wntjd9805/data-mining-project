This study demonstrates that formula-driven supervised learning (FDSL) can achieve comparable or superior performance to ImageNet-21k without the need for real images, human supervision, or self-supervision during pre-training of Vision Transformers (ViTs). By utilizing synthetic images generated through formulas, issues such as privacy concerns, copyright problems, labeling costs and errors, and biases associated with real images can be avoided. This approach has significant potential for effectively pre-training general models. The researchers conducted experiments to validate the performance of synthetic images and tested two hypotheses. Firstly, they constructed a dataset consisting of simple object contour combinations and found that it can achieve performance levels similar to fractals. Secondly, they observed that increasing the complexity of the pre-training task generally leads to improved fine-tuning accuracy.