Despite the advancements in deep models for crack recognition, the discriminative power of deeply learned features supervised by the cross-entropy loss is still lacking due to inconsistent cracks in different sizes, shapes, and with noisy background textures. This paper introduces the geometry-aware guided loss (GAGL) to enhance discrimination ability during the training stage without additional computation and memory usage during inference. GAGL comprises the feature-based geometry-aware projected gradient descent method (FGA-PGD) that estimates the geometric distances of features to class boundaries, and a geometry-aware update rule that learns an anchor for each class as an approximation of the feature with the largest expected geometric distance to the corresponding class boundary. By minimizing the distances between features and their respective class anchors in the feature space, the discriminative power is improved. To overcome the limited availability of relevant benchmarks, a fully annotated dataset called NPP2021 is collected, which includes inconsistent cracks and noisy backgrounds in real-world nuclear power plants. The proposed GAGL outperforms state-of-the-art methods on various benchmark datasets, including CRACK2019, SDNET2018, and NPP2021.