This paper introduces a novel self-supervised learning algorithm called Contextualized Spatio-Temporal Contrastive Learning (ConST-CL) for effectively learning fine-grained video representations. Unlike traditional algorithms that focus on persistency of instance representations across views, ConST-CL takes into account the evolving nature of scenes and instances in videos. The algorithm utilizes a region-based pretext task that requires the model to transform instance representations from one view to another, guided by context features. Additionally, a simple network design is proposed to simultaneously learn both holistic and local representations. The learned representations are evaluated on various downstream tasks and achieve competitive results on six datasets. The code and models for ConST-CL are made available at a specified GitHub repository.