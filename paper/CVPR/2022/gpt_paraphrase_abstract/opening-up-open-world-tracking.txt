Tracking and detecting objects, even those that have never been encountered before during model training, is a crucial but challenging capability for autonomous systems. It is concerning that most current systems are blind to never-seen-before objects, as this poses a safety hazard in real-world operations. One of the main obstacles in advancing object tracking is the difficulty of evaluating performance in this task. Therefore, it is essential to establish a benchmark that allows for a fair comparison of different approaches. This paper aims to address the evaluation deficiency by presenting the landscape and methodology for detecting and tracking both known and unknown objects in an open-world setting. To achieve this, we introduce a new benchmark called TAO-OW (Tracking Any Object in an Open World), analyze existing efforts in multi-object tracking, and establish a baseline for this task. Additionally, we highlight future challenges that need to be tackled. Our goal is to contribute to the advancement of multi-object tracking research and ultimately enable intelligent systems to operate safely in real-world scenarios.