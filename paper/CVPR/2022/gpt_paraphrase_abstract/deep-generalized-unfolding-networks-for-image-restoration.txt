We propose a Deep Generalized Unfolding Network (DGUNet) for image restoration. Unlike most existing deep neural network (DNN) methods, our approach maintains interpretability and transparency. We integrate a gradient estimation strategy into the Proximal Gradient Descent (PGD) algorithm, allowing it to handle complex and real-world image degradation. Additionally, we address the information loss in deep unfolding networks (DUN) by designing inter-stage information pathways across proximal mapping in different PGD iterations. This rectifies the intrinsic information loss through a multi-scale and spatial-adaptive approach. By combining flexible gradient descent and informative proximal mapping, we transform the iterative PGD algorithm into a trainable DNN. Our method outperforms state-of-the-art approaches in image restoration tasks, while maintaining interpretability and generalizability. The source code is available at github.com/MC-E/DGUNet.