Motion-based video frame interpolation often requires refinement of the warped result due to challenges in motion estimation. This decreases the efficiency for multi-frame interpolation. To address this issue, we propose a fully differentiable Many-to-Many (M2M) splatting framework. This framework estimates bidirectional flows to directly warp pixels to the desired time step and fuses overlapping pixels. By doing so, each source pixel contributes to multiple target pixels, and each target pixel can be synthesized from a larger visual context. This approach enables robust interpolation with minimal artifacts. Additionally, M2M only requires motion estimation once for each input frame pair, resulting in fast multi-frame interpolation with low computational overhead. Experimental analysis demonstrates that M2M significantly improves efficiency while maintaining high effectiveness.