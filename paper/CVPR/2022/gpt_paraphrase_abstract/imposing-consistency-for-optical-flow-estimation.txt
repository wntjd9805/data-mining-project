This study presents innovative and effective approaches to enhance optical flow estimation using consistency strategies. Optical flow estimation is a challenging task due to the difficulty in obtaining accurate labels from real-world data. The proposed strategies include occlusion consistency, zero forcing, self-supervised learning, and semi-supervised learning through transformation consistency. By incorporating these strategies into a baseline network model, the pixel-level motion description is improved without the need for additional annotations. The results show that applying these consistency strategies to the original datasets and labels leads to significant improvements, achieving state-of-the-art performance on the KITTI-2015 scene flow benchmark in the non-stereo category. Notably, our method achieves the best foreground accuracy (4.33% in Fl-all) across both stereo and non-stereo categories, using only monocular image inputs.