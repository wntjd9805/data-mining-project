Optical flow estimation is a fundamental task in computer vision. Recent advancements in deep neural networks have led to direct-regression methods that achieve impressive performance. However, these methods struggle with handling large motions because they fail to capture long-term motion correspondences. To address this limitation, we propose a novel framework called GMFlowNet that combines global matching with direct regression. Inspired by traditional matching-optimization methods, we introduce a global matching step before the direct regression to handle large displacements. We efficiently calculate global matching by applying argmax on 4D cost volumes. Additionally, we propose patch-based overlapping attention to improve the matching quality and extract large context features. Our extensive experiments demonstrate that GMFlowNet significantly outperforms the popular optimization-only method, RAFT, and achieves state-of-the-art performance on standard benchmarks. GMFlowNet's matching and overlapping attention techniques lead to major improvements in predictions for texture-less regions and large motions. We have made our code publicly available at https://github.com/xiaofeng94/GMFlowNet.