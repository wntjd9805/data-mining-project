We present a novel visual localization system that utilizes synthetic data to estimate camera poses in the real world. While previous learning-based approaches focus on a single domain and require a dense database of geo-tagged images, our system overcomes the data scarcity issue by introducing TOPO-DataGen, a versatile tool that generates synthetic data bridging the real and virtual worlds based on geographic camera viewpoint. We propose new large-scale benchmark datasets that demonstrate the effectiveness of synthetic data in improving neural network performance on real data. Additionally, we introduce CrossLoc, a cross-modal visual representation learning approach that leverages scene coordinate ground truth through self-supervision. Remarkably, CrossLoc outperforms state-of-the-art methods and achieves higher efficiency in utilizing real-data samples without requiring additional data. Our code and datasets can be accessed at crossloc.github.io.