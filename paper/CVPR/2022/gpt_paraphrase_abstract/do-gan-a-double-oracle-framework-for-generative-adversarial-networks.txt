This paper proposes a novel approach for training Generative Adversarial Networks (GANs) using a double-oracle framework with generator and discriminator oracles. GANs are a two-player game between the generator and discriminator, and training them is challenging due to the lack of pure Nash equilibrium and the difficulty of finding a mixed Nash equilibrium in the large strategy space of GANs. The proposed framework, called DO-GAN, extends the double oracle framework to GANs by generalizing the players' strategies as trained models and computing meta-strategies using a linear program. To address scalability, two solutions are proposed: pruning weakly-dominated strategies and applying continual learning to retain previous knowledge. The framework is applied to various GAN architectures, including vanilla GAN, Deep Convolutional GAN, Spectral Normalization GAN, and Stacked GAN. Experimental results on MNIST, CIFAR-10, and CelebA datasets demonstrate significant improvements in both qualitative evaluation and quantitative metrics compared to their respective GAN architectures.