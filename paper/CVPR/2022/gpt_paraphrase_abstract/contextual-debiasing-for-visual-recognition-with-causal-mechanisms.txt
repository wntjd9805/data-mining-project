Contextual bias is a common issue in visual recognition, where the recognition of objects relies heavily on their co-occurrence context rather than the objects themselves. This problem is particularly challenging in multi-label tasks due to the presence of multiple targets and the lack of location information. Previous studies have attempted to address this problem, but removing the negative impact of context remains difficult due to the difficulty in obtaining the representation of contextual bias. In this paper, we propose a straightforward yet effective framework that utilizes causal inference to mitigate contextual bias. We introduce a Structural Causal Model (SCM) that explains the causal relationship between object representations, context, and predictions. We then develop a novel Causal ContextDebiasing (CCD) Module that focuses on the direct effect of an instance. This module employs causal intervention to remove the influence of confounders and employs counterfactual reasoning to obtain a Total Direct Effect (TDE) that is not affected by contextual bias. Importantly, our CCD framework is independent of existing statistical models and can be applied to any other backbone architectures. Through extensive experiments on multiple multi-label classification datasets, we demonstrate that our model outperforms other state-of-the-art baselines.