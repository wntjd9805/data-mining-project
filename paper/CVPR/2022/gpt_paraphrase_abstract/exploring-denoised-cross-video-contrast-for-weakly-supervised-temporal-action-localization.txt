In weakly-supervised temporal action localization, the goal is to identify and locate actions in untrimmed videos using only video-level labels. Most current methods tackle this problem by localizing action regions based on snippet-wise classification sequences. However, these classifications are prone to errors due to the limited information provided by video-level labels. To overcome this limitation, we propose a new denoised cross-video contrastive algorithm that aims to improve the discrimination ability of video snippets for accurate temporal action localization in weakly-supervised scenarios. This algorithm incorporates three key elements: 1) a module to denoise pseudo-labels and mitigate the impact of noisy contrastive features, 2) an efficient strategy for region-level feature contrast using a memory bank to capture global contrasts across the entire dataset, and 3) a diverse contrastive learning strategy that enables the separation of actions from backgrounds and improves both intra-class compactness and inter-class separability. Our approach outperforms existing methods, as demonstrated by extensive experiments on the THUMOS14 and ActivityNet v1.3 datasets.