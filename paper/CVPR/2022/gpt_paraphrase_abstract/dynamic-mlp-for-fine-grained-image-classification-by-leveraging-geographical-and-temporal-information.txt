Fine-grained image classification is a difficult task in computer vision, as many species have similar visual appearances, leading to misclassification based solely on visual clues. To address this issue, it is beneficial to utilize additional information, such as data shooting locations and dates, which are easily accessible but often overlooked. Previous multimodal methods have fused multiple features on a single dimension, which is insufficient for effective feature discrimination. In this paper, we propose a dynamic MLP (Multi-Layer Perceptron) that interacts with multimodal features at a higher and broader dimension to fully explore their potential. The dynamic MLP is a parameterized structure that uses learned embeddings of variable locations and dates, acting as an adaptive nonlinear projection for generating more discriminative image representations.This is the first attempt to use dynamic networks to exploit multimodal information in fine-grained image classification tasks. Extensive experiments demonstrate the effectiveness of our method, as the t-SNE algorithm visually shows improved recognizability of visually similar but different categories of image representations. Moreover, our dynamic MLP consistently achieves state-of-the-art results across multiple fine-grained datasets and ranks third in the iNaturalist challenge at FGVC8.The code for our method is available at https://github.com/megvii-research/DynamicMLPForFinegrained. The authors of this paper are from PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology.Figure 1 illustrates the t-SNE representations of well-trained models. The different colors represent various similar species from the genus Turdus in the iNaturalist 2021 dataset. The visualization of an image-only model (a) shows the difficulty in distinguishing between visually similar species. Concatenating the image, location, and date features before the classification head (b) is a typical strategy to utilize additional information, leading to a more discriminative representation. Our proposed dynamic MLP (c) further expands the diversity among different fine-grained species compared to the image-only or concatenation framework. The 3D visualizations (d) and (e) demonstrate the improved separation achieved by our dynamic MLP.