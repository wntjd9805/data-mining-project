The Transformer model has shown great success in 2D vision tasks, but it faces challenges when applied to large-scale point cloud data due to the uneven distribution of points in 3D space. Existing methods address this problem by either grouping points into clusters or using discretized representations, but these approaches have drawbacks such as point dropout or narrow attention fields. This paper introduces a new architecture called VoxSeT, which utilizes voxel-based set attention (VSA) to detect 3D objects from point clouds. VSA reduces self-attention within each voxel using cross-attentions and models features in a hidden space defined by latent codes. VoxSeT can handle point clusters of different sizes and process them in parallel with linear complexity. By combining the performance of Transformer with the efficiency of voxel-based models, VoxSeT serves as a viable alternative to convolutional and point-based backbones. Experimental results on KITTI and Waymo detection benchmarks demonstrate the competitiveness of VoxSeT. The source codes for VoxSeT can be found at https://github.com/skyhehe123/VoxSeT.