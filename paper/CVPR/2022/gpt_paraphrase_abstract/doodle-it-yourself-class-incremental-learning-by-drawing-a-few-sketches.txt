The human visual system has the ability to learn new visual concepts with just a few examples. Few-shot class incremental learning (FS-CIL) aims to achieve this by ensuring that the model does not forget previously learned information. However, there are two challenges in applying FS-CIL widely: (i) Can the model learn from different modalities other than photos, like humans do? (ii) What if photos are not readily available due to ethical and privacy concerns? To address these challenges, we propose a new approach called "DoodleIt Yourself" (DIY) FS-CIL framework, which leverages sketches as a new modality for class support. Users can freely sketch a few examples of a novel class, and the model learns to recognize photos of that class. Our framework incorporates gradient consensus for domain invariant learning, knowledge distillation to preserve old class information, and graph attention networks for message passing between old and novel classes. Through experiments, we demonstrate that sketches are more effective than text as class support in the context of FS-CIL, aligning with findings in the sketching literature.