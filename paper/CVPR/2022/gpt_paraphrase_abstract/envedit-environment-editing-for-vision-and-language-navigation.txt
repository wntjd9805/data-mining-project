In the field of Vision-and-Language Navigation (VLN), agents are required to navigate their environment based on natural language instructions. However, the limited availability of training data and the finite diversity of navigation environments poses a challenge for agents to generalize to new, unseen environments. To address this issue, we propose a solution called ENVEDIT, which is a data augmentation method that generates new environments by editing existing ones. These augmented environments differ from the original ones in three different aspects: style, object appearance, and object classes. By training the agent on these edit-augmented environments, we prevent overfitting to existing environments and improve generalization to new, unseen environments. In our empirical evaluation on the Room-to-Room and multi-lingual Room-Across-Room datasets, we demonstrate that the ENVEDIT method significantly improves performance on various metrics for both pre-trained and non-pre-trained VLN agents. Additionally, our method achieves the new state-of-the-art on the test leaderboard. Furthermore, we explore the ensembling of VLN agents trained on different edited environments and find that these edit methods are complementary to each other.