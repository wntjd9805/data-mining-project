This study focuses on the importance of identifying challenging examples for machine learning models. The ability to recognize atypical examples is crucial for ensuring the safe deployment of models, identifying samples that require human inspection, and gaining insight into model behavior. To address this, the authors propose a metric called Variance of Gradients (VoG) that can efficiently rank data by difficulty and highlight the most challenging examples for human auditing. The authors demonstrate that data points with high VoG scores are particularly difficult for the model to learn and often consist of corrupted or memorized examples. By evaluating the model's performance on the test set instances with the lowest VoG, the authors observe an improvement in generalization performance. Additionally, the study highlights the usefulness of VoG as a ranking metric for detecting out-of-distribution samples. Overall, the findings suggest that VoG is a valuable and efficient tool for understanding model limitations and enhancing model performance.