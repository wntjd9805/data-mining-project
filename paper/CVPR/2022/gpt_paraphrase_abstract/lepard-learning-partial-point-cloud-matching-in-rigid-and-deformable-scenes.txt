We introduce Lepard, a learning-based method for matching partial point clouds in both rigid and deformable scenes. Our approach leverages 3D positional information to achieve accurate point cloud matching. We employ three key techniques: 1) an architecture that separates point cloud representation into feature space and 3D position space, 2) a position encoding method that explicitly encodes 3D relative distance information using dot product of vectors, and 3) a repositioning technique that adjusts the relative positions of cross-point clouds. Ablation studies confirm the effectiveness of these techniques.In rigid scenarios, when combined with RANSAC and ICP algorithms, Lepard achieves outstanding registration recall rates of 93.9% and 71.3% on the 3DMatch and 3DLoMatch datasets, respectively. For deformable cases, Lepard outperforms prior methods by achieving 27.1% and 34.8% higher recall rates for non-rigid feature matching on our newly created 4DMatch and 4DLoMatch benchmarks. The code and data for Lepard are accessible at https://github.com/rabbityl/lepard.