Pan-sharpening is a technique that combines texture-rich panchromatic (PAN) images and multi-spectral (MS) images to generate texture-rich MS images. However, existing Pan-sharpening methods do not effectively utilize the complementary information between PAN and MS images, resulting in poor handling of information redundancy and limited performance. To address this issue, we propose a new Pan-sharpening framework based on mutual information. Our approach involves independently projecting PAN and MS images into a feature space and then minimizing the mutual information between them to encourage the learning of complementary information. This operation reduces information redundancy and enhances model performance. We conducted extensive experiments on various satellite datasets, which demonstrated the superiority of our algorithm compared to other state-of-the-art methods in terms of quality and quantity. Additionally, our algorithm exhibits great generalization ability for real-world scenes.