The conventional approach to motion forecasting involves learning behavioral patterns from observational data. However, this approach has two main drawbacks: it is not adaptable to changes in data distribution and it is inefficient for transferring knowledge. This study proposes a solution to these challenges by adopting a causal representation perspective. The authors introduce a formalism for motion forecasting that views the problem as a dynamic process with three groups of latent variables: invariant variables, style confounders, and spurious features. To address the first shortcoming, the authors utilize the subtle differences between datasets collected from different locations by incorporating an invariance loss that encourages the model to suppress irrelevant correlations. To tackle the second shortcoming, the authors devise a modular architecture that separates the representations of invariant mechanisms and style confounders to approximate a sparse causal graph. Additionally, they introduce a style contrastive loss that enforces the structure of style representations and serves as a self-supervisory signal for refining predictions at test time. Experimental results on both synthetic and real datasets demonstrate that the proposed method enhances the robustness and reusability of learned motion representations. It significantly outperforms previous state-of-the-art models in terms of generalization to out-of-distribution scenarios and transfer learning with limited data.