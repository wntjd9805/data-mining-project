In order to address the problem of overfitting in dehazing models trained on synthetic hazy-clean image pairs, recent methods have focused on training models on unpaired data to improve their generalization ability. However, most of these methods overlook the physical properties of real-world hazy environments, such as the variation of haze with density and depth. This paper proposes a self-augmented image dehazing framework called D4 (Dehazing via Decomposing transmission map into Density and Depth) for generating and removing haze. Instead of solely estimating transmission maps or clean content, the proposed framework explores the scattering coefficient and depth information in both hazy and clean images. By estimating scene depth, the method is able to re-render hazy images with different thicknesses, which benefits the training of the dehazing network. Importantly, the entire training process only requires unpaired hazy and clean images, yet it successfully recovers the scattering coefficient, depth map, and clean content from a single hazy image. Comprehensive experiments demonstrate that the proposed method outperforms state-of-the-art unpaired dehazing methods with fewer parameters and FLOPs. The code for the method is available at https://github.com/YaN9-Y/D4.