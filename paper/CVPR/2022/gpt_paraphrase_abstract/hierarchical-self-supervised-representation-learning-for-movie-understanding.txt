This paper focuses on self-supervised video learning for movie understanding, which is different from most existing approaches that concentrate on action recognition. The authors propose a novel hierarchical self-supervised pretraining strategy for their movie understanding model. The strategy involves separately pretraining each level of the hierarchical model using different tasks and data sources. The low-level video backbone is pretrained using a contrastive learning objective, while the higher-level video contextualizer is pretrained using an event mask prediction task.  The effectiveness of the proposed pretraining strategies is demonstrated through improved performance on various tasks and metrics in the VidSitu benchmark. For instance, the semantic role prediction CIDEr scores are increased from 47% to 61%. Furthermore, the authors show the effectiveness of their contextualized event features on LVU tasks, both when used alone and in combination with instance features, highlighting their complementarity.