We propose an end-to-end Motion-modulated Temporal Fragment Alignment Network (MT-FAN) to address the challenge of extending Few-Shot Action Recognition (FSAR) models to action recognition in videos. Our MT-FAN model has several advantages. Firstly, we introduce a motion modulator that activates channels related to task-shared motion patterns for each frame based on learned task-specific motion embeddings. Secondly, we propose a segment attention mechanism that automatically identifies higher-level segments for multi-level temporal fragment alignment, including frame-to-frame, segment-to-segment, and segment-to-frame alignments. This is the first work to utilize task-specific motion modulation for FSAR. Experimental results on four standard benchmarks demonstrate that our proposed model outperforms state-of-the-art FSAR methods.