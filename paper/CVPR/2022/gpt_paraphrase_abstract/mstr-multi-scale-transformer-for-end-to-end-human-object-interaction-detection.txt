The task of Human-Object Interaction (HOI) detection involves identifying sets of ⟨human, object, interaction⟩ triplets from images. Previous approaches have used transformer encoder-decoder architectures to eliminate the need for hand-designed components in HOI detection. However, these approaches have limitations in handling scenes with humans, objects, and their interactions at different scales and distances. To address this issue, we propose a Multi-Scale TRansformer (MSTR) for HOI detection, which incorporates two new HOI-aware deformable attention modules called Dual-Entity attention and Entity-conditioned Context attention. Unlike existing deformable attention methods that negatively impact HOI detection performance, our proposed attention modules in MSTR effectively attend to crucial sampling points for identifying interactions. Experimental results demonstrate that our approach achieves state-of-the-art performance on two HOI detection benchmarks.