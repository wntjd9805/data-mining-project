This study explores the use of knowledge distillation to improve the training of vision transformers, which have a more relaxed inductive bias that may not perform well with limited data. Unlike previous approaches that only use heavy convolution-based teachers, this paper investigates the impact of different models' inductive biases, such as convolution and involution, in knowledge distillation. The authors observe that the accuracy of the teacher model is not the main factor influencing the student model's accuracy, but rather the teacher's inductive bias is more important. They demonstrate that lightweight teachers with different architectural inductive biases can effectively guide and enhance the performance of the student transformer. This is because models with diverse inductive biases tend to focus on different patterns, and teachers with different biases acquire various knowledge even when trained on the same dataset. This diverse knowledge contributes to a more precise and comprehensive understanding of the data, leading to improved performance during distillation. Additionally, the authors propose a token inductive bias alignment method to align the inductive bias of each token with its corresponding teacher model. By employing lightweight teachers and utilizing this cross-inductive bias distillation approach, their vision transformers (referred to as CiT) achieve superior results compared to previous vision transformers of the same architecture on the ImageNet dataset. Furthermore, their smaller-sized model, CiT-SAK, achieves an impressive 82.7% Top-1 accuracy on ImageNet without any modifications to the attention module of the ViT. The code for this study is available at the provided GitHub link.