We present a rapid approach for reconstructing the per-scene radiance field from a set of images with known poses. This task, commonly used for novel view synthesis, has been recently improved by Neural Radiance Field (NeRF) for its high-quality results and flexibility. However, NeRF and its variations require lengthy training times, ranging from hours to days, for a single scene. In contrast, our method achieves comparable quality to NeRF and converges quickly in less than 15 minutes using a single GPU. We utilize a representation consisting of a density voxel grid for scene geometry and a feature voxel grid with a shallow network for view-dependent appearance. While explicit and discretized volume representations are not new, we introduce two simple but effective techniques that contribute to fast convergence and high-quality output. Firstly, we employ post-activation interpolation on voxel density to generate sharp surfaces even at lower grid resolutions. Secondly, direct voxel density optimization often leads to suboptimal geometry solutions, so we enhance the optimization process by incorporating several priors. Our method is evaluated on five inward-facing benchmarks and demonstrates comparable or superior quality to NeRF, while only requiring approximately 15 minutes of training time for a new scene. The code for our approach is available at https://github.com/sunset1995/DirectVoxGO.