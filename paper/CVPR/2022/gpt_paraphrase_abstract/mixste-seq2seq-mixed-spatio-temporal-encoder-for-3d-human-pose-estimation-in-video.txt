We propose MixSTE, a novel approach for estimating 3D human pose from 2D keypoint sequences. Existing methods that utilize transformer-based solutions have limitations in effectively modeling the inter-frame correspondence of each joint, resulting in insufficient learning of spatial-temporal correlation. To address this, MixSTE incorporates a temporal transformer block to model the temporal motion of each joint separately and a spatial transformer block to learn inter-joint spatial correlation. These blocks are alternately utilized to enhance spatio-temporal feature encoding. Furthermore, our approach extends the network output from the central frame to the entire input video, improving the coherence between input and output sequences. Extensive experiments on three benchmarks demonstrate the superiority of our model, with performance improvements of 10.9% P-MPJPE and 7.6% MPJPE over the state-of-the-art approach. The code for our model is available at https://github.com/JinluZhang1126/MixSTE.