In an image dataset, there are hierarchical semantic structures where semantically relevant clusters can be merged into larger clusters with coarser-grained semantics. Current contrastive representation learning methods lack the ability to capture these structures and also use negative pairs that may not be semantically distinct, resulting in inaccurate image representations. To address these limitations, we propose a new contrastive learning framework called Hierarchical Contrastive Selective Coding (HCSC). HCSC utilizes hierarchical prototypes that are constructed and updated to represent the hierarchical semantic structures in the latent space. We enhance conventional instance-wise and prototypical contrastive learning by implementing a pair selection scheme that chooses more diverse positive pairs with similar semantics and more precise negative pairs with distinct semantics. Our extensive experiments demonstrate that HCSC achieves state-of-the-art performance on various downstream tasks, validating the effectiveness of the model components. We provide a comprehensive model zoo, and our source code and model weights are publicly available at https://github.com/gyfastas/HCSC.