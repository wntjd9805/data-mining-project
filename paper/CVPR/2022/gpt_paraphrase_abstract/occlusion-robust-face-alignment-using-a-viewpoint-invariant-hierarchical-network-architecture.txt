The problem of occlusion significantly affects the accuracy of face alignment. Current solutions focus on annotating occlusion data, boundary estimation, and deeper models to improve neural network robustness. However, under extreme occlusion conditions (occlusion of over 50%), models still perform poorly due to the lack of facial context information. This paper suggests that using neural networks to model facial hierarchies is a more effective approach to handle extreme occlusion. Surprisingly, there has been limited research on representing facial hierarchies using neural networks. To address this gap, a new network architecture called GlomFace is proposed. GlomFace is divided into two modules: the part-whole hierarchical module and the whole-part hierarchical module. The former captures the hierarchical dependencies of facial parts to suppress occlusion information, while the latter incorporates structural reasoning by establishing hierarchical relations among facial parts. GlomFace has a clear topological interpretation as it corresponds to facial hierarchies. Extensive experiments show that GlomFace performs comparably to existing state-of-the-art methods, especially in cases of extreme occlusion. The models can be found at https://github.com/zhuccly/GlomFace-Face-Alignment.