Object tracking is an important aspect of computer vision, with separate communities focusing on Single Object Tracking (SOT) and Multiple Object Tracking (MOT). However, current methods in one scenario are not easily adaptable to the other due to differences in training datasets and tracking objects. Although UniTrack has shown that a shared appearance model with multiple heads can address individual tracking tasks, it does not effectively utilize large-scale tracking datasets for training and performs poorly in single object tracking. In this study, we introduce the Unified Transformer Tracker (UTT), which addresses tracking problems in different scenarios using a single paradigm. Our UTT incorporates a track transformer that exploits the correlation between the target feature and the tracking frame feature to localize the target in both SOT and MOT. We demonstrate that our framework can solve both SOT and MOT tasks and can be trained end-to-end by optimizing the objectives of both tasks on individual datasets. Extensive experiments on various benchmarks validate the effectiveness of our unified model trained on both SOT and MOT datasets.