Pansharpening is a technique used to combine a high-resolution panchromatic image (PAN) with a low-resolution hyperspectral image (LR-HSI) in order to create an enhanced HSI with improved spatial and spectral resolution. However, existing pansharpening methods do not utilize an attention mechanism to effectively transfer high-resolution texture features from PAN to LR-HSI features, resulting in distortions in both spatial and spectral aspects.   In this study, we propose a new attention mechanism called HyperTransformer for pansharpening. HyperTransformer treats the features of LR-HSI and PAN as queries and keys, respectively, within a transformer framework. The HyperTransformer model consists of three main modules: separate feature extractors for PAN and HSI, a multi-head feature soft-attention module, and a spatial-spectral feature fusion module. This architecture enables the network to capture cross-feature space dependencies and long-range details from both PAN and LR-HSI, leading to improvements in both spatial and spectral quality measures of the pansharpened HSI. Additionally, HyperTransformer can be applied across multiple spatial scales to further enhance its performance.  Extensive experiments were conducted on three widely used datasets to evaluate the performance of HyperTransformer. The results demonstrate that our proposed method achieves significant improvements over state-of-the-art techniques in terms of both spatial and spectral quality measures. The implementation code and pre-trained weights of HyperTransformer are accessible at https://github.com/wgcban/HyperTransformer.