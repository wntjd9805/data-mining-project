We propose a method called ActiveZero that combines the strengths of simulation and real-world data to improve depth estimation for stereovision systems. Our approach eliminates the need for real-world depth annotation. We demonstrate the transferability of our method to out-of-distribution real data through a mixed domain learning strategy. In the simulation domain, we use supervised disparity loss and self-supervised losses on a shape primitives dataset. In the real domain, we only use self-supervised losses on a dataset that is different from both the training simulation data and the test real data. Additionally, we introduce a new self-supervised loss called temporal IR reprojection to enhance the accuracy of our reprojections in challenging regions. Our method can be trained end-to-end, and each module plays a crucial role in achieving the final results. Extensive evaluations on real data show that our approach outperforms even a commercial depth sensor. The code for ActiveZero is available at: https://github.com/haosulab/active_zero.