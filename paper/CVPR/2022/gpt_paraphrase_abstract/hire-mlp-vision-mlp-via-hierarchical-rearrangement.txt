This paper introduces Hire-MLP, a vision MLP architecture that addresses the limitations of previous MLP models such as MLP-Mixer and ResMLP. These models take linearly flattened image patches as input, making them inflexible for different input sizes and unable to capture spatial information effectively. This hinders MLPs from achieving comparable performance to transformer-based models and limits their potential as a general backbone for computer vision. Hire-MLP overcomes these issues through hierarchical rearrangement, which involves two levels of rearrangements. The inner-region rearrangement captures local information within a spatial region, while the cross-region rearrangement enables communication between different regions and captures global context by circularly shifting all tokens along spatial directions. Extensive experiments demonstrate the versatility of Hire-MLP as a backbone for various vision tasks. It achieves competitive results in image classification, object detection, and semantic segmentation, surpassing previous transformer-based and MLP-based models in terms of accuracy and throughput trade-off. For instance, it achieves 83.8% top-1 accuracy on ImageNet, 51.7% box AP and 44.8% mask AP on COCO val2017, and 49.9% mIoU on ADE20K.