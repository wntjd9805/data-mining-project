This paper introduces an End-to-End framework called E2FGVI for Flow-Guided Video Inpainting. Previous methods in video inpainting rely on hand-crafted flow-based processes applied separately, resulting in less efficiency and heavy reliance on intermediate results. E2FGVI overcomes these limitations by incorporating three trainable modules: flow completion, feature propagation, and content hallucination. These modules correspond to the three stages of previous methods but can be jointly optimized, leading to a more efficient and effective inpainting process. Experimental results show that E2FGVI outperforms state-of-the-art methods in terms of quality and quantity, demonstrating promising efficiency. The code for E2FGVI is available at https://github.com/MCG-NKU/E2FGVI.