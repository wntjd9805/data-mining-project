We propose a novel approach called Occluded Human Mesh Recovery (OCHMR) to overcome the limitations of top-down methods for monocular human mesh recovery. These methods typically assume a single-human scenario and struggle to accurately recover 3D human meshes when there is severe person-person occlusion. OCHMR incorporates image spatial context to address this issue by conditioning the top-down model on body-center heatmaps. We introduce Contextual Normalization (CoNorm) blocks to enable adaptive modulation of intermediate features, allowing our model to distinguish between overlapping human bounding-boxes and improve performance in multi-person occlusion scenarios. Our approach achieves superior results compared to state-of-the-art methods on challenging multi-person benchmarks such as 3DPW, CrowdPose, and OCHuman. Specifically, when applied to the SPIN model with a ResNet-50 backbone, our contextual reasoning architecture improves performance by 6.9 mm on 3DPW-PC, 6.4 AP on CrowdPose, and 20.8 AP on OCHuman datasets.