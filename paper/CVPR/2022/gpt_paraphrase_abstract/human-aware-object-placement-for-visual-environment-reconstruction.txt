Humans constantly interact with and navigate through their environment, providing valuable information for understanding 3D scenes and human-scene interactions (HSIs). This paper proposes leveraging HSIs to enhance the 3D reconstruction of scenes from monocular RGB videos. The approach involves accumulating HSIs from multiple input images as a person moves and interacts with the scene, optimizing the 3D scene layout to ensure consistency and physical plausibility. The optimization-based method utilizes three types of HSI constraints: (1) depth ordering constraints imposed by occlusions between humans and objects, (2) constraints on humans moving through free space without intersecting objects, and (3) constraints on the spatial alignment of contact surfaces between humans and objects. By incorporating these constraints into the optimization process, the accuracy of 3D scene layout reconstruction is significantly improved. Additionally, the reconstructed scene can be used to refine the initial estimation of 3D human pose and shape (HPS). The proposed method is evaluated qualitatively and quantitatively using the PROX and PiGraphs datasets. The code and data are publicly available for research purposes at https://mover.is.tue.mpg.de.