We present TubeDETR, a transformer-based architecture designed to solve the problem of localizing a spatio-temporal tube in a video based on a given text query. This task is difficult due to the need to consider temporal, spatial, and multi-modal interactions simultaneously. Our model incorporates an efficient video and text encoder that captures spatial multi-modal interactions across sparsely sampled frames. Additionally, we introduce a space-time decoder that performs joint spatio-temporal localization. Through extensive experimentation, we demonstrate the effectiveness of our proposed components. Our approach outperforms the state of the art on challenging benchmarks, VidSTG and HC-STVG, for the spatio-temporal video grounding task.