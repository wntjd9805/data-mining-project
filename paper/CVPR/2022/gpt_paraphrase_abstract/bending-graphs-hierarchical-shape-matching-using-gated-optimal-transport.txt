Shape matching is a well-studied problem in computer graphics and vision, aiming to establish a dense correspondence between deformed meshes. Existing approaches either focus on local descriptions of sampled points or utilize global shape information to find correspondences. In this research, we explore a hierarchical learning framework that incorporates both local patch-level information and global shape-level structures. This flexible representation allows for accurate correspondence prediction and offers comprehensive features for the matching process. Additionally, we propose a new optimal transport solver that recurrently updates features on non-confident nodes to achieve globally consistent correspondences between shapes. Our experiments on publicly available datasets demonstrate the robust performance of our method, even in the presence of significant deformations, without requiring extensive training or refinement.