This paper presents a new framework called OVE6D for estimating the 6D pose of objects from a single depth image and a target object mask. The framework is trained using synthetic data from ShapeNet and is able to generalize well to new real-world objects without the need for fine-tuning. The 6D pose is decomposed into viewpoint, in-plane rotation, and translation, and novel lightweight modules are introduced to estimate each component in a cascaded manner. The resulting network has less than 4M parameters and achieves excellent performance on challenging datasets without specific training. OVE6D outperforms deep learning-based pose estimation methods trained on individual objects or datasets with real-world training data. The implementation is available at https://github.com/dingdingcai/OVE6D-pose.