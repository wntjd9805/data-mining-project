The recent development of cost volume pyramid based deep neural networks has allowed for efficient utilization of high-resolution images in depth estimation from multi-view stereo. However, existing approaches assume that each pixel's depth follows a unimodal distribution, which leads to inaccurate depth predictions for boundary pixels that have multi-modal distributions. To address this limitation, we propose a method that constructs the cost volume using non-parametric depth distribution modeling, allowing for both unimodal and multi-modal distributions. Our approach generates multiple depth hypotheses at the coarser level to prevent errors in the early stage, and performs local search around these hypotheses in subsequent levels. This allows for flexible depth spatial ordering, and we introduce a sparse cost aggregation network to extract information from each volume. We evaluate our approach on the DTU and Tanks & Temples benchmark datasets, and our experimental results demonstrate significant improvements over existing methods, particularly in boundary regions.