Depth estimation from single images is a challenging task in monoc-ular 3D object detection (M3OD) due to its inherent ill-posed nature. Existing methods rely on assumptions to fill in the missing spatial information in monocular images and predict a single depth value for each object of interest. However, these assumptions do not always hold in practical applications. To address this issue, we propose a depth solving system that leverages visual clues from various subtasks in M3OD and generates multiple depth estimations for each target. These estimations are based on different assumptions and therefore exhibit diverse distributions. Even if some assumptions fail, the estimations based on the remaining assumptions remain reliable. We also develop a strategy for selecting and combining the depth estimations. This strategy eliminates abnormal estimations caused by failed assumptions and intelligently combines the remaining estimations into a single one. By exploiting clues from multiple M3OD subtasks and without introducing any additional information, our method outperforms the current state-of-the-art by over 20% on the Moderate level of the KITTI 3D object detection benchmark, while maintaining real-time efficiency.