The reconstruction of hand-object state and understanding of interaction affordances are enhanced by physical contact. However, estimating occluded regions from monocular images poses a significant challenge. Current methods rely on distance thresholds or prior information from contact-labeled datasets, but these patterns are not easily generalized due to limited subject and object variations in indoor datasets. Our approach involves reconstructing contact patterns directly from monocular images and optimizing them using a physical stability criterion in simulation. This criterion is based on resultant forces and contact distribution computed by a physics engine. Our framework can adapt to personalized hands and diverse object shapes, unlike existing solutions. We also create an interaction dataset with additional physical attributes to ensure the consistency of our methods in both simulation and real-world scenarios. Through comprehensive evaluations, we demonstrate that our framework accurately and stably reconstructs hand-object contact.