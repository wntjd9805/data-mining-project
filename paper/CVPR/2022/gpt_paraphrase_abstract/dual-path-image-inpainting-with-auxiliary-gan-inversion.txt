Deep image inpainting techniques have been successful in filling in missing parts of corrupted images using feed-forward inference. However, they struggle when it comes to handling large missing areas or complex semantic information. A recent approach to address these challenges is the use of GAN inversion-based inpainting methods, which utilize the semantic information from pretrained generators like StyleGAN. Unlike feed-forward methods, these approaches aim to find the closest latent code to the corrupted image and input it into the pretrained generator. However, inferring the latent code is either time-consuming or inaccurate. To overcome these limitations, this paper introduces a dual-path inpainting network that incorporates both an inversion path and a feed-forward path. The inversion path provides auxiliary information to assist the feed-forward path. Additionally, a novel deformable fusion module is designed to align the feature maps in both paths. Experimental results on FFHQ and LSUN datasets demonstrate that our proposed method effectively addresses the aforementioned challenges and produces more realistic results compared to state-of-the-art methods.