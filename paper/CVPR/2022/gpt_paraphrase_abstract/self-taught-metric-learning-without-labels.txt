We introduce a new self-taught framework for unsupervised metric learning. This framework involves predicting class-equivalence relations between data using an embedding model and then using these predicted relations as pseudo labels to train the model. Our framework utilizes an algorithm that examines the contexts of data in the embedding space to predict their class-equivalence relations. This algorithm allows for efficient end-to-end training without requiring an external module for pseudo labeling. The class-equivalence relations provide valuable supervisory signals for learning the embedding space. In comparison to existing unsupervised learning methods, our framework consistently outperforms them on standard benchmarks for metric learning. In some cases, it even surpasses supervised learning models that use the same backbone network. Furthermore, we apply our framework to semi-supervised metric learning to leverage additional unlabeled data, resulting in state-of-the-art performance by significantly improving supervised learning outcomes.