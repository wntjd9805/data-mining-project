We introduce a novel method for learning dynamic 3D deformations of garments on human bodies without the need for ground-truth samples. Existing approaches rely on supervised training with large datasets obtained through expensive physics-based simulations or professional multi-camera setups. Our method employs an optimization-based approach to model physics-based deformation, allowing us to formulate loss terms that can train neural networks without relying on precomputed ground-truth data. This enables us to learn models for interactive garments, including dynamic deformations and fine wrinkles, with significantly faster training times compared to current supervised methods.