Optimization-based meta-learning shows promise for few-shot learning in computer vision applications. However, learning from few samples introduces uncertainty, and it is crucial to quantify model confidence for accurate predictions. Additionally, randomly sampling few-shot tasks for meta-training leads to high labeling costs and computational overhead. To address these challenges, we propose an innovative task selection model that considers uncertainty. This model formulates a multidimensional belief measure to quantify both known and unknown uncertainties for a given task. Our theoretical result establishes a relationship between conflicting and incorrect beliefs, allowing us to estimate the total uncertainty of a task. This estimation provides a principled criterion for task selection. Moreover, we introduce a novel multi-query task formulation to enhance the computational and labeling efficiency of meta-learning. Experimental results on real-world few-shot image classification tasks demonstrate the effectiveness of our proposed model.