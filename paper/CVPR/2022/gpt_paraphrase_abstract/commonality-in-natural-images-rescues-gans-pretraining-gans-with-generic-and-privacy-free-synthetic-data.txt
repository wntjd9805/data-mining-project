Transfer learning has been successful in improving the performance of Generative Adversarial Networks (GANs) in scenarios with limited training data. However, previous studies have shown that pretrained models using a single benchmark dataset do not generalize well to different target datasets. Additionally, these pretrained models can be susceptible to copyright or privacy risks due to membership inference attacks. To address these issues, we propose an unbiased and effective data synthesizer called Primitives-PS, which is inspired by the generic characteristics of natural images. Our synthesizer considers the generic statistics of the frequency magnitude spectrum, the representation of structure information through elementary shapes, and the existence of saliency as a prior. By focusing on the generic properties of natural images, our single pretrained model can consistently transfer to various target datasets and even outperform previous methods pretrained with natural images in terms of Fr√©chet inception distance. Extensive analysis, ablation studies, and evaluations confirm the effectiveness of each component in our data synthesizer and provide insights into the desirable nature of pretrained models for the transferability of GANs.