The objective of self-supervised learning is to learn image feature representations without the need for manually annotated labels. It is commonly used as a preliminary step to obtain initial network weights that enhance the speed and performance of downstream tasks. While self-supervision helps bridge the gap between supervised and unsupervised learning without labels, it still requires a strong bias towards downstream tasks for effective transfer learning. This study introduces a self-supervision method called MATTER, which is based on material and texture representation learning. Inspired by classical material and texture methods, MATTER effectively describes surfaces, including tactile properties, color, and specularity. By extension, it can also describe other semantic classes associated with these materials and textures. MATTER utilizes multi-temporal, spatially aligned remote sensing imagery of unchanged regions to learn invariance to illumination and viewing angle, ensuring consistency in material and texture representation. The results demonstrate that our self-supervision pre-training method leads to significant performance improvements of up to 24.22% and 6.33% in unsupervised and fine-tuned setups, respectively. Additionally, it enables up to 76% faster convergence in change detection, land cover classification, and semantic segmentation tasks. The code and dataset for MATTER are available at https://github.com/periakiva/MATTER.