Unsupervised image-to-image (I2I) translation is a technique used to learn a function that can convert images from one domain to another without the need for paired data. However, current methods that rely on matching the distributions of the source and target domains often result in a mismatch of the underlying semantics, leading to inconsistencies between the input and translated images. This is known as the semantics distortion problem. This paper focuses on low-level I2I translation, where image structure is closely related to semantics. To address the issue of semantic distortions in this type of translation without paired supervision, the authors propose a new constraint called the Structure Consistency Constraint (SCC). The SCC aims to promote consistency in image structures by reducing the randomness of color transformation during the translation process. To facilitate the estimation and maximization of the SCC, the authors introduce a new approximate representation of mutual information called relative Squared-loss Mutual Information (rSMI), which has efficient analytic solutions. The SCC can be easily incorporated into existing translation models. Through quantitative and qualitative comparisons on various low-level I2I translation tasks, the authors demonstrate that translation models with the SCC outperform the original models significantly with minimal additional computational and memory costs.