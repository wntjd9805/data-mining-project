This study explores the issue of object discovery, which involves separating objects from the background without the use of manual labels. Existing methods rely on appearance cues, like color, texture, and location, to group pixels into regions resembling objects. However, these approaches struggle to accurately distinguish objects from the background in complex scenes with clutter. This limitation arises because the definition of an object is inherently ambiguous and context-dependent. To address this ambiguity, the focus of this study is on dynamic objects, which are entities capable of independent movement in the environment. The study adapts recent auto-encoder based frameworks for unsupervised object discovery, originally designed for simpler synthetic images, to complex real-world scenes. To achieve this, the architecture of the frameworks is simplified, and the resulting model is enhanced with a weak learning signal obtained from general motion segmentation algorithms. Experimental results indicate that despite capturing only a small subset of moving objects, this signal is sufficient to generalize and segment both moving and static instances of dynamic objects. The scalability of the model is demonstrated through its application to a newly collected synthetic dataset featuring photo-realistic street driving scenarios. The dataset includes ground truth segmentation and flow annotations, enabling comprehensive evaluation and analysis. Moreover, experiments conducted on the real-world KITTI benchmark reveal that the proposed approach outperforms both heuristic- and learning-based methods by effectively utilizing motion cues.