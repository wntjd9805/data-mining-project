The challenge of learning a distinct, understandable, and organized hidden representation in 3D generative models for faces and bodies remains unresolved. This issue becomes more pronounced when precise control over identity features is necessary. In this study, we introduce a straightforward yet effective self-supervised technique for training a 3D shape variational autoencoder (VAE) that promotes a disentangled hidden representation of identity features. By swapping arbitrary features among different shapes during the creation of mini-batches, we define a loss function that takes advantage of known differences and similarities in the hidden representations. Our experimental results, conducted on 3D meshes, demonstrate that current state-of-the-art methods for disentangling hidden representations are unsuccessful in separating identity features of faces and bodies. In contrast, our proposed approach successfully separates the generation of such features while maintaining strong representation and reconstruction capabilities. The code and pre-trained models for our method are accessible at github.com/simofoti/3DVAE-SwapDisentangled.