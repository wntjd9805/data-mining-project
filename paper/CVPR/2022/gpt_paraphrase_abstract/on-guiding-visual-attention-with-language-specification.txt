Most visual classification methods use numerical indices to define categories, but real world challenges often use language words or phrases. Language specification of classes can be helpful for biased and noisy datasets by clarifying task-relevant features. While multimodal models can recognize concepts from language specifications alone, they struggle with fine-grained tasks. On the other hand, CNNs can extract subtle image features for fine-grained discrimination but are prone to overfitting biases and noise. Our approach is to use language specification to guide the classification evidence towards task-relevant features and away from distractors. We achieve this by grounding task-relevant words or phrases using attention maps from a pretrained model and using this grounding to supervise the spatial attention of a classifier, thus reducing the influence of distracting context. Our experiments show that this method improves performance on classification tasks with biased and noisy data, resulting in significant accuracy and fairness improvements.