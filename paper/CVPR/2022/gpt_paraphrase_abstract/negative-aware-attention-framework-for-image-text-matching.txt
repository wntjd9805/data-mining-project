Image-text matching is an important task that connects visual and linguistic information. Previous approaches focused on measuring similarity based on matching fragments, while neglecting the impact of mismatched fragments. This study argues that mismatched textual fragments, which contain valuable mismatching clues, are crucial for image-text matching. To address this, a new framework called Negative-Aware Attention Framework (NAAF) is proposed. NAAF utilizes both the positive effect of matched fragments and the negative effect of mismatched fragments to determine image-text similarity. It incorporates an iterative optimization method to maximize the exploitation of mismatched fragments, enhancing the discriminative and robust negative effects. Additionally, NAAF employs a two-branch matching mechanism to accurately calculate the degrees of similarity/dissimilarity for matched and mismatched fragments with different masks. Experimental results on the Flickr30K and MSCOCO datasets demonstrate that NAAF outperforms existing methods, achieving state-of-the-art performance. The code for NAAF is available at: https://github.com/CrossmodalGroup/NAAF.