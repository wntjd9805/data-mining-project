Transformers are introduced in this paper to improve weakly-supervised semantic segmentation (WSSS) with image-level labels. Current methods based on convolutional neural networks do not properly utilize global information, leading to incomplete object regions. To address this, the authors propose an Affinity from Attention (AFA) module that learns semantic affinity from the multi-head self-attention in Transformers. This learned affinity is then used to refine initial pseudo labels for segmentation. Additionally, a Pixel-Adaptive Refinement module is devised to incorporate low-level image appearance information and ensure local consistency of pseudo labels. Experimental results show that the proposed method outperforms recent end-to-end methods and multi-stage competitors on the PASCAL VOC 2012 and MS COCO 2014 datasets, achieving mIoU scores of 66.0% and 38.9% respectively. The code for the proposed method is available at https://github.com/ rulixiang/afa.