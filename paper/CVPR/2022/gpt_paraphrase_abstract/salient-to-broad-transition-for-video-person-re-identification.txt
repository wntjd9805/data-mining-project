The mainstream methods for video re-identification (re-id) lack the use of temporal relations, resulting in partial and similar frame-level attention regions. To overcome this issue, we propose a Salient-to-Broad Module (SBM) that gradually enlarges the attention regions. In this module, earlier frames focus on salient regions while later frames focus on broader regions. By incorporating additional information from the broader regions, we can enhance the video-level representations. To further improve SBM, we introduce an Integration-and-Distribution Module (IDM) that enhances frame-level representations. IDM integrates features from the entire feature space and distributes them to each spatial location. SBM and IDM complement each other as they enhance video-level and frame-level representations, respectively. Our method is evaluated on four popular benchmarks and demonstrates its effectiveness and superiority. The source code is available at https://github.com/baist/SINet.