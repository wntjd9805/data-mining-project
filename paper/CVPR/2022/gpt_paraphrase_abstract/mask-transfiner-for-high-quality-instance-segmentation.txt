We introduce Mask Transfiner, a novel approach for high-quality and efficient instance segmentation. While existing methods have achieved impressive results, the segmented masks they produce are still relatively coarse. In contrast, Mask Transfiner decomposes the image regions into a quadtree representation instead of dense tensors, enabling more precise segmentation. By utilizing a transformer-based approach, our method focuses on processing error-prone tree nodes and correcting their errors concurrently. Although these sparse pixels make up a small portion of the total, they play a crucial role in improving the final mask quality. As a result, Mask Transfiner can accurately predict instance masks while maintaining low computational cost. Through extensive experiments, we demonstrate that our approach surpasses current instance segmentation methods on three widely used benchmarks, achieving significant improvements in both two-stage and query-based frameworks. Specifically, we achieve a +3.0 mask AP increase on COCO and BDD100K datasets, as well as a +6.6 boundary AP increase on Cityscapes. We provide our code and trained models at https://github.com/SysCV/transfiner.