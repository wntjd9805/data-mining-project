We present a unified framework for enhancing blurry videos caused by slow shutter speed and long exposure time in frame-based cameras. Our approach combines event-based motion deblurring and frame interpolation to minimize motion blur and predict intermediate frames. We use a learnable double integral network to predict the mapping relationship between blurry frames and sharp latent images. A fusion network is then used to refine the results by incorporating information from consecutive blurry inputs and concurrent events. To train the network, we propose a self-supervised learning framework that exploits the mutual constraints among blurry frames, latent images, and event streams using real-world blurry videos and events. Extensive experiments show that our method outperforms state-of-the-art approaches on synthetic and real-world datasets. The code is available at https://github.com/XiangZ-0/EVDI.