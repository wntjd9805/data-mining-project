The estimation of 3D hand mesh is difficult when hands are occluded by objects. Previous methods have ignored information from occluded regions, but we believe that these regions have strong correlations with hands and can provide valuable information for accurate 3D hand mesh estimation. In this study, we introduce a new network called HandOccNet, which effectively utilizes information from occluded regions to enhance image features. We propose two Transformer-based modules, namely feature injecting transformer (FIT) and self-enhancing transformer (SET), to achieve this. FIT injects hand information into occluded regions by considering their correlation, while SET further refines the output of FIT using a self-attention mechanism. By incorporating hand information into occluded regions, HandOccNet achieves state-of-the-art performance on challenging 3D hand mesh benchmarks with hand-object occlusions. The source code for HandOccNet can be found at the following GitHub repository: https://github.com/namepllet/HandOccNet.