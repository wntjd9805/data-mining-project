Generating annotations for large training sets can be costly, particularly in domains that require domain knowledge, like behavior analysis. Weak supervision has been explored as a means to reduce annotation expenses by incorporating weak labels from task-specific labeling functions (LFs) to supplement ground truth labels. However, this approach still necessitates the manual creation of various LFs for different tasks, which limits scalability. To minimize the burden on domain experts, we introduce AutoSWAP: a framework that automatically synthesizes data-efficient task-level LFs. Our approach revolves around efficiently representing expert knowledge in a reusable domain-specific language and broader domain-level LFs. We employ state-of-the-art program synthesis techniques and a small labeled dataset to generate task-level LFs. Furthermore, we propose a novel structural diversity cost that enables the synthesis of diverse sets of LFs, enhancing the performance of AutoSWAP. We assess the effectiveness of AutoSWAP in three behavior analysis domains and demonstrate that it outperforms existing methods while utilizing only a fraction of the data. Our findings indicate that AutoSWAP is a valuable tool for automatically generating LFs and significantly reducing the expert effort required for behavior analysis.