In this paper, we address the limitations of single image depth estimation (SIDE) models in accurately capturing isolated holes in objects and boundary regions. We propose a novel approach called mask-guided depth refinement, which utilizes a generic mask to improve the depth prediction of SIDE models. Our framework involves layered refinement and inpainting/outpainting, where the depth map is decomposed into two layers based on the mask and inverse mask. Since datasets with depth and mask annotations are scarce, we introduce a self-supervised learning scheme that leverages arbitrary masks and RGB-D datasets. Our empirical results demonstrate the robustness of our method to different types of masks and initial depth predictions, effectively refining depth values in inner and outer mask boundary regions. We also conduct an ablation study to analyze our model and provide real application results. For more details, please refer to our project page.