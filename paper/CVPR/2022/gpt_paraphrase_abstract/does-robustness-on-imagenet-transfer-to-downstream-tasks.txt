Concerns about robust accuracy under distributional shifts have grown as clean ImageNet accuracy approaches its limit. While methods to make neural networks more robust have been proposed, they often focus on models trained on ImageNet classification. However, ImageNet pretrained backbones are commonly used for object detection, semantic segmentation, and image classification in different domains. This raises the question of whether robust image classifiers can transfer their robustness to downstream tasks. In the case of object detection and semantic segmentation, a vanilla Swin Transformer performs better in transferring robustness compared to Convolutional Neural Networks trained to be robust to corrupted versions of ImageNet. However, for CIFAR10 classification, models that are robustified for ImageNet do not maintain their robustness when fully fine-tuned. These findings suggest that current robustification techniques prioritize ImageNet evaluations and that network architecture plays a significant role in robustness during transfer learning.