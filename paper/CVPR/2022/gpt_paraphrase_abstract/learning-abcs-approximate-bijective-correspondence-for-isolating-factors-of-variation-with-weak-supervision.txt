We propose a new algorithm that uses a weak form of supervision to learn representations in deep learning applications. The data is divided into sets based on common factors of variation that do not change within each set. Our insight is that by comparing elements from different sets, we can learn strong representations that exclude the inactive factors of variation and focus on the active factors that vary across all sets. This allows us to use a combination of supervised and unsupervised data, even from different domains. We apply our method to the problem of transferring object pose from synthetic to real images without pose annotations. We isolate pose information that can generalize across categories and the synthetic/real domain gap. Additionally, our method improves performance in supervised settings by strengthening intermediate representations and can be applied to scenarios with limited quantities of set-supervised natural images. The accompanying code can be found on github.