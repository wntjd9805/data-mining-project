Label-to-image translation models currently rely on a large number of annotated samples to generate images from semantic label maps. However, when presented with new training samples that have annotations for novel semantic classes, these models must be trained from scratch, including both previously learned and new classes. This limitation hampers their practical use and has motivated us to develop an incremental learning strategy for label-to-image translation.In this paper, we propose a few-shot incremental learning approach for label-to-image translation. Our method learns new classes one by one using only a few samples of each class. To achieve this, we introduce semantically-adaptive convolution filters and normalization techniques. When incrementally trained on a novel semantic class, the model only learns a small number of additional parameters specific to that class, thus preventing catastrophic forgetting of previously learned semantic classes. This design enables the translation of label-to-image scenes with increasingly rich content.To facilitate few-shot learning, we also propose a modulation transfer strategy for improved initialization. Through extensive experiments, we demonstrate that our method outperforms existing approaches in most cases and achieves zero forgetting, meaning that previously learned information is retained during incremental learning.