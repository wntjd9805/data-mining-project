This paper presents a method for developing a comprehensive and versatile object detection system. The approach involves utilizing all labels from various annotated datasets, even if they have inconsistent taxonomies. The researchers propose a straightforward technique for training a unified detector using multiple large-scale datasets. While each dataset has its specific training protocols and losses, they share a common detection architecture with dataset-specific outputs. The paper demonstrates how these dataset-specific outputs can be automatically integrated into a shared semantic taxonomy without the need for manual reconciliation. The experiments conducted show that the learned taxonomy outperforms an expert-designed taxonomy across all datasets. The multi-dataset detector performs equally well as dataset-specific models within each training domain and can effectively generalize to new, unseen datasets without requiring fine-tuning. The code for this system is available at https://github.com/xingyizhou/UniDet.