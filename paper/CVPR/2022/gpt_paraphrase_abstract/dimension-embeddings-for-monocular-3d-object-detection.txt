Most current deep learning approaches for detecting 3D objects using a single camera overlook the importance of accurately estimating the dimensions of objects. This paper presents a general method for learning suitable embeddings to estimate dimensions in monocular 3D object detection. The method considers two key factors: constraining the pairwise distance between embeddings to reflect the similarity of corresponding dimensions and learning representative shape templates in the embedding space. By using an attention mechanism, each object can interact with the templates and obtain initial estimates for dimensions, which are further refined using combined features from the object and templates. Experimental results on the KITTI dataset show that the proposed method improves dimension estimation without significant additional computation. The method achieves state-of-the-art performance on the KITTI 3D object detection benchmark.