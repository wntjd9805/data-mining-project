Rendering articulated objects while controlling their poses is crucial for virtual reality and animation applications. However, manipulating the pose of an object necessitates an understanding of its underlying structure, including its joints and their interactions. Existing methods assume prior knowledge of the structure, limiting their applicability to new object categories. In this study, we propose a novel approach to learn the appearance and structure of previously unseen articulated objects without any supervision or information about their joints. We exploit the observation that static 3D points relative to each other should belong to the same part, while adjacent parts that move relative to each other must be connected by a joint. To leverage this insight, we represent object parts as ellipsoids in 3D, enabling us to identify joints. Our approach combines explicit and implicit representations to compensate for approximation. We demonstrate the effectiveness of our method on various structures, including quadrupeds, single-arm robots, and humans. The source code is available at https://github.com/NVlabs/watch-it-move, and an animated version of this manuscript can be found at https://arxiv.org/abs/2112.11347.