This work presents the vulnerability of vision transformers (ViTs) to gradient-based inversion attacks. The researchers introduce a method called GradViT, which utilizes an iterative process to optimize random noise into visually realistic images. The optimization objective comprises matching the gradients, incorporating image prior based on batch-normalization statistics of a pretrained CNN model, and applying total variation regularization on patches to guide accurate recovery locations. To overcome local minima, a unique loss scheduling function is proposed. The effectiveness of GradViT is evaluated on ImageNet1K and MS-Celeb-1M datasets, showcasing unprecedented fidelity and similarity to the original data. The study reveals that vision transformers are more susceptible to attacks compared to CNNs due to the attention mechanism. GradViT achieves state-of-the-art results in both qualitative and quantitative assessments. Further details can be found on the project page at https://gradvit.github.io/.