The goal of human parsing is to divide an image of a human into its constituent parts. To achieve this, each pixel in the image needs to be labeled according to its corresponding body part. Since the human body is made up of parts that are hierarchically structured, each body part may have a distinct position distribution. For example, a human head is unlikely to be located below the feet, while arms are more likely to be near the torso. Taking this into account, we create instance class distributions by accumulating the original human parsing labels in both horizontal and vertical directions. These distributions serve as supervision signals to guide the network in exploiting the inherent position distribution of each class. We combine these guided features to create a spatial guidance map, which is then integrated into the baseline network through multiplication and concatenation. This allows for precise differentiation of the human parts. We conducted extensive experiments on three well-known benchmarks (LIP, ATR, and CIHP databases) to demonstrate the effectiveness and superiority of our approach.