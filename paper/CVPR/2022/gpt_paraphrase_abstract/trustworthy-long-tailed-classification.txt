Classification on long-tailed distributed data poses challenges due to class-imbalance, resulting in poor performance for tail classes. Ensembling based methods have shown promising results, but they have limitations. Firstly, their predictions are unreliable for failure-sensitive applications, especially for tail classes. Secondly, they assign the same number of experts to all samples, which is unnecessary and computationally expensive for easy samples. To address these issues, we propose Trustworthy Long-tailed Classification (TLC), a method that combines classification and uncertainty estimation in a multi-expert framework. TLC utilizes evidence-based uncertainty and evidence for each expert and combines them using the Dempster-Shafer Evidence Theory (DST). Additionally, we introduce dynamic expert engagement to reduce the number of engaged experts for easy samples, improving efficiency without compromising performance. We evaluate TLC through comprehensive experiments on classification, tail detection, out-of-distribution (OOD) detection, and failure prediction tasks. The results demonstrate that TLC outperforms existing methods and provides trustworthy predictions with reliable uncertainty estimation.