This study focuses on 3D-aware image synthesis, which involves generating images of objects from multiple views using a 3D representation. However, existing approaches in this field lack geometry constraints, leading to inconsistent images. To overcome this challenge, the authors propose a novel approach called Multi-View Consistent Generative Adversarial Networks (MVCGAN). MVCGAN leverages the underlying 3D geometry information, such as depth and camera transformation matrix, to establish stereo correspondence between views and perform multi-view joint optimization. The approach enforces photometric consistency between view pairs and incorporates a stereo mixup mechanism during training to encourage the model to understand the correct 3D shape. Additionally, a two-stage training strategy with feature-level multi-view joint optimization is introduced to enhance image quality. Extensive experiments conducted on three datasets demonstrate that MVCGAN achieves state-of-the-art performance in 3D-aware image synthesis.