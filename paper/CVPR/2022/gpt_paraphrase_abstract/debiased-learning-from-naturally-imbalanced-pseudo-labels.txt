Pseudo-labels are confident predictions made by a classifier on unlabeled target data using labeled source data. These labels are commonly used to adapt a model to unlabeled data in semi-supervised learning. However, we have discovered that pseudo-labels are inherently imbalanced due to the similarity of the data, even when the model is trained on balanced source data and evaluated on balanced target data. This imbalance creates biases in the model towards false majorities. To address this problem, we propose a new debiased learning method that uses counterfactual reasoning and adaptive margins. Counterfactual reasoning removes the classifier's response bias, while adaptive margins adjust the margin of each class based on the imbalance of pseudo-labels. Through extensive experimentation, we have found that our simple debiased learning approach significantly improves accuracy compared to the current state-of-the-art methods, achieving a 26% increase in semi-supervised learning with 0.2% annotations and a 9% increase in zero-shot learning on the ImageNet-1K dataset. Our code can be accessed at: https://github.com/frank-xwang/debiased-pseudo-labeling.