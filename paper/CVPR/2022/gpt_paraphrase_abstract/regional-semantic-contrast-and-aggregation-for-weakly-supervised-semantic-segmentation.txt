Learning semantic segmentation from weakly-labeled data, such as image tags, is challenging because it is difficult to infer detailed object regions from sparse semantic information. Current approaches often rely on limited semantic annotations from individual images or pairs of images, resulting in incomplete localization maps. In this study, we address this issue by leveraging the rich semantic contexts present in abundant weakly-labeled training data. We introduce a method called regional semantic contrast and aggregation (RCA), which incorporates a regional memory bank to store diverse object patterns observed in the training data. This memory bank serves as a strong support for exploring the dataset-level semantic structure. Specifically, we propose two components: semantic contrast, which enhances network learning by contrasting categorical object regions and facilitating a holistic understanding of object patterns, and semantic aggregation, which gathers diverse relational contexts from the memory bank to enrich semantic representations. By employing RCA, we achieve a high level of fine-grained semantic understanding, resulting in state-of-the-art performance on two popular benchmarks: PASCAL VOC 2012 and COCO 2014.