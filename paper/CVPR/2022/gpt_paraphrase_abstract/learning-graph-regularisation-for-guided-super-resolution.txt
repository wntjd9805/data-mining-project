We present a new approach to guided super-resolution that utilizes a learned affinity graph and a differentiable optimization layer. By using graph potentials, we can incorporate contextual information from the guide image, ensuring accurate high-resolution results. Unlike existing methods, our approach treats the source image as a constraint rather than just an input, resulting in images that better reproduce the source when downsampled. This approach also enables the learning of edge potentials, which capture rich contextual information. Our method outperforms recent baselines in terms of quantitative reconstruction errors and produces visually sharper outputs. Additionally, it generalizes well to new datasets not seen during training.