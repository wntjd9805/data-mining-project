We present FWD, a novel view synthesis (NVS) method called FWD that addresses the challenge of generating photorealistic images from new viewpoints. While previous image-based rendering (IBR) methods are fast, they lack quality when input views are sparse. Recent approaches like Neural Radiance Fields (NeRF) produce impressive results but are not real-time. FWD, on the other hand, is a real-time NVS method that can handle sparse inputs and deliver high-quality synthesis.FWD utilizes explicit depth and differentiable rendering techniques to achieve competitive results compared to state-of-the-art methods. It offers a speedup ranging from 130 to 1000 times faster while maintaining better perceptual quality. Additionally, FWD can seamlessly incorporate sensor depth information during training or inference, further enhancing image quality without sacrificing real-time performance.Given the increasing prevalence of depth sensors, we anticipate that methods leveraging depth information will become increasingly valuable in the future.