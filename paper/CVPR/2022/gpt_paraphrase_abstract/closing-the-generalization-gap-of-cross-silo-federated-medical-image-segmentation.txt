In recent years, cross-silo federated learning (FL) has gained significant attention in the field of medical imaging analysis. This approach addresses the challenges of limited data, data privacy, and training efficiency. However, a notable issue arises due to the non-iid data distribution among participating clients, resulting in a generalization gap between FL-trained models and centrally trained models. This problem, known as client drift, undermines the effectiveness of FL. To tackle this issue, we introduce FedSM, a novel training framework that successfully mitigates client drift and reduces the generalization gap in medical image segmentation tasks. Our proposed framework incorporates a personalized FL objective formulation and a new method called SoftPull to address this challenge. We provide rigorous theoretical analysis to ensure the convergence of our framework for optimizing the non-convex smooth objective function. Additionally, we validate the efficacy of our approach through real-world medical image segmentation experiments using deep FL. These experiments confirm the motivations and effectiveness of our proposed method.