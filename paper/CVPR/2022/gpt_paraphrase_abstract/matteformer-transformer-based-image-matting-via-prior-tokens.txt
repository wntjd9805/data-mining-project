This paper presents a novel image matting model called MatteFormer, which utilizes trimap information within a transformer-based framework. The model introduces prior-tokens, representing global information for each trimap region (foreground, background, and unknown), which are incorporated into the self-attention mechanism of each transformer block. The encoder stages consist of Prior-Attentive Swin Transformer (PAST) blocks, which differ from the original Swin Transformer by including a Prior-Attentive Window Self-Attention (PA-WSA) layer that considers both spatial-tokens and prior-tokens. Additionally, the PAST blocks feature prior-memory, which accumulates prior-tokens from previous blocks and transfers them to subsequent blocks. The proposed method is evaluated on standard image matting datasets and achieves state-of-the-art performance. The code for MatteFormer is available at https://github.com/webtoon/matteformer.