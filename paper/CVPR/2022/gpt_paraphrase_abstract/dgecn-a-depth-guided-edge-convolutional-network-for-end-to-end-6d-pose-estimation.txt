Monocular 6D pose estimation is a crucial task in computer vision. Previous methods typically use a two-stage approach, involving establishing correspondences and utilizing a RANSAC algorithm to calculate the 6 degrees-of-freedom (6DoF) pose. Recent studies have attempted to achieve end-to-end 6D pose estimation by integrating differentiable RANSAC algorithms. However, these methods often overlook the geometric features in 3D space and disregard topology cues during the differentiable RANSAC algorithms. In this study, we propose a Depth-Guided Edge Convolutional Network (DGECN) for the 6D pose estimation task. Our approach focuses on three main aspects: 1) Utilizing estimated depth information to guide both the correspondence extraction process and the cascaded differentiable RANSAC algorithm by incorporating geometric information.2) Leveraging the uncertainty of the estimated depth map to enhance the accuracy and robustness of the output 6D pose.3) Introducing a differentiable Perspective-n-Point (PnP) algorithm using edge convolution to explore the topology relations between 2D-3D correspondences. Experimental results demonstrate that our proposed network surpasses current methods in terms of both effectiveness and efficiency.