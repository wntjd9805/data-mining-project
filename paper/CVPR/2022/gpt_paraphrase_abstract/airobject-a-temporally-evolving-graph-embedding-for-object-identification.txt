Object encoding and identification are crucial for various robotic tasks, including autonomous exploration, semantic scene understanding, and re-localization. Existing approaches either track objects or generate descriptors for object identification, but they are limited to fixed partial object representations from a single viewpoint. In robot exploration scenarios, there is a need for a global object representation that evolves over time as the robot observes the object from multiple viewpoints. Additionally, the object identification process must be able to handle unknown novel objects without relying on specific classes. In this study, we propose a novel approach called AirObject for temporal 3D object encoding. AirObject utilizes a graph attention-based encoding method to obtain global keypoint graph-based embeddings of objects. These embeddings are generated using a temporal convolutional network that considers structural information from multiple frames. Our experimental results demonstrate that AirObject achieves state-of-the-art performance in video object identification and is robust to challenges such as severe occlusion, perceptual aliasing, viewpoint shift, deformation, and scale transform. It outperforms existing single-frame and sequential descriptors. Notably, AirObject is one of the first methods for temporal object encoding. The source code for AirObject is available at https://github.com/Nik-V9/AirObject.