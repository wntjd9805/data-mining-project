Scene Graph Generation (SGG) has gained increasing attention among visual researchers due to the valuable structural-semantic details provided by Scene Graphs (SG). However, the usefulness of SG in downstream tasks is limited by the bias in predicate classification, which is caused by imbalanced data distribution and results in a semantic bias in the predicted relation predicates. Existing approaches focus on reducing this bias by improving context aggregation and incorporating external knowledge, but they overlook the semantic similarities between predicates. This study introduces a new approach called Predicate Probability Distribution based Loss (PPDL) to train biased SGG models and ultimately obtain unbiased Scene Graphs. The proposed method utilizes a predicate probability distribution as the semantic representation of a specific predicate class. By rebalancing the biased training loss based on the similarity between the predicted and estimated probability distributions, the long-tailed bias in predicate classification is eliminated. Importantly, the PPDL method is model-agnostic, and experiments conducted on the Visual Genome dataset demonstrate significant performance improvements, particularly for tail classes, compared to state-of-the-art methods.