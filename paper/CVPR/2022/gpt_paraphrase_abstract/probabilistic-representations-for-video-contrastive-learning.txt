This paper introduces a novel approach called Probabilistic Video Contrastive Learning, which combines contrastive learning with probabilistic representation to improve self-supervised representation learning. The authors argue that while video clips may have different distributions in terms of short-term duration, they collectively represent the complex and intricate distribution of the entire video. To capture this, the proposed method represents video clips as normal distributions and combines them into a Mixture of Gaussians, creating a model for the overall video distribution. Unlike previous deterministic methods that heavily rely on careful sampling or transformations to generate augmented views of the clips, this approach samples embeddings from the entire video distribution. This eliminates the need for intricate sample generation strategies. Additionally, the authors propose a stochastic contrastive loss function that takes into account the inherent uncertainty in raw video data, enabling proper learning of video distributions. Experimental results demonstrate that this probabilistic embedding approach achieves state-of-the-art performance in action recognition and video retrieval tasks on popular benchmarks such as UCF101 and HMDB51.