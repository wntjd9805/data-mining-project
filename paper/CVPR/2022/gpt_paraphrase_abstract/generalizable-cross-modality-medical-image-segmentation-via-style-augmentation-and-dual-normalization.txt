This paper addresses the challenge of generalizable cross-modality segmentation in medical image analysis. Specifically, the authors investigate the performance of a model trained on MR images in the source domain for directly segmenting CT images in the target domain. This task is more challenging than domain adaptation and has potential clinical applications. To tackle this problem, the authors propose a novel dual-normalization model that leverages augmented source-similar and source-dissimilar images during segmentation. The model uses a nonlinear transformation to augment these images and employs a shared backbone with independent batch normalization layers for separate normalization. Additionally, a style-based selection scheme is introduced to automatically choose the appropriate path during testing. The proposed method is evaluated on three publicly available datasets and outperforms other state-of-the-art domain generalization methods. The code for the method is available at a specified GitHub repository. The work was supported by various funding sources, and the authors are affiliated with different institutions. The abstract also includes a figure showing example slices from the BraTS dataset and a performance comparison with other methods on the Cross-center prostate segmentation task and the Cross-modality brain tumor segmentation task.