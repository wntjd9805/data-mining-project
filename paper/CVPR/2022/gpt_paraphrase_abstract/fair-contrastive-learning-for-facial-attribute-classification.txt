Learning high-quality visual representations is crucial for image classification. Recent advancements in contrastive representation learning have led to remarkable achievements. One such method, SupCon, has surpassed other approaches based on cross-entropy loss in representation learning. However, we have identified potential ethical concerns associated with supervised contrastive learning. In this paper, we conduct the first analysis of unfairness arising from this learning paradigm and propose a novel solution called Fair Supervised Contrastive Loss (FSCL) for fair visual representation learning.Inspired by the philosophy of supervised contrastive learning, FSCL aims to encourage the proximity of representations belonging to the same class while ensuring fairness by penalizing the inclusion of sensitive attribute information in the representations. Additionally, we introduce group-wise normalization to reduce disparities in intra-group compactness and inter-class separability between demographic groups, which can lead to unfair classification. Through extensive experiments on CelebA and UTK Face datasets, we demonstrate that our proposed method outperforms SupCon and other state-of-the-art techniques in terms of achieving a balance between top-1 accuracy and fairness. Furthermore, our approach proves to be robust against data bias and effectively operates in scenarios with limited supervision. The source code for our method is publicly available at https://github.com/sungho-CoolG/FSCL.