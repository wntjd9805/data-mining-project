Curating a large amount of fully annotated training data for medical image segmentation can be expensive. While weaker forms of annotation, such as scribbles, are more accessible, training segmentation models with limited supervision from scribbles is still challenging. To address this issue, we propose a new framework called CycleMix for scribble learning-based medical image segmentation. CycleMix combines mix augmentation and cycle consistency to improve performance. It uses the mixup strategy with random occlusion to incrementally and decrementally modify scribbles for supervision augmentation. Additionally, CycleMix intensifies the training objective with consistency losses to penalize inconsistent segmentation, resulting in significant improvements in performance. We evaluated the proposed method on the ACDC and MSCMRseg datasets, and it achieved impressive results, comparable to or even better than fully-supervised methods. The code and expert-made scribble annotations for the MSCMRseg dataset are publicly available at https://github.com/BWGZK/CycleMix.