This paper introduces a new approach for detecting lanes in RGB images using parametric curve-based methods. Unlike existing methods that rely on segmentation or point detection, our approach allows for a more holistic representation of lanes. To overcome optimization challenges, we propose using parametric BÃ©zier curves, which offer computational ease, stability, and flexibility in transformations. We also introduce a deformable convolution-based feature flip fusion technique to leverage the symmetry properties of lanes in driving scenes. Our method achieves state-of-the-art performance on the LLAMAS benchmark and demonstrates high accuracy on the TuSimple and CULane datasets, while maintaining low latency and a small model size. This work can serve as a new baseline for lane detection using parametric curves. The source code for our model and the PytorchAutoDrive framework for self-driving perception can be found at: [link].