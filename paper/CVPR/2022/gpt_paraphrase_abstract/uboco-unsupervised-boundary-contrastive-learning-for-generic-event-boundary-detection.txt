Generic Event Boundary Detection (GEBD) is a newly introduced task in video understanding that aims to identify deeper semantic boundaries within events. This task has the potential for various applications, such as interpretable and semantically valid video parsing. However, current GEBD solvers are simple extensions of existing video understanding tasks and do not fully consider the unique characteristics of GEBD.In this paper, we propose a novel framework for unsupervised/supervised GEBD using the Temporal Self-similarity Matrix (TSM) as the video representation. Our Recursive TSM Parsing (RTP) algorithm utilizes local diagonal patterns in the TSM to detect boundaries. Additionally, we incorporate the Boundary Contrastive (BoCo) loss to train our encoder to generate more informative TSMs. Our framework can be applied to both unsupervised and supervised settings, achieving state-of-the-art performance with a significant margin on the GEBD benchmark.Remarkably, our unsupervised method surpasses the previous state-of-the-art "supervised" model, highlighting its exceptional effectiveness. Overall, our proposed framework provides a promising solution for GEBD, bridging the gap between human perception and video understanding.