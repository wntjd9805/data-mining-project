Continual learning (CL) seeks to develop techniques that allow a single model to adapt to a growing number of tasks encountered sequentially, potentially benefiting from knowledge acquired in previous tasks in a resource-efficient manner. One of the main challenges in CL is catastrophic forgetting, where the model forgets earlier tasks when learning new ones. To overcome this, replay-based CL approaches maintain and repeatedly retrain on a small buffer of data selected from the tasks encountered. In this study, we propose a new strategy called Gradient CoresetReplay (GCR) for selecting and updating the replay buffer using a carefully designed optimization criterion. Our approach involves selecting and maintaining a 'coreset' that closely approximates the gradient of all the data observed so far with respect to the current model parameters. We also discuss important strategies for effectively applying this method to the continual learning setting. Our experiments demonstrate significant improvements (2%-4% absolute) over the current state-of-the-art in offline continual learning. Moreover, these findings extend to online/streaming CL settings, where we observe gains of up to 5% compared to existing approaches. Additionally, we showcase the effectiveness of using supervised contrastive loss in continual learning, which leads to a cumulative accuracy gain of up to 5% when combined with our subset selection strategy.