This paper introduces Uformer, a Transformer-based architecture for image restoration that incorporates a hierarchical encoder-decoder network. Uformer utilizes two core designs. Firstly, it introduces a novel locally-enhanced window (LeWin) Transformer block that performs non-overlapping window-based self-attention instead of global self-attention. This reduces computational complexity on high-resolution feature maps while capturing local context effectively. Secondly, Uformer proposes a learnable multi-scale restoration modulator in the form of a multi-scale spatial bias. This modulator adjusts features in multiple layers of the Uformer decoder and demonstrates superior capability in restoring details for various image restoration tasks with minimal additional parameters and computational cost. These two designs enable Uformer to capture both local and global dependencies for image restoration effectively. Extensive experiments on image denoising, motion deblurring, defocus deblurring, and deraining tasks validate the effectiveness of Uformer, showing superior or comparable performance compared to state-of-the-art algorithms. The code and models for Uformer are publicly available at https://github.com/ZhendongWang6/Uformer.