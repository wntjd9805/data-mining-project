Unsupervised domain adaptation (UDA) is a significant topic in the field of computer vision. The main challenge is finding a common characteristic between the source and target domains to align the features extracted from both domains. In this study, we propose a simple and effective method to regularize cross-domain representation learning using a domain-agnostic prior (DAP). The DAP ensures that the features obtained from the source and target domains align with a domain-agnostic space. This can be easily implemented as an additional loss term with minimal costs. We evaluate the effectiveness of different types of DAP in the standard evaluation protocol of transferring synthesized data to real data. Particularly, we explore a DAP borrowed from a text embedding model, which outperforms state-of-the-art UDA approaches in terms of segmentation accuracy. Our research indicates that UDA can benefit significantly from improved proxies, potentially from other data modalities.