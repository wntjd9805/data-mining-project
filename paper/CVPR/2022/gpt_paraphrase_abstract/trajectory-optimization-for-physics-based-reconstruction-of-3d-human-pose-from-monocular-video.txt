We present a method for estimating realistic human motion from monocular video by incorporating a physics engine into the pose estimation process. Previous approaches that neglect physics often produce inconsistent and artifact-ridden results, while current physics-based methods are limited to controlled environments or simplified body-ground contact. Our approach addresses these limitations by estimating the ground-plane location and body dimensions, and then optimizing the motion trajectory. This formulation allows our method to be applied to various scenes with different ground properties and supports self-contact and contact with scene geometry. We demonstrate that our approach achieves competitive results on benchmark datasets and can be directly applied to dynamic motions and uncontrolled internet videos without the need for re-training.