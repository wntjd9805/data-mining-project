The saliency ranking task investigates how humans shift their attention among different objects in a scene based on their levels of saliency. Previous approaches have focused on learning relationships between objects or between objects and scenes. However, these approaches tend to prioritize objects with strong semantics, leading to unrealistic saliency rankings. We recognize that spatial attention plays a concurrent role with object-based attention in the human visual recognition system. Inspired by this, we propose a novel method that combines spatial attention and object-based attention for saliency ranking. Our model includes a selective object saliency (SOS) module to infer the semantic representation of salient objects and an object-context-object relation (OCOR) module to allocate saliency ranks to objects by considering both object-context and context-object interactions. Our experimental results demonstrate that our approach surpasses existing state-of-the-art methods in saliency ranking. The code and pretrained model for our approach can be found at https://github.com/GrassBro/OCOR.