The study of data symmetry is crucial in machine learning, particularly in analyzing point cloud data used in 3D environmental perception. Point clouds naturally possess strong radial symmetry. This research utilizes a divide-and-conquer approach to leverage this symmetry, enhancing 3D perception performance and simplifying optimization. The proposed method, Azimuth Normalization (AziNorm), normalizes point clouds along the radial direction to eliminate variability caused by differences in azimuth. AziNorm can be easily incorporated into various LiDAR-based perception methods. To confirm its effectiveness and applicability, AziNorm is applied to object detection and semantic segmentation tasks. For object detection, AziNorm is integrated into the SECOND and PV-RCNN detectors, resulting in performance improvements of 7.03 mAPH and 3.01 mAPH, respectively, on the Waymo Open Dataset. Regarding semantic segmentation, AziNorm is integrated into KPConv, leading to a 1.6/1.1 mIoU improvement on the validation and test sets of the SemanticKitti dataset. Furthermore, AziNorm significantly enhances data efficiency and convergence speed, reducing the required data amounts or training epochs by an order of magnitude. Even with only 10% of the data or training epochs, SECOND with AziNorm performs notably better than a fully trained vanilla SECOND. The code and models for AziNorm are publicly available at https://github.com/hustvl/AziNorm.