The focus of clinical outcome prediction using medical images has primarily been on analyzing single-timepoint scans. However, it has been observed that disease progression can be better understood by considering temporal imaging. With this in mind, we proposed a deep learning method that incorporates temporal progression information to enhance clinical outcome predictions. Our approach combines a self-attention based Temporal Convolutional Network (TCN) and a Vision Transformer to learn representative features from single-timepoint images. The main innovation lies in the development of a recalibration module that utilizes maximum mean discrepancy loss (MMD) to align the distributions of these contextual representations. By training our system to predict clinical outcomes and severity grades based on single-timepoint images, we conducted experiments on chest and osteoarthritis radiography datasets and demonstrated superior performance compared to other state-of-the-art techniques.