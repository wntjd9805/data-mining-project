Blind face restoration, which aims to reconstruct high-quality images from low-quality inputs, can be improved by integrating shape and generative priors. This approach involves a shape restoration module to recover facial geometry through 3D reconstruction, and a pretrained facial generator to generate realistic high-resolution images. To ensure high-fidelity, hierarchical spatial features extracted from the low-quality inputs and rendered 3D images are inserted into the decoder using an Adaptive Feature Fusion Block (AFFB). Hybrid-level losses are introduced to jointly train the shape and generative priors, along with other network parts, to better adapt to the blind face restoration task. The proposed Shape and Generative Prior integrated Network (SGPN) can restore high-quality images with clear face shapes and realistic facial details. Experimental results on synthetic and real-world datasets show that SGPN outperforms state-of-the-art blind face restoration methods.