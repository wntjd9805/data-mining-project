Conventional methods for semantic segmentation of point clouds often use an encoder-decoder architecture that extracts geometric information by aggregating mid-level features locally. However, relying too heavily on these class-agnostic local geometric representations can lead to confusion between similar-looking or spatially adjacent parts from different categories. To address this problem, we propose enhancing mid-level features with semantic information through a technique called semantic-affine transformation. This transformation uses class-specific affine parameters to transform features of mid-level points belonging to different categories. Based on this idea, we introduce SemAffiNet, a method for point cloud semantic segmentation. SemAffiNet incorporates the attention mechanism from the Transformer module to capture both implicit and explicit global structural knowledge within local parts, enabling a comprehensive understanding of each category. We evaluate our approach on the ScanNetV2 and NYUv2 datasets and compare it to various 3D point cloud and 2D image segmentation baselines. Both qualitative and quantitative results demonstrate the superior performance and generalization ability of our proposed approach. The code for SemAffiNet is available at https://github.com/wangzy22/SemAffiNet.