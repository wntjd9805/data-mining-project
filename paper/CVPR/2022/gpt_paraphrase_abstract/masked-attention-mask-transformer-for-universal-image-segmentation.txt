The current focus of image segmentation is on designing specialized architectures for different semantic tasks, such as category or instance segmentation. However, this approach requires significant research effort for each task. In this study, we propose a new architecture called Masked-attention Mask Transformer (Mask2Former) that can handle any image segmentation task, including panoptic, instance, and semantic segmentation. Mask2Former utilizes masked attention to extract localized features by constraining cross-attention within predicted mask regions. Compared to specialized architectures, Mask2Former reduces the research effort by at least three times and achieves superior performance on four popular datasets. Notably, Mask2Former achieves state-of-the-art results in panoptic segmentation (57.8 PQ on COCO), instance segmentation (50.1 AP on COCO), and semantic segmentation (57.7 mIoU on ADE20K).