Co-salient object detection (CoSOD) has made significant progress in retrieval-related tasks but raises a new safety concern: personal and sensitive content can be extracted by powerful CoSOD methods. This paper addresses this issue by introducing adversarial co-saliency attack, where an adversarial version of an image is generated to mislead CoSOD methods into predicting incorrect co-salient regions. This task faces challenges of low success rate due to diverse image appearance and low transferability across CoSOD methods. To tackle these challenges, a black-box joint adversarial exposure and noise attack (Jadena) is proposed. Jadena adjusts the exposure and additive perturbations of the image based on a contrast-sensitive loss function. The proposed method significantly degrades the performance of CoSOD methods on various datasets and makes co-salient objects undetectable, enhancing the security of personal photos shared online. Furthermore, the method can be used as a metric to evaluate the robustness of CoSOD methods.