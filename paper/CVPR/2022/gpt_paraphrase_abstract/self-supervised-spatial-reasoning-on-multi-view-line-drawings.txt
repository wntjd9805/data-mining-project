Recently, state-of-the-art supervised deep networks have shown puzzlingly low performances on the SPARE3D dataset when it comes to spatial reasoning on multi-view line drawings. We propose two self-supervised learning approaches to address this issue and improve the baseline performance on the SPARE3D dataset. For the first approach, we utilize a self-supervised binary classification network to identify the differences in line drawings between different views of similar 3D objects. This enables the trained networks to effectively learn detail-sensitive yet view-invariant representations of 3D objects in line drawings.For the second approach, we introduce a self-supervised multi-class classification framework to train a model to select the correct corresponding view from which a line drawing is rendered. This method proves to be useful even for downstream tasks with unseen camera poses.Experimental results demonstrate that our proposed method significantly enhances the baseline performance on the SPARE3D dataset, while other popular self-supervised learning methods fail to do so.