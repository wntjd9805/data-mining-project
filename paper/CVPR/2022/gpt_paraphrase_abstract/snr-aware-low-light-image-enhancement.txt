This paper introduces a novel approach to enhance low-light images using a combination of Signal-to-Noise-Ratio (SNR)-aware transformers and convolutional models. The proposed method applies different operations based on the SNR of image regions, utilizing long-range operations for regions with extremely low SNR and short-range operations for other regions. To guide the feature fusion, an SNR prior is used, and a new self-attention model is formulated in the SNR-aware transformer to exclude tokens from noisy image regions with very low SNR. Extensive experiments demonstrate that our framework consistently outperforms state-of-the-art (SOTA) methods on seven representative benchmarks while maintaining the same structure. Furthermore, a large-scale user study involving 100 participants confirms the superior perceptual quality of our results. The source code for this work is available at https://github.com/dvlab-research/SNR-Aware-Low-Light-Enhance.