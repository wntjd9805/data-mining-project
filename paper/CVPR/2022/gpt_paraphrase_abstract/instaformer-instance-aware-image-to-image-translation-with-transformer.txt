We introduce a new network architecture called InstaFormer for instance-aware image-to-image translation. InstaFormer effectively combines global- and instance-level information by treating content features as tokens and using self-attention in Transformers to capture contextual information. By incorporating instance-level features based on bounding box information, our framework establishes a connection between object instances and the overall image, enhancing instance-awareness. We improve multi-modal translation by replacing layer normalization with adaptive instance normalization, allowing for the inclusion of style codes. Moreover, we propose an instance-level content contrastive loss to enhance instance-awareness and translation quality in object regions. Through experiments and ablation studies, we demonstrate the effectiveness of InstaFormer compared to existing methods.