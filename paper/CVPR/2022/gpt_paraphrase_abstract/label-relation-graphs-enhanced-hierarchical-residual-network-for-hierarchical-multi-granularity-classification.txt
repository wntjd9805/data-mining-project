The study focuses on hierarchical multi-granularity classification (HMC), which assigns hierarchical labels to objects. However, the definition of what is considered fine-grained is subjective, and image quality can impact identification. This leads to samples being observed at different levels of the hierarchy, and coarse categories often being neglected in the conventional HMC setting. The proposed method addresses these issues by learning with objects labeled at various levels and transferring hierarchical knowledge between levels. It also ensures that lower-level classes inherit attributes from upper-level superclasses. The combinatorial loss, derived from information in the tree hierarchy, maximizes the probability of the observed label. If the label is at the leaf level, the combinatorial loss includes a multi-class cross-entropy loss to emphasize fine-grained classification. To account for hierarchical feature interaction, a hierarchical residual network (HRN) is proposed, where features from parent levels act as residual connections added to features of children levels. Experiments on three datasets demonstrate the effectiveness of the approach compared to state-of-the-art HMC methods. The code is available at https://github.com/MonsterZhZh/HRN.