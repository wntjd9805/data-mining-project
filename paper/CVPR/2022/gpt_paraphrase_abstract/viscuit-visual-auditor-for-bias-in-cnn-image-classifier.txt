CNN image classifiers are widely used for their efficiency and accuracy, but they can be affected by biases that hinder their practical applications. Existing techniques to investigate bias are either not suitable for general image classification tasks or require users to manually specify data attributes for inspection. To address this, we introduce VISCUIT, an interactive visualization system that uncovers and explains biases in CNN classifiers. VISCUIT visually summarizes the subgroups where the classifier performs poorly and helps users identify the causes by highlighting image concepts that activate neurons leading to misclassifications. VISCUIT is accessible through modern browsers and is open-source, facilitating easy access and extension for other model architectures and datasets. Those interested can access VISCUIT at the following public demo link: https://poloclub.github.io/VisCUIT. Additionally, a video demonstration is available at https://youtu.be/eNDbSyM4R_4.