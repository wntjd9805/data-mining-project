Gaze object prediction is a task that aims to identify the objects that humans are looking at. Although this task has practical applications, there is currently no unified solution framework. One approach is to incorporate object detection into existing gaze prediction methods. However, previous methods use separate networks for scene and head images, resulting in a complex architecture and hindering joint optimization. In this paper, we propose a new framework called GaTector to address the gaze object prediction problem in a unified manner. We introduce a specific-general-specific (SGS) feature extractor that uses a shared backbone to extract general features from both scene and head images. To account for input and task specificity, SGS incorporates input-specific blocks before the shared backbone and task-specific blocks after. We also design a Defocus layer to generate object-specific features for the object detection task without losing information or requiring additional computations. Additionally, we introduce an energy aggregation loss to guide the gaze heatmap to focus on the object of interest. Lastly, we propose a novel wUoC metric that can differentiate between objects even when they do not overlap. Experimental results on the GOO dataset demonstrate the effectiveness of our method in object detection, gaze estimation, and gaze object prediction.