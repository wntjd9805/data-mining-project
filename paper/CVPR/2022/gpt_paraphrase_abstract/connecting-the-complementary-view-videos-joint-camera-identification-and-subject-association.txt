We aim to connect data from different viewpoints, specifically top views from drone-mounted cameras and side views from wearable cameras on the ground. Analyzing this complementary-view data collaboratively can help build a cooperative visual system for various applications. However, this task is challenging due to the significant differences in perspective between the top and side views. In this study, we present a novel approach that addresses three tasks simultaneously: localizing the side-view camera in the top view, estimating the view direction of the side-view camera, and detecting and associating the same subjects across the complementary views. Our approach leverages the spatial position layout of the subjects in both views by introducing a spatial-aware position representation method. Additionally, we propose a cross-view video collaboration framework that includes a camera identification module and a subject association module to perform the aforementioned tasks concurrently. To evaluate the performance of our method, we collect a synthetic dataset comprising pairs of top-view and side-view video sequences. Experimental results demonstrate the effectiveness of our proposed approach.