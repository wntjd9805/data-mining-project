Advancements in optical sensors and learning algorithms have significantly improved autonomous vehicles. However, their reliability is still limited due to restricted line-of-sight sensing and the vulnerability of data-driven methods in extreme circumstances. To address this, cooperative perception using vehicle-to-vehicle communication has emerged as a promising approach for enhancing autonomous driving in dangerous or emergency situations. This study presents COOPERNAUT, an end-to-end learning model that employs cross-vehicle perception for vision-based cooperative driving. The model uses compact point-based representations of Li-DAR data that can be transmitted between vehicles through realistic wireless channels. To evaluate the model, the researchers developed AUTOCASTSIM, a simulation framework that incorporates network augmentation and includes accident-prone scenarios. Results from experiments conducted on AUTOCASTSIM demonstrate that the cooperative perception driving models in COOPERNAUT improve the average success rate by 40% compared to egocentric driving models in challenging driving situations. Additionally, these models require 5 times less bandwidth than prior work V2VNet. The COOPERNAUT model and AUTOCASTSIM framework are both accessible at https://ut-austin-rpl.github.io/Coopernaut/.