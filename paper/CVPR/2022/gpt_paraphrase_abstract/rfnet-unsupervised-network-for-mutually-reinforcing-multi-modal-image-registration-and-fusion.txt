This paper presents RFNet, a novel approach for multi-modal image registration and fusion. The registration process is conducted in a coarse-to-fine manner, with the fusion feedback being utilized to enhance registration accuracy. This integration of registration and fusion improves the performance of both processes. To address the challenges of defining registration metrics for multi-modal images and ensuring network convergence, we propose metrics based on image translation and fusion at different stages. The convergence is facilitated by a deformable convolution-based network. In terms of image fusion, we prioritize texture preservation to enhance the quality and information content of the fused images, as well as improve the fusion feedback. We evaluate the proposed method on various scenarios, including images with large global parallaxes, local misalignments, and aligned images. The results demonstrate the effectiveness of our approach in both registration and fusion tasks.