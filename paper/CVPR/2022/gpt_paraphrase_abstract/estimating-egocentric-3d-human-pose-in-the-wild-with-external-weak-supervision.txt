Recently, there has been significant interest in estimating 3D human pose using a single fish-eye camera. However, current methods struggle to estimate poses from real-world images due to the lack of large-scale in-the-wild egocentric datasets. Additionally, these methods often fail when body parts are occluded or interacting with the surrounding environment. To address this data shortage, we have collected a new dataset called Egocentric Poses in the Wild (EgoPW) using a head-mounted fish-eye camera and an auxiliary external camera. This dataset provides a third-person perspective during training. We have developed a new pose estimation method that can be trained on this dataset with weak external supervision. We first generate pseudo labels for the EgoPW dataset using a spatio-temporal optimization method that incorporates the external-view supervision. These pseudo labels are then used to train an egocentric pose estimation network. To aid in the network training, we propose a novel learning strategy that supervises the egocentric features with high-quality features extracted by a pretrained external-view pose estimation model. Our experiments demonstrate that our method accurately predicts 3D poses from a single in-the-wild egocentric image and performs better than current state-of-the-art methods both quantitatively and qualitatively.