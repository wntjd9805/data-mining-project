We present a pipeline that can generate Neural RadianceFields (NeRF) for an object or scene of a specific class using only a single input image. This is a challenging task because typically, training NeRF requires multiple views of the same scene along with their corresponding poses, which can be difficult to obtain. Our approach is based on π-GAN, a generative model that can synthesize 3D-aware images without any specific conditions. This model maps random latent codes to radiance fields of objects within a specific class. We optimize our pipeline by combining the π-GAN objective, which generates high-quality 3D-aware images, with a well-designed reconstruction objective. This objective includes an encoder that works together with the π-GAN generator to form an auto-encoder. Unlike previous methods for generating NeRF using only a few training examples, our pipeline is unsupervised and can be trained using independent images without the need for 3D, multi-view, or pose supervision. The applications of our pipeline are diverse and include tasks such as 3D avatar generation, synthesizing novel views of objects from a single input image, and 3D-aware super-resolution, among others.