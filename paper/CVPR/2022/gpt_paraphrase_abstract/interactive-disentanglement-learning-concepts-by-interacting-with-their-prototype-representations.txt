Learning visual concepts without strong supervision from raw images is a difficult task. This study explores the benefits of using prototype representations to better understand and modify the latent space of neural concept learners. To achieve this, the researchers propose a new framework called interactive Concept Swapping Networks (iCSNs), which learns concept-grounded representations using weak supervision and implicit prototype representations. iCSNs accomplish this by swapping the latent representations of paired images, thereby associating conceptual information with specific prototype slots. This approach creates a semantically grounded and discrete latent space that enhances human understanding and interaction with the machine. To validate their approach, the researchers conduct experiments on a new dataset called "Elementary Concept Reasoning" (ECR), focusing on visual concepts related to geometric objects. The output of the study is presented in an abstract format, providing only a summary of the main points.