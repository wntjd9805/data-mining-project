This paper presents a newly introduced dataset called In-staOrder, which aims to provide insights into the geometrical relationships of objects within an image. The dataset comprises 2.9 million annotations of geometric orderings for instances labeled with classes in 101,000 natural scenes. The annotations were gathered from 3,659 crowd-workers who determined the occlusion order and depth order for each instance. The occlusion order identifies the occluder and occludee, while the depth order describes the relative distance from the camera. The dataset offers joint annotation for both types of orderings, revealing their complementary nature. Additionally, the paper introduces two networks: InstaOrderNet, a geometric order prediction network that outperforms existing methods, and InstaDepthNet, a dense depth prediction network that utilizes an auxiliary geometric order loss to enhance the accuracy of the state-of-the-art depth prediction approach, MiDaS [54].