We present PartGlot, a neural framework and associated models for learning the semantic segmentation of parts in 3D shape geometry using only linguistic descriptions. We leverage the fact that language can provide prior knowledge about the parts of a shape, as it reflects human perception of object structure and aids in recognition. Our training data comes from ShapeGlot, where speakers generate utterances to distinguish a target shape from distractors and listeners locate the target based on these utterances. Our network incorporates a Transformer-based attention module to accurately highlight the parts described in the language, enabling multi-modal recognition without direct supervision on the geometry. Additionally, we show that the learned part information generalizes to unseen shape classes, eliminating the need for large-scale part geometry annotations and facilitating annotation acquisition. The code can be found at the provided GitHub link.