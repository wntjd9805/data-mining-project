The advancement of sensors and deep learning techniques has led to a growing interest in 3D object detection using point clouds. Current state-of-the-art methods, such as VoteNet, struggle to accurately predict object offsets and orientations due to the challenges in rotation classification. In this study, we propose a new approach that disentangles the direct offset into Local Canonical Coordinates (LCC), box scales, and box orientations. We only regress LCC and box scales, while box orientations are generated using a canonical voting scheme. Additionally, we introduce an LCC-aware back-projection checking algorithm that iteratively removes false positives from the generated vote maps. Our model achieves the best performance on three widely used real-world benchmarks: ScanNet, SceneNN, and SUN RGB-D. The code for our approach is available on https://github.com/qq456cvb/CanonicalVoting.