Pan-sharpening techniques have been successful in obtaining high-resolution multi-spectral (MS) images for remote sensing systems, particularly with the use of deep learning-based methods. However, most existing methods lack interpretability and blindly concatenate MS images with panchromatic (PAN) images, resulting in copy artifacts. To address these issues, we propose an interpretable deep neural network called Memory-augmented Deep Conditional Unfolding Network. This network incorporates two core designs. Firstly, it formulates the Pan-sharpening problem as a variational model, minimizing it with a denoising-based prior and a non-local auto-regression prior. This allows for the identification of similarities between long-range patches, enhancing texture. The model design is transparent thanks to the use of a novel iteration algorithm with built-in CNNs. Secondly, to fully exploit the potential of each band of MS images, the PAN image is combined selectively with each band, providing high-frequency details and reducing copy artifacts. Extensive experiments demonstrate the superiority of our proposed algorithm compared to other state-of-the-art methods.