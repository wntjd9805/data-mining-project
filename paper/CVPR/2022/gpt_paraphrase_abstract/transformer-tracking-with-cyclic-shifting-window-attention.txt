This paper introduces a novel transformer architecture for visual object tracking that improves attention from the pixel level to the window level. Existing transformer-based approaches focus on pixel-to-pixel attention, which overlooks the integrity of objects. Our proposed architecture, called multi-scale cyclic shifting window attention, addresses this limitation. It incorporates cross-window multi-scale attention to aggregate attention at different scales and generate precise fine-scale matches for the target object. Additionally, the cyclic shifting strategy enhances accuracy by expanding window samples with positional information while reducing computational power by eliminating redundant calculations. Extensive experiments demonstrate the superior performance of our method, which sets new state-of-the-art records on challenging datasets, including VOT2020, UAV123, LaSOT, TrackingNet, and GOT-10k benchmarks. The code for our project is available at https://github.com/SkyeSong38/CSWinTT.