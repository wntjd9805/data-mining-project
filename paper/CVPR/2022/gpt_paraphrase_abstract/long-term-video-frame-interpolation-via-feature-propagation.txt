This study addresses the limitations of video frame interpolation (VFI) when the temporal distance between input frames is large. Existing motion estimation modules struggle to handle large motions, resulting in inaccurate interpolation. To overcome this, the authors propose a novel framework that propagates information from one side of the input to a reliable time frame using the other input as a reference. The remaining intermediate frames can then be interpolated using standard approaches. The authors introduce a propagation network (PNet) that combines feature-level forecasting with a motion-to-feature approach. They also present a simple interpolation model and a procedure to train the full model in an end-to-end manner. Experimental results on benchmark datasets demonstrate the effectiveness of their method for long-term VFI compared to existing approaches.