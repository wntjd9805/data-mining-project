This study focuses on utilizing both labeled and unlabeled data for semi-supervised learning in video action detection. The researchers propose a simple approach that effectively utilizes unlabeled data by considering two constraints: classification consistency and spatio-temporal consistency. However, the presence of predominant background and static regions in videos makes it challenging to apply spatio-temporal consistency for action detection. To overcome this challenge, the researchers introduce two novel regularization constraints: temporal coherency and gradient smoothness. These constraints exploit the temporal continuity of actions in videos and prove to be effective in utilizing unlabeled videos for action detection. The proposed approach is evaluated on two benchmark datasets, UCF101-24 and JHMDB-21, and also demonstrates its generalization capability in video object segmentation on Youtube-VOS. The results show that the proposed approach achieves competitive performance by using only 20% of annotations compared to recent fully supervised methods. On UCF101-24, it improves the score by +8.9% and +11% at 0.5 f-mAP and v-mAP, respectively, compared to the supervised approach. The code and models of the proposed approach will be publicly available at the given GitHub link.