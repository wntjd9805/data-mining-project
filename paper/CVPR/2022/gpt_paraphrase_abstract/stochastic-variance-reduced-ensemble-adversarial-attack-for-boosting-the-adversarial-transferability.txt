The black-box adversarial attack has gained considerable attention in the field of deep learning security. However, it is challenging because it lacks access to the target model's network architecture and internal weights. Ensemble-based adversarial attack methods have emerged as efficient approaches, as they exploit the transferability of attacks across multiple models. Existing ensemble attacks, though, often overlook the investigation of different ways to conduct the ensemble attack. This study treats the iterative ensemble attack as an optimization process using stochastic gradient descent. However, the variance of gradients across different models can lead to suboptimal results. To address this, we propose a new attack method called the stochastic variance reduced ensemble (SVRE) attack, which minimizes the gradient variance among ensemble models. Experimental results on the ImageNet dataset demonstrate the effectiveness of SVRE in enhancing adversarial transferability, outperforming existing ensemble attacks significantly. The code for SVRE is available at https://github.com/JHL-HUST/SVRE.