This paper introduces a novel model, called the meta convolutional neural network, to address the problem of single domain generalization in image recognition. The model decomposes the convolutional features of images into meta features, which are considered as universal and fundamental visual elements for image representation. By treating meta features as reference points, the model applies compositional operations to remove irrelevant features from local convolutional features and reconstructs the feature maps as a composition of relevant meta features. This encoding process ensures that images are represented in a domain-agnostic manner, allowing them to be processed by modules trained in the source domain. The compositional operations utilize regression analysis to learn the meta features in an online batch learning fashion. Extensive experiments conducted on various benchmark datasets validate the effectiveness of the proposed model in enhancing the single domain generalization capability.