High-speed cameras are expensive for recording fast motion, so there has been interest in interpolating low-FPS videos from cheaper cameras. However, current methods rely on motion assumptions that cannot model complex motions effectively. Event cameras, which produce events of brightness change at a temporal resolution of microseconds, have the potential to enable video interpolation with arbitrarily complex motion. However, the lack of processing algorithms has limited their use. This paper proposes a novel algorithm called TimeReplayer that can interpolate videos captured by commodity cameras with event data. The algorithm is trained in an unsupervised cycle-consistent style, eliminating the need for high-speed training data and also allowing for video extrapolation. The paper presents state-of-the-art results and demo videos that demonstrate the promising future of event-based vision.