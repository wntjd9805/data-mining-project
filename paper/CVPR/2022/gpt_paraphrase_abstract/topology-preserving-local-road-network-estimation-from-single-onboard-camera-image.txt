Recovering road network topology from a single image is crucial for autonomous planning and navigation. However, this area of research has only been partially explored and it is important to consider the ground plane where driving actions take place. This paper focuses on extracting the local road network topology in a complex urban setting, specifically in the bird's-eye-view (BEV). The method utilizes a single onboard camera image as input. The road topology is represented using directed lane curves and their intersections. To improve the representation of topology, the concept of minimal cycles and their covers is introduced. A minimal cycle represents the smallest cycle formed by the directed curve segments, and the cover is a set of curves that contribute to forming a minimal cycle. The study proves that the covers are sufficient for accurately representing the road topology. Deep neural networks are trained using the covers and lane curve supervision to predict the road topology from a single input image. The results on the NuScenes and Argo-verse benchmarks show significant improvements compared to baseline methods. The code for this research can be found at https://github.com/ybarancan/TopologicalLaneGraph.