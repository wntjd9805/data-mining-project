We propose a method for monocular depth estimation in supervised settings, where ground-truth depth is only available during training. Our approach leverages the regularity of real 3D scenes by selectively using information from coplanar pixels to improve depth predictions. We introduce a piecewise planarity prior, stating that each pixel has a seed pixel sharing the same planar 3D surface. To implement this, we design a network with two heads: one for pixel-level plane coefficients and the other for a dense offset vector field identifying seed pixel positions. The plane coefficients of seed pixels are used to predict depth at each position. We fuse this prediction with the initial prediction using a learned confidence to account for deviations from local planarity. The entire architecture is trained end-to-end, producing regular depth maps with sharp edges at occlusion boundaries. Our method outperforms prior techniques on NYU Depth-v2 and the Garg split of KITTI, delivering plausible 3D reconstructions of input scenes. Code is available at: https://github.com/SysCV/P3Depth.