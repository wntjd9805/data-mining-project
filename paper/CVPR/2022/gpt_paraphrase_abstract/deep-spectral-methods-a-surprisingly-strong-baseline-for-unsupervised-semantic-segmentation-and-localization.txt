Unsupervised localization and segmentation have long been challenging tasks in computer vision. These tasks involve breaking down an image into semantically meaningful segments without the use of labeled data. The difficulty and cost of obtaining dense image annotations make these tasks particularly interesting in an unsupervised setting. However, existing unsupervised approaches struggle with complex scenes that contain multiple objects. Unlike these methods, which rely solely on deep learning, we draw inspiration from traditional spectral segmentation methods and reframe image decomposition as a graph partitioning problem. Specifically, we analyze the eigenvectors of the Laplacian matrix of a feature affinity matrix derived from self-supervised networks. We discover that these eigenvectors are capable of decomposing an image into meaningful segments and can be used effectively for object localization in a scene. Additionally, by clustering the features associated with these segments across a dataset, we can obtain well-defined and identifiable regions, known as semantic segmentations. Experimental results on complex datasets such as PASCAL VOC and MS-COCO demonstrate that our simple spectral method significantly outperforms the current state-of-the-art in unsupervised localization and segmentation. Furthermore, our method can be easily applied to various complex image editing tasks like background removal and compositing.