Current deep neural network methods for estimating camera pose rely on scene structure for 3D motion estimation, but this approach lacks robustness and struggles with generalization across different datasets. Conversely, classical approaches to structure from motion estimate 3D motion using optical flow and then calculate depth. However, the accuracy of these methods heavily relies on the quality of the optical flow. To address this issue, direct methods have been proposed, which separate 3D motion from depth estimation but use only image gradients to compute 3D motion.In this study, we introduce a network called NFlowNet, which estimates normal flow to enforce robust and direct constraints. We utilize normal flow to estimate the relative camera pose based on the cheirality (depth positivity) constraint. To achieve this, we formulate the optimization problem as a differentiable cheirality layer, enabling end-to-end learning of camera pose. We extensively evaluate the sensitivity of our proposed DiffPoseNet to noise and its generalization across datasets through qualitative and quantitative analysis. We compare our approach to existing state-of-the-art methods on the KITTI, TartanAir, and TUM-RGBD datasets.