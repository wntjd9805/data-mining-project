We introduce a novel data-driven approach that combines physics-based priors to estimate the normal of complex scenes from a single polarization image. While previous methods focused on estimating normals of single objects, our approach tackles the challenge of scene-level estimation. A major obstacle in achieving high-quality scene-level estimation is the scarcity of real-world data for complex scenes. To address this limitation, we present the first real-world dataset for scene-level estimation, consisting of paired polarization images and ground-truth normal maps. To handle the increased polarization ambiguities caused by complex materials and non-orthographic projection in scene-level estimation, we propose a learning-based framework. This framework incorporates a multi-head self-attention module and viewing encoding. Our trained model can generalize to far-field outdoor scenes as the relationship between polarized light and surface normals remains unaffected by distance. Experimental results demonstrate that our approach outperforms existing methods on two datasets. We showcase the effectiveness of polarization in our method by providing examples where polarization helps in accurately estimating surface normals, even when objects have similar materials. For instance, in the presence of a printed image on a wall, polarization provides geometry cues to prevent our model from being misled. In conclusion, our work contributes a new approach for scene-level normal estimation from a single polarization image. We introduce a dataset and a learning-based framework that effectively addresses the challenges posed by complex scenes. Our approach outperforms existing methods and showcases the benefits of polarization in estimating surface normals. The dataset and source code for our work are publicly available.