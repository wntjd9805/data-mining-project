This study focuses on learning scene flow on point clouds through self-supervised methods. The authors propose a novel approach for generating pseudo scene flow by estimating piecewise rigid motion. They decompose the source point cloud into local regions and consider each region as rigid. By aligning each region with its counterpart in the target point cloud, they obtain region-specific rigid transformations to represent the flow. This generates pseudo scene flow labels for the entire scene, enabling network training. Unlike existing methods that rely on point-wise similarities, this approach enforces region-wise rigid alignments, resulting in locally rigid pseudo scene flow labels. The effectiveness of this self-supervised learning method is demonstrated on the FlyingThings3D and KITTI datasets. The experiments show that this method achieves state-of-the-art performance in self-supervised scene flow learning, surpassing some supervised counterparts. The proposed method's superiority is illustrated through a comparison of pseudo scene flow labels generated using nearest neighbor search and the proposed method. The green lines represent correct pseudo labels, while the red lines represent incorrect pseudo labels. The proposed method produces more accurate pseudo labels with minimal errors.