We introduce ShapeFormer, a transformer-based network that generates a range of object completions based on incomplete and potentially noisy point clouds. These completions are realistic and faithful to the input data. To enable the use of transformers for 3D tasks, we propose a compact 3D representation called vector quantized deep implicit function (VQDIF). VQDIF employs spatial sparsity to represent a 3D shape approximation using a concise sequence of discrete variables. Our experiments demonstrate that ShapeFormer surpasses previous methods in terms of both completion quality and diversity when dealing with uncertain partial inputs. Furthermore, our approach proves effective in handling various shape types, incomplete patterns, and real-world scans.