Detecting human-scene contact (HSC) is crucial for understanding human interactions with their environment. While progress has been made in detecting 2D human-object interactions (HOI) and reconstructing 3D human pose and shape (HPS), accurately reasoning about 3D human-scene contact from a single image remains a challenge. Existing methods for HSC detection have limitations, such as considering only a limited number of predefined contacts, oversimplifying the body and scene, and overlooking image evidence. To address these limitations, we introduce the RICH dataset, which includes multiview outdoor/indoor video sequences, ground-truth 3D human bodies, 3D body scans, and high-resolution 3D scene scans. Importantly, RICH also includes accurate vertex-level contact labels on the body. Using the RICH dataset, we train a network called Body-Scene contact TRansfOrmer (BSTRO) to predict dense body-scene contacts from a single RGB image. Our key insight is that regions in contact are often occluded, requiring the network to explore the entire image for evidence. To capture these non-local relationships, we employ a transformer in BSTRO. Unlike previous methods that focus on foot contact or infer contact from body pose without considering the scene, BSTRO directly estimates 3D body-scene contact. Our experiments demonstrate that BSTRO outperforms previous methods. The code and dataset are publicly available for research purposes at https://rich.is.tue.mpg.de.