We propose a novel multi-modal framework called SFD (Sparse Fuse Dense) to address the limitations of current LiDAR-only 3D detection methods due to sparse point clouds. Existing multi-modal approaches struggle to fuse different image and point cloud representations, leading to suboptimal performance. To overcome this, we generate pseudo point clouds using depth completion and introduce a new RoI fusion strategy called 3D-GAF (3D Grid-wise Attentive Fusion) to extract information from different types of point clouds more effectively. 3D-GAF attentively fuses 3D RoI features in a fine-grained and precise manner. We also propose SynAugment (Synchronized Augmentation) to enable our framework to utilize data augmentation techniques designed for LiDAR-only methods. Additionally, we develop a feature extractor called CPConv (Color Point Convolution) specifically for pseudo point clouds, which simultaneously captures 2D image features and 3D geometric features. Our SFD framework achieves the highest performance on the KITTI car 3D object detection leaderboard, demonstrating its effectiveness. We will make the code publicly available.