The challenge of providing annotations for facial action unit (AU) recognition in large amounts of facial images is addressed in this study. A novel knowledge-driven self-supervised representation learning framework is proposed, utilizing AU labeling rules from the Facial Action Coding System (FACS). The framework trains a representation encoder using facial images without AU annotations. Facial partition manners and correlations between facial regions are determined based on FACS rules. The method employs a backbone network to extract representations of local facial areas and a project head to map these representations into a low-dimensional latent space. A contrastive learning component uses inter-area differences to learn AU-related local representations while maintaining intra-area instance discrimination. Additionally, correlations between facial regions derived from AU labeling rules are utilized in a predicting learning component. Experimental results on two benchmark databases demonstrate the effectiveness and efficiency of the learned representation for AU recognition.