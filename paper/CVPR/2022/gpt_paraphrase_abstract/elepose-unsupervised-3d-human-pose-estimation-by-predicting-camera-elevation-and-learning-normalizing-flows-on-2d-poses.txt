We propose an unsupervised approach for human pose estimation from single images. Currently, there is a lack of labeled training data for many human activities as 3D annotation requires specialized motion capture systems. Our approach aims to predict 3D human pose using only 2D pose data, which is easily obtainable through crowd-sourcing. We achieve this by estimating the most likely 3D pose through random projections, with the likelihood calculated using normalizing flows on 2D poses. Unlike previous methods that rely on strong priors on camera rotations in the training data, we learn the distribution of camera angles, resulting in improved performance. Additionally, we stabilize the training process by applying normalizing flows on high-dimensional 3D pose data after projecting the 2D poses to a linear subspace. Our approach outperforms existing unsupervised human pose estimation methods on benchmark datasets such as Human3.6M and MPI-INF-3DHP across multiple evaluation metrics.