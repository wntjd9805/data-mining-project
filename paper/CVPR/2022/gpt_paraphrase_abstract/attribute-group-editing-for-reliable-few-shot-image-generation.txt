Few-shot image generation is a difficult task, even with advanced Generative Adversarial Networks (GANs). The quality and diversity of generated images are typically low due to the unstable GAN training process and limited training data. To address this issue, we propose a new method called Attribute Group Editing (AGE) for few-shot image generation. AGE operates on the assumption that images consist of attributes, and the editing direction for a specific attribute is shared across all categories. By examining the internal representation learned in GANs, AGE identifies semantically meaningful directions. It uses the class embedding, which is the mean vector of the latent codes from a specific category, to represent category-relevant attributes. The category-irrelevant attributes are learned globally through Sparse Dictionary Learning on the difference between the sample embedding and the class embedding. With a well-trained GAN on seen categories, AGE can synthesize diverse images of unseen categories by editing category-irrelevant attributes while keeping category-relevant attributes unchanged. Importantly, AGE achieves this without re-training the GAN. It not only produces more realistic and diverse images for downstream visual applications with limited data but also allows for controllable image editing using interpretable category-irrelevant directions. The code for AGE is available at https://github.com/UniBester/AGE.