Many existing algorithms for detecting Out-Of-Distribution (OOD) examples rely on a single input source, such as features, logits, or softmax probabilities. These methods are often not robust enough to handle the diverse range of OOD samples. Some OOD samples may be easy to identify in the feature space but difficult to distinguish in the logit space, and vice versa. In light of this observation, we propose a new OOD scoring method called Virtual-logit Matching (ViM). ViM combines the class-agnostic score from the feature space with the In-Distribution (ID) class-dependent logits. We generate an additional logit representing the virtual OOD class by calculating the residual of the feature against the principal space and then scale it to match the original logits. The probability of this virtual logit after softmax serves as an indicator of OOD-ness. To facilitate the evaluation of large-scale OOD detection in academia, we have created a new OOD dataset for ImageNet-1K, which is human-annotated and significantly larger than existing datasets. We conducted extensive experiments using CNNs and vision transformers to demonstrate the effectiveness of our proposed ViM score. Specifically, when using the BiT-S model, our method achieved an average AUROC of 90.91% on four challenging OOD benchmarks, outperforming the best baseline by 4%. The code and dataset for our method are available at https://github.com/haoqiwang/vim.