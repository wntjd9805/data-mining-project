There is a significant gap between current visual pattern recognition models and human-level visual cognition, particularly in few-shot learning and compositional reasoning of new concepts. To address this, we introduce Bongard-HOI, a visual reasoning benchmark that focuses on learning human-object interactions (HOIs) from natural images. Inspired by the Bongard problems, our benchmark incorporates few-shot concept learning and context-dependent reasoning. We carefully select challenging few-shot instances with positive and negative images that only differ in action labels, requiring more than object recognition to complete the benchmark. We also create multiple test sets with varying overlap of HOI concepts between training and test instances. Bongard-HOI poses a significant challenge to current visual recognition models, as the state-of-the-art HOI detection model achieves only 62% accuracy on few-shot binary prediction, while even amateur human testers achieve 91% accuracy. By introducing the Bongard-HOI benchmark, we aim to advance research in visual reasoning, particularly in holistic perception-reasoning systems and representation learning.