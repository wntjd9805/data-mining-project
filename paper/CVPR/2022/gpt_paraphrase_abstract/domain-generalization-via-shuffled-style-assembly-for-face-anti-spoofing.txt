Generalizable face anti-spoofing (FAS) has become increasingly important as diverse presentation attacks continue to emerge. Existing methods typically use domain generalization (DG) on complete representations, but different image statistics may have unique properties for FAS tasks. This study introduces a novel approach called the Shuffled Style Assembly Network (SSAN) that separates representations into content and style features. SSAN then extracts and reassembles these features to create a stylized feature space. To achieve a generalized representation, a contrastive learning strategy is employed to emphasize liveness-related style information and suppress domain-specific information. The resulting representations are used to distinguish between living and spoofing during inference. In addition to addressing the technical aspects of FAS, there is a gap between academia and industry, mainly due to differences in data quantity and distribution. To bridge this gap, a large-scale benchmark for FAS is created to evaluate algorithm performance in real-world scenarios. This benchmark, along with existing benchmarks, is used to assess the effectiveness of the proposed methods both qualitatively and quantitatively. The codes for the proposed methods are made available at https://github.com/wangzhuo2019/SSAN.