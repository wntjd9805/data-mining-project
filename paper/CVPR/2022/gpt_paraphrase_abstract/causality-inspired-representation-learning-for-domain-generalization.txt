Domain generalization (DG) is an issue of generalizing knowledge from multiple known domains to an unseen domain. Current approaches use statistical models to model the relationship between data and labels, aiming to learn domain-independent representations. However, these models are limited because they only focus on modeling dependence rather than the underlying causal mechanisms. When the dependence changes in the unseen domain, these models may fail to generalize. To address this limitation, we propose a general structural causal model to formalize the DG problem. We assume that each input consists of causal factors (whose relationship with the label remains consistent across domains) and non-causal factors (independent of the category), and only the former factors affect the classification. Our objective is to identify the causal factors and reconstruct the invariant causal mechanisms. However, this theoretical idea is impractical as the required causal/non-causal factors are unobserved. We emphasize that ideal causal factors should possess three properties: separation from non-causal factors, joint independence, and causal sufficiency for classification. To achieve this, we introduce a Causality Inspired Representation Learning (CIRL) algorithm that enforces representations to satisfy these properties and uses them to simulate the causal factors, resulting in improved generalization. Extensive experiments on widely used datasets validate the effectiveness of our approach.