Our objective is to populate digital environments with diverse digital humans who have different body shapes and move realistically. The main challenge is to create authentic, controllable, and endless motions for various 3D bodies. To address this, we introduce generative motion primitives using body surface markers, or GAMMA for short. In our approach, we break down the long-term motion into a sequence of motion primitives. We utilize body surface markers and a conditional variational autoencoder to model each motion primitive and generate long-term motion recursively. To control the motion towards a goal, we employ a policy network to explore the latent space of the generative model, and a tree-based search to maintain motion quality during testing. Experimental results demonstrate that our method outperforms existing data-driven approaches in terms of producing more realistic and controllable motion. The code is available for research purposes at: https://yz-cnsdqz.github.io/eigenmotion/GAMMA/.