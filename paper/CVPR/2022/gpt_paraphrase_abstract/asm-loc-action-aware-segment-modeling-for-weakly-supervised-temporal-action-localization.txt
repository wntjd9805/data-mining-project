Weakly-supervised temporal action localization is a task that involves recognizing and localizing action segments in untrimmed videos with only video-level action labels for training. Existing methods primarily rely on multiple instance learning (MIL), where unlabeled video snippets are supervised by classifying labeled bags (untrimmed videos). However, these methods often overlook the temporal structures within and across action segments. To address this issue, we propose ASM-Loc, a novel framework that goes beyond standard MIL-based methods by explicitly modeling action segments. Our framework consists of three segment-centric components: dynamic segment sampling to account for short actions, intra- and inter-segment attention to capture action dynamics and temporal dependencies, and pseudo instance-level supervision to enhance action boundary prediction. Additionally, we introduce a multi-step refinement strategy to progressively improve action proposals during model training. Our approach is evaluated on the THUMOS-14 and ActivityNet-v1.3 datasets, and the results demonstrate its effectiveness, establishing a new state of the art on both datasets. The code and models for ASM-Loc are publicly available at https://github.com/boheumd/ASM-Loc.