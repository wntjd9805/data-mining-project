Unsupervised methods for learning image representations have achieved impressive results by utilizing contrastive learning, clustering, and other pretext tasks. However, the field has become crowded with numerous methods that yield similar outcomes on standard benchmarks like linear evaluation on ImageNet. This paper aims to compare these methods using performance-based benchmarks, including linear evaluation, nearest neighbor classification, and clustering, across multiple datasets. By doing so, it highlights the absence of a clear frontrunner among the current state-of-the-art approaches. Unlike previous studies that solely compare supervised versus unsupervised methods, this research compares various unsupervised methods against each other. To enhance this comparison, the study analyzes embeddings using measurements such as uniformity, tolerance, and centered kernel alignment (CKA). Additionally, it introduces two new metrics: nearest neighbor graph similarity and linear prediction overlap. Through this analysis, the paper demonstrates that popular methods should not be regarded as representative of the entire field, and future research should explore ways to leverage the complementary nature of these methods. The study also employs CKA to establish a framework for robustly quantifying augmentation invariance and reminds researchers that certain types of invariance may not be desirable for downstream tasks.