We present a novel self-explaining deep model that incorporates an explanation generation module into a basic network. This model is able to learn latent concept-based explanations during training, eliminating the need for post-hoc explanation generation techniques. Our model achieves high predictive performance while generating meaningful explanations in terms of concepts. We propose a training strategy for unsupervised concept learning that requires less parameter space compared to baseline methods. Additionally, our model can leverage self-supervision on concepts to improve explanation quality. When provided with full concept supervision, our model outperforms recently proposed concept-based explainable models in terms of predictive performance. We provide qualitative and quantitative results on two datasets without ground truth concepts (CIFAR10, ImageNet) and two datasets with ground truth concepts (AwA2, CUB-200) to demonstrate the effectiveness of our method in both cases. Notably, our method is the first to demonstrate results with a large-scale dataset like ImageNet using an ante-hoc explanation generation approach.