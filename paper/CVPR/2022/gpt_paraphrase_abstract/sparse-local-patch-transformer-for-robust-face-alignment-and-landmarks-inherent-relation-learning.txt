Recent advancements in face alignment techniques have primarily focused on heatmap regression methods. However, these methods overlook the inherent relationship between different facial landmarks. To address this issue, we introduce a novel approach called Sparse Local Patch Transformer (SLPT) that aims to learn this intrinsic relationship. The SLPT generates a representation for each individual landmark by extracting information from a local patch and combines them using an attention mechanism that adapts to the inherent relationship. By aggregating the features, we can independently predict the subpixel coordinates of each landmark. To further enhance the performance of SLPT, we propose a coarse-to-fine framework that works in conjunction with it. This framework allows the initial landmarks to progressively converge towards the target facial landmarks by utilizing fine-grained features obtained from dynamically resized local patches. To evaluate the effectiveness of our method, extensive experiments were conducted on three popular benchmark datasets: WFLW, 300W, and COFW. The results demonstrate that our proposed approach achieves state-of-the-art performance while significantly reducing computational complexity. This is accomplished by effectively learning the inherent relationship between facial landmarks. The code for our method is available on the project website.