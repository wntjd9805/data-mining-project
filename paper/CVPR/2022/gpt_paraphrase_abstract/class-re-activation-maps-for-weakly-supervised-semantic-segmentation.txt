The current method for generating pseudo masks in weakly-supervised semantic segmentation (WSSS) using class activation maps (CAM) is unsatisfactory due to the binary cross-entropy loss (BCE) used in CAM. The sum-over-class pooling in BCE causes each pixel in CAM to be responsive to multiple classes in the same area. This leads to inaccuracies where hot CAM pixels of one class invade the territory of other classes, and non-hot pixels may actually belong to the class. To address this issue, we propose a simple yet effective solution called ReCAM. ReCAM involves reactivating the converged CAM using softmax cross-entropy loss (SCE). We extract feature pixels for each class using CAM and train another fully-connected layer (after the backbone) using SCE and the class label. Once converged, we extract ReCAM in the same way as CAM. ReCAM disentangles the pixel responses into different classes, reducing mask ambiguity. We evaluated ReCAM on PASCALVOC and MS COCO datasets and found that it generates high-quality masks and can be easily incorporated into any CAM variant with minimal additional computational overhead. Our code is publicly available at https://github.com/zhaozhengChen/ReCAM.