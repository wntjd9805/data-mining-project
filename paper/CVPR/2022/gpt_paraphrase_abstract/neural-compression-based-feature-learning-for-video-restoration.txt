Efficiently utilizing temporal features is crucial yet challenging in video restoration. These features often contain noisy and uncorrelated information that can interfere with restoring the current frame. This study proposes learning noise-robust feature representations to aid video restoration. Inspired by the denoising capabilities of neural codecs, a neural compression module is designed to filter out noise and retain the most valuable information for restoration. To ensure robustness to noise, the compression module employs a spatial-channel-wise quantization mechanism to determine the quantization step size for each position in the latent. Experimental results demonstrate that our approach significantly enhances video denoising performance, achieving a 0.13 dB improvement over BasicVSR++ with only 0.23x FLOPs. Additionally, our method achieves state-of-the-art results in video deraining and dehazing tasks.