We present a new approach for addressing regression problems using limited supervision or few-shot learning. Our method is based on the observation that Generative Adversarial Networks (GANs) are highly effective at encoding semantic information in their latent space, even without explicit supervision. This encoding is characterized by smooth, linear directions that disentangle image attributes. These directions have been successfully utilized for image editing in GAN-based frameworks. In our work, we exploit these directions for few-shot regression tasks. We recognize that distances traveled along these directions serve as reliable features for estimating the magnitude of a property in an image. Without explicit supervision, we use these distances to solve tasks such as image sorting and ordinal regression. By calibrating these distances with just a few labeled examples, we transform a pre-trained GAN into a state-of-the-art few-shot regression model. This approach allows us to tackle regression tasks on datasets and attributes that are challenging to annotate accurately. Extensive experiments demonstrate the versatility of our method across various domains, utilizing different latent direction discovery frameworks. Our approach achieves state-of-the-art performance in few-shot and low-supervision settings, even outperforming methods specifically designed for single-task regression. The code for our method is available on our project website.