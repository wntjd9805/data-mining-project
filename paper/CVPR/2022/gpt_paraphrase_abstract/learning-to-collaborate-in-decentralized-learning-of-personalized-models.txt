Learning personalized models for user-customized computer-vision tasks is difficult due to limited private-data and computation on each edge device. Decentralized learning (DL) can train a global model using images distributed over a network topology, but it is not designed to train personalized models or optimize the topology. Additionally, the mixing weights used in DL to aggregate gradient messages from neighbors may not be optimal for personalization. This paper introduces two approaches: "learning to collaborate (L2C)" and "meta-L2C". L2C optimizes mixing weights to minimize local validation loss for a set of predefined nodes/tasks. Meta-L2C learns an attention mechanism to automatically assign mixing weights by comparing model updates between nodes. Both approaches are evaluated on image classification benchmarks, showing advantages in identifying collaborators, learning sparse topology, and producing better personalized models with low communication and computational costs.