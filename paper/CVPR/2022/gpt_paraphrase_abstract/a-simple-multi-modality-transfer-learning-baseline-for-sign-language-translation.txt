This research proposes a basic method for transfer learning in sign language translation. Due to the limited amount of sign language datasets available, training effective translation models is challenging. To address this issue, the researchers suggest a progressive pretraining approach using both general-domain and within-domain datasets. The visual network is pretrained on general human action datasets and within-domain sign-to-gloss datasets, while the translation network is pretrained on a general multilingual corpus and within-domain gloss-to-text datasets. The two networks are then fine-tuned using a visual-language mapper module. This simple approach outperforms previous state-of-the-art results on two sign language translation benchmarks, demonstrating the effectiveness of transfer learning. The researchers believe that this approach can serve as a strong baseline for future research due to its simplicity and strong performance.