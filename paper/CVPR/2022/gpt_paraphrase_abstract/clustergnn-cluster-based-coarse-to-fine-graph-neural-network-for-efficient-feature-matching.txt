Graph Neural Networks (GNNs) with attention have been successfully used in visual feature matching. However, these methods have a quadratic complexity due to learning with complete graphs. To address this issue, we propose ClusterGNN, an attentional GNN architecture that operates on clusters for feature matching. We leverage the observation that self- and cross-attention matrices converge to a sparse representation. Our approach includes a progressive clustering module that adaptively divides keypoints into subgraphs to reduce redundant connectivity. Additionally, we employ a coarse-to-fine paradigm to mitigate miss-classification within images. Our method significantly reduces runtime (by 59.7%) and memory consumption (by 58.4%) compared to current state-of-the-art GNN-based matching, while maintaining competitive performance on various computer vision tasks.