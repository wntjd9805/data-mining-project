The task of automated panoptic symbol spotting in 2D computer-aided design (CAD) drawings is important for creating 3D prototypes in architecture, engineering, and construction industries. However, the irregular ordering and orientations in CAD drawings pose challenges for existing methods based on convolutional neural networks (CNNs) and/or graph neural networks (GNNs). In this paper, we present a novel framework called CADTransformer that modifies vision transformer (ViT) backbones to address these limitations. CADTransformer tokenizes graphical primitives in CAD drawings and optimizes semantic and instance symbol spotting through prediction heads. The backbone is enhanced with neighborhood aware self-attention, hierarchical feature aggregation, and graphic entity position encoding to incorporate structure prior while optimizing efficiency. Additionally, a new data augmentation method called Random Layer is proposed. CADTransformer significantly improves the previous state-of-the-art in the panoptic quality metric and can spot symbols with irregular shapes and orientations. Our codes are available at the given GitHub link.