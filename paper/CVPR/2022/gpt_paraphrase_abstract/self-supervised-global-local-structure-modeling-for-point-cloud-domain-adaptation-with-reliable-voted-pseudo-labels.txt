This paper proposes an unsupervised method for deep point cloud representation learning in domain adaptation. The method involves learning global representations of unlabeled data by scaling point clouds and predicting scales, as well as capturing local structure by projecting a 3D area onto a 2D plane and reconstructing it. To transfer knowledge from a source domain, pseudo labels are voted for target samples based on their nearest source neighbors in a shared feature space. Only reliable target samples with high voting consistencies are selected to enhance adaptation and avoid noise from incorrect pseudo labels. The voting method adaptsively selects more target samples during training, increasing the amount of labeled target data. Experimental results on various datasets demonstrate the effectiveness of the proposed method.