Generative Adversarial Networks (GANs) have been successful in generating images. However, they struggle with fine-grained data due to limited training samples and subtle differences between categories. To address this, we propose a new approach called SphericGAN that focuses on discovering and utilizing the underlying structure of real data to regulate the spatial organization of latent space. Our model reduces the reliance on labeled data by introducing a semi-supervised hyper-sphericalGAN for class-conditional fine-grained image generation. By projecting random vectors onto a hyper-sphere, we can model complex distributions, with the similarity between latent vectors dependent on angles rather than magnitudes. Additionally, we incorporate a mapping network to align real images with the hyper-sphere's structure, creating a spatially organized latent space that captures class-independent variation factors. Experimental results show that SphericGAN achieves state-of-the-art performance in generating high-fidelity images with precise class semantics.