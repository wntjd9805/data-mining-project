Label noise in deep learning is a significant problem as deep neural networks have the ability to fit all training data. Previous research has focused on using sample selection methods to address this issue, but these methods often rely on hyper-parameters that are difficult to tune and vary depending on the dataset. In this study, we propose an approach called PNP (Probabilistic Noise Prediction) that explicitly models label noise. Our method involves training two networks, one for predicting the category label and the other for predicting the noise type. By predicting label noise probabilistically, we can identify noisy samples and optimize the networks accordingly. We also introduce a joint loss function that combines the classification loss, auxiliary constraint loss, and in-distribution consistency loss for network updates. Through experiments on synthetic and real-world datasets, we demonstrate the effectiveness of our approach. The source code and models are available at the provided GitHub link.