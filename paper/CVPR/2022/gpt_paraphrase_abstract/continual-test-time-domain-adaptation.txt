Test-time domain adaptation is a technique used to adapt a pre-trained model from a source domain to a target domain without using any source data. Previous methods have focused on static target domains, but real-world machine perception systems operate in dynamic environments where the target domain distribution can change over time. Existing methods based on self-training and entropy regularization struggle in these non-stationary environments.This study introduces a continual test-time adaptation approach called CoTTA to address these challenges. CoTTA consists of two parts. Firstly, the error accumulation is reduced by utilizing weight-averaged and augmentation-averaged predictions, which are typically more accurate. Secondly, to prevent catastrophic forgetting, a small portion of the neurons is stochastically restored to the source pre-trained weights during each iteration, preserving the source knowledge in the long-term. This approach allows for long-term adaptation of all parameters in the network.CoTTA is easy to implement and can be easily integrated into pre-trained models. The effectiveness of CoTTA is demonstrated on four classification tasks and a segmentation task for continual test-time adaptation, outperforming existing methods. The code for CoTTA is available at https://qin.ee/cotta.