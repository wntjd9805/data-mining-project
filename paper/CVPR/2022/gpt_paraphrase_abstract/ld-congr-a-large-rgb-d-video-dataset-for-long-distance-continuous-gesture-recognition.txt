This paper introduces the LD-ConGR dataset, which is a large RGB-D video dataset specifically designed for long-distance gesture recognition in interactive scenes like meetings and smart homes. Unlike existing gesture datasets that focus on close-range interactions, LD-ConGR captures gestures up to 4m away from the camera, providing a more realistic long-distance scenario. Additionally, LD-ConGR includes fine-grained annotations, such as temporal segmentation of gestures and hand location, enhancing the dataset's usability. The videos in LD-ConGR are captured at high resolution and frame rate, ensuring high-quality data for analysis. The paper also presents experimental results that demonstrate the effectiveness of gesture region estimation and key frame sampling strategies in dealing with long-distance gesture recognition and the uncertainty of gesture duration. Overall, the LD-ConGR dataset and the findings from this research are expected to advance the field of long-distance gesture recognition. The dataset is publicly available for further research and can be accessed through the provided link.