The traditional approach to continual learning is to adjust the model parameters to accommodate changing data distributions, but this often leads to catastrophic forgetting. Existing methods tackle this issue by using a rehearsal buffer or known task identity during testing to retrieve previously learned knowledge. In contrast, this study introduces a novel approach to continual learning that focuses on training a more efficient memory system without relying on task identity during testing. The proposed method, called Learn to Prompt (L2P), prompts a pre-trained model to learn tasks sequentially with different task transitions. Prompts are small, learnable parameters stored in a memory space, and the objective is to optimize prompts to guide the model's predictions and manage both task-specific and task-invariant knowledge while ensuring model adaptability. The researchers conducted extensive experiments on popular image classification benchmarks using various challenging continual learning scenarios, and L2P consistently outperformed previous state-of-the-art methods. Surprisingly, L2P achieved competitive results even without a rehearsal buffer and is directly applicable to challenging task-agnostic continual learning. The source code for L2P is available at https://github.com/google-research/l2p.