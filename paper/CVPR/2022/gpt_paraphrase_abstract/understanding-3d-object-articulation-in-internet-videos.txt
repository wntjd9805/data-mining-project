We aim to investigate the identification and characterization of the 3D planar articulation of objects using regular RGB videos. While humans find this task relatively simple, it presents numerous challenges for computers. Our proposed method involves a top-down detection system that identifies planes capable of articulation. Subsequently, we optimize for a 3D plane that can explain a series of detected articulations. We demonstrate that this system can be trained using a combination of videos and 3D scan datasets. Our approach achieves impressive performance when tested on challenging Internet videos and the Charades dataset.