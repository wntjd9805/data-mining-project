The RecogTrans paradigm for self-supervised video representation learning has been overshadowed by instance discrimination approaches in recent works. However, after comparing RecogTrans and InstDisc methods, it is clear that RecogTrans has great potential for both semantic-related and temporal-related tasks. Existing RecogTrans approaches suffer from noisy supervision signals, so we developed TransRank, a unified framework that recognizes transformations in a ranking formulation. TransRank provides accurate supervision signals by recognizing transformations relatively, outperforming classification-based methods. The framework can be used with any set of temporal or spatial transformations, demonstrating its generality. Through empirical practices, we achieved competitive performance in video retrieval and action recognition. TransRank surpasses the previous state-of-the-art method by 6.4% and 8.3% in action recognition, and improves video retrieval by 20.4%. These promising results show that RecogTrans is still a valuable paradigm for video self-supervised learning. The code for TransRank is available at https://github.com/kennymckormick/TransRank.