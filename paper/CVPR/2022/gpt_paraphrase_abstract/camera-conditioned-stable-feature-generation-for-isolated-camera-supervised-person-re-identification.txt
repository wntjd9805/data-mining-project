In order to address the challenge of learning camera-view invariant features for person re-identification (Re-ID) when cross-camera image pairs are unavailable, a new approach called Camera-Conditioned Stable Feature Generation (CCSFG) is proposed. This approach involves synthesizing cross-camera samples in the feature space for model training. The CCSFG method optimizes both the feature encoder and generator in an end-to-end manner. To ensure the stability of the generative model training, a new feature generator called σ-Regularized Conditional Variational Autoencoder (σ-Reg. CVAE) is introduced, which is analyzed theoretically and experimentally for its robustness. Extensive experiments conducted on two ISo-lated Camera Supervised (ISCS) person Re-ID datasets demonstrate the superiority of CCSFG compared to other competing methods. The abstract is accompanied by Figure 1, which illustrates the training samples in different person Re-ID settings, emphasizing the absence of cross-camera image pairs in the ISCS setting.