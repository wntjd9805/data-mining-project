Nowadays, AI-equipped cameras are capable of automatically capturing and analyzing images to detect people. However, these AI systems can be prone to errors when faced with intentionally designed patterns in the real world, known as physical adversarial examples. Previous studies have demonstrated that printing adversarial patches on clothing can be used to evade person detectors based on deep neural networks (DNNs). However, these adversarial examples often experience a significant decrease in their success rate when the viewing angle of the camera changes. To address this limitation, we propose a multi-angle attack technique called Adversarial Texture (AdvTexture). AdvTexture can be applied to clothes of various shapes, allowing individuals wearing such clothing to hide from person detectors at different viewing angles. We introduce a generative method called Toroidal-Cropping-based Expandable Gen-erative Attack (TC-EGA) to create AdvTexture with repetitive structures. We printed several pieces of cloth with AdvTexture and used them to make T-shirts, skirts, and dresses in the real world. Experimental results demonstrate that these clothes successfully deceive person detectors in physical environments.