Recent advancements in point cloud registration have focused on incorporating learning techniques to improve feature descriptors. However, most of these approaches still rely on traditional methods like nearest-neighbor feature matching and RANSAC outlier filtering to determine the final correspondences for pose estimation. In this study, we propose an alternative approach by utilizing attention mechanisms to replace explicit feature matching and RANSAC. We introduce an end-to-end framework that directly predicts the final set of correspondences. Our framework utilizes a network architecture primarily composed of transformer layers with self and cross attentions. We train this network to predict the probability of each point lying in the overlapping region and its corresponding position in the other point cloud. By directly estimating the required rigid transformation from the predicted correspondences, we eliminate the need for additional post-processing. Despite its simplicity, our approach achieves state-of-the-art performance on benchmark datasets such as 3DMatch and ModelNet. The source code for our method can be found at https://github.com/yewzijian/RegTR.