Many researchers have focused on improving the spatial invariance of convolutional networks in order to accurately count objects. However, our investigation into mainstream counting networks has revealed that overly strict pixel-level spatial invariance can actually introduce noise in the generation of density maps. In this study, we propose a novel approach using locally connected Gaussian kernels instead of traditional convolution filters to estimate the spatial position in the density map. This allows the feature extraction process to potentially overcome annotation noise and enhance the generation of density maps. Inspired by previous work, we introduce a low-rank approximation with translation invariance to efficiently approximate massive Gaussian convolution. Our findings suggest that future research should explore ways to relax the overly strict pixel-level spatial invariance in object counting. We evaluate our approach on four popular object counting networks and conduct extensive experiments on seven benchmarks across three applications: crowd, vehicle, and plant counting. The experimental results demonstrate that our method outperforms state-of-the-art approaches, achieving promising results in learning the spatial position of objects.