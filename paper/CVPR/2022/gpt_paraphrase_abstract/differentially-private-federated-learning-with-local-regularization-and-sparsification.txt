This paper examines the problem of decreased model accuracy in federated learning when ensuring user-level differential privacy (DP). The authors identify that the issue can be addressed by limiting the norm of local updates before implementing DP mechanisms. They propose two techniques, Bounded Local Update Regularization and Local Update Sparsification, to enhance model quality while preserving privacy. The authors provide theoretical analysis on the convergence of their framework and offer rigorous privacy guarantees. Extensive experiments demonstrate that their approach significantly improves the trade-off between privacy and utility compared to existing methods for federated learning with user-level DP guarantee.