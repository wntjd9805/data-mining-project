Existing video frame interpolation algorithms often rely on complex models with heavy parameters or large delays, limiting their real-time applications. In this study, we introduce an efficient encoder-decoder network called IFRNet for quickly synthesizing intermediate frames. The network extracts pyramid features from input frames and refines the bilateral intermediate flow fields along with a powerful intermediate feature to generate the desired output. The progressively refined intermediate feature not only aids in estimating intermediate flows but also compensates for contextual details, eliminating the need for additional synthesis or refinement modules. To fully unlock its potential, we propose a novel task-oriented optical flow distillation loss that focuses on learning valuable teacher knowledge for frame synthesis. Additionally, a new geometry consistency regularization term is applied to the progressively refined intermediate features to maintain better structural layout. Experimental results on various benchmarks demonstrate the outstanding performance and fast inference speed of our proposed approaches. The code for our work is available at https://github.com/ltkong218/IFRNet.