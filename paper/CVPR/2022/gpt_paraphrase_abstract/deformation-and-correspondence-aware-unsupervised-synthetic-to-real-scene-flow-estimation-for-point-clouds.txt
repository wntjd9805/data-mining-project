Point cloud scene flow estimation is crucial for autonomous driving in dynamic environments. Currently, methods rely on synthetic data for model training due to the difficulty of obtaining scene flow labels. However, the significant discrepancies between synthetic datasets and real scenes lead to poor model transfer. To address this issue, we propose two contributions. Firstly, we introduce a point cloud collector and scene flow annotator for the GTA-V engine, enabling the automatic generation of diverse and realistic training samples without human intervention. This allows us to create a large-scale synthetic scene flow dataset called GTA-SF. Secondly, we present a mean-teacher-based domain adaptation framework that utilizes self-generated pseudo-labels from the target domain. Our framework also incorporates shape deformation regularization and surface correspondence refinement to tackle distortions and misalignments during domain transfer. Through extensive experiments, we demonstrate that our GTA-SF dataset significantly enhances model generalization compared to the commonly used FT3D dataset when tested on three real datasets (Waymo, Lyft, and KITTI). Additionally, our framework achieves superior adaptation performance on six source-target dataset pairs, reducing the average domain gap by 60%. The data and codes for our approach are available at https://github.com/leolyj/DCA-SRSFE.