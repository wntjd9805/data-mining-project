We introduce Masked Feature Prediction (MaskFeat) as a method for self-supervised pre-training of video models. Our approach involves randomly masking a portion of the input sequence and then predicting the features of these masked regions. We explore five different types of features and discover that Histograms of Oriented Gradients (HOG), a manually engineered feature descriptor, performs exceptionally well in terms of both effectiveness and efficiency. We find that the local contrast normalization within HOG is crucial for achieving good results, consistent with previous research on HOG for visual recognition. Our approach enables the learning of abundant visual knowledge and facilitates the training of large-scale Transformer-based models. Remarkably, MaskFeat, which does not rely on additional model weights or supervision, achieves unprecedented results on various datasets, including 86.7% with MViTv2-L on Kinetics-400, 88.3% on Kinetics-600, 80.4% on Kinetics-700, 38.8 mAP on AVA, and 75.0% on SSv2. Moreover, MaskFeat's capabilities extend to image inputs, where it can be interpreted as a video with a single frame, and it achieves competitive performance on ImageNet.