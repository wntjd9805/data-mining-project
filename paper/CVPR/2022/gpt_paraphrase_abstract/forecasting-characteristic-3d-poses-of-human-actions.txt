We introduce a new task called characteristic 3D pose forecasting, which involves predicting the future pose of a person in a specific action-defining pose based on a short sequence observation. Previous approaches to human motion prediction focused on estimating future poses at fixed time intervals, but this approach fails to capture the temporal and intentional aspects of human action. Instead, we propose a semantically meaningful pose prediction task that separates the predicted pose from time, drawing inspiration from goal-directed behavior.To achieve accurate characteristic pose prediction, we propose a probabilistic approach that considers the possible multi-modality in the distribution of likely poses. By sampling future pose hypotheses from the predicted distribution in an autoregressive manner, we are able to model the dependencies between joints. To evaluate the effectiveness of our method, we create a dataset of manually annotated characteristic 3D poses. Our experiments with this dataset demonstrate that our proposed probabilistic approach outperforms state-of-the-art methods by an average of 26%.