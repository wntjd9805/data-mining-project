This study focuses on the limitations of 6D object pose estimation networks when it comes to scaling to a large number of object instances. These networks rely on high-fidelity object CAD models and make the close-set assumption. However, this work aims to address a new open set problem, which involves few-shot 6D object pose estimation. This means estimating the 6D pose of an unknown object using only a few support views without additional training. To tackle this problem, the researchers emphasize the importance of fully exploring the appearance and geometric relationship between the support views and query scene patches. They propose a dense prototypes matching framework that utilizes transformers to extract and match dense RGBD prototypes. Additionally, the researchers highlight the significance of diverse appearance and shape priors for generalization capability and introduce a large-scale RGBD photorealistic dataset called ShapeNet6D for network pre-training. They also introduce an online texture blending approach to eliminate the domain gap in the synthesis dataset, enhancing appearance diversity. The researchers conclude by discussing potential solutions to this problem and establishing benchmarks on popular datasets to facilitate future research. The core idea is to address the few-shot 6D object pose estimation problem by exploring the appearance and geometric relationship between support views and query scene patches, utilizing a dense prototypes matching framework with transformers, and leveraging diverse appearance and shape priors through pre-training on ShapeNet6D dataset. They also introduce an online texture blending approach and establish benchmarks for future research.