Recent advancements in computer vision have shown that a pure MLP architecture composed of fully-connected layers can achieve comparable performance to CNN and transformer models. However, existing MLP models overlook the varying semantic information of tokens from different images by aggregating them with fixed weights. To address this issue, we propose representing each token in a vision MLP as a wave function consisting of an amplitude and a phase term. The amplitude represents the original feature, while the phase term is a complex value that changes based on the semantic contents of the input images. By introducing the phase term, we can dynamically modulate the relationship between tokens and fixed weights in the MLP. Building upon this wave-like token representation, we introduce a novel architecture called Wave-MLP for vision tasks. Extensive experiments demonstrate that Wave-MLP outperforms state-of-the-art MLP architectures in various vision tasks, including image classification, object detection, and semantic segmentation. The source code for Wave-MLP is available at the following links: [insert links].