We present 3D Moments, a novel computational photography technique that generates a video effect. Our method utilizes a pair of nearly identical photos, capturing moving subjects from similar angles, which are commonly found in people's photo collections. The output is a video that seamlessly interpolates the motion of the scene from the first photo to the second, while also incorporating camera motion with parallax to create a heightened perception of depth.  To achieve this effect, we employ a representation of the scene consisting of two layered depth images, based on features, and augmented with scene flow. This representation allows for motion interpolation and independent control of the camera viewpoint. Our system generates space-time videos that are visually realistic, incorporating motion parallax and scene dynamics. Moreover, it effectively recovers regions that were occluded in the original views.  We have conducted extensive experiments to validate the performance of our system. The results demonstrate its superiority over baseline methods when tested on public datasets and real-world photos. For more information, please visit our project page: https://3d-moments.github.io/.