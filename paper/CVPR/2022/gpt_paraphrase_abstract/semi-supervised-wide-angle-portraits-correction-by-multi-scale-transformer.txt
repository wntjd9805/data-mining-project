We present a new approach to correct wide-angle portraits using a semi-supervised network. Wide-angle images often have perspective distortion, particularly noticeable in the face regions. Previous deep learning methods require ground-truth correction flow maps for training, which are costly to obtain manually. To address this, we propose a semi-supervised scheme that utilizes both labeled and unlabeled data to improve performance. Our scheme incorporates novel components such as direction and range consistency (DRC) and regression consistency (RC) to ensure consistency in the correction process. Additionally, we introduce the Multi-Scale Swin-Unet (MS-Unet) based on the multi-scale swin transformer block (MSTB) to simultaneously learn short-distance and long-distance information and avoid artifacts. Extensive experiments demonstrate that our method outperforms state-of-the-art techniques and other baselines. The source code and dataset can be found at https://github.com/megvii-research/Portraits_Correction.