We examine the issue of omni-supervised object detection, where various types of annotations, including unlabeled, fully labeled, and weakly labeled data, are used. Our approach, Omni-DETR, combines the student-teacher framework and transformer-based object detection to create a unified architecture. By utilizing different weak labels, we can generate accurate pseudo labels for the model to learn through a filtering mechanism based on bipartite matching. In our experiments, Omni-DETR achieves state-of-the-art results across multiple datasets and settings. We also find that weak annotations can improve detection performance and a combination of these annotations offers a better balance between annotation cost and accuracy compared to complete annotations. These findings suggest the potential for larger object detection datasets with mixed annotations. The code for Omni-DETR is available at https://github.com/amazon-research/omni-detr.