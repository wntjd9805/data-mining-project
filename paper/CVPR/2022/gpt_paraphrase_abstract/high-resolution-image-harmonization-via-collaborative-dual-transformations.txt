The demand for high-resolution image harmonization, which adjusts the foreground of a composite image to match the background, has increased. However, this area of research is still largely unexplored. Traditional methods for image harmonization focus on global RGB-to-RGB transformations, which can easily handle high-resolution images but overlook local context. Deep learning methods have emerged recently, aiming to learn dense pixel-to-pixel transformations for generating harmonious outputs. However, these methods are limited in low resolution. In this study, we propose a high-resolution image harmonization network called Collaborative Dual Transformation (CDTNet) that combines pixel-to-pixel and RGB-to-RGB transformations in a coherent end-to-end network. CDTNet includes a low-resolution generator for pixel-to-pixel transformation, a color mapping module for RGB-to-RGB transformation, and a refinement module that leverages both transformations. We conducted extensive experiments on high-resolution benchmark datasets and our own high-resolution composite images, demonstrating that CDTNet achieves a favorable balance between efficiency and effectiveness. The datasets used in our experiments can be accessed at https://github.com/bcmi/CDTNet-High-Resolution-Image-Harmonization.