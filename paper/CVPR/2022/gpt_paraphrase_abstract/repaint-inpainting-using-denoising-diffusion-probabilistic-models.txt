This study introduces RePaint, a novel approach to free-form inpainting that overcomes limitations of existing methods. Traditional approaches are typically trained on specific types of masks, limiting their ability to generalize to unseen mask types. Additionally, these approaches often produce simple texture extensions rather than semantically meaningful content. RePaint addresses these issues by utilizing a Denoising Diffusion Probabilistic Model (DDPM) as a generative prior. The model is pretrained and unconditional, allowing it to produce high-quality and diverse output images for any inpainting form. The generation process is conditioned by altering reverse diffusion iterations and sampling unmasked regions using the given image information. This conditioning technique does not modify the original DDPM network itself. The effectiveness of RePaint is demonstrated through experiments on both face and general-purpose image inpainting, using standard and extreme masks. RePaint outperforms state-of-the-art Autoregressive and GAN approaches for at least five out of six mask distributions. The code for RePaint is available on the Github repository git.io/RePaint.