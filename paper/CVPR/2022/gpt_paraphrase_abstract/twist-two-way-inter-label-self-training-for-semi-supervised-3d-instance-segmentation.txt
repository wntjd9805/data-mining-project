We investigate a method to address the problem of requiring a large number of labeled data in a semi-supervised context for 3D instance segmentation. In order to improve the performance of the model using unlabeled data, we propose a new framework called TWIST (Two-Way Inter-label Self-Training). TWIST leverages the inherent correlations between the understanding of semantic information and instance-level details in a scene. We introduce two types of pseudo labels for supervision at the semantic and instance levels. Our main approach involves providing object-level information to refine the quality of the pseudo labels and utilizing their correlation to enhance each other, thereby continuously improving the quality of the pseudo labels. TWIST achieves superior performance on both ScanNet and S3DIS datasets compared to recent 3D pre-training methods. It can also be combined with these methods to further improve performance, with a notable increase of 4.4% in AP50 on the 1%-labeled ScanNet data-efficient benchmark. The source code for TWIST is available at https://github.com/dvlab-research/TWIST.