We propose a novel framework for detecting camouflaged objects in videos called video camouflaged object detection (VCOD). Camouflaged objects are difficult to identify in still images because they blend in with the background. Therefore, effectively handling the temporal dynamics in videos is crucial for VCOD. Current VCOD methods often use homography or optical flows to represent motion, but this can lead to detection errors due to motion estimation and segmentation errors. In contrast, our method combines motion estimation and object segmentation in a single optimization framework. We create a dense correlation volume to capture motion between neighboring frames and optimize motion estimation and segmentation together using the final segmentation supervision. To ensure temporal consistency within a video sequence, we use a spatio-temporal transformer to refine short-term predictions. Experimental results on VCOD benchmarks demonstrate the effectiveness of our approach. We also introduce a new VCOD dataset called MoCA-Mask, which includes pixel-level ground-truth masks, and construct a comprehensive benchmark with previous methods to facilitate further research in this area.