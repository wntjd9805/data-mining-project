We propose a new approach to enhance the interpretability of deep neural networks (DNNs) by promoting alignment between weights and inputs during training. Instead of using linear transforms in DNNs, we suggest replacing them with our B-cos transform. By utilizing a sequence of these transforms, we can generate a single linear transform that accurately summarizes the model computations. This B-cos transform applies pressure on the weights during optimization, leading to highly interpretable linear transforms that align with task-relevant features. Importantly, the B-cos transform can be easily integrated into popular DNN architectures like VGGs, ResNets, InceptionNets, and DenseNets without sacrificing performance on ImageNet. The resulting explanations are visually appealing and perform well in terms of interpretability metrics. The code for our approach is available at github.com/moboehle/B-cos.