Our objective is to acquire knowledge of visual correspondence through unlabeled videos. We have developed a method called LIIR, which addresses three essential aspects of self-supervised correspondence learning: instance discrimination, location awareness, and spatial compactness. Unlike previous approaches that focus solely on intra-video self-supervision, LIIR incorporates cross-video affinities as additional negative samples within a unified inter- and intra-video reconstruction framework. This enables the learning of discriminative representations by contrasting desired intra-video pixel associations with negative inter-video correspondences. Additionally, we integrate positional information into correspondence matching and employ a position shifting strategy to mitigate the side effects of position encoding when computing inter-video affinities, thereby enhancing the location sensitivity of LIIR. Furthermore, to fully exploit the spatial continuity inherent in video data, we impose a constraint based on compactness during correspondence matching, resulting in sparser and more reliable solutions. Our learned representation surpasses the performance of state-of-the-art self-supervised methods on label propagation tasks involving objects, semantic parts, and keypoints.