This paper introduces a novel approach called universal photometric stereo, which aims to address the limitations of existing methods that rely on specific lighting models. The proposed solution algorithm is designed to work for objects with different shapes and materials, under various lighting conditions, without making any assumptions about specific models. To tackle this challenging task, a data-driven method is presented, which replaces the recovery of physical lighting parameters with the extraction of a generic lighting representation known as global lighting contexts. These contexts are used as lighting parameters in a calibrated photometric stereo network to estimate surface normal vectors at the pixel level. To ensure the adaptability of the network to different shapes, materials, and lighting conditions, it is trained on a synthetic dataset that simulates the appearance of objects in natural environments. The effectiveness of the proposed method is demonstrated by comparing it with other state-of-the-art uncalibrated photometric stereo methods using test data.