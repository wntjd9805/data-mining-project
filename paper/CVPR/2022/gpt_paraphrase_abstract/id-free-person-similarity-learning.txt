This study focuses on training a unified model for person detection and re-identification without the need for manually labeling person identities in the training dataset. Typically, training such models requires labeled images/videos with both person boxes and identities, which can be expensive to collect. To address this, the authors propose a contrastive learning framework that learns person similarity without using manually labeled identity annotations. They apply image-level augmentation to public person detection datasets to train a strong model for general person detection and short-term re-identification. For longer-term re-identification, they leverage the natural appearance evolution of each person in videos as instance-level appearance augmentation. Despite not having access to the target dataset or person identity annotations, their model achieves competitive results compared to existing fully-supervised methods in person search and tracking tasks. Additionally, their model shows promising potential for reducing annotation costs while maintaining performance in person search tasks.