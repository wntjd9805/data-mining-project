We introduce a new framework called PlaneMVS for reconstructing 3D planes from multiple input views with known camera poses. Unlike previous methods that rely on single-view regression and suffer from depth scale ambiguity, our approach utilizes a multi-view-stereo (MVS) pipeline that takes advantage of multi-view geometry. We divide the plane reconstruction process into a semantic plane detection branch and a plane MVS branch. The semantic plane detection branch is similar to a single-view plane detection framework but with some differences. The plane MVS branch uses a set of slanted plane hypotheses instead of conventional depth hypotheses to perform a plane sweeping strategy and learns pixel-level plane parameters and planar depth maps. We explain how the two branches are learned in a balanced manner and propose a soft-pooling loss to combine their outputs and leverage each other's benefits. Extensive experiments on various indoor datasets demonstrate that PlaneMVS outperforms state-of-the-art single-view plane reconstruction methods in terms of both plane detection and 3D geometry metrics. Our method even surpasses a set of state-of-the-art learning-based MVS methods due to the learned plane priors. To our knowledge, this is the first work on 3D plane reconstruction within an end-to-end MVS framework.