Transformer-based methods have been successful in human-object interaction (HOI) detection. However, these models often use queries that have multiple interpretations, which limits the transformer's ability to learn representations effectively. Additionally, there is a scarcity of labeled human-object pairs in existing datasets, which restricts the transformer's predictive power. To address the first issue, we propose a knowledge distillation model called Distillation using Oracle Queries (DOQ). This model shares parameters between a teacher network and a student network. The teacher network uses clear and semantically unambiguous oracle queries to generate high-quality decoder embeddings. By imitating both the attention maps and decoder embeddings of the teacher network, the student network's representation learning capability is significantly enhanced.To tackle the second problem, we introduce a data augmentation method called Context-Consistent Stitching (CCS). This method generates complex images in real-time by stitching labeled human-object pairs from multiple training images. The selection of source images with similar contexts ensures that the synthesized images appear visually realistic. Our methods greatly improve the accuracy and training efficiency of transformer-based HOI detection models.Experimental results demonstrate that our proposed approach consistently outperforms state-of-the-art methods on three benchmark datasets: HICO-DET, HOI-A, and V-COCO. The code for our approach is available at https://github.com/SherlockHolmes221/DOQ.