Neural Radiance Fields (NeRF) are widely used for generating realistic images from new viewpoints. However, their performance suffers when there are fewer input views. We identified that errors in estimating scene geometry and divergent behavior during training contribute to these issues. To address this, we introduced regularization techniques to improve the geometry and appearance of unobserved viewpoints. We also utilized a normalizing flow model to enhance the color consistency of these viewpoints. Our approach outperformed not only other single-scene optimization methods but also conditional models trained on large multi-view datasets.