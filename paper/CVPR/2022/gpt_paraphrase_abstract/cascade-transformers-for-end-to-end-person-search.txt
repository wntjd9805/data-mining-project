This study focuses on the challenging task of person search, which involves locating a specific individual within a collection of scene images. The difficulty lies in dealing with factors such as variations in scale, changes in pose and viewpoint, and occlusions. To address this, the authors propose a novel approach called Cascade Occluded Attention Transformer (COAT) for end-to-end person search. The method consists of three stages, with the first stage dedicated to detecting people and subsequent stages refining the representation for person detection and re-identification. At each stage, the occluded attention transformer applies stricter intersection over union thresholds to encourage the learning of coarse-to-fine pose and scale invariant features. Additionally, the authors calculate the occluded attention for each detection, allowing the differentiation of a person's tokens from those of other people or the background. This accounts for the occlusion effects caused by other objects at the token level. The effectiveness of the proposed method is demonstrated through extensive experiments, showcasing its superior performance compared to existing approaches on two benchmark datasets.