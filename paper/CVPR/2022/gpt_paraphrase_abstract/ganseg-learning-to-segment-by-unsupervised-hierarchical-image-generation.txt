Segmenting an image into its constituent parts is a common preprocessing step in high-level vision tasks like image editing. However, the process of annotating masks for supervised training is costly. Although weakly-supervised and unsupervised methods exist, they rely on comparing pairs of images, such as those from different viewpoints, video frames, or image augmentation, which limits their practicality. To overcome this limitation, we propose a GAN-based approach that generates images conditioned on latent masks, eliminating the need for full or weak annotations required by previous methods. We demonstrate that this mask-conditioned image generation can be effectively learned by conditioning the masks hierarchically on 2D latent points that explicitly define the position of image parts. Without the need for supervised masks or points, this strategy enhances the robustness of masks to changes in viewpoint and object position. Additionally, it enables the generation of image-mask pairs that can be used for training a segmentation network, outperforming state-of-the-art unsupervised segmentation methods on established benchmarks. The source code for our approach can be accessed at https://github.com/xingzhehe/GANSeg.