Object detection has made significant progress in recent years with the emergence of powerful deep neural networks. However, current methods are limited by two main assumptions: they are trained on fixed datasets and evaluated on pre-recorded test sets, and the models are frozen after training without any further updates. These limitations restrict the applicability of object detection methods in real-world settings. In this paper, we introduce Interactron, a method for adaptive object detection in an interactive setting where an agent navigates different environments. Instead of relying on fixed training and test sets, Interactron continues training during inference and adapts the model at test time by interacting with the environment. Our adaptive object detection model outperforms the recent high-performance detector, DETR, with an 11.8 point improvement in average precision (AP) and a 19.1 point improvement in AP50. Furthermore, our model shows the ability to adapt to environments with different appearance characteristics, performing on par with models trained with full supervision for those environments. The code for Interactron is available at: https://github.com/allenai/interactron.