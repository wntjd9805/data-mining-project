This paper introduces a new method for detecting deepfakes called self-blended images (SBIs). SBIs are created by blending pseudo source and target images from single pristine images, replicating common forgery artifacts. The main idea behind SBIs is that more general and less recognizable fake samples encourage classifiers to learn generic and robust representations without becoming too specific to manipulation-related artifacts. The proposed approach is compared to state-of-the-art methods on various datasets, including FF++, CDF, DFD, DFDC, DFDCP, and FFIW, using standard cross-dataset and cross-manipulation protocols. Extensive experiments demonstrate that the method enhances model generalization to unknown manipulations and scenes. Specifically, on DFDC and DFDCP datasets where existing methods struggle with the gap between the training and test sets, the proposed approach achieves a performance improvement of 4.90% and 11.78% points in the cross-dataset evaluation, respectively. The code for this method can be found at https://github.com/mapooon/SelfBlendedImages.