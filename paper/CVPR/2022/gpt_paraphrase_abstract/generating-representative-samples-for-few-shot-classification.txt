We propose a method for few-shot learning that addresses the issue of biased class representations due to limited data. Our approach involves generating visual samples based on semantic embeddings using a conditional variational autoencoder (CVAE) model. We train the CVAE model on base classes and utilize it to generate features for novel classes. Crucially, we improve the representativeness of the generated samples by excluding non-representative samples from the base training set during CVAE model training. Our experimental results demonstrate significant improvements over three baseline methods for few-shot learning, achieving state-of-the-art performance on the miniImageNet and tieredImageNet datasets in both 1-shot and 5-shot settings. The code for our method is available at: https://github.com/cvlab-stonybrook/fsl-rsvae.