Convolutional image deraining networks have achieved significant success but are computationally and memory intensive. Most model compression methods require original data for iterative fine-tuning, which is often limited in real-world applications due to storage, privacy, and transmission constraints. Fine-tuning compressed models with self-collected data may lead to poor generalization across different degradation characteristics. To tackle this issue, a data-free compression framework is proposed for deraining networks. The framework leverages the clustering of deep degradation representations based on degradation characteristics, regardless of image content. The proposed approach generates diverse degraded images using a deep inversion paradigm and uses them to distill the pruned model. The performance of the pruned model is preserved through a dual-branch approach. In one branch, the pre-trained model (teacher) is inverted to reconstruct degraded inputs resembling the original distribution, with orthogonal regularization ensuring degradation diversity in deep features. In the other branch, the pruned model (student) is distilled to fit the teacher's statistical modeling on these dreamed inputs. Additionally, an adaptive pruning scheme is introduced to determine hierarchical sparsity, reducing regression drift in the initial pruned model. Experimental results on various deraining datasets demonstrate that the proposed method can reduce the FLOPs (floating point operations) of state-of-the-art models by approximately 40% without original data while maintaining comparable performance.