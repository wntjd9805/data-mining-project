This paper presents a novel approach to domain adaptive object detection, which is a challenging task due to the differences in data distribution between the source and target domains. The proposed framework focuses on achieving domain-invariant feature learning by aligning the dependencies across different levels of granularity, including pixels, instances, and categories. The framework utilizes a multi-granularity alignment strategy that simultaneously considers pixel-, instance-, and category-level information to align the two domains. Starting with pixel-level feature maps from the backbone network, the framework incorporates an omni-scale gated fusion module to combine discriminative representations of instances through scale-aware convolutions. This enables robust multi-scale object detection.Additionally, the framework introduces multi-granularity discriminators to determine the domain of different granularities of samples, such as pixels, instances, and categories. These discriminators leverage both the discriminability of instances across different categories and the consistency of categories between the two domains.The effectiveness of the proposed framework is evaluated through extensive experiments on various domain adaptation scenarios. The results demonstrate its superiority over state-of-the-art algorithms when applied to anchor-free FCOS and anchor-based Faster R-CNN detectors with different backbone networks.