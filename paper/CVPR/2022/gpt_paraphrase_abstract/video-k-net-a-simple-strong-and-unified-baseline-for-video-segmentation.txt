This paper introduces Video K-Net, a unified framework for video panoptic segmentation. Video K-Net is based on K-Net, a method that combines learnable kernels for image segmentation. By leveraging the learnable kernels from K-Net, Video K-Net can associate identical instances across video frames. It achieves state-of-the-art results on Citscapes-VPS and KITTI-STEP without any additional complexity. On KITTI-STEP, it outperforms previous methods by almost 12% relative improvement. Video K-Net also improves various baselines by 2% on the VSPW dataset for video semantic segmentation. Additionally, K-Net is extended into a clip-level video framework for video instance segmentation, achieving 40.5% and 51.5% mAP on the YouTube-2019 validation set using ResNet50 and Swin-base backbones, respectively. This simple yet effective method can serve as a flexible baseline in video segmentation.