This paper introduces a new method called HierKD for open-vocabulary one-stage object detection. The goal of open-vocabulary object detection is to detect objects that are not part of the training set. While two-stage detectors have been successful in aligning the visual space of the detector with the semantic space of the Pre-trained Visual-Language Model (PVLM), one-stage detectors have struggled due to the lack of class-agnostic object proposals. This hinders the knowledge distillation on unseen objects and leads to poor performance.  To address this issue, the proposed HierKD method incorporates a hierarchical visual-language knowledge distillation approach. It utilizes global-level knowledge distillation to transfer knowledge from the PVLM to the detector for unseen categories. Additionally, it combines global-level knowledge distillation with instance-level knowledge distillation to learn both seen and unseen category knowledge simultaneously.  Experiments conducted on the MS-COCO dataset demonstrate the effectiveness of HierKD. It outperforms the previous best one-stage detector, achieving gains of 11.9% and 6.7%AP50 under the zero-shot detection and generalized zero-shot detection settings. Furthermore, it reduces the AP50 performance gap from 14% to 7.3% compared to the best two-stage detector. The code for HierKD will be made available at the provided URL.