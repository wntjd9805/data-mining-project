We present DiffPhy, a differentiable physics-based model for reconstructing articulated 3D human motion from video. Previous approaches in human motion analysis using physics-based reasoning have been limited due to the complexity of constructing accurate physical models and the challenges of performing stable and efficient inference with physics involved. We address these challenges by proposing an approach that combines a realistic body representation with anatomical joint limits, a differentiable physics simulator, and optimization techniques that ensure good performance and robustness against suboptimal solutions. Unlike recent methods, our approach supports full-body contact, including interactions with objects in the scene. Furthermore, our model can be seamlessly integrated with images, allowing for direct physics optimization using gradient-based methods and image-based loss functions. We validate our model by demonstrating its ability to accurately reconstruct physically plausible 3D human motion from monocular video, both on established benchmarks with available 3D ground-truth data and on videos obtained from the internet.