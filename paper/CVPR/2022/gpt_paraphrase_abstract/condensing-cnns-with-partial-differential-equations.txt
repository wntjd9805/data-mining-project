Convolutional neural networks (CNNs) are known for their depth, which allows them to capture complex features. However, this depth also leads to high computational costs, especially for low-resource IoT devices. To address this issue, we investigate the use of partial differential equations (PDEs) as an alternative to convolutional operators. By leveraging PDEs, we can achieve a global receptive field without the need for large kernel convolutional filters. We introduce a new layer called the Global layer, which applies PDE constraints to the feature maps, resulting in more informative features. These constraints are solved using iterative schemes embedded within the network. The Global layer can be integrated into any deep CNN, effectively reducing its depth and making it more compact and computationally efficient. Despite the reduction in complexity, our experimental evaluation shows that architectures with Global layers perform similarly to the original networks while requiring 2-5 times less computational and storage resources.