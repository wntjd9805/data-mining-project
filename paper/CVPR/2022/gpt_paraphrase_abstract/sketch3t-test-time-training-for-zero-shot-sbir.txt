Zero-shot sketch-based image retrieval is a method that involves applying a trained model to unseen categories. However, we argue that this approach is not suitable for sketches due to their abstract and subjective nature. While the model may work well for new categories, it fails to understand sketches that belong to different test-time distributions. To address this limitation, we introduce an extension to zero-shot sketch-based image retrieval that considers both categories and sketch distributions. Our main contribution is a test-time training approach that can adapt using just one sketch. Since there is no paired photo available, we utilize a sketch raster-vector reconstruction module as a self-supervised auxiliary task. To ensure the fidelity of the trained cross-modal joint embedding during test-time update, we propose a novel meta-learning based training approach that distinguishes between model updates related to the auxiliary task and the primary objective of discriminative learning. Extensive experiments demonstrate that our model surpasses state-of-the-art methods, thanks to the proposed test-time adaptation that not only transfers to new categories but also accommodates new sketching styles.