We present Amazon Berkeley Objects (ABO), a novel dataset intended to bridge the gap between real and virtual 3D environments. ABO consists of images from product catalogs, metadata, and 3D models created by artists. These models possess intricate geometries and physically-based materials that accurately represent real household objects. To evaluate the current capabilities of real-world 3D object comprehension, we establish challenging benchmarks that leverage the distinctive characteristics of ABO. These benchmarks focus on three open problems: single-view 3D reconstruction, material estimation, and cross-domain multi-view object retrieval.