Non-exemplar class-incremental learning poses a challenge when old class samples cannot be stored, as recognizing both old and new classes requires supervision from new classes. To tackle this problem, we propose a novel self-sustaining representation expansion scheme. Our scheme involves a structure reorganization strategy that combines main-branch expansion and side-branch updating to maintain old features, along with a main-branch distillation scheme to transfer invariant knowledge. Additionally, we introduce a prototype selection mechanism to improve discrimination between old and new classes by selectively incorporating new samples into the distillation process. Our extensive experiments on three benchmarks demonstrate significant incremental performance, surpassing the state-of-the-art methods by margins of 3%, 3%, and 6% respectively.