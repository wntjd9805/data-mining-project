In visual search, existing methods often overlook the continual updating of the model when the gallery set grows incrementally. This results in a high computational cost as the new model needs to re-extract features for the entire gallery set to maintain compatibility. To address this issue, we propose a continual learning (CL) approach that incorporates backward embedding consistency. Our approach enforces losses to ensure coherence between inter-session data, neighbor-session models, and intra-session discrimination. Furthermore, our CL solution is not limited to disjoint setups and can handle the addition of new classes with blurry boundaries without assuming prior knowledge of all categories. To the best of our knowledge, our CL method is the first to tackle the problem of backward-consistent feature embedding while allowing for the occurrence of novel classes in new sessions. Extensive experiments on various benchmarks demonstrate the effectiveness of our approach across a wide range of scenarios.