In this study, we investigate the potential use of CNN-based models to detect gall-bladder cancer (GBC) from ultrasound (USG) images, as no previous research has been conducted on this topic. USG is commonly used for diagnosing gall-bladder diseases due to its affordability and accessibility. However, analyzing USG images poses challenges due to their low quality, noise, and varying perspectives caused by the handheld nature of the sensor. Our comprehensive examination of state-of-the-art image classification techniques reveals that they often struggle to identify the important regions of the gall-bladder due to the presence of shadows in the USG images. Similarly, existing object detection techniques perform poorly due to the interference of spurious textures caused by noise or neighboring organs. To address these challenges, we propose GBCNet. This method first detects the regions of interest (ROIs) by identifying the gall-bladder (excluding the cancerous parts) and then utilizes a novel multi-scale, second-order pooling architecture designed specifically for GBC classification. Additionally, we introduce a curriculum inspired by human visual acuity to effectively handle spurious textures and reduce biases in GBCNet. Our experimental results demonstrate that GBCNet outperforms state-of-the-art CNN models and even expert radiologists in GBC detection. Furthermore, our technical innovations have broader applicability to other USG image analysis tasks. To validate this, we also demonstrate the effectiveness of GBCNet in detecting breast cancer from USG images. The project page provides access to the source code, trained models, and data. Figure 1 illustrates the differences between normal, benign, and malignant gall-bladder samples in USG images. It also showcases the challenges faced by existing methods and how GBCNet overcomes them, aiding radiologists in accurate diagnosis.