The research topic of 3D object detection in computer vision often uses 3D point clouds as input. However, there is a growing trend of combining multiple sources of input data, such as 2D images, to improve detection accuracy. The challenge is that the heterogeneity of 2D and 3D representations makes it difficult to apply existing neural networks for multimodal fusion. To address this, we propose a new architecture called Bridged Transformer (BrT) for 3D object detection. BrT is a simple and effective approach that learns to identify object bounding boxes from both points and image patches. It utilizes object queries to bridge the gap between 3D and 2D spaces, allowing for the fusion of different data representations in the Transformer model. We also introduce a feature aggregation technique using point-to-patch projections to enhance the interaction between images and points. Additionally, BrT seamlessly combines point clouds with multi-view images. Experimental results on SUN RGB-D and ScanNetV2 datasets demonstrate that BrT outperforms current state-of-the-art methods in 3D object detection.