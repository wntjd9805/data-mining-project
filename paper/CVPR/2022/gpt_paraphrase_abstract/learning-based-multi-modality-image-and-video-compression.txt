This study introduces a multi-modality compression framework for infrared and visible image pairs. The framework aims to address the challenges posed by increased data modalities in terms of storage and transmission. Unlike existing approaches that utilize individual codecs for each modality, the proposed framework takes into account the correlation between different modalities. It utilizes a channel-wise alignment module to generate aligned features based on affine transformation, using the image in the reference modality as a basis. These aligned features serve as context information for compressing the image in the current modality, while the corresponding affine coefficients are compressed with minimal loss. Additionally, a Transformer-based spatial alignment module is introduced to exploit the correlation between intermediate features during decoding for different modalities. The flexibility of the framework allows for easy extension to multi-modality video compression. Experimental results demonstrate that the proposed framework outperforms traditional and learning-based single modality compression methods on the FLIR and KAIST datasets.