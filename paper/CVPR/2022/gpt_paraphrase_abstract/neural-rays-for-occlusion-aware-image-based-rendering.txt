We introduce a new neural representation called NeuralRay (NeuRay) for the task of synthesizing novel views. Existing methods use image features to create radiance fields that can render new view images and generalize to different scenes. However, occlusions can make certain 3D points invisible to some input views, causing inconsistencies in the radiance field construction. To address this issue, we incorporate visibility prediction into our NeuRay representation. This allows us to focus on visible image features during radiance field construction, leading to significant improvements in rendering quality. Additionally, we propose a novel consistency loss to refine visibility within NeuRay when fine-tuning on a specific scene. Our experiments demonstrate that our approach achieves state-of-the-art performance in novel view synthesis, outperforming per-scene optimization methods after fine-tuning. Further details can be found on our project page: https://liuyuan-pal.github.io/NeuRay/.