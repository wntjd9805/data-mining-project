This paper introduces a new approach called Distribution-Aware Single-stage (DAS) model for multi-person 3D pose estimation. Unlike existing methods, the DAS model can simultaneously localize person positions and their corresponding body joints in the 3D camera space in a single pass, resulting in a simplified and more efficient pipeline. Additionally, the DAS model learns the true distribution of body joints for regression, instead of assuming a simple Laplacian or Gaussian distribution like previous works. This prior knowledge improves the model's predictions and allows it to achieve competitive performance with volumetric-based approaches. Moreover, the DAS model utilizes a recursive update strategy to progressively approach the regression target, reducing optimization difficulties and further improving regression performance. The DAS model is implemented using a fully Convolutional Neural Network and is end-to-end trainable. Experimental results on CMU Panoptic and MuPoTS-3D benchmarks demonstrate the superior efficiency of the DAS model, achieving a 1.5x speedup compared to the previous best model, while also achieving state-of-the-art accuracy for multi-person 3D pose estimation.