We present a new approach called Unified Conditional image Repainting Network (UniCoRN) for the task of conditional image repainting (CIR). CIR involves generating visual content in specific regions based on multiple cross-modality constraints and seamlessly blending it with a given background. Existing methods rely on a two-phase architecture that assumes a dependency between the phases, resulting in color-image inconsistencies. To address this issue, we propose breaking the two-phase assumption by establishing an interaction and dependency relationship between the background and other conditions. Additionally, we introduce a hierarchical structure to the cross-modality similarity model to capture feature patterns at different levels and bridge the gap between visual content and color condition. We also collected and annotated a new LANDSCAPE-CIR dataset to expand the application scenarios of CIR. Experimental results demonstrate that UniCoRN produces higher synthetic quality, better condition consistency, and more realistic compositing effects compared to existing methods.