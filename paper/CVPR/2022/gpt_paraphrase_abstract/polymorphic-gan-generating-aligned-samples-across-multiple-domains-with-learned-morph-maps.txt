In this study, a novel generative adversarial network called Polymorphic-GAN is introduced. Unlike existing models that are trained on a single domain or class of objects, Polymorphic-GAN is capable of generating aligned image samples from multiple related domains simultaneously. The model takes advantage of the fact that various object classes share common attributes but have geometric differences. To address this, Polymorphic-GAN learns shared features across all domains and incorporates a per-domain morph layer to adapt these shared features based on each specific domain.  The framework proposed in this study allows for the simultaneous modeling of images with highly varying geometries, including human faces, painted and artistic faces, and different animal faces. Experimental results demonstrate that the Polymorphic-GAN model successfully produces aligned samples for all domains. Moreover, the model's capabilities extend to applications such as segmentation transfer, cross-domain image editing, and training with limited data.  Furthermore, the Polymorphic-GAN is applied to image-to-image translation tasks, showcasing its superiority over previous approaches when dealing with domains that exhibit significant geometric differences. This highlights the model's potential for effectively handling cases with diverse domains.  In summary, this study introduces the Polymorphic-GAN, a generative adversarial network that can generate aligned image samples from multiple related domains. The model's ability to learn shared features and adapt them to specific domains enables various applications, including segmentation transfer, cross-domain image editing, and improved performance in cases with significant geometric differences between domains.