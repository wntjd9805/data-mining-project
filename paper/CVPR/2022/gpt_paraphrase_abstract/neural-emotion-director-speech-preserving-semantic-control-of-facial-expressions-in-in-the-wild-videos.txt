This paper presents a new deep learning technique for realistically manipulating the emotional state of actors in real-world videos. The method utilizes a 3D face representation that separates facial identity from head pose and expressions. It employs a deep domain translation framework to consistently and plausibly modify facial expressions, considering their dynamics. The altered expressions are then used to manipulate the facial region in the input scene using a neural face renderer. Notably, our method can control the actor's expressions solely based on semantic labels of desired emotions while preserving lip movements related to speech. Through extensive qualitative and quantitative evaluations, we demonstrate the effectiveness and promising results of our approach. This novel method opens up various possibilities for neural rendering technologies, including applications in movie post-production, video games, and the creation of realistic emotional avatars.