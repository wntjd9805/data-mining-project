Recent research in the field of talking face generation has primarily focused on developing a model that can adapt to various source speech and target identity combinations. Several studies have claimed to achieve this capability and have even asserted that their models can generalize to any language. However, our investigation using languages from different language families reveals that these models struggle to perform well when the training language and testing language differ significantly. As a result, we narrow down the problem scope to constructing a language-agnostic talking face generation system that works effectively for known identities, meaning the target identity aligns with the training identity. In this study, we propose a talking face generation system that can accommodate different languages. To assess the effectiveness of our system, we utilize a multilingual text-to-speech system. We present our integrated text-to-speech and talking face generation system as a neural dubber system. A demonstration of our system can be accessed at https://bit.ly/ml-face-generation-cvpr22-demo, and we have also uploaded a screencast at https://youtu.be/F6h0s0M4vBI.