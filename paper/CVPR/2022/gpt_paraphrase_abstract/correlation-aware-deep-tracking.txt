Visual object tracking requires robustness and discrimination power. However, popular Siamese-like networks fail to fully discriminate between tracked targets and distractors, making it challenging to meet both requirements simultaneously. While existing methods focus on designing robust correlation operations, we propose a novel target-dependent feature network inspired by the self-/cross-attention scheme. Unlike Siamese-like feature extraction, our network incorporates cross-image feature correlation in multiple layers, effectively suppressing non-target features and enabling instance-varying feature extraction. This eliminates the need for an extra correlation step in predicting target locations using the output features of the search image. Additionally, our model can be pre-trained on unpaired images, leading to faster convergence compared to existing methods. Extensive experiments demonstrate that our approach achieves state-of-the-art results in real-time. Our feature networks can also seamlessly enhance the tracking performance of existing pipelines.