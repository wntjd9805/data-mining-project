Convolutional Neural Networks (CNNs) are commonly used for visual recognition tasks. However, convolution-free networks based on multi-head self-attention (MSA) or multi-layer perceptrons (MLPs) have gained popularity. Applying these networks to video recognition is challenging due to the complexity and variations in video data. This paper introduces MLP-3D networks, a novel MLP-based 3D architecture for video recognition. The architecture consists of MLP-3D blocks, which include a token-mixing MLP and a channel MLP. The token-mixing MLP applies MLP across tokens, while the channel MLP operates independently on each token. The novel grouped time mixing (GTM) operations are introduced to enable temporal modeling in the token-mixing MLP. GTM divides input tokens into temporal groups and linearly maps the tokens within each group using a shared projection matrix. Multiple variants of GTM with different grouping strategies are devised and incorporated into different blocks of the MLP-3D network through greedy architecture search. The MLP-3D networks achieve high accuracy (68.5% on Something-Something V2 and 81.4% on Kinetics-400 datasets) without relying on convolutions or attention mechanisms. These results are comparable to state-of-the-art 3D CNNs and video transformers while requiring fewer computations.