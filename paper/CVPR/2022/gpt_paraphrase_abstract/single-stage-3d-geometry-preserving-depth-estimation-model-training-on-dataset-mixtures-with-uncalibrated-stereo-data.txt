Single-view depth estimation (SVDE) is gaining attention in the fields of robotics, augmented reality (AR), and 3D modeling. SVDE allows for the estimation of scene geometry from a single RGB image. The accuracy of SVDE methods relies heavily on the diversity and volume of the training data. However, existing RGB-D datasets obtained from depth capturing or 3D reconstruction are limited in size and lack diversity. Synthetic datasets are not realistic enough, further reducing their usefulness. To address this, researchers have turned to stereo images or videos from the web, which provide large-scale and diverse data. However, stereo data is typically uncalibrated and lacks complete geometric information, making it difficult for SVDE methods trained on stereo data to recover 3D geometry accurately.Recently, a method was proposed to correct the distorted point clouds obtained from stereo-trained SVDE methods using additional point cloud modules (PCM) trained on geometrically complete data. In contrast, we propose a new training scheme called GP2 (General-Purpose and Geometry-Preserving) that allows conventional SVDE models to learn correct shifts without the need for post-processing or PCM. By utilizing stereo data even in the geometry-preserving setting, our GP2-trained models outperform methods relying on PCM in both accuracy and speed. We achieve state-of-the-art results in general-purpose geometry-preserving SVDE through experiments on different dataset mixtures.Furthermore, we demonstrate that SVDE models can learn to predict geometrically correct depth even when the geometrically complete data comprises only a minor part of the training set. This highlights the effectiveness of our GP2 training scheme in leveraging the benefits of stereo data for accurate depth estimation.