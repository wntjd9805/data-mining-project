We propose a solution for action segmentation in instructional task videos, called Semi-Weakly-Supervised Learning (SWSL), which involves a small number of weakly-labeled training videos and a large number of unlabeled videos. Our approach is a general framework that efficiently learns from both types of videos and can incorporate any weakly-supervised action segmentation methods. We observe that the transcript of an unlabeled video is similar to the transcripts of weakly-labeled videos from the same task, although not identical. Based on this observation, we introduce a Soft Restricted Edit (SRE) loss that encourages small variations between the predicted transcripts of unlabeled videos and the ground-truth transcripts of weakly-labeled videos. To compute the SRE loss, we develop a flexible transcript prediction (FTP) method that utilizes the output of an action classifier to determine the length of the transcript and the sequence of actions in an unlabeled video. To optimize our proposed loss, we employ an efficient learning scheme that alternates between minimizing the loss and generating pseudo-transcripts for unlabeled videos. Through experiments on two benchmark datasets, we demonstrate that our approach significantly improves performance by leveraging unlabeled videos, particularly when the number of weakly-labeled videos is limited.