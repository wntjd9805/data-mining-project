Neural priors offer a promising approach to capturing low-level vision statistics without relying on manually designed regularizers. Recent research has successfully demonstrated the use of neural architecture biases to implicitly regularize various image processing tasks such as denoising, super-resolution, inpainting, synthesis, and scene flow. Unlike traditional approaches that depend on large datasets to capture prior statistics, neural priors generalize well to unseen data. Building upon these advancements, we investigate the application of neural priors for representing trajectories. Traditionally, trajectories have been represented using handcrafted bases that have limited expressive power. In this study, we propose a neural trajectory prior that captures continuous spatio-temporal information without the need for offline data. We show how our proposed objective is optimized during runtime to estimate trajectories for two important tasks: Non-Rigid Structure from Motion (NRSfM) and lidar scene flow integration for self-driving scenes. Our results are competitive with state-of-the-art methods for both tasks.