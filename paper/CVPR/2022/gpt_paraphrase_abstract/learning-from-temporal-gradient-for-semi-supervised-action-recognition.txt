Semi-supervised video action recognition has shown impressive results by using deep neural networks with limited labeled data. However, existing methods primarily rely on image-based techniques and do not fully exploit the temporal dynamics and multimodal attributes of videos, leading to suboptimal performance. To address this, our approach introduces temporal gradient as an additional modality to enhance feature extraction. Specifically, we extract fine-grained motion representations from the temporal gradient and ensure consistency between RGB and temporal gradient modalities. This method significantly improves the performance of semi-supervised action recognition without any additional computation or parameters during inference. We achieve state-of-the-art results on three video action recognition benchmarks (Kinetics-400, UCF-101, and HMDB-51) under various semi-supervised settings. The code for our method is available at https://github.com/lambert-x/video-semisup.