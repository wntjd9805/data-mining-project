This research focuses on the optimization of coding efficiency in learned image compression. While learned image compression models have shown great modeling capacity, they often do not consider the Rate-Distortion Optimization (RDO) of each individual input image. In this study, we propose a neural data-dependent transform and introduce a continuous online mode decision mechanism to jointly optimize coding efficiency for each image. We utilize an additional model stream to generate transform parameters at the decoder side, allowing our model to learn more abstract neural-syntax and cluster latent representations of images more compactly. Additionally, we employ neural-syntax based post-processing for scenarios requiring higher quality reconstructions, disregarding extra decoding overhead. The involvement of the model stream enables us to optimize both the representation and decoder in an online manner, achieving continuous online mode decision (similar to coding modes in traditional codecs) to improve coding efficiency based on individual input images. Experiment results demonstrate the effectiveness of our proposed neural-syntax design and continuous online mode decision mechanism, highlighting the superior coding efficiency of our method. More details can be found at the following link: https://dezhao-wang.github.io/Neural-Syntax-Website/.