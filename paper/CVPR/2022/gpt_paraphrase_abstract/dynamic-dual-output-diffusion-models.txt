Iterative denoising-based generation, also known as de-noising diffusion models, has been proven to be as good as, if not better than, other types of generative models, such as Generative Adversarial Networks (GANs), which are currently the leading models for image generation. However, one major drawback of this method is that it takes a large number of iterations to produce satisfactory results. Recent studies have suggested ways to speed up the generation process with fewer iterations, but this compromises the quality of the generated images. In this research, we investigate the factors that affect the quality of diffusion models when fewer iterations are used and propose a simple yet effective solution to address this issue. We consider two different approaches for iterative denoising: one predicts the applied noise, and the other predicts the image directly. Our solution combines these two approaches and dynamically alternates between them during the denoising process. This solution is applicable to any existing diffusion model and, when applied to state-of-the-art architectures, immediately improves the quality of the generated images with minimal added complexity and parameters. We conduct experiments on multiple datasets and configurations, and support our findings with a comprehensive ablation study.