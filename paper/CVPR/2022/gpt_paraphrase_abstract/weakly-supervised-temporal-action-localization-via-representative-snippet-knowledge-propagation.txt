This research focuses on weakly supervised temporal action localization, which involves localizing the temporal boundaries of actions and identifying their categories using only video-level category labels. Existing methods generate pseudo labels to bridge the gap between classification and localization, but they often rely on limited contextual information for pseudo label generation. To address this issue, we propose a framework that involves snippet summarization and propagation. Our method mines representative snippets in each video and propagates information between video snippets to generate improved pseudo labels. We update the input features intra- and inter-video by propagating the representative snippets from each video and a memory bank. Pseudo labels are generated from the temporal class activation maps of the updated features to refine the predictions of the main branch. Our method outperforms existing methods on two benchmarks, THUMOS14 and ActivityNet1.3, achieving gains of up to 1.2% in terms of average mAP on THUMOS14. The code for our method is available at https://github.com/LeonHLJ/RSKP.