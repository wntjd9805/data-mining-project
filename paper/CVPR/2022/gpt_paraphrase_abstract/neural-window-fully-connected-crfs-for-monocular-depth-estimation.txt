Estimating accurate depth from a single image is a difficult task due to its inherent ambiguity and ill-posed nature. While recent approaches focus on using complex networks to directly regress the depth map, we propose an alternative method using CRFs optimization. However, the computation cost of CRFs is high, so we perform it on smaller windows instead of the entire graph. This allows us to leverage the potential of fully-connected CRFs while reducing complexity. To enhance the graph's node relationships, we employ a multi-head attention mechanism to calculate a multi-head potential function. This function is then used as input to the network, which outputs an optimized depth map. Our approach follows a bottom-up-top-down structure, with a neural window FC-CRFs module serving as the decoder and a vision transformer acting as the encoder. Experimental results demonstrate that our method significantly improves performance on various metrics for both the KITTI and NYUv2 datasets compared to previous techniques. Additionally, our proposed method outperforms previous panorama methods on the MatterPort3D dataset and can be directly applied to panorama images.