We present a technique for controlling the animation of fluid elements in still images to create cinema-graphs. Our focus is on fluid elements such as water, smoke, and fire, which exhibit repeating textures and continuous fluid motion. Inspired by previous works, we represent the motion of these fluid elements as a 2D optical flow map. Users can provide arrow directions, associated speeds, and a mask indicating the regions to animate. This input is converted into a dense flow map, which approximates the plausible motion of the elements in the image. We refine the flow map using a generative-adversarial network to achieve more realistic results. We develop a UNet-based architecture to generate future frames based on the refined optical flow map. Our method outperforms baselines in both qualitative and quantitative evaluations on a publicly available dataset. Additionally, we demonstrate the ability to animate objects in directions not present in the training set, allowing for the synthesis of videos that would not exist in the real world. The project can be accessed at https://controllable-cinemagraphs.github.io/.