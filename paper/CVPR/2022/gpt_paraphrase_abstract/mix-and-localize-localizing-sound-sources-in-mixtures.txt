We propose a method for simultaneously localizing multiple sound sources in a visual scene. This involves grouping a sound mixture into individual sources and associating them with a visual signal. Inspired by the contrastive random walk of Jabri et al., our method solves both tasks together by creating a graph with images and separated sounds as nodes. We train a random walker to transition between nodes of different modalities with high return probability. The transition probabilities are determined by an audio-visual similarity metric learned by our model. Experimental results with musical instruments and human speech demonstrate that our model successfully localizes multiple sounds and outperforms other self-supervised methods.