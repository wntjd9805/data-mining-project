Determining the movement patterns of various types of traffic participants is crucial for autonomous driving. There is a growing interest in directly predicting the motion of these participants using sensor data such as LiDAR point clouds or a combination of point clouds and images. However, existing motion prediction frameworks face a trade-off between joint semantic segmentation and motion prediction performance. To address this, we propose a new network called BE-STI (Spatial-Temporal Integrated network with Bidirectional Enhancement) that improves temporal motion prediction by incorporating spatial semantic features. Our approach enhances the spatial features of each point cloud by considering the similarity among neighboring frames and enhances global temporal features by considering the spatial difference among non-adjacent frames in a coarse-to-fine manner. Extensive experiments on nuScenes and Waymo Open Dataset demonstrate that our framework outperforms state-of-the-art LiDAR-based and RGB+LiDAR-based methods significantly, using only point clouds as input.