Recently, there has been a lot of interest in object detection under imperfect data. Weakly supervised object detection (WSOD) struggles with accurately localizing objects due to the lack of detailed annotations, while semi-supervised object detection (SSOD) faces difficulties caused by differences between labeled and unlabeled data. In this study, we introduce Single Instance annotated Object Detection (SIOD), which only requires one instance annotation for each category in an image. By focusing on the discrepancies within an image rather than between tasks or images, SIOD provides more reliable prior knowledge for identifying unlabeled instances and balances the cost of annotation with performance. To address SIOD, we propose a straightforward yet effective framework called Dual-Mining (DMiner). DMiner consists of two modules: a Similarity-based Pseudo Label Generating module (SPLG) and a Pixel-level Group Contrastive Learning module (PGCL). SPLG mines latent instances from the feature representation space to alleviate the problem of missing annotations. To prevent being misled by inaccurate pseudo labels, PGCL enhances the tolerance to false pseudo labels. Through extensive experiments on MS COCO, we demonstrate the feasibility of the SIOD approach and the superiority of our proposed method. Our method consistently outperforms baseline methods and achieves comparable results to fully supervised object detection (FSOD) methods, even with annotations for only 40% of the instances. The code for our method is available at https://github.com/solicucu/SIOD.