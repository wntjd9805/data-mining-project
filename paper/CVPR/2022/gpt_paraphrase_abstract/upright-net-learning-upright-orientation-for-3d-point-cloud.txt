This paper presents Upright-Net, a deep-learning-based method for determining the upright orientation of 3D point clouds. The pose of input 3D models significantly impacts automatic 3D shape analysis. Upright-Net leverages the concept that the natural base of an object serves as a common functional structure, supporting the object in a commonly seen pose based on specific rules such as physical laws, geometric properties, and semantic cues. By employing a data-driven deep learning approach, Upright-Net encodes these rules and formulates the orientation estimation problem as a classification model. It identifies the points on a 3D model that constitute the natural base and computes the upright orientation as the normal of this base. This approach offers three main advantages: (1) it converts the continuous orientation estimation task into a discrete classification task while maintaining the continuity of the solution space, (2) it automatically learns criteria for defining a natural base for general 3D models, even those with asymmetric geometry, and (3) the orientation-aware features learned by the network can be effectively utilized in downstream tasks. Experimental results demonstrate that Upright-Net outperforms previous methods in orientation estimation, showcasing strong generalization and transfer capabilities.