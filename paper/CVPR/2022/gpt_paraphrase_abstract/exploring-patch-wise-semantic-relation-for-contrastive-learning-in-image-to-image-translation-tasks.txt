Recently, researchers have introduced contrastive learning-based techniques for image translation that aim to enhance spatial correspondence by comparing different spatial locations. However, these methods often overlook the diverse semantic relationships present within the images. To address this limitation, we propose a new approach called semantic relation consistency (SRC) regularization, which incorporates diverse semantics by focusing on the heterogeneous semantics between patches within a single image. Additionally, we introduce a hard negative mining technique that leverages the semantic relation to further improve performance. We evaluate our method on three tasks: single-modal and multi-modal image translations, as well as GAN compression for image translation. Experimental results demonstrate that our method achieves state-of-the-art performance in all three tasks.