We present a tracking framework called MixFormer that simplifies the multi-stage pipeline used in tracking tasks. MixFormer is built upon transformers and combines feature extraction and target information integration into a single process using a Mixed Attention Module (MAM). This allows for the extraction of target-specific discriminative features and facilitates communication between the target and search area. By stacking multiple MAMs with progressive patch embedding and adding a localization head, we construct the MixFormer tracking framework. To handle multiple target templates during online tracking, we employ an asymmetric attention scheme in MAM to reduce computational cost and introduce a score prediction module for template selection. Our MixFormer achieves state-of-the-art performance on five tracking benchmarks, including LaSOT, TrackingNet, VOT2020, GOT-10k, and UAV123. Notably, MixFormer-L achieves an NP score of 79.9% on LaSOT, 88.9% on TrackingNet, and an EAO of 0.555 on VOT2020. We also conduct detailed ablation studies to demonstrate the effectiveness of simultaneous feature extraction and information integration. The code and trained models for MixFormer are publicly available at https://github.com/MCG-NJU/MixFormer.