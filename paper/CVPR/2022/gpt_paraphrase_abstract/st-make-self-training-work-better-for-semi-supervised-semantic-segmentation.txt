Self-training with pseudo labeling is a widely used method to utilize unlabeled data. In this study, we enhance the self-training approach for semi-supervised semantic segmentation by incorporating strong data augmentations on unlabeled images. This helps combat overfitting and improves the consistency between teacher and student predictions. Our enhanced self-training method outperforms existing techniques without the need for iterative re-training. We also investigate the impact of strong data augmentations through empirical analysis. However, the presence of incorrect pseudo labels can still affect performance. To address this, we propose a more advanced self-training framework called ST++, which selectively retrains the model using reliable unlabeled images based on prediction-level stability. We save multiple model checkpoints during the initial supervised training and use the discrepancy between their predictions on unlabeled images to determine reliability. Our approach considers holistic contextual information and demonstrates better suitability for segmentation compared to pixel-wise selection. ST++ further improves the performance of our self-training method. The code for our approach is available at https://github.com/LiheYoung/ST-PlusPlus.