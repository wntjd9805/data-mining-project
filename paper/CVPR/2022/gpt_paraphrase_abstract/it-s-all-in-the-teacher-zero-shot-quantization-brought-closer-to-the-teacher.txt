Model quantization is a promising approach to reduce the resource requirements of deep neural networks. One common method to mitigate the performance drop caused by quantization errors is to fine-tune quantized networks using training data. However, in real-world scenarios, this method is often not feasible due to the unavailability of training data for security, privacy, or confidentiality reasons. Zero-shot quantization addresses this issue by leveraging information from the weights of a full-precision teacher network to compensate for the performance degradation of quantized networks.This study analyzes the loss surface of state-of-the-art zero-shot quantization techniques and identifies several key findings. Unlike traditional knowledge distillation problems, zero-shot quantization faces challenges in optimizing multiple loss terms simultaneously and exhibits poor generalization due to the use of synthetic samples. Additionally, it is observed that many weights fail to cross the rounding threshold during training, even when it is necessary for improved performance.Based on these observations, a novel technique called AIT is proposed to address the aforementioned challenges in zero-shot quantization. AIT utilizes a KL distance loss instead of a cross-entropy loss and manipulates gradients to ensure that a certain proportion of weights are properly updated after crossing the rounding thresholds. Experimental results demonstrate that AIT significantly outperforms existing methods, establishing it as the new state-of-the-art approach in this field.