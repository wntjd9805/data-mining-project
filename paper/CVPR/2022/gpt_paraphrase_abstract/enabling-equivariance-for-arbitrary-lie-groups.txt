Convolutional neural networks (CNNs) are known to lose performance when faced with general geometric transformations during testing. Capsule Networks (CapsNets) have emerged as an alternative, but they lack theoretical guarantees of invariance. This study introduces a mathematical framework that allows for invariance to any Lie group of warps using convolutions, without the need for capsules. Previous work on group convolutions had limitations due to assumptions about the group, which restricted their application to common warps in computer vision. The proposed framework enables the implementation of group convolutions over any finite-dimensional Lie group. Experimental results on an affine-invariant classification task demonstrate a significant improvement in accuracy compared to conventional CNNs and outperform most CapsNets. Additionally, a homography-convolutional model trained using the framework achieves superior robustness on a homography-perturbed dataset, where CapsNet performance degrades.