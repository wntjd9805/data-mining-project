To understand the inner workings of deep networks, researchers often try to associate individual neurons with concepts that humans can comprehend. However, current methods overlook the inherent connections between different concepts, which means they miss out on explaining neurons that are responsible for higher-level concepts. In this study, we investigate hierarchical concepts inspired by how humans process information hierarchically. To address this, we propose a method called HIerarchical Neuron concepT explainer (HINT) that can efficiently establish bidirectional associations between neurons and hierarchical concepts in a cost-effective and scalable manner. HINT allows us to systematically and quantitatively explore whether and how neurons embed implicit hierarchical relationships of concepts. Specifically, HINT identifies collaborative neurons that contribute to a single concept and multimodal neurons that relate to multiple concepts at various semantic levels, ranging from specific concepts like "dog" to more abstract ones like "animal". We validate the accuracy of these associations using Weakly Supervised Object Localization and showcase its versatility in tasks such as identifying saliency regions and explaining adversarial attacks. The source code for HINT is publicly available at https://github.com/AntonotnaWang/HINT.