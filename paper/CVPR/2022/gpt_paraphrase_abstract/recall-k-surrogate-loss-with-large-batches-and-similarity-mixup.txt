This research focuses on developing deep visual representation models for retrieval by examining the relationship between a new loss function, batch size, and a novel regularization technique. When dealing with non-differentiable evaluation metrics like recall in retrieval, direct optimization through gradient descent is not feasible. To address this, the study proposes a differentiable surrogate loss for recall. By employing a technique that overcomes GPU memory limitations, the method trains with a large batch size, which is crucial for metrics computed on the entire retrieval database. Additionally, an efficient mixup regularization approach is implemented, further increasing the effective batch size by operating on pairwise scalar similarities. The proposed method achieves state-of-the-art performance in various image retrieval benchmarks when applied to deep metric learning. In terms of instance-level recognition, it surpasses similar approaches that rely on an approximation of average precision.