This paper focuses on semantics-guided image outpainting, which involves completing an image by generating semantically meaningful content. Unlike existing methods, we approach this task by understanding and completing image semantics at the scene graph level. We introduce a novel network called Scene Graph Transformer (SGT) that models the structural information of scene graphs using node and edge features. Our SGT incorporates feature attention at both the node and edge levels, leveraging relationships and co-occurrence of nodes to improve graph understanding and processing. By utilizing a partial input image with its layout and scene graph, our SGT can expand the scene graph and convert it into a complete layout. This enables us to successfully complete image outpainting with sufficient and practical semantics. We evaluate our proposed SGT and outpainting frameworks on the MS-COCO and Visual Genome datasets, demonstrating their effectiveness through quantitative and qualitative experiments.