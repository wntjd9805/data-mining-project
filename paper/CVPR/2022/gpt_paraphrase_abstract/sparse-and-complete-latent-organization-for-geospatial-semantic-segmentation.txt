Geospatial semantic segmentation in remote sensing images faces challenges due to significant intra-class variance in both foreground and background classes. The small size of foreground objects in these images leads to a large intra-class variance, making it difficult to distinguish between foreground classes. Additionally, the complex context of the background class introduces false alarms, caused by the high intra-class variance within the background. To address these issues, we propose a solution that constructs a sparse and complete latent structure using prototypes. We enhance the sparsity of the latent space through prototypical contrastive learning, which groups prototypes of the same category together and keeps prototypes of different categories far apart. This approach improves discrimination between foreground classes. Furthermore, we strengthen the completeness of the latent space by modeling all foreground categories and the most challenging background objects (nearest in proximity). To handle remote sensing images with complex contexts, we introduce a patch shuffle augmentation technique. This augmentation ensures that the semantic information of an object is only correlated with the limited context within the specific patch relevant to its category. This reduction in large intra-class variance helps improve the accuracy of the segmentation.We evaluated our approach on a large-scale remote sensing dataset and found that it significantly outperforms state-of-the-art methods by a considerable margin.