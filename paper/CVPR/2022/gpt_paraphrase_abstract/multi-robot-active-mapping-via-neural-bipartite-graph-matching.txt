This study focuses on multi-robot active mapping, aiming to construct a complete scene map in the shortest possible time. The key challenge is accurately estimating the goal position to optimize robot movements. Previous approaches have either used a myopic solution by selecting the frontier as the goal position, which is not time-efficient, or used reinforcement learning to regress the goal position, but without guaranteeing complete map construction. In this paper, we propose a new algorithm called NeuralCoMapping that combines the strengths of both approaches. We formulate the problem as bipartite graph matching between robots and frontiers. We introduce a multiplex graph neural network (mGNN) that learns the neural distance to enhance graph matching. We optimize the mGNN using a differentiable linear assignment layer, prioritizing long-term values that promote time efficiency and map completeness through reinforcement learning. We compare our algorithm with existing multi-robot active mapping approaches and reinforcement-learning baselines. Experimental results demonstrate the superior performance and generalization ability of our algorithm across various indoor scenes and different numbers of robots, even with training on only nine indoor scenes.