Recent advancements in learned image compression techniques have shown impressive results, surpassing traditional lossy image coders. These techniques are now being considered for widespread adoption. To ensure practicality, it is crucial to thoroughly investigate the architecture design of learned image compression in terms of compression performance and running speed. In this paper, we introduce a novel approach called uneven channel-conditional adaptive coding, based on the observation of energy compaction in learned image compression. By combining this approach with existing context models, we develop a spatial-channel contextual adaptive model that improves coding performance without compromising running speed. Additionally, we analyze the structure of the main transform and propose an efficient model called ELIC, which achieves state-of-the-art speed and compression ability. The proposed model not only delivers superior performance but also supports fast preview decoding and progressive decoding, making it highly promising for future applications of learning-based image compression.