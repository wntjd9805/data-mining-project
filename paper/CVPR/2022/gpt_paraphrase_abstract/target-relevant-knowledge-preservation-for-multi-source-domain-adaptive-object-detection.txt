Domain adaptive object detection (DAOD) is a promising approach to improve the performance of detectors in new scenes. While there has been significant progress in single source domain adaptation, there is still limited exploration in the more challenging task of multiple source domains, primarily due to the degradation of knowledge when combining them. To address this issue, we propose a new method called target-relevant knowledge preservation (TRKP) for unsupervised multi-source DAOD. TRKP utilizes a teacher-student framework, where a multi-head teacher network extracts knowledge from labeled source domains and guides the student network in learning detectors for the unlabeled target domain. The teacher network is enhanced with an adversarial multi-source disentanglement (AMSD) module, which preserves domain-specific knowledge and ensures cross-domain alignment. Additionally, a holistic target-relevant mining (HTRM) scheme is developed to adjust the weights of the source images based on their relevance to the target domain. This encourages the teacher network to capture target-relevant knowledge, thereby reducing the domain shift when training object detectors in the target domain. Extensive experiments on various benchmark datasets demonstrate the effectiveness of our approach, with new state-of-the-art results achieved.