We propose a neural inverse rendering pipeline called IRON that uses photometric images to generate high-quality 3D content in the form of triangle meshes and material textures. Our approach utilizes neural representations for geometry (signed distance fields) and materials, allowing for flexibility and efficiency. We employ a hybrid optimization scheme for neural SDFs, first optimizing with a volumetric radiance field approach to ensure accurate topology, and then refining the geometry and separating materials and lighting using an edge-aware physics-based surface rendering method. In addition, we incorporate a novel edge sampling algorithm inspired by mesh-based differentiable rendering to enhance performance. Our IRON system outperforms previous methods in terms of inverse rendering quality, as demonstrated through the reconstruction of real-world objects under global illumination.