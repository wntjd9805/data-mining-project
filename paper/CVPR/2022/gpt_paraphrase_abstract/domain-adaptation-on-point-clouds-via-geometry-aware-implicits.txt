Point clouds, a popular geometric representation, have gained attention in 3D vision and found applications in autonomous driving and robotics. However, a major challenge in learning from point clouds is the significant geometric variations that can occur when different procedures or sensors are used to generate them. These inconsistencies create domain gaps, making it difficult for neural networks trained on one domain to generalize to others. Adversarial training is a common technique used to reduce the domain gap by aligning point clouds in the feature space. However, adversarial training often leads to negative adaptation gains due to degenerated local minima. To address this issue, we propose a simple and effective method for unsupervised domain adaptation on point clouds. Our method involves a self-supervised task of learning geometry-aware implicits, which serves two critical purposes. Firstly, it preserves the geometric information in the point clouds through implicit representations for downstream tasks. Secondly, it effectively learns away domain-specific variations in the implicit space. Additionally, we introduce an adaptive strategy for computing unsigned distance fields for arbitrary point clouds, as practical shape models are often lacking. When combined with a task loss, our proposed method outperforms state-of-the-art unsupervised domain adaptation methods that rely on adversarial domain alignment and more complex self-supervised tasks. We evaluate our method on the PointDA-10 and GraspNet datasets, and the code and data are available at the provided GitHub link.