In many real-world applications, there are often a few labeled anomaly examples available, in addition to normal training samples. These anomaly examples, such as defect samples identified during quality inspection or lesion images confirmed by radiologists, provide valuable knowledge about specific abnormalities in the application. Recent models have shown improved detection of similar anomalies by leveraging this knowledge. However, these models often struggle to generalize to unseen anomaly classes, as the anomalies seen during training do not cover every possible class. This paper addresses this challenge by proposing a novel approach to open-set supervised anomaly detection. The approach involves learning disentangled representations of abnormalities using seen anomalies, pseudo anomalies, and latent residual anomalies. Pseudo anomalies are samples designed to detect unseen anomalies, while latent residual anomalies are samples with unusual residuals compared to normal data in a latent space. Experimental results on nine real-world anomaly detection datasets demonstrate the superior performance of our model in detecting both seen and unseen anomalies across diverse settings. The code and data for our approach are available at the provided GitHub link.