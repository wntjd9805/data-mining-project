Single-step adversarial training (AT) has gained considerable attention due to its efficiency and robustness. However, a significant issue of catastrophic overfitting arises during training, where the robust accuracy against projected gradient descent (PGD) attack suddenly drops to 0%. In this study, we approach this problem from an innovative optimization perspective and reveal the strong correlation between the rapid growth of gradients and overfitting. This understanding also helps to comprehend robust overfitting in multi-step AT. To address this issue, we propose a novel AT method called Subspace Adversarial Training (Sub-AT), which effectively controls the growth of gradients by confining AT within a carefully extracted subspace. This approach successfully resolves both types of overfitting and significantly enhances robustness. Additionally, within the subspace, we allow single-step AT with larger steps and radii, further improving robustness performance. Consequently, we achieve state-of-the-art single-step AT results. Remarkably, our single-step AT achieves over 51% robust accuracy against a strong PGD-50 attack with a radius of 8/255 on CIFAR-10, rivaling the performance of standard multi-step PGD-10 AT while enjoying substantial computational advantages. The code for our method is publicly available at https://github.com/nblt/Sub-AT.