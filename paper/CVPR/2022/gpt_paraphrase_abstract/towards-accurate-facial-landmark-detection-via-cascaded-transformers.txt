This paper introduces a facial landmark detector based on cascaded transformers that aims to accurately detect facial landmarks. The proposed model treats facial landmark detection as a coordinate regression task, allowing for end-to-end training. By incorporating self-attention in transformers, the model can effectively leverage the structured relationships between landmarks, which proves advantageous in challenging conditions such as large pose and occlusion. The model utilizes a cascaded refinement approach to extract relevant image features around the target landmark, enhancing the accuracy of alignment through a deformable attention mechanism. Additionally, a novel decoder is proposed that simultaneously refines image features and landmark positions, resulting in improved detection performance with minimal increase in parameters. The model achieves state-of-the-art performance on various facial landmark detection benchmarks and demonstrates strong generalization capabilities in cross-dataset evaluation.