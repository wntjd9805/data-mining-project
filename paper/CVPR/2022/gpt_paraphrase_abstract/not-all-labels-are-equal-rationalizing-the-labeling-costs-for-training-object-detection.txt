Deep neural networks have achieved high accuracy in object detection tasks, but they heavily rely on large amounts of labeled data. To mitigate the need for extensive labeling, various active learning strategies have been proposed, primarily based on the confidence of the detector. However, these approaches tend to favor high-performing classes, resulting in acquired datasets that do not accurately represent the testing set data. In this study, we present a unified framework for active learning that takes into account both the uncertainty and robustness of the detector. This ensures that the network performs well across all classes. Additionally, our method incorporates auto-labeling to address potential distribution drift and enhance the model's performance. Experimental evaluations conducted on PASCAL VOC07+12 and MS-COCO datasets demonstrate that our approach consistently outperforms a wide range of active learning methods. It leads to an improvement of up to 7.7% in mean Average Precision (mAP) or a reduction in labeling cost of up to 82%. The code for our method is available at https://github.com/NVlabs/AL-SSL.