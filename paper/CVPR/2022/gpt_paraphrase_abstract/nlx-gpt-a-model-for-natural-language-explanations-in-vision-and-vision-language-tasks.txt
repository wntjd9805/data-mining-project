NLE models seek to explain the decision-making process of a black box system by generating human-friendly, high-level, and detailed natural language sentences. Currently, NLE models explain the decision-making process of a vision or vision-language model, such as a VQA model, using a separate language model for explanation. However, this disconnects the explanation from the reasoning process used to predict the answer. In this study, we propose NLX-GPT, a compact language model that can predict an answer and provide an explanation simultaneously. We first pre-train NLX-GPT on a large dataset of image-caption pairs to develop a general understanding of images. Then, we formulate the answer prediction task along with the explanation. Our framework outperforms the current state-of-the-art model in terms of evaluation scores, parameter count, and speed, without the need for region proposals or a task model. We also address the challenge of evaluating explanations, which can often be generic, biased, or come in different forms. To overcome this, we introduce two new evaluation measures: explain-predict and retrieval-based attack, which are self-evaluation methods that do not require labels. The code for our model is available at: https://github.com/fawazsammani/nlxgpt. The answer format only includes the main idea.