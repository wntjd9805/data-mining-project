In this study, we address the lack of attention given to the task of arranging element layouts in text logo design. We propose a content-aware layout generation network that automatically synthesizes aesthetic layouts for glyph images and their corresponding text. Our approach includes a dual-discriminator module to evaluate the character placing trajectories and rendered shapes of synthesized text logos. We also incorporate linguistic information from texts and visual semantics from glyphs to guide layout prediction. To evaluate our approach, we create a dataset called TextLogo3K, consisting of 3,500 text logo images and their pixel-level annotations. Experimental studies show that our approach effectively synthesizes visually-pleasing text logos and outperforms existing methods.