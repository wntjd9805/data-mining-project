We present a novel technique for compressively capturing a dynamic light field using a single-shot coded image. Our method combines aperture coding and pixel-wise exposure coding within a single exposure time to effectively embed the original information in the observed image. We use a convolutional neural network (CNN) trained with camera-side coding patterns to reconstruct the light field from the observed image. Additionally, we have developed a hardware prototype to capture real-time 3D scenes. We have successfully acquired a dynamic light field with 5Ã—5 viewpoints over 4 temporal sub-frames (100 views in total) from a single observed image. By repeating the capture and reconstruction processes, we can achieve a temporal resolution four times higher than the camera's frame rate. Our method is the first to achieve a finer temporal resolution in compressive light field acquisition compared to the camera itself. Our software can be accessed through our project webpage.