A significant portion of videos captured nowadays are shot from wearable cameras and are known as first-person videos. Deep Neural Networks (DNNs) are commonly used in egocentric vision techniques, like other computer vision tasks. However, DNNs are vulnerable to Adversarial Attacks (AAs), where imperceptible noise is added to the input. Both black-box and white-box attacks have been demonstrated for image and video analysis tasks. Most AA techniques add intensity perturbation to an image or video frame independently. However, the definition of imperceptibility used for images may not be applicable to videos as small intensity changes between consecutive frames can still be noticeable. This paper proposes a novel approach to use perturbation in optical flow for AAs on video analysis systems, particularly for egocentric videos. Since there is already a lot of shake in egocentric videos, adding a small amount of perturbation makes it highly imperceptible. The idea involves adding structured, parametric noise as adversarial perturbation. The implementation of this approach by adding 3D rotations to frames demonstrates that using this technique, a black-box AA can be carried out on an egocentric activity detection system with one-third of the queries compared to the current state-of-the-art AA technique.