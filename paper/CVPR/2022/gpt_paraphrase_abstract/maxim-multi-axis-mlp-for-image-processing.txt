Recent advancements in Transformers and multi-layer perceptron (MLP) models have introduced new architectural designs for computer vision tasks. While these models have demonstrated effectiveness in tasks like image recognition, challenges remain in adapting them for low-level vision tasks. The main obstacles include limited support for high-resolution images and constraints of local attention. In this study, we propose MAXIM, a multi-axis MLP-based architecture that serves as a flexible and efficient general-purpose vision backbone for image processing tasks. MAXIM utilizes a hierarchical structure resembling UNet and enables long-range interactions through spatially-gated MLPs. MAXIM consists of two MLP-based building blocks: a multi-axis gated MLP that facilitates efficient and scalable spatial integration of local and global visual cues, and a cross-gating block that replaces cross-attention and accounts for cross-feature conditioning. Both modules rely solely on MLPs but also possess the desirable properties of being global and fully-convolutional, which are crucial for image processing. Extensive experimental results demonstrate that MAXIM achieves state-of-the-art performance across various image processing benchmarks, including denoising, de-blurring, deraining, dehazing, and enhancement. Moreover, MAXIM achieves these results with fewer or comparable parameters and computational operations compared to competing models. The source code and trained models for MAXIM will be made available at https://github.com/google-research/maxim.