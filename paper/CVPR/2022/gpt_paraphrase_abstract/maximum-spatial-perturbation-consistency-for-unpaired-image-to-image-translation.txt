Unpaired image-to-image translation (I2I) is a challenging problem because there are numerous translation functions that can map the source domain to the target domain. To address this, previous methods have introduced constraints such as cycle consistency, geometry consistency, and contrastive learning-based constraints. However, these constraints have limitations, as they may be too restrictive or weak for specific tasks, and can result in content distortion when there are significant spatial variations between domains. To overcome these limitations, this paper proposes a universal regularization technique called maximum spatial perturbation consistency (MSPC). MSPC enforces a spatial perturbation function and the translation operator to be commutative. Additionally, the method introduces two adversarial training components. The first component enables the spatial perturbation function to compete with the translation operator to achieve maximum perturbation. The second component allows the translation operator and the spatial perturbation function to compete with discriminators to align spatial variations caused by changes in object size, distortion, and background interruptions. Experimental results demonstrate that our method outperforms state-of-the-art methods on most I2I benchmarks. We also introduce a new benchmark, the front face to profile face dataset, to highlight the challenges of I2I in real-world applications. Furthermore, ablation experiments are conducted to study the sensitivity of our method to the severity of spatial perturbation and its effectiveness for distribution alignment.