This paper introduces a novel attention mechanism called Box-Attention, which enhances the learning capability of transformers for various vision tasks by enabling spatial interaction between grid features. The authors propose BoxeR, also known as BoxTransformer, which attends to a set of boxes by predicting their transformation from a reference window on an input feature map. BoxeR utilizes its grid structure to compute attention weights on these boxes. BoxeR-2D, in particular, incorporates box information within its attention module, making it suitable for end-to-end instance detection and segmentation tasks. Additionally, BoxeR-3D leverages rotation invariance in the box-attention module to generate discriminative information from a bird's-eye view for 3D object detection. Experimental results demonstrate that BoxeR-2D achieves state-of-the-art performance on COCO detection and instance segmentation. Moreover, BoxeR-3D surpasses the baseline for end-to-end 3D object detection and demonstrates promising results for the vehicle category in Waymo Open without any class-specific optimization. The code for BoxeR is available at https://github.com/kienduynguyen/BoxeR.