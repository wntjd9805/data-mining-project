We aim to solve the problem of aligning color (RGB) and multi-spectral (MS) images with vastly different resolutions by finding corresponding pairs of pixels. To address this, we have created a new dataset consisting of 13 indoor scenes with a total of 34 image pairs. These image pairs have been annotated with high-resolution ground-truth labels in the form of disparity maps.   To tackle this task, we propose a deep learning architecture that is trained in a self-supervised manner. During the training phase, we utilize an additional RGB camera. This setup allows us to learn how to match different modalities without relying on ground-truth labels. Instead, we distill knowledge from an easier RGB-RGB matching task using a collection of around 11,000 unlabeled image triplets.  Our experiments demonstrate that our proposed pipeline achieves a high level of performance, with an average registration error of 1.16 pixels. This sets a strong baseline for future research on this challenging task.