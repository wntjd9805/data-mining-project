In order to create coherent descriptions for image captioning, it is important to understand the semantic content of an image and arrange them in a linguistically meaningful order. Current techniques rely on pre-trained object detectors/classifiers to identify the semantics in an image, but they often overlook the linguistic ordering of these semantics. This paper proposes a new approach called Comprehending and Ordering Semantics Networks (COS-Net) that combines semantic comprehension and semantic ordering into a single architecture. The COS-Net utilizes a cross-modal retrieval model to find relevant sentences for each image, and extracts all words from these sentences as primary semantic cues. A semantic comprehender is then used to filter out irrelevant words and infer missing relevant words based on the visual content of the image. The screened and enriched semantic words are then fed into a semantic ranker, which learns to arrange them in a linguistically meaningful order. These ordered semantic words, along with visual tokens of the image, are used to generate descriptive sentences. Experimental results demonstrate that COS-Net outperforms existing approaches, achieving the highest CIDEr score of 141.1% on the Karpathy test split of the COCO dataset. The source code for COS-Net is available at https://github.com/YehLi/xmodaler/tree/master/configs/image_caption/cosnet.