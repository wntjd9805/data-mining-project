This paper focuses on the problem of stereo matching using images of different resolutions. Ground-truth disparity labels are difficult to obtain in real-world systems, so the study approaches this from an unsupervised learning perspective. However, the inconsistency in resolution between the two views hampers the effectiveness of the commonly used photometric consistency assumption. To address this challenge, the paper proposes a feature-metric consistency approach, which enforces consistency between the views in a feature space rather than the image space. Interestingly, even though a stereo matching network trained with photometric loss is not optimal, its feature extractor can generate degradation-agnostic and matching-specific features. These features are then used to formulate a feature-metric loss that avoids photometric inconsistency. Additionally, a self-boosting strategy is introduced to progressively optimize the feature extractor, further enhancing the feature-metric consistency. The proposed method is validated through experiments on simulated datasets with various degradations and a self-collected real-world dataset, demonstrating its superior performance compared to existing solutions.