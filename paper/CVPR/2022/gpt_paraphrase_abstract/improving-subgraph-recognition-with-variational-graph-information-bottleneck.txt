Subgraph recognition involves finding a condensed substructure within a graph that provides the most relevant information about the graph's properties. This can be achieved by optimizing the Graph Information Bottleneck (GIB) using a mutual information estimator. However, GIB has issues with training instability and producing inadequate results due to its inherent optimization process.   To address these problems, we propose a new approach called the Variational Graph Information Bottleneck (VGIB) framework, which breaks down the subgraph recognition problem into two steps: graph perturbation and subgraph selection. In VGIB, we introduce noise injection to control the flow of information from the input graph to a perturbed graph. The perturbed graph is then encouraged to contain informative properties about the original graph. Finally, the desired subgraph is obtained by filtering out the noise present in the perturbed graph.  By customizing the noise prior for each input, the VGIB objective function is endowed with a tractable variational upper bound. This leads to superior empirical performance and theoretical properties. Extensive experiments conducted on graph interpretation, explainability of Graph Neural Networks, and graph classification demonstrate that VGIB outperforms existing methods in discovering more suitable subgraphs.  In summary, our proposed VGIB framework addresses the limitations of GIB in subgraph recognition by introducing graph perturbation and subgraph selection steps. This approach yields better subgraphs, as confirmed by empirical experiments in various graph-related tasks.