Cluster discrimination is a useful method for unsupervised representation learning, consisting of two phases: clustering and discrimination. The main challenge lies in the clustering phase, as existing methods often require batch processing and can result in a dominant cluster. To address these issues, we propose a novel approach called online Constrained K-means (CoKe) for clustering-based representation learning. Unlike balanced clustering, our method only imposes a constraint on the minimum cluster size, allowing for more flexibility in capturing the underlying data structure. Additionally, our online assignment method guarantees convergence to the global optimum. By separating clustering and discrimination, CoKe achieves competitive performance even with a single instance view. Experimental results on ImageNet and other benchmark datasets confirm the effectiveness and efficiency of our approach.