This study addresses the limitation of previous object tracking methods that primarily focus on favorable lighting conditions and neglect performance in nighttime scenarios. To overcome this, the researchers propose a novel unsupervised domain adaptation framework called UDAT for nighttime aerial tracking. They introduce a unique object discovery approach to generate training patches from raw nighttime tracking videos. To address the domain discrepancy between day and night, they incorporate a Transformer-based bridging layer after the feature extractor to align image features from both domains. Additionally, a day/night feature discriminator is employed to adversarially train the tracking model for nighttime tracking. The researchers also create a benchmark dataset called NAT2021, consisting of 180 manually annotated tracking sequences in the test set and over 276k unlabelled nighttime tracking frames in the train set. Through extensive experiments, they demonstrate the robustness and adaptability of their proposed framework for nighttime aerial tracking. The code and benchmark dataset can be accessed at https://github.com/vision4robotics/UDAT.