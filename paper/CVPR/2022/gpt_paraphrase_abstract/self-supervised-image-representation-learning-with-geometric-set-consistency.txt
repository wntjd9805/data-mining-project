We present a novel approach for self-supervised image representation learning using 3D geometric consistency. Our idea is that the consistency of 3D geometric features, such as smooth regions and surface discontinuities, can indicate consistent semantics or object boundaries. These features can serve as strong cues to guide the learning of 2D image representations without the need for semantic labels. To achieve this, we incorporate 3D geometric consistency into a contrastive learning framework to enforce feature consistency within image views. We propose using geometric consistency sets as constraints and adapting the InfoNCE loss accordingly. Our experimental results demonstrate that the learned image representations are versatile. By fine-tuning these pre-trained representations for various 2D image-based tasks, such as semantic segmentation, object detection, and instance segmentation using real-world indoor scene datasets, we achieve superior performance compared to state-of-the-art methods.