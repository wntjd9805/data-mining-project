We propose a novel framework that compresses scenes while maintaining localization accuracy. This is important for large-scale environments, especially on mobile devices with limited storage and bandwidth. Our framework involves three stages of compression. First, we cluster the database frames using co-visibility information. Then, a point selection module prunes the points in each cluster, considering the final pose estimation accuracy. Finally, the selected points' features are further compressed using learned quantization. We are the first to propose learned scene compression for visual localization, and we demonstrate its effectiveness and efficiency on various outdoor datasets. Our method achieves accurate localization with low memory consumption.