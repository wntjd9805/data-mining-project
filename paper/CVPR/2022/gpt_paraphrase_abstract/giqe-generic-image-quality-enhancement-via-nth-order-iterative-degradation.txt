Degradations like motion blur, raindrop, rain, snow, illumination, and fog negatively impact image quality and the performance of perception algorithms used in outdoor settings. Existing restoration techniques are specific to individual degradations and fail to address scenarios with multiple degradations simultaneously. To overcome this, blind image restoration and reconstruction algorithms are necessary, but the lack of a diverse dataset hampers their development. In this study, we use a synthetic degradation model that applies random degradations recursively to generate realistic degraded images of different complexities. We introduce a transformer-based architecture that incorporates long-range dependencies to account for spatial variance during image restoration. To reduce computational costs, we propose a multi-branch structure with modifications like a feature selection mechanism and lightweight multiscale convolutions. Additionally, we integrate an auxiliary decoder branch to predict the degradation mask, aiding the network in localizing degradation information for improved restoration and reconstruction. Through empirical analysis on 10 datasets covering various tasks such as raindrop removal, deraining, dehazing, image enhancement, and deblurring, we demonstrate the effectiveness of our approach, achieving state-of-the-art performance.