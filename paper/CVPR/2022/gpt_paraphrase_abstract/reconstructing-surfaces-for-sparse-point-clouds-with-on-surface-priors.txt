Reconstructing surfaces from 3D point clouds is a significant task. Existing methods use Signed Distance Functions (SDFs) to reconstruct surfaces from single point clouds without ground truth signed distances or point normals. However, these methods require dense point clouds, which limits their performance in real-world applications. To address this limitation, we propose a method to reconstruct highly accurate surfaces from sparse point clouds using an on-surface prior. We train a neural network to learn SDFs by projecting queries onto the surface represented by the sparse point cloud. Our approach involves inferring signed distances by ensuring that query projections lie on the surface and have the minimum projection distance. To achieve this, we train the neural network to capture the on-surface prior, which determines whether a point is on the sparse point cloud or not. We then use this prior as a differentiable function to learn SDFs from unseen sparse point clouds. Our method can learn SDFs without relying on ground truth signed distances or point normals. In our numerical evaluation using widely used benchmarks, our method achieves state-of-the-art reconstruction accuracy, especially for sparse point clouds. The code and data for our method are available at https://github.com/mabaorui/OnSurfacePrior.