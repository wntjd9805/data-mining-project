Deep models trained on a specific dataset struggle to generalize when applied to new datasets with different data distributions. This issue is amplified when there is no access to samples from the new dataset. In this paper, we tackle the problem of domain-generalized semantic segmentation, where we aim to train a segmentation model that is robust across domains without using any data from the new domain. Existing methods address this problem by standardizing the data into a common distribution. However, we argue that while this promotes global normalization, it does not produce features that are sufficiently discriminative for clear segmentation boundaries. To address this, we propose a framework that includes two novel modules: Semantic-Aware Normalization (SAN) and Semantic-Aware Whitening (SAW). SAN focuses on aligning features at the category level between different image styles, while SAW enforces distributed alignment for the already aligned features. By incorporating SAN and SAW, we encourage both compactness within categories and separability between categories. We validate our approach through extensive experiments on popular datasets (GTAV, SYNTHIA, Cityscapes, Mapillary, and BDDS), and our method demonstrates significant improvements over existing state-of-the-art models across different backbone networks. The code for our approach is available at https://github.com/leolyj/SAN-SAW.