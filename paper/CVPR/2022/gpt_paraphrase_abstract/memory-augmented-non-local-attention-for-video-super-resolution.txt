This paper introduces a video super-resolution method that focuses on generating high-quality, high-resolution videos from low-resolution ones. Unlike previous methods that rely on temporal neighbor frames for super-resolution, our approach utilizes a cross-frame non-local attention mechanism that does not require frame alignment. This makes our method more resilient to large motions in videos. Additionally, we propose a novel memory-augmented attention module to capture general video details and compensate for information loss due to large motions. We conducted extensive evaluations on various challenging datasets and found that our method outperforms recent video super-resolution approaches, particularly in the case of videos with large motions. We also provide our source code and a new benchmark dataset called Parkour, which can be accessed at https://github.com/jiy173/MANA.