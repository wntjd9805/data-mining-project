We propose the Granularly Controlled Audio-Visual Talking Heads (GC-AVT) method, which aims to generate realistic and expressive talking heads by controlling lip movements, head poses, and facial expressions in a granular manner. We decouple the audio-visual driving sources through prior-based pre-processing designs, which involve disassembling the driving image into three complementary parts: a cropped mouth for lip-sync, a masked head for learning pose, and the upper face for expression. These encoded features from the three sources are balanced through reconstruction training. Our method successfully generates expressive faces with synchronized mouth shapes, controllable poses, and accurately animated emotional expressions.