Self-supervised methods have made significant progress in narrowing the gap with end-to-end supervised learning for image classification. However, in the case of human action videos, where both appearance and motion are important factors, this gap still remains significant. The reason for this is that the current approach of sampling similar video clips, which is necessary for many self-supervised contrastive learning methods, is done conservatively to avoid false positives. Typically, it is assumed that similar clips only occur close together in time within a single video, resulting in insufficient examples of motion similarity.To address this limitation, we propose SLIC, a clustering-based self-supervised contrastive learning method specifically designed for human action videos. Our main contribution is an improvement on the traditional intra-video positive sampling by utilizing iterative clustering to group similar video instances. This allows our method to leverage pseudo-labels obtained from the cluster assignments, enabling the sampling of harder positives and negatives. SLIC surpasses state-of-the-art video retrieval baselines by achieving a 15.4% improvement in top-1 recall on UCF101 and a 5.7% improvement when directly applied to HMDB51. When combined with end-to-end finetuning for action classification, SLIC achieves a top-1 accuracy of 83.2% on UCF101 (an increase of 0.8%) and 54.5% on HMDB51 (an increase of 1.6%). Furthermore, even after self-supervised pretraining on Kinetics400, SLIC remains competitive with the state-of-the-art in action classification.