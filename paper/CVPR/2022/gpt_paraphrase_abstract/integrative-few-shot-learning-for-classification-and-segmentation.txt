We present a new task called few-shot classification and segmentation (FS-CS) that involves classifying and segmenting objects in an image using only a few examples of each target class. This task combines the challenges of few-shot classification and segmentation, and extends them to scenarios where the target classes may or may not be present in the query image. To tackle this task, we propose the integrative few-shot learning (iFSL) framework for FS-CS, which trains a learner to generate class-specific foreground maps for both multi-label classification and pixel-level segmentation. We also introduce an effective iFSL model called attentive squeeze network (ASNet), which utilizes deep semantic correlation and global self-attention to produce reliable foreground maps. Our experimental results demonstrate promising performance on the FS-CS task and achieve state-of-the-art results on standard few-shot segmentation benchmarks.