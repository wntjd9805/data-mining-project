The ability of humans to recognize structured relationships in visual observations and decompose complex scenes into simpler parts is not well explored in the current literature on semantic segmentation. Existing work focuses on predicting target classes for each pixel without considering hierarchical reasoning. In this paper, we propose a hierarchical semantic segmentation (HSS) framework called HSSN. HSSN addresses two critical issues: how to adapt existing segmentation networks to the HSS setting and how to use hierarchy information to improve HSS network learning. To tackle the first issue, HSSN treats HSS as a pixel-wise multi-label classification task with minimal changes to current segmentation models. To address the second issue, HSSN leverages the inherent properties of the hierarchy as a training objective, enforcing segmentation predictions to follow the hierarchy structure. Additionally, HSSN reshapes the pixel embedding space using hierarchy-induced margin constraints to generate well-structured pixel representations and improve segmentation. We evaluate HSSN on four semantic segmentation datasets with different class hierarchies, network architectures, and backbones, demonstrating its generalization and superiority.