We propose a new method called C3Det for annotating multiple instances of tiny objects from multiple classes in images. Our approach uses point-based user inputs to relate the full image context with annotator inputs. We incorporate late-fusion and feature-correlation techniques to combine local and global information. We conducted experiments on the Tiny-DOTA and LCell datasets using two-stage and one-stage object detection architectures, and our approach outperformed existing methods in terms of mAP with fewer clicks. We also conducted a user study to validate the annotation efficiency of our approach, which showed that it is 2.85x faster and has a lower task load compared to manual annotation. The code for our method is available on GitHub at https://github.com/ChungYi347/Interactive-Multi-Class-Tiny-Object-Detection.