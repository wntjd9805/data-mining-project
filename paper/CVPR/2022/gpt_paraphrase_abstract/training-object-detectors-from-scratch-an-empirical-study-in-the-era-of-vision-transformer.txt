Convolutional neural networks (CNNs) have dominated computer vision modeling, but transformers designed for visual data have recently gained attention for their superior performance. However, these vision transformers heavily rely on large-scale pre-training, which limits architectural design and causes learning bias and domain mismatch. This study aims to train a vision transformer-based object detector from scratch, moving away from the traditional "pre-train & fine-tune" paradigm. Previous work successfully trained CNN-based detectors without pre-training, but this approach does not generalize well to vision transformers. Instead of proposing a specific vision transformer-based detector, this study aims to provide insights into training such detectors from scratch, with the hope of assisting other researchers and inspiring further research in related fields. The key finding is that both architectural changes and more training epochs are crucial for training vision transformer-based detectors from scratch. Experiments on the MS COCO dataset show that these detectors can achieve similar performance to their ImageNet pre-trained counterparts.