The main challenge in zero-shot learning (ZSL) is determining the hidden semantic knowledge between visual and attribute features for known classes and transferring this knowledge to unknown classes. Previous approaches either align global image features with class semantic vectors or use one-way attention to learn limited semantic representations. However, these methods fail to effectively discover the intrinsic semantic knowledge between visual and attribute features. To address this issue, we propose a Mutually Semantic Distillation Network (MSDN) that progressively distills intrinsic semantic representations between visual and attribute features for ZSL. MSDN consists of an attribute→visual attention sub-net that learns attribute-based visual features, and a visual→attribute attention sub-net that learns visual-based attribute features. Additionally, we introduce a semantic distillation loss that enables the two attention sub-nets to learn collaboratively and teach each other during training. Our proposed MSDN significantly outperforms existing methods and achieves state-of-the-art results on three challenging benchmarks. The source code for MSDN is available at https://github.com/shiming-chen/MSDN.