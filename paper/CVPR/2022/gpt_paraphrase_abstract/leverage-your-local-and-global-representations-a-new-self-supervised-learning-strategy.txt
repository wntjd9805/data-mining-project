This paper introduces a new self-supervised learning strategy called LoGo that addresses the issue of view-invariant representation learning. Current self-supervised learning methods focus on maximizing similarity between features extracted from different crops of the same image, without considering that these crops may contain different image information. This limits the diversity of the learned representations. LoGo explicitly considers both local and global crops to achieve view invariance. It promotes similarity between global crops from the same image and between a global crop and a local crop. However, it also acknowledges that smaller crops may have entirely different content and encourages dissimilarity between two local crops while remaining close to global crops. The LoGo strategy can be easily applied to existing self-supervised learning methods. Extensive experiments on various datasets and self-supervised learning frameworks validate the superiority of the LoGo approach compared to existing methods. Notably, using only 1/10 of the data, LoGo achieves better results than supervised models in transfer learning.