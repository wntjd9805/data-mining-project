Current state-of-the-art video action recognition models have made significant progress, thanks to deep convolutional networks. However, these models often lack interpretability in their predicted actions. This study addresses this issue by developing an action reasoning framework based on Markov Logic Network (MLN) for probabilistic logical inference. The framework encodes actions using first-order logical rules that represent temporal changes in visual relationships in videos. The proposed model achieves two main contributions: 1) It simultaneously localizes temporal boundaries and recognizes action categories by grounding MLN's logical rules in videos. The weight associated with each rule provides a confidence estimate, making the model more explainable and robust. 2) Instead of using hand-crafted logical rules, a data-driven instantiation of MLN is developed, combining MLN's weight learning and reinforcement learning. The proposed framework can also be integrated with deep models for enhanced performance. Comprehensive experiments on two video action datasets (Charades & CAD-120) demonstrate the effectiveness and explainability of the proposed method.