We present Retrieval Augmented Classification (RAC), a universal method for enhancing conventional image classification pipelines by incorporating a dedicated retrieval module. RAC comprises a standard image encoder combined with a parallel retrieval branch that utilizes a non-parametric external memory consisting of pre-encoded images and associated text snippets. We apply RAC to address the challenge of long-tail classification and demonstrate considerable improvement compared to previous state-of-the-art methods on the Places365-LT and iNaturalist-2018 datasets, achieving increases of 14.5% and 6.7% respectively. Notably, RAC solely relies on the training datasets themselves as the external information source. Moreover, we show that RAC's retrieval module independently learns a high level of accuracy for tail classes, allowing the base encoder to focus on common classes and enhance its performance in those areas. Therefore, RAC provides an alternative approach to leveraging large, pretrained models without the need for fine-tuning, while also paving the way for more effective utilization of external memory in common computer vision architectures.