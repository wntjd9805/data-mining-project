Interactive image segmentation is a crucial tool for annotating pixels and editing images. Users typically add interaction clicks around object details to refine a high-precision binary segmentation mask. Current methods consider these repair clicks as guidance for determining the global prediction. However, this global view causes the model to lose focus on later clicks and does not align with user intentions. In this study, we propose a new approach called FocusCut that shifts the focus back to the clicks themselves, giving them a decisive role in refining object details. We demonstrate the necessity of this focus view by designing a pipeline that integrates object segmentation and local refinement. After obtaining the global prediction, we crop click-centered patches from the original image to progressively refine the local predictions. Our method achieves state-of-the-art results without requiring user perception or increasing parameters. Extensive experiments and visualized results show that FocusCut enables hyper-fine segmentation in interactive image segmentation.