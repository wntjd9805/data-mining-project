We present a new model called Structured state-Evolution (SEvol) for the Vision-and-language Navigation (VLN) task. VLN requires an agent to navigate to a distant location based on natural language instructions. Existing methods use sequence models like Transformer and LSTM for navigation, where a one-dimensional vector represents the navigation state. However, these models discard important navigation clues related to the environment layout.   To address this limitation, we propose SEvol, which uses a graph-based feature to represent the navigation state instead of a vector-based state. We also introduce Reinforced Layout clues Miner (RLM), which mines and detects the most crucial layout graph for long-term navigation using a customized reinforcement learning strategy. Additionally, we propose the Structured Evolving Module (SEM) to maintain the structured graph-based state during navigation, allowing the model to gradually learn the object-level spatial-temporal relationship.  Our experiments on the R2R and R4R datasets demonstrate that SEvol significantly improves the performance of VLN models. For example, on the R2R test set, NvEM achieves a +3% absolute SPL accuracy improvement, and EnvDrop achieves an improvement of +8% with the use of SEvol.