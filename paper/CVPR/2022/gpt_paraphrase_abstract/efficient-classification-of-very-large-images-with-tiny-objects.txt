The classification of large images with small informative objects poses challenges in computer vision, particularly in medical imaging and remote sensing applications. Two main challenges arise: the size of input images is typically in the order of mega- or giga-pixels, making it difficult for existing deep architectures to process them due to memory limitations; and only a small fraction of the input images contain relevant information, resulting in a low region of interest (ROI) to image ratio. Current convolutional neural networks (CNNs) are designed for datasets with large ROIs and small image sizes, and previous approaches have addressed these challenges separately. In this study, we propose an end-to-end CNN model called Zoom-In network that utilizes hierarchical attention sampling to classify large images with tiny objects using a single GPU. We evaluate our model on four datasets related to histopathology, road scenes, satellite imaging, and a pathology dataset with gigapixel images. Experimental results demonstrate that our model achieves higher accuracy compared to existing methods while requiring less memory resources.