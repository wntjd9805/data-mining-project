Current approaches for supervised learning of spatio-temporal representations in videos rely on manually trimmed videos, which restricts the diversity of visual patterns and limits performance improvement. In this study, we propose a method to learn representations using untrimmed videos, which contain more abundant information. Our approach involves learning a hierarchy of consistencies in videos, including visual consistency and topical consistency. Visual consistency refers to pairs of clips that are visually similar when separated by a short time span, while topical consistency refers to pairs that share similar topics when separated by a long time span. We introduce a hierarchical consistency learning framework called HiCo, where visually consistent pairs are encouraged to have the same representation through contrastive learning, and topically consistent pairs are coupled by a topical classifier that determines their topic-relatedness. We also implement a gradual sampling algorithm for hierarchical consistency learning, which we demonstrate to be theoretically superior. Experimental results show that HiCo not only generates stronger representations on untrimmed videos but also improves representation quality when applied to trimmed videos. Unlike standard contrastive learning, HiCo is effective in learning appropriate representations from untrimmed videos.