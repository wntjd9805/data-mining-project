Focus control is crucial for cameras to capture sharp images in challenging real-world situations. The autofocus (AF) feature helps with focus control by automatically adjusting the focus settings. However, event cameras, which have been recently introduced, lack effective AF methods, causing their focus control to rely on simple AF techniques like manual adjustments. This results in poor adaptation in challenging real-world conditions. The differences between event and frame data, such as sensing modality, noise, and temporal resolutions, pose challenges in designing an effective AF method for event cameras. To address these challenges, we have developed a novel event-based autofocus framework. This framework includes an event-specific focus measure called event rate (ER) and a robust search strategy called event-based golden search (EGS). We have created an event-based autofocus dataset (EAD) that contains well-synchronized frames, events, and focal positions in various challenging scenes with severe lighting and motion conditions. Through experiments on this dataset and additional real-world scenarios, we have demonstrated that our method outperforms state-of-the-art approaches in terms of efficiency and accuracy.