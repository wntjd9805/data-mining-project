Open-world instance segmentation is a challenging task that involves grouping pixels into object instances without using a pre-defined taxonomy. Current state-of-the-art methods rely on explicit class semantics obtained from labeled datasets, which leads to a significant decrease in performance when evaluated on out-of-domain data. To address this, we propose a new approach called Generic Grouping Networks (GGNs) for mask proposals. Unlike existing methods, our approach does not require semantic supervision.  GGNs combine a local measure of pixel affinity with instance-level mask supervision to create a training regimen that maximizes the model's generality. We introduce a novel method called Pairwise Affinities (PA) for predicting the local relationship between pairs of pixels. PA can effectively generalize to unseen categories. Using PA, we generate a large set of pseudo-ground-truth instance masks, which, when combined with human-annotated instance masks, are used to train GGNs.  Our approach significantly outperforms the state-of-the-art methods in open-world instance segmentation on various benchmarks including COCO, LVIS, ADE20K, and UVO. By eliminating the reliance on explicit class semantics and leveraging the diversity of the data, our method demonstrates improved performance and generalization capabilities.