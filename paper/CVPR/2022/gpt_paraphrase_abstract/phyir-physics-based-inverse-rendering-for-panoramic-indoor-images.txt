Inverse rendering of complex materials, such as glossy, metal, and mirror materials, has long been a challenging problem in this field, with previous approaches unable to effectively tackle it due to simplified BRDF (Bidirectional Reflectance Distribution Function) and inadequate illumination representations. This paper introduces PhyIR, a neural inverse rendering method that addresses these limitations by employing a more comprehensive SVBRDF (Spatially-Varying Bidirectional Reflectance Distribution Function) representation and a physics-based in-network rendering layer. This approach can handle complex materials and incorporate physical constraints by re-rendering realistic and detailed specular reflectance. The proposed framework estimates geometry, material, and spatially-coherent illumination from a single indoor panorama. To address the lack of panoramic datasets with complete SVBRDF and full-spherical light probes, the authors introduce a dataset called FutureHouse, which is artist-designed and includes high-quality geometry, SVBRDF, and per-pixel spatially-varying lighting. To ensure the coherence of spatially-varying lighting, a novel spatially-coherent loss function is proposed. Extensive experiments on both synthetic and real-world data demonstrate that the proposed method outperforms existing techniques in terms of both quantitative and qualitative results. It is capable of producing photorealistic outcomes for various applications, including dynamic virtual object insertion.