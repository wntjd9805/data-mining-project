This paper aims to develop a universal facial representation that can improve all face analysis tasks. The authors introduce a framework called FaRL, which focuses on transfer performance of pre-trained models and general facial representation learning. FaRL incorporates a contrastive loss to extract high-level semantic meaning from image-text pairs and also utilizes low-level information through masked image modeling to enhance face representation. The authors conduct pre-training on the LAION-FACE dataset, consisting of face image-text pairs, and evaluate the representation capability on various downstream tasks. The results demonstrate that FaRL outperforms previous pre-trained models in terms of transfer performance and performs exceptionally well in low-data scenarios. Furthermore, FaRL surpasses state-of-the-art methods in face analysis tasks such as face parsing and face alignment.