Data augmentation is a technique used to improve the generalization ability of neural networks by expanding the training dataset. However, it is still unclear how to effectively augment graph data to enhance the performance of Graph Neural Networks (GNNs). While existing methods focus on manipulating the graph's topological structures, we propose a novel approach called FLAG (Free Large-scale Adversarial Augmentation on Graphs) that augments node features instead. During training, FLAG iteratively applies gradient-based adversarial perturbations to the node features. This helps the model become invariant to small fluctuations in input data, enabling better generalization to out-of-distribution samples and improving model performance during testing. FLAG is a versatile method that can be applied to various graph-related tasks such as node classification, link prediction, and graph classification. It is highly flexible and scalable, compatible with different GNN backbones and large-scale datasets. We validate the effectiveness and stability of FLAG through extensive experiments and ablation studies. Additionally, we provide intuitive insights to deepen the understanding of our approach. Our implementation of FLAG is publicly available on GitHub at https://github.com/devnkong/FLAG.