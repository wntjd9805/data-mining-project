The current leading method for face recognition involves using large-scale datasets and a margin-based softmax loss to learn deep feature embeddings. However, the Fully Connected (FC) layer used in this approach becomes increasingly memory and computationally expensive as the number of identities in the training set grows. Additionally, large-scale training data often faces conflicts between different classes and follows a long-tailed distribution.To address these issues, this paper introduces a modified version of the FC layer called Partial FC (PFC). In each iteration, the PFC selects positive class centers and a random subset of negative class centers to calculate the margin-based softmax loss. While all class centers are still maintained throughout the entire training process, only a subset is chosen and updated in each iteration. This significantly reduces the computational requirements, the likelihood of conflicts between classes, and the frequency of passive updates on less common class centers. Extensive experiments conducted using various training data and backbone models (such as CNN and ViT) validate the effectiveness, robustness, and efficiency of the proposed PFC method. The source code for implementing this method is available at the GitHub repository: https://github.com/deepinsight/insightface/tree/master/recognition.