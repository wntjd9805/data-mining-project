We introduce a new semantic segmentation network called WildNet that can generalize across different domains by incorporating a diverse range of content and styles from the wild. In domain generalization, the inability to generalize to unseen domains is often attributed to overfitting to the source domain. Previous approaches have attempted to address this issue by diversifying the styles of the source domain, but they overlook overfitting to the source content. In our work, we propose to diversify both the content and style of the source domain using the wild as a resource. Our main idea is for networks to learn domain-generalized semantic information from the wild. We achieve this by augmenting source features to resemble wild styles, enabling networks to adapt to various styles. Additionally, we encourage networks to learn discriminative features by incorporating semantic variations from the wild into the source contents in the feature space. Finally, we regularize networks to capture consistent semantic information even when the content and style of the source domain are extended to the wild. Our extensive experiments on five different datasets demonstrate the effectiveness of WildNet, as it significantly outperforms state-of-the-art methods. The source code and model for WildNet are available online at https://github.com/suhyeonlee/WildNet.