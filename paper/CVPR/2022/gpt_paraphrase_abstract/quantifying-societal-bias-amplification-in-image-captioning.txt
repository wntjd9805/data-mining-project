In this study, we investigate how societal biases are intensified in image captioning. Previous research has demonstrated that image captioning models tend to reinforce gender and racial biases. However, there is currently no standardized set of metrics to measure, quantify, and assess the societal bias present in captions. To address this gap, we conduct a thorough examination of the strengths and limitations of existing metrics. Additionally, we propose a new metric called LIC, which is specifically designed to analyze bias amplification in captioning. Our argument is that, in the context of image captioning, it is insufficient to solely focus on accurately predicting the protected attribute. Instead, the entire context should be considered. To validate our claims, we extensively evaluate both traditional and state-of-the-art image captioning models. Surprisingly, our findings reveal that bias mitigation models, when solely concentrating on the protected attribute prediction, unintentionally exacerbate bias amplification.