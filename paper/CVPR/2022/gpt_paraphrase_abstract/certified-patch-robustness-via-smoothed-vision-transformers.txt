Certified patch defenses ensure the resilience of an image classifier against arbitrary changes in a limited area. However, currently, this robustness negatively impacts the classifier's standard accuracy and inference speed. In this study, we showcase the effectiveness of vision transformers in enhancing certified patch robustness while maintaining computational efficiency and minimizing the decline in standard accuracy. The improvements arise from the vision transformer's capability to handle heavily masked images effectively.