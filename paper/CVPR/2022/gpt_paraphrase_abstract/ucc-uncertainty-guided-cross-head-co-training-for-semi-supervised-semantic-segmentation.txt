We propose a novel learning framework called Uncertainty guided Cross-head Co-training (UCC) for semi-supervised semantic segmentation using deep neural networks (DNNs). This framework combines the benefits of consistency and self-training by introducing weak and strong augmentations within a shared encoder. Each segmentation head interacts with its peers, with the weak augmentation result used to supervise the strong. To boost the diversity of consistency training samples and alleviate distribution mismatch and class imbalance problems, we employ Dynamic Cross-Set Copy-Paste (DCSCP). Additionally, our proposed Uncertainty Guided Re-weight Module (UGRM) enhances the self-training pseudo labels by modeling uncertainty and suppressing the effect of low-quality pseudo labels from its peer. Experimental results on Cityscapes and PASCAL VOC 2012 datasets demonstrate the effectiveness of our UCC framework. Our approach outperforms other state-of-the-art semi-supervised semantic segmentation methods, achieving 77.17% and 76.49% mIoU on Cityscapes and PASCAL VOC 2012 datasets respectively under 1/16 protocols, which are +10.1% and +7.91% better than the supervised baseline.