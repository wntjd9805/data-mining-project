Generalization under distributional shift is a major challenge in machine learning. The Invariant Risk Minimization (IRM) framework has shown promise in addressing this issue by extracting invariant features. However, recent studies have shown negative results when applying IRM to deep models. We believe that the failure of IRM in deep models can be attributed to their tendency to overfit the data. Our theoretical analysis reveals that IRM becomes equivalent to empirical risk minimization (ERM) when overfitting occurs. Our empirical evidence also supports this finding, as IRM methods that perform well in typical settings deteriorate when the model size is slightly increased or the training data is reduced. To mitigate this problem, we propose Bayesian Invariant Risk Minimization (BIRM) by incorporating Bayesian inference into IRM. The main idea is to estimate the penalty of IRM based on the posterior distribution of classifiers, which is less susceptible to overfitting compared to a single classifier. Extensive experiments on four datasets demonstrate that BIRM consistently outperforms existing IRM baselines.