Deep stereo models have shown excellent performance in driving scenes, but they struggle when applied to unseen scenes. Although continuous online adaptation has helped reduce this performance gap, it is not suitable for rapidly changing scenes as it requires continuous gradient updates during inference. To address these challenges, we propose a method called Reusable Architecture Growth (RAG) for continual stereo matching. RAG incorporates task-specific neural unit search and architecture growth to enable continual learning of new scenes while preventing forgetting of previously learned scenes. It also introduces a module called Scene Router, which dynamically selects the appropriate architecture path for each scene during inference. Our experimental results demonstrate that our approach achieves impressive performance in various difficult driving scenes.