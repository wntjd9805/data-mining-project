This paper addresses the problem of Few-Shot Image Classification (FSIC) in the presence of adversarial examples. Adversarial examples are particularly challenging for deep learning methods, as they can still be vulnerable even with a large amount of labeled training data. Existing approaches to this problem rely on meta-learning with sampled few-shot tasks. In contrast, this paper proposes a simpler approach that directly learns generalizable representations without the need for task sampling. The proposed method incorporates an adversarial-aware mechanism that uses feature-level differences between legitimate and adversarial examples for auxiliary supervision. Additionally, a novel adversarial-reweighted training strategy is introduced to address the imbalance among adversarial examples. A feature purifier is also employed as post-processing for adversarial features. Furthermore, the proposed method demonstrates superior transferability even when faced with cross-domain adversarial examples. Extensive experiments show that the proposed method outperforms state-of-the-art adversarially robust FSIC methods on two standard benchmarks.