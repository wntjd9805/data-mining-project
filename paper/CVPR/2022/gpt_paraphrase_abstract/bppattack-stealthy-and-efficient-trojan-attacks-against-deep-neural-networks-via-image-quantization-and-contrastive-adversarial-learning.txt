This paper introduces a new type of Trojan attack called BPPATTACK that exploits the vulnerability of deep neural networks. Unlike existing attacks which use visible patterns as triggers, BPPATTACK utilizes image quantization and dithering techniques to introduce imperceptible changes that are difficult for humans to detect. This stealthy and efficient attack does not require training auxiliary models. However, injecting such triggers during training is challenging due to the minimal alterations made to the images. To address this issue, the authors propose a contrastive learning approach that uses adversarial attacks to generate negative sample pairs, resulting in a precise and accurate trigger. The effectiveness of the proposed method is demonstrated through high attack success rates on four benchmark datasets, including MNIST, CIFAR-10, GTSRB, and CelebA. Furthermore, BPPATTACK is able to bypass existing Trojan defenses and human inspection. The code for this attack can be found at the provided GitHub link.