This paper introduces OCSampler, an efficient framework for video representation. Videos contain both meaningful information and redundant data, so it is important to select informative frames for efficient video recognition. Previous methods approached frame sampling as a sequential decision task, selecting frames based on their importance. However, OCSampler presents a more efficient approach by condensing the representation into a single short clip. It achieves this by designing instance-specific video condensation policies that select frames in a single step, rather than sequentially. These policies are derived from a skim network and a policy network. Additionally, the proposed method incorporates a frame number budget, allowing the framework to produce accurate predictions with as few frames as possible. Experimental results on various benchmarks demonstrate that OCSampler outperforms previous methods in terms of accuracy and efficiency. For example, it achieves a mean average precision of 76.9% and 21.7 GFLOPs on ActivityNet, with an impressive throughput of 123.9 Video/s on a single TITAN Xp GPU.