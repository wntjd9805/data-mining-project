Deep neural networks have made significant advancements in various tasks such as autonomous driving, face recognition, and medical diagnosis. However, they are vulnerable to backdoor attacks, where malicious triggers are injected during model training, leading to specific behaviors chosen by attackers during inference. This poses serious security threats. To address this, we propose a novel approach called Shapley Pruning (ShapPruning) that utilizes the Shapley value to identify triggered neurons and mitigate backdoor attacks, even in situations with limited data availability (e.g., one image per class or no data). By considering neuron interactions, ShapPruning successfully identifies and prunes a small percentage of infected neurons (less than 1%) while maintaining the model's structure and accuracy. To enhance the efficiency of ShapPruning, we introduce a discarding threshold and Ïµ-greedy strategy to accelerate Shapley estimation, enabling the repair of poisoned models in just a few minutes. Our experimental results demonstrate the effectiveness and robustness of ShapPruning compared to existing methods in defending against various attacks and tasks.