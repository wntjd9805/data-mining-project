In recent years, unbiased scene graph generation (SGG) models have made significant progress. However, most existing models overlook the quality of ground-truth annotations in prevailing SGG datasets. These models assume that all manually annotated positive samples are equally correct and that all unannotated negative samples are purely background. This paper argues that these assumptions do not apply to SGG as there are numerous "noisy" ground-truth predicate labels that violate these assumptions and harm the training of unbiased SGG models. To address this issue, the paper proposes a novel model-agnostic strategy called NoIsy label CorrEction (NICE) for SGG. NICE not only detects noisy samples but also reassigns high-quality predicate labels to them. By training with NICE, a cleaner version of the SGG dataset can be obtained for model training. NICE consists of three components: negative Noisy Sample Detection (Neg-NSD), positive NSD (Pos-NSD), and Noisy Sample Correction (NSC).In Neg-NSD, the task is formulated as an out-of-distribution detection problem, and pseudo labels are assigned to all detected noisy negative samples. In Pos-NSD, a clustering-based algorithm is used to divide all positive samples into multiple sets, with the samples in the noisiest set considered as noisy positive samples. Finally, in NSC, a weighted K-nearest neighbors (KNN) algorithm is employed to reassign new predicate labels to the noisy positive samples. Extensive experiments with different backbones and tasks demonstrate the effectiveness and generalization abilities of each component of NICE. The results validate the usefulness of NICE in addressing the issue of noisy ground-truth annotations in SGG datasets.