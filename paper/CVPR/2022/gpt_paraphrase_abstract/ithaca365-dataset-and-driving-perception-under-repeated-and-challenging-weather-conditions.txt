Recent advances in self-driving car technology have been driven by the availability of large-scale datasets, usually collected in specific locations and favorable weather conditions. However, in order to ensure high safety standards, these perception systems need to be robust enough to operate in various weather conditions, including snow and rain. This paper introduces a new dataset that aims to enable robust autonomous driving through a unique data collection process. The dataset consists of recordings along a 15 km route, encompassing diverse scenes (urban, highway, rural, campus), weather conditions (snow, rain, sun), time variations (day/night), and traffic scenarios (pedestrians, cyclists, cars). It includes images and point clouds captured by cameras and LiDAR sensors, as well as precise GPS/INS data to establish correspondence across routes. Additionally, the dataset provides annotations for roads and objects using amodal masks to account for partial occlusions and 3D bounding boxes. The paper showcases the dataset's uniqueness by analyzing the performance of baseline models in tasks such as amodal segmentation, depth estimation, and 3D object detection. The inclusion of repeated routes in the dataset also opens up new research avenues in object discovery, continual learning, and anomaly detection.