Most semi-supervised learning methods train models using only a portion of the unlabeled data, typically selecting samples with confidence scores higher than a predefined threshold. However, we propose that better recognition performance can be achieved by utilizing all unlabeled data. To accomplish this, we introduce the Adaptive Confidence Margin (Ada-CM) approach for semi-supervised deep facial expression recognition. At each training epoch, the confidence scores of unlabeled samples are compared to an adaptively learned confidence margin, dividing them into two subsets. Subset I consists of samples with confidence scores equal to or higher than the margin, while subset II contains samples with scores lower than the margin. In subset I, we enforce the predictions to match pseudo labels, while in subset II, we employ a feature-level contrastive objective to learn effective facial expression features. We conduct thorough evaluations on four challenging datasets and demonstrate that Ada-CM achieves state-of-the-art performance, surpassing fully-supervised baselines in a semi-supervised manner. Ablation study further confirms the effectiveness of our method. The source code can be found at https://github.com/hangyu94/Ada-CM.