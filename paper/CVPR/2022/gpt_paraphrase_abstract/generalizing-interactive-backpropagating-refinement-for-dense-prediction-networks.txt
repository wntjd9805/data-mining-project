With the increasing popularity of deep neural networks in computer vision tasks, various methods have been developed to automatically estimate target outputs based on visual inputs. Despite improvements in accuracy, interactive refinement is often necessary for further correction. A recent approach called feature backpropagating refinement scheme (f-BRS) has been proposed for interactive segmentation, which optimizes auxiliary variables in a pretrained network to improve object segmentation based on user inputs. However, this method only allows for global refinement due to the limited auxiliary variables used (channel-wise scale and bias).To address this limitation and extend backpropagating refinement to a wider range of dense prediction tasks, we present a new set of layers called Generalized Backpropagating Refinement Scheme (G-BRS). These layers enable both global and localized refinement for tasks such as interactive segmentation, semantic segmentation, image matting, and monocular depth estimation. Our experiments on various datasets demonstrate that the G-BRS method can successfully generalize and significantly enhance the performance of existing pretrained models with just a few user interactions.