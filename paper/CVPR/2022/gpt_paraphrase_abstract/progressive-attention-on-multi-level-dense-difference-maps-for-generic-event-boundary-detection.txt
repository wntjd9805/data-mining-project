Generic event boundary detection (GEBD) is a challenging task in video understanding that involves detecting moments where humans perceive event boundaries. The task is difficult due to the various temporal variations of event boundaries. This paper introduces an end-to-end learnable framework called DDM-Net to address this challenge. Three notable improvements are made to handle the diversity and complex semantics of event boundaries.   Firstly, a feature bank is constructed to store multi-level features of space and time, enabling difference calculation at multiple scales. This helps capture the differences between event boundaries effectively. Secondly, dense difference maps (DDM) are introduced to comprehensively characterize motion patterns, addressing the issue of inadequate temporal modeling in previous methods. By using DDM, the motion aspect of event boundaries is better captured.   Lastly, progressive attention is employed on multi-level DDM to aggregate both appearance and motion clues. This allows for a more comprehensive understanding of event boundaries by considering both visual and movement information. As a result, DDM-Net achieves significant performance improvements of 14% and 8% on the Kinetics-GEBD and TAPOS benchmark datasets, respectively. It also outperforms the top-1 winner solution of the LOVEU Challenge@CVPR 2021 without any additional enhancements.   These results demonstrate the effectiveness of richer motion representation and more sophisticated aggregation techniques in handling the diversity of GEBD. The code for DDM-Net is available at https://github.com/MCG-NJU/DDM.