The traditional CAM (Class Activation Map) method tends to activate object regions but also includes irrelevant background regions. This can be problematic for weakly supervised semantic segmentation (WSSS) models that only have access to a fixed set of image-level object labels. In this paper, we propose a novel framework called Cross Language Image Matching (CLIMS) that leverages the Contrastive Language-Image Pre-training (CLIP) model to address this issue. Our framework introduces natural language supervision to activate more accurate object regions and suppress closely-related background regions. We achieve this by designing object, background region, and text label matching losses to guide the model in generating more reasonable object regions for each category. Additionally, we incorporate a co-occurring background suppression loss that prevents the model from activating background regions closely related to the objects, using a predefined set of class-related background text descriptions. These design choices enable CLIMS to produce more complete and compact activation maps for the target objects. Through extensive experiments on the PASCAL VOC2012 dataset, we demonstrate that CLIMS outperforms previous state-of-the-art methods. The code for our framework is available at https://github.com/CVI-SZU/CLIMS.