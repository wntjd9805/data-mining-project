Recently, there has been a growing interest in 360-degree imaging. However, the angular resolution of these images is lower compared to narrow field-of-view perspective images captured with a fisheye lens and the same sensor size. To address this issue, it is advantageous to super-resolve the 360-degree images. Previous attempts at super-resolution mostly relied on equirectangular projection (ERP) despite its latitude-dependent distortions. This approach can lead to information loss when transforming the high-resolution (HR) image to other projection types. In this study, we propose a novel framework called SphereSR to generate a continuous spherical image representation from a low-resolution (LR) 360-degree image. Our goal is to predict RGB values at specific spherical coordinates for super-resolution with any 360-degree image projection. Our framework consists of a feature extraction module that represents the spherical data using an icosahedron and efficiently extracts features on the spherical surface. We also introduce a spherical local implicit image function (SLIIF) to predict RGB values at the spherical coordinates. This allows SphereSR to reconstruct an HR image flexibly, regardless of the projection type. Experimental results on various benchmark datasets demonstrate the superior performance of our proposed method compared to existing approaches.