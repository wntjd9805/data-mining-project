The focus of learning-based multi-view stereo (MVS) has been on using 3D convolution on cost volumes. However, this approach has limitations in terms of computation and memory consumption, leading to a restricted resolution of output depth. Instead of refining cost volumes, we propose directly optimizing the depth value along each camera ray, similar to a laser scanner's range finding. This approach, called RayMVSNet, simplifies the MVS problem by prioritizing ray-based depth optimization over full cost volume optimization. We utilize transformer features to enable sequential prediction of a 1D implicit field along each camera ray, with the zero-crossing point indicating scene depth. Additionally, we implement multi-task learning for improved optimization convergence and depth accuracy. Our method outperforms previous learning-based approaches on both the DTU and Tanks & Temples datasets, achieving an overall reconstruction score of 0.33mm on DTU and an f-score of 59.48% on Tanks & Temples.