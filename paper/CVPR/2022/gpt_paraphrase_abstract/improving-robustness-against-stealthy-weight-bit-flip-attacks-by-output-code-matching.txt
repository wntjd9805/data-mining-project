Deep neural networks (DNNs) are susceptible to adversarial weight bit-flip attacks, where faulty hardware injects faults into the memory systems storing network parameters. Recent attacks are even more concerning as they can find minimal targeted and stealthy weight bit-flips that maintain the expected behavior for untargeted test samples, making them undetectable from a DNN operation perspective. To address this, we propose a defense mechanism that enhances the robustness of DNNs against realistic stealthy weight bit-flip attacks.  Our approach involves using output code matching networks that utilize a different output coding scheme. Instead of the traditional one-hot encoding of classes, we replace it with partially overlapping bit strings. This new encoding significantly reduces the stealthiness of the attack. Importantly, our defense mechanism is compatible with existing defenses and DNN architectures. It can be easily implemented on pre-trained models by redefining the output classification layer and fine-tuning.  We conducted experimental benchmark evaluations to compare our approach with existing regularized weight quantization based defenses. The results demonstrate that output code matching is superior in defending against stealthy weight bit-flip attacks. Our defense mechanism proves to be effective and provides an additional layer of security for DNNs.