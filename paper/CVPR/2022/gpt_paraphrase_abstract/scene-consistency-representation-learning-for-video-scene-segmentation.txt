We propose a Self-Supervised Learning (SSL) framework to improve the identification of scene boundaries in long-term videos, such as movies or TV shows. Our approach focuses on learning better shot representations from unlabeled videos by ensuring scene consistency. We achieve this through data augmentation and shuffling methods to enhance the model's generalizability. Unlike previous methods, we do not explicitly learn scene boundary features. Instead, we use a temporal model to assess the quality of shot features with fewer biases. Our method outperforms existing approaches in Video Scene Segmentation and we provide a fair benchmark for evaluating such methods. The code for our framework is available.