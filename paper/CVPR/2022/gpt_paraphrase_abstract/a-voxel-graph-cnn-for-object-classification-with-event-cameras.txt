Event cameras are gaining attention for their low power consumption, high dynamic range, and high temporal resolution. Recent success in event-based object classification has been achieved by converting sparse events into dense frames for traditional 2D learning methods. However, this approach requires heavy models and has high computational complexity due to redundant information. This study aims to address the problem of balancing accuracy and model complexity in event-based classification models. A novel graph representation for event data is introduced to better exploit sparsity, and a lightweight voxel graph convolutional neural network (EV-VGCNN) is customized for event-based classification. This includes using voxel-wise vertices instead of point-wise inputs to capture regional 2D semantics while maintaining sparsity, and proposing a multi-scale feature relational layer (MFRL) to extract spatial and motion cues from each vertex based on its distance to neighbors. Comprehensive experiments demonstrate that the proposed model achieves high classification accuracy with low model complexity (only 0.84M parameters).