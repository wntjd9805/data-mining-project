We propose Styleformer, a generator that uses style vectors based on the Transformer structure to synthesize images. In this study, we effectively utilize a modified Transformer structure with increased multi-head attention and pre-layer normalization. We also introduce an innovative Attention Style Injection module, which is a method for style modulation and demodulation in self-attention operations. These new components address the limitations of convolutional neural networks (CNNs) by handling long-range dependencies and understanding the global structure of objects. We present two methods for generating high-resolution images using Styleformer. Firstly, we apply Linformer to visual synthesis (Styleformer-L), allowing Styleformer to generate higher resolution images while improving computation cost and performance. This is the first instance of using Linformer for image generation. Secondly, we combine Styleformer with StyleGAN2 (Styleformer-C) to efficiently generate high-resolution compositional scenes, with Styleformer capturing long-range dependencies between components. With these adaptations, Styleformer achieves comparable performance to state-of-the-art models in both single and multi-object datasets. Additionally, groundbreaking results from style mixing and attention map visualization demonstrate the advantages and efficiency of our model.