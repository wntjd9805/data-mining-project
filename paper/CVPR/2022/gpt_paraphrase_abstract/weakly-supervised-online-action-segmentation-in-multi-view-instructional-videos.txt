This paper focuses on the problem of weakly-supervised online action segmentation in instructional videos. The authors propose a framework that uses Dynamic Programming to segment streaming videos online during test time, and they demonstrate its superiority over the greedy sliding window approach. To enhance the framework, they introduce the Online-Offline Discrepancy Loss (OODL) to encourage segmentation results with higher temporal consistency. During training, they leverage frame-wise correspondence between multiple views to supervise the weakly-labeled instructional videos. They explore three different multi-view inference techniques to generate more accurate pseudo ground-truth without additional annotation cost. The authors present results and conduct ablation studies on two benchmark datasets, Breakfast and IKEA ASM, in the domains of cooking and assembly. The experimental results demonstrate the effectiveness of the proposed methods both qualitatively and quantitatively.