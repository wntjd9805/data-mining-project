We introduce CLIP-NeRF, a method for manipulating 3D objects using neural radiance fields (NeRF). Our approach leverages the joint language-image embedding space of the CLIP model to enable user-friendly manipulation of NeRF. We propose a unified framework that allows manipulation through text prompts or exemplar images. We introduce a disentangled conditional NeRF architecture that enables individual control over shape and appearance by using a learned deformation field for shape conditioning and deferring color conditioning to the rendering stage. We design code mappers that update latent codes based on CLIP embeddings to reflect targeted editing, trained with a matching loss to ensure accuracy. Additionally, we propose an inverse optimization method that accurately projects input images to latent codes for manipulation of real images. We evaluate our approach through extensive experiments with text prompts and exemplar images, and provide an intuitive interface for interactive editing.