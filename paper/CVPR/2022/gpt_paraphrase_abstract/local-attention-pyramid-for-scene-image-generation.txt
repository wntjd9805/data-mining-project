This paper addresses the issue of class-wise visual quality imbalance in scene images generated by Generative Adversarial Networks (GANs). The authors observe that the visual quality of different object classes in the generated images is correlated with the dominance of those classes in the training data. Specifically, less frequent and smaller object classes tend to have lower quality in the synthesized images. To tackle this problem, the authors propose a new attention module called Local Attention Pyramid (LAP) module, which is designed specifically for scene image synthesis. This module aims to encourage GANs to generate diverse object classes of high quality by spreading high attention scores to local regions of the images, since objects in scene images are spread throughout the entire image. Additionally, the LAP module assigns attention scores at multiple scales to account for the scale diversity of different objects. The experimental results on three different datasets demonstrate consistent improvements in evaluation metrics such as Frechet Inception Distance (FID) and Frechet Segmentation Distance (FSD) compared to state-of-the-art baselines. Furthermore, the LAP module is applied to various GAN methods, showcasing its wide applicability.