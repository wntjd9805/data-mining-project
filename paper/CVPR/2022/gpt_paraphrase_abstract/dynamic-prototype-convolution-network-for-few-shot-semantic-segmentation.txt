The main challenge in few-shot semantic segmentation is how to effectively combine support and query features to accurately segment objects in episodic training scenarios. Current methods rely on simple operations like cosine similarity and feature concatenation, which often fail to capture important object details in query images, leading to inaccurate segmentation results. To address this issue, we propose a dynamic prototype convolution network (DPCN) that can capture intrinsic object details for precise semantic segmentation. DPCN utilizes a dynamic convolution module (DCM) to generate dynamic kernels from support foreground, enabling information interaction through convolution operations on query features. Additionally, DPCN includes a support activation module (SAM) and a feature filtering module (FFM) to generate pseudo masks and filter out background information in query images, respectively. This combination of SAM and FFM enhances context information extraction from query features. DPCN is also flexible and efficient for k-shot few-shot semantic segmentation. Experimental results on PASCAL-5i and COCO-20i datasets demonstrate that DPCN outperforms other methods in both 1-shot and 5-shot settings.