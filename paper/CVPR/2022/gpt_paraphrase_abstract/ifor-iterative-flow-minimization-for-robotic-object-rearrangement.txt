We present IFOR, a novel approach called Iterative Flow Minimization for Robotic Object Rearrangement, which addresses the significant challenge of accurately rearranging objects in unstructured environments using visual information. Our method is designed to work with unknown objects, utilizing RGBD images of the initial and final scenes.   To achieve accurate object positioning, we first train an optical flow model based on RAFT using synthetic data. This model enables us to estimate the relative transformation of objects. We then employ an iterative minimization algorithm that utilizes this flow information to accurately position previously unseen objects. Importantly, our method is effective even in cluttered scenes and in real-world scenarios, despite being trained solely on synthetic data.   For further demonstration, videos showcasing the capabilities of our method are available at https://imankgoyal.github.io/ifor.html.