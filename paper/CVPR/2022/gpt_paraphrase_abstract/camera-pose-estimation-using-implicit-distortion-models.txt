This paper investigates an alternative approach to intrinsic camera calibration in computer vision. Instead of using low-dimensional parametric models that explicitly describe the mapping between viewing rays and image pixels, we propose a method that implicitly models lens distortion. This is achieved by replacing the parametric model with a regularization term that ensures smooth variation of the distortion map across the image. Our model does not require explicit knowledge of the intrinsic calibration and is parameter-free. It allows for optimization of the camera pose with 6 degrees of freedom. We demonstrate the applicability of our method to various cameras with different distortion characteristics and in multiple applications like visual localization and structure-from-motion.