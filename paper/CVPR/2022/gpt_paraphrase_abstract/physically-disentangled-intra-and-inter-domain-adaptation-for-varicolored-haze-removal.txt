Learning-based methods for dehazing images have made significant progress in recent years. However, these approaches often rely on synthetic data and struggle to perform well in real-world scenarios due to the differences between synthetic and real images. Additionally, only a few studies have addressed the challenge of removing varicolored haze caused by chromatic casts in real scenes. In this study, we aim to tackle the task of removing varicolored haze in real-world settings. To achieve this, we propose a novel approach that combines intra-domain and inter-domain adaptation. Intra-domain adaptation focuses on color correction by translating atmospheric light from varicolored space to a unified color-balanced space and reconstructing the haze image using the scattering model. Inter-domain adaptation involves exchanging the background and other components between synthetic and real images. This allows us to reconstruct haze images that are consistent in both identity and domain, using self-consistency and adversarial loss. Extensive experiments demonstrate that our method outperforms state-of-the-art techniques for removing varicolored haze in real images.