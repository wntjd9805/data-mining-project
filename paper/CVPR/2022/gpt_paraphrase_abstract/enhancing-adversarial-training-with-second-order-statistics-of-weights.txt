Adversarial training is a powerful method for enhancing the resilience of deep neural networks. By optimizing model weights and adversarial perturbations, the robustness of the network can be improved. This paper introduces a new approach called Second-Order Statistics Optimization (S2O), which treats model weights as random variables. By relaxing the assumption of weight independence, the authors derive an improved PAC-Bayesian adversarial generalization bound. Experimental results demonstrate that S2O not only enhances the robustness and generalization of trained neural networks in isolation but also integrates effectively with state-of-the-art adversarial training techniques. The code for S2O is available at the provided GitHub repository.