Misinformation poses a significant threat to our democratic and societal values. Adversaries often spread false stories by using out-of-context misinformation, wherein real images are repurposed to support different narratives by distorting their context or elements. To combat this, we propose an inspectable method that automates the process of fact-checking image-caption pairings using web evidence. We introduce the concept of 'multi-modal cycle-consistency check' to integrate evidence and cues from both textual and visual modalities. Our novel architecture, Consistency-Checking Network (CCN), mimics layered human reasoning across modalities to compare the caption vs. textual evidence, image vs. visual evidence, and image vs. caption. This work serves as a benchmark for open-domain, content-based, multi-modal fact-checking and outperforms previous baselines by leveraging external evidence.