We develop embodied neural networks that can effectively plan and navigate complex 3D environments without prior knowledge of the agent or environment. Our approach focuses on real-world deployment and avoids relying on trial-and-error reinforcement learning. Instead, we train differentiable planners, such as Value Iteration Networks (VIN), using safe expert demonstrations. However, we address two limitations that hinder the deployment of these planners. Firstly, we find that current differentiable planners struggle to plan for the long-term in environments with high branching complexity. Although they should learn to assign low rewards to obstacles to avoid collisions, these penalties are not strong enough to guarantee collision-free operation. To overcome this, we impose a structural constraint on the value iteration process, explicitly modeling impossible actions and noisy motion. Secondly, we extend the model to incorporate exploration using a limited perspective camera with translation and fine rotations, which is crucial for real robot deployment. Our proposed improvements significantly enhance semantic navigation and exploration in various 2D and 3D environments, even in settings that are challenging for differentiable planners. Notably, we successfully apply our approach to the difficult Active Vision Dataset, which includes real images captured from a robot.