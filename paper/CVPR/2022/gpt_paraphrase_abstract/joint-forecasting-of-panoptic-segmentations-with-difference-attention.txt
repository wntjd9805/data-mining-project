Forecasting is crucial for ensuring safe and effective autonomy. Recent research has focused on panoptic segmentations as a promising representation for this task. However, current state-of-the-art models for panoptic segmentation forecasting face two challenges. Firstly, they treat individual object instances independently, which limits their ability to capture interactions between objects. Secondly, they merge individual forecasts in a heuristic manner, leading to suboptimal results.To overcome these limitations, we propose a new panoptic segmentation forecasting model that addresses both issues. Our model employs a transformer architecture and utilizes a novel approach called "difference attention" to jointly forecast all object instances in a scene. This allows the model to explicitly reason about velocities and acceleration by considering the difference in quantities such as object locations. Additionally, our model incorporates depth estimates to further refine its predictions.To evaluate the effectiveness of our proposed model, we conduct experiments on two benchmark datasets: Cityscapes and AIODrive. The results demonstrate that the use of difference attention is particularly well-suited for forecasting tasks, as it enables the model to capture dynamic relationships between objects. Consequently, our model achieves state-of-the-art performance in terms of panoptic segmentation forecasting metrics.In summary, our work introduces a novel panoptic segmentation forecasting model that addresses the limitations of existing approaches. By leveraging difference attention and depth estimates, our model achieves superior performance in forecasting all object instances in a scene. This research contributes to the advancement of safe and effective autonomy by providing a more comprehensive and accurate representation for forecasting tasks.