Video understanding has made significant progress in representation learning tasks such as video captioning, video object grounding, and video descriptive question-answer. However, current methods face challenges in video reasoning tasks, specifically evidence reasoning and commonsense reasoning. To address this, we introduce the task of Causal-VidQA, which covers four types of questions ranging from scene description to evidence reasoning and commonsense reasoning. For commonsense reasoning, we propose a two-step solution that involves answering the question and providing a proper reason. Our experiments on existing VideoQA methods reveal that while they excel in descriptions, they struggle with reasoning. We believe that Causal-VidQA can serve as a guide for advancing video understanding research, shifting the focus from representation learning to deeper reasoning. The dataset and related resources for Causal-VidQA are available at https://github.com/bcmi/Causal-VidQA.git. The answer format only provides the abstraction.