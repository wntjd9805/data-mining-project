This abstract discusses the lack of research on directly learning to model 4D human captures with detailed geometry using deep learning techniques. The authors propose a new framework called H4D that effectively learns a compact and compositional representation for dynamic humans by leveraging the widely used SMPL parametric model. H4D represents a dynamic 3D human over time using SMPL shape and initial pose parameters, as well as latent codes for motion and auxiliary information. The authors introduce a linear motion model to estimate rough and regularized motion, followed by per-frame compensation for pose and geometry details using residual information encoded in the auxiliary code. The authors utilize novel GRU-based architectures to improve learning and representation capability. Extensive experiments show that their method accurately captures dynamic human motion and detailed geometry, and is applicable to various 4D human-related tasks such as motion retargeting, motion completion, and future prediction.