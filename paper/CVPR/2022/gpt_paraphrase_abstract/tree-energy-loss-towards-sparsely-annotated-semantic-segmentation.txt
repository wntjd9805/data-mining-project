This paper introduces a new approach called tree energy loss for sparsely annotated semantic segmentation (SASS). SASS involves training a segmentation network using only a small number of labeled pixels per image. The proposed tree energy loss incorporates semantic guidance for unlabeled pixels by representing images as minimum spanning trees. These trees model both low-level and high-level pairwise affinities. By applying these affinities to the network prediction sequentially, soft pseudo labels are generated for unlabeled pixels in a coarse-to-fine manner, enabling dynamic online self-training. The tree energy loss is easy to incorporate into existing frameworks by combining it with a traditional segmentation loss. Compared to previous SASS methods, our approach does not require multi-stage training strategies, alternating optimization procedures, additional supervised data, or time-consuming post-processing. Despite these advantages, our method outperforms existing approaches in all SASS settings. The code for our method is available at https://github.com/megvii-research/TreeEnergyLoss.