In this study, we introduce an inertia prior for optical flow, which maintains the consistency of object motion in consecutive frames. We propose a flow completion network that aligns and aggregates flow features based on this inertia prior, resulting in improved video inpainting quality. However, existing methods fail to consider variations in lighting and sharpness across frames, leading to spatial incoherence after warping. To address this issue, we propose the Adaptive Style Fusion Network (ASFN), which uses style information from valid regions to guide gradient refinement in warped regions. We also develop a data simulation pipeline to facilitate the training of ASFN. Our experimental results demonstrate the superiority of our method over existing approaches in terms of both quantitative and qualitative evaluations. This work is supported by grants from the Natural Science Foundation of China and the Fundamental Research Funds for the Central Universities.