This paper presents a method for reconstructing a highly realistic human avatar from a single video. The proposed framework takes into account the challenges of pose and shape changes between frames by using a dynamic surface network to recover pose-dependent surface deformations. This approach allows for the separation of the person's shape and texture. To generate photo-realistic results, the authors propose a reference-based neural rendering network and a fine-tuning strategy that enhances details through bottom-up sharpening. The framework also enables applications such as synthesizing novel views and poses, as well as shape editing. Experimental results show that the proposed method outperforms existing state-of-the-art techniques. The code and dataset used in this research will be made available for public use.