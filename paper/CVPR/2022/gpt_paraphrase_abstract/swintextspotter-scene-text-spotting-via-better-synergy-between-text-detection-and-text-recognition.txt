The success of end-to-end scene text spotting, which combines text detection and recognition, has led to increased attention in recent years. However, current methods typically only share the backbone between detection and recognition tasks, without fully utilizing the interaction between the two. In this paper, we propose a new framework called SwinTextSpotter that integrates a transformer encoder with a dynamic head as the detector, and introduces a Recognition Conversion mechanism to guide text localization through recognition loss. This design allows for a concise framework that does not require additional rectification modules or character-level annotation for arbitrary-shaped text. Our experiments on various datasets show that SwinTextSpotter outperforms existing methods in terms of both qualitative and quantitative results. The code for our framework is available at https://github.com/mxin262/SwinTextSpotter.