Generating explanations for complex visual models without direct supervision is challenging. To address this, we propose a framework called LaViSE that enables any convolutional neural network to generate text descriptions about its own latent representations at the filter level. Our approach establishes a mapping between visual and semantic spaces using generic image datasets, using images and category names. This mapping is then transferred to a target domain that lacks semantic labels. The modular structure of our framework allows analysis of any trained network, even without access to its original training data. We demonstrate that our method can generate novel descriptions for learned filters beyond the categories defined in the training dataset. We evaluate our approach extensively on multiple datasets and present a novel application for unsupervised dataset bias analysis. This application allows us to automatically uncover hidden biases or compare different subsets without additional labels. To support further research, we have made the dataset and code publicly available.