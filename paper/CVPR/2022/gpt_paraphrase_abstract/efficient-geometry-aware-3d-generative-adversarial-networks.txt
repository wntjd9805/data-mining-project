Generating high-quality multi-view-consistent images and 3D shapes from single-view 2D photographs without supervision has been a difficult task. Existing 3D GANs either require significant computational resources or make approximations that compromise the 3D consistency of the results. These limitations affect the quality, resolution, and multi-view consistency of the generated images. In this study, we propose a new approach to improve the computational efficiency and image quality of 3D GANs while minimizing the reliance on these approximations. We introduce a hybrid explicit-implicit network architecture that can generate high-resolution multi-view-consistent images and high-quality 3D geometry in real-time. By separating feature generation and neural rendering, our framework can utilize efficient and expressive 2D CNN generators like StyleGAN2. We demonstrate the effectiveness of our approach with experiments on FFHQ and AFHQ Cats datasets, showcasing state-of-the-art 3D-aware synthesis.