We present a technique for extracting persistent elements from a dynamic scene in a video. These elements are represented as Deformable Sprites, which consist of a 2D texture image for the entire video, per-frame masks for each element, and non-rigid deformations that map the texture image onto each video frame. This decomposition allows for consistent video editing and does not rely on large datasets or pre-trained models. Additionally, our method does not require object masks or user input, and is capable of discovering a wider variety of moving objects compared to previous approaches. We evaluate our method using standard video datasets and showcase qualitative results from various Internet videos.