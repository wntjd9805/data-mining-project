This paper introduces a novel loss function called Hypergraph-Induced Semantic Tuplet (HIST) loss for deep metric learning. The HIST loss leverages multilateral semantic relations of multiple samples to multiple classes through hypergraph modeling. In this approach, deep metric learning is formulated as a hypergraph node classification problem, where each sample in a mini-batch is treated as a node and each hyperedge represents class-specific semantic relations in the form of a semantic tuplet.  Unlike previous graph-based losses that only consider pairwise relations, the HIST loss utilizes the rich multilateral semantic relations provided by the semantic tuplets. By incorporating these semantic relations, the HIST loss guides the embedding model to learn visual semantics that are discriminative for different classes. This leads to improved generalization performance and enhances the model's robustness against input corruptions.  The proposed method is extensively evaluated through experiments and ablations. The results demonstrate the effectiveness of the HIST loss in improving feature learning, achieving state-of-the-art results on three widely used benchmarks. The code for implementing the HIST loss is publicly available at https://github.com/ljin0429/HIST.  Figure 1 illustrates how the HIST loss utilizes multilateral semantic relations between each sample and class in a given mini-batch. A semantic tuplet is defined for each class, representing the sample's semantic relations to the class. Positive samples within the semantic tuplet have definite relation values (equal to 1), while negative samples have soft relation values (less than or equal to 1) based on their likelihood of belonging to the class. Each semantic tuplet is modeled as a hyperedge in the hypergraph. The objective of the hypergraph is to perform node classification. By leveraging the multilateral semantic relations, the HIST loss enables the embedding network to capture important visual semantics suitable for deep metric learning.