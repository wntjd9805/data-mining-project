Post-hoc explanation methods like Grad-CAM allow humans to examine the spatial regions responsible for a network's decision. However, these explanations are not always consistent with human expectations, particularly when it comes to image transformations. To address this issue, we propose a novel training method that enhances the consistency of Grad-CAM explanations. Instead of defining a ground truth for model interpretation, we draw inspiration from contrastive self-supervised learning and apply it to the interpretations themselves. Our approach, called ContrastiveGrad-CAM Consistency (CGC), produces Grad-CAM interpretation heatmaps that align more closely with human annotations while maintaining comparable classification accuracy. Additionally, CGC serves as a regularizer and improves accuracy in limited-data, fine-grained classification scenarios. Another advantage of our method is its ability to leverage unlabeled data during training, leading to better generalization of the model. The code for CGC is available at https://github.com/UCDvision/CGC.