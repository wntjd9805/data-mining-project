This study proposes a framework called MobRecon for reconstructing hand meshes from a single-view image. The framework aims to achieve high reconstruction accuracy, fast inference speed, and temporal coherence. To achieve these goals, the study introduces lightweight stacked structures for 2D encoding and depth-separable spiral convolution for 3D decoding. A novel feature lifting module is also presented to bridge the gap between 2D and 3D representations. This module combines heatmap encoding and position regression paradigms for improved 2D accuracy and temporal coherence. Additionally, pose pooling and pose-to-vertex lifting approaches are used to transform 2D pose encodings into semantic features of 3D vertices. The MobRecon framework is computationally efficient and has a small model size, achieving a high inference speed of 83FPS on Apple A14 CPU. Experiments conducted on popular datasets demonstrate that MobRecon outperforms other methods in terms of reconstruction accuracy and temporal coherence. The code for MobRecon is publicly available at https://github.com/SeanChenxy/HandMesh.