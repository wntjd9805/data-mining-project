Convolutional neural networks (CNNs) used for object recognition are susceptible to changes in depiction due to their focus on low-level statistics of texture patches. Recent studies aim to enhance robustness by incorporating style transfer into training examples, in order to prevent over-fitting to a single depiction style. Although these approaches have shown improved performance, they overlook the geometric variations in object shape that are commonly found in real art. Artists often deform and warp objects for artistic purposes. Building upon this observation, we propose a method to reduce bias by simultaneously increasing the diversity of both texture and geometry in the training data. Essentially, we expand the visual object class to include examples with shape changes that artists employ. Our method involves learning the distribution of warps that cover each object class and augmenting textures based on a wide range of styles. Through experiments, we demonstrate that our approach enhances performance on various cross-domain benchmarks.