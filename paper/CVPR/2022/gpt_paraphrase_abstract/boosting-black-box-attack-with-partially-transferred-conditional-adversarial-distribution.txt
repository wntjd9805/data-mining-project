This study investigates black-box adversarial attacks on deep neural networks (DNNs), where the attacker has limited access to the queried feedback from the targeted DNN model and lacks information about model parameters and training datasets. One potential approach to enhance attack effectiveness is leveraging the transferability of adversarial attacks between white-box surrogate models and the target model. However, differences in model architectures and training datasets, known as "surrogate biases," can weaken the contribution of adversarial transferability to improving attack performance. To address this issue, a novel black-box attack method is proposed, incorporating a mechanism of adversarial transferability that is resilient to surrogate biases. The approach involves transferring partial parameters of the conditional adversarial distribution (CAD) from surrogate models and learning the untransferred parameters based on queries to the target model, allowing flexibility in adjusting the CAD of the target model for new benign samples. Extensive experiments on benchmark datasets and real-world API attacks demonstrate the superior performance of the proposed method. The code for the method will be made available at https://github.com/Kira0096/CGATTACK.