Addressing dataset bias in machine learning is crucial as it can negatively impact models by capturing unintended decision rules through spurious correlations. Previous approaches to handling this issue rely on human supervision, but obtaining appropriate annotations is often impractical and unrealistic. To overcome this limitation, we propose an unsupervised debiasing technique that is simple yet effective. Our approach involves identifying pseudo-attributes using clustering in the feature embedding space, even without explicit bias attribute supervision. We then utilize a cluster-wise reweighting scheme to learn a debiased representation. This method ensures that minority groups are not discounted in order to minimize overall loss, which is important for worst-case generalization. Extensive experiments demonstrate the exceptional performance of our approach on various standard benchmarks, even achieving competitive accuracy compared to supervised methods. The source code for our technique can be found on our project page.