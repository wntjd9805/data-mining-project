Recent research has emphasized the significance of incorporating long-range interactions in the process of inpainting. Existing methods rely on either stand-alone attention techniques or transformers but typically operate at low resolutions due to computational constraints. This study introduces a novel transformer-based model that combines the advantages of transformers and convolutions to effectively handle high-resolution images in large hole inpainting. The framework is meticulously designed to ensure the production of high-quality and diverse recovered images. Notably, an inpainting-oriented transformer block is customized, wherein the attention module aggregates non-local information solely from partially valid tokens, as indicated by a dynamic mask. Extensive experiments conducted on various benchmark datasets demonstrate that the proposed model achieves state-of-the-art performance. The code for this model is publicly available at https://github.com/fenglinglwb/MAT.