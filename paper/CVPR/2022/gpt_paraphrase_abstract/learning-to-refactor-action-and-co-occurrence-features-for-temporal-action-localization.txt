Temporal Action Localization is a challenging task that involves identifying subtle human actions in untrimmed videos while accounting for co-occurring elements such as context and background. Previous approaches have made progress by developing advanced action detectors, but they still struggle with the dominance of these co-occurring elements over the actual action content in videos. In this study, we address this issue by examining two different aspects of a video snippet: the action features and the co-occurrence features. We introduce a novel auxiliary task that separates these two types of features within a video snippet and then combines them to create a new feature representation that highlights the most important action information for accurate action localization. We call our approach RefactorNet, as it factors in the action content and regularizes its co-occurrence features before generating a new video representation that is dominated by action-related information. Through extensive experiments and ablation studies on THUMOS14 and ActivityNet v1.3 datasets, we demonstrate that our new representation, when combined with a simple action detector, significantly improves action localization performance. We also present Figure 1, which visualizes the action and co-occurrence components that our method decouples from a snippet representation. While the co-occurrence components help reduce ambiguity and uncertainty in actions, they often overshadow the action components in a video, negatively impacting action detection. The challenge lies in finding the right balance between these two components in a snippet representation, which is an important yet under-explored problem.