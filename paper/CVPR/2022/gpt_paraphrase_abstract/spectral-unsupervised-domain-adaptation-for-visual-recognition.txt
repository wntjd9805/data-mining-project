Unsupervised domain adaptation (UDA) is a challenging task due to the lack of target annotations and the significant differences between source and target distributions. In this study, we propose a technique called Spectral UDA (SUDA) that operates in the spectral space and can be applied to various visual recognition tasks. SUDA addresses UDA challenges by using a spectrum transformer (ST) to reduce inter-domain discrepancies. The ST enhances domain-invariant spectra while suppressing domain-variant spectra in both source and target samples. Additionally, SUDA incorporates multi-view spectral learning, which maximizes mutual information between multiple ST-generated spectral views of each target sample. Experimental results demonstrate that SUDA consistently achieves higher accuracy than existing methods in object detection, semantic segmentation, and image classification tasks. Furthermore, SUDA can be used in conjunction with transformer-based networks and achieves state-of-the-art performance in object detection. The proposed spectrum transformer (ST) converts images from different domains into the frequency space and decomposes the converted frequency signals into multiple frequency components (FCs) in low, middle, and high frequency bands. The ST learns to identify and enhance domain-invariant FCs while suppressing domain-variant FCs, effectively reducing inter-domain discrepancies. The effectiveness of this process is visually illustrated in Figure 1.