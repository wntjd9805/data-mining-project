We present Ev-TTA, a straightforward and efficient algorithm for adapting event-based object recognition to different test conditions. While event cameras are designed to capture scenes with fast motion and varying lighting conditions, existing recognition algorithms often struggle when faced with extreme scenarios due to significant differences in the data. Ev-TTA addresses this issue by fine-tuning the pre-trained classifiers during the testing phase, using loss functions inspired by the spatio-temporal characteristics of events. By enforcing similar predictions for adjacent events, our algorithm quickly adapts to changes in the environment. Additionally, we leverage the spatial correlations between the two polarities of events to handle noise caused by extreme lighting conditions, as different polarities exhibit distinct noise distributions. Ev-TTA achieves substantial performance improvements across a wide range of event-based object recognition tasks without requiring extensive additional training. Our approach is applicable to various input representations and can be extended to regression tasks. We anticipate that Ev-TTA will play a crucial role in deploying event-based vision algorithms in challenging real-world applications, where significant domain shifts are unavoidable.