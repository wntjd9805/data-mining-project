We introduce HOI4D, a comprehensive dataset aimed at advancing research on human-object interaction at the category level. HOI4D comprises a vast collection of 2.4 million egocentric video frames captured in 4D, across 4000 sequences involving 9 participants. The dataset showcases interactions with 800 distinct object instances from 16 categories, encompassing 610 indoor rooms. To enhance its usability, HOI4D includes meticulous annotations for panoptic segmentation, motion segmentation, 3D hand pose, category-level object pose, and hand action. Moreover, reconstructed object meshes and scene point clouds are provided. To facilitate evaluation and comparison, we establish three benchmark tasks: semantic segmentation of 4D dynamic point cloud sequences, category-level object pose tracking, and egocentric action segmentation with diverse interaction targets. Our detailed analysis demonstrates that HOI4D presents significant challenges for existing methods while simultaneously offering ample research opportunities.