We propose a novel approach for learning dense, continuous 2D-3D correspondence distributions on object surfaces without prior knowledge of visual ambiguities such as symmetry. Additionally, we introduce a new method for estimating the 6D pose of rigid objects by utilizing the learned distributions to generate, evaluate, and refine pose hypotheses. Our approach involves training object-specific latent spaces using an encoder-decoder query model and a small fully connected key model, employing a contrastive loss. Despite being unsupervised in terms of visual ambiguities, our query and key models effectively capture accurate multi-modal surface distributions. Furthermore, our pose estimation technique significantly outperforms existing state-of-the-art methods on the comprehensive BOP Challenge, even when trained solely on synthetic data, surpassing models trained on real data. More information about the project can be found at surfemb.github.io.