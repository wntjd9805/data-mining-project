Occluded person re-identification (ReID) involves matching occluded person images with unoccluded ones across different camera views. Non-Pedestrian Occlusions (NPO) and Non-Target Pedestrians (NTP) often disrupt the identification of Target Pedestrians (TP). Existing methods focus on improving the model's robustness against NPO but overlook the contamination of features from NTP. In this paper, we propose a novel approach called Feature Erasing and Diffusion Network (FED) to address challenges from both NPO and NTP. Our method utilizes an NPO augmentation strategy to simulate NPO on unoccluded pedestrian images and generate accurate occlusion masks. The Occlusion Erasing Module (OEM) explicitly removes NPO features from the representations. Then, we use the Feature Diffusion Module (FDM) to synthesize NTP characteristics in the feature space by combining them with other stored features. The feature diffusion process is guided by occlusion scores from OEM, focusing on visible body parts to enhance the quality of the synthesized NTP characteristics. By jointly optimizing OEM and FDM, our model improves its ability to perceive TP while mitigating the influence of NPO and NTP. Additionally, FDM serves as an auxiliary module for training and is not involved in the inference phase, providing flexibility. Experimental results on occluded and unoccluded person ReID benchmarks demonstrate the superior performance of FED compared to state-of-the-art methods.