Domain Adaptive Object Detection (DAOD) aims to learn a transformation that can estimate target labels using annotated images from a source domain. However, existing methods assume that the source domain labels are completely accurate, which is not always the case in large-scale datasets due to annotation errors. These errors can introduce biases in the source distribution and significantly degrade the performance of domain adaptive detectors. To address this issue, this paper introduces the concept of noisy DAOD and proposes a Noise Latent Transferability Exploration (NLTE) framework. The framework consists of three key components. Firstly, Potential Instance Mining (PIM) is used to identify and recapture miss-annotated instances by leveraging eligible proposals from the background. Secondly, the Morphable Graph Relation Module (MGRM) models the adaptation feasibility and transition probability of noisy samples using relation matrices. And finally, the Entropy-Aware Gradient Reconcilement (EAGR) incorporates semantic information into the discrimination process, ensuring that the gradients provided by noisy and clean samples are consistent in learning domain-invariant representations.The effectiveness of NLTE is evaluated on benchmark DAOD datasets with noisy source annotations. The results show that NLTE improves the mean Average Precision (mAP) by 8.4% even with 60% corrupted annotations. Furthermore, NLTE approaches the performance of training on a clean source dataset, which is considered the ideal upper bound. Overall, the evaluation validates the effectiveness of NLTE in mitigating the impact of noisy annotations in DAOD.