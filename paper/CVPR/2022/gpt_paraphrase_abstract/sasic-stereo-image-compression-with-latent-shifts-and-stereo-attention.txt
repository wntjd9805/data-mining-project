We present a novel approach to compress stereo images by exploiting the similarity between the left and right images in a stereo pair. Our method involves compressing the left image using a learned compression technique based on an autoencoder with a hyperprior entropy model. The encoded information from the compressed left image is then used in both the encoding and decoding stages of compressing the right image. Specifically, we only encode the difference between the latent representation of the right image and the optimally shifted latent representation of the left image. Additionally, we incorporate a stereo attention module to establish a connection between the left and right images during the decoding process. We evaluate the performance of our proposed method on two benchmark stereo image datasets (Cityscapes and InStereo2K) and demonstrate superior results compared to previous stereo image compression methods, all while maintaining a significantly smaller model size.