We introduce a novel approach called reference-based video super-resolution (RefVSR) that utilizes reference videos to achieve high-quality results. Specifically, we focus on RefVSR in a triple-camera setup, where our goal is to enhance the resolution of a low-resolution ultra-wide video by utilizing wide-angle and telephoto videos as references. To accomplish this, we propose a RefVSR network that recurrently aligns and propagates temporal reference features combined with features extracted from low-resolution frames. In order to facilitate the fusion and propagation of these temporal reference features, we introduce a propagative temporal fusion module. To train and evaluate our network, we create the first RefVSR dataset comprising triplets of ultra-wide, wide-angle, and telephoto videos captured simultaneously using a smartphone's triple cameras. Additionally, we propose a two-stage training strategy that fully exploits the video triplets in our dataset for real-world 4× video super-resolution. Through extensive evaluation, our method demonstrates state-of-the-art performance in 4× super-resolution.