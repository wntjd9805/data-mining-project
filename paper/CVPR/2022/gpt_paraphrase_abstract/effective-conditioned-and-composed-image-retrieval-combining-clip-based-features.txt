Conditioned and composed image retrieval systems enhance CBIR systems by incorporating additional text that conveys the user's intent and specifies additional requirements regarding the visual content of the query image. This type of search is particularly useful for e-commerce applications and the development of interactive multimodal searches and chatbots. In this demonstration, we introduce an interactive system that utilizes a combiner network, trained using contrastive learning, to merge visual and textual features extracted from the OpenAI CLIP network for conditioned CBIR. This system can be employed to enhance e-shop search engines, especially in the fashion domain, allowing users to search for dresses, shirts, and toptees by providing a starting image and specifying visual differences such as color, pattern, or shape. The proposed network achieves state-of-the-art performance on the FashionIQ dataset and the more recent CIRR dataset, demonstrating its effectiveness in conditioned retrieval within the fashion domain and in more general composed image retrieval tasks. Figure 1 illustrates an example of using conditioned image retrieval in the fashion domain for e-commerce applications, where users can refine their product searches by providing details and constraints in natural language. The system leverages both visual and textual features to retrieve the desired results. The answer format only provides the abstract.