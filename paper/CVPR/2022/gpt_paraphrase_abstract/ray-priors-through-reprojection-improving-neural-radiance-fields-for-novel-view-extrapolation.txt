Neural Radiance Fields (NeRF) have become popular for generating realistic images of scenes. However, they struggle to produce high-quality results for viewpoints that differ significantly from the training data. This paper focuses on novel view extrapolation, where the training images describe an object well, but there is a notable difference between the training and test viewpoints. To address this, we propose RapNeRF (RAy Priors), which uses a random ray casting policy to train unseen views using seen views. Additionally, we demonstrate that a pre-computed ray atlas can improve the rendering quality for extrapolated views. One limitation of RapNeRF is that it removes strong view-dependent effects due to its reliance on multi-view consistency.