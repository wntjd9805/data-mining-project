Regressing rotations on the SO(3) manifold using deep neural networks is a significant yet unresolved issue. The disparity between the Euclidean network output space and the non-Euclidean SO(3) manifold presents a major challenge for neural network learning in both the forward and backward passes. While some studies have suggested various rotation representations suitable for regression, only a few have focused on improving the gradient backpropagation during the backward pass. In this study, we propose a manifold-aware gradient that directly backpropagates into the deep network weights. By utilizing Riemannian optimization to create a novel projective gradient, our method, called the regularized projective manifold gradient (RPMG), enables networks to achieve state-of-the-art performance in various rotation estimation tasks. Additionally, our proposed gradient layer can be applied to other smooth manifolds, such as the unit sphere. Further details and our project page can be found at https://jychen18.github.io/RPMG.