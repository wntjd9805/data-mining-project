This paper explores the use of diffusion models to restore noisy data by optimizing the denoising score matching loss. The authors suggest that restoring data corrupted with specific noise levels can serve as a pretext task for the model to learn visual concepts effectively. To prioritize these noise levels during training, the weighting scheme of the objective function is redesigned. The authors demonstrate that this simple redesign greatly enhances the performance of diffusion models, regardless of the datasets, architectures, and sampling strategies employed.