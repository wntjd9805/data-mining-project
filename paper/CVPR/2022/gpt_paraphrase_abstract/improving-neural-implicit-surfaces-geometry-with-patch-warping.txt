We propose a method called NeuralWarp to improve the accuracy of neural implicit surfaces in multi-view 3D reconstruction. The limitation in accuracy is attributed to the difficulty of neural networks in learning and rendering high frequency textures. To address this, we introduce a direct photo-consistency term to the neural rendering optimization. This term ensures that the implicit geometry warps views consistently across different angles. Our approach relies on two key elements: (i) warping entire patches using predicted occupancy and normals of 3D points along each ray, and measuring their similarity using robust structural similarity (SSIM); (ii) handling visibility and occlusion to avoid giving too much importance to incorrect warps while encouraging a complete reconstruction. We evaluate our approach on the DTU and EPFL benchmarks and demonstrate that NeuralWarp outperforms state-of-the-art unsupervised implicit surface reconstructions by over 20% on both datasets. The code for our method is available at https://github.com/fdarmon/NeuralWarp.