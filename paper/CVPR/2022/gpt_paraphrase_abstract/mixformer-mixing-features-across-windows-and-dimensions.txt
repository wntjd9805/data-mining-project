While local-window self-attention is effective in vision tasks, it has limitations in terms of receptive field and modeling capability. This is due to the use of non-overlapping windows and shared weights on the channel dimension. To address these issues, we propose Mix-Former. This approach combines local-window self-attention with depth-wise convolution to enhance cross-window connections and expand the receptive fields. Additionally, we introduce bi-directional interactions across branches to incorporate complementary information in both the channel and spatial dimensions. By integrating these designs, Mix-Former efficiently mixes features among windows and dimensions. In image classification, our approach achieves competitive results compared to EfficientNet, outperforming RegNet and Swin Transformer. Moreover, in various dense prediction tasks on MS COCO, ADE20k, and LVIS, Mix-Former demonstrates superior performance with lower computational costs. The code for Mix-Former is available at https://github.com/PaddlePaddle/PaddleClas.