This paper proposes an end-to-end approach for object detection and motion forecasting using raw sensor measurements instead of ground truth tracks. Unlike traditional methods that predict current frame locations and forecast forward in time, our approach directly predicts future object locations and backcasts to determine where each trajectory began. This approach improves accuracy compared to other modular or end-to-end baselines and challenges the role of explicit tracking in embodied perception. By linking future and current locations, our approach can reason about multiple futures, a capability previously considered difficult for end-to-end approaches. Extensive experiments on the nuScenes dataset demonstrate the effectiveness of our approach. We also explore the limitations of using standard forecasting metrics in an end-to-end setup and propose a novel set of joint forecasting and detection metrics to measure accuracy. The code for our approach is available on GitHub.