Few-shot classification is a difficult task due to the limited number of training examples available for each new task. One approach to tackle this problem is to use deep representations that are guided by a similarity measure between a query image and a few support images from the same class. This similarity measure involves assessing the dependence between image features, which are treated as random vectors in a high-dimensional embedding space. Existing methods for few-shot classification either rely solely on marginal distributions, which limits their representation capability, or they are computationally expensive.In this study, we propose a solution called DeepBDC (deep Brownian Distance Covariance) for few-shot classification. DeepBDC works by learning image representations through the comparison of joint characteristic functions of embedded features with the product of their marginals. We decouple the BDC (Brownian Distance Covariance) metric and formulate it as a modular and efficient layer. Additionally, we apply DeepBDC in two different few-shot classification frameworks. We evaluate our method on six standard few-shot image benchmarks that cover various tasks, including general object recognition, fine-grained categorization, and cross-domain classification. The extensive evaluations demonstrate that DeepBDC outperforms existing approaches and achieves state-of-the-art results. The source code for DeepBDC is available at http://www.peihuali.org/DeepBDC.