We propose a fast method for reconstructing opaque objects in 3D from multiple viewpoints, regardless of their materials and lighting conditions. Existing methods use neural surface representations and rendering techniques, but these surface representations are time-consuming to optimize. Instead, we use triangle meshes to represent the surfaces and develop a differentiable rendering pipeline using triangle rasterization and neural shading. This renderer is used in a gradient descent optimization process where both the triangle mesh and the neural shader are jointly optimized to reproduce the multi-view images. We evaluate our method on a publicly available 3D reconstruction dataset and demonstrate that it achieves comparable reconstruction accuracy to traditional and neural approaches while outperforming them in terms of optimization time. Furthermore, we analyze the neural shader and find that it learns a meaningful representation of appearance, allowing for applications such as 3D material editing.