The objective of open-world compositional zero-shot learning (OW-CZSL) is to identify compositions of state and objects in images, using only a subset of them for training and without any prior knowledge of the unseen compositions. Previous approaches address this problem by learning embeddings for compositions together. However, in this study, we revisit a simple CZSL baseline and predict the primitives (states and objects) independently. To ensure that the model develops features specific to each primitive, we employ separate non-linear feature extractors for state and object classifiers. Additionally, we utilize external knowledge to estimate the feasibility of each composition, allowing us to remove unfeasible compositions from the output space. Furthermore, we introduce a new setting called CZSL under partial supervision (pCZSL), where either only object or state labels are available during training, and we leverage our prior knowledge to estimate the missing labels. Our model, Knowledge-Guided Simple Primitives (KG-SP), achieves state-of-the-art performance in both OW-CZSL and pCZSL, outperforming recent competitors even when combined with semi-supervised learning techniques. The code for our model is available at: https://github.com/ExplainableML/KG-SP.