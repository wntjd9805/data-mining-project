In this study, we address the importance of e-commerce images in capturing people's attention during online shopping and retailing. However, research on accurately predicting attention in this context is lacking. To fill this gap, we introduce the SalECI dataset, the first dataset specifically designed for predicting saliency in e-commerce images. We conduct a comprehensive analysis of e-commerce images, emphasizing their unique features such as non-locality and correlation with text regions. Leveraging the non-local and self-attention mechanisms, we propose a salient SWin-Transformer backbone. Additionally, we incorporate a multi-task learning approach with saliency and text detection heads, and introduce an information flow mechanism to enhance both tasks. Through experiments, we demonstrate that our approach achieves state-of-the-art performance in the e-commerce domain.