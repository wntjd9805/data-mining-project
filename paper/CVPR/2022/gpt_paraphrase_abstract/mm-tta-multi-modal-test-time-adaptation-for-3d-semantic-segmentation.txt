This paper introduces a new approach called Multi-Modal Test-Time Adaptation (MM-TTA) for 3D semantic segmentation. The authors propose two modules, Intra-modal Pseudo-label Generation (Intra-PG) and Inter-modal Pseudo-label Refinement (Inter-PR), to handle the challenge of multi-modal input during test-time adaptation. Intra-PG generates reliable pseudo labels within each modality by combining information from two pre-trained models that are updated at different paces. Inter-PR then selects more reliable pseudo labels from different modalities based on a consistency scheme. These modules work together to produce stable self-learning signals for multi-modal test-time adaptation. The proposed framework allows a model to quickly adapt to multi-modal test data without needing access to the source domain training data. The experimental results demonstrate the effectiveness of the regularized pseudo labels generated by the MM-TTA framework.