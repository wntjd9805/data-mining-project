This paper introduces a new method called Contrastive learning for Class-agnostic Activation Map (C2AM) generation, which aims to improve weakly supervised object localization (WSOL) and semantic segmentation (WSSS) using unlabeled image data. Unlike existing methods that focus on discriminating object regions, C2AM leverages the observation that foreground objects have different semantic information compared to their backgrounds, and objects with similar appearance or backgrounds with similar color/texture have similar representations in the feature space.   To exploit these relations, C2AM forms positive and negative pairs and utilizes a novel contrastive loss to disentangle foreground and background in the network's class-agnostic activation map. By guiding the network to discriminate foreground-background relationships across images, the learned class-agnostic activation maps generate more complete object regions. C2AM successfully extracts class-agnostic object bounding boxes for object localization and background cues to refine the class activation maps generated by the classification network for semantic segmentation.  The proposed C2AM is evaluated on three datasets: CUB-200-2011, ImageNet-1K, and PASCAL VOC2012. The experimental results demonstrate the effectiveness of C2AM in improving both WSOL and WSSS. The code for C2AM will be made available at https://github.com/CVI-SZU/CCAM.