Image prediction methods often struggle with tasks that involve object position changes, resulting in blurry images that fail to capture the specific positions objects might occupy. To address this issue, we propose a straightforward modification to existing image similarity metrics. Our approach involves matching images using optical flow and then measuring the visual similarity of corresponding pixels. This modification significantly improves the accuracy and crispness of predictions without requiring any changes to the image prediction network itself. We have tested our method on various video prediction tasks and achieved strong performance using simple network architectures. Additionally, we have also applied our approach to the task of video interpolation. More information, including code and results, can be found on our webpage: https://dangeng.github.io/CorrWiseLosses.