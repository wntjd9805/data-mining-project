Self-supervised learning (SSL) has the potential to utilize large amounts of unlabeled data effectively. However, current SSL methods mainly focus on single-centric-object images like those in ImageNet, neglecting the correlation between scenes and instances, as well as the semantic differences among instances within a scene. To address these limitations, we propose a novel framework called Unified Self-supervised Visual Pre-training (UniVIP). UniVIP can learn versatile visual representations on both single-centric-object and non-iconic datasets. Our framework considers representation learning at three levels: 1) scene-scene similarity, 2) scene-instance correlation, and 3) instance-instance discrimination. We employ the optimal transport algorithm to automatically measure instance discrimination during the learning process. Extensive experiments demonstrate that UniVIP, pre-trained on non-iconic COCO dataset, achieves state-of-the-art transfer performance on various downstream tasks, including image classification, semi-supervised learning, object detection, and segmentation. Additionally, our method can also leverage single-centric-object datasets like ImageNet, outperforming BYOL by 2.5% with the same pre-training epochs in linear probing. Moreover, UniVIP surpasses current self-supervised object detection methods on the COCO dataset, highlighting its universality and potential.