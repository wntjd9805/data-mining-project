We introduce IterMVS, an innovative data-driven technique for high-resolution multi-view stereo. Our approach involves a new GRU-based estimator that incorporates pixel-wise probability distributions of depth in its hidden state. By incorporating scale matching information, our model refines these distributions through multiple iterations to infer depth and confidence. To obtain depth maps, we combine traditional classification and regression methods in a unique way. We validate the efficiency and effectiveness of our approach on DTU, Tanks&Temples, and ETH3D datasets. Despite being the most efficient method in terms of memory and run-time, our model achieves competitive performance on DTU and demonstrates better generalization capabilities on Tanks&Temples and ETH3D compared to most state-of-the-art methods. The code for our method is available at https://github.com/FangjinhuaWang/IterMVS.