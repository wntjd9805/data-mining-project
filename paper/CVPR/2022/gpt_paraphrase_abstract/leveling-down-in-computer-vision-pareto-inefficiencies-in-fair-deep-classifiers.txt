Algorithmic fairness is often achieved by sacrificing overall performance in order to improve accuracy for disadvantaged groups. However, our research shows that existing fairness approaches applied to computer vision actually decrease performance for all groups, with the best performing groups experiencing the greatest decline. By extending the bias-variance decomposition to fairness, we explain why fairness methods designed for low capacity models should not be used in high-capacity models, which are common in computer vision. Our extensive experiments support this analysis, demonstrating that many fairness heuristics used in computer vision also harm the most disadvantaged groups. Based on these findings, we propose an adaptive augmentation strategy that uniquely improves performance for the disadvantaged groups, outperforming all other tested methods.