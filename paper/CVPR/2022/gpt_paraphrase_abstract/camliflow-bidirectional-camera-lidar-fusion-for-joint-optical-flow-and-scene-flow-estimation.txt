This paper focuses on the problem of estimating optical flow and scene flow using synchronized 2D and 3D data. Existing methods either use a complex pipeline or fuse the 2D and 3D information in different ways. However, these approaches do not fully utilize the characteristics of each modality or maximize the complementarity between them. To address this issue, we propose a new framework called CamLiFlow, which consists of 2D and 3D branches connected bi-directionally in specific layers. Unlike previous work, our method uses a point-based 3D branch to better extract geometric features and incorporates a learnable operator to fuse dense image features with sparse point features. Experimental results demonstrate that CamLiFlow achieves superior performance with fewer parameters. In fact, our method outperforms previous state-of-the-art approaches on the KITTI Scene Flow benchmark using only 1/7 of the parameters. The code for our method is available at https://github.com/MCG-NJU/CamLiFlow.