3D object detection is crucial for autonomous driving systems, but few methods utilize segmentation information to improve the detection process. This paper introduces a new framework that combines 3D object detection and panoptic segmentation. The method enhances the 3D object detection backbone in the Bird's-Eye-View plane by incorporating Range-View feature maps from the panoptic segmentation backbone. This allows the detection backbone to utilize multi-view information and overcome the limitations of each projection view. Additionally, the method incorporates foreground semantic information to make the detection task easier by highlighting object class locations in the feature maps. Furthermore, a center density heatmap is generated based on instance-level information to guide the detection backbone by suggesting potential box center locations for objects. The proposed method can be used with any BEV-based 3D object detection method and achieves significant performance improvements based on experiments on the nuScenes dataset. Notably, the method using the CenterPoint 3D object detection network achieves state-of-the-art performance on the nuScenes 3D Detection Benchmark with a score of 67.3 NDS.