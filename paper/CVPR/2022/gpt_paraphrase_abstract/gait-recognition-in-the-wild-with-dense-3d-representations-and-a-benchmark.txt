This paper addresses the limitations of existing studies on gait recognition, which mainly focus on 2D representations of the human body in controlled environments. However, since humans live and walk in a 3D space, projecting the 3D body onto a 2D plane leads to the loss of important information for gait recognition, such as viewpoint, shape, and dynamics. To address this issue, the paper proposes a new framework called SMPLGait that utilizes dense 3D representations of the human body for gait recognition in real-world scenarios. The framework consists of two branches: one extracts appearance features from silhouettes, while the other learns 3D viewpoints and shapes from the 3D SMPL model. To support the development and evaluation of the proposed framework, the paper introduces Gait3D, a large-scale dataset for 3D representation-based gait recognition. This dataset contains data from 4,000 subjects and over 25,000 sequences captured by 39 cameras in an unconstrained indoor setting. The dataset also includes 3D SMPL models recovered from video frames, which provide dense 3D information about body shape, viewpoint, and dynamics. The paper compares the proposed method with existing approaches using Gait3D and demonstrates its superior performance, highlighting the potential of 3D representations for gait recognition in real-world scenarios. The code and dataset are publicly available at: https://gait3d.github.io.