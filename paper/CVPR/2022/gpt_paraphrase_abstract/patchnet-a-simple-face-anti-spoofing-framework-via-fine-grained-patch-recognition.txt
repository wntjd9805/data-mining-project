Face anti-spoofing (FAS) is crucial for protecting face recognition systems from presentation attacks. Existing methods have used pixel-level supervision and domain generalization to address unseen spoof types, but they neglect the local characteristics of image captures, such as capturing devices and presenting materials. This information is necessary for networks to differentiate between live and spoof images. To address this, we propose PatchNet, which reframes FAS as a fine-grained patch-type recognition problem. Our framework identifies the combination of capturing devices and presenting materials based on patches cropped from non-distorted face images. This approach significantly enhances data variation and encourages the network to learn discriminative features from local capture patterns. Additionally, we introduce the Asymmetric Margin-based Classification Loss and Self-supervised Similarity Loss to enhance the generalization ability of spoof features and regularize the patch embedding space. Experimental results confirm our hypothesis and demonstrate that our model robustly recognizes unseen spoof types by focusing on local regions. Furthermore, our fine-grained and patch-level reformulation of FAS outperforms existing methods on intra-dataset, cross-dataset, and domain generalization benchmarks. Our PatchNet framework also enables practical applications like Few-Shot Reference-based FAS and supports further exploration of spoof-related cues.