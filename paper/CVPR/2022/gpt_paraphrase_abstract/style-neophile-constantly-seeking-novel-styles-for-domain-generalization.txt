This study focuses on domain generalization and the use of domain-invariant representation learning. Current methods in this field assume that a domain can be characterized by the styles of its images, and they train a network using data that has been augmented with different styles. This approach helps to prevent the network from being biased towards specific style distributions. However, these methods have a limitation in that they are only able to work with a finite set of styles. This is because they either use a fixed set of external images or interpolate styles from the training data for augmentation. In order to overcome this limitation and maximize the benefits of style augmentation, the authors propose a new method that continuously synthesizes new styles during training. The proposed method uses multiple queues to store the styles that have been observed so far and generates novel styles that have a distinct distribution from the styles in the queues. The process of synthesizing styles is formulated as a monotone submodular optimization, which allows for efficient implementation using a greedy algorithm. The authors conducted extensive experiments on four public benchmarks and the results demonstrate that their proposed method achieves state-of-the-art performance in domain generalization.