Egocentric activity anticipation involves predicting future actions and objects based on current interactions. Current models for activity anticipation face limitations in accurately predicting long-term actions and capturing the desired semantics of the target activity. To address these issues, we propose a hybrid framework called "HRO" that combines memory-augmented recurrent and one-shot representation forecasting strategies. To overcome the limitation of accumulated errors in long-term prediction, we introduce a memory-augmented contrastive learning paradigm. This paradigm utilizes an external memory bank that maintains long-term prototypical activity semantics, ensuring that the anticipated representations are reconstructed from discriminative activity prototypes. To enhance the learning of the memory bank, we design two auxiliary loss functions based on diversity and sparsity mechanisms. Additionally, we propose a one-shot transferring paradigm to enrich the forecasted representations by distilling holistic activity semantics in offline training. Our experimental results on two large-scale datasets demonstrate the effectiveness of the HRO method.