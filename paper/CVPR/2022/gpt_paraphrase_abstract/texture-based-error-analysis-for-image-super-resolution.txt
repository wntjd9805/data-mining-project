Current evaluation practices for image super-resolution (SR) rely heavily on single-value metrics like PSNR or SSIM, which offer limited understanding of the errors and behavior of the SR models. To address this limitation, it is crucial to shift towards a more comprehensive and interpretable evaluation approach. In this study, we emphasize a thorough error analysis from various perspectives. Our primary contribution involves utilizing a texture classifier to assign semantic labels to patches, enabling us to identify the sources of SR errors at both the global and local levels. This approach allows us to determine the semantic alignment of SR datasets, evaluate the performance of SR models for each label, assess the semantic correspondence between high-resolution (HR) and SR patches, and more. By examining the SR process from these diverse angles, we can uncover potential pitfalls and blindspots. Our investigation yields numerous unexpected insights, serving as an initial step towards effectively debugging blackbox SR networks.