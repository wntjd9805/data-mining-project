The conventional method for estimating optical flow, which involves finding the 2D motion field by matching pixels between two images, struggles to accurately estimate large displacements with motion blur. This is because the correlation volume, which is used for pixel matching, is computed using convolutional features that are susceptible to noise. To address this issue, we propose a new architecture called "CRoss-Attentional Flow Transformer" (CRAFT). CRAFT incorporates a Semantic Smoothing Transformer layer to make the features more global and stable, and replaces the dot-product correlations with transformer Cross-Frame Attention to filter out noise and compute more accurate correlations. CRAFT achieves state-of-the-art performance on benchmark datasets and demonstrates robustness against large artificial motions generated through an image shifting attack. The code for CRAFT is available at https://github.com/askerlee/craft.