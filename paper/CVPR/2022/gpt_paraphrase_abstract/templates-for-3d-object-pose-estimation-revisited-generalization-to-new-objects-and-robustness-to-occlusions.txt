We propose a method to recognize and estimate the 3D pose of new objects in RGB images, even when they are partially occluded. Unlike existing methods, our approach does not require training on these specific objects or real images of them. Instead, we use CAD models to learn local object representations and match the input image to a set of rendered templates. This allows our method to generalize to objects that are different from the training objects. We demonstrate the effectiveness of our approach by outperforming state-of-the-art template matching methods on various datasets. Our analysis also highlights the advantages of using local features for template matching. The code and data for our method are available at https://github.com/nv-nguyen/template-pose.