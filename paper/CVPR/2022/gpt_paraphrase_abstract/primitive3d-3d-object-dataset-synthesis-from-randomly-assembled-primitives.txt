We propose a cost-effective method for generating a large dataset of 3D objects with annotations. By assembling random primitives, we synthesize objects and automatically annotate them with part labels. This enables us to perform multi-task learning by combining supervised segmentation with unsupervised reconstruction. To address the learning overhead, we introduce a dataset distillation strategy to remove redundant samples. We conduct experiments on 3D object classification tasks and find that our dataset, along with multi-task pretraining, achieves the best performance compared to other datasets. Additionally, our strategy improves model performance, particularly for small-scale datasets. Pretraining with our dataset distillation method significantly reduces pretraining time with minimal performance degradation. Our approach offers a new perspective for training 3D deep models.