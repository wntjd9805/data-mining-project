Appearance-based gaze estimation is a technique used to predict the direction of someone's gaze based on their appearance in an image. While deep learning methods have shown impressive performance in this field, they typically assume that there is only one person's face in each image and cannot estimate gaze for multiple people simultaneously in real-time. However, being able to estimate gaze for multiple people in real-world scenarios is crucial for practical applications. In this study, we introduce GazeOnce, a novel one-stage end-to-end gaze estimation method that can predict gaze directions for multiple faces (>10) in a single image. To support the development of this method, we also create a new dataset called MPSGaze, which consists of images of multiple people with ground truth 3D gaze information. Our experimental results demonstrate that our unified framework not only achieves faster processing speed but also provides more accurate gaze estimation compared to state-of-the-art approaches. This technique has the potential to be valuable in real-time applications involving multiple users.