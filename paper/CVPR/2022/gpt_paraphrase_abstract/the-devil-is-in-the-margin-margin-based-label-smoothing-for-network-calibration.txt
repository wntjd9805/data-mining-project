Despite the strong performance of deep neural networks, recent studies have found that they often make overconfident predictions due to poor calibration. This problem is worsened by overfitting during training, as it causes the predicted probabilities to closely match the assigned labels. As a result, the correct class activation becomes significantly larger than the others. To address this issue, researchers have explored loss functions that maximize the entropy of predictions, leading to improved calibration. We present a unified perspective on these state-of-the-art calibration losses, viewing them as approximations of a linear penalty or Lagrangian term that enforces equality constraints on logit distances. However, we highlight a limitation of these equality constraints, as their gradients tend to push towards uninformative solutions, hindering the model's ability to strike the right balance between discriminative performance and calibration during optimization. Based on our findings, we propose a simple and flexible generalization using inequality constraints, which introduces a controllable margin on logit distances. Through comprehensive experiments on various tasks like image classification, semantic segmentation, and NLP, we demonstrate that our method achieves new state-of-the-art results in terms of network calibration without sacrificing discriminative performance. The code for our method is available at https://github.com/by-liu/MbLS.