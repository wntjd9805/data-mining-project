Dense self-supervised representation learning has achieved impressive results in dense prediction tasks by considering spatial correspondence. However, the pixel-level correspondence often contains noise due to misleading pixels like backgrounds. To address this issue, our paper proposes the use of set similarity (SetSim) for dense self-supervised representation learning. We extend the concept of pixel-wise similarity to set-wise similarity to enhance robustness, as sets contain more semantic and structural information. By utilizing attentional features of views, we establish corresponding sets, effectively filtering out noisy backgrounds that can lead to incorrect correspondences. Additionally, these attentional features maintain coherence within the same image across different views, reducing semantic inconsistencies. We also leverage structured neighborhood information by searching for cross-view nearest neighbors of sets, further enhancing the model's robustness. Empirical evaluations demonstrate that SetSim outperforms or performs comparably to state-of-the-art methods in object detection, keypoint detection, instance segmentation, and semantic segmentation.