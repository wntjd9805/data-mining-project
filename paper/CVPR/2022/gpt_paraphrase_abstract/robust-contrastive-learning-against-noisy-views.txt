Contrastive learning relies on the assumption that positive pairs consist of related views that share underlying information about an instance. However, when this assumption is violated and noisy views are present, the effectiveness of contrastive learning diminishes. This paper proposes a new contrastive loss function that is robust against noisy views. The authors provide theoretical justifications by establishing connections to robust symmetric losses for noisy binary classification and developing a new contrastive bound for mutual information maximization using the Wasserstein distance measure. The proposed loss function is modality-agnostic and can be easily integrated into existing contrastive frameworks as a drop-in replacement for the InfoNCE loss. Experimental results demonstrate consistent improvements over state-of-the-art approaches on various contrastive learning benchmarks involving images, videos, and graphs with different real-world noise patterns.