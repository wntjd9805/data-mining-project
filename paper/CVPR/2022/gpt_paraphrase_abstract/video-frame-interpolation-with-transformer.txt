Video frame interpolation (VFI) has made significant advancements in recent years through the use of deep convolutional networks. However, existing methods that rely on convolution operations struggle to handle large motion due to their localized nature. In order to address this challenge, we propose a new framework that incorporates Transformer, a model capable of capturing long-range pixel correlations between video frames. Additionally, our network features a novel cross-scale window-based attention mechanism, which fosters interaction between windows of different scales. This design effectively expands the receptive field and consolidates multi-scale information. Through extensive quantitative and qualitative experiments, we demonstrate that our approach achieves state-of-the-art results on various benchmark datasets.