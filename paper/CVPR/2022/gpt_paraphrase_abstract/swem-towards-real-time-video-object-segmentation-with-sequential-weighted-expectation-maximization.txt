Matching-based methods, particularly those utilizing space-time memory, are the leading solutions for semi-supervised video object segmentation (VOS). However, the continuous growth and redundancy of template features pose efficiency issues. To address this, we introduce a new Sequential Weighted Expectation-Maximization (SWEM) network that effectively reduces memory feature redundancy. Unlike previous methods that only identify redundancy between frames, SWEM merges both intra-frame and inter-frame similar features using the sequential weighted EM algorithm. Additionally, adaptive weights for frame features allow SWEM to handle challenging samples, enhancing template discrimination. Moreover, our proposed method maintains a fixed number of template features in memory, ensuring stable inference complexity for the VOS system. Extensive experiments on widely used datasets, such as DAVIS and YouTube-VOS, validate SWEM's high efficiency (36 FPS) and performance (84.3% J & F on DAVIS 2017 validation dataset).