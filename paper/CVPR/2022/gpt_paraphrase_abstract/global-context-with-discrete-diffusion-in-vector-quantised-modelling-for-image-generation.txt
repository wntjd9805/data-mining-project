The combination of Vector Quantised Variational AutoEncoder (VQ-VAE) and autoregressive models has been successful in generating high-quality images. However, the autoregressive models have limitations in capturing global information due to their strict adherence to progressive scanning order during sampling. On the other hand, Denoising Diffusion Probabilistic Models (DDPM) in the continuous domain have shown the ability to capture global context and generate high-quality images. In the discrete state space, some works have demonstrated the potential for text and low-resolution image generation. This study proposes the integration of a content-rich discrete visual codebook from VQ-VAE with the discrete diffusion model to generate high-fidelity images with global context, compensating for the limitations of classical autoregressive models. Additionally, the integration of the discrete VAE with the diffusion model addresses the issues of oversized conventional autoregressive models and excessive sampling time. The quality of the generated images is heavily dependent on the discrete visual codebook. Extensive experiments show that the proposed Vector Quantised Discrete Diffusion Model (VQ-DDM) achieves comparable performance to top-tier methods with low complexity. It also outperforms other vectors quantised with autoregressive models in image inpainting tasks without the need for additional training.