This research focuses on the use of weakly supervised pre-training in visual recognition systems. While fully supervised pre-training on datasets like ImageNet is currently the norm, recent studies have suggested that large-scale weakly supervised pre-training can yield better results. In this study, the authors revisit weakly supervised pre-training using hashtag supervision and modern versions of residual networks, utilizing the largest-ever dataset of images and corresponding hashtags. The performance of the resulting models is examined in various transfer-learning scenarios, including zero-shot transfer. The models are also compared with those obtained through large-scale self-supervised learning. The findings reveal that the weakly supervised models are highly competitive across all settings and significantly outperform their self-supervised counterparts. Additionally, the study investigates whether the models have learned troubling associations or stereotypes. Overall, the results strongly advocate for the adoption of weakly supervised learning in the development of visual recognition systems. The models developed in this research, named Supervised Weakly through hashtAGs (SWAG), are publicly available.