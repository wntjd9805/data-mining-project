Prototypical methods have become popular recently because of their ability to provide interpretable results through the use of prototypes. As the use of model reuse and distillation increases, it is important to understand how interpretability can be transferred from one model to another. In this study, we introduce a new method called Proto2Proto that transfers the interpretability of one prototypical part network to another using knowledge distillation. Our approach focuses on making the "dark" knowledge transferred from the teacher model to the shallower student model interpretable. We propose two new losses: the "Global Explanation" loss and the "Patch-Prototype Correspondence" loss, which help facilitate this transfer. The Global Explanation loss ensures that the student prototypes are close to the teacher prototypes, while the Patch-Prototype Correspondence loss ensures that the local representations of the student are similar to those of the teacher. Additionally, we propose three new metrics to evaluate the student's proximity to the teacher as a measure of interpretability transfer. We demonstrate the effectiveness of our method on the CUB-200-2011 and Stanford Cars datasets through qualitative and quantitative experiments. Our results show that our method successfully transfers interpretability from the teacher to the student while maintaining competitive performance. The code for our method is available at https://github.com/archmaester/proto2proto.