The wavelet scattering transform is known for its ability to create geometric invariants and maintain deformation stability. It has been demonstrated to be more effective at generating discriminative representations compared to other non-learned representations in various signal domains. It has also been found to outperform learned representations in certain tasks, especially when dealing with limited labeled data and highly structured signals. Typically, the wavelet filters used in the scattering transform are chosen to create a tight frame through a parameterized mother wavelet. However, in this study, we aim to determine if this standard wavelet filterbank construction is optimal. Specifically, we concentrate on Morlet wavelets and propose learning the scales, orientations, and aspect ratios of the filters to tailor the scattering transform for specific problems. Our findings indicate that the learned versions of the scattering transform result in significant improvements in small-sample classification scenarios compared to the standard scattering transform. Furthermore, our empirical results suggest that traditional filterbank constructions may not always be necessary for the scattering transform to extract effective representations.