Neural Architecture Search (NAS) is a method used to find efficient models for multiple tasks. While most NAS methods focus on finding solutions for a single task, there is a growing interest in transferring network design knowledge across multiple tasks. However, effectively modeling task correlations has been largely overlooked. To address this, we propose Arch-Graph, a transferable NAS method that predicts task-specific optimal architectures based on task embeddings. By incorporating task embeddings into the predictor's input, Arch-Graph leverages correlations across multiple tasks for fast adaptation.In our approach, we treat NAS as an architecture relation graph prediction problem. We construct a relational graph with candidate architectures as nodes and their pairwise relations as edges. To ensure basic properties such as acyclicity in the graph, we introduce additional constraints to the optimization process. This converts NAS into the problem of finding a Maximal Weighted Acyclic Subgraph (MWAS). Our algorithm aims to eliminate cycles and establish edges in the graph only if the rank results can be trusted.Using the MWAS formulation, Arch-Graph effectively ranks candidate models for each task with a small budget for predictor finetuning. We conducted extensive experiments on TransNAS-Bench-101 and demonstrated Arch-Graph's transferability and high sample efficiency across numerous tasks. It outperformed many NAS methods designed for both single-task and multi-task search. Under a budget of only 50 models, Arch-Graph was able to find top-ranking architectures on average, achieving a success rate of 0.16% and 0.29% on two search spaces.Overall, Arch-Graph presents a novel approach to NAS that incorporates task correlations and achieves efficient model search across multiple tasks.