Most previous approaches to ultra-high resolution image segmentation focus on reducing memory consumption, but neglect inference speed. This paper introduces ISDNet, a novel segmentation framework that directly infers the whole image, resulting in significantly faster inference speed without sacrificing accuracy. The framework integrates shallow and deep networks in a new way and incorporates a Relational-Aware feature Fusion module to improve performance and robustness. Experimental results on Deep-globe, Inria Aerial, and Cityscapes datasets demonstrate that ISDNet outperforms state-of-the-art methods consistently. On Deepglobe, it achieves a mean Intersection over Union (mIoU) of 73.30 with a speed of 27.70 frames per second (FPS), making it more accurate and 172 times faster than the leading competitor. The code is available at https://github.com/cedricgsh/ISDNet.