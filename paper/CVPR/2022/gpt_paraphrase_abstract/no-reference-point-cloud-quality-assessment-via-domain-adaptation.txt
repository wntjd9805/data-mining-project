We introduce a new method called image transferred point cloud quality assessment (IT-PCQA) for evaluating the quality of 3D point clouds. No-reference metric design using deep neural networks (DNN) has proven effective, but the lack of large-scale subjective databases poses a challenge for point cloud quality assessment. Our approach is motivated by the fact that the human visual system (HVS) is responsible for quality assessment regardless of the media type. By leveraging subjective scores of natural images, we can use DNN to determine evaluation criteria for human perception and transfer this capability to 3D point clouds. We treat natural images as the source domain and point clouds as the target domain, using unsupervised adversarial domain adaptation to infer point cloud quality. To extract valuable features and minimize domain differences, we propose a hierarchical feature encoder and a conditional-discriminative network. To address the regression of objective scores, we introduce a novel conditional cross entropy loss in the conditional-discriminative network to penalize negative samples that impede the convergence of the quality regression network. Experimental results demonstrate that our method outperforms traditional no-reference metrics and achieves comparable results to full-reference metrics. Additionally, our method suggests the possibility of assessing the quality of specific media content without costly and cumbersome subjective evaluations. The code for our method is available at https://github.com/Qi-Yangsjtu/IT-PCQA.