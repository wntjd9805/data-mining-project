Efficiently utilizing information from previous frames is crucial for real-time applications in online video instance segmentation (VIS). However, most existing methods employ a two-stage approach that requires additional computations and fails to fully exploit the available information. In this study, we propose a novel single-stage framework for online VIS that is built on a grid structured feature representation. By using grid-based features, we can employ fully convolutional networks for real-time processing and easily reuse and share features across different components. Additionally, we introduce co-operatively operating modules that aggregate information from available frames to enhance the features for all subtasks in VIS. Our design effectively utilizes previous information in a grid format for all tasks in VIS, resulting in state-of-the-art accuracy (38.6 AP and 36.9 AP) and speed (40.0 FPS) on the YouTube-VIS 2019 and 2021 datasets compared to other online VIS methods. The code for our framework is available at https://github.com/SuHoHan95/VISOLO.