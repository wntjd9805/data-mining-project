We introduce TubeR, a straightforward solution for detecting actions in videos. Unlike existing methods that rely on offline actor detection or manual actor-positional assumptions, we propose a direct approach to detect action tubelets by simultaneously localizing and recognizing actions from a single representation. TubeR learns a set of tubelet-queries and employs a tubelet-attention module to capture the dynamic spatio-temporal characteristics of a video clip. This enhances the model's capacity compared to using actor-positional assumptions in the spatio-temporal domain. To handle transitional states or scene changes in videos, we propose a context aware classification head that leverages short-term and long-term context to improve action classification accuracy. Additionally, we introduce an action switch regression head to accurately determine the temporal extent of an action. TubeR is capable of generating action tubelets of various lengths and performs well on long video clips. It surpasses the previous state-of-the-art approaches on popular action detection datasets such as AVA, UCF101-24, and JHMDB51-21. The code for TubeR will be made available on GluonCV (https://cv.gluon.ai/).