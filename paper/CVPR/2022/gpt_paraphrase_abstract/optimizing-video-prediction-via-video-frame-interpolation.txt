Video prediction and video frame interpolation are tasks that involve predicting future frames and estimating intermediate frames between two frames, respectively. While video frame interpolation has seen significant advancements, general video prediction in real-world scenarios remains an open question. This study proposes a new optimization framework for video prediction by leveraging video frame interpolation. The framework solves an extrapolation problem using an interpolation model. Unlike traditional approaches, this framework does not require a training dataset, eliminating any domain gap issues between training and test data. Additionally, it does not rely on additional information such as semantic or instance maps, making it applicable to any video. Extensive experiments on various datasets demonstrate the robustness of the proposed approach in general scenarios, outperforming other video prediction methods that rely on large training datasets or extra semantic information.