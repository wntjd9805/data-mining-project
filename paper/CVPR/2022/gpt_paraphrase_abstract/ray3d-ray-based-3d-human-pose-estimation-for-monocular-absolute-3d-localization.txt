This paper presents a new method called Ray3D for accurately estimating the absolute 3D pose of a human using a monocular camera. The problem of estimating 3D pose from 2D pose input is challenging due to its ill-posed nature. To overcome this challenge, the authors propose converting the input from pixel space to 3D normalized rays, which makes the approach robust to changes in camera intrinsic parameters. Additionally, the authors address variations in camera extrinsic parameters by explicitly incorporating them as inputs to the Ray3D model, which models the distribution between 3D pose rays and camera extrinsic parameters. The novel network design of Ray3D enables it to achieve outstanding generalizability. To evaluate the impact of variations in camera intrinsic and extrinsic parameters on the accuracy of absolute 3D key-point localization, the authors conduct thorough experiments on three single person 3D benchmarks and one synthetic benchmark. These experiments demonstrate that Ray3D outperforms existing state-of-the-art models. The code and synthetic dataset for the proposed method are publicly available at https://github.com/YxZhxn/Ray3D.