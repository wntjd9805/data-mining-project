Previous research has focused on correcting either underexposed or overexposed images, resulting in limited generalization to different exposure levels. One solution is to combine multiple exposures to train a single network. However, the differences in correcting underexposure and overexposure lead to discrepancies in the network's ability to handle multiple exposures, resulting in poor performance. To address this issue, we propose a framework called Exposure Normalization and Compensation (ENC) module, which bridges different exposure representations. The ENC module consists of an exposure normalization part that maps different exposure features to an exposure-invariant feature space, and a compensation part that integrates the initial unprocessed features to ensure complete information. Additionally, to address imbalanced performance during the optimization process, we introduce a parameter regularization fine-tuning strategy to improve the performance of the worst-performed exposure without degrading others. Our model, empowered by the ENC module, outperforms existing methods by over 2dB and is robust in various image enhancement tasks, demonstrating its effectiveness and generalization capability for real-world applications. The code for our model is available at https://github.com/KevinJ-Huang/ExposureNorm-Compensation.