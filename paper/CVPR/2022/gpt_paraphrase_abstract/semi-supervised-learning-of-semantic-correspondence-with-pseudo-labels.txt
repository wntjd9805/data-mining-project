Establishing dense correspondences between similar images is a difficult task due to variations within classes and background clutter. Traditionally, supervised learning methods required a large amount of manually-labeled data, while self-supervised or weakly-supervised learning methods offered limited performance. This paper proposes a simple yet effective solution called SemiMatch for semantic correspondence. The framework learns networks in a semi-supervised manner by using a small number of ground-truth correspondences along with a large number of confident correspondences as pseudo-labels. Pseudo-labels are generated using the model's own predictions between the source and weakly-augmented target, and then used to improve the model's robustness between the source and strongly-augmented target. The paper also introduces a novel confidence measure for pseudo-labels and data augmentation techniques specifically designed for semantic correspondence. Experimental results demonstrate that SemiMatch achieves state-of-the-art performance on various benchmarks.