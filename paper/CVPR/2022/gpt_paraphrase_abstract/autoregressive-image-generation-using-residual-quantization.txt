We propose a two-stage framework called Residual-QuantizedVAE (RQ-VAE) and RQ-Transformer for autoregressive modeling of high-resolution images. Previous methods using vector quantization (VQ) were unable to reduce the code sequence length while maintaining high image quality. However, our framework effectively generates high-resolution images by approximating the image feature map with RQ-VAE and predicting the next stack of codes with RQ-Transformer. This allows us to represent a 256x256 image as an 8x8 resolution feature map, reducing computational costs. Our framework outperforms existing autoregressive models in unconditional and conditional image generation benchmarks. Additionally, our approach has a significantly faster sampling speed and can generate high-quality images from unseen text conditions.