Video highlight detection is a valuable tool for simplifying video browsing and enabling a wide range of applications. However, existing methods often require manual identification and labeling of interesting moments, known as highlights. Some weakly supervised approaches have emerged that eliminate the need for highlight annotations but still rely on extensive data collection efforts. In light of this, we propose an unsupervised highlight detection framework that does not rely on any annotations at the frame or video level during training. Our framework utilizes contrastive learning to encode a video into a vector representation, allowing it to distinguish the video from others. By incorporating dropout noise in the contrastive objective, our framework is able to identify video clips that correspond to highlights. Through extensive evaluations on three benchmark datasets, we demonstrate the superior performance of our approach.