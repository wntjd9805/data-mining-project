The paper introduces EfﬁcientVIS, a fully end-to-end framework for Video Instance Segmentation (VIS) that addresses the limitations of existing methods. While clip-level VIS has shown better performance than frame-level VIS, most clip-level methods are not end-to-end learnable or real-time. VisTR, a recent method, performs VIS end-to-end within a clip but has long training times and requires hand-crafted data association between multiple clips. EfﬁcientVIS aims to overcome these issues by proposing a tracklet query and tracklet proposal approach that associates and segments regions-of-interest across space and time. It also introduces correspondence learning to make tracklets linking between clips end-to-end learnable. Compared to VisTR, EfﬁcientVIS achieves state-of-the-art accuracy on the YouTube-VIS benchmark while requiring significantly fewer training epochs. Additionally, EfﬁcientVIS enables whole video instance segmentation in a single end-to-end pass without the need for data association.