In recent years, various Bayesian deep learning methods have been proposed for semi-supervised medical image segmentation. While these methods have shown promising results on medical benchmarks, they still face some challenges. Firstly, their overall architectures are categorized as discriminative models, which means they only utilize labeled data for training in the early stages. This could potentially lead to overfitting on the labeled data. Additionally, these methods are only partially based on Bayesian deep learning, as their overall architectures are not designed within the Bayesian framework. However, by unifying the overall architecture under the Bayesian perspective, we can establish a rigorous theoretical foundation for the architecture, enabling each part of it to have a clear probabilistic interpretation.  To address these problems, we propose a new architecture called generative Bayesian deep learning (GBDL). GBDL belongs to the generative models category, aiming to estimate the joint distribution of input medical volumes and their corresponding labels. By implicitly considering the distribution of data, GBDL allows for the utilization of both labeled and unlabeled data in the early stages of training, effectively mitigating the potential overfitting issue. Furthermore, GBDL is fully designed within the Bayesian framework, and we provide its complete Bayesian formulation, which establishes a theoretical probabilistic foundation for our architecture.  Extensive experiments conducted on three public medical datasets demonstrate that our GBDL outperforms previous state-of-the-art methods in terms of four commonly used evaluation indicators.