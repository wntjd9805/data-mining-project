Federated learning (FL) is a distributed learning method that allows clients to collectively train a global model while maintaining data privacy. However, in real-world FL scenarios, client data may contain label noise, and the level of label noise can vary significantly between clients. Current methods for handling label noise in centralized learning do not work well in FL settings due to the smaller client datasets and privacy requirements. To address this issue, we propose a framework called FedCorr, which can handle heterogeneous label noise in FL without assuming any specific noise models and while preserving client data privacy. FedCorr consists of multiple stages: 1. FedCorr identifies noisy clients by analyzing the dimensionalities of model prediction subspaces measured on all clients independently. It then detects incorrect labels on these noisy clients using per-sample losses. To handle data heterogeneity and improve training stability, an adaptive local proximal regularization term based on estimated local noise levels is introduced. 2. After identifying clean clients, the global model is fine-tuned on these clients, and the noisy labels of the remaining noisy clients are corrected. 3. Finally, the usual training on all clients is applied to utilize all local data effectively. Experiments conducted on CIFAR-10/100 datasets with federated synthetic label noise and a real-world noisy dataset, Clothing1M, demonstrate the robustness of FedCorr to label noise. FedCorr outperforms state-of-the-art methods at various noise levels.