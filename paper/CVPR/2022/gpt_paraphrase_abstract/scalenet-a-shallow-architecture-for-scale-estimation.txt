This paper focuses on the problem of estimating scale factors between images. The authors propose a new architecture called ScaleNet, which utilizes dilated convolutions, self-correlation, and cross-correlation layers to predict the scale between images. They demonstrate that rectifying images using the estimated scales significantly improves performance in various tasks and methods. The authors specifically show how ScaleNet can enhance camera pose estimation, 3D reconstruction, and dense geometric matching in different benchmarks and datasets. They provide a thorough evaluation of ScaleNet's performance and analyze its computational overhead. The code, evaluation protocols, and trained models are publicly available at https://github.com/axelBarroso/ScaleNet.