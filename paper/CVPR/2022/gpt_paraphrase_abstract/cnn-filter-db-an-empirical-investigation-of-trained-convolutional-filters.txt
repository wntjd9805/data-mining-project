This abstract discusses the current unresolved questions regarding the transferability and robustness of Convolutional Neural Networks (CNNs). While research is being conducted to address these issues from various perspectives, this study focuses on investigating the shifts in the learned weights of trained CNN models, specifically the distributions of the commonly used 3x3 convolution filter kernels. The researchers have gathered a dataset consisting of over 1.4 billion filters from hundreds of trained CNNs, which they make publicly available. The dataset encompasses a wide range of datasets, architectures, and vision tasks. In one use case of this dataset, the authors analyze the distribution shifts between trained filters based on different meta-parameters such as visual category, task, architecture, and layer depth. The findings suggest that model pre-training can be successful on any dataset as long as they meet certain size and variance conditions. Additionally, the study reveals that many pre-trained models contain degenerated filters, which diminish their robustness and suitability for fine-tuning on specific applications. The dataset can be accessed on the provided project website.