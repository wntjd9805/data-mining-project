Deep learning models often suffer from catastrophic forgetting when they learn new classes incrementally. In the field of computer vision, continual learning for semantic segmentation (CSS) is a growing area of interest. However, there is a problem in CSS where models tend to confuse visually similar old and new classes, resulting in forgetting the old ones. To address this issue, we introduce REMINDER, a new CSS framework that incorporates a novel class similarity knowledge distillation (CSW-KD) method. Our CSW-KD method leverages the knowledge of a previous model on old classes that are similar to the new ones. This approach offers two main advantages: (i) selectively revising old classes that are more likely to be forgotten, and (ii) facilitating the learning of new classes by relating them to previously encountered classes. Through extensive experiments on the Pascal-VOC 2012 and ADE20k datasets, we demonstrate that our approach outperforms state-of-the-art methods in standard CSS settings, achieving performance improvements of up to 7.07% and 8.49% respectively.