Recent research has focused on incorporating non-local operations into CNNs or Transformers to improve image restoration performance. However, these approaches suffer from the lack of locality and high computational complexity. To address these issues, we propose a new attention mechanism called k-NN Image Transformer (KiT). KiT utilizes locality sensitive hashing (LSH) to group k-nearest neighbor patches, which are then aggregated into each query patch through pair-wise local attention. This approach allows for non-local connectivity while maintaining the benefits of local attention, such as inductive bias of locality and linear computational complexity. Experimental results demonstrate that our method outperforms state-of-the-art approaches in image denoising, deblurring, and deraining tasks. The code for our method will be made available soon.