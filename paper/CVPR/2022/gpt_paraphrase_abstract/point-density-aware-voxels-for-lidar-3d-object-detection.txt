LiDAR is a widely used sensor in autonomous driving for 3D object detection. However, its non-uniform sampled point cloud poses challenges for extracting volumetric features. Existing methods either rely on voxelized point clouds or use inefficient farthest point sampling to address density variation issues, but they overlook the importance of point density as a feature and its relationship with distance from the LiDAR sensor. To address this, we propose a two-stage LiDAR 3D object detection architecture called Point Density-Aware Voxel network (PDV). PDV effectively localizes voxel features by considering point density variations. It utilizes a density-aware RoI grid pooling module that incorporates kernel density estimation (KDE) and self-attention with point density positional encoding to aggregate spatially localized voxel features. Additionally, we exploit the relationship between LiDAR's point density and distance to enhance our final bounding box confidences. PDV achieves superior performance compared to existing methods on the Waymo Open Dataset and produces competitive results on the KITTI dataset.