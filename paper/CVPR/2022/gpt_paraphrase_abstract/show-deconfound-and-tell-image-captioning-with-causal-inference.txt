The transformer-based encoder-decoder framework has achieved impressive results in image captioning. However, existing methods often overlook two types of hidden factors, namely the visual and linguistic confounders, which can introduce bias, create spurious correlations during training, and hinder the model's generalization. This paper utilizes Structural Causal Models (SCMs) to demonstrate how these confounders negatively impact image captioning. To address this problem, the authors propose a novel causal inference based image captioning (CIIC) framework, employing backdoor adjustment. The CIIC framework consists of an interventional object detector (IOD) and an interventional transformer decoder (ITD), which collectively tackle both confounders. The IOD separates region-based visual features by deconfounding the visual confounder in the encoding stage. In the decoding stage, the ITD introduces causal intervention into the transformer decoder to simultaneously address the visual and linguistic confounders. These modules collaborate to mitigate the spurious correlations caused by unobserved confounders. Experimental results on MSCOCO demonstrate that the proposed method outperforms state-of-the-art encoder-decoder models on the Karpathy split and online test split. The code for this work is available at https://github.com/CUMTGG/CIIC.