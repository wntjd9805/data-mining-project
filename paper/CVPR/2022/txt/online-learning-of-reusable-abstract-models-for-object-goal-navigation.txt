Abstract Models for Object Goal Navigation
Tommaso Campari1,2
Leonardo Lamanna2,3
Paolo Traverso2
Luciano Serafini2
Lamberto Ballan1 1 University of Padova, Italy 2 Fondazione Bruno Kessler (FBK), Trento, Italy 3 University of Brescia, Italy
{tcampari,llamanna,traverso,serafini}@fbk.eu lamberto.ballan@unipd.it
Abstract
In this paper, we present a novel approach to incremen-tally learn an Abstract Model of an unknown environment, and show how an agent can reuse the learned model for tackling the Object Goal Navigation task. The Abstract
Model is a finite state machine in which each state is an ab-straction of a state of the environment, as perceived by the agent in a certain position and orientation. The perceptions are high-dimensional sensory data (e.g., RGB-D images), and the abstraction is reached by exploiting image segmen-tation and the Taskonomy model bank. The learning of the
Abstract Model is accomplished by executing actions, ob-serving the reached state, and updating the Abstract Model with the acquired information. The learned models are memorized by the agent, and they are reused whenever it recognizes to be in an environment that corresponds to the stored model. We investigate the effectiveness of the pro-posed approach for the Object Goal Navigation task, rely-ing on public benchmarks. Our results show that the reuse of learned Abstract Models can boost performance on Ob-ject Goal Navigation. 1.

Introduction
In Embodied AI, agent’s intelligence emerges from the interaction with the environment as the result of sensorimo-tor activities [39]. While acting in a real environment, an agent should acquire and effectively represent some knowl-edge of its surrounding, obtained through sensors (such as
RGB or depth cameras). However, this knowledge acquisi-tion process is a key challenge. To this end, two major direc-tions can be followed. On the one hand, knowledge can be codified in a sub-symbolic model (e.g., a neural network), which is learned, for instance, by designing supervised or reinforcement learning techniques that can be directly ap-plied to the sensory data [17, 42]. On the other hand, one can adopt a symbolic/semantic representation of the envi-ronment (e.g., by exploiting a semantically rich relational act0 s0 chair table apple oven s1 oven table chair fork act1 map s2 sink table chair
. . . act2 s3 pizza table chair
. . . l e d o m t c a r t s b
A act0 act1 act2
Figure 1. During its navigation in a complex 3D scenario, an agent incrementally acquires knowledge about the environment by stor-ing rich semantic information in an Abstract Model. For instance, when the robot is in s0, chair and table are visible; by performing act0, other objects become visible, thus the Abstract Model is up-dated to s1. Our work shows how knowledge can be incrementally learned and effectively reused over time. structure) which captures the high-level critical aspects of the environment, abstracting away useless details [24, 37].
In our work, we follow this second approach, in the at-tempt of obtaining a more abstract and general knowledge representation that can be, eventually, reused across time.
To this end, an agent, such as a robot navigating in a com-plex scenario, will represent the acquired knowledge of the environment in an Abstract Model that encodes the follow-ing key features: (i) some semantic insights about objects, scene elements, and their relations; e.g., it represents a spe-cific state such as “the agent is close to a fridge and a table is visible from that position” (see Fig. 1); (ii) the elements of the Abstract Model are “grounded” to the perceptions; for instance, the agent stores in the Abstract Model some in-formation of each encountered object, such as its position, the corresponding visual features, etc.; (iii) the Abstract
Model is dynamically updated to incorporate the additional information the agent acquires during its operations; i.e., if a new object is discovered, it should be added to the model; (iv) the models learned in the past should be reusable by the agent whenever it recognizes to be in an environment that corresponds to the stored model. This last property is es-sential because it is here that we can observe the maximum utility of the learned Abstract Model.
In this work we specifically focus on the Object Goal
Navigation task [7], in which an agent is asked to go close to an instance of a given object class. Recent approaches often tackle this problem by constructing environment’s semantic maps [10, 13] and exploiting SLAM [14, 40]. Instead, we propose to acquire and store the environment knowledge in an abstract, and semantically rich, model. Concretely, such a model is represented by a finite automata whose set of states explicitly describe (at a semantic level) what’s an agent views, given a pose. Thus, a state corresponds to an agent pose, a set of object classes (those visible from that pose), and an estimation of the position of each object. We incrementally learn (online) the Abstract Model by navigat-ing the environment, similarly to [12, 13]. The informa-tion associated to each abstract state is obtained from the low-level perceptions, acquired from RGB and RGB-D im-ages processed through segmentation models [21] and the
Taskonomy model bank [46]. The learned Abstract Model is then stored for future reuse. Therefore, once an agent rec-ognizes that the current environment is similar to one that it has visited before, the proper Abstract Model representing the information previously acquired within the visited en-vironment can be reloaded by the agent, and then updated with the new observations. To implement this feature, we design a “relocation” mechanism that allows the agent to match states of different Abstract Models. We evaluate our approach on the popular Habitat simulator [35], with 3D real environments from the MatterPort3D dataset [11]. In our experiments we focus on the Object Goal Navigation task, and we show that the Abstract Model is helpful to im-prove the success rate (e.g., avoiding some false positive detections) and the optimality of the planned path.
Summing up, the contributions of this paper are three-fold: (i) the proposed framework allows an agent to in-crementally enhance and reuse previously acquired knowl-edge, relevant to the current environment; (ii) we inte-grate sub-symbolic techniques such as image processing, path planning, global policy learning, with symbolic rea-soning on Abstract Models; (iii) our experimental analysis shows that learning and reusing Abstract Models is an effec-tive way to exploit previously acquired knowledge, obtained from noisy observations (e.g., from inaccurate semantic segmentations), for the Object Goal Navigation Task. 2.