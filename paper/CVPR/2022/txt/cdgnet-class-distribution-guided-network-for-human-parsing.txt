Abstract
The objective of human parsing is to partition a human in an image into constituent parts. This task involves label-ing each pixel of the human image according to the classes.
Since the human body comprises hierarchically structured parts, each body part of an image can have its sole posi-tion distribution characteristic. Probably, a human head is less likely to be under the feet, and arms are more likely to be near the torso. Inspired by this observation, we make instance class distributions by accumulating the original human parsing label in the horizontal and vertical direc-tions, which can be utilized as supervision signals. Using these horizontal and vertical class distribution labels, the network is guided to exploit the intrinsic position distribu-tion of each class. We combine two guided features to form a spatial guidance map, which is then superimposed onto the baseline network by multiplication and concatenation to distinguish the human parts precisely. We conducted ex-tensive experiments to demonstrate the effectiveness and su-periority of our method on three well-known benchmarks:
LIP, ATR, and CIHP databases. † 1.

Introduction
Human parsing involves segmenting human bodies into constituent parts, such as the head, body parts, and clothing items. It belongs to the field of scene parsing, where per-pixel categorization is performed for a given image. Human parsing is highly challenging owing to the complex textures and styles of clothes, deformable human poses, and scale diversity of different semantic parts. Human parsing en-ables fine-grained semantic segmentation, benefits human understanding, and supports human-centric applications.
Since the emergence of fully convolutional networks (FCNs) [26], various studies have developed several so-lutions from different perspectives to boost the perfor-mance of this dense prediction task. Several previous meth-* Equal contribution corresponding author
†Our code is available at https://github.com/tjpulkl/CDGNet.
Figure 1. Guidance of class distribution. (Top) We build the novel horizontal and vertical class distribution labels from the original label to simplify the 2D spatial human parsing problem with 1D positional labels in the horizontal and vertical direc-tions. (Bottom-left) We directly teach the backbone network with our horizontal and vertical class distribution labels as a positional guidance signal of human parts. (Bottom-right) For instance, the horizontal and vertical face positions are correctly estimated as ob-served in the visualization heatmap examples. ods [4,8,9,14,18,21,30,36–38,44] using both spatial and se-mantic contexts have achieved great successes in scene seg-mentation; however, human parsing has unique characteris-tics that make it much harder than the conventional pixel-level segmentation tasks. Specifically, the human body comprises symmetrical and structural parts. The left and right arms, and the left and right shoes, have a similar ap-pearance as well as a similar vertical position but must be separated into different classes. Naturally, in this case, we utilize the horizontal position difference between the left and right human parts. Furthermore, the scarf and glasses are too small parts to be segmented; however, most of them are on the face or the neck, not on the legs, and we can ob-tain better performance when using this structural knowl-edge successfully. Several works took advantage of human characteristics for achieving better performance in human
parsing. Ji et al. [19] designed a novel semantic neural tree to encode the physiological structure of the human body and achieved competitive results. Wang et al. [31, 32] ex-ploited deep graph networks and hierarchical human struc-tures to capture the relation information of human parts and obtained better performances. These mechanisms involve designing a complex semantic tree or message-passing net-work that leads to heavy computing complexity while im-proving performance. Moreover, building different tree structures for diverse datasets limits the deployment of these methods. Zhang et al. [43] utilized human pose and non-local mechanism to achieve good performance, but it re-quired accurate human pose information in advance. Con-sequently, most recent works have attempted to solve com-plex human parsing problems by utilizing complex modules such as graph network [32] and human pose estimator [43].
In this paper, we attempt to solve the human parsing problem following the divide and conquer strategy. We simplify the human structure information complexly rep-resented in 2D space into horizontal and vertical 1D po-sition information with the corresponding classes. To this end we propose a novel class distribution guided network (CDGNet) taught by human categorical positional knowl-edge represented in the horizontal and vertical directions.
As shown at the top of Fig. 1, we first build the horizontal and vertical class distributions as new supervision signals by accumulating the horizontal-wise and vertical-wise bina-rized map for each class from the original label. We squeeze the baseline feature in the horizontal and vertical directions and then teach them using the corresponding class distribu-tion labels, as described in the bottom of Fig. 1. For ex-ample, the face candidate region is successfully represented by the face class distributions at the right bottom of Fig. 1.
Note that we can use all the classes without selecting a few specific classes for learning the model because we have sim-plified the complex human parsing problem. Finally, in order to accomplish the precise human paring results, we merge these guided features and then superimpose them on the backbone network features.
The major contributions of our work are summarized as follows:
• We simplify the complex spatial human parsing problem into the horizontal and vertical positions of human parts individually. Accordingly, we build the class distribution labels in the horizontal and vertical directions as new su-pervision signals from the original label of human parsing.
• Using these class distribution labels, we propose the
CDGNet that guides the backbone network toward exploit-ing the intrinsic position distribution of human parts.
• We verify the significant performance improvement gained by the proposed method through extensive experi-ments on LIP, ATR, and CIHP benchmarks. 2.