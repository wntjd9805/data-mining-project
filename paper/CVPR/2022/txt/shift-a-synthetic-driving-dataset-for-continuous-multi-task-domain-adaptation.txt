Abstract
Discrete domain shifts
Adapting to a continuously evolving environment is a safety-critical challenge inevitably faced by all autonomous-driving systems. Existing image- and video-based driving datasets, however, fall short of capturing the mutable nature of the real world. In this paper, we intro-duce the largest multi-task synthetic dataset for autonomous driving, SHIFT. It presents discrete and continuous shifts in cloudiness, rain and fog intensity, time of day, and vehi-cle and pedestrian density. Featuring a comprehensive sen-sor suite and annotations for several mainstream perception tasks, SHIFT allows to investigate how a perception sys-tems’ performance degrades at increasing levels of domain shift, fostering the development of continuous adaptation strategies to mitigate this problem and assessing the robust-ness and generality of a model. Our dataset and benchmark toolkit are publicly available at www.vis.xyz/shift. 1.

Introduction
Recent years have witnessed the remarkable progress of perception systems for autonomous driving. Betting on the role that autonomous driving will serve for society, indus-try [5, 7, 18, 29, 31, 52, 76] and academia [10, 17, 45, 50, 94] have joined forces to collect and release several large-scale driving datasets, raising hopes for a forthcoming successful deployment of self-driving cars.
Providing a playground for different techniques to com-pete and thrive on multiple tasks, large-scale driving datasets have played a pivotal role in the prosperity of per-ception algorithms. However, while their accuracy surges, progress in terms of generalization to unforeseen environ-mental conditions has been underwhelming [11, 47].
*Equal contribution. urban village rural overcast rainy foggy afternoon dusk night
Continuous domain shifts daytime clear night rainy
Figure 1. SHIFT provides (a) discrete domain shifts: sequences are collected using separated domain parameters and random ini-tial states, used for robustness evaluation and domain adaptation; (b) continuous domain shifts: domain parameters change contin-uously during driving, used for continuous domain adaptation.
To achieve full autonomy, self-driving cars must adapt to new environments and identify life-threatening failure cases to promptly prevent crashes. Examples of domain shifts af-fecting driving are changes in weather and lighting condi-tions, scenery, and behavior, appearance, and quantity of agents on the road. Domain shift [2] is a well-known prob-lem for learning algorithms, causing unforeseeable perfor-mance drops under conditions different from the training ones. Techniques to prevent, counteract or assess its im-pact have been developed in the form of, respectively, do-main generalization [32, 48, 80, 88], domain adaptation [15, 42, 84, 91], uncertainty estimation [14, 36, 43, 58] and out-of-distribution (OOD) detection [26, 57, 68, 93]. However, such approaches are typically deployed and tested on toy datasets [39,69,86] or synthetically corrupted ones [24]. Al-though there are preliminary attempts at providing driving datasets with different domains [5, 11, 55, 67, 72, 73, 83, 94], each only covers a limited amount of perception tasks (e.g. only semantic segmentation [72,73]) and a narrow selection of domain shift directions (e.g. only rain [83] or snow [55]).
Consequently, current solutions to domain shift cannot un-dergo scrutiny in controlled autonomous driving scenarios, making it difﬁcult to verify their safety without risking real-world car crashes.
Given their short length, sequences from existing driving datasets are captured under approximately stationary con-ditions, and only discrete shifts are witnessed among sets of sequences presenting different homogeneous conditions from one set to another (e.g. clear weather and rainy). How-ever, as the ancient Greek philosopher Heraclitus of Eph-esus uttered, nothing in this world is constant except change and becoming. Continuous shifts - the intra-sequence shifts from one domain into another - are a certainty in the real world, where a sunny day can rapidly turn into a rainy one, or a quiet road can quickly become busy. Moreover, contin-uous distributional shift has recently been shown to repre-sent a critical challenge for current learning systems [59].
An adequate dataset design is thus needed to quantify and address domain shift both at discrete and continuous levels. Consequently, we set the goal of overcoming the outdated paradigm of previous driving datasets and intro-duce SHIFT, a new synthetic dataset capturing the con-tinuously evolving nature of the real world through realis-tic discrete and continuous shifts along safety-critical en-vironmental directions: time of day, cloudiness, rain, fog strength, and vehicle and pedestrian density. Collected by means of the CARLA Simulator [13], SHIFT includes a comprehensive sensor suite and covers the most important perception tasks. Counting 4,800+ sequences captured from a multi-view sensor suite in 8 different locations, it supports 13 perception tasks for multi-task driving systems: seman-tic/instance segmentation, monocular/stereo depth regres-sion, 2D/3D object detection, 2D/3D multiple object track-ing (MOT), optical ﬂow estimation, point cloud registration, visual odometry, trajectory forecasting and human pose es-timation.
With our dataset, we aim to foster research in several under-explored ﬁelds related to the generality and relia-bility of perception systems for autonomous driving, e.g. domain generalization, domain adaptation, and uncertainty estimation. Moreover, by collecting incremental discrete shifts from one domain to another, we hope to foster re-search in the ﬁeld of continual learning [20, 87, 90] for au-tonomous driving, so far only studied on discrete levels of synthetic corruptions [24] of traditional image classiﬁca-tion datasets [12, 35]. Finally, by collecting sequences with realistic intra-sequence continuous domain shifts, we pro-vide the ﬁrst driving dataset allowing research on continu-ous test-time learning and adaptation [56, 77, 81, 82, 90].
We summarize the main contributions of this work:
• We introduce SHIFT, a multi-task driving dataset fea-turing the most important perception tasks under a vari-ety of conditions and with a comprehensive sensor setup.
To the best of our knowledge, it is the largest synthetic dataset for autonomous driving and provides the most inclusive set of annotations and conditions.
• Using SHIFT, we analyze the importance of modeling discrete and continuous domain shifts, and demonstrate new ﬁndings on different adaptation and uncertainty es-timation methods under continuous shifts. 2.