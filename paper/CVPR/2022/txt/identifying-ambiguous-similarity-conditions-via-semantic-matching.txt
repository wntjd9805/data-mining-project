Abstract
Rich semantics inside an image result in its ambiguous relationship with others, i.e., two images could be similar in one condition but dissimilar in another. Given triplets like “aircraft” is similar to “bird” than “train”, Weakly Su-pervised Conditional Similarity Learning (WS-CSL) learns multiple embeddings to match semantic conditions without explicit condition labels such as “can fly”. However, sim-ilarity relationships in a triplet are uncertain except pro-viding a condition. For example, the previous compari-son becomes invalid once the conditional label changes to
“is vehicle”. To this end, we introduce a novel evaluation criterion by predicting the comparison’s correctness after assigning the learned embeddings to their optimal condi-tions, which measures how much WS-CSL could cover la-tent semantics as the supervised model. Furthermore, we propose the Distance Induced Semantic COndition VER-ification Network (DISCOVERNET), which characterizes the instance-instance and triplets-condition relations in a
“decompose-and-fuse” manner. To make the learned em-beddings cover all semantics, DISCOVERNET utilizes a set module or an additional regularizer over the correspon-dence between a triplet and a condition. DISCOVERNET achieves state-of-the-art performance on benchmarks like
UT-Zappos-50k and Celeb-A w.r.t. different criteria. 1.

Introduction
Learning embeddings (a.k.a. representations) from data benefits machine learning and visual recognition sys-tems [1,6,11,25,27,39,42,43,49]. Side information such as triplets [9, 10, 22, 29, 31] indicates the comparison relation-ship of objects, from which the embedding pulls visually similar objects close while pushing dissimilar ones away.
The linkage between objects conveys rich information about the object itself as well as its relationship with others, which becomes ambiguous when the similarity is measured from different perspectives. As illustrated in Fig. 1 (upper), (a) female with glasses, (b) female without glasses, and (c)
Figure 1. Upper: Two triplets with the same set of instances could be both meaningful when we measure similarity from different conditions. Lower Left: Given original (correct) triplets and their reversed variants (invalid w.r.t. the same similarity condition) on
UT-Zappos-50k, we compute the proportion a model predicts them as valid ones. Last three are WS-CSL methods. Lower right: Our proposed criterion avoids the issue of reversed triplets naturally, and our DISCOVERNET outperforms other WS-CSL methods. male with glasses are organized in triplets.1 We think (a) and (b) are more similar when we measure based on “gen-der”. In contrast, we also treat (a) and (c) as neighbors since they “wear glasses”. Since one embedding space outputs fixed relationships between instances, learning multiple em-beddings facilitates discovering rich semantics.
Given triplets associated with their condition labels, in-dicating under what kind of similarity the comparisons are made, Conditional Similarity Learning (CSL) learns mul-tiple embeddings to cover latent semantic [36, 38]. Dur-ing the evaluation, CSL predicts whether a triplet is mean-ingful or not under a specified condition. Although super-vised CSL has been successfully applied in various appli-cations [18, 19, 26, 34], labeling conditions introduces ad-ditional costs. As in a recommendation system, users may click relevant items (label item-wise similarities) based on particular preferences, and we only collect diverse compar-ison relationships without explicit condition labels. [24, 32] propose Weakly Supervised-CSL (WS-CSL), where multi-ple embeddings are learned with triplets and the model is unaware of their corresponding conditions. 1In a valid triplet (a, b, c), (a, b) is more similar than (a, c).
Current WS-CSL borrows the evaluation protocol from supervised CSL [36], which checks the validness of a triplet but neglects the specified condition. For example, we pre-dict whether “aircraft” is similar to “bird” than “train” con-ditioned on “can fly” in the supervised scenario, but ask the model to predict the correctness of the triplet free from the condition in WS-CSL. Since a triplet could be ambigu-ous, WS-CSL may focus on weighting those embeddings to explain the triplet instead of learning semantically condi-tional embeddings corresponding to the ground-truth.
We demonstrate the challenge with the following ex-periment. After removing all condition labels of correct triplets, we compute the proportion a WS-CSL model pre-dicts those triplets as valid ones via its learned embed-dings, which equals the “accuracy” used in WS-CSL evalu-ation. Then we reverse those triplets — changing the order of the second and the third items, which makes them in-valid under previous conditions. We further compute the valid ratio over reversed triplets. Results in Fig. 1 (lower left) show an optimal supervised model has 100% and 0% proportion/accuracy in two cases. A WS-CSL method
SCE-Net [32] has a higher proportion than the supervised
CSN [36] on original triplets as well as a high proportion on reversed ones, which means it treats both original and reversed triplets as valid. The diverse results between WS-CSL and its supervised counterparts indicate the “accuracy” is biased towards predicting all triplets as valid, and the cor-rectness of a triplet without a specified condition is mean-ingless. To check the coverage of all semantics, we propose to measure the comparison ability of multiple learned em-beddings after assigning them to target conditions.
We also propose Distance Induced Semantic COndi-tion VERification Network (DISCOVERNET) to balance the ability of comparison prediction and semantic coverage.
DISCOVERNET works in a “decompose-and-fuse” manner, which identifies similarity conditions and captures the am-biguous relationship with discriminative embeddings.
We aim to ensure the learned multiple embeddings in
WS-CSL are able to reveal the similarities in the target con-ditions as much as the supervised methods. In DISCOVER-NET, we achieve the goal from two aspects. First, we use a set module to map various triplets with the same set of instances to one condition, avoiding messy training update signals. On the other hand, we add a regularizer to force se-lecting different conditional embeddings when a model pre-dicts both a triplet and its reversed one as valid. DISCOV-ERNET demonstrates higher performance on benchmarks like UT-Zappos-50k in our newly proposed criterion, which is shown in Fig. 1 (lower right). The code is available at https://github.com/shiy19/DiscoverNet.
Our contributions could be summarized as:
• We point out the challenges in WS-CSL evaluation and design a novel criterion.
• Based on the proposed DISCOVERNET, we improve the quality of learned embeddings and match the ground-truth semantics from two aspects.
• DISCOVERNET can identify latent rich conditions and works better than others in our criterion. 2.