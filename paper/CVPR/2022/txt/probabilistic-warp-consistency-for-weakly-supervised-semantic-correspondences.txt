Abstract
We propose Probabilistic Warp Consistency, a weakly-supervised learning objective for semantic matching. Our approach directly supervises the dense matching scores pre-dicted by the network, encoded as a conditional probability distribution. We first construct an image triplet by apply-ing a known warp to one of the images in a pair depict-ing different instances of the same object class. Our prob-abilistic learning objectives are then derived using the con-straints arising from the resulting image triplet. We fur-ther account for occlusion and background clutter present in real image pairs by extending our probabilistic output space with a learnable unmatched state. To supervise it, we design an objective between image pairs depicting dif-ferent object classes. We validate our method by apply-ing it to four recent semantic matching architectures. Our weakly-supervised approach sets a new state-of-the-art on four challenging semantic matching benchmarks. Lastly, we demonstrate that our objective also brings substantial improvements in the strongly-supervised regime, when com-bined with keypoint annotations. 1.

Introduction
The semantic matching problem entails finding pixel-wise correspondences between images depicting instances of the same semantic category of object or scene, such as
‘cat’ or ‘bird’. It has received growing interest, due to its applications in e.g., semantic segmentation [35, 38] and im-age editing [1, 6, 9, 22]. The task nevertheless remains ex-tremely challenging due to the large intra-class appearance and shape variations, view-point changes, and background-clutter. These issues are further complicated by the inherent difficulty to obtain ground-truth annotations.
While a few current datasets [10, 11, 30] provide man-these are often ill-ually annotated keypoints matches, defined, ambiguous and scarce. Strongly-supervised ap-proaches relying on such annotations therefore struggle
Figure 1. From a real image pair (I, J) representing the same object class, we generate a new image I ′ by warping I accord-ing to a randomly sampled transformation. We further extend the image triplet with an additional image A, that depicts a different object class. For each pixel in I ′, we introduce two consistency objectives by enforcing the conditional probability distributions obtained either from the composition I ′ → J → I, or directly through I ′ → I, to be equal to the known warping distribution.
We further model occlusion and unmatched regions by introduc-ing a learnable unmatched state. It is trained by enforcing the pre-dicted distribution between the non-matching images (I ′, A) to be mapped to the unmatched state for all pixels. to generalize across datasets, as demonstrated in recent works [4, 31]. As a prominent alternative, unsupervised approaches [27, 31–33, 37, 39, 41] often train the network with synthetically generated dense ground-truth and image data. While benefiting from direct supervision, the lack of real image pairs often leads to poor generalization to real data. Weakly-supervised methods [13,16,31,33,34] thus ap-pear as an attractive paradigm, leveraging supervision from real image pairs by only exploiting image-level class labels, which are inexpensive compared to keypoint annotations.
Previous weakly-supervised alternatives introduce ob-jectives on the predicted dense correspondence volume, which encapsulates the matching confidences for all pair-wise matches between the image pair. The most common strategy is to maximize the maximum scores [13, 34] or negative entropy [31] of the correspondence volume com-puted between images of the same class, while minimizing
the same quantity for images of different classes. How-ever, these strategies only provide very limited supervi-sion due to their weak and indirect learning signal. While these approaches act directly on the predicted dense corre-spondence volume, Truong et al. [42] recently introduced
Warp Consistency, a weakly-supervised learning objective for dense flow regression. The objective is derived from flow constraints obtained when introducing a third image, constructed by randomly warping one of the images in the original pair. While it achieves impressive results, the warp consistency objective is limited to the learning of flow re-gression. As such an approach predicts a single match for each pixel without any confidence measure, it struggles to handle occlusions and background clutter, which are promi-nent in the semantic matching task.
We propose Probabilistic Warp Consistency, a weakly-supervised learning objective for semantic matching. Fol-lowing [4,13,34] and unlike [42], we employ a probabilistic mapping representation of the predicted dense correspon-dences, encoding the transitional probabilities from every pixel in one image to every pixel in the other. Starting from a real image pair (I, J), we consider the image triplet in-troduced in [42], where the synthetic image I ′ is related to I by a randomly sampled warp (Fig. 1). We derive our probabilistic consistency objective based on predicting the known probabilistic mapping relating I ′ to I with the com-position through the image J. The composition is obtained by marginalizing over all the intermediate paths that link pixels in image I ′ to pixels in I through image J.
Since the constraints employed to derive our objective are only valid in mutually visible object regions, we fur-ther tackle the problem of identifying pixels that can be matched. This is particularly challenging in the presence of background clutter and occlusions, common in semantic matching. We explicitly model occlusion and unmatched regions, by introducing a learnable unmatched state into our probabilistic mapping formulation. To train the model to detect unmatched regions, we design an additional proba-bilistic loss that is applied on pairs of images depicting dif-ferent object classes, as illustrated in Fig. 1. Further, we also employ a visibility mask, which constrains our introduced consistency loss to visible object regions.
We extensively evaluate and analyze our approach by applying it to four recent semantic matching architectures, across four benchmark datasets.
In particular, we train
SF-Net [21] and NC-Net [34] with our weakly-supervised
Probabilistic Warp Consistency objective. Our approach brings relative gains of 4.3% and 5.8% on PF-Pascal [11] and PF-Willow [10] respectively, for SF-Net, and +22.6% and +14.8% for NC-Net on SPair-71K [30] and TSS [38], respectively. This leads to a new state-of-the-art on all four datasets. Finally, we extend our approach to the strongly-supervised regime, by combining our probabilistic objec-tives with keypoint supervision. When integrated in SF-Net,
NC-Net, DHPF [31] and CATs [4], it leads to substantially better generalization properties across datasets, setting a new state-of-the-art on three benchmarks. Code is available at github.com/PruneTruong/DenseMatching 2.