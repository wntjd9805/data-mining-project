Abstract
In this paper, we study an untouched problem in visible-infrared person re-identiﬁcation (VI-ReID), namely, Twin
Noise Labels (TNL) which refers to as noisy annotation and correspondence. In brief, on the one hand, it is inevitable to annotate some persons with the wrong identity due to the complexity in data collection and annotation, e.g., the poor recognizability in the infrared modality. On the other hand, the wrongly annotated data in a single modality will even-tually contaminate the cross-modal correspondence, thus leading to noisy correspondence. To solve the TNL prob-lem, we propose a novel method for robust VI-ReID, termed
DuAlly Robust Training (DART). In brief, DART ﬁrst com-putes the clean conﬁdence of annotations by resorting to the memorization effect of deep neural networks. Then, the proposed method rectiﬁes the noisy correspondence with the estimated conﬁdence and further divides the data into four groups for further utilizations. Finally, DART employs a novel dually robust loss consisting of a soft identiﬁcation loss and an adaptive quadruplet loss to achieve robustness on the noisy annotation and noisy correspondence. Exten-sive experiments on SYSU-MM01 and RegDB datasets ver-ify the effectiveness of our method against the twin noisy labels compared with ﬁve state-of-the-art methods. The code could be accessed from https://github.com/
XLearning-SCU/2022-CVPR-DART. 1.

Introduction
Person re-identiﬁcation (ReID) aims to match a speciﬁed person from the gallery set. However, most existing per-son Re-ID methods [3, 4, 28, 32–34] only focus on search-ing RGB images captured by visible cameras, which might fail to achieve encouraging results under poor illumination environments (e.g., at night). To solve this problem, some visible-infrared person re-identiﬁcation (VI-ReID) meth-*Corresponding author i /Rj
Figure 1. The twin noisy labels in VI-ReID. In the ﬁgure, Vj i denotes sample i with the annotated identity j from the vi-sual/infrared modality, and the color indicates the latent correct identity. (a) Noisy annotations: due to the poor recognizability in the infrared modality, samples 2 of identity 1 and 2 will be mixed up thus being wrongly annotated with identity 2 and 1, respec-tively, i.e., R1 2 are noisy annotations. (b) Noisy correspon-dence: as the cross-modal pairs are constructed resorting to the an-notations, both the positive and negative pairs might be false due to noisy annotations, leading to the mismatching phenomenons.
With such noisy correspondences, the false-positive and -negative would be wrongly pulled and pushed during training, respectively. 2 and R2 ods [17, 18, 23, 26, 29] have been proposed to ﬁnd the cor-responding identities across two modalities. More specif-ically, these methods usually leverage the identity annota-tions to establish the cross-modal correspondence so that the identity-aware discrimination is enlarged and the cross-modal discrepancy is eliminated.
Although VI-ReID has achieved promising performance, its success heavily relies on high-quality annotated data.
In practice, however, it is daunting and even impossible to precisely annotate all samples due to the poor recog-nizability, especially the color information is lost in the infrared modality as shown in Fig. 1(a). As a result, it is inevitable to result in noisy annotations (NA) problem, thus degrading the performance of ReID models. Although some studies [30, 31] have devoted to mitigating the perfor-mance degradation caused by the noisy annotations, all of them only focus on the noisy annotation problem in vis-ible modality ReID, while ignoring multi-modality cases such as VI-ReID. Furthermore, once multi-modality Re-ID is considered, another special noisy label will be encoun-tered, i.e., noisy correspondence (NC). More formally, we deﬁne the noisy correspondence as the mismatched cross-modal pairs whose correspondence is established by using the noisy annotations from their respective modalities. As illustrated in Fig. 1(b), such a cross-modal pair construction approach will inevitably lead to noisy correspondence for
VI-ReID, i.e., False Positive (FP) pairs, and False Negative (FN) pairs.
Based on the above observation, in this paper, we re-veal a new problem for VI-ReID, termed Twin Noisy La-bels (TNL). Different from the traditional noisy label stud-ies [6, 6, 10, 12, 16] which only consider the NA challenge,
TNL simultaneously consider NA in category and NC in cross-modal pairs.
It should be pointed out that, it is in-tractable to adopt existing NA-oriented methods to rectify the noisy annotations in VI-ReID so that the TNL problem is solved due to the following reasons. First, the success of most existing noisy label methods is mainly limited to the case of small category numbers, whereas the category (per-son) number in ReID is in hundreds at least. Second, despite the issue of category number, it is impossible to fully rectify all noisy annotations and accordingly avoid the noisy corre-spondence problem. In other words, TNL is unavoidable in practice. Third, it is nontrivial and hard to achieve a promis-ing result by employing the existing noisy annotation meth-ods such as [10] to correct wrong annotations for VI-ReID due to the difﬁculty in sampling and joint optimization. For a comprehensive study, we present experiments to verify the above claim in the supplementary.
To solve the TNL problem in VI-ReID, we propose a novel method for learning with both noisy annotations and correspondence. The proposed DuAlly Robust Training (DART) consists of co-modeling and pair-division modules with a novel objective function. In detail, the co-modeling module ﬁrst computes the clean conﬁdence for each sam-ple resorting to the memorization effect of deep neural net-works. Then the pair-division module rectiﬁes the noisy correspondence with the conﬁdence and further divides the noisy pairs into four subsets, i.e., true positive pairs (TP), true negative pairs (TN), false positive pairs (FP), and false negative pairs (FN). Finally, to achieve robust VI-ReID, we propose a novel dually robust objective function which consists of a soft identiﬁcation loss and adaptive quadru-plet loss. In short, the soft identiﬁcation loss is employed to penalize samples of noisy annotation while learning the identity-aware representation. The adaptive quadruplet loss leverages the above four kinds of pairs to alleviate the modality discrepancy.
The contributions and novelties of this work could be summarized as follows:
• We reveal a new problem for VI-ReID, termed twin noisy labels, which could be a new paradigm for noisy labels. Different from the existing noisy label studies which only consider the NA problem, TNL refers to both the NA in the category and accompanying NC be-tween cross-modal pairs. Notably, as far as we know, there is no study on VI-ReID with noisy annotation, not to mention the more practical and challenging TNL problem.
• To achieve robust VI-ReID, we propose a novel method for learning with TNL, termed dually robust training. To the best of our knowledge, the proposed method could be the ﬁrst successful solution towards
TNL.
• Extensive experiments on SYSU-MM01 and RegDB datasets verify the effectiveness of our method against twin noisy labels compared with ﬁve state-of-the-art methods. 2.