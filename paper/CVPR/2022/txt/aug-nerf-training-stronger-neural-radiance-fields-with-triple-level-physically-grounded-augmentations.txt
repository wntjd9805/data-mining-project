Abstract
Neural Radiance Field (NeRF) regresses a neural param-eterized scene by differentially rendering multi-view images with ground-truth supervision. However, when interpolat-ing novel views, NeRF often yields inconsistent and visually non-smooth geometric results, which we consider as a gen-eralization gap between seen and unseen views. Recent ad-vances in convolutional neural networks have demonstrated the promise of advanced robust data augmentations, either random or learned, in enhancing both in-distribution and out-of-distribution generalization. Inspired by that, we pro-pose Augmented NeRF (Aug-NeRF), which for the first time brings the power of robust data augmentations into regular-izing the NeRF training. Particularly, our proposal learns to seamlessly blend worst-case perturbations into three dis-tinct levels of the NeRF pipeline with physical grounds, including (1) the input coordinates, to simulate imprecise camera parameters at image capture; (2) intermediate fea-tures, to smoothen the intrinsic feature manifold; and (3) pre-rendering output, to account for the potential degra-dation factors in the multi-view image supervision. Exten-sive results demonstrate that Aug-NeRF effectively boosts
NeRF performance in both novel view synthesis (up to 1.5dB
PSNR gain) and underlying geometry reconstruction. Fur-thermore, thanks to the implicit smooth prior injected by the triple-level augmentations, Aug-NeRF can even recover scenes from heavily corrupted images, a highly challeng-ing setting untackled before. Our codes are available in https://github.com/VITA-Group/Aug-NeRF. 1.

Introduction
Neural radiance fields (NeRF) [29] and its variants have demonstrated impressive progresses in learning to represent 3D objects and scenes from images towards photo-realistic novel view synthesis. NeRF leverages a multi-layer percep-tron (MLP) to implicitly modeling the mapping from an input 5D coordinates (i.e., 3D coordinates (x, y, z) and 2D viewing
*Equal Contribution.
Figure 1. Comparisons between Aug-NeRF (ours) and NeRF [29].
From upper to bottom, we present the test-set synthesized views, 3D geometry, and their zoom-in RGBσ distributions, respectively. directions (θ, ϕ)) to volume density σ and view-dependent emitted radiance color (r, g, b) at the corresponding position in the scene. Then, the obtained continuous 5D function (i.e.,
MLP) can be utilized to generate novel views with traditional volume rendering mechanisms.
Although NeRF is capable of producing novel views, it unfortunately suffers from inconsistent and non-smooth ge-ometries since the vanilla MLP lacks geometry-awareness.
For example, as shown in Fig. 1, the depth maps and 3D geometries of the scene generated by NeRF show obvious discontinuity and outliers, especially around the edge of ob-jects. Considering that the quality of reconstructed geometry plays a central role in view rendering, that might account for
NeRF’s limited generalization to unseen views.
To fill in this research gap, a straightforward solution is introducing explicit geometric regularizers like Lapla-cian [17, 45] or total variation (TV) [84] to enhance the continuity. However, these explicit regularizers are often
found to constrain the representation flexibility of MLP too aggressively, resulting in inferior performance. Recent ad-vances in robust data augmentations [72] establish promising successes in image recognition in terms of both improved functional smoothness and generalization.
Motivated by that, we design an Augmented NeRF (Aug-NeRF) training framework, which injects worst-case per-turbations [23] to implicitly regularize the NeRF pipeline with physical foundations. Specifically, Aug-NeRF con-siders to regularize three different levels, including (i) the input coordinates, where perturbations can imitate the in-accurate camera poses during collecting images; (ii) the intermediate features, in order for a smooth/flat model loss landscape [5, 8, 70] when fitting objects’ 3D geometries that is believed to enhance generalization; (iii) the pre-rendering output, to model potential degradation factors in the image supervision. As presented in Fig. 1, our Aug-NeRF achieves smoother and more consistency reconstructed geometry and improved unseen view synthesis. Additionally, we find Aug-NeRF to show surprising resilience towards severely cor-rupted supervision images. The main contributions of this paper can be summarized as follows:
• We reveal the existence of highly non-smooth geome-tries in representing scenes as neural radiance fields (NeRF), which we regard as a crucial bottleneck of
NeRF’s generalization ability to unseen views.
• To address such limitation of NeRF, we propose Aug-NeRF, a triple-level, physically-grounded augmented training pipeline, by leveraging worst-case perturba-tions to implicated regularize the input coordinate, in-termediate feature, and pre-rendering output levels.
• Extensive experiments validate the effectiveness of our proposal on diverse scene synthesis tasks, to endow
NeRF with smoothness-aware geometry reconstruction, enhanced generalization to synthesizing unseen views, and stronger tolerance of noisy supervisions. 2.