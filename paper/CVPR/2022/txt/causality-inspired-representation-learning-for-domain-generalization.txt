Abstract
Domain generalization (DG) is essentially an out-of-distribution problem, aiming to generalize the knowledge learned from multiple source domains to an unseen target domain. The mainstream is to leverage statistical models to model the dependence between data and labels, intending to learn representations independent of domain. Nevertheless, the statistical models are superﬁcial descriptions of reality since they are only required to model dependence instead of the intrinsic causal mechanism. When the dependence changes with the target distribution, the statistic models may fail to generalize. In this regard, we introduce a gen-eral structural causal model to formalize the DG problem.
Speciﬁcally, we assume that each input is constructed from a mix of causal factors (whose relationship with the label is invariant across domains) and non-causal factors (category-independent), and only the former cause the classiﬁcation judgments. Our goal is to extract the causal factors from inputs and then reconstruct the invariant causal mechanisms.
However, the theoretical idea is far from practical of DG since the required causal/non-causal factors are unobserved.
We highlight that ideal causal factors should meet three basic properties: separated from the non-causal ones, jointly inde-pendent, and causally sufﬁcient for the classiﬁcation. Based on that, we propose a Causality Inspired Representation
Learning (CIRL) algorithm that enforces the representations to satisfy the above properties and then uses them to simu-late the causal factors, which yields improved generalization ability. Extensive experimental results on several widely used datasets verify the effectiveness of our approach. 1 1.

Introduction
In recent years, with the increasing complexity of tasks in real world, out-of-distribution (OOD) problem has raised a severe challenge for deep neural networks based on the
∗ Corresponding author. 1 Code is available at "https://github.com/BIT-DA/CIRL". i.i.d. hypothesis [23, 24, 30]. Directly applying the model trained on source domain to an unseen target domain with different distribution typically suffers from a catastrophic performance degradation [13, 29, 31, 57]. In order to deal with the domain shift problem, Domain Generalization (DG) has attracted increasing attention, which aims to generalize the knowledge extracted from multiple source domains to an unseen target domain [2, 20, 22, 35].
In order to improve generalization capability, many DG methods have been proposed, which can be roughly cate-gorized into invariant representation learning [9, 22, 25, 34], domain augmentation [53,59,63,66], meta-learning [2,6,21], etc. Though promising results have been achieved, there ex-ists one intrinsic problem with them. These efforts merely try to make up for the problems caused by OOD data and model the statistical dependence between data and labels without explaining the underlying causal mechanisms. It has been argued recently [43] that such practices may not be sufﬁ-cient, and generalizing well outside the i.i.d. setting requires learning not mere statistical dependence between variables, but an underlying causal model [3, 39, 42, 43, 49, 54]. For instance, in an image classiﬁcation task, it is very likely that all the giraffes are on the grass, showing high statistical dependence, which could easily mislead the model to make wrong predictions when the background varies in target do-main. After all, the characteristics of giraffes such as head, neck, etc., instead of the background make a giraffe giraffe.
In this paper, we intro-duce a structural causal model (SCM) [48] to for-malize the DG problem, aiming to excavate the intrinsic causal mecha-nisms between data and labels, and achieve bet-ter generalization ability.
Speciﬁcally, we assume the category-related infor-Figure 1. SCM of DG. The solid arrow indicates that the parent node causes the child one; while the dash arrow means there ex-ists statistical dependence.
resentations jointly independent and then can be used to approximate the causal factors. Furthermore, to be causally sufﬁcient towards classiﬁcation, we design an adversarial mask module which iteratively detects dimensions that con-tain relatively less causal information and forces them to contain more and novel causal information via adversarial learning between a masker and the representation generator.
The contributions of our work are as follows:
• We point out the insufﬁciency of only modeling statis-tical dependence and introduce a causality-based view into DG to excavate the intrinsic causal mechanisms.
• We highlight three properties that the ideal causal fac-tors should possess, and propose a CIRL algorithm to learn causal representations that can mimic the causal factors, which have better generalization ability.
• Extensive experiments on several widely used datasets and analytical results demonstrate the effectiveness and superiority of our method. 2.