Abstract
Neural implicit functions have recently shown promis-ing results on surface reconstructions from multiple views.
However, current methods still suffer from excessive time complexity and poor robustness when reconstructing un-bounded or complex scenes.
In this paper, we present
RegSDF, which shows that proper point cloud supervi-sions and geometry regularizations are sufficient to pro-duce high-quality and robust reconstruction results. Specif-ically, RegSDF takes an additional oriented point cloud as input, and optimizes a signed distance field and a sur-face light field within a differentiable rendering framework.
We also introduce the two critical regularizations for this optimization. The first one is the Hessian regularization that smoothly diffuses the signed distance values to the en-tire distance field given noisy and incomplete input. And the second one is the minimal surface regularization that compactly interpolates and extrapolates the missing geome-try. Extensive experiments are conducted on DTU, Blended-MVS, and Tanks and Temples datasets. Compared with re-cent neural surface reconstruction approaches, RegSDF is able to reconstruct surfaces with fine details even for open scenes with complex topologies and unstructured camera trajectories. 1.

Introduction
Surface reconstruction from multiple calibrated views is one of the key tasks in 3D computer vision. Traditionally, the task is solved by first estimating a point cloud from im-ages by multi-view stereo (MVS) [1, 4, 22, 26], and then extracting a triangular mesh from the point cloud [8,11,14].
Recently, neural implicit surface reconstruction also shows comparable or even better results especially for texture-less and non-Lambertian surfaces. These methods apply multi-layer perceptrons (MLP) to map a space coordinate
*This work is done when Jingyang Zhang was an intern at Apple to different geometry properties, such as density [16], oc-cupancy [17] or signed distance to the nearest surface point
[25, 28, 29, 31]. The MLP can be fit into explicit geome-try representations such as contour masks [17, 29], depth maps [31] and point clouds [23], or can be further opti-mized with the scene appearance through differentiable ren-dering [16–18, 25, 28–30].
However, it is still a challenging task to conduct sur-face reconstruction in the wild. First, textureless or non-Lambertian surfaces, which exist in real-world scenes, are hard to be recovered even for learning-based methods. Sec-ond, camera trajectories of real-world data may be unstruc-tured instead of object-centric. In traditional mesh recon-struction pipelines, although multi-view stereo [22, 26] has been proven to be effective for a variety of different scenes, the reconstructed point cloud inevitably suffers from miss-ing or noisy geometries, which are difficult to be corrected in later mesh extraction steps. On the other hands, recent neural surface methods [16, 18, 25, 28] is able to generate surfaces directly from multi-view images. However, the op-eration of volumetric rendering [16,18,25,28] with implicit functions is time-consuming, and those methods are origi-nally designed for reconstructions of object-centric captures rather than open scenes with unstructured camera trajecto-ries.
In this paper, we propose RegSDF, a neural framework for surface reconstruction from multi-view images for a broad variety of scenes. Implementation-wise, we choose a signed distance field (SDF) as the geometry representation and a surface light field as the appearance model to gener-ate rendered images for network training. To take advan-tages of well-established MVS pipelines, we additionally apply an oriented point cloud from MVS as input to our re-construction, where the SDF will be fit into observed data points and also normal directions. Two critical regulariza-tions, namely the Hessian regularization of second deriva-tives and the minimal surface constraint, are proposed for robust neural surface reconstruction. The Hessian regular-ization is designed to let the signed distance value smoothly
diffuse to the entire signed distance field, which is important for reconstructing complete surface from incomplete and noisy point clouds. Meanwhile, the minimal surface reg-ularization is introduced to compactly interpolate holes and extrapolate missing parts in the implicit surface. We show in experiments that the proposed two regularizations, along with the point cloud supervision, are sufficient to produce high-quality and robust reconstruction results from multi-view images.
The proposed method has been evaluated on DTU [6],
BlendedMVS [27], and Tanks and Temples [10] datasets.
We show by both qualitative and quantitative results that our method outperforms other neural implicit surface re-construction systems by higher surface accuracy, stronger generalization ability to complex scenes, and shorter train-ing time. Also, compared with traditional meshing meth-ods, the proposed framework is robust against point cloud noise and can produce realistic rendered images. 2.