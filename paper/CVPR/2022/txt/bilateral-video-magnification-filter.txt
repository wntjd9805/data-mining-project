Abstract 1.

Introduction
Eulerian video magnification (EVM) has progressed to magnify subtle motions with a target frequency even under the presence of large motions of objects. However, exist-ing EVM methods often fail to produce desirable results in real videos due to (1) mis-extracting subtle motions with a non-target frequency and (2) collapsing results when large de/acceleration motions occur (e.g., objects suddenly start, stop, or change direction). To enhance EVM performance on real videos, this paper proposes a bilateral video magni-fication filter (BVMF) that offers simple yet robust temporal filtering. BVMF has two kernels; (I) one kernel performs temporal bandpass filtering via a Laplacian of Gaussian whose passband peaks at the target frequency with unity gain and (II) the other kernel excludes large motions out-side the magnitude of interest by Gaussian filtering on the intensity of the input signal via the Fourier shift theorem.
Thus, BVMF extracts only subtle motions with the target frequency while excluding large motions outside the magni-tude of interest, regardless of motion dynamics. In addition,
BVMF runs the two kernels in the temporal and intensity domains simultaneously like the bilateral filter does in the spatial and intensity domains. This simplifies implementa-tion and, as a secondary effect, keeps the memory usage low. Experiments conducted on synthetic and real videos show that BVMF outperforms state-of-the-art methods.
We humans often fail to visually perceive subtle motions in our world: subtle head motions with blood circulation, slight deformation of materials absorbing external forces, or subtle autonomous fluctuations of a flying drone. Such variations are quite useful for helping us deeply understand scene context [1, 3, 4, 25, 28] or anomalous behavior [2, 10], but they are difficult to see with the naked eye.
To magnify such subtle yet important motions in a video,
Eulerian video magnification (EVM) methods have been widely researched [6, 10, 13, 17, 21, 22, 25, 26, 28, 30]. EVM methods generally measure local motions in a video as a phase signal within each spatial subband along each ori-entation at each pixel position [7, 25]. They then perform temporal filtering on the oriented-subband phase signal to extract only subtle motions with a target frequency (e.g., respiratory cycle). However, since subtle motions are easily overwhelmed by large motions of objects, the standard tem-poral filtering in the early EVM methods [25, 26, 28] often fail to extract subtle motions when objects move largely.
To overcome this issue, temporal filtering in EVM has been continually improved [22, 30]. Specifically, Zhang et al. designed the Laplacian of Gaussian filter (LoGF) to per-form temporal bandpass filtering while excluding slow large motions, which approximate linearly at short time scales, via its Laplacian property [30]. Furthermore, to exclude
Table 1. Comparisons of temporal filtering results of an EVM with the existing temporal filters [22, 30] and BVMF
Method
Frequency response
Large motions exclusion
Memory usage slow ← de/acceleration → quick
LoGF [30]
LoGF w/ JAF [22]
BVMF (ours) shifted shifted non-shifted
✓
✓
✓
✗
✗
✓
✗
✓
✓ low high low quick large motions, a combination of LoGF with the jerk-aware filter (JAF) was proposed [22]; JAF excludes only them effectively by assessing jerk-based motion steepness, which represents quick large motions. Thus, this combina-tion extracts subtle motions with a target frequency while excluding slow and quick large motions.
However, LoGF with JAF [22] often fails to produce de-sirable results in real videos due to the following problems: (1) The passband of LoGF is shifted against the target fre-quency (see Fig. 2). Thus, LoGF mis-extracts subtle mo-tions with a non-target frequency, or it extracts ones with the target frequency but their magnitude is lower than the original (i.e., the passband gain of LoGF is not unity at the target frequency). (2) LoGF or JAF is specifically designed for excluding only slow or quick large motions, but besides those, there often exist large deceleration or acceleration motions that need to reach the slow or quick large motions in real videos (e.g., objects suddenly start, stop, or change direction). Thus, LoGF with JAF mis-extracts such large de/acceleration motions and collapses results (see Fig. 1).
Due to the above problems, EVM in real videos remains a challenging task.
In this paper, we propose a bilateral video magnifica-tion filter (BVMF), it is simple yet robust temporal filter-ing that enhances EVM performance on real videos. Ta-ble 1 summarizes comparisons of the existing temporal fil-ters [22, 30] and BVMF. Inspired by the bilateral filter in which two kernels achieve the simple yet robust spatial smoothing process [18, 23], we designed BVMF with two kernels: (I) one kernel performs temporal bandpass filter-ing via a LoG whose passband peaks at the target frequency with unity gain thanks to new formulations and (II) the other kernel excludes large motions outside the magnitude of in-terest by Gaussian filtering on the intensity of the phase sig-nal via the Fourier shift theorem (this theorem enables us to measure the magnitude of motions precisely as the inten-sity of the phase signal). Thus, BVMF extracts only subtle motions with the target frequency while excluding various large motions outside the magnitude of interest regardless of motion dynamics, namely slow, quick, or de/acceleration.
In addition, BVMF runs the two kernels in the temporal and intensity domains of the input phase signal simultaneously like the bilateral filter does in the spatial and intensity do-mains of an image [18, 23]. This simplifies implementation compared to LoGF with JAF that requires multiple input
Figure 2. Bandpass frequency response of LoGF [30] (Paper,
GitHub)1 and our BVMF. In this comparison, the target frequency ft = 10 Hz with a sampling rate fs = 120 Hz. The standard devi-ation σft of LoGF (Paper) is set such that its filter width matches the wavelength of ft with fs, referring to the scale selection in blob detection [11, 16]. This is not specifically designed for tem-poral filtering and thus shifts the passband of LoGF against ft (see the blue plot). In contrast, BVMF has its passband peak at ft with unity gain, namely 1.0, thanks to new formulations of Eqs. (5) and (7) (see the yellow plot). phase signals across spatial subbands to exclude large mo-tions effectively [22]. As a secondary effect, this simple and bilateral implementation keeps the memory usage as low as using just LoGF [30] alone.
The contributions of this paper are as follows. (i) We link the LoG parameters to the passband characteristics by new formulations that strictly set the peak gain of the passband to unity at the target frequency. (ii) We exclude large mo-tions outside the magnitude of interest by Gaussian filtering on the intensity of the phase signal via the Fourier shift theo-rem. This is simpler than existing approaches [22,30] while being more robust because it makes no assumptions as to motion dynamics (namely, slow, quick, or de/acceleration). (iii) We, for the first time, introduce the bilateral princi-ple into temporal filtering in EVM, which leads to simpler implementation and, as a secondary effect, lower memory (iv) We conduct exten-usage than LoGF with JAF [22]. sive experiments and show that our method outperforms the baseline methods, including color magnification results. 1The implementation of LoGF differs between the original paper and the official GitHub [30]. The standard deviation σft of LoGF is set as
σft = fs/(4 2ft) (Paper) and σft = fs/8ft (GitHub). The filter normalization coefficient, Z, is set so that the sum of the absolute value of
LoGF coefficients is 1.0, referring to the official GitHub version [30].
√
2.