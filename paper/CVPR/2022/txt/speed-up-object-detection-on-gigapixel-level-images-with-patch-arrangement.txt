Abstract
With the appearance of super high-resolution (e.g., gigapixel-level) images, performing efficient object detec-tion on such images becomes an important issue. Most ex-isting works for efficient object detection on high-resolution images focus on generating local patches where objects may exist, and then every patch is detected independently. How-ever, when the image resolution reaches gigapixel-level, they will suffer from a huge time cost for detecting numerous patches. Different from them, we devise a novel patch ar-rangement framework for fast object detection on gigapixel-level images. Under this framework, a Patch Arrangement
Network (PAN) is proposed to accelerate the detection by determining which patches could be packed together into a compact canvas. Specifically, PAN consists of (1) a Patch
Filter Module (PFM) (2) a Patch Packing Module (PPM).
PFM filters patch candidates by learning to select patches between two granularities. Subsequently, from the remain-ing patches, PPM determines how to pack these patches to-gether into a smaller number of canvases. Meanwhile, it generates an ideal layout of patches on canvas. These can-vases are fed to the detector to get final results. Experiments show that our method could improve the inference speed on gigapixel-level images by 5× while maintaining great per-formance. 1.

Introduction
With the widespread use of super high-resolution cam-eras, image resolution has increased rapidly and recently reached the gigapixel level (e.g., 25,000 × 14,000 pix-els) [20]. Therefore, it’s a great challenge to analyze such images efficiently. Recently, some object detection meth-ods [8, 23] have been proposed for efficient high-resolution object detection. As shown in Figure 1a, in order to speed-up object detection, they focused on generating local re-gions (termed as ‘patch’) that may contain object candi-dates from high-resolution images. Then detection is only
*Corresponding authors. (a) (b) (a) Previous:
Figure 1. Comparison between pipelines. it first generates patches where object candidates exist, then detection is conducted on all patches separately. (b) Ours: based on a multi-grained patch tree, certain patches are selected and packed together into compact canvases with a smaller number. Detection is only conducted on canvases. performed on these resized patches instead of the whole im-age to achieve the speed-up. Therefore, their time cost is dependent on the number of patches. However, when be-ing applied to super high-resolution images (e.g., gigapixel-level images), these methods may require numerous patches to ensure performance. Thus, they may still suffer huge time costs on gigapixel-level images.
In gigapixel-level images, we observed that it is neither necessary nor ideal to perform detection separately on each generated patch. As shown in Figure 1b, some patches can be packed together to form a new and compact one (called
‘canvas’).
In this way, processing a smaller number of canvases rather than numerous patches could significantly speed up the detection.
Based on the above intuition, we propose a novel frame-work for object detection on gigapixel-level images. Un-der this detection framework, a Patch Arrangement Net-work (PAN) arranges patches into compact canvases in a local-to-global view, into compact canvases for final de-tection. Thereby it significantly speeds up object detec-tion in gigapixel-level images while maintaining ideal per-formance. First, we build up a multi-grained patch tree for the input gigapixel-level image, which consists of fine-grained patches (leaf layer nodes) and their corresponding coarser-grained patches (middle layer nodes). To embed information of patches and explore the relationship among them, an LSTM-based tree structure encoder is applied. The subsequent arrangement is performed based on the multi-grained patch candidates in this tree. Second, we propose a
Patch Filter Module (PFM), which learns an adaptive patch selection between two granularities, i.e, it arranges some neighboring fine-grained patches into their corresponding coarser one. In this way, detection can be accelerated by re-placing some patch candidates with fewer coarser patches.
Third, we further develop a Patch Packing Module (PPM).
It determines how to pack all remaining patches together to form a smaller number of canvases, and generates a com-pact layout of packed patches in the canvas. PFM performs arrangement over neighboring patches (local view) while
PPM takes all the patches into consideration for arrange-ment (global view). Finally, the whole framework is trained jointly with policy-based reinforcement learning.
Note that our theoretical speed-up ratio is controllable by setting the maximum amount of patches that can be packed in each canvas. We evaluate our approach on the gigapixel-level PANDA [20] dataset and a wide range of detectors.
PAN maintains ideal detection performance while improv-ing the inference speed by 5×. The main contributions of our work are three-fold:
• We devise a novel framework for efficient object detec-tion on gigapixel-level images, which adaptively packs patches into a compact canvas and generates an ideal layout for selected patches in this canvas.
• Under this framework, we propose a novel multi-grained patch tree to explore the relationship among patches. Based on this tree, a patch filter module and patch packing module are proposed to arrange patch candidates in a local and global view, respectively.
• Extensive experiments show that PAN can speed up the inference speed of detection on gigapixel images by 5× while maintaining high detection performance. the first gigapixel-level (25,000×14,000) human-centric video&image dataset.
It further expands the frontiers of high-resolution image analysis [10, 11] and remains a great challenge for speeding up object detection on such large im-ages.
A major line of accelerating object detection focuses on devising efficient network architecture (e.g., Faster R-CNN [15], YOLO [14], and SSD [12]). However, most of them are developed on general images like MSCOCO. Di-rectly applying them to HR images may still cause a huge time cost. Meanwhile, specific approaches have not been well-studied for HR images before.
For this reason, recently, some works have been pro-posed to speed up object detection on relatively HR images.
[4] proposes an image-level solution, which adaptively se-lects a resolution for each input image. It’s acknowledged that we can only conduct necessary computations on some partial regions instead of the whole HR image. Based on this intuition, most existing works focus on finding local spatial patches where objects may exist.
[16] regards the detected boxes obtained on a low resolution as patches and performs final detection on these patches at a refined reso-lution. Similarly, CRENet [21] clusters the coarse detection results to form the patches. ClusDet [23] follows the idea of RPN [15] and employs a neural network to estimate ac-curate patches. AutoFocus [13] and GLSAN [5] generate patches based on the image features. DMNet [8] obtains patches with the guidance of density maps. Besides, rein-forcement learning (RL) has also been adopted to find the valuable patches [6, 18]. Nevertheless, the above methods usually require more patches to ensure the performance as the image resolution increases. When the image resolution reaches gigapixel-level, the number of patches will be nu-merous (may exceed 12,000). Therefore, their correspond-ing time costs are still unbearable in real-world applications. 3. Proposed Method
Figure 2a illustrates an overview of our framework. In the following sections, we first describe the construction of our multi-grained patch tree. Based on this tree, we elab-orate the main modules involved in our approach: Patch
Filter Module (PFM) and Patch Packing Module (PPM). Fi-nally, we describe how to optimize our framework. 2.