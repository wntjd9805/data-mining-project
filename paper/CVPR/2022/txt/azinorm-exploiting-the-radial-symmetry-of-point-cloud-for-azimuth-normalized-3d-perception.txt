Abstract
Studying the inherent symmetry of data is of great im-portance in machine learning. Point cloud, the most impor-tant data format for 3D environmental perception, is natu-rally endowed with strong radial symmetry. In this work, we exploit this radial symmetry via a divide-and-conquer strategy to boost 3D perception performance and ease op-timization. We propose Azimuth Normalization (AziNorm), which normalizes the point clouds along the radial direc-tion and eliminates the variability brought by the differ-ence of azimuth. AziNorm can be ﬂexibly incorporated into most LiDAR-based perception methods. To validate its effectiveness and generalization ability, we apply Azi-Norm in both object detection and semantic segmentation.
For detection, we integrate AziNorm into two representa-tive detection methods, the one-stage SECOND detector and the state-of-the-art two-stage PV-RCNN detector. Ex-periments on Waymo Open Dataset demonstrate that Azi-Norm improves SECOND and PV-RCNN by 7.03 mAPH and 3.01 mAPH respectively. For segmentation, we in-tegrate AziNorm into KPConv. On SemanticKitti dataset,
AziNorm improves KPConv by 1.6/1.1 mIoU on val/test set. Besides, AziNorm remarkably improves data efﬁciency and accelerates convergence, reducing the requirement of data amounts or training epochs by an order of magni-tude. SECOND w/ AziNorm can signiﬁcantly outperform fully trained vanilla SECOND, even trained with only 10% data or 10% epochs. Code and models are available at https://github.com/hustvl/AziNorm. 1.

Introduction
Environmental perception based on 3D LiDAR point clouds is a fundamental and indispensable ability for au-topilot system aiming at high robustness and security. Ac-curate perception results are the basis of credible motion
†Xinggang Wang is the corresponding author.
Figure 1. AziNorm remarkably improves data efﬁciency (a) and accelerates convergence (b). With data amounts and training epochs reduced, the performance of SECOND drops dramatically, but SECOND w/ AziNorm still achieves comparable performance.
Even trained with only 10% data or 10% epochs, SECOND w/
AziNorm obviously outperforms fully trained vanilla SECOND. planning and control, avoiding trafﬁc accidents. And the passed several years have witnessed tremendous perfor-mance improvements of LiDAR-based perception. Previ-ous works [24, 25, 29, 30, 42, 44–47, 51] mostly focus on de-signing network architectures to effectively and efﬁciently extract semantic information from the point cloud data.
Different from the exhaustively studied network archi-tecture design, the inherent property of LiDAR point cloud has not been explored and exploited yet. LiDAR emits
laser rays that travel outwards in all azimuths isotropically.
Laser rays bounce off surrounding objects, capturing object surface characteristics, and then return to the LiDAR. Both incident rays and reﬂected rays are along the radial direc-tion. And the generated point clouds are radially symmetri-cal in a broad sense (Fig. 2).
From the perspective of machine learning, the inherent symmetry of data can serve as a powerful inductive bias for reducing the variability of data and simplifying the recog-In this paper, we propose Azimuth Nor-nition system. malization (AziNorm) to exploit the radial symmetry of point cloud. We split the whole LiDAR scene into individ-ual patches and then normalize the patch’s sub point clouds along the radial direction. By normalization, we eliminate the data variability brought by the difference of azimuth and makes perception on normalized point clouds much easier.
AziNorm can be ﬂexibly incorporated into most LiDAR-based perception methods without modifying any imple-mentation detail and signiﬁcantly boost the performance.
To validate its effectiveness and generalization ability, we apply AziNorm in both object detection and semantic seg-For detection, we integrate AziNorm into mentation. two representative detection methods, the one-stage SEC-OND [42] detector and the state-of-the-art two-stage PV-RCNN [28] detector. Experiments on large-scale Waymo
Open Dataset [33] demonstrate that AziNorm improves
SECOND and PV-RCNN by 7.03 mAPH and 3.01 mAPH respectively. For segmentation, we integrate AziNorm into
KPConv [36]. On SemanticKitti [1] dataset, AziNorm im-proves KPConv by 1.6/1.1 mIoU on val/test set.
More importantly, AziNorm remarkably improves data efﬁciency and accelerates convergence. Even trained with only 10% data or 10% epochs, SECOND w/ AziNorm sig-niﬁcantly outperforms fully trained vanilla SECOND. Azi-Norm can reduce the requirement of training epochs or data amounts by an order of magnitude, lowering the cost of data acquisition and labeling, which is of great practical value, especially for the data-driven autopilot system.
The main contributions of this paper can be summarized as follows:
• We propose a novel normalization method termed as
AziNorm, which exploits the inherent radial symmetry of point clouds to reduce the data variability.
• AziNorm can be easily integrated into most LiDAR-based perception methods and signiﬁcantly boost the performance. We validate the effectiveness and gener-alization ability of AziNorm in two perception tasks (object detection and semantic segmentation), based on three methods (SECOND [42], PV-RCNN [28] and
In 3D perception, azimuth is the horizontal direction expressed as the angular distance between the direction of observer’s heading and the direc-tion of the observed location.
KPConv [36]), and on two datasets (Waymo Open
Dataset [33] and SemanticKitti [1]).
• AziNorm can reduce the requirement of data amounts or training epochs by an order of magnitude, lower-ing the cost of data acquisition and labeling, which is of great practical value, especially for the data-driven autopilot system. 2.