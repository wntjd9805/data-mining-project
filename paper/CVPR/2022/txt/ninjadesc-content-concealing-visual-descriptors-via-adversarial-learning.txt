Abstract
In the light of recent analyses on privacy-concerning scene revelation from visual descriptors, we develop de-scriptors that conceal the input image content. In partic-ular, we propose an adversarial learning framework for training visual descriptors that prevent image reconstruc-tion, while maintaining the matching accuracy. We let a fea-ture encoding network and image reconstruction network compete with each other, such that the feature encoder tries to impede the image reconstruction with its generated de-scriptors, while the reconstructor tries to recover the in-put image from the descriptors. The experimental results demonstrate that the visual descriptors obtained with our method signiﬁcantly deteriorate the image reconstruction quality with minimal impact on correspondence matching and camera localization performance. 1.

Introduction
Local visual descriptors [7, 13, 56, 72, 74] are fundamen-tal to a wide range of computer vision applications such as SLAM [15, 40, 42, 45], SfM [1, 64, 71], wide-baseline stereo [30, 43], calibration [49], tracking [24, 44, 51], image retrieval [3, 4, 32, 46, 47, 66, 77, 78], and camera pose esti-mation [5,17,54,61,62,75,76]. These descriptors represent local regions of images and are used to establish local cor-respondences between and across images and 3D models.
The descriptors take the form of vectors in high-dimensional space, and thus are not directly interpretable by humans. However, researchers have shown that it is pos-sible to reveal the input images from local visual descrip-tors [10, 16, 80]. With the recent advances in deep learning, the quality of the reconstructed image content has been sig-niﬁcantly improved [11, 53]. This poses potential privacy concerns for visual descriptors if they are used for sensitive data without proper encryption [11, 69, 80].
To prevent the reconstruction of the image content from visual descriptors, several methods have been proposed.
These methods include obfuscating keypoint locations by
Figure 1. Our proposed content-concealing visual descriptor. a)
We train NinjaNet, the content-concealing network via adversar-ial learning to give NinjaDesc. b) On the two examples shown, we compare inversions on SOSNet [74] descriptors vs. NinjaDesc (encoding SOSNet with NinjaNet). c) NinjaDesc is able to conceal facial features and landmark structures, while retaining correspon-dences. Image credits: laylamoran4battersea & sgerner (Flickr)1. lifting them to lines that pass through the original points [21, 65, 69, 70], or to afﬁne subspaces with augmented adversar-ial feature samples [18] to increase the difﬁculty of recov-ering the original images. However, recent work [9] has demonstrated that the closest points between lines can yield a good approximation to the original points’ locations.
In this work, we explore whether such local feature in-version could be mitigated at the descriptor level. Ideally, we want a descriptor that does not reveal the image con-tent without a compromise in its performance. This may seem counter-intuitive due to the trade-off between utility and privacy discussed in the recent analysis on visual de-scriptors [11], where the utility is deﬁned as matching ac-curacy, and the privacy is deﬁned as non-invertibility of the descriptors. The analysis showed that the more useful the descriptors are for correspondence matching, the easier it is to invert them. To minimize this trade-off, we propose an
†Corresponding author. 1CC BY 2.0 & CC BY-SA 2.0 licenses.
adversarial approach to train visual descriptors.
Speciﬁcally, we optimize our descriptor encoding net-work with an adversarial loss for descriptor invertibility, in addition to the traditional metric learning loss for fea-ture correspondence matching. For the adversarial loss, we jointly train an image reconstruction network to compete with the descriptor network in revealing the original image content from the descriptors. In this way, the descriptor net-work learns to hinder the reconstruction network by gen-erating visual descriptors that conceal the image content, while being optimized for correspondence matching.
In particular, we introduce an auxiliary encoder net-work NinjaNet that can be trained with any existing visual descriptors and transform them to our content-concealing
NinjaDesc, as illustrated in Fig. 1.
In the experiments, we show that visual descriptors trained with our adversarial learning framework lead to only marginal drop in perfor-mance for feature matching and visual localization tasks, while signiﬁcantly reducing the visual similarity of the re-construction to the original input image.
One of the main beneﬁts of our method is that we can control the trade-off between utility and privacy by chang-ing a single parameter in the loss function. In addition, our method generalizes to different types of visual descriptors, and different image reconstruction network architectures.
In summary, our main innovations are as follows: a) We propose a novel adversarial learning framework for visual descriptors to prevent reconstructing original input image content from the descriptors. We experimentally validate that the obtained descriptors signiﬁcantly deteriorate the image quality from descriptor inversion with only marginal drop in matching accuracy using standard benchmarks for matching (HPatches [6]) and visual localization (Aachen
Day-Night [63,84]). b) We empirically demonstrate that we can effectively control the trade-off between utility (match-ing accuracy) and privacy (non-invertibility) by changing a single training parameter. c) We provide ablation stud-ies by using different types of visual descriptors, image re-construction network architectures and scene categories to demonstrate the generalizability of our method. 2.