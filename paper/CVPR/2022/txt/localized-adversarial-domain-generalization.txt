Abstract
Deep learning methods can struggle to handle domain shifts not seen in training data, which can cause them to not generalize well to unseen domains. This has led to research attention on domain generalization (DG), which aims to the model’s generalization ability to out-of-distribution. Ad-versarial domain generalization is a popular approach to
DG, but conventional approaches (1) struggle to sufficiently align features so that local neighborhoods are mixed across domains; and (2) can suffer from feature space over col-lapse which can threaten generalization performance. To address these limitations, we propose localized adversar-ial domain generalization with space compactness mainte-nance (LADG) which constitutes two major contributions.
First, we propose an adversarial localized classifier as the domain discriminator, along with a principled primary branch. This constructs a min-max game whereby the aim of the featurizer is to produce locally mixed domains. Sec-ond, we propose to use a coding-rate loss to alleviate fea-ture space over collapse. We conduct comprehensive ex-periments on the Wilds DG benchmark to validate our ap-proach, where LADG outperforms leading competitors on most datasets. 1.

Introduction
Deep neural networks can suffer from poor generaliza-tion performance on out-of-distribution (OOD) data from unseen domains, i.e., from domain shift. For this reason, techniques to improve generalization abilities have gained increasing attention over the past decade, e.g. domain gen-eralization (DG) and domain adaptation (DA). DA requires access to data from testing domains during training. In con-trast, DG aims to construct a generalized model by exposing the training process to multiple training domains without exposure to OOD data from testing domains. As such, DG can reflect challenges in many real-life applications.
*Work was done while Wei Zhu interned at PAII Inc.
Figure 1. Localized discriminator can align two domains in a more fine-grained way.
Different DG methods have been proposed, including empirical risk minimization (ERM)-based methods [40, 52, 59], meta-learning based methods [28], domain-invariant representation based methods [16, 29, 33, 44], invariant risk minimization based methods [3, 54], and gradient agree-ment methods [39, 42]. Among them, domain invariant rep-resentation based methods, specifically adversarial domain generalization (ADG) methods, seem to the most popular according to recent literature [19, 43]. ADG methods are inspired by generative adversarial networks [18] and learn a common feature space by adversarial learning for train-ing domains [16]—the common feature space is expected to help generalization to unseen domains [16]. Although in-tuitively reasonable and technically sound, most of these methods show little performance gain over the baseline
ERM in practice as indicated by recent benchmarks [19,25].
In this work, we argue that two issues limit the per-formance impact of current ADG methods. First, we find that ERM feature representations are surprisingly already roughly aligned, with features clustered class-wisely re-gardless of their domain labels. The discrepancy between domains can be observed at local regions where local neigh-borhoods are not mixed across domains. Since ADG meth-ods operate under the assumption of significant domain shift, this less obvious domain-level discrepancy challenges
conventional ADG methods. Second, we measure the com-pactness of the feature space using three different metrics and found that the featurizer may trivially fool the discrim-inator by over collapsing the feature space. The collapsed feature space can cause overfitting [50].
To address these limitations, we propose localized adver-sarial domain generalization with space compactness main-tenance (LADG). As shown in Fig. 1, LADG incorporates a localized domain classifier [6] with adversarial learning.
Since the predictions of local classifiers are made according to samples around a target sample, a local domain classifier can thus be used to describe the quality of alignment of lo-cal regions. We adopt label propagation in this paper as it is effective and differentiable [32, 53]. We also outline how to integrate localized classification properly within a genera-tor loss that encourages neighbor hood mixing. To alleviate feature space over collapse, LADG measures and maintains the compactness of the feature space using a differentiable coding ratio [50].
We summarize our contributions as follows: 1. We argue that ERM can already roughly align training domains with a linear primary task predictor, which undermines the assumption of most existing ADG methods. We also observe that applying ADG to the feature space can lead to feature space over collapse. 2. We propose localized adversarial domain generaliza-tion (LADG) to alleviate these two limitations. LADG adopts a principled label propagation as the domain discriminator to allow a fine-grained domain align-ment and penalizes the space collapse caused by ad-versarial learning. 3. We conduct extensive experiments on benchmark datasets to verify our observations and show the effec-tiveness of the proposed method. 2.