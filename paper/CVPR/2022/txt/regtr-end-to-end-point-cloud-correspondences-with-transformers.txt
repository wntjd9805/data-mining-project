Abstract
Despite recent success in incorporating learning into point cloud registration, many works focus on learning fea-ture descriptors and continue to rely on nearest-neighbor feature matching and outlier filtering through RANSAC to obtain the final set of correspondences for pose estima-tion.
In this work, we conjecture that attention mecha-nisms can replace the role of explicit feature matching and
RANSAC, and thus propose an end-to-end framework to directly predict the final set of correspondences. We use a network architecture consisting primarily of transformer layers containing self and cross attentions, and train it to predict the probability each point lies in the overlapping region and its corresponding position in the other point cloud. The required rigid transformation can then be es-timated directly from the predicted correspondences with-out further post-processing. Despite its simplicity, our ap-proach achieves state-of-the-art performance on 3DMatch and ModelNet benchmarks. Our source code can be found at https://github.com/yewzijian/RegTR. 1.

Introduction
Rigid point cloud registration refers to the problem of finding the optimal rotation and translation parameters that align two point clouds. A common solution to point cloud registration follows the following pipeline: 1) detect salient keypoints, 2) compute feature descriptors for these keypoints, 3) obtain putative correspondences via nearest neighbor matching, and 4) estimate the rigid transforma-tion, typically in a robust fashion using RANSAC. In recent years, researchers have applied learning to point cloud reg-istration. Many of these works focus on learning the feature descriptors [14, 15, 54] and sometimes also the keypoint de-tection [2, 20, 49]. The final two steps generally remain un-changed and these approaches still require nearest neighbor matching and RANSAC to obtain the final transformation.
These algorithms do not take the post-processing into ac-count during training, and their performance can be sensi-tive to the post-processing choices to pick out the correct
Figure 1. Our network directly outputs final correspondences and the overlap scores. The required rigid transformation can then be directly computed from these correspondences without RANSAC. correspondences, e.g. number of sampled interest points or distance threshold in RANSAC.
Several works [44, 45, 50] avoid the non-differentiable nearest neighbor matching and RANSAC steps by esti-mating the alignment using soft correspondences computed from the local feature similarity scores. In this work, we take a slightly different approach. We observe that the learned local features in these works are mainly used to es-tablish correspondences. Thus, we focus on having the net-work directly predict a set of clean correspondences instead of learning good features. We are motivated by the recent line of works [7, 30] which make use of transformer atten-tion [43] layers to predict the final outputs for various tasks with minimal post-processing. Although attention mech-anisms have previously been used in registration of both point clouds [20, 44] and images [35], these works utilize
attention layers mainly to aggregate contextual information to learn more discriminative feature descriptors. A subse-quent RANSAC or optimal transport step is still often used to obtain the final correspondences. In contrast, our Regis-tration Transformer (REGTR) utilizes attention layers to di-rectly output a consistent set of final point correspondences, as illustrated in Fig. 1. Since our network outputs clean cor-respondences, the required rigid transformation can be es-timated directly without additional nearest neighbor match-ing and RANSAC steps.
Our REGTR first uses a point convolutional backbone
[40] to extract a set of features while downsampling the in-put pair of point clouds. The features of both point clouds are passed into several transformer [43] layers consisting of multi-head self and cross attentions to allow for global in-formation aggregation, while taking into account the point positions through positional encodings to allow the net-work to utilize rigidity constraints to correct bad correspon-dences. The resulting features are then used to predict the corresponding transformed locations of the downsampled points. We additionally predict overlap probability scores to weigh the predicted correspondences when computing the rigid transformation. Unlike the more common approach of computing correspondences via nearest neighbor feature matching, which requires interest points to be present at the same locations in both point clouds, our network is trained to directly predict corresponding point locations. As a re-sult, we do not require sampling large number of interest points (e.g. in [20, 54]) or a keypoint detector (e.g. [26, 55]) that produces repeatable points. Instead, we establish cor-respondences on simple grid subsampled points.
Although our REGTR is simple in design, it achieves state-of-the-art performance on the 3DMatch [54] and Mod-elNet [46] datasets. It also has fast run times since it does not require running RANSAC on a large number of putative correspondences. In summary, our contributions are:
• We directly predict a consistent set of final point cor-respondences via self and cross attention, without us-ing the commonly used RANSAC nor optimal trans-port layers.
• We evaluate on several datasets and demonstrate state-of-the-art performance, achieving precise alignments despite using a small number of correspondences. 2.