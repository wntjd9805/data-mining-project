Abstract
Model heterogeneous federated learning is a challeng-ing task since each client independently designs its own model. Due to the annotation difficulty and free-riding par-ticipant issue, the local client usually contains unavoidable and varying noises, which cannot be effectively addressed by existing algorithms. This paper starts the first attempt to study a new and challenging robust federated learning problem with noisy and heterogeneous clients. We present a novel solution RHFL (Robust Heterogeneous Federated
Learning), which simultaneously handles the label noise and performs federated learning in a single framework. It is featured in three aspects: (1) For the communication be-tween heterogeneous models, we directly align the models feedback by utilizing public data, which does not require additional shared global models for collaboration. (2) For internal label noise, we apply a robust noise-tolerant loss function to reduce the negative effects. (3) For challenging noisy feedback from other participants, we design a novel client confidence re-weighting scheme, which adaptively as-signs corresponding weights to each client in the collabo-rative learning stage. Extensive experiments validate the effectiveness of our approach in reducing the negative ef-fects of different noise rates/types under both model ho-mogeneous and heterogeneous federated learning settings, consistently outperforming existing methods. 1.

Introduction
Local clients such as mobile devices or whole organiza-tions generally have limited private data and limited gen-eralizability. Therefore, using all clients’ private data to centralized learn a public model will greatly improve per-formance. However, due to the existence of data silos and data privacy, we cannot use traditional centralized learning
*Corresponding Author: Mang Ye (yemang@whu.edu.cn)
Figure 1. Illustration of federated learning with noisy and hetero-geneous clients, where clients possess heterogeneous local models and noisy datasets with different noise rates. in practical applications [19]. To address these challenges,
Federated Learning (FL) has been proposed by McMahan et al. [33]. Federated learning is a distributed machine learning framework that enables multiple clients to collab-oratively train models with decentralized data. The clients never share private data with server ensuring basic privacy.
Recently, the widely used federated learning algorithms, e.g., FedAvg [33] and FedProx [29], are based on averaging the model parameters of the participating clients. Most of these federated learning methods [44, 27, 40, 32, 8, 14] are developed based on the assumption that participating client models have the same neural architecture.
In real-world scenarios, due to the differences in the per-sonalized requirements [28], each client might expect to de-sign its own model independently [17, 38, 41, 26, 13, 3, 9], resulting in the model heterogeneous federated learning problem. For example, when many healthcare organizations engage in collaborative learning without sharing private
data, they design different models to meet different tasks and specifications, as illustrated in Fig. 1. In this scenario, institutions are often reluctant to disclose or share the details of the model design due to business purposes. Therefore, to perform federated learning with heterogeneous models, a number of heterogeneous federated learning methods have been proposed [23, 31, 30, 60, 7, 55, 6, 16]. FedMD [23] is a framework based on knowledge distillation, which is implemented through the class scores by client models on the public dataset. FedDF [31] leverage unlabeled data to perform ensemble distillation for each different model ar-chitecture. These strategies mainly rely on a unified global consensus or shared models. However, learning a global consensus has a major limitation in that the clients cannot individually adjust their learning direction to accommodate the differences among clients. Besides, building extra mod-els will increase computational overhead, thereby affecting efficiency and effectiveness. Therefore, how to perform fed-erated learning with heterogeneous clients without relying on a global consensus or shared models is challenging.
In addition, the methods mentioned above mainly rely on the assumption that each client has a clean dataset, which cannot be satisfied in many practical applications. When the clients contain inevitable noisy samples, existing fed-erated learning methods cannot eliminate the negative ef-fect caused by label noise, suffering from a significant per-formance drop [25]. Since federated learning contains a large number of participating clients, the data in each par-ticipating client usually has different noisy patterns. Gen-erally, in practical applications, the label noise is caused by the following two aspects: 1) Due to the limitation and scarcity of human expertise, the quality of labeled data will be affected by human subjective factors, which means that high-quality labeled data requires high cost and thus in-evitably results in some wrong annotation. 2) In the fed-erated learning framework, considering the user fairness is-sue, there may be some free-riding participants in the sys-tem who want to learn from the global model, but do not want to provide useful information. Therefore, some users are reluctant to share their real information with other users and deliberately generate some wrong labels. In order to reduce the negative impact of label noise, existing meth-ods [12, 57, 46, 35, 42, 24, 58, 49, 53, 52] are usually devel-oped for the image classification task with a single model.
The approaches can be divided into four categories: label transition matrix estimation [39, 36, 50, 10], robust regular-ization [54, 2, 34], robust loss function design [43, 5, 48], and clean sample selection [11, 47, 18]. Under the feder-ated learning framework, we expect that each class of sam-ples will be learned sufficiently while avoiding overfitting to noisy samples. Therefore, how to reduce the negative im-pact of the internal label noise on the local model conver-gence during the local update phase is an important issue.
Furthermore, the above mentioned two problems lead to a new challenging issue, i.e., how to reduce the negative and noisy influence from other clients while collaborative learning in the federated learning framework. Due to model heterogeneity, the participating clients will have different decision boundaries and varying noisy patterns. As a re-sult, besides local noise, we also need to pay attention to the noise from other clients, and then it is crucial to reduce the contribution of noisy clients in the whole federated system.
The existing methods for solving noise in machine learning only eliminate the negative effect of internal model label noise, but are unable to solve the noise from other clients.
Therefore, it is crucial to handle the noisy feedback from other noisy clients under the federated learning framework.
In this paper, we provide the corresponding solution
RHFL (Robust Heterogeneous Federated Learning) for the robust federated learning problem with noisy and heteroge-neous clients: 1) Aligning the logits output distributions in heterogeneous federated learning. In order to commu-nicate learning in the presence of model heterogeneity, we learn the knowledge distribution of other clients by align-ing models feedback on public data. This allows each client to adjust different learning directions, which does not de-pend on a public model for communication. 2) Local noise learning with a noise-tolerant loss function. We analyze the negative effect caused by internal model label noise. In the local learning phase, we consider symmetrically using cross-entropy loss and reverse cross-entropy loss to avoid overfitting noise samples while fully learning all classes. 3)
Client confidence re-weighting for external noise. Since the label noise comes from the feedback by other clients, we propose a new weighting approach, namely Client Con-fidence Re-weighting (CCR), to reduce the contribution of noisy clients in federated communication. CCR models the loss decreasing pattern of the local models on private datasets for participant re-weighting. Its basic idea is to si-multaneously quantifies the label quality of dataset through the loss value and the loss decreasing speed, and then adap-tively assign the weight of the clean and efficient clients.
The main contributions in this work are as follows:
• We study a novel and important robust federated learn-ing problem with noisy and heterogeneous clients.
• We propose a new loss correction approach CCR, which computes the optimal weighted combination of participating clients. CCR adaptively adjusts the con-tribution of each client during loss updating, reducing the contribution of noisy clients, and increasing the contribution of clean clients.
• We validate the proposed method under various set-tings, including both heterogeneous and homogeneous models with different noise types and noise rates.
Experimental results show that RHFL consistently achieves stronger robustness than competing methods.
2.