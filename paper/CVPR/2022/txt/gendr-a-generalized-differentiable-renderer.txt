Abstract
In this work, we present and study a generalized family of differentiable renderers. We discuss from scratch which components are necessary for differentiable rendering and formalize the requirements for each component. We instan-tiate our general differentiable renderer, which generalizes existing differentiable renderers like SoftRas and DIB-R, with an array of different smoothing distributions to cover a large spectrum of reasonable settings. We evaluate an array of differentiable renderer instantiations on the popu-lar ShapeNet 3D reconstruction benchmark and analyze the implications of our results. Surprisingly, the simple uniform distribution yields the best overall results when averaged over 13 classes; in general, however, the optimal choice of distribution heavily depends on the task. 1.

Introduction
In the past years, many differentiable renderers have been published. These include the seminal differentiable mesh renderer OpenDR [1], the Neural 3D Mesh Ren-derer [2], and SoftRas [3] among many others. Using a dif-ferentiable renderer enables a multitude of computer vision applications, such as human pose estimation [4], camera in-trinsics estimation [5], 3D shape optimization [2], 3D re-construction [2], [3], [6], and 3D style transfer [2].
A fundamental difference between different classes of differentiable renderers is the choice of the underlying 3D representation.
In this work, we focus on differentiable 3D mesh renderers [1]–[3], [6]; however, the aspects that we investigate could also be applied to other differentiable rendering concepts, such as rendering voxels [7], point clouds [8], surfels [9], signed distance functions [10], and other implicit representations [11], [12].
Differentiable mesh renderers can be constructed in dif-ferent ways: either using an exact and hard renderer with approximate surrogate gradients or using an approximate renderer with natural gradients. Loper et al. [1] and Kato et al. [2] produce approximate surrogate gradients for their differentiable renderer, while their forward rendering is
In contrast, other differentiable renderers approxi-hard. mate the forward rendering in such a way that they produce a natural gradient. This can be achieved by modeling or ap-proximating a renderer under a probabilistic perturbation, which is continuous and makes the renderer differentiable.
For that, Rhodin et al. [13] model it with a Gaussian dis-tribution, while Liu et al. [3] model it with the square root of a logistic distribution, Petersen et al. [14] use a logis-tic distribution, and Chen et al. [6] use the exponential dis-tribution. While this variational interpretation of perturb-ing by a respective distribution is not stressed in some of these papers [3], [6], we believe it is important because it explicitly allows comparing the characteristics of the dif-ferentiable renderers. Moreover, the methods that only ap-proximate gradients can also be seen as approximately mod-elling a perturbation: the gradient computed for the Neural 3D Mesh Renderer [2] is approximately a perturbation by a uniform distribution. Note that, here, the solutions for rendering under perturbations are obtained analytically in closed-form without sampling.
In this work, we introduce a generalized differentiable renderer (GenDR). By choosing an appropriate probabil-ity distribution, we can (at least approximately) recover the above differentiable mesh renderers, which shows that a core distinguishing aspect of differentiable renderers is the type of distributions that they model. The choice of probability distribution herein is directly linked to the sig-moid (i.e., S-shaped) function used for the rasterization.
For example, a Heaviside sigmoid function corresponding to the Dirac delta distribution yields a conventional non-differentiable renderer, while a logistic sigmoid function of squared distances corresponds to the square root of a lo-gistic distribution. Herein, the sigmoid function is the cu-mulative distribution function (CDF) of the corresponding distribution. In this work, we select and present an array of distributions and examine their theoretical properties. i.e.,
Another aspect of approximate differentiable renderers is their aggregation function, the function that ag-gregates the occupancy probabilities of all faces for each pixel. Existing differentiable renderers commonly aggre-gate the probabilities via the probabilistic sum (⊥P (a, b) = a + b − ab or 1 − (cid:81) t∈T (1 − pt)), which corresponds to the probability that at least one face covers the pixel as-suming that probabilities pt for each triangle t are stochas-tically independent (cf. Eq. 4 in [3] or Eq. 6 in [6]).
In the field of real-valued logics and adjacent fields, this is well-known as a T-conorm, a relaxed form of the logi-cal ‘or’. Two examples of other T-conorms are the max-imum T-conorm ⊥M (a, b) = max(a, b) and the Einstein sum ⊥E(a, b) = (a + b)/(1 + ab), which models the rel-ativistic addition of velocities. We generalize our differen-tiable renderer to use any continuous T-conorm and present a variety of suitable T-conorms.
In total, the set of resulting concrete instances arising from our generalized differentiable renderer and the pro-posed choices amounts to 1 242 concrete differentiable ren-derers. We extensively benchmark all of them on a shape optimization task and a camera pose estimation task. Fur-ther, we evaluate the best performing and most interesting instances on the popular ShapeNet [15] 13 class single-view 3D reconstruction experiment [2]. Here, we also in-clude those instances that approximate other existing dif-ferentiable renderers. We note that we do not introduce a new shading technique in this paper, and rely on existing blended shaders instead.
We summarize our contributions as follows:
• We propose a generalized differentiable mesh renderer.
• We identify existing differentiable renderers (approxi-mately) as instances of our generalized renderer.
• We propose a variety of suitable sigmoid functions and
T-conorms and group them by their characteristics.
• We extensively benchmark 1 242 concrete differen-tiable renderers, analyze which characteristics and families of functions lead to a good performance, and find that the best choice heavily depends on the task, class, or characteristics of the data. 2.