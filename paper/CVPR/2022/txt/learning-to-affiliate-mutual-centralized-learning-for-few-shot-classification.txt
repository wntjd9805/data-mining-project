Abstract 1.

Introduction
Few-shot learning (FSL) aims to learn a classiﬁer that can be easily adapted to accommodate new tasks, given only a few examples. To handle the limited-data in few-shot regimes, recent methods tend to collectively use a set of local features to densely represent an image instead of using a mixed global feature. They generally explore a unidirec-tional paradigm, e.g., ﬁnding the nearest support feature for every query feature and aggregating local matches for a joint classiﬁcation. In this paper, we propose a novel Mutual
Centralized Learning (MCL) to fully afﬁliate these two dis-joint dense features sets in a bidirectional paradigm. We ﬁrst associate each local feature with a particle that can bidirec-tionally random walk in discrete feature space. To estimate the class probability, we propose the dense features’ acces-sibility that measures the expected number of visits to the dense features of that class in a Markov process. We relate our method to learning a centrality on an afﬁliation network and demonstrate its capability to be plugged in existing meth-ods by highlighting centralized local features. Experiments show that our method achieves the new state-of-the-art.
Few-shot classiﬁcation aims to learn a classiﬁer that can be readily adapted to novel classes given just a small number of labeled instances. To address this problem, a line of previous literature adopts metric-based methods [23, 25, 26] that learn a global image representation in an appropriate feature space and use a distance metric to predict their labels.
Recent approaches [12, 14, 17, 31] have demonstrated that the signiﬁcant intra-class variations would inevitably drive the image-level embedding from the same category far apart in a given metric space under low-data regimes. In contrast, densely representative local features can provide transferrable information across categories that have shown promising performances in the few-shot scenario. Among those methods illustrated in Figure 1, DN4 [12] ﬁnds the nearest neighbor support feature for each query feature and accumulates all the local matches in a Naive-Bayes way to represent an image-to-class similarity; DeepEMD [31] uses the earth mover distance to compare the complex struc-tured representations composed of local features. FRN [29] reconstructs each of query dense features with a linear com-bination of support dense features in a latent space and use the reconstruction distance to measure the image-to-class
relevance. They all follow a unidirectional query-to-support paradigm, whose evident character is an accumulation over all query features followed by a softmax probability.
In this paper, we incorporate an extra support-to-query connection as a complement to thoroughly afﬁliate two dis-joint sets of dense features. The potential offered by this bidirectional paradigm stems from the intuition that, except for using query features to ﬁnd related support features, it is also plausible to estimate the task-relevance of query features according to the support features. Speciﬁcally, we associate dense features with particles that could bidirectionally ran-dom walk to the opposite dense features set in the discrete feature space. The prediction probability for each class is then estimated by the dense features’ accessibility, i.e., the expected number of visits to the dense features of that class in a time-homogeneous Markov process.
The contributions are as follows: (1) We propose to learn mutual afﬁliations between the query and support dense fea-tures instead of following the unidirectional query-to-support paradigm in FSL. (2) We introduce the dense features’ acces-sibility to FSL and demonstrate that traditional transductive methods could be easily adapted to the inductive setting if we treat dense features from a single query image as a set of unlabeled data. (3) We propose a novel bidirectional random walk based method in FSL and draw its connection to the single-mode eigenvector centrality of an afﬁliation network. (4) The underlying centrality investigated in this work can be plugged in existing global feature based methods like
ProtoNet and RelationNet by highlighting task-centralized local features instead of global average pooling. 2.