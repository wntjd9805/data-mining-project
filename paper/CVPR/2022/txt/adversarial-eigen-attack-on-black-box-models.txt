Abstract
Black-box adversarial attack has aroused much research attention for its difficulty on nearly no available information of the attacked model and the additional constraint on the query budget. A common way to improve attack efficiency is to transfer the gradient information of a white-box substitute model trained on an extra dataset. In this paper, we deal with a more practical setting where a pre-trained white-box model with network parameters is provided without extra training data. To solve the model mismatch problem between the white-box and black-box models, we propose a novel algorithm EigenBA by systematically integrating gradient-based white-box method and zeroth-order optimization in black-box methods. We theoretically show the optimal di-rections of perturbations for each step are closely related to the right singular vectors of the Jacobian matrix of the pretrained white-box model. Extensive experiments on Ima-geNet, CIFAR-10 and WebVision show that EigenBA can consistently and significantly outperform state-of-the-art baselines in terms of success rate and attack efficiency. 1.

Introduction
Despite the fast development of deep learning, its se-curity problem has aroused much attention.
It has been demonstrated that a deep learning model can be successfully attacked at a small query cost without knowing the specific implementation of the model. Such techniques are called black-box attack [6, 11, 19], which is intensively studied in recent years with the aim of promoting the development of machine learning towards robustness.
In previous studies, there are two kinds of settings related to black-box attack. One is pure black-box attack, where nothing is available but the input and output of the black-box model. A common technique used in this setting is the zeroth-order optimization [11], where the gradient information is estimated by sampling different directions of perturbation and aggregating the relative changes of a certain loss function related to the output. The other setting is transfer-based attack [10], where a substitute white-box model is trained on an extra training dataset, and the gradient information of the white-box model is exploited to help improve the efficiency of attacking the black-box model. Usually, by leveraging extra information, transfer-based attack is more efficient and effective than pure black-box attack. But completely re-training a complex model is time-consuming and even infeasible if sufficient training data is unavailable.
In this paper, we aim for a new setting of transfer-based at-tack. Considering the easy availability of pre-trained models, we assume a pre-trained white-box model (i.e. its network structure and parameters) is given, but there is no additional training dataset available. In other words, the pre-trained model cannot be modified or fine-tuned before being used for black-box attack. Then in this setting, the critical chal-lenge that we need to tackle is the model mismatch between the pre-trained white-box model and the black-box model, which is presented in two cases. One is that the conditional probability of P (y|x) for two models is different. This will lead to disagreement on gradient direction of the two models.
The other, a even more challenging case, is that the category label set is different in white-box and black-box models. In literature, the first case is partially tackled by [2, 7, 25]. How-ever, they ask the label set of the two models to be the same and utilize the information of the output class probability given by the pre-trained model when attacking. This limits the practical use, as in real applications, cases of totally same label set for two models are rare and even in more extreme scenarios the pre-trained model is trained in an unsupervised manner [8], where no label information is available from the pre-trained model.
To solve this model mismatch problem in broader scenar-ios, we combine the ideas of white-box attack and black-box attack and utilize the representation layer of the pre-trained model. We regard the mapping function from the intermedi-ate representation of the white-box model to the output of the black-box model as a black-box function, and exploit com-mon practices of black-box attack on this black-box function.
Meanwhile, the mapping from the original input to the in-termediate representation layer is a part of the pre-trained
model, which could be processed as in a white-box setting.
It is noteworthy that the rationality of the idea depends on the generalization ability of the intermediate representation layer in the pre-trained white-box model. This can be un-derpinned by the findings in previous works that the lower layers of deep neural networks, i.e. the representation learn-ing layers, are transferrable across different datasets or data distributions [26].
More specifically, we propose a novel Eigen Black-box
Attack (EigenBA) method by systematically integrating the gradient-based white-box method and zeroth order optimiza-tion in black-box methods. We theoretically prove that the most efficient attack is to conduct singular value decompo-sition to the Jacobian matrix of the intermediate represen-tation layer to the original inputs in the white-box model, and perturb the input sample with the right singular vectors corresponding to the k largest singular values iteratively.
We conduct extensive experiments to evaluate the effec-tiveness of EigenBA in multiple settings. The results demon-strate that EigenBA can consistently and significantly out-perform state-of-the-art baselines in terms of success rate and attack efficiency. Also, the ablation studies show that
EigenBAâ€™s advantage can be exerted as long as the represen-tation layer of the white-box model has moderate generaliza-tion ability, implying its wide applicability in practice. 2.