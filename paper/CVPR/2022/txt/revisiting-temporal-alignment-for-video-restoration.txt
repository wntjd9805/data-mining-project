Abstract
Long-range temporal alignment is critical yet challeng-ing for video restoration tasks. Recently, some works at-tempt to divide the long-range alignment into several sub-alignments and handle them progressively. Although this operation is helpful in modeling distant correspondences, error accumulation is inevitable due to the propagation mechanism. In this work, we present a novel, generic itera-tive alignment module which employs a gradual refinement scheme for sub-alignments, yielding more accurate motion compensation. To further enhance the alignment accuracy and temporal consistency, we develop a non-parametric re-weighting method, where the importance of each neighbor-ing frame is adaptively evaluated in a spatial-wise way for aggregation. By virtue of the proposed strategies, our model achieves state-of-the-art performance on multiple bench-marks across a range of video restoration tasks including video super-resolution, denoising and deblurring. 1.

Introduction
Frame alignment plays an essential role in aggregating temporal information in video restoration tasks, e.g., video super-resolution (Video SR), video deblurring, and video denoising. In recent years, great attempts have been made to study this problem. Especially, deep learning-based meth-ods are successful in building temporal correspondences and achieve promising results.
The existing alignment methods can be roughly cate-gorized into two classes: (i) independent alignment that conducts frame-to-frame alignments totally independently (see Fig. 2(a)) and (ii) progressive alignment that performs temporally consecutive alignments sequentially in a recur-sive manner (see Fig. 2(b)). Those independent alignment approaches typically focus on designing effective feature descriptors and motion estimation modules to improve the performance. For example, EDVR [29] develops pyramid,
*Equal contribution
†Corresponding author
Figure 1. Performance and efficiency comparison on Vimeo-90K-T [33]. Besides high PSNR and fast inference, our alignment al-gorithm can be easily integrated into existing frameworks (e.g.,
IconVSR [3]) to further improve performance. Circle sizes are set proportional to the numbers of parameters. cascading and deformable convolutions (PCD) for more ac-curate alignment. Whereas, without exploiting the correla-tions between multiple alignments, this strategy is still fac-ing challenges to estimate the long-range motion fields. The second line typically adopts a recurrent framework for grad-ual alignment. Taking BasicVSR [3] for example, the au-thors propose an optical-flow-based recurrent architecture for video super-resolution. They predict the bidirectional optical flow between two neighboring frames and then con-duct a bidirectional propagation, where the temporal infor-mation is aggregated by warping image features produced by previous steps. This kind of methods is mainly proposed to model long-range dependencies since it only needs to handle relatively small motion between neighboring frames in one step. However, such chain-rule-based propagation has no chance to correct the misalignment caused by previ-ous steps and may suffer from the error accumulation issue.
As illustrated in Fig. 2(c), we observe that differ-ent long-range alignments (Ai) actually share some sub-alignments (ai), e.g., a1 is shared among A1, A2 and A3, so as a2 in A2 and A3. How can we utilize this property
Figure 2. Three alignment strategies in video restoration tasks. (a) Independent alignment that estimates frame-to-frame correspondences in isolation. (b) Progressive alignment that performs multiple alignments sequentially. (c) Our proposed iterative alignment scheme that performs gradual refinement for shared sub-alignments. Ak refers to the k-th temporal alignment and ai is the i-th sub-alignment. to improve the accuracy of the shared sub-alignments? In this work, we propose an iterative alignment module (IAM) built upon the progressive alignment strategy to gradually refine the shared sub-alignments. For a specific shared sub-alignment (e.g., a2 in A2 and A3), the previously estimated result (a2 in A2) is used as a prior in the current iteration (a2 in A3). Our IAM has two merits over the progressive alignment scheme. First, the progressive alignment only conducts a single prediction for each sub-alignment so that misalignment can not be corrected. In contrast, our IAM refines each sub-alignment iteratively, yielding more accu-rate alignment. Second, the progressive alignment performs multi-frame aggregation based on a chain-like propagation so that misalignment will be propagated to the end. In our
IAM, each neighboring frame is aligned through individual propagation, making it more reliable. Furthermore, to re-duce the computational complexity, we elaborate a simple yet efficient alignment unit for temporal sub-alignments.
From Fig. 1, it is observed that our alignment algorithm yields high inference efficiency and superior performance compared with state-of-the-art video SR methods. Partic-ularly, our IAM can be easily plugged into existing deep models. For example, by replacing the original independent alignment module of IconVSR [3] with our “IAM” (denoted as “IconVSR+IAM” in Fig. 1), the PSNR is boosted from 37.47dB to 37.56dB on Vimeo-90K-T [33], while reducing the number of parameters from 8.7M to 7.8M.
Besides, the aggregation of multiple aligned frames re-mains an essential step, for the purpose of preserving details while eliminating alignment errors. Modern restoration sys-tems either employ a sequence of convolutions to directly fuse the aligned features [3, 28] or adopt spatial-temporal adaptive aggregation strategies [9, 13, 15, 16, 19, 29, 31].
However, all these methods solely rely on the learned pa-rameters, raising the risk of overfitting on a specific do-In this work, we propose a non-parametric re-main. weighting module, where two strategies are designed to ex-plicitly evaluate the spatially-adaptive importance of differ-ent frames. First, we explore the accuracy of alignments.
Patches in the aligned frames are compared with the coun-terparts in the reference frame, and those of high similar-ity are assigned with larger weights during fusion. Second, to evaluate the consistency of alignments, we compute the pixel-wise L2 distances of the aligned frames with their av-erage. Pixels with smaller distances are considered to be more consistent with other frames and hence are assigned with larger weights. The proposed re-weighting module is parameterless and hence can be plugged into other models.
The main contributions are summarized as:
• We rethink issues of the progressive alignment and accordingly propose an iterative alignment scheme, yielding more accurate estimation, especially over long-range correspondences.
• We propose a non-parametric re-weighting module that simultaneously evaluates the alignment accuracy and temporal consistency.
• The quantitative and qualitative results justify the state-of-the-art performance of our method across sev-eral video restoration tasks. 2.