Abstract
We propose a semi-supervised network for wide-angle portraits correction. Wide-angle images often suffer from skew and distortion affected by perspective distortion, espe-cially noticeable at the face regions. Previous deep learn-ing based approaches need the ground-truth correction flow maps for training guidance. However, such labels are ex-pensive, which can only be obtained manually.
In this work, we design a semi-supervised scheme and build a high-quality unlabeled dataset with rich scenarios, allow-ing us to simultaneously use labeled and unlabeled data to improve performance. Specifically, our semi-supervised scheme takes advantage of the consistency mechanism, with several novel components such as direction and range con-sistency (DRC) and regression consistency (RC). Further-more, different from the existing methods, we propose the
Multi-Scale Swin-Unet (MS-Unet) based on the multi-scale swin transformer block (MSTB), which can simultaneously learn short-distance and long-distance information to avoid artifacts. Extensive experiments demonstrate that the pro-posed method is superior to the state-of-the-art methods and other representative baselines. The source code and dataset are available at https://github.com/megvii-research/Portraits_Correction 1.

Introduction
In recent years, a growing number of smartphones have been equipped with wide-angle cameras, which take wide-angle images with rich contents. However, a wider FOV camera often causes severe perspective distortions, which bends straight edges on buildings, and distorts faces, as shown in Fig. 1(a). Therefore, an ideal intelligent algorithm is required to correct the distortion image. After correction, the faces will look more natural while the curved lines in the background are also corrected, as shown in Fig. 1(b).
The traditional undistortion methods apply perspective projection using calibrated camera parameters, which cor-*Equal contribution. †Corresponding authors.
Figure 1. An example of our method. (a) the original wide-angle image with curved lines and distorted faces. (b) result by the pro-posed semi-supervised method, both lines and faces are corrected. rectly warp the lines at the background to straight [3,8,24].
Nevertheless, faces on the image are stretched unnaturally due to incorrect projection as a plane. Compared to per-spective projection, the mercator and stereographic projec-tions [28] can preserve the shape of faces locally, but they also bend linear structures in the background [4].
It is obvious that facial regions and background need two different types of projections for the wide-angle image cor-rection. Carroll et al. [4] presented a content-preserving approach that finds an optimal mapping solution accord-ing to the user-specified lines. Recently, Shih et al. [26] designed an optimization problem to create a mesh that adapts stereographic projection on facial regions regionally and applies perspective projection on background, enabling a smooth transition between portraits and background by solving the optimization problem automatically. However, the method [26] sometimes causes distorted architectures nearby corrected faces. In addition, it requires portraits seg-mentation mask and camera parameters as additional inputs.
Tan et al. [29] proposed the first fully-supervised CNN-based method for wide-angle image correction, which con-sists of a line correction network and a portraits correction network. Tan’s method obtained satisfactory results with the distorted image as input. However, there still exists dis-advantages in their work. First, it needs many training pho-tos under rich scenarios, and each face in the photo must be manually undistorted by specific tools. Meanwhile, errors may occur in manual annotation, causing uneven annota-tion quality or introducing dirty data. Therefore, the whole data preparation procedure is complex and expensive, mak-ing it unrealistic to improve performance by enlarging the training dataset. Second, Tan’s method also creates artifacts in some cases because it does not use long-range semantic information for local variations of faces.
To address the above problems, we attempt to lever-age a novel semi-supervised strategy, aiming to reduce the cost of preparing an expensive manual corrected dataset.
Specifically, we adopt the semi-supervised strategy, con-taining direction and range consistency (DRC) and regres-sion consistency (RC), to make full use of both labeled and unlabeled data by introducing a surrogate task (segmen-tation). Besides, compared with Tan et al. [29], we de-velop a novel network based on the multi-scale swin trans-former block (MSTB), dubbed as Multi-Scale Swin-Unet (MS-Unet) which is better suitable for portraits correction.
In particular, we also collect more than 5, 000 unlabeled dis-tortion images from different phones and scenes to train
MS-Unet by the semi-supervised strategy. Experimental results show that our approach can correct distortions in wide-angle portraits with superior performance than previ-ous methods, and it only needs a small amount of manually labeled data. In summary, our main contributions are:
• We propose the first semi-supervised learning strategy for wide-angle portraits correction, which dramatically reduces the requirement of labeled training data.
• We develop a novel transformer-based network called
MS-Unet, based on MSTB, to fully utilize both local-scale and long-range semantic information interaction for wide-angle portraits correction.
• We provide a high-quality unlabeled dataset that can be used to train semi-supervised wide-angle portraits correction algorithms. 2.