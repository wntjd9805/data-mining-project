Abstract
Data augmentation helps neural networks generalize better by enlarging the training set, but it remains an open question how to effectively augment graph data to enhance the performance of GNNs (Graph Neural Networks). While most existing graph regularizers focus on manipulating graph topological structures by adding/removing edges, we offer a method to augment node features for better perfor-mance. We propose FLAG (Free Large-scale Adversarial
Augmentation on Graphs), which iteratively augments node features with gradient-based adversarial perturbations dur-ing training. By making the model invariant to small fluctu-ations in input data, our method helps models generalize to out-of-distribution samples and boosts model performance at test time. FLAG is a general-purpose approach for graph data, which universally works in node classification, link prediction, and graph classification tasks. FLAG is also highly flexible and scalable, and is deployable with arbi-trary GNN backbones and large-scale datasets. We demon-strate the efficacy and stability of our method through ex-tensive experiments and ablation studies. We also provide intuitive observations for a deeper understanding of our method. We open source our implementation at https:
//github.com/devnkong/FLAG. 1.

Introduction
Graph Neural Networks (GNNs) have emerged as pow-erful architectures for learning and analyzing graph repre-sentations. The Graph Convolutional Network (GCN) [21] and its variants have been applied to a wide range of tasks, including visual recognition [33], meta-learning [11], social analysis [23,29], and recommender systems [41]. However, the training of GNNs on large-scale datasets usually suffers from overfitting, and realistic graph datasets often involve a high volume of out-of-distribution test nodes [17], posing significant challenges for prediction problems.
One promising solution to combat overfitting in deep neural networks is data augmentation [22], which is com-monplace in computer vision tasks. Data augmentations apply label-preserving transformations to the inputs, such as translations and reflections for images. As a result, data augmentation effectively enlarges the training set while in-curring negligible computational overhead. However, it re-mains an open problem how to effectively generalize the notion of data augmentation to GNNs. Transformations on images rely heavily on image structures [3], and it is chal-lenging to design low-cost transformations that preserve se-mantic meaning for non-visual tasks like natural language processing [38] and graph learning. Generally speaking, graph data for machine learning comes with graph struc-ture (or edge features) and node features.
In the limited cases where data augmentation can be done on graphs, it generally focuses exclusively on the graph structure by adding/removing edges [13, 14, 16, 30, 37, 42].
In the meantime, adversarial data augmentation, which applies small perturbations in the input feature space to maximially alter model outputs, is known to boost neural network robustness and promote resistance to adversarially chosen inputs [15, 26]. Despite the wide belief that adver-sarial training harms standard generalization and leads to worse accuracy [1, 35], recently a growing amount of at-tention has been paid to using adversarial perturbations to augment datasets and ultimately alleviate overfitting. For example, [36] and [34] showed adversarial data augmenta-tion is a data-dependent regularization that could help gen-eralize to out-of-distribution samples, and its efficacy has been verified in domains including computer vision [40], language understanding [19,27,44], and visual question an-swering [10]. Despite the success of adversarial augmenta-Figure 1. Generalization performance of FLAG on all three tasks. Left: node classification with GAT as baseline on ogbn-products;
Middle: link prediction with hits@20 as metric (the higher the better) and GraphSAGE as baseline on ogbl-ddi; Right: graph classifica-tion with GIN as baseline on ogbg-molhiv. Plotted lines are attained by smoothing the original lines (the shallow ones), where smooth weights are 0.75, 0.75, and 0.5 respectively. tion in language and vision, it remains unclear how to effec-tively and efficiently improve GNNs’ clean accuracy using adversarial augmentation.
Present work. We propose FLAG, Free Large-scale
Adversarial Augmentation on Graphs, to tackle the over-fitting problem. While existing literature focuses on mod-ifying graph structures to augment datasets, FLAG works purely in the node feature space by adding adversarial per-turbations (generated by gradient-based robust optimization algorithms), to the input node features with graph structures unchanged. FLAG leverages “free” adversarial training methods [31] to conduct efficient adversarial training so that it is highly scalable to large datasets. The method also takes advantage of multi-scale adversarial augmentation to make the model fully generalized in the input feature space. We verify the effectiveness of our method on the Open Graph
Benchmark (OGB) [17], which is a collection of large-scale, realistic, and diverse graph datasets for node, link, and graph property prediction tasks. We conduct extensive ex-periments across OGB datasets by applying FLAG to com-petitive GNN baselines and show that FLAG brings non-trivial improvements in most cases. For example, FLAG lifts the test accuracy of GAT on ogbn-products by an absolute value of 2.31%. FLAG is simple (easy to implement with a dozen lines of code in PyTorch), gen-eral (model-free and task-free), and efficient (able to bring salient improvement at tractable or even no extra cost). Our main contributions are summarized as follows:
• Method: To the best of our knowledge, our work is the first general-purpose feature-based data augmenta-tion method on graph data, which is complementary to other regularizers (e.g., dropout) and topological aug-mentations. The novel method incorporates “free” and multi-scale techniques to craft feature augmentations more effectively.
• Experiments: We show the efficacy and scalability of our method through extensive experiments and abla-tion studies on large-scale datasets across node, link, and graph property prediction tasks. We validate that
FLAG is superior to existing adversarial augmentation methods.
• Analysis: We provide observations and analysis to sup-port our conjecture that the discrete vs. continuous distribution discrepancy of input features is the key to different effects (beneficial vs. harmful) of adversarial augmentations on model accuracy. 2. Preliminaries and