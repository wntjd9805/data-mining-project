Abstract
This paper introduces a new matting task called human instance matting (HIM), which requires the pertinent model to automatically predict a precise alpha matte for each hu-man instance. Straightforward combination of closely re-lated techniques, namely, instance segmentation, soft seg-mentation and human/conventional matting, will easily fail in complex cases requiring disentangling mingled colors belonging to multiple instances along hairy and thin bound-ary structures. To tackle these technical challenges, we propose a human instance matting framework, called Inst-Matt, where a novel mutual guidance strategy working in tandem with a multi-instance refinement module is used, for delineating multi-instance relationship among humans with complex and overlapping boundaries if present. A new instance matting metric called instance matting qual-ity (IMQ) is proposed, which addresses the absence of a unified and fair means of evaluation emphasizing both in-stance recognition and matting quality. Finally, we con-struct a HIM benchmark for evaluation, which comprises of both synthetic and natural benchmark images. In addi-tion to thorough experimental results on complex cases with multiple and overlapping human instances each has intri-cate boundaries, preliminary results are presented on gen-eral instance matting. Code and benchmark are available in https://github.com/nowsyn/InstMatt. 1.

Introduction
Fast development of mobile internet technology has trig-gered the rapid growth of multimedia industry especially we-media, where users are heavily engaged in editing tools to beautify or re-create their image and video contents. As one of the primary techniques for efficient image editing, image matting has achieved significant improvement with the wide adoption of deep neural networks in the task. How-ever, existing matting methods still fail or else are not easy to use in many scenarios, such as extracting the foreground
This work was done when Yanan Sun was a student intern at Kuaishou
Technology, which was supported by Kuaishou Technology and the Re-search Grant Council of the Hong Kong SAR under grant no. 16201420.
Figure 1. Comparisons with related tasks, including soft segmen-tation results from SSS [5], instance segmentation results from
MaskRCNN [22], human matting results from RVM [36] as well as ours, and human instance matting results from ours. human while removing background humans, or instance-level editing as shown in Figure 1: what if we want to inde-pendently extract and edit each human instance?
Similar to semantic versus instance segmentation, exist-ing matting methods, which focus on a region based on a given trimap or a known object class, are unable to differ-entiate instances. To address this issue, we propose a new task called human instance matting (HIM), which aims to automatically extract precise alpha matte for each human instance in a given image. HIM shares similarities to the following conventional tasks while embodying fundamental differences making it a problem on its own: 1) instance seg-mentation aims at distinguishing instances, but it can only produce sharp object boundary without semi-transparency consideration; 2) recent soft segmentation [5] is capable of generating soft segments for multiple instances of different classes with instance-aware features, but cannot deal with instances of the same class; 3) conventional matting aims at extracting precise alpha matte, but it lacks instance aware-ness. Overall, human instance matting is a unified task encompassing the characteristics of the aforementioned re-lated tasks while introducing new technical challenges.
Conventional matting is based on the image compositing
equation where an image I is the combination of foreground
F layer, background B layer modulated by alpha α:
I = αF + (1 − α)B. (1)
To adapt to multiple instance matting, we modify the 2-layer Equation 1 to one of multi-instance layered compo-sition, where each instance layer is attenuated by its corre-sponding α:
I = n (cid:88) i=0
αiLi, s.t. n (cid:88) i=0
αi = 1 (2) where Li and αi respectively denote the foreground and al-pha matte for instance i > 0; L0 and α0 respectively rep-resent the background and its corresponding alpha matte; n is the number of instances. This equation had also appeared in [5, 31], but all such relevant matting and segmentation tasks were not instance aware. The goal of instance matting is to solve for target mattes αi for all i > 0.
By exploring the complex relation among multiple in-stances, we propose a new instance matting framework, called InstMatt, where a novel mutual guidance strategy enables a deep model to decompose mingled compositing colors into their respective instances. Our mutual guidance strategy takes both the relation between instances and the background, and the relation among instances into consid-eration. Besides, a multi-instance refinement module is carefully designed and engineered for interchanging infor-mation among instances to synchronize predictions for fur-ther refinement. Equipped with the novel mutual guidance and multi-instance refinement, our InstMatt is able to not only produce high-quality human alpha matte but also dis-tinguish multiple human instances shown in Figure 1.
With this new HIM task, existing evaluation metrics for instance segmentation or matting are insufficient, which were designed for either one of the tasks. We propose a new metric, called instance matting quality (IMQ), that si-multaneously measures instance recognition quality and al-pha matte quality. To provide a general and comprehen-sive validation on instance matting techniques, we construct an instance matting benchmark, HIM2K, which consists of a synthetic image benchmark and a natural image bench-mark totaling 2,000 images with high-quality matte ground truths.
To demonstrate the promise of our technical contribu-tions beyond human instance matting, we present prelimi-nary results on matting multi-object instances not limited to humans, a fruitful future direction to explore. 2.