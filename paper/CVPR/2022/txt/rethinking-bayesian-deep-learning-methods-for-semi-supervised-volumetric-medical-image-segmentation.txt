Abstract
Recently, several Bayesian deep learning methods have been proposed for semi-supervised medical image segmen-tation. Although they have achieved promising results on medical benchmarks, some problems are still existing. Firstly, their overall architectures belong to the discriminative mod-els, and hence, in the early stage of training, they only use la-beled data for training, which might make them overﬁt to the labeled data. Secondly, in fact, they are only partially based on Bayesian deep learning, as their overall architectures are not designed under the Bayesian framework. However, unifying the overall architecture under the Bayesian perspec-tive can make the architecture have a rigorous theoretical basis, so that each part of the architecture can have a clear probabilistic interpretation. Therefore, to solve the prob-lems, we propose a new generative Bayesian deep learning (GBDL) architecture. GBDL belongs to the generative mod-els, whose target is to estimate the joint distribution of input medical volumes and their corresponding labels. Estimating the joint distribution implicitly involves the distribution of data, so both labeled and unlabeled data can be utilized in the early stage of training, which alleviates the potential overﬁtting problem. Besides, GBDL is completely designed under the Bayesian framework, and thus we give its full
Bayesian formulation, which lays a theoretical probabilistic foundation for our architecture. Extensive experiments show that our GBDL outperforms previous state-of-the-art meth-ods in terms of four commonly used evaluation indicators on three public medical datasets. 1.

Introduction gions from medical images. Training segmentation networks usually relies on large labeled medical image datasets, but they are scarce and difﬁcult to obtain, since not everyone is qualiﬁed to annotate medical data, and there is only a lim-ited number of medical experts. Therefore, semi-supervised segmentation has become an important research direction in the area of medical computer vision.
Several methods [1, 2, 5, 6, 9–11, 14, 15, 17–19, 21, 22] have been proposed in recent years.1 Among these works,
Bayesian deep-learning-based methods [14,15,17,18,21] are closely related to this work, as they are based on Monte Carlo (MC) dropout [4], which is an approximation of Bayesian neural networks (BNNs). These methods are mainly built with the teacher-student architecture, which can be regarded as the discriminative model. Speciﬁcally, they initially build the model P (Y |X) only from labeled data, and then apply the model to generate pseudo labels that are reﬁned or rec-tiﬁed based on the epistemic uncertainty [7] provided by
MC dropout for unlabeled ones. Then, the pseudo labels are further combined with unlabeled and labeled data to further train the overall architecture.
The works [14, 15, 17, 18, 21] mainly have two issues.
Firstly, their models are built only with labeled data in the early stage of training and may overﬁt to them, since the quantity of labeled data is limited. Consequently, the new pseudo labels generated by the models might be inaccurate, which adversely impacts the subsequent training process.
Secondly, their models are only partially based on Bayesian deep learning and are not designed under the Bayesian frame-work. Hence, they are unable to give a Bayesian formulation with regard to their models, lacking a solid theoretical basis.
As a result, some modules in their models are empirically designed, and the functions of those modules remain unclear.
Deep neural networks are a powerful tool for visual learn-ing, and they have outperformed previous methods that are based on hand-crafted features in many classical computer vision tasks. Due to the power of deep neural networks, researchers also try to use them to segment pathology re-1Note that we only consider previous methods that build their architec-tures with 3D CNNs, since our architecture is also based on 3D CNNs. In most cases, using 3D CNNs to process medical volumetric data performs better than using 2D CNNs, as the relationships among neighboring slices are preserved in 3D CNNs. Thus, comparing our method with 2D-CNN-based methods is unfair to them.
In this work, we aim to ﬁx these two problems by propos-ing a new generative model, named generative Bayesian deep learning (GBDL) architecture, as well as its corresponding full Bayesian formulation. Unlike teacher-student-based architectures, GBDL estimates the joint probability distribu-tion P (X, Y ) via both labeled and unlabeled data, based on which more reliable pseudo-labels can be generated, since the generative model is more faithful about the overall data distribution P (X) and the intrinsic relationship between in-puts and their corresponding labels (modeled by P (X, Y )), alleviating the overﬁtting problem. Moreover, GBDL is en-tirely constructed under the Bayesian framework, and its related full Bayesian formulation lays a solid theoretical foundation, so that every part of GBDL has its correspond-ing probabilistic formulation and interpretation.
The main contributions of this paper are as follows:
• We propose a new generative Bayesian deep learning (GBDL) architecture. GBDL aims to capture the joint distribution of inputs and labels, which moderates the potential overﬁtting problem of the teacher-student archi-tecture in previous works [14, 15, 17, 18, 21].
• Compared with previous methods [14, 15, 17, 18, 21],
GBDL is completely designed under the Bayesian frame-work, and its full Bayesian formulation is also given here.
Thus, it has a theoretical probabilistic foundation, and the choice of each module in GBDL and the construction of the loss functions are more mathematically grounded.
• In extensive experiments, GBDL outperforms previous methods with a healthy margin in terms of four evaluation indicators on three public medical datasets, illustrating that GBDL is a superior architecture for semi-supervised volumetric medical image segmentation.
The rest of this paper is organized as follows. In Section 2, we review related methods. Section 3 presents our GBDL architecture and its Bayesian formulation, followed by the experimental settings and results in Section 4. In Section 5, we give a summary and an outlook on future research.
The source code is available at https://github.com/Jianf-Wang/GBDL. 2.