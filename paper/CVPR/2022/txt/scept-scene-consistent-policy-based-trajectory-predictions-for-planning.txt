Abstract
Trajectory prediction is a critical functionality of au-tonomous systems that share environments with uncon-trolled agents, one prominent example being self-driving vehicles. Currently, most prediction methods do not en-force scene consistency, i.e., there are a substantial amount of self-collisions between predicted trajectories of differ-ent agents in the scene. Moreover, many approaches gen-erate individual trajectory predictions per agent instead of joint trajectory predictions of the whole scene, which makes downstream planning difﬁcult.
In this work, we present
ScePT, a policy planning-based trajectory prediction model that generates accurate, scene-consistent trajectory predic-tions suitable for autonomous system motion planning. It explicitly enforces scene consistency and learns an agent interaction policy that can be used for conditional predic-tion. Experiments on multiple real-world pedestrians and autonomous vehicle datasets show that ScePT matches cur-rent state-of-the-art prediction accuracy with signiﬁcantly improved scene consistency. We also demonstrate ScePT’s ability to work with a downstream contingency planner. 1.

Introduction
Predicting the future motion of uncontrolled agents is critical to the safety of autonomous systems that interact with them. A prominent example is self-driving cars, where the ego-vehicle shares the road with other road users such as vehicles, pedestrians, and cyclists. The prediction task is difﬁcult as humans are notoriously uncertain and incon-sistent. For example, it is well-known that humans demon-strate multimodal behaviors in the context of driving, such as being simultaneously able to maintain their current lane, change lanes, yield, or overtake in the future. As a re-sult, early works on human driving behavior prediction [37] were not accurate enough to be used in an autonomous ve-hicle’s motion planning stack. To remedy this, many re-searchers have been developing phenomenological meth-ods, i.e., methods that learn the behavior of agents from a wealth of data (e.g., [2, 28, 29, 44]), to great effect.
In a typical autonomy stack, the trajectory prediction module is followed by a planning module which takes the
Figure 1. An illustration of ScePT’s output, comprised of multi-modal trajectory predictions for each agent. Different stroke type (solid, dashed, dotted) represents the different modes of the scene-consistent joint trajectory prediction. Agents in a scene are par-titioned into highly-interacting cliques, an example of which is visualized with yellow dashed lines. predicted trajectories of surrounding agents and plans the ego-motion accordingly. With this downstream planner in mind, several requirements, in addition to prediction accu-racy, emerge, and are discussed in detail below. 1.1. Desiderata
Typical features desired for a trajectory prediction model include high prediction accuracy, fast inference speed, and calibrated uncertainties. When predictions are subsequently consumed by a downstream planner, the following features are also critical for overall system performance:
Compatibility: Trajectory predictions for different agents in a scene should be compatible with each other within a single joint prediction. In particular, collisions among pre-dicted trajectories should be rare, as collisions are them-selves rare in reality.
Tractable Joint Trajectory Prediction: As mentioned pre-viously, the future motion of the agents can be multimodal.
In a scene consisting of multiple agents, if the multimodal predictions are generated for individual nodes, a down-stream motion planner needs to consider all combinations of these trajectory predictions. Since the number of modes grows exponentially with the number of agents, the planner
is quickly overwhelmed. Alternatively, the motion plan-ner could take a conservative approach and avoid all pre-dicted trajectories, yet often at the price of compromised planning performance (e.g., bringing the robot to a stand-still if all plans seem to collide). As a result, we desire multimodal, joint predictions of all agents with a limited, but fully-representative number of modes such that a down-stream planner can perform contingency planning.
Time Consistency: With a downstream planner, the motion plan heavily depends on the prediction results. To ensure smooth motion plans, predictions should not change signif-icantly between subsequent time steps if the scene itself has not changed drastically in the meantime. As a result, sam-pling should be avoided as predictions may change signif-icantly between time steps, causing discontinuity in the re-sulting motion plans which may hurt planning performance and safety.
Conditioning: Conditioning is the operation of ﬁxing one or multiple agents’ future trajectories and predicting the re-sulting distribution of other agents’ future trajectories. Con-ditional prediction is useful for motion planning (condi-tioned on the ego agent’s motion plan) and for understand-ing interactions between agents. Conditioning is available in several existing works such as [42], yet requires explicit modeling. Ideally, conditional distributions would be gen-erated without requiring structural changes to the model. 1.2. Contributions
In this work we present ScePT, a trajectory forecast-ing method that generates joint trajectory predictions for multiple interacting agents. Our contributions are three-fold: First, we propose predicting the futures of cliques of agents rather than individuals or the scene graph as a whole (Sec. 3.1), and present a neural network architecture to do so (Sec. 3.2). Second, we leverage insights from motion planning and propose a policy network that autoregressively rolls out closed-loop trajectory predictions via a GNN that models agent-to-agent interactions and maps them to con-trol inputs (Sec. 3.3). Finally, we improve output sample di-versity by augmenting our loss function with a tunable risk measure that determines weights between trajectory sam-ples during training (Sec. 3.6).
When evaluated on large-scale, real-world pedestrian and driving datasets, ScePT reduces the dimensionality necessary to capture scene-level multimodality (Sec. 4.1); achieves signiﬁcant improvements in the scene consistency of its predictions, as measured by collision rate (Sec. 4.2); and easily enables counterfactual analyses (Sec. 4.3); all of which are critical for simulation (Sec. 4.3), downstream planning (Sec. 4.4), and veriﬁcation of autonomous vehicle performance. 2.