Abstract
Mining precise class-aware attention maps, a.k.a, class activation maps, is essential for weakly supervised semantic segmentation. In this paper, we present L2G, a simple on-line local-to-global knowledge transfer framework for high-quality object attention mining. We observe that classiﬁ-cation models can discover object regions with more de-tails when replacing the input image with its local patches.
Taking this into account, we ﬁrst leverage a local classi-ﬁcation network to extract attentions from multiple local patches randomly cropped from the input image. Then, we utilize a global network to learn complementary atten-tion knowledge across multiple local attention maps online.
Our framework conducts the global network to learn the captured rich object detail knowledge from a global view and thereby produces high-quality attention maps that can be directly used as pseudo annotations for semantic seg-mentation networks. Experiments show that our method at-tains 72.1% and 44.2% mIoU scores on the validation set of PASCAL VOC 2012 and MS COCO 2014, respectively, setting new state-of-the-art records. Code is available at https://github.com/PengtaoJiang/L2G. 1.

Introduction
Deep learning algorithms [37, 41, 64] have promoted the rapid development of the semantic segmentation task in re-cent years. However, training a deep neural network for se-mantic segmentation requires a large number of pixel-wise accurate labels, which consume lots of human labors and re-sources. Recently, to reduce the reliance on accurate anno-tations, researchers have attempted to study semantic seg-mentation based on cheap supervisions, such as bounding boxes [12,42], scribbles [36,50], points [4], and image-level labels [23, 53]. Among these weak supervisions, image-level labels only provide information on the existence of the target object categories, making them more popular than
∗Qibin Hou is the corresponding author.
Figure 1. Conceptual working pipeline of the proposed method.
We utilize the attention maps for local views with rich details ex-tracted from the local network to teach the global network. This enables the global network to learn the rich local details knowl-edge from the local network online and thereby more integral ob-ject attentions. other supervisions due to the easy way to collect. In this pa-per, we also focus on weakly supervised semantic segmen-tation (WSSS) based on image-level labels.
Speaking of WSSS, one of the most important compo-nents should be the class activation map (CAM) [65] which contains both semantic and location information about the target objects and can be used as pseudo pixel-level an-notations for training segmentation networks. Since the quality of CAMs has a great inﬂuence on the segmenta-tion results, recently, many strategies have been proposed to advance the original CAM method, including adver-sarial erasing [22, 53, 63, 66], online attention accumula-tion [25, 26], seed region expansion [24, 28], and afﬁnity learning [1, 2, 57], etc. Despite the good performance, these works mostly take the whole input image as the sole input to the model. However, we empirically observe that clas-siﬁcation models can discover more discriminative regions when taking local image patches as input compared to the whole input image. This suggests a proper way to improve the quality of attention maps by making use of local image patches.
2.