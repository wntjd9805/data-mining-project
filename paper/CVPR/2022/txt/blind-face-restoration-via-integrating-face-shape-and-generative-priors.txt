Abstract
Blind face restoration, which aims to reconstruct high-quality images from low-quality inputs, can benefit many applications. Although existing generative-based methods achieve significant progress in producing high-quality im-ages, they often fail to restore natural face shapes and high-fidelity facial details from severely-degraded inputs. In this work, we propose to integrate shape and generative pri-ors to guide the challenging blind face restoration. Firstly, we set up a shape restoration module to recover reason-able facial geometry with 3D reconstruction. Secondly, a pretrained facial generator is adopted as decoder to gener-ate photo-realistic high-resolution images. To ensure high-fidelity, hierarchical spatial features extracted from the low-quality inputs and rendered 3D images are inserted into the decoder with our proposed Adaptive Feature Fusion
Block (AFFB). Moreover, we introduce hybrid-level losses
* Chengjie Wang and Ying Tai are corresponding authors. to jointly train the shape and generative priors together with other network parts such that these two priors better adapt to our blind face restoration task. The proposed Shape and Generative Prior integrated Network (SGPN) can re-store high-quality images with clear face shapes and real-istic facial details. Experimental results on synthetic and real-world datasets demonstrate SGPN performs favorably against state-of-the-art blind face restoration methods. 1.

Introduction
Real-world low-quality face images suffer from un-known degradations during acquisition and Internet trans-mission. Blind Face Restoration (BFR) has been attracting considerable attention [2, 44, 52] due to its wide applica-tions in real-world scenarios, such as restoring old images and film footage. However, it is still challenging to restore a high-fidelity image with natural facial geometry and real-istic facial details from severely degraded face images.
Previous works exploit different kinds of facial priors to help face restoration, e.g., sparse constraints [6, 49, 54], parsing maps [2, 3, 43] and facial landmarks [3]. Addition-ally, the shape priors [15, 40] are adopted to guide face deblurring and super-resolution. However, they only han-dle specific image degradation, with over-smoothed results missing details. The resolutions (256 [40] and 128 [15]) are relatively low compared to recent methods. Besides, they first finetune the D3DFR [4] model on paired low- and high-quality images in advance before training their deblur-ring or super-resolution network. The finetuned model can not produce accurate 3D reconstructions for those LQ im-ages with extreme pose or severe degradation (see Fig. 3).
With the rapid progress of GAN-based high-quality face generation [7, 20, 22], it is observed that the learned convo-lution weights of generative networks are able to capture a distribution over high-quality images [8, 34]. Such gener-ative prior is adopted to produce visually realistic outputs from extremely low-quality images [8, 32, 34]. GPEN [52] and GFPGAN [44] further improve the fidelity by perform-ing spatial modulation on the features of the embedded face generator. Unfortunately, existing methods [44, 52] often overemphasize generation and hallucinate faces with unnat-ural facial components on severely-degraded images.
To address the challenges, we introduce a new blind face restoration network designed to achieve a good balance between face shape reconstruction and face detail genera-tion. The proposed Shape and Generative Prior integrated
Network (SGPN) consists of two modules: 1) Face shape restoration module. 2) The shape and generative prior inte-gration module. To restore the inherent face structure, we leverage a deep neural network (ResNet50 [13]) to predict the coefficients of 3D morphable face models (3DMMs [1]) from the low-quality input. The rendered 3D image con-tains natural and sharp face structures. The pretrained gen-erator of StyleGAN2 [23] is adopted as our decoder to gen-erate photo-realistic high-resolution image. We develop a dual-branch encoder to extract hierarchical spatial features from the low-quality inputs and its reconstructed result ren-dered from the predicted 3DMM coefficients. The spatial features are injected into the decoder progressively with a dedicated Adaptive Feature Fusion Block (AFFB), which learns a explicit weighting mask to adaptively fuse the spa-tial features from the dual-branch encoder.
The whole networks including shape and generative prior are jointly optimized with a combination of image-and mesh-level objectives. Specifically, the image-level loss favors pixel-level reconstruction and global realness, while the mesh-level loss encourages the face shape recovery. Ex-periments demonstrate that our method is able to recover realistic facial details and natural face shapes. In addition, our method can be easily generalized to face inpainting. In summary, the contributions of our work are as follows:
• To combine the merits of face shape and generative prior, we propose a blind face restoration framework to integrate them seamlessly. Our SGPN with adaptive feature fusion block achieves a good balance between face shape reconstruction and face detail generation.
• The face shape and generative priors are jointly opti-mized with other network parts to better facilitate the blind face restoration task.
• Extensive experiments demonstrate that our method achieves superior performance on both synthetic and real-world low-quality images, along with good gener-alization ability to face inpainting. 2.