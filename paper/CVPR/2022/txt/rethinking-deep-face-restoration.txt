Abstract
A model that can authentically restore a low-quality face image to a high-quality one can beneﬁt many applications.
While existing approaches for face restoration make sig-niﬁcant progress in generating high-quality faces, they of-ten fail to preserve facial features that compromise the au-thenticity of reconstructed faces. Because the human vi-sual system is very sensitive to faces, even minor changes may signiﬁcantly degrade the perceptual quality.
In this work, we argue that the problems of existing models can be traced down to the two sub-tasks of the face restoration problem, i.e. face generation and face reconstruction, and the fragile balance between them. Based on the observa-tion, we propose a new face restoration model that improves both generation and reconstruction. Besides the model improvement, we also introduce a new evaluation metric for measuring models’ ability to preserve the identity in the restored faces. Extensive experiments demonstrate that our model achieves state-of-the-art performance on multi-ple face restoration benchmarks, and the proposed metric has a higher correlation with user preference. The user study shows that our model produces higher quality faces while better preserving the identity 86.4% of the time com-pared with state-of-the-art methods. 1.

Introduction
Face images play a critical role in our daily life and are at the very center of success for many applications such as portrait taking, face identiﬁcation, etc. While these applica-tions usually rely on having decent quality faces as inputs, low-quality face images are inevitable in the real world due to various reasons, e.g. low image resolution, motion blur, defocus blur, sensor noises, encoding artifacts, etc. There-fore, a method that can faithfully restore a degraded face
∗Work done during an internship at Google Research. into a high-ﬁdelity one regardless of the type of degrada-tion is highly desired.
Much progress has been made in face restoration in the past few years, thanks to the rapid development of deep generative adversarial networks (GANs) [8]. Exist-ing works treat face restoration as a conditional image gen-eration problem, and they learn a U-Net model that pre-dicts a high-quality face image given a low-qualiy one as input [3, 20, 21, 23, 35, 36, 40]. Despite being able to gen-erate realistic faces, they still suffer from unique challenges introduced by face restoration. Speciﬁcally, they often fail to preserve delicate facial features in the input but instead hallucinate a high-quality face that does not resemble the original subject. The model may change the subject’s eye color, skin texture, shape of face components, etc, as shown in Figure 1. While these changes may be negligible in pixel space and are irrelevant to the realisticness, they are es-sential for authenticity and can signiﬁcantly impact down-stream applications. For example, they may break a face identiﬁcation system because the biometric characteristics deviate from the original subject, and they may degrade the perceptual quality of a photo because the subject looks like a different person.
We argue that the above issues are caused by the fragile balance between face generation and face reconstruction.
As we will show later, the face restoration problem can be interpreted as a combination of two sub-tasks, i.e. gener-ation and reconstruction, where face generation aims to learn the distribution of high quality faces and face recon-struction aims to capture the face characteristic (e.g. shape and texture) from an image regardless of its quality [5, 36].
A model that overemphasizes generation and fails in recon-struction may hallucinate a face that does not belong to the subject. In contrast, a model that fails in generation leads to unsatisfactory restoration quality. Therefore, a success-ful face restoration model has to address the two sub-tasks simultaneously, which remains to be realized.
Based on the observation, we propose a new model that aims to improve both generation and reconstruction. To
Input
DFDNet
GPEN
GFPGAN
Ours
GT
Figure 1. Problems of state-of-the-art face restoration models. GPEN [40] and GFPGAN [36] are biased toward face generation and may alter facial details (e.g. eye color) that are highly correlated with the identity. DFDNet [20] is biased toward reconstruction and does not remove all degradations. Our approach achieves the best balance and restore a high quality face while preserving the identity. improve face generation, we inject an adaptive conditional noise to the model, motivated by the great success of recent image generation models. The noises empower the restora-tion model with stochastic property and allow the model to capture the non-deterministic nature of the face restoration problem. To improve face reconstruction, we enhance the latent features in the skip connections by 1) quantizing the features using a codebook learned from high-quality images and 2) introducing a global feature fusion module for an adaptive combination of the features from the decoder and the skip connections. These improvements are based on the observations that the features extracted by the encoder may harm the reconstruction performance, especially when the input quality is poor. Finally, we explore the model archi-tecture, particularly the number of skip connections, to op-timize the balance between generation and reconstruction.
Like the models, the evaluation metrics for face restora-tion also suffer from overemphasizing either the genera-tion or the reconstruction aspect of the problem. Exist-ing works borrow either metrics designed for image gen-eration, e.g. Fr´echet inception distance (FID) [12], or met-rics developed for image reconstruction, e.g. Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), or Learned Perceptual Image Patch Similarity (LPIPS) [44].
They focus on the perceptual quality or the pixel similarity between the output and the target respectively, and neither of them was able to capture subtle changes in facial fea-tures. To this end, we propose a new metric that measures both image quality and content preservation, where content preservation is deﬁned by the ability to preserve the iden-tity. Experiment results demonstrate that the proposed met-ric better correlates with the perceptual quality of human raters in the face restoration problem.
The main contributions of this paper are as follows. First, we show that issues of existing face restoration models may be traced down to the two sub-tasks of the problem, i.e. face generation and face reconstruction. Second, we propose a new face restoration model by improving the model design for both sub-tasks. Finally, we introduce a new evaluation metric for face restoration that measures both the percep-tual quality and identity preservation. Empirical results on two benchmarks, blind face restoration (BFR) and super-resolution (SR), show that proposed model consistently out-performs state-of-the-art methods, and the proposed metric better correlates with the perceptual quality of human raters.
In addition, user study shows that our model is preferred by human raters 86.4% of the time compared with state-of-the-art face restoration models. 2.