Abstract
Weakly-supervised semantic segmentation (WSSS) with image-level labels is an important and challenging task.
Due to the high training efficiency, end-to-end solutions for
WSSS have received increasing attention from the commu-nity. However, current methods are mainly based on con-volutional neural networks and fail to explore the global information properly, thus usually resulting in incomplete object regions. In this paper, to address the aforementioned problem, we introduce Transformers, which naturally inte-grate global information, to generate more integral initial pseudo labels for end-to-end WSSS. Motivated by the inher-ent consistency between the self-attention in Transformers and the semantic affinity, we propose an Affinity from Atten-tion (AFA) module to learn semantic affinity from the multi-head self-attention (MHSA) in Transformers. The learned affinity is then leveraged to refine the initial pseudo labels for segmentation. In addition, to efficiently derive reliable affinity labels for supervising AFA and ensure the local con-sistency of pseudo labels, we devise a Pixel-Adaptive Re-finement module that incorporates low-level image appear-ance information to refine the pseudo labels. We perform extensive experiments and our method achieves 66.0% and 38.9% mIoU on the PASCAL VOC 2012 and MS COCO 2014 datasets, respectively, significantly outperforming re-cent end-to-end methods and several multi-stage competi-tors. Code is available at https://github.com/ rulixiang/afa. 1.

Introduction
Semantic segmentation, aiming at labeling each pixel
In the past in an image, is a fundamental task in vision.
*Corresponding author. This work was done when Lixiang Ru was a research intern at JD Explore Academy.
Figure 1. (a) Image and the query points (denote with ”⋆”) to vi-sualize the attention and affinity maps; (b) the self-attention maps in Transformer blocks only capture coarse semantic-level affin-ity relations; (c) the learned reliable semantic affinity from self-attention with our proposed method. decade, deep neural networks have achieved great success in semantic segmentation. However, due to the data-hungry nature of deep neural networks, fully-supervised semantic segmentation models usually require a large amount of data with labour intensive pixel-level annotations. To settle this problem, some recent methods seek to devise semantic seg-mentation models using weak/cheap labels, such as image-level labels [2, 25, 47, 23, 50, 27, 35], points [3], scribbles
[28, 54, 52], and bounding boxes [24]. Our method falls into the category of weakly-supervised semantic segmen-tation (WSSS) using only image-level labels, which is the most challenging one in all WSSS scenarios.
Prevailing WSSS methods with image-level labels com-monly adopt a multi-stage framework [35, 23, 22]. Specif-ically, these methods firstly train a classification model and 1
The learned affinity is then employed to revise the initial pseudo labels via random walk propagation [2, 1], which could diffuse object regions and dampen the falsely acti-vated regions. To derive highly-confident pseudo affinity labels for AFA and ensure the local consistency of the prop-agated pseudo labels, we further propose a Pixel-Adaptive
Refinement module (PAR). Based on the pixel-adaptive convolution [4, 37], PAR efficiently integrates the RGB and position information of local pixels to refine the pseudo la-bels, enforcing better alignment with low-level image ap-pearance. In addition, given the simplicity, our model can be trained in an end-to-end manner, thus avoiding a com-plex training pipeline. Experimental results on PASCAL
VOC 2012 [12] and MS COCO 2014 [29] demonstrate that our method remarkably surpasses recent end-to-end meth-ods and several multi-stage competitors.
In summary, our contributions are listed as follows.
• We propose an end-to-end Transformer-based framework for WSSS with image-level labels. To the best of our knowledge, this is the first work to explore Transformers for WSSS.
• We exploit the inherent virtue of Transformer and devise an Affinity from Attention (AFA) module. AFA learns reliable semantic affinity from MHSA and propagates the pseudo labels with the learned affinity.
• We propose an efficient Pixel-Adaptive Refinement (PAR) module, which incorporates the RGB and position information of local pixels for label refinement. 2.