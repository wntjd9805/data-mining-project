Abstract
It is an important task to reconstruct surfaces from 3D point clouds. Current methods are able to reconstruct sur-faces by learning Signed Distance Functions (SDFs) from single point clouds without ground truth signed distances or point normals. However, they require the point clouds to be dense, which dramatically limits their performance in real applications. To resolve this issue, we propose to re-construct highly accurate surfaces from sparse point cloud-s with an on-surface prior. We train a neural network to learn SDFs via projecting queries onto the surface repre-sented by the sparse point cloud. Our key idea is to in-fer signed distances by pushing both the query projections to be on the surface and the projection distance to be the minimum. To achieve this, we train a neural network to capture the on-surface prior to determine whether a point is on a sparse point cloud or not, and then leverage it as a differentiable function to learn SDFs from unseen sparse point cloud. Our method can learn SDFs from a single s-parse point cloud without ground truth signed distances or point normals. Our numerical evaluation under widely used benchmarks demonstrates that our method achieves state-of-the-art reconstruction accuracy, especially for sparse point clouds. Code and data are available at https:
//github.com/mabaorui/OnSurfacePrior. 1.

Introduction
Reconstructing surfaces from 3D point clouds is a vi-tal task in 3D computer vision. It bridges the gap between the data capturing and the surface editing for various down-stream applications. It has been studied for decades using geometric approaches [5, 28, 35, 44]. However, these meth-ods require extensive human interaction to set proper pa-rameters for different 3D point clouds, which leads to poor
∗The corresponding author is Yu-Shen Liu. This work was supported by National Key R&D Program of China (2018YFB0505400, 2020YF-F0304100), the National Natural Science Foundation of China (62072268), and in part by Tsinghua-Kuaishou Institute of Future Media Data. generalization ability. Therefore, the data-driven strategy becomes more promising to resolve this problem.
Recent learning based methods [11, 26, 32, 37, 54] lever-age this strategy to learn signed distance functions (SDF-s) from 3D point clouds, and further leverage the learned
SDFs to reconstruct surfaces using the marching cubes al-gorithm [35]. One kind of these methods [11, 26, 32] re-quires supervision including ground truth signed distances or point normals during training, and infers SDFs for un-seen 3D point clouds during test. To remove the require-ment of the ground truth supervision, another kind of meth-ods [1, 12, 37] can directly learn SDFs from single unseen 3D point cloud with geometric constraints [1, 12] or neu-ral pulling [37]. One key factor that makes these methods successful without the ground truth supervision is that the single point cloud should be dense, which supports to esti-mate the zero level set [12] or search accurate pulling target-s [37]. However, due to the high cost of dense point clouds capturing, the assumption of dense point clouds fails in real applications. Therefore, it is appealing but challenging to learn SDFs from sparse point clouds without ground truth signed distances or normals.
To resolve this issue, we introduce to learn SDFs from single sparse point clouds with an on-surface prior. For a surface represented by a sparse point cloud, we aim to per-ceive its surrounding signed distance ﬁeld via projecting an arbitrary query location onto the surface. Our novelty lies in the two constraints that we add on the projections, so that each projection locates on the surface and is the nearest to the query. This leads to two losses to train a neural network to learn SDFs. One loss is provided by the on-surface prior, which determines whether a projection is on the surface rep-resented by the sparse point cloud or not, even if the projec-tion is not a point of the sparse point cloud. While the other loss encourages the projection distance is the minimum to the surface. To achieve this, we train a neural network using a data-driven strategy to capture the on-surface prior from a dataset during training, and leverage the trained network as a differentiable function to learn SDFs for unseen sparse point clouds. For the learning of SDFs, our method does not
require ground truth signed distances or point normals, and enables highly accurate surface reconstruction from sparse point clouds. We show our superior performance over the state-of-the-art methods by numerical and visual compari-son under the widely used benchmarks. Our contributions are listed below. i) We propose a method to learn SDFs from sparse point clouds without ground truth signed distances or point normals. ii) We introduce an on-surface prior which can determine the relationship between a point and a sparse point cloud, and further be used to train another network to learn SDFs. iii) Our method signiﬁcantly outperforms the state-of-the-art methods in terms of surface reconstruction accuracy under large-scale benchmarks. 2.