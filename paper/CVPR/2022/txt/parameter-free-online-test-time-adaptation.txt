Abstract
Training state-of-the-art vision models has become pro-hibitively expensive for researchers and practitioners. For the sake of accessibility and resource reuse, it is important to focus on adapting these models to a variety of down-stream scenarios. An interesting and practical paradigm is online test-time adaptation, according to which training data is inaccessible, no labelled data from the test distri-bution is available, and adaptation can only happen at test time and on a handful of samples. In this paper, we inves-tigate how test-time adaptation methods fare for a number of pre-trained models on a variety of real-world scenarios, signiﬁcantly extending the way they have been originally evaluated. We show that they perform well only in narrowly-deﬁned experimental setups and sometimes fail catastroph-ically when their hyperparameters are not selected for the same scenario in which they are being tested. Motivated by the inherent uncertainty around the conditions that will ultimately be encountered at test time, we propose a partic-ularly “conservative” approach, which addresses the prob-lem with a Laplacian Adjusted Maximum-likelihood Esti-mation (LAME) objective. By adapting the model’s out-put (not its parameters), and solving our objective with an efﬁcient concave-convex procedure, our approach ex-hibits a much higher average accuracy across scenarios than existing methods, while being notably faster and have a much lower memory footprint. The code is available at https://github.com/fiveai/LAME. 1.

Introduction
In recent years, training state-of-the-art models has be-come a massive computational endeavor for many machine learning problems (e.g. [5, 13, 38]). For instance, it has been estimated that each training of GPT-3 [5] produces an equivalent of 552 tons of CO2, which is approximately the amount emitted in six ﬂights from New York to San Fran-cisco [35]. As implied in the whitepaper on “foundation
*Work done as part of a research internship at FiveAI. Corresponding author: malik.boudiaf.1@etsmtl.net models” [4], we should expect that more and more efforts will be dedicated to the design of procedures that allow for the efﬁcient adaptation of pre-trained large models under a variety of circumstances. In other words, these models will be “trained once” on a vast dataset and then adapted at test time to newly-encountered scenarios. Besides be-ing important for resource reuse, being able to abstract the pre-training stage away from the adaptation is paramount in privacy-focused applications, and in any other situation in which preventing access to the training data is desirable. To-wards this goal, it is important that, from the point of view of the adaptation system, there is neither access to the train-ing data nor the training procedure of the model to adapt.
With this context in mind, we are particularly interested in designing adaptation methods ready to be used in realistic scenarios, and that are suitable for a variety of models.
One aspect that many real-world applications have in common is the need to perform adaptation online, and with a limited amount of data. That is, we should be able to per-form adaptation while the data is being received. Take for instance the vision model with which an autonomous vehi-cle or a drone may be equipped. At test-time, it will ingest a video stream of highly-correlated data (non-i.i.d.), which could be used for adaptation. We would like to be con-ﬁdent that leveraging this information will be useful, and not destructive, no matter the type of domain shift that may exist between training and test data. Such shifts could be, for instance, “low-level” (e.g. the data stream is affected by snowy weather which has never been encountered during the California-sunlit training stage), or “high-level” (e.g. the data include the particular Art Deco architecture of Miami
Beach’s Historic District), or even a combination of both.
To summarize, we are interested in the design of test-time adaptation systems that 1) are unsupervised; 2) can oper-ate online and on potentially non-i.i.d. data; 3) assume no knowledge of training data or training procedure; and 4) are not tailored to a certain model, so that the progress made by the community can be directly harnessed.
This problem speciﬁcation falls under the fully test-time adaptation paradigm studied in a handful of recent works [1, 27, 29, 56], where simple techniques like test-time
learning of batch normalization’s scale and bias parame-ters [56] have proven to be very effective in some scenar-ios, like the one represented by low-level corruptions [17].
In our experimental results, we observe that existing meth-ods [25, 27, 29, 56] have to be used with great care in un-certain yet realistic situations because of their sensitivity to variables such as the model to adapt or the type of domain shift. As a matter of fact, we show that, when selecting their hyperparameters to maximize the average accuracy over a number of scenarios, existing methods do not outperform a non-adaptive baseline. For them to perform well, hyperpa-rameters need to be adjusted in a scenario-speciﬁc fashion.
However, this is clearly not an option when the test-time conditions are unknown in advance.
These ﬁndings suggest that, while being agnostic to both training and testing circumstances is important, it is wise to approach the problem of test-time adaptation prudently.
Instead of adapting the parameters of a pre-trained model, we only adapt its output by ﬁnding the latent assignments that optimize a manifold-regularized likelihood of the data.
The manifold-smoothness assumption has been successful in a wide range of other problems, including graph cluster-ing [45,46,52], semi-supervised learning [2,7,19], and few-shot learning [62], as it enforces desirable and general prop-erties on the solutions. Speciﬁcally, we embed Laplacian regularization as a corrective term, and derive an efﬁcient concave-convex procedure for optimizing our overall objec-tive, with guaranteed convergence. When aggregating over different conditions, this simple and “conservative” strategy signiﬁcantly improves both over the non-adaptive baseline and existing test-time adaptation methods in an extensive set of experiments covering 7 datasets, 19 shifts, 3 training strategies and 5 network architectures. Moreover, by virtue of not performing model adaptation but only output correc-tion, it reduces by half both the total inference time and the memory footprint compared to existing methods. 2.