Abstract
In this work, we propose a framework for single-view hand mesh reconstruction, which can simultaneously achieve high reconstruction accuracy, fast inference speed, and temporal coherence. Specifically, for 2D encoding, we propose lightweight yet effective stacked structures.
Regarding 3D decoding, we provide an efficient graph oper-ator, namely depth-separable spiral convolution. Moreover, we present a novel feature lifting module for bridging the gap between 2D and 3D representations. This module begins with a map-based position regression (MapReg) block to integrate the merits of both heatmap encoding and position regression paradigms for improved 2D accuracy and temporal coherence. Furthermore, MapReg is followed by pose pooling and pose-to-vertex lifting approaches, which transform 2D pose encodings to semantic features of 3D vertices. Overall, our hand reconstruction frame-work, called MobRecon, comprises affordable computa-tional costs and miniature model size, which reaches a high inference speed of 83FPS on Apple A14 CPU. Extensive experiments on popular datasets such as FreiHAND, RHD, and HO3Dv2 demonstrate that our MobRecon achieves superior performance on reconstruction accuracy and tem-poral coherence. Our code is publicly available at https:
//github.com/SeanChenxy/HandMesh. 1.

Introduction
Single-view hand mesh reconstruction has been exten-sively investigated for years due to its wide range of appli-cations in AR/VR [24, 65], behavior understanding [36, 56], etc. Tremendous research efforts have been made towards this task, including [15, 79, 42, 75], to name a few.
The primary focus of typical existing methods is the reconstruction accuracy [45, 46], while real-world appli-cations additionally necessitate inference efficiency and
In particular, 3D hand information temporal consistency.
*Corresponding author, chenxingyu@kuaishou.com
Figure 1. Accuracy vs. inference speed. The marker size is related to the model size. Besides, our tailored method can run at a fast speed on mobile CPUs. is a vital component in mobile applications [65], where the devices comprise limited memory and computational budgets. Thereby, this work aims to explore 3D hand reconstruction for mobile platforms.
A typical pipeline for single-view hand reconstruction includes three phases: 2D encoding, 2D-to-3D mapping, and 3D decoding. In 2D encoding, existing approaches [42, 9, 45, 46] usually adopt computationally intensive networks
[26, 67] to handle this highly non-linear task, which are hard to deploy on mobile devices. Instead, if naively leveraging a mature mobile network (e.g., [28]) which is not tailored for our target task, the reconstruction accuracy dramatically degrades [18]. Hence, our motivation is to develop a lightweight 2D encoding structure tailored to balance the inference efficiency and accuracy. Besides, the efficiency of 2D-to-3D mapping and 3D decoding remains relatively unexplored. Thus, we intend to explore a lightweight yet effective lifting method to tackle the 2D-to-3D mapping problem and design an efficient graph operator for process-ing of 3D mesh data.
Although as crucial as accuracy in real-world applica-tions, temporal coherence is usually neglected in the task of 3D hand reconstruction. Previous methods [11, 37, 41, 49] adopt sequential models to incorporate both past and future
semantic information for stable predictions. Since this methodology is offline or computationally expensive, these approaches are difficult to use for mobile applications.
Hence, we are inspired to explore the temporal coherence with a non-sequential method.
In this work, we propose Mobile Mesh Reconstruction (MobRecon) for 3D hand to simultaneously explore supe-rior accuracy, efficiency, and temporal coherence. For 2D encoding, we leverage the spirit of the hourglass network
[55] to design efficient stacked encoding structures. As for 3D decoding, we propose a depth-separable spiral convo-lution (DSConv), which is a novel graph operator based on spiral sampling [44]. The DSConv is inspired by depth-wise separable convolution [29], leading to efficient handling of graph-structured mesh data. Regarding the 2D-to-3D mapping, we propose a feature lifting module with map-based position regression (MapReg), pose pooling, and pose-to-vertex lifting (PVL) approaches. In this module, we first investigate the pros and cons of 2D pose representations based on heatmap or position regression, and then propose a hybrid method MapReg to simultaneously improve 2D pose accuracy and temporal consistency. Furthermore, the
PVL transforms 2D pose encodings to 3D vertex features based on a learnable lifting matrix, resulting in enhanced 3D accuracy and temporal consistency. Compared to tra-ditional approaches based on fully connected operation in a latent space [42, 15, 9], our feature lifting module also significantly reduces the model size. In addition, we build a synthetic dataset with uniformly distributed hand poses and viewpoints. Referring to Figure 1, we achieve better performance in terms of accuracy, speed, and model size.
Our main contributions are summarized as follows:
• We propose MobRecon as a mobile-friendly pipeline for hand mesh reconstruction, which only involves 123M multiply-add operations (Mult-Adds) and 5M parameters and can run up to 83FPS on Apple A14 CPU.
• We present lightweight stacked structures and DSConv for efficient 2D encoding and 3D decoding.
• We propose a novel feature lifting module with MapReg, pose pooling, and PVL methods to bridge the 2D and 3D representations.
• We demonstrate that our method achieves superior per-formance in terms of model efficiency, reconstruction ac-curacy, and temporal coherence via comprehensive evalu-ations and comparisons with state-of-the-art approaches. 2.