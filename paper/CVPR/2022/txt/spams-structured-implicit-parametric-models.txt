Abstract
Parametric 3D models have formed a fundamental role in modeling deformable objects, such as human bodies, faces, and hands; however, the construction of such para-metric models requires significant manual intervention and domain expertise. Recently, neural implicit 3D represen-tations have shown great expressibility in capturing 3D shape geometry. We observe that deformable object mo-tion is often semantically structured, and thus propose to learn Structured-implicit PArametric Models (SPAMs) as a deformable object representation that structurally decom-poses non-rigid object motion into part-based disentangled representations of shape and pose, with each being repre-sented by deep implicit functions. This enables a structured characterization of object movement, with part decomposi-tion characterizing a lower-dimensional space in which we can establish coarse motion correspondence.
In particu-lar, we can leverage the part decompositions at test time to fit to new depth sequences of unobserved shapes, by estab-lishing part correspondences between the input observation and our learned part spaces; this guides a robust joint opti-mization between the shape and pose of all parts, even un-der dramatic motion sequences. Experiments demonstrate that our part-aware shape and pose understanding lead to state-of-the-art performance in reconstruction and tracking of depth sequences of complex deforming object motion. 1.

Introduction
Understanding non-rigidly deforming shapes is essen-tial for perception, as we live in a 4D world where humans, animals, and other 3D objects move in a non-rigid fash-ion. Dynamic tracking and reconstruction remains a notable challenge, and while significant advances have been made in 4D reconstruction and tracking, they often require com-plex multi-view setups [5] or build on a domain-specific,
*This work was conducted during an internship at Meta RL Research.
fixed-topology template [1,4,35,36]. In the latter case, para-metric 3D models in particular have made notable impact in modeling domain-specific deformable 3D objects, such as for human bodies [2, 20, 23], faces [22, 34], hands [40], and animals [51]. However, such parametric 3D models require a complex construction process involving domain-specific knowledge and manual efforts, while remaining limited in expressability of local shape details.
Recently, advances in learned continuous implicit repre-sentations for modeling 3D shapes have shown impressive representation power for capturing effective static 3D shape geometry at relatively high resolutions [7, 8, 17, 28, 29, 33, 39]. Such approaches have also been extended to represent 4D reconstruction of dynamic objects by efficiently disen-tangling learned implicit spaces representing shape and dy-namic movement [31, 32]. This has proven to be a very promising direction, but these approaches characterize ob-jects as a whole, whereas we observe that the 4D motion of an object typically maintains a strong structured correlation on a lower-level part basis.
Thus, we propose Structured-implicit PArametric Mod-els (SPAMs), which learn a structured, part-based, disentan-gled representation of deformable 3D objects. Given a set of observations of various shape identities in different poses (including a canonical pose) with coarse part annotations, we learn part-based latent spaces characterizing each part’s geometry and motion. Note that we do not require compre-hensive surface correspondence throughout the dataset, nor complex domain-specific knowledge (e.g., skeleton, kine-matic chain). We leverage continuous implicit function representations for each part’s geometry, represented as a signed distance field in its canonical space, and pose, repre-sented as a local deformation relative to the canonical space.
At test time, we traverse the learned latent part spaces to fit to new depth sequences. Crucially, our part-based representation allows leveraging predicted part segmenta-tion of the new observation to establish global correspon-dences with our part-based latent representations. By estab-lishing correspondence through our part priors, we can ro-bustly track sequences with significant motion changes by discovering high-level part correspondence and leveraging it to guide our joint optimization over part-based shape and pose. Experiments on non-rigid tracking and reconstruc-tion of single-camera depth sequences of humans from the
RenderPeople dataset [12] show that the part-aware reason-ing of our SPAMs can outperform the state of the art by an order of magnitude on reconstruction (Chamfer distance) and by 43% on tracking (3D End-Point-Error). In summary, we present the following contributions:
• We learn a part-based disentanglement of shape and pose, capturing local characteristics of deformable 3D objects in latent spaces representing shape and pose of each part.
• Our learned, optimizable spaces enable part-based rea-soning to guide joint optimization over parts to fit unseen test sequences. By establishing high-level part correspon-dence between a new observation and our learned part spaces, we can robustly guide a joint optimization over part geometry and pose, resulting in a more globally con-sistent non-rigid reconstruction and tracking. 2.