Abstract
Learning behavioral patterns from observational data has been a de-facto approach to motion forecasting. Yet, the current paradigm suffers from two shortcomings: brittle under distribution shifts and inefficient for knowledge trans-fer. In this work, we propose to address these challenges from a causal representation perspective. We first introduce a causal formalism of motion forecasting, which casts the problem as a dynamic process with three groups of latent variables, namely invariant variables, style confounders, and spurious features. We then introduce a learning frame-work that treats each group separately: (i) unlike the com-mon practice mixing datasets collected from different loca-tions, we exploit their subtle distinctions by means of an invariance loss encouraging the model to suppress spuri-ous correlations; (ii) we devise a modular architecture that factorizes the representations of invariant mechanisms and style confounders to approximate a sparse causal graph; (iii) we introduce a style contrastive loss that not only en-forces the structure of style representations but also serves as a self-supervisory signal for test-time refinement on the fly. Experiments on synthetic and real datasets show that our proposed method improves the robustness and reusabil-ity of learned motion representations, significantly outper-forming prior state-of-the-art motion forecasting models for out-of-distribution generalization and low-shot transfer. 1.

Introduction
Motion forecasting is essential for autonomous systems running in dynamic environments. Yet, it is a challeng-ing task due to strong spatial-temporal interactions, which arise from two major sources: (i) physical laws (e.g., in-ertia, goal-directed behaviors) that govern general dynam-ics; (ii) social norms (e.g., separation distance, left or right-hand traffic) that influence motion styles. Classical mod-els attempt to describe these interactions based on domain knowledge but often fall short of social awareness in com-plex scenes [16, 31, 76]. As an alternative, learning motion representations from observational data has become a de-*Riccardo and Jonas contributed similarly to this work
Figure 1.
Illustration of motion forecasting under environment changes. We introduce a framework that enables deep motion rep-resentations to robustly generalize to non-causal shifts of spurious features, e.g., agent density, and efficiently adapt to new motion styles, e.g., from right to left-hand traffic. facto approach [2,49,65]. In light of rapid progress over the past few years, solving motion forecasting is seemingly just around the corner by pursuing this fashion at larger scales.
However, the promise of the current learning paradigm for motion forecasting is shadowed by two shortcomings:
• struggle to discover physical laws from data, e.g., output inadmissible solutions under spurious shifts [63];
• inefficient for knowledge transfer, e.g., require a large number of observations to adapt from one environment to another even if the underlying change is sparse [18].
These issues do not become any less severe with larger mod-els [64]. Instead, they are profoundly rooted in the princi-ple of statistical learning that only seeks correlations for the prediction task at hand, regardless of their robustness and reusability under distribution shifts that may occur in prac-tice (illustrated in Figure 1)
In this work, we aim to tackle these challenges from a causal representation perspective. Incorporating causal re-lations into statistical modeling has garnered growing inter-est lately, as it not only offers a mathematical language to articulate distribution changes [56, 59] but also brings crit-ical insights to representation learning [21, 68, 81]. Studies in cognitive science have also revealed its paramount im-portance in the motion context: few-month-old infants are already able to reason sensibly about physical and social causalities [67]; they can even learn that by sorely observing adult behaviors, without any hands-on experience of their own [79]. How can we build learning algorithms capable of acquiring such causal knowledge in the same way?
To this end, we introduce a new formalism of motion forecasting that describes human motion behaviors as a dy-namical process with three groups of latent variables: (i) domain-invariant causal variables that account for the phys-ical laws universal to everyone at any place, (ii) domain-specific confounders associated with motion styles, which may vary from site to site, (iii) non-causal spurious fea-tures, whose correlations with future motions may change drastically under different conditions. This causal formal-ism motivates us to treat each group distinctively with the following three components.
First, we propose to promote causal invariance of the learned motion representations by seeking the common-alities across multiple domains. Oftentimes, the training dataset is not collected from a single place but comprises multiple subsets from different locations. Previous work typically merges them into a larger one, e.g., the notable
ETH-UCY datasets [40, 57]. However, each subset is often inherently different [13]. Directly combining them not only entails a risk of biases but also destroys the critical infor-mation about the stability of correlations. To address this issue, we train motion forecasting models with a penalty on the variation of empirical risks across environments. This regularizer encourages the model to suppress spurious fea-tures and only exploit causally invariant ones. As a conse-quence, the resulting model is close to equally optimal in all environments – both the ones seen during training and those unseen encountered at test – for robust generalization.
Second, we design a modular architecture that factorizes the representations of invariant mechanisms and style con-founders in a structural way. One unique property of mo-tion problems is that the style confounder may also vary across environments, but constitute an indispensable part of causal variables for human motions. To explicitly model their impact, we devise an architecture that contains two encoders responsible for the invariant mechanisms and style confounders separately. This modular design approximates the sparse causal graph [54] in our motion formalism, en-abling the model to precisely localize and adapt a small sub-set of parameters to account for the underlying style shift.
Third, we introduce a style contrastive loss to further strengthen the modular structure of motion styles. Specif-ically, we introduce an auxiliary contrastive task that en-courages the style encoder to produce an embedding space capturing style relations between different scenes through a simple distance measure. This peculiar form of discrimina-tive task does not impose prior assumptions on the number of style classes, and is hence particularly suitable for incre-mental knowledge transfer to new motion styles. Moreover, when the predicted output is sub-optimal, the style con-trastive loss can naturally serve as a self-supervisory signal for test-time refinement on the fly [5, 41–43, 71]. By tightly coupling the modular architecture design with the style con-trastive loss, our method makes effective use of the knowl-edge stored in the style encoder during both training and deployment.
We evaluate the proposed method in two settings: syn-thetic simulation datasets and controlled real-world exper-iments.
In the presence of spurious correlations, motion forecasting models trained by our invariant loss demonstrate superior out-of-distribution (OOD) generalization ability over previous methods. Under variations of motion styles, our proposed modular architecture and style loss greatly im-prove the transferability of forecasting models in the low-shot setting. We hope our findings will pave the way for a tight integration of causal modeling and representation learning in the motion context, a largely under-explored yet highly promising direction towards reliable and adaptive au-tonomy. Our code is available at https://github. com/vita-epfl/causalmotion. 2.