Abstract
In this paper, we study the problem of stereo matching from a pair of images with different resolutions, e.g., those acquired with a tele-wide camera system. Due to the dif-ficulty of obtaining ground-truth disparity labels in diverse real-world systems, we start from an unsupervised learn-ing perspective. However, resolution asymmetry caused by unknown degradations between two views hinders the effec-tiveness of the generally assumed photometric consistency.
To overcome this challenge, we propose to impose the con-sistency between two views in a feature space instead of the image space, named feature-metric consistency. Inter-estingly, we find that, although a stereo matching network trained with the photometric loss is not optimal, its feature extractor can produce degradation-agnostic and matching-specific features. These features can then be utilized to for-mulate a feature-metric loss to avoid the photometric incon-sistency. Moreover, we introduce a self-boosting strategy to optimize the feature extractor progressively, which further strengthens the feature-metric consistency. Experiments on both simulated datasets with various degradations and a self-collected real-world dataset validate the superior per-formance of the proposed method over existing solutions. 1.

Introduction
Tele-wide camera systems consisting of two (or more) lenses with different focal lengths are widely deployed in smartphones nowadays. This kind of systems usually gen-erates a pair (or a set) of images with different resolutions at one shot, which enables a number of desirable applications, such as continuous optical zoom [29] and image quality en-hancement [37, 41, 43]. For these applications, correspon-dence estimation from resolution-asymmetric stereo images is a key step, which is typically conducted by conventional symmetric stereo matching algorithms (e.g., SGM [13]) to-gether with image upsampling [29]. However, this straight-*Corresponding author: zwxiong@ustc.edu.cn
Figure 1. The common assumption of photometric consistency (i.e., IL[pL]=IR[pR]) in symmetric stereo is violated in resolution-asymmetric stereo (represented by dense and sparse grids). To avoid such photometric inconsistency (i.e., IL[pL]̸=Ir↑[pr↑]), we establish the feature-metric consistency, which ensures that the pixels (e.g., pL and pr↑), recording the light rays (red arrows) emitted from the same scene point (e.g., P), have the same fea-ture representation (i.e., FL[pL]=Fr↑[pr↑]). forward solution is vulnerable to the artifacts introduced by upsampling, especially when the upsampling scale is large.
Asymmetric stereo matching has been studied in litera-ture under several specific contexts, e.g., radiometric vari-ation [15] and modality difference [49]. In this paper, we focus on the resolution-asymmetric setting, which is practi-cal yet has rarely been investigated explicitly. As a recent related work, Liu et al. propose a unified network for visu-ally imbalanced stereo matching that addresses monocular blur and noise [25]. Despite of its inspiring idea, this fully supervised approach requires not only the ground-truth dis-parity and the high-quality version of the degraded view as labels but also the explicit degradation [3,7,17,42,44] form to learn the parameters of the network, making it difficult to be applicable in diverse real-world systems where the su-pervision information is seldom available. Therefore, we turn to the direction of unsupervised learning.
For unsupervised stereo matching, the most widely
adopted assumption is photometric consistency [50]. Under this assumption, the corresponding pixels in two views (e.g., pL and pR in Fig. 1(a)), which record the light rays emitted from the same scene point (e.g., P), should have the same intensity or color (i.e., IL[pL]=IR[pR]). Unfortunately, this assumption is violated for a resolution-asymmetric stereo pair, where the low-resolution (LR) view is degraded by an unknown downsampling kernel compared to the high-In other words, the corresponding resolution (HR) view. 1 in pixels in the asymmetric stereo pair (e.g., pL and pr↑
Fig. 1(b)) may not have the same intensity or color (i.e.,
IL[pL]̸=Ir↑[pr↑]). Such photometric inconsistency will re-sult in difficulties for correspondence learning. A possi-ble solution for remedy is to restore the LR view to an HR one by super-resolution (SR) techniques [10, 26, 48]. How-ever, existing SR methods are mostly degradation-specific and suffer from performance drops if the real degradation is different from the assumed one (for non-blind SR) or not inside the assumed range (for blind SR) [4,6,23,47]. There-fore, the effectiveness of SR methods to make up the pho-tometric inconsistency will be hindered in practice.
To overcome the above challenge, we propose to solve resolution-asymmetric stereo matching from a new per-spective by imposing the consistency of two views in a feature space instead of the image space, named feature-metric consistency. Interestingly, we find that, although a stereo matching network trained with the photometric loss is not optimal, its feature extractor can produce degradation-agnostic (i.e., robustness to the degradation between IL and Ir↑) and matching-specific features for correspond-ing asymmetric pixels (i.e., FL[pL]=Fr↑[pr↑] in Fig. 1(b)).
These features can then be utilized to formulate a feature-metric loss to avoid the photometric inconsistency. More-over, by finetuning the stereo matching network using the feature-metric loss, we can optimize the feature extractor to capture more consistent properties from the stereo pair, strengthening the feature-metric consistency. To this end, we introduce a self-boosting strategy to optimize the fea-ture extractor progressively. Specifically, we use the fea-ture extractor learned from the previous stage to form a new feature-metric loss for the current stage. In this way, our method remains effective even for large degradations.
To quantitatively evaluate the performance of our method, we simulate four resolution-asymmetric stereo datasets, two from the widely used stereo datasets Middle-bury [14] and KITTI2015 [28] and two from the light field datasets Inria SLFD [32] and HCI [16] with a narrow base-line between two views which is closer to the configura-tion on smartphones. The LR view is generated under vari-ous degradations from its original HR version. To evaluate our method in real-world scenarios, we collect a resolution-asymmetric stereo dataset with the tele-wide camera system 1↑ denotes upsampling. equipped on a Huawei P30 smartphone. Experimental re-sults on both simulated and real-world datasets demonstrate that our method outperforms existing as well as potential solutions by a large margin.
Contributions of this paper are summarized as follows:
• The first unsupervised learning method for correspon-dence estimation from resolution-asymmetric stereo.
• An effective and efficient realization of feature-metric consistency to avoid photometric inconsistency caused by unknown degradations.
• A self-boosting strategy to strengthen feature-metric con-sistency by progressive loss update.
• Distinct performance improvements over comparison methods on both simulated and real-world datasets. 2.