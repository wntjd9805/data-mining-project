Abstract
Self-supervised learning has shown its great potential to extract powerful visual representations without human an-notations. Various works are proposed to deal with self-supervised learning from different perspectives: (1) con-trastive learning methods (e.g., MoCo, SimCLR) utilize both positive and negative samples to guide the training direc-tion; (2) asymmetric network methods (e.g., BYOL, Sim-Siam) get rid of negative samples via the introduction of a predictor network and the stop-gradient operation; (3) fea-ture decorrelation methods (e.g., Barlow Twins, VICReg) instead aim to reduce the redundancy between feature di-mensions. These methods appear to be quite different in the designed loss functions from various motivations. The ﬁ-nal accuracy numbers also vary, where different networks and tricks are utilized in different works. In this work, we demonstrate that these methods can be uniﬁed into the same form. Instead of comparing their loss functions, we derive a uniﬁed formula through gradient analysis. Furthermore, we conduct fair and detailed experiments to compare their performances. It turns out that there is little gap between these methods, and the use of momentum encoder is the key factor to boost performance.
From this uniﬁed framework, we propose UniGrad, a simple but effective gradient form for self-supervised learn-ing.
It does not require a memory bank or a predictor network, but can still achieve state-of-the-art performance and easily adopt other training strategies. Extensive experi-ments on linear evaluation and many downstream tasks also show its effectiveness. Code shall be released.
∗Equal contribution.
†This work is done when Chenxin Tao,
Honghui Wang, and Jiahua Dong are interns at SenseTime Research.
BCorresponding author.
Figure 1. Overview of three typical types of self-supervised learn-ing methods and our proposed UniGrad. u1 and u2 are two aug-mented views of the same image. v denote views of other images.
We ﬁnd these methods have a similar gradient structure composed of the positive and negative gradients, which can be analogous to positive and negative samples in contrastive learning. Because some methods do not explicitly utilize negative samples, we high-light the source of negative gradient in each method. 1.

Introduction
Self-supervised learning (SSL) has recently attracted much research interest [1, 6, 8, 17, 21, 34]. It has shown the potential to extract powerful visual representations that are competitive with supervised learning, and delivered supe-rior performance on multiple visual tasks.
Recent works deal with SSL from different points of view, leading to three typical types of methods (see Fig-ure 1), while siamese networks are always employed. Con-trastive Learning methods [6,7,9,17] aim to reduce the dis-tance between two augmented views from the same image (positive samples), and push apart views from different im-ages (negative samples). Negative samples play an impor-tant role in these methods to avoid representational collapse.
Asymmetric Network methods [8, 21] claim that only adopt-ing positive samples is sufﬁcient. The key is the introduc-tion of asymmetric network architecture. In these methods, a predictor network is only appended after one branch of the siamese network, and the other branch is detached from the gradient back-propagation. Although these methods have achieved impressive performance, they are still poorly un-derstood. Recent work [28] has tried to analyze their train-ing dynamics, but still lacks a straight-forward explana-tion. Feature Decorrelation methods [1, 13, 20, 34] have recently been proposed as a new solution for SSL. They in-stead focus on reducing the redundancy between different feature dimensions. These methods seem to be highly dif-ferent in how to learn representations, and it’s also hard to compare their performances because different networks and tricks are utilized in different works. With so many differ-ent methods, it is natural to ask: What is the relationship among them? Are there any connections among the work-ing mechanisms behind them? What factors actually cause the performance difference?
In this work, we unify the aforementioned three typical types of SSL methods in a uniﬁed framework. Instead of comparing their loss functions, the uniﬁed formula is de-rived through gradient analysis. We ﬁnd that all these meth-ods have similar gradient formulas. They consist of three components: the positive gradient, the negative gradient and a scalar that balances these two terms. The positive gradi-ent is the representation of another augmented view from the same image, while the negative gradient is a weighted combination of the representations from different images.
The effects of these two terms are similar to that of positive and negative samples in contrastive learning methods. This suggests that these methods share a similar working mech-anism, but organize the loss functions in different manners.
Moreover, since these methods are different in the speciﬁc formula of the gradient, we conduct fair and detailed exper-iments for comparison. It turns out that different gradient formulas result in close performance, and what really mat-ters is the use of momentum encoder.
From this uniﬁed framework, we propose a concise but effective gradient formula named UniGrad, which explic-itly maximizes the similarity between positive samples and expects the similarity between negative samples to be zero.
This formula does not require memory bank or asymmet-ric network, and can easily adopt prevalent augmentation strategies (e.g., CutMix [33] and multi-crop [4, 5]) to fur-ther improve the performance. Extensive experiments show that our method is competitive on various tasks, including the standard linear evaluation protocol, the semi-supervised learning task and various downstream vision tasks. Our contribution can be summarized as:
• A uniﬁed framework is proposed for different self-supervised learning methods through the perspective of gradient analysis. This shows that although previ-ous works seem to be distinct in loss functions, they actually work in a similar mechanism;
• Different self-supervised learning methods are com-pared under a fair and controlled experiment setting.
The results show that they can achieve similar perfor-mance, while the momentum encoder is actually the key factor affecting the ﬁnal performance;
• UniGrad is proposed as a concise but effective gradient formula for self-supervised learning. Extensive exper-iments demonstrate its competitive performance. 2.