Abstract
Fitting geometric models onto outlier contaminated data is provably intractable. Many computer vision systems rely on random sampling heuristics to solve robust fitting, which do not provide optimality guarantees and error bounds. It is therefore critical to develop novel approaches that can bridge the gap between exact solutions that are costly, and fast heuristics that offer no quality assurances. In this pa-per, we propose a hybrid quantum-classical algorithm for robust fitting. Our core contribution is a novel robust fit-ting formulation that solves a sequence of integer programs and terminates with a global solution or an error bound.
The combinatorial subproblems are amenable to a quan-tum annealer, which helps to tighten the bound efficiently.
While our usage of quantum computing does not surmount the fundamental intractability of robust fitting, by provid-ing error bounds our algorithm is a practical improvement over randomised heuristics. Moreover, our work represents a concrete application of quantum computing in computer vision. We present results obtained using an actual quantum computer (D-Wave Advantage) and via simulation1. 1.

Introduction
Imperfections in sensing and processing in computer vi-sion inevitably generate data that contain outliers. There-fore, it is necessary for vision pipelines to be robust against outliers in order to mitigate their harmful effects.
In 3D vision, where a major goal is to recover the scene structure and camera motion, a basic task is to fit a geo-metric model onto noisy and outlier prone measurements.
This is often achieved through the consensus maximisation framework [18]: given N data points D = {pi}N i=1 and a target geometric model parametrised by x ∈ Rd, let PN be the power set of index set {1, . . . , N }. We aim to solve max
I∈PN , x∈Rd s.t.
|I| ri(x) ≤ ϵ ∀i ∈ I, (1) 1Source code: https://github.com/dadung/HQC-robust-fitting where ri(x) is the residual of point pi w.r.t. x, and ϵ is a given inlier threshold. The form of ri(x) depends on the specific geometric model (more details in Sec. 3). A can-didate solution (I, x) consists of a consensus set I and its
“witness” (an estimate) x, where the points in I are the in-liers of x. Problem (1) seeks the maximum consensus set
I ∗, whose witness x∗ is a robust estimate of the model2.
Many computer vision systems employ random sam-pling heuristics, i.e., RANSAC [32] and its variants (e.g., [5, 6, 20, 57, 68, 69]), for consensus maximisation. The ba-sic idea is to repeatedly fit the model on randomly sam-pled minimal subsets of D, and return the ˜x with the largest consensus set ˜I. Such heuristics can only approximate (1) and generally do not provide optimality guarantees or er-ror characterisation, e.g., a tight bound on the discrepancy
|I ∗| − |˜I|. Moreover, ˜x is subject to randomness, and post-processing or reruns are often executed to vet the result.
Unfortunately, consensus maximisation is provably in-tractable [4, 16], hence there is little hope in finding effi-cient algorithms that can solve it exactly. While there has been active research into globally optimal algorithms [13, 17, 44, 54, 55], such techniques are realistic only for small input instances (small d, N and/or number of outliers [17]).
Bridging the gap between exact algorithms that are costly and randomised heuristics that offer no quality as-surances is an important research direction in robust fitting with practical ramifications. Towards this aim, determinis-tic approximate algorithms [14, 41, 42, 59, 73] eschew ex-haustive search (e.g., branch-and-bound) and randomisa-tion, and instead adopt deterministic subroutines such as convex optimisation, proximal splitting, etc. These methods avoid the vagaries of random sampling, and some can even guarantee convergence [41, 42, 59]. However, none of them provide error bounds. Indeed, complexity results [4,16] also preclude efficient approximate solutions with error bounds.
Partly buoyed by the dominance of deep learning in com-puter vision, learning-based solutions to robust geometric fitting have been developed [10, 60, 70]. Such techniques leverage statistics in large datasets to learn a mapping from 2This also depends on using a correct ϵ. The large volume of works that apply consensus maximisation suggest setting ϵ is usually not a concern.
the input instance to the desired solution. Despite show-ing promising results in benchmark datasets, learning meth-ods do not provide optimality guarantees and error bounds.
Whether the learned model can generalise is also a concern.
To summarise, existing algorithms for robust fitting, par-ticularly those targeted at consensus maximisation, have yet to satisfactorily solve the problem. It is thus worthwhile to investigate novel approaches based on new insights.
Our contributions We propose a new approach that leverages quantum computing for consensus maximisation.
Our core contribution is a consensus maximisation algo-rithm that iteratively solves a sequence of integer programs and terminates with either x∗ or a suboptimal solution ˜x with a known error bound |I ∗| − |˜I| ≤ ρ. The integer pro-grams are amenable to a quantum annealer [64, Chap. 8], which is utilised to tighten the bound efficiently. Since our method employs convex subroutines and random sampling, it is a hybrid quantum-classical algorithm [11, 36, 40, 56].
We will present results using an actual quantum com-puter, the D-Wave Advantage [23], as well as simulation.
While our technique does not yet outperform state-of-the-art algorithms, in part due to the limitations of current quan-tum technology, our work represents a concrete application of quantum computing in computer vision. We hope to in-spire future efforts on this topic in the community. 2.