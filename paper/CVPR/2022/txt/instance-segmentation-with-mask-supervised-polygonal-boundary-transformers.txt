Abstract
In this paper, we present an end-to-end instance segmen-tation method that regresses a polygonal boundary for each object instance. This sparse, vectorized boundary repre-sentation for objects, while attractive in many downstream computer vision tasks, quickly runs into issues of parity that need to be addressed: parity in supervision and parity in performance when compared to existing pixel-based meth-ods. This is due in part to object instances being anno-tated with ground-truth in the form of polygonal boundaries or segmentation masks, yet being evaluated in a conve-nient manner using only segmentation masks. Our method,
BoundaryFormer, is a Transformer based architecture that directly predicts polygons yet uses instance mask segmen-tations as the ground-truth supervision for computing the loss. We achieve this by developing an end-to-end differ-entiable model that solely relies on supervision within the mask space through differentiable rasterization. Boundary-Former matches or surpasses the Mask R-CNN method in terms of instance segmentation quality on both COCO and
Cityscapes while exhibiting significantly better transferabil-ity across datasets. 1.

Introduction
Image segmentation [23] and scene labeling [28, 30] are amongst the most studied topics in computer vision. In ad-dition to pixel-wise masks, representing segments/objects using vectorized boundary representations has applications and significance in many downstream tasks such as shape recognition [2], tracking [4], image understanding [31], medical imaging [26], and 3D reconstruction [5].
The recently emerged instance segmentation task (ob-jects or areas of interest) [10] greatly propels the practical significance for object segmentation. Unlike detection, in-stance segmentation predicts the detailed extent of an object rather than a coarse bounding box. However, while a bound-ing box can be represented by only two coordinate pairs
Code at https : / / github . com / mlpc - ucsd /
BoundaryFormer.
Figure 1. We present a model of instance segmentation which pre-dicts the boundaries of each object in the form of a polygon. This treats instance segmentation as a regression problem and allows for end-to-end differentiability of predictions. At the same time, our model requires no sacrifices in terms of resulting segmentation quality nor introduces additional supervision requirements com-pared algorithms which directly predict masks. and is therefore easily turned into a regression problem, there are difficulties when deciding how to best represent and predict the segmentation of an object. These difficulties combined with a historical preference for convolutional op-erations has led the computer vision community to become mask-centric. This entails almost all segmentation models relying on a spatially dense function which outputs a bi-nary confidence to determine whether each pixel belongs to a particular object. This is in contrast to a boundary-centric notion where a sparse set of structured points are predicted to denote the boundary of the object in question. Polygons are one natural choice for this structure. However, because of some inherent difficulties along with mask-centric biases, polygons have large hurdles to overcome. First, there is not an immediately obvious metric (and thus loss) for poly-gons. Second, the training regimes of mask-based models often relies on operations and augmentations that are in-herently difficult to robustly and efficiently implement on polygons directly. This includes even basic operations like cropping and intersection. Finally, evaluation of segmen-tation quality is performed with respect to masks and not contours which leads to a possible mismatch in training and
testing objectives when predicting polygons.
Furthermore, one might question why even predict boundaries over masks? Despite [10] attaining high quality masks for instance segmentation, obtaining object boundaries can be more suited towards certain tasks. While masks have a large degree of flexibility, they also lack an explicit topology which can lead to degenerate or undesir-able behavior (e.g., uncertainty at the boundary or unex-pected interior holes). Explicit boundaries, however, facili-tate downstream tasks such as plane detection [18] not only in the form of a rich, top-down structural prior but also as a continuous output which can be end-to-end differentiated in a larger system.
Despite many obstacles, past efforts to predict polygons within instance segmentation have been made. Neverthe-less, none have been able to achieve parity with baseline mask-based segmentation models across commonly used benchmarks. By parity, we mean a few things: 1). Parity in supervision: The method should require no additional sources of supervision than its mask-based coun-terpart. In particular, the method should not rely on poly-gons directly as a source of supervision. This is crucial since polygons are not always available and deriving poly-gons from a mask-based ground truth can introduce subop-timal performance or uncertainty – see Table 4. 2). Parity in evaluation: While polygonal boundary an-notations do exist in some instance segmentation datasets, e.g. [16], further technical barriers await when using poly-gon predictions for evaluation against the ground-truth di-rectly. This is due to the vectorized polygon representation not being unique and there existing a one-to-many represen-tation from masks to polygons. In other words, two similar masks may have polygons that have large differences in the control points, creating a mismatch between training loss and evaluation.
Finally, we also want to deal with 3). Parity in access.
While the predictive model itself might deviate in terms of architecture, the model should be generally considered to be a “drop-in” replacement for a mask-based segmentation head. This includes working within one and two-stage ar-chitectures, e.g., with respect to either full image or RoI features.
While certain works have touched upon aspects of our model [9,14], none has yet to provide a fully polygon based solution that is accessible to a myriad of architectures and matches performance of mask-based architectures on stan-dard datasets. We believe providing a clearer picture into the capabilities of polygons in providing a performant and end-to-end differentiable segmentation pipeline could be helpful to further development within the field. We outline our contributions below: 1. In this paper, we present a new instance segmenta-tion method, BoundaryFormer, a Transformer based approach for predicting an object’s boundary as a polygon directly. Our model outperforms the strong baseline Mask R-CNN [10] on the MS-COCO [16] dataset and achieves competitive results on Cityscapes
[7] when training from scratch while significantly out-performing it when transferring from a COCO-based initialization. To the best of our knowledge, this is the first time a method with polygonal outputs has matched or exceeded Mask R-CNN on the MS-COCO dataset. Furthermore, BoundaryFormer does so with-out compromising its ability to be trained end-to-end. 2. BoundaryFormer uses pixel-wise masks as ground-truth for supervision and evaluation by utilizing a novel differentiable rasterization module. There-fore, BoundaryFormer adds no new supervision re-quirements over Mask R-CNN [10]. 3. By only relying on masks as a source of supervision, our model can be placed as a drop-in replacement for the mask-based segmentation head of R-CNN [10] as either a full image-based component or an RoI-based component. Furthermore, it can be adopted in other common architectures including FCOS [29]. 2.