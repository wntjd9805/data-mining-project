Abstract
Robust visual recognition under adverse weather condi-tions is of great importance in real-world applications. In this context, we propose a new method for learning seman-tic segmentation models robust against fog. Its key idea is to consider the fog condition of an image as its style and close the gap between images with different fog conditions in neural style spaces of a segmentation model. In particu-lar, since the neural style of an image is in general affected by other factors as well as fog, we introduce a fog-pass filter module that learns to extract a fog-relevant factor from the style. Optimizing the fog-pass filter and the segmentation model alternately gradually closes the style gap between different fog conditions and allows to learn fog-invariant features in consequence. Our method substantially outper-forms previous work on three real foggy image datasets.
Moreover, it improves performance on both foggy and clear weather images, while existing methods often degrade per-formance on clear scenes. 1.

Introduction
We have witnessed great advances in semantic segmen-tation for the last decade. However, most of existing mod-els and datasets focus merely on improving accuracy under controlled environments, without considering image degra-dation caused by adverse weather conditions (e.g., fog, rain, and snow), over- and under-exposure, motion blur, sensor noise, etc. The robustness of semantic segmentation mod-els against these factors is of great importance in safety-critical applications and recently has gained increasing at-tention [3, 6, 8, 50–52, 56, 66].
Motivated by this, we study semantic segmentation of foggy scenes, whose goal and results are illustrated in Fig. 1.
The task is challenging since fog often damages visibility of images seriously, leading to substantial performance degra-dation. Attaching a fog removal network to the front of
*This work was done while Taeyoung Son was in POSTECH.
Figure 1. A summary of our results. Predictions of FIFO are accurate for both clear weather and real foggy images while the baseline, an ordinary segmentation model trained on clear weather images, fails to handle foggy images. an existing model is not always useful for mitigating this issue [47, 52] as well as being heavy in computation and memory. The other reason for the difficulty is the absence of fully annotated data for the task. Collecting a large set of foggy scenes is not straightforward since they can be cap-tured under only a specific condition, and it is hard to label them due to their limited visibility.
Existing methods [8, 51, 52] tackle these issues through synthetic foggy image datasets, which are obtained by ap-plying realistic fog effects to fully annotated clear weather images and are used for supervised learning of seman-tic segmentation. Furthermore, they introduce curriculum learning approaches [8, 51] that gradually adapt a model from light synthetic fog to dense real fog using unlabeled real foggy images additionally. Although these methods have achieved impressive robustness, there remains room for further improvement in that their training strategies are limited to ordinary supervised learning. In addition, the cur-riculum adaptation demands external modules to control the fog density of real foggy images in training, and tends to make the final model biased to foggy scenes; it thus requires extra computation and additional hyper-parameters in train-ing, and often degrades performance on clear images.
To resolve the above issues, we propose a new method that learns Fog-Invariant features for FOggy scene segmen-tation, dubbed FIFO. Its overall pipeline is illustrated in
Fig. 2. FIFO considers the fog condition of an image as its
Figure 2. Overall pipeline of FIFO. For each iteration of training, the fog-pass filtering module and the segmentation network are updated (top) Given Gram matrices of feature maps of the segmentation network as input, the fog-pass filtering module learns to alternately. extract fog factors so that fog conditions of images are discriminated by their fog factors. (bottom) The segmentation network is trained by reducing the gap between fog factors of images with different fog conditions as well as by the segmentation loss. Note that the fog-pass filters are auxiliary modules used only in training. style, ideally independent of its content, and aims to learn a segmentation model insensitive to fog style variation of input image. To this end, we first define three different domains of training images, i.e., clear weather (CW), syn-thetic fog (SF), and real fog (RF), where images of the first two domains are labeled while those of the last one are not.
FIFO then encourages the segmentation network to close the style discrepancy between different fog domains in fea-ture spaces so that it learns fog-invariant features.
Then the success of FIFO depends heavily on the quality of the fog style representation. Unfortunately, existing style representation schemes [17, 60] are not desirable for our task since they are manually designed to capture the holistic style of an image that is affected also by factors other than fog (e.g., when and where the image was taken) and even the content of the image [6]; the direct use of these neural styles thus introduce side-effects like content alteration and result in suboptimal solutions consequently.
To address this issue, we present fog-pass filters, learn-able modules that take an ordinary neural style—the Gram matrix of a feature map [17] as input and extract only a fog-relevant information from the style precisely in the form of embedding vectors, called fog factors. In particular, they learn to draw fog factors of the same domain together and hold those of different domains apart so that they discrim-inate fog conditions of input images through their fog fac-tors. The segmentation model is in turn encouraged to re-duce the gap between fog factors of images from differ-ent domains during training. The alternating optimization of the fog-pass filter and the segmentation network gradu-ally closes the fog style gap between different domains and eventually leads to fog-invariant features of the segmenta-tion network. Note that the fog-pass filters are auxiliary modules for training only, thus not required in testing.
FIFO has advantages over the previous work [8, 51, 52] in terms of both simplicity in training and efficacy in test-ing. Unlike the previous work, FIFO does not need to con-trol fog density levels of synthetic and real foggy images in training, thus allowing end-to-end learning of a segmenta-tion model with fewer hyper-parameters. More importantly, for the same reason, it demands no extra module for esti-mating and manipulating fog density of real foggy images in training. Regarding the effectiveness, FIFO clearly out-performs all existing records and improves performance on both foggy and clear weather domains, while existing meth-ods often degrade performance on clear scenes. 2.