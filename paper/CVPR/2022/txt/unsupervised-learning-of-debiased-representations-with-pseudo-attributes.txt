Abstract
Dataset bias is a critical challenge in machine learning since it often leads to a negative impact on a model due to the unintended decision rules captured by spurious correla-tions. Although existing works often handle this issue based on human supervision, the availability of the proper annota-tions is impractical and even unrealistic. To better tackle the limitation, we propose a simple but effective unsupervised debiasing technique. Specifically, we first identify pseudo-attributes based on the results from clustering performed in the feature embedding space even without an explicit bias attribute supervision. Then, we employ a novel cluster-wise reweighting scheme to learn debiased representation; the proposed method prevents minority groups from being dis-counted for minimizing the overall loss, which is desirable for worst-case generalization. The extensive experiments demonstrate the outstanding performance of our approach on multiple standard benchmarks, even achieving the com-petitive accuracy to the supervised counterpart. The source code is available at our project page1. 1.

Introduction
Deep neural networks have achieved impressive perfor-mance by minimizing the average loss on training datasets.
Although we typically adopt the empirical risk minimiza-tion framework as a training objective, it is sometimes prob-lematic due to dataset bias leading to significant degrada-tion of worse-case generalization performance as discussed in [2, 12, 18, 37, 38]. This is because models do not always learn what we expect, but, to the contrary, rather capture unintended decision rules from spurious correlations. For example, on the Colored MNIST dataset [1, 21, 25], where each digit is highly correlated to a certain color, a network often learns the color patterns in images, not the digit in-formation, while ignoring few conflicting samples. Such an unintended rule works well on most of the training samples but incurs unexpected worst-case errors for the examples in 1https://github.com/skynbe/pseudo-attributes
Figure 1. Representative examples on the CelebA dataset for the problem that we focus on. Since most of the people with blond hair are women, hair color attribute has a spurious correlation with gender attribute. Thus, when trained to classify the hair color, a network captures the unintended decision rule using gender, lead-ing to poor worst-group and unbiased accuracies, despite its high overall accuracy. Our model aims to learn debiased representa-tion, which gives better worst-group and unbiased accuracies, es-pecially when the bias information is unavailable. minority groups, which makes the model unable to general-ize on test environments with distribution shifts or robust-ness constraints. Figure 1 illustrates the problem that we mainly deal with in this paper.
To mitigate the bias issue, learning debiased representa-tions from a biased dataset has received growing attention from machine learning community [1, 3, 14, 21, 26, 28, 34].
However, most previous works rely on the explicit supervi-sion or prior knowledge under the assumption of the pres-ence of dataset bias. This setting is problematic because it is challenging to identify what kinds of bias exist and which attributes involve spurious correlations without thor-ough analysis of model and dataset. Note that, even with the information about dataset bias, the relevant annotations over all training examples is challenging. Contrary to the super-vised approaches, [25,30] tackle a more challenging setting, where the bias information is unavailable, via failure-based learning or subgroup-based penalizing.
This paper presents a simple but effective unsupervised debiasing technique via feature clustering and cluster re-weighting. We first observe that the examples with the same label for a certain attribute other than the target at-tribute tend to have similar representations in the feature space by the model trained sufficiently. Based on this ob-servation, we estimate bias pseudo-attributes in an unsuper-vised manner from the clustering results within each class.
To exploit the bias pseudo-attributes for learning debiased representations, we introduce a reweighting scheme for the corresponding clusters, where each cluster has an impor-tance weight depending on its size and task-specific accu-racy. This strategy encourages the minority clusters to par-ticipate in the optimization process actively, which is crit-ical to improving worst-group generalization. Despite its simplicity, our method turns out to be effective for debias-ing without any supervision of bias information; it is even comparable to the supervised debiasing method. The main contributions of our work are summarized below:
• We propose a simple but effective unsupervised debi-asing approach, which requires no explicit supervision about spurious correlations across attributes.
• We introduce a technique to learn debiased representa-tions by identifying bias pseudo-attributes via cluster-ing and reweighting the corresponding clusters based on both their size and target loss.
• We provide extensive experimental results and achieve outstanding performance in terms of unbiased and worst-group accuracies, which are even as competitive as supervised debiasing methods.
The rest of this paper is organized as follows. We re-view the prior research in Section 2. Section 3 presents the proposed framework for learning debiased representations, and Section 4 demonstrates its effectiveness with extensive empirical analysis. We conclude our paper in Section 5. 2.