Abstract
Understanding network generalization and feature dis-crimination is an open research problem in visual recogni-tion. Many studies have been conducted to assess the qual-ity of feature representations. One of the simple strategies is to utilize a linear probing classifier to quantitatively eval-uate the class accuracy under the obtained features. The typical linear probe is only applied as a proxy at the in-ference time, but its efficacy in measuring features’ suit-ability for linear classification is largely neglected in train-ing. In this paper, we propose an episodic linear probing (ELP) classifier to reflect the generalization of visual rep-resentations in an online manner. ELP is trained with de-tached features from the network and re-initialized episod-ically.
It demonstrates the discriminability of the visual representations in training. Then, an ELP-suitable Regu-larization term (ELP-SR) is introduced to reflect the dis-tances of probability distributions between the ELP classi-fier and the main classifier. ELP-SR leverages a re-scaling factor to regularize each sample in training, which modu-lates the loss function adaptively and encourages the fea-tures to be discriminative and generalized. We observe sig-nificant improvements in three real-world visual recognition tasks: fine-grained visual classification, long-tailed visual recognition, and generic object recognition. The perfor-mance gains show the effectiveness of our method in im-proving network generalization and feature discrimination. 1.

Introduction
Deep neural networks have achieved impressive im-provements in visual recognition. The neural networks trained on large-scale visual recognition datasets, e.g., Ima-*This work was performed at Baidu Research. geNet [30], OpenImages [27], demonstrate remarkable gen-eralization capabilities. The learned visual representations are compact and enjoy strong discriminability. Many works have been conducted to theoretically explain the rationale behind deep networks’ generalization [60], but this problem is still largely unsolved and remains to be investigated.
There are a few analytical tools to probe deep neural networks’ learning and generalization capabilities. Early works utilize visualization tools to understand the optimized parameters or employ dimensionality reduction techniques to visualize the quality of learned representations [42, 51, 59]. Though helpful, such visualization techniques only provide qualitative inspections on deep networks [8]. Some works develop geometric probes to analyze the geometric properties of object manifold and connect object category manifolds’ linear separability with the underlying geomet-ric properties [46]. These methods reveal the structure of memorization from different layers in deep networks but only probe layer capacity at the inference time, as shown in Fig. 1 (a).
Another simple strategy is to perform linear probing.
One can use linear probes to evaluate the feature’s quality quantitatively. Since the discrimination capability of lin-ear classifiers is low, linear classifiers heavily rely on the quality of the input representation to obtain good classifi-cation accuracy [3]. Alain et al. [1] use linear probes to examine the dynamics of intermediate layers. The linear probe is a linear classifier taking layer activations as inputs and measuring the discriminability of the networks. This linear probe does not affect the training procedure of the model. Recently, linear probes [3] have been used to evalu-ate feature generalization in self-supervised visual represen-tation learning. After representation pre-training on pretext tasks [3], the learned feature extractor is kept fixed. The linear probe classifier is trained on top of the pre-trained feature representations. Though conceptually straightfor-ward, linear probes are effective and have been widely used
sifier produces a high prediction score, it indicates that the main network exhibits overfitting on the given instance and a larger penalty should be enforced for proper regulariza-tion. Thus we design an ELP-suitable Regularization term (ELP-SR) to mitigate the intrinsic model bias and improve the linear separability of the learned features. ELP-SR sets a re-scaling factor to each instance and adaptively modulates the cross-entropy loss to avoid overfitting. The re-scaling factor considers the deviation between an example’s predic-tive score from the main classifier and ELP classifier, which, to a certain extent, assesses the example’s suitability for lin-ear classification.
Without bells and whistles, our method achieves signifi-cant improvements for visual recognition tasks in the wild, providing consistent gains for fine-grained, long-tailed, and generic visual recognition. The fine-grained visual recogni-tion datasets often contain high inter-class similarities. The long-tailed visual recognition datasets exhibit long-tailed data distribution, which is realistic in real-world recogni-tion problems. We extensively evaluate the generalization performance on six standard datasets. The results indicate that our strategy empowers various deep networks with bet-ter discrimination and mitigates the model bias. 2.