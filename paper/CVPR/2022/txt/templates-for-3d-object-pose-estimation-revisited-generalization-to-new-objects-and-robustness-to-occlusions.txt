Abstract
Training objects
New objects w/o occlusion w/ occlusion w/o occlusion w/ occlusion
We present a method that can recognize new objects and estimate their 3D pose in RGB images even under partial occlusions. Our method requires neither a training phase on these objects nor real images depicting them, only their
CAD models.
It relies on a small set of training objects to learn local object representations, which allow us to lo-cally match the input image to a set of “templates”, ren-dered images of the CAD models for the new objects. In contrast with the state-of-the-art methods, the new objects on which our method is applied can be very different from the training objects. As a result, we are the first to show generalization without retraining on the LINEMOD and
Occlusion-LINEMOD datasets. Our analysis of the failure modes of previous template-based approaches further con-firms the benefits of local features for template matching.
We outperform the state-of-the-art template matching meth-ods on the LINEMOD, Occlusion-LINEMOD and T-LESS datasets. Our source code and data are publicly available at https://github.com/nv-nguyen/template-pose. 1.

Introduction 3D object pose estimation has significantly improved over the past decade in terms of both robustness and ac-In particular, the robustness curacy [17, 29, 33, 19, 43]. to partial occlusions has greatly increased [27, 16, 23], and the need for large amounts of real annotated training images has been relaxed thanks to domain transfer [1], domain ran-domization [35, 18, 30], and self-supervised learning [32] techniques that leverage synthetic images for training.
Nevertheless, the use of image-based 3D object pose es-timation remains limited in the industry, despite its huge potential for robotics and augmented reality. Scalable in-dustrial applications would, for example, require the abil-ity to handle arbitrary, previously-unseen objects with-out retraining and with access only to the objects’ CAD
Query image
Template recovered
Query image
Template recovered
Figure 1: Our method can estimate the 3D pose of new ob-jects in query images by matching them with templates cre-ated from their 3D models. These new objects can be very different from the ones, and can be partially occluded in the query images. models, thus saving both training and data capture time.
While a few works have already tackled this challenging task [30, 28, 38, 2], most of them impose some additional constraints by assuming that the new objects belong to a known category [37], remain similar to the training ones as in the T-LESS dataset [30], or have prominent corners [28].
By contrast, template-based approaches [38, 2] offer the promise of generalizing to arbitrary new objects by learning an image embedding used to match the input image to a se-ries of templates generated from their CAD models. Unfor-tunately, their use with new objects has been demonstrated only anecdotally, and we show in our experiments that these methods struggle in this challenging scenario, particularly in the presence of occlusions. We indeed notice that the
global representations used in [38, 2] to compare the in-put image to the CAD-generated templates have two limi-tations. First, they generalize poorly to new objects in the presence of a cluttered background, and result in inaccurate pose estimation even for uniform background. Furthermore, they are ill-suited to handle occlusions.
These observations motivate us to keep the 2D structure of the images for a template-based approach. More pre-cisely, given a small set of training objects, we learn local features that can be used to reliably match real images and synthetical templates. Relying on local features allows us to discard the background: While the object’s mask in the input image is not available at run-time, we can use the tem-plate’s mask, thus solving the first limitation of global rep-resentations. Note that using the template’s mask to instead remove the background in the real image before computing the image global representation requires us to recompute the input image representation for each template, which would result in very slow matching.
As will be shown by our experiments, using local fea-tures also results in much more accurate poses. This can be explained by the fact that we do not use pooling operations, which remove critical information about the poses, espe-cially for new objects. Finally, yet another advantage is that our method can be robust to partial occlusions. To do so, we introduce a measure to evaluate the similarity between two images that explicitly takes into account the object’s mask in the template and the possible occlusions in the query im-age.
We demonstrate the benefits of our approach on the LINEMOD [11], Occlusion-LINEMOD [3], and T-LESS [13] datasets.
It consistently outperforms previous works [38, 2, 31, 30] on new objects by a large margin. In summary, our contributions are:
• A failure-case analysis of previous template-based methods when testing on new objects;
• A method that can predict the pose of new objects from their CAD models, without training on these objects nor restricting these objects to be similar to the training ones;
• A method robust to occlusions even in the challenging scenario when objects are both new and occluded. 2.