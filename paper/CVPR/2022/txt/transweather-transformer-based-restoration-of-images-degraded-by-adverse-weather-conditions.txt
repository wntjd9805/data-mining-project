Abstract
Removing adverse weather conditions like rain, fog, and snow from images is an important problem in many appli-cations. Most methods proposed in the literature have been designed to deal with just removing one type of degrada-tion. Recently, a CNN-based method using neural archi-tecture search (All-in-One) was proposed to remove all the weather conditions at once. However, it has a large num-ber of parameters as it uses multiple encoders to cater to each weather removal task and still has scope for improve-ment in its performance. In this work, we focus on devel-oping an efﬁcient solution for the all adverse weather re-moval problem. To this end, we propose TransWeather, a transformer-based end-to-end model with just a single en-coder and a decoder that can restore an image degraded by any weather condition. Speciﬁcally, we utilize a novel transformer encoder using intra-patch transformer blocks to enhance attention inside the patches to effectively re-move smaller weather degradations. We also introduce a transformer decoder with learnable weather type embed-dings to adjust to the weather degradation at hand. Tran-sWeather achieves signiﬁcant improvements across multi-ple test datasets over both All-in-One network as well as methods ﬁne-tuned for speciﬁc tasks. TransWeather is also validated on real world test images and found to be more effective than previous methods. Implementation code can be found in the supplementary document. Code is available at https://github.com/jeya-maria-jose/TransWeather. 1.

Introduction
Weather conditions like rain, fog, and snow reduce the visibility and corrupt the information captured by an image.
This drastically affects the performance of many computer vision algorithms like detection, segmentation and depth es-timation [3, 5, 41, 52, 59] which are important parts of au-tonomous navigation and surveillance systems [28, 34–36].
Hence, it is essential to remove adverse weather effects from images in order to make these vision systems more reliable. Also, a clean image without any weather degrada-Figure 1. Top row: Weather Removal Frameworks - (a) Sepa-rate networks designed for each type of weather removal like rain, fog and snow. (b) All-in-One Network [23] proposes a framework with separate encoders for each task but a generic decoder. (c) Our proposed method, Transweather, has a single encoder and a de-coder and learns weather type queries to solve all adverse weather removal efﬁciently. Bottom row: Performance Comparison - A single model instance of TransWeather achieves signiﬁcant perfor-mance boost when compared to both All-in-One framework and state-of-the-art networks designed and trained individually for spe-ciﬁc tasks while also being faster during inference. tion is desired in photography. Early methods for weather removal involve modelling priors for weather conditions using empirical observations [13, 45, 46]. These priors have to be modelled separately for each weather condi-tion and a common prior modelled for all weather condi-tions is not effective. Recently, Convolutional Neural Net-works (CNNs) based solutions have been explored exten-sively for deraining [11, 37, 53, 56, 61, 63, 69, 70, 76], de-hazing [8, 19, 41, 57, 69, 71, 72], desnowing [29, 44, 73] and raindrop removal [37, 40, 66]. Transformer-based methods
have also been explored for weather removal tasks achiev-ing better performance than CNNs [38, 48, 74]. Most of these methods just focus on one task at hand or ﬁne-tune the model separately for each task. Although they achieve excellent performance, these are not generic solutions for all adverse weather removal problems as the networks have to trained separately for each task. This makes it difﬁcult to adopt them for real-time systems as there have to be mul-tiple models making it computationally complex. Also, the system would have to decide and switch between a series of weather removal algorithms (Figure 1 (a)) making the pipeline more complicated.
Recently, Li et al. [23] proposed an All-in-One bad weather removal network which was the ﬁrst work to pro-pose an algorithm that takes in an image degraded by any weather condition as input and predicts the clean image.
All-in-One network was tested across 3 datasets of rain, fog, and snow removal and achieved better or comparable per-formance than the previous methods which were tuned indi-vidually on separate datasets. All-in-One network is CNN-based and uses multiple encoders. In particular, it uses sep-arate encoders for the different weather degradation at hand and uses neural architecture search to ﬁnd the best network to address the problem (Figure 1 (b)). This network is still computationally complex as there are multiple encoders. To the best of our knowledge, no other methods apart from All-in-One network [23] have been proposed for a generic ad-verse weather removal in the literature. Although recent methods like MPR-Net [67], U-former [55], Swin-IR [27] have been proposed as generic restoration networks vali-dated on multiple datasets, they are still ﬁne-tuned on the individual datasets and do not use a single model for all the weather removal tasks.
In this work, we propose a single encoder-single decoder transformer network, called TransWeather, to tackle all ad-verse weather removal problems at once. Instead of using multiple encoders, we introduce weather type queries in the transformer decoder to learn the task (Figure 1 (c)). Here, the multi-head self attention mechanisms take in weather type queries as input and match it with keys and values taken from features extracted from the transformer encoder.
These weather type embeddings are learned along with the network to understand and adjust to the weather degradation type present in the image. The decoded features and the hi-erarchical features obtained form the encoder are fused and projected to the image space using a convolutional block.
Thus, TransWeather just has one encoder and one decoder to learn the weather type as well as produce the clean image.
Transformers are good at extracting rich global information when compared to CNNs [9]. However, we argue that when the patches are large like in ViT [9], we fail to attend much to the information within the patch. Weather degradations like rain streak, rain drop and snow are usually small in size and so multiple artifacts can occur within a single patch.
To this end, we propose a novel transformer encoder with intra-patch transformer (Intra-PT) blocks. Intra-PT works on sub-patches created from the original patches and ex-Intra-PT cavates features and details of smaller patches. thus focuses on attention inside the main patches to re-move weather degradations effectively. We use efﬁcient self-attention mechanisms to calculate the attention be-tween sub-patches to keep the computational complexity low. From our experiments, we ﬁnd that introducing Intra-PT blocks enhances the performance of transformer and helps it adapt better to weather removal tasks. We train our network on a similar conﬁguration as All-in-One and obtain superior performance across multiple test datasets for rain removal, snow removal, fog removal and even a combination of these weather degradations. We also outper-form the methods designed speciﬁcally for these individual tasks which are ﬁnetuned on those datasets. We also show that TransWeather is fast during inference. Finally, we also test TransWeather on real-world weather degraded images, achieving excellent performance compared to the previous methods. TransWeather can act as an efﬁcient backbone in the future for generic weather removal frameworks.
The key contributions of this work are as follows:
• We propose TransWeather - an efﬁcient solution for all adverse weather removal problem with just a single en-coder and a single decoder using transformers. We pro-pose using weather type queries to efﬁciently handle the
All-in-One problem.
• We propose a novel transformer encoder using intra-patch transformer (Intra-PT) blocks to cater to ﬁne detail feature extraction for low-level vision tasks like weather removal.
• We achieve state-of-the-art performance on multiple datasets. We also validate the effectiveness of the pro-posed method on real-world images. 2.