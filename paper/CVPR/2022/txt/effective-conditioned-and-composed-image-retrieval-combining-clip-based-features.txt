Abstract
Conditioned and composed image retrieval extend CBIR systems by combining a query image with an additional text that expresses the intent of the user, describing additional requests w.r.t. the visual content of the query image. This type of search is interesting for e-commerce applications, to develop interactive multimodal searches and chat-e.g. bots. In this demo, we present an interactive system based on a combiner network, trained using contrastive learning, that combines visual and textual features obtained from the
OpenAI CLIP network to address conditioned CBIR. The system can be used to improve e-shop search engines. For example, considering the fashion domain it lets users search for dresses, shirts and toptees using a candidate start image and expressing some visual differences w.r.t. its visual con-tent, e.g. asking to change color, pattern or shape. The pro-posed network obtains state-of-the-art performance on the
FashionIQ dataset and on the more recent CIRR dataset, showing its applicability to the fashion domain for condi-tioned retrieval, and to more generic content considering the more general task of composed image retrieval.
Figure 1. Example of use of conditioned image in the fashion domain for e-commerce application. The user can refine product search providing details and constraints in natural language. The system uses both visual and textual features to retrieve the desired result. 1.

Introduction
Content-Based Image Retrieval (CBIR) is a basic task in computer vision and multimedia research and can be ap-plied to general web images, as in Google Reverse Image
Search, or it can be specialized to a large number of do-mains like landmarks [18, 37], medical images [41], cul-tural heritage [12,31] and e-commerce, either for general e-shopping [32,44,45] or in specific e-commerce domains like fashion [13,22,23] or interior design [36]. These CBIR sys-tems retrieve images from a database using an input image, computing a distance between the visual features extracted from the query and the features stored in the database. Fea-tures must be discriminative enough to deal with different images and must be robust to a number of transformations to also retrieve variations of the same images. A main dif-ficulty is to overcome the proverbial semantic gap between the low-level visual features used and the high-level mean-ing of the images [34].
Several variations of the basic CBIR task have been pro-posed to narrow this gap, requesting that the user provides some additional information regarding the intent or context
of the query. Relevance feedback is one of such mecha-nisms, where users refine iteratively the search results pro-viding additional information on what is “similar” or “dis-similar” according to them [28]. More recently, CBIR systems have been extended by adding context obtained through natural language processing, where users describe what conditions must be met by the desired results in addi-tion to the visual features of the query image. This defines the task of conditioned image retrieval, proposed to imple-ment interactive search systems for fashion [15, 40]. But it can be effectively used in many different domains of on-line retail, where the retrieval of relevant products could be based on the type of product, its texture or color, shape, material or brand [30]. Composed image retrieval, instead, generalizes the approach composing the query as an image-language pair, using both visual and textual modalities to specify the user’s intent [27].
In this work, we address both conditioned retrieval ap-plied to the fashion domain and composed retrieval applied to general images. The proposed system is based on a net-work that combines visual and textual features derived from the OpenAI CLIP network. Despite the simplicity of the network design, the system achieves state-of-the-art results on two commonly used standard datasets, FashionIQ [40] for the fashion domain, and CIRR [27] for more general content. The system can be used to develop interactive e-commerce sites and chatbots, or to improve the performance of image search engines. 2.