Abstract
Conventional point cloud semantic segmentation meth-ods usually employ an encoder-decoder architecture, where mid-level features are locally aggregated to extract geomet-ric information. However, the over-reliance on these class-agnostic local geometric representations may raise confu-sion between local parts from different categories that are similar in appearance or spatially adjacent. To address this issue, we argue that mid-level features can be further en-hanced with semantic information, and propose semantic-affine transformation that transforms features of mid-level points belonging to different categories with class-specific affine parameters. Based on this technique, we propose Se-mAffiNet for point cloud semantic segmentation, which uti-lizes the attention mechanism in the Transformer module to implicitly and explicitly capture global structural knowl-edge within local parts for overall comprehension of each category. We conduct extensive experiments on the Scan-NetV2 and NYUv2 datasets, and evaluate semantic-affine transformation on various 3D point cloud and 2D image segmentation baselines, where both qualitative and quan-titative results demonstrate the superiority and generaliza-tion ability of our proposed approach. Code is available at https://github.com/wangzy22/SemAffiNet. 1.

Introduction
Point cloud semantic segmentation is a fundamental task for both structural representation learning [11, 45, 56] and stereoscopic scene understanding [15, 27, 49] in computer vision. It aims at partitioning the scene space into semantic-meaningful regions based on conformation and geometry knowledge inherited in point cloud layouts. Its successful applications in autonomous driving, robotic manipulation, and virtual reality have been motivating researchers to de-velop more fine-grained and more accurate solutions.
*Corresponding author
Figure 1. Illustration of Semantic-Affine Transformation. The left figure is the input point cloud, with different colors referring to dif-ferent categories. We select one local part (red circle) and extract its mid-level features, resulting in the top-right figure. Some rep-resentations of the points from different categories are entangled with each other in the embedding space, which may be caused by the appearance similarities or spatial adjacency. We propose to perform the semantic-affine transformation on these mid-level fea-tures, predicting particular affine parameters for each category re-spectively. Therefore, once obtaining classification predictions of mid-level points, we can pull points from the same category closer while pushing points from different categories apart via semantic-affine transformation, as is shown in the bottom-right figure.
Recent methods for point cloud segmentation usually adopt an encoder-decoder architecture as image semantic segmentation [4, 6, 7, 51, 69], ranging from voxel based-ones [11, 20, 52, 67, 71] to point-based ones [34, 46, 54, 60].
Despite the popularity of the encoder-decoder architecture, there still exists the local confusion problem as shown in
Figure 1. On the one hand, there are local parts from differ-ent categories but with similar shapes, such as the similar
legs of chairs and desks. On the other hand, adjacent lo-cal parts are blended in the input space and may obfuscate the model during segmentation, leaving ambiguous segment boundaries. The reasons are two folds: the heavy use of the local aggregation during feature processing, and the class-agnostic nature of the mid-level features. In the commonly-used encoder-decoder architecture, the mid-level features of the decoder are locally aggregated via convolution or set ab-straction. The limitation of receptive fields produces similar feature vectors for visually-similar local parts, and the ag-gregation operation results in entangled mid-level features for spatially-adjacent local parts. Therefore, it is insuffi-cient to use geometric-only information and the encoder-decoder architecture demands more knowledge to separate similar and entangled local representations. One possible solution to this problem is alleviating the reliance on geo-metric knowledge and introducing additional semantic in-formation to enrich mid-level features. However, most ex-isting literature fails to fully exploit semantic knowledge in the network design of the encoder-decoder architecture, as semantic annotations are mostly used for data augmenta-tion [8,44,65] or supervision on final prediction [45,46,56].
Therefore, the mid-level features from the intermediate lay-ers are only implicitly or weakly supervised via gradient descent, making them almost class-agnostic.
To address the local confusion problem, we propose
Semantic-Affine Transformation to transform mid-level decoder features with class-specific affine parameters that encode semantic information, which explicitly pulls fea-tures from the same category closer and pushes features from different categories apart.
In this way, we enhance the semantic representation ability of mid-level features and boost semantic segmentation performance. Based on the proposed semantic-affine transformation, we design a semantic-aware network named SemAffiNet and introduce
Transformer [55] to manage semantic information both im-plicitly and explicitly. The Transformer encoder implic-itly communicates geometric information across modalities via the self-attention technique, while the special design of class queries in the Transformer decoder performs explicit semantic-aware reasoning to predict semantic-affine param-eters via the cross-attention mechanism. We conduct exten-sive experiments on the ScanNetV2 [14] dataset and outper-form the previous state-of-the-art BPNet [26] baselines. We also evaluate on the NYUv2 [43] dataset to verify the gen-eralization ability of the SemAffiNet model. As the core of
SemAffiNet, the proposed semantic-affine transformation is evaluated on both 3D point cloud and 2D image segmenta-tion baselines under various settings, revealing the general-ization ability of the proposed transformation.
In conclusion, the contributions of our paper can be sum-marized as follows: (1) We propose Semantic-Affine Trans-formation to enhance the semantic representation ability of mid-level features in encoder-decoder segmentation archi-tecture. (2) We propose SemAffiNet to perform semantic-aware segmentation both explicitly and implicitly via spe-cial designs of Transformer modules. (3) We conduct exper-iments on various datasets under different settings, reveal-ing the superiority and generalization ability of our method. 2.