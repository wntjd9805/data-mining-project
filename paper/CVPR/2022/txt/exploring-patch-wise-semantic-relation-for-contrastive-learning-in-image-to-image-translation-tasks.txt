Abstract
Recently, contrastive learning-based image translation methods have been proposed, which contrasts different spatial locations to enhance the spatial correspondence.
However, the methods often ignore the diverse semantic relation within the images. To address this, here we propose a novel semantic relation consistency (SRC) regularization along with the decoupled contrastive learning, which utilize the diverse semantics by focusing on the heterogeneous semantics between the image patches of a single image.
To further improve the performance, we present a hard negative mining by exploiting the semantic relation. We verified our method for three tasks: single-modal and multi-modal image translations, and GAN compression task for image translation. Experimental results confirmed the state-of-art performance of our method in all the three tasks. 1.

Introduction
One of the main objectives of image-to-image translation tasks is to learn a mapping function from a source domain to a target domain so that it preserves contents while convert-ing the appearance similar to target domain. The cycle con-sistency loss, which enforces the consistency between the input image and reconstructed image by an inverse mapping of the converted image, is widely used in various frame-works [8, 14, 19, 36]. However, it requires an additional generator and discriminator to learn the inverse mapping.
Also, [15, 20, 26] claimed that the cycle-consistency con-straint may produce distortion due to its overly restrictive constraint. Thus, one-sided image translation methods are suggested to bypass the cycle-consistency constraint by en-hancing the correspondence between the input and output in various ways [1, 4, 9].
Recently, inspired by the success of contrastive learning,
CUT [20] firstly utilized the contrastive learning to maxi-∗Co-first authors.
Figure 1. Concept of the proposed method. Decoupled contrastive learning forms the embedding. Consistency regularization of di-verse semantic relation is imposed to enhance the correspondence between the input and output. mize the mutual information between the same location of input and output images. The authors of NEGCUT [26] proposed a contrastive learning method using hard negative samples generated by the negative generator. However, the method requires additional training procedure for the nega-tive generator from random vectors, which may not guaran-tee to follow the real negative sample distribution and cause the instability of training. F-LSeSim [34] utilized the patch-wise similarity map for the contrastive learning, but they ig-nored the semantic relation between the patches, taking all negative patches as equal negative.
In this paper, we propose a novel contrastive learning method to utilize the heterogeneous semantics within an image. Specifically, as shown in Fig. 1, the key idea is to impose the consistency regularization on the similarity re-lation that preserves the spatial semantic relation during the
image translation tasks. Specifically, we capture the patch-wise semantic relationship with an image in terms of distri-butional similarity and enforce it to be preserved during the image translation tasks. This semantic regularization pre-vents from generating image artifacts which violate seman-tical relationship. Furthermore, we propose a hard negative mining strategy based on the spatially varying semantic re-lations between image patches. This strategy further im-proves the performance by avoiding sampling ‘easy’ neg-ative samples which have unrelated semantic information, but more focusing on ‘hard’ negative samples.
Experimental results using single- and multi-modal translation task and GAN compression confirmed that our method produces the state-of-the-art (SOTA) performance thanks to its capability of utilizing semantic relationship. 2.