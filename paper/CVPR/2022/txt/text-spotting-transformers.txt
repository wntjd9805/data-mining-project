Abstract
In this paper, we present TExt Spotting TRansformers (TESTR), a generic end-to-end text spotting framework us-ing Transformers for text detection and recognition in the wild. TESTR builds upon a single encoder and dual de-coders for the joint text-box control point regression and character recognition. Other than most existing litera-ture, our method is free from Region-of-Interest operations and heuristics-driven post-processing procedures; TESTR is particularly effective when dealing with curved text-boxes where special cares are needed for the adaptation of the tra-ditional bounding-box representations. We show our canon-ical representation of control points suitable for text in-stances in both Bezier curve and polygon annotations. In addition, we design a bounding-box guided polygon de-tection (box-to-polygon) process. Experiments on curved and arbitrarily shaped datasets demonstrate state-of-the-art performances of the proposed TESTR algorithm. 1.

Introduction
Text detection and recognition in natural scenes, called text spotting, is an active area of research in computer vi-sion [11, 15, 23, 24, 29, 33, 38]. Text spotting is of great importance in real-world applications such as mapping, au-tonomous driving, and image retrieval. The text spotting problem typically consists of two sub-tasks: 1) text detec-tion that localizes text boxes in a natural image, and 2) text recognition that reads the characters from the detected text.
Despite its practical significance and a steady progress ob-served recently, text spotting remains a challenging prob-lem that requires further improvement. The main difficulty in text spotting is contributed by multiple factors including large variations in font, size, style, color, shape, occlusion, distortion, and layout for natural scene images.
Classical text spotting methods [24, 38] often perform text detection and recognition in two separate steps. In the detection module, the regions of interest are proposed for
Code available at https://github.com/mlpc-ucsd/TESTR.
Figure 1. Illustration of the overall TESTR pipeline. The input image is passed through a feature backbone and Transformer en-coder, and the multi-scale feature is shared across the location and character decoder, which predict the coordinates of control points and characters of the text instance respectively. The canonical representation of control points serves both polygon vertices and
Bezier curve control points. text instance detection. After alignment, the features are then used in the text recognition module. In natural scenes, text-boxes often appear in arbitrary orientations [50] and are non-rectangular [24]. This poses further challenges for the algorithm development that typically requires a number of heuristics designs with intermediate and post-processing steps [11, 15, 29, 34].
Transformers [43] have achieved a remarkable success in natural language processing [4] and computer vision [6].
DEtection TRansformers (DETR) [2] have also made a profound impact to object detection by removing the pro-posal anchors and the non-maximum suppression processes needed in the sliding window based approaches [36]. LETR
[49] extends DETR by adopting Transformers to directly detect geometric structures such as line segments beyond the bounding box representation.
Inspired by the DETR family models [2, 16, 49, 52], we propose TExt Spotting TRansformers (TESTR), a
Transformer-based text spotting method that performs text detection and recognition in a unified framework. TESTR avoids the heuristics design and the intermediate stages re-quired in many of the existing text spotting approaches.
The contribution of TESTR is listed as follows.
• We propose a single-encoder dual-decoder framework that jointly performs curved text instance detection and recognition using Transformers beyond the stan-Figure 2. Overview of some end-to-end scene text spotting methods that are most relevant to ours. Inside the GT (ground-truth) box, ‘W’ and ‘C’ represent word-level annotation and character-level annotation. The ‘H’, ‘Q’, and ‘A’ represent that the method is able to detect horizontal, quadrilateral, and arbitrarily-shaped text, respectively. The dashed box represents the shape of the text which the method is unable to detect. Figure style from [24, 46]. dard bounding box representation. Our method, thanks to direct regression of the control points co-is a holistic approach that requires nei-ordinates, ther heuristics-driven post-processing procedures, nor
Region-of-Interest operations.
• We introduce a box-to-polygon process that achieves bounding-box guided polygon detection in the detec-tion Transformers. Experimental results show an ap-parent performance boost.
• The canonical representation of control points makes our method appropriate for both the polygonal and
Bezier curve annotations. TESTR achieves state-of-the-art performances on challenging datasets, i.e.
Total-Text and CTW1500. 1.1.