Abstract
Human skeleton, as a compact representation of hu-man action, has received increasing attention in recent years. Many skeleton-based action recognition methods adopt GCNs to extract features on top of human skele-tons. Despite the positive results shown in these attempts,
GCN-based methods are subject to limitations in robust-ness, interoperability, and scalability. In this work, we pro-pose PoseConv3D, a new approach to skeleton-based ac-tion recognition. PoseConv3D relies on a 3D heatmap vol-ume instead of a graph sequence as the base representa-tion of human skeletons. Compared to GCN-based methods,
PoseConv3D is more effective in learning spatiotemporal features, more robust against pose estimation noises, and generalizes better in cross-dataset settings. Also, PoseC-onv3D can handle multiple-person scenarios without ad-ditional computation costs. The hierarchical features can be easily integrated with other modalities at early fusion stages, providing a great design space to boost the perfor-mance. PoseConv3D achieves the state-of-the-art on five of six standard skeleton-based action recognition bench-marks. Once fused with other modalities, it achieves the state-of-the-art on all eight multi-modality action recog-nition benchmarks. Code has been made available at: https://github.com/kennymckormick/pyskl. 1.

Introduction
Action recognition is a central task in video understand-ing. Existing studies have explored various modalities for feature representation, such as RGB frames [6, 54, 59], op-tical flows [47], audio waves [62], and human skeletons
[60, 64]. Among these modalities, skeleton-based action recognition has received increasing attention in recent years due to its action-focusing nature and compactness. In prac-tice, human skeletons in a video are mainly represented as a sequence of joint coordinate lists, where the coordinates are extracted by pose estimators. Since only the pose infor-mation is included, skeleton sequences capture only action information while being immune to contextual nuisances, such as background variation and lighting changes. (a) 2D poses estimated with HRNet. (b) 3D poses collected with Kinect. (c) 3D poses estimated with VIBE.
Figure 1. PoseConv3D takes 2D poses as inputs. In general, 2D poses are of better quality than 3D poses. We visualize 2D poses estimated with HRNet for videos in NTU-60 and FineGYM in (a).
Apparently, their quality is much better than 3D poses collected by sensors (b) or estimated with state-of-the-art estimators (c).
Table 1. Differences between PoseConv3D and GCN.
Input
Format
Architecture
Previous Work 2D / 3D Skeleton
Coordinates
GCN
PoseConv3D 2D Skeleton 3D Heatmap Volumes 3D-CNN
Among all the methods for skeleton-based action recognition [15, 57, 58], graph convolutional networks (GCN) [64] have been one of the most popular approaches.
Specifically, GCNs regard every human joint at every timestep as a node. Neighboring nodes along the spatial and temporal dimensions are connected with edges. Graph convolution layers are then applied to the constructed graph to discover action patterns across space and time. Due to the good performance on standard benchmarks for skeleton-based action recognition, GCNs have been a standard ap-proach when processing skeleton sequences.
While encouraging results have been observed, GCN-based methods are limited in the following aspects: (1) Ro-bustness: While GCN directly handles coordinates of hu-man joints, its recognition ability is significantly affected by the distribution shift of coordinates, which can often oc-cur when applying a different pose estimator to acquire the coordinates. A small perturbation in coordinates often leads to completely different predictions [66]. (2) Interoperabil-ity: Previous works have shown that representations from different modalities, such as RGB, optical flows, and skele-tons, are complementary. Hence, an effective combination of such modalities can often result in a performance boost in action recognition. However, GCN is operated on an ir-regular graph of skeletons, making it difficult to fuse with other modalities that are often represented on regular grids, especially in the early stages. (3) Scalability: In addition, since GCN regards every human joint as a node, the com-plexity of GCN scales linearly with the number of persons, limiting its applicability to scenarios that involve multiple persons, such as group activity recognition.
In this paper, we propose a novel framework PoseC-onv3D that serves as a competitive alternative to GCN-based approaches. In particular, PoseConv3D takes as input 2D poses obtained by modern pose estimators shown in Fig-ure 1. The 2D poses are represented by stacks of heatmaps of skeleton joints rather than coordinates operated on a hu-man skeleton graph. The heatmaps at different timesteps will be stacked along the temporal dimension to form a 3D heatmap volume. PoseConv3D then adopts a 3D convolu-tional neural network on top of the 3D heatmap volume to recognize actions. Main differences between PoseConv3D and GCN-based approaches are summarized in Table 1.
PoseConv3D can address the limitations of GCN-based approaches stated above. First, using 3D heatmap volumes is more robust to the up-stream pose estimation: we empir-ically find that PoseConv3D generalizes well across input skeletons obtained by different approaches. Also, PoseC-onv3D, which relies on heatmaps of the base representa-tion, enjoys the recent advances in convolutional network architectures and is easier to integrate with other modali-ties into multi-stream convolutional networks. This charac-teristic opens up great design space to further improve the recognition performance. Finally, PoseConv3D can han-dle different numbers of persons without increasing com-putational overhead since the complexity over 3D heatmap volume is independent of the number of persons. To ver-ify the efficiency and effectiveness of PoseConv3D, we conduct comprehensive studies across several datasets, in-cluding FineGYM [43], NTURGB-D [34], UCF101 [51],
HMDB51 [26], Kinetics400 [6], and Volleyball [22], where
PoseConv3D achieves state-of-the-art performance com-pared to GCN-based approaches. 2.