Abstract
Recent self-supervised pretraining methods for object detection largely focus on pretraining the backbone of the object detector, neglecting key parts of detection architecture.
Instead, we introduce DETReg, a new self-supervised method that pretrains the entire object detection network, including the object localization and embedding components. During pretraining, DETReg predicts object localizations to match the localizations from an unsupervised region proposal gen-erator and simultaneously aligns the corresponding feature embeddings with embeddings from a self-supervised image encoder. We implement DETReg using the DETR family of detectors and show that it improves over competitive baselines when finetuned on COCO, PASCAL VOC, and
Airbus Ship benchmarks. In low-data regimes, including semi-supervised and few-shot learning settings, DETReg es-tablishes many state-of-the-art results, e.g., on COCO we see a +6.0 AP improvement for 10-shot detection and over 2
AP improvements when training with only 1% of the labels.1 1.

Introduction
Object detection is a key task in computer vision, yet it largely relies on the availability of human-annotated train-ing datasets. Building such datasets is not only costly but sometimes infeasible for privacy-sensitive applications such as medical imaging or personal photos [46, 68]. Fortunately, recent advancements in self-supervised representation learn-ing have substantially reduced the amount of labeled data needed for a variety of applications, including object detec-tion [6, 11, 26, 27].
Despite this recent progress, current approaches are lim-ited in their ability to learn good representations for ob-ject detection because they do not pretrain the entire ob-ject detection network, specifically the localization and region embedding components. Most recent works (e.g., 1Code: https://www.amirbar.net/detreg/.
Figure 1. Top class-agnostic object detections after pretraining.
Self-supervised pretraining methods, such as SwAV [6], pretrain only the detector’s backbone, so the object localizations following the pretraining stage solely depend on the random initialization of the localization components (green). UP-DETR [16] pretrains the entire detection network, but since its pretraining operates by re-identifying random regions, it does not specialize in localizing objects after the pretraining (orange dashes). Our model, DETReg, pretrains the entire detection network using object-centric pretrain-ing, and following the pretraining stage can localize objects (blue).
SwAV [6], ReSim [62], InsLoc [67]) follow the same pre-training playbook for the detection network as a super-vised image-classification-based pretraining, where only the
CNN backbone can be initialized from the pretrained model.
While the recent UP-DETR [16] method pretrains a full de-tection architecture, it still does not localize objects within the image, but rather random image regions.
In this work, we present a model for Detection with Trans-formers using Region priors (DETReg), which unlike exist-ing pretraining methods, learns to both localize and encode
Figure 2. The DETReg model and pretext tasks. Given embeddings v from image x, we use the DETR family of detectors [5, 71] to predict region proposals (fbox(v) = ˆb), associated object embeddings (femb(v) = ˆz), and object scores (fcat(v) = ˆp). Pseudo ground-truth region proposals labels (b) can be generated by existing unsupervised region proposal methods like [54, 59], and pseudo ground-truth object embeddings (z) can be generated via existing self-supervised approaches like [6, 27], where the object score c is always 1 for these proposals.
Predictions are assigned to pseudo labels via Bipartite Matching, and unmatched predictions are assigned with padded proposals with c = 0. objects simultaneously in the unsupervised pretraining stage – see Figure 1. DETReg involves two object-centric and category-agnostic pretraining tasks: an Object Localization
Task to localize objects, and an Object Embedding Task to encode an object’s visual properties. Taken together, these tasks pretrain the entire detection network – see Figure 2 for an overview. A final object classification head can then be finetuned with a small number of labels yielding better performance than existing methods.
DETReg’s object localization task uses simple region proposal methods for class-agnostic bounding-box supervi-sion [3, 3, 14, 15, 54]. These methods require little or no training data and can produce region proposals at a high recall. For example, Selective Search [54], the region pro-posal method we adopt in DETReg, uses object cues such as continuity in color, hierarchy, and edges to extract object proposals. DETReg builds upon these region priors to learn a class-agnostic detector during pretraining.
DETReg’s object embedding task aims to predict the embeddings of a separate self-supervised image encoder evaluated on object regions. Self-supervised image encoders, e.g., SwAV [6], learn transformation-invariant embeddings, so training the detector to predict these values distills the learned invariances into the detector’s embeddings. Thus, the object embedding head learns representations that are robust to transformations such as translation or image cropping.
We conduct an extensive evaluation of DETReg on stan-dard object detection benchmarks like MS COCO [41] and
PASCAL VOC [18], and on an aerial images dataset, Air-bus Ship Detection [1]. We find that DETReg improves the performance using two state-of-the-art base architectures compared to challenging baselines, especially when small amounts of annotated data are available.
Quantitatively, DETReg improves over a backbone-only image-classification pretraining baseline by 4 AP points on
PASCAL VOC, 1.6 AP points on MS COCO, and 1.2 AP points on Airbus Ship Detection. Additionally, DETReg out-performs pretraining baselines in semi-supervised learning when using 1% to 10% of data, and on 10 and 30 shot. Taken together, these results indicate that pretraining an entire de-tection network, including region proposal prediction and embedding components, is beneficial and that our specific
DETReg model realizes new SOTA performance by taking advantage of this object-centric self-supervised pretraining. 2.