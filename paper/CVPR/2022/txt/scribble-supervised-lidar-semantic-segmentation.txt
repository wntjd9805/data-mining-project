Abstract
Densely annotating LiDAR point clouds remains too ex-pensive and time-consuming to keep up with the ever grow-ing volume of data. While current literature focuses on fully-supervised performance, developing efficient methods that take advantage of realistic weak supervision have yet to be explored. In this paper, we propose using scribbles to annotate LiDAR point clouds and release ScribbleKITTI, the first scribble-annotated dataset for LiDAR semantic seg-mentation. Furthermore, we present a pipeline to reduce the performance gap that arises when using such weak annotations. Our pipeline comprises of three stand-alone contributions that can be combined with any LiDAR se-mantic segmentation model to achieve up to 95.7% of the fully-supervised performance while using only 8% labeled points. Our scribble annotations and code are available at github.com/ouenal/scribblekitti. 1.

Introduction
With the increase of LiDAR’s popularity on autonomous vehicles, data acquisition has significantly ramped up.
However, it is very hard to keep pace with the volume of data, as the dense data annotation process is very expensive and time-consuming for large scale datasets, especially in 3D where the navigation of the annotation tool is not trivial.
Even with powerful annotation tools [5] that allow labeling of superimposed LiDAR frames, a single 100m by 100m tile can take up to 4.5 hours for an experienced annotator [5].
In stark contrast to the 2D cases [1,14,24,31], current ef-forts in 3D semantic segmentation mainly focus on design-ing networks for densely annotated data (e.g. [41,45,57]), as opposed to developing efficient methods for creating more labels or learning from cheap/weak supervision. It is clear that only by doing the latter, the scaling of 3D semantic seg-mentation can keep up with the growth of applications and data volume. In this paper, we present a method for this very purpose, by firstly introducing a new annotation strat-egy and later developing a pipeline to directly exploit such annotations.
Figure 1. Example of scribble-annotated LiDAR point cloud scenes of a single frame (top) and superimposed frames (bottom).
Compared are the proposed ScribbleKITTI (left) with the fully la-beled counterpart from SemanticKITTI [5] (right).
Using scribbles as annotations has proven to be a popu-lar and effective method for 2D semantic segmentation [7, 22, 24]. The weak annotation method allows annotators to simply mark object centers, avoiding the time consuming task of determining class boundaries.
We adopt this idea for LiDAR point clouds to supervise 3D semantic segmentation. As opposed to 2D images, 3D point clouds preserve the metric space and therefore things and stuff follow highly geometric structures. To accompany this, we propose using the more geometric line-scribble to annotate LiDAR point clouds. Compared to free-formed scribbles, annotators only need to determine the start and end points of a line annotation. This allows faster labeling of classes that span large distances (e.g. roads, buildings, fences), while also providing as sufficient information for smaller object classes (e.g. cars, trucks), as short lines and free-formed scribbles become less distinguishable.
We provide scribble-annotations for the train-split of Se-manticKITTI [5] for 19 classes. The resulting scribble-annotated data, which we call ScribbleKITTI, contains 189 million labeled points corresponding to 8.06% of the total
point count. Fig. 1 shows an example from ScribbleKITTI.
Furthermore, in this paper we develop a novel learn-ing method for 3D semantic segmentation that directly exploits scribble annotated LiDAR data. Learning from scribble annotations provides a unique challenge as no su-pervision/regularization is available from unlabeled points, which form the majority of the training data. A performance gap between scribble-supervised and fully supervised train-ing could be very large if no special methods are designed for the former. To tackle this issue, we introduce three stand-alone contributions that can be combined with any 3D
LiDAR segmentation model: a teacher-student consistency loss on unlabeled points, a self-training scheme designed for outdoor LiDAR scenes, and a novel descriptor that im-proves pseudo-label quality.
Specifically, we first introduce a weak form of super-vision from unlabeled points via a consistency loss. Sec-ondly, we strengthen this supervision by fixing the confi-dent predictions of our model on the unlabeled points and employing self-training with pseudo-labels. The standard self-training strategy is however very prone to confirmation bias due to the long-tailed distribution of classes inherent in autonomous driving scenes and the large variation of point density across different ranges inherent in LiDAR data. To combat these, we develop a class-range-balanced pseudo-labeling strategy to uniformly sample target labels across all classes and ranges. Finally, to improve the quality of our pseudo-labels, we augment the input point cloud by using a novel descriptor that provides each point with the semantic prior about its local surrounding at multiple resolutions.
In summary, our contributions are as follows:
• We present ScribbleKITTI, the first scribble-annotated
LiDAR semantic segmentation dataset.
• We propose class-range-balanced self-training to com-bat the inherent bias towards dominant classes and close ranged dense regions in pseudo-labels.
• We further improve the pseudo-labeling quality by augmenting the input point cloud with a pyramid lo-cal semantic-context descriptor.
• Putting these two contributions along with the mean teacher framework, our scribble-based pipeline achieves up to 95.7% relative performance of fully su-pervised training while using only 8% labeled points.
Our contributions remain orthogonal to the development of better neural network architectures and can be combined with any 3D LiDAR segmentation model. 2.