Abstract
Deep spatiotemporal models are used in a variety of computer vision tasks, such as action recognition and video object segmentation. Currently, there is a limited under-standing of what information is captured by these models in their intermediate representations. For example, while it has been observed that action recognition algorithms are heavily inﬂuenced by visual appearance in single static frames, there is no quantitative methodology for evaluat-ing such static bias in the latent representation compared to bias toward dynamic information (e.g. motion). We tackle this challenge by proposing a novel approach for quanti-fying the static and dynamic biases of any spatiotemporal model. To show the efﬁcacy of our approach, we anal-yse two widely studied tasks, action recognition and video object segmentation. Our key ﬁndings are threefold: (i)
Most examined spatiotemporal models are biased toward static information; although, certain two-stream architec-tures with cross-connections show a better balance between the static and dynamic information captured. (ii) Some datasets that are commonly assumed to be biased toward dynamics are actually biased toward static information. (iii) Individual units (channels) in an architecture can be bi-ased toward static, dynamic or a combination of the two. 1 1.

Introduction
This paper focuses on the problem of interpreting the in-formation learned by deep neural networks (DNNs) trained for video understanding tasks. Interpreting deep spatiotem-poral models is a largely understudied topic in computer vi-sion despite their achieving state-of-the-art performance on video understanding tasks, such as action recognition [53] and video object segmentation [48]. These models are trained in an end-to-end fashion to learn discriminative static and dynamic features over space and time. Here, we use the term static to refer to attributes that can be extracted 1Project page and code
Figure 1. We introduce a general technique that, given a model and a video dataset, can quantify the bias in any intermediate rep-resentation within the model toward encoding static (red) or dy-namic (blue) information. We use this technique to study the tasks of action recognition (squares) and video object segmentation (dia-monds) and explore the effect of architectures and training datasets on static and dynamic biases. from a single image (e.g. color and texture) and the term dy-namic to attributes that arise from consideration of multiple frames (e.g. motion and dynamic texture).
While this learning-based paradigm has led to great suc-cess across a wide range of tasks, the internal representa-tions of the learned models remain largely opaque. This lack of explainability is unsatisfying from both scientiﬁc and application perspectives. From a scientiﬁc perspec-tive, there is limited understanding of what information is driving the decision-making underlying the network output.
Elucidating the decision-making process may yield direc-tions to improve models. From an applications perspec-tive, there have been multiple cases showing the ethical and damaging consequences of deploying opaque vision mod-els, e.g. [3, 21]. Currently, however, the explainability of
spatiotemporal models is under-explored [25]. Some evi-dence suggests that these models exhibit considerable bias toward static information, e.g. [6,24,47]; therefore, an inter-esting question to answer about the representations in deep spatiotemporal models is: How much static and dynamic information is being captured? While a few video inter-pretation methods exist, they have various limitations, e.g. being primarily qualitative [16], using a certain dataset that prevents evaluating the effect of the training dataset [20] or using classiﬁcation accuracy as a metric without quantify-ing a model’s internal representations [20, 39].
In response, we present a quantitative paradigm for eval-uating the extent that spatiotemporal models are biased to-ward static or dynamic information in their internal repre-sentations. We deﬁne bias toward a certain factor (dynamic or static) as the percentage of units (i.e. channels) within in-termediate layers that encode that factor; see Fig. 1 (top).
Inspired by previous work [10, 27], we propose a metric to estimate the amount of static vs. dynamic bias based on the mutual information between sampled video pairs corre-sponding to these factors. We explore two common tasks to show the efﬁcacy of our approach as a general tool for un-derstanding spatiotemporal models, action recognition and video object segmentation. We focus our study on answer-ing the following three questions: (i) What effect does the model architecture have on static and dynamic biases? (ii)
How does the training dataset affect these biases? (iii) What role do units that jointly encode static and dynamic informa-tion play in relation to the architecture and dataset?
Contributions. Overall, we make three main contributions. (i) We introduce a general method for quantifying the static and dynamic bias contained in spatiotemporal models, in-cluding a novel sampling procedure to produce static and dynamic video pairs. (ii) We propose a technique for iden-tifying units that jointly encode static and dynamic factors. (iii) Using the aforementioned techniques, we provide a uni-ﬁed study on two widely researched tasks, action recogni-tion and video object segmentation, with a focus on the ef-fect of architecture and training dataset on a model’s static and dynamic biases; see Fig. 1 (bottom). Among other ﬁnd-ings, we discover in both tasks that all networks are heav-ily static biased, except for two-stream architectures with cross connections encouraging models to capture dynam-ics. Additionally, we conﬁrm that, contrary to previous be-liefs [2, 33], the Diving48 [33] dataset is not dynamically biased and Something-Something-v2 (SSv2) [19] is better suited to evaluate a model’s ability to capture dynamics. 2.