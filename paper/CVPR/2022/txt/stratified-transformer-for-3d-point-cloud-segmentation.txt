Abstract 3D point cloud segmentation has made tremendous progress in recent years. Most current methods focus on aggregating local features, but fail to directly model long-In this paper, we propose Stratified range dependencies.
Transformer that is able to capture long-range contexts and demonstrates strong generalization ability and high perfor-mance. Specifically, we first put forward a novel key sam-pling strategy. For each query point, we sample nearby points densely and distant points sparsely as its keys in a stratified way, which enables the model to enlarge the effec-tive receptive field and enjoy long-range contexts at a low computational cost. Also, to combat the challenges posed by irregular point arrangements, we propose first-layer point embedding to aggregate local information, which fa-cilitates convergence and boosts performance. Besides, we adopt contextual relative position encoding to adaptively capture position information. Finally, a memory-efficient implementation is introduced to overcome the issue of vary-ing point numbers in each window. Extensive experiments demonstrate the effectiveness and superiority of our method on S3DIS, ScanNetv2 and ShapeNetPart datasets. Code is available at https:// github.com/ dvlab-research/ Stratified-Transformer. 1.

Introduction
Nowadays 3D point clouds can be conveniently col-lected. They have demonstrated great potential in various applications, such as autonomous driving, robotics and aug-mented reality. Unlike regular pixels in 2D images, 3D points are arranged irregularly, hampering direct adoption of well-studied 2D networks to process 3D data. Therefore, it is imperative to explore advanced methods that are tai-lored for 3D point cloud data.
Abundant methods [7, 15, 16, 34, 35, 41, 52, 61, 62] have explored 3D point cloud segmentation and obtained decent
*Equal Contribution
†Corresponding Author
Input / Ground Truth bed chair w/o stratified desk curtain w/ stratified floor table wall
Figure 1. Visualization of Effective Receptive Field (ERF) [29], given the feature of interest (shown with green star) in the output layer. Red region corresponds to high contribution. Left: Input point cloud and the ground truth. Middle: The ERF and prediction of the model without stratified strategy and by only attending to its own window. Right: The ERF and prediction of the model with direct long-range dependency, using the stratified strategy. More illustrations are shown in the supplementary file. performance. Most of them focus on aggregating local fea-tures, but fail to explicitly model long-range dependencies, which has been demonstrated to be crucial in capturing con-texts from a long distance [49]. Along another line of re-search, Transformer [44] can naturally harvest long-range information via the self-attention mechanism. However, only limited attempts [31, 62] have been made to apply
Transformer to 3D point clouds. Point Transformer [62] proposes “vector self-attention” and “subtraction relation” to aggregate local features, but it is still difficult to directly capture long-range contexts. Voxel Transformer [31] is tai-lored for object detection and performs self-attention over the voxels, but it loses accurate position due to voxelization.
Differently, we develop an efficient segmentation net-work to capture long-range contexts using the standard multi-head self-attention [44], while keeping position infor-mation intact. To this end, we propose a simple and power-ful framework, namely, Stratified Transformer.
Specifically, we first partition the 3D space into non-overlapping cubic windows, inspired by Swin Trans-in Swin Transformer, different former [26]. However, windows work independently, and each query token only chooses the tokens within its window as keys, thus attend-ing to a limited local region. Instead, we propose a strati-fied strategy for sampling keys. Rather than only selecting nearby points in the same window as keys, we also sparsely sample distant points. In this way, for each query point, both denser nearby points and sparser distant points are sampled to form the keys all together, achieving a significantly en-larged effective receptive field while incurring negligible extra computations. For instance, we visualize the Effec-tive Receptive Field (ERF) [29] in Fig. 1 to show the impor-tance of modeling long-range contexts. In the middle of the figure, due to incapability to model the direct long-range de-pendency, the desk merely attends to the local region, lead-ing to false predictions. Contrarily, with our proposed strat-ified strategy, the desk is able to aggregate contexts from distant objects, such as the bed or curtain, which helps to correct the prediction.
Moreover, it is notable that irregular point arrangements pose significant challenges in designing 3D Transformer. In 2D images, patch-wise tokens can be easily formed with spatially regular pixels. But 3D points are completely dif-ferent. In our framework, each point is deemed as a token and we perform point embedding for each point to aggre-gate local information in the first layer, which is beneficial for faster convergence and stronger performance. Further-more, we adopt effective relative position encoding to cap-ture richer position information. It can generate the posi-tional bias dynamically with contexts, through the interac-tion with the semantic features. Also, considering that 3D point numbers in different windows vary a lot and cause unnecessary memory occupation for windows with a small number of points, we introduce a memory-efficient imple-mentation to significantly reduce memory consumption.
In total, our contribution is threefold:
• We propose Stratified Transformer to additionally sample distant points as keys but in a sparser way, en-larging the effective receptive field and building direct long-range dependency while incurring negligible ex-tra computations.
• To handle irregular point arrangements, we design first-layer point embedding and effective contextual position encoding, along with a memory-efficient im-plementation, to build a strong Transformer tailored for 3D point cloud segmentation.
• Experiments show our model achieves state-of-the-art results on widely adopted large-scale segmenta-i.e., S3DIS [1], ScanNetv2 [10] and tion datasets,
ShapeNetPart [5]. Extensive ablation studies verify the benefit of each component. 2.