Abstract
Discriminative learning, restorative learning, and adver-sarial learning have proven beneficial for self-supervised learning schemes in computer vision and medical imaging.
Existing efforts, however, omit their synergistic effects on each other in a ternary setup, which, we envision, can sig-nificantly benefit deep semantic representation learning. To realize this vision, we have developed DiRA, the first frame-work that unites discriminative, restorative, and adversar-ial learning in a unified manner to collaboratively glean complementary visual information from unlabeled medical images for fine-grained semantic representation learning.
Our extensive experiments demonstrate that DiRA (1) en-courages collaborative learning among three learning in-gredients, resulting in more generalizable representation across organs, diseases, and modalities; (2) outperforms fully supervised ImageNet models and increases robustness in small data regimes, reducing annotation cost across mul-tiple medical imaging applications; (3) learns fine-grained semantic representation, facilitating accurate lesion local-ization with only image-level annotation; and (4) enhances state-of-the-art restorative approaches, revealing that DiRA is a general mechanism for united representation learning.
All code and pretrained models are available at https:
//github.com/JLiangLab/DiRA. 1.

Introduction
Self-supervised learning (SSL) aims to learn general-izable representations without using any expert annota-tion. The representation learning approaches in the SSL paradigm can be categorized into three main groups: (1) discriminative learning, which utilizes encoders to clus-ter instances of the same (pseudo) class and distinguish instances from different (pseudo) classes; (2) restorative learning, which utilizes generative models to reconstruct
*Equal contributors ordered alphabetically.
Figure 1. Despite the critical contributions of discriminative, restorative, and adversarial learning to SSL performance, yet no
SSL method simultaneously employs all three learning ingredi-ents. Our proposed DiRA, a novel SSL framework, unites discrim-inative, restorative, and adversarial learning in a unified manner to collaboratively glean complementary visual information from un-labeled data for fine-grained semantic representation learning. original images from their distorted versions; and (3) ad-versarial learning, which utilizes adversary models to en-hance restorative learning.
In computer vision, discrimi-native SSL approaches, especially contrastive learning [8, 12, 13, 15, 21, 24, 27, 27, 34, 44, 53], currently offer state-of-the-art (SOTA) performance, surpassing standard super-vised ImageNet models in some tasks. In medical imaging, however, restorative SSL methods [10, 25, 26, 43, 55, 57] compared to discriminative approaches [3, 56] presently reach a new height in performance. Naturally, we contem-plate: What contributes to the popularity differences be-tween discriminative and restorative methods in computer vision and in medical imaging? Furthermore, from our ex-tensive literature review, we have discovered that no SSL method exploits all three learning components simultane-ously; therefore, we ponder: Can discriminative, restora-tive, and adversarial learning be seamlessly integrated into
more fine-grained details. Putting these understandings and fundamental differences between photographic and medi-cal images together would explain why restorative learning is preferred in medical imaging while discriminative learn-ing is preferred in computer vision. More importantly, we have acquired a new and intriguing insight into trio of dis-criminative, restorative, and adversarial learning to excavate effective features required for medical recognition tasks— not only high-level anatomical representations but also fine-grained discriminative cues embedded in the local parts of medical images.
Based on the insights above, we have designed a novel self-supervised learning framework, called DiRA, by uniting discriminative learning, restorative learning, and adversarial learning in a unified manner to glean comple-mentary visual information from unlabeled medical im-ages. Our extensive experiments demonstrate that (1)
DiRA encourages collaborative learning among three learn-ing components, resulting in more generalizable representa-tion across organs, diseases, and modalities (see Fig. 4); (2)
DiRA outperforms fully supervised ImageNet models and increases robustness in small data regimes, thereby reduc-ing annotation cost in medical imaging (Tab. 1 and Tab. 2); (3) DiRA learns fine-grained representations, facilitating more accurate lesion localization with only image-level an-notations (Fig. 5); and (4) DiRA enhances SOTA restorative approaches, showing that DiRA is a general framework for united representation learning (Tab. 3).
In summary, we make the following contributions:
• The insights that we have gained into the synergy of discriminative, restorative, and adversarial learning in a ternary setup, realizing a new paradigm of collabora-tive learning for SSL.
• The first self-supervised learning framework that seamlessly unites discriminative, restorative, and ad-versarial learning in a unified manner, setting a new
SOTA for SSL in medical imaging.
• A thorough and insightful set of experiments that demonstrate not only DiRA’s generalizability but also its potential to take a fundamental step towards devel-oping universal representations for medical imaging. 2.