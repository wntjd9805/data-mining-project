Abstract
This paper investigates the problem of temporally inter-polating dynamic 3D point clouds with large non-rigid de-formation. We formulate the problem as estimation of point-wise trajectories (i.e., smooth curves) and further reason that temporal irregularity and under-sampling are two ma-jor challenges. To tackle the challenges, we propose IDEA-Net, an end-to-end deep learning framework, which disen-tangles the problem under the assistance of the explicitly learned temporal consistency. Speciﬁcally, we propose a temporal consistency learning module to align two consecu-tive point cloud frames point-wisely, based on which we can employ linear interpolation to obtain coarse trajectories/in-between frames. To compensate the high-order nonlin-ear components of trajectories, we apply aligned fea-ture embeddings that encode local geometry properties to regress point-wise increments, which are combined with the coarse estimations. We demonstrate the effectiveness of our method on various point cloud sequences and observe large improvement over state-of-the-art methods both quantita-tively and visually. Our framework can bring beneﬁts to 3D motion data acquisition. The source code is publicly avail-able at https://github.com/ZENGYIMING-EAMON/IDEA-Net.git. 1.

Introduction
Dynamic 3D point clouds, which are sequences of 3D point cloud frames sampled in the temporal domain for capturing the changes in geometric details or motion of scenes/objects, have been widely used in many application scenarios, such as autopilot [22], immersive communica-tion [6], computer animation [27], and virtual/augmented reality [40]. Despite of rapid development in 3D sensing technology [41], it is still difﬁcult and costly to acquire 3D point cloud sequences with high temporal resolution (HTR), which hinders to ﬁnely represent deformable 3D 1This work was supported by the HK RGC Grant CityU 11202320 and 11218121. Corresponding author: J. Hou.
Figure 1. Illustration of the problem considered in this paper. One can adopt a low-cost 3D sensing device to sample the motion at a low frequency, leading to an LTR point cloud sequence, then ap-ply the computational method to interpolate/estimate in-between point cloud frames to obtain an HTR one for ﬁnely representing the 3D motion of objects (or 3D shapes/objects deforming over time). We are interested in point cloud sequences with massive non-rigid deformation. Moreover, in real application scenario, the point cloud frames of a sequence are independently captured in the sensor space, thus lacking point-wise temporal consistency. objects [36]. Instead of relying on hardware development, we consider computational methods to construct an HTR point cloud sequence from one with low temporal resolu-tion (LTR), as illustrated in Fig. 1.
Although the considered problem shares similar proper-ties with 2D video frame interpolation, both of which aim to interpolate/predict the in-between frames of any two con-secutive frames of an LTR sequence, the essentially differ-ent data modality (i.e., illumination vs. geometry informa-tion) makes it non-trivial to extend existing 2D video frame interpolation methods [13,14,21] to 3D point clouds. More-over, the unordered and irregular nature of 3D point cloud data in spatial and temporal domains poses great challenges. several deep learning-based interpolation methods for 3D point cloud sequences have been pro-posed [12,19,29,31]. Nevertheless, for the ﬂow-based Poin-tINet [19], it is mainly applicable to shapes with nearly rigid transformation and cannot well generalize to those with large non-rigid deformation. For the auto-encoder-based methods like [29, 31], which directly interpolate global fea-tures, since the global features are abstract and insufﬁcient
Recently,
(b)
Figure 2. Visual comparisons of (a) our IDEA-Net, (b) PointINet [19], and (c) the ground-truth on the Swing sequence. (c) (a) to describe the details of motion changes, the interpolated frames tend to have similar shape appearances and lack tem-poral continuity, leading to stuck motion sequences. Be-sides, they are architecturally designed as separate learning stages, instead of fully end-to-end, which may suffer from severe information loss. Unlike existing works, we seek to build an interpretable interpolation framework with a clear geometric explanation. Moreover, in terms of application scenarios, we are interested in challenging dynamic point cloud data with large non-rigid deformation.
Technically, we formulate the problem as estimation of point-wise trajectories (i.e., smooth curves in 3D Euclidean space) and reason that the challenges are mainly posed by temporal irregularity and under-sampling, which motivates us to disentangle the problem, leading to a two-step learning process: i) coarse linear interpolation and ii) trajectory com-pensation. Based on the explicit formulation, we propose
IDEA-Net, an end-to-end deep interpolation framework, which features a dual-branch structure and consists of three steps: 1) extracting point-wise high-dimensional features, 2) learning point-wise temporal consistency and deducing coarse trajectories/in-between frames via linear interpola-tion, and 3) exploiting temporally regularized features to compensate the non-linear components of smooth trajecto-ries. Experiments on both synthetic and real-scanned data demonstrate our IDEA-Net quantitatively and visually out-performs state-of-the-art methods to a large extent, as visu-alized in Fig. 2. We also conduct extensive ablation studies to validate the rationality of our design.
In summary, we make the following contributions:
• a new formulation for the problem of temporally inter-polating dynamic 3D point cloud sequences;
• a symmetric and coarse-to-ﬁne network for end-to-end reconstructing HTR point cloud sequences from LTR point cloud sequences with large non-rigid deforma-tion. 2.