Abstract 3D room layout estimation by a single panorama us-ing deep neural networks has made great progress. How-ever, previous approaches can not obtain efﬁcient geometry awareness of room layout with the only latitude of bound-aries or horizon-depth. We present that using horizon-depth along with room height can obtain omnidirectional-geometry awareness of room layout in both horizontal and vertical directions.
In addition, we propose a planar-geometry aware loss function with normals and gradients of normals to supervise the planeness of walls and turn-ing of corners. We propose an efﬁcient network, LGT-Net, for room layout estimation, which contains a novel Trans-former architecture called SWG-Transformer to model ge-ometry relations. SWG-Transformer consists of (Shifted)
Window Blocks and Global Blocks to combine the local and global geometry relations. Moreover, we design a novel relative position embedding of Transformer to enhance the spatial identiﬁcation ability for the panorama. Experi-ments show that the proposed LGT-Net achieves better per-formance than current state-of-the-arts (SOTA) on bench-mark datasets. The code is publicly available at https:
//github.com/zhigangjiang/LGT-Net. 1.

Introduction
The goal of estimating the 3D room layout by an indoor
RGB image is to locate the corners or the ﬂoor-boundary and ceiling-boundary, as shown in Fig. 3a, which plays a crucial role in 3D scene understanding [24]. The panoramic images have wider (360◦) ﬁeld of view (FoV) than perspec-tive images and contain the whole-room contextual infor-mation [30]. With the development of deep neural networks and the popularity of panoramic cameras in recent years, 3D room layout estimation by a single panorama has made great achievements [23, 28, 32].
Most room layouts conform to the Atlanta World as-sumption [20] with horizontal ﬂoor and ceiling, along with
*Corresponding author.
Figure 1. Overall architecture of the proposed LGT-Net. The net-work estimates the room layout from a single panorama using the omnidirectional-geometry aware loss of horizon-depth and room height and the planar-geometry aware loss of normals and gra-dients of normals. We visualize the predicted boundaries (green) by the horizon-depth and room height, and the ﬂoor plan (red) with post-processing by Manhattan constraint, ﬁnally output the 3D room layout. vertical walls [18]. Thus the room layout can be repre-sented by ﬂoor-boundary and room height, as shown in
Fig. 3a. However, previous approaches [23, 24, 26] estimate the room height by ceiling-boundary. And the networks pre-dict the ﬂoor-boundary and ceiling-boundary with the same output branch, which affects each other since they need to predict both horizontal shape and vertical height of room layout. Meanwhile, most previous approaches [23, 28, 32] use Manhattan constraint [3] or directly simplify bound-aries [18] in post-processing without considering the pla-nar attribute of the walls to constrain the network output results. In addition, for models [23, 24, 26] which formu-late the room layout estimation task as 1D sequence predic-tion, a sequence processor is needed to model the geometry relationship. Bidirectional Long Short-Term Memory (Bi-LSTM) [11, 21] is used in [23, 26]. Transformer [25] is an efﬁcient framework for sequence processing and has made great success in natural language processing (NLP) tasks.
Vision Transformer (ViT) [5] has demonstrated strong abil-ities in the computer vision ﬁeld recently. Nevertheless, there is no specially designed Transformer architecture for panoramas as we know.
Due to the above problems, we propose an efﬁcient net-work called LGT-Net for panoramic room layout estima-tion. It contains a feature extractor to convert the panorama to feature sequence and a Transformer architecture as se-quence processor. Our proposed network directly predicts the room height and ﬂoor-boundary by two branches in the output layer, as shown in Fig. 1. Inspired by Wang et al. [26], we represent the ﬂoor-boundary by horizon-depth.
Thus, we propose an omnidirectional-geometry aware loss function that computes the errors of horizon-depth and room height, which brings better geometry awareness of the room layout in both horizontal and vertical directions.
In addition, we observe the planar attribute of the walls and the turning attribute of the corners. Thus we propose to use the planar-geometry aware loss function of normal consis-tencies and gradient of normal errors to supervise these at-tributes.
Moreover, we design a novel Transformer architecture called SWG-Transformer as the sequence processor for our network, which consists of (Shifted) Window Blocks [15] and Global Blocks to combine the local and global geome-try relations, as shown in Fig. 1. With the attention mech-anism [16], our SWG-Transformer can better process the left and right borders of the panoramas than Bi-LSTM. In addition, we design a novel relative position embedding
[13, 19, 22] of Transformer architecture to enhance the spa-tial identiﬁcation ability for the panoramas.
In order to demonstrate the effectiveness of our proposed approach, we conduct extensive experiments on benchmark datasets, including ZInD [4] dataset. Meanwhile, we con-duct ablation study on MatterportLayout [33] dataset in the following aspects: loss function, network architecture, and position embedding of Transformer to demonstrate the ef-fectiveness of each component. Experiments show that our proposed approach performs better than SOTA. The main contributions of our work are as follows:
• We represent the room layout by horizon-depth and room height and output them with two branches of our network. Furthermore, we compute the horizon-depth and room height errors to form omnidirectional-geometry aware loss function and compute normal and gradient errors to form planar-geometry aware loss function.
• We show that exploiting Transfomer as a sequence pro-cessor is helpful for panoramic understanding. And our proposed SWG-Transformer can better establish the local and global geometry relations of the room layout.
• We specially design a relative position embedding of
Transformer to enhance the spatial identiﬁcation abil-ity for the panoramas. 2.