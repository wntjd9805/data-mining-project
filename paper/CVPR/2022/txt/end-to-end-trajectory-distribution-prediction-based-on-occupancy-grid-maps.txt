Abstract
In this paper, we aim to forecast a future trajectory distri-bution of a moving agent in the real world, given the social scene images and historical trajectories. Yet, it is a chal-lenging task because the ground-truth distribution is un-known and unobservable, while only one of its samples can be applied for supervising model learning, which is prone to bias. Most recent works focus on predicting diverse trajec-tories in order to cover all modes of the real distribution, but they may despise the precision and thus give too much credit to unrealistic predictions. To address the issue, we learn the distribution with symmetric cross-entropy using occupancy grid maps as an explicit and scene-compliant approxima-tion to the ground-truth distribution, which can effectively penalize unlikely predictions. In specific, we present an in-verse reinforcement learning based multi-modal trajectory distribution forecasting framework that learns to plan by an approximate value iteration network in an end-to-end manner. Besides, based on the predicted distribution, we generate a small set of representative trajectories through a differentiable Transformer-based network, whose atten-tion mechanism helps to model the relations of trajectories.
In experiments, our method achieves state-of-the-art per-formance on the Stanford Drone Dataset and Intersection
Drone Dataset. 1.

Introduction
Trajectory prediction has gained increasing attention due to its emerging applications such as robot navigation and self-driving cars. Due to the inherent multimodal uncer-tainty from an agent’s intention or environment, a large number of works have been proposed to learn a multi-modal distribution of the future trajectories. For example, in [20, 26], the multimodal distribution is explicitly mod-eled using the Gaussian mixture model, though it is hard to
*Jia Pan is the corresponding author. This project is supported by HK-SAR RGC GRF 11202119, 11207818, T42-717/20-R, HKSAR Technol-ogy Commission under the InnoHK initiative, and the National Natural
Science Foundation of China (Grant No. 62072110).
Figure 1. Illustration of trajectory prediction distributions of P2T and our method on Stanford Drone Dataset. Although the predic-tion of P2T is more diverse, it predicts many infeasible outcomes (e.g., those trajectories intersecting with the parterre) and assigns too high probability to the turning action. optimize and prone to overfitting. Others have attempted to model the trajectory distribution implicitly using gen-erative models such as conditional variational autoencoder (CVAE) [6, 19, 28, 44], normalizing flow (NF) [34, 38], or generative adversarial network (GAN) [2, 8, 9, 11, 43].
However, most previous works focus on the diversity of the predicted trajectories rather than the more important precision, except a few works (e.g. [34, 38]). The issue is that if the model is only encouraged to cover all modes of real distribution, it may assign too many probabilities to un-realistic predictions and cannot accurately reflect the real probability density. One such example is shown in Fig. 1 where a large portion of the diverse trajectories predicted by P2T [6] turn and intersect with obstacles, which are cer-tainly implausible and inconsistent with common knowl-edge that moving straight ahead is more likely than turn-ing. In such circumstances, a navigation decision based on the predictions will overreact to less likely futures, while underestimating the more likely ones.
Specifically, to learn a diverse trajectory distribution, previous works usually minimize the variety loss [6, 9, 13] or the forward cross-entropy [23, 26, 44]. Yet, the variety loss does not penalize bad predictions as long as there ex-ists one prediction close to the ground-truth, and it does not lead to ground-truth distribution but approximately its square root [46]. On the other hand, the forward cross-entropy also fails to adequately penalize the unlikely pre-dictions [34,38] and exhibits noise sensitivity [48]. To over-come the limitations of these losses, our solution is to learn a distribution minimizing the symmetric cross-entropy, i.e. the combination of forward and reverse cross-entropy be-tween the predictive distribution and ground-truth distribu-tion. Compared with the forward cross-entropy, the reverse cross-entropy can penalize the prediction with low likeli-hood, but it requires ground-truth distribution as a refer-ence, which unfortunately is not available in many cases.
An effective solution is to employ an occupancy grid map (OGM), which divides the social space into grid cells with an occupancy probability in each cell. Thus, the trajectory probability can be approximated as the product of all future position probabilities conditioned on the OGM. In [38], an
OGM, parameterized as a cost map, is embedded from spa-tial scene features by a convolutional neural network (CNN) to assign proper probabilities to different social areas. How-ever, representing all future position distributions with a single OGM is inaccurate, since it neglects the spatial-temporal correspondence of trajectories. Instead, we pre-dict an OGM for each future position with a convolutional long short-term memory (ConvLSTM) [51] network based on our novel deconvolution parameterization of the position probability flow. The resulting dynamic OGMs can help not only the trajectory prediction [23] but also downstream planning tasks [4, 53].
When minimizing the symmetric cross-entropy, previ-ous approaches [34, 38] usually make use of the normal-izing flow, which transforms a simple Gaussian distribution into the target trajectory distribution through a sequence of auto-regressive mappings. These mappings are required to be invertible, differentiable, and easy for computing Jaco-bian determinants, which are difficult to be satisfied in prac-tice. In addition, the latent variable sampled from the Gaus-sian distribution is hard to interpret. To address these is-sues, we develop an end-to-end interpretable model to back-propagate the symmetric cross-entropy loss. In particular, we construct a CVAE model using a coarse future trajec-tory plan within neighboring grids as the interpretable la-tent variable, similar to P2T [6]. However, P2T cannot be trained in an end-to-end manner, because it learns the plan-ning policy using the maximum-entropy inverse reinforce-ment learning (MaxEnt IRL) [50, 58] by matching feature expectation. Instead, we implement value iteration in IRL by differentiable value iteration network (VIN) [45] and in-corporate Gumbel-Softmax [15] into the discrete planning policy sampling. In our VIN-based IRL, planning and tra-jectory generation policy can be learned simultaneously by maximizing the data likelihood.
Even though a large number of possible future trajec-tories can be sampled from the learned distribution, many downstream applications often demand a small set of repre-sentative predictions. This requirement is traditionally ac-complished by learning the distribution model with the vari-ety loss [5, 9, 13] or post-processing with heuristic methods like greedy approximation [36] or K-means [6, 7]. Moti-vated by the insight that clustering like K-means can be re-garded as paying different attention to different samples, we propose a Transformer-based refinement network, whose attention mechanism can also ensure sampling diversity, to attentively obtain a small set of representative samples from the over-sampled outcomes of our prediction model. The representative properties can be conveniently adjusted by its loss, e.g. the variety loss for diversity. In experiments, we compare our method with a set of state-of-the-art ap-proaches on the Stanford Drone Dataset [40] and Intersec-tion Drone Dataset [3] and demonstrate the superiority of our method in both trajectory diversity and quality.
In summary, the main contributions are as follows.
• We propose a VIN-based IRL method, simplifying the learning process while allowing the gradients from tra-jectory generation to flow back to the planning module.
• We improve the approximation of ground-truth with
OGMs in learning trajectory distribution using sym-metric cross-entropy.;
• We introduce a Transformer-based refinement network for sampling from trajectory distribution to obtain rep-resentative and realistic trajectories;
• We demonstrate the state-of-the-art performance of our framework on two real-world datasets: Stanford
Drone dataset [40] and Intersection Drone dataset [3]. 2.