Abstract
We introduce AiD Regen, a novel system that gener-ates 3D wound models combining 2D semantic segmenta-tion with 3D reconstruction so that they can be printed via 3D bio-printers during the surgery to treat diabetic foot ul-cers (DFUs). AiD Regen seamlessly binds the full pipeline, which includes RGB-D image capturing, semantic segmen-tation, boundary-guided point-cloud processing, 3D model reconstruction, and 3D printable G-code generation, into a single system that can be used out of the box. We developed a multi-stage data preprocessing method to handle small and unbalanced DFU image datasets. AiD Regen’s human-in-the-loop machine learning interface enables clinicians to not only create 3D regenerative patches with just a few touch interactions but also customize and conﬁrm wound boundaries. As evidenced by our experiments, our model outperforms prior wound segmentation models and our re-construction algorithm is capable of generating 3D wound models with compelling accuracy. We further conducted a case study on a real DFU patient and demonstrated the ef-fectiveness of AiD Regen in treating DFU wounds. 1.

Introduction
Diabetic foot ulcer (DFU) is the most costly and dev-astating complication of diabetes mellitus, which affects 15 % of diabetic patients during their lifetimes [61]. Poor blood circulation and high glucose levels decrease diabetic patients’ ability to heal, and every 20 seconds, a leg is lost through amputation due to infection and necrosis [3].
With the urgent need for a novel treatment method, the integration of 3D printing and bio-materials is paving the way toward devising innovative solutions in regenerative medicine [48]. Kesavan et al. [35] have applied 3D bio-printed patches, that consist of minimally manipulated ex-tracellular matrix (MA-ECM) harvested from autologous fat tissues, to DFU wounds and shown a complete healing with re-epithelialization only within about four weeks.
However, such use of 3D bio-printing technology is not accessible for many medical practitioners as it requires a complex process of 3D scanning and modeling. Conven-tional medical scanning methods, such as CT and MRI scans, often demand large, special devices and environ-ments as well as experts who can operate them. In addition, the results of these scans usually include unnecessary parts and peripherals so that hospitals need to hire CAD engi-neers for post-processing the results or rely on outsourcing; either way, cost increases are inevitable. Also, since treat-ments of skin wounds like DFU are usually followed by debridement, a surgical removal of damaged tissue, the 3D patch creation must be done as quickly as possible to pre-vent debrided wounds from contamination. External post-processing and outsourcing might not be the best solutions in such time sensitive situations. Though portable indus-trial 3D scanners [53] lowered spatial and technical barri-ers, they still require users to understand correct scanning
methods, and the post-processing needs remain the same. 3D object reconstruction using RGB-D images [65] has been actively studied to automate modeling tasks; segment-ing each part of an object can be done in real-time [42].
Unfortunately, however, most existing wound datasets con-sist only of 2D images, and available medical data are of-ten small or fragmented due to their sensitive nature; that is, preparing a large RGB-D or 3D wound training dataset might be difﬁcult. Hybrid approaches, that combine fea-tures extracted from 2D images with depth data, could be good solutions to this as they have shown convincing per-formance in reconstructing wounds [19, 21, 64].
In this work, we introduce AiD Regen, a novel sys-tem that generates 3D models based on the shape and ge-ometry of wounds combining 2D image segmentation and 3D reconstruction so that they can be printed via 3D bio-printers during the surgery to treat DFUs. AiD Regen seam-lessly binds the full pipeline, which includes RGB-D image capturing, semantic segmentation, boundary-guided point-cloud processing (BGPCP), 3D model reconstruction, and 3D bio-printable G-code generation, into a single system that can be used out of the box. We also develop a multi-stage data pipeline to handle small and unbalanced charac-teristics of a DFU image dataset. Reﬂecting requirements of medical practitioners, AiD Regen’s human-in-the-loop (HITL) machine learning (ML) interface enables clinicians to not only create 3D regenerative patches with just a few number of touch interactions, but also customize and con-ﬁrm wound boundaries. We evaluate the performance of our 2D segmentation and 3D model generation methods through a series of experiments and demonstrate the effec-tiveness of AiD Regen by conducting a case study on a real
DFU patient. 2.