Abstract
Deep implicit shape models have become popular in the computer vision community at large but less so for biomed-ical applications. This is in part because large training databases do not exist and in part because biomedical an-notations are often noisy. In this paper, we show that by introducing templates within the deep learning pipeline we can overcome these problems. The proposed framework, named ImplicitAtlas, represents a shape as a deformation field from a learned template field, where multiple templates could be integrated to improve the shape representation ca-pacity at negligible computational cost. Extensive experi-ments on three medical shape datasets prove the superiority over current implicit representation methods. 1.

Introduction
Shape modeling is central to medical image analysis, and many different approaches to surface representation have been used for this purpose [16, 36]. In recent years, deep implicit surfaces [8, 38, 44] have emerged as a powerful al-ternative to more established methods. This is particularly true in the field of computer vision at large but less so in the subfield of biomedical imaging.
This is attributable to the specific challenges posed by biomedical datasets [27, 56]: For manufactured objects, there are large datasets [6, 31] that can be used for train-ing purposes of shape models. These do not exist for many objects of interests in medical imaging, such as the shape of organs and lesions. Even when medical images and the corresponding 3D models are available, the models are of much lower quality due to the complexity and expense of precise annotation. Furthermore, within a single dataset, spatial resolution is rarely constant and often anisotropic.
Human errors can result in labeling noise, and organ bound-aries are often cropped due to the limitations of imaging process. Fig. 2 illustrates some of these difficulties.
To address these issues, we propose ImplicitAtlas, a data-efficient implicit shape model for medical imaging. During training, exemplars represented on discrete grids are taken
*Corresponding author.
Figure 1. ImplicitAtlas. We propose a data-efficient shape model for medical imaging.
It represents shapes by deforming one of several learned templates. as input, the most common representation in the biomed-ical imaging, and the model outputs a continuous occu-pancy grid. Here, an implicit function learns multiple tem-plates, which can undergo non-rigid deformations learned by another implicit function. As in multi-atlas segmen-tation [21, 58], the templates make our approach better at dealing with limited training data and less sensitive to la-bel noise. Thanks to a straight-through estimator (STE) [3], multiple templates can be learned in an end-to-end fash-ion at negligible computational cost. Finally, to improve the data efficiency further, we introduce a convolutional im-plicit function [9, 45] to extract multi-scale features.
To demonstrate the effectiveness of ImplicitAtlas, we perform extensive experiments on three medical shape datasets of liver, hippocampus and pancreas. Our method outperforms current implicit representation-based meth-ods [12, 38, 45, 72] by considerable margins, especially when trained in a few-shot learning setting. We also demon-strate several potential applications, such as shape comple-tion from user-supplied point annotations and keypoint la-lem, which requires refined techniques [15, 41]. Triangu-lated meshes allow memory-efficient processing for high-fidelity surface reconstruction [14, 28, 61, 62] but changing their topology is non-trivial. There are algorithms designed for this purpose [37], but they require ad hoc heuristics that do not generalize well.
Implicit Representations. Recently, implicit representa-tions [8, 38, 44] has become increasingly popular in deep learning-based 3D computer vision. They represent a 3D shape as an isosurface in a continuous 3D field, which is parameterized by a deep network. Due to their flexibility, memory efficiency, and ability to represent any topology at any resolution, implicit representations have been widely investigated not only for shape, but also appearance [39] and scene [42] modeling.
However, they have not yet made big inroads in medical image analysis. On of the few studies in that area can be found in [49]. But it focuses on refining medical image seg-mentation produced using existing implicit representation methods. We instead focus on a high-quality implicit rep-resentation method to address the difficulty of developing implicit fields in biomedical imaging area.
This paucity of implicit methods can be attributed to the specific challenges in biomedical image processing: Large databases are rarely available and annotations are often im-precise. Using atlases and templates in shape modeling has long been known as a good approach to tackle these issues, and we discuss them below.
Atlases and Templates. Probabilistic atlases are widely used for atlas-based image segmentation [21, 58] because they are an excellent mean to deal with the noise in biomed-ical imagery. With the advent of deep learning, atlases have been integrated into convolutional neural networks [2, 13, 20, 54]. All these approaches rely on pre-computed atlases.
They are created by fusing multiple manually annotated im-ages; the atlases must also be pre-registered to the target im-ages to align them with the structures of interest. In [60], an attempt is made to use atlases that could be automatically aligned and deformed to match the target structures.
On the other hand, templates are used in conjunction with implicit surfaces in [12, 72]. This involves using an implicit method to predict deformations around a template, where the deformation and template are both parameter-ized implicitly. However, these methods were developed on large training datasets in mind, and data efficiency is not the primary focus. Both rely on MLP decoders that do not in-troduce spatial reductive bias as convolutional ones do [45].
Besides, only a single implicit template can be automati-cally learned by these methods, and a central argument of this paper is that it is beneficial to more than one.
Figure 2. Common Artefacts in Biomedical Shapes. As medi-cal shapes are annotated in image stacks, they are generally rep-resented in discrete grids. The annotations usually include label noise and incomplete borders. beling by the learned dense correspondences. As will be shown, in spite of the challenges that biomedical datasets pose, the proposed implicit methods is made very effective by allowing them to learn multiple templates from training data, and to choose one to reconstruct a particular organ. 2.