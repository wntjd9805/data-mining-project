Abstract
Modern handheld devices can acquire burst image se-quence in a quick succession. However, the individual ac-quired frames suffer from multiple degradations and are misaligned due to camera shake and object motions. The goal of Burst Image Restoration is to effectively combine complimentary cues across multiple burst frames to gen-erate high-quality outputs. Towards this goal, we develop a novel approach by solely focusing on the effective in-formation exchange between burst frames, such that the degradations get filtered out while the actual scene de-tails are preserved and enhanced. Our central idea is to create a set of pseudo-burst features that combine com-plimentary information from all the input burst frames to seamlessly exchange information. However, the pseudo-burst cannot be successfully created unless the individ-ual burst frames are properly aligned to discount inter-frame movements. Therefore, our approach initially ex-tracts pre-processed features from each burst frame and matches them using an edge-boosting burst alignment mod-ule. The pseudo-burst features are then created and en-riched using multi-scale contextual information. Our fi-nal step is to adaptively aggregate information from the pseudo-burst features to progressively increase resolution in multiple stages while merging the pseudo-burst features.
In comparison to existing works that usually follow a late fusion scheme with single-stage upsampling, our approach performs favorably, delivering state-of-the-art performance on burst super-resolution, burst low-light image enhance-ment and burst denoising tasks. The source code and pre-trained models are available at https://github. com/akshaydudhane16/BIPNet. 1.

Introduction
High-end DSLR cameras can capture images of excel-lent quality with vivid details. With the growing popularity of smartphones, the main goal of computational photogra-phy is to generate DSLR-like images with smartphone cam-eras [24]. However, the physical constraints of smartphone
Figure 1. Holistic diagram of our burst image processing ap-proach. Our network BIPNet takes as input a RAW image burst and generates a high-quality RGB image. BIPNet has three key stages. (1) Edge boosting feature alignment to remove noise, and inter-frame spatial and color misalignment. (2) Pseudo-burst fea-ture fusion mechanism to enable inter-frame communication and feature consolidation. (3) Adaptive group upsampling to progres-sively increase spatial resolution while merging multi-frame infor-mation. While BIPNet is generalizable to other restoration tasks, here we show super-resolution application. cameras hinder the image reconstruction quality. For in-stance, small sensor size limits spatial resolution and small lens and aperture provides noisy and color distorted images in low-light conditions [12]. Similarly, small pixel cavities accumulate less light therefore yielding low-dynamic range.
To alleviate these issues, burst (multi-frame) photography is a natural solution instead of single-frame processing [21].
The goal of burst imaging is to composite a high-quality image by merging desired information from a collection of (degraded) frames of the same scene captured in a rapid succession. However, burst image acquisition presents its own challenges. For example, during image burst capturing, any movement in camera and/or scene objects will cause misalignment issues, thereby leading to ghosting and blur-ring artifacts in the output image [53]. Therefore, there is a pressing need to develop a multi-frame processing al-gorithm that is robust to alignment problems and requires no special burst acquisition conditions. We note that ex-isting burst processing techniques [4, 5] extract and align features of burst images separately and usually employ late feature fusion mechanisms, which can hinder flexible infor-mation exchange among frames. In this paper, we present a burst image processing approach, named BIPNet, which is based on a novel pseudo-burst feature fusion mechanism that enables inter-frame communication and feature consol-idation. Specifically, a pseudo-burst is generated by ex-changing information across frames such that each feature in the pseudo-burst contains complimentary properties of all input burst frames.
Before synthesizing pseudo-bursts, it is essential to align the input burst frames (having arbitrary displacements) so that the relevant pixel-level cues are aggregated in the later stages. Existing works [4, 5] generally use explicit mo-tion estimation techniques (e.g., optical flow) to align in-put frames which are typically bulky pretrained modules that cannot be fully integrated within an end-to-end learn-able pipeline. This can result in errors caused during the flow estimation stage to be propagated to the warping and image processing stages, thereby negatively affecting the generated outputs. In our case, the proposed BIPNet im-plicitly learns the frame alignment with deformable con-volutions [64] that can effectively adapt to the given prob-lem. Further, we integrate the edge boosting refinement via back-projection operation [19] in the alignment stage to re-tain high-frequency information. It facilitates sustaining the alignment accuracy in cases where highly complex motions between burst images exist and only the deformable convo-lutional may not be sufficient for reliable alignment.
Noise is always present in images irrespective of the lighting condition in which we acquire them. Therefore one of our major goals is to remove noise [57] early in the network to reduce difficulty for the alignment and fusion stages. To this end, we incorporate residual global con-text attention in BIPNet for feature extraction and refine-ment/denoising. While the application of BIPNet can be generalized to any burst processing task, we demonstrate its effectiveness on burst super-resolution, burst low-light im-age enhancement and burst denoising. In super-resolution (SR), upsampling is the key step for image reconstruction.
Existing burst SR methods [4, 5] first fuse the multi-frame features, and then use pixel-shuffle operation [43] to obtain the high-resolution image. However, we can leverage the in-formation available in multiple frames to perform merging and upsampling in a flexible and effective manner. As such, we include adaptive group upsampling in our BIPNet that progressively increases the resolution while merging com-plimentary features. BIPNet schematic is shown in Fig. 1.
The main contributions of this work include:
• An edge boosting alignment technique that removes spatial and color misalignment issues among the burst features. (Sec. 3.1)
• A novel pseudo-burst feature fusion mechanism to en-able inter-frame communication and feature consoli-dation. (Sec. 3.2)
• An adaptive group upsampling module for progressive fusion and upscaling. (Sec. 3.3)
Our BIPNet achieves state-of-the-art results on synthetic and real benchmark datasets for the burst super-resolution, low-light image enhancement and burst denoising tasks. We provide comprehensive ablation results and visual examples to highlight the contributing factors in BIPNet (Sec. 4). 2.