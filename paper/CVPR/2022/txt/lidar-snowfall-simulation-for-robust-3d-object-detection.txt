Abstract 3D object detection is a central task for applications such as autonomous driving, in which the system needs to localize and classify surrounding traffic agents, even in the presence of adverse weather. In this paper, we address the problem of LiDAR-based 3D object detection under snow-fall. Due to the difficulty of collecting and annotating train-ing data in this setting, we propose a physically based method to simulate the effect of snowfall on real clear-weather LiDAR point clouds. Our method samples snow particles in 2D space for each LiDAR line and uses the in-duced geometry to modify the measurement for each LiDAR beam accordingly. Moreover, as snowfall often causes wet-ness on the ground, we also simulate ground wetness on
LiDAR point clouds. We use our simulation to generate par-tially synthetic snowy LiDAR data and leverage these data for training 3D object detection models that are robust to snowfall. We conduct an extensive evaluation using several state-of-the-art 3D object detection methods and show that our simulation consistently yields significant performance gains on the real snowy STF dataset compared to clear-weather baselines and competing simulation approaches, while not sacrificing performance in clear weather. Our code is available at github.com/SysCV/LiDAR snow sim. 1.

Introduction
A light detection and ranging (LiDAR) sensor is an ac-tive range sensor useful for several applications [10, 27, 39, 61]. Its high-quality 3D output renders LiDAR the modal-ity of choice for several tasks that require 3D reasoning, such as 3D object detection [25, 59]. As LiDAR sensors are becoming increasingly cheaper [53], their integration into autonomous cars becomes increasingly feasible as well.
Nonetheless, previous sensor tests have revealed that such active pulsed systems are vulnerable in scattering me-dia, leading to decreases of perception distances in various weather conditions such as rain [4, 14, 52], fog [2, 4, 18, 19, 52], and snow [19, 24, 28], as shown in Fig. 1. In these con-ditions, the optical medium contains particles of water or snow which interact with the laser beam and absorb, reflect
Figure 1. 3D object detection results in heavy snowfall with prior training on the proposed data augmentation scheme (top right) in comparison to no augmentation (top left). The bottom row shows the RGB image as reference. or refract its photons. This results in two effects: (i) atten-uation of the received power that corresponds to the target at the line of sight, and (ii) backscattering from particles leading to spurious maxima in the received power and thus to spurious returns at ranges different from the true range of the target. Consequently, there is a severe degradation of measurement quality due to intense noise, a large do-main shift relative to point clouds captured in clear weather, and hence a detrimental effect on performance of high-level tasks such as 3D object detection [1, 16]. Yet, achieving robust perception in adverse weather is a desirable goal as fatality rates for human drivers are notably higher in adverse weather, as reported by the US Department of Transporta-tion [49] and the European Commission [8].
Since adverse-weather data are hard to collect [1], pre-vious works have investigated simulation methods to close the domain gap for camera data in fog [36] and rain [48].
More recently, simulation methods for LiDAR sensors in fog [1, 16] and rain [14, 22] have also been proposed. Moti-vated by this line of work, we introduce a physically based method to simulate snowfall on real clear-weather LiDAR point clouds. In particular, we use the linear system intro-duced in [33] to model the transmission of LiDAR pulses and the associated received power at the sensor. We sim-ulate snowfall by explicitly sampling snow particles and modeling them as opaque spheres, the size of which is con-trolled by the snowfall rate [15, 32]. In our sampling, we obey the exclusion principle that no two particles intersect with each other. Given the sample of snow particles, we compute for each LiDAR beam the set of particles that in-tersect with it and derive the angle of the beam cross-section that is reflected by each particle, taking potential occlusions into account. This derivation directly delivers the modi-fied impulse response of the linear system in the presence of snowfall, which allows the analytical calculation of the received power at the sensor.
Another condition associated with snowfall is wetness on the ground. This emerging thin water layer increases the specular component of reflection by the ground sur-face [44]. To model the ground reflection, we introduce an optical model using the Fresnel equations and the reflection on thin surfaces, which provides adapted reflectance values for wet surfaces.
The generated partially synthetic point clouds with our snowfall and wet ground simulation are used as train-ing data for optimizing state-of-the-art 3D object detection methods, so that the learned models are more robust un-der snowfall. The hope is that our physically based sim-ulation is realistic enough to relieve us from the need for real snowy training samples. We benchmark the models trained in this regime on the challenging real snowy sub-set of the STF dataset [1] and find that the models trained on our simulated snow consistently achieve significant per-formance gains over baseline models trained only on clear weather and competing simulation methods. 2.