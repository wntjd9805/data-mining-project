Abstract
We present a novel approach for unsupervised activity segmentation which uses video frame clustering as a pretext task and simultaneously performs representation learning and online clustering. This is in contrast with prior works where representation learning and clustering are often per-formed sequentially. We leverage temporal information in videos by employing temporal optimal transport. In partic-ular, we incorporate a temporal regularization term which preserves the temporal order of the activity into the stan-dard optimal transport module for computing pseudo-label cluster assignments. The temporal optimal transport mod-ule enables our approach to learn effective representations for unsupervised activity segmentation. Furthermore, pre-vious methods require storing learned features for the entire dataset before clustering them in an ofﬂine manner, whereas our approach processes one mini-batch at a time in an on-line manner. Extensive evaluations on three public datasets, i.e. 50-Salads, YouTube Instructions, and Breakfast, and our dataset, i.e., Desktop Assembly, show that our approach performs on par with or better than previous methods, de-spite having signiﬁcantly less memory constraints. 1.

Introduction
With the advent of deep learning, signiﬁcant progress has been made in understanding human activities in videos.
However, most of the research efforts so far have been in-vested in action recognition [11, 76, 77, 82], where the task is to classify simple actions in short videos. Recently, a few approaches have been proposed for dealing with com-plex activities in long videos, e.g., temporal action local-ization [13, 68, 69, 88], which aims to detect video seg-† indicates joint ﬁrst author.
{sateesh,sanjay,awais,andrey,zeeshan,huy}@retrocausal.ai.
Figure 1. (a) Previous approaches [43, 52, 65, 78] often perform representation learning and clustering sequentially, while storing embedded features for the entire dataset before clustering them. (b) We unify representation learning and clustering into a single joint framework, which processes one mini-batch at a time. Our method explicitly optimizes for unsupervised activity segmenta-tion and is much more memory efﬁcient. ments containing the actions of interest, and anomaly de-tection [27, 32, 74], whose goal is to localize video frames containing anomalous events in an untrimmed video.
In this paper, we are interested in the problem of tempo-ral activity segmentation, where our goal is to assign each frame of a long video capturing a complex activity to one of the action/sub-activity classes. One popular group of meth-ods [14, 40, 41, 46, 53] on this topic require per-frame ac-tion labels for fully-supervised training. However, frame-level annotations for all training videos are generally difﬁ-cult and prohibitively costly to acquire. Weakly-supervised approaches which need weak labels, e.g., the ordered action list or transcript for each video [12,18,35,42,50,61,62,64], have also been proposed. Unfortunately, these weak labels are not always available a priori and can be time consuming to obtain, especially for large datasets.
To avoid the above annotation requirements, unsuper-vised methods [3, 43, 52, 57, 65, 66, 78] have been intro-duced recently. Given a collection of unlabeled videos,
they jointly discover the actions and segment the videos by grouping frames across all videos into clusters, with each cluster corresponding to one of the actions. Previ-ous approaches [43, 52, 65, 78] in unsupervised activity seg-mentation usually separate the representation learning step from the clustering step in a sequential learning and clus-tering framework (see Fig. 1(a)), which prevents the feed-back from the clustering step from ﬂowing back to the rep-resentation learning step. Also, they need to store computed features for the entire dataset before clustering them in an ofﬂine manner, leading to inefﬁcient memory usage.
In this work, we present a joint representation learn-ing and online clustering approach for unsupervised activ-ity segmentation (see Fig. 1(b)), which uses video frame clustering as a pretext task and hence directly optimizes for unsupervised activity segmentation. We employ tem-poral optimal transport to leverage temporal information in videos. Speciﬁcally, the temporal optimal transport mod-ule preserves the temporal order of the activity when com-puting pseudo-label cluster assignments, yielding effective representations for unsupervised activity segmentation. In addition, our approach processes one mini-batch at a time, thus having substantially lesser memory requirements.
In summary, our contributions include:
• We propose a novel method for unsupervised activ-ity segmentation, which jointly performs representa-tion learning and online clustering. We leverage video frame clustering as a pretext task, thus directly opti-mizing for unsupervised activity segmentation.
• We introduce the temporal optimal transport module to exploit temporal cues in videos by imposing tempo-ral order-preserving constraints on computed pseudo-label cluster assignments, yielding effective represen-tations for unsupervised activity segmentation.
• Our method performs on par with or better than the state-of-the-art in unsupervised activity segmentation on public datasets, i.e., 50-Salads, YouTube Instruc-tions, and Breakfast, and our dataset, i.e., Desktop As-sembly, while being much more memory efﬁcient.
• We collect and label our Desktop Assembly dataset, which is available at https://bit.ly/3JKm0JP. 2.