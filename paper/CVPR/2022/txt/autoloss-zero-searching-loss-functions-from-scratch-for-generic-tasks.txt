Abstract
Signiﬁcant progress has been achieved in automating the design of various components in deep networks. How-ever, the automatic design of loss functions for generic tasks with various evaluation metrics remains under-investigated.
Previous works on handcrafting loss functions heavily rely on human expertise, which limits their extensibility. Mean-while, searching for loss functions is nontrivial due to the vast search space. Existing efforts mainly tackle the issue by employing task-speciﬁc heuristics on speciﬁc tasks and par-ticular metrics. Such work cannot be extended to other tasks without arduous human effort.
In this paper, we propose
AutoLoss-Zero, which is a general framework for searching loss functions from scratch for generic tasks. Speciﬁcally, we design an elementary search space composed only of primitive mathematical operators to accommodate the het-erogeneous tasks and evaluation metrics. A variant of the evolutionary algorithm is employed to discover loss func-tions in the elementary search space. A loss-rejection pro-tocol and a gradient-equivalence-check strategy are devel-oped so as to improve the search efﬁciency, which are ap-plicable to generic tasks. Extensive experiments on various computer vision tasks demonstrate that our searched loss functions are on par with or superior to existing loss func-tions, which generalize well to different datasets and net-works. Code shall be released. 1.

Introduction
Recent years have witnessed exciting progress in Au-toML for deep learning [15, 35, 36, 41, 42, 68]. The auto-matic design of many components has been explored, rang-ing from architectures (e.g., neural architectures [50] and normalization-activation operations [35]) to learning strate-*Equal contribution. †This work is done when Hao Li and Tianwen Fu are interns at SenseTime Research. ‡Corresponding author. gies (e.g., data augmentation strategies [15], dropout pat-terns [42], and training hyper-parameters [16]). However, to automate the entire deep learning process, an essential component is under-investigated, namely, the automatic de-sign of loss functions for generic tasks.
Loss functions are indispensable parts in deep network training.
In various tasks, including semantic segmenta-tion [7, 65], object detection [19, 51], instance segmenta-tion [3, 23] and pose estimation [56], cross-entropy (CE) and L1/L2 losses are the default choices for categorization and regression, respectively. As the default loss functions are usually approximations for speciﬁc evaluation metrics, there usually exists a misalignment between the surrogate loss and the ﬁnal evaluation metric. For example, for bounding box localization in object detection, L1 loss is widely used, while the IoU metric is the standard evalu-ation metric [63]. Similar discrepancy has also been ob-served in semantic segmentation [31], where some metrics measure the accuracy of the whole image, while others fo-cus more on the segmentation boundaries. The misalign-ment between network training and evaluation results in sub-optimal solutions with degraded performance.
A multitude of handcrafted loss functions have been pro-posed for different evaluation metrics. Since most desired metrics are non-differentiable and cannot be directly used as training objectives, many existing works [4, 19, 29, 33, 44, 53, 61] design differentiable variants of the CE and
L1/L2 losses by carefully analyzing speciﬁc evaluation met-rics. Another series of works [2, 38, 43, 45, 52, 63, 66] handcraft clever surrogate losses based on the mathematical expressions of speciﬁc evaluation metrics. Although these handcrafted loss functions show improvement on their tar-get metrics, they heavily rely on expertise and careful anal-ysis for speciﬁc scenarios, which limits their extendibility.
In this paper, we aim to automate the design of loss func-tions for generic tasks. Although there are several pioneer works [30, 31, 37, 58] on loss function search, they are
all limited to speciﬁc tasks and particular evaluation met-rics, with task-speciﬁc heuristics, which cannot be applied to generic tasks. For example, [31] constructs the search space by parametrizing the evaluation metrics of semantic segmentation, which can hardly be applied to mAP metric in object detection; [37] proposes a rejection protocol for object detection, which is designed based on speciﬁc analy-sis of mAP metric properties by human expertise. Searching loss functions for generic tasks is much more challenging, because of the heterogeneity of various tasks and evalua-tion metrics. The search space should be composed of ba-sic primitive operators so as to accommodate such hetero-geneity, and the search algorithm should be efﬁcient enough so as to ﬁnd the best combination of basic primitives for the given task and evaluation metric. Meanwhile, no task-speciﬁc heuristics should be involved in the search.
This paper presents a general loss function search frame-work applicable to various evaluation metrics across dif-ferent tasks, named AutoLoss-Zero. We build our search space only with primitive mathematical operators to enjoy the high diversity and expressiveness. A variant of the evo-lutionary algorithm is employed to discover the high-quality loss functions from scratch with minimal human expertise.
Speciﬁcally, AutoLoss-Zero formulates loss functions as computational graphs composed only of primitive mathe-matical operators (see Table 1). The computation graphs are randomly built from scratch, and are evolved according to their performance on the target evaluation metrics. In the search algorithm, to improve the search efﬁciency, we pro-pose a loss-rejection protocol that efﬁciently ﬁlters out the unpromising loss function candidates, which brings great speed-up to the search procedure. A gradient-equivalence-check strategy is developed to avoid duplicate evaluations of equivalent loss functions. The loss-rejection protocol and the gradient-equivalence-check strategy, with no task-speciﬁc or metric-speciﬁc design, are generally applicable to various tasks and metrics.
We validate our framework on various computer vision tasks, including semantic segmentation, object detection, instance segmentation, and pose estimation. Extensive ex-periments on large-scale datasets such as COCO [34], Pas-cal VOC [17] and Cityscapes [13] show that the searched losses are on par with or superior to existing handcrafted and speciﬁcally searched loss functions. Ablation studies show that our searched loss functions can effectively gener-alize to different networks and datasets. Our main contribu-tions can be summarized as follows:
• AutoLoss-Zero is a general AutoML framework to search loss functions from scratch for generic tasks with minimal human expertise. The effectiveness is demon-strated on a variety of computer vision tasks.
• A novel loss-rejection protocol is developed to ﬁlter out the unpromising loss functions efﬁciently. A gradient-equivalence-check strategy is also developed to avoid duplicate evaluations. These techniques bring great im-provement to the search efﬁciency, and are designed with special focus to enable generalization to all tasks and metrics without extra effort.
• The searched loss functions by themselves are contribu-tions, because they are transferable across different mod-els and datasets with competitive performance. 2.