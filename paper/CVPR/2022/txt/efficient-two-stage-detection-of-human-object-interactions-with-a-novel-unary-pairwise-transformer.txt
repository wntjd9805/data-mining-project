Abstract
Recent developments in transformer models for visual data have led to signiﬁcant improvements in recognition and detection tasks. In particular, using learnable queries in place of region proposals has given rise to a new class of one-stage detection models, spearheaded by the De-tection Transformer (DETR). Variations on this one-stage approach have since dominated human–object interaction (HOI) detection. However, the success of such one-stage
HOI detectors can largely be attributed to the represen-tation power of transformers. We discovered that when equipped with the same transformer, their two-stage coun-terparts can be more performant and memory-efﬁcient, while taking a fraction of the time to train. In this work, we propose the Unary–Pairwise Transformer, a two-stage de-tector that exploits unary and pairwise representations for
HOIs. We observe that the unary and pairwise parts of our transformer network specialise, with the former preferen-tially increasing the scores of positive examples and the lat-ter decreasing the scores of negative examples. We evaluate our method on the HICO-DET and V-COCO datasets, and signiﬁcantly outperform state-of-the-art approaches. At in-ference time, our model with ResNet50 approaches real-time performance on a single GPU. 1.

Introduction
Human–object interaction (HOI) detectors localise inter-active human–object pairs in an image and classify the ac-tions. They can be categorised as one- or two-stage, mirror-ing the grouping of object detectors. Exempliﬁed by Faster
R-CNN [24], two-stage object detectors typically include a region proposal network, which explicitly encodes po-tential regions of interest in the form of bounding boxes.
These bounding boxes can then be classiﬁed and further re-ﬁned via regression in a downstream network. In contrast, one-stage detectors, such as RetinaNet [18], retain the ab-(a) Image with human and object detections. (b) Unary and pairwise tokens with predicted scores (riding a motorcycle).
Figure 1. Our Unary–Pairwise Transformer encodes human and object instances individually and in pairs, allowing it to reason about the data in complementary ways. In this example, our net-work correctly identiﬁes the interactive pairs for the action riding a motorcycle, while suppressing the visually-similar non-interactive pairs and those with different associated actions. stract feature representations of objects throughout the net-work, and decode them into bounding boxes and classiﬁca-tion scores at the end of the pipeline.
In addition to the same categorisation convention, HOI detectors need to localise two bounding boxes per instance instead of one. Early works [2, 8, 16, 23] employ a pre-trained object detector to obtain a set of human and object boxes, which are paired up exhaustively and processed by a downstream network for interaction classiﬁcation. This methodology coincides with that of two-stage detectors and quickly became the mainstream approach due to the acces-sibility of high-quality pre-trained object detectors. The
ﬁrst instance of one-stage HOI detectors was introduced by
Figure 2. Mean average precision as a function of the number of epochs (left) and training time (right) to convergence. The back-bone networks for all methods have been initialised with the same weights and trained on 8 GeForce GTX TITAN X GPUs.
Table 1. The performance discrepancy between existing state-of-the-art one-stage and two-stage HOI detectors is largely at-tributable to the choice of backbone network. We report the mean average precision (×100) on the HICO-DET [2] test set.
Method
Type
Detector Backbone
SCG [28]
SCG [28]
SCG [28]
Faster R-CNN R-50-FPN two-stage two-stage DETR R-50 two-stage DETR R-101
QPIC [25]
QPIC [25] one-stage DETR R-50 one-stage DETR R-101
Ours
Ours two-stage DETR R-50 two-stage DETR R-101 mAP 24.88 28.79 29.26 29.07 29.90 31.66 32.31
Liao et al. [17]. They characterised human–object pairs as interaction points, represented as the midpoint of the human and object box centres. Recently, due to the great success in using learnable queries in transformer decoders for local-isation [1], the development of one-stage HOI detectors has been greatly advanced. However, HOI detectors that adapt the DETR model rely heavily on the transformer, which is notoriously difﬁcult to train [20], to produce discriminative features. In particular, when initialised with DETR’s pre-trained weights, the decoder attends to regions of high ob-jectness by default. The heavy-weight decoder stack then has to be adapted to attend to regions of high interactive-ness. Consequently, training such one-stage detectors of-ten consumes large amounts of memory and time as shown in Fig. 2. In contrast, two-stage HOI detectors do not re-purpose the backbone network, but maintain it as an object detector. Since the ﬁrst half of the pipeline already func-tions as intended at the beginning of training, the second half can be trained quickly for the speciﬁc task of HOI de-tection. Furthermore, since the object detector can be de-coupled from the downstream interaction head during train-ing, its weights can be frozen, and a lighter-weight network can be used for interaction detection, saving a substantial amount of memory and computational resources.
Despite these advantages, the performance of two-stage detectors has lagged behind their one-stage counterparts.
However, most of these two-stage models used Faster R-CNN [24] rather than more recent object detectors. We found that simply replacing Faster R-CNN with the DETR model in an existing two-stage detector (SCG) [28] resulted in a signiﬁcant improvement, putting it on par with a state-of-the-art one-stage detector (QPIC), as shown in Tab. 1.
We attribute this performance gain to the representation power of transformers and bipartite matching loss [1]. The latter is particularly important because it resolves the mis-alignment between the training procedure and evaluation protocol. The evaluation protocol dictates that, amongst all detections associated with the same ground truth, the high-est scoring one is the true positive while the others are false positives. Without bipartite matching, all such detections will be labelled as positives. The detector then has to resort to heuristics such as non-maximum suppression to mitigate the issue, resulting in procedural misalignment.
We propose a two-stage model that reﬁnes the output features from DETR with additional transformer layers for
HOI classiﬁcation. As shown in Fig. 1, we encode the instance information in two ways: a unary representation where individual human and object instances are encoded separately, and a pairwise representation where human– object pairs are encoded jointly. These representations pro-vide orthogonal information, and we observe different be-haviours in their associated layers. The unary encoder layer preferentially increases the predicted interaction scores for positive examples, while the pairwise encoder layer sup-presses the negative examples. As a result, this comple-mentary behaviour widens the gap between scores of posi-tive and negative examples, particularly beneﬁting ranking metrics such as mean average precision (mAP).
Our primary contribution is a novel and efﬁcient two-stage HOI detector with unary and pairwise encodings. Our secondary contribution is demonstrating how pairwise box positional encodings—critical for HOI detection—can be incorporated into a transformer architecture, enabling it to jointly reason about unary appearance and pairwise spa-tial information. We further provide a detailed analysis on the behaviour of the two encoder layers, showing that they have complementary properties. Our proposed model not only outperforms state-of-the-art methods, but also con-sumes much less time and memory to train. The latter al-lows us to employ more memory-intensive backbone net-works, further improving the performance. 2.