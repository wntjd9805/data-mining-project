Abstract
Video deblurring has achieved remarkable progress thanks to the success of deep neural networks. Most meth-ods solve for the deblurring end-to-end with limited in-formation propagation from the video sequence. How-ever, different frame regions exhibit different characteris-tics and should be provided with corresponding relevant information. To achieve fine-grained deblurring, we de-signed a memory branch to memorize the blurry-sharp fea-ture pairs in the memory bank, thus providing useful infor-mation for the blurry query input. To enrich the memory of our memory bank, we further designed a bidirectional recurrency and multi-scale strategy based on the memory bank. Experimental results demonstrate that our model out-performs other state-of-the-art methods while keeping the model complexity and inference time low. The code is avail-able at https://github.com/jibo27/MemDeblur. 1.

Introduction
Video deblurring is a core restoration and enhancement task aiming to recover a sharp video from a blurry input video. Blur in videos arises from various sources, e.g. ob-ject motion, camera shake, and depth of field. Video deblur-ring is a highly ill-posed problem as multiple sharp sources may correspond to a single blurred result. The problem becomes especially pertinent as more and more videos are captured by smartphones.
Video deblurring distinguishes itself from the image de-blurring task in that it is critical to use the information from the entire sequence of frames effectively. To do so, window-based models [17,22,23,27] feed consecutive blurry frames to an encoder-decoder to directly restore a sharp frame. Re-current models [6, 15, 30, 35, 36] on the other hand maintain a hidden state across the frames to sequentially propagate features from the first frame to the last. However, these methods cannot utilize the information from all the frames in the video sequence. Moreover, neighbouring frames are often used in simplistic manners, e.g. via an alignment.
An underexplored aspect in video-deblurring is that blur-ring occurs from non-uniform blur kernels. The blur ar-tifacts differ not only for the same object across different (a) Frame 0 (b) Frame 16 (c) Frame 20 (d) Frame 86
Figure 1. Different image regions have different blurry artifacts. frames but also for different objects or regions in the same frame. As shown in Fig. 1, the same flower in different frames of a sequence exhibits different extents of blur (com-pare the blue sample in frame 16 and 86 vs. 0 and 20). Dif-ferent flowers in the same frame (see frames 16, 20) also have various blur distortions due to object motion. This makes spatio-temporal information aggregation difficult as it is necessary to provide the appropriate information to dif-ferent regions of a frame.
To remedy this problem, we adopt the principle of mem-ory networks [2, 12, 16, 24]. Memory networks were orig-inally developed for language modeling [24] and are cur-rently popular in vision for video object segmentation [2, 16]. In segmentation, the memory encodes high-level se-mantics like objects, but they have not been explored in the context of low-level enhancement tasks like deblurring. The memory networks used in our model record blurry-sharp feature pairs. We compute a spatio-temporal attention be-tween each location of the memory features and that of a query frame region to find helpful sharp information. The implicit advantage is that even if the blur kernel is unknown, we can still extract the corresponding sharp information simply by matching the queried region with memorized fea-tures.
Different from previous works using memory networks, we use memory to supplement information to the deblur-ring backbone. The core deblurring branch is still responsi-ble for recovering low-level details. To enrich the features
(a) Window-based method [17, 22, 27]. (b) Recurrent method [6, 15, 30, 36]. (c) Our proposal.
Figure 2. Temporal receptive field comparison between differ-ent methods for video deblurring. Window-based approach re-constructs sharp images referencing neighbouring frames within a small fixed-size window. Recurrent methods collectively aggre-gate frame features till up-to-date to provide restoration cues. In contrast, our method allows the feature propagation from the entire sequence when restoring the given frame. in the memory bank, we propose a bidirectional and multi-scale structure that better captures information from the en-tire video sequence at different scales. The multi-scale de-sign also allows our model to handle large displacements more effectively. Our contributions can be listed as follows:
• We present a novel memory-based architecture that stores blurry and sharp spatio-temporal patterns to achieve fine-grained video deblurring. To the best of our knowledge, we are the first to adopt a memory net-work for a video enhancement task.
• To increase the diversity of memories in the mem-ory bank, we developed a bidirectional and multi-scale structure based on the memory bank. The multiple scales share the same memory bank, which allows cross-scale matching and effective handling of large motions.
• The experimental results demonstrate that our model achieves superior results than state-of-the-art methods under comparable computational budgets. 2.