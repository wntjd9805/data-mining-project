Abstract
Object rotation is among long-standing, yet still unex-plored, hard issues encountered in the task of weakly super-vised object detection (WSOD) from aerial images. Exist-ing predominant WSOD approaches built on regular CNNs which are not inherently designed to tackle object rota-tions without corresponding constraints, thereby leading to rotation-sensitive object detector. Meanwhile, current so-lutions have been prone to fall into the issue with unsta-ble detectors, as they ignore lower-scored instances and may regard them as backgrounds. To address these is-sues, in this paper, we construct a novel end-to-end weakly supervised Rotation-Invariant aerial object detection Net-work (RINet).
It is implemented with a flexible multi-branch online detector refinement, to be naturally more rotation-perceptive against oriented objects. Specifically,
RINet first performs label propagating from the predicted instances to their rotated ones in a progressive refinement manner. Meanwhile, we propose to couple the predicted in-stance labels among different rotation-perceptive branches for generating rotation-consistent supervision and mean-while pursuing all possible instances. With the rotation-consistent supervisions, RINet enforces and encourages consistent yet complementary feature learning for WSOD without additional annotations and hyper-parameters. On the challenging NWPU VHR-10.v2 and DIOR datasets, extensive experiments clearly demonstrate that we signif-icantly boost existing WSOD methods to a new state-of-the-art performance. The code will be available at: https://github.com/XiaoxFeng/RINet. 1.

Introduction
Object detection is an indispensable task in both com-puter vision and earth vision with many applications. Re-cent impressive progress in object detection has been boosted by the boom of powerful deep Convolutional Neu-ral Network (CNN) and the availability of abundant datasets with subtle annotations. However, collecting such subtle annotations is time-consuming and even infeasible, which
∗Corresponding author.
Figure 1. Typical issues and our solutions for WSOD in aerial images. (a) The image and its rotated image produce inconsistent detection results. (b) Existing WSOD methods incline to detect salient objects or object parts, leading to instances missing. has seriously impeded the applications of object detection in the real-world. To alleviate the heavy label cost, WSOD, which requires only incomplete image-level annotations to learn the precise object detection model, has been exten-sively explored and achieved impressive results.
As far as we know, almost all predominated WSOD methods [5,7,8,10,14,17,19,24,27,30,31,33–35,39,45,47] are built on the Weakly Supervised Deep Detection Net-work (WSDDN) [14] and formulate WSOD as multiple instance learning problems. Based on it, a constructive work, named Online Instance Classifier Refinement (OICR)
[31], is proposed to iteratively refine instance classifier in a unified network. More recently, some advanced works
[9, 17, 19, 24, 25, 27, 30, 33, 34, 43] are proposed to boost the development of WSOD via adopting novel training strate-gies [19, 27, 33, 34, 44, 46], contextual information [17] or extra segmentation networks [9, 24, 38].
The typical WSOD approaches [7, 36, 37, 42] in aerial images are mainly inspired by the object detection algo-rithms developed for natural scenes and endeavor to address the sub-optimal problem. Despite their successes, such ill-posed solution ignores the property of aerial images, that is, many object instances with the same category in aerial
It in-images usually appear with arbitrary orientations. troduces dramatic class-agnostic feature changes, causing sparse feature distribution. Existing predominant WSOD approaches based on regular CNNs which cannot actively encourage such sparse features to be pulled closer without corresponding constraints, causing two typical issues. (1) Rotation-sensitive. As shown in Figure 1 (a), existing methods incline to detect rotation-insensitive object parts and the detection results are inconsistent after rotation even for the same instance. A natural approach to address it is to use instance-level labels where object rotations come from themselves or rotated transformation, whereas WSOD does not have such annotations. Thus, it is regarded as amongst the hardest challenge of WSOD with no effective solutions. (2) Instance missing. Most of the existing WSOD works only explore the most discriminative object. Unfortunately, it is common for an aerial image to contain many instances with the same category. This kind of solution leads to seem-ingly representative yet unstable object detector learning, as it will inevitably introduce class collision problem. Exam-ple testifying this issue is illustrated in Figure 1 (b). The ignored lower-scored instances may be regarded as back-ground. A straightforward way to pursue all possible in-stances is to mine top-ranking instances. However, it is im-practical to eliminate uncertainties and trivial solutions for each category under the weakly supervised paradigm.
To tackle the aforementioned issues, in this paper, we propose a novel weakly supervised rotation-invariant aerial object detection network (RINet), and aim at learning rotation-invariant object detectors and pursuing all possi-ble instances. RINet is inspired by human knowledge i.e., the category of object in aerial images remains consistent after arbitrary rotation. It can be treated as an implicit con-straint for rotation-invariance learning. Encouraging the detection model to make consistent prediction for the pre-dicted instances before and after the rotation can facilitate rotation-invariant learning online. To this end, RINet is implemented with a flexible multi-branch online detector refinement where the predicted instance labels supervise their arbitrary rotated ones in the latter stream. Finally, the instance-level labels before and after rotation are cou-pled to generate rotation-consistent annotations for rotation-invariant learning online.
Furthermore, RINet also naturally projects object in-stances from sparse space to different rotation-aware sub-spaces, which encourages the same category object in-stances with similar orientations to be pulled closer on the embedding space. Motivated by this, coupling instances from different rotation-perceptive branches in a comple-mentary manner is conducive to discover all possible in-stances with the same category. RINet greedily projects predicted labels from different rotation-perceptive branches to an interaction space. Within this interaction space, la-bel propagating is performed over the unlabeled instances under implicit constraint to activate instances in a comple-mentary manner. Integrating all possible instances into the iterative training process can capture abundant intra-class complementary visual patterns to facilitate a more powerful rotation-invariant object detector.
By leveraging category-invariance in rotation, a flexible weakly supervised rotation-invariant object detection net-work is proposed. It not only bridges the gap existing in the object rotation but also provides the reliable and implicit constraint for instance mining. With an end-to-end learning procedure, as shown in Figure 1, RINet effectively allevi-ates the aforementioned challenges and generates consistent detection results. The main contributions of this paper are as follows:
• To the best of our knowledge, we are the first at-tempt to construct a rotation-invariant aerial object de-tection network under a weakly supervised paradigm, and jointly optimize instance refinement and rotation-invariant object detector in a systematic end-to-end manner.
• We design a rotation-invariant multiple instance mining strategy, coupling instances from different rotation-perceptive branches in a complementary man-instances of the ner, same category without introducing additional hyper-parameters. to mine all possible object
• Experiments on NWPU VHR-10.v2 [22] and DIOR
[23] datasets demonstrate that the proposed RINet sig-nificantly updates the performance of state-of-the-art results by a large margin. 2.