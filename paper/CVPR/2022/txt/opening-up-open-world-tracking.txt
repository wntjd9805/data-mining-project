Abstract
Tracking and detecting any object, including ones never-seen-before during model training, is a crucial but elusive capability of autonomous systems. An autonomous agent that is blind to never-seen-before objects poses a safety haz-ard when operating in the real world – and yet this is how almost all current systems work. One of the main obstacles towards advancing tracking any object is that this task is no-toriously difﬁcult to evaluate. A benchmark that would al-low us to perform an apples-to-apples comparison of exist-ing efforts is a crucial ﬁrst step towards advancing this im-portant research ﬁeld. This paper addresses this evaluation deﬁcit and lays out the landscape and evaluation method-ology for detecting and tracking both known and unknown objects in the open-world setting. We propose a new bench-mark, TAO-OW: Tracking Any Object in an Open World, analyze existing efforts in multi-object tracking, and con-struct a baseline for this task while highlighting future chal-lenges. We hope to open a new front in multi-object tracking research that will hopefully bring us a step closer to intelli-gent systems that can operate safely in the real world.
* These authors contributed equally to this work. 1.

Introduction
Understanding common scenarios is easy. Vision systems, trained on millions of examples of cars and pedestrians, work pretty well at detecting these objects, determining what and where they are, and tracking them through a scene. Understanding never-seen-before scenarios is ex-tremely hard. What happens when a plane lands on the road in front an autonomous vehicle? Or a new children’s toy is thrown onto the road? How will current vision systems be able to handle these previously unseen and unknown situa-tions? Will a system designed to detect and track potentially hazardous objects pick up on these at all? Or will they be completely ignored with disastrous consequences (such as a vehicle hitting the child stroller in Fig. 1, bottom-left)?
Tracking and detection methods work reasonably well for objects that have a huge amount of data collected on them. But without building systems that can deal with never-seen-before objects, vision systems will never be safe enough to work in the real world and collecting more data can never scale up to address the inﬁnite variety of possible unknown things that can happen. Many anecdotal exam-ples indicate that current vision systems perform poorly in previously unseen scenarios [60], but we cannot quantita-tively measure this phenomenon, or even evaluate progress, because there are no benchmarks on which to evaluate.
Figure 2. TAO-OW Benchmark class distribution in the valida-tion set, showing known classes for which training data is given, and the unknown classes which serve as a proxy for the inﬁnite variety (unknown unknowns) of objects which may appear in an open-world. Note the y-axis is log-scaled.
In this paper we present a new benchmark (TAO-OW:
Tracking Any Object in an Open World) for measuring de-tection and tracking performance in an open-world setting.
Closed-world multi-object tracking benchmarks [16,18,24] and methods [7,40,78] focus on tracking object classes that belong to a predeﬁned set of frequently observed classes. In contrast, in our Open-World Tracking (OWT) task, all ob-ject must be tracked, and methods are speciﬁcally evaluated on how well they can track object classes that they weren’t allowed to train on (unknown objects), as well as objects which were in the training set (known objects).
Open-World evaluation is inherently difﬁcult. One has to restrict the set of objects that algorithms are allowed to train on. These known objects should be varied and diverse enough to represent the set of objects that could typically be expected to have data collected for, but there should be plen-tiful examples of further unknown objects, not presented as labeled samples to the models being evaluated. We base our work upon the recently introduced TAO dataset [16]1, which contains a large corpus of videos from many diverse scenarios such as driving, movies, and everyday scenes.
Such a wide diversity is important in order to be able to capture a wide range of unknown objects. For known classes we use the 80 classes from COCO [42], which cover a wide range of common objects, while leaving over 700 unknown object categories to evaluate the performance of algorithms on objects for which they have not been trained. In Fig. 2 we show our TAO-OW benchmark, with its inherently long tailed distribution of object categories, its known and un-known split, and a comparison to previous tracking bench-marks [18,24,64,75,88,91], which are all limited to closed-world evaluation on a small number of categories.
Another inherent difﬁculty with open-world evaluation is dealing with the fact that it is impossible to exhaustively an-notate the complete set of objects which should be detected and tracked (by deﬁnition, we do not want to penalize track-ers for tracking unknown, unannotated objects). To tackle this issue, we propose a new evaluation metric called Open-World Tracking Accuracy (OWTA) which naturally decom-poses detection and tracking evaluation components allow-1License available at taodataset.org. ing the evaluation of tracking accuracy in the setting where extra unannotated object detections are not penalized. Such evaluation is enabled by the constraint that proposed objects must be supplied as non-overlapping segmentation masks.
Armed with our Open-World Tracking benchmark and evaluation methodology, we analyze several methods which have attempted this task but have lacked a common eval-uation protocol [17, 47, 56]. A signiﬁcant contribution of this paper is our thorough analysis of a wide variety of ap-proaches. This analysis leads us to propose an open-world tracking approach which currently performs the best on our
Open-World Tracking Benchmark, while also performing very competitively on previous closed-world benchmarks, even though it was not designed or tuned for these.
In summary, the main contribution of this work is to open up a new direction in vision-based multi-object track-ing that goes beyond current closed-world benchmarks. We formalize the Open-World Tracking problem, (i) propose a benchmark with a suitable recall-based evaluation to mea-sure progress, (ii) analyze existing design paradigms, pro-viding a large collection of baselines based on state-of-the-art approaches from the closed-world setting, and (iii) present a strong method which works well for both open-and closed-world tracking. Our experiments show that closed-world detectors work surprisingly well for localizing even unknown objects. However, tracking unknown objects remains more challenging than known objects. 2.