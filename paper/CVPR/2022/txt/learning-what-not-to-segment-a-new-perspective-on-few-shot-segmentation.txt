Abstract
Recently few-shot segmentation (FSS) has been exten-sively developed. Most previous works strive to achieve generalization through the meta-learning framework de-rived from classiﬁcation tasks; however, the trained models are biased towards the seen classes instead of being ide-ally class-agnostic, thus hindering the recognition of new concepts. This paper proposes a fresh and straightforward insight to alleviate the problem. Speciﬁcally, we apply an additional branch (base learner) to the conventional FSS model (meta learner) to explicitly identify the targets of base classes, i.e., the regions that do not need to be segmented.
Then, the coarse results output by these two learners in par-allel are adaptively integrated to yield precise segmentation prediction. Considering the sensitivity of meta learner, we further introduce an adjustment factor to estimate the scene differences between the input image pairs for facilitating the model ensemble forecasting. The substantial perfor-mance gains on PASCAL-5i and COCO-20i verify the effec-tiveness, and surprisingly, our versatile scheme sets a new state-of-the-art even with two plain learners. Moreover, in light of the unique nature of the proposed approach, we also extend it to a more realistic but challenging setting, i.e., generalized FSS, where the pixels of both base and novel classes are required to be determined. The source code is available at github.com/chunbolang/BAM. 1.

Introduction
Beneﬁting from the well-established large-scale datasets
[8, 9, 29], a wealth of convolutional neural network (CNN) based computer vision techniques have undergone rapid de-velopment over the past few years [15–17, 27, 28, 35, 43– 45, 48]. However, collecting sufﬁcient labeled data is no-toriously time-consuming and labor-intensive, especially for dense prediction tasks, such as instance segmentation
[2,3,15,21,59] and semantic segmentation [1,25,35,40,45].
In striking contrast with the machine learning paradigms,
*Gong Cheng is the corresponding author.
Figure 1. Comparison of our BAM and previous work. (a) Con-ventional approaches typically employ meta-learning frameworks to train the FSS models, which is inevitably biased towards base classes rather than being ideally class-agnostic, thus hindering the recognition of target objects for novel class (e.g., cat (•)). (b)
Our BAM introduces an additional branch, namely base learner, to explicitly predict the regions of base classes. In this way, the distractor objects (e.g., person (•) and sofa (•)) in the query im-age can be suppressed signiﬁcantly after the ensemble module. (c)
Extension of our BAM under the generalized FSS settings, where the pixels of both base and novel classes are required to be deter-mined. The reﬁned results are again merged with the output of the base learner to generate comprehensive predictions. humans can easily recognize new concepts or patterns from a handful of examples, which greatly stimulates the research interest of the community [39,52,53]. Thus, few-shot learn-ing (FSL) is proposed to address this problem by building a network that can be generalized to unseen domains with scarce annotated samples available [7, 42, 54, 57].
In this paper, we undertake the application of FSL in
the ﬁeld of semantic segmentation, termed as few-shot seg-mentation (FSS), where the model leverages only very few labeled training data to segment the targets of a speciﬁc semantic category from the raw image [46]. Fueled by the success of few-shot classiﬁcation, most existing FSS approaches strive to achieve generalization through meta-learning frameworks [23, 30–34, 36–38, 47, 55, 56, 58, 61, 62, 64–67]. A series of learning tasks (episodes) are sam-pled from the base dataset to mimic the few-shot scenar-ios of novel classes, i.e., match training and testing con-ditions. However, it is woefully inadequate and underpow-ered. Meta-training on the base dataset with abundant anno-tated samples inevitably introduces a bias towards the seen classes rather than being ideally class-agnostic, thus hin-dering the recognition of new concepts [10]. Notably, when countering hard query samples that share similar categories with base data, the generalization performance might be on the verge of collapse.
We argue that aside from designing more powerful fea-ture extraction modules [23, 60, 61], adjusting the use of base datasets containing sufﬁcient training samples is also an alternative method to alleviate the above-mentioned bias problem, which has been neglected in previous works. To this end, we introduce an additional branch (base learner) to the conventional FSS model (meta learner) to explicitly predict the targets of base classes (see Fig. 1). Then, the coarse results output by these two learners in parallel are adaptively integrated to generate accurate predictions. The central insight behind such an operation is to identify con-fusable regions in the query image through a high-capacity segmentation model trained within the traditional paradigm, further facilitating the recognition of novel objects. Inciden-tally, the proposed scheme is named BAM as it consists of two unique learners, i.e., base and the meta.
Moreover, we notice that meta learners are typically sen-sitive to the quality of support images, and the large vari-ances between the input image pairs could lead to severe performance degradation. On the contrary, base learners tend to provide highly reliable segmentation results and stable performance due to the single query image as in-put. Based on this observation, we further propose to lever-age the evaluation results of the scene differences between query-support image pairs to adjust the coarse predictions derived from meta learners. Inspired by the style loss that is extensively adopted in the domain of image style trans-fer [12, 13, 20], we ﬁrst calculate the difference of the Gram matrices of the two input images and then utilize the Frobe-nius norm to obtain the overall indicator for guiding the ad-justment process. As illustrated in Fig. 1(b), the distrac-tor objects of base classes (e.g., person and sofa) in the query image are suppressed signiﬁcantly after the ensem-ble module, achieving accurate localization of novel objects (e.g., cat). Furthermore, in light of the unique character of the proposed approach, we also extend the current task to a more realistic but challenging setting (i.e., generalized
FSS), where the pixels of both base and novel classes are required to be determined, as presented in Fig. 1(c). To sum up, our primary contributions can be concluded as follows:
• We propose a simple but efﬁcient scheme to address the bias problem by introducing an additional branch to ex-plicitly predict the regions of base classes in the query im-ages, which sheds light on future works.
• We propose to estimate the scene differences between the query-support image pairs through the Gram matrix for mitigating the adverse effects caused by the sensitivity of meta learner.
• Our versatile scheme sets new state-of-the-arts on FSS benchmarks across all settings, even with two plain learners.
• We extend the proposed approach to a more chal-lenging setting, i.e., generalized FSS, which simultaneously identiﬁes the targets of base and novel classes. 2.