Abstract
Humans are able to recognize structured relations in ob-servation, allowing us to decompose complex scenes into simpler parts and abstract the visual world in multiple lev-els. However, such hierarchical reasoning ability of human perception remains largely unexplored in current literature of semantic segmentation. Existing work is often aware of
ﬂatten labels and predicts target classes exclusively for each pixel. In this paper, we instead address hierarchical seman-tic segmentation (HSS), which aims at structured, pixel-wise description of visual observation in terms of a class hierar-chy. We devise HSSN, a general HSS framework that tackles two critical issues in this task: i) how to efﬁciently adapt ex-isting hierarchy-agnostic segmentation networks to the HSS setting, and ii) how to leverage the hierarchy information to regularize HSS network learning. To address i), HSSN dire-ctly casts HSS as a pixel-wise multi-label classiﬁcation task, only bringing minimal architecture change to current seg-mentation models. To solve ii), HSSN ﬁrst explores inherent properties of the hierarchy as a training objective, which en-forces segmentation predictions to obey the hierarchy stru-cture. Further, with hierarchy-induced margin constraints,
HSSN reshapes the pixel embedding space, so as to generate well-structured pixel representations and improve segmen-tation eventually. We conduct experiments on four seman-tic segmentation datasets (i.e., Mapillary Vistas 2.0, City-scapes, LIP, and PASCAL-Person-Part), with different class hierarchies, segmentation network architectures and back-bones, showing the generalization and superiority of HSSN. 1.

Introduction
Semantic segmentation, which aims to identify semantic categories for pixel observations, is viewed as a vital step to-wards intelligent scene understanding [82]. The vast major-ity of modern segmentation models simply assume that all the target classes are disjoint and should be distinguished ex-clusively during pixel-wise prediction. This fails to capture
∗Work done during an internship at Baidu Research.
†Corresponding author: Wenguan Wang.
Figure 1. Hierarchical semantic segmentation explains visual scenes with multi-level abstraction (left), by considering structured class relations (right). The class taxonomy is borrowed from [58]. the structured nature of the visual world [53]: complex scenes arise from the composition of simpler entities. Walking city, vehicles and pedestrian ﬁll our view (Fig. 1). After focusing on the vehicles, we identify cars, buses, and trucks, which consist of more ﬁne-grained parts like wheel and window.
On the other hand, structured understanding of our world in terms of relations and hierarchies is a central ability in hu-man cognition [68,95]. We group chair and bed as furniture, while cat and dog as pet. We understand this world over multiple levels of abstraction, in order to maintain stable, coherent percepts in the face of complex visual inputs [37].
The ubiquity of hierarchical decomposition serves as a core motivation behind many structured machine learning mod-els [20, 85], which have shown wide success in document classiﬁcation [39,55] and protein function prediction [8,75].
In semantic segmentation literature, surprisingly little is understood about how to accommodate pixel recognition into semantic hierarchies. [43, 45, 56, 80, 81, 83, 89] are rare exceptions that exploit class hierarchies in segmentation networks. Nevertheless, they either focus speciﬁcally on the structured organization of human body parts [80,81,83], or introduce hierarchy-induced architectural changes to the
segmentation network [43, 45, 56, 89], both hindering gen-erality. More essentially, these methods are more aware of making efﬁcient information propagation over the hierar-chies (e.g., graph message passing [43, 83, 109], multi-task learning [89]), without imposing tree-structured label de-pendencies/constraints into prediction and learning.
To mimic human hierarchical visual perception, we pro-pose a novel approach for hierarchical semantic segmen-tation (HSS). In HSS, classes are not arranged in a “ﬂat” structure, but organized as a tree-shaped hierarchy. Thus each pixel observation is associated to a root-to-leaf path of the class hierarchy (e.g., human→rider→bicyclist), capturing general-to-speciﬁc relations between classes. Our algorithm, called HSSN, addresses two core issues in HSS, yet untouched before. First, instead of previous structured segmentation models focusing on sophisticated network de-sign, HSSN directly formulates HSS as a pixel-wise multi-label classiﬁcation task. This allows to easily adapt exist-ing segmentation models to the HSS setting, densely link-ing the ﬁelds of classic hierarchy-agnostic segmentation and
HSS together. Second, HSSN makes full use of the class hierarchy in HSS network learning. To make pixel pre-dictions coherent with the class hierarchy, HSSN explores two hierarchy constraints, i.e., i) a pixel sample belong-ing to a given class must also belong to all its ancestors in the hierarchy, ii) a pixel sample not belonging to a given class must also not belong to all its descendants, as opti-mization criterion. This leads to a pixel-wise hierarchical segmentation learning strategy, which enforces segmenta-tion predictions to obey the hierarchy structure during train-ing. HSSN further encodes the structured knowledge in-troduced by the class hierarchy into the pixel embedding space. This leads to a pixel-wise hierarchical representa-tion learning strategy, which inspires tree-induced margin separation for embedding space reshaping. As the hierarchy characterizes the underlying relationships between classes,
HSSN is able to enrich pixel embeddings by pulling seman-tically similar pixels (e.g., bicycle and motorcycle) closer, while pushing semantically dissimilar pixels (e.g., pedestrian and lamppost) farther away. This leads to more efﬁcient learning by discovering and reusing common patterns [27], facilitating hierarchical segmentation eventu-ally. This also allows our model to take different levels of mistakes into consideration. This is essential for some crit-ical systems [7]. Take autonomous driving as an example: mistaking a bicycle for a motorcycle is less of a prob-lem than confusing a pedestrian with a lamppost.
This work represents a solid step towards HSS. Our ap-proach is elegant and principle; it is readily incorporated to arbitrary previous hierarchy-agnostic segmentation net-works, with only marginal modiﬁcation on the segmenta-tion head. We train and test HSSN over four public bench-marks (i.e., Mapillary Vistas 2.0 [58], Cityscapes [18], LIP
[44], PASCAL-Person-Part [87]), with different class hier-archies for urban street scene parsing and human semantic parsing. Extensive experimental results with different seg-mentation network architectures (i.e., DeepLabV3+ [13],
OCRNet [98], MaskFormer [16]) and backbones (i.e.,
ResNet-101 [34], HRNetV2-W48 [79], Swin-Small [49]) verify the generalization and effectiveness of HSSN. 2.