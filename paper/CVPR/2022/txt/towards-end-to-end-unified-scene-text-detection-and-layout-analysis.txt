Abstract
Scene text detection and document layout analysis have long been treated as two separate tasks in different im-age domains.
In this paper, we bring them together and introduce the task of uniﬁed scene text detection and lay-out analysis. The ﬁrst hierarchical scene text dataset is introduced to enable this novel research task. We also propose a novel method that is able to simultaneously de-tect scene text and form text clusters in a uniﬁed way.
Comprehensive experiments show that our uniﬁed model achieves better performance than multiple well-designed baseline methods. Additionally, this model achieves state-of-the-art results on multiple scene text detection datasets without the need of complex post-processing. Dataset and code: https://github.com/google-research-datasets/hiertext. 1.

Introduction
The ability to read and understand text in natural scenes and digital documents plays an important role in anthro-pocentric applications of computer vision. While state-of-the-art text detection systems such as [44,61] excel at local-izing individual text entities, visual text understanding [2] requires comprehension of the semantic and geometric lay-out [5, 7] of the textual content. In the current literature, most works focus on the individual tasks of text entities detection [3, 18, 61] and layout analysis [26, 58] in a sep-arate way, devoting all the power of deep learning models to task-speciﬁc performance. We argue that joint treatment of these two closely related problems can result not only in simpler and more efﬁcient models, but also models that are more accurate across all tasks. Additionally, an all-in-one, uniﬁed text and layout detection architecture can become indispensable for text reasoning tasks such as text-based
VQA [4, 47] and image captioning [57].
The division between text detection and geometric layout analysis tasks has led to parallel and separate research direc-tions. Text detectors [14, 18, 40, 61] usually treat word-level annotations, i.e. sequence of characters not interrupted by
Figure 1. Top: We introduce the task of uniﬁed text detection and layout analysis, and collect a dataset called HierText with hier-archical annotations. Blue boxes are word level bounding boxes.
Yellow boundaries mark the ground-truth clustering of text. Line-level annotations and transcriptions are not visualized to avoid overcrowding. Bottom: We propose an end-to-end model called
Uniﬁed Detector which can simultaneously detect text as masks and further group them into clusters. The model produces masks for text detection and an afﬁnity matrix to cluster text lines, both in an end-to-end fashion without complex post-processing. We visualize the layout analysis results by coloring text line masks according to their clusters. space, as the only supervision signal. Conversely, geometric layout analysis algorithms [2, 26, 54, 58, 62] focus on digital documents and either assume word-level text information as given [2, 54, 58] or directly predict geometric structures without reasoning for their atomic elements [62]. We ask:
Can there be a reconciliation of text entity detection and geometric layout analysis? Can geometric layout analysis target both natural scenes and digital documents? These questions are important given their relevance in real-world
applications, such as screen readers for visually impaired and image-based translation.
Our work aims to unify text detection and geometric layout analysis. We introduce a new image dataset called
HierText. It is the ﬁrst dataset featuring hierarchical an-notations of text in natural scenes and documents (Fig. 1, top). The dataset contains high quality word, line, and para-graph level annotations. “Text lines” are deﬁned as logi-cally connected sequences of words that are aligned in spa-tial proximity. Text lines that belong to the same seman-tic topic and are geometrically coherent form “paragraphs”.
Images in HierText average more than 100 words per im-age, twice denser than the current highest density scene text dataset [48]. Experimental results show our dataset is com-plementary to other public datasets [10,11,19,22,37,38,48, 49, 59, 60] for the standalone text detection task.
In addition to HierText, we present a novel model, Uni-ﬁed Detector, that simultaneously detects text entities and performs layout analysis by grouping text entities, as illus-trated in the bottom of Fig. 1. Uniﬁed detector consolidates an end-to-end instance segmentation model, MaX-DeepLab
[53], to detect arbitrarily shaped text and multi-head self-attention layers [51] to form text clusters. The proposed model enables end-to-end training and inference with a single-stage simpliﬁed pipeline. It eliminates complex la-bel generation processes [3,44] during training and sophisti-cated post-processing [33,63] during inference. Uniﬁed De-tector outperforms competitive baselines and even a com-mercial solution on the task of uniﬁed text detection and geometric layout analysis, demonstrating its effectiveness.
Along with the uniﬁed task, we also evaluate our model on the standalone scene text detection task using existing public datasets, including ICDAR 2017 MLT [38], Total-Text [10], CTW1500 [60], MSRA-TD500 [59], and achieve state-of-the-art results. While ﬁne-tuning is a common practice in recent works [44, 63], the proposed model is di-rectly trained using a combination of datasets without ﬁne-tuning on each individual target dataset. The uniﬁed detec-tor is the ﬁrst end-to-end model that achieves state-of-the-art performance on the text detection task and simultane-ously recovers important text layout information.
In conclusion, our core contributions are as follows:
•
•
•
•
We propose the task of uniﬁed text detection and lay-out analysis, bringing together two tasks that have been studied independently, yet are intrinsically connected.
A new high quality dataset with hierarchical text anno-tations is introduced to facilitate research on this task.
We propose an end-to-end uniﬁed model, which out-performs competitive multi-stage baselines that treat the two tasks separately.
Our model, which is free of complex post-processing, achieves state-of-the-art results on multiple challeng-ing public text detection benchmarks. 2.