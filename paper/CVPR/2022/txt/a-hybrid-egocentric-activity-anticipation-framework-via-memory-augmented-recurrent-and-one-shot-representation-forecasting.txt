Abstract
Egocentric activity anticipation involves identifying the interacted objects and target action patterns in the near future. A standard activity anticipation paradigm is re-currently forecasting future representations to compensate the missing activity semantics of the unobserved sequence.
However, the limitations of current recursive prediction models arise from two aspects: (i) The vanilla recurren-t units are prone to accumulated errors in relatively long periods of anticipation. (ii) The anticipated representation-s may be insufﬁcient to reﬂect the desired semantics of the target activity, due to lack of contextual clues. To address these issues, we propose “HRO”, a hybrid framework that integrates both the memory-augmented recurrent and one-shot representation forecasting strategies. Speciﬁcally, to solve the limitation (i), we introduce a memory-augmented contrastive learning paradigm to regulate the process of the recurrent representation forecasting. Since the exter-nal memory bank maintains long-term prototypical activity semantics, it can guarantee that the anticipated represen-tations are reconstructed from the discriminative activity prototypes. To further guide the learning of the memory bank, two auxiliary loss functions are designed, based on the diversity and sparsity mechanisms, respectively. Fur-thermore, to resolve the limitation (ii), a one-shot transfer-ring paradigm is proposed to enrich the forecasted repre-sentations, by distilling the holistic activity semantics af-ter the target anticipation moment, in the ofﬂine training.
Extensive experimental results on two large-scale data sets validate the effectiveness of our proposed HRO method. 1.

Introduction
With the popularity of wearable cameras, e.g., GoPro, e-gocentric perception has attracted extensive attention over the past decade [40, 51]. Among the diverse egocentric vi-sion tasks [3, 28, 34, 45], anticipating the near future activi-Figure 1. Illustration of task deﬁnition and basic pipeline for ego-centric activity anticipation. ties is a crucial high-level task, due to its wide-spread real-world applications [16, 32], e.g., human-robot interaction, autonomous driving, abnormal event alerts, etc. However, anticipating an unseen egocentric-activity before it starts is non-trivial, because of a number of challenges, such as the semantics gap between past and future events, the scarci-ty of useful clues in incomplete observations, and frequent ego-motion and cluttered backgrounds in egocentric videos.
Therefore, egocentric activity anticipation (EAA) is still a challenging task.
As illustrated in Fig. 1, following the deﬁnition in [8], the “observation time” to is the temporal length of the ob-served video clip, and the ”anticipation time” ta indicates the temporal interval before the target anticipation moment.
Thus, the goal of the EAA task is to anticipate an egocen-tric activity occurring at moment δs, by merely observing a video clip in the range of [δs − (to + ta), δs − ta], i.e., preceding the target activity beginning at moment δs by a duration ta. Recurrent forecasting [12, 54] is a commonly used paradigm for anticipating future activities, as it is ﬂex-ible to predict results at any moment. Typically, the recur-sive anticipation model summarizes the past observations, and then forecasts what will occur in the near future. This process is continuously conducted until the target anticipa-tion moment δs arrives. Therefore, the performance of a recursive anticipation system depends on whether it is able
to forecast discriminative representations, which cover the activity semantics in the unseen video sequence. However, the current recursive-model-based EAA methods still strug-gle to achieve satisfactory performance.
We argue that the improvement is impeded by two ma-jor obstacles. First, the vanilla recursive model, based on recurrent neural networks (RNNs), is prone to accumulated prediction errors, especially in relatively long-period antic-ipation. Although some methods [40, 54] attempted to in-troduce contrastive learning [6, 22, 38] to regulate the rep-resentation forecasting, the performance still obviously de-grades when the anticipation interval increases. The under-lying reason is that the RNN-based model mainly updates the memory cell states by remembering information from the previous step, which makes it hard to maintain long-term dependencies among all the past steps.
In addition, given a short-length observation input with limited dynam-ics, it is difﬁcult for the RNN-based model to anticipate the subsequent activities, as the cell states can only reveal the relations within the current observed short sequence, with-out any access to external knowledge. Second, the exist-ing methods merely force the forecasted representations to compensate the semantics of the anticipation time, which are likely insufﬁcient to represent the future activity. In oth-er words, the lack of contextual cues after the target antic-ipation time-step poses great challenges to the anticipation model to make correct prediction, especially when the an-ticipation moment is at the transition boundary of two con-secutive activities. For example, as shown in Fig. 1, even if the forecasted representations contain the semantics of
“scoop cheese” covering the anticipation time, directly u-tilizing these features to infer the subsequent activity, i.e.,
“put down cheese” is still ambiguous. The relations be-tween the representations before and after the anticipation time step have not been well studied.
To address the aforementioned issues, in this paper, we propose a hybrid framework in a combination of memory-augmented recurrent and one-shot representation forecast-ing, termed as “HRO”, for egocentric activity anticipation.
First, to mitigate the error accumulation issues in conven-tional recursive models, we introduce a memory bank in-to the process of recurrent representation forecasting. D-ifferent from the internal memory cells of the RNN unit-s, the memory bank externally stores long-term prototypi-cal activity semantics learned from training data, which are not limited to the current observation inputs. Our model is trained to reconstruct future representations by a convex combination of the memory items, via an attention-based memory addressing mechanism. To further guide the learn-ing of the memory bank, we design two loss functions, based on a diversity scheme and a sparsity scheme, respec-tively, which can force the memory bank to be equipped with the desired properties. Second, to maximally incor-porate contextual clues into the forecasted representation, we propose a one-shot transferring strategy to explicitly ex-plore semantics relations between the features before and after the anticipation time-step. Speciﬁcally, in the ofﬂine training, at each target anticipation moment, we adopt a transition layer to project the features anticipated by the re-current model, into another space to simulate the activity semantics extracted from a future video clip. This holistic transferring process is supervised by a similarity learning loss, which minimizes the semantics gap between simulat-ed and future features.
The main contributions of this paper can be summarized in three ways. 1) We propose a memory-augmented re-current representation forecasting paradigm, which aims to guarantee that the anticipated representations always con-tain the discriminative activity semantics, with the help of a compressed memory bank. Moreover, two regularization loss terms, based on the diversity and sparsity mechanisms, are designed to guide the updating of the memory bank. 2)
A one-shot transferring strategy is presented to further re-calibrate the forecasted representations, by injecting future activity semantics, at the target activity anticipation time step. 3) Extensive experimental results on two challenging data sets, i.e., EGTEA Gaze+ [32] and EPIC-Kitchens [9], highlight the performance improvements of our proposed hybrid framework over other state-of-the-art methods. 2.