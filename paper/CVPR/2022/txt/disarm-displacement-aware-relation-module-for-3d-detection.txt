Abstract
We introduce Displacement Aware Relation Module (DisARM), a novel neural network module for enhanc-ing the performance of 3D object detection in point cloud scenes. The core idea is extracting the most principal con-textual information is critical for detection while the tar-get is incomplete or featureless. We ﬁnd that relations be-tween proposals provide a good representation to describe the context. However, adopting relations between all the object or patch proposals for detection is inefﬁcient, and an imbalanced combination of local and global relations brings extra noise that could mislead the training. Rather than working with all relations, we ﬁnd that training with relations only between the most representative ones, or an-chors, can signiﬁcantly boost the detection performance.
Good anchors should be semantic-aware with no ambigu-ity and able to describe the whole layout of a scene with no redundancy. To ﬁnd the anchors, we ﬁrst perform a pre-liminary relation anchor module with an objectness-aware sampling approach and then devise a displacement based module for weighing the relation importance for better uti-lization of contextual information. This light-weight rela-tion module leads to signiﬁcantly higher accuracy of ob-ject instance detection when being plugged into the state-of-the-art detectors. Evaluations on the public benchmarks of real-world scenes show that our method achieves the state-of-the-art performance on both SUN RGB-D and Scan-Net V2. The code and models are publicly available at https://github.com/YaraDuan/DisARM . 1.

Introduction
Detecting objects directly from the 3D point cloud is challenging yet imperative in many computer vision tasks, such as autonomous navigation, path planning for robotics, as well as some AR applications. The goal of 3D object detection is to localize all valid shapes and recognize their semantic label simultaneously, which puts forward high re-quirements for understanding the whole input scene.
∗Corresponding author: kevin.kai.xu@gmail.com
Figure 1. Illustration of the importance of DisARM. (b) It is easy to mistake the cabinet as a table when the point cloud is incom-plete and featureless. (c) Redundant relations are usually incom-plete and lose the important displacement information of the target object. (d) The network can recognize and locate the cabinet eas-ily with the help of DisARM which provides valid surrounding environment information.
With the rapid development of deep learning and the in-creasing scale of the online 3D dataset, data-driven methods such as CNN have been widely adopted for object detection.
The critical observation of these methods is that the context is as important as the object itself for accurate detection.
However, the extra information provided by 3D brings noise and irregularity, which makes it more challenging to apply convolution to gather the correct context for detection.
To avoid irregularity while applying convolution for 3D object detection, the community recently introduces two typical categories of methods. [17, 37, 45] are trying to project the raw point cloud onto aligned structures such as voxel grids which can apply 3D convolution naturally. In an alternative way, [25] adopts max-pooling to fuse infor-mation of an irregular point cloud directly. These methods can achieve good performance while the input scene is com-plete and clean. However, the real scanned data is usually incomplete and noisy, making it difﬁcult to extract the key information through this intrinsic context fusion approach.
To further release the power of context, some meth-ods try to adopt the context explicitly for object detection.
Building a relation graph between objects is a natural way to utilize the context. [32] leverages inference on scene graphs to enhance 3D scene understanding. However, it requires additional supervision for regression of a correct scene graph. Some methods intend to utilize all the possi-ble relations among the scene to avoid this extra labeling labor. [34] introduces a multi-level framework to fuse all the local and global neighborhoods for 3D object detection.
Even a hierarchical architecture is proposed to maintain the context, considering all the relations is still redundant. Fur-thermore, most methods that adopt context explicitly have their customized network architecture, making it difﬁcult to enhance existing detection methods.
We believe that context fusion is critical for 3D under-standing, which can improve object detection performance.
We introduce a novel neural network module named Dis-placement Aware Relation Module (DisARM). It can be easily assembled with most existed object detection meth-ods and achieves state-of-the-art performance on existing benchmarks. The key idea is that context should not only be a structure for information fusion. The relation itself is also a critical feature for 3D understanding. Unlike some pre-vious methods, we try to encode the most critical relations explicitly for potential proposals to allow richer information to be included during the training.
To avoid the redundant relation features that mislead the training and extract the information that matters, we select and collect the most critical context from two aspects. First, we introduce a relation anchor module, which only sam-ples the most representative and informative proposals as anchors through an objectness-aware Furthest Point Sam-pling (FPS) on feature space. The insight of this design is that the relation anchors for context encoding should dis-tribute uniformly over the feature space while being com-plete and clean. Our experiments demonstrate that adopting these relation anchors instead of the whole set of relations for context fusion is more efﬁcient and accurate. To maxi-mize the utilization of the proposed relation anchors, we in-troduce a dynamic weighing mechanism depending on spa-tial and feature displacement. The key insight here is that the importance of each anchor should be variant regarding recognizing different objects. The importance should de-pend on the spatial layout and semantic relations between the object and the anchors since the object placement usu-ally go with some speciﬁc organization pattern for indoor scenes. In summary, the contributions of this paper include:
• We propose a portable network module that can be as-sembled with most existing 3D object detection meth-ods to further improve the performance, which can be easily implemented as a plug-in for widely used object detection toolbox like MMdetection3D [5].
• We introduce a method describing 3D context as a set of weighted representative anchors. This method can effectively extract valid information from the redun-dant relations in a complex scene.
• Our method is simple but effective, which achieves state-of-the-art performances on ScanNet V2 and mAP@0.25 on SUN RGB-D. 2.