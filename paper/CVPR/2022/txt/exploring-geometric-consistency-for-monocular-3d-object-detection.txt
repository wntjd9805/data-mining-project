Abstract
This paper investigates the geometric consistency for monocular 3D object detection, which suffers from the ill-posed depth estimation. We ﬁrst conduct a thorough anal-ysis to reveal how existing methods fail to consistently lo-calize objects when different geometric shifts occur. In par-ticular, we design a series of geometric manipulations to diagnose existing detectors and then illustrate their vulner-ability to consistently associate the depth with object ap-parent sizes and positions. To alleviate this issue, we pro-pose four geometry-aware data augmentation approaches to enhance the geometric consistency of the detectors. We
ﬁrst modify some commonly used data augmentation meth-ods for 2D images so that they can maintain geometric con-sistency in 3D spaces. We demonstrate such modiﬁcations are important. In addition, we propose a 3D-speciﬁc image perturbation method that employs the camera movement.
During the augmentation process, the camera system with the corresponding image is manipulated, while the geomet-ric visual cues for depth recovery are preserved. We show that by using the geometric consistency constraints, the pro-posed augmentation techniques lead to improvements on the
KITTI and nuScenes monocular 3D detection benchmarks
In addition, we demonstrate with state-of-the-art results. that the augmentation methods are well suited for semi-supervised training and cross-dataset generalization. 1.

Introduction
Given an input image, the objective of monocular 3D object detection is to detect objects of interest and recover their position in 3D space. Recently, it has received increas-ing attention due to its importance in many downstream tasks, such as autonomous driving, robot navigation, etc.
Different from stereo or lidar sensors, a monocular camera requires a lower cost to perceive the surrounding environ-ments. However, it suffers from unreliable depth recovery, leading to unsatisﬁed performance for deployment. (a) Visualization of different copy-paste manipulation techniques. (b) Visualization of the estimated depth from the baseline and augmentation-enhanced detectors under the copy-paste manipulation (see the details in
Sec 4.2).
Figure 1. We select one of the proposed manipulation tech-niques (copy-paste) to illustrate the instability of object localiza-tion under distortion of objects’ apparent size and vertical posi-tion. “Size+pos” denotes geometry-consistent manipulation that shifts the two visual cues with satisfying geometric constraints,
“Size only” and “Pos only” denote geometry-inconsistent manip-ulation that only shifts the vertical position or apparent size. The shaded region indicates the std of the depth in the “Size + pos” manipulation.
To alleviate the ambiguity in depth estimation, recent approaches [1, 3, 22, 24] leverage deep neural networks to model the semantic and geometric information for depth
reasoning. However, what geometric features existing de-tectors use and if they are robust when the used features are perturbed are still under-explored. As a result, this work conducts a comprehensive study on the geometry robust-ness of existing detectors and proposes several augmenta-tion techniques to enhance their geometric consistency un-der geometric shifts. Different from 2D detection, the ge-ometric visual cues for depth recovery are supposed to be preserved when the objects’ coordinates are manipulated, which is not straightforward.
It is demonstrated in [10] that neural networks might rely on the features of appearance size and vertical posi-tion to estimate object depth. As visualized in Figure 1a, objects farther away from the camera have smaller apparent sizes and their vertical position is closer to the vanishing points. To study if detectors utilize these two pictorial vi-sual cues in localizing objects, we conduct controlled exper-iments that shift one of the visual cues during manipulating.
As the results of “Size + pos”, “Size only” and “Pos only” shown in Figure 1, the estimated depth changes as the shift of pictorial visual cues, especially for the objects’ appar-ent size. We further evaluate the robustness of the detectors in utilizing them to estimate depth by manually distorting the visual cues (i.e., shifting the objects’ apparent size or vertical position) with the proposed manipulations (visual-ized in Figure 2 and 1a). Through the evaluation, we ob-serve that detectors cannot capture consistent relationships between depth with the two pictorial visual cues, even they can identify the variation of them. As shown in Figure 1b and 3, the estimated depth from the baseline detectors has a strong deviation when the images are manipulated.
Inspired by the above analysis, we convert the manipula-tions into several geometry-aware data augmentation tech-niques to improve the geometric consistency of existing de-tectors. The awareness means that the pictorial visual cues for estimating object depth are preserved during manipulat-ing. At the image level, we lift random scale and random crop, the commonly used 2D augmentation to 3D space by connecting the image manipulation with the shift of camera focal lengths and receptive ﬁeld. With the help of a dense depth estimation network, we provide a new 3D augmenta-tion method that models the shifts of the camera’s 3D loca-tion. At the instance level, we propose a geometry-aware copy-paste that leverage the guidance of geometric hints to guide the pasting procedure. Through modeling the geo-metric constraints, the objects are pasted to novel scenes, while their pictorial visual cues are still preserved.
By enhancing the geometric consistency, the proposed augmentation techniques yield signiﬁcant performance boost in both state-of-the-art anchor-free and anchor-based detectors. Compared with the baseline in Figure 1b, the estimated depth from the enhanced detectors with the de-signed geometric augmentation methods has less deviation under manipulation. With regularizing the geometric con-sistency, the trained detectors also show strong robustness in the cross-domain scenario. Furthermore, the consistency regularization techniques also can be applied in the semi-supervised setting, which boosts the performance by regu-larizing the output consistency under different levels of ma-nipulations. Our contributions are summarized as follows:
• Through a study of how monocular detectors estimate depth, we identiﬁed an instability problem of depth re-covery under the changes of the object’s apparent size and position.
• We provide four geometry-aware augmentation tech-niques at the image-level and instance-level to address this problem. With the proposed augmentation tech-niques, we achieve state-of-the-art results on both the
KITTI and nuScenes monocular 3D object detection benchmarks.
• We extend the geometry augmentation techniques into semi-supervised training and cross-domain evaluation, showing the effectiveness of improving performance by regularizing the geometric consistency. 2.