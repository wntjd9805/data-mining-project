Abstract
Implicit neural representations such as Neural Radiance
Field (NeRF) have focused mainly on modeling static ob-jects captured under multi-view settings where real-time rendering can be achieved with smart data structures, e.g.,
PlenOctree.
In this paper, we present a novel Fourier
PlenOctree (FPO) technique to tackle efficient neural mod-eling and real-time rendering of dynamic scenes captured under the free-view video (FVV) setting. The key idea in our FPO is a novel combination of generalized NeRF,
PlenOctree representation, volumetric fusion and Fourier transform. To accelerate FPO construction, we present a novel coarse-to-fine fusion scheme that leverages the gen-eralizable NeRF technique to generate the tree via spa-tial blending. To tackle dynamic scenes, we tailor the im-plicit network to model the Fourier coefficients of time-varying density and color attributes. Finally, we construct the FPO and train the Fourier coefficients directly on the leaves of a union PlenOctree structure of the dynamic se-quence. We show that the resulting FPO enables com-pact memory overload to handle dynamic objects and sup-ports efficient fine-tuning. Extensive experiments show that the proposed method is 3000 times faster than the original
NeRF and achieves over an order of magnitude accelera-tion over SOTA while preserving high visual quality for the free-viewpoint rendering of unseen dynamic scenes. 1.

Introduction
Interactive and immersive applications, such as Telep-resence and Virtual Reality (VR), make plenty use of free-viewpoint videos to provide unique and fully controllable viewing experiences. At the core are fast generation and real-time rendering at new viewpoints with ultra-high pho-* Authors contributed equally to this work. # The corresponding authors are Jingyi Yu (yujingyi@shanghaitech.edu.cn) and Lan Xu (xu-lan1@shanghaitech.edu.cn).
Figure 1. Our method achieves a photo-realistic rendered result for dynamic scenes in real-time based on our novel Fourier PlenOctree structure. torealism. Traditional image-based modeling and rendering approaches rely on feature matching and view interpolation, whereas the latest neural rendering techniques are able to in-tegrate the two processes into a deep net that simultaneously represents the geometry and appearance for efficient render-ing. By far, most neural rendering techniques have focused on modeling static objects and employing smart data struc-tures. For example, volumetric neural modeling techniques
[28, 32] overcome many limitations of traditional meth-ods, including tailored matching algorithms and optimiza-tion procedures and can even tackle non-Lambertian materi-als. The seminal work of the Neural Radiance Field (NeRF)
[32] learns a neural representation based on MLP to repre-sent static scenes as radiance fields with the property of den-sity and color. It only requires calibrated multi-view images to produce compelling free-viewpoint rendering. However, the MLP structure is still too slow to achieve real-time per-formance. Existing techniques explore using thousands of tiny MLPs [45], applying factorization [13], tailored volu-metric data structures [16, 69], and primitive-based render-ing [29]. Despite their effectiveness, very few techniques are directly applicable to handle dynamic scenes, in partic-ular, objects with non-rigid deformations such as the human body. In this work, we present a novel neural representa-tion for generating free-viewpoint videos from multi-view
sequence inputs as well as for real-time photorealistic ren-dering.
Several recent efforts have investigated combining neu-ral modeling with classical flow or geometry estimations
[38, 43]. For example, one can apply motion flows to ex-plicitly transform sampled points in individual frames to a canonical model to partially account for non-rigid deforma-tions. However, they are vulnerable to lost tracks and can lead to motion artifacts. There are also emerging interests on utilizing pre-defined (e.g. skeleton [40] or parametric models [27, 41]) to explicitly calculate stable motion flows from model animations. These approaches, however, are limited to handling specific types of objects consistent with the pre-defined model. [58] directly predicts a neural ra-diance field using a general network for each frame while avoiding online training. Its rendering speed, however, is not yet sufficient for interactive and immersive experiences.
In this paper, we present a novel Fourier PlenOctree (FPO) technique for neural dynamic scene representation, which enables efficient neural modeling and real-time ren-dering of unseen dynamic objects with compact memory overload, as illustrated in Fig. 1. The key idea in our FPO is a novel combination of generalized NeRF, PlenOctree rep-resentation, volumetric fusion, and Fourier transform.
For efficient scene modeling, we present a novel coarse-to-fine fusion scheme that leverages generalizable
NeRF [59] technique to generate the PlenOctree with fast plenoptic functions inference. Inspired by the volumetric fusion strategy [36], we propose a spatial blending scheme to generate the neural tree in the order of minutes. To tackle dynamic scenes, we tailor the implicit network to model the
Fourier coefficients of time-varying density and plenoptic functions of the dynamic PlenOctree. By discarding high-frequency bases, our novel representation can achieve high storage efficiency while persevering perceptive details. Fi-nally, we construct the FPO and train the Fourier coeffi-cients directly on the leaves of a union PlenOctree struc-ture of the dynamic sequence. By combining the benefits of
PlenOctree rendering and Fourier operations, our FPO en-ables real-time free-viewpoint synthesis of dynamic scenes and supports efficient fine-tuning. Comprehensive experi-ments show that FPO is 3000 times faster than the original
NeRF implementation and achieves over an order of mag-nitude acceleration over state-of-the-art techniques for dy-namic scene modeling and rendering. To summarize, our contributions include:
• We introduce a FPO representation that enables real-time rendering of general dynamic scenes with fast fine-tuning and compact memory overload.
• We present a coarse-to-fine scheme that utilizes gen-eralizable NeRF for PlenOctree generation and con-structing FPO efficiently. 2.