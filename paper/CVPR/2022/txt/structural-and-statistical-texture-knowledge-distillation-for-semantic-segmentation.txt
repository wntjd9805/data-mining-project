Abstract
Existing knowledge distillation works for semantic seg-mentation mainly focus on transfering high-level contextual knowledge from teacher to student. However, low-level tex-ture knowledge is also of vital importance for characteriz-ing the local structural pattern and global statistical prop-erty, such as boundary, smoothness, regularity and color contrast, which may not be well addressed by high-level deep features.
In this paper, we are intended to take full advantage of both structural and statistical texture knowl-edge and propose a novel Structural and Statistical Texture
Knowledge Distillation (SSTKD) framework for Semantic
Segmentation. Specifically, for structural texture knowl-edge, we introduce a Contourlet Decomposition Module (CDM) that decomposes low-level features with iterative laplacian pyramid and directional filter bank to mine the structural texture knowledge. For statistical knowledge, we propose a Denoised Texture Intensity Equalization Mod-ule (DTIEM) to adaptively extract and enhance statistical texture knowledge through heuristics iterative quantization and denoised operation. Finally, each knowledge learning is supervised by an individual loss function, forcing the stu-dent network to mimic the teacher better from a broader perspective. Experiments show that the proposed method achieves state-of-the-art performance on Cityscapes, Pas-cal VOC 2012 and ADE20K datasets.
Figure 1. The overview of the structural and statistical texture knowledge distillation of an example image. Two kinds of the tex-ture knowledge are extracted from the low-level feature of a CNN backbone. The original structural and statistical texture are fuzzy and in low-contrast. After distillation, the contour is clearer and the intensity contrast is more equalized, showing that two kinds of the texture are both enhanced. 1.

Introduction
Semantic segmentation, which aims to assign each pixel a unique category label for the input image, is a cru-cial and challenging task in computer vision. Recently, deep fully convolution network [32] based methods have
*Equal Contribution
†Corresponding Authors. Hongtao Lu is also with MOE Key Lab of
Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China. achieved remarkable results in semantic segmentation, and extensive methods have been investigated to improve the segmentation accuracy by introducing sophisticated mod-els [6, 8, 23, 27, 44, 46, 47, 50, 52]. However, these methods are usually based on a large model, which contains tremen-dous parameters. Since semantic segmentation has shown great potential in many applications like autonomous driv-ing, video surveillance, robot sensing and so on, how to keep efficient inference speed and high accuracy with high-resolution images is a critical problem.
The focus of this paper is knowledge distillation, which is introduced by Hinton et al. [22] based on a teacher-student framework, and has received increasing attention in semantic segmentation community [20, 30, 31, 37, 42].
Previous works mainly focus on the high-level contex-tual knowledge [30, 37] or the final response knowledge
[20,31,42], which are appropriate to capture the global con-text and long range relation dependencies among pixels, but will also result in coarse and inaccurate segmentation re-sults, since they are usually extracted with a large receptive field and miss many low-level texture details. In this paper, we concentrate on exploiting the texture knowledge from the teacher to enrich the low-level information of the stu-dent. According to the digital image processing [18], tex-ture is a region descriptor which can provide measures for both local structural property and global statistical property of a image. The structural property can also be viewed as spectral domain analysis and often refer to some local pat-terns, such as boundary, smoothness and coarseness. While the statistical property pay more attention to the global dis-tribution analysis, such as histogram of intensity.
Based on the above analysis, we propose a novel
Structural and Statistical Texture Knowledge Distillation (SSTKD) framework to effectively distillate two kinds of the texture knowledge from the teacher model to the student model, as shown in Figure 1. More comprehensively, we introduce a Contourlet Decomposition Module (CDM) that decomposes low-level features to mine the structural tex-ture knowledge with iterative laplacian pyramid and direc-tional filter bank. The contourlet decomposition is a kind of multiscale geometric analysis tool and can enable the neu-ral network the ability of geometric transformations, thus is naturally suitable for describing the structural properties.
Moreover, we propose a Denoised Texture Intensity Equal-ization module (DTIEM) to adaptively extract and enhance the statistical knowledge, cooperated with an Anchor-Based
Adaptive Importance Sampler. The DTIEM can effectively describe the statistical texture intensity in a statistical man-ner in deep neural networks, as well as suppress the noise produced by the amplification effect in near-constant re-gions during the texture equalization. Overall, our contri-bution is threefold:
• To our knowledge, it is the first work to introduce both the structural and statistical texture to knowledge distillation for semantic segmentation. We propose a novel Structural and Statistical Texture Knowledge
Distillation (SSTKD) framework to effectively extract and enhance the unified texture knowledge and apply them to teacher-student distillation.
• More comprehensively, we introduce the Contourlet
Decomposition Module (CDM) and propose the
Denoised Texture Intensity Equalization Module (DTIEM) to describe the structural and statistical tex-ture, respectively. Moreover, DTIEM utilizes an adap-tive importance sampler and a denoised operation for efficient and accurate characterization.
• Experimental results show that the proposed frame-work achieves the state-of-the-art performance on three popular benchmark datasets in spite of the choice of student backbones. 2.