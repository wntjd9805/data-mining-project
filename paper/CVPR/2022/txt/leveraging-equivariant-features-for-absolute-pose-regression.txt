Abstract
While end-to-end approaches have achieved state-of-the-art performance in many perception tasks, they are not yet able to compete with 3D geometry-based methods in pose estimation. Moreover, absolute pose regression has been shown to be more related to image retrieval. As a result, we hypothesize that the statistical features learned by classical Convolutional Neural Networks do not carry enough geometric information to reliably solve this inher-ently geometric task. In this paper, we demonstrate how a translation and rotation equivariant Convolutional Neural
Network directly induces representations of camera motions into the feature space. We then show that this geometric property allows for implicitly augmenting the training data under a whole group of image plane-preserving transfor-mations. Therefore, we argue that directly learning equiv-ariant features is preferable than learning data-intensive intermediate representations. Comprehensive experimental validation demonstrates that our lightweight model outper-forms existing ones on standard datasets.1 1.

Introduction
In computer vision, camera pose estimation, and its ref-erence frame inverse, i.e., object pose estimation, have been extensively studied over the last decades [38, 42, 54].
Traditionally, pose estimation has been addressed using 3D geometry. In practice, a set of 2D-3D feature correspon-dences is generated, then statistically leveraged to recover the camera pose [18, 39, 49, 64]. More recently, direct Ab-solute Pose Regression (APR) approaches have been intro-duced, drawing upon early successes of deep learning [1]. 1This work was funded by the Luxembourg National Research Fund (FNR), under the project reference BRIDGES2020/IS/14755859/MEET-A/Aouada, and by LMO (https://www.lmo.space).
Figure 1. Illustration of our approach - Our method adopts a translation and rotation-equivariant convolutional neural network to extract geometry-aware features that directly encode camera planar motions R, t. While camera moves, equivariance of the proposed feature extractor F leads to explicit image (ϕ(I)
R,t) and feature (ϕ(F)
R,t) changes. This property is leveraged to propose a more efficient solution to the absolute pose regression problem.
These methods consist in directly mapping an image to its pose using a suitably trained Convolutional Neural Network (CNN). Therefore, end-to-end trainable methods have the advantage of providing fully differentiable results, enabling the optimization of all parameters in a comprehensive man-ner. Moreover, predictions are achieved at a steady speed and power consumption, whereas RANdom SAmple Con-sensus (RANSAC)-based methods [18] are less predictable
and likely to suffer from an efficiency drop when the in-lier rate is low. However, state-of-the-art APR methods have been proven theoretically and shown experimentally to have a lower accuracy compared to 3D structure-based approaches [50]. Indeed, the former are more closely re-lated to image retrieval than to 3D structure [50].
The questions we ask in this work are: Why do current
APR methods fall short in accuracy ? How can they reach their full potential? Our hypothesis is that there is a lack of exploitation of the geometric properties of data. This happens typically at the level of the feature extraction lay-ers commonly used in classical deep learning approaches.
Specifically, we posit that in the case of APR and pose esti-mation, having a representation which is equivariant to the group of rigid motions, i.e., rotations and translations in 3D, may be an effective way to boost the network performance.
This should play the role of an implicit data augmentation by means of group equivariance, and in turn alleviate the need for an explicit data augmentation for training.
Indeed, recently, there has been a growing interest in de-signing more geometric models that are equivariant to groups of such transformations. These approaches lever-age theoretical contributions from group theory, represen-tation theory, harmonic analysis and fundamental deep learning [8–10, 12, 21, 22, 61]. More specifically, group-equivariant neural networks, or Group-equivariant CNNs (G-CNNs), are part of the broader and promising field of geometric deep learning [4], that aims to exploit any under-lying geometric relationship that can exist within the data.
In particular, the special Euclidean groups in 2 and 3 dimen-sions, denoted as SE(2) and SE(3) and encompassing re-spective rigid motions, are of particular interest in 3D com-puter vision [13, 61].
Despite the conceptual advances they represent, to the best of our knowledge, the use of deep equivariant features in the APR context is still considerably unexplored. This paper proposes, for the first time, to investigate and justify the use of deep equivariant features for solving APR (see
Figure 1).
Contributions. Our contributions are summarized below: (1) A formulation of how an equivariant CNN induces rep-resentations of planar camera motions, lying in SE(2), di-rectly into the feature space. (Section 4.1) (2) An intuitive explanation is provided as to how SE(2)-equivariant features can be leveraged to recover any camera motion lying in SE(3). (Section 4.2) (3) A lightweight equivariant pose regression model, re-ferred to as E-PoseNet, is introduced. (Section 5) (4) Extensive experimental evaluation of E-PoseNet show-ing its competitive performance as compared to existing
APR methods on standard datasets. (Section 6)
Paper organization. An overview of state-of-the-art APR methods and current exploitations of deep equivariant fea-tures is given in Section 2. Section 3 presents the for-mal definition of equivariance along with the formulation of APR. The theoretical justification as to how SE(2)-equivariant features can explicitly encode planar camera motions is presented in Section 4, whereas the full pose re-gression pipeline is introduced in Section 5. An extensive experimental validation is given in Section 6 along with a discussion of limitations. Section 7 concludes the paper. 2.