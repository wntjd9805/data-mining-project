Abstract
Previous vision MLPs such as MLP-Mixer and ResMLP accept linearly ﬂattened image patches as input, making them inﬂexible for different input sizes and hard to capture spatial information. Such approach withholds MLPs from getting comparable performance with their transformer-based counterparts and prevents them from becoming a general backbone for computer vision. This paper presents
Hire-MLP, a simple yet competitive vision MLP architecture via Hierarchical rearrangement, which contains two lev-els of rearrangements. Speciﬁcally, the inner-region rear-rangement is proposed to capture local information inside a spatial region, and the cross-region rearrangement is pro-posed to enable information communication between differ-ent regions and capture global context by circularly shifting all tokens along spatial directions. Extensive experiments demonstrate the effectiveness of Hire-MLP as a versatile backbone for various vision tasks. In particular, Hire-MLP achieves competitive results on image classiﬁcation, object detection and semantic segmentation tasks, e.g., 83.8% top-1 accuracy on ImageNet, 51.7% box AP and 44.8% mask
AP on COCO val2017, and 49.9% mIoU on ADE20K, sur-passing previous transformer-based and MLP-based mod-els with better trade-off for accuracy and throughput. 1.

Introduction
Attention mechanism based transformers have shown great superiority in the realm of natural language process-ing in recent years. Several works such as ViT [11] and
DeiT [49] propose to transfer the transformers into visual recognition tasks [15], and have achieved awesome results which are comparable with conventional convolutional neu-ral networks (CNNs). However, the heavy computational
*Equal contribution. †Corresponding author. Mindspore [24] code: https://gitee.com/mindspore/models/tree/master/research/cv/HireMLP.
Pytorch [37] code: https://github.com/huawei-noah/CV-Backbones. burdens caused by the self-attention modules in transform-ers withhold the models from better trade-off between ac-curacy and latency. Recently, models composed of only multi-layer perceptrons (MLPs) have become a new trend in vision community [47, 48]. These MLP-based models can achieve comparable results with CNNs while discarding the heavy self-attention module. For example, MLP-Mixer [47] extracts per-location information through MLPs that are ap-plied to every image patch, and captures long-range infor-mation through MLPs that are applied across patches.
Although MLP-Mixer can obtain the global receptive
ﬁeld, there are two intractable ﬂaws that prevent the model from becoming a more general backbone for vision tasks: (i) The number of the patches (tokens) will change as the input size changes, which means it cannot be directly ﬁne-tuned at other resolutions that are different from those used in pre-training phase, making MLP-Mixer infeasible to be transferred into downstream vision tasks such as detection and segmentation. (ii) MLP-Mixer rarely explores the lo-cal information, which is demonstrated as an useful in-ductive bias in both CNNs and transformer-based architec-tures [18, 55]. The above challenges naturally motivate us to explore an efﬁcient MLP-based architecture which can encode both local and global information while being com-patible with ﬂexible input resolutions at the same time.
To address the two aforementioned challenges, we pro-pose the Hire-MLP, which innovates the existing MLP-based models by using hierarchical rearrangement opera-tions. Taking the ﬁrst challenge into account, the sequence of tokens in MLP-Mixer [47] are denoted as X ∈ RHW ×C, where HW and C denote the number of tokens and chan-nels, respectively. MLP-Mixer ﬁrst uses a token-mixing
MLP which acts on the columns of X to map RHW (cid:55)→
RHW , and then uses a channel-mixing MLP which acts on the rows of X to map RC (cid:55)→ RC. The parameters of the token-mixing MLP are conﬁgured by the number of tokens
HW , which depends on the resolution of input images and results in the ﬁrst challenge. To this end, we construct our
Hire-MLP merely by channel-mixing MLPs applied on the
Figure 1. The overall architecture of the proposed Hire-MLP-Tiny. More details and other variants of Hire-MLP can be found in Table A.1 in supplementary materials. Rearrangement layer and restoration layer in hire module are illustrated in Figure 2. channel dimension. As for the second challenge, we build the blocks of Hire-MLP based on hierarchical rearrange-ments and channel-mixing MLPs. The hierarchical rear-rangement operation consists of the inner-region rearrange-ment and the cross-region rearrangement, in which both the local and global information can be easily captured in both height and width directions. We ﬁrst split the input tokens into multiple regions along the height/width directions, and leverage the inner-region rearrangement operation to shufﬂe all adjacent tokens belonging to the same region into a one-dimensional vector, followed by two fully connected lay-ers to capture local information within these features. Af-ter that, this one-dimensional vector is restored back to the initial arrangement, as illustrated in Figure 1. For the com-munication between tokens from different regions, a cross-region rearrangement operation is implemented by shifting all the tokens along a speciﬁc direction, as shown in Fig-ure 2(c)(d). Such hierarchical rearrangement operation en-ables our model to obtain both local and global information, and can easily handle the ﬂexible input resolutions.
To be speciﬁc, our Hire-MLP has a hierarchical archi-tecture similar to conventional CNNs [18] and recently pro-posed transformers [35,52] to generate pyramid feature rep-resentations for downstream vision tasks. The overall archi-tecture is shown in Figure 1. After the ﬁrst projection layer, the resulting feature X ∈ RH×W ×C is then fed into a se-quence of Hire-MLP blocks. Hire module is a key compo-nent in Hire-MLP block, which consists of three indepen-dent branches. The ﬁrst two branches consist of a cross-region rearrangement layer, an inner-region rearrangement layer, two channel-mixing fully connected (FC) layers, an inner-region restore layer and a cross-region restore layer to capture local and global information along speciﬁc di-rection, i.e., the height and the width direction. The last branch is built upon a simple channel-mixing FC layer to capture channel information. Compared to existing MLP-based models that spatially shift features in different direc-tions [31,57] or leverage a new cycle fully connected opera-tor [5], our Hire-MLP needs only the channel-mixing MLPs and rearrangement operations. Furthermore, the rearrange-ment operations can be easily realized by commonly used reshape and padding operations in Pytorch/Tensorﬂow. And our Hire-MLP is completely capable to serve as a versatile backbone for various computer vision tasks.
Experiments show that Hire-MLP can largely improve the performances of existing MLP-based models on vari-ous tasks, including image classiﬁcation, object detection, instance segmentation, and semantic segmentation. For example, the Hire-MLP-Small attains an 82.1% top-1 ac-curacy on ImageNet, outperforming Swin-T [35] signiﬁ-cantly with a higher throughput. Scaling up the model to larger sizes, we can further obtain 83.2% and 83.8% top-1 accuracy. Using Hire-MLP-Small as backbone, Cascade
Mask R-CNN achieves 50.7% box AP and 44.2% mask AP on COCO val2017. In addition, Hire-MLP-Small obtains 46.1% single-scale mIoU on ADE20K, which has an im-provement of +1.6% mIoU over Swin-T, demonstrating that
Hire-MLP can achieve a better accuracy-latency trade-off than prior MLP-based and transformer-based architectures. 2.