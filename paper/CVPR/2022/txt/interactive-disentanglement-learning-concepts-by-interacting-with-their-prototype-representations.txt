Abstract
Learning visual concepts from raw images without strong supervision is a challenging task. In this work, we show the advantages of prototype representations for un-derstanding and revising the latent space of neural concept learners. For this purpose, we introduce interactive Con-cept Swapping Networks (iCSNs), a novel framework for learning concept-grounded representations via weak super-vision and implicit prototype representations. iCSNs learn to bind conceptual information to speciﬁc prototype slots by swapping the latent representations of paired images. This semantically grounded and discrete latent space facilitates human understanding and human-machine interaction. We support this claim by conducting experiments on our novel data set “Elementary Concept Reasoning” (ECR), focusing on visual concepts shared by geometric objects.1 1.

Introduction
Learning an adequate representation of concepts from raw data without strong supervision is a challenging task.
However, it remains important for research in areas of knowledge discovery where sufﬁcient prior knowledge is missing, and the goal is to attain novel understandings. With better representations and architectural components of ma-chine learning models, this appears to become more and more achievable [73]. However, if remained unchecked this bears the danger of learning incorrect concepts or even confounding features [18, 70]. A further difﬁcult aspect of concept learning, regardless of the level of supervision, is its dynamic and subjective nature. One downstream task might require more ﬁne-grained concepts than others, but also when encountering evidence on novel concepts (e.g. in an online learning setting), the knowledge and hierarchy of concepts should be constantly re-approved, discussed, and 1Code available at: https://github.com/ml- research/
XIConceptLearning
Would you consider these objects  to share an underlying concept?
Yes, they all have the color blue.
Would you consider these objects  to share an underlying concept?
Yes, they all have a triangular shape.
What about these objects?
No, I think these three and these  three objects share a concept:
Figure 1. A trained model (left) queries the human user (right) if the concepts that it has extracted from the data coincides with the knowledge of the user. Subsequently, the model can receive revisions from the user. possibly updated. It thus remains desirable that the repre-sentations learned by such concept learners to be human-understandable and revisable.
An evident approach to teaching concept information to a machine learning model is to train it in a supervised fash-ion through symbolic representations, e.g., one-hot encod-ing vectors and corresponding raw input [44, 84]. However, this requires extensive prior knowledge of relevant concepts and seems impractical given the subjective and dynamic na-ture of concept learning.
Another branch of research focuses on learning disen-tangled latent distribution models [27, 31, 80]. Although initially focused on unsupervised approaches, many re-cent studies have shifted away from unsupervised learn-ing and show promising results with weak supervision
[41, 49, 51, 58, 74, 81]. An often implicit assumption of dis-What do you call this object?:
I'm not sure. However, it is very similar to this prototypical large, blue circle:
You're right. It is large and blue.  I love the color blue!
But actually this represents a new shape.
Great thanks!
What is the concept of love?
Figure 2. Human-machine interaction for learning about novel concepts. The user queries an object and guides the machine’s prototype suggestion if necessary. entanglement research is that the learned latent represen-tations should correspond to human-interpretable factors.
Many state-of-the-art variational [51,58] and generative ad-versarial [13,46,56,59,60] approaches, however, learn con-tinuous latent representations, making these difﬁcult for a human to understand without additional techniques for in-terpreting the latent space [68].
Due to the intricate nature of concept learning and in-spired by ﬁndings on concept prototypes in the ﬁelds of psychology and cognitive science, we investigate the ad-vantages of prototype representations in learning human-understandable and revisable concept representations for neural concept learners. To this end, we introduce the novel framework of Interactive Concept Swapping Network (iCSN) that learns to implicitly bind semantic concepts to latent prototype representations through weak supervision.
This binding is enforced via a discretized distance estima-tion and swapping of shared concept representations be-tween paired data samples. Among other things, iCSNs al-low for querying and revising its learned concepts cf. Fig. 1, and integrating knowledge about unseen concepts cf. Fig. 2.
Explicitly focusing on learning object-centric visual con-cepts, we develop Elementary Concept Reasoning (ECR), a novel data set containing images of 2D geometrical objects and perform multiple experiments, emphasizing the advan-tages of our approach. To summarize, our work highlights the advantages of prototype representations for (i) learning a consistent and human-understandable latent space through weak supervision, (ii) revising concept representations via human interactions, and (iii) updating these in an online learning fashion. 2.