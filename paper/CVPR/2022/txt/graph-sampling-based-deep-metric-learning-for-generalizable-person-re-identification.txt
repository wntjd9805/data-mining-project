Abstract 1.

Introduction
Recent studies show that, both explicit deep feature matching as well as large-scale and diverse training data can significantly improve the generalization of person re-identification. However, the efficiency of learning deep matchers on large-scale data has not yet been adequately studied. Though learning with classification parameters or class memory is a popular way, it incurs large memory and computational costs. In contrast, pairwise deep met-ric learning within mini batches would be a better choice.
However, the most popular random sampling method, the well-known PK sampler, is not informative and efficient for deep metric learning. Though online hard example min-ing has improved the learning efficiency to some extent, the mining in mini batches after random sampling is still limited. This inspires us to explore the use of hard ex-ample mining earlier, in the data sampling stage. To do so, in this paper, we propose an efficient mini-batch sam-pling method, called graph sampling (GS), for large-scale deep metric learning. The basic idea is to build a near-est neighbor relationship graph for all classes at the be-ginning of each epoch. Then, each mini batch is com-posed of a randomly selected class and its nearest neigh-boring classes so as to provide informative and challeng-ing examples for learning. Together with an adapted com-petitive baseline, we improve the state of the art in gen-eralizable person re-identification significantly, by 25.1% in Rank-1 on MSMT17 when trained on RandPerson. Be-sides, the proposed method also outperforms the compet-itive baseline, by 6.8% in Rank-1 on CUHK03-NP when trained on MSMT17. Meanwhile, the training time is sig-nificantly reduced, from 25.4 hours to 2 hours when trained on RandPerson with 8,000 identities. Code is available at https://github.com/ShengcaiLiao/QAConv.
*Shengcai Liao is the corresponding author.
Person re-identification is a popular computer vision task, where the goal is to find a person, given in a query image, from the search over a large set of gallery images.
In the last two years, generalizable person re-identification has gain increasing attention due to both its research and practical value [11, 12, 17, 21, 26, 46, 48]. This task stud-ies the generalizability of a learned person re-identification model in unseen scenarios, and employs direct cross-dataset evaluation [10, 38] for performance benchmarking.
For deep metric learning, beyond feature representation learning and loss designs, explicit deep feature matching schemes are shown to be effective for matching person im-ages [1, 14, 17, 24, 28], due to the advantages in address-ing pose and viewpoint changes, occlusions, and misalign-ments. In particular, a recent method, called query-adaptive convolution (QAConv) [17], has proved that explicit convo-lutional matching between gallery and query feature maps is quite effective for generalizable person re-identification.
However, these methods all require more computational costs compared to conventional feature learning methods.
Beyond novel generalizable algorithms, another way to improve generalization is to enlarge the scale and diversity of the training data. For example, a recent dataset called
RandPerson [33] synthesized 8,000 identities, while [31] and [2] both collected 30K persons for re-identification training. These studies all observed improved generaliza-tion ability for person re-identification. However, the effi-ciency of deep metric learning from large-scale data has not yet been adequately studied in person re-identification.
There are some popular ways of learning deep person re-identification models, including classification (with the
ID loss [43]), metric learning (with a pairwise loss [5, 38] or triplet loss [9]), and their combinations (e.g. ID + triplet loss). Using an ID loss is convenient for classification learn-ing. However, in large-scale deep learning, involving clas-sifier parameters incurs large memory and computational costs in both the forward and backward passes. Similarly,
(a) PK sampler (b) GS sampler
Figure 1. Two different sampling methods: (a) PK sampler; and (b) the proposed GS sampler. Different shapes indicate different classes, while different colors indicate different batches. GS constructs a graph for all classes and always samples nearest neighboring classes. involving class signatures for metric learning in a global view is also not efficient. For example, QAConv in [17] is difficult to scale up for large-scale training, because a class memory module is designed, where full feature maps are stored for all classes as signatures, and they are required for cross feature map convolutional matching during training.
Therefore, involving class parameters or signatures in either classification or metric learning is not efficient for large-scale person re-identification training. In contrast, we consider that pairwise deep metric learning between sam-ples in mini batches is better suited for this task. Accord-ingly, the batch sampler plays an important role for effi-cient learning [9, 37]. The well-known PK sampler [9, 22] is the most popular random sampling method in person re-identification. It first randomly selects P classes, and then randomly samples K images per class to construct a mini batch of size B = P × K. Since this is performed ran-domly, the sampled instances within a mini batch are uni-formly distributed across the whole dataset (see Fig. 1 (a)), and might therefore not be informative and efficient for deep metric learning. To address this, an online hard example mining method was proposed in [9], which improved the learning efficiency to some extent. However, the mining is performed online on the already sampled mini batches.
Therefore, this method is still limited by the fully random
PK sampler, because the mini batches obtained by this sam-pler do not consider the sample relationship information.
To address this, we propose to shift the hard example mining earlier to the data sampling stage. Accordingly, we propose an efficient mini-batch sampling method, called graph sampling (GS), for large-scale deep metric learning.
The basic idea is to build a nearest neighbor relationship graph for all classes at the beginning of each epoch. Then, the mini-batch sampling is performed by randomly select-ing a class as anchor, and its top-k nearest neighboring classes, with the same K instances per class, as shown in
Fig. 1 (b). This way, instances within a sampled mini batch are mostly similar to each other, so as to provide informative and challenging examples for discriminant learning. From face recognition loss function studies [4,19,35], it is known that focusing on boundary (hard) examples helps improving the discriminant ability of the learned model, and helps re-sulting in compact representations that generalize well be-yond the training data. The GS sampler shares a similar idea in focusing on nearest neighboring classes, and thus has a potential of improving the discrimination and gener-alization ability of the learned model.
In summary, the contributions of this paper include: (1)
We propose a new mini-batch sampling method, termed GS, and prove that it enables more efficient learning than the well-known PK sampler; (2) We improve a very competitive baseline by 6.8% in Rank-1 with MSMT17 → CUHK03-NP, and reduce the training time significantly, from 25.4 hours to 2 hours on RandPerson with 8,000 identities; and (3) Together with the baseline, we improve the state of the art in generalizable person re-identification significantly, by 20.6% in Rank-1 with Market-1501 → MSMT17, and by 25.1% in Rank-1 with RandPerson → MSMT17. 2.