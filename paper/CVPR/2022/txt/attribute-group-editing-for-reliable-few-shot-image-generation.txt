Abstract
Few-shot image generation is a challenging task even using the state-of-the-art Generative Adversarial Networks (GANs). Due to the unstable GAN training process and the limited training data, the generated images are often
In this work, we pro-of low quality and low diversity. pose a new “editing-based” method, i.e., Attribute Group
Editing (AGE), for few-shot image generation. The basic assumption is that any image is a collection of attributes and the editing direction for a specific attribute is shared across all categories. AGE examines the internal represen-tation learned in GANs and identifies semantically mean-ingful directions. Specifically, the class embedding, i.e., the mean vector of the latent codes from a specific category, is used to represent the category-relevant attributes, and the category-irrelevant attributes are learned globally by
Sparse Dictionary Learning on the difference between the sample embedding and the class embedding. Given a GAN well trained on seen categories, diverse images of unseen categories can be synthesized through editing category-irrelevant attributes while keeping category-relevant at-tributes unchanged. Without re-training the GAN, AGE is capable of not only producing more realistic and di-verse images for downstream visual applications with lim-ited data but achieving controllable image editing with in-terpretable category-irrelevant directions. Code is avail-able at https://github.com/UniBester/AGE. 1.

Introduction
The emergence of GANs [10] has enabled the deep gen-erative model to generate images with higher quality and di-versity. However, due to the characteristics of GANs, train-ing a good GAN model often requires a lot of training data
*These authors contributed equally to this work.
†Corresponding authors.
Figure 1. Illustration of attribute editing in the latent space. (a) The category-relevant attribute editing between the class em-bedding wcm . (b) The category-irrelevant attribute editing within categories. The same editing in the latent space is universal be-tween different categories and is difficult to converge [41]. Given a few images from an unseen category, it is hard for GANs to generate new realistic and diverse images for this category. This task is referred to as few-shot image generation, which can benefit a bunch of downstream tasks like low-data detection [8] and few-shot classification [34, 36].
Existing few-shot image generation methods can be roughly divided into three types, i.e., optimization-based [7, 23], fusion-based [4, 11, 14, 15], and transformation-based [3, 13]. Optimization-based methods introduce meta-learning paradigms to generate new images by learning an initialized base model and fine-tuning the model with each unseen category, but images generated by methods of this type are blurry and of low quality. Fusion-based methods fuse several input images in a feature space and decode the fused feature back to a realistic image of the same cate-gory. However, these methods need at least two images as
input and can only generate images similar to input images.
Transformation-based methods find intra-category transfor-mations and apply these transformations to unseen cate-gory samples to generate more images of the same category.
However, the end-to-end training of image transformation and generation is very unstable. Worse still, these transfor-mations tends to be complicated, and the generated images are often of low-quality and even crashed.
Drawing on the idea of StyleGAN [20,21], an image can be regarded as a collection of different attributes. The cat-egory of an image is decided by objects’ category-relevant attributes, such as the shape of the face and the morphology of the fur. Differences between images of the same cate-gory are reflected in category-irrelevant attributes including expressions, postures, etc. Moreover, many works [12, 32] have shown that GANs represent these attributes in the la-tent space. Moving the latent code along an identified di-rection can accordingly change the semantic in the output images. Theoretically, given a pretrained GAN, an object of an unseen category can be generated with combinations of attributes from seen categories as shown in Figure 1(a). Di-verse images of the same category can be generated by edit-ing category-irrelevant attributes, which are shared across all categories as shown in Figure 1(b). If these semantically meaningful directions can be distinguished, we can achieve reliable few-shot image generation needless of re-training a
GAN.
In order to identify such directions, image editing meth-ods typically annotate a collection of synthesized samples and train linear classifiers in the latent space. They require a clear definition of the target attributes as well as the corre-sponding manual annotations. However, it will be unrealis-tic to obtain such detailed annotations for more complicated multi-category image generation [6, 24, 26]. Therefore, the key challenge of the editing-based method is to factorize the meaningful directions for category-relevant and category-irrelevant attributes without explicit supervision.
To achieve this goal, we propose Attribute Group Edit-ing (AGE), which examines the variation relationship be-tween the image and the internal representation. The core of AGE is to factorize the directions of category-irrelevant attributes and category-relevant attributes without explicit supervision. First, the class embedding for a specific cate-gory is obtained from the mean representation of all samples from this category. As shown in Figure 1(a), for a seen cat-egory with a large amount of training data, this embedding is likely to disentangle all category-relevant attributes from major category-irrelevant attributes. Afterward, any sam-ples in the dataset can be regarded as category-irrelevant editing from the corresponding class embedding. In order to factorize category-irrelevant directions in latent space, we model this editing process with Sparse Dictionary Learn-ing (SDL) [2, 25]. A number of constraints are used to en-sure that every direction in the dictionary is semantically meaningful and category-irrelevant. Different linear com-binations of directions in the dictionary can facilitate gener-ation of diverse images without changing their category.
Our contributions can be summarized as follows:
- We present a new perspective for few-shot image gen-eration, i.e., diverse images of unseen categories can be pro-duced through category-irrelevant image editing.
- We propose a new method, Attribute Group Edit-ing (AGE), which can identify groups of category-relevant and category-irrelevant editing directions from a pretrained
GAN without explicit supervision.
- Extensive experiments suggest that AGE achieves more stable few-shot image generation with high quality and di-versity. Besides, since the editing directions discovered by AGE are semantically meaningful, we can also perform controllable image generation based on the learned attribute dictionary. 2.