Abstract
In this paper, we propose an unsupervised domain adap-tation method for deep point cloud representation learning.
To model the internal structures in target point clouds, we first propose to learn the global representations of unla-beled data by scaling up or down point clouds and then predicting the scales. Second, to capture the local structure in a self-supervised manner, we propose to project a 3D local area onto a 2D plane and then learn to reconstruct the squeezed region. Moreover, to effectively transfer the knowledge from source domain, we propose to vote pseudo labels for target samples based on the labels of their nearest source neighbors in the shared feature space. To avoid the noise caused by incorrect pseudo labels, we only select re-liable target samples, whose voting consistencies are high enough, for enhancing adaptation. The voting method is able to adaptively select more and more target samples dur-ing training, which in return facilitates adaptation because the amount of labeled target data increases. Experiments on
PointDA (ModelNet-10, ShapeNet-10 and ScanNet-10) and
Sim-to-Real (ModelNet-11, ScanObjectNN-11, ShapeNet-9 and ScanObjectNN-9) demonstrate the effectiveness of our method. 1.

Introduction
Large-scale learning methods based on deep neural net-works [7–10, 15, 25, 26, 35, 36, 39] constitute the recent ad-vances in 3D vision, and play an important role for visual perception in intelligent platforms such as robots, drones
∗Part of this work was done when Wanyue Zhang was an intern at
Agency for Science, Technology, and Research, Singapore.
Figure 1. Illustration of the self-supervised global-local structure modeling for point cloud domain adaptation. The global structure is modeled by scaling up/down the point cloud and then predicting the scale. To capture the local structure, a random 3D local area is squeezed onto a 2D plane and then reconstructed by the network. and self-driving cars. These intelligent platforms often em-ploy real-time depth sensors, such as LiDAR, to capture the accurate geometric information of scenes, which are repre-sented by 3D point clouds. However, deep neural neural networks usually requires massive amounts of labeled point clouds for representation learning, which limits the scalabil-ity to the real world. To alleviate this problem, unsupervised point cloud domain adaption is recently attracting increas-ing attention from the community [1, 27, 31, 43]. Domain adaptation aims to transfer the knowledge from a labeled source domain to a related but unlabeled target domain, in which the source and target domains share the same feature space. However, due to different point scales, object sizes, densities, styles, sensor perspectives, etc., point cloud rep-resentations in the target domain inevitably deviate from the corresponding representations in the source domain, result-during training, our reliable voting method adaptively se-lects more target data, which in return facilitates learning because the amount of labeled target data increases.
To evaluate our method, we conduct experiments on the widely-used 3D domain adaptation benchmark
PointDA [27], which consists of 10 shared classes from
ModelNet40 [37], ShapeNet [2] and ScanNet [3]. More-over, we also conduct experiments on a Sim-to-Real dataset [16], which consists of 11 shared classes from Mod-elNet40 and ScanObjectNN [34], and 9 shared classes from
ShapeNet and ScanObjectNN, respectively. The contribu-tions of this paper are threefold:
• To model the structure of unlabeled target point clouds, we propose the global scaling-up-down prediction and local 3D-2D-3D projection-reconstruction methods for point cloud domain adaptation.
• To transfer the knowledge from source domain, we propose a voting method to assign reliable pseudo la-bels to target samples. The method is able to iteratively select more and more target data during training, which in return facilitates learning.
• Extensive experiments on two datasets show that the proposed method effectively improves the accuracy of unsupervised domain adaptation on point clouds. 2.