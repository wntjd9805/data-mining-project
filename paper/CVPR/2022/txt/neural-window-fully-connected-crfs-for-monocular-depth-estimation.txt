Abstract
Estimating the accurate depth from a single image is challenging since it is inherently ambiguous and ill-posed.
While recent works design increasingly complicated and powerful networks to directly regress the depth map, we take the path of CRFs optimization. Due to the expensive com-putation, CRFs are usually performed between neighbor-hoods rather than the whole graph. To leverage the poten-tial of fully-connected CRFs, we split the input into windows and perform the FC-CRFs optimization within each win-dow, which reduces the computation complexity and makes
FC-CRFs feasible. To better capture the relationships be-tween nodes in the graph, we exploit the multi-head atten-tion mechanism to compute a multi-head potential function, which is fed to the networks to output an optimized depth map. Then we build a bottom-up-top-down structure, where this neural window FC-CRFs module serves as the decoder, and a vision transformer serves as the encoder. The ex-periments demonstrate that our method signiﬁcantly im-proves the performance across all metrics on both the KITTI and NYUv2 datasets, compared to previous methods. Fur-thermore, the proposed method can be directly applied to panorama images and outperforms all previous panorama methods on the MatterPort3D dataset. 1 1.

Introduction
Depth prediction is a classical task in computer vision and is essential for numerous applications such as 3D recon-struction, autonomous driving, and robotics [8, 13, 41, 42].
Such a vision task aims to estimate the depth map from a single color image, which is an ill-posed and inherently ambiguous problem since inﬁnitely many 3D scenes can be projected to the same 2D scene. Therefore, this task is chal-lenging for traditional methods [22, 23, 30], which are usu-ally limited to low-dimension and sparse distances [22], or known and ﬁxed objects [23].
Recently, many works have employed the deep networks to directly regress the depth maps and achieved good per-formances [1, 2, 6, 7, 17, 18]. Nevertheless, since there are no geometric constraints of multi-view [9,40,43] to exploit, 1Project page: https://weihaosky.github.io/newcrfs
Figure 1. The neural window fully-connected CRFs take image feature F and upper-level prediction X as input, and compute the fully-connected energy E in each window, which is then fed to the networks to output an optimized depth map. the focus of most works is designing more powerful and more complicated networks. This renders this task a difﬁ-cult ﬁtting problem without the help of other guidance.
In traditional monocular depth estimation, some meth-ods build the energy function from Markov Random Fields (MRFs) or Conditional Random Fields (CRFs) [30, 31, 37].
They exploit the observation cues, such as the texture and position information, along with the last prediction to build the energy function, and then optimize this energy to ob-tain a depth prediction. This approach is demonstrated to be effective in guiding the estimation of the depth, and is also introduced in some deep methods [11,20,29,38]. How-ever, they are all limited in neighbor CRFs rather than fully-connected CRFs (FC-CRFs) due to the expensive computa-tion, while the fully-connected CRFs capture the relation-ship between any node in a graph and are much stronger.
To address the above challenge, in this work we seg-ment the input to multiple windows, and build the fully-connected CRFs energy within each window, in which way the computation complexity is reduced considerably and the fully-connected CRFs becomes feasible. To capture more relationships between the nodes in the graph, we exploit the multi-head attention mechanism [35] to compute the pair-wise potential of the CRFs, and build a new neural CRFs module, as is shown in Figure 1. By employing this neural window FC-CRFs module as decoder, and a vision trans-former as encoder, we build a straightforward bottom-up-top-down network to estimate the depth. To make up for
the isolation of each window, a window shift action [21] is performed, and the lack of global information in these window FC-CRFs is addressed by aggregating the global features from global average pooling layers [45].
In the experiments, our method is demonstrated to out-perform previous methods by a signiﬁcant margin on both the outdoor dataset, KITTI [8], and the indoor dataset,
NYUv2 [32]. Although the state-of-the-art performance on KITTI and NYUv2 has been saturated for a while, our method further reduces the errors considerably on both datasets. Speciﬁcally, the Abs-Rel error and the RMS er-ror of KITTI are decreased by 10.3% and 9.8%, and that of NYUv2 are decreased by 7.8% and 8.2%. Our method now ranks ﬁrst among all submissions on the KITTI on-line benchmark.
In addition, we evaluate our method on the panorama images. As is well-known, the networks de-signed for perspective images usually perform poorly on the panorama dataset [14, 33, 34, 36]. Remarkably, our method also sets a new state-of-the-art performance on the panorama dataset, MatterPort3D [3]. This demonstrates that our method can handle the common scenarios in the monocular depth prediction task.
The main contributions of this work are then summarized as follows:
• We split the input image into sub-windows and per-form fully-connected CRFs optimization within each win-dow, which reduces the high computation complexity and makes the FC-CRFs feasible.
• We employ the multi-head attention to capture the pair-wise relationships in the window FC-CRFs, and embed this neural CRFs module in a network to serve as the decoder.
• We build a new bottom-up-top-down network for monocular depth estimation and show a signiﬁcant im-provement of the monocular depth across all metrics on
KITTI, NYUv2, and MatterPort3D datasets. 2.