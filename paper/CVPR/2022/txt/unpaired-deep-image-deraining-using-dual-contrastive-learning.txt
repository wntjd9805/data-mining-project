Abstract
Learning single image deraining (SID) networks from an unpaired set of clean and rainy images is practical and valuable as acquiring paired real-world data is al-most infeasible. However, without the paired data as the supervision, learning a SID network is challenging. More-over, simply using existing unpaired learning methods (e.g., unpaired adversarial learning and cycle-consistency con-straints) in the SID task is insufﬁcient to learn the under-lying relationship from rainy inputs to clean outputs as there exists signiﬁcant domain gap between the rainy and
In this paper, we develop an effective un-clean images. paired SID adversarial framework which explores mutual properties of the unpaired exemplars by a dual contrastive learning manner in a deep feature space, named as DCD-GAN. The proposed method mainly consists of two coop-erative branches: Bidirectional Translation Branch (BTB) and Contrastive Guidance Branch (CGB). Speciﬁcally, BTB exploits full advantage of the circulatory architecture of ad-versarial consistency to generate abundant exemplar pairs and excavates latent feature distributions between two do-mains by equipping it with bidirectional mapping. Simulta-neously, CGB implicitly constrains the embeddings of dif-ferent exemplars in the deep feature space by encouraging the similar feature distributions closer while pushing the dissimilar further away, in order to better facilitate rain re-moval and help image restoration. Extensive experiments demonstrate that our method performs favorably against existing unpaired deraining approaches on both synthetic and real-world datasets, and generates comparable results against several fully-supervised or semi-supervised models. 1.

Introduction
Images captured under complicated rain weather envi-ronments often suffer from unfavorable visibility by rain streaks. Such these degraded images usually affect many computer vision tasks (including detection [20], segmen-Figure 1. Derained results on a real-world rainy image by unpaired learning approaches. Directly employing existing unpaired learn-ing methods, e.g., CycleGAN and DCLGAN, does not effecively remove rain streaks. tation [38] and video surveillance [28], etc.) with drastic performance drop. Thus, it is of great interest to develop an effective algorithm to recover high-quality rain-free images.
In general, the rain process is usually modeled by the following linear superimposition model:
O = B + R, (1) where O, B, and R denote the rainy image, clean image, and rain streaks, respectively. The goal of single image de-raining (SID) is to estimate clean image B from the input rainy image O. This is an ill-posed problem as only rainy image is known. To make the problem well-posed, conven-tional methods [17, 19, 23, 47] usually impose certain priors on the clean images and rain components. Although decent results have been achieved, the priors are based on empirical statistical results and may not model the inherent properties of the clean images and rain components, which thus do not effectively remove the rain well.
Recently, numerous data-driven learning methods have developed [15, 27, 42, 45, 49]. Although remarkable perfor-mance has been achieved, these fully-supervised methods need paired synthetic data which does not model the real-world degradation well. Therefore, these methods usually do not perform well when handling the real-world rainy im-ages due to the domain gap between the training and test data. Moreover, obtaining large scale paired real-world data for training in complex rainy environments is challenging.
To overcome these problems, the semi-supervised [13,
22, 36, 43] and unsupervised [9, 51] learning have been pro-posed for SID. These methods [13, 16] either focus on do-main invariant features by leveraging the limited labeled data and introducing the auxiliary optimization objectives or develop domain adaption strategies [9, 37] to improve the generalization capabilities of the deep models. How-ever, without suitable constraints for rain streaks and clean images, existing unpaired learning methods [8, 52] do not effectively restore high-quality derained results, as shown in Fig. 1 (b) and (c). Note that, these methods mainly con-sider the mapping relationship in the image space but ignore the potential relationship in the feature space, which does not fully excavate the useful feature information for SID.
Since the ground truth labeled data is not fully available, how to model the latent-space representation by exploring the relationship between the rainy inputs and clean outputs is important for the deep learning-based methods. In addi-tion, given that clean images can be easily obtained, it is also important to develop an effective method that can ex-plore properties of the clean exemplars to facilitate image restoration when paired data is not available.
Towards this end, we develop a Dual Contrastive Derain-GAN (DCD-GAN) method which incorporates recent con-trastive learning with adversarial framework to explore use-ful features from the rainy images and unpaired clean im-ages so that the extracted features can better facilitate rain removal. Ideally, we note that if a deep model can accu-rately restore a clean image from rainy one, the features that are for clean image reconstruction would have mutual infor-mation with the ones from the ground truth rain-free images by the same deep model. This motivates us to introduce a contrastive learning method to mining the mutual features of rainy images and clean ones in the deep feature space, so that we can use the features from the clean images to better guide the image restoration. Therefore, our proposed
DCD-GAN includes two main interactive branches: Bidi-rectional Translation Branch (BTB) and Contrastive Guid-ance Branch (CGB). Speciﬁcally, BTB is equipped with bidirectional mapping to mine rain-related or clean-cue fea-tures, and the use of adversarial training produces rich ex-emplar pairs during the optimization. In addition, CGB im-plicitly constrains the latent space of corresponding patches to guide deraining by encouraging the positives (i.e, simi-lar feature distributions) closer while keeping the negatives (i.e, dissimilar ones) further away. To summarize, the main contributions of this paper are summarized as follows:
• We formulate an effective DCD-GAN which leverages dual contrastive learning to encourage the model to ex-plore mutual features while distinguish the dissimilar ones between the rainy domain and the rain-free do-main in the deep feature space.
• The proposed DCD-GAN is performed without paired training information, where the features from the un-paired clean exemplars can facilitate rain removal. The learned latent restoration can boost the cross-domain deraining generalization performance.
• Experimental results on challenging datasets consider-ably show that our developed method performs favor-ably against existing unpaired deraining approaches, and achieves comparable performance against several fully-supervised or semi-supervised models. 2.