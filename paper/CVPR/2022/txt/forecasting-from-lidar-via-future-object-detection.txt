Abstract
Object detection and forecasting are fundamental com-ponents of embodied perception. These two problems, how-ever, are largely studied in isolation by the community. In this paper, we propose an end-to-end approach for detection and motion forecasting based on raw sensor measurement as opposed to ground truth tracks. Instead of predicting the current frame locations and forecasting forward in time, we directly predict future object locations and backcast to de-termine where each trajectory began. Our approach not only improves overall accuracy compared to other modular or end-to-end baselines, it also prompts us to rethink the role of explicit tracking for embodied perception. Addition-ally, by linking future and current locations in a many-to-one manner, our approach is able to reason about multiple futures, a capability that was previously considered difficult for end-to-end approaches. We conduct extensive experi-ments on the popular nuScenes dataset and demonstrate the empirical effectiveness of our approach. In addition, we in-vestigate the appropriateness of reusing standard forecast-ing metrics for an end-to-end setup, and find a number of limitations which allow us to build simple baselines to game these metrics. We address this issue with a novel set of joint forecasting and detection metrics that extend the commonly used AP metrics from the detection community to measur-ing forecasting accuracy. Our code is available on GitHub. 1.

Introduction
Object detection and forecasting are fundamental com-ponents of embodied perception that are often studied inde-pendently. In this paper we rethink the methods and metrics for trajectory forecasting from LiDAR sensor data. Trajec-tory forecasting is a critical perception task for autonomous robot navigation, thus building meaningful evaluation met-rics and robust methods is of utmost importance.
Traditional trajectory forecasting methods [6, 9, 47] de-*Work done during an internship at Argo AI
Figure 1. (a) Current stage-wise methods independently address the problems of detection, tracking, and forecasting, allowing for compounding errors in the full pipeline. Each sub-module incor-rectly assumes that its input will be perfect, leading to further inte-gration errors. In contrast to current forecasting methods that use object tracks as input, end-to-end forecasting directly from LiDAR sensory data (b) streamlines forecasting pipelines. To this end, we propose FutureDet (c), an end-to-end model capable of forecasting multiple-future trajectories directly from LiDAR via future object detection. We show that our end-to-end pipeline improves upon state-of-the-art three-stage and end-to-end methods. tect [44–46] and track [23, 48, 50] objects in 3D LiDAR scans to obtain past trajectories (Fig. 1a). These can be used in conjunction with auto-regressive forecasting meth-ods [1, 20, 22, 43] to estimate the future actions of sur-rounding agents. Recent efforts [33, 37, 51] streamline such multi-stage perception stacks and train multi-task neural networks to jointly detect, track and forecast object posi-tions directly from raw sensor data (Fig. 1b). However, such end-to-end approaches tend to predict only a single future trajectory for each object, not accounting for future uncertainty. This is not surprising as estimating multiple fu-tures is a significant challenge in forecasting, requiring ma-chinery such as multiple-choice-loss [5] or generative mod-els [2, 10, 11, 20, 22, 25, 29, 42].
We rethink the forecasting task and propose FutureDet, an approach that reframes forecasting as the task of fu-ture object detection (Fig. 1c).
Importantly, existing de-tectors [27, 53, 56] already learn to predict heatmaps that capture distributions over possible object locations. We re-purpose this machinery to represent possible future object states. To this end, we encode an accumulated sequence of past raw LiDAR scans using standard backbones for 3D
LiDAR-based object detection and train our network to (i) detect objects multiple timesteps into the future and (ii) es-timate trajectories for these future detections back in time (i.e., back-cast) to the current frame. By matching back-casted future detections to current detections in a many-to-one manner, our approach can represent a distribution over multiple plausible future states. Our extensive evaluation on the large-scale nuScenes [6] dataset for trajectory forecast-ing reveals that our proposed FutureDet outperforms state-of-the-art methods, without requiring object tracks or HD-maps as inputs to the model. We posit that tracking may emerge from our network (since tracking objects from accu-mulated past LiDAR scans may make them easier to fore-cast), similar to the emergence of tracking and forecasting in streaming perception [31].
Furthermore, we investigate the utility of current metrics
[33,49] for evaluating forecasting directly from raw LiDAR data. We find that existing metrics are not well suited for the task of joint detection and forecasting, allowing them to be gamed by trivial forecasters. Current metrics for end-to-end
LiDAR forecasting adapt trajectory-based forecasting met-rics, such as average/final displacement error (ADE/FDE).
These metrics were designed for evaluating forecasting in a setting where perfect tracks are given as input, and ob-jects don’t have to be detected. However, these metrics don’t adapt well to the end-to-end setting. We demonstrate that such metrics can be gamed by baselines that simply rank all stationary objects (which are trivially easy to fore-cast) with high confidence, dramatically outperforming all prior art. Moreover, these evaluation metrics detach two in-herently inter-connected tasks of detection and forecasting.
Consequentially, they do not penalize false forecasts, i.e., forecasts that do not actually belong to any objects. In this sense, the end-to-end setup and evaluation is more realistic.
To address these short-comings, we rethink the evalua-tion procedure for joint object detection and forecasting di-rectly from sensor data. Our key insight is that the versatile average precision (AP) metric, a gold standard for assess-ing object detection performance, can be generalized to the task of joint detection and forecasting. The key feature of our novel forecasting mAP is that a forecast is correct only if the object is both correctly detected and forecasted. Our forecasting mAP is then calculated by simply using the ma-chinery of AP, but using this joint detection and forecasting definition of a true positive. Furthermore, our forecasting mAP can be extended to evaluating multiple-future forecasts for each object by simply evaluating w.r.t. the top-K most confident forecasts per-detection. Our metric appropriately adapts forecasting metrics for end-to-end evaluation: fore-casting mAP jointly assesses forecasting and detection, pe-nalizing both missed forecasts as well as false forecasts. It assesses forecasting performance on the full set of object detections and embraces the inherent multi-future nature of forecasting.
Contributions: We (i) repurpose object detectors for the task of end-to-end trajectory forecasting and propose a model that can predict multiple forecasts for each current detection, (ii) rethink trajectory forecasting evaluation and show that detection and forecasting can be jointly evalu-ated using a generalization of well-accepted object detec-tion metrics, and (iii) thoroughly analyze the performance of our model on the challenging nuScenes dataset [7], show-ing that it outperforms both previous end-to-end trainable methods and more traditional multi-stage approaches. 2.