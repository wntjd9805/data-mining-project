Abstract
Two-stage and query-based instance segmentation meth-ods have achieved remarkable results. However, their seg-mented masks are still very coarse. In this paper, we present
Mask Transfiner for high-quality and efficient instance seg-mentation. Instead of operating on regular dense tensors, our Mask Transfiner decomposes and represents the image regions as a quadtree. Our transformer-based approach only processes detected error-prone tree nodes and self-corrects their errors in parallel. While these sparse pix-els only constitute a small proportion of the total number, they are critical to the final mask quality. This allows Mask
Transfiner to predict highly accurate instance masks, at a low computational cost. Extensive experiments demon-strate that Mask Transfiner outperforms current instance segmentation methods on three popular benchmarks, signif-icantly improving both two-stage and query-based frame-works by a large margin of +3.0 mask AP on COCO and
BDD100K, and +6.6 boundary AP on Cityscapes. Our code and trained models are available at https://github. com/SysCV/transfiner. 1.

Introduction
Advancements in image instance segmentation has largely been driven by the developments of powerful ob-ject detection paradigms. Approaches based on Mask R-CNN [12,21,24,28,34] and more recently DETR [15,17,23] have achieved ever increasing performance on, for instance, the COCO challenge [33]. While these methods excel in detection and localization of objects, the problem of effi-ciently predicting highly accurate segmentation masks has so far remained elusive.
As shown in Figure 3, there is still a significant gap be-tween the bounding box and segmentation performance of the recent state-of-the-art methods, especially for the re-cent query-based methods. This strongly indicates that im-provements in mask quality has not kept pace with the ad-vancements detection capability. In Figure 2, the predicted masks of previous methods are very coarse, most often over-smoothing object boundaries. In fact, efficient and accurate mask prediction is highly challenging, due to the need for
Figure 1. We propose Mask Transfiner for high-quality instance segmentation. It first builds a quadtree based on the sparse inco-herent regions on the RoI pyramid and then jointly refines all tree nodes using the refinement transformer with quadtree attention. high-resolution deep features, which demands large compu-tational and memory costs [38].
To address these issues, we propose Mask Transfiner, an efficient transformer-based approach for high-quality in-stance segmentation. In Figure 1, our approach first iden-tifies error-prone regions, which are mostly strewn along object boundaries or in high-frequency regions. To this end, our network learns to detect incoherent regions, de-fined by the loss of information when downsampling mask itself. These incoherent pixels are sparsely located, con-sisting only of a small portion of the total pixels. How-ever, as they are shown to be critical to the final segmenta-tion performance, it allows us to only process small parts of the high-resolution feature maps in the refinement process.
Thus, we build a hierarchical quadtree [18] to represent and process the incoherent image pixels at multiple scales.
To refine the mask labels of the incoherent quadtree nodes, we design an refinement network based on the trans-former instead of standard convolutional networks because they require operating on uniform grids. Our transformer has three modules: node encoder, sequence encoder and pixel decoder. The node encoder first enriches the feature embedding for each incoherent point. The sequence en-coder then takes these encoded feature vectors across mul-tiple quadtree levels as input queries. Finally, the pixel de-coder predicts their corresponding mask labels. Comparing
Figure 2.
Instance Segmentation on COCO [33] validation set by a) Mask R-CNN [21], b) BMask R-CNN [12], c) SOLQ [15], d)
PointRend [28], g) Mask Transfiner (Ours) using R50-FPN as backbone, where Mask Transfiner produces significantly more detailed results at high-frequency image regions by replacing Mask R-CNNâ€™s default mask head. Zoom in for better view. gorithms, while QueryInst [17] adopts dynamic mask heads with mask information flow. However, the large gaps be-tween the detection and segmentation performance in Fig-ure 3 reveals that the mask quality produced by these query-based methods are still unsatisfactory.
In contrast to the above methods, Mask Transfiner is targeted for high-quality instance segmentation. In our efficient transformer the input queries are incoherent pixels nodes, instead of representing the objects. Our method is applicable to and effective in both the two-stage and query-based frameworks.
Refinement for Instance Segmentation Most exist-ing works on instance segmentation refinement rely on specially designed convolutional networks [36, 47] or
MLPs [28]. PointRend [28] samples feature points with low-confidence scores and refines their labels with a shared
MLP, where the selected points are determined by the coarse predictions of the Mask R-CNN. RefineMask [47] incorporates fine-grained features with an additional se-mantic head as the guidance. The post-processing method
BPR [36] crops boundary patches of images and initial masks as input and use [38] for segmentation. Notably some methods [11, 14, 46] focus on refining semantic segmenta-tion details. However, it is challenging for instance segmen-tation due to the more complex segmentation setting, with varying number of objects per image and the requirement of delineating overlapping objects [27].
Compared to these refinement methods, Mask Trans-finer is an end-to-end instance segmentation method, us-ing a transformer for correcting errors. The regions to be refined are predicted using a lightweight FCN, instead of non-deterministic sampling based on mask scores [28]. Dif-ferent from the MLP in [28], the sequential and hierarchical input representation enables Mask Transfiner to efficiently take non-local sparse feature points as input queries, where the strong global processing of transformers is a natural fit for our quadtree structure. 3. Mask Transfiner
We propose an approach to efficiently tackle high-quality instance segmentation. The overall architecture of Mask
Transfiner is depicted in Figure 5. From the base object de-tection network, e.g. Mask R-CNN [21], we employ a multi-scale deep feature pyramid. The object detection head then predicts bounding boxes as instance proposals. This com-Figure 3. The performance gap between object detection and seg-mentation for instance segmentation models on COCO test-dev set using R50-FPN as backbone. Detailed comparisons are in Table 9. to MLP [28], the sequential representation and multi-head attention enables Mask Transfiner to flexibly takes as in-put sparse feature points across levels in parallel, models their pixel-wise relations, and then propagates information among them even in a long distance range.
We extensively analyze our approach on COCO,
Cityscapes and BDD100K benchmarks, where quantitative and qualitative results show that Mask Transfiner not only outperforms existing two-stage and query-based methods, but also is efficient in computation and memory cost com-pared to standard transformer usages. We establish a new state-of-the-art result on COCO test-dev of 41.6 APMask us-ing ResNet-50, outperforming most recent SOLQ [15] and
QueryInst [17] by a significant margin. 2.