Abstract
Disjoint Setup 
Blurry Setup 
In visual search, the gallery set could be incrementally growing and added to the database in practice. However, existing methods rely on the model trained on the entire dataset, ignoring the continual updating of the model. Be-sides, as the model updates, the new model must re-extract features for the entire gallery set to maintain compatible feature space, imposing a high computational cost for a large gallery set. To address the issues of long-term visual search, we introduce a continual learning (CL) approach that can handle the incrementally growing gallery set with backward embedding consistency. We enforce the losses of inter-session data coherence, neighbor-session model co-herence, and intra-session discrimination to conduct a con-tinual learner. In addition to the disjoint setup, our CL so-lution also tackles the situation of increasingly adding new classes for the blurry boundary without assuming all cat-egories known in the beginning and during model update.
To our knowledge, this is the ﬁrst CL method both tackling the issue of backward-consistent feature embedding and al-lowing novel classes to occur in the new sessions. Extensive experiments on various benchmarks show the efﬁcacy of our approach under a wide range of setups1. 1.

Introduction
Continual learning (CL) aims to learn new tasks while keeping the functions learned from the old sessions. The technology has been rapidly evolving; nevertheless, the ac-tive research area in CL focuses on image classiﬁcation but ignores the demand for image retrieval (aka visual search).
For obtaining powerful feature representations in image re-trieval, most works [37,44,57,67] still require a model to be trained on an entire dataset simultaneously instead of in an incremental manner. However, a practical visual search sys-tem should be capable of continually learning from new ma-terials while consolidating the old knowledge to cope with the data accumulated with time.
* indicates corresponding author. 1Code: https://github.com/ivclab/CVS
Space 2 
Space 1 
Session 2 
Session 1 
Space 2 
Space 1 
Session 1 
Session 2 
General Incremental Setup 
Session 1 
Session 2 
Session J 
Figure 1. Illustration of the proposed approach with the general incremental setup. Our solution allows the new gallery set of seen and unseen classes freely and incrementally added to the database with respect to the widely adopted disjoint and the recent blurry setups. In addition, it also considers backward compatible embed-ding for a session sequence. This avoids the gallery embeddings of old and new sessions from being separated in incompatible feature spaces. Thus, our approach is more practical for real retrieval ap-plications. Semi-transparent icons represent the data points from the previous sessions collected so far.
As data grows, despite updating the model by simply
ﬁne-tuning, many observations [11, 69] reveal that catas-trophic forgetting happens. A series of strategies have been developed in CL to address the problem [11, 29, 43]. The methods can make a single deep model capable of updating itself successively while avoiding disappointing overall per-formance. However, there are still several ongoing issues.
First, many works in CL emphasize the disjoint setup where the data from the old class will not show during train-ing in a new task (or session). The task boundary arising over classes restricts the usage of CL since many retrieval systems need to collect extra data of the seen labels for im-proving their models in new sessions. Although recent stud-ies (e.g. [2, 4]) allow the class overlapping among the tasks, the blurry setup in these works assumes that all the class la-bels in the future sessions are pre-given in advance; only the instance ratios in the classes vary with the session (Fig. 1).
This kind of data scenario is impractical for most visual-search applications (e.g., in an e-commerce system, the new
product arrives over season). Moving toward a more gen-eral setup is desirable to fulﬁll real-world scenarios.
Second, a model updated from new data will deploy on-line in retrieval. An essential step is to re-extract the feature embedding from previous gallery images to maintain a con-sistent feature space on the pairwise distance measurement.
For visual search on large-scale data, feature re-extraction is computationally intensive. Thus, an ideal design for con-tinual visual search is that an updated model only extracts features for incoming gallery data while keeping the previ-ously generated feature representations unchanged. How-ever, it leads to the further difﬁculty of pairwise similarity measurement in uneven feature spaces. Motivated by this, we argue that current CL studies lack consideration for fea-ture compatibility between the ongoing and previous data.
Hence, designing a CL algorithm with backward consistent feature embedding is demanded.
To address the above issues, we introduce a novel
CL approach, namely, CVS (Continual-learner for Visual
Search), for a generally incremental setup of visual search.
CVS can learn effective feature representations with back-ward consistency. For learning new knowledge, our learner obtains discriminating features for the current task. We introduce a cross-task gallery embedding consistency con-straint that keeps the currently learned features compatible with the representatives from the obsolete gallery features.
For consolidating old knowledge while keeping feature con-sistency, we develop a metric-based knowledge distillation to draw together the embedding from the different feature spaces. By coordinating the components, CVS can achieve continual visual search with backward-compatible feature embedding effectively. Also, we conduct extensive exper-iments under various incremental data distributions, espe-cially for the general-incremental setup, to validate the ef-fectiveness of CVS. The main characteristics include:
General Incremental Setup: We introduce a new CL sce-nario to simulate real-world visual search application sys-tems. It includes the previous disjoint and blurry setups as special cases and tackles the general setting that the classes in a coming session can be either seen or unseen before.
Backward Consistent Feature Space Learning: Our learner can learn discriminative features for unseen classes.
It can also maintain the distance metric learned effective for the seen classes in both new and old sessions, where the old-session features can be kept unchanged without the need to be re-extracted every time in a visual search system.
Extensive experiments on multiple datasets under incre-mental data distributions show that our method achieves state-of-the-art results. Fig. 2 shows our system diagram. 2.