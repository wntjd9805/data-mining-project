Abstract
To represent people in mixed reality applications for col-laboration and communication, we need to generate realis-tic and faithful avatar poses. However, the signal streams that can be applied for this task from head-mounted devices (HMDs) are typically limited to head pose and hand pose estimates. While these signals are valuable, they are an incomplete representation of the human body, making it chal-lenging to generate a faithful full-body avatar. We address this challenge by developing a flow-based generative model of the 3D human body from sparse observations, wherein we learn not only a conditional distribution of 3D human pose, but also a probabilistic mapping from observations to the latent space from which we can generate a plausible pose along with uncertainty estimates for the joints. We show that our approach is not only a strong predictive model, but can also act as an efficient pose prior in different optimization settings where a good initial latent code plays a major role. 1.

Introduction
Mixed reality technology provides new ways to interact with people, with applications in remote collaboration, vir-tual gatherings, gaming and education. People are at the heart of all these applications, and so generating realistic human representations with high fidelity is key to the user experience. Whilst external sensors and cameras [33] are effective, using only head-mounted devices (HMDs) to gen-erate realistic and faithful human representations remains a challenging problem. The relevant data available from
HMDs such as Microsoft HoloLens and Oculus Quest is limited to the location and orientation of the head and the location and orientation of the hands, obtained either via egocentric hand tracking [11, 39] or the signal from motion controllers. This is a very incomplete signal for the pose and motion of the full human body.
Although prior work has proposed human pose priors for generating 3D human body poses from partial and
Figure 1. We generate a full body avatar given sparse HMD input (three SE3s for head and hands), by training a flow-based genera-tive model that provides an invertible mapping between the base distribution and 3D human pose distribution. At test time, given the HMD signal, we predict a region in the latent space that is used as the input to the flow-based model to generate a pose. ambiguous observations such as images [3, 19, 42], 2D joints/keypoints [4, 26], and markers [9, 22, 44, 45], such observations are richer sources of data than those available in practice from HMDs. Despite the importance of this prob-lem, there have been few attempts to generate full body pose from extremely sparse observations, i.e., head and hand posi-tion and orientation. Dittadi et al. [8] developed a variational autoencoder (VAE) to compress the head and hands inputs to a latent space, allowing a full-body pose to be generated by sampling from that latent space.
We propose a new approach based on conditional nor-malizing flows for sparse inputs. Specifically, we learn the conditional distribution of the full body pose given the head and hand data via a flow-based model which enables an invertible mapping between the 3D pose distribution and the base distribution. Invertibility of our model then allows us to go further by learning a probabilistic mapping from the condition to the high-likelihood region in the same base distribution, as illustrated in Fig. 1. We name our approach a flow-based avatar generative model (FLAG). The strengths of this design are: first, using a flow-based generative model enables exact pose likelihood computation in contrast to the approximate likelihoods seen in VAE-based pose pri-ors [8, 26]. Second, the invertibility of our generative model allows us to compute the oracle latent code. During training, the oracle latent code then acts as the ground truth for our mapping function. This allows us to learn a representative mapping from the observed head and hands to the latent
space, making our approach a strong predictive model. Fi-nally, when optimizing either in pose space or latent space, using our model as the pose prior provides a superior ini-tialization in the latent space, making optimization very efficient. 2.