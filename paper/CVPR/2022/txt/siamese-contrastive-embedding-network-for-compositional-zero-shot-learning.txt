Abstract
Compositional Zero-Shot Learning (CZSL) aims to rec-ognize unseen compositions formed from seen state and ob-ject during training. Since the same state may be various in the visual appearance while entangled with different ob-jects, CZSL is still a challenging task. Some methods recog-nize state and object with two trained classiﬁers, ignoring the impact of the interaction between object and state; the other methods try to learn the joint representation of the state-object compositions, leading to the domain gap be-tween seen and unseen composition sets. In this paper, we propose a novel Siamese Contrastive Embedding Network (SCEN)1 for unseen composition recognition. Considering the entanglement between state and object, we embed the visual feature into a Siamese Contrastive Space to capture prototypes of them separately, alleviating the interaction
In addition, we design a State between state and object.
Transition Module (STM) to increase the diversity of train-ing compositions, improving the robustness of the recogni-tion model. Extensive experiments indicate that our method signiﬁcantly outperforms the state-of-the-art approaches on three challenging benchmark datasets, including the recent proposed C-QGA dataset. 1.

Introduction
Humans possess the ability to compose their knowledge of known entities to generalize to novel concepts inherently.
Given words, such as green horse, people can combine the known state green with the known object horse immedi-ately, although they have never seen the inexistent stuff.
To equip an AI system the similar ability, Compositional
Zero-Shot Learning (CZSL) [20] is proposed, which aims to recognize unseen compositions composed of a set of seen states and objects. In CZSL setting, each composition com-prises two components, namely, state and object, where the compositions of train and test sets are disjoint.
*Corresponding author. 1Code: https://github.com/XDUxyLi/SCEN-master
Figure 1. The overall concept of our method. We aim to separately extract discriminative prototypes of state and object based on es-tablishing state and object speciﬁc databases, which can generalize to represent corresponding properties.
In order to infer unknown concepts such as green horse,
CZSL aims to understand the meaning of state green and object horse after trained on other compositional concepts that separately contain green or horse, e.g., green grasses and young horse. The challenge of the task lies in the in-teraction degree between state and object that we cannot quantify, which gives rise to varying contextuality within different state-object combinations. For instance, we can not equate the state old in old car and that in old tiger, since they are fundamentally distinct in visual presenta-tions, which greatly hinders the recognition of novel com-positions.
Existing mainstream methods [17, 20, 26] focus on con-verting such problem into a general supervised recognition task by training two classiﬁers for state and object, respec-tively. They aim to directly predict state and object from the original visual features, ignoring their entanglement. Based on this problem, classiﬁers cannot capture discriminative state and object features, which potentially limits the recog-nition accuracy. In addition, other methods [23, 24] aim to learn a common embedding space where the compositions as well as visual features can be projected to narrow the distance between them, such as Euclidean distance. How-ever, these methods, only regarding compositions as enti-ties, neglect the domain gap between training and testing compositions, which can be simply confused by similar im-ages from unseen compositions (e.g., young cat and young tiger). Therefore, it is vital to excavate the discriminative prototypes of state and object to separate the interaction be-tween them and consider the domain transfer between train-ing and testing samples.
To address the problem mentioned above, we propose a
Siamese Contrastive Embedding Network (SCEN) for rec-ognizing novel compositions in this paper, aiming to exca-vate discriminative prototypes of state and object, respec-tively, as shown in Fig. 1. To be speciﬁc, we ﬁrst project the visual features into state/object-based contrastive spaces to gain the prototypes of state and object. Then, to excavate the discriminative prototypes by contrastive constraints, we set up speciﬁc databases named State-constant and Object-constant databases as positive samples. Besides, a shared irrelevant database is built up as a negative sample set, which is embedded into two contrastive spaces. Beneﬁt-ing from this learning paradigm, our proposed model can successfully excavate discriminative prototypes to represent the corresponding component. In addition, considering that the distribution between seen and unseen compositions is discrepant, we present a State Transition Module (STM), which generates the virtual but reasonable samples to aug-ment the diversity of training data. In this way, the domain gap between seen and unseen composition sets can be miti-gated effectively.
To sum up, our main contributions are as follows:
• We propose a novel Siamese Contrastive Embedding
Network (SCEN) to excavate prototypes of state and object for successfully recognizing both seen and un-seen compositions.
• We present a State Transition Module (STM) to pro-duce virtual samples and augment the diversity of training compositions, guiding the model to general-ize to those compositions not existing in the training process, and alleviating the issue of model migration performance.
• Comprehensive experimental results on three bench-mark datasets demonstrate the effectiveness of our pro-posed approach, which outperforms the state-of-the-art
CZSL methods. 2.