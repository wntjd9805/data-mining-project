Abstract
Optimization of image transformation functions for the purpose of data augmentation has been intensively studied.
In particular, adversarial data augmentation strategies, which search augmentation maximizing task loss, show sig-nificant improvement in the model generalization for many tasks. However, the existing methods require careful param-eter tuning to avoid excessively strong deformations that take away image features critical for acquiring generaliza-tion.
In this paper, we propose a data augmentation op-timization method based on the adversarial strategy called
TeachAugment, which can produce informative transformed images to the model without requiring careful tuning by leveraging a teacher model. Specifically, the augmentation is searched so that augmented images are adversarial for the target model and recognizable for the teacher model.
We also propose data augmentation using neural networks, which simplifies the search space design and allows for up-dating of the data augmentation using the gradient method.
We show that TeachAugment outperforms existing methods in experiments of image classification, semantic segmenta-tion, and unsupervised representation learning tasks. 1.

Introduction
Data augmentation is an important technique used to im-prove model generalization. To automatically search effi-cient augmentation strategies for model generalization, Au-toAugment [9] has been proposed. Searched data augmen-tation policies lead to significant generalization improve-ments. However, AutoAugment requires thousands of GPU hours to search for efficient data augmentation.
Recent studies [17, 22, 30] have demonstrated methods leading to dramatic reductions in search costs with Au-toAugment, meaning that computational costs are no longer a problem.
In particular, online data augmentation opti-mization frameworks [18, 28, 49, 58] that alternately update
Code: https : / / github . com / DensoITLab /
TeachAugment
Figure 1. Concept of TeachAugment. Adversarial data augmen-tation, a baseline method, transforms data to increase loss for the target model fθ. The augmented data are often meaningless (e.g., black-out and noise images) or difficult to recognize without any constraints. TeachAugment, the proposed method, transforms data so that they are adversarial for the target model but they are rec-ognizable for the teacher model f ˆθ. As a result, the augmented images will be more informative than the adversarial data aug-mentation. augmentation policies and a target network have not only reduced the computational costs but also simplified the data augmentation search pipeline by unifying the search and training processes.
Many online optimization methods are based on an ad-versarial strategy that searches augmentation maximizing task loss for the target model, which is empirically known to improve model generalization [28, 37, 41, 48, 58]. How-ever, the adversarial data augmentation is unstable without any constraint because maximizing the loss can be achieved by collapsing the inherent meanings of images, as shown in
Fig. 1. To avoid the collapse, previous methods regularize augmentation based on prior knowledge and/or restrict the search range of the magnitude parameters of functions in the search space, but there are many tuned parameters that will annoy practitioners.
To alleviate the parameter tuning problem, we propose an online data augmentation optimization method using teacher knowledge, called TeachAugment. TeachAugment
is also based on the adversarial data augmentation strategy, but it searches augmentation in the range where the trans-formed image can be recognizable for a teacher model, as shown in Fig. 1. Unlike previous adversarial data augmen-tation methods [37, 48, 49, 58], thanks to the teacher model,
TeachAugment does not require priors and hyperparameters to avoid the excessively strong augmentation that collapses the inherent meanings of images. As a result, TeachAug-ment does not require parameter tuning to ensure that the transformed images are recognizable.
Moreover, we propose data augmentation using neural networks that represent two functions, geometric augmen-tation and color augmentation. Our augmentation model applies only two transformations to data but they can rep-resent most functions included in the search space of Au-toAugment and their composite functions. The use of the neural networks has two advantages compared to conven-tional augmentation functions: (i) we can update the aug-mentation parameters using the gradient method with back-propagation, and (ii) we can reduce the number of functions in the search space from tens of functions to two functions.
In particular, because of the latter advantage, practitioners only need to consider the range of the magnitude parame-ters for the two functions when they adjust the size of the search space for better convergence.
Contribution. Our contribution is summarized as fol-lows: (1) We propose an online data augmentation opti-mization framework based on the adversarial strategy us-ing teacher knowledge called TeachAugment. TeachAug-ment makes the adversarial augmentation more informative without careful parameter tuning by leveraging the teacher model to avoid collapsing the inherent meaning of im-ages. (2) We also propose data augmentation using neu-ral networks. The proposed augmentation simplifies the search space design and enables updating of its parameters by the gradient method in TeachAugment. (3) We show that TeachAugment outperforms previous methods, includ-ing online data augmentation [28, 58] and state-of-the-art augmentation strategies [10, 39] in classification, seman-tic segmentation, and unsupervised representation learning tasks without adjusting the hyperparameters and size of the search space for each task. 2.