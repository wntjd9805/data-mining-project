Abstract
In Heterogeneous Face Recognition (HFR), the objective is to match faces across two different domains such as vis-ible and thermal. Large domain discrepancy makes HFR a difﬁcult problem. Recent methods attempting to ﬁll the gap via synthesis have achieved promising results, but their performance is still limited by the scarcity of paired train-ing data. In practice, large-scale heterogeneous face data are often inaccessible due to the high cost of acquisition and annotation process as well as privacy regulations. In this paper, we propose a new face hallucination paradigm for HFR, which not only enables data-efﬁcient synthesis but also allows to scale up model training without breaking any privacy policy. Unlike existing methods that learn face syn-thesis entirely from scratch, our approach is particularly designed to take advantage of rich and diverse facial priors from visible domain for more faithful hallucination. On the other hand, large-scale training is enabled by introducing a new federated learning scheme to allow institution-wise col-laborations while avoiding explicit data sharing. Extensive experiments demonstrate the advantages of our approach in tackling HFR under current data limitations. In a uniﬁed framework, our method yields the state-of-the-art hallucina-tion results on multiple HFR datasets. 1.

Introduction
Deep convolutional neural networks have led to unprece-dented success on visual face recognition [5, 58, 61, 66], where state-of-the-art methods achieve more than 99% ac-curacy on multiple benchmarks. These near-perfect perfor-mances come from both well-elaborated architectures and exhaustive training on massive datasets. Nevertheless, in many real-world scenarios with low-visibility, such as low-light and night-time, it is often infeasible to obtain clear visible (VIS) images. Under these circumstances, sensors deployed for other imaging spectra, e.g. Thermal (TH), can capture more discriminative information and serve as a more reliable solution. This raises a great need of heterogeneous face recognition (HFR) [32, 33, 40], an important task in
*equal contribution computer vision and biometrics, that matches images from
TH modality to its VIS counterpart 1. The HFR problem has numerous applications in surveillance, monitoring and security.
Unfortunately, due to the large domain discrepancy, naively deploying a state-of-the-art face recognition algo-rithm trained on VIS images often leads to poor performance on a TH dataset [21]. Over the past decade, tremendous ef-forts have been spent to address the HFR problem by either learning domain-invariant features [10, 14, 15, 37] or ﬁnding a common subspace [28, 49, 59, 72]. Owing to the rapid progress in Generative Adversarial Networks (GANs) [16], most recent methods [7, 8, 12, 60, 73, 75] reformulate HFR as a face synthesis/translation problem. The resulting “recogni-tion via hallucination” scheme embraces a huge beneﬁt that any off-the-shelf recognizer can be directly applied on the synthesised images.
While these synthesis-based approaches ﬁll the gap to some extent, the produced VIS images are still unsatisfac-tory, often accompanied with distorted and incorrect facial structures (shown in Figure 4), which signiﬁcantly degrades the recognition accuracy. We found that the bottleneck is likely due to the limited size of the dataset which fails to offer sufﬁcient information to guide image synthesis. Unlike visible images that are easy to obtain and widely available over the Internet [20], collecting and annotating a large-scale high-quality TH dataset is difﬁcult. Challenges stem from many aspects. First, the acquisition process is both time-consuming and costly, which often requires laborious setup and non-trivial calibrations [52, 63]. Second, the diversity of collected data can be limited. Due to the physical constraints, it is typically infeasible for a single institution to collect a comprehensive dataset that covers a diverse set of identities with various attributes, such as race, gender and age. Most existing datasets [1, 9, 42, 47] are conﬁned to a small number of subjects, leading to biased results and over-ﬁtting. Third, face data is privacy sensitive. Since it contains subjects’ personal identiﬁcation information, one has to deal with pri-vacy concerns when collecting and storing them, making it 1Note that HFR is a general term that is used for matching two face images taken in two different domains such as TH, VIS or sketch. In this paper, we refer to HFR as a speciﬁc problem of matching TH images with
VIS images.
difﬁcult to share the data with other institutions.
Besides poor synthesis quality, most existing methods can only process images at a resolution no more than 128 × 128. This not only leads to visually unappealing results, but also reduces their applicability in many downstream tasks that depend on high-resolution inputs, such as face parsing [38, 39], editing [74] and reenactment [53].
In this paper, we present a uniﬁed hallucination frame-work for HFR, that is capable of synthesizing high-resolution visible faces (512 × 512) from low-resolution heterogeneous data (i.e. smaller than 128 × 128), with superior realness and higher ﬁdelity. Our approach consists of two separate strate-gies. The ﬁrst one comes with a new generation paradigm inspired by the recent success in GAN inversion [68]. The core idea is to leverage rich and diverse facial priors from the visible domain to eschew the need of learning generation from scratch. This is accomplished by embedding a pre-trained GAN (e.g. StyleGAN [25, 26]) as a facial decoder which hallucinates visible faces conditioned on the latent rep-resentations of a U-shaped encoder. The encoder is carefully designed with a novel Multi-scale Contexts Aggregation (MSCA) mechanism which merges scale-wise information to enhance representation. MSCA offers better ﬁne-grained generation control and is pivotal for preserving identity infor-mation. The proposed method, called Visual Prior enhanced
GAN (VPGAN), can break the underlying data limitation by producing faces with state-of-the-art accuracy and photo-realism.
Deep models are data hungry and VPGAN may be further improved with large-scale training. However, in practice,
HFR data tends to be separately collected and dispersed among different intuitions. Due to privacy concerns, one cannot simply share the data for centralized training. To this end, our second strategy introduces Federated Learning (FL) [29] to further improve HFR, which enables collabora-tive model training while avoiding explicit data exchanging.
Speciﬁcally, we allow each institution to perform local train-ing on their private HFR data and deploy a centralized server to periodically communicate with each institution, aggregat-ing local models and updating a global model. The whole process does not involve any data transfer but beneﬁts deep models a lot by integrating information from a signiﬁcantly broader range of data. To make our approach more suitable for real-world HFR, we have to tackle the heterogeneous data distributions across institutions. This challenge, which may be caused by differences in sensor types or acquisition protocols, can lead to locally skewed updates, resulting in slow convergence and sub-optimal performance [31, 35]. To tackle this issue, we build our FL algorithm based on a new
Model Proximity Regularization (MPR), which corrects lo-cal gradient updates by constraining the discrepancy between the latent representations from the global and local models.
As a result, our approach achieves superior robustness to-wards non-ideal data distribution, implying its applicability for solving real-world HFR problems.
In our uniﬁed framework, we integrate VPGAN as the basic component and use it in the proposed FL scheme. We term this new framework VPFL. In the experiment section, we demonstrate that our approach generates VIS faces at high-resolution with superior realness and accuracy.
Within the infrared spectrum, various modalities have been explored for thermal-to-visible (TH-VIS) face recog-nition. These include Near Infrared (NIR), Short-Wave In-frared (SWIR), Mid-Wave Infrared (MWIR) and Long-Wave
Infrared (LWIR). The use of a particular thermal modal-ity depends on the application. For instance, in long-range surveillance applications, SWIR or MWIR modalities are often used. Unlike NIR images, which are close to the VIS spectrum images, LWIR images are often acquired in low-resolution with many facial details missing on the captured imagery. This is well-reﬂected by the performance drop of the existing recognition methods on such datasets [23, 51].
Also, greater than 99% accuracy has been reported on many
NIR face datasets [8, 12]. However, the performance of vari-ous HFR methods on LWIR data is signiﬁcantly low [23, 51].
In summary, the main contributions of our paper are:
• We propose a new data-efﬁcient generation scheme for
HFR. Thanks to the powerful visual priors, it manages to alleviate fundamental data challenges, resulting in superior hallucination results.
• We introduce a uniﬁed framework to make large-scale training possible in real-world scenarios. VPFL makes multi-institutional collaborations possible without rais-ing any privacy concerns.
• Extensive experiments show that our method can pro-duce faces with state-of-the-art photo-realism and ﬁ-delity, which in turn signiﬁcantly boosts the recognition accuracy. These merits show its great potential to serve as a universal solution towards real-world applications. 2.