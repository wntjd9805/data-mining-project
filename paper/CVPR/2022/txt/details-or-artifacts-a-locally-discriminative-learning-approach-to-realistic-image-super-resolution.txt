Abstract
Single image super-resolution (SISR) with generative ad-versarial networks (GAN) has recently attracted increas-ing attention due to its potentials to generate rich details.
However, the training of GAN is unstable, and it often in-troduces many perceptually unpleasant artifacts along with the generated details. In this paper, we demonstrate that it is possible to train a GAN-based SISR model which can stably generate perceptually realistic details while inhibit-ing visual artifacts. Based on the observation that the local statistics (e.g., residual variance) of artifact areas are often different from the areas of perceptually friendly details, we develop a framework to discriminate between
GAN-generated artifacts and realistic details, and conse-quently generate an artifact map to regularize and stabi-lize the model training process. Our proposed locally dis-criminative learning (LDL) method is simple yet effective, which can be easily plugged in off-the-shelf SISR meth-ods and boost their performance. Experiments demonstrate that LDL outperforms the state-of-the-art GAN based SISR methods, achieving not only higher reconstruction accuracy but also superior perceptual quality on both synthetic and real-world datasets. Codes and models are available at https://github.com/csjliang/LDL. 1.

Introduction
Single image super-resolution (SISR) [6, 13, 14, 19, 20, 30–33, 38, 40, 42, 45, 47, 48], which aims to reconstruct a high-resolution (HR) image from its low-resolution (LR) observation, is one hot yet challenging research topic in low-level computer vision. It has become prevalent to train deep neural networks (DNNs) for SISR, while many DNN-based SISR models [2, 6, 27, 37, 48] are trained with pixel-wise ℓ1 and ℓ2 losses, and/or local window based metrics
It is well-known that though high (such as SSIM [41]).
*Equal contribution.
†This work is supported by the Hong Kong RGC RIF grant (R5001-18).
Figure 1. Three representative types of SISR regions generated by
ESRGAN [40]. For each example, the left is an LR patch and the right is its GAN-SR result. Type A patches represent regions that are easy to super-resolve, e.g., smooth and large-scale structural areas, where the main structures are preserved in the LR input. In contrast, patches of type B and type C are with fine-scale details, which are hard to be faithfully restored due to the signal alias-ing in the LR inputs. The results of texture-like type B patches are perceptually realistic despite the pixel-wise differences to the ground-truth, since the patterns are naturally irregular with weak priors for observers. However, the results of type C patches exhibit perceptually unpleasant visual artifacts since the overshoot pixels and distorted structures are sensitive to human perception.
PSNR and SSIM indices might be induced by these losses, they can hardly produce rich image details [4, 20].
With the rapid development of generative adversarial networks (GAN) [9, 15], GAN-based SISR (GAN-SR for short) has recently attracted significant attention for its po-tentials to recover sharp images with rich details [20,30,32, 40, 44]. Though great progresses have been achieved, ad-versarial training is unstable and often introduces unpleas-ant visual artifacts [20, 44]. As users are mostly expecting
rich and realistic details in SISR results [5, 12, 28], how to inhibit the visual artifacts of GAN-SR without affecting the realistic details becomes a key issue. Unfortunately, details and artifacts are often entangled in high-frequency compo-nents of images. As a result, optimizing one of them often harms the other under existing frameworks [4, 20, 25, 40].
In order to address the above mentioned challenges, we investigate in-depth the GAN-SR methods and categorize their results into three typical types of regions, as illustrated in Figure 1. Specifically, type A patches (e.g., flat sky, long edges) are easy to reconstruct since they are smooth or con-tain only large-scale structures. In contrast, it is difficult to produce high-fidelity SISR results for patches of type B and type C because they have much fine-scale details and suf-fer from signal aliasing in the degradation process, where most high-frequency components are lost. Fortunately, for texture-like type B patches (e.g., animal fur, tree leaves in distance), the pixels are randomly distributed so that the dif-ferences between SR results and ground truth are insensitive to human perception. Therefore, rich details generated by
GAN-SR methods can lead to better perceptual quality in these regions. However, patches of type C (e.g., thin twigs, dense windows in the building) contain many fine-scale reg-ular structures or sharp transitions among adjacent pixels.
The distorted structures and overshoot pixels generated by
GAN-SR methods can be easily perceived by observers as unpleasant artifacts.
Based on the above analysis, we can see that to get per-ceptually realistic SISR results, the visual artifacts in type C regions should be inhibited, while the realistic details gen-erated in type A and type B regions should be preserved. To achieve this goal, we analyze the local statistic of the three types of GAN-SR regions, and find that the local variance of residuals between SISR results and ground truth HR images can serve as an effective feature to distinguish unpleasant artifacts from realistic details. Accordingly, we construct a pixel-wise map indicating the probability of each pixel being artifacts based on the local and patch-level residual variances. We further refine the discrimination map via a model ensemble strategy to encourage stable and accurate optimization direction toward high-fidelity reconstruction.
Based on the refined map, we design a Locally Discrimi-native Learning (LDL) framework to penalize the artifacts without affecting realistic details.
To sum up, in this paper we first analyze the GAN-SR results and the instability of model training. We then pro-pose to explicitly discriminate visual artifacts from realistic details, and design an LDL framework to regularize the ad-versarial training. Our method is simple yet effective, and it can be easily plugged into off-the-shelf GAN-SR methods.
It provides a novel way to suppress the artifacts in GAN-SR while generating rich realistic details. We conduct extensive experiments on synthetic and real-world SISR tasks, and
LDL demonstrates clear improvements against the state-of-the-arts both quantitatively and qualitatively. 2.