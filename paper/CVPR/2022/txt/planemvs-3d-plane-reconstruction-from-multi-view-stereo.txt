Abstract
We present a novel framework named PlaneMVS for 3D plane reconstruction from multiple input views with known camera poses. Most previous learning-based plane recon-struction methods reconstruct 3D planes from single im-ages, which highly rely on single-view regression and suffer from depth scale ambiguity. In contrast, we reconstruct 3D planes with a multi-view-stereo (MVS) pipeline that takes advantage of multi-view geometry. We decouple plane re-construction into a semantic plane detection branch and a plane MVS branch. The semantic plane detection branch is based on a single-view plane detection framework but with differences. The plane MVS branch adopts a set of slanted plane hypotheses to replace conventional depth hypothe-ses to perform plane sweeping strategy and finally learns pixel-level plane parameters and its planar depth map. We present how the two branches are learned in a balanced way, and propose a soft-pooling loss to associate the out-puts of the two branches and make them benefit from each other. Extensive experiments on various indoor datasets show that PlaneMVS significantly outperforms state-of-the-art (SOTA) single-view plane reconstruction methods on both plane detection and 3D geometry metrics. Our method even outperforms a set of SOTA learning-based MVS meth-ods thanks to the learned plane priors. To the best of our knowledge, this is the first work on 3D plane reconstruction within an end-to-end MVS framework. 1.

Introduction 3D planar structure reconstruction from RGB images has been an important yet challenging problem in computer vi-sion for decades.
It aims to detect piece-wise planar re-gions and predict the corresponding 3D plane parameters from RGB images. The recovered 3D planes can be used in various applications such as robotics [46], Augmented
Reality (AR) [4], and indoor scene understanding [51].
Traditional methods [9, 13, 43] work well in certain cases but usually highly rely on some assumptions (e.g.,
*Work primarily done while interning at OPPO US Research Center
â€ Corresponding author (peterji530@gmail.com)
Figure 1. Comparison among: (a) single-view plane reconstruc-tion framework, (b) conventional depth-based MVS framework, (c) the proposed multi-view plane reconstruction framework. Our system employs slanted plane hypotheses for plane-sweeping to build the plane MVS branch, which interacts with the plane detec-tion branch. The two branches can benefit from each other.
Manhattan-world assumption [9]) of the target scene and are thus not always robust in complicated real-world cases.
Recently, some methods [31, 32, 47, 56, 61] have been pro-posed to recover planes from single-view images based on
Convolutional Neural Networks (CNNs). These methods could reconstruct 3D planes better in terms of completeness and robustness compared with traditional methods. How-ever, all of them, albeit achieving reasonable results on 2D plane segmentation, attempt to recover 3D plane geometry from a single image, which is an ill-posed problem as it only relies on single-view regression for plane parameters and has ambiguity in depth scale recovery. Thus the recovered 3D planes from those methods are far from being accurate.
The limitations of these methods motivate us to consider the possibility of reconstructing 3D planes from multiple views
with CNNs in an end-to-end framework.
In contrast to reconstructing 3D geometry from single images, multi-view-stereo (MVS) [10] takes multiple im-ages as input with known relative camera poses. MVS methods achieve superior performance on 3D reconstruc-tion compared with single-view methods since the scale of a scene can be resolved by triangulating matched fea-ture points on calibrated images [17]. Recently, a few learning-based MVS methods [16, 19, 57, 58] have been proposed and have achieved promising improvements for a wide range of scenes. While effective in reconstruct-ing areas with rich textures, their pipelines would suffer from ambiguity in finding feature matches in the texture-less area, which often belongs to planar regions. Besides, the generated depth map usually lacks smoothness as planar structures are not explicitly parsed. Some recent MVS ap-proaches [26, 34, 63] propose to jointly learn the geometric relationship between depth and normal to capture local pla-narity. However, these methods usually estimate depth and normal separately, and only learn pixel-level planarity by enforcing the constraints by additional losses. Piece-wise planar structures, e.g., walls and floors, which usually indi-cate strong global geometric smoothness, are not well cap-tured in these approaches.
In this work, as shown in Fig. 1, we take advantage of both sets of methods and propose to reconstruct planar structures in an MVS framework. Our framework consists of dual branches: a plane detection branch and a plane MVS branch. The plane detection branch predicts a set of 2D plane masks with their corresponding semantic labels of the target image. The plane MVS branch, which is our key contribution, takes posed target and source images as input.
Inspired by the frontal plane sweeping formulation that is widely used in MVS pipelines, we propose a slanted plane sweeping strategy to learn the plane parameters without am-biguity. Specifically, instead of using a set of frontal plane hypotheses (i.e., depth hypotheses) for plane sweeping as in conventional MVS methods, we perform plane sweeping with a group of slanted plane hypotheses to build a plane cost volume for per-pixel plane parameter regression.
To associate the two branches, we present a soft-pooling strategy to get piece-wise plane parameters and propose a loss objective based on it to make the two branches benefit from each other. We apply learned uncertainties [25] on different loss terms to train the multi-task learning system in a balanced way. Moreover, our system can generalize well in new environments with different data distributions. The results can be further improved with a simple but effective finetuning strategy without groundtruth plane annotations.
To the best of our knowledge, this is the first work that reconstructs planar structures in an end-to-end MVS frame-work. The reconstructed depth map takes advantage of multi-view geometry to resolve the scale ambiguity issue.
It is much smoother geometrically compared with depth-based MVS schemes by parsing planar structures. Experi-mental results across different indoor datasets demonstrate that our proposed PlaneMVS not only significantly outper-forms single-view plane reconstruction methods, but is also better than several SOTA learning-based MVS approaches. 2.