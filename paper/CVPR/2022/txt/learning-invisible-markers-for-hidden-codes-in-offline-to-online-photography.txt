Abstract
QR (quick response) codes are widely used as an ofﬂine-to-online channel to convey information (e.g., links) from publicity materials (e.g., display and print) to mobile de-vices. However, QR codes are not favorable for taking up valuable space of publicity materials. Recent works pro-pose invisible codes/hyperlinks that can convey hidden in-formation from ofﬂine to online. However, they require markers to locate invisible codes, which fails the purpose of invisible codes to be visible because of the markers.
This paper proposes a novel invisible information hiding ar-chitecture for display/print-camera scenarios, consisting of hiding, locating, correcting, and recovery, where invisible markers are learned to make hidden codes truly invisible.
We hide information in a sub-image rather than the entire image and include a localization module in the end-to-end framework. To achieve both high visual quality and high re-covering robustness, an effective multi-stage training strat-egy is proposed. The experimental results show that the pro-posed method outperforms the state-of-the-art information
In hiding methods in both visual quality and robustness. addition, the automatic localization of hidden codes signif-icantly reduces the time of manually correcting geometric distortions for photos, which is a revolutionary innovation for information hiding in mobile applications. 1.

Introduction
Scanning QR codes with smartphones provides conve-nience for people to obtain information from ofﬂine to on-line anytime and anywhere. However, with the increasing demand for the quality of experience (QoE), the unaesthetic appearance limits the application of QR codes in many sce-narios, such as interactive visual media, and IP protection of user-generated (UGG). To achieve ofﬂine-to-online ex-periences while maintaining good QoE, invisible informa-tion hiding becomes a novel alternative [11, 20]. The core
*Equal contribution
†Corresponding author requirement of information hiding in display/print-camera scenarios is to make the information invisible to human eyes but detectable by mobile devices.
The general process of invisible information hiding in display/print-camera scenarios includes ﬁve steps as Fig-ure 1: (i) encoding information in images, (ii) display-ing/printing, (iii) capturing, (iv) locating the encoded infor-mation and correcting geometric distortion, and (v) decod-ing. The main challenge of the above process is that the de-coding procedure needs to recover the hidden information from photos that contains distortions caused by the cam-era imaging process. These distortions can be divided into three categories according to their sources: (i) from envi-ronments, e.g., brightness, contrast, and color distortions), (ii) from camera sides, e.g., defocus blur, noise, and com-pression, (iii) from photographer sides, e.g., motion blur and geometric distortion. We deﬁne the image containing hidden information as the encoded image. Existing meth-ods [7, 8, 11, 20, 25] can recover hidden information under the above-mentioned distortions. However, these methods assume that the coordinates of the encoded image’s four vertices in photos are provided such that the geometric dis-tortion can be corrected by performing perspective trans-formation. Thus, these methods require preprocessing to locate the encoded image’s four vertices and rectify the en-coded image from photos taken from different perspectives, which is essential for the success of decoding [8].
Existing preprocessing methods commonly used to re-move geometric distortions include two categories: manual locating [8, 25] and automatic locating [7, 11, 20]. Manual locating is to ﬁnd the four vertices of the encoded image manually, as Figure 1. However, manually locating the ver-tex coordinates is time-consuming and sometimes is difﬁ-cult when hidden codes are invisible. Traditional automatic locating requires additional markers such that encoded im-ages with distortions are distinguishable from backgrounds.
These methods add visible markers, such as bounding boxes
[11] and barcodes [7], around the encoded image. How-ever, the markers break the invisibility of invisible codes. In addition to the traditional automatic methods, Tancik et al.
Sub-Image
Cover Image
Hidden Code (ii) Displaying
Efficient  (cid:312) 
Author: 
Xxx.Xx
Date:  xxxx-xx-xx
Link: www.xx.com (v) Decoding ii) (iii) Capturing, (iv) Automatic 
Locating and Correcting (i ) i i
Datamatrix
Hidden Region (x1,y1) (x2,y2) (i) Encoding (x3,y3)
Existing Methods: Hiding in Entire Images, Manual Locating and Correcting  (x4,y4)
Corrected Image
Time-Consuming
❌
Figure 1. Comparison of the proposed method with the previous methods [7,8,11,20,25]. Compared to the previous methods, the proposed method can automatically locate the accurate position containing the hidden information, which is efﬁcient in mobile applications.
[20] propose StegaStamp, which is an end-to-end trainable framework. The encoder and the decoder of [20] consist of convolution neural network (CNN). During training, Ste-gaStamp uses a series of differentiable distortion operations to process the encoded image and feed the distorted image to its decoder. Thus, the decoder can learn to locate and recover information under different distortions. However, experimental results show that the CNN-based decoder is vulnerable to geometric distortions, thus additional mark-ers (white borders) are still required to locate the encoded image in [20].
This paper proposes a novel invisible information hid-ing model in display/print-camera scenarios, which can automatically locate the hidden information (data matrix) by learning invisible markers. Inspired by the success of
[11, 20], the proposed model is a CNN-based end-to-end framework consisting of an encoder, a distortion network, a localization network, and a decoder. Unlike [7,8,11,20,25], the encoder hides information (data matrix) in a sub-image rather than the entire cover image such that the image area outside the sub-image is considered as backgrounds in pho-tos. The role of the distortion network is similar to [20] and the decoder recovers information from the distorted sub-image. We add a localization network between the distor-tion network and the decoder for the ﬁrst time. Different from manual locating or adding artiﬁcial markers, the joint training of the encoder and the localization network makes the encoder learn to generate invisible markers around the sub-image while the localization network learns to detect these invisible markers under various distortions, especially geometric distortions. In other words, the optimization goal is to make the markers of the hidden codes invisible to the human eyes, but can be detected by the localization net-work. Given the detected coordinates of the sub-image, we can remove geometric distortion such that the decoder only needs to recover information from the corrected sub-image.
The main contributions of this paper are summarized below:
• We propose a novel invisible information hiding archi-tecture in display/print-camera scenarios, consisting of information hiding, locating, correcting, and informa-tion recovery.
• For the ﬁrst time, we learn invisible markers and de-velop a localization module in the end-to-end frame-work for hidden codes. The joint training of the en-coder and the localization network generates markers that are invisible to human eyes but detectable by the localization network, which considerably reduces the time of correcting geometric distortions without break-ing the visual invisibility.
• To achieve a good trade-off between the detectabil-ity of invisible markers, recovery accuracy of hidden codes, and visual invisibility, we propose an effective multi-stage training strategy. A series of loss functions are designed to make the sub-images containing hid-den information comfortable to human eyes. 2.