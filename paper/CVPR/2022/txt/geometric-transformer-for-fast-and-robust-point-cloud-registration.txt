Abstract
We study the problem of extracting accurate correspon-dences for point cloud registration. Recent keypoint-free methods bypass the detection of repeatable keypoints which is difﬁcult in low-overlap scenarios, showing great poten-tial in registration. They seek correspondences over down-sampled superpoints, which are then propagated to dense points. Superpoints are matched based on whether their neighboring patches overlap. Such sparse and loose match-ing requires contextual features capturing the geometric structure of the point clouds. We propose Geometric Trans-former to learn geometric feature for robust superpoint matching. It encodes pair-wise distances and triplet-wise angles, making it robust in low-overlap cases and invari-ant to rigid transformation. The simplistic design attains surprisingly high matching accuracy such that no RANSAC is required in the estimation of alignment transformation, leading to 100 times acceleration. Our method improves the inlier ratio by 17∼30 percentage points and the registra-tion recall by over 7 points on the challenging 3DLoMatch benchmark. Our code and models are available at https:
//github.com/qinzheng93/GeoTransformer. 1.

Introduction
Point cloud registration is a fundamental task in graph-ics, vision and robotics. Given two partially overlapping 3D point clouds, the goal is to estimate a rigid transformation that aligns them. The problem has gained renewed interest recently thanks to the fast growing of 3D point representa-tion learning and differentiable optimization.
The recent advances have been dominated by learning-based, correspondence-based methods [4, 7, 9, 14, 15, 36]. A neural network is trained to extract point correspondences between two input point clouds, based on which an align-ment transformation is calculated with a robust estimator, e.g., RANSAC. Most correspondence-based methods rely on keypoint detection [1,4,7,15]. However, it is challenging to detect repeatable keypoints across two point clouds, espe-cially when they have small overlapping area. This usually
*Corresponding author: kevin.kai.xu@gmail.com.
Figure 1. Given two low-overlap point clouds, GeoTransformer improves inlier ratio over vanilla transformer signiﬁcantly, both for superpoint (patch) level (left) and for dense point level (right).
A few representative patch correspondences are visualized with distinct colors. Notice how GeoTransformer preserves the spatial consistency of the matching patches across two point clouds. It corrects the wrongly matched patches around the symmetric cor-ners of the chair back (see the yellow point cloud). results in low inlier ratio in the putative correspondences.
Inspired by the recent advances in image matching [22, 25, 39], keypoint-free methods [36] downsample the input point clouds into superpoints and then match them through examining whether their local neighborhood (patch) over-laps. Such superpoint (patch) matching is then propagated to individual points, yielding dense point correspondences.
Consequently, the accuracy of dense point correspondences highly depends on that of superpoint matches.
Superpoint matching is sparse and loose. The upside is that it reduces strict point matching into loose patch over-lapping, thus relaxing the repeatability requirement. Mean-while, patch overlapping is a more reliable and informa-tive constraint than distance-based point matching for learn-ing correspondence; consider that two spatially close points could be geodesically distant. On the other hand, superpoint matching calls for features capturing more global context.
To this end, Transformer [28] has been adopted [31, 36] to encode contextual information in point cloud registra-tion. However, vanilla transformer overlooks the geometric structure of the point clouds, which makes the learned fea-tures geometrically less discriminative and induces numer-ous outlier matches (Fig. 1(top)). Although one can inject positional embeddings [33,38], the coordinate-based encod-ing is transformation-variant, which is problematic when registering point clouds given in arbitrary poses. We ad-vocate that a point transformer for registration task should be learned with the geometric structure of the point clouds so as to extract transformation-invariant geometric features.
We propose Geometric Transformer, or GeoTransformer for short, for 3D point clouds which encodes only distances of point pairs and angles in point triplets.
Given a superpoint, we learn a non-local representation through geometrically “pinpointing” it w.r.t. all other su-perpoints based on pair-wise distances and triplet-wise an-gles. Self-attention mechanism is utilized to weigh the im-portance of those anchoring superpoints. Since distances and angles are invariant to rigid transformation, GeoTrans-former learns geometric structure of point clouds efﬁciently, leading to highly robust superpoint matching even in low-overlap scenarios. Fig. 1(left) demonstrates that GeoTrans-former signiﬁcantly improves the inlier ratio of superpoint (patch) correspondences. For better convergence, we devise an overlap-aware circle loss to make GeoTransformer focus on superpoint pairs with higher patch overlap.
Beneﬁtting from the high-quality superpoint matches, our method attains high-inlier-ratio dense point correspon-dences (Fig. 1(right)) using an optimal transport layer [23], as well as highly robust and accurate registration without relying on RANSAC. Therefore, the registration part of our method runs extremely fast, e.g., 0.01s for two point clouds with 5K correspondences, 100 times faster than RANSAC.
Extensive experiments on both indoor and outdoor bench-marks [13,37] demonstrate the efﬁcacy of GeoTransformer.
Our method improves the inlier ratio by 17∼30 percentage points and the registration recall by over 7 points on the 3DLoMatch benchmark [15]. Our main contributions are:
• A fast and accurate point cloud registration method which is both keypoint-free and RANSAC-free.
• A geometric transformer which learns transformation-invariant geometric representation of point clouds for robust superpoint matching.
• An overlap-aware circle loss which reweights the loss of each superpoint match according to the patch over-lap ratio for better convergence. 2.