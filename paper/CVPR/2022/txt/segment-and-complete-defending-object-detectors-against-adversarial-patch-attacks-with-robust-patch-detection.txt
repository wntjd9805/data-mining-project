Abstract
Object detection plays a key role in many security-critical systems. Adversarial patch attacks, which are easy to im-plement in the physical world, pose a serious threat to state-of-the-art object detectors. Developing reliable de-fenses for object detectors against patch attacks is critical but severely understudied. In this paper, we propose Seg-ment and Complete defense (SAC), a general framework for defending object detectors against patch attacks through detection and removal of adversarial patches. We first train a patch segmenter that outputs patch masks which provide pixel-level localization of adversarial patches. We then pro-pose a self adversarial training algorithm to robustify the patch segmenter. In addition, we design a robust shape com-pletion algorithm, which is guaranteed to remove the entire patch from the images if the outputs of the patch segmenter are within a certain Hamming distance of the ground-truth patch masks. Our experiments on COCO and xView datasets demonstrate that SAC achieves superior robustness even under strong adaptive attacks with no reduction in perfor-mance on clean images, and generalizes well to unseen patch shapes, attack budgets, and unseen attack methods.
Furthermore, we present the APRICOT-Mask dataset, which augments the APRICOT dataset with pixel-level annotations of adversarial patches. We show SAC can significantly re-duce the targeted attack success rate of physical patch at-tacks. Our code is available at https://github.com/ joellliu/SegmentAndComplete. 1.

Introduction
Object detection is an important computer vision task that plays a key role in many security-critical systems including autonomous driving, security surveillance, identity verifi-cation, and robot manufacturing [42]. Adversarial patch attacks, where the attacker distorts pixels within a region of bounded size, pose a serious threat to real-world object detection systems since they are easy to implement physi-Figure 1. We adopt a “detect and remove” strategy for defend-ing object detectors against patch attacks. Left: Predictions on a clean image; middle: predictions on an adversarial image; right: predictions on SAC masked image. cally. For example, physical adversarial patches can make a stop sign [40] or a person [41] disappear from object de-tectors, which could cause serious consequences in security-critical settings such as autonomous driving. Despite the abundance [9, 22, 23, 25, 29, 39–41, 43, 45, 51] of adversar-ial patch attacks on object detectors, defenses against such attacks have not been extensively studied. Most existing defenses for patch attacks are restricted to image classifica-tion [16, 17, 24, 32, 34, 44, 46, 49]. Securing object detectors is more challenging due to the complexity of the task.
In this paper, we present Segment and Complete (SAC) defense that can robustify any object detector against patch attacks without re-training the object detectors. We adopt a “detect and remove” strategy (Fig. 1): we detect adver-sarial patches and remove the area from input images, and then feed the masked images into the object detector. This is based on the following observation: while adversarial patches are localized, they can affect predictions not only locally but also on objects that are farther away in the image because object detection algorithms utilize spatial context for reasoning [38]. This effect is especially significant for deep learning models, as a small localized adversarial patch
can significantly disturb feature maps on a large scale due to large receptive fields of neurons. By removing them from the images, we minimize the adverse effects of adversarial patches both locally and globally.
The key of SAC is to robustly detect adversarial patches.
We first train a patch segmenter to segment adversarial patches from the inputs and produce an initial patch mask.
We propose a self adversarial training algorithm to enhance the robustness of the patch segmenter, which is efficient and object-detector agnostic. Since the attackers can potentially attack the segmenter and disturb its outputs under adaptive attacks, we further propose a robust shape completion al-gorithm that exploits the patch shape prior to ensure robust detection of adversarial patches. Shape completion takes the initial patch mask and generates a “completed patch mask” that is guaranteed to cover the entire adversarial patch, given that the initial patch mask is within a certain Hamming dis-tance from the ground-truth patch mask. The overall pipeline of SAC is shown in Fig. 2. SAC achieves 45.0% mAP under 100 × 100 patch attacks, providing 30.6% mAP gain upon the undefended model while maintaining the same 49.0% clean mAP on the COCO dataset.
Besides digital domains, patch attacks have become a se-rious threat for object detectors in the physical world [9, 23, 39–41, 43, 45]. Developing and evaluating defenses against physical patch attacks require physical-patch datasets which are costly to create. To the best of our knowledge, APRI-COT [6] is the only publicly available dataset of physical adversarial attacks on object detectors. However, APRICOT only provides bounding box annotations for each patch with-out pixel-level annotations. This hinders the development and evaluation of patch detection and removal techniques like SAC. To facilitate research in this direction, we create the APRICOT-Mask dataset, which provides segmentation masks and more accurate bounding boxes for adversarial patches in APRICOT. We train our patch segmenter with segmentation masks from APRICOT-Mask and show that
SAC can effectively reduce the patch attack success rate from 7.97% to 2.17%.
In summary, our contributions are as follows:
• We propose Segment and Complete, a general method for defending object detectors against patch attacks via patch segmentation and a robust shape completion algorithm.
• We evaluate SAC on both digital and physical attacks.
SAC achieves superior robustness under both non-adaptive and adaptive attacks with no reduction in per-formance on clean images, and generalizes well to un-seen shapes, attack budgets, and unseen attack methods.
• We present the APRICOT-Mask dataset, which is the first publicly available dataset that provides pixel-level annotations of physical adversarial patches. 2.