Abstract
Weakly supervised learning can help local feature meth-ods to overcome the obstacle of acquiring a large-scale dataset with densely labeled correspondences. However, since weak supervision cannot distinguish the losses caused by the detection and description steps, directly conducting weakly supervised learning within a joint training describe-then-detect pipeline suffers limited performance. In this pa-per, we propose a decoupled training describe-then-detect pipeline tailored for weakly supervised local feature learn-ing. Within our pipeline, the detection step is decoupled from the description step and postponed until discriminative and robust descriptors are learned. In addition, we intro-duce a line-to-window search strategy to explicitly use the camera pose information for better descriptor learning. Ex-tensive experiments show that our method, namely PoSFeat (Camera Pose Supervised Feature), outperforms previous fully and weakly supervised methods and achieves state-of-the-art performance on a wide range of downstream task. 1.

Introduction
Finding pixel correspondences is a fundamental problem in computer vision. Sparse local feature [5,12,22,36,48], as one of the mainstream methods to find correspondences, has been widely applied in many areas, such as simultaneous localization and mapping (SLAM) [29, 52], structure from motion (SfM) [1, 40], and visual localization [7, 16, 38, 51].
Traditional sparse local feature methods [5, 22, 36] fol-low a detect-then-describe pipeline. Specifically, keypoints are first detected and then patches centered at these key-points are used to generate descriptors. Early methods
[15, 17, 19, 22] focus on the detection step and are pro-posed to distinguish distinctive areas to detect good key-points. Later works pay more attention to the description step and make attempts to design powerful descriptors us-ing advanced representations [5, 8, 36].
*Corresponding author: Yulan Guo (guoyulan@sysu.edu.cn).
Codes: https://github.com/The-Learning-And-Vision-Atelier-LAVA/PoSFeat. (a) DISK-W, a DISK model [46] trained with weak supervision (b) PoSFeat (ours)
Figure 1. An illustration of the influence of ambiguity for weakly supervised local feature methods. Keypoints that succeed and fail to create landmarks are shown. (a) With joint training describe-then-detect pipeline, DISK-W [46] produces inaccurate keypoints (b) With our decoupled training that are out of the objects. describe-then-detect pipeline, PoSFeat can produce more reason-able keypoints. Best viewed in color.
Motivated by the success of deep learning, many efforts
[23, 27, 31, 44, 50] have been made to replace the detection or description step in the detect-then-describe pipeline with
CNNs. Recent works [13,24,34,46] find that keypoints and descriptors are interdependent and propose a joint training describe-then-detect pipeline. Specifically, the description network and detection network are combined into a single
CNN and optimized jointly. The joint training describe-then-detect pipeline achieves better performance than the detect-then-describe pipeline, especially under challenging conditions [18,45]. However, these methods are fully super-vised and rely on dense ground-truth correspondence labels for training.
Because collecting a large dataset with pixel-level ground-truth correspondences is expensive, self-supervised and weakly supervised learning are investigated for train-ing. Specifically, DeTone et al. [12] used a single im-age and a virtual homography to generate image pairs to conduct self-supervised learning. However, homography transformation cannot cover complicated geometry trans-formations in real-world settings, resulting in limited per-formance. Noh et al. [30] used landmark labels to train the local feature network, which suffers extremely poor perfor-mance on viewpoint changes. Owing to the convenience of collecting camera poses, Wang et al. [47] introduced cam-era poses as weak supervision for descriptor learning. Al-though weakly supervised learning achieves promising re-sults within the detect-then-describe pipeline, directly ap-plying it to the joint training describe-then-detect pipeline is hard to produce satisfying results [46].
When a detection network and a description network are jointly optimized within a joint training describe-then-detect pipeline with only weak supervision (e.g., camera pose), the loss produced by these two components cannot be distinguished. Specifically, when only one component is failed (Fig. 2), both the detection network and the de-scription network cannot be correctly updated within a joint training describe-then-detect pipeline. As a result, the de-scription network is hard to produce highly discriminative descriptors, and the detection network may produce false detected keypoints that are out of object boundaries, as shown in Fig. 1.
In this paper, we propose a decoupled training describe-then-detect pipeline tailored for weakly supervised local feature learning. Our main insight is that, with only weak supervision, the detection network relies heavily on a good descriptor for accurate keypoint detection (Fig. 1). Conse-quently, we decouple the detection network from the de-scription network to postpone it until a discriminative and robust descriptor is learned. Different from the detect-then-describe pipeline that relies on low-level structures for early detection, our keypoints detection depends on the higher-level structures encoded in the descriptors. As a result, bet-ter robustness is achieved. In contrast to the joint training describe-then-detect pipeline that simultaneously perform detection and description optimization, the two networks are trained separately and thus the loss function for these two components are decoupled to address the ambiguity. It is demonstrated that our decoupled training describe-then-detect pipeline facilitates local feature methods to achieve much better performance with only weak supervision. Our contributions can be summarized as: (1) We introduce a decoupled training describe-then-detect pipeline for weakly supervised local feature learning.
This simple yet efficient pipeline significantly improves the performance of weakly supervised local features. (2) We propose a line-to-window search strategy to ex-ploit the weak supervision of camera poses for descriptor learning. This strategy can make full use of the geometric information of camera poses to reduce the search space and
Figure 2. Motivation of decoupling. Two reasonable keypoints can be matched incorrectly due to the low discriminativeness of descriptors (e.g., caused by repetitive textures). Meanwhile, two false detected keypoints can also be matched with a high descriptor similarity. Best viewed in color. learn highly discriminative descriptors. (3) Our method achieves state-of-the-art performance on three datasets and largely closes the gap between fully and weakly supervised methods. 2.