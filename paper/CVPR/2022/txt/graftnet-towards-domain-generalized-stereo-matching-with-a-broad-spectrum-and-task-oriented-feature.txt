Abstract
Although supervised deep stereo matching networks have made impressive achievements, the poor generaliza-tion ability caused by the domain gap prevents them from being applied to real-life scenarios. In this paper, we pro-pose to leverage the feature of a model trained on large-scale datasets to deal with the domain shift since it has seen various styles of images. With the cosine similarity based cost volume as a bridge, the feature will be grafted to an ordinary cost aggregation module. Despite the broad-spectrum representation, such a low-level feature contains much general information which is not aimed at stereo matching. To recover more task-speciﬁc information, the grafted feature is further input into a shallow network to be transformed before calculating the cost. Extensive ex-periments show that the model generalization ability can be improved signiﬁcantly with this broad-spectrum and task-oriented feature. Speciﬁcally, based on two well-known ar-chitectures PSMNet and GANet, our methods are superior to other robust algorithms when transferring from Scene-Flow to KITTI 2015, KITTI 2012, and Middlebury. Code is available at https://github.com/SpadeLiu/Graft-PSMNet. 1.

Introduction
As a low-cost means to acquire depth, stereo matching has been studied as a fundamental problem in the vision so-ciety for decades. Given a rectiﬁed image pair, the objective is to search for the corresponding points and calculate their disparities. Stereo matching algorithms generally involve four steps [27]: matching cost computation, cost aggrega-tion, disparity optimization, and disparity reﬁnement.
Although Convolutional Neural Network (CNN) based supervised stereo matching methods have achieved ad-mirable performances, huge amounts of annotated data are required to train the models, which is cumbersome for real-Figure 1. The toy experiment to validate the grafting operation.
Two models with the cost volume formed by feature concatena-tion (Subﬁgure c) and cosine similarity (Subﬁgure e) are trained on SceneFlow, then their feature extraction modules are replaced with a Broad-Spectrum feature (Subﬁgure d and f). For the four models, the 3-pixel error rates on a KITTI sample are labeled. life applications. Synthetic data [20] is sufﬁcient while the domain gap between the source and the target images pre-vents the models from generalizing well. There are three solutions to this issue: the unsupervised image reconstruc-tion loss [34, 35], domain adaptation techniques [18, 31], and domain generalized approaches [2, 45]. In this paper, we focus on the third situation which is more challenging since the target images are not available during training.
In domain generalized stereo matching, feature represen-tation plays a crucial role [45] since the feature extraction module directly confronts images from different domains.
Then a question is raised: can the goal be achieved by re-placing the feature extraction module of an ordinary stereo matching network (ordinary means it is trained with syn-thetic data) with a broad-spectrum feature (i.e. the feature of a model trained on large-scale datasets)? Since this fea-ture has seen various styles of images and learns to general-ize well. In traditional algorithms, various feature descrip-tors [13] and cost aggregation methods [12, 42] could be
combined with each other to use. However in deep frame-works, the parameterized modules are entangled through end-to-end training, is this grafting operation (i.e. combin-ing two trained modules without ﬁnetuning) practical?
To answer this question, we ﬁrst conduct a toy experi-ment. With PSMNet [3] as the basic architecture, we train a model on a synthetic dataset SceneFlow [20], then its fea-ture extraction module is replaced with the feature of VGG
[30] trained on ImageNet [7]. Finally, the cross-domain per-formances are evaluated on KITTI 2015 [21]. As illustrated in Subﬁgure (c) and (d) of Figure 1, simply grafting a broad-spectrum feature to an ordinary cost aggregation module leads to a collapse of the disparity result. We analyze this is caused by the feature concatenation based cost volume, which forces the cost aggregation module to learn to mea-sure the similarity based on the feature. When the feature is replaced, the learned metric will not be effective.
In order to disentangle the feature extraction module and the cost aggregation module, it is necessary to construct a generalized cost space [2]. On one hand, the cost volume should contain pure similarity information.
In this way, the prior knowledge about the similarity metric is injected, preventing the cost aggregation module from overﬁtting to the used feature. Besides, the semantical information [10] which may interfere with cost aggregation due to the varied semantic classes of different domains is discarded. On the other hand, integrating the normalization of the cost value is beneﬁcial for the generalization ability [31]. To this end, we utilize the elegant cosine similarity to construct the cost volume. In addition to satisfying the above demands, co-sine similarity projects features with arbitrary channels to a scalar, making the cost accessible for various features.
Owing to the generalized cost space, when the feature extraction module trained with synthetic data is replaced with a broad-spectrum feature, the cross-domain perfor-mance is improved signiﬁcantly, as shown in Subﬁgure (e) and (f) of Figure 1. This also experimentally validates that a broad-spectrum feature can be employed to handle the do-main shift. However, grafting such a low-level feature of the classiﬁcation model is still suboptimal since it contains much general information that serves various tasks.
It is necessary to adapt the grafted feature to our stereo matching task. Inspired by the researches in multi-task learning [15] and transfer learning [24], we build a shallow network and force it to recover more task-speciﬁc information from the grafted feature. Although this training process is conducted on the source domain, the feature adaptor is robust since its input, the broad-spectrum feature has weakened the inﬂu-ence of the image style. Besides, the small amount of the parameters will reduce the risk of overﬁtting [38].
In summary, there are two fundamental steps in our domain generalized stereo matching network GraftNet.
Firstly, grafting a broad-spectrum feature (i.e. the feature of a model trained on large-scale datasets) to the cost ag-gregation module of an ordinary stereo matching network.
Secondly, transforming the feature with a shallow network to recover the task-speciﬁc information.
In practice, we
ﬁnd retraining the cost aggregation module with this trans-formed feature can further improve the performance.
It is worth noting that our method can be built upon arbi-trary stereo matching networks, the only modiﬁcation is to construct the cost volume with cosine similarity. Without bells and whistles, our models based on PSMNet [3] and
GANet [44] are superior to other robust and domain gener-alized algorithms when transferring from a synthetic dataset
SceneFlow [20] to some realistic datasets such as KITTI 2015 [21], KITTI 2012 [8], and Middlebury [26]. 2.