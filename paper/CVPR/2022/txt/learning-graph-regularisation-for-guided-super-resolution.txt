Abstract
We introduce a novel formulation for guided super-Its core is a differentiable optimisation layer resolution. that operates on a learned affinity graph. The learned graph potentials make it possible to leverage rich con-textual information from the guide image, while the ex-plicit graph optimisation within the architecture guarantees rigorous fidelity of the high-resolution target to the low-resolution source. With the decision to employ the source as a constraint rather than only as an input to the predic-tion, our method differs from state-of-the-art deep archi-tectures for guided super-resolution, which produce targets that, when downsampled, will only approximately repro-duce the source. This is not only theoretically appealing, but also produces crisper, more natural-looking images. A key property of our method is that, although the graph con-nectivity is restricted to the pixel lattice, the associated edge potentials are learned with a deep feature extractor and can encode rich context information over large receptive fields.
By taking advantage of the sparse graph connectivity, it be-comes possible to propagate gradients through the optimi-sation layer and learn the edge potentials from data. We extensively evaluate our method on several datasets, and consistently outperform recent baselines in terms of quan-titative reconstruction errors, while also delivering visually sharper outputs. Moreover, we demonstrate that our method generalises particularly well to new datasets not seen dur-ing training. 1.

Introduction
Guided super-resolution takes as input two images of different resolution, a low-resolution source and a high-resolution guide from a different domain.
It returns a termed high-resolution version of the source as output, the target. This task is relevant in many practical appli-*Equal contribution.
Figure 1. Our method takes as input a low-resolution source image and a high-resolution guide image of another modality to build a graph using high-level image features. The graph is then used in a differentiable optimisation layer as a regularisation to reconstruct the target. cations such as medical [62] and satellite imaging [26], where performing a diagnosis or analysis from low-quality images can be extremely difficult. Another very popu-lar example in computer vision is upsampling depth maps, where the low-resolution depth is the source, a conven-tional grayscale or RGB image is the guide, and the tar-get is a high-resolution depth map. Consumer-grade depth sensors provide low-resolution depth maps, but a high-resolution RGB camera is usually mounted on the same de-vice and can acquire a high-resolution image of the same scene. Guided super-resolution methods can be divided into two main categories, conventional and deep learning-based methods. The former typically cast the task into an optimi-sation problem [7, 8, 10, 12]. The goal is to create a high-resolution target image that, when downsampled, matches the source, while at the same time complying with an ap-propriate regularisation term that favours a desired image characterstic such as (piecewise) smoothness. Deep learn-ing methods [15, 17–19, 52] instead rely on a dataset of source/guide/target triplets to learn a feed-forward mapping from the source and guide to the target. To that end the model must learn the statistical correlations that allow it to transfer high-frequency details from the guide to the tar-get, while, at the same time, ensuring that the predicted tar-get stays close to the source. A considerable advantage of the conventional approach is that, by individually solving a properly formulated optimisation for each image, the pre-diction is usually guaranteed to match the source. On the other hand, designing an adequate regularisation term based on low-level image features is a complicated task. Deep learning methods exhibit rather complementary strengths: as long as one has access to enough training data and that data is representative of the images encountered at test time, these methods tend to perform very well, due to the un-matched ability of deep networks to mine complex, highly informative features from images. On the other hand, with limited training data, or when there is a domain shift be-tween the training and the test set [54], feed-forward meth-ods can no longer guarantee that downsampling the pre-dicted target will produce the source, thus contradicting the fundamental relation behind super-resolution.
In this work, we show how to combine the two schools, and learn the graph of an optimisation-based super-resolution scheme, – see Figure 1. In particular, we learn a mapping from the two inputs (source and guide) to the edge potentials (also called edge weights) of an affinity graph be-tween pixels of the target. The learned graph serves as the regulariser for an optimisation-based reconstruction of the high-resolution target, which is particularly suited for sig-nals with a piecewise smooth structure. This entire map-ping is trained end-to-end: the mapping function, which is parametrised as a convolutional network, is learned from training data, by back-propagating the gradients of the loss through the optimisation layer. CRF-RNN [9] also pro-posed to perform an online optimisation and include a graph in their network for semantic segmentation. However, they construct a dense graph and use an RNN to approximate
In contrast, we show that the inference of the posterior. a sparse, local graph is sufficient while performing exact maximum a posteriori inference. We test our method on three different guided depth super-resolution datasets and show that it compares favourably against conventional and deep learning-based methods, across a range of upsampling 16. We further show that our proposed factors from method is much more robust to distribution shifts and can effectively generalise across datasets. 4 to
×
×
In summary, the contributions of this paper are the fol-(i) We introduce a novel formulation of guided lowing: super-resolution, where a deep feature extractor is trained to derive the edge potentials for a graph-based energy min-imisation from the input (source and guide) images; (ii) we develop a differentiable optimiser for the graph regularisa-tion, taking advantage of the sparse graph connectivity to efficiently process large input patches up to 2562 pixels1; 1Code is available at https://github.com/prs-eth/graph-super-resolution (iii) in this way, our scheme therefore combines the power of learned, deep feature extractors with large receptive fields and the rigor of graph-based optimisation in an end-to-end trainable framework. As a result, it produces crisp, natural-looking images that correctly adhere to the underlying im-age formation model. 2.