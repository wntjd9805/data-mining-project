Abstract
Obtaining annotations for large training sets is expen-sive, especially in settings where domain knowledge is re-quired, such as behavior analysis. Weak supervision has been studied to reduce annotation costs by using weak la-bels from task-specific labeling functions (LFs) to augment ground truth labels. However, domain experts still need to hand-craft different LFs for different tasks, limiting scal-ability. To reduce expert effort, we present AutoSWAP: a framework for automatically synthesizing data-efficient task-level LFs. The key to our approach is to efficiently represent expert knowledge in a reusable domain-specific language and more general domain-level LFs, with which we use state-of-the-art program synthesis techniques and a small labeled dataset to generate task-level LFs. Addition-ally, we propose a novel structural diversity cost that allows for efficient synthesis of diverse sets of LFs, further improv-ing AutoSWAP’s performance. We evaluate AutoSWAP in three behavior analysis domains and demonstrate that Au-toSWAP outperforms existing approaches using only a frac-tion of the data. Our results suggest that AutoSWAP is an effective way to automatically generate LFs that can signif-icantly reduce expert effort for behavior analysis. 1.

Introduction
In recent years, machine learning has enabled the study of large-scale datasets in many behavior analysis domains, such as neuroscience [24, 27], sports analytics [30, 37], and motion forecasting [7]. However, obtaining labeled data to train models can be difficult and costly, especially when do-main expertise is required for annotation, such as for many behavior analysis tasks [24]. One way to reduce annotation cost is through weak supervision, which uses noisy, task-level heuristic “labeling functions” (LFs) to weakly label data. LFs for a specific task (task-level LFs) are supplied by domain experts, and are applied to obtain a set of weak labels. Weakly labeled data can then be used in downstream settings, such as active learning [4] and self-training [17].
*Work done while author was affiliated with Caltech.
†Correspondence to atseng@caltech.edu.
Figure 1. We present AutoSWAP, a framework for automatically synthesizing diverse sets of task-level labeling functions (LFs) with a small labeled dataset and domain knowledge encoded in domain-level LFs and a DSL. AutoSWAP significantly reduces la-beler effort by automating LF generation.
While weak supervision has worked well in a wide range of settings [4, 10, 23], it has not been well-explored for be-havior analysis tasks. For one, the requirement that LFs must provide labels and not, for example, features prevents more general domain knowledge from being used [22] (e.g. the behavioral features in [14, 24]). Furthermore, new LFs must be hand-crafted by domain experts for new tasks (such as new behaviors to study), limiting the scalability of man-ual weak supervision [33]. To address these challenges, we study efficient domain knowledge representations and de-velop automated weak supervision methods towards reduc-ing annotation bottlenecks in behavior analysis settings.
Our Approach. We propose AutoSWAP (Automatic
Synthesized WeAk SuPervision), a data-efficient frame-work for automatically generating task-level LFs using a novel diverse program synthesis formulation. As depicted in Figure 1, experts provide a domain-specific language (DSL) and domain-level LFs (LFs specific to a domain of tasks) for a given domain, such as mouse behaviors or ve-hicle motion planning. For each task to be studied in that domain, experts provide a small labeled dataset to specify the task, and AutoSWAP returns a set of structurally di-verse task-level LFs that can be used in weakly supervised frameworks. The domain-level LFs (Figure 2) provide fine-grained, label-space agnostic “atomic instructions,” while the DSL contains abstract structural domain knowledge for composing the more general domain-level LFs into task-level LFs (Figure 3). The novel diversity cost enables Au-toSWAP to generate structurally diverse LFs, which we and others empirically show outperform structurally homoge-neous LFs in downstream tasks [33].
To the best of our knowledge, we are the first to demon-strate the effectiveness of program synthesis for automated
LF generation. Existing works for generating LFs include iteratively selecting LFs by repeatedly querying experts for feedback [5] and training exponentially many simple heuristics models [33], which have limitations in scalability and tractability. In contrast, our approach represents domain knowledge in a DSL and domain-level LFs, which can then be used to automatically synthesize LFs for arbitrary tasks in a domain with our diverse program synthesizer.
We evaluate our approach in three behavior analy-sis domains with both sequential and nonsequential data: mouse [27], fly [14], and basketball player [36] behaviors.
In these domains, data collection is expensive and new tasks frequently emerge, highlighting the importance of scalabil-ity. The datasets we use are based on agent trajectories, which provide low-dimensional inputs for easily creating domain-level LFs. We show that with existing expert de-fined domain-level LFs from [14, 24] and a simple DSL,
AutoSWAP is capable of synthesizing high quality LFs with very little labeled data. These LFs outperform LFs from ex-isting automatic weak supervision methods [33] and offer a data efficient approach to reducing domain expert effort.
To summarize, our contributions are:
• We propose AutoSWAP, which combines program synthesis with weak supervision to scalably and effi-ciently generate labeling functions.
• We propose a novel program-structural diversity cost that enables AutoSWAP to directly synthesize diverse sets of labeling functions, which we empirically show are more data efficient than purely optimal sets.
• We evaluate AutoSWAP in multiple behavior analy-sis domains and downstream tasks, and show that Au-toSWAP is capable of significantly improving data ef-ficiency and reducing expert cost.
Our implementation of AutoSWAP can be found at https://github.com/autoswap/autoswap_cvpr_2022. 2.