Abstract 3D semantic segmentation is a fundamental building block for several scene understanding applications such as autonomous driving, robotics and AR/VR. Several state-of-the-art semantic segmentation models suffer from the part-misclassification problem, wherein parts of the same object are labelled incorrectly. Previous methods have utilized hi-erarchical, iterative methods to fuse semantic and instance information, but they lack learnability in context fusion, and are computationally complex and heuristic driven. This paper presents Segment-Fusion, a novel attention-based method for hierarchical fusion of semantic and instance in-formation to address the part misclassifications. The pre-sented method includes a graph segmentation algorithm for grouping points into segments that pools point-wise features into segment-wise features, a learnable attention-based net-work to fuse these segments based on their semantic and instance features, and followed by a simple yet effective connected component labelling algorithm to convert seg-ment features to instance labels. Segment-Fusion can be flexibly employed with any network architecture for seman-tic/instance segmentation. It improves the qualitative and quantitative performance of several semantic segmentation backbones by upto 5% on the ScanNet and S3DIS datasets. 1.

Introduction
The growing resolution and availability of 3D visual sen-sors in recent years (e.g. Kinect, RealSense, Xtion) have en-abled high fidelity representation of real world scenes using 3D data, allowing machines to understand 3D scenes with higher accuracy. One of the most important tasks in scene understanding includes 3D semantic segmentation, which aims to recognize the object class that each point in the scene belongs to. 3D semantic segmentation is fundamental to various applications, such as autonomous driving, robotic navigation and AR/VR [11, 28, 31, 38].
∗1,2Contact us at:
{anirud.thyagharajan, benjamin.ummenhofer, prashant.laddha, om.j.omer, sreenivas.subramoney}@intel.com
Figure 1. Semantic labels with baseline [37] and our Segment-Fusion approach on a sample point cloud from ScanNet Validation set [5]. The circled regions highlight how well Segment-Fusion addresses the part misclassification problem prevailing in many state-of-the-art semantic segmentation methods.
Recent advancements in 3D scene understanding have been greatly influenced by deep neural networks achieving state-of-the-art results [3,9,10,15–17,20,23,34,37] on mul-tiple benchmarks and wide range of datasets [1, 5]. How-ever, many of these methods are often plagued by the part-misclassification problem, where parts of the same object are labelled incorrectly as shown in Figure 1. This problem can be better addressed if object instance boundaries can be correctly estimated, which includes annotating points with object instance identifiers. This helps to group all points associated with an object instance and utilize consensus to rectify semantic mispredictions.
Jointly solving semantic and instance segmentation has been explored by several previous works [2, 7, 12, 13, 18, 22, 24, 35, 36]. Many of these methods [13, 18, 24, 35, 36] focus on employing models for instance and semantic seg-mentation, before fusing pointwise features. However, they require higher compute resources as they fuse at a fine-grained level and do not exploit local continuities in scene structure. Methods such as [2, 7, 12, 22] include hierarchi-cal pooling of features over a spatial region addressing the part misclassification problem by fusing these regions, with an assumption that these regions do not stretch over object boundaries. Such hierarchical methods are more efficient since they work with regions and not directly with points.
While such methods are more efficient, they employ itera-Figure 2. Overview of the Segment-Fusion approach. The Graph Segmentation module (GS) groups points into segments and enables pooling pointwise semantic and instance features S, I into segment-wise features ¯S, ¯I. The Segment Fusion Network maps these features to a common feature space ¯F which is then used in the connected component labelling algorithm (CCL) to create the final set of segments. tive clustering and aggregation techniques that are known to be heuristic-driven, non-learnable and specific to the back-bone models used for extracting semantic and instance fea-tures. They also use complex post-processing [6, 27] to transform instance features to labels. Thus, there is a need for hierarchical, learnable methods for fusing such regions with simple post-processing.
Our prime objective is to improve semantic segmentation performance of a generic semantic segmentation model by using a hierarchical fusion of semantic and instance infor-mation. We use a graph segmentation algorithm to group points into regions and pool region-wise semantic and in-stance features but downstream, we propose a learnable clustering algorithm. It is desirable that the method should be learnable and agnostic to dataset specific heuristics.
• We propose a graph segmentation algorithm optimized for semantic segmentation across datasets, which is used to compose semantic and instance features at a coarser level (which we term as segments).
• We propose a learnable attention based network, Seg-ment Fusion, to hierarchically fuse segments based on the similarity of their semantic and instance features, thus understanding the appropriate granularity of con-text (local to global: points to instance to scene).
• Our approach offers the advantages of adapting to in-puts from other datasets and other backbones, as well as offering the possibility to perform end-to-end train-ing and maintain efficiency (while working on a hi-erarchically smaller representation, and not working on individual points). These proposals help ameliorate the problem of part-misclassification by improving the performance (mIoU) of multiple semantic backbones on datasets like ScanNet [5] and S3DIS [1] upto 5%.
We also compare the impact of our proposed method with the iterative clustering method proposed by Oc-cuseg [12] and report 1-2% mIoU improvement in se-mantic segmentation. 2.