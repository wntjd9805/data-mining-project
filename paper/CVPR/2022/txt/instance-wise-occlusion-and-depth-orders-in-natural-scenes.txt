Abstract
In this paper, we introduce a new dataset, named In-staOrder, that can be used to understand the geometrical relationships of instances in an image. The dataset consists of 2.9M annotations of geometric orderings for class-labeled instances in 101K natural scenes. The scenes were anno-tated by 3,659 crowd-workers regarding (1) occlusion order that identiﬁes occluder/occludee and (2) depth order that de-scribes ordinal relations that consider relative distance from the camera. The dataset provides joint annotation of two kinds of orderings for the same instances, and we discover that the occlusion order and depth order are complemen-tary. We also introduce a geometric order prediction network called InstaOrderNet, which is superior to state-of-the-art approaches. Moreover, we propose a dense depth prediction network called InstaDepthNet that uses auxiliary geometric order loss to boost the accuracy of the state-of-the-art depth prediction approach, MiDaS [54]. 1.

Introduction
Understanding a scene from an image is a fundamen-tal problem in computer vision. Deep learning-based ap-proaches have achieved great success in various tasks, such as object detection [2, 13, 17, 18, 23, 37, 55, 56], semantic segmentation [5, 6, 36, 42, 43, 48, 64, 65, 74, 81], instance segmentation [11, 12, 22, 32, 41, 50, 51, 80] and depth esti-mation [4, 14, 20, 29, 33, 39, 58, 61, 70, 78]. More recently, approaches have inferred high-level information, such as amodal segmentation [52, 73, 83, 84], physics [68], and 3D-property recognition [10, 16, 25, 47, 59, 60, 72, 75]. More importantly, many studies have emphasized the importance of understanding relationships between objects to learn high-level context [15, 27, 46, 49, 53, 85]. Given a natural image (Figure 1a, b), examples of such understanding would be
‘Horse3 occludes Person2.’, ‘Horse1 and Person3 occlude each other.’, or ‘Horse2 is closer than Person2.’.
For this purpose, we introduce a new large-scale dataset, called INSTAORDER, for geometric scene understanding.
The dataset has extensive annotations on geometric order-(a) Image (b) Instance masks (c) Occlusion order (d) Depth order
Figure 1. Overview of the proposed INSTAORDER dataset. (a and b) Example image of a cluttered scene and instance masks with class labels. (c) Occlusion order. Arrows run from occluder to occludee. (d) Depth order. Arrows point from close to far. ings between class-labeled instances in the natural scenes.
INSTAORDER provides (1) Occlusion order that determines objects that occlude others (occluders), and objects that are occluded (occludees), and (2) Depth order that describes which object is closer or farther to the camera. INSTAORDER is the ﬁrst dataset that provides these two kinds of orders together from the same image.
The two types of geometric relations can be expressed us-ing directed graphs (Figure 1c, d). Occlusion order and depth order are complementary to each other, and neither alone can fully depict the geometric relationship in the cluttered scene.
For example, Horse2 in the occlusion graph (Figure 1c) is isolated, so Horse2’s depth is not clear without looking at the depth order graph (Figure 1d). In contrast, looking only at the depth order graph does not demonstrate whether Horse1 occludes Horse3, whereas the occlusion order graph does provide such information. Compared with other datasets
shown in Figure 2, INSTAORDER is the only large-scale and comprehensive dataset that provides instance segmentation mask, instance class label, occlusion, and depth order with delicate annotation of ordering types as shown as bidirec-tional edges and dashed edges.
INSTAORDER is built on the COCO 2017 [38] dataset. A total of 3,659 crowd-workers annotated geometric ordering for 100,623 images having 503,939 instances, for a total of 2,859,919 depth and occlusion orderings. Such large-scale annotation distinguishes INSTAORDER from the prior datasets that only cover occlusion order [52, 84] or depth order [7]. In addition to its scale, INSTAORDER introduces richer annotation on ambiguous cases that had not been addressed before [7, 52, 84]. For example, bidirectional or-der covers the case (Figure 1) in which Horse3 and Person1 occlude each other. For depth order, in addition to {closer, farther, or equal} orderings, we introduce distinct and over-lapping depth orders. For example, some parts of Person1’s left leg are closer than Horse3, whereas the right arm is far-ther (Figure 1a). This case is annotated as overlap depth and displayed as a dashed line (Figure 1d). The direction of the dashed line indicates that some part of Person1 (left leg) is nearer than any part of Horse3.
We also propose new networks called InstaOrderNet and
InstaDepthNet. InstaOrderNet is used to recover instance-wise orders from an image. We show that InstaOrderNet achieves higher accuracy than state-of-the-art approaches, such as PCNet-M [77] and OrderNetM+I [84]. InstaDepth-Net is used to predict a dense depth map from an image.
With the proposed instance-wise disparity loss and the IN-STAORDER dataset, InstaDepthNet can boost the accuracy of MiDaS [54], a state-of-the-art depth estimation network.
The contributions of this paper are:
• We introduce the INSTAORDER dataset that provides 2.9M of comprehensive instance-wise geometric order-ings for 101K natural scenes. INSTAORDER is the ﬁrst dataset of both occlusion and depth order from the same image, with bidirectional occlusion order and delicate depth range annotations.
• We discover that occlusion and depth order are comple-mentary, and that instance-wise orders are helpful for the monocular depth prediction task.
• We introduce InstaOrderNet for geometric order pre-diction and show its superior accuracy over state-of-the-arts. In addition, we introduce InstaDepthNet, which demonstrates that the proposed auxiliary loss for geo-metric ordering can boost the depth prediction accuracy of the state-of-the-art approach, MiDaS [54].
• The INSTAORDER dataset, pre-trained model, and toolbox are available at https://github.com/
POSTECH-CVLab/InstaOrder 2.