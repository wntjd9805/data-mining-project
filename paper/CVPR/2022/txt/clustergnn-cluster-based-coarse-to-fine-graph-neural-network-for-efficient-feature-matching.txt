Abstract
Graph Neural Networks (GNNs) with attention have been successfully applied for learning visual feature match-ing. However, current methods learn with complete graphs, resulting in a quadratic complexity in the number of fea-tures. Motivated by a prior observation that self- and cross- attention matrices converge to a sparse represen-tation, we propose ClusterGNN, an attentional GNN ar-chitecture which operates on clusters for learning the fea-ture matching task. Using a progressive clustering mod-ule we adaptively divide keypoints into different subgraphs to reduce redundant connectivity, and employ a coarse-to-fine paradigm for mitigating miss-classification within im-ages. Our approach yields a 59.7% reduction in runtime and 58.4% reduction in memory consumption for dense de-tection, compared to current state-of-the-art GNN-based matching, while achieving a competitive performance on various computer vision tasks. 1.

Introduction
Finding correspondences between images is an essen-tial task for many computer vision applications such as Si-multaneous Localization and Mapping (SLAM) [14, 20],
Structure-from-Motion (SfM) [32, 43] and camera pose es-timation [48]. Given a pair of images, correspondences can be established through point-to-point feature matching.
Classical pipelines typically obtain correspondences with a nearest neighbor (NN) search of feature descriptors and re-ject outliers based on their match score or using a mutual
NN check. Such methods focus only on the local similarity between feature descriptors while ignoring geometric infor-mation and the global receptive field.
Recent works [5, 30, 35] have proposed to learn the task of feature matching using graph neural networks (GNNs)
*These authors contributed equally to this work.
â€ Corresponding authors.
Figure 1. Sparse attention in cluster-based feature matching. Each keypoint interacts only with points within its cluster (proposed method) instead of interacting with all keypoints as in current
GNN-based feature matching [30]. and attention. In SuperGlue [30], Transformer [40] based
GNNs are applied on the complete graph of keypoints within (intra graph) and between (inter graph) images. Each node is represented with an encoded keypoint descriptor and updated using self- and cross- multi-head attention, while alternating between the intra- and inter- complete graphs, respectively. Learning complete graphs with attention suf-fers from a computational and memory complexity which is quadratic in N, where N is the number of keypoints. How-ever, keypoints typically show a strong correlation with just a small number of points (sparse adjacency matrix). Fur-thermore, in the context of feature matching, a large portion of keypoints are non-repeatable and irrelevant for matching.
A complete graph representation is thus redundant and re-sults in wasteful attention-based message passing.
Efforts to reduce the quadratic complexity of attention mainly focused on self-attention. For example, reducing the attention dimension by splitting the input sequence into local windows [23] or by approximating attention with ker-nels [8]. However, these works are less suitable for fea-ture matching, where we are required to perform self- and cross- attention on features within and between images, re-spectively. Inspired by the Routing Transformer [27], we propose a coarse-to-fine cluster-based GNN to learn the fea-ture matching task with a lower redundancy and compu-tational complexity. We extract query and key features of keypoints across images to classify the points with strong correlation into the same cluster and establish local graphs using points from the same category. Each point interacts only with points in the same local graph resulting with a sparser attention computation (Fig. 1) . Since clustering keypoints across images may lead to an erroneous group-ing within images, we take a coarse-to-fine approach and first divide the points into a small number of major clus-ters which are gradually divided into multiple smaller clus-ters. We evaluate our method on multiple tasks, namely: relative pose estimation, homography estimation and visual localization. Our model achieves state-of-the-art accuracy across tasks, with a significant improvement in efficiency for dense detection (59.7% and 58.4% reduction in runtime and memory, respectively).
In summary, our contributions are as follows: 1. We present a learnable, coarse-to-fine clustering method to establish local graphs for feature matching, which reduces the spread of redundant information and makes message passing more effective. 2. We introduce the ClusterGNN architecture, an atten-tional GNN for learning the feature matching task us-ing gradually forming clusters, approximating atten-tion on complete graphs. 3. The proposed ClusterGNN method achieves state-of the-art results on various tasks, with a significant re-duction in runtime and memory consumption on dense detection (59.7% and 58.4%, respectively) compared to the current leading feature matching method (Su-perGlue). 2.