Abstract
We propose Clustering Mask Transformer (CMT-DeepLab), a transformer-based framework for panoptic segmentation designed around clustering. It rethinks the ex-isting transformer architectures used in segmentation and detection; CMT-DeepLab considers the object queries as cluster centers, which ﬁll the role of grouping the pixels when applied to segmentation. The clustering is computed with an alternating procedure, by ﬁrst assigning pixels to the clusters by their feature afﬁnity, and then updating the cluster centers and pixel features. Together, these oper-ations comprise the Clustering Mask Transformer (CMT) layer, which produces cross-attention that is denser and more consistent with the ﬁnal segmentation task. CMT-DeepLab improves the performance over prior art signif-icantly by 4.4% PQ, achieving a new state-of-the-art of 55.7% PQ on the COCO test-dev set. 1.

Introduction
Panoptic segmentation [47], a recently proposed chal-lenging segmentation task, aims to unify semantic seg-mentation [34] and instance segmentation [31]. Due to its complicated nature, most panoptic segmentation frame-works [18,47,89] decompose the problem into several man-ageable proxy tasks, such as box detection [73], box-based segmentation [32], and semantic segmentation [65].
Recently, the paradigm has shifted from the proxy-based approaches to end-to-end systems, since the pioneering work DETR [10], which introduces the ﬁrst end-to-end object detection method with transformers [80].
In their framework, the image features, extracted by a convolutional network [50], are enhanced by transformer encoders. After-wards, a set of ﬁxed size of positional embeddings, named object queries, interact with the extracted image features through several transformer decoders, consisting of cross-attention and self-attention modules [3]. The object queries, transformed into output embeddings by the decoders, are
∗Work done during an internship at Google.
Figure 1. Our CMT-DeepLab generates denser cross-attention maps than MaX-DeepLab [82]. The visualization is based on the last transformer layer with averaged multi-head attentions. then directly used for bounding box predictions.
Along the same direction, end-to-end panoptic segmen-tation framework [82] has been proposed to simplify the panoptic segmentation procedure, avoiding manually de-signed modules. The core idea is to exploit a set of ob-ject queries conditioned on the inputs to predict a set of pairs, each containing a class prediction and a mask em-bedding vector. The mask embedding vector, multiplied by the image features, yields a binary mask prediction. No-tably, unlike the box detection task, where the prediction is based on object queries themselves, segmentation mask prediction requires both object queries and pixel features to interact with each other to obtain the results, which con-sequently incurs different needs when updating the object queries. To have a deeper understanding towards the role that object queries play, we particularly look into the cross-attention module in the mask transformer decoder, where object queries interact with image features.
Our investigation ﬁnds that the update and usage of ob-ject queries are performed differently in the transformer-based method for segmentation tasks [82]. Speciﬁcally, when updating the object queries, a softmax operation is applied to the image dimension, allowing each query to identify its most similar pixels. On the other hand, when computing the segmentation output, a softmax is performed among the object queries so that each pixel ﬁnds its most similar object queries. The formulation may potentially cause two issues: sparse query updates and infrequent pixel-query communication. First, the object queries are only sparsely updated due to the softmax being applied to a large image resolution, so it tends to focus on only a few locations (top row in Fig. 1). Second, the pixels only have one chance to communicate with the object queries in the ﬁnal output.
The ﬁrst issue is particularly undesired, since segmentation tasks require dense predictions, and ideally a query should densely activate all the pixels that belong to the same target.
This is different from the box detection task, where object extremities are sufﬁcient (see Fig. 6 of DETR paper [10]).
To alleviate the issues, we draw inspiration from the tra-ditional clustering algorithms [1, 64]. In the current end-to-end panoptic segmentation system [82], the ﬁnal segmenta-tion output is obtained by assigning each pixel to the object queries based on the feature afﬁnity, similar to pixel-cluster assignment step in [1, 64]. The observation motivates us to rethink the transformer-based methods from the cluster-ing perspective by considering the object queries as clus-ter centers. We therefore propose to additionally perform the cluster-update step, where the centers are updated by pooling pixel features based on the clustering assignment, when updating the cluster centers (i.e., object queries) in the cross-attention module. As a result, our model gen-erates denser attention maps (bottom row in Fig. 1). We also utilize the pixel-cluster assignment to update the pixel features within each transformer decoder, enabling frequent communication between pixel features and cluster centers.
Additionally, we notice that in the cross-attention mod-ule, pixel features are treated as in “bag of words” [49], while the location information is not well utilized. To re-solve the issue, we propose to adopt a dynamic position en-coding conditioned on the inputs for location-sensitive clus-tering. We explicitly predict a reference mask consisting of a few points for each cluster center. The location-sensitive clustering is then achieved by adding location information to pixel features and cluster centers via the coordinate con-volution [59] at the beginning of each transformer decoder.
Combining all the proposed components results in our
CMT-DeepLab, which reformulates and further improves the previous end-to-end panoptic segmentation system [82] from the traditional clustering perspective. The panop-tic segmentation result is naturally obtained by assigning each pixel to its most similar cluster center based on the feature afﬁnity (Fig. 2).
In the Clustering Mask Trans-former (CMT) module, the pixel features, cluster centers,
Figure 2. Panoptic segmentation from a clustering perspective. In the proposed Clustering Mask Trasnformer (CMT) layer, pixels are assigned to cluster centers based on the feature afﬁnity, and the clustering results are used to update both pixel features and cluster centers. After several CMT layers, a reﬁned pixel-cluster assignment is obtained, resulting in the ﬁnal panoptic mask. and pixel-cluster assignments are updated in a manner sim-ilar to the clustering algorithms [1, 64]. As a result, without bells and whistles, our proposed CMT-DeepLab surpasses its baseline MaX-DeepLab [82] by 4.4% PQ and achieves 55.7% PQ on COCO panoptic test-dev set [58]. 2.