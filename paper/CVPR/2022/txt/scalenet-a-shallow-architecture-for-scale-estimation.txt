Abstract
In this paper, we address the problem of estimating scale factors between images. We formulate the scale es-timation problem as a prediction of a probability distri-bution over scale factors. We design a new architecture,
ScaleNet, that exploits dilated convolutions as well as self-and cross-correlation layers to predict the scale between images. We demonstrate that rectifying images with es-timated scales leads to significant performance improve-ments for various tasks and methods.
Specifically, we show how ScaleNet can be combined with sparse local fea-tures and dense correspondence networks to improve cam-era pose estimation, 3D reconstruction, or dense geomet-ric matching in different benchmarks and datasets. We pro-vide an extensive evaluation on several tasks, and analyze the computational overhead of ScaleNet. The code, evalua-tion protocols, and trained models are publicly available at https://github.com/axelBarroso/ScaleNet. 1.

Introduction
Establishing correspondences is the very first step in many different 3D pipelines. Advancing on this task will have a direct impact on the performance of downstream ap-plications such as camera pose estimation [39], autonomous driving [6], or 3D reconstructions [41]. However, methods that search for correspondences between images face sig-nificant challenges, and although some solutions are more mature than others, the task still is far from being solved.
As the field advances, even though the intermediate tasks in the correspondence search remain the same, their methods are being revisited and redesigned, e.g., keypoint detectors/descriptors [10, 11, 37], dense geometric match-ers [25,53], or geometric verification techniques [31,40,46].
These new approaches have shown that the downstream tasks can be pushed to new performance levels through ro-bust correspondences. The key objective of these new meth-ods is to handle more and more extreme cases where pre-vious pipelines failed, and although some methods are ar-guably application-specific [60], their robustness to extreme
Figure 1. We propose a scale-aware system that helps establish correspondences under strong scale changes, allowing to correctly match pairs where previous pipelines were not successful. We in-troduce ScaleNet, a network that estimates the scale distribution between two images so that regions of interest can be corrected and exhibit the same scale factor (top). We display (bottom) an in-door and outdoor example where matches from R2D2 with multi-scale pyramid (left) increase if using ScaleNet rectification (right). conditions is the main reason for success.
Inspired by the previous methods targeting visual ro-bustness [29, 30, 58], we address the problem of handling the scale change between images, which is a long-standing challenge in computer vision [23, 26]. Scale robustness and estimation have been the focus of much research in the area of handcrafted feature extraction [23, 54, 60] as a reliable solution that can significantly boost the performance of ex-isting methods. Moreover, the scale change is arguably the most challenging, and the most important parameter to esti-mate compared to rotation, translation, or even local affine deformations [54]. There are several strategies to deal with scale changes, with the multi-scale pyramid being one of the most popular solutions [3,4,11,23,37,52,54]. Although the multi-scale pyramid mitigates the problem of different
scales, it increases complexity and ambiguity as the matcher needs to establish correspondences among multiple scale levels. Figure 1 (bottom) shows an example of extreme pairs for which R2D2 [37] with multi-scale pyramid can only get a high number of correct matches once we rec-tify the scales. Besides the added complexity, a multi-scale pyramid is not always a straightforward solution to incor-porate in some methods, such as dense correspondence net-works [18,45,53]. In contrast to multi-scale pyramids, some works aim at being invariant to different scales through their learning process [10, 34], however, as a side effect, they be-come progressively less discriminative [55]. Another pos-sible direction, and popular strategy, is to estimate the local or global transformations and rectify the images prior to es-tablishing the correspondences [30, 36, 50, 58].
The scale factor characterizes the relationship between pairs of images and, in general, an accurate estimate can only be achieved when considering both images at the same time. Using pairs of images as input may increase the complexity beyond acceptable in some applications such as large-scale retrieval and localization unless used in their fi-nal verification stage. Nonetheless, solving the scale before the main analysis improves the discriminative power and allows less robust but more efficient methods to be used in challenging scenarios [34]. Hence, we propose a new ap-proach that estimates and corrects the scale factor between a given pair of images before the correspondence search, which is illustrated at the top of figure 1. Our scale pre-dictor network, termed ScaleNet, is inspired by dense geo-metric methods [25, 51, 53] and conditioned local features extractors [14, 34, 55]. ScaleNet extracts features from two low-resolution images and exploits CNN correlation layers to predict the scale factor. Due to the non-linear nature of scale changes, we formulate the scale regression problem as the estimation of a probability distribution in logarithmic space. We show how ScaleNet can be combined with differ-ent methods and demonstrate the improvements on different tasks and datasets.
Our contributions include: 1) a scale-aware matching system based on a novel scale predictor architecture, 2) a strategy to measure and label the scale factor between two images, and 3) a learning scheme that tackles the non-linear nature of scale changes. 2.