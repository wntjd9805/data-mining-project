Abstract
Recent progress in few-shot learning promotes a more realistic cross-domain setting, where the source and tar-get datasets are in different domains. Due to the domain gap and disjoint label spaces between source and target datasets, their shared knowledge is extremely limited. This encourages us to explore more information in the target do-main rather than to overly elaborate training strategies on the source domain as in many existing methods. Hence, we start from a generic representation pre-trained by a cross-entropy loss and a conventional distance-based classifier, along with an image retrieval view, to employ a re-ranking process to calibrate a target distance matrix by discovering the k-reciprocal neighbours within the task. Assuming the pre-trained representation is biased towards the source, we construct a non-linear subspace to minimise task-irrelevant features therewithin while keep more transferrable discrim-inative information by a hyperbolic tangent transformation.
The calibrated distance in this target-aware non-linear sub-space is complementary to that in the pre-trained repre-sentation. To impose such distance calibration informa-tion onto the pre-trained representation, a Kullback-Leibler divergence loss is employed to gradually guide the model towards the calibrated distance-based distribution. Exten-sive evaluations on eight target domains show that this tar-get ranking calibration process can improve conventional distance-based classifiers in few-shot learning. 1.

Introduction
Few-Shot Learning (FSL) promises to allow a machine to learn novel concepts from limited experience, i.e. few novel target data and data-rich source data. Typically, the defaulted FSL assumes that the source and target data is in the same domain, but belong to different classes.
In practice, FSL is required to generalise to different tar-get domains. Cross-Domain Few-Shot Learning (CD-FSL)
[9, 10, 12, 20, 41] has been studied more recently. In CD-FSL, the target data not only has a different label space but also are from a different domain to the source data.
Figure 1. An illustration of ranking distance calibration pro-cess in a FSL task. The idea is to first discover likely positive samples (e.g. sample 7) for each instance (e.g. sample 1) and then to calibrate their pairwise distances. This is achieved by mining the reciprocal ranking relations for each instance retrieval task in the target domain so to expand the k-nearest neighbours set.
It is nontrivial to directly extend the general FSL ap-proach to address the CD-FSL challenges.
In fact, many promising FSL methods [8, 34, 36, 38] performed poorly in
CD-FSL [10, 41]. The central idea of these general FSL methods is to transfer and generalise the visual representa-tions learned from source data to target data. However, the significant visual domain gap between the source and target data in CD-FSL makes it fundamentally difficulty to learn a shared visual representation across different domains.
A few recent CD-FSL studies [20, 23, 41, 45] try to learn a generalisable feature extractor to improve model transfer-ability, which is a popular idea in domain generalisation and domain adaptation [18, 43, 46, 52, 54] where the source and target domains share the same label space. Empirically, this approach shows some improvement on CD-FSL but it does not model any visual and label characteristics of the target domain and more importantly their cross-domain impact on the pre-trained source domain representation. We argue this cross-domain mapping between the source domain repre-sentation and its interpretion in the context of the target do-main data characteristics is essential for effective CD-FSL.
From a related perspective, other CD-FSL studies have con-sidered fine-tuning the source domain feature representation from augmenting additional support data in the target do-main, e.g. either explicitly augmenting the support data by adversarial training [45] and image transformations [10], or
implicitly augmenting the support data by training an auto-encoder [20]. However, these methods for CD-FSL are straightforward data-augmentation methods for increasing training data in target domain model fine-tuning, without considering how to quantify cross-domain relevance of the pre-trained source domain representation.
In this work, we consider an alternative approach with a new perspective to treat cross-domain few-shot learning as an image retrieval task. We wish to optimise model adapta-tion by leveraging target domain retrieval task context, that is, not only the labelled support data but also the unlabelled query data. To that end, we use a generic representation pre-trained by a cross entropy loss and a simple distance-based classifier as a baseline, then employ a k-reciprocal neighbour discovery (as in Fig. 1) and encoding process to calibrate pairwise distances between each unlabelled query image and its likely matches. Our idea is both orthogonal and complementary to other generalisable model learning methods [10, 20, 21]. It can be flexibly used in either fine-tuning or without fine-tuning based model learning.
Generally, the distance matrix for CD-FSL task contains many incorrect results as this distance is built on a po-tentially biased pre-trained source domain representational space. To calibrate this distance matrix towards the target domain so to reduce its bias to the source domain, we ex-plore the re-ranking concept in the target domain by con-sidering CD-FSL optimisation as re-ranking in a retrieval task given few-shots as anchor points. As in Fig. 1, re-ranking first computes a k-nearest neighbour ranking list.
This is further expanded by discovering the k-reciprocal nearest neighbours in the target domain. The expanded ranking list is used for re-computing a Jaccard distance to measure the difference between the original ranking list and the expanded ranking list, achieving a more robust and ac-curate distance matrix. Critically, a pre-trained represen-tation from source domain is biased and poor for general-isation cross-domains in CD-FSL. The reason is that con-ventional FSL methods assume implicitly linear transfor-mations mostly between the source and target data as they are sampled from the same domain. This becomes invalid in CD-FSL with mostly nonlinear transformations across source and target domains. To address this problem, we pro-pose a task-adaptive subspace mapping to minimise trans-ferring task-irrelevant representational information from the source domain. In particular, we explore a hyperbolic tan-gent function to project the source domain representation to a non-linear space. Compared to the linear Euclidean space, this non-linear space performs a dimensionality re-duction to optimise the retention of transferrable informa-tion from the source to the target domain. Moreover, we explore the idea of re-ranking to calibrate and align two distance matrices in two representational spaces between the original pre-trained source domain linear space and the new non-linear subspace. The calibrated matrices are com-bined to construct a single distance matrix for the target domain in CD-FSL. We call this Ranking Distance Cali-bration (RDC). To impose the above distance calibration into the representational space transform, we approximate the distance matrices by their corresponding distributions, and then a Kullback-Leibler (KL) divergence loss func-tion is optimised for iteratively mapping the original dis-tance distribution from the source domain towards the cali-brated space. This provides an additional RDC Fine-Tuning (RDC-FT) model optimisation.
Our contributions from this work are three-fold: (1)
To transform the biased distance matrix in the source do-main representational space towards the target domain in
CD-FSL, we use a re-ranking method to re-compute a Jac-card distance for distance calibration by discovering the re-ciprocal nearest neighbours within the task. We call this
Ranking Distance Calibration. (2) We propose a non-linear subspace to shadow the pre-trained source domain repre-sentational space. This is designed to model any inherent non-linear transform in CD-FSL and used to facilitate the distance calibration process between the source and target domains. By modelling explicitly this nonlinearity, we for-mulate a more robust and generalisable Ranking Distance
Calibration (RDC) model for CD-FSL. (3) We further im-pose RDC as a constraint to the model optimisation process.
This is achieved by a RDC with Fine-Tuning (RDC-FT) for iteratively mapping the original source domain distance dis-tribution to a calibrated target domain distance distribution for a more stable and improved CD-FSL.
We evaluated the proposed RDC and RDC-FT methods for CD-FSL on eight target domains. The results show that
RDC can improve notably the conventional distance-based classifier, and RDC-FT can improve the representation for target domain to achieve competitive or better performance than the state-of-the-art CD-FSL models. 2.