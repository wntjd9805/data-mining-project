Abstract
The 360◦ imaging has recently gained much attention; however, its angular resolution is relatively lower than that of a narrow field-of-view (FOV) perspective image as it is captured using a fisheye lens with the same sensor size.
Therefore, it is beneficial to super-resolve a 360◦ image.
Several attempts have been made, but mostly considered equirectangular projection (ERP) as one of the ways for 360◦ image representation despite the latitude-dependent distortions.
In that case, as the output high-resolution (HR) image is always in the same ERP format as the low-resolution (LR) input, additional information loss may oc-cur when transforming the HR image to other projection types. In this paper, we propose SphereSR, a novel frame-work to generate a continuous spherical image represen-tation from an LR 360◦ image, with the goal of predicting the RGB values at given spherical coordinates for super-resolution with an arbitrary 360◦ image projection. Specif-ically, first we propose a feature extraction module that rep-resents the spherical data based on an icosahedron and that efficiently extracts features on the spherical surface.
We then propose a spherical local implicit image func-tion (SLIIF) to predict RGB values at the spherical coordi-nates. As such, SphereSR flexibly reconstructs an HR image given an arbitrary projection type. Experiments on various benchmark datasets show that the proposed method signifi-cantly surpasses existing methods in terms of performance. 1.

Introduction
The 360◦ imaging has recently gained much attention in many fields, including the AR/VR field.
In general, raw 360◦ images are transformed into 2D planar represen-tations while preserving the omnidirectional information, e.g., equirectangular projection (ERP) and cube map pro-jection (CP) to ensure compatibility with imaging pipelines.
Omnidirectional images (ODIs)1 are sometimes projected
*Lin Wang is currently with HKUST. 1Throughout the paper, we use omnidirectional images and 360◦ im-ages interchangeably.
Figure 1. Learning continuous spherical image representation.
SphereSR leverages SLIIF to predict RGB values at given spheri-cal coordinates for SR with arbitrary image projection. back onto a sphere or transformed with different types of projection and rendered for display in certain applications.
However, the angular resolution of a 360◦ image tends to be lower than that of a narrow field-of-view (FOV) per-spective image, as it is captured using a fisheye lens with an identical sensor size. Moreover, the 360◦ image quality can be degraded during a transformation between different image projection types. Therefore, it is imperative to super-resolve the low-resolution (LR) 360◦ image by considering various projections to provide high-level visual quality un-der diverse conditions. Early studies attempted to recon-struct high-resolution (HR) ODIs by interpolating the miss-ing data between the LR image pixels [3, 5, 25].
Recently, deep learning (DL) has brought a significant performance boost to 2D single image super-resolution (SISR) [17, 37, 44]. These methods mostly explore super-resolving 2D LR image using high-capacity convolutional neural networks (CNNs) via, e.g., residual connections [21], and learning algorithms including generative adversarial networks (GANs) [18, 40, 41]. However, directly using these methods for 360◦ images represented in 2D planar representations is less applicable as the pixel density and texture complexity vary across different positions in 2D pla-nar representations of 360◦ images, as pointed in [10].
Consequently, several attempts were made to address SR problems in relation to 360◦ imaging [10, 28, 36, 46]. In particular, 360-SS [28] proposes a GAN-based framework using the Pix2Pix pipeline [14]. however, it focuses only on the ERP format and does not fully consider the proper-ties of 360◦ images. LAU-Net [10] introduces a method to identify ODI distortions on the latitude and upsample ODI pixels on segmented patches. However, this process leads to considerable disconnections along the patches. In a nut-shell, existing methods for ODI SR ignore the projection process of 360◦ images in real applications and only take the ERP image as the LR input, producing the HR ERP out-put. Indeed, a 360◦ image can be flexibly converted into various projection types, as in real applications, the user specifies the projection type, direction, and FOV. Thus, it is vital to address the ERP distortion problems and strive to super-resolve an ODI image to an HR image with an arbi-trary projection type rather than a fixed type.
In this paper, as shown in Fig. 1, we propose a novel framework, called SphereSR, with the goal of super-resolving an LR 360◦ image to an HR image with an ar-bitrary projection type via continuous spherical image rep-resentation. First, we propose a feature extraction module that represents spherical data based on icosahedron and effi-ciently extracts features on a spherical surface composed of uniform faces (Sec. 3.1). As such, we solve the ERP image distortion problem and resolve the pixel density difference according to the latitude. Second, we propose a spherical local implicit image function (SLIIF) that can predict RGB values at arbitrary coordinates on a sphere feature map, in-spired by LIIF [7] (Sec. 3.2). SLIIF works on triangular faces, buttressed by position embedding based on normal plane polar coordinates to obtain relative coordinates on a sphere. Therefore, our method tackles pixel-misalignment issue when the image is projected onto another ODI projec-tion. As a result, SphereSR can predict RGB values for any
SR scale parameters. Additionally, to train SphereSR, we introduce a feature loss that measures the similarity between two projection types, leading to a considerable performance enhancement (Sec. 3.3). Extensive experiments on various benchmark datasets show that our method significantly sur-passes existing methods.
In summary, the contributions of our paper are four-fold. (I) We propose a novel framework, called SphereSR, with the goal of super-resolving an LR 360◦ image to an HR im-age with an arbitrary projection type. (II) We propose a fea-ture extraction module that represents spherical data based on an icosahedron and extracts features on a spherical sur-face. (III) We propose SLIIF, which predicts RGB values from the spherical coordinates. (IV) Our method achieves the significantly better performance in the extensive experi-ments. 2.