Abstract
Existing learning-based stereo compression methods usually adopt a unidirectional approach to encoding one image independently and the other image conditioned upon
This paper proposes a novel bi-directional the ﬁrst. coding-based end-to-end stereo image compression net-work (BCSIC-Net). BCSIC-Net consists of a novel bi-directional contextual transform module which performs nonlinear transform conditioned upon the inter-view con-text in a latent space to reduce inter-view redundancy, and a bi-directional conditional entropy model that employs inter-view correspondence as a conditional prior to improve cod-ing efﬁciency. Experimental results on the InStereo2K and
KITTI datasets demonstrate that the proposed BCSIC-Net can effectively reduce the inter-view redundancy and out-performs state-of-the-art methods. 1.

Introduction
With the rapid development of stereoscopic imaging technologies, stereo images are widely used in many ap-plications, such as augmented reality, autonomous driving, and robot navigation [23, 11, 31, 21]. Accordingly, several methods [8, 14, 15, 18, 19, 24, 13] have been developed and improved to compress stereo images. Different from single image compression, compression of stereo images needs to reduce the inter-view redundancy in addition to the intra-view redundancy.
Traditionally, stereo image compression methods em-ploy inter-view prediction, such as disparity compensation prediction (DCP) [8, 15, 18, 19], to deal with the inter-view redundancy. For instance, when compressing the right im-age, DCP estimates the disparities between the right image and the reconstructed left image, then derives the prediction of the right image via disparity compensation. The dispari-ties and the residues between the actual and predicted right image are encoded. However, the hand-crafted prediction methods struggle to cope with the intricate inter-view cor-*Corresponding author.
Figure 1. Illustration of compression performance achieved by the proposed method and the state-of-the-art method HESIC [13]. relations for complex scenes, and thus the residues and the bits often remain large.
With the development of deep learning, end-to-end sin-gle image compression [2, 3, 27, 20, 22, 26, 10, 12, 25, 17, 16] has achieved promising progress. These works have provided insights and methodologies for stereo image com-pression, and some frameworks [24, 13] following the deep learning paradigm have been preliminarily studied. Specif-ically, they adopt deep learning-based single image com-pression networks and inter-view prediction networks to re-duce the intra-view and inter-view redundancy, respectively.
The existing methods mainly employ a unidirectional cod-ing mechanism to reduce the inter-view redundancy, i.e., the reconstruction [8, 18, 19, 13] or the latent representa-tion [24] of the left image is propagated as a context to the right-view coding branch. Therefore, they follow on the strictly sequential coding order that the left image is ﬁrst encoded and then the right image or vice versa. Such a uni-directional framework, on the one hand, is not always effec-tive to reduce the inter-view redundancy. On the other hand, it is difﬁcult to extend the framework into a bi-directional coding framework that is expected to be more effective in reducing the inter-view redundancy, hence, saving the bi-trate.
To address this issue, this paper proposes an end-to-end stereo image compression network based on bi-directional coding (BCSIC-Net). The main idea of the proposed method is to eliminate the limitation of sequential cod-ing by designing a novel inter-view context dependency, i.e., extending the unidirectional coding mechanism to a bi-directional one. Thus, a bi-directional contextual trans-form module (Bi-CTM) and a bi-directional conditional en-tropy model (Bi-CEM) are proposed. As shown in Fig-ure. 1, compared with the state-of-the-art unidirectional method [13], the proposed BCSIC-Net can achieve higher reconstruction quality with lower bit-consuming.
The major contributions of this paper are summarized as follows. 1) A novel end-to-end stereo image compression net-work based on bi-directional coding (BCSIC-Net) is pro-posed to improve the performance of stereo image compres-sion by effectively exploiting the inter-view correlation. 2) A bi-directional contextual transform module (Bi-CTM) that performs nonlinear transform conditioned on the inter-view context is presented to effectively reduce the re-dundancy between stereo views. 3) A bi-directional conditional entropy model (Bi-CEM) is developed to improve the efﬁciency of entropy coding by exploiting the inter-view correspondence as a conditional prior. 4) Experimental results on popular benchmark datasets show that the proposed method achieves the state-of-the-art coding performance.
The rest of this paper is organized as follows. Section II summarizes the related works of the single image compres-sion and stereo image compression. The proposed method is described in Section III, followed by experimental results and analysis in Section IV. Section V concludes the paper. 2.