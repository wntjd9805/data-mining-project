Abstract
Ground Truth
Ours
Mip-NeRF [2]
Neural Radiance Fields (NeRF) is a popular view syn-thesis technique that represents a scene as a continuous volumetric function, parameterized by multilayer percep-trons that provide the volume density and view-dependent emitted radiance at each location. While NeRF-based tech-niques excel at representing fine geometric structures with smoothly varying view-dependent appearance, they often fail to accurately capture and reproduce the appearance of glossy surfaces. We address this limitation by introduc-ing Ref-NeRF, which replaces NeRF’s parameterization of view-dependent outgoing radiance with a representation of reflected radiance and structures this function using a col-lection of spatially-varying scene properties. We show that together with a regularizer on normal vectors, our model significantly improves the realism and accuracy of specular reflections. Furthermore, we show that our model’s inter-nal representation of outgoing radiance is interpretable and useful for scene editing. 1.

Introduction
Neural Radiance Fields (NeRF) [22] renders compelling photorealistic images of 3D scenes from novel viewpoints using a neural volumetric scene representation. Given any input 3D coordinate in the scene, a “spatial” multilayer per-ceptron (MLP) outputs the corresponding volume density at that point, and a “directional” MLP outputs the outgo-ing radiance at that point along any input viewing direc-tion. Although NeRF’s renderings of view-dependent ap-pearance may appear reasonable at first glance, a close in-spection of specular highlights reveals spurious glossy ar-tifacts that fade in and out between rendered views (Fig-ure 1), rather than smoothly moving across surfaces in a physically-plausible manner.
These artifacts are caused by two fundamental issues with NeRF (and top-performing extensions such as mip-NeRF [2]). First, NeRF’s parameterization of the outgoing radiance at each point as a function of the viewing direction
PSNR↑/MAE↓: 35.6dB/11.5◦ 30.3dB/59.5◦
Figure 1. Ref-NeRF significantly improves normal vectors (top row) and visual realism (remaining rows) compared to mip-NeRF, the previous top-performing neural view synthesis model. Ref-NeRF’s improvements are apparent in rendered frames (Rows 2 & 3), and even more in rendered videos (bottom row epipolar plane images and supplementary video), where its glossy highlights shift realistically across views instead of blurring and fading like mip-NeRF’s. Image PSNR (higher is better) and surface normal mean angular error (lower is better) shown as insets. is poorly-suited for interpolation. Figure 2 illustrates that, even for a simple toy setup, the scene’s true radiance func-tion varies quickly with view direction, especially around specular highlights. As a consequence, NeRF is only able to accurately render the appearance of scene points from
the specific viewing directions observed in the training im-ages, and its interpolation of glossy appearance from novel viewpoints is poor. Second, NeRF tends to “fake” specular reflections using isotropic emitters inside the object instead of view-dependent radiance emitted by points at the surface, resulting in objects with semitransparent or “foggy” shells.
Our key insight is that structuring NeRF’s representa-tion of view-dependent appearance can make the underly-ing function simpler and easier to interpolate. We present a model, which we call Ref-NeRF, that reparameterizes
NeRF’s directional MLP by providing the reflection of the viewing vector about the local normal vector as input in-stead of the viewing vector itself. Figure 2 (left column) illustrates that, for a toy scene comprised of a glossy object under distant illumination, this reflected radiance function is constant across the scene (ignoring lighting occlusions and interreflections) because it is unaffected by changes in surface orientation. Consequently, since the directional
MLP acts as an interpolation kernel, our model is better able to “share” observations of appearance between nearby points to render more realistic view-dependent effects in in-terpolated views. We additionally introduce an Integrated
Directional Encoding technique, and we structure outgoing radiance into explicit diffuse and specular components to allow the reflected radiance function to remain smooth de-spite variation in material and texture over the scene.
While these improvements crucially enable Ref-NeRF to accurately interpolate view-dependent appearance, they rely on the ability to reflect viewing vectors about normal vectors estimated from NeRF’s volumetric geometry. This presents a problem, as NeRF’s geometry is foggy and not tightly concentrated at surfaces, and its normal vectors are too noisy to be useful for computing reflection directions (as shown in the right column of Figure 1). We ameliorate this issue with a novel regularizer for volume density that signif-icantly improves the quality of NeRF’s normal vectors and encourages volume density to concentrate around surfaces, enabling our model to compute accurate reflection vectors and render realistic specular reflections, shown in Figure 1.
To summarize, we make the following contributions: 1. A reparameterization of NeRF’s outgoing radiance, based on the reflection of the viewing vector about the local normal vector (Section 3.1). 2. An Integrated Directional Encoding (Section 3.2) that, when coupled with a separation of diffuse and specu-lar colors (Section 3.3), enables the reflected radiance function to be smoothly interpolated across scenes with varying materials and textures. 3. A regularization that concentrates volume density around surfaces and improves the orientation of
NeRF’s normal vectors (Section 4).
We apply these changes on top of mip-NeRF [2], cur-rently the top-performing neural representation for view
Figure 2. Visualizations of outgoing radiance in NeRF and Ref-NeRF, using 2D position-angle slices of radiance along an x-parameterized surface curve on a glossy object under colored lights. Because NeRF (middle row) uses view angle ϕo as input, when presented with glossy reflectances (left) or spatially-varying materials (right) it must interpolate between highly complicated functions like the irregularly curved colored lines shown here. In contrast, Ref-NeRF (bottom row) parameterizes radiance using a normal vector ˆn and a reflection angle ϕr, and adds diffuse color cd and roughness ρ to its spatial MLP, which collectively makes radiance functions simple to model even for shiny or spatially-varying materials. The gray checkerboard indicates directions be-low the surface at position x. synthesis. Our experiments demonstrate that Ref-NeRF produces state-of-the-art renderings of novel viewpoints, and substantially improves upon the quality of previous top-performing view synthesis methods for highly specular or glossy objects. Furthermore, our structuring of outgoing ra-diance produces interpretable components (normal vectors, material roughness, diffuse texture, and specular tint) that enable convincing scene editing capabilities.
2.