Abstract
Unbiased SGG has achieved signiﬁcant progress over recent years. However, almost all existing SGG models have overlooked the ground-truth annotation qualities of prevail-ing SGG datasets, i.e., they always assume: 1) all the man-ually annotated positive samples are equally correct; 2) all the un-annotated negative samples are absolutely back-ground. In this paper, we argue that both assumptions are inapplicable to SGG: there are numerous “noisy” ground-truth predicate labels that break these two assumptions, and these noisy samples actually harm the training of unbi-ased SGG models. To this end, we propose a novel model-agnostic NoIsy label CorrEction strategy for SGG: NICE.
NICE can not only detect noisy samples but also reassign more high-quality predicate labels to them. After the NICE training, we can obtain a cleaner version of SGG dataset for model training. Speciﬁcally, NICE consists of three compo-nents: negative Noisy Sample Detection (Neg-NSD), posi-tive NSD (Pos-NSD), and Noisy Sample Correction (NSC).
Firstly, in Neg-NSD, we formulate this task as an out-of-distribution detection problem, and assign pseudo labels to all detected noisy negative samples. Then, in Pos-NSD, we use a clustering-based algorithm to divide all positive sam-ples into multiple sets, and treat the samples in the noisiest set as noisy positive samples. Lastly, in NSC, we use a sim-ple but effective weighted KNN to reassign new predicate labels to noisy positive samples. Extensive results on differ-ent backbones and tasks have attested to the effectiveness and generalization abilities of each component of NICE. 1.

Introduction
† Corresponding author. This work started when Long Chen at ZJU.
Codes available at: https://github.com/muktilin/NICE.
Scene Graph Generation (SGG), i.e., detecting all object instances and their pairwise visual relations, is a crucial step
towards comprehensive visual scene understanding. In gen-eral, each scene graph is a visually-grounded graph, where each node and edge refer to an object and visual relation, re-spectively. Recently, with the release of several large-scale
SGG benchmarks (e.g., Visual Genome (VG) [15]) and ad-vanced object detectors [28, 1, 35], SGG has received un-precedented attention [7]. However, due to the composi-tional nature of pairwise visual relations, the number distri-butions of different triplets in SGG datasets are much more imbalanced (i.e., long-tailed) than other recognition tasks.
Accordingly, the performance of many state-of-the-art SGG models [42, 2, 32, 23] degrades signiﬁcantly on the tail cat-egories1 compared to the head categories counterparts.
Currently, the mainstream solutions to mitigate the long-tailed problem in SGG can be coarsely categorized into two types: 1) Re-balancing strategy: It utilizes class-aware sam-ple re-sampling or loss re-weighting to balance the propor-tions of different predicate categories in the network train-ing. The former attempts to balance the number of training samples in instance-level2 or image-level [17], and the latter leverages prior commonsense knowledge (e.g., frequency of predicates [22], predicate correlations [39], or rule-based predicate priority [23, 14]) to re-weight the contributions of different categories in loss calculations. 2) Biased-model-based strategy: It inferences debiased predictions from pre-trained biased SGG models. For instance, using counterfac-tual causality to disentangle frequency biases [31], deriving more balanced loss weights for different predicates [41], or adjusting the probabilities of predicate predictions [4].
Although these methods have dominated performance on debiasing metrics (e.g., mean Recall@K), it is worth noting that almost all existing models have taken two plausible as-sumptions about the ground-truth annotations for granted:
Assumption 1: All the manually annotated positive sam-ples are equally correct.
Assumption 2: All the un-annotated negative samples are absolutely background.
For the ﬁrst assumption, by “equally”, we mean that the conﬁdence (or quality) of annotated ground-truth predicate label for each positive sample2 is the same as others, i.e., all positive predicate labels are of high quality. Unfortunately, unlike other close-set classiﬁcation tasks where each sample has only a unique ground-truth label, a subject-object pair in SGG sometimes has multiple reasonable predicates. This phenomenon has led to two inevitable annotation charac-teristics in SGG datasets: 1) Common-prone: When these reasonable relations are in different semantic granularities, 1For brevity, we directly use “tail”, “body”, and “head” categories to represent the predicate categories in the tail, body, and head parts of the number distributions of different predicates in SGG datasets, respectively. 2We use “instance” to denote an instance of visual relation triplet, and we also use “sample” to represent the triplet instance interchangeably. the annotators tend to select the most common predicate (or coarse-grained) as ground-truth. As shown in Figure 1(a), both riding and on are “reasonable” for man and bike, but the annotated ground-truth predicate is less informative on instead of more convincing riding. And this charac-teristic is very common in SGG datasets (more examples in
Figure 1(a)). 2) Synonym-random: When these reasonable relations are synonymous for the subject-object pair, the an-notators usually randomly choose one predicate as ground-truth, i.e., the annotations for some similar visual patterns are inconsistent. For example, in Figure 1(b), both has and with denote “be dressed in” for man/woman and shirt, but the ground-truth annotations are inconsistent even in the same image. We further visualize thousands of sampled in-stances of (cid:2)man-has / with-shirt(cid:3) in VG, and these in-stances are all randomly distributed in the feature space (cf.
Figure 1(b)). Thus, we argue that all the positive samples are NOT equally correct, i.e., a part of positive samples are not high-quality — their labels can be more ﬁne-grained (cf. common-prone) or more consistent (cf. synonym-random).
For the second assumption, although all SGG works have agreed that visual relations in existing datasets are always sparsely identiﬁed and annotated [25] (Figure 1(c)), almost all of them still train their models by regarding all the un-annotated pairs as background, i.e., there is no visual re-lation between the subject and object. In contrast, we argue that all negative samples are NOT absolutely background, i.e., a part of negative samples are not high-quality — they are actually foreground with missing annotations.
In this paper, we try to get rid of these two questionable assumptions, and reformulate SGG as a noisy label learning problem. To the best of our knowledge, we are the ﬁrst work to take a deep dive into the ground-truth annotation qualities of both positive and negative samples in SGG. Speciﬁcally, we propose a novel model-agnostic NoIsy label CorrEction strategy, dubbed as NICE. NICE can not only detect numer-ous noisy samples, but also reassign more high-quality pred-icate labels to them. By “noisy”, we mean that these sam-ples break these two assumptions. After the NICE training, we can obtain a cleaner version of dataset for SGG training.
Particularly, we can: 1) increase the number of ﬁne-grained predicates (common-prone); 2) decrease annotation incon-sistency among similar visual patterns (synonym-random); 3) increase the number of positive samples (assumption 2).
NICE consists of three components: negative noisy sam-ple detection (Neg-NSD), positive noisy sample detection (Pos-NSD), and noisy sample correction (NSC). Firstly, in
Neg-NSD, we reformulate the negative NSD as an out-of-distribution (OOD) detection problem, i.e., regarding all the positive samples as in-distribution (ID) training data, and all the un-annotated negative samples as OOD test data. In this way, we can detect the missing annotated (ID) samples with pseudo labels. Then, in Pos-NSD, we use a clustering-based
algorithm to divide all positive samples (including the out-puts of Neg-NSD) into multiple sets, and regard samples in the noisiest set as noisy positive samples. The clustering re-sults are based on the local density of each sample. Lastly, in NSC, we use a simple but effective weighted KNN to reassign new predicate labels to all noisy positive samples.
We evaluate NICE on the most prevalent SGG bench-mark: VG [15]. Since NICE only focuses on reﬁning noisy annotations of the dataset, it can be seamlessly incorporated into any SGG architecture to boost their performance. Ex-tensive ablations have attested to the effectiveness and gen-eralization abilities of each component of NICE.
In summary, we make three contributions in this paper: 1. We are the ﬁrst to reformulate SGG as a noisy label learn-ing problem, and point out the two plausible assumptions are not applicable for SGG, i.e., the devil is in the labels. 2. We propose a novel model-agnostic strategy NICE. Ex-tensive ablations on several baselines, tasks, and metrics have demonstrated its excellent generalization abilities. 3. Each part of NICE can serve as an independent plug-and-play module to improve SGG annotation qualities3. 2.