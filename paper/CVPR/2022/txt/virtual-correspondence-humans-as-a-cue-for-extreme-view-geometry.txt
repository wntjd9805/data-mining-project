Abstract 1.

Introduction
Recovering the spatial layout of the cameras and the geometry of the scene from extreme-view images is a long-standing challenge in computer vision. Prevailing 3D re-construction algorithms often adopt the image matching paradigm and presume that a portion of the scene is co-visible across images, yielding poor performance when there
In contrast, humans can is little overlap among inputs. associate visible parts in one image to the corresponding invisible components in another image via prior knowledge of the shapes. Inspired by this fact, we present a novel con-cept called virtual correspondences (VCs). VCs are a pair of pixels from two images whose camera rays intersect in 3D. Similar to classic correspondences, VCs conform with epipolar geometry; unlike classic correspondences, VCs do not need to be co-visible across views. Therefore VCs can be established and exploited even if images do not overlap. We introduce a method to ﬁnd virtual correspondences based on humans in the scene. We showcase how VCs can be seamlessly integrated with classic bundle adjustment to re-cover camera poses across extreme views. Experiments show that our method signiﬁcantly outperforms state-of-the-art camera pose estimation methods in challenging scenarios and is comparable in the traditional densely captured setup.
Our approach also unleashes the potential of multiple down-stream tasks such as scene reconstruction from multi-view stereo and novel view synthesis in extreme-view scenarios1. 1Project page: https : / / people . csail . mit . edu / weichium/virtual-correspondence/
Epipolar geometry and correspondence estimation are two keystones of mainstream 3D reconstruction systems.
When given a set of RGB images as input, a classic 3D pipeline [34, 53] ﬁrst identiﬁes co-visible 3D points across images via pixel-wise visual features, and then recovers the spatial relationships among cameras. Such a “golden stan-dard” framework has experienced huge success in practice and has given birth to numerous applications in robotics,
AR, VR, etc. The reliance on correspondences, however, makes one ponder: what if the input images have little or no overlap? Does this still work when there are barely any co-visible 3D points in the scene (see Fig. 1)?
At ﬁrst thought the answer is no. Predominant correspon-dence estimators focus on ﬁnding pixel pairs that describe the same, co-visible 3D points in the scene by matching their visual features. If the viewpoint differences across images are extreme, the pixels will be inherently different and cannot be matched, rendering current 3D systems to fail catastrophically. In contrast, humans can identify where the two photographs were taken with respect to the scene despite the large viewpoint variations. Such a remarkable capability comes from our prior knowledge of the underlying geometry, which helps us match pixels between images even if their exact correspondences are occluded or invisible in the other image. For instance, we know how the front and back of a human body should look like. Therefore, if we see a human face in one image and the back of a head in the other, we can easily associate them and infer that the two cameras are roughly 180 degrees apart. The aim of this paper is to equip 3D systems with similar abilities.
Towards this goal, we ﬁrst ask the following question:
do we have to rely on pixels describing the same 3D points to recover camera poses2? While such (implicit) premises seem to lay the foundation for existing 3D reconstruction algorithms, as we will show in Sec. 3, the answer is negative.
Our key observation is that epipolar geometry holds for ar-bitrary pixels whose camera rays intersect in 3D. Therefore, so long as one can identify those pixels, one can leverage them to recover relative camera poses, regardless of whether the pixels are semantically or visually similar or not. This interpretation is particularly exciting, as it allows one to go beyond the image space and establish geometric relation-ships among pixels even from extreme viewpoints.
Unfortunately, determining whether two camera rays in-tersect in 3D often requires camera poses to be known a priori, making the whole process a chicken-and-egg problem.
Our key idea is to exploit prior knowledge of the foreground objects within the scene to break the loop. Speciﬁcally, we make use of humans, arguably one of the most common, salient “objects” in images. Consider the images in Fig. 1. If the system has prior knowledge about human shape and pose, it will know that a ray shooting through the human back in the leftmost image will intersect with the chest region on its way out. Furthermore, the intersecting chest pixel can be observed in the other image. Thus, we can ﬁnd a pair of pixels that correspond to two intersecting camera rays with ease. Note that different from classic correspondences, these two pixels do not depict the same 3D point and thus cannot be found via visual similarities. Since we establish the geometric connection virtually by hallucinating a 3D shape, we call them virtual correspondences (VCs).
With this inspiration in mind, we ﬁrst deﬁne virtual corre-spondences and present a methodology to derive them from images containing humans. We then showcase how VCs can be seamlessly integrated with the classic bundle adjustment algorithm, resulting in a generalized structure from motion (Sf M) framework that could be applied to both traditional setup and extreme-view scenarios. We evaluate the effective-ness of our approach on the CMU Panoptic dataset [40, 42], the Mannequin Challenge dataset [51], and multiple chal-lenging in-the-wild images. Our method signiﬁcantly outper-forms prior art in challenging extreme-view scenarios and is comparable in the conventional, densely overlapping setup.
Importantly, our estimated poses from extreme viewpoints unleash the potential of multiple downstream applications such as scene reconstruction from multi-view stereo and novel view synthesis in challenging scenarios.
In summary, we make the following contributions: 1. We present virtual correspondences, a novel concept for 3D reconstruction algorithms, and establish its geo-metric connection to existing correspondences. 2. We develop a method to estimate VCs from images with humans and showcase how to integrate them into 2We will ignore other primites such as lines or planes for now.
Classic correspondences
Virtual correspondences
Available when scene  overlap is large
Fail to establish correspondences  when scene overlap is little
Available regardless of viewpoints. 
Semantics, appearances can differ.
Figure 2. Classic correspondences vs. virtual correspondences. existing 3D frameworks. The new framework can be applied to a wide range of scenarios while also reduces to the classical Sf M when no VCs are found. 3. We exploit the estimated camera poses for multiple downstream tasks and empirically show that our method enables extreme-view scenarios that were not feasible. 2.