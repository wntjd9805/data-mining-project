Abstract
Learning semantic segmentation from weakly-labeled (e.g., image tags only) data is challenging since it is hard to infer dense object regions from sparse semantic tags. De-spite being broadly studied, most current efforts directly learn from limited semantic annotations carried by individ-ual image or image pairs, and struggle to obtain integral localization maps. Our work alleviates this from a novel perspective, by exploring rich semantic contexts synergis-tically among abundant weakly-labeled training data for network learning and inference. In particular, we propose regional semantic contrast and aggregation (RCA) . RCA is equipped with a regional memory bank to store massive, di-verse object patterns appearing in training data, which acts as strong support for exploration of dataset-level semantic structure. Particularly, we propose i) semantic contrast to drive network learning by contrasting massive categorical object regions, leading to a more holistic object pattern un-derstanding, and ii) semantic aggregation to gather diverse relational contexts in the memory to enrich semantic repre-sentations. In this manner, RCA earns a strong capability of ﬁne-grained semantic understanding, and eventually es-tablishes new state-of-the-art results on two popular bench-marks, i.e., PASCAL VOC 2012 and COCO 2014. 1.

Introduction
Semantic segmentation continues to be a fundamental task in computer vision, with numerous applications in au-tonomous driving, robotics, human-computer interactions and medical imaging analysis. While fully supervised sys-tems have achieved tremendous progress, they are limited by the availability of pixel-level annotations, often har-vested at great cost, even with smart interfaces [3]. Weakly supervised semantic segmentation (WSSS) alternatively in-vestigates whether this task can be adequately addressed with efﬁcient and weak supervisory signals (e.g., image labels [2, 25, 37, 66], scribbles [39, 40, 54], bounding boxes [14, 34, 44, 51]). This work studies the form of image-level labels which can be obtained effortlessly, and
∗ Equal contributions; † Corresponding author: Jianwu Li. (e.g., [2, 25, 35, 59, 66, 71]) (e.g., [17, 37, 52])
Figure 1. The main idea promoted throughout the paper is that semantic contexts subserve localization of individual objects in
WSSS. Our RCA thus performs dataset-level relation learning (c) to mine rich contextual knowledge from massive (ideally all) train-ing samples, rather than from an individual image (a) or image pair (b). This enables our model to procure in-depth semantic pattern understanding, improving object localization eventually. thus have been widely embraced in mainstream approaches.
In the absence of the true “image label” to “object re-learning to map gion” correspondence in training data, visual concepts to pixel regions is particularly challeng-i.e., class activation mapping ing. The seminal work, (CAM) [81], solves this by mining regions from internal activation of an image classiﬁer. However, the technique is prone to give sparse and incomplete object estimations, since the classiﬁer is only driven to activate a small pro-portion of features with strong discriminative capability. To address this, a prevalent of subsequent efforts strive to learn more complete object regions by, e.g., region growing to ex-pand initial responses [24, 30, 60], adversarial erasing in a hide-and-seek fashion [23, 32, 33, 64], feature enrichment to collect within-image contexts [66, 72], seeking auxiliary saliency supervisions [35, 71, 74], or self-supervised learn-ing with pre-designed pretext tasks [6, 47, 63].
Though impressive, these methods use only single-image information for object localization (Fig. 1 (a)), ne-Image-level glecting inter-image contextual information. labels not only tell the categories appearing in each indi-vidual image, but also unveil the semantic structure of all
images in the dataset. For each concept (i.e., cat in Fig. 1), the dataset contains numerous semantically similar but vi-sually different instances; for any two different concepts (e.g., cat and dog), all their instances are semantically different, even though some may look very similar with each other. This a priori knowledge should be exploited to gain more accurate semantic pattern understanding. Though some preliminary attempts [17, 52, 80, 83] have been made towards this (Fig.1(b)), they focus on pairwise [17, 52, 80] or quadruplet [83] context modeling in a limited number of images, and thus cannot guarantee a sufﬁcient understand-ing of holistic semantic patterns in the entire dataset.
In addition, all these methods favor pixel-wise relation model-ing, which is rather difﬁcult due to the lack of proper super-visory signal and causes prohibitive computation cost.
Motivated by above analysis, we propose regional se-mantic contrast and aggregation (RCA) to maximally ex-ploit contextual knowledge in visual data (Fig. 1 (c)), aiming for comprehensive object pattern learning as well as effec-tive CAM inference. In lieu of pixel-level relation modeling in [17, 52, 83], RCA prefers region-aware representations that are more efﬁcient and robust to noises. In particular, for each mini-batch image, we divide it into categorical pseudo regions according to an intermediate, coarse CAM, which is learned under the supervision of its single-image label. For each pseudo region, RCA establishes its relations to regions in all other images to facilitate dataset-level semantic con-text learning. For feasible computations, we associate RCA with a continuously-updated memory bank, which collects and preserves meaningful region semantics in the dataset as the training goes, and is applicable to both network learn-ing and inference phases. During training, RCA explores semantic relations of regions in each mini-batch and the memory bank from two novel perspectives:
• Semantic contrast, which lets the model learn to discrim-inate all possible object regions in the dataset, promot-ing more holistic object pattern understanding. Particu-larly, for each pseudo region, semantic contrast enforces the network to pull its embedding close to memory em-beddings of the same category and push apart those of different. Such a contrastive property well complements the classiﬁcation objective (for each single image) to im-prove object representation learning.
• Semantic aggregation, which allows the model to gather dataset-level contextual knowledge to yield more mean-ingful object representations. This is achieved via a non-parametric attention module which summarizes memory representations for each image independently. In com-parison with conventional intra-image context learning schemes [12, 73], our semantic aggregation focuses on inter-image context mining, and thus is able to capture more informative dataset-level semantics.
These two context modeling schemes are indispensable to our model. Semantic contrast helps the network to learn more structured object embedding space from a holistic view, while semantic aggregation focuses on improving fea-ture representations of each image by collecting diverse se-mantic contexts. In addition, semantic contrast is essential to maintain unique and informative memory embeddings, which is a prerequisite to yield reliable semantic aggrega-tion. These two components work together to make RCA a powerful WSSS model (see Table 1). Our RCA is ﬂexible and can be easily incorporated into existing WSSS models.
It shows consistently improved segmentation performance on challenging datasets (i.e., PASCAL VOC 2012 [15] and
COCO 2014 [41]), on top of state-of-the-art WSSS models (i.e., OAA+ [25], EPS [35]).
Main Contributions. i) We study an essential yet long-ignored problem in WSSS to explore rich contexts among weakly labeled training data for network learning. This essentially narrows the gap between image-level semantic concepts and pixel-level object regions. Technically, ii) we introduce a robust contrastive learning algorithm for seman-tic contrast, which is able to learn effective representations from imperfect, pseudo region features, as well as iii) a non-parametric attention model for semantic aggregation to col-lect rich contextual knowledge from the entire dataset . 2.