Abstract
Estimating keypoint scale and orientation is crucial to extracting invariant features under significant geometric changes. Recently, the estimators based on self-supervised learning have been designed to adapt to complex imaging conditions. Such learning-based estimators generally pre-dict a single scalar for the keypoint scale or orientation, called hard estimators. However, hard estimators are dif-ficult to handle the local patches containing structures of different objects or multiple edges. In this paper, a Soft Self-Supervised Estimator (S3Esti) is proposed to overcome this problem by learning to predict multiple scales and orien-tations. S3Esti involves three core factors. First, the esti-mator is constructed to predict the discrete distributions of scales and orientations. The elements with high confidence will be kept as the final scales and orientations. Second, a probabilistic covariant loss is proposed to improve the con-sistency of the scale and orientation distributions under dif-ferent transformations. Third, an optimization algorithm is designed to minimize the loss function, whose convergence is proved in theory. When combined with different keypoint extraction models, S3Esti generally improves over 50% ac-curacy in image matching tasks under significant viewpoint changes. In the 3D reconstruction task, S3Esti decreases more than 10% reprojection error and improves the number of registered images. [code release] 1.

Introduction
Keypoint-based image matching is one of the fundamen-tal problems in many applications such as image mosaic
[13], camera pose estimation [6], 3D reconstruction [15] and visual localization [14]. High matching accuracy re-quires the keypoint feature invariant to different imaging conditions [24]. However, it is challenging to maintain the invariance under significant geometric changes [21, 35].
An intuitive solution is to estimate the geometric change parameters and rectify the local image patches. Many ex-isting works [3, 30, 41] demonstrate that keypoint scale and orientation can effectively represent the local geomet-ric changes because the scaling and rotation transformations generally dominate the geometric changes in a local region.
Moreover, more accurate scales and orientations generally induce higher keypoint matching accuracy [28, 38]1. The hand-crafted methods typically estimate the scale and orien-tation with the analyses of gradients in the local region [5].
Some predict only one scale/orientation for a patch [32], termed as hard estimators in this paper.
The existing works [8, 22] demonstrate that predicting a single scale/orientation is not robust for some patches. Such patches generally contain structures of different objects or multiple edges, termed as composite-pattern patches in this paper. Fig. 1 shows the example patches containing differ-ent objects (a solar panel and a wall), involving at least two significant edges. A hard estimator is difficult to provide robust results for the composite-pattern patch because the most significant orientation (or scale) may be switched after an image transformation. Concerning this problem, some hand-crafted models [1, 3, 22] are constructed to predict multiple scales or orientations, which are termed as soft es-timators. For example, SIFT first measures the confidences of different orientations based on the histogram of oriented gradients, and then keeps at most two orientations with high confidences. Experiments demonstrate that soft estimators can generally provide more robust predictions [4, 22].
However, the existing hand-crafted estimators are not ro-bust to the complex scenes involving illumination changes or inessential patterns because the image gradients are sen-sitive to these interferences [41]. A failed result is shown in Fig. 1 (a). Recently, some learning-based models have
*Yihua Tan and Yansheng Li are corresponding authors.
The code is available at https://github.com/elvintanhust/S3Esti. 1The experimental evidence is shown in Supplementary Section 8.
Figure 1. Rectify image patches with the scales and orientations predicted by different estimators. In this example, each estimator predicts one or two pairs of scale and orientation. Every scale&orientation pair is used to resize and rotate the original patch, and the obtained patch is termed as a rectified patch. A good estimator should make the rectified patches as similar as possible if the original patches are centered at the same scene point. (a) The scales and orientations of SIFT are sensitive to illumination changes. Even though multiple predictions are kept, the rectified patches are not similar enough. (b) The learning-based CovDet can predict only one scale and orientation. It is difficult to provide robust predictions for the composite-pattern patch, making the rectified patches dissimilar. (c) The proposed S3Esti is a soft learning-based estimator that can predict multiple scales&orientations robust to illumination changes. S3Esti is more likely to get consistent scales and orientations. So it can still provide similar rectified patches under significant geometric changes. been constructed to improve the adaptiveness for complex scenes. The existing learning-based estimators [18] are gen-erally regression models that output one scalar prediction for a keypoint scale or orientation. The scalar formula-tion can hardly provide the confidences for multiple po-tential scales/orientations [11, 27], making the soft estima-tion strategy hard to be applied. Therefore, the existing learning-based models are hard estimators that are not ro-bust to composite-pattern patches. The failed result in Fig. 1 (b) also demonstrates this problem.
This paper is motivated to design a soft learning-based estimator to integrate twofold advantages: the ability to pre-dict multiple scales/orientations, and the data-driven adap-tiveness for complex scenes. The proposed Soft Self-Supervised Estimator (S3Esti) is implemented as a convo-lutional neural network (CNN) [36] that is fed a local patch and outputs two confidence vectors. Each element of the vectors represents the confidence of a discretized scale or orientation. Some outputs of S3Esti are shown in Fig. 1 (c).
The existing loss functions are not suitable for such vector-ized outputs because they are designed for scalar prediction.
There are two difficulties in designing the loss function and optimization algorithm for S3Esti. First, S3Esti is a classification model for the discretized scales/orientations, but the scale/orientation labels are hard to be determined
[18, 41]. Therefore, this paper formulates the labels as la-tent discrete distributions and integrates them into a novel probabilistic covariant loss. This loss can be considered as a probabilistic variant of the loss in [18].
Second, it is inefficient to update the latent scale and ori-entation labels with a pure gradient descent (GD) algorithm.
Intuitively, there will be M independent scale and orienta-tion labels for a training set containing M patches. As la-bels are unknown, GD algorithms initialize them randomly and update them with gradients. Every latent label is up-dated only once per epoch because each patch appears in only one mini-batch. This update frequency is low because the randomly initialized labels are inaccurate and the mini-batch gradients are noise. This paper designs an alternate optimization algorithm to search the optimal latent labels for the current parameters of CNN estimators.
Overall, the contributions of this paper are threefold: (1) A soft self-supervised estimator is proposed to pre-dict multiple scales and orientations for composite-pattern patches. Experiments demonstrate that S3Esti can provide more accurate results than the existing estimators. (2) A loss function named probabilistic covariant loss is de-signed for S3Esti, making the scale/orientation predictions consistent under different geometric changes. (3) An alternate optimization algorithm is designed by it-eratively searching the latent scale&orientation labels and updating the neural network parameters.
2.