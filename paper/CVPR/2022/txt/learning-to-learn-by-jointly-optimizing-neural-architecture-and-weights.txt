Abstract
Meta-learning enables models to adapt to new envi-ronments rapidly with a few training examples. Current gradient-based meta-learning methods concentrate on find-ing good model-agnostic initialization (meta-weights) for learners. In this paper, we aim to obtain better meta-learners by co-optimizing the architecture and meta-weights simulta-neously. Existing NAS-based meta-learning methods apply a two-stage strategy, i.e., first searching architectures and then re-training meta-weights on the searched architecture. How-ever, this two-stage strategy would break the mutual impact of the architecture and meta-weights since they are optimized separately. Differently, we propose progressive connection consolidation, fixing the architecture layer by layer, in which the layer with the largest weight value would be fixed first.
In this way, we can jointly search architectures and train the meta-weights on fixed layers. Besides, to improve the gener-alization performance of the searched meta-learner on all tasks, we propose a more effective rule for co-optimization, namely Connection-Adaptive Meta-learning (CAML). By searching only once, we can obtain both adaptive archi-tecture and meta-weights for meta-learning. Extensive ex-periments show that our method achieves state-of-the-art performance with 3x less computational cost, revealing our method’s effectiveness and efficiency. 1.

Introduction
As a popular solution for the few-shot learning problem1, meta-learning develops deep learning models with the ability to fit unseen tasks using only a few training examples [6, 30, 37]. Particularly, the gradient-based meta-learning methods like MAML [6] attempt to find a set of initialization of models’ weights (meta-weights). The model with meta-weights can produce good generalization performance on an unseen task quickly with only a few gradient steps.
In addition, to obtain the optimized meta-weights, it’s also vital to find better architectures good at meta-learning. Unlike previous methods built on hand-crafted architectures, we aim to obtain better meta-learners by enriching architecture flexibility via Neural Architecture Search (NAS).
In this work, our target is to find optimal architecture and meta-weights for a meta-learner which can quickly adapt to new tasks with a few training samples. We represent the candidate operations (e.g., conv and pooling) in each layer as connections. Each of them is weighted by an attention value over all candidate operations in the same layer, which is called connection parameters. Larger values mean more important operations/connections and we call each layer’s adaptive connection as meta-connections. Thus the adaptive architecture is composed of meta-connections, and the train-ing process can be regarded as a co-optimization problem of the connection parameters and the network weights.
There have been some recent works focusing on the ex-ploration of architecture impact in meta-learning [10, 15].
However, most of these works either fall into the dilemma of breaking the mutual impact between the architecture and meta-weights or optimize the learner with a biased updating rule. First, both Auto-Meta [10] and Auto-MAML [15] apply a two-stage training strategy that obtains architectures and meta-weights separately, i.e., first searching architec-tures and then retraining meta-weights using the searched architecture, as illustrated in Figure 1 (b). As mentioned in the lottery ticket hypothesis [7], sub-networks pruned from the supernet2 cannot get optimized effectively unless they are initialized with the supernet’s network weights. It inspires us that architectures and network weights have a mutual impact on each other. Therefore, in NAS-based meta-learning, we need to preserve the mutual impact between the architecture
*Siliang Tang is the corresponding author. 1A N -way, K-shot task denotes K samples from each class and N classes in few-shot learning. 2A supernet is a neural network whose layers consist of more than one candidate operation (e.g., convolution, pooling). When searching finished, each layer is pruned, leaving one specific operation at most.
Figure 1. (a) MAML focuses on the model-agnostic meta-weights. (b) The current NAS-based meta-learning methods consist of two stages.
The fixed architectures and their meta-weights are obtained separately, overlooking the mutual impact between them. (c) By co-optimizing the architecture and meta-weights, our method can simultaneously obtain adaptive architecture and meta-weights for all unseen tasks, requiring 3x less computational cost. and meta-weights. Nevertheless, during the searching phase,
Auto-Meta [10] and Auto-MAML [15] could only obtain the architecture with non-matched meta-weights. The matched meta-weights are acquired based on the searched architecture in the second stage (the re-training stage). Thus, the architec-ture and meta-weights of existing works are trained one by one (separately) instead of jointly optimized, breaking the mutual impact between the architecture and meta-weights.
Second, to co-optimize the architecture parameters and net-work weights, Auto-MAML [15] proposed one simple so-lution called One-Propagation NAS-Based Meta-Learning (OPML) [5, 15], as illustrated in Figure 3. For simplicity,
OPML treats the connection parameters and network weights equally and updates them by one backpropagation in every iteration. Nevertheless, due to the unequal learning rates, the meta-learner’s real update direction is not parallel to the cal-culated meta-gradient, which may harm the generalization performance of meta-learner on all tasks.
To preserve the mutual impact between the architecture and meta-weights, we propose progressive connection con-solidation, as shown in Figure 1 (c). During searching, we prune the supernet layer by layer, in which the layer with the largest connection weight value will be consolidated first. As the connections get fixed gradually, we can train the matched meta-weights on these consolidated connections.
In return, the meta-weights would further affect the update of the other unfixed connections. In this way, we continu-ously preserve the mutual impact of the meta-connections and meta-weights during the entire training phase. Mean-while, we remove the update of the pruned connections and weights and avoid retraining the derived architecture from scratch, saving 66% computational cost. To update the meta-learner in an un-biased way, we propose Connection-Adaptive Meta-Learning (CAML), as demonstrated in Fig-ure 2.(b). By backpropagating twice and updating alter-nately, CAML can optimize both the connection parameters and network weights using the same update direction as the meta-gradients’, respectively. Thus, CAML improves the searched meta-learner’s generalization performance on all tasks, which is essential in meta-learning. Our contributions are summarized as follows:
• To address the two-stage strategy’s separate optimiza-tion problem, we propose progressive connection con-solidation to gradually prune the supernet during searching, preserving the mutual impact of the meta-connections and meta-weights.
• We propose a more effective method, namely
Connection-Adaptive Meta-Learning (CAML), which can improve the generalization performance of the opti-mal architecture and meta-weights on all tasks.
• Extensive experiments show that our method achieves state-of-the-art performance on both FC100 and Mini-Imagenet datasets under various settings with 3x less computational cost, revealing the effectiveness and effi-ciency of our method. 2.