Abstract
We propose WarpingGAN, an effective and efficient 3D point cloud generation network. Unlike existing methods that generate point clouds by directly learning the mapping functions between latent codes and 3D shapes, Warping-GAN learns a unified local- warping function to warp multi-ple identical pre- defined priors (i.e., sets of points uniformly distributed on regular 3D grids) into 3D shapes driven by local structure- aware semantics. In addition, we also in-geniously utilize the principle of the discriminator and tai-lor a stitching loss to eliminate the gaps between differ-ent partitions of a generated shape corresponding to dif-ferent priors for boosting quality. Owing to the novel gen-erating mechanism, WarpingGAN, a single lightweight net-work after one- time training, is capable of efficiently gen-erating uniformly distributed 3D point clouds with vari-ous resolutions. Extensive experimental results demonstrate the superiority of our WarpingGAN over state- of- the- art methods in terms of quantitative metrics, visual quality, and efficiency. The source code is publicly available at https://github.com/yztang4/WarpingGAN.git. 1.

Introduction 3D point clouds have been employed in various ap-plications, such as computer-aided design [11, 13], aug-This work was supported by the HK RGC Grant CityU 11202320 and 11218121. Corresponding author: J. Hou.
*Equal Contributions mented/virtual reality [16], animation [9, 27], and immer-sive telepresence [21]. However, obtaining 3D point cloud data is still costly and time-consuming in realistic scenarios, especially the shapes with complex geometry and topology.
Besides, the acquired point clouds with 3D sensing devices are usually incomplete and sparse due to occlusions, dis-tances, and surface materials. The great success of gener-ative adversarial network (GAN)-based 2D image genera-tion [4, 6, 31] makes synthesizing realistic-looking 3D point clouds promising, i.e., generating point clouds whose sta-tistical distribution is similar to real point clouds. However, the essentially different data modality as well as the unique characteristics of 3D point clouds, i.e., the irregular struc-ture and unorderness, makes it non-trivial to extend GAN-based methods for generating 2D images to 3D point cloud generation.
Recently, several works on 3D point cloud generation have been proposed [1, 10, 12, 15, 20, 22, 26, 28]. For ex-ample, GAN-based methods [1, 10, 20, 22, 26] usually use multi-layer perceptrons (MLPs) as generators to directly learn mapping functions between latent codes and 3D point clouds, which require a large number of parameters to fit.
Moreover, as the adversarial learning mechanism cannot impose strong constraints on global shapes and local ge-ometric details, these approaches tend to generate non-uniformly distributed point clouds, as illustrated in Fig. 2.
Yang et al. [28] and Luo et al. [17] considered 3D point cloud generation as probabilistic problems, which first sam-ple points from a Gaussian space and then move them to the
(a) TreeGAN (b) PDGN (c) SP-GAN (d) WarpingGAN
Figure 2. Visual comparisons of the point clouds generated by different GAN-based methods. target position by learning the distribution transformation.
However, these methods generate blurry point clouds with-out clear global shapes and local details, since they tend to estimate the average distribution of training data. In addi-tion to the limited quality, existing methods also suffer from low efficiency because time-consuming k nearest neighbor (kNN) search is adopted in PDGN [10] and SP-GAN [15], a progressive generation process is utilized in TreeGAN [20] and PDGN [10], and a two-stage training strategy is re-quired in ShapeGF [5], which also prohibits the end-to-end optimization.
To address the above-mentioned issues, we propose
WarpingGAN, which introduces a novel mechanism for
GAN-based 3D point cloud generation. By taking advan-tage of multiple 3D uniform priors, i.e., sets of points uni-formly located on a unit 3D cube, WarpingGAN formu-lates the generation process as the learning of a function that warps multiple 3D priors into different local regions of a 3D shape under the guidance of local structure-aware semantics, which is fundamentally different from existing methods that directly learn the process of producing a fixed number of points from the latent code. Meanwhile, we tailor a stitching loss, which minimizes the local differ-ence between generated and real point clouds, to shrink the gaps between different partitions. Such a new mechanism makes WarpingGAN featured with compactness and high efficiency. Also, it enables WarpingGAN to generate point clouds with various numbers of points after one-time train-ing. Besides, the uniformity of the 3D priors can implic-itly regularize WarpingGAN to some extent to promote the generation of uniformly distributed point clouds, as shown in Fig. 2.
In summary, we make the following contributions:
• we investigate the GAN-based 3D point cloud genera-tion from the new perspective of unified local- warping, leading to WarpingGAN featured with lightweight, high efficiency, and flexible output; and
• by taking advantage of the inherent design of the dis-criminator without introducing additional complex op-erations, we propose a stitching loss tailored to Warp-ingGAN to boost the generator; and
• we conduct extensive experiments and analysis to demonstrate the superiority of WarpingGAN over state-of-the-art methods. 2.