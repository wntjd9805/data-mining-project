Abstract tectures.
Much of the recent progress in 3D vision has been driven by the development of specialized architectures that incor-porate geometrical inductive biases. In this paper we tackle 3D reconstruction using a domain agnostic architecture and study how to inject the same type of inductive biases directly as extra inputs to the model. This approach makes it possi-ble to apply existing general models, such as Perceivers, on this rich domain, without the need for architectural changes, while simultaneously maintaining data efﬁciency of bespoke models. In particular we study how to encode cameras, projective ray incidence and epipolar geometry as model inputs, and demonstrate competitive multi-view depth estimation performance on multiple benchmarks. 1.

Introduction
The focus of modern computer vision research is, to a large extent, to identify good architectures for each task of interest. There are many tasks of interest, ranging from clas-sical ones such as optical ﬂow [19], to highly specialized (yet arguably important) ones such as recognizing equine action units [31]. Creating dedicated models for every pos-sible task naturally results in a sprawling catalog of archi-∗Work done during internship at DeepMind.
Eventually it seems desirable to build a more general vi-sual system that can deal with most perceptual problems. To get there, one option is to combine state-of-the-art systems for all of those problems, but this would be complex, inel-egant and not scalable. Another option is to employ mod-els without much customization or inductive biases for any particular task, but these models will by deﬁnition be less data-efﬁcient and hence less accurate than specialized ones given a ﬁxed data budget.
In this paper we explore the single-general-model route.
We ask the following question: can the lack of architecture-level inductive biases be replaced by extra inputs which en-code our knowledge about the problem structure? In other words, can we feed those priors as inputs rather than hard-wire them into the model architecture (Fig. 1), like a load-able software solution instead of a more rigid hardware so-lution. As the general model we employ the recently pub-lished Perceiver IO [23] and as domain we focus on multi-view geometry and 3D reconstruction, an area of computer vision where architectural specialization is particularly ex-uberant [20, 22, 30, 36, 44, 66, 69].
Our main contribution is in mapping out and evaluating some of the options for expressing priors for 3D reconstruc-tion as input features, in particular in the setting of depth estimation from stereo image pairs. We consider concepts in multiview geometry such as camera viewpoint, light ray
direction and epipolar constraints. Similar to the prior work we compare with [20, 22, 30, 56], we assume ground truth cameras are given, but they could in principle be computed by the model as well and passed back as inputs recurrently.
[7],
We experiment on multiple datasets—ScanNet
SUN3D [59], RGBD-SLAM [49] and Scenes11 [56]—and present results that are comparable or better to those ob-tained by state-of-the-art specialized architectures on all of them. This is achieved without using cost volumes, warp-ing layers, etc., and in fact (proudly) without introducing any architectural innovation. Instead, we propose powerful input-level 3D inductive biases that substantially improve data efﬁciency. This paper reﬂects a new avenue for prob-lem solving in computer vision, in which domain knowl-edge is valued but applied in a ﬂexible manner, as additional model inputs. 2.