Abstract
Keypoint detection is an essential component for the ob-ject registration and alignment. In this work, we reckon keypoint detection as information compression, and force the model to distill out important points of an object. Based on this, we propose UKPGAN, a general self-supervised 3D keypoint detector where keypoints are detected so that they could reconstruct the original object shape. Two mod-ules: GAN-based keypoint sparsity control and salient in-formation distillation modules are proposed to locate those important keypoints. Extensive experiments show that our keypoints align well with human annotated keypoint labels, and can be applied to SMPL human bodies under various non-rigid deformations. Furthermore, our keypoint detec-tor trained on clean object collections generalizes well to real-world scenarios, thus further improves geometric regis-tration when combined with off-the-shelf point descriptors.
Repeatability experiments show that our model is stable under both rigid and non-rigid transformations, with lo-cal reference frame estimation. Our code is available on https://github.com/qq456cvb/UKPGAN. 1.

Introduction
Recently, 3D object analysis and scene understanding receive more and more attentions. Though plenty of meth-ods [7, 13, 19, 23] on object analysis have been proposed, there is still a lack of capability of processing and under-standing objects, especially under an unsupervised setting. 3D keypoints, unlike part annotations, provide a sparse but meaningful representations of an object. They are widely leveraged in many tasks such as object matching, object tracking, shape retrieval and registration [4,22,34]. Keypoint detections have its origin in 2D image processing [12,21,28].
In 3D domain, traditional methods like Harris-3D [29],
HKS [30], Salient Points [5], Mesh Saliency [18], ISS [41],
*Cewu Lu and Weiming Wang are the corresponding authors. Cewu Lu is member of Qing Yuan Research Institute and MoE Key Lab of Artifi-cial Intelligence, AI Institute, Shanghai Jiao Tong University, China and
Shanghai Qi Zhi institute.
Sift-3D [27] and Scale Dependent Corners [24] propose to detect keypoints based on geometric variations. However, these hand-crafted detectors rely heavily on hard-coded pa-rameters and their performance is not comparable to current learning-based methods.
Figure 1. Our model outputs unsupervised keypoints and embed-dings given a point cloud, in either rigid or non-rigid deformations.
Left are keypoint predictions on clean models (indicated by red) and right are keypoint predictions on real scenes, best viewed in color.
These keypoints are consistent and could be used for registration.
Recently, some learning-based methods like USIP [20] and D3Feat [2] have been proposed. USIP regresses keypoint locations from pre-segmented local groups and then utilizes a probabilistic chamfer loss. However, their method requires the farthest point sampling and may output points that are not on the input. D3Feat instead gives saliency scores and descriptors densely for each point. Both USIP and D3Feat predict 3D keypoints by solving the auxiliary task of cor-rectly estimating rotations in a Siamese architecture. They both require real-world point clouds during training, and do not have much control on the output keypoints.
To solve these problems, we follow a totally different route to obtain 3D keypoints, which is named Unsupervised
Key Point GANeration (UKPGAN). A keypoint saliency distribution is given through a detector network, with a novel adversarial GAN loss to control its sparsity. Then, to make these keypoints informative, we leverage a salient informa-tion distillation process to reconstruct the original point cloud from these sparse keypoints, forming an encoder-decoder architecture. Our model can be seen as an infor-mation compression scheme, keeping most information of
the object with the least keypoints. The rationale behind our method is simple but powerful: one should be able to fully recover an object’s structure from a small set of key-points. This also coincides with that mentioned in [35]:
“much of human learning, perception, and cognition, may be understood as information compression”. Results show that our model could output stable informative keypoints from unseen objects, and generalize well to real-world scenarios.
Compared to previous methods, UKPGAN has the fol-lowing advantages: 1) our detector is proven to be rotation invariant without any data augmentations, by first estimating a Local Reference Frame (LRF), which also makes our local keypoint representation disentangled from rotations; 2) de-tected keypoints are intra-class consistent and stable on both rigid and non-rigid objects, with high repeatability; 3) our model trained on clean object collections (i.e. ModelNet) generalizes well to real-world point clouds, free from the usage of real-world training data.
We first evaluate our method on ShapeNet models with keypoint labels. Our model achieves remarkable results in keep consistent with human labeled part and keypoints. UKP-GAN cannot only be applied to rigid but non-rigid objects by keeping consistency on SMPL human body deformable meshes. As an application of our model, we also evalu-ate UKPGAN on 3DMatch and ETH datasets, which are real-world geometric registration benchmarks. Experiments show that when trained on clean objects (i.e. ModelNet), our model generalizes well to real-world scenarios, and further improves the registration performance of current state-of-the-art methods. At last, extensive experiments are conducted to demonstrate that UKPGAN achieves high rotation repeatabil-ity, which is an important and desired property of keypoints. 2.