Abstract 3D point cloud understanding is an important compo-nent in autonomous driving and robotics.
In this paper, we present a novel Embedding-Querying paradigm (EQ-Paradigm) for 3D understanding tasks including detection, segmentation and classiﬁcation. EQ-Paradigm is a uniﬁed paradigm that enables combination of existing 3D back-bone architectures with different task heads. Under the EQ-Paradigm, the input is ﬁrst encoded in the embedding stage with an arbitrary feature extraction architecture, which is independent of tasks and heads. Then, the querying stage enables the encoded features for diverse task heads. This is achieved by introducing an intermediate representation, i.e., Q-representation, in the querying stage to bridge the embedding stage and task heads. We design a novel Q-Net as the querying stage network. Extensive experimental re-sults on various 3D tasks show that EQ-Paradigm in tan-dem with Q-Net is a general and effective pipeline, which enables ﬂexible collaboration of backbones and heads. It further boosts performance of state-of-the-art methods. 1.

Introduction 3D point cloud understanding is an essential line in com-puter vision since it could beneﬁt many applications, such as autonomous driving [14], robotics [12], and augmented reality [31].
In point cloud understanding, there are two dominant input representations: points and voxels. Speciﬁcally de-signed for these two representations, mainstream mod-els can be grouped into point- [19, 23, 28, 36, 51, 56, 69] and voxel-based [7, 16, 61, 71] networks.
In both cases, state-of-the-art models consist of an encoder network to gradually downsample the points/voxels by sampling al-gorithms / strided convolution.
There are also a de-coder network to propagate features of the subsampled points/voxels into original ones and a task-speciﬁc head for making predictions. We call these methods Encoder-Decoder paradigm (ED-Paradigm) models. Due to the
∗ Equal contribution. Work done during internship at SmartMore.
Figure 1.
Illustration of the uniﬁed query-based EQ-Paradigm.
The query position can be randomly designated in the 3D scene, thus making it possible to combine any backbone embedding net-works with different task heads. downsampling-upsampling design, ED-Paradigm models extract features for some ﬁxed positions appearing in the downsampling process.
In this paper, we propose a novel Embedding-Querying paradigm (EQ-Paradigm) for 3D understanding tasks.
Compared to the ED-Paradigm, which extracts features for
ﬁxed positions, EQ-Paradigm enables feature generation for any position in the 3D scene. Thus, the EQ-paradigm is generalization of the ED-Paradigm. Any ED-Paradigm model has an EQ-Paradigm counterpart. An EQ-Paradigm model consists of three stages: an Embedding stage, a
Querying stage, and a task-speciﬁc head.
The embedding stage can be implemented with any fea-ture extraction architecture, including voxel- and point-based networks, regardless of tasks and heads. We use the embedding network to extract support features for follow-ing stages. The querying stage then takes a set of positions as query positions and generates their intermediate repre-sentation, i.e., Q-representation, based on the support fea-tures. Note that the query positions could be any point in the contiguous 3D space, thus enabling feature generation for any location. We further present a novel querying stage net-work called Q-Net to effectively extract Q-representation.
Afterwards, a task head is employed for generating predic-tions based on the Q-representation.
Due to the ﬂexibility in query position designation, the
EQ-Paradigm is a uniﬁed query-based paradigm that can easily combine any state-of-the-art 3D backbone networks with different task heads without extra efforts (Figure 1), which gives a lot of freedom in the head design. For example, SSD head [21] designed for voxel-based detec-tors [61, 72] can be applied with a point-based embedding network under EQ-Paradigm; an EQ-Paradigm segmenta-tion model can directly obtain point-wise features based on a voxel-based embedding network [7, 16]; also, an EQ-Paradigm version of PVRCNN [39] is able to directly gen-erate proposal grid features from the voxel-based backbones for the following detection head. This greatly increases the
ﬂexibility of model design for different tasks.
We evaluate our EQ-Paradigm on multiple important 3D understanding tasks including object detection [26, 32, 39, 40, 61], semantic segmentation [7, 16] and shape classiﬁca-tion [36]. Our experiments show that our EQ-Paradigm and
Q-Net can be well integrated with any state-of-the-art mod-els regardless of tasks, backbone architectures and head de-signs, while making consistent performance improvement.
Our primary contributions are the following.
• We propose an Embedding-Querying paradigm for 3D point cloud understanding. It is a uniﬁed query-based paradigm enabling combination of arbitrary point- or voxel-based networks with different task heads.
• We present a novel querying stage network Q-Net, to extract intermediate Q-representation, i.e., query fea-tures, for the designed query positions.
• We integrate our EQ-Paradigm and Q-Net into multi-ple state-of-the-art 3D networks for different tasks and achieve consistent performance improvement from ex-tensive experiments. 2.