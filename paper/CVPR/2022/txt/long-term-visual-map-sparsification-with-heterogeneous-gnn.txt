Abstract
We address the problem of map sparsification for long-term visual localization. For map sparsification, a com-monly employed assumption is that the pre-build map and the later captured localization query are consistent. How-ever, this assumption can be easily violated in the dynamic world. Additionally, the map size grows as new data ac-cumulate through time, causing large data overhead in the long term. In this paper, we aim to overcome the environ-mental changes and reduce the map size at the same time by selecting points that are valuable to future localization.
Inspired by the recent progress in Graph Neural Network (GNN), we propose the first work that models SfM maps as heterogeneous graphs and predicts 3D point importance scores with a GNN, which enables us to directly exploit the rich information in the SfM map graph. Two novel supervi-sions are proposed: 1) a data-fitting term for selecting valu-able points to future localization based on training queries; 2) a K-Cover term for selecting sparse points with full-map coverage. The experiments show that our method selected map points on stable and widely visible structures and out-performed baselines in localization performance. 1.

Introduction
In long-term visual localization, a common strategy is to build and accumulate maps from the captured image streams, and then localize new incoming queries by match-In the presence of en-ing against the accumulated map. vironmental changes, the accumulated map contains an in-creasing number of points and many of which are outdated.
This will affect both the computational cost and the perfor-mance of localization in the long run. Therefore, the ability to identify and remove these invalid points is important for many applications that target dynamic environments, such as autonomous driving, field robotics, and Augmented Re-ality. Additionally, for devices with limited on-board mem-ory, it enables keeping a compact map that only contains the most valuable information for future localization queries.
Existing works on map sparsification mostly fall into the category of subset selection, i.e., treating the 3D map as an over-sampled representation of a static world and aiming to select the most valuable point subset from them. The se-lection of point subset is typically formulated as a K-Cover problem. Assuming the map keyframes cover all the pos-sible camera positions, the K-Cover algorithm encourages each keyframe in the map to observe K points under a total point number constraint [7, 14, 15, 17]. These methods are purely based on the historical data stored in the map, there-fore lacking the ability to identify points invalidated due to environmental changes. When the environment changes, the map can only be updated by collecting new query data over the whole mapped area and solve the K-Cover problem again with the new query data, which is inefficient and ex-pensive. Apart from sparsifying a 3D map, there are some works on selecting 2D key points, e.g., by predicting the
persistency [8] or the repeatability [6] of visual features.
However, the predictors proposed only take instantaneous measurements (such as local image patches) and not exploit the full context stored in the accumulated map.
Recently, Graph Neural Networks (GNN) have shown promising results with data with different structures, such as citation graphs [29], local feature matching [20] and vis-ibility graphs [23]. In this work, we exploit this flexibility of
GNNs to formulate map sparsification as a learning problem and overcome the limitations of previous methods. First, by modeling the SfM map as a graph, we can directly employ the context-rich SfM map as the GNN input instead of in-stantaneous measurements. Second, in contrast to the K-Cover based methods that requires full-extent new queries to update the map, we are able to train a GNN with only partial queries and use it to sparsify the whole map. A main improvement from previous methods is the ability to incor-porate the partial new data and select important points from the whole map according to the partial new data, as there is no trivial way for the baseline methods to do this without collecting new data that covers the whole mapped area.
To this end, we propose the first work that extracts fea-tures from SfM maps with a heterogeneous GNN. We first represent the SfM map with a heterogeneous graph, where 3D points, 2D key points and images are modeled as graph nodes, and the context such as the visibility between 2D and 3D points are modeled as graph edges. Afterwards, we use a heterogeneous GNN to predict map point importance scores based on the local appearance and the spatial con-text in the map graph. In addition, we propose two novel losses to guide the training: 1) a data-fitting term that se-lects points based on the appearance and the spatial distri-bution of the training query data, and 2) a K-Cover loss term that drives to sparse point selection with full-map cover-age. When evaluated on an outdoor long-term dataset with significant environmental changes (Extended CMU Sea-sons [22]), our approach can select map points on stable and widely-visible structures (e.g., buildings/utility poles), while discarding points on changing object (e.g., foliage) or with highly repetitive texture (e.g., pavement). Compared with the K-Cover baseline [14], our approach outperforms in visual localization performance with the same map size. 2.