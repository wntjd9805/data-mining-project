Abstract
Weakly-supervised instance segmentation (WSIS) has been considered as a more challenging task than weakly-supervised semantic segmentation (WSSS). Compared to
WSSS, WSIS requires instance-wise localization, which is difficult to extract from image-level labels. To tackle the problem, most WSIS approaches use off-the-shelf proposal techniques that require pre-training with instance or ob-ject level labels, deviating the fundamental definition of the fully-image-level supervised setting. In this paper, we pro-pose a novel approach including two innovative compo-nents. First, we propose a semantic knowledge transfer to obtain pseudo instance labels by transferring the knowledge of WSSS to WSIS while eliminating the need for the off-the-shelf proposals. Second, we propose a self-refinement method to refine the pseudo instance labels in a self-supervised scheme and to use the refined labels for train-ing in an online manner. Here, we discover an erroneous phenomenon, semantic drift, that occurred by the missing instances in pseudo instance labels categorized as back-ground class. This semantic drift occurs confusion between background and instance in training and consequently de-grades the segmentation performance. We term this prob-lem as semantic drift problem and show that our proposed self-refinement method eliminates the semantic drift prob-lem. The extensive experiments on PASCAL VOC 2012 and
MS COCO demonstrate the effectiveness of our approach, and we achieve a considerable performance without off-the-shelf proposal techniques. The code is available at https:
//github.com/clovaai/BESTIE. 1.

Introduction
The recent line of weakly-supervised semantic segmen-tation (WSSS) approaches [21,28,29,45] have achieved im-pressive performance enhancement, with commonly using class activation maps (CAMs) [46] to obtain class-wise lo-calization maps from image-level labels. However, weakly-Figure 1. Two limitations of previous WSIS methods: (1) de-pendency on off-the-shelf proposal technique that requires pre-training with high-level labels including object or instance infor-mation. (2) semantic drift problem caused by the missing instances in the pseudo label guided as background class. Our proposed
BESTIE aims to solve the two problems simultaneously. supervised instance segmentation (WSIS) using image-level labels is still an open task because the CAM does not provide instance-wise localization maps.
To extract the instance-wise information, most WSIS methods use off-the-shelf proposal techniques. PRM [47] takes suitable instance masks from segment proposals gen-erated by MCG [38] and generates pseudo instance labels.
Also, LIID [33] utilizes a pre-trained salient instance seg-mentor [12] which produces class-agnostic instance-level masks. We note that MCG and salient instance segmentor used in each method require pre-training with object bound-ary labels and class-agnostic instance masks, respectively.
However, the proposal-guided WSIS methods have two limitations as shown in Figure 1. First, their dependency on the off-the-shelf proposal techniques is considerably high, and it makes the methods difficult to apply to other specific domains such as medical images since the proposal tech-niques mostly target general objects. Furthermore, in a strict sense, the use of the proposal techniques trained by ob-ject or instance level information deviates from the defini-tion of fully-image-level supervised segmentation. Second, these methods cannot cope with the performance degrada-tion caused by noisy pseudo-labels containing missing in-stances (i.e., false-negatives). As shown in Figure 1, the left two missing cows are guided to the background class
and the right cow is guided to the cow class, although all cows have semantically similar visual cues. We call this problem as semantic drift problem. This semantic drift be-tween background and instance confuses the network and deteriorates the stable training convergence.
In this paper, we propose a new WSIS method, BESTIE:
BEyond Semantic segmentation To InstancE Segmentation.
BESTIE deprecates the use of off-the-shelf techniques to strictly follow a fully-image-level supervised setting. Also,
BESTIE alleviates the semantic drift problem. To solve the two problems, BESTIE proposes two innovative compo-nents, semantic knowledge transfer and self-refinement.
Specifically, in semantic knowledge transfer, we trans-fer the knowledge of WSSS, which is relatively profoundly studied, to WSIS to generate the rough pseudo instance la-bels. To obtain the instance cues from image-level labels, we propose peak attention module (PAM) that makes the
CAM highlight the sparse representative region of objects.
We note that the proposed components only use image-level labels, including the WSSS, and this eliminates the need for the off-the-shelf proposal technique. Furthermore, to ad-dress the semantic drift problem, we introduce instance-aware guidance that dynamically assigns the guidance re-gion only to the labeled instance region. This strategy al-lows more stable training of the network and progres-sively captures instance-level information of the missing instances. Along with this strategy, to further refine the pseudo labels, we propose the self-supervised instance la-bel refinement method that converts false-negatives in the pseudo labels to true-positives by a self-supervised manner and reflects them to the training in an online manner. This method, shortly named self-refinement, improves the quality of the pseudo labels as training progresses.
The extensive experiments on PASCAL VOC 2012 [11] and MS COCO 2017 [31] show the effectiveness of the pro-posed design. Even without the off-the-shelf proposal tech-niques, our method achieves a state-of-the-art performance of 51.0% mAP50 on VOC 2012 and 28.0% AP50 on COCO dataset. Furthermore, we model the point-supervised in-stance segmentation by replacing the instance cues with point labels and can further boost the performance with an economical annotation cost.
Our contribution can be summarized as follows:
• We propose a novel WSIS method only using image-level labels, strictly following the fully-image-level su-pervised setting without the help of the proposal tech-niques pre-trained by object or instance level labels.
• We design the semantic knowledge transfer strategy to obtain pseudo instance labels. This transfers the knowledge of WSSS and instance cues, extracted from the proposed PAM, to WSIS while eliminating the use of off-the-shelf proposal techniques.
• We propose a self-refinement method to refine the pseudo instance labels in a self-supervised manner and reflect them back to the training in an online manner.
Here, we introduce the instance-aware guidance strat-egy to resolve the semantic drift problem newly dis-covered in this paper. 2.