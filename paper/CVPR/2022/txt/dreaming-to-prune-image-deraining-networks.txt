Abstract
Convolutional image deraining networks have achieved great success while suffering from tremendous computa-tional and memory costs. Most model compression methods require original data for iterative fine-tuning, which is lim-ited in real-world applications due to storage, privacy, and transmission constraints. We note that it is overstretched to fine-tune the compressed model using self-collected data, as it exhibits poor generalization over images with different degradation characteristics. To address this problem, we propose a novel data-free compression framework for de-raining networks. It is based on our observation that deep degradation representations can be clustered by degrada-tion characteristics (types of rain) while independent of im-age content. Therefore, in our framework, we “dream” di-verse in-distribution degraded images using a deep inver-sion paradigm, thus leveraging them to distill the pruned model. Specifically, we preserve the performance of the pruned model in a dual-branch way.
In one branch, we invert the pre-trained model (teacher) to reconstruct the de-graded inputs that resemble the original distribution and employ the orthogonal regularization for deep features to yield degradation diversity. In the other branch, the pruned model (student) is distilled to fit the teacher’s original sta-tistical modeling on these dreamed inputs. Further, an adaptive pruning scheme is proposed to determine the hi-erarchical sparsity, which alleviates the regression drift of the initial pruned model. Experiments on various derain-ing datasets demonstrate that our method can reduce about 40% FLOPs of the state-of-the-art models while maintain-ing comparable performance without original data. 1.

Introduction
Convolutional Neural Networks (CNNs) based ap-proaches have achieved remarkable progress on single im-age deraining [5, 10, 16, 28, 31]. However, due to the in-*Equal contribution. † Corresponding author. (a) Input (100H) (b) Original output (c) Pruned (d) Fine-tuned (web) (e) Fine-tuned (100L) (f) Ours (data-free)
Figure 1. Pre-trained HINet [5] drops significantly after pruning 30% weights (1b → 1c). Fine-tuning the pruned model with im-ages from website or Rain100L [29] exhibits poor generalization to images in Rain100H [29]. We preserve the performance of the pruned model without the original data. herent properties of dense prediction tasks, coupled with the requirements to handle various degradation character-istics, these CNN models typically suffer from tremendous computational costs and bulky memory usage. This lim-its their applications in real scenarios, especially on devices with constrained computing capacity.
In practice, various attempts have been made to com-press the heavy CNN models, including quantization [11, 12, 23], pruning [8, 13, 15, 21], distillation [3, 7, 14], and so on. These approaches require original data for interactive training to preserve the performance of compressed models.
However, the original training data is often unaccessible due to storage, privacy, or transmission constraints. To alleviate this problem, one may naturally acquire paired data by col-lecting degraded (rainy) images and exporting their pseudo labels output by the pre-trained model. However, our study suggests this way exhibits poor generalization. For exam-ple, state-of-the-art deraining network HINet [5] gets a sig-nificant performance drop after pruning 30% weights, as shown in Fig. 1c. Fine-tuning the pruned model with data collected from the website or Rain100L [29] exhibits poor generalization to images in Rain100H [29], as shown in
Fig. 1d and Fig. 1e. Those heavy deraining models typi-cally achieve promising performance over images with var-ious degradation characteristics, such as rain steaks or drops in different orientations and densities. It is impractical to acquire all types of in-distribution data on which the model has ever been trained.
Recently, some feasible methods have been proposed to perform data-free model compression. They mainly at-tempt to reconstruct the original data for data-free knowl-edge distillation, either through a model inversion paradigm
[9, 19, 22, 30] similar to DeepDream [1], or by retraining a generative network [4]. However, these studies focus only on image recognition tasks, in which argmax of the class conditional probabilities determine decisions. Moreover, their synthetic images are visually unnatural and difficult to yield diversity since constrained mainly by category con-tent. Thus, these existing data-free approaches for model compression cannot be employed on a direct basis.
In this paper, we propose a novel data-free deraining model compression framework by exploring the statistical priors learned from pre-trained networks. This method is based on our statistical observations that image deraining networks can learn deep representations for degradation characteristics (rain types) independent of image content (detailed in Sec. 3.1). This motivates us to reconstruct di-verse and in-distribution degraded images and thus provide sufficient supervision to compensate for the statistical drift of the compressed model without original data.
Specifically, given a pre-trained image restoration model (teacher), we utilize two branches in one stage to optimize both the random noise input and the pruned model (stu-dent). In one branch, the random noise forward through the fixed teacher model, then the output is forced to be close to the collected clean images (target) under the constraint of a dream loss. Meanwhile, we employ the orthogonality regularization of the deep features along the batch dimen-sion to yield diverse degradation characteristics. In another branch, these input and output pairs are employed to dis-till the pruned model supervised by a knowledge distillation loss. Further, to alleviate the statistical drift caused by prun-ing before distillation, an adaptive pruning scheme is pro-posed to determine the hierarchical sparsity by constructing an explicit metric for pruning sensitivities of different lay-ers combined with our reconstruction. The contributions of this paper are summarized as follows: 1) We find that pre-trained deraining networks can learn deep degradation representations that are independent of image content. Thus, we propose a novel data-free compression framework for deraining networks, in which diverse degraded images are reconstructed and utilized to distill the pruned model. 2) We further propose an adaptive pruning scheme to de-termine the hierarchical sparsities and moderate the statistical drift of the pruned model before fine-tuning. 3) Experiments on various deraining datasets demon-strate that our method can compress about 40% FLOPs of the state-of-the-art models while maintaining com-parable performance without original data. 2.