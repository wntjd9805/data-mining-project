Abstract
Deep learning (DL) models trained to minimize empir-ical risk on a single domain often fail to generalize when applied to other domains. Model failures due to poor gen-eralizability are quite common in practice and may prove quite perilous in mission-critical applications, e.g., diag-nostic imaging where real-world data often exhibits pro-nounced variability. Such limitations have led to increased interest in domain generalization (DG) approaches that im-prove the ability of models learned from a single or multiple source domains to generalize to out-of-distribution (OOD) test domains. In this work, we propose BoosterNet, a lean add-on network that can be simply appended to any arbi-trary core network to improve its generalization capability without requiring any changes in its architecture or train-ing procedure. Specifically, using a novel measure of fea-ture culpability, BoosterNet is trained episodically on the most and least culpable data features extracted from crit-ical units in the core network based on their contribution towards class-specific prediction errors, which have shown to improve generalization. At inference time, correspond-ing test image features are extracted from the closest class-specific units, determined by smart gating via a Siamese network, and fed to BoosterNet for improved generaliza-tion. We evaluate the performance of BoosterNet within two very different classification problems, digits and skin lesions, and demonstrate a marked improvement in model generalization to OOD test domains compared to SOTA. 1.

Introduction
The remarkable advances in deep learning (DL) mod-els rendered deep neural networks (DNNs) ubiquitous in various fields, particularly in computer vision including safety-critical applications such as medical image analy-sis [21, 32, 60]. Despite their relative success when applied to new data in certain applications, practical deployment of
DNN based solutions remains very risky with one of the main concerns being vulnerability to domain shifts which leads to poor generalizability to out-of-distribution (OOD) data. Such limitations not only impair model performance but can result in serious unacceptable failures when test data is drawn from a different distribution than that of the train-ing data [16,43,58]. This unpredictable performance degra-dation on real life data continues to hamper reliable practi-cal deployment such as in healthcare.
Recognizing this serious problem, much research has re-cently focused on improving model generalizability. In un-supervised domain adaptation (UDA), the aim is to transfer the knowledge of a label-rich training domain to unlabeled test domains with the same classes as those of the training data [31, 36, 49, 63, 66]. However, UDA methods have lim-ited value due to the requirement of accessing some of the test data which may not be available in advance. In Domain generalization (DG) approaches, the aim is to instead utilize a single or multiple source domains’ information to better generalize to OOD domains without requiring any access to the test data. The field of DG is quite rich with a spectrum of techniques ranging from domain alignment [28, 46] to data augmentation [51, 57, 65], meta-learning [7, 34] and ensem-ble learning [45, 55]. However, despite significant perfor-mance improvements, most DG approaches still suffer from common drawbacks. First, they typically require training data from multiple domains, which can be rather challeng-ing, costly and even infeasible, e.g., due to privacy issues in medical data applications. Second, they often require re-structuring or changes in the network architecture or learn-ing strategy to achieve the desired performance [8,9,19,30].
For end users who are not seasoned data scientists, e.g., der-matologists trying to classify skin lesions with minimal or no training in DL, such amendments are impractical.
In this work, we propose a single-source DG framework for improving generalizability of an arbitrary off-the-shelf
DNN (core network A) by learning from its mistakes. We argue that BoosterNet ameliorates shortcut learning and feature suppression, a problem that has only recently gained more attention [12, 18, 44], where in the presence of mul-tiple predictive input features, a model tends to only use a
subset and ignores the other features often leading to ‘short-cut’ decision rules that might perform well on training data but would harm generalization ability and lead to poor ro-bustness to data shifts. To combat shortcut learning and im-prove generalization capabilities, BoosterNet comprises a lean add-on network that is encouraged to learn, through episodic training, from the most culpable features in the core network A most associated with erroneous prediction (hereafter referred to as confusion features). To balance the learning process, BoosterNet is trained to also retain focus on the most predictive ‘trivial’ characteristics of the data, namely by training on the least culpable features as well (hereafter referred to as discriminant features). A high level overview of our DG framework is illustrated in Fig-ure 1 (training and inference details are illustrated in Fig-ure 2). Using our proposed culpability score, the confusion and discriminant features are extracted from class-specific units (filters/neurons) in network A being associated with the highest and lowest culpability in erroneous prediction in a specific class, respectively. At inference time, Booster-Net processes a test image by extracting confusion and dis-criminant features corresponding to the closest class-units as determined by a smart gating mechanism based on a
Siamese network. Our extensive experiments illustrate that our method outperforms state-of-the-art (SOTA) in single domain generalization on classification benchmark datasets including digits and medical skin images. 2.