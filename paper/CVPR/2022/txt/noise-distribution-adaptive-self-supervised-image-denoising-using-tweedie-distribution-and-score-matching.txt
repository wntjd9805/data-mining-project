Abstract
Tweedie distributions are a special case of exponential dispersion models, which are often used in classical statis-tics as distributions for generalized linear models. Here, we show that Tweedie distributions also play key roles in modern deep learning era, leading to a distribution adap-tive self-supervised image denoising formula without clean reference images. Specifically, by combining with the recent
Noise2Score self-supervised image denoising approach and the saddle point approximation of Tweedie distribution, we provide a general closed-form denoising formula that can be used for large classes of noise distributions without ever knowing the underlying noise distribution. Similar to the original Noise2Score, the new approach is composed of two successive steps: score matching using perturbed noisy im-ages, followed by a closed form image denoising formula via distribution-independent Tweedie’s formula.
In addi-tion, we reveal a systematic algorithm to estimate the noise model and noise parameters for a given noisy image data set. Through extensive experiments, we demonstrate that the proposed method can accurately estimate noise mod-els and parameters, and provide the state-of-the-art self-supervised image denoising performance in the benchmark dataset and real-world dataset. 1.

Introduction
Image denoising is a fundamental problem in low-level computer vision problems. Nowadays, typical supervised learning approaches easily outperform classical denois-ing algorithms such as Block-Matching and 3D filtering (BM3D) [2] and Weighted Nuclear Norm Minimization (WNNM) [5]. Nonetheless, the supervised approaches are
Figure 2. Overall reconstruction flow of the proposed method, where the first step is the estimation of the score function ˆl′ by training a neural network RΘ, which is followed by the estimation of noise model and noise level to obtain final denoised results. During the training procedure, input images y that belong to the distribution of train set PY , are sampled. not practical in many real-world applications as they require a large number of matched clean images for training.
To address this issue, researchers have proposed various forms of self-supervised learning approaches trained with ingenious forms of loss functions that are not associated with clean reference images [1,6,9,12,14,21]. Specifically, these approaches have focused on designing loss functions to prevent from learning identity mapping, and can be cat-egorized into two classes: 1) one with generating altered target images from noisy input images [1, 6, 12, 14], and 2) the other by adding regularization terms from Stein’s Unbi-ased Risk Estimation (SURE) [9, 21].
Although these algorithms appear seemingly different, a recent Noise2Score [10] revealed that the procedure of gen-erating altered target images or SURE-based regularization term is closely related to the score matching [7], and there exists a Bayes optimal denoising formula in terms of score function for any exponential family distributions. Unfortu-nately, Noise2Score requires a prior knowledge of the noise distribution, so when the underlying noise distribution is un-known, Noise2Score provide a sub-optimal performance.
One of the most important contributions of this paper is, therefore, a novel discovery that the classical Tweedie distribution can provide a “magic” recipe that can be used for a large class of noise distribution even without knowing the distribution. Specifically, Tweedie distribution can be synergistically combined with Noise2Score to provide an explicit de-noising formulation and an algorithm for esti-mating the underlying noise model and parameters. In par-ticular, inspired by the fact that various exponential fam-ily distributions like Gaussian, Gamma, Poisson, etc. can be described by saddle point approximation of the Tweedie distribution by simply changing one parameter, we provide a universal noise removal formula that can be used for a large class exponential family distributions without prior knowledge of the noise model. Furthermore, by assum-ing that slightly perturbed noisy image may produce simi-lar denoising results, we provide a systematic algorithm that can estimate the noise type and associate parameters for any given images. In spite of the blind nature of the algorithm, experimental results demonstrated that our method outper-forms other self-supervised image denoising methods that are trained with prior knowledge of noise distributions.
Our contribution can be summarized as follows.
• We provide a general closed-form denoising formula for large classes of noise distributions by combining
Noise2Score approach and the saddle point approxi-mation of Tweedie distribution.
• We propose an algorithm to estimate the noise model and noise parameter for given noisy images. In partic-ular, the proposed noise estimation algorithm signifi-cantly improves the performance and boosts the infer-ence speed compared to the original Noise2Score [10].
• We show that the proposed method produces the state-of-the-art performance amongst various self-supervised image denoising algorithms in the bench-mark dataset and real-environment dataset. 2.