Abstract 1.

Introduction
This work is concerned with a representation of shapes that disentangles ﬁne, local and possibly repeating geom-etry, from global, coarse structures. Achieving such dis-entanglement leads to two unrelated advantages: i) a sig-niﬁcant compression in the number of parameters required to represent a given geometry; ii) the ability to manipu-late either global geometry, or local details, without harm-ing the other. At the core of our approach lies a novel pipeline and neural architecture, which are optimized to represent one speciﬁc atlas, representing one 3D surface.
Our pipeline and architecture are designed so that disen-tanglement of global geometry from local details is accom-plished through optimization, in a completely unsupervised manner. We show that this approach achieves better neu-ral shape compression than the state of the art, as well as enabling manipulation and transfer of shape details.
Project page http://geometry.cs.ucl.ac.uk/ projects/2022/cnnmaps/.
*Partially worked on the project during internship at Adobe Research.
Triangle meshes have been the most popular represen-tation across much of geometry processing since its early stages, however research has been devoted to devising novel representations of geometry to circumvent many of the shortcoming of triangular meshes. Lately, the rising promi-nence of deep learning has lead researchers to investigate ways to represent shapes via neural networks. While the immediate use of neural networks in this context is to rep-resent entire shape spaces by using the same set of weights to decode any shape from a shared latent space, other meth-ods use a shape-speciﬁc set of weights to represent a spe-ciﬁc instance. This approach captures geometric detail efﬁ-ciently and accurately and creates outputs that are on par with existing 3D models, while holding novel properties not attainable with surface meshes, such as differentiabil-ity. These neural representations for shape instances were demonstrated to be useful in geometry processing applica-tions such as efﬁcient rendering [34], level of details [23], surface parameterization, and inter-surface mapping [26].
The choice of the shape representation, and of the neu-ral network’s architecture, plays a critical role in how ef-ﬁciently the capacity of the network is utilized. Existing
representations usually use MLPs to model the shape as a function that maps points either from a 2D atlas to the sur-face [26] or points in a 3D volume to an implicit function such as a distance ﬁeld [27]. The disadvantage of these ar-chitectures is that they entangle geometric details and over-all shape structure, and do not have a natural mechanism to reuse the network weights to represent repeating local details, as Convolution Neural Networks (CNNs) achieve on images. Some methods indeed opt to use 2D images to represent geometry [31], however those exhibit ﬁnite reso-lution and hence cannot model surfaces with details in sub-pixel resolution. Alternatively, instead of a single global
MLP, some prior techniques leverage repetitions by break-ing the shape into smaller 3D voxels, each represented by an SDF function [23], however, these representations do not account for the fact that surface details are usually aligned with the surface, and thus, are less effective at representing local geometric textures that ﬂow with the shape.
In this paper, we set to deﬁne a novel representation that achieves separation of local geometric details (“tex-ture”) from the global coarse geometry of the model, and thus leads to the reuse of network weights for repeating patterns that change their orientation with the surface. We achieve this by considering the standard atlas-based repre-sentation as in [15,26], but encode a surface as combination of a coarse surface, deﬁning the general, coarse structure of the shape, represented via an MLP, along with an associ-ated ﬁne detail map, which adds geometric texture on top, represented via a CNN, which deﬁnes a continuous map of offsets. The geometric details are added to the coarse ge-ometry either along its normal directions, or as general dis-placement vectors. Since the local displacement details are expressed with convolutional kernels, they can effectively be reused across similar regions of the surface. We call this hybrid representation neural convolutional surfaces.
This novel architecture enables the network to disentan-gle the ﬁne CNN representation from the coarse MLP repre-sentation, in a completely unsupervised manner, i.e., with-out the need to supervise the split explicitly during ﬁtting.
We show that the inductive bias in our designed architecture leads to automatic separation of the shapes into coarse base shapes and reusable convolutional details, see Figure 1.
We evaluate our method on a range of complex sur-faces and explore the associated tradeoff between represen-tation quality and model complexity. We compare against a set of state-of-the-art alternatives (e.g., NeuralLod [34],
ACORN [23], Neural Surface Maps [26]) and demonstrate that our model achieves better accuracy at a fraction of the model-complexity – between 1% to 10% parameters. Ad-ditionally, we demonstrate that the convolutional aspect of the representation makes it interpretable, leading to applica-tions including detail modiﬁcation within individual shapes and details transfer across different models – see Figure 7. 2.