Abstract
We present an efficient method for joint optimization of topology, materials and lighting from multi-view im-age observations. Unlike recent multi-view reconstruction approaches, which typically produce entangled 3D repre-sentations encoded in neural networks, we output triangle meshes with spatially-varying materials and environment lighting that can be deployed in any traditional graphics en-gine unmodified. We leverage recent work in differentiable rendering, coordinate-based networks to compactly repre-sent volumetric texturing, alongside differentiable march-ing tetrahedrons to enable gradient-based optimization di-rectly on the surface mesh. Finally, we introduce a differ-entiable formulation of the split sum approximation of en-vironment lighting to efficiently recover all-frequency light-ing. Experiments show our extracted models used in ad-vanced scene editing, material decomposition, and high quality view interpolation, all running at interactive rates in triangle-based renderers (rasterizers and path tracers). 1.

Introduction 3D content creation is a challenging, mostly manual task which requires both artistic modeling skills and technical knowledge. Efforts to automate 3D modeling can save sub-stantial production costs or allow for faster and more diverse content creation. Photogrammetry [48,56] is a popular tech-nique to assist in this process, where multiple photos of an object are converted into a 3D model. Game studios lever-age photogrammetry to quickly build highly detailed virtual landscapes [21]. However, this is a multi-stage process, including multi-view stereo [52] to align cameras and find correspondences, geometric simplification, texture param-eterization, material baking and delighting. This complex pipeline has many steps with conflicting optimization goals and errors that propagate between stages. Artists rely on a plethora of software tools and significant manual adjust-ments to reach the desired quality of the final 3D model.
Project page: https://nvlabs.github.io/nvdiffrec/
Reference photo
Scene editing
Cloth simulation
Material editing kd/korm/n
Figure 1. We reconstruct a triangular mesh with unknown topol-ogy, spatially-varying materials, and lighting from a set of multi-view images. We show examples of scene manipulation using off-the-shelf modeling tools, enabled by our reconstructed 3D model.
Mesh
Our goal is to frame this process as an inverse render-ing task, and optimize as many steps as possible jointly, driven by the quality of the rendered images of the recon-structed model, compared to the captured input imagery.
Recent work approaches 3D reconstruction with neural ren-dering, and provides high quality novel view synthesis [39].
However, these methods typically produce representations that entangle geometry, materials and lighting into neural networks, and thus cannot easily support scene editing op-erations. Furthermore, to use them in traditional graph-ics engines, one needs to extract geometry from the net-work using methods like Marching Cubes which may lead to poor surface quality, particularly at low triangle counts.
Recent neural methods can disentangle shape, materials, and lighting [3, 68, 70], but sacrifice reconstruction qual-ity. Also, the materials encoded in neural networks cannot easily be edited or extracted in a form compatible with tradi-tional game engines. In contrast, we reconstruct 3D content compatible with traditional graphics engines, supporting re-lighting and scene editing.
In this paper, we present a highly efficient inverse render-ing method capable of extracting triangular meshes of un-known topology, with spatially-varying materials and light-ing from multi-view images. We assume that the object is illuminated under one unknown environment lighting con-dition, and that we have corresponding camera poses and masks indicating the object in these images, as in past work [3]. Our approach learns topology and vertex po-sitions for a surface mesh without requiring any initial guess for the 3D geometry. The heart of our method is a differentiable surface model based on a deformable tetra-hedral mesh [54], which we extend to support spatially-varying materials and high dynamic range (HDR) environ-ment lighting, through a novel differentiable split sum ap-proximation. We optimize geometry, materials and lighting (50M+ parameters) jointly using a highly optimized differ-entiable rasterizer with deferred shading [22, 30]. The re-sulting 3D model can be deployed without conversion on any device supporting triangle rendering, including phones and web browsers, and renders at interactive rates.
Experiments show our extracted models used in scene editing (e.g., Figure 1), material decomposition, and high quality view interpolation, all running at interactive rates in triangle-based renderers (rasterizers and path tracers). 2.