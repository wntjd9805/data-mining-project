Abstract
We present a novel high-resolution and challenging stereo dataset framing indoor scenes annotated with dense and accurate ground-truth disparities. Peculiar to our dataset is the presence of several specular and transparent surfaces, i.e. the main causes of failures for state-of-the-art stereo networks. Our acquisition pipeline leverages a novel deep space-time stereo framework which allows for easy and accurate labeling with sub-pixel precision. We re-lease a total of 419 samples collected in 64 different scenes and annotated with dense ground-truth disparities. Each sample include a high-resolution pair (12 Mpx) as well as an unbalanced pair (Left: 12 Mpx, Right: 1.1 Mpx). Addi-tionally, we provide manually annotated material segmenta-tion masks and 15K unlabeled samples. We evaluate state-of-the-art deep networks based on our dataset, highlighting their limitations in addressing the open challenges in stereo and drawing hints for future research. 1.

Introduction
Depth estimation from images has long been deemed a favourable alternative compared to expensive and intrusive active sensors. Among several image-based approaches, stereo vision [32,36] is arguably the most popular and heav-ily researched technique. In the years, huge progresses have
∗ Joint first authorship. been made in this field, also thanks to the availability of challenging stereo benchmarks [15, 29, 34, 38] where the community competes for the higher ranks. Moreover, the abundance of stereo images paved the way for deep learning to succeed also in this field [22,28,54]. Indeed, by browsing the most popular benchmarks, one can notice how nowa-days all the top-ranking proposals consist in end-to-end deep networks that can reach sub-pixel precision in most cases. Just to name a few, KITTI 2012 and 2015 [15, 29] or ETH3D [38] seem solved, with top entries achieving av-erage error rates near to 1%. Should this evidence suggest that, thanks to deep learning, stereo vision is a solved prob-lem? As shown in Fig. 1, we believe that this is definitely not the case and, rather, it is time for the community to fo-cus on the open-challenges left unsolved in the field. In particular, we identify two of such challenges, namely i) non-Lambertian surfaces and ii) high-resolution images.
As for non-Lambertian reflectivity, a variety of materials and surfaces still represent a hard challenge to most com-puter vision methodologies and to deep stereo alike. Specif-ically, matching pixels dealing with transparent or specular surfaces is extremely difficult and may consist in an inher-ently ill-posed problem in many cases. Yet, we reckon that objects with such properties are almost absent or unlabeled in most stereo benchmarks, except for KITTI 2015, where cars have been replaced with CAD models providing super-vision on some specular/transparent surfaces on cars. As re-ported in the KITTI 2015 online benchmark, deep learning has the potential to tackle this challenge as well, if properly
annotated samples are available.
Concerning the second challenge, when considering higher-resolution images, for instance in the Middlebury 2014 benchmark [34], we can notice in general higher er-rors. These are caused by the much larger image dimensions (and thus disparity range) and, consequently, by a larger number of occluded and untextured pixels in the images framed in this dataset. Besides, processing images at high resolution sets forth computational complexity issues, in particular when deploying deep networks. Indeed, most of the entries in the Middlebury benchmark can only process input images downsampled to half or quarter of the orig-inal 6 Mpx resolution. Moreover, an additional challenge emerges due the peculiar camera setup featured by modern smartphones, typically equipped with both a high resolution and a much lower resolution image sensors. In such a set-ting, one may wish to recover a high resolution depth map despite the different resolution of the input pair, i.e., solve an unbalanced stereo problem. However, such a research direction has been only barely explored so far [1, 26].
To this aim, in this paper we present a novel high-resolution challenging stereo benchmark. Each image in our dataset, collected in indoor environments, features a set of objects and surfaces that are either specular or transpar-ent, as well as very large untextured regions. To accurately annotate each collected sample, we implement a novel deep space-time stereo pipeline [10] which combines disparity estimates computed from multiple static images – up to 100 – acquired under a variety of texture patterns projected onto the scene from different directions and after having care-fully painted all non-Lambertian surfaces. Peculiar to our pipeline is the use of a state-of-the-art, pretrained deep net-work [25] to compute the individual disparity maps accu-mulation through time within the space-time framework.
Furthermore, a final careful manual cleaning is carried out to remove outliers/artefacts and ensure high-quality dispar-ity labels. We point out that for some non-Lambertian sur-faces it might be possible to provide multiple depth ground-truths: for instance, for transparent surfaces we might pro-vide both depths for the surface itself and the objects seen through the surface. Yet, in our dataset we provide depth labels for the closest surfaces only, thereby enabling evalua-tion and training of stereo methods designed to return a sin-gle depth prediction per pixel. As such, our dataset mainly addresses scenarios dealing with autonomous driving, ob-stacle avoidance and robotic manipulation, while being less amenable to applications such as AR and novel view syn-thesis. The main contributions of our paper are:
• We propose a novel dataset consisting of both high-resolution as well as unbalanced stereo pairs featuring a large collection of labeled non-Lambertian objects. In par-ticular, we have acquired a total of 64 scenes under dif-ferent illuminations, yielding 419 balanced stereo pairs at 12 Mpx and 419 unbalanced pairs, each consisting in a 12
Mpx and 1.1 Mpx image. The latter setup provides the first-ever dataset for unbalanced stereo matching, as prior work is limited to simulation experiments [1, 26]. In both setups, samples are annotated with dense ground-truth disparities and grouped into 228 training images and 191 test images – for which ground-truth is withheld.
• Data annotation is performed in a semi-automatic manner based on a novel deep space-time stereo frame-work, which enables to deploy modern stereo networks [25] within the well-known space-time stereo framework [10].
• Alongside with ground-truth disparities, we provide manually annotated segmentation maps that identify and rank the hard-to-match materials based on specularity and transparency. This is conducive to focus on the open-challenges addressed in this paper when analyzing the be-haviour of state-of-the-art networks. Moreover, we provide an additional set of 15K raw pairs, both in balanced and un-balanced settings, to encourage the development of weakly-supervised solutions to the open challenges in stereo.
• We evaluate the prominent state-of-the-art stereo net-works [5, 9, 49, 55], as trained by their authors, on the test split of our dataset. The experimental findings highlight the open-challenges that need to be faced by the stereo commu-nity and provide hints on possible future research directions.
Our Benchmark on open-challenges in stereo (Booster) is available at https://cvlab-unibo.github.io/ booster-web/. 2.