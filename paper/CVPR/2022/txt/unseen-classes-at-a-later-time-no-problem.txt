Abstract
Recent progress towards learning from limited supervi-sion has encouraged efforts towards designing models that can recognize novel classes at test time (generalized zero-shot learning or GZSL). GZSL approaches assume knowl-edge of all classes, with or without labeled data, before-hand. However, practical scenarios demand models that are adaptable and can handle dynamic addition of new seen and unseen classes on the ﬂy (i.e continual general-ized zero-shot learning or CGZSL). One solution is to se-quentially retrain and reuse conventional GZSL methods, however, such an approach suffers from catastrophic for-getting leading to suboptimal generalization performance.
A few recent efforts towards tackling CGZSL have been lim-ited by difference in settings, practicality, data splits and protocols followed – inhibiting fair comparison and a clear direction forward. Motivated from these observations, in this work, we ﬁrstly consolidate the different CGZSL setting variants and propose a new Online-CGZSL setting which is more practical and ﬂexible. Secondly, we introduce a uniﬁed feature-generative framework for CGZSL that lever-ages bi-directional incremental alignment to dynamically adapt to addition of new classes, with or without labeled data, that arrive over time in any of these CGZSL settings.
Our comprehensive experiments and analysis on ﬁve bench-mark datasets and comparison with baselines show that our approach consistently outperforms existing methods, espe-cially on the more practical Online setting. 1.

Introduction
Deep Neural Networks (DNNs) have shown great promise as predictive models and are increasingly being used for various computer vision applications. However, their reliance on large-scale labeled datasets limit their use in practical scenarios encountered in the real-world. The occurrence of objects in the real world inherently follows long-tailed distributions [16, 35], implying that visual data sampled from the real world may not be readily available
∗equal contribution
Figure 1. Illustration of proposed setting. Applicability of a General-ized Zero-shot Learning (GZSL) model (row 1) and our proposed model (row 2) in a real-world scenario on dynamic addition of new seen (depicted in yellow) and unseen (depicted in blue) categories. The GZSL setting does not allow dynamic addition of newer classes, seen or unseen, that are added over time. Our proposed CGZSL setting is more ﬂexible and can tackle dynamic changes in the initial pool of seen and unseen categories, enhancing model scalability and applicability in practical settings. for all categories of interest at the same time. Thus, it is required for models to have the ability to generalize and recognize novel objects semantically similar to the ones en-countered during training even though visual data for these novel classes is not seen by the model. Existing efforts aim to tackle this problem, by designing generalized zero-shot learning (GZSL) models that are equipped with the ability to generalize to unseen classes at test time.
Another important aspect of object occurrence in the real world is the gradual addition of object categories with time.
This can be attributed to the discovery of new objects or the continuous nature of data collection process owing to which a previously rare object may have abundantly available sam-ples at a later stage. However, existing GZSL approaches are not designed to tackle dynamic addition of classes in the initial pool of seen and unseen categories, limiting their scalability and applicability in challenging practical set-tings. Fig. 1 illustrates the shortcomings of a GZSL model in such practical settings where classes arrive over time. Ev-idently, the GZSL setting is limiting, and is unable to adapt to dynamic changes to the initial pool of categories brought by the gradual addition of new seen and unseen classes over
time. This can be attributed to the fact that since the pre-vious data is no longer available, the GZSL model tends to catastrophically forget knowledge pertaining to previ-ous tasks when sequentially trained and reused over time.
This necessitates concerted effort toward carefully design-ing problem settings that resemble the occurence of objects in the real world, and building models that can adapt over time and seamlessly tackle such challenges.
Very recently, sporadic efforts [6, 9, 26] have been made towards designing models that can dynamically adapt and generalize on addition of new seen and unseen classes. The aforementioned works term this setting as continual gener-alized zero-shot learning (CGZSL). However, these efforts are nascent, and vary in the deﬁnition of the problem set-ting, practicality, data splits and protocols followed – thus inhibiting fair comparison and a clear path forward. To ad-dress this issue and motivated by the need for progress in this direction, in this work, we ﬁrstly consolidate the dif-ferent CGZSL settings tackled in these recent efforts, and clearly segregate existing methods and settings according to the challenges they tackle. We propose a more ﬂexible and realistic Online-CGZSL setting which more closely resem-bles scenarios encountered in the real world. In addition, we propose a uniﬁed framework that employs a bi-directional incremental alignment-based replay strategy to seamlessly adapt and generalize to new seen and unseen classes that arrive over time. Our replay strategy is based on a feature-generative architecture, and hence does not require storing samples from previous tasks. We also use a static archi-tecture for incremental learning (as against using a model-growing one) in order to facilitate scalability and efﬁciency.
In summary, the key contributions of our work are below:
• We identify the different challenges of the relatively new
CGZSL setting, and consolidate its different variants based on the challenges they tackle and restrictions they impose. We hope that this will enable fair comparison among such approaches and further progress in the ﬁeld.
• We establish a practical, but more challenging, Online-CGZSL setting which more closely resembles real-world scenarios encountered in practice.
• We propose a novel feature-generative framework to ad-dress the different CGZSL setting variants, which avoids catastrophic forgetting through bi-directional incremen-tal alignment thereby allowing forward semantic knowl-edge transfer from previous tasks and enabling general-ization.
• We perform extensive experiments and analysis on three different CGZSL settings on well-known benchmark datasets: AWA1, AWA2, Attribute PASCAL and Yahoo (aPY), Caltech-UCSD-Birds (CUB) and SUN, demon-strating the promise of our approach. We observe that our model consistently improves over baselines and existing approaches, especially on the more challenging Online setting. 2.