Abstract
Pseudo-LiDAR 3D detectors have made remarkable progress in monocular 3D detection by enhancing the ca-pability of perceiving depth with depth estimation networks, and using LiDAR-based 3D detection architectures. The ad-vanced stereo 3D detectors can also accurately localize 3D objects. The gap in image-to-image generation for stereo views is much smaller than that in image-to-LiDAR gener-ation. Motivated by this, we propose a Pseudo-Stereo 3D detection framework with three novel virtual view gener-ation methods, including image-level generation, feature-level generation, and feature-clone, for detecting 3D objects from a single image. Our analysis of depth-aware learning shows that the depth loss is effective in only feature-level virtual view generation and the estimated depth map is ef-fective in both image-level and feature-level in our frame-work. We propose a disparity-wise dynamic convolution with dynamic kernels sampled from the disparity feature map to filter the features adaptively from a single image for generating virtual image features, which eases the feature degradation caused by the depth estimation errors. Till sub-mission (November 18, 2021), our Pseudo-Stereo 3D de-tection framework ranks 1st on car, pedestrian, and cyclist among the monocular 3D detectors with publications on the
KITTI-3D benchmark. The code is released at https:
//github.com/revisitq/Pseudo-Stereo-3D. 1.

Introduction
Detecting the 3D objects from monocular image enables the machine to perceive and understand the 3D real world, which has a wide applications including virtual reality, robotics and autonomous driving. Monocular 3D detection is a challenging task because of the lack of accurate 3D in-formation in a single image. However, the huge potential in such a cheap and easy-to-deploy solution to 3D detection at-tracts more and more researchers. Remarkable progress has been made in Pseudo-LiDAR detectors [11, 29, 34, 43, 52] that use a pre-trained depth estimation network to generate
Pseudo-LiDAR representations, e.g. pseudo point clouds
Figure 1. Overview of our Pseudo-Stereo 3D detection framework with novel virtual view generation methods: (a) Image-level to use the generated disparity map for forward warping the input left im-age into a virtual right image, (b) Feature-level to convert the left features into virtual right features. A feature conversion baseline is to clone the left features as the special case in stereo views. and pseudo voxels, and then feed them to LiDAR-based 3D detectors. It shows that enhancing the capability of per-ceiving depth can improve monocular 3D detection perfor-mance. However, there is a huge performance gap between
Pseudo-LiDAR and LiDAR-based detectors because of the errors in image-to-LiDAR generation [32].
Apart from LiDAR-based detectors, the stereo 3D detec-tors [9,17] can also accurately localize 3D objects. Also, the gap in image-to-image generation for stereo views is much smaller than that in image-to-LiDAR generation, which is
Instead of Pseudo-LiDAR, a cross-modality conversion. we propose a novel Pseudo-Stereo 3D detection framework for monocular 3D detection. Our Pseudo-Stereo 3D detec-tion framework generates a virtual view from a single input image to compose Pseudo-Stereo views with the generated virtual view and the input view. Then, we feed the Pseudo-Stereo views to stereo 3D detectors for detecting 3D objects from the single input image. We use one of the most ad-vanced stereo 3D detectors, LIGA-Stereo [17], as the base detection architecture. Thus, the virtual view generation is the key to our Pseudo-Stereo 3D detection framework.
We take KITTI-3D as an example only to explain how to generate a virtual view. Note that the virtual view does not require the ground-truth actual view in the dataset for training. In KITTI-3D, the monocular 3D detection is per-formed on the left image from the stereo views. Our aim
is to construct Pseudo-Stereo views by generating the vir-tual right view from the input left view in either image-level or feature-level for monocular 3D detection. As shown in
Figure 1, we propose two types of virtual view generation: (a) image-level to generate the virtual right image from the input left image and (b) feature-level to convert the left fea-tures into virtual right features.
In image-level, we con-vert the estimated depth map from the input left image into disparities and use them to forward warp the input left im-age into a virtual right image to compose the Pseudo-Stereo views with the input left view. In feature-level, we propose a disparity-wise dynamic convolution with dynamic kernels sampled from disparity feature map to filter the left features adaptively for generating virtual right features, which eases the feature degradation caused by the depth estimation er-rors. Also, a simple feature conversion is to clone the left features as the virtual right features, which is the special case of stereo views that the virtual right view is the same as the left view. We summarize our contributions:
• We propose a Pseudo-Stereo 3D detection framework with three novel virtual view generation methods, in-cluding image-level generation, feature-level genera-tion and feature-clone, for detecting 3D objects from a single image, achieving significant improvements in monocular 3D detection. The proposed framework with feature-level virtual view generation ranks 1st among the monocular 3D detectors with publications across three object classes on KITTI-3D benchmark.
• In our framework, we analyze two major effects of learning depth-aware feature representations, includ-ing the estimated depth map and the depth loss as the depth guidance. It is very interesting to find that the depth loss is effective in feature-level virtual view gen-eration only and the estimated depth map is effective in both image-level and feature-level for depth-aware feature learning.
• In our feature-level virtual view generation method, we propose a disparity-wise dynamic convolution with dy-namic kernels from disparity feature map to adaptively filter the features from a single image for generating virtual image features, which avoids the feature degra-dation caused by the depth estimation errors. 2.