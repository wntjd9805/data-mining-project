Abstract
The past few years have witnessed an increasing interest in improving the perception performance of LiDARs on au-tonomous vehicles. While most of the existing works focus on developing new deep learning algorithms or model ar-chitectures, we study the problem from the physical design perspective, i.e., how different placements of multiple Li-DARs inﬂuence the learning-based perception. To this end, we introduce an easy-to-compute information-theoretic sur-rogate metric to quantitatively and fast evaluate LiDAR placement for 3D detection of different types of objects. We also present a new data collection, detection model training and evaluation framework in the realistic CARLA simula-tor to evaluate disparate multi-LiDAR conﬁgurations. Us-ing several prevalent placements inspired by the designs of self-driving companies, we show the correlation between our surrogate metric and object detection performance of different representative algorithms on KITTI through exten-sive experiments, validating the effectiveness of our LiDAR placement evaluation approach. Our results show that sen-sor placement is non-negligible in 3D point cloud-based ob-ject detection, which will contribute to 5% ∼ 10% perfor-mance discrepancy in terms of average precision in chal-lenging 3D object detection settings. We believe that this is one of the ﬁrst studies to quantitatively investigate the inﬂu-ence of LiDAR placement on perception performance. 1.

Introduction
LiDAR sensors are becoming the critical 3D sensors for autonomous vehicles (AVs) since they could provide accu-rate 3D geometry information and precise distance mea-sures under various driving conditions [26]. The point cloud data generated from LiDARs has been used to perform a se-ries of perception tasks, such as object detection and track-ing [38, 39, 41], SLAM and localization [27, 51], etc.
*equal contribution
†work done while interning at CMU, prior to current afﬁliations (a) Toyota (b) Cruise (c) Pony.ai (d) Argo AI (e) Ford (f) Zoox
Figure 1. Different multi-LiDAR conﬁgurations used in different autonomous vehicles [1–6].
High-quality point cloud data and effective perception algorithms are usually both required to achieve accurate 3D object detection in practice [45]. A number of stud-ies propose to improve the 3D object detection perfor-mance for point cloud data by developing novel percep-tion algorithms, which assume that the data is of high qual-ity [15, 22, 39, 41, 46]. However, only a little literature con-siders the LiDAR perception problem from the viewpoint of data acquisition [21, 25, 28] and LiDAR placement. We be-lieve that this new perspective should be equally crucial for real-world AV applications since improper LiDAR place-ment may cause poor-quality sensing data, and thus cor-rupt the perception algorithm and lead to poor performance
[11, 21, 24, 25, 30, 45]. In addition, LiDAR is an expensive sensor, so maximizing its utility to save the deployment cost is also important for mass production. Therefore, we aim to investigate the interplay between LiDAR sensor placement and perception performance for AVs. We use placement and conﬁguration interchangeably throughout this paper.
However, it is not easy to evaluate the efﬁcacy of dif-ferent LiDAR placement layouts based on the perception performance in the real world, which comes with effort-costly and time-consuming full loops of LiDAR deploy-ment, data collection, model training, and performance evaluation. Moreover, as shown in Figure 1, many com-panies’ self-driving vehicles are equipped with more than 2
LiDARs. As the LiDAR number increases, the cost of Li-DAR conﬁguration evaluation and optimization will also in-crease exponentially. Therefore, it is a crucial but still open problem to accelerate the quantitative evaluation of the Li-DAR conﬁgurations regarding perception performance with low cost. Thoroughly studying the interplay between Li-DAR sensor placement and perception performance is es-sential to AV perception systems, saving deployment cost and without sacriﬁcing driving safety.
In this paper, we study the perception system from the sensing perspective and focus on investigating the relation-ship between LiDAR conﬁgurations and 3D object detec-tion using our evaluation framework shown in Figure 2. The contributions of this paper are summarized as follows:
• We establish a systematic framework to evaluate the object detection performance of different LiDAR placements and investigate prevalent LiDAR place-ments inspired by self-driving companies, showing that LiDAR placement dramatically inﬂuences the per-formance of object detection up to 10% in challenging 3D detection settings. As far as we know, we are one of the ﬁrst works to quantitatively study the interplay be-tween LiDAR placement and perception performance.
• We propose a novel surrogate metric with maximum information gain (S-MIG) to accelerate the evaluation of LiDAR placement by modeling object distribution through the proposed scalable Probabilistic Occupancy
Grids (POG). We show the correlation between the sur-rogate metric and detection performance, which is the-oretically explained via S-MIG and validates its effec-tiveness for the LiDAR conﬁguration evaluation.
• We contribute an automated multi-LiDAR data collec-tion and detection model evaluation pipeline in the re-alistic CARLA simulator and conduct extensive exper-iments with state-of-the-art LiDAR-based 3D object detection algorithms. The results reveal that LiDAR placement plays an important role in the perception system. The code for the framework is available on https://github.com/HanjiangHu/Multi-LiDAR-Placement-for-3D-Detection. 2.