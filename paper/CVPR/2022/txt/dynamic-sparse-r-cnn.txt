Abstract
Sparse R-CNN is a recent strong object detection base-line by set prediction on sparse, learnable proposal boxes and proposal features. In this work, we propose to improve
Sparse R-CNN with two dynamic designs. First, Sparse R-CNN adopts a one-to-one label assignment scheme, where the Hungarian algorithm is applied to match only one pos-itive sample for each ground truth. Such one-to-one as-signment may not be optimal for the matching between the learned proposal boxes and ground truths. To ad-dress this problem, we propose dynamic label assignment (DLA) based on the optimal transport algorithm to assign increasing positive samples in the iterative training stages of Sparse R-CNN. We constrain the matching to be gradu-ally looser in the sequential stages as the later stage pro-duces the reﬁned proposals with improved precision. Sec-ond, the learned proposal boxes and features remain ﬁxed for different images in the inference process of Sparse R-CNN. Motivated by dynamic convolution, we propose dy-namic proposal generation (DPG) to assemble multiple pro-posal experts dynamically for providing better initial pro-posal boxes and features for the consecutive training stages.
DPG thereby can derive sample-dependent proposal boxes and features for inference. Experiments demonstrate that our method, named Dynamic Sparse R-CNN, can boost the strong Sparse R-CNN baseline with different backbones for object detection. Particularly, Dynamic Sparse R-CNN reaches the state-of-the-art 47.2% AP on the COCO 2017 validation set, surpassing Sparse R-CNN by 2.2% AP with the same ResNet-50 backbone. 1.

Introduction
Object detection is a fundamental task in computer vi-sion which aims at predicting a set of objects with loca-tions and corresponding pre-deﬁned categories in a given image. It has been widely applied in multiple ﬁelds includ-ing intelligent surveillance and autonomous driving. Ob-*Equal contribution.
Figure 1. Performance vs. training epochs on the COCO 2017 validation set. All results are reported with single-scale infer-ence using the ResNet-50 backbone. Our Dynamic Sparse R-CNN achieves the state-of-the-art 47.2% AP with the same 36 training epochs as Sparse R-CNN. Circles: Transformer-based methods.
Triangles: CNN-based methods. ject detection has witnessed a rapid development in the recent years, with varying feature extraction backbones from convolutional neural network (CNN) [7, 11, 24, 27] to
Transformer [6, 18] and varying detection pipeline designs
[2, 17, 22, 23, 25, 28]. The detectors can mainly be divided into one-stage, two-stage and multi-stage methods accord-ing to the regression times. One-stage detectors [17, 28] di-rectly predict the regression targets and categories of objects in a given image without the reﬁnement step. Two-stage de-tectors [4,9,14,23] ﬁrst generate a limited number of candi-date proposals for foreground (e.g., region proposal network (RPN)) and then pass the proposals to the detection network to reﬁne the location and category. Multi-stage detectors [1] would reﬁne the location and category multiple times with improved performance but often require large computation overhead. One-stage methods generally can be divided into anchor-based and anchor-free detectors. Anchor-based de-tectors [15, 17, 22] design dense pre-deﬁned anchors, tile anchors across the image, and then directly predict category and reﬁne the coordinates of anchors. However, manual an-chor conﬁgurations could be sub-optimal for the ﬁnal per-formance. Anchor-free detectors [13, 28] are proposed to overcome this issue by removing the anchor design. They
typically use center points or regions inside ground truth to deﬁne positive proposals and predict offsets to obtain ﬁnal bounding boxes.
CNN detector obtains a large AP gain of 2.2%, reaching the state-of-the-art 47.2% AP on the COCO validation set with
ResNet-50.
Recently, Transformer-based detectors [2, 20, 25, 29] have been proposed by formulating object detection as a set prediction problem using the Transformer encoder and decoder architecture. These methods replace anchor mech-anisms with a small number of learnable object queries, which can model the relationships between objects and global image context to output the ﬁnal predictions. Hun-garian algorithm is used to ﬁnd a bipartite matching be-tween ground truths and predictions based on the combined loss of classiﬁcation and regression. The label assignment in these detectors is a one-to-one way where only one single detection matches one ground truth during training.
Motivated by existing CNN-based methods using many-to-one label assignment schemes [8,15,28], We assume that assigning multiple positives to a GT can optimize the pro-posals more efﬁciently and can promote the detector train-ing for better performance. Thus, we propose dynamic la-bel assignment (DLA) with many-to-one matching based on the optimal transport algorithm for the strong baseline of
Sparse R-CNN. We also adopt gradually increasing positive samples assigned to GTs in the iterative stages of Sparse
R-CNN. Since each stage produces reﬁned proposal boxes and features for the next one, we expect to constrain the matching between GTs and prediction boxes to be stricter in the early stages and looser in the later stages owing to the increasing precision of predictions in the sequential stages. Moreover, in Sparse R-CNN, the object queries (i.e., proposal boxes and proposal features) are learnable during training but remain ﬁxed for different images during infer-ence. Motivated by dynamic convolution [3], we propose dynamic proposal generation (DPG) to provide better initial proposal boxes and features in the ﬁrst iterative stage. Com-pared to ﬁxed proposals, DPG can aggregate multiple paral-lel proposal experts which are sample-dependent and output dynamic proposals for inference. We name our method as
Dynamic Sparse R-CNN, which reaches the state-of-the-art 47.2% AP on the COCO 2017 validation set, surpassing the
Sparse R-CNN baseline by a large margin of 2.2% AP with the same ResNet-50 backbone (Figure 1).
Our main contributions can be summarized as follows. (1) We point out that many-to-one label assignment in
Transformer-based detection is more reasonable and effec-tive than the one-to-one scheme. We apply the optimal transport assignment method into Sparse R-CNN and as-sign gradually increasing positive samples to GTs in the it-erative stages. (2) We design a dynamic proposal generation mechanism to learn multiple proposal experts and assemble them for generating dynamic proposal boxes and features for inference. (3) We integrate the two dynamic designs into Sparse R-CNN and the resulting Dynamic Sparse R-2.