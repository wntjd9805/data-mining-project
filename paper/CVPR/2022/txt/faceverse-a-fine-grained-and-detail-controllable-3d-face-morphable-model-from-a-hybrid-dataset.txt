Abstract
We present FaceVerse, a fine-grained 3D Neural Face
Model, which is built from hybrid East Asian face datasets containing 60K fused RGB-D images and 2K high-fidelity 3D head scan models. A novel coarse-to-fine structure is proposed to take better advantage of our hybrid dataset. In the coarse module, we generate a base parametric model from large-scale RGB-D images, which is able to predict ac-curate rough 3D face models in different genders, ages, etc.
Then in the fine module, a conditional StyleGAN architec-ture trained with high-fidelity scan models is introduced to enrich elaborate facial geometric and texture details. Note that different from previous methods, our base and detailed modules are both changeable, which enables an innovative application of adjusting both the basic attributes and the facial details of 3D face models. Furthermore, we pro-pose a single-image fitting framework based on differen-tiable rendering. Rich experiments show that our method outperforms the state-of-the-art methods. 1.

Introduction 3D human face modeling has been a hot topic in com-puter vision and computer graphics, which enables a wide range of applications such as film, video games, mixed re-ality, etc. Since 3D Morphable Model (3DMM) [4] was proposed in 1999, it has been one of the most powerful tools in face-related researches due to its effective control of facial shape, expression and texture. However, recent researches pose more challenges to 3DMM in terms of ac-curacy, photo-realistic details and editability. On one hand, the performance of 3DMMs is limited due to the difficulty of data acquisition. On the other hand, given a coarse face model, detailed facial geometry and texture are still not changeable in the previous methods [26, 43], which lim-its the detailed adjustment of facial features. To overcome the above issues, we propose a hybrid dataset and design a coarse-to-fine structure to combine high generalization abil-ity and fidelity. Furthermore, facial geometry and texture details, like small changes of facial features, can also be parameter-changeable.
At one end of the spectrum, existing 3D face datasets are usually limited in either scale or fidelity. The captur-ing system can be divided into two categories: sparse or dense camera arrays [6, 19, 26, 31, 43] and consumer depth sensors [8, 18, 30, 45]. The former system requires elab-orated setup and the data collection process is quite time-consuming, which limits the scale of captured dataset to a few hundreds. The latter system is off-the-shelf and takes less time in data acquisition, which allows collecting RGB-D data from a large number of identities. However, the cap-tured RGB-D data usually suffers from low resolution and low precision. The insufficiency of scale or fidelity limits
the performance of previous works in either generalization or fidelity. Therefore, we propose to build a hybrid dataset.
At the other end, the formulation of previous 3DMMs can not represent parameter-changeable facial details.
PCA-based methods [6, 18, 27, 30, 45] can describe shape and expression changes in an effective way. Multi-linear methods [8, 31] present a larger parameter space to cover more information of the corresponding datasets. Non-linear methods [21, 40] use neural networks to achieve better flex-ibility. However, all the above methods can not repre-sent the facial details, like the detailed shape of facial fea-tures. Recent methods [26,43] show strong capability in 3D fine-grained face model reconstruction, but they still rely on pre-trained super-resolution or displacement prediction networks, which means the facial details are not parame-ter changeable. To conclude, a 3DMM representation with changeable facial details has not been proposed yet.
To overcome the limitations above, in this paper, we pro-pose FaceVerse, which achieves high generalization abil-ity and fidelity using a hybrid dataset and can generate parameter-changeable facial details. Firstly, we collect a hybrid dataset of East Asians consisting of a large-scale dataset captured by consumer depth sensors and a high-fidelity dataset captured by a multi-camera system. Sec-ondly, we propose a coarse-to-fine structure to scheme our parametric model. The base model is first built from the large-scale dataset, which guarantees strong generalization ability and basic fidelity of the base model. Then, input with the UV maps unwrapped from the base model, we build our detailed model using a novel conditional StyleGAN ar-chitecture, which can generate changeable facial details in-put with additional latent code and noise while preserving the basic facial attributes provided by the input base model.
Different from the original StyleGAN [22, 23], our genera-tor takes advantage of multi-scale features encoded from the input maps to constrain the output maps and we use an ad-ditional normal discriminator to further enrich the geometry details. Note that two conditional StyleGAN networks are used in two phases: detail generation and expression refine-ment. Finally, we propose a single-image fitting pipeline based on differentiable rendering, which also follows the coarse-to-fine idea. Benefiting from the hybrid dataset, the coarse-to-fine scheme and the novel conditional StyleGAN architecture, the proposed FaceVerse shows better perfor-mance than previous 3DMM methods both qualitatively and quantitatively.
Our contributions are summarized as follows:
• We build a hybrid dataset and propose a coarse-to-fine scheme to make better use of the dataset: the large-scale RGB-D dataset guarantees high generalization ability of our base model and the high-fidelity scan dataset helps to enrich the geometry and texture details of our detailed model.
• We propose a conditional StyleGAN architecture with normal discriminators, which allows changing facial details while preserving basic facial attributes.
• The proposed FaceVerse provides a powerful tool for face modeling of East Asians and we have released our pre-trained models and the detailed dataset to public for research purpose1. 2.