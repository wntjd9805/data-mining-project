Abstract
This paper presents a new solution for low-light image enhancement by collectively exploiting Signal-to-Noise-Ratio-aware transformers and convolutional models to dynamically enhance pixels with spatial-varying opera-tions. They are long-range operations for image regions of extremely low Signal-to-Noise-Ratio (SNR) and short-range operations for other regions. We propose to take an SNR prior to guide the feature fusion and formulate the SNR-aware transformer with a new self-attention model to avoid tokens from noisy image regions of very low SNR. Extensive experiments show that our framework consistently achieves better performance than SOTA approaches on seven representative benchmarks with the same structure. Also, we conducted a large-scale user study with 100 participants to verify the superior perceptual quality of our results. The code is available at https://github.com/dvlab-research/SNR-Aware-Low-Light-Enhance. 1.

Introduction
Low-light imaging is critical for many tasks, such as object and action recognition at night [18, 27]. Low-light images are generally with poor visibility for human perception. Similarly, downstream vision tasks can be affected when taking low-light images directly as the input.
Several methods have been proposed to enhance low-light images. The de facto approach nowadays is to develop neural networks that learn to manipulate color, tone, and contrast to enhance low-light images [12, 15, 41, 56], while some recent works account for noise in images [29, 48]. In this paper, our key insight is that different regions in a low-light image can have different characteristics of lightness, noise, visibility, etc. Regions of extremely low lightness are heavily corrupted by noise, while other regions in the same image can still have reasonable visibility and contrast.
For better overall image enhancement, we should adaptively consider different regions in the low-light images.
To this end, we study the relation between signal and noise in image space by exploring Signal-to-Noise-Ratio
Figure 1. Our approach consistently achieves better performance in terms of PSNR/SSIM over 10 SOTA methods on 7 different benchmarks with the same network structure. Each plot is for comparison on one benchmark dataset. (SNR) [3, 54] for achieving spatial-varying enhancement.
In particular, regions of lower SNR are typically unclear.
So we exploit non-local image information in longer spatial range for image enhancement. On the other hand, regions of relatively higher SNR typically have higher visibility and less noise. Thus local image information is typically sufficient. Fig. 2 shows a low-light image example for illustration. Further discussion is presented in Sec. 3.1.
Our solution to low-light image enhancement in the
RGB domain is to collectively exploit long- and short-In the deepest hidden layer, we design range operations. two branches. The long-range branch with a transformer structure [38] is to capture non-local information and the short-range one with convolutional residual blocks [17] captures local information. When enhancing each pixel, we determine the contribution of local (short-range) and non-local (long-range) information dynamically based on the
Figure 2. Low-light image enhancement requires spatial-varying operations. The blue (or red) region has extremely low (or relatively high) SNR. It offers inadequate (or sufficient) local image information for image enhancement. In operations, we use long-range image information for the blue region, since it has been heavily corrupted by noise. We linearly scale up brightness on the right for visualizing noise in different image regions. pixel’s signal-to-noise ratio. Hence, in regions of high SNR, local information plays a vital role during the enhancement, whereas in regions of very low SNR, non-local messages are effective. To achieve such spatial-varying operations, we construct an SNR prior and use it to guide feature fusion.
Also, we modify the attention mechanism in the transformer structure and propose the SNR-aware transformer. Unlike existing transformer structure, not all tokens contribute to the attention computation. We consider only the tokens with sufficient SNR values to avoid noise influence from the very-low-SNR regions.
Our framework effectively enhances low-light images of dynamic noise levels.
Extensive experiments were conducted on 7 representative datasets: LOL (v1 [45], v2-real [53], & v2-synthetic [53]), SID [5], SMID [4], and
SDSD (indoor & outdoor) [39]. As shown in Fig. 1, our framework outperforms 10 SOTA approaches on all datasets with the same structure. Further, we conduct large-scale user study with 100 participants to verify the effectiveness of our approach. Qualitative comparison is presented in
Fig. 3. Overall, our contribution is threefold.
• We propose a new signal-to-noise-aware framework that simultaneously adopts a transformer structure and a convolutional model for achieving spatial-varying low-light image enhancement with an SNR prior.
• We design an SNR-aware transformer with a new self-attention module for low-light image enhancement.
• We conducted extensive experiments on seven rep-resentative datasets, manifesting that our framework consistently outperforms a rich set of SOTA methods. 2.