Abstract
Preserving geometric structures in the scene plays a vi-tal role in image stitching. However, most of the existing methods ignore the large-scale layouts reflected by straight lines or curves, decreasing overall stitching quality. To ad-dress this issue, this work presents a structure-preserving stitching approach that produces images with natural vi-sual effects and less distortion. Our method first employs deep learning-based edge detection to extract various types of large-scale edges. Then, the extracted edges are sampled to construct multiple groups of triangles to represent geo-metric structures. Meanwhile, a GEometric Structure pre-serving (GES) energy term is introduced to make these tri-angles undergo similarity transformation. Further, an op-timized GES energy term is presented to reasonably deter-mine the weights of the sampling points on the geometric structure, and the term is added into the Global Similar-ity Prior (GSP) stitching model called GES-GSP to achieve a smooth transition between local alignment and geomet-ric structure preservation. The effectiveness of GES-GSP is validated through comprehensive experiments on a stitch-ing dataset. The experimental results show that the pro-posed method outperforms several state-of-the-art methods in geometric structure preservation and obtains more nat-ural stitching results. The code and dataset are available at https://github.com/flowerDuo/GES-GSP-Stitching. 1.

Introduction
With the popularity of multimedia devices such as smart-phones and digital cameras, the requirement to obtain high-quality panoramic images is increasing [9, 20]. Although, image stitching [24] has made tremendous progress, it is still a challenge to produce high-quality panoramic im-ages [23] due to the wide baseline, large parallax, and low-texture under complex stitching scenes [24].
The overall naturalness is an important factor affect-ing the quality of image stitching. The existing stitching methods can be roughly classified into single feature-based alignment and multiple features-based alignment. The for-mer relies on the homography transformation estimated by point features. The AutoStitch [1] uses global homogra-phy transformation for image mapping, but it cannot handle multi-plane scenes. In the dual homography warp (DHW)
[4], the scene is simply considered composed of a per-spective plane and a ground plane. Furthermore, the as-projective-as-possible (APAP) warps [27] divides the image into meshes and estimates a set of smooth transformations for each grid to improve local alignment. The robust elastic warping (ELA) [10] applies the Bayesian model to improve local alignment for images with parallax. However, the use of only one or more homographic transformations may re-sult in excessive perspective transformation and affect the overall naturalness of the stitching result. Therefore, some works such as the smoothly varying affine (SVA) stitch-ing [16], the shape-preserving half-projective (SPHP) [2], the adaptive as-natural-as-possible (AANAP) warps [14] and the global similarity prior (GSP) model [3] try to obtain more natural stitching results by exploring the advantage of local or global similarity transformation.
On the other hand, joint alignment of point features and line features [8, 12, 13, 25] at the same time can better es-timate homography transformation attributed to its strong constraint for image stitching. Li et al. first proposed dual-feature including point and line features for warping-based motion model estimation (DFW) [12] to handle the lack of features during stitching. The single-perspective warp (SPW) [13] solves projective distortion to a certain extent, and Xiang et al. [25] proposed a line-guided local warping method with a global similarity constraint. Jia et al. [8] pro-posed to leverage line-point consistence (LPC) to preserve structures, which introduces global collinear structures to enhance the desired characters for image warping. Then,
Zhang et al. [30] applied LPC to the regularization [6] of the stitched result.
†Corresponding author: Jifeng Ning, njf@nwsuaf.edu.cn
Generally, the feature registration method mainly de-Figure 1. An example of stitching 10 images. (a) The AutoStitch’s [1] result is severely distorted. (b) The person on the right side is distorted in the APAP’s [27] result. (c) Several misalignments (red and green closeup) in the ELA’s [10] result. (d) The SPW’s [13] result exhibits significant wrong scale at the right end. (e) There are some distortions, e.g., the floor and carpet in the red box become curved in the result obtained by GSP [3]. (f) Our result preserves the salient geometric structures in the scene. pends on more homography transformations and local or global similarity constraints to improve stitching quality.
However, the curve constraints effectively reflecting the critical structure of the scene are not considered. Although the stitching method based on dual features [8, 13, 25] can better keep the scene structure compared with the method based on a single feature, it needs to find the corresponding relationship between the point and the line features among the stitched images. Also, when it is extended to multiple images, finding the correspondence becomes more compli-cated. Besides, the geometric structure of the scene contains not only straight lines but also curves with better integrity.
Interestingly, the seam-guided local alignment for parallax-tolerant image stitching (Seagull) [15] performs similarity transformation on the edges to improve stitching quality [5], indicating the importance of geometric structure informa-tion.
In this work, curve structures are introduced into sin-gle feature-based stitching model to preserve the geometric structure better than the methods based on point and line features [8, 12, 13, 25]. Different from Seagull [15] only handling a local alignment near the seam line, this work not only ensures the alignment accuracy but also protects the geometric structure in all overlapping and non-overlapping regions. Our method is built on GSP [3] because of the whole naturalness of its stitching result. This work designs a special scheme to protect line and curve structures in over-lapping regions and non-overlapping regions to obtain more natural stitching results. example in [19]. It can be seen that the stitching result of
AutoStitch [1] is severely distorted. In the stitching result of APAP [27], the person on the right side is distorted. In the stitching result of ELA [10], the salient geometric struc-tures are not destroyed, but there are several misalignments (red and green closeup). In the stitching result of SPW [13], there is a significant wrong scale at the right end. GSP [3] solves the problem of limited field of view, but there are dis-tortions in the local geometric structure, e.g., the floor and carpet in the red box become curved and the toy track is too small in scale than the real scene. The stitching result of our method maintains the geometric structures of carpets, toys, and floors well, and it also looks more natural locally and globally. Our method performs significantly better than
AutoStitch, APAP, SPW, and GSP and slightly better than
ELA. Generally, the contributions of this work are summa-rized as follows:
• This work fully utilizes the line and edge features ex-tracted from the stitched images to represent the large-scale geometric structure to obtain high-quality para-noiac images.
• A geometric structure-preserving energy term is added to the GSP stitching model, and the weights of the sampling points on geometric structures are set reason-ably to ensure a smooth transition between local align-ment and geometric structure preservation to achieve natural stitching results.
Figure 1 illustrates the stitching result of a challenging
• The experiments on 50 sets of images demonstrate that
the proposed method outperforms several state-of-the-art structure-preserving methods. 2.