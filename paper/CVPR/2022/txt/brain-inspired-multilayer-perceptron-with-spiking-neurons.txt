Abstract
Recently, Multilayer Perceptron (MLP) becomes the hotspot in the field of computer vision tasks. Without in-ductive bias, MLPs perform well on feature extraction and achieve amazing results. However, due to the simplic-ity of their structures, the performance highly depends on the local features communication machenism. To further improve the performance of MLP, we introduce informa-tion communication mechanisms from brain-inspired neu-ral networks. Spiking Neural Network (SNN) is the most famous brain-inspired neural network, and achieve great success on dealing with sparse data. Leaky Integrate and
Fire (LIF) neurons in SNNs are used to communicate be-tween different time steps.
In this paper, we incorporate the machanism of LIF neurons into the MLP models, to achieve better accuracy without extra FLOPs. We pro-pose a full-precision LIF operation to communicate be-tween patches, including horizontal LIF and vertical LIF in different directions. We also propose to use group LIF to extract better local features. With LIF modules, our
SNN-MLP model achieves 81.9%, 83.3% and 83.5% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively, which are state-of-the-art re-sults as far as we know. The source code will be available at https : //gitee.com/mindspore/models/tree/master/ research/cv/snn mlp. 1.

Introduction
With the help of inductive bias, convolution neural net-work (CNN) has become the most popular algorithm in several computer vision tasks, including image classifica-tion [19], semantic segmentation [52] and object detec-tion [4, 18]. CNN is easier to train and has fewer parame-ters compared with MLP, but inductive bias also limits its learning ability. Nowadays, CNNs are facing challenges from new types of vision backbones, like Transformers and
âˆ—Corresponding author
MLPs. Transformers [47] are initially proposed in the area of Nature Language Process (NLP), and researchers find that the self-attention machenism is also suitable for com-puter vision tasks [11]. MLP receives wide-spread atten-tion in academics, researchers find that easy operations like
MLPs are as good as self-attention module. Without in-ductive bias, MLPs show better learning ability on larger datasets. The key point to utilize Transformers and MLPs is to divide images into patches and then apply the calculation to each patch. At present, one of the hotspots of research is how to communicate between patches. Permutation [22] and shift operation [30, 56] are the most common choice, and they all achieve admirable results.
In terms of information communication, SNN [34] has a mature mechanism to deal with it. SNN is a kind of brain-inspired neural networks, and are frequently used to deal with sparse data, such as dynamic vision sensor (DVS) [28].
The energy efficiency of SNN is highly competitive while
SNN suffers from accuracy loss compared with CNN. The transformation from CNN/ANN to SNN often means up to 10% accuracy drop on ImageNet and large time steps up to hundreds and thousands. Recently, the researches on SNN have been developed into two tracks. One shows how to transform CNN to SNN more efficiently and loss-less [40, 41]. The other shows how to train SNN directly to achieve comparable accuracy with CNN [50, 59]. Now state-of-the-art ANN-SNN conversion could adapt to clas-sic CNN models with only 1%-2% accuracy drop while the time step is larger than 1000 [41]. And state-of-the-art SNN training method could achieve 5%-8% accuracy drop with less than 10 time steps [50, 59]. More time steps mean larger latency, so the performance of SNNs on general vi-sion dataset like ImageNet is still not satisfying.
As we mentioned before, spiking neuron is used to com-In this paper, we municate between different time step. introduce the brain-inspired spiking neurons (i.e. the LIF module in our paper) to communicate the information be-tween patches in the MLP models. We utilize LIF neuron in a full-precision manner to keep the information from the input patches. Moreover, we propose the horizontal LIF and
Figure 1. (a) FLOPs-Accuracy Pareto frontier. (b) Throughput-Accuracy Pareto frontier. The proposed SNN-MLP achieves the best results among these MLPs on both FLOPs-Accuracy and Throughput-Accuracy trade-off. vertical LIF to inhert the knowledge in different directions and the group LIF to extract better local features. Exper-iments on classification, segmenation and detection show that the proposed SNN-MLP models can achieve the state-of-the-art performance among existing MLPs. Especially, the proposed model achieves 81.9%, 83.3% and 83.5% top-1 accuracy on ImageNet dataset with only 4.4G, 8.5G and 15.2G FLOPs, respectively. The FLOPs-Accuracy Pareto frontier is shown in Figure 1. 2.