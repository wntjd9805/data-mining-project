Abstract
Iterative denoising-based generation, also known as de-noising diffusion models, has recently been shown to be comparable in quality to other classes of generative mod-els, and even surpass them. Including, in particular, Gen-erative Adversarial Networks, which are currently the state of the art in many sub-tasks of image generation. However, a major drawback of this method is that it requires hun-dreds of iterations to produce a competitive result. Recent works have proposed solutions that allow for faster gen-eration with fewer iterations, but the image quality grad-ually deteriorates with increasingly fewer iterations being applied during generation. In this paper, we reveal some of the causes that affect the generation quality of diffusion models, especially when sampling with few iterations, and come up with a simple, yet effective, solution to mitigate them. We consider two opposite equations for the iterative denoising, the ﬁrst predicts the applied noise, and the sec-ond predicts the image directly. Our solution takes the two options and learns to dynamically alternate between them through the denoising process. Our proposed solution is general and can be applied to any existing diffusion model.
As we show, when applied to various SOTA architectures, our solution immediately improves their generation quality, with negligible added complexity and parameters. We ex-periment on multiple datasets and conﬁgurations and run an extensive ablation study to support these ﬁndings. 1.

Introduction
Over the past few years, deep generative models have reached the ability to generate high-quality samples in var-ious domains, including images [2], speech [25], and nat-ural language [3]. For image generation, generative mod-els can be divided into two main branches: approaches based on generative adversarial networks (GAN) [7] and log-likelihood-based methods, such as variational autoen-coders (VAE) [15], autoregressive models [26], and normal-izing ﬂows [14,29]. Log-likelihood models have the advan-tage of possessing a straightforward objective, which makes them easier to optimize, while GANs are known to be un-stable during training [8, 31]. However, until recently, well optimized GAN models outperformed their log-likelihood counterparts in generation quality [2, 11–13].
This changed when Ho et al. [9] introduced a new type of log-likelihood model called the Denoising Diffusion Prob-abilistic Model (DDPM). With this model, image quality surpasses GANs [6], while it is also very stable and easy to train. DDPMs follow the concept of iterative denois-ing: given a noisy image xt, it is gradually denoised by predicting a less noisy image xt−1. This process, when done over hundreds (or thousands) of iterations, is able to generate images with very high quality and diversity, even when starting from random noise. DDPMs have many com-puter vision applications, such as super-resolution [18, 30] and image translation [33], and are also extremely effective in non-visual domains [4, 21, 28].
DDPM incorporates a probabilistic denoising process that is dependant on the estimation of the mean compo-nent µt−1. This is done by a neural network parameterized over θ and denoted as µθ(xt, t). However, it was found that through the forward and backward equations this process is better formalized by predicting either the noise (cid:15)θ(xt, t) or the original image xθ(xt, t) [9]. Their experiments found the former to be empirically superior, and, as far as we can ascertain, no further comparisons between the two options (noise or original image) have been performed as yet.
In this work, we revisit the original implementation of
DDPM, and ﬁnd that the preference of (cid:15)θ over xθ is circum-stantial and depends on the hyperparameters and datasets.
In addition, in certain timesteps, the denoising process has less error when predicting the noise component (cid:15)θ, while in others it predicts the original image xθ better. This realiza-tion motivated us to design a model capable of predicting both values and adaptively selecting the more reliable out-put at each sampling iteration. The modiﬁed model has a negligible number of added parameters and complexity. We apply this method to various DDPM models and show a marked improvement in terms of image quality (measured by FID) for many benchmarks. This addition to the frame-work is orthogonal to existing advancements (that we know
of), and is able to improve sampling quality, especially with the restriction of few iterations. 2.