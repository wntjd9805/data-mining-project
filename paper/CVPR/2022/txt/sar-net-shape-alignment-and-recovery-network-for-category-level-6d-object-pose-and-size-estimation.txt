Abstract
Given a single scene image, this paper proposes a method of Category-level 6D Object Pose and Size Esti-mation (COPSE) from the point cloud of the target object, without external real pose-annotated training data. Specif-ically, beyond the visual cues in RGB images, we rely on the shape information predominately from the depth (D) channel. The key idea is to explore the shape alignment of each instance against its corresponding category-level template shape, and the symmetric correspondence of each object category for estimating a coarse 3D object shape.
Our framework deforms the point cloud of the category-level template shape to align the observed instance point cloud for implicitly representing its 3D rotation. Then we model the symmetric correspondence by predicting symmet-ric point cloud from the partially observed point cloud. The concatenation of the observed point cloud and symmetric one reconstructs a coarse object shape, thus facilitating ob-ject center (3D translation) and 3D size estimation. Ex-tensive experiments on the category-level NOCS benchmark demonstrate that our lightweight model still competes with state-of-the-art approaches that require labeled real-world images. We also deploy our approach to a physical Bax-ter robot to perform grasping tasks on unseen but category-known instances, and the results further validate the effi-cacy of our proposed model. Code and pre-trained models are available on the project webpage 1. 1.

Introduction
Estimating accurate 6D poses of objects plays a pivotal role in the tasks of augmented reality [34], scene under-†indicates corresponding author.
§Haitao Lin is with Academy for Engineering and Technology, and En-gineering Research Center of AI and Robotics, Shanghai, China.
‡Yanwei Fu is with the School of Data Science, Fudan University, and
Fudan ISTBI—ZJNU Algorithm Centre for Brain-inspired Intelligence,
Zhejiang Normal University, Jinhua, China. This work was supported in part by NSFC under Grant (No. 62076067), Shanghai Municipal Science and Technology Major Project (2018SHZDZX01). 1Project webpage. https://hetolin.github.io/SAR-Net
Figure 1. (a) The visual difference between synthetic and real im-ages. They may have different textures and colors, but the shape and geometry maintain the same. (b) Illustration of shape align-ment. Objects within a category have consistent 3D rotation if their shapes are visually aligned. (c) Illustration of symmetric cor-respondence. Most objects are manufactured with (near) symmet-ric shapes with reflectional symmetry or rotational symmetry. standing [49], and robotic manipulation [7, 9, 33, 51, 53].
However, most 6D pose estimation works [8,9,15,19,28,37, 39,55,57] assume exact 3D CAD object models at instance-level, which unfortunately greatly limits their practical ap-plicability in real-world applications. To this end, this pa-per studies the task of Category-level 6D Object Pose and
Size Estimation (COPSE). Thus the model is trained only by category-level supervision, reducing reliance on the ex-act CAD model for each instance.
Generally, the key challenge of COPSE task lies in the huge color and shape variations of instances from the same category [43–45]. To handle intra-class variations, previ-ous works [5,24,52,58] learn the RGB(-D) features of each instance to help map these instances into a unified space and minimize the intra-class variations. On the other hand, as the COPSE task relies on supervised learning from large amounts of well-labeled data, recent works [5, 30, 52, 58] utilize synthetic data to train the COPSE model. Unfortu-nately, as illustrated in Fig. 1(a), the domain gap between synthetic and real images potentially hinders the perfor-mance of COPSE model in the real-world deployment.
While most previous works exploit texture and color cues in RGB images, the shape information has been less touched, with some recent exceptions of reconstructing the observed point cloud [6], and analyzing geometric stability of object surface patches [47]. For example, cups of simi-lar or identical shapes have very diverse colors in Fig. 1(a).
This motivates us to systematically explore shape informa-tion predominately from the depth (D) channel. Thus to al-leviate challenges of intra-class variation and synthetic-real image domain gap, we propose encoding the shape by shape alignment and symmetric correspondence. Particularly, our method encourages insightful shape analysis about geomet-rical similarity and symmetric correspondence.
Shape alignment. Assuming the instances of the same cat-egory are well aligned by shapes, they should have the con-sistent 3D rotation, as cups are shown in Fig. 1(b). Thereby, the idea of shape alignment can be implemented as object 3D rotation consistency.
In particular, given a category-level template shape in the form of a point cloud, it is de-formed to align against the observed instance point cloud.
We denote such the deformed template point cloud as an implicit representation for object 3D rotation, as shown in
Fig. 2(a). Mathematically, the object rotation is thus recov-ered by solving the classical orthogonal Procrustes prob-lem [46], which calculates the approximation of alignment matrix between point clouds of the category-level template and deformed one. The shape alignment learns to be robust to intra-class variations of instances.
Symmetric correspondence. Given the fact that many man-made object categories have the design principle with a symmetric structure [62], symmetry is an important ge-ometric cue to help our COPSE task. As in Fig. 1(c), the underlying symmetry allows for reasoning the reflectional and rotational symmetry of 3D shape from occluded 2D images. Note that specific object instances are practically never perfectly symmetric due to various shape variations of instances. To this end, we exploit the underlying sym-metry by point clouds of objects, as our COPSE task does not demand the exact 3D shape recovery. Furthermore, we model the point cloud of symmetric objects by an encoder-decoder structure learned end-to-end with the other compo-nents of our framework. Thus, this actually facilitates the whole framework being robust to those objects which have some parts that are less symmetric as in Fig. 2(b).
Formally, this paper proposes a novel Shape Alignment and Recovery Network (SAR-Net) to exploit the underlying object shapes for the COPSE tasks. Specifically, the RGB-D scene image is utilized as the input. We firstly employ
Mask-RCNN [14] to pre-process the RGB image, and in-fer the segmentation mask and category label of each object instance. The points from depth channel are filtered by the predicted mask and further fed into the 3D segmentation
Figure 2. (a) Illustration of implicit 3D object rotation. The de-formed template point cloud posses same 3D rotation with ob-served instance point cloud. (b) Illustration of weakly symmetric objects. Such objects usually have global symmetric shapes but asymmetric local parts. network 3D-GCN [31] to generate observed point cloud of the object. Furthermore, taking as inputs the point clouds of both observed object instance and category-level tem-plate, our SAR-Net predicts the implicit representation of deformed template point cloud, and infers symmetric point cloud. The 3D object rotation is further computed from the category-level and deformed template point clouds by
Umeyama algorithm [54]. Finally, we concatenate the ob-served and symmetric point clouds for a coarse object shape obtainment, which reduces the estimation uncertainty of ob-ject center (3D translation) and 3D size. Extensive experi-ments conducted on the category-level NOCS dataset [58] demonstrate that our synthetic-only approach outperforms the state-of-the-art methods.
Contributions. Our main contribution is to propose a novel learning paradigm that efficiently encodes the shape infor-mation by the shape alignment and symmetric correspon-dence for the COPSE. We present a novel framework –
SAR-Net to implement this idea. In particular, 1) Based on shape similarities, our SAR-Net has the novel sub-net component that efficiently infers the implicit ro-tation representation by shape alignment between point clouds of the category-level template shape and instance. 2) A novel sub-net component for symmetric correspon-dence is proposed in this paper. It can predict symmetric point cloud from partially observed point cloud to obtain a coarse shape. The coarse shape helps to estimate the object center and size accurately. 3) Practically, our SAR-Net is a very lightweight model with only 6.3M parameters. Such a single model is capable of doing the COPSE of multiple categories, and performs better than previous approaches of more model parameters. 4) Critically, our SAR-Net is entirely trained on synthetic data and performs very well generalization on real-world scenarios. Remarkably, our synthetic-only approach still outperforms other competitors which typically require both synthetic and real-world data. 2.