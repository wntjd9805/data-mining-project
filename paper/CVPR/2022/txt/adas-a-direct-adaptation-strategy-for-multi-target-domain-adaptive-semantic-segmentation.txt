Abstract 1.

Introduction
In this paper, we present a direct adaptation strategy (ADAS), which aims to directly adapt a single model to mul-tiple target domains in a semantic segmentation task with-out pretrained domain-speciÔ¨Åc models. To do so, we design a multi-target domain transfer network (MTDT-Net) that aligns visual attributes across domains by transferring the domain distinctive features through a new target adaptive denormalization (TAD) module. Moreover, we propose a bi-directional adaptive region selection (BARS) that reduces the attribute ambiguity among the class labels by adap-tively selecting the regions with consistent feature statistics.
We show that our single MTDT-Net can synthesize visually pleasing domain transferred images with complex driving datasets, and BARS effectively Ô¨Ålters out the unnecessary region of training images for each target domain. With the collaboration of MTDT-Net and BARS, our ADAS achieves state-of-the-art performance for multi-target domain adap-tation (MTDA). To the best of our knowledge, our method is the Ô¨Årst MTDA method that directly adapts to multiple domains in semantic segmentation.
Unsupervised domain adaptation (UDA) [14, 20, 26, 27, 49] aims to alleviate the performance drop caused by the distribution discrepancy between domains. It is widely uti-lized in synthetic-to-real adaptation for various computer vision applications that require a large number of labeled data. Most of the works are designed for single-target do-main adaptation (STDA), which allows a single network to adapt to a speciÔ¨Åc target domain. It rarely addresses the vari-ability in the real-world, particularly changes in driving re-gion, illumination, and weather conditions in autonomous driving scenarios. This issue can be tackled by adopting multiple target-speciÔ¨Åc adaptation models, but this limits the memory efÔ¨Åciency, scalability, and practical utility of embedded autonomous systems.
Recently, multi-target domain adaptation (MTDA) meth-ods [11,18,40,43,48,58] have been proposed, which enables a single model to adapt a labeled source domain to mul-tiple unlabeled target domains. Most of works train mul-tiple STDA models and then distill the knowledge into a single multi-target domain adaptation network. Recent ap-proaches [18, 40, 48] transfer the knowledge from label pre-ùíØ!
ùíØ"
Adapt indirectly
STDA model
‚ãÆ
MTDA model
STDA model
ùíØ!
‚ãÆ
ùíØ"
Adapt directly
MTDA model (a) Existing MTDA method (b) Ours
Figure 2. Illustration of the existing MTDA and our method. (a)
Conventional MTDA methods pretrain each STDA model then distill the knowledge into a single MTDA model. (b) Our ADAS directly adapts multiple target domains. dictors as shown in Fig. 2-(a). These methods show impres-sive results, but their performance can be restricted by the performance of the pretrained models. Moreover, inaccurate label predictions in the teacher network can degrade model performance, but none of works have deeply investigated them. To address this problem, we propose A Direct Adap-tation Strategy (ADAS) that directly adapts a single model to multiple target domains without pretrained STDA mod-els, as shown in Fig. 2-(b). Our approach achieves robust multi-domain adaptation by exploiting the feature statistics of training data on multiple domains. The followings pro-vides a detailed introduction of our sub-modules: Multi-Target Domain Transfer Networks (MTDT-Net) and a Bi-directional Adaptive Region Selection (BARS).
MTDT-Net We present a Multi-Target Domain Transfer
Network (MTDT-Net) that transfers the distinctive attribute of target domains to a source domain rather than learning all of the target domain distributions. Our network consists of a novel Target Adaptive Denormalization (TAD) that helps to adapt the statistics of source feature to that of the target fea-ture. While the existing works on UDA [3,6,7,14,31,34,37] require domain-speciÔ¨Åc encoders and generators for multi-target domain adaptation, the TAD module enables our sin-gle network to adapt to multiple domains. Fig. 1 shows how a single MTDT-Net can efÔ¨Åciently synthesize visually pleasing domain transferred images.
BARS Although the visual attributes across domains are well-aligned, there are still some attribute ambiguities among the class labels in semantic segmentation. The am-biguity is usually observed on the regions with similar at-tributes but different label, such as the sidewalks in GTA5 and the roads in Cityscapes as shown in Fig. 3-(a),(c). This confuses the model Ô¨Ånding the accurate decision bound-ary. Moreover, the predictions from target domains usu-ally have noisy labels leading to inaccurate training of the task network, as shown in Fig. 3-(b),(d). To solve these issues, we propose a Bi-directional Adaptive Region Se-lection (BARS), which alleviates the confusion. It adap-tively selects the regions with consistent feature statistics as shown in Fig. 3-(e). It can also select the pseudo label
GTA5 ‚Üí Cityscapes
Cityscapes (a) Domain transferred image (b) Target image (c) Ground-truth label of (a) (d) Pseudo label of (b) (e) Selected region of (c) (f) Selected region of (d)
Figure 3. Examples of the regions with similar attributes but differ-ent labels (c) (purple: road, pink: sidewalk), and the noisy prediction (d). The black regions in (e) and (f) are regions Ô¨Åltered by BARS. of the target images for our self-training scheme, as shown in Fig. 3-(f). We show that BARS allows the task network to perform robust training and achieve the improved perfor-mance.
To the best of our knowledge, our multi-target domain adaptation method is the Ô¨Årst approach that directly adapts the task network to multiple target domains without pre-trained STDA models in semantic segmentation. The exten-sive experiments show that the proposed method achieves state-of-the-art performance on semantic segmentation task.
At the end, we demonstrate the effectiveness of the pro-posed MTDT-Net and BARS. 2.