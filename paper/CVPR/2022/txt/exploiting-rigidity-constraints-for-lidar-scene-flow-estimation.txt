Abstract
Previous LiDAR scene flow estimation methods, espe-cially recurrent neural networks, usually suffer from struc-ture distortion in challenging cases, such as sparse reflec-In this paper, we propose a tion and motion occlusions. novel optimization method based on a recurrent neural net-work to predict LiDAR scene flow in a weakly supervised manner. Specifically, our neural recurrent network exploits direct rigidity constraints to preserve the geometric struc-ture of the warped source scene during an iterative align-ment procedure. An error awarded optimization strategy is proposed to update the LiDAR scene flow by minimizing the point measurement error instead of reconstructing the cost volume multiple times. Trained on two autonomous driving datasets, our network outperforms recent state-of-the-art networks on lidarKITTI by a large margin. The code and models will be available at https://github. com/gtdong-ustc/LiDARSceneFlow. 1.

Introduction
LiDAR scene flow estimation is a fundamental task in 3D scene understanding, which is vital to autonomous driv-ing and many other computer vision applications. Com-pared with optical flow estimation, which focuses on fea-∗Equal contribution. † Corresponding author: zwxiong@ustc.edu.cn ture matching for ordered RGB data, scene flow estima-tion poses an extra challenge as it involves aggregating un-ordered data from the LiDAR sensor.
To deal with unordered data, several convolutional neu-ral networks (CNNs) for scene flow estimation have been proposed.
In term of convolution operation, these CNN-based methods can be divided into two categories, 2D con-volution based methods [1, 11, 32] and 3D convolution based methods [16, 19, 26, 35, 36]. Typically, the 2D con-volution based methods convert 3D point clouds into 2D representations, e.g. depth map and bird’s-eye-view map, which inevitably brings in quantification errors. With re-cent advances in point cloud convolution [27], methods uti-lizing the 3D convolution operations are proposed to di-rectly operate unordered point cloud data and achieve suc-cess [16, 19, 34–36].
HPLFlowNet [10] and FlowNet3D [19] introduced dif-ferent 3D convolutions to operate the unordered point clouds directly. They both employed an end-to-end network to learn deep hierarchical features of point clouds and cor-relation embeddings for scene flow estimation. For small displacements between two consecutive point clouds, these works are effective but not satisfying in large displacements.
Then PointPWC-Net, utilizing a coarse-to-fine strategy, was proposed to handle large displacements [36]. The scene flow is first computed at low resolution to estimate large displacements and then gradually refined at high resolution.
One drawback of PointPWC-Net lies in the error accumula-In Fig. 2, we show the overview of our scene flow es-timation pipeline, which provides the abstraction of error awarded optimization, direct multi-body rigidity constraints and the pretrained segmentation network. Similar to [8], for training our proposed network, we don’t need the ground-truth scene flow. The essential supervision is the binary background mask and ego-motion. In other words, our net-work is trained in a weakly supervised manner. To validate the effectiveness of the proposed network, we train the net-work on two datasets SemanticKITTI and Waymo Open, and test on lidarKITTI with and without ground points.
The main contributions are summarized as follows:
• We introduce direct multi-body rigidity constraints to a
GRU-based recurrent neural network for LiDAR scene flow estimation.
• We propose an effective error awarded optimization strategy that updates the scene flow by minimizing a point-metric error instead of reconstructing cost vol-ume multiple times.
• The proposed network is trained in a weakly super-vised manner. Experimental results demonstrate that our method outperforms state-of-the-art scene flow es-timation methods by a large margin. 2.