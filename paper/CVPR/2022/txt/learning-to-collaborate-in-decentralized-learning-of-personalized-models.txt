Abstract
Learning personalized models for user-customized computer-vision tasks is challenging due to the limited private-data and computation available on each edge de-vice. Decentralized learning (DL) can exploit the images dis-tributed over devices on a network topology to train a global model but is not designed to train personalized models for different tasks or optimize the topology. Moreover, the mix-ing weights used to aggregate neighbors’ gradient messages in DL can be sub-optimal for personalization since they are not adaptive to different nodes/tasks and learning stages.
In this paper, we dynamically update the mixing-weights to improve the personalized model for each node’s task and meanwhile learn a sparse topology to reduce communication costs. Our first approach, “learning to collaborate (L2C)”, directly optimizes the mixing weights to minimize the local validation loss per node for a pre-defined set of nodes/tasks.
In order to produce mixing weights for new nodes or tasks, we further develop “meta-L2C”, which learns an attention mechanism to automatically assign mixing weights by com-paring two nodes’ model updates. We evaluate both methods on diverse benchmarks and experimental settings for image classification. Thorough comparisons to both classical and recent methods for IID/non-IID decentralized and federated learning demonstrate our method’s advantages in identifying collaborators among nodes, learning sparse topology, and producing better personalized models with low communica-tion and computational cost. 1.

Introduction
Training large models for computer-vision tasks, like deep neural networks (DNNs) and vision transform-ers [6, 38, 40], is known to be data hungry but data in many applications are distributed over millions or even billions of personal/IoT devices. Transmitting their local data is usually forbidden due to privacy protection and limited communication bandwidth, so centralized learning on all
Figure 1. Decentralized learning alternates between local model update and aggregation of neighbors’ model updates. We propose “learning to col-laborate (L2C)” and meta-L2C to optimize and produce the mixing weights wi,j for model aggregation in each round to achieve better personalization of local models on their own tasks/data. While L2C directly optimizes the mixing weights, meta-L2C learns an attention mechanism to automatically produce mixing weights between two models θi and θj . data is infeasible. Instead, federated learning (FL) [29] and decentralized learning (DL) [24], as two widely studied dis-tributed learning schemes, aim at training a global model by only sharing local models/gradients across multiple devices without leaking their private data. Both FL and DL iterates between on-device local model updates and cross-device model aggregation, i.e., each node uses its local data to update its model for iterations before updated by aggregating the models of other nodes. Their main difference is that FL periodically updates a global model on a central server by aggregating local models and synchronizes all nodes with the updated global model. In contrast, DL neither presumes a central server nor an explicit global model: each device can only communicate with its neighbor nodes on a network topology and aggregate their messages to update its own local model without global synchronization. Under certain assumptions to the topology and mixing weights for the aggregation [24], the local models in DL provably converge to a “consensus” global model. FL and DL target different
distributed learning settings in practice.
However, in practice, devices and their users may target different tasks and their local data distributions are not identi-cal, e.g., when they belong to separate geographic groups, so one global model may not perform well on all devices. How to personalize each local model for its own task/distribution and meanwhile exploit the knowledge shared across devices is a key challenge emerging in both FL and DL. Recently, there has been a growing interest to address the data/task het-erogeneity across devices by personalization [5, 8, 20, 32, 33].
In FL, since the global model is explicitly optimized and broadcasted, the trade-off between global consensus and local model personalization is inevitable and may rely on careful hyperparameter tuning [20]. It becomes even more challenging when taking other criteria, e.g., fairness and robustness of the global model, into account. On the contrary, it is more natural to formulate local personalization in DL: the main challenge is to optimize the aggregation of neighbors’ messages for each device’s own task instead of the global consensus. Recently, CGA [7] considers learnable mixing weights for each node in non-IID DL and finds a descent direction positively correlated with its neighbors’ gradients. However, this does not directly optimize the personalization performance and introduces an extra constraint. Moreover, the aggregation is only learned for a fixed set of nodes/tasks on a predefined topology and thus cannot generalize to newly added devices or unseen tasks.
In this paper, we take a further step towards more auto-mated and adaptive decentralized learning of personalized lo-cal models. To this end, we learn an aggregation scheme, i.e.,
“learn to collaborate (L2C)”, which automatically weighs and mixes neighbors’ messages to update each local model for better performance on its local task/data. Similar to FL/DL, we alternate between local model training and the aggrega-tion of neighbors’ model updates for each node. Inspired by meta-learning, we formulate this problem as minimizing the validation loss of each local model after being updated by the weighted aggregation per round. L2C optimizes the mixing weights solely based on the validation loss so every node is agnostic to other nodes’ tasks or data distributions for better protection of their privacy. Empirically, the mix-ing weights learned by L2C can faithfully reflect whether two nodes have similar tasks and/or data distributions and thus are usually sparse in practice. Moreover, they quickly converge in earlier stages so we can leverage their sparsity to create a sparse network topology, which can substantially save the communication cost for the rest training.
However, the mixing weights learned by L2C are asso-ciated with a fixed set of pre-defined nodes/tasks and thus cannot be adapted to new nodes/tasks or data distributions.
To avoid optimizing the mixing weights from scratch for new nodes, we propose meta-L2C that learns an attention mecha-nism to automatically assign the mixing weights given the models of a node and its neighbors. Similar to meta-learning, we can train meta-L2C on a training set of nodes with dif-ferent tasks and then apply it to a new set of nodes/tasks without re-training or fine-tuning. Hence, a pre-trained meta-L2C can produce mixing weight with sparse topology that accurately capture the task similarity at the very beginning of training, which further improves the training and commu-nication efficiency of L2C.
We summarize the main framework of L2C and meta-L2C in Figure. 1, both only requiring light-weight models. In ex-periments on three benchmark datasets, L2C and meta-L2C consistently outperform FL/DL methods with and without specific designs for personalization or data heterogeneity.
We further demonstrate the promising generalization perfor-mance of meta-L2C when transferred to unseen tasks or data.
Moreover, we present an empirical analysis with case studies to show that L2C/meta-L2C can produce mixing weights precisely capturing the task correlation among nodes and a sparse topology for efficient communication. In addition, we empirically analyze how sensitive L2C/meta-L2C is to train-ing/validation splitting and communication rounds/budget. 2.