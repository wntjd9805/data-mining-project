Abstract
Metrics for evaluating generative models aim to measure the discrepancy between real and generated images. The often-used Fr´echet Inception Distance (FID) metric, for ex-ample, extracts “high-level” features using a deep network from the two sets. However, we find that the differences in
“low-level” preprocessing, specifically image resizing and compression, can induce large variations and have unfore-seen consequences. For instance, when resizing an image, e.g., with a bilinear or bicubic kernel, signal processing principles mandate adjusting prefilter width depending on the downsampling factor, to antialias to the appropriate bandwidth. However, commonly-used implementations use a fixed-width prefilter, resulting in aliasing artifacts. Such aliasing leads to corruptions in the feature extraction down-stream. Next, lossy compression, such as JPEG, is commonly used to reduce the file size of an image. Although designed to minimally degrade the perceptual quality of an image, the operation also produces variations downstream. Further-more, we show that if compression is used on real training images, FID can actually improve if the generated images are also subsequently compressed. This paper shows that choices in low-level image processing have been an under-appreciated aspect of generative modeling. We identify and characterize variations in generative modeling development pipelines, provide recommendations based on signal pro-cessing principles, and release a reference implementation to facilitate future comparisons. 1.

Introduction
With the proliferation of generative modeling techniques, such as Generative Adversarial Networks (GANs) [24], ac-curately discerning which methods are performing better has become a critical aspect of the field. For visual data, metrics such as Inception Score (IS) [59], Kernel Inception
Distance (KID) [4], and the ubiquitously-used Fr´echet In-ception Distance (FID) [26] have become standard practice for developing and adopting models. Under the hood, these methods evaluate the discrepancy between generated and natural images, in a deep feature space, to capture relevant
Figure 1. Downsampling a circle. We resize an input image (left) by a factor of 8, using different image processing libraries. The
Lanczos, bicubic, and bilinear implementations by PIL (top row) adjust the antialiasing filter width by the downsampling factor (marked as
). Other implementations (including those used for
PyTorch-FID and TensorFlow-FID) use fixed filter widths, intro-ducing aliasing artifacts (marked as
) and resemble naive near-est subsampling. Aliasing artifacts induce inconsistencies in the calculation of downstream metrics such as Fr´echet Inception Dis-tance [26], KID [4], IS [59], and PPL [33]. Note that antialias flag is available in TensorFlow 2, but is set to False (default value) for the FID calculation. features of the two distributions. After all, at its core, gener-ative modeling involves learning and mimicking high-order, complex statistics of visual data.
However, we find that low-level, seemingly innocuous operations, can induce surprisingly large discrepancies in high-level statistics. For example, consider Figure 1. Given the same input image, different image processing libraries produce drastically different results. Specifically, the im-plementations using OpenCV, TensorFlow and PyTorch li-braries with default flags, contain severe aliasing artifacts.
Similarly, the simple act of saving images as JPEG with the
Secondly, we investigate the implication of image com-pression. While the JPEG protocol is a lossy compression scheme, designed to preserve perceptual similarity to the original [67], it can perturb an image enough to corrupt downstream feature extraction. This affects performance drastically and can create mismatches when comparing meth-ods. Perhaps more surprisingly, when training images are saved with JPEG compression, modern GANs are unable to fully mimic the induced artifacts, and large FID improve-ments can actually be artificially achieved by tweaking the
JPEG compression ratios when storing the generated images.
We quantify the surprising effects of this compression oper-ation, and again offer a concrete, standardized protocol to avoid inconsistencies and hindrances to proper evaluation.
In conclusion, we characterize the surprising importance of low-level image processing steps, resizing and quantiza-tion, when training and evaluating generative models, such as GANs. We focus our experiments on the widely adopted
FID metric, and show additional results on the KID met-ric [4] as well as IS [59] and Perceptual Path Length (PPL) metrics [33] (in the supplement). Importantly, any metric, present or future, that derives statistics from images undergo-ing these processing steps, will be affected by these factors. 2.