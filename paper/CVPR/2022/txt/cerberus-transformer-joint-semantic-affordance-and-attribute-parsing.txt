Abstract
Multi-task indoor scene understanding is widely consid-ered as an intriguing formulation, as the affinity of differ-In this pa-ent tasks may lead to improved performance. per, we tackle the new problem of joint semantic, affordance and attribute parsing. However, successfully resolving it requires a model to capture long-range dependency, learn from weakly aligned data and properly balance sub-tasks during training. To this end, we propose an attention-based architecture named Cerberus and a tailored training frame-work. Our method effectively addresses aforementioned challenges and achieves state-of-the-art performance on all three tasks. Moreover, an in-depth analysis shows concept affinity consistent with human cognition, which inspires us to explore the possibility of weakly supervised learn-ing. Surprisingly, Cerberus achieves strong results using only 0.1% − 1% annotation. Visualizations further con-firm that this success is credited to common attention maps across tasks. Code and models can be accessed at https:
//github.com/OPEN-AIR-SUN/Cerberus. 1.

Introduction
Understanding indoor scenes is a fundamental computer vision topic, with many applications in intelligent robots and metaverse. To achieve a holistic understanding, many sub-tasks need to be addressed and it is widely believed and evidenced that jointly addressing them lead to more accu-rate results [46] [9] [35] [40] [10]. Different from former arts, we study a new and challenging formulation: joint se-mantic, affordance, and attribute parsing from a single im-age. As shown in Fig. 1, these three tasks cover a wide spectrum of human recognition and cognition abilities. The attribute of an object (like wood or Glossy) is a low-level physical property. The semantic category of a region (like floor or sofa) is a recognition-level concept. Affordance prediction (like movable or walkable) is a cognition-level problem. These three tasks are closely associated, since ob-jects with specific semantics tend to have specific attribute
Figure 1. Cerberus Transformer. Given a single image, Cerberus parses attribute, affordance and semantics simultaneously. The cartoon is credited to https://www.redbubble.com/i/sticker/Baby-Cerberus-by-ArtOfBianca/48150266.EJUG5. or affordance. Parsing them jointly is a natural yet unex-plored formulation.
This new formulation brings both challenges and op-portunities.
In order to resolve three tasks with a single model, we need to learn shared representations that effec-tively serve all of them. Meanwhile, the representations are expected to model long range dependency in inputs in a principled manner. In order to simultaneously meet these two requirements, we resort to the transformer architec-ture [36], which has a global receptive field at each layer.
The proposed architecture is named as Cerberus.
Our formulation is challenged by another uncommon is-sue: weakly aligned data. During the historical develop-ment of scene understanding techniques, attribute [47] and affordance [27] annotations are gradually added to the orig-inal NYUd2 semantic parsing dataset [34]. Unfortunately, their image-annotation pairs are only weakly aligned in the spatial domain. This is in contrast to former multi-task scene understanding methods which exploit aligned one-input-multi-output datasets. To this end, we develop a tai-lored training framework that treats three datasets as sepa-rate sources and leverages a gradient projection technique
It unleashes on pre-computed task-wise gradient tensors. the power of multi-task learning and boosts the quantitative results of all three tasks to a state-of-the-art level.
As mentioned before, opportunities come along with challenges. We first conduct in-depth analyses to investigate concept affinity in our three tasks. Interestingly, we observe concept affinity matrices well aligned with human cognitive commonsense. For example, if a pixel is predicted as floor, naturally it should be labelled as walkable. This finding inspires us to leverage task affinity for weakly supervised learning. During the training of Cerberus, we reduce the annotation amount of a specific sub-task to only 0.1% − 1% and rely upon representations learnt by other sub-tasks. It is shown that Ceberus consistently out-performs baselines by significant margins in these settings. What’s more, we visualize attention maps and validate that the capability of weakly-supervised learning is indeed enabled by shared at-tention weights. We argue this is a human-like learning fea-ture: If one (e.g., an infant) knows what is floor, then she can learns where is walkable using very few examples.
We have following contributions: (1) We propose a novel multi-task dense prediction transformer named Cerberus, for joint semantic, affordance and attribute parsing in indoor scenes; (2) Cerberus achieves state-of-the-art results for all three tasks while requiring a single forward pass, with the help of a task weight balancing framework that learns from weakly-aligned data. (3) Via extensive analyses, we show that Cerberus learns task affinity consistent with human cognition and achieves strong weakly-supervised learning performance using only 0.1% annotation. 2.