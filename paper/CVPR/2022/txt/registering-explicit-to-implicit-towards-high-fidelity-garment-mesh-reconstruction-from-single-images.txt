Abstract
Fueled by the power of deep learning techniques and implicit shape learning, recent advances in single-image human digitalization have reached unprecedented accu-racy and could recover fine-grained surface details such as garment wrinkles. However, a common problem for the implicit-based methods is that they cannot produce separated and topology-consistent mesh for each garment piece, which is crucial for the current 3D content creation pipeline. To address this issue, we proposed a novel geom-etry inference framework ReEF that reconstructs topology-consistent layered garment mesh by registering the explicit garment template to the whole-body implicit fields pre-dicted from single images. Experiments demonstrate that our method notably outperforms the counterparts on single-image layered garment reconstruction and could bring high-quality digital assets for further content creation. 1.

Introduction
High-quality human-related 3D contents are highly de-manded by various real-world applications, including vir-tual live-streaming, gaming, and filming. However, produc-ing visually plausible 3D digital human assets has always been a laborious task, which may take hours even for an expert modeler.
In contrast, in-the-wild images are easily accessible with commercial cameras and from the internet. Therefore, re-cent researches have extensively studied human digitaliza-tion from single in-the-wild images, aiming at assisting people without expertise to generate visually plausible 3D human-related contents efficiently.
Compared with the recent advances in single image body
[3, 13, 20–22, 24, 27, 33, 35, 37] and clothed human recon-struction [1, 2, 7, 25, 32, 36, 38, 42, 44], research on single image layered garment reconstruction is quite sparse. The main challenges towards a high-fidelity garment reconstruc-tion are as two folds: generating garment styles and re-covering surface details. To generate garments with differ-ent styles, Multi-Garment Net(MGN) [5], BCNet [17] and
SMPLicit [10] adopted either explicit parametric models or implicit parametric models trained on the digital wardrobes but failed to recover the garments with novel garment styles from the image. To generate novel garment styles from the input images, Deep Fashion3D [53] proposed to de-pict garment styles with the feature lines predicted from the input image. Nevertheless, it fails to generate garment styles well aligned with the input images due to the inac-curacy of the boundary prediction. As for recovering sur-face details, MGN [5] and SMPLicit [10] can only produce smoothed garment mesh with limited surface details. BC-Net [17] carves fine-grained details onto the garment tem-plate with an image-guided graph convolutional network though it fails to produce large-scale wrinkle deformations.
Although Deep Fashion3D [53] can generate large-scale surface deformations based on Occupancy Network [31], the generated surface details may deviate from the input im-age as it only adopts global image features. Therefore, none of existing methods can recover garment styles and surface details aligning with the appearances from the input image.
The recent emergence of the pixel-aligned implicit [38, 39, 49] framework has made it possible to reconstruct clothed humans with image-aligned appearances. On the other hand, it poses a question on how to exploit the power of the pixel-aligned framework to produce layered garment meshes that faithfully reflect the image appearances.
To this end, we propose ReEF, a novel geometry in-ference framework that can produce high-fidelity layered garments by [re]gistering the [e]xplicit garment template meshes to the full-body implicit [f]ields predicted from sin-gle images. However, due to the diversity of the real-world garment geometry, it is non-trivial to establish correspon-dence between the garment template meshes and the cloth-ing on an individual frame of the implicit clothed human.
To address this issue, we proposed novel methods to gen-erate boundary fields and semantic fields to align the ex-plicit garment template with the implicit clothed body. On top of the alignment, separated garment meshes with class-specific topology could be instantiated from the implicit fields with a dedicated designed optimization system. Ex-periments demonstrated that ReEF is capable of producing high-quality garment meshes from single images that could serve as off-the-shelf assets for various downstream appli-cations, e.g., animation and simulation.
The main contribution of this work can be summarized as follows:
• We proposed a novel geometry inference frame-work that reconstructs high-fidelity and topological-consistent garment meshes from single images by reg-istering the explicit garment templates to an individual frame of the implicit clothed human body.
• We contribute to a novel learning-based method that predicts the implicit garment boundary fields with pixel-aligned features and curve-aligned features. The predicted garment boundaries can be well aligned to the appearances from the input image and the implicit clothed body.
• We conducted experiments on both synthetic datasets and in-the-wild datasets. The experiments demon-strated that our method could generate high-quality layered garments with accurate styles and expressive surface details. 2.