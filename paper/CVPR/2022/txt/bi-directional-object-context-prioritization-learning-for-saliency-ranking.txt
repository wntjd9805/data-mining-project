Abstract
The saliency ranking task is recently proposed to study the visual behavior that humans would typically shift their attention over different objects of a scene based on their de-grees of saliency. Existing approaches focus on learning ei-ther object-object or object-scene relations. Such a strategy follows the idea of object-based attention in Psychology, but it tends to favor objects with strong semantics (e.g., hu-mans), resulting in unrealistic saliency ranking. We observe that spatial attention works concurrently with object-based attention in the human visual recognition system. During the recognition process, the human spatial attention mech-anism would move, engage, and disengage from region to region (i.e., context to context). This inspires us to model region-level interactions, in addition to object-level reason-ing, for saliency ranking. Hence, we propose a novel bi-directional method to unify spatial attention and object-based attention for saliency ranking. Our model has two novel modules: (1) a selective object saliency (SOS) module to model object-based attention via inferring the semantic representation of salient objects, and (2) an object-context-object relation (OCOR) module to allocate saliency ranks to objects by jointly modeling object-context and context-object interactions of salient objects. Extensive experiments show that our approach outperforms existing state-of-the-art methods. Code and pretrained model are available at https://github.com/GrassBro/OCOR. 1.

Introduction
Saliency detection is a fundamental task in computer vi-sion. Previous works mainly focus on the salient object / instance detection tasks [9, 17, 38], and the gaze prediction task [33]. Recently, Siris et al. [34] propose to study a novel task called saliency ranking, which aims to detect the salient instances and infer their saliency ranks simultaneously. By
† Ke Xu and Xin Yang are joint corresponding authors.
‡ Rynson Lau leads this project. (a) Image (b) RSDNet
[19] (c) ASSR
[34] (d) IRSR
[28] (e) Ours (f) GT
Figure 1. Existing salient ranking approaches [19, 28, 34] pro-duce unrealistic saliency ranks. (b) RSDNet [19] is a pixel-level method and does not predict object-level saliency ranks well. (c)
ASSR [34] and (d) IRSR [28] explore object-object and object-scene relations for inferring saliency ranks. However, they favor objects with strong semantics and tend to assign people with high saliency ranks. (e) Our method explores both spatial and object-based attentions with a bi-directional object-context prioritization learning formulation, yielding faithful saliency ranking results. mimicking how humans change their attention across the scenes depending on the saliency ranks, saliency ranking can benefit many down-stream visual tasks, e.g., image ma-nipulation [6, 49], scene understanding [37], important per-son identification [24] and their interaction reasoning [10].
Islam et al. [19] propose the first saliency ranking work, which directly predicts a relative saliency map with dif-ferent pixel values indicating different saliency degrees, as shown in Figure 1(b). However, this method only studies the relative saliency of pixels. Later, Siris et al. [34] pro-pose to study the salient object ranking as humans shift at-tention from object to object. They propose to model the relations between objects and global context for reasoning their ranks. Liu et al. [28] further propose a neural graph-based method to learn relations between objects and local contexts as well as relations between objects. However, these two methods [28, 34] tend to favor objects with strong semantics (e.g., people) as shown in Figure 1, resulting in incorrect saliency ranks. For example, in the first and sec-ond rows of Figure 1(c,d), they assign people with high-est saliency ranks, despite the visual distinctiveness of the green screen in the first example and the relatively larger horse in the second example. In the last row, the two meth-ods do not even consider the skateboard as a salient object.
In this paper, we tackle the saliency ranking problem based on the observation that as revealed by psychologi-cal studies [2,8], spatial attention and object-based atten-tion work concurrently in the human visual system. While object-based attention directs our views to the candidate ob-jects or perceptual groups via a preattentive segmentation of the scene [8], the human spatial attention mechanism allows us to process the scene sequentially through prior-itizing the regions (where the objects belong to) based on low-level visual stimuli (e.g., rich colors), functionalities of the objects, and interactions among the objects. This inspires us to jointly exploit spatial attention and object-based attention for saliency ranking. Based on this obser-vation, we formulate a bi-directional object-context prior-itization learning approach to model both region-level and object-level relations. We first propose a Selective Object
Saliency (SOS) module to model object-based attention via inferring and enriching the semantic representations of the salient objects based on their local contexts. We then pro-pose an object-context-object relation (OCOR) module to exploit the spatial attention mechanism by reasoning in the object-context and context-object bi-directional way. We formulate a multi-head attention mechanism to model the way that an object with its context would interact with other objects with their contexts. As shown in Figure 1(e), our ap-proach produces more faithful saliency ranks over the state-of-the-art methods. For example, our method can detect the screen (first row) and the horse (second row) as the most salient objects according to their visual distinctiveness. In the third row, our method can detect and rank the skateboard by modeling its interaction with the person.
To summarize, this work has three main contributions: 1) Inspired by the psychological studies, we propose a novel bi-directional object-context prioritization learning approach for saliency ranking, by jointly exploiting spatial and object-based attention mechanisms. 2) We propose a novel selective object saliency (SOS) module for modeling object-based attention, and a novel object-context-object re-lation (OCOR) module for modeling spatial attention via inferring the relations of objects in a bi-directional object-context and context-object manner. 3) We conduct exten-sive experiments to analyze our approach and verify its su-perior performance over the state-of-the-art methods. 2.