Abstract 1.

Introduction
We propose GAN-Supervised Learning, a framework for learning discriminative models and their GAN-generated training data jointly end-to-end. We apply our framework to the dense visual alignment problem. Inspired by the clas-sic Congealing method, our GANgealing algorithm trains a Spatial Transformer to map random samples from a GAN trained on unaligned data to a common, jointly-learned tar-get mode. We show results on eight datasets, all of which demonstrate our method successfully aligns complex data and discovers dense correspondences. GANgealing signiﬁ-cantly outperforms past self-supervised correspondence al-gorithms and performs on-par with (and sometimes exceeds) state-of-the-art supervised correspondence algorithms on several datasets—without making use of any correspondence supervision or data augmentation and despite being trained exclusively on GAN-generated data. For precise correspon-dence, we improve upon state-of-the-art supervised methods by as much as 3
. We show applications of our method for augmented reality, image editing and automated pre-processing of image datasets for downstream GAN training.
⇥
Code and models: www.github.com/wpeebles/gangealing
Visual alignment, also known as the correspondence or registration problem, is a critical element in much of com-puter vision, including optical ﬂow, 3D matching, medical imaging, tracking and augmented reality. While much recent progress has been made on pairwise alignment (aligning im-age A to image B) [2, 14, 22, 34, 51, 57, 58, 60, 68–71, 75], the problem of global joint alignment (aligning all images across a dataset) has not received as much attention. Yet, joint align-ment is crucial for tasks requiring a common reference frame, such as automatic keypoint annotation, augmented reality or edit propagation (see Figure 1 bottom row). There is also evidence that training on jointly aligned datasets (such as FFHQ [42], AFHQ [15], CelebA-HQ [40]) can produce higher quality generative models than training on unaligned data.
In this paper, we take inspiration from a series of classic works on automatic joint image set alignment. In particular, we are motivated by the seminal unsupervised Congealing method of Learned-Miller [48] which showed that a set of im-ages could be brought into alignment by continually warping them toward a common, updating mode. While Congeal-ing can work surprisingly well on simple binary images, such as MNIST digits, the direct pixel-level alignment is not powerful enough to handle most datasets with signiﬁcant appearance and pose variation.
To address these limitations, we propose GANgealing: a GAN-Supervised algorithm that learns transformations of input images to bring them into better joint alignment. The key is in employing the latent space of a GAN (trained on the unaligned data) to automatically generate paired train-ing data for a Spatial Transformer [35]. Crucially, in our proposed GAN-Supervised Learning framework, both the
Spatial Transformer and the target images are learned jointly.
Our Spatial Transformer is trained exclusively with GAN images and generalizes to real images at test time.
We show results spanning eight datasets—LSUN Bicy-cles, Cats, Cars, Dogs, Horses and TVs [87], In-The-Wild
CelebA [52] and CUB [83]—that demonstrate our GANgeal-ing algorithm is able to discover accurate, dense correspon-dences across datasets. We show our Spatial Transformers are useful in image editing and augmented reality tasks.
Quantitatively, GANgealing signiﬁcantly outperforms past self-supervised dense correspondence methods, nearly dou-bling key point transfer accuracy (PCK [4]) on many SPair-71K [59] categories. Moreover, GANgealing sometimes matches and even exceeds state-of-the-art correspondence-supervised methods. 2.