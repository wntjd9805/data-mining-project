Abstract
We propose a novel method of registering less-overlap
RGB-D scans. Our method learns global information of a scene to construct a panorama, and aligns RGB-D scans to the panorama to perform registration. Different from existing methods that use local feature points to register less-overlap RGB-D scans and mismatch too much, we use global information to guide the registration, thereby allevi-ating the mismatching problem by preserving global consis-tency of alignments. To this end, we build a scene inference network to construct the panorama representing global in-formation. We introduce a reinforcement learning strategy to iteratively align RGB-D scans with the panorama and re-ﬁne the panorama representation, which reduces the noise of global information and preserves global consistency of both geometric and photometric alignments. Experimental results on benchmark datasets including SUNCG, Matter-port, and ScanNet show the superiority of our method. 1.

Introduction
Registering RGB-D scans is the basis of 3D reconstruc-tion and 3D modeling, and has been increasingly studied
[5,9,19,26]. Most existing methods [27,29] usually require a large overlap (≥ 70%) to achieve good registration results.
However, in practice, there will inevitably appear to be less-overlap RGB-D scans when cameras are moved suddenly and rapidly, or multiple cameras are deployed in less or no co-visible regions. Rescanning can compensate for the lack of overlap of less-overlap scans [1, 15], but it is somewhat costly and inefﬁcient. Therefore, many researchers have been initiated to investigate directly registering less-overlap scans.
Existing methods [30, 31] use scene completion strate-gies and the conventional three-step paradigm (i.e., feature extraction, feature matching, and pose estimation) to regis-ter less-overlap scans. However, these methods do not work
*Corresponding author well in registration of blurred and texture-less regions that commonly appear in the completing scene images, because the local feature points they used for matching only con-tain local neighborhood information around the points. The local neighborhood information is often similar with less discriminative [14, 25], especially in blurred and texture-less regions. Therefore, local feature points are prone to be mismatched, and further incur incorrect pose estimation and registration. In this paper, we propose to use global in-formation (e.g., scene layout and objects’ surroundings) of a scene to guide the registration. We align the less-overlap scans with the scene globally in a jigsaw-like manner and preserve global consistency of both geometric and photo-metric alignments, thereby alleviating the problem caused by less discriminative local feature points.
Using global information to register less-overlap scans is non-trivial. Since the global information is acquired only based on less-overlap RGB-D scans and their com-pletion, much noise will be produced from the unaligned scans and unreliable completion. In particular, we have to face the chicken-and-egg problem: global information re-lies on good alignments of scans, and aligning scans relies on good global information. Many methods [2, 29] adopt a simple iterative strategy to solve the problem by aligning scans merely based on current global information and re-ﬁning global information, iteratively. However, the simple iterative strategy ignores the impact of future reﬁned global information on scan alignments. This greedy strategy may lead to suboptimal solutions of alignments, thus obtaining global information with much noise. The noise degrades the ﬁdelity of global information, remaining a signiﬁcant challenge in the registration of less-overlap scans.
To tackle the challenge, we present a global-aware regis-tration method of less-overlap RGB-D scans by jointly re-ducing noise and improving alignments in a reinforcement learning process. We use reinforcement learning to align
RGB-D scans with the scene on the basis of both current and future global information, and reﬁne the information based on the alignment. Our method makes full use of global in-formation and improves its ﬁdelity by trial-and-error learn-ing in a non-greedy manner. To do this, we build a scene inference network to generate the panorama. The panorama is a weighted initialization representation of the global in-formation that represents reliable regions with less noise.
We use global constraints of both photometry and geome-try according to the alignment between less-overlap scans and the panorama. We introduce a reinforcement learning strategy to achieve the global constraints for reﬁning the panorama representation and aligning scans with the reﬁned panorama, iteratively.
We evaluate our method by both establishing correspon-dences and estimating relative poses between RGB-D scans with less than 10% overlap on SUNCG [23], Matterport [4], and ScanNet [6] datasets. Experimental results show that our method outperforms existing state-of-the-art methods. 2.