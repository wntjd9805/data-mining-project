Abstract
Digital watermarking is widely used for copyright pro-tection. Traditional 3D watermarking approaches or com-mercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. How-ever, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retriev-ing messages from 2D renderings of 3D meshes is still chal-lenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh ge-ometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our exper-iments, we show that our model can learn to embed infor-mation visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning. 1.

Introduction
Digital watermarking is a key technology for copyright pro-tection, source tracking, and authentication for digital con-tent. The goal of digital watermarking is to embed mes-sages in another media, e.g., image, video, or 3D, and be able to decode the messages even after the watermarked media is copied, edited or distorted. There are two types of watermarking: invisible or visible. In this paper, we will mainly focus on invisible watermarking which means the watermarked media should be perceptually the same as the original media. 3D models, due to their increasing ubiquity in a wide
∗Currently affiliated with Microsoft Azure AI.
Figure 1. A chair mesh is watermarked with a message “CVPR”, then rendered as images. The embedded message can be retrieved from rendered images from different views and lighting condi-tions. range of applications such as movie making, gaming, 3D printing, augmented reality (AR), 3D mapping, etc., have become an important subject of digital watermarking. The classic problem of watermarking for 3D models has been primarily formulated as embedding and retrieving mes-sages, both in 3D space. While traditional 3D watermarking methods [18,34] and commercial tools [27] are useful in 3D manufacturing and printing industries, they are inapplicable to mediums such as gaming, movie making and graphic de-sign, where the messages need to be retrievable from 2D renderings of the 3D models.
In this work, we study the problem of 3D-to-2D water-marking – how to embed messages invisibly in 3D meshes and recover them robustly from 2D renderings. Recently, a number of research works [1, 15, 42] shows that approaches based on deep neural networks can achieve the state-of-the-art performance on image watermarking. One possible so-Figure 2. Overview of our deep watermarking pipeline. The encoder embeds messages into 3D meshes in an imperceptible fashion.
Then we apply some distortions like crop, scaling to the watermarked 3D mesh. The rendered images are generated using a differentiable renderer. After that we extract the messages from the rendered 2D images. lution that takes advantage of these methods is to embed and retrieve messages in the rendered 2D images of 3D objects.
However, this approach cannot be easily adapted to decode 2D renderings of the same objects from different camera views or under varied lighting and shading conditions and thus is impractical. Another solution is to embed messages in the 2D textures of 3D meshes and extract the messages from 2D renderings. Our experiments show that it does not work since the existing deep image watermarking solution is not robust to 3D to 2D rendering distortion.
To address these issues, we propose an end-to-end train-able deep 3D-to-2D watermarking framework which is re-sistant to various 3D distortions and capable of extract-ing messages from images rendered under different lighting conditions and camera views.
Our framework consists of 1) an encoder; 2) a dis-tortion layer; 3) a differentiable renderer; and 4) a de-coder as shown in Fig. 2. Specifically, inspired by the ad-vances of 3D reconstruction using differentiable renderers
[12, 32, 38], we employ a state-of-the-art differentiable ren-derer to bridge the gap between the 3D encoding and 2D decoding stages. In the encoding stage, our model first em-beds message bits into either 3D geometry and/or 2D tex-tures of the original 3D data. In the decoding stage, it learns to extract message bits from 2D images generated by the differentiable renderer. We build a 3D-to-2D watermarking benchmark including 5146 3D objects with textures, and we investigate the performance of different architectures on it.
We then analyze the performance of our method by measur-ing its capacity, i.e., the size of the message we can embed, its robustness, i.e., the bit accuracy with respect to various distortions, and its quality or invisibility, i.e., difference be-tween watermarked/unwatermarked 2D renderings. Finally, we show that our model can work with other renderers, such as ray tracing and real-time renderers, as well as the avail-ability of fine-tuning our decoder for other not differentiable renderers.
Our key contributions are following:
• To the best of our knowledge, this paper presents the first 3D-to-2D watermarking method which can re-trieve messages encoded in 3D meshes from its ren-dered 2D image and broaden 3D watermarking usage.
• The use of differentiable rendering makes our method fully-differentiable, which enables to train the whole framework end-to-end with a collection of differen-tiable 3D distortions.
• Our decoder can decode the embedded messages from non-differentiable renderers, and can be improved fur-ther by fine-tuning.
While our model performs well as shown in Sec. 4, it is still limited in multiple aspects. For example, our method has low bit capacities compared to traditional 3D water-marking methods. However, low bit capacities are still use-ful for copyright protection ( e.g., zero-bit watermarking).
Another limitation is that if attackers use totally different style rendering techniques such as cartoon rendering, our model needs to be re-trained.
2.