Abstract
With the wide applications of deep neural network mod-els in various computer vision tasks, more and more works study the model vulnerability to adversarial examples. For data-free black box attack scenario, existing methods are in-spired by the knowledge distillation, and thus usually train a substitute model to learn knowledge from the target model using generated data as input. However, the substitute model always has a static network structure, which limits the attack ability for various target models and tasks. In this paper, we propose a novel dynamic substitute training attack method to encourage substitute model to learn better and faster from the target model. Specifically, a dynamic substitute structure learning strategy is proposed to adap-tively generate optimal substitute model structure via a dy-namic gate according to different target models and tasks.
Moreover, we introduce a task-driven graph-based structure information learning constrain to improve the quality of generated training data, and facilitate the substitute model learning structural relationships from the target model mul-tiple outputs. Extensive experiments have been conducted to verify the efficacy of the proposed attack method, which can achieve better performance compared with the state-of-the-art competitors on several datasets. Project page: https://wxwangiris.github.io/DST 1.

Introduction
Deep neural network models have achieved the state of the art performances in many challenging computer-vision tasks [9, 16, 29]. These models have been wide-spread adopted in real-world applications, e.g., self-driving cars, li-cense plate reading, disease diagnosis from medical images, and activity classification. However, recent studies [8, 30] show that deep neural networks are highly vulnerable to ad-versarial examples, which contain small and imperceptible perturbations crafted to fool the target models. This attracts more researchers to study the attack and defense for better
†indicates corresponding author.
Figure 1. A conceptual overview of our method. Rather than retain all blocks, our approach learns to generate optimal substitute struc-ture according to the black-box attack target. The lighter green blocks with ‘S’ indicate the skipped blocks, and dark green blocks with ‘K’ are the keeping blocks. The graph-based structural infor-mation is used to facilitate substitute training. assessing and improving the robustness of deep models.
Adversarial attack methods can be categorized into two main settings, i.e., white-box attack [2, 5, 17, 21, 24] and black-box attack [3, 3, 4, 6, 7, 12, 13, 35], by whether or not the attackers can have full access to the structure and param-eters of the target model. Nowadays, in the era of big data, data is one of the most valuable assets for companies, and much of it also has privacy issues. Thus, in practical cases, it is not only difficult for attackers to know the details of the target model, but also hardly obtain the training data for the target model, even the number of categories.
The purpose of this paper is to successfully achieve a data-free black-box attack according to the given target model. “Data-free” suggests that we cannot access any knowledge about the data distribution (e.g., the type of data, number of categories, etc.), which was used for the target model; “Black-box” indicates the target model structure is completely shielded from the attackers, resulting in the lim-itation on getting model parameters or features of middle layers. The only available thing we can use is the output of probabilities/labels from the target model. Such a strict setting is more in line with the requirements of real-world scenarios, especially at a time when privacy data protec-tion has attracted more attention. Inspired by the substitute training methods in black-box attack, many works [32, 38]
try to tackle the data-free black-attack through learning a substitute model for the target one with generated training data. However, there exist two main limitations in exist-ing methods, (1) static substitute model structure for differ-ent targets: due to the lack of prior knowledge, utilizing the same and static substitute model architecture for vari-ous target models or tasks definitely can not achieve power-ful attack. Meanwhile, it is impractical and cost expensive to train multiple models to find the most suitable substitute model structure for each target variation. (2) Assumption of knowing the number of categories for the target model: for the total data-free black-box attack, it is unreasonable for knowing the number of training data classes for the tar-get model. Thus, using the label as the generator guidance information to synthesize diverse and label-controlled data for substitute training is unpractical.
In this study, to address the limitations of existing meth-ods, we propose a novel and task-driven Dynamic Substitute
Training (DST) attack method for data-free black-box at-tacking, as illustrated in Fig. 1. Our DST attack adopts the basic substitute learning framework as in [14, 32, 38], which generates the training data via a generator with noise as input, and takes advantage of the knowledge distillation concept to encourage the substitute model to has the same output as the target one when facing the same synthesized training image. To tackle the constant substitute model ar-chitecture problem (limitation (1)), in our DST attack al-gorithm, for the first time, we introduce a dynamic substi-tute structure learning strategy to automatically generate a more suitable substitute model structure according to differ-ent target models and tasks. To achieve such dynamic struc-ture generation, we specially design a learnable dynamic gate to determine which blocks in the deep architecture can be skipped. To deal with being unaware of the prior knowl-edge about the training data classes issue (limitation (2)), we introduce a graph-based structural information learning strategy in DST, to further improve the generator perfor-mance and enhance the substitute training process. Such a learning strategy can facilitate the substitute model learning more implicit and detailed information from the structural relationship among multiple target model outputs. Mean-while, such structural information can reflect the represen-tation distance among a group of generated training data and stimulate the generator to deliver more valuable training data. Overall, our DST attack can adaptively generate opti-mal substitute model structure for various targets, improve the consistency between the substitute and target model, and encourage the generator to synthesize better training data via learning structural information. This can promote the data-free black-box attack performance.
The main contributions of this work are summarized be-low, (1) We propose a novel and task-driven dynamic substi-tute training attack method to boost the data-free black-box attacking performance. (2) For the first time, we introduce a dynamic substitute structure learning strategy to adaptively generate optimal substitute model architecture according to the different target models and tasks, instead of adopting (3) To encourage the sub-the same and static network. stitute model to learn more details from the target model and improve the quality of generated training data, we pro-pose a graph-based structural information learning strategy to deeply explore the structural, relational, and valuable in-formation from a bunch of target outputs. (4) The compre-hensive experiments over four public datasets and one on-line machine learning platform demonstrate that our DST method can achieve SOTA attack performance and signifi-cantly reduce the query times during the substitute training. 2.