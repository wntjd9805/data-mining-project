Abstract
Style transfer has been well studied in recent years with excellent performance processed. While existing methods usually choose CNNs as the powerful tool to accomplish superb stylization, less attention was paid to the latent style space. Rare exploration of underlying dimensions results in the poor style controllability and the limited practical ap-plication. In this work, we rethink the internal meaning of style features, further proposing a novel unsupervised algo-rithm for style discovery and achieving personalized manip-*Yi Li is the corresponding author. ulation. In particular, we take a closer look into the mecha-nism of style transfer and obtain different artistic style com-ponents from the latent space consisting of different style features. Then fresh styles can be generated by linear com-bination according to various style components. Experi-mental results have shown that our approach is superb in 1) restylizing the original output with the diverse artistic styles discovered from the latent space while keeping the content unchanged, and 2) being generic and compatible for var-ious style transfer methods. Our code is available in this page: https://github.com/Shelsin/ArtIns.
1.

Introduction
The target of artistic style transfer is to transform the style of one image into an arbitrary image, keeping the latter’s content unchanged. The work in this topic has seen rapid development in both academy and industry re-cently. Convolutional neural networks (CNNs) [3, 8, 16] is frequently used to achieve stylization because of its supe-rior learning property and excellent performance, especially
VGG-net [35]. Besides CNNs, style transfer methods also require large-scale datasets and more advanced neural net-works to improve the quality of image generation. Never-theless, it is still challenging to produce satisfying and con-vincing artworks.
Starting from neural style transfer (NST) [7], recent works tend to generate high-quality stylized image via two main ways: iterative optimization [6, 23, 29] and feed-forward network [9, 16, 40]. With the former, the prior works rely on an optimization process to ﬂexibly combine content and style of arbitrary images, which requires a long time to achieve stylization. The later achieves fast styl-ization with a single forward pass, but a major limitation of most feed-forward methods is that each network is re-stricted to a ﬁxed number of styles.
While achieving impressive results in artistic style trans-fer, existing methods focus much on style extraction and content reconstruction but ignore the signiﬁcance of the latent space. Although underlying knowledge learned by these prior works can be transformed into the ﬁnal output, the real sense of them is less explored. In other words, the essence of the stylization process is projecting the original style features from the image space into the intermediate space, then the decoder transforms the latent knowledge back into the image space. During the process of style trans-fer, most existing methods ignore the rich latent information contained in the image space, which conducts limited style controllability and diversity. Meanwhile, most of the pre-vious methods need advanced devices like GPU with large memory to train their models for diverse styles, which limits their application to real-world scenarios.
In order to solve the problem, we propose a generally applicable approach to discover a large number of artis-tic styles via mathematical computation, which is unsu-pervised and independent of any form of training. Our method is named ArtIns as the short for Artistic Ingredi-ents/Components Separation. In this work, we take a step back and rethink the whole transfer process. After examin-ing the relation between latent style features and the image variation, we ﬁnd that versatile styles can be divided into multiple independent style components. According to these style components, fresh styles can be obtained to produce
In other high-quality and controllable stylization results. words, diverse artistic styles are discovered from the latent space consisting of various style representations, which is exhibited in Fig. 1. Extensive experiments based on popu-lar pre-trained style transfer models(e.g., AdaIN [14], Lin-ear [20], SANet [26] and MST [41]) indicate the effective-ness and ﬂexibility of our algorithm.
To summarize, the main contributions are as follows:
• We introduce a novel unsupervised algorithm that can discover various styles from the latent space, advanc-ing the ability of controllable stylization.
• We obtain the independent style components from the mixed latent style dimensions in style transfer, result-ing in multiple artistic stylizations and lowering com-putational costs.
• Our method is generally applicable without training and we demonstrate the effectiveness and ﬂexibility of our approach via abundant experiments on several state-of-the-art style transfer models. 2.