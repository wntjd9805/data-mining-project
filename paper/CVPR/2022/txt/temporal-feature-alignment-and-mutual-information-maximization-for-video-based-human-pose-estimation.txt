Abstract
Multi-frame human pose estimation has long been a compelling and fundamental problem in computer vision.
This task is challenging due to fast motion and pose oc-clusion that frequently occur in videos. State-of-the-art methods strive to incorporate additional visual evidences from neighboring frames (supporting frames) to facilitate the pose estimation of the current frame (key frame). One aspect that has been obviated so far, is the fact that cur-rent methods directly aggregate unaligned contexts across frames. The spatial-misalignment between pose features of the current frame and neighboring frames might lead to un-satisfactory results. More importantly, existing approaches build upon the straightforward pose estimation loss, which unfortunately cannot constrain the network to fully leverage useful information from neighboring frames.
To tackle these problems, we present a novel hierarchi-cal alignment framework, which leverages coarse-to-ﬁne deformations to progressively update a neighboring frame to align with the current frame at the feature level. We further propose to explicitly supervise the knowledge ex-traction from neighboring frames, guaranteeing that useful complementary cues are extracted. To achieve this goal, we theoretically analyzed the mutual information between the frames and arrived at a loss that maximizes the task-relevant mutual information. These allow us to rank No.1 in the Multi-frame Person Pose Estimation Challenge on benchmark dataset PoseTrack2017, and obtain state-of-the-art performance on benchmarks Sub-JHMDB and Pose-Track2018. Our code is released at https://github. com/Pose-Group/FAMI-Pose, hoping that it will be useful to the community.
∗Corresponding Authors
Figure 1. State-of-the-art methods like PoseWarper and DCPose directly aggregate unaligned contexts from neighboring frames, which may fail for scenes with fast motion or pose occlusion.
We perform temporal feature alignment between each supporting frame and the key frame, delivering robust pose estimations. 1.

Introduction
A key component of our capacity to interact with oth-ers lies in our ability to recognize the poses of humans
[36, 37, 48]. Likewise, detecting human poses is crucial for an intelligent machine to adjust its action and properly allo-cate its attention when interacting with people. Nowadays, pose estimation ﬁnds abundant applications in a wide spec-trum of scenarios including action recognition, augmented reality, surveillance, and tracking [39, 67].
An extensive body of literature focuses on pose esti-mation in static images, ranging from earlier approaches
[47, 57, 59, 70] utilising tree models or random forest mod-els to recent attempts employing deep convolutional neural networks [6, 42, 54, 60]. For pose estimation in videos, such methods are severely challenged in handling deteriorated video frames arising from scenes with fast motion and pose occlusion. Incorporating and leveraging additional contexts from neighboring frames is desirable to ﬁll in the absent motion dynamics within a single frame and facilitate pose
estimation.
One line of work [2, 39, 58] proposes to aggregate vanilla sequential features of neighboring frames (support-ing frames). [39] trains a convolutional LSTM to model both spatial and temporal features, and directly predicts pose sequences for videos. [58] presents a 3D-HRNet to assemble features over a tracklet. Another line of work
[35, 45, 50] employs optical ﬂow or implicit motion estima-tion to polish the pose estimation of the current frame (key frame). [45, 50] propose to compute dense optical ﬂow be-tween frames, and leverage the ﬂow based motion ﬁeld for reﬁning pose heatmaps temporally across multiple frames.
[35] aggregates the pose heatmaps of consecutive frames and models motion residuals to improve pose estimation of the key frame.
Upon scrutinizing and experimenting on the released im-plementations of existing methods [5, 11, 35], we observe that they suffer from performance deterioration in challeng-ing cases such as rapid motion and pose occlusion. As il-lustrated in Fig. 1, in the pose occlusion scenario, existing methods like DCPose fail to recognize the right ankle of the occluded person, leading to unexpected results. In the fast motion scenario, existing methods encounter difﬁculties in identifying the left wrist due to motion blur. We conjec-ture that the reasons are twofolds. (1) It is common that the same person in the current frame and a neighboring frame is not well aligned, especially for situations involving rapid motion of human subjects or cameras. However, existing methods tend to directly aggregate unaligned contexts from neighboring frames, these spatially misaligned features po-tentially diminish the performances of models. (2) State-of-the-art approaches simply employ the conventional MSE (Mean Square Error of joints) loss to supervise the learning of pose heatmaps, while lacking an effective constraint on guaranteeing information gain from neighboring frames as well as a supervision at the intermediate feature level.
In this paper, we present a novel framework, along with theoretical analysis, to tackle the above challenges. The proposed method, termed FAMI-Pose (Feature Alignment and Mutual Information maximization for Pose estima-tion), consists of two key components. (i) FAMI-Pose con-ducts coarse-to-ﬁne deformations that systematically up-date a neighboring frame to align with the current frame at the feature level. Speciﬁcally, FAMI-Pose ﬁrst performs a global transformation, which holistically rearranges neigh-boring frame feature to preliminarily rectify spatial shifts or jitter. Subsequently, a local calibration is exploited to adaptively move and modulate each pixel of neighboring frame feature for enhanced feature alignment. (ii) FAMI-Pose further engages an information-theoretic objective as an additional intermediate supervision at the feature level.
Maximizing this mutual information objective allows our model to fully mine task-relevant cues within the neighbor-ing frames, extracting purposeful complementary knowl-edge to enhance pose estimation on the key frame. To the best of our knowledge, we are the ﬁrst to methodi-cally investigate the problem of feature alignment in human pose estimation and provide insights from an information-theoretic perspective.
We extensively evaluate the proposed method on three widely used benchmark datasets, PoseTack2017, Pose-Track2018, and Sub-JHMDB. Empirical evaluations show that our approach signiﬁcantly outperforms current state-of-the-art methods. Our method achieves 84.8 mAP, 82.2 mAP, and 96.0 mAP on PoseTrack2017, PoseTrack2018, and Sub-JHMDB, respectively. Our results are submitted to the ofﬁcial evaluation server of PoseTack2017, and rank
No.1 for this large benchmark dataset. We also present ex-tensive ablation analyses on the contribution of each com-ponent, and validate the efﬁcacy of feature alignment and the proposed mutual information loss.
The contributions of this work are summarized as:
• We propose to examine the multi-frame human pose estimation task from the perspective of effectively leveraging temporal contexts through feature align-ment.
• To explicitly supervise the knowledge extraction from neighboring frames, we propose an information-theoretic loss function, which allows maximizing the task-relevant cues mined from supporting frames.
• Our approach sets new state-of-the-art results on three benchmark datasets, PoseTrack2017, PoseTrack2018, and Sub-JHMDB. Our source code has been released. 2.