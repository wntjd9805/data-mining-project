Abstract
While GANs can produce photo-realistic images in ideal conditions for certain domains, the generation of full-body human images remains difficult due to the diversity of iden-In-tities, hairstyles, clothing, and the variance in pose. stead of modeling this complex domain with a single GAN, we propose a novel method to combine multiple pretrained
GANs, where one GAN generates a global canvas (e.g., hu-man body) and a set of specialized GANs, or insets, focus on different parts (e.g., faces, shoes) that can be seamlessly inserted onto the global canvas. We model the problem as jointly exploring the respective latent spaces such that the generated images can be combined, by inserting the parts from the specialized generators onto the global can-vas, without introducing seams. We demonstrate the setup by combining a full body GAN with a dedicated high-quality face GAN to produce plausible-looking humans. We evalu-ate our results with quantitative metrics and user studies. 1.

Introduction
Generative adversarial networks (GANs) have emerged as a very successful image generation paradigm. For exam-ple, StyleGAN [14] is now the method of choice for creating near photorealistic images for multiple classes (e.g., human faces, cars, landscapes). However, for classes that exhibit complex variations, creating very high quality results be-comes harder. For example, full-body human generation still remains an open challenge, given the high variability of human pose, shape, and appearance.
How can we generate results at both high resolution and high quality? One approach is to break the target image into tiles and train a GAN to sequentially produce them [7].
Such methods, however, are unsuited for cases where the coupling between the (object) parts are nonlocal and/or can-not easily be statistically modeled. An alternate approach is to aim for collecting very high resolution images and train a single GAN, at full resolution. However, this makes the data collection and training tasks very expensive, and varia-tions in object configuration/poses cause further challenges.
To the best of our knowledge, neither such a high resolution dataset, nor a corresponding high resolution GAN architec-ture has been published.
We propose InsetGAN towards solving the above prob-lems. Specifically, we propose to combine a generator to provide the global context in the form of a canvas, and a set of specialized part generators that provide details for dif-ferent regions of interest. The specialized results are then
B
IA
IB wA
GA wB
GB wB
B wA wB
I ↓
A
EA
Lborder
EB
Lcoarse
I ↓
B
Figure 2. InsetGAN Pipeline. Given two latents wA and wB, along with pretrained generators GA and GB, that generate two images
IA := GA(wA) and IB := GB(wB), respectively, we design a pipeline that can optimize either only wA (a), or iteratively optimize both wA and wB (b) in order to achieve a seamless output composition of face and body. We use a set of losses Lcoarse and Lborder to describe the conditions we want to minimize during optimization. On the right, we show that given an input body, mere copy and pasting of a target face yields boundary artifacts. We show an application of one-way optimization (top right) and two-way optimization (bottom right) to create a seamlessly merged result. Note that when the algorithm can optimize in both inset-face and canvas-body generator spaces, it produces more natural results at the seam boundary – notice how the hair and skin tone blend from the head to the body region. The joint optimization is challenging as the bounding box B(IA) is conditioned on the variable wA. pasted, as insets, on to the canvas to produce a final gen-eration. Such an approach has multiple advantages: (I) the canvas GAN can be trained on medium quality data, where the object parts are not necessarily aligned. Although this results in the individual parts in the canvas being somewhat blurry (e.g., fuzzy/distorted faces in case of human bodies), this is sufficient to provide global coordination for later spe-cialized parts to be inserted; (II) the specialized parts can be trained on part-specific data, where consistent alignment can be more easily achieved; and (III) different canvas/part
GANs can be trained at different resolutions, thus lower-ing the data (quality) requirements. CollageGAN [20] has explored a similar idea in a conditional setting. Given a semantic map which provides useful shape and alignment hints, they create a collage using an ensemble of outputs from class-specific GANs [20]. In contrast, our work fo-cuses on the unconditional setting, which is more challeng-ing since our multiple generators need to collaborate with one another to generate a coherent shape and appearance together without access to a semantic map for hints.
The remaining problem is how to coordinate the canvas and the part GANs, such that adding the insets to the can-vas does not reveal seam artifacts at the inset boundaries.
This aspect is particularly challenging when boundary con-ditions are nontrivial and the inset boundaries themselves are unknown. For example, a face, when added to the body, should have consistent skin tone, clothing boundaries, and hair flow. We solve the problem by jointly seeking latent codes in (pretrained) canvas and part GANs such that the fi-nal image, formed by inserting the part insets on the canvas, does not exhibit any seams. In this paper, we investigate this problem in the context of human body generation, where the human faces are created by a face-specific GAN.
We evaluate InsetGAN on a custom dataset, compare with alternative approaches, and evaluate the quality of the results with quantitative metrics and user studies. Fig. 1 shows human body generation applications highlighting both seamless results, across face insets, as well as having diversity of solutions across face insertion boundaries.
Contributions. (1) We propose a multi-GAN optimiza-tion framework that jointly optimizes the latent codes of two or more collaborative generators such that the overall com-posed result is coherent and free of boundary artifacts when the generated parts are inserted as insets into the generated canvas. (2) We demonstrate our framework on the highly challenging full-body human generation task and propose the first viable pipeline to generate plausible-looking hu-mans unconditionally at 1024×1024px resolution. 2.