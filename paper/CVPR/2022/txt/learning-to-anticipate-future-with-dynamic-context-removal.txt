Abstract
Anticipating future events is an essential feature for in-telligent systems and embodied AI. However, compared to the traditional recognition task, the uncertainty of future and reasoning ability requirement make the anticipation task very challenging and far beyond solved. In this filed, previous methods usually care more about the model ar-chitecture design or but few attention has been put on how to train an anticipation model with a proper learning pol-icy. To this end, in this work, we propose a novel training scheme called Dynamic Context Removal (DCR), which dynamically schedule the visibility of observed future in the learning procedure. It follows the human-like curriculum learning process, i.e., gradually removing the event context to increase the anticipation difficulty till satisfying the fi-nal anticipation target. Our learning scheme is plug-and-play and easy to integrate any reasoning model includ-ing transformer and LSTM, with advantages in both effec-tiveness and efficiency. In extensive experiments, the pro-posed method achieves state-of-the-art on four widely-used benchmarks. Our code and models are publicly released at https://github.com/AllenXuuu/DCR. 1.

Introduction
Anticipating human action in the near future is a funda-mental ability of humans as well as a basic requirement for intelligent systems with reasoning functionality. It serves as a support for many applications like autonomous driv-ing [1, 40] and human-robot interaction [29, 42], where the future prediction of pedestrians and users are essential.
With the rapid evolution of deep learning techniques, the comprehensive understanding and analysis of human action videos attract attention in edging researches. In the tradi-tional recognition field, modern video models [6, 13, 15, 34, 44,48,49,53,54] leverage spatiotemporal modeling to learn both spatial patterns and temporal logic and achieve signif-*Cewu Lu is the corresponding author, member of Qing Yuan Research
Institute and MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai
Jiao Tong University, China and Shanghai Qi Zhi institute.
Figure 1. Revisiting learning curriculums in the classical Sudoku game, a kid starts with an easy Sudoku game of more observation (hints) then gets taught a harder level of less observable numbers.
This reveals the curriculum learning process of how humans learn to reason in the physical world. In this work, we are inspired by learning Sudoku and build action anticipation model with similar curriculum designs. We leverage extra auxiliary frames in training but dynamically schedule their visibility to gradually strengthen the reasoning ability of model. icant progress in many video recognition tasks [8, 21, 26].
Besides, there is also growing interests in action anticipa-tion [8, 9, 30, 33, 46]. Similarly, they both expect systems to discriminate the existing actions in videos. Differently, the observed video segment given for systems shifts forward in action anticipation, while in action recognition systems have the all the information of videos. Due to the temporal misalignment between visual observation and target action semantics, action anticipation is a much more challenging task than action recognition. It can hardly be simply treated as classification like video recognition for some reasons.
First, the spatial configurations which deep neural networks (DNN) learned in the anticipation task is biased towards the supervision of future action labels, leading to the inaccurate representation of the current visual observation [18]. Sec-ond, the observation has a gap with the start time of action event, which challenges the high-level reasoning ability of model especially in the long-term dense action prediction setting [27, 43].
To tackle with the action anticipation, previous meth-ods [10, 18â€“20, 22, 43, 57] proposed various neural archi-tectures to focus on learning the temporal logic from past observations, with the intention to apply the past logic in reasoning the future. Though such methods achieve im-provements, they still face performance bottlenecks on chal-lenging benchmarks [8, 9, 30, 33, 46]. We argue that the rea-son is mainly that they did not learn from the way humans learn. In this work, we propose a simple but effective per-spective for action anticipation. We want the model to learn temporal logic with the auxiliary of the future snippet but keep the functionality to reason out the future only given the observation in the past, which meets up the restriction of anticipation problem. To achieve our intention, we pro-pose Dynamic Context Removal (DCR) learning scheme, which integrates the motivation of curriculum learning [4] to train with sufficient context auxiliary at first then remove redundant context for better adaptation to a more difficult anticipation task, following the gradual learning process of humans. Fig. 1 gives an intuitive example.
Our training scheme is flexible and can easily advance different temporal reasoning architectures. Here, we mainly choose transformer [51] to implement our paradigm. First, in the full context mode, we propose the order-aware pre-training to learn video sequential order, which is a gen-eralized method for transformer architecture. Next, in the partial context mode, we aim to reconstruct frames during action occurrence and dynamically schedule the visibility of auxiliary context. This learning paradigm conforms to how humans learn [4]. Apart from the transformer [51], we show our training scheme can also improve LSTM [24] based neural architecture.
We conduct experiments and analyses on four widely-used action anticipation benchmarks: EPIC-KITCHENS-100 [8], EPIC-KITCHENS-55 [9], EGTEA GAZE+ [33], 50-Salads [46]. Our training strategy turns out to be effec-tive and achieves state-of-the-art on all four benchmarks.
Moreover, we believe the proposed subtractive and adap-tive paradigm can pave the way for the other complex and challenging temporal predictive tasks.
Our contribution includes: (1) We propose a novel learn-ing scheme DCR, which advances the effectiveness and ef-ficient of practical temporal modeling architecture includ-(2) We propose a ing transformer [51] and LSTM [24]. general order-aware pre-training for transformer architec-ture to carry out unsupervised pre-training using sequential order as supervision. (3) We achieve state-of-the-art on four widely-used action anticipation benchmarks. 2.