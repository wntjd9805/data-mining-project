Abstract
In this work we present point-level region contrast, a self-supervised pre-training approach for the task of object detection. This approach is motivated by the two key fac-tors in detection: localization and recognition. While accu-rate localization favors models that operate at the pixel- or point-level, correct recognition typically relies on a more holistic, region-level view of objects.
Incorporating this perspective in pre-training, our approach performs con-trastive learning by directly sampling individual point pairs from different regions. Compared to an aggregated repre-sentation per region, our approach is more robust to the change in input region quality, and further enables us to im-plicitly improve initial region assignments via online knowl-edge distillation during training. Both advantages are im-portant when dealing with imperfect regions encountered in the unsupervised setting. Experiments show point-level region contrast improves on state-of-the-art pre-training methods for object detection and segmentation across mul-tiple tasks and datasets, and we provide extensive ablation studies and visualizations to aid understanding. Code will be made available. 1.

Introduction
Un-/self-supervised learning – in particular contrastive learning [6, 20, 24] – has recently arisen as a powerful tool to obtain visual representations that can potentially bene-ﬁt from an unlimited amount of unlabeled data. Promis-ing signals are observed on important tasks like object de-tection [28]. For example, MoCo [20] shows convincing improvement on VOC [16] over supervised pre-training by simply learning to discriminate between images as holis-tic instances [14] on the ImageNet-1K dataset [37]. Since then, numerous pre-text tasks that focus on intra-image con-trast have been devised speciﬁcally for object detection as the downstream transfer task [23, 43, 51]. While there has been steady progress, state-of-the-art detectors [1] still use weights from supervised pre-training (e.g., classiﬁcation on
ImageNet-22K [12]). The full potential of unsupervised
*Work done during an internship at FAIR.
Figure 1. For intra-image contrastive learning, samples of a feature map can be aggregated and then compared between regions (1), compared directly between all samples (2), or only compared di-rectly between samples in different regions (3). We call (3) point-level region contrast, it allows both learning at the point-level to help localization, and at the region-level to help holistic object recognition – two crucial aspects for object detection. pre-training for object detection is yet to be realized.
Object detection requires both accurate localization of objects in an image and correct recognition of their seman-tic categories. These two sub-tasks are tightly connected and often reinforce each other in successful detectors [32].
For example, region proposal methods [2, 41, 54] that ﬁrst narrow down candidate object locations have enabled R-CNN [18] to perform classiﬁcation on rich, region-level fea-tures. Conversely, today’s dominant paradigm for object instance segmentation [21] ﬁrst identiﬁes object categories along with their coarse bounding boxes, and later uses them to compute masks for better localization at the pixel-level.
With this perspective, we hypothesize that to learn a useful representation for object detection, it is also desir-able to balance recognition and localization by leveraging information at various levels during pre-training. Object recognition in a scene typically takes place at the region-level [18, 35]. To support this, it is preferable to maintain a conceptually coherent ‘label’ for each region, and learn to contrast pairs of regions for representation learning. On the other hand, for better localization, the model is preferred
to operate at the pixel-, or ‘point-level’ [9, 26], especially when an initial, unsupervised, assignment of pixels to re-gions (i.e., segmentation) is sub-optimal (see Fig. 1 for an example). To our knowledge, existing methods in this fron-tier can be lacking in either of these two aspects (to be dis-cussed in Sec. 2).
In this paper, we present a self-supervised pre-training approach that conceptually contrasts at the region-level while operating at the point-level. Starting from MoCo v2 [7] as an image-level baseline, we introduce the notion of ‘regions’ by dividing each image into a non-overlapping grid [23]. Treating rectangular regions on this grid as sep-arate instances, we can deﬁne the task of intra-image dis-crimination on top of the existing inter-image one [14] and pre-train a representation with contrastive objectives. Devi-ating from the common practice that aggregates features for contrastive learning [6, 20, 23], we directly operate at the point-level by sampling multiple points from each region, and contrasting point pairs individually across regions (see
Fig. 1, right column for illustrations).
The advantage of operating at the point-level is two-fold, both concerning dealing with imperfect regions as there is no ground-truth. First, such a design can be more robust to the change in region quality, since feature aggregation can cause ambiguities when the regions are not well local-ized (e.g., in Fig. 1, both regions of interest can mean ‘a mixture of dog and couch’), whereas individual points still allow the model to see distinctions. Second and perhaps more importantly, it can enable us to bootstrap [19] for po-tentially better regions during the training process. This is because any segmentation can be viewed as a hard-coded form of point afﬁnities – 1 for point pairs within the same region and 0 otherwise; and a natural by-product of con-trasting point pairs is soft point afﬁnities (values between 0 and 1) that implicitly encode regions. By viewing the mo-mentum encoder as a ‘teacher’ network, we can formulate the problem as knowledge distillation one [4, 25], and im-proving point afﬁnities (and thus implicitly regions) online in the same self-supervised fashion.
Empirically, we applied our approach to standard pre-training datasets (ImageNet-1K [12] and COCO train set [28]), and transferred the representation to multiple downstream datasets: VOC [16], COCO (for both object de-tection and instance segmentation), and Cityscapes [10] (se-mantic segmentation). We show strong results compared to state-of-the-art pre-training methods which use image-level, point-level, or region-level contrastive learning. Moreover, we provide extensive ablation studies covering different as-pects in design, and qualitatively visualize the point afﬁni-ties learned through knowledge distillation.
While we are yet to showcase improvements on larger models, longer training schedules, stronger augmenta-tions [17], and bigger pre-training data for object detec-tion, we believe our explorations on the pre-training design that better balances recognition and localization can inspire more works in this direction. 2.