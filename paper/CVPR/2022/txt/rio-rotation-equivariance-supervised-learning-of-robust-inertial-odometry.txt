Abstract
This paper introduces rotation-equivariance as a self-supervisor to train inertial odometry models. We demon-strate that the self-supervised scheme provides a powerful supervisory signal at training phase as well as at inference stage. It reduces the reliance on massive amounts of labeled data for training a robust model and makes it possible to up-date the model using various unlabeled data. Further, we propose adaptive Test-Time Training (TTT) based on uncer-tainty estimations in order to enhance the generalizability of the inertial odometry to various unseen data. We show in experiments that the Rotation-equivariance-supervised
Inertial Odometry (RIO) trained with 30% data achieves on par performance with a model trained with the whole dataset. Adaptive TTT improves modelsâ€™ performance in all cases and makes more than 25% improvements under several scenarios. We release our code and dataset at this website. 1.

Introduction
Accurate and robust localization with low-cost Inertial
Measurement Units (IMUs) is an ideal solution to a wide range of applications from augmented reality [34] to in-door positioning services [30,35]. An IMU usually consists of accelerometers and gyroscopes, sometimes magnetome-ters and can sample linear acceleration, angular velocity and magnetic field density in an energy-efficient way. It can be light-weight and pretty cheap that many mobile devices like smartphones and VR headsets are instrumented with it. In many scenarios such as indoor or underground where global navigation satellite system is not available, ubiquitous IMU is a promising signal source, which can provide reliable and continuous location service. Unlike Visual-Inertial Odom-etry (VIO) [9] that is sensitive to surroundings and cannot work under extreme lighting, IMU-only inertial odometry is more desired and possible to perform accurate and robust localization every time and everywhere [11, 20].
Recent advances of data-driven approaches (e.g., IONet
[4], RoNIN [14], TLIO [20]) based on machine learning
*1 denotes equal contribution.
Figure 1. An example trajectory estimation improved by RIO.
On the left, we show original model performance before rotation-equivariance supervised learning and right is the result of RIO.
In the middle, we show uncertainty estimation (orange), auxil-iary losses (blue) computed by the self-supervised task, original estimated velocity MSE (red) and updated model velocity MSE (green). and deep learning have pushed the limit of traditional iner-tial odometry [15, 22]. These advancements make IMU de-vice usable in the wild. However, to the best of our knowl-edge, all of them are based on purely supervised learning, which is notoriously weak under distribution shifts. IMU sensor data varies widely with different devices and users, and sometimes the sensor data drifts over time. It is hard to control the distribution variability when the supervised al-gorithms are deployed in diverse applications. A rich and diverse datasets such as RoNIN [14] can alleviate the prob-lem to some extent, but it is cumbersome to collect such a big dataset and there are always scenarios that the dataset does not include and therefore the supervised model cannot capture their characteristics.
In order to mitigate the challenge of distribution shift in real-world, we propose a geometric constraint, rotation-equivariance, that can improve generalizability of deep model in training phase and help the deep model to learn from shifted sensor data at inference time. Heading-Agnostic Coordinate Frame (HACF) is one coordinate frame whose Z-axis is aligned with gravity as presented in
RoNIN [14]. We use HACF to solve pedestrian trajectory estimation and constrain rotation under horizontal plane.
The assumption of rotation-equivariance is when the IMU
sequence in HACF is rotated around Z axis by a random an-gle, the corresponding predicted trajectory should be trans-formed by the same horizontal rotation.
Under this assumption, we propose an auxiliary task. It is to minimize angle error between deep model prediction for rotated IMU data, and rotated prediction of the orig-inal data.
In experiments we validate that the auxiliary task improves model robustness in training phase when it is jointly optimized with the supervised velocity loss. During inference time, we formulate the auxiliary task as a self-supervised learning problem alone. Auxiliary loss is gen-erated by test samples at inference time. We update model parameters based on it and therefore the model is adapted to the distribution of given test data. This process is named as
Test-Time Training (TTT) [27]. Empirical results of TTT indicate the proposed self-supervision task brings substan-tial improvements at inference time. Furthermore, we intro-duce deep ensembles, a promising approach for simple and scalable predictive uncertainty estimation [19]. We show in experiments that the estimated uncertainty using deep en-sembles is consistent with the error distribution.
It helps us to develop adaptive TTT, in which model parameters are updated when the uncertainty of prediction reaches a cer-tain level. We compare different TTT strategies and study the relationship between update frequency and model pre-cision.
In summary, our paper has the following three main con-tributions: 1) We propose Rotation-equivariance-supervised Iner-tial Odometry (RIO) and demonstrate that rotation-equivariance can be formulated as an auxiliary task with powerful supervisory signal in training phase. 2) We employ TTT based on rotation-equivariance for learning-based inertial odometry and validate that it helps to improve the generalizability of RIO. 3) We introduce deep ensembles as a practical approach for uncertainty estimation, and utilize the uncertainty result as indicators for adaptively triggering TTT.
The remainder structure of this paper is: we first give an overview on previous work regarding inertial odometry algorithms and related self-supervised tasks. Then we intro-duce our method and finally present experiments and eval-uations. 2.