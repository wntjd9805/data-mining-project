Abstract
We study the problem of attribute compression for large-scale unstructured 3D point clouds. Through an in-depth exploration of the relationships between different encoding steps and different attribute channels, we introduce a deep compression network, termed 3DAC, to explicitly compress the attributes of 3D point clouds and reduce storage us-age in this paper. Speciﬁcally, the point cloud attributes such as color and reﬂectance are ﬁrstly converted to trans-form coefﬁcients. We then propose a deep entropy model to model the probabilities of these coefﬁcients by consider-ing information hidden in attribute transforms and previous encoded attributes. Finally, the estimated probabilities are used to further compress these transform coefﬁcients to a
ﬁnal attributes bitstream. Extensive experiments conducted on both indoor and outdoor large-scale open point cloud datasets, including ScanNet and SemanticKITTI, demon-strated the superior compression rates and reconstruction quality of the proposed method. 1.

Introduction
As a common 3D data representation, point clouds have been widely used in a variety of real applications such as mixed reality [28], self-driving vehicles [16, 21], and high-resolution mapping [20, 37]. Thanks to the remarkable progress achieved in 3D acquisition, point clouds become increasingly accessible. However, the storage and trans-mission of massive irregularly sampled points pose a new challenge to existing compression techniques. In particu-lar, along with the raw 3D coordinates of points, the com-pression of their attributes (e.g., color, reﬂectance) is also non-trivial1. In this regard, we will study effective attribute compression for unstructured point clouds in this paper.
To achieve point cloud attribute compression, early
*Corresponding author: Yulan Guo (guoyulan@sysu.edu.cn). 1For example, with the standard point cloud compression algorithm of
MPEG (i.e., G-PCC [39]), attribute compression takes up to 60% and 90% of the overall bitstream for lossy and lossless compression, respectively.
Figure 1. Qualitative point cloud attribute compression results of 3D auto-encoder, G-PCC, and our method on the ScanNet [10].
Bits Per Point (BPP) and Peak Signal-to-Noise Ratio (PSNR) of the luminance component are reported. Note that, the raw point clouds usually use uint8 RGB values (i.e., 8 × 3 = 24 BPP). works [11,29,30,41,42,45,48,57] usually apply image pro-cessing techniques to 3D point clouds. In particular, early methods usually follow a two-step framework, i.e., initial coding of attributes and entropy coding of transform coef-ﬁcients. A number of approaches focus on developing so-phisticated initial coding algorithms, which convert point cloud attributes to coefﬁcients in a speciﬁc domain. How-ever, entropy coding, which further losslessly encodes co-efﬁcients to a ﬁnal bitstream, has been largely overlooked.
There are only a few entropy coders [18, 26, 39] have been proposed for attribute compression in recent works.
In general, entropy coding is independently included in the aforementioned attribute compression framework with ini-tial coding. More speciﬁcally, these traditional hand-crafted entropy coders take coefﬁcients as a sequence of symbols and estimate the probability distribution2 only considering 2According to the information theory [40], a lower bound of bitrate can be achieved by an entropy coder given the actual distribution of the transmitted coefﬁcients.
the previous input symbols as context information. Most of prior entropy coders do not incorporate geometry informa-tion of point clouds or context information of initial coding.
Moreover, these approaches separately encode attributes for each channel and do not make full use of the inter-channel correlations between different attributes.
In this paper, we propose a learning-based compres-sion framework, termed 3DAC, for point cloud attributes.
Speciﬁcally, the proposed 3DAC adopts Region Adaptive
Hierarchical Transform (RAHT) [11] for initial coding.
Then, we propose an attribute-oriented deep entropy model to estimate the probability distribution of transform coefﬁ-cients. In particular, we model the probabilities of these co-efﬁcients by exploring context information from the initial coding stage and inter-channel correlations between differ-ent attributes. As shown in Fig. 1, our method achieves higher reconstruction quality with a lower bitrate, indicat-ing excellent attribute compression performance. The main contributions of this paper are as follows:
• We introduce a learning-based, effective framework for attribute compression of 3D point clouds, with competitive compression performance.
• We propose an attribute-oriented deep entropy model to connect the initial coding and entropy coding steps in attribute compression, and explore the inter-channel correlations between different attributes.
• We demonstrate the state-of-the-art compression per-formance of the proposed method on both indoor and outdoor point cloud datasets. 2.