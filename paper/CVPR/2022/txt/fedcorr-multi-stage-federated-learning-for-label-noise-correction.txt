Abstract
Federated learning (FL) is a privacy-preserving dis-tributed learning paradigm that enables clients to jointly train a global model.
In real-world FL implementations, client data could have label noise, and different clients could have vastly different label noise levels. Although there exist methods in centralized learning for tackling la-bel noise, such methods do not perform well on heteroge-neous label noise in FL settings, due to the typically smaller sizes of client datasets and data privacy requirements in FL.
In this paper, we propose FedCorr, a general multi-stage framework to tackle heterogeneous label noise in FL, with-out making any assumptions on the noise models of local clients, while still maintaining client data privacy. In par-ticular, (1) FedCorr dynamically identiﬁes noisy clients by exploiting the dimensionalities of the model prediction subspaces independently measured on all clients, and then identiﬁes incorrect labels on noisy clients based on per-sample losses. To deal with data heterogeneity and to in-crease training stability, we propose an adaptive local prox-imal regularization term that is based on estimated local noise levels. (2) We further ﬁnetune the global model on identiﬁed clean clients and correct the noisy labels for the remaining noisy clients after ﬁnetuning. (3) Finally, we ap-ply the usual training on all clients to make full use of all local data. Experiments conducted on CIFAR-10/100 with federated synthetic label noise, and on a real-world noisy dataset, Clothing1M, demonstrate that FedCorr is robust to label noise and substantially outperforms the state-of-the-art methods at multiple noise levels. 1.

Introduction
Federated learning (FL) is a promising solution for large-scale collaborative learning, where clients jointly train a machine learning model, while still maintaining local data privacy [18, 24, 34]. However, in real-world FL implemen-tations over heterogeneous networks, there may be differ-*Equal contributions. † Corresponding author.
Code: https://github.com/Xu-Jingyi/FedCorr ences in the characteristics of different clients due to di-verse annotators’ skill, bias, and hardware reliability [4,35].
Client data is rarely IID and frequently imbalanced. Also, some clients would have clean data, while other clients may have data with label noise at different noise levels. Hence, the deployment of practical FL systems would face chal-lenges brought by discrepancies in two aspects i): local data statistics [5, 12, 19, 24], and ii): local label quality [4, 35].
Although recent works explored the discrepancy in local data statistics in FL, and learning with label noise in central-ized learning (CL), there is at present no uniﬁed approach for tackling both challenges simultaneously in FL.
The ﬁrst challenge has been explored in recent FL works, with a focus on performance with convergence guarantees
[20, 25]. However, these works have the common implicit assumption that the given labels of local data are completely correct, which is rarely the case in real-world datasets.
The second challenge can be addressed by reweight-ing [4, 7, 28] or discarding [33] those client updates that are most dissimilar. In these methods, the corresponding clients are primarily treated as malicious agents. However, dissimi-lar clients are not necessarily malicious and could have label noise in local data that would otherwise still be useful after label correction. For FL systems, the requirement of data privacy poses an inherent challenge for any label correction scheme. How can clients identify their noisy labels to be corrected without needing other clients to reveal sensitive information? For example, [35] proposes label correction for identiﬁed noisy clients with the guidance of extra data feature information exchanged between clients and server, which may lead to privacy concerns.
Label correction and, more generally, methods to deal with label noise, are well-studied in CL. Yet, even state-of-the-art CL methods for tackling label noise [3, 8, 9, 16, 27, 30, 32, 37], when applied to local clients, are inadequate in mitigating the performance degradation in the FL setting, due to the limited sizes of local datasets. These CL meth-ods cannot be applied on the global sever or across multiple
This work is supported by the National Research Foundation, Singa-pore under its AI Singapore Program (AISG Award No: AISG-RP-2019-015), and under its NRFF Program (NRFFAI1-2019-0005). This work is also supported in part by the SUTD Growth Plan Grant for AI.
Figure 1. An overview of FedCorr, organized into three stages. Algorithm steps are numbered accordingly. clients due to FL privacy requirements. So, it is necessary and natural to adopt a more general framework that jointly considers the two discrepancies, for a better emulation of real-world data heterogeneity. Most importantly, privacy-preserving label correction should be incorporated in train-ing to improve robustness to data heterogeneity in FL.
In this paper, we propose a multi-stage FL framework to simultaneously deal with both discrepancy challenges; see
Fig. 1 for an overview. To ensure privacy, we introduce a dimensionality-based ﬁlter to identify noisy clients, by measuring the local intrinsic dimensionality (LID) [10] of local model prediction subspaces. Extensive experiments have shown that clean datasets can be distinguished from noisy datasets by the behavior of LID scores during train-ing [22,23]. Hence, in addition to the usual local weight up-dates, we propose that each client also sends an LID score to the server, which is a single scalar representing the discrim-inability of the predictions of the local model. We then ﬁlter noisy samples based on per-sample training losses indepen-dently for each identiﬁed noisy client, and relabel the large-loss samples with the predicted labels of the global model.
To improve training stability and alleviate the negative im-pact caused by noisy clients, we introduce a weighted prox-imal regularization term, where the weights are based on the estimated local noise levels. Furthermore, we ﬁnetune the global model on the identiﬁed clean clients and relabel the local data for the remaining noisy clients.
Our main contributions are as follows:
• We propose a general multi-stage FL framework
FedCorr to tackle data heterogeneity, with respect to both local label quality and local data statistics.
• We propose a general framework for easy generation of federated synthetic label noise and diverse (e.g. non-IID) client data partitions.
• We identify noisy clients via LID scores, and identify noisy labels via per-sample losses. We also propose an adaptive local proximal regularization term based on estimated local noise levels.
• We demonstrate that FedCorr outperforms state-of-the-art FL methods on multiple datasets with different noise levels, for both IID and non-IID data partitions. 2.