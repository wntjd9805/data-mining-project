Abstract
Deep neural networks (DNN) have achieved great suc-cess in image restoration. However, most DNN methods are designed as a black box, lacking transparency and inter-pretability. Although some methods are proposed to com-bine traditional optimization algorithms with DNN, they usually demand pre-defined degradation processes or hand-crafted assumptions, making it difficult to deal with com-plex and real-world applications. In this paper, we propose a Deep Generalized Unfolding Network (DGUNet) for im-age restoration. Concretely, without loss of interpretability, we integrate a gradient estimation strategy into the gradi-ent descent step of the Proximal Gradient Descent (PGD) algorithm, driving it to deal with complex and real-world image degradation. In addition, we design inter-stage in-formation pathways across proximal mapping in different
PGD iterations to rectify the intrinsic information loss in most deep unfolding networks (DUN) through a multi-scale and spatial-adaptive way. By integrating the flexible gradi-ent descent and informative proximal mapping, we unfold the iterative PGD algorithm into a trainable DNN. Exten-sive experiments on various image restoration tasks demon-strate the superiority of our method in terms of state-of-the-art performance, interpretability, and generalizability. The source code is available at github.com/MC-E/DGUNet. 1.

Introduction
Image restoration (IR) aims to recover the high-quality image x from its degraded measurement y. The degradation process is generally defined as: y = Ax + n, (1) where A is the degradation matrix, and n represents the ad-ditive noise. It is typically an ill-posed problem. According
Figure 1. Real image denoising performance (y-axis) of our
DGUNet and some recent denoisers (VDNet [75], GDANet [76],
AINDNet [33], MIRNet [78], DeamNet [53], MPRNet [79]) under different parameter capacities (x-axis) on DND [52] dataset. to A, IR can be categorized into many subtasks, e.g., image denoising, deblurring, deraining, compressive sensing. In the past few decades, IR has been extensively studied, lead-ing to three main active research topics, i.e., model-based methods , deep learning methods , and hybrid methods.
Model-based methods (e.g., [7,12,17,25,32,56]) usually formulate IR as a Bayesian problem, solving Eq. (1) under a unified MAP (maximizing a posterior) framework:
ˆx = argmax logP (x|y) = argmax logP (y|x) + logP (x), x x (2) where logP (y|x) and logP (x) represent the data fidelity and regularization terms, respectively. The data fidelity term is usually defined as an ℓ2 norm, expressing Eq. (2) as the following energy function:
ˆx = argmin x 1 2
||y − Ax||2 2 + λJ(x), (3)
This work was supported in part by Shenzhen Fundamental Research
Program (No.GXWD20201231165807007-20200807164903001) and Na-tional Natural Science Foundation of China (61902009). (Corresponding author: Jian Zhang.) where λ is a hyper-parameter to weight the regulariza-tion term J(x). The data fidelity term guarantees the so-lution accords with degradation. The regulation term al-leviates the ill-posed problem by enforcing desired prop-erty, which involves sophisticated priors, e.g., total varia-tion [49], sparse representation [15, 18, 42], low-rank [23], and self-similarity [7,12]. However, the representation abil-ity of handcrafted design is limited, leading to unstable re-sults, and they are usually time-consuming in inference.
Recently, deep-learning IR [13, 91–93] has achieved im-pressive success, as they can learn strong priors from large-scale datasets. Up to now, numerous function units have been proposed. [62] proposed a memory strategy to broad-cast useful information in different layers. [6, 24, 33, 75, 79] utilized hourglass-shaped architectures to explore multi-scale features. Some non-local methods [40, 45, 46] were proposed to enlarge the receptive field. Although the promising performance and fast inference, the black box design makes it hard to analyze the role of different compo-nents, and performance gains are often attributed to stacking new modules at the price of increased model complexity.
To combine interpretability and adaptivity, some hy-brid methods proposed integrating deep networks into clas-sic optimization algorithms. For instance, deep plug-and-play (PNP) methods [44, 74, 89, 92, 94] integrated pre-trained CNN denoiser, as the prior, into iterative optimiza-tion frameworks for different IR tasks. Unfortunately, they usually suffer from time-consuming inference. Recently, deep unfolding networks (DUN) [16, 53, 83, 88] proposed optimizing all parameters end-to-end, delivering better per-formance and faster inference. However, due to the inter-pretable design, most of them require known degradation processes to derive the solution. Nevertheless, the degra-dation processes in real-world applications are complicated and unassured with signal-dependent and spatially variant distribution. Thus, most DUN methods make handcrafted degradation assumptions [16] or explicitly provide the net-work with degradation factors [88] to deal with pre-defined image degradation problems. In addition, since traditional model-based methods output an image in each iteration, the corresponding DUN has to adopt the input and output of each stage as an image. This inherent design inevitably re-sults in feature-to-image information distortion. Such infor-mation loss in DUN has little notice in existing works.
To rectify the above issues and bridge the gap between model-based methods and deep learning methods, we pro-pose a deep generalized unfolding network (DGUNet). On the one hand, our method has good interpretability as model-based methods by formulating the model design via a Proximal Gradient Descent (PGD) algorithm. On the other hand, similar to deep learning methods, our method is trained end-to-end with an unhindered feature pathway and can be easily applied to complex and real-world appli-cations. To achieve this, we first integrate a gradient es-timation strategy to the gradient descent step of the PGD algorithm to predict the gradient in degradation-unknown cases. We then design inter-stage information pathways to compensate for the intrinsic information loss in DUN. To summarize, this work has the following contributions:
• The iterative optimization step of PGD algorithm is used to guide the mode design, leading to an end-to-end trainable and also interpretable model (DGUNet).
• Our DGUNet presents a general CNN-based imple-mentation of DUN by combining a gradient estimation strategy into the PGD algorithm, enabling PGD to be easily applied to complex and real-world IR tasks.
• We design inter-stage information pathways in the
DUN framework to broadcast multi-scale features in a spatial-adaptive normalization way, which rectifies the intrinsic information loss in most DUN methods.
• Extensive experiments demonstrate that our method can solve general IR tasks with state-of-the-art perfor-mance (including twelve synthetic and real-world test sets) and attractive complexity (see Fig. 1). 2.