Abstract
Deep learning-based image salient object detection (SOD) heavily relies on large-scale training data with pixel-wise labeling. High-quality labels involve intensive labor and are expensive to acquire. In this paper, we propose a novel multi-source uncertainty mining method to facilitate unsupervised deep learning from multiple noisy labels gen-erated by traditional handcrafted SOD methods. We design an Uncertainty Mining Network (UMNet) which consists of multiple Merge-and-Split (MS) modules to recursively ana-lyze the commonality and difference among multiple noisy labels and infer pixel-wise uncertainty map for each label.
Meanwhile, we model the noisy labels using Gibbs distri-bution and propose a weighted uncertainty loss to jointly train the UMNet with the SOD network. As a consequence, our UMNet can adaptively select reliable labels for SOD network learning. Extensive experiments on benchmark datasets demonstrate that our method not only outperforms existing unsupervised methods, but also is on par with fully-supervised state-of-the-art models. 1.

Introduction
Image salient object detection (SOD) aims at identifying and segmenting the most prominent object in a scene. Ex-isting SOD methods can be mainly divided into two cate-gories, i.e., convolutional neural network (CNN) based and traditional handcrafted methods. Both of them have their unique pros and cons. On the one hand, driven by the strong model capacity of deep networks, CNN based SOD meth-ods have achieved remarkable success. However, they heav-ily rely on large amounts of training data with pixel-wise annotations, which are labor-intensive and expensive to ac-quire. On the other hand, handcrafted SOD methods are more flexible to the data annotations, but they are fragile in practice due to the limitations of manually designed image features and priors.
With the above concern, one research topic termed deep unsupervised SOD [20,38,40,43] has been activated, which focuses on training the deep SOD networks using the noisy
*Corresponding author: Lijun Wang, ljwang@dlut.edu.cn (a) Image (b) Four pseudo labels generated by traditional methods (c) Saliency GT (d) Uncertainty GTs of the above four pseudo labels (e) Saliency prediction (f) Our predicted uncertainty maps
Figure 1. Motivation. Given an input image (a) and its correspond-ing four pseudo labels generated by the traditional SOD methods (b), our UMNet predicts the uncertainty maps (f) of the pseudo labels, according to which our SODNet is learned under the su-pervision of the reliable labeling samples and generates promising saliency result (e). The ground truths of uncertainty maps (d) are obtained by the computing the difference between each pseudo la-bel in (b) with the saliency ground truth (c), which are not available under the unsupervised learning setting. pseudo labels generated by traditional handcrafted SOD methods. Directly training networks using the noisy la-bels is not a wise choice since the deep network can eas-ily fit to the corrupted labels [37]. One straightforward so-lution is first performing label refinement and then using the refined labels for network training [20]. Another pop-ular line [38, 40, 43] devotes to modeling the noise of the pseudo labels. For instance, the work of [43] assumes that the label noise obeys a Gaussian distribution and builds a noise modeling module to fit such distribution. Zhang et al. [40] compute a dense confidence map based on the vari-ance of network predictions among different training iter-ations. While promising results have been delivered, it is still an open problem to model the noisy labels and find the reliable ones in an unsupervised learning manner.
In this paper, we establish a novel deep unsupervised
SOD framework for effectively mining the reliable pixel-wise labels from multiple pseudo labels. As shown in Fig-ure 1 (b), different handcrafted methods perform diversely for the same input image since they follow different manu-ally designed principles. Nevertheless, each of the pseudo labels contains some reliable label samples (cf . the dark region of Figure 1 (d)). Accurately identifying these reli-able/certain samples is troublesome when only observing single pseudo label without any other reference. Alterna-tively, it becomes much feasible if we simultaneously em-ploy multiple labels of the same image for cross reference.
Based on this insight, we design a novel Uncertainty Min-ing Network (UMNet) to densely capture the soft uncer-tainty from multi-source pseudo labels. It consists of mul-tiple Merge-and-Split (MS) modules and infers the pixel-wise uncertainty map for each label by recursively analyz-ing the commonality and difference among multiple noisy labels. According to the predicted uncertainty by the UM-Net, the Salient Object Detection Network (SODNet) can be learned using the reliable label samples.
For network training, another concern is encountered.
Considering that the ground truth of uncertainty is not avail-able under the unsupervised setting, it may lead to a triv-ial solution for the UMNet optimization, e.g., all the labels are uncertain. We attack this issue by modeling the noisy labels using Gibbs distribution under the Bayesian frame-work and developing an uncertainty weighted loss function for end-to-end training UMNet with SODNet. As a con-sequence, our UMNet is able to effectively identify the re-liable pseudo labels while softly filtering out those of low qualities. The selected reliable pseudo labels are employed to provide supervision on SODNet, leading to more supe-rior performance.
The contributions of this work can be summarized into three folds as follows. (1) We develop a novel deep unsupervised SOD paradigm which automatically learns to mine the reliable labels from noisy pseudo ones of multiple sources, leading to more effective unsupervised learning. (2) We present a Merge-and-Split module that helps the uncertainty mining network to effectively capture the per-pixel reliability of the pseudo labels by simultaneously an-alyzing the commonality and difference of multi-source noisy labels. (3) We propose an uncertainty weighted loss function that models the noisy labels as Gibbs distribution in a princi-pled way, allowing the whole networks to be jointly trained in an elegant manner without uncertainty annotations.
Experiments on popular SOD benchmark datasets show that the proposed method can effectively facilitate the SOD network learning with noisy labels and achieves the state-of-the-art performance. 2.