Abstract
We present Lepard, a Learning based approach for partial point cloud matching in rigid and deformable scenes. The key characteristics are the following techniques that exploit 3D positional knowledge for point cloud match-ing: 1) An architecture that disentangles point cloud repre-sentation into feature space and 3D position space. 2) A position encoding method that explicitly reveals 3D rela-tive distance information through the dot product of vec-tors. 3) A repositioning technique that modiﬁes the cross-point-cloud relative positions. Ablation studies demon-strate the effectiveness of the above techniques.
In rigid cases, Lepard combined with RANSAC and ICP demon-strates state-of-the-art registration recall of 93.9% / 71.3% on the 3DMatch / 3DLoMatch. In deformable cases, Lep-ard achieves +27.1% / +34.8% higher non-rigid feature matching recall than the prior art on our newly constructed 4DMatch / 4DLoMatch benchmark. Code and data are available at https://github.com/rabbityl/lepard. 1.

Introduction
Matching partial point clouds from range sensors lies at the core of many 3D computer vision applications includ-ing SLAM and dynamic tracking and reconstruction. The former assumes rigid scenes, e.g. [28, 47], while the latter focuses on scenes that are non-rigidly deforming, e.g. [46].
This work aims at developing a robust point clouds match-ing method for both rigid and deformable scenes.
Point cloud matching methods often consist of two phases: point cloud feature extraction followed by nearest neighbor search in feature space. Recent learning-based works have made substantial progress for representation learning in 3D data. State-of-the-art point clouds match-ing approaches [6, 14, 26] employ the geometry features ex-tracted by 3D convolutional networks, such as the KPConv-based [62] or the Minkowski Engine [13]. These 3D feature extractors are strictly translation invariant, and, to a certain extent, also invariant to rotation transformations given the commonly adopted max-pooling layers in the networks and random rotation-based data augmentation during training.
Transformation invariance is well suited for local geom-etry feature representation. However, it may cause ambi-guity in scenes that have repetitive geometry patterns. For instance, the same kind of chairs scattered in different lo-cations of a ﬂoor, or left and right hands of a human could yield similar geometry features. We argue that such ambi-guity can be resolved by enhancing geometry features with the 3D positional knowledge. Intuitively, humans associate things across observations by referring to not only things’ appearance but also their relative locations.
Motivated by the above observations, we design Lepard, a novel partial point clouds matching method that exploits 3D positional knowledge. We ﬁrst build our baseline us-ing the fully convolutional feature extractor KPFCN [62], the concept of Transformer [64] with self and cross atten-tion, and the idea of differentiable matching [55, 61]. Then, to leverage 3D position information, we introduce the fol-lowing techniques: 1) A framework that fully disentangles the point cloud representations into a features space and a position space. 2) A position encoding method that ex-plicitly reveals 3D relative distance information through the dot product of vectors. 3) A repositioning module that ad-justs the cross-point-cloud relative positions which beneﬁts cross attention and differentiable matching. Ablation stud-ies demonstrate the effectiveness of the above techniques.
In addition, we propose a partial point cloud match-ing benchmark called 4DMatch, and its low overlap ver-sion 4DLoMatch. 4DMatch contains point clouds that are non-rigidly deforming across the time axis. Compared to the rigid situations, the time-varying geometry in 4DMatch poses more challenges for both matching and registration.
We apply Lepard for both rigid and deformable point cloud matching.
In rigid cases, Lepard combined with
RANSAC and ICP demonstrates state-of-the-art registra-tion recall of 93.9% / 71.3% on the 3DMatch / 3DLoMatch.
On the newly proposed 4DMatch and 4DLoMatch bench-marks, Lepard achieves +27.1% and +34.8% higher non-rigid matching recall than the prior art. 2.