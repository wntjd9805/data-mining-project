Abstract
The goal of person search is to localize a target per-son from a gallery set of scene images, which is extremely challenging due to large scale variations, pose/viewpoint changes, and occlusions. In this paper, we propose the Cas-cade Occluded Attention Transformer (COAT) for end-to-end person search. Our three-stage cascade design focuses on detecting people in the first stage, while later stages si-multaneously and progressively refine the representation for person detection and re-identification. At each stage the occluded attention transformer applies tighter intersection over union thresholds, forcing the network to learn coarse-to-fine pose/scale invariant features. Meanwhile, we cal-culate each detection’s occluded attention to differentiate a person’s tokens from other people or the background.
In this way, we simulate the effect of other objects occlud-ing a person of interest at the token-level. Through com-prehensive experiments, we demonstrate the benefits of our method by achieving state-of-the-art performance on two benchmark datasets. 1.

Introduction
Person search aims to localize a particular target person from a gallery set of scene images, which is an extremely difficult fine-grained recognition and retrieval problem. A person search system must both generalize to separate peo-ple from the background, and specialize to discriminate identities from each other.
In real-world applications, person search systems must detect people across a wide variety of image sizes and re-identify people despite large changes in resolution and viewpoint. To this end, modern person search methods, ei-ther two-step or one-step (i.e., end-to-end), consist of reli-able person detection and discriminative feature embedding learning. Two-step methods [5, 10, 13, 18, 30, 38] conduct person re-identification (ReID) on cropped person patches
*Rui Yu’s work on this paper was done when he was a summer intern at Kitware.
Figure 1. Main challenges of person search, e.g., scale variations, pose/viewpoint change, and occlusion. The boxes with the same color represent the same ID. For better viewing, we highlight the small-scale individuals at bottom-right corners. found by a separate object detector. In contrast, end-to-end methods [2, 20, 32–34, 39] jointly solve the detection and
ReID sub-problems in a more efficient, multi-task learning framework. However, as shown in Figure 1, they still suffer from three main challenges:
• There is a conflict in feature learning between person detection and ReID. Person detection aims to learn fea-tures which generalize across people to distinguish peo-ple from the background, while ReID aims to learn fea-tures which do not generalize across people but distin-guish people from each other. Previous works follow a
“ReID first” [33] or “detection first” [20] principle to give priority to one subtask over the other. However, it is diffi-cult to balance the importance of two subtasks in different situations when relying on either strategy.
• Significant scale or pose variations increase identity recognition difficulty; see Figure 1. Feature pyramids or deformable convolutions [14, 18, 33] have been used to solve scale, pose or viewpoint misalignment in feature learning. However, simple feature fusion strategies may introduce additional background noise in feature embed-dings, resulting in inferior ReID performance.
• Occlusions with background objects or other people make appearance representations more ambiguous, as shown in
Figure 1. The majority of previous person search meth-person representations in occluded scenes. 3) Extensive experiments on two datasets show the superiority of our method over existing person search approaches. 2.