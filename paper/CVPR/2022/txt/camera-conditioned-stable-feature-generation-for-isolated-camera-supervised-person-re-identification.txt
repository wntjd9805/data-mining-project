Abstract
To learn camera-view invariant features for person Re-IDentification (Re-ID), the cross-camera image pairs of each person play an important role. However, such cross-view training samples could be unavailable under the ISo-lated Camera Supervised (ISCS) setting, e.g., a surveillance system deployed across distant scenes. To handle this chal-lenging problem, a new pipeline is introduced by synthesiz-ing the cross-camera samples in the feature space for model training. Specifically, the feature encoder and generator are end-to-end optimized under a novel method, Camera-Conditioned Stable Feature Generation (CCSFG). Its joint learning procedure raises concern on the stability of gen-erative model training. Therefore, a new feature genera-tor, σ-Regularized Conditional Variational Autoencoder (σ-Reg. CVAE), is proposed with theoretical and experimental analysis on its robustness. Extensive experiments on two
ISCS person Re-ID datasets demonstrate the superiority of our CCSFG to the competitors. 1
Figure 1.
Illustrations of the training samples under different person Re-ID settings. The light-blue areas indicate the feature space. Different shapes corresponding to identities. Different col-ors mean under different cameras. (a) Cross-camera person images are available under the conventional settings. (b) No cross-camera image pairs under the ISCS setting for model training. 1.

Introduction
Person re-identification (Re-ID) aims to retrieve the same person across different cameras in a surveillance net-work. Extracting the discriminative view-invariant features of person images play a central role for the Re-ID task.
With the cross-camera images of each person available dur-ing training, existing methods have made great progress un-der different settings, e.g., the supervised [2, 38, 42, 50] and the unsupervised [5, 21, 23, 40]. The importance of cross-camera samples for model training is also demonstrated.
However, such cross-camera person images are not guar-anteed during training under some realistic scenarios. For
*indicates corresponding author. 1https://github.com/ftd-Wuchao/CCSFG example, a surveillance system is needed to re-identify a person across distant scenes, e.g., different cities, and each camera is isolated. It is too expensive to collect sufficient cross-camera person images for model training. A more ap-plicable solution is exploiting the large amount of camera-specific images of different persons instead. As the cross-camera image pairs no longer exist during training, many existing methods [17, 38, 50, 57] fail to obtain the ideal per-formance on such data. This challenging person Re-ID set-ting, called ISolated Camera Supervised (ISCS), is first pro-posed by [52] as Single-Camera-Training (SCT). The com-parison between different settings is shown in Fig. 1.
To handle the challenging ISCS settings, existing meth-ods [10, 52] explicitly align the feature distributions across cameras with new losses and network architectures. In this
can be more discriminative and less variant across cameras.
On the other hand, with the more discriminative features from E, the generator G can be more focused on captur-ing the camera information. However, this joint learning procedure forms an obstacle in training the generator G.
The input of G is the output of encoder E that is still un-der training. Therefore, the enlarging dynamic variance of such input causes instability in training G and eventually leads to collapsed learning of the whole model. To handle this issue, a novel generative model, σ-Regularized CVAE (σ-Reg. CVAE), is proposed with a simple yet effective so-lution based on feature normalization and used as the gener-ator G. More importantly, we provide the theoretical analy-sis and demonstrate it with experiments.
The main contributions of this paper are in three-fold. (1) To handle the challenging ISCS person Re-ID prob-lem, a novel pipeline is proposed to explicitly generate the cross-view samples in the feature space for better encoder learning. (2) Following the pipeline above, a novel method,
CCSFG, is instantiated. The encoder E and generator G are jointly optimized for iterative improvements. (3) To achieve stable joint learning in CCSFG, a novel generative model,
σ-Reg. CVAE, is proposed with detailed analysis provided.
The effectiveness of the proposed CCSFG is demonstrated by its state-of-the-art performance on two ISCS person Re-ID benchmark datasets. 2.