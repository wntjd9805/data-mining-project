Abstract
Long-term action quality assessment is a task of eval-uating how well an action is performed, namely, estimat-ing a quality score from a long video.
Intuitively, long-term actions generally involve parts exhibiting different lev-els of skill, and we call the levels of skill as performance grades. For example, technical highlights and faults may appear in the same long-term action. Hence, the final score should be determined by the comprehensive effect of dif-ferent grades exhibited in the video. To explore this latent relationship, we design a novel Likert scoring paradigm in-spired by the Likert scale in psychometrics, in which we quantify the grades explicitly and generate the final qual-ity score by combining the quantitative values and the cor-responding responses estimated from the video, instead of performing direct regression. Moreover, we extract grade-specific features, which will be used to estimate the re-sponses of each grade, through a Transformer decoder ar-chitecture with diverse learnable queries. The whole model is named as Grade-decoupling Likert Transformer (GDLT), and we achieve state-of-the-art results on two long-term ac-tion assessment datasets.1
Figure 1. A brief illustration of our idea. The features of an action video are first disentangled into different grade-aware features, which contain the information related to specific grades. Then they will be regarded as “evidence” to generate responses and “fill” the
“scale”. The final quality score is generated by aggregating the scores of “scale questions” (i.e., different grades) according to the responses from the video. 1.

Introduction
Action quality assessment (AQA) is a task to evaluate how well a specific action is performed and is usually mod-eled as a score regression task. Due to its rich application scenarios in the real world, such as sport events [16, 27, 30– 32, 37, 43–45], surgical training [10–12, 21, 41] and daily skills [8, 9, 18], AQA has attracted growing attention from the computer vision community.
Compared with actions that only take a few seconds
*Corresponding author. 1Project page https : / / isee - ai . cn / ˜angchi / CVPR22 _
GDLT.html (e.g., diving), AQA of long-term actions (e.g., figure skat-ing) is more challenging since they contain richer and more
Intuitively, a long video is very complex information. likely to exhibit different levels of skill (e.g., excellent, good, fair or poor) at different parts [9], and we call the levels of skill as performance grades. For exam-ple, a perfect air twist, a substandard leg lifting, and a fall fault may occur in the same long-term action (figure skating). Therefore, we conceive that the quality score should be determined by the comprehensive effect of dif-ferent grades exhibited in a video. In other words, we sup-pose that there exists an inherent mapping from grades to scores. This observation has hardly been discussed in pre-vious works [21, 27, 43, 45], and these existing works use
MLP to directly regress the score from video representa-tions, ignoring this inherent complexity.
In this work, we aim to explicitly model the influences of different grades on the score. To this end, we propose a novel scoring paradigm, named Likert scoring, which is inspired by the well-known Likert scale [19] in psychomet-rics and sociological investigation. A scale is a psychomet-ric tool for quantitatively evaluating the psychological state of the respondent, which consists of several related ques-tions or statements about different aspects. The respondent is asked to evaluate how well he/she agrees with each state-ment. Then the agreement degrees of each statement will be converted into quantified scores, and all scores are added to get a total score, which indicates the respondent’s mental-ity. In the context of this paper, we treat assessing a complex action as filling a “scale”, whose “statements (questions)” refer to the inherent performance grades. The input video is then required to “answer” the questions that how well it matches each grade, i.e., the response intensities are esti-mated for each grade from the video. These intensities will be combined with the pre-quantified scores to determine the final quality score. The underlying insight here is to evalu-ate a complex objective (i.e., action quality) by explicitly measuring several inherent components, which is consis-tent with the Likert scale. A brief illustration of this idea is shown in Figure 1.
Moreover, to fill the “scale”, we need “evidence” for each question (i.e., the information related to each grade
For this pur-from the video) to generate responses. pose, we disentangle video features into different grade-aware features, which contain the grade-specific informa-tion. This procedure is called grade decoupling.
In-spired by DETR [3], this step is implemented by a Trans-former [39] decoder, which ingests a video feature sequence and a set of learnable vectors serving as the prototypes of various grades, and the grade-specific semantics are ex-tracted from video features by these prototypes via the cross-attention mechanism.
Formally, we name our whole model as Grade-decoupling Likert Transformer (GDLT), which is com-posed of a standard Transformer [39] encoder-decoder ar-chitecture and a Likert Scoring Module (LSM). The former consists of a Temporal Context Encoder (TCE) and a Grade-aware Decoder (GAD). In the TCE, we leverage the self-attention mechanism to better explore the rich context in-formation for each segment, which is critical for long video understanding. Then the GAD and LSM will perform grade decoupling and Likert scoring respectively.
In summary, our main contributions are two-fold:
• A novel assessment paradigm named Likert scoring inspired by psychological research is proposed to ex-plore the comprehensive effect of different grades on the score.
• A Transformer [39] encoder-decoder architecture is in-troduced to perform grade decoupling, which aims to extract grade-specific features used for Likert scoring from the input video. To the best of our knowledge, it is the first work to adopt the Transformer in AQA.
To evaluate our idea, we conduct experiments on two public long-term action assessment datasets: Rhythmic
Gymnastics [45] and Fis-V [43]. Our model achieves state-of-the-art results on both datasets, demonstrating its effec-tiveness. 2.