Abstract
Person image generation aims to perform non-rigid de-formation on source images, which generally requires un-aligned data pairs for training. Recently, self-supervised methods express great prospects in this task by merging the disentangled representations for self-reconstruction. How-ever, such methods fail to exploit the spatial correlation between the disentangled features. In this paper, we pro-pose a Self-supervised Correlation Mining Network (SCM-Net) to rearrange the source images in the feature space, in which two collaborative modules are integrated, Decom-posed Style Encoder (DSE) and Correlation Mining Module (CMM). Specifically, the DSE first creates unaligned pairs at the feature level. Then, the CMM establishes the spa-tial correlation field for feature rearrangement. Eventually, a translation module transforms the rearranged features to realistic results. Meanwhile, for improving the fidelity of cross-scale pose transformation, we propose a graph based
Body Structure Retaining Loss (BSR Loss) to preserve rea-sonable body structures on half body to full body gener-ation. Extensive experiments conducted on DeepFashion dataset demonstrate the superiority of our method com-†Corresponding author. pared with other supervised and unsupervised approaches.
Furthermore, satisfactory results on face generation show the versatility of our method in other deformation tasks. 1.

Introduction
Pose guided person image generation is an unaligned im-age to image translation problem, which aims to change the posture of a person image given target poses as con-dition [18, 20, 21, 31, 36, 41]. Person image generation has shown great potential in many fields, such as film industry and multimedia creation. However, the difficulty of per-forming non-rigid deformation makes this task an active topic in the community of computer vision.
Due to the large spatial misalignment between the source and target images, existing approaches generally need un-aligned data pairs to supervise the training process [18, 21, 31,36,41]. For instance, [31,41] calculate the attention map between paired poses to guide the anomalous pose deforma-tion. [3,7,25] establish the coordinate offset flow to promote the position-level source feature sampling for person feature alignment. With such attention or flow mechanism, the gen-erative methods could be capable to perform spatial trans-formations when the source images and target poses are
provided. However, collecting paired data requires heavy workload and limits the application scenarios of these su-pervised approaches. Therefore, some unsupervised meth-ods are proposed to deal with this limitation [22, 30], which utilize cycle consistent methods or create pseudo labels to promote the training procedure. However, such methods still have limitations in generation quality intuitively.
Recently, self-supervised methods demonstrate power-ful prospects to perform non-rigid spatial transformations with only source images [4, 19, 20]. They could learn dis-entangled representations of different image types, which are merged in the following for self-reconstruction. Early studies [4, 19] employ multi-branch network to disentangle different features and concatenate them to reconstruct the source images. Ma et al. [20] utilize AdaIN [11] for fea-ture merging by transferring statistics from style features to pose features. However, these methods still encounter three challenges. First, the disentangled features are aligned in the feature space, which cannot provide enough super-vision for spatial transformation in self-supervised meth-ods. Second, these merging methods (e.g. concatenation or statistics transfer) are global operations, which are lim-ited to exploiting the spatial correlation information. Third, the model lacks prior knowledge of invisible regions due to the self-supervised training process within the single pose scale, which limits the reasonable completions for invisible regions in the half body to full body transformation.
In this paper, we propose a Self-supervised Correlation
Mining Network (SCM-Net) for person image generation.
The entire architecture of SCM-Net can be summarized as disentanglement, fusion and translation. In the disentangle-ment phase, inspired by the decomposed strategy in [21], we design a Decomposed Style Encoder (DSE) to extract the semantic-aware decoupled style features, which could form “unaligned pairs ” with its counterpart pose features.
Through this design, the source image itself could provide supervision for spatial feature deformation. In the fusion phase, we propose a Correlation Mining Module (CMM) to further exploit the spatial correlation between disentangled feature pairs. The CMM module computes the pairwise correlation between the corresponding positions of feature pairs to establish the dense spatial correlation field. Based on this correlation field, our model could align these disen-tangled features through spatially rearranging the style fea-ture positions. In the translation phase, a translation gen-erator with skip connections is introduced to transform the rearranged style features into realistic person images. The entire model is trained in an end-to-end manner.
For the lack of prior information on the lower body, we design a Body Structure Retaining Loss (BSR Loss) to cap-ture the semantic relationships among different body parts.
Thus, the model could make reasonable completions based on these relationships. Specifically, we employ the graph representation to model the semantic relationships of hu-man body parts. In this body graph, each node represents the perceptual features of each semantic region and each edge measures the similarity between each node pair. We match the graphs between each input person image and the corresponding generated result to establish the graph based constraint, which incorporates the body semantic relation-ships into our model.
During inference, our model could introduce new target poses for human pose transfer, and perform reference based attribute editing through partial replacement of style fea-tures. Figure 1 shows some applications of our model.
The main contributions can be summarized as follows:
• We propose a Self-supervised Correlation Mining Net-work (SCM-Net) to achieve person image deformation without the supervision of unaligned data pairs.
• We design two main collaborative modules, the De-composed Style Encoder (DSE) and the Correlation Mining
Module (CMM), which could perform feature disentangling and merging for person image deformation.
• We propose a Body Structure Retaining Loss (BSR
Loss) to acquire the prior knowledge of invisible regions through incorporating semantic relationships among body parts.
• Our method performs competitive results compared with the state-of-the-art methods and also obtains satisfac-tory results on face generation tasks, which demonstrates the migration capability of our model. 2.