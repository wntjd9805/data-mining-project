Abstract
Learned image compression has achieved great success due to its excellent modeling capacity, but seldom further considers the Rate-Distortion Optimization (RDO) of each input image. To explore this potential in the learned codec, we make the ﬁrst attempt to build a neural data-dependent transform and introduce a continuous online mode decision mechanism to jointly optimize the coding efﬁciency for each individual image. Speciﬁcally, apart from the image content stream, we employ an additional model stream to generate the transform parameters at the decoder side. The pres-ence of a model stream enables our model to learn more abstract neural-syntax, which helps cluster the latent repre-sentations of images more compactly. Beyond the transform stage, we also adopt neural-syntax based post-processing for the scenarios that require higher quality reconstructions regardless of extra decoding overhead. Moreover, the in-volvement of the model stream further makes it possible to optimize both the representation and the decoder in an on-line way, i.e. RDO at the testing time. It is equivalent to a continuous online mode decision, like coding modes in the traditional codecs, to improve the coding efﬁciency based on the individual input image. The experimental results show the effectiveness of the proposed neural-syntax de-sign and the continuous online mode decision mechanism, demonstrating the superiority of our method in coding efﬁ-ciency. Our project is available at: https://dezhao-wang.github.io/Neural-Syntax-Website/. 1.

Introduction
Image compression is one of the most fundamental tech-nologies since human society has entered the digital infor-mation age.
It becomes more and more important when currently the big data applications meet the constantly in-*Corresponding author. This work was supported in part by the Na-tional Key Research and Development Program of China under Grant No. 2018AAA0102702, the National Natural Science Foundation of China un-der Contract No.62172020, and a research achievement of Key Laboratory of Science, Techonology and Standard in Press Industry (Key Laboratory of Intelligent Press Media Technology) and State Key Laboratory of Media
Convergence Production Technology and Systems.
Transform Coefficient (a) (b) (c)
Image Dataset
Image Dataset
One Transform for All
One Transform for One Cluster
- Less flexible to model global distribution  e.g. JPEG, Hyper-prior
- Discrete mode decision
- Hand-crafted designed prior e.g. VVC, Ensemble Learning
One Transform for One Input
- Continuous mode decision
- Learned from data
- Model in the local manifold (cid:198) More compact transform
Figure 1. Three transform paradigms. (a) Single transform adopted in previous end-to-end trained image compression meth-ods. (b) Cluster-speciﬁed transform utilized in conventional image codecs. (c) Proposed data-dependent transform. In our method, the transform is generated based on the input sample. By model-ing the distribution in a local manifold, we derive a more compact transform and make the decoder more powerful and ﬂexible. creased visual experience demand, e.g. high-resolution visual applications like 8K streaming and Virtual Real-ity (VR). Continuous endeavors are made to obtain highly efﬁcient compressed and high-quality images/videos that can be stored, displayed, and analyzed with limited hard-ware resources.
In recent decades, a series of codecs have been devel-oped to optimize the reconstruction quality (i.e. distortion) with bit-rate constraints (rate) jointly, which forms the core problem of lossy compression: rate-distortion optimiza-tion (RDO). It perfectly describes the key aspects of human needs for a large amount of images/videos: maximizing re-construction quality leads to preserving the critical visual information of the image signal; whereas minimizing the bit-rate beneﬁts the efﬁcient transmission and storage.
The mainstream image compression standards and sys-tems, e.g. JPEG [31] and BPG [14] based on HEVC [30], adopt the route of transform/hybrid coding framework for
RDO. The framework consists of cascaded transform, quan-tization and entropy coding. The elaborate designs of these components lead to higher coding efﬁciency. Among these efforts, there are two important directions. One branch of researches focus on designing more powerful transforms, the improved variants [3, 29, 33] of discrete cosine e.g.
transform (DCT) [9, 14], and the theoretically optimal lin-ear Karhunen-Lo`eve Transform (KLT) [34]. Although more decorrelated and energy-compact coefﬁcients are obtained to improve the coding performance, these methods heav-ily rely on the distribution, and therefore are not general and ﬂexible enough. The other branch of works pay atten-tion to fully capturing the properties of the input samples.
These methods introduce syntax elements to project the im-age signals into a speciﬁc subspace, e.g. intra-prediction based on different directions, where more compact repre-sentations can be naturally obtained and related processing can be more data-dependent. However, the syntax and cor-responding subspace are manually predeﬁned, e.g. the di-rectional modes of intra-prediction, which leads to limited performance gains and leaves less space for future improve-ment.
With the rapid development of deep learning, the pros-perity of end-to-end optimized image compression meth-ods is witnessed. the whole neural
In these methods, codecs [5, 6] (including encoders and decoders) are totally learned from a large collection of high-quality images. Via optimizing the rate-distortion (R-D) cost over the large-scale training set, the encoders provide ﬂexible and pow-erful nonlinear neural transforms.
However, existing end-to-end optimized compression methods seldom pay attention to the model’s adaptivity to handle images with diverse contexts or distributions. The training only leads to an average low R-D cost on the training set. For a given input sample, the codec might not be good at capturing the input’s probability proper-ties and fail to provide an optimal transform during the inference stage. Some insights in traditional codecs bring in new inspirations. First, transforms can be totally data-dependent [15, 20, 28] instead of using ﬁxed weights. Sec-ond, syntax might be very useful to simplify the distribution of the encoded coefﬁcients via an implicit subspace parti-tion.
To address the above-mentioned issues and inspired by the useful insights from traditional codecs, we make the
ﬁrst attempt to build a neural data-dependent transform for learned image compression. Our new model aims to gener-ate transform parameters dynamically based on the informa-tion of the input sample. To this end, apart from the image content stream, our model additionally introduces neural-syntax as the model stream to generate transform parame-ters at the decoder side. The neural-syntax describes the rough contexts of images/features and therefore can make the distribution of the encoded coefﬁcients more compact.
We also introduce the neural-syntax into a post-processing network which targets further enhancing the reconstruction quality when computation and time budgets are sufﬁcient.
With the aid of neural-syntax, our model can be online op-timized towards achieving better R-D performance on the given input sample. Similar to traditional codecs that tra-verse and select the best coding mode, we introduce a con-tinuous online mode decision mechanism, optimizing the model stream codes on the input sample, to further improve the coding efﬁciency. The experiments demonstrate the su-periority of our method. More ablation studies and analyses show the effectiveness of each designed module as well as the rationality of our motivations and interpretations.
Our contributions are summarized as follows,
• We make the ﬁrst attempt to build a neural data-dependent transform for learned image compression.
The transform enables the decoder to be more power-ful and ﬂexible, offering superior R-D performance.
• We propose a new joint paradigm to optimize the con-tent and model streams simultaneously, with the aid of neural-syntax in an end-to-end image compression framework.
• The encoded coefﬁcients of neural-syntax are online optimized over input samples with a continuous on-line mode decision to further improve the coding efﬁ-ciency. 2.