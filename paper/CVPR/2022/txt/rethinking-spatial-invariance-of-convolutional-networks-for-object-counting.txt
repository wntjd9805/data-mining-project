Abstract
Previous work generally believes that improving the spa-tial invariance of convolutional networks is the key to ob-ject counting. However, after verifying several mainstream counting networks, we surprisingly found too strict pixel-level spatial invariance would cause overfit noise in the den-sity map generation. In this paper, we try to use locally con-nected Gaussian kernels to replace the original convolution filter to estimate the spatial position in the density map. The purpose of this is to allow the feature extraction process to potentially stimulate the density map generation process to overcome the annotation noise. Inspired by previous work, we propose a low-rank approximation accompanied with translation invariance to favorably implement the approx-imation of massive Gaussian convolution. Our work points a new direction for follow-up research, which should in-vestigate how to properly relax the overly strict pixel-level spatial invariance for object counting. We evaluate our methods on 4 mainstream object counting networks (i.e.,
MCNN, CSRNet, SANet, and ResNet-50). Extensive exper-iments were conducted on 7 popular benchmarks for 3 ap-plications (i.e., crowd, vehicle, and plant counting). Exper-imental results show that our methods significantly outper-form other state-of-the-art methods and achieve promising learning of the spatial position of objects1. 1.

Introduction
Object counting has been widely studied since it can po-tentially solve crowd flow monitoring, traffic management, etc. The previous works [8, 28, 62] believe that the latchkey to improving the object counting is to improve the spa-tial invariance of CNNs. Based on this starting point, more and more networks (such as dilated CNNs [3, 13, 39], de-formable CNNs [17, 34] and multi-column CNNs [11, 13, 71]) are studied for object counting.
Figure 1. The left shows the idea of density map generation, and the right is an example from SHTech-PartA dataset [76], where the red dot is the annotation in groundtruth, and the black dot is the real center position. The density map is generated by smoothing the center points with the multi-dimensional Gaussian distribution.
There are two main types of noise: 1) the error ϵ between the true center points and the annotations and 2) the overlap Σ caused by multiple Gaussian kernels. Note that the left is merely an example.
The center point of crowd counting usually refers to the center of the head. [Best view in color].
However, this research direction has appeared perfor-mance bottlenecks. We noticed that the counting accuracy had not been significantly improved with further continu-ously optimizing the network architectures. Some recent studies [6, 10, 30, 59] also witnessed a lot of noise during density generation and conjecture that this might be the rea-son for the performance bottleneck. Although these efforts have made some progress, we are still ignorant of the fol-lowing questions. 1) Is blindly improving spatial invariance valuable for object counting tasks? 2) How does density noise affect performance?
Before answering these questions, let’s briefly introduce the generation process of the density map. Figure 1 takes crowd counting as an example. The density map is gener-ated by smoothing the center point with multiple Gaussian kernels. This preprocessing converts the discrete count-ing problem into a continuous density regression, but in-evitably brings some noise. In general, there are two types of noise. 1) The error between the actual center point and annotation (i.e., ϵ between the red and black dots). 2) The overlay of Gaussian kernels (i.e., Σ)2. More formal mathe-matical description is in Sec. 3.1 and 3.2.
*Work done during a remote research collaboration with CMU. 1Code is at https://github.com/zhiqic/Rethinking-Counting 2Note that we have some abuse symbols here.
To answer these problems, we have thoroughly verified four mainstream object counting methods (MCNN [77],
CSRNet [28], SANet [4] and ResNet-50 [18]) in three dif-ferent tasks (crowd, vehicles and plants counting). Ex-tensive verification experiments reveal that too strict pixel-level spatial invariance will not only cause the large predic-tion variances, but also overfitting to the noise in the den-sity map as Sec. 4.2. We observed that the existing mod-els 1) cannot be generalized, even impossible within the same crowd counting task and 2) essentially impossible to learn the actual object position and distribution in the den-sity maps. In general, these experiments provide the fol-lowing answers. 1) Solely increasing the spatial invariance is not beneficial to object counting tasks. 2) The pixel-level spatial invariance makes the model easier to overfit the den-sity map noise.
To solve these problems, inspired by the previous works
[15, 19, 26, 57], we try to replace the traditional convolu-tion operation with Gaussian convolution. The motivation behind is to mimic the Gaussian-style density generation throughout the whole feature learning, rather than merely generating the final density map. To a certain extent, this modification is equivalent to a relaxation of the pixel-level spatial invariance. After the pixel-grid filters are revised with Gaussian kernels, we can jump out of the over-strict pixel-level restrictions. Fortunately, the experimental result of Sec. 4.4 proved that this relaxation could allow us to avoid overfitting to the density map noise and promisingly learn the object position and distribution law.
Technically, we propose a novel low-rank approximation to simulate the process of Gaussian-style density map gen-eration during the feature extraction. Although previous work [59] uses a multivariate Gaussian approximation to optimize the density map in the loss function, it is unclear how to explicitly model this approximation during the con-volution process. Note that the approximation in [59] only imposes the constraints on predicted density maps, while leaving the density estimation unchanged. In contrast, our approach employs Gaussian convolution to replace stan-dard convolution, where our low-rank approximation uses finite Gaussian kernels (Eq. 10) to approximate the massive
Gaussian kernel convolution (Eq. 7). It is worth noting that our method concentrates on the density estimation process, while [59] only focuses on the generated density maps.
As shown in Figure 3, we replace the standard convo-lution operation with Gaussian convolution to provide a novel way to generate the density map. We first propose a Low-rank Approximation module to approximate the mas-sive Gaussian convolution. Specifically, we sample a few
Gaussian kernels from the groundtruth density map as in-put, and then employ Principal Component Analysis (PCA) to select some representative Gaussian kernels. Through a simple attention mechanism, the correlation between the se-lected Gaussian kernels is learned, which is operated to ap-proximate the massive Gaussian convolution. Correspond-ingly, we also propose a Translation Invariance Module to accelerate the inference. On the input side, we adopt the translation invariance to decouple the Gaussian kernel op-eration to accelerate the convolution operation. At the out-put side, we utilize the weights obtained from the low-rank approximation module to accomplish approximation. Note that all of our implementations are based on CUDA. It can be seamlessly applied to mainstream CNNs and is end-to-end trainable. To conclude, our contributions are mainly three folds:
• We reveal that the overly restrictive spatial invari-ance in object counting is unnecessary or even harmful when facing the noises in the density maps.
• A low-rank Gaussian convolution is proposed to han-dle the noises in density map generation. Equipped with low-rank approximation and translation invari-ance, we can favorably replace standard convolutions with several Gaussian kernels.
• Extensive experiments on seven datasets for three counting tasks (i.e. crowd, vehicle, plant counting) fully demonstrate the effectiveness of our method. 2.