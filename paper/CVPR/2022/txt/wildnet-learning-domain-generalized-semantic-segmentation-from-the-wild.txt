Abstract
We present a new domain generalized semantic seg-mentation network named WildNet, which learns domain-generalized features by leveraging a variety of contents and styles from the wild. In domain generalization, the low gen-eralization ability for unseen target domains is clearly due to overfitting to the source domain. To address this prob-lem, previous works have focused on generalizing the do-main by removing or diversifying the styles of the source domain. These alleviated overfitting to the source-style but overlooked overfitting to the source-content. In this paper, we propose to diversify both the content and style of the source domain with the help of the wild. Our main idea is for networks to naturally learn domain-generalized seman-tic information from the wild. To this end, we diversify styles by augmenting source features to resemble wild styles and enable networks to adapt to a variety of styles. Further-more, we encourage networks to learn class-discriminant features by providing semantic variations borrowed from the wild to source contents in the feature space. Finally, we regularize networks to capture consistent semantic infor-mation even when both the content and style of the source domain are extended to the wild. Extensive experiments on five different datasets validate the effectiveness of our
WildNet, and we significantly outperform state-of-the-art methods. The source code and model are available online: https://github.com/suhyeonlee/WildNet. 1.

Introduction
Domain generalized semantic segmentation aims to bet-ter predict pixel-level semantic labels on multiple unseen target domains while learning only on the source domain.
Unfortunately, the domain shift between the source and tar-get domains makes a segmentation model trained on the given source data behave stupidly on the unseen target data, as shown in Fig. 1b. In domain generalization (DG), the low generalization performance for unseen domains is ob-viously due to overfitting to the source domain. Since the
*Corresponding author. (a) Unseen domain image (b) Baseline (mIoU 35.16%) (c) RobustNet (mIoU 36.58%) (d) Ours (mIoU 44.62%)
Figure 1. Semantic segmentation results on (a) an unseen domain image. The models are trained on GTAV [46] train set and vali-dated on Cityscapes [10] validation set. (b) Baseline model over-fits the source domain and performs poorly with mIoU 35.16% on the unseen target domain. (c) RobustNet [7], a state-of-the-art method, improved mIoU to 36.58% by whitening the style, but still has low generalization capability. (d) Our WildNet achieves supe-rior generalization performance with mIoU 44.62% by learning various styles and contents from the wild. More qualitative results on other datasets are available in the supplementary material. model cannot see any information about the target domains in the learning process and even unlabeled target images are not provided unlike domain adaptation (DA), it over-learns the statistical distribution of the given source data.
Recently, some studies [7, 29, 41, 42] have proposed learning the domain-generalized content feature by ‘remov-ing’ domain-specific style information from the data to pre-vent overfitting to the source domain. Based on the correla-tion between the feature’s covariance matrix and style [13, 14], they assumed that only content features would remain if elements of features considered the domain-specific style were whitened [23, 30, 50, 53]. However, since the content and style are not orthogonal, whitening the style may cause a loss of semantic content, which is indispensable for se-mantic category prediction. As a result, they predict seman-tic categories from incomplete content features and have difficulty making accurate predictions, as shown in Fig. 1c.
In this paper, we propose a new domain generalized se-mantic segmentation network called WildNet, which learns
the domain-generalized semantic feature by ‘extending’ both content and style to the wild. Although some previous works [22,45,62] utilized various styles from the wild, e.g.,
ImageNet [11] for real styles and Painter by Numbers [38] for unreal styles, they overlooked that the high generaliza-tion ability comes from learning not only various styles but also various contents. In contrast to previous studies, our main idea is to naturally learn domain-generalized se-mantic information by leveraging a variety of contents and styles from the wild, without forcing whitening on domain-specific styles.
To extend both content and style to the wild, we present four effective learning methods. (i) Based on the relevance of style and feature statistics, feature stylization diversifies the style of the source feature by transferring the statistics of the wild feature to the source feature over several layers. (ii) To prevent overfitting to the source contents, we pro-pose content extension learning to increase the intra-class content variability in the latent embedding space. Extending content from source to wild helps networks make general-ized predictions on unseen contents. (iii) To prevent over-fitting to the source style, we propose style extension learn-ing to encourage networks to adapt to the various styles ex-tended to the wild. (iv) Finally, semantic consistency reg-ularization enables networks to capture consistent seman-tic information even when both the content and style of the source domain are extended to the wild. With the proposed learning methods, our WildNet learns domain-generalized semantic features by leveraging a variety of contents and styles from the wild. Extensive experiments over multiple domains show that our network achieves superior perfor-mance on domain generalization for semantic segmentation.
Our main contributions are as follows:
• We present a novel domain generalized semantic segmentation network named WildNet, which learns domain-generalized semantic features by leveraging a variety of contents and styles from the wild.
• We propose four learning techniques to train domain-generalized networks by extending both the content and style of the source domain to the wild. These en-able our model to make reliable predictions on various unseen target domains without training on them.
• Our network achieves superior performance in exten-sive experiments on domain generalization for seman-tic segmentation constructed over multiple domains. 2.