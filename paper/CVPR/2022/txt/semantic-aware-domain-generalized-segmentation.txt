Abstract
Deep models trained on source domain lack generaliza-tion when evaluated on unseen target domains with different data distributions. The problem becomes even more pro-nounced when we have no access to target domain samples
In this paper, we address domain gener-for adaptation. alized semantic segmentation, where a segmentation model is trained to be domain-invariant without using any target domain data. Existing approaches to tackle this problem standardize data into a unified distribution. We argue that while such a standardization promotes global normaliza-tion, the resulting features are not discriminative enough to get clear segmentation boundaries. To enhance sepa-ration between categories while simultaneously promoting domain invariance, we propose a framework including two
∗Corresponding Author: Yinjie Lei (yinjie@scu.edu.cn) novel modules: Semantic-Aware Normalization (SAN) and
Semantic-Aware Whitening (SAW). Specifically, SAN fo-cuses on category-level center alignment between features from different image styles, while SAW enforces distributed alignment for the already center-aligned features. With the help of SAN and SAW, we encourage both intra-category compactness and inter-category separability. We validate our approach through extensive experiments on widely-used datasets (i.e. GTAV, SYNTHIA, Cityscapes, Mapillary and
BDDS). Our approach shows significant improvements over existing state-of-the-art on various backbone networks.
Code is available at https://github.com/leolyj/SAN-SAW 1.

Introduction
Semantic segmentation is a critical machine vision task with multiple downstream applications, such as robotic nav-igation [25, 36, 41, 64], autonomous vehicles [17, 27, 50, 63] and scene parsing [28, 68, 69, 71]. While the current fully supervised deep learning based segmentation methods can achieve promising results when they are trained and evalu-ated on data from same domains [1, 4–6, 21, 37, 40, 67, 70], their performance dramatically degrades when they are evaluated on unseen out-of-domain data. To enable gener-alization of models across domains, different domain adap-tation techniques have been recently proposed [3, 15, 16, 23, 44, 46, 55, 62, 75]. However, a critical limitation of domain adaptation methods is their reliance on the availability of target domain in advance for training purposes. This is im-practical for many real-world applications, where it is hard to acquire data for rarely occurring concepts.
In this paper, we consider the challenging case of
Domain Generalized Semantic Segmentation (DGSS), where we do not have access to any target domain data at the training time [9, 47, 48, 51, 66]. Existing methods tackle
DGSS using two main approaches: (1) Domain Random-ization [51, 66] which aims to increase the variety of train-ing data by augmenting the source images to multiple do-main styles. However, this is limiting since the augmen-tation schemes used are unable to cover different scenar-ios that may occur in the target domain. (2) Normalization and Whitening [9,47,48] which utilizes predefined Instance
Normalization (IN) [61] or Instance Whitening (IW) [32] to standardize the feature distribution of different samples. IN separately standardizes features across each channel of in-dividual images to alleviate the feature mismatch caused by style variations. However, as shown in Fig. 1 (a), IN only achieves center-level alignment and ignores the joint dis-tribution among different channels. IW can remove linear correlation between channels, leading to well-clustered fea-tures of uniform distributions (see Fig. 1 (b)). Recent stud-ies [9, 48] propose to combine IN and IW to achieve joint distributed feature alignment (see Fig. 1 (c)). Nevertheless, such global alignment strategy lacks the consideration of local feature distribution consistency. The features belong-ing to different object categories, which are originally well separated, are mapped together after normalization, leading to confusion among categories especially when generaliz-ing to unseen target domains. Such semantic inconsistency inevitably results in sub-optimal training, causing perfor-mance degradation on unseen target domain and even the training domain (i.e. source domain).
To address the inherent limitations of IN and IW, we pro-pose two modules, Semantic-Aware Normalization (SAN) and Semantic-Aware Whitening (SAW), which collabora-tively align category-level distributions aiming to enhance the discriminative strength of features (see Fig. 1 (d)). Com-pared with traditional IN&IW based methods, our approach brings two appealing benefits: First, it carefully integrates semantic-aware center alignment and distributed alignment, enabling both discriminative and compact matching of fea-tures from different styles. Therefore, our method can sig-nificantly enhance models’ generalization to out-of-domain distributed data. Second, existing methods improve the gen-eralization ability at the cost of source domain performance
[9, 47]. Nevertheless, our approach enhances the semantic consistency while improving category-level discrimination, thus leading to effective generalization with negligible per-formance drop on source domain.
Our extensive empirical evaluations on benchmark datasets show that our approach improves upon previous
DGSS methods, setting new state-of-the-art performances.
Remarkably, our method also performs favorably compared with existing SOTA domain adaptation methods that are trained using target domain data. In summary, followings are the major contributions of our work.
• We propose effective feature alignment strategies to tackle out-of-domain generalization for segmentation, without access to target domain data for training.
• The proposed semantic-aware alignment modules,
SAN and SAW, are plug-and-play and can easily be integrated with different backbone architectures, con-sistently improving their generalization performance.
• Through extensive empirical evaluations, and careful ablation analysis, we show the efficacy of our approach across different domains and backbones, where it sig-nificantly outperforms the current state-of-the-art. Re-markably, we even perform at par with approaches us-ing target domain data for training purposes. 2.