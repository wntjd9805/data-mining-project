Abstract
With diverse presentation attacks emerging continually, generalizable face anti-spoofing (FAS) has drawn growing attention. Most existing methods implement domain gener-alization (DG) on the complete representations. However, different image statistics may have unique properties for the
FAS tasks. In this work, we separate the complete represen-tation into content and style ones. A novel Shuffled Style
Assembly Network (SSAN) is proposed to extract and re-assemble different content and style features for a stylized feature space. Then, to obtain a generalized representa-tion, a contrastive learning strategy is developed to empha-size liveness-related style information while suppress the domain-specific one. Finally, the representations of the cor-rect assemblies are used to distinguish between living and spoofing during the inferring. On the other hand, despite the decent performance, there still exists a gap between academia and industry, due to the difference in data quan-tity and distribution. Thus, a new large-scale benchmark for FAS is built up to further evaluate the performance of algorithms in reality. Both qualitative and quantitative re-sults on existing and proposed benchmarks demonstrate the effectiveness of our methods. The codes will be available at https://github.com/wangzhuo2019/SSAN. 1.

Introduction
As the most successful computer vision technology, face recognition (FR) [11, 51] has been widely employed in dif-ferent application scenarios, such as mobile access control and electronic payments. Despite great success, FR systems may still suffer from presentation attacks (PAs), including print attacks, video replay, and 3D masks. To tackle these issues, a series of face anti-spoofing (FAS) methods have been proposed, from hand-craft descriptors based methods
[9, 38] to deep representation based ones [52, 55, 57, 59, 61].
* denotes the corresponding author.
Figure 1. The illustration of style transfer using the method of [18] when live face as content input and spoof face as style input.
The previous FAS methods have achieved promising per-formance in intra-domain scenarios, but may encounter dra-matic degradation under the cross-domain settings. The major reason behind this lies in the conflict between the limitations of training data and the capability of networks
[17, 32, 58], which makes the models trapped in dataset bias [43] and leads to poor generalization toward new do-mains. To address this problem, domain adaptation (DA) techniques [23, 49] are used to alleviate the discrepancy be-tween source and target domains by using unlabeled target data. However, in most real-world FAS scenarios, it is inef-ficient to collect sufficient unlabeled target data for training.
Thus, domain generalization (DG) methods are proposed to generalize well on the unseen target domain, which can be coarsely classified into three categories: learning a com-mon feature space [21, 41], learning for disentangled repre-sentations [48], and learning to learn [40, 42]. These meth-ods almost implement DG on the complete representations from common modules (i.e., CNN-BN-ReLU), but ignore fully taking advantage of subtle properties of global and lo-cal image statistics in FAS. Specifically, different normal-ization approaches lay stress on different statistics informa-tion in FAS. For example, Batch Normalization (BN) [19] based structures are usually used to summarize global im-age statistics, such as semantic features and physical at-tributes. Instance Normalization (IN) [45] based structures focus on the specific sample for distinctive characteristics, such as liveness-related texture and domain-specific exter-nal factors. Thus, to mine different statistics in FAS, [30] adopts an adaptive approach to adjust the ratio of IN and
BN in feature extraction. Differently, we adopt BN and IN based structures to separate the complete representation into global and local image statistics, denoted as content and style features respectively, then implement specific mea-sures on them for generalizable FAS.
Besides, style transfer [18] can be used to reassemble the pairs of content features as global statistics and style features as local statistics to form stylized features for spe-cific supervision. As shown in Fig. 1, spoofing cues as style input can be applied to live faces to generate the correspond-ing spoof manipulations. Thus, [35, 54] directly utilize this approach for data augmentation before the training in FAS.
However, these two-stage methods are inefficient in large-scale training. Thus, an end-to-end approach is adopted based on style transfer at the feature level in this work.
Combined with the abovementioned viewpoints, we pro-pose a novel framework, called shuffled style assembly net-work (SSAN), based on style transfer at the feature level.
Specifically, a two-stream structure is utilized to extract content and style features, respectively. For content infor-mation, they mainly record some global semantic features and physical attributes, thus a shared feature distribution is easily acquired by using adversarial learning. For style in-formation, they preserve some discriminative information that is beneficial to enhance the distinction between liv-ing and spoofing. Different from the image-to-image style transfer proposed in [18], we stack up successive shuffled style assembly layers to reassemble various content and style features for a stylized feature space. Then, a con-trastive learning strategy is adopted to enhance liveness-related style information and suppress domain-specific one.
Lastly, our end-to-end architecture and training approach are more suitable for large-scale training in reality.
Due to the data distribution difference between academic and industrial scenarios, previous evaluation protocols are limited to reflect the genuine performance of algorithms in reality. Thus, to simulate the data quantity and distribution in reality, we combine twelve datasets to build a large-scale evaluation benchmark and further verify the effectiveness of algorithms. Specifically, the TPR@FPR at specific values as the metrics are utilized to evaluate the performance of different models on each dataset, where all live samples as negative cases and partial spoof samples as positive cases.
The main contributions of this work are four-fold:
• To utilize the global and local statistics separately for their unique properties, we propose a novel architecture called shuffled style assembly network (SSAN) for gener-alizable face anti-spoofing.
• To enhance liveness-relative style information and sup-press domain-specific one, we adopt a contrastive learning approach to control the stylized features close or far from the anchor feature. The corresponding loss function is uti-lized to supervise our network.
• Based on the real-world data distribution, we com-bine twelve public datasets into a large-scale benchmark for face anti-spoofing in reality. The metric of single-side
TPR@FPR is proposed for a comprehensive assessment.
• Our proposed methods achieve the state-of-the-art per-formance on existing and proposed benchmarks. 2.