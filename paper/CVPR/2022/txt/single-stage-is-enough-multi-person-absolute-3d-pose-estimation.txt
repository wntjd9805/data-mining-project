Abstract
The existing multi-person absolute 3D pose estimation methods are mainly based on two-stage paradigm, i.e., top-down or bottom-up, leading to redundant pipelines with high computation cost. We argue that it is more desirable to simplify such two-stage paradigm to a single-stage one to promote both efﬁciency and performance. To this end, we present an efﬁcient single-stage solution, Decoupled Re-gression Model (DRM), with three distinct novelties. First,
DRM introduces a new decoupled representation for 3D pose, which expresses the 2D pose in image plane and depth infor-mation of each 3D human instance via 2D center point (cen-ter of visible keypoints) and root point (denoted as pelvis), respectively. Second, to learn better feature representation for the human depth regression, DRM introduces a 2D Pose-guided Depth Query Module (PDQM) to extract the features in 2D pose regression branch, enabling the depth regression branch to perceive the scale information of instances. Third,
DRM leverages a Decoupled Absolute Pose Loss (DAPL) to facilitate the absolute root depth and root-relative depth estimation, thus improving the accuracy of absolute 3D pose.
Comprehensive experiments on challenging benchmarks in-cluding MuPoTS-3D and Panoptic clearly verify the superior-ity of our framework, which outperforms the state-of-the-art bottom-up absolute 3D pose estimation methods. 1.

Introduction
Estimating 3D human pose from a monocular RGB cam-era is a signiﬁcant task in computer vision and artiﬁcial intelligence, due to its foundation in many higher-level appli-cations, e.g., robotics [41], action recognition [8, 15], anima-tion [36, 37], human-object interaction detection [6, 12, 38], virtual ﬁtting [11], etc. With the recent notable progress in
Person
Detector
Keypoint
Detector
Single-Person
Pose Estimator (a) Top-down Method
Keypoint
Partitioner (b) Bottom-up Method
. . .
. . .
Model 2D Pose Regression Depth Regression (c) Our Single-stage Solution
Figure 1. Comparison between our single-stage solution and exist-ing top-down and bottom-up methods for the multi-person 3D pose estimation. single-person based 3D pose estimation [3, 7, 23, 25, 33], a more realistic and challenging problem setting has attracted increasing attention, i.e., to estimate 3D human pose for multiple persons from a single image.
In general, existing multi-person 3D pose estimation paradigms can be classiﬁed as top-down and bottom-up meth-ods, as illustrated in Fig. 1 (a), (b), respectively. Top-down approaches [1, 13, 20, 30] use a human detector to obtain the bounding box of each person, and then perform the single-person pose estimation, while bottom-up approaches [19,39] estimate the poses of all persons simultaneously, and then combine the keypoints belonging to the same person. The former category estimates pose for each person separately, hence the total computation cost grows linearly with the number of people in the image; the latter category requires grouping the keypoints into corresponding persons, leading to redundant computational complexity.
*Corresponding authors: Xiaojuan Wang and Jian Zhao.
Despite the recent popularity and promising perfor-mance of the single-stage methods for 2D pose estima-tion [22,31,32,40], the single-stage pipeline for multi-person 3D pose estimation is barely explored, as it remains unclear how to effectively combine the end-to-end 2D pose regres-sion with person depth estimation. In this paper, we propose a single-stage pipeline, termed as Decoupled Regression
Model (DRM). DRM introduces a new decoupled formula-tion, which represents the 2D pose and depth information of each 3D human instance via 2D center point (center of visible keypoints) and root point (denoted as pelvis). Specif-ically, we perform 2D keypoint regression from 2D center point and keypoint depth estimation from root point via two parallel branches, thus effectively unifying the 2D pose re-gression with person depth estimation to jointly perform 3D pose regression.
Since measuring depth from a single image is ambiguous, estimating absolute 3D pose naturally suffers from the inac-curate human depth estimation. Considering that the features used for the absolute depth prediction need to adequately perceive the high-level features, e.g., human scale, relative location, etc. From the perspective camera model, the hu-man scale and location can partly describe depth information.
To learn better feature representation for distinguishing in-stances at different depth, DRM introduces a plug-in 2D
Pose-guided Depth Query Module (PDQM) to extract the features in the 2D pose regression branch, which is experi-mentally proved to be beneﬁcial to absolute depth prediction.
Speciﬁcally, we design a warp operation to query features from the positions of predicted 2D poses, and then concate-nate these features to that of the depth to enhance the depth prediction branch. Also, in order to further improve the ac-curacy of estimation for both the root absolute depth and the root-relative depth, we propose a Decoupled Absolute
Pose Loss (DAPL) to supervise the human absolute 3D pose in the camera coordinate system. It is proved that DAPL can further advance the improvements brought by PDQM.
Comprehensive experiments on the challenging 3D pose benchmarks MuPoTS-3D [18] and Panoptic [9] evidently demonstrate the superior efﬁcacy of the proposed DRM.
Our main contributions are summarized as follows.
• We propose the ﬁrst single-stage solution Decoupled
Regression Model (DRM) for multi-person absolute 3D pose estimation, which decomposes the problem-to-solve into 2D pose regression and depth regression via decoupled representation.
• DRM introduces a plug-in 2D Pose-guided Depth
Query Module (PDQM) to inject the features of the 2D pose regression branch to the depth regression branch through a position query operation, which helps our model adaptively perceive the scale information of in-stances.
• DRM also introduces a Decoupled Absolute Pose Loss (DAPL) to focus on the absolute depth prediction, which serves as a supplement to the PDQM.
• DRM achieves comparable performance with the most top-down methods and signiﬁcantly outperforms the state-of-the-art bottom-up method [39] by 4.6 PCKrel and 2.3 PCKabs on the MuPoTS-3D [18] and 4.9
MPJPE on Panoptic [9] benchmarks, respectively. 2.