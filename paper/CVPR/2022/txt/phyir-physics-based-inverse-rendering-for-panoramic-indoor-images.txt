Abstract
Inverse rendering of complex material such as glossy, metal and mirror material is a long-standing ill-posed prob-lem in this area, which has not been well solved. Pre-vious approaches cannot tackle them well due to simpli-fied BRDF and unsuitable illumination representations. In this paper, we present PhyIR, a neural inverse render-ing method with a more completed SVBRDF representa-tion and a physics-based in-network rendering layer, which can handle complex material and incorporate physical con-straints by re-rendering realistic and detailed specular re-flectance. Our framework estimates geometry, material and
Spatially-Coherent (SC) illumination from a single indoor panorama. Due to the lack of panoramic datasets with com-pleted SVBRDF and full-spherical light probes, we intro-duce an artist-designed dataset named FutureHouse with high-quality geometry, SVBRDF and per-pixel Spatially-Varying (SV) lighting. To ensure the coherence of SV light-ing, a novel SC loss is proposed. Extensive experiments on both synthetic and real-world data show that the proposed method outperforms the state-of-the-arts quantitatively and qualitatively, and is able to produce photorealistic results for a number of applications such as dynamic virtual object insertion. 1.

Introduction
Inverse rendering is a fundamental yet challenging task in computer vision and computer graphics. This task aims to recover geometry, material and illumination from a single image. The above properties play a vital role in emerging applications, such as scene editing and virtual object inser-tion in mixed reality. All these applications require phys-ically reasonable realism. However, reconstructing physi-cally accurate properties of a scene is very difficult, because inverse rendering is an ill-posed problem. It contains com-plicated geometry, different types of material and varying local illumination, which will result in complex lighting ef-*Co-corresponding authors. The project page is at https://lzleejean.git-hub.io/PhyIR (b) (c) (d) (e) (a) (f) (g) 1⃝ 2⃝ (h) 3⃝
Figure 1. Given an LDR panorama (a), we estimate geometry (b-c), SV illumination and SVBRDFs, including base color (d), roughness (e) and metalness (f). Our physics-based differentiable renderer can produce detailed specular reflectance (g) on complex material. Based on such physical constraint, our predictions are qualified to produce virtual object insertion (h) with realistic light-ing effects, e.g., highlight caused by unseen light source in 1⃝ and specular reflectance on the cabinet in 2⃝. fects, e.g., specular reflectance on glossy and mirror mate-rial, inter-reflection and cast shadows.
There are three main challenges in solving this task phys-ically. 1) Complex material is difficult to model. Most existing methods assume that all surfaces are Lamber-tian [2, 21, 27, 30, 34–37, 40, 46, 56] and only produce dif-fuse reflectance. Some methods handle specular reflectance in an unphysical way, such as neural residual renderer [39], additional specular shading [48] and phong parameters [17].
Although some approaches use a relatively physical BRDF representation [7, 29, 31, 52], complex material, e.g., glossy, metal and mirror material, still cannot be handled well due to limited BRDF. Moreover, since the re-renderer is built on such a limited BRDF, physical constraints cannot be incor-porated well. 2) Changeable local illumination is difficult to represent. The illumination of indoor scene is spatially-varying (SV) because of occlusion and non-uniform light distribution [16], and is also spatially-coherent (SC) due to coherent variability. Most approaches fail to ensure coher-ence [16, 29, 36, 41, 55, 56], which leads to flickering re-sults for dynamic object insertion. Although the projection-based method [27] and uniform volumetric lighting rep-resentation [43, 46] are used to alleviate this issue, they are not easily incorporated into a physics-based framework due to non-differentiable or memory-hungry. 3) The lack of high-quality datasets containing comprehensive labels.
Collecting ground truth (GT) labels from real-world images is difficult at scale. Moreover, some properties are quite difficult to measure. Meanwhile, recently used synthetic datasets [28, 54] lack necessary properties, e.g., HDR light-ing and essential material; the dataset proposed by Open-Rooms [32] consists of SVBRDFs used in InvIndoor [29] and hemisphere lighting.
Motivated by these concerns, we propose PhyIR, an end-to-end neural inverse rendering framework with a more completed SVBRDF representation and a physics-based in-network rendering layer, as shown in Figure 1. We tackle the aforementioned three challenges from the following per-spectives. 1) We present a more physical inverse rendering model without Lambertian assumption. It can process spec-ular reflectance well for glossy, metal and even mirror ma-terial; it provides physics-based constraints, which can sig-nificantly assist the optimization of components. 2) A novel
SC loss is proposed to ensure the consistence of neighbor-ing SV light probes, which provides an overall constraint on per-pixel lighting of the whole scene to avoid mutation. 3) With great efforts, we generate a large-scale photorealis-tic panorama dataset with high-quality depth, normal, per-pixel illumination and comprehensive SVBRDFs, namely, base color, roughness and metalness. Thanks to physics-based rendering, there is a smaller divergence between our artist-designed dataset and the real-world data (as detailed in Sec. 3.1).
In summary, the main contributions of our method are as follows: 1. A physics-based inverse rendering framework that can handle complex material, including metal and mirror material. 2. A spatially-coherent loss to guarantee spatial consis-tence of neighboring per-pixel illumination. 3. A large-scale photorealistic indoor panorama dataset with high-quality depth, normal, SVBRDFs and per-pixel spatially-varying illumination. 2.