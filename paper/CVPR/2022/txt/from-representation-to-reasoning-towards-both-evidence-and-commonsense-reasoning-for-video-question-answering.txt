Abstract
Video understanding has achieved great success in rep-resentation learning, such as video caption, video object grounding, and video descriptive question-answer. How-ever, current methods still struggle on video reasoning, including evidence reasoning and commonsense reason-ing. To facilitate deeper video understanding towards video reasoning, we present the task of Causal-VidQA, which includes four types of questions ranging from scene de-scription (description) to evidence reasoning (explanation) and commonsense reasoning (prediction and counterfac-tual). For commonsense reasoning, we set up a two-step solution by answering the question and providing a proper reason. Through extensive experiments on existing
VideoQA methods, we find that the state-of-the-art methods are strong in descriptions but weak in reasoning. We hope that Causal-VidQA can guide the research of video under-standing from representation learning to deeper reasoning.
The dataset and related resources are available at https:
//github.com/bcmi/Causal-VidQA.git. 1.

Introduction
Videos, which are organized as a sequence of images along the temporal dimension, usually contain richer tem-poral and causal relations than simple images [2]. With ad-vanced neural network, video understanding has achieved great progress in representation learning, such as video cap-tioning [23], video action recognition [38], video relation grounding [45], video descriptive question-answering [48], and video instance segmentation [50]. Therefore, for a com-putational model, recognizing some independent actions or segmenting some specific instances in a video becomes rel-atively easy [12, 31, 57], however, performing the reasoning from video clips remains a great challenge. On the contrary, it is easy for human beings to answer reasoning questions
*Corresponding author.
Figure 1. Sample video, questions, and answers from our Causal-VidQA dataset. Causal-VidQA is designed to evaluate whether models can understand what is in the video (description), explain the intentions of actions or procedures to certain targets (expla-nation), predict what will happen in the future (prediction), and imagine the scenarios in different conditions (counterfactual). from video clips, such as explaining why something is hap-pening, predicting what is about to happen, and imagining what would happen under different conditions [39].
For example, in the video clip in Figure 1, a man is climbing down along the ropes. Recognizing the hu-man actions like “abseiling” or segmenting and tracking
“[person 1]” is easy for the state-of-the-art vision systems
[8, 51]. Nevertheless, for the evidence reasoning (explana-tory) and commonsense reasoning (prediction and counter-factual) (e.g. Why did [person 1] hold tight on the rope?
Where will [person 2] go? and What would happen if the rope broke?), human beings are capable of correlating the position and tendency of [person 1] and [person 2] to an-swer the aforementioned questions with proper reasons, but current models still struggle on the reasoning tasks [46, 52].
Considering that most of the video tasks mainly focus on representation learning [23,38,45] and reasoning is also less explored, now is the right time to explore video reasoning.
Usually visual reasoning can be divided into two groups, evidence reasoning (i.e. all the clues to the answer are vis-ible in visual content) and commonsense reasoning (i.e. some clues to the answer need to be imagined beyond the visual content). Based on the definition, some works have taken the visual reasoning into consideration. As an im-age dataset for visual reasoning, VCR [55] aims to provide a proper reason while answering a certain question, how-ever, images do not include enough temporal relation and action for commonsense reason. There are also some video datasets for visual reasoning. Social-IQ [54] focuses on comprehending complex human social behaviors with rich causal inference, but the scope is quite limited and the scale is also too small (only 1250 videos with 7500 question-answer pairs). CLEVRER [52] focuses on the causal re-lations grounded in object dynamics and physical interac-tions, but it only targets at the virtual scene and ignores the reasoning in reality. NExT-QA [46] focuses on the causal and temporal action while ensuring that the answers can be inferred from the video clips. However, NExT-QA [46] only focuses on evidence reasoning, where an appropriate expan-sion (i.e. commonsense reasoning) is missing.
To facilitate a deeper understanding towards video rea-soning, we present the task of Causal-VidQA. Given a video clip, our Causal-VidQA task requires the model to answer four types of questions including scene descrip-tion (description), evidence reasoning (explanation), and commonsense reasoning (prediction and counterfactual) to thoroughly understand the video content. Moreover, for the commonsense reasoning questions (i.e. prediction and counterfactual), the model is required to not only provide a right answer but also offer a proper reason justifying why that answer is true, referring to some video details and commonsense knowledge. Our new dataset Causal-VidQA has 26,900 unique video clips and 107,600 question-answer pairs including descriptive, explanatory, predictive, and counterfactual questions, which makes Causal-VidQA the first large-scale dataset in this realm. Different from exist-ing datasets, our dataset focuses on evidence and common-sense reasoning in real-world actions, including large-scale action categories and various types of questions to satisfy the requirement of deeper video understanding. Consider-ing that a reasoning question may correspond to more than one rational answers and reasons, all our tasks are framed as multiple-choice question-answering.
When constructing our dataset, we consider two criti-cal problems. First, the number of action categories should be large enough to prevent learning a short-cut for rea-soning by correlating the action categories with questions and answers. Therefore, we study several different video datasets and finally decide to use the Kinetics-700 [20] as our video dataset, which includes 700 different action categories in real world. Besides, we also split the train-ing/validation/testing set by video action category. Second, the instances in video clip should be described precisely and briefly to ensure that the core of our task is Causal-VidQA instead of video object grounding. To solve this problem, we combine the image instance segmentation and video instance segmentation together to replace the text de-scription with some explicit references to video regions for all frames, like “[person 1]” and “[person 1]” in Figure 1.
Detailed process of dataset construction is in Sec. 3.2.
Based on Causal-VidQA, we evaluate different state-of-the-art VideoQA methods [6, 9, 16–18, 26, 34]. Although some methods achieve satisfied results on the descriptive and explanatory questions, their performances on predic-tive, and counterfactual questions are far from satisfactory.
These experimental results represents that these models do not truly understand the causal relation and fail to reason about commonsense phenomena. Hence, Causal-VidQA offers new challenges for deeper video understanding. Our contributions can be summarized as
• We explore evidence and commonsense reasoning to advance VideoQA beyond representation learning to-wards deeper reasoning;
• We contribute Causal-VidQA, a new challenging
VideoQA benchmark containing four types of ques-tions (i.e. description, explanation, prediction, and counterfactual);
• We extensively evaluate some SOTA video reasoning methods on our Causal-VidQA dataset, providing de-tailed comparison and in-depth analyses. 2.