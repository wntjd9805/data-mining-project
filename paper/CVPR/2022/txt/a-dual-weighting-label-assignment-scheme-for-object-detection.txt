Abstract
Label assignment (LA), which aims to assign each train-ing sample a positive (pos) and a negative (neg) loss weight, plays an important role in object detection. Existing LA methods mostly focus on the design of pos weighting func-tion, while the neg weight is directly derived from the pos weight. Such a mechanism limits the learning capacity of detectors.
In this paper, we explore a new weighting paradigm, termed dual weighting (DW), to specify pos and neg weights separately. We first identify the key influential factors of pos/neg weights by analyzing the evaluation met-rics in object detection, and then design the pos and neg weighting functions based on them. Specifically, the pos weight of a sample is determined by the consistency degree between its classification and localization scores, while the neg weight is decomposed into two terms: the probabil-ity that it is a neg sample and its importance conditioned on being a neg sample. Such a weighting strategy offers greater flexibility to distinguish between important and less important samples, resulting in a more effective object de-tector. Equipped with the proposed DW method, a single
FCOS-ResNet-50 detector can reach 41.5% mAP on COCO under 1× schedule, outperforming other existing LA meth-ods.
It consistently improves the baselines on COCO by a large margin under various backbones without bells and whistles. Code is available at https://github.com/ strongwolf/DW . 1.

Introduction
As a fundamental vision task, object detection has been drawing significant attention from researchers for decades.
The community has recently witnessed a fast evolution of detectors with the development of convolutional neural networks (CNNs) [13–15, 34–37] and visual transformers (ViTs) [4, 6, 8, 10, 27, 39, 40, 42, 50]. Current state-of-the-art detectors [1, 22, 24, 29–31, 38, 46, 48, 49] mostly perform dense detection by predicting class labels and regression offsets with a set of pre-defined anchors. As the basic unit in detector training, anchors need to be assigned with proper
Figure 1. An illustration of the difference between the proposed
DW method and existing label assignment methods, e.g., GFL [21] and VFL [43]. For ambiguous anchors B, C and D, GFL and VFL will assign nearly the same pos and neg weights to {B, D} and {C,
D}, respectively. In contrast, our DW assigns a distinct (pos, neg) pair for each anchor. classification (cls) and regression (reg) labels to supervise the training process. Such a label assignment (LA) process can be regarded as a task of assigning loss weight to each anchor. The cls loss (reg loss can be similarly defined) for an anchor can be generally expressed as:
Lcls = −wpos × ln (s) − wneg × ln (1 − s), (1) where wpos and wneg are the positive (pos) and negative (neg) weights, respectively, and s is the predicted classifi-cation score. Depending on the design of wpos and wneg, the LA methods can be roughly divided into two categories: hard LA and soft LA.
Hard LA assumes that each anchor is either pos or neg, which means that wpos, wneg ∈ {0, 1} and wneg + wpos = 1. The core idea of this strategy is to find a proper divi-sion boundary to split the anchors into a positive set and a negative set. The division rule along this line of research can be further categorized into static and dynamic ones.
Static rules [18, 24, 32, 38] adopt pre-defined metrics such as the IoU or the distance from the anchor center to the ground truth (GT) center to match objects or background 1
to each anchor. Such static assignment rules ignore the fact that the division boundaries of objects with different sizes and shapes may vary. Recently, many dynamic as-signment rules [12, 26] have been proposed. For instance,
ATSS [44] splits the training anchors of an object based on their IoU distributions. Prediction-aware assignment strate-gies [4, 17, 19] regard the predicted confidence score as a reliable indicator for estimating an anchor’s quality. Both static and dynamic assignment methods ignore the fact that samples are not equally important. The evaluation metric in object detection suggests that an optimal prediction should have not only a high classification score but also an accurate localization, which implies that anchors with higher con-sistencies between the cls head and reg head should have greater importance during training.
With the above motivation, researchers have opted to as-sign soft weights to anchors. GFL [21] and VFL [43] are two typical methods which define soft label targets based on
IoUs and then translate them into loss weights by multiply-ing a modulation factor. Some other works [9, 11] compute sample weights by jointly considering the reg score and cls score. Existing methods mainly focus on the design of pos weighting function while the neg weight is simply derived from the pos weight, which may limit the learning capacity of detectors due to little new supervision information pro-vided by neg weights. We argue that such coupled weight-ing mechanism cannot distinguish each training sample at a finer level. Fig. 1 shows an example. Four anchors have different prediction results. However, GFL and VFL assign nearly the same (pos, neg) weight pair to (B, D) and (C, D), respectively. GFL also assigns both zero pos and neg weight to anchor A and C since each one has the same cls score and
IoU. As the neg weighting function is highly correlated with the pos one in existing soft LA methods, anchors with dif-ferent attributes can sometimes be assigned nearly the same (pos, neg) weights, which may impair the effectiveness of the trained detector.
To provide more discriminative supervision signals to the detector, we propose a new LA scheme, termed dual weighting (DW), to specify pos and neg weights from dif-ferent perspectives and make them complementary to each other. Specifically, the pos weights are dynamically deter-mined by the combination of confidence scores (obtained from the cls head) and the reg scores (obtained from the reg head). The neg weight for each anchor is decomposed into two terms: the probability that it is a neg sample and its importance conditioned on being a neg sample. The pos weight reflects the consistency degree between the cls head and reg head, and it will push anchors with higher consis-tencies to move forward in the anchor list, while the neg weight reflects the inconsistency degree and pushes the in-consistent anchors to the rear of the list. By this means, at inference the bounding boxes with higher cls scores and more precise locations will have better chances to survive after NMS, and those bounding boxes with imprecise loca-tions will fall behind and be filtered out. Referring to Fig. 1,
DW distinguishes four different anchors by assigning them distinct (pos, neg) weight pairs, which can provide the de-tector with more fine-grained supervision training signals.
In order to provide our weighing functions with more ac-curate reg scores, we further propose a box refinement op-eration. Specifically, we devise a learned prediction module to generate four boundary locations based on the coarse re-gression map, and then aggregate the prediction results of them to get the updated bounding box for the current an-chor. This light-weight module enables us to provide more accurate reg scores to DW by only introducing moderate computational overhead.
The advantage of our proposed DW method is demon-strated by comprehensive experiments on MS COCO [23].
In particular, it boosts the FCOS [38] detector with ResNet-50 [13] backbone to a 41.5/42.2 AP w/wo box refinement on the COCO validation set under the common 1× training scheme, surpassing other LA methods. 2.