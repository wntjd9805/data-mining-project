Abstract
Recently, significant progress has been made applying machine learning to the problem of table structure inference and extraction from unstructured documents. However, one of the greatest challenges remains the creation of datasets with complete, unambiguous ground truth at scale. To ad-dress this, we develop a new, more comprehensive dataset for table extraction, called PubTables-1M. PubTables-1M contains nearly one million tables from scientific articles, supports multiple input modalities, and contains detailed header and location information for table structures, mak-ing it useful for a wide variety of modeling approaches. It also addresses a significant source of ground truth incon-sistency observed in prior datasets called oversegmentation, using a novel canonicalization procedure. We demonstrate that these improvements lead to a significant increase in training performance and a more reliable estimate of model performance at evaluation for table structure recognition.
Further, we show that transformer-based object detection models trained on PubTables-1M produce excellent results for all three tasks of detection, structure recognition, and functional analysis without the need for any special cus-tomization for these tasks. Data and code will be released at https://github.com/microsoft/table-transformer. 1.

Introduction
A table is a compact, structured representation for storing and communicating data in documents and other manners of presentation. In its presented form, however, a table, such as the one in Fig. 1, may not explicitly represent its logical structure. This is a significant problem as a large amount of data is communicated through documents, and the absence of structure information can impede this data’s use.
Inferring a table’s structure from its presentation and converting it to a structured form is known as table extraction (TE). TE entails three subtasks [5], which we illustrate in
Figure 1. An example presentation table whose underlying logical structure is missing and must be inferred.
Fig. 2: table detection (TD), which locates the table; table structure recognition (TSR), which recognizes a table’s rows, columns, and cells; and functional analysis (FA), which recognizes a table’s keys and values. TE is challenging for automated systems [8, 11, 16, 22] due to the wide variety of formats, styles, and layouts found in presented tables.
Recently, there has been a shift in the research litera-ture from traditional rule-based methods [3, 10, 17] for TE to data-driven methods based on deep learning (DL) [13,16,21].
The primary advantage of DL methods is that they can learn to be more robust to the wide variety of table presentation formats. However, manually annotating tables for TSR is a difficult and time-consuming process [6]. To overcome this, researchers have turned recently to crowd-sourcing to construct larger datasets [8, 21, 22]. These datasets are as-sembled from documents created by thousands of authors, where each table’s structure and content is annotated in a markup format such as HTML, XML, or LaTeX.
While crowd-sourcing solves the problem of dataset size, repurposing annotations unintended for TE and automati-cally converting these to ground truth presents its own chal-lenges with respect to the completeness, consistency, quality, and explicitness of information. For instance, markup does not encode spatial coordinates for cells and encodes logical relationships implicitly through cues such as layout [19].
This lack of explicit information limits not only the range of potential modeling approaches, but also the quality control that can be done to verify the annotations’ correctness.
Figure 2. Illustration of the three subtasks of table extraction addressed by the PubTables-1M dataset.
Another significant challenge for the use of crowd-sourced markup annotations is that their structures often exhibit an issue we refer to as oversegmentation. Over-segmentation occurs when a spanning cell in a header is incorrectly split into multiple grid cells. We illustrate this in Fig. 3. Oversegmentation in markup has no effect on how a presentation table appears when borders between cells are absent, leaving the implicit logical structure and inter-pretation unaffected. However, oversegmentation can lead to significant issues when used as ground truth for model training and evaluation.
The first issue is that an oversegmented annotation contra-dicts the logical interpretation of a table that its presentation is meant to suggest. For instance, oversegmenting a cell may indicate that its text applies to only one row when its presentation form suggests its text is meant to apply to sev-eral rows, as in the cell in column 1, row 3 in Fig. 3. This is problematic for use as ground truth to train a machine learning model to interpret a table’s structure. Even if over-segmented annotations were considered a valid interpretation of a table’s structure, allowing them leads to inconsistent ground truth, due to there then being multiple possible valid interpretations for a table’s structure, as in Fig. 3. This vio-lates the standard modeling assumption that there is exactly one correct ground truth for each table. Thus, datasets that contain oversegmented annotations lead to inconsistent, con-tradictory feedback during training and an underestimate of performance during evaluation.
To address these and other challenges, we develop a new large-scale dataset for table extraction called PubTables-1M.
PubTables-1M contains nearly one million tables from scien-tific articles in the PubMed Central Open Access1 (PMCOA) 1https://www.ncbi.nlm.nih.gov/pmc/tools/openftlist/ database. Among our contributions:
• PubTables-1M is nearly twice as large as the current largest comparable dataset and addresses all three tasks of table detection (TD), table structure recognition (TSR), and functional analysis (FA).
• Compared to prior datasets, PubTables-1M contains richer annotation information, including annotations for projected row headers and bounding boxes for all rows, columns, and cells, including blank cells. It also includes annotations on their original source documents, which supports multiple input modalities and enables a wide range of potential model architectures.
• We introduce a novel canonicalization procedure that corrects oversegmentation and whose goal is to ensure each table has a unique, unambiguous structure inter-pretation.
• To reduce additional sources of error, we implement several quality verification and control steps and pro-vide measurable guarantees about the quality of the ground truth.
• We show that data improvements alone lead to a sig-nificant increase in performance for TSR, due both to improved training and a more reliable estimate of per-formance at evaluation.
• We apply the Detection Transformer (DETR) [1] for the first time to TD, TSR, and FA, and demonstrate how with PubTables-1M all three tasks can be addressed with a transformer-based object detection framework without any special customization for these tasks.
(a) Oversegmented structure annotation (b) Canonical structure annotation
Figure 3. In this example, the structure annotation on the left is oversegmented, creating extra blank cells in the row and column headers.
The canonical structure annotation on the right merges these cells and captures the table’s true logical structure. The blank cells in the top left corner are not part of the table and can be structured using any consistent scheme. 2.