Abstract
Face anti-spoofing (FAS) plays a critical role in securing face recognition systems from different presentation attacks.
Previous works leverage auxiliary pixel-level supervision and domain generalization approaches to address unseen spoof types. However, the local characteristics of image captures, i.e., capturing devices and presenting materials, are ignored in existing works and we argue that such infor-mation is required for networks to discriminate between live and spoof images. In this work, we propose PatchNet which reformulates face anti-spoofing as a fine-grained patch-type recognition problem. To be specific, our framework recog-nizes the combination of capturing devices and presenting materials based on the patches cropped from non-distorted face images. This reformulation can largely improve the data variation and enforce the network to learn discrim-inative feature from local capture patterns.
In addition, to further improve the generalization ability of the spoof feature, we propose the novel Asymmetric Margin-based
Classification Loss and Self-supervised Similarity Loss to regularize the patch embedding space. Our experimen-tal results verify our assumption and show that the model is capable of recognizing unseen spoof types robustly by only looking at local regions. Moreover, the fine-grained and patch-level reformulation of FAS outperforms the ex-isting approaches on intra-dataset, cross-dataset, and do-main generalization benchmarks. Furthermore, our Patch-Net framework can enable practical applications like Few-Shot Reference-based FAS and facilitate future exploration of spoof-related intrinsic cues. 1.

Introduction
Face anti-spoofing (FAS) is a crucial technique to pre-vent face recognition systems from security attacks. With the advance of deep neural network, several learning-based approaches were proposed to discriminate live faces from physical presentation attacks.
Figure 1. The face recognition model learns a face embedding space to discriminate between identities. Our fine-grained patch-type recognition model learns a patch embedding space to dis-criminate between patches with different capture characteristics.
Previous face anti-spoofing methods are highly limited by the scale and variation of the datasets. Commonly used datasets [1, 5, 18, 27, 34] contain less than 100 iden-tities during training, and the spoof images are captured under limited variation. Based on our observation, train-ing on such datasets with a binary classification model is prone to overfit to the biases introduced by the data collec-tion, and the learned features are vulnerable in the unseen testing scenarios. Therefore, previous face anti-spoofing works [14, 15, 18, 21, 29, 30] leverage auxiliary pixel-wise supervision (e.g., the facial depth map and reflection map) as a strong prior knowledge to achieve better generalization ability under testing scenarios with unseen illumination or spoof types. The other FAS works [19,33] propose to adopt
Generative Adversarial Network (GAN) to disentangle the feature maps of live faces and spoof images by reconstruct-ing new live and spoof facial images. Despite the effective-ness of these spoof-detecting techniques, it is still remained as an open question to describe the intrinsic cues learned from networks. Yu et al. [29] rephrase FAS as a structural material recognition problem, which assumes that the dis-crimination of the structural materials between human fa-cial skin and physical spoofing carriers is the essence for
FAS tasks. Following the similar motivation, we believe that the capability of recognizing and comparing different
fine-grained material types is the key to learn robust intrin-sic cues for FAS.
In this paper, we propose PatchNet which learns discrim-inative features based on patches cropped from the entire
Inspired by previous works [2, 6, 28], the face regions. patch-level inputs can enhance the data variation and en-force the network to learn spoof-specific features in the lo-cal region, and thus prevent the network from overfitting to
Instead of resizing the the biases introduced by datasets. input face images into the same size as adopted by recent
FAS works, we directly crop the fixed-size patches from raw facial captures to avoid the distortion of discriminative
FAS cues. With the patch-level inputs, our PatchNet aims at classifying the corresponding fine-grained categories, i.e., the capturing devices and presenting materials, and we de-note each category as a specific “patch-type”. To enforce the network to learn robust spoof-related feature to recog-nize unseen patch types during testing, we adopt the an-gular margin-based softmax loss that is commonly used in face recognition tasks [8,23,25], which aims to optimize the face embedding on the normalized hypersphere (Figure 1).
Moreover, since the patch type classes are not symmetric between live and spoof faces, we propose “asymmetric an-gular margin loss” and impose a larger margin on live type classes.
Inspired by the recent works on self-supervised learning [3,4,10], and the fact that material patterns are pre-sented spatially in the entire face region, we also propose
“self-supervised similarity loss” to regularize the features with location and rotation invariance.
To demonstrate the effectiveness of PatchNet, we con-duct extensive experiments on intra-dataset, cross-dataset, and domain generalization benchmark datasets, and Patch-Net achieves the state-of-the-art performance under most testing scenarios. Moreover, we also conduct the ablation study to further investigate the proposed components.
Our contributions are summarized as follows:
• We reformulate face anti-spoofing as a fine-grained patch recognition problem, and design a simple frame-work called PatchNet to learn an embedding space to encode intrinsic cues from local patches to represent captures’ characteristics.
• We propose novel Asymmetric Margin-based Softmax
Loss and Self-supervised Similarity Loss to supervise the PatchNet training. While the former helps to learn a more generalized patch type embedding space to ad-dress the asymmetry between live and spoof, the latter can enforce the patch feature to be invariant within a single capture.
• The proposed framework could achieve state-of-the-art performance on intra-dataset, cross-dataset, and do-main generalization benchmarks simultaneously with-out auxiliary pixel-wise supervision and domain gen-eralization techniques. Moreover, the learned patch embedding space can enable applications like Few-Shot reference FAS and patch type retrieval, which can boost the FAS performance in certain deployment sce-narios. 2.