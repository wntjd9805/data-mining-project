Abstract
Due to the rising concern of data privacy, it’s reason-able to assume the local client data can’t be transferred to a centralized server, nor their associated identity label is provided. To support continuous learning and fill the last-mile quality gap, we introduce a new problem setup called “local-adaptive face recognition (LaFR)”. Leverag-ing the environment-specific local data after the deployment of the initial global model, LaFR aims at getting optimal performance by training local-adapted models automati-cally and un-supervisely, as opposed to fixing their initial global model. We achieve this by a newly proposed embed-ding cluster model based on Graph Convolution Network (GCN), which is trained via meta-optimization procedure.
Compared with previous works, our meta-clustering model can generalize well in unseen local environments. With the pseudo identity labels from the clustering results, we fur-ther introduce novel regularization techniques to improve the model adaptation performance. Extensive experiments on racial and internal sensor adaptation demonstrate that our proposed solution is more effective for adapting face recognition models in each specific environment. Mean-while, we show that LaFR can further improve the global model by a simple federated aggregation over the updated local models. 1.

Introduction
Face recognition [30] has been commercialized widely for a variety of applications, such as FaceID, surveillance monitoring. The COVID-19 pandemic even accelerates the biometric technologies for touch-less solutions, such as face recognition enabled payment and access control. Although remarkable progress has been achieved lately, one has to admit that face recognition still hasn’t been fully solved.
Among many other remaining challenges (i.e., vulnerabil-ity for adversarial attack [4]), how to scale up the repre-* indicates equal contribution.
Figure 1. Local-Adaptive Face Recognition (LaFR): For each lo-cal environment, a specialized model is produced by the adapter module with only the pre-trained model and images from the en-vironment. Note that there is no real identity label associated with the images, the meta-cluster model generates pseudo labels for ro-bust model adaptation. sentation learning to reduce the risk of fairness and bias to support various local environments becomes a more urgent challenge. As studied in previous works [14, 39, 44], such fairness and bias issues come from both algorithmic de-sign and under-represented data distributions. For example, when the model is predominantly trained on RGB images, it generalizes poorly for images captured by Infrared cam-eras. Likewise, for a model pre-trained on Caucasian only, it performs substantially worse for African and Indian.
While it is worthwhile to push the domain-invariant face recognition [10, 25] with the hope of generalizing to ev-erywhere without adaptation, it is arguably that the chal-lenges for real-world scenarios could be more than we ex-pected. So the question is: given an imperfect pre-trained model, how can we improve and fill the last-mile perfor-mance gap for each local environment and thereafter scale up the process? In this paper, we are interested in study-ing how to properly adapt the pre-trained model to a “spe-cialized” one that tailors for the specific environment in an automatic and unsupervised manner. Here, the “environ-ment” could be defined broadly, including a specific new
camera sensor (i.e. an infrared camera with particular wave-length), a unique identity distribution with racial bias, or a physical environment that has unique camera placement and lighting condition, etc. We call such a problem setup as
“Local-Adaptive Face Recognition (LaFR)”, whose work-flow (see Fig. 1) starts from an imperfect pre-trained global model deployed to a specific environment, where it accu-mulates some amount of new data.
It then applies unsu-pervised adaptation technique to adapt the initial model lo-cally, hence no data is transferred to server. Finally, after the adaptation, the new model is expected to perform much better than the initial global model as it is trained to tailor that environment. As an optional step, Federated Learn-ing [24] is further employed to aggregate many such local models in a secure manner. Therefore, “LaFR” essentially provides a way to scale up the representation learning and model generalization via such “dual-loop” paradigm.
Although unsupervised domain adaptation (UDA) [37] has been widely studied in person re-identification (re-ID) [7, 18–20, 28, 43, 47], it is much less explored in face recognition except [33, 39]. Most of those works either de-signed special for person re-ID [7], or their setups require both source and target dataset to be available during the adaptation stage, or they only aim at closed-set problem.
Moreover, person re-ID works heavily depend on variants of triplet loss, as we show in prior works, there are more ro-bust losses (i.e., CircleLoss [29]) that proved to work better for face recognition.
To overcome the challenges, we first introduce a graph-based meta-clustering algorithm designed to predict pseudo labels for any unlabelled dataset. To do this, we collect a set of labeled datasets from multiple domains and extract their face embeddings from the given pre-trained model, we then apply Graph Convolution Network (GCN) to model the non-convex structure relationship for face embeddings within each set, which is trained efficiently through meta-learning [6] to make the cluster prediction more general-izable for the unseen dataset. Secondly, to better facili-tate the transfer learning, we introduce a new technique by transferring the representation of class (pseudo label) cen-ter from the pre-trained model to the classifier of the new model and keep it fixed while only fine-tuning the feature representation in the context of margin-based training ob-jectives such as [3,29,34]. Moreover, instead of regularizing the feature distance (commonly used in knowledge distilla-tion [8,13,27]), we regularize the network weights to ensure a small deviation between the pre-trained and the new local model.
To summarize, we make the following major contribu-tions: (1) we introduce a novel unsupervised model adap-tation problem setup for face recognition, we argue that it’s practical yet scalable motivated from both continuous learn-ing and data privacy concerns; (2) we use graph convolution network (GCN) to model the dataset structure and predict the clustering labels, through a meta learning framework; (3) Our novel regularized center transfer (RCT) technique can significantly reduce the risk of overfitting and improve transfer learning performance for even smaller datasets; (4)
Experiments show that our entire solution not only outper-form other strong baselines for local adaption but also en-able the federated learning to further improve the global model. 2.