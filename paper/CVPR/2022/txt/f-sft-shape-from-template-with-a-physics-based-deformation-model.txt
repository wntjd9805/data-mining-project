Abstract
Shape-from-Template (SfT) methods estimate 3D sur-face deformations from a single monocular RGB camera while assuming a 3D state known in advance (a template).
This is an important yet challenging problem due to the under-constrained nature of the monocular setting. Exist-ing SfT techniques predominantly use geometric and sim-pliﬁed deformation models, which often limits their recon-struction abilities. In contrast to previous works, this paper proposes a new SfT approach explaining 2D observations through physical simulations accounting for forces and ma-terial properties. Our differentiable physics simulator reg-ularises the surface evolution and optimises the material elastic properties such as bending coefﬁcients, stretching stiffness and density. We use a differentiable renderer to minimise the dense reprojection error between the estimated 3D states and the input images and recover the deformation parameters using an adaptive gradient-based optimisation.
For the evaluation, we record with an RGB-D camera chal-lenging real surfaces exposed to physical forces with var-ious material properties and textures. Our approach sig-niﬁcantly reduces the 3D reconstruction error compared to multiple competing methods. For the source code and data, see https://4dqv.mpi-inf.mpg.de/phi-SfT/. 1.

Introduction
Reconstructing general deformable, temporally-coherent surfaces in 3D from monocular RGB videos is a long-standing, challenging and ill-posed problem. It was studied under different assumptions, and methods addressing it can be roughly classiﬁed into (template-free) non-rigid struc-ture from motion (NRSfM) [8, 14], (template-based) shape-from-template (SfT) [34, 40], and neural 3D mesh regres-sion [27]. The objective of SfT is: Given a known initial 3D state (a template) of an observed deformable scene or an object, reconstruct all its 3D states observed in the entire image sequence [45]. Recent learning-based SfT methods encode prior knowledge in neural network weights [13, 47].
This offers multiple advantages over a vast body of previ-Figure 1. Our φ-SfT approach uses a physics simulator to reconstruct challenging deforming 3D surfaces observed in a monocular RGB video. Compared to existing methods, our esti-mates are signiﬁcantly more accurate and physically plausible. ous, model-based works [34, 36, 38, 40, 45, 46, 61], such as the ability to handle larger deformations, a broader spec-trum of supported types of motions and deformations (in-cluding highly nonlinear ones), and real-time operation.
One of the pivotal limitations of both classical and neural
SfT methods is that they capture general 3D states well but not ﬁne local surface deformations. This is a consequence of the non-awareness of the physical fold formation pro-cess attributable to the elastic properties of the materials and forces acting on them. As a result, existing methods can only reconstruct predominantly global deformations.
This paper proposes φ-SfT (from Greek φυσικη mean-ing physics): A new analysis-by-synthesis SfT method which addresses several limitations of the current state of the art and improves the accuracy of monocular non-rigid 3D reconstruction by a signiﬁcant margin; see Fig. 1 for an overview. Our approach explicitly models the physical fold formation process, and its parameters are physically meaningful. φ-SfT does not require training data. We en-able gradient-based optimisation by employing two compo-nents: A differentiable renderer and a differentiable physics simulator. Our core idea is to use the latter as a regulariser during the optimisation of our objective function. Next, the differentiable renderer ensures that the reprojections of the recovered 3D states accurately match the observed images.
In contrast to earlier photometric terms used for SfT [61],
differentiable rendering allows us for the ﬁrst time to de-ﬁne the reprojection error densely per pixel and not only per vertex. We can thus exploit the information present in the texture regardless of the mesh resolution. φ-SfT is sig-niﬁcantly more accurate than related methods and supports
ﬁner-scale local folds, which is shown on a wide spectrum of deformations in extensive experiments (Sec. 4). In sum-mary, this paper has the following technical contributions:
• A new optimisation-based SfT approach with a physics-based deformation model that ensures high physical ﬁ-delity and realism for the surface evolution, outputting temporally smooth 3D shape sequences that are aware of the forces acting on the object (Sec. 3).
• Differentiable rendering for SfT to encourage the 2D pro-jections of the reconstructed 3D structure to match the ob-served images. The differentiability allows optimising for the deformation parameters by minimising a dense per-pixel photometric energy (Sec. 3.2).
• A new dataset of real deforming surfaces recorded in a way to facilitate the quantitative evaluation of reconstruc-tion methods against reference depth maps (Sec. 4.1). The dataset contains surfaces of various textures and materi-als, exposed to different external forces. We release our dataset and source code to encourage future research. 2.