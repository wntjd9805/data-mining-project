Abstract
Discriminative representation is crucial for the associ-ation step in multi-object tracking. Recent work mainly utilizes features in single or neighboring frames for con-structing metric loss and empowering networks to extract representation of targets. Although this strategy is effec-tive, it fails to fully exploit the information contained in a whole trajectory. To this end, we propose a strategy, namely multi-view trajectory contrastive learning, in which each trajectory is represented as a center vector. By maintain-ing all the vectors in a dynamically updated memory bank, a trajectory-level contrastive loss is devised to explore the inter-frame information in the whole trajectories. Besides, in this strategy, each target is represented as multiple adap-tively selected keypoints rather than a pre-defined anchor or center. This design allows the network to generate richer representation from multiple views of the same target, which can better characterize occluded objects. Additionally, in the inference stage, a similarity-guided feature fusion strat-egy is developed for further boosting the quality of the tra-jectory representation. Extensive experiments have been conducted on MOTChallenge to verify the effectiveness of the proposed techniques. The experimental results indicate that our method has surpassed preceding trackers and es-tablished new state-of-the-art performance. 1.

Introduction
As a fundamental vision perception task, multiple ob-ject tracking (MOT) has been extensively deployed in broad applications, e.g., autonomous driving, video analysis and intelligent robots [6, 41]. Previous MOT methods mainly adopt the tracking-by-detection paradigm [4, 27, 29, 39], which mainly comprises two parts, i.e, detection and as-sociation. For the detection part, a detector is established to localize objects of interest. In the association part, some methods utilize a motion predictor for forecasting the posi-*Equal contribution
â€ Corresponding author
Figure 1. Comparison between existing methods and our pro-posed method. (a) Existing methods only utilize the information in a single or two adjacent frames to learn representation. (b) On the contrary, our method fully exploits the features in the whole trajectories, which contain numerous frames. tions of objects in the next frames and rely on the position information to associate them [16]. However, when these methods are applied to the challenging cases where targets are missing for several frames, it is hard to reconnect these targets to the corresponding trajectories correctly.
To alleviate this problem, existing trackers seek help from appearance-based strategies [39, 47, 51], in which ob-jects are identified based on the similarity of extracted fea-tures. Nevertheless, the effectiveness of the appearance-based association strategy is still limited. Many objects with different identities are associated with the same trajec-tory because they are occluded or blurry, thus causing the learned representation to be indistinguishable. Hence, ex-tracting more meaningful and discriminative representation is desired for enhancing the association accuracy.
In order to improve the quality of the extracted repre-sentation, we revisit existing representation learning meth-ods in MOT and observe that they only use samples in a single or neighboring frames to construct loss for training
tively aggregates features based on the historical feature similarity to alleviate the influence of these poor features on the trajectory representation.
Incorporating all the above proposed techniques, the re-sulting model, namely multi-view tracker (MTrack), has been evaluated on four public benchmarks, i.e., MOT15
[23], MOT16 [26], MOT17 [26] and MOT20 [12]. The ex-perimental results indicate that all our proposed strategies are effective and MTrack outperforms preceding counter-parts significantly. For instance, MTrack achieves IDF1 of 69.2% and MOTA of 63.5% on MOT20. 2.