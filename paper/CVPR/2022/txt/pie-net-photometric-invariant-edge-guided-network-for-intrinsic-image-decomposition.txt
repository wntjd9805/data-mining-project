Abstract
Intrinsic image decomposition is the process of recover-ing the image formation components (reflectance and shad-ing) from an image. Previous methods employ either ex-plicit priors to constrain the problem or implicit constraints as formulated by their losses (deep learning). These meth-ods can be negatively influenced by strong illumination con-ditions causing shading-reflectance leakages.
Therefore, in this paper, an end-to-end edge-driven hy-brid CNN approach is proposed for intrinsic image decom-position. Edges correspond to illumination invariant gra-dients. To handle hard negative illumination transitions, a hierarchical approach is taken including global and local refinement layers. We make use of attention layers to fur-ther strengthen the learning process.
An extensive ablation study and large scale experiments are conducted showing that it is beneficial for edge-driven hybrid IID networks to make use of illumination invari-ant descriptors and that separating global and local cues helps in improving the performance of the network. Fi-nally, it is shown that the proposed method obtains state of the art performance and is able to generalise well to real world images. The project page with pretrained mod-els, finetuned models and network code can be found at https://ivi.fnwi.uva.nl/cv/pienet/. 1.

Introduction
Intrinsic Image Decomposition (IID) is the process of recovering the image formation components such as re-flectance (albedo) and shading (illumination) from an im-age. The reflectance image can be used for albedo texture edits [7, 33, 50], fabric recolouring [48] or semantic seg-mentation [4]. As for shading, the illumination image can be used for relighting [43] or shape-from-shading i.e. esti-mating the shape/geometry of objects or scenes [21, 45].
The problem of IID is inherently ill-defined. There-fore, previous IID approaches employ priors to constrain the problem. Retinex [24] is based on gradient informa-tion derived from images where shading variations corre-spond to small (soft) gradients and reflectance transitions to larger (stronger) ones. Other constraints are explored by [2], like piece-wise constancy, parsimony of reflectance, shading smoothness, etc. Other approaches include global sparsity priors on the palette of colours (albedo’s) and mod-elling the problem as latent variable Random Fields by [18].
However, these explicitly imposed constraints (i.e. assump-tions about the world) may limit the applicability of these methods. Recently, deep learning based methods are pro-posed [34, 42]. These methods are based on implicit con-straints as formulated by losses, and multiple datasets or image sequences [28, 46]. However, these approaches are purely data-driven and therefore they may be limited in their generalisation abilities (dataset bias). Traditional con-straints and deep learning approaches are combined by [16] by means of image edge guidance. However, edge-driven hybrid methods can be influenced by strong illumination conditions. For example, in case of strong shadows, the net-work may classify shadows as being reflectance edges. This happens when the gradient assumption is violated: illumi-nation changes correspond to soft gradients and reflectance transitions to hard ones. This leads to the well-known prob-lem of shading-reflectance leakage i.e. illumination (strong shadow/shading) transitions which are interpreted/classified as albedo transitions also called hard negative illumination transitions, or simply hard (illumination) negatives.
Therefore, in this paper, an edge-driven hybrid CNN ap-proach is proposed using gradients based on illumination invariant descriptors i.e. Cross Color Ratios (CCR) [19].
CCR are illumination (including shadows and shading pat-terns) invariant gradients and hence only dependent on albedo changes. To solve for hard negative illumination transitions, a hierarchical CNN is proposed including global
Figure 1. Overview of the proposed Network. The architecture consists of 4 sub-modules denoted by dotted boxes. Inputs to the network are (a) a RGB image and (b) a CCR image. The CCR image is computed from (a). The outputs of the networks are: (c) the reflectance edge, (d) the shading edge, (e) the unrefined reflectance prediction, (f) the unrefined shading prediction, (g) the final refined reflectance, (h) the final refined shading, and (i) the scaled edge outputs @(64, 128). and local refinement layers. The global layer ensures a smooth image decomposition eliminating (soft) negative il-lumination transitions and therefore minimising shading-reflectance misclassification. The local refinement will eliminate the hard (illumination) negatives. A two-staged approach is beneficial because by adding an incremental parameter space that is conditioned on the previous step, the network is no longer required to model both strong and soft illumination patterns in a single process, but rather a refinement elimination process to remove the hard nega-tives. The proposed method implicitly encodes the image intrinsics within the network without the need of manual thresholding. Since intrinsic components are spatially de-pendent, spatial attention layers are included. This allows the network to focus on image areas containing hard nega-tives. Fig. 1 provides an overview of the proposed network.
In summary, our contributions are as follows:
• An end-to-end edge-driven hybrid approach is pro-posed for intrinsic image decomposition using gradi-ents based on illumination invariant descriptors.
• To solve for hard negative illumination transitions, a hierarchical approach is taken including global and lo-cal refinement layers.
• It is shown that separating the parameter space in a global and local space, rather than a unified parameter space, outperforms single parameter space learning.
• It is shown that the proposed algorithm is able to achieve state of the art performance and is able to gen-eralise well to real world images. 2.