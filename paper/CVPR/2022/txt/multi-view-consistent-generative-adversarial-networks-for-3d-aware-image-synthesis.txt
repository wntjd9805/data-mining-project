Abstract 3D-aware image synthesis aims to generate images of objects from multiple views by learning a 3D representa-tion. However, one key challenge remains: existing ap-proaches lack geometry constraints, hence usually fail to generate multi-view consistent images. To address this challenge, we propose Multi-View Consistent Generative
Adversarial Networks (MVCGAN) for high-quality 3D-aware image synthesis with geometry constraints. By lever-aging the underlying 3D geometry information of generated images, i.e., depth and camera transformation matrix, we explicitly establish stereo correspondence between views to perform multi-view joint optimization. In particular, we en-force the photometric consistency between pairs of views and integrate a stereo mixup mechanism into the training process, encouraging the model to reason about the cor-rect 3D shape. Besides, we design a two-stage training strategy with feature-level multi-view joint optimization to improve the image quality. Extensive experiments on three datasets demonstrate that MVCGAN achieves the state-of-the-art performance for 3D-aware image synthesis. 1.

Introduction
We study the problem of 3D-aware image synthesis, aiming at generating images with explicit control over the camera pose. Generating photorealistic and editable image content is a long-standing problem in computer vision and graphics. In the past years, generative adversarial networks (GAN) [19] have demonstrated impressive results in synthe-sizing high-resolution images of high quality from unstruc-tured image collections [3, 8, 9, 22, 24â€“26, 63, 65]. Despite the tremendous success, most of the methods typically only
Figure 1.
HQ [24] dataset.
Images synthesized by MVCGAN on the CELEBA-learn the manifold of 2D images while ignoring the 3D rep-resentation of the scene.
Several works consider the task of 3D-aware image syn-thesis [1,13,20,29,37,38,66], which can generate images of objects from multiple views by learning a 3D-aware gener-ative model. Different from 2D generative adversarial net-works, 3D-aware image synthesis models learn 3D scene representations from images, such as voxels [37, 38], in-termediate 3D primitives [29], and neural radiance fields (NeRF) [4, 13, 39, 45]. Among these approaches, NeRF-based approaches [4, 13, 39, 45] have gained a surge of in-terest due to the extraordinary performance for high-fidelity view synthesis. However, one key challenge remains in ex-isting approaches [4, 39, 45]: they do not guarantee geome-try constraints between views, hence usually fail to generate multi-view consistent images in some views.
*This work was done during an internship at Alibaba.
In this paper, we address this problem by proposing
Figure 2. Typical failure cases. Taking a representative method GIRAFFE [39] as an example, the generated images in the first row have obvious appearance inconsistent artifacts between views, such as the direction of hair (blue box) and the opening mouth (green box).
Besides, we notice that GIRAFFE [39] suffers from collapsed results under large pose variations (see the leftmost and rightmost pictures in the first row), which indicates that the model does not learn an appropriate 3D shape. In contrast, our method generates high-quality images with multi-view consistency (see the second row).
MVCGAN, a multi-view consistent generative model for high-quality 3D-aware image synthesis with geometry con-straints (see Fig. 1). We first present typical failure cases of existing approach [39] in Fig. 2. Then we identify the cause of the inconsistent phenomenon between views: pre-vious methods optimize a single view of the generated im-age independently while ignoring the geometry constraints between views (see Sec. 3.2.1). To tackle this problem, we take inspiration from the classical multi-view geome-try methods [2, 6, 11, 18, 46, 64] and jointly optimize mul-tiple views with geometry constraints. By leveraging the underlying 3D geometry information, we explicitly estab-lish stereo correspondence between views through projec-tive geometry. To encourage the network to reason about the correct 3D shape, we perform multi-view joint optimization by enforcing the photometric consistency between pairs of views with re-projection loss and integrating a stereo mixup mechanism into the training process. Therefore, the gener-ator not only learns the manifold of 2D images, but also ensures the correctness of the underlying 3D shape.
Besides, we notice that NeRF-based generative ap-proaches [4, 39, 45] typically struggle to render high-resolution images with fine details due to the huge com-putational complexity of NeRF model [35]. Existing meth-ods [4, 39, 45] adopt different strategies to synthesize high-resolution images. However, they all have limitations.
GRAF [45] introduces a multi-scale patch-based discrimi-nator, which causes uneven image quality and local over-fitting to the last batch. pi-GAN [45] increases the res-olution of the generator by sampling rays more densely, which still requires intensive memory consumption. GI-RAFFE [39] combines the 3D representation with a neu-ral rendering pipeline, which suffers from collapsed results under large pose variations. In this paper, we adopt a hy-brid MLP-CNN architecture to disentangle the geometry of 3D shape from the fine details of 2D appearance. In par-ticular, the MLP-based NeRF model [35] renders the ge-ometry of 3D shape, and the CNN-based decoder produces fine details for 2D appearance. The structure can generate photorealistic high-resolution images while alleviating the computation-intensive problem.
Overall, our contributions are summarized as follows: 1. We identify one challenging problem of missing the geometry constraints in 3D-aware image synthesis, which leads to inconsistent images across views. 2. We propose a multi-view consistent generative model (MVCGAN) for high-quality 3D-aware image syn-thesis. By establishing the geometry constraints, we jointly optimize multiple views to guarantee the ge-ometry consistency between views. Besides, we de-sign a two-stage training strategy with the feature-level multi-view joint optimization to further improve the image quality. 3. We demonstrate the effectiveness of the proposed ap-proach through evaluating on various datasets, i.e.,
CELEBA-HQ [24], FFHQ [25], and AFHQv2 [9].
Extensive experiments substantiate that MVCGAN achieves the state-of-the-art performance for 3D-aware image synthesis. 2.