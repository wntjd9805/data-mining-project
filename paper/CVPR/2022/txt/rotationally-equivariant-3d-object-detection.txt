Abstract
Rotation equivariance has recently become a strongly de-sired property in the 3D deep learning community. Yet most existing methods focus on equivariance regarding a global input rotation while ignoring the fact that rotation symme-try has its own spatial support. Speciﬁcally, we consider the object detection problem in 3D scenes, where an object bounding box should be equivariant regarding the object pose, independent of the scene motion. This suggests a new desired property we call object-level rotation equivariance.
To incorporate object-level rotation equivariance into 3D object detectors, we need a mechanism to extract equivariant features with local object-level spatial support while being able to model cross-object context information. To this end, we propose Equivariant Object detection Network (EON) with a rotation equivariance suspension design to achieve object-level equivariance. EON can be applied to modern point cloud object detectors, such as VoteNet and PointR-CNN, enabling them to exploit object rotation symmetry in scene-scale inputs. Our experiments on both indoor scene and autonomous driving datasets show that signiﬁcant im-provements are obtained by plugging our EON design into existing state-of-the-art 3D object detectors. Project website: https://kovenyu.com/EON/. 1.

Introduction 3D object detection is a fundamental problem in vari-ous downstream applications including augmented reality, robotics, and autonomous driving. Research efforts in de-signing 3D object detection networks have shown great effec-tiveness for both indoor [17, 27] and outdoor scenes [21, 29].
However, existing 3D object detectors cannot explicitly treat object rotation equivariance in their designs. Object rotation equivariance in 3D detection is well-reﬂected in the rotation invariance of shape and equivariance of orientation. For example, no matter how an object is oriented in an input scene, the detection result (typically represented as an ori-ented bounding box) associated with the object should orient in the same way while retaining the same shape. Explicit
Figure 1. Rotation symmetry in object detection includes the equiv-ariant orientation and invariant shape of the bounding box. The object-level rotation equivariant detector explicitly models these strong priors and intrinsically generates oriented bounding box to rotate following the object, while maintaining the same box shape.
Non-equivariant detectors, however, may suffer from box shape changes and unaligned variations in box orientation. modeling of these strong priors save the needs for expensive data augmentations, and can increase the expressivity and discriminative power of detection models without heavily increasing the number of parameters and introducing addi-tional optimization challenges.
A recent trend to explicitly exploit rotation equivariance is through equivariant networks [4, 25, 26] (EN). The main idea is that the equivariant geometric features carry both shape information and orientation information separately by design. Rotation equivariant networks have been explored for object classiﬁcation and pose estimation [2,7,13], but not yet for 3D object detection. A main challenge is that existing
EN mostly explores rotation equivariance regarding the full visual input, while equivariance to rotations of a whole scene is not ideal for object detection, because individual object orientation can be independent of the scene. Thus, it is unclear how to achieve object-level rotation equivariance and how to beneﬁt 3D object detection in cluttered scenes.
We identify two key technical challenges toward object-level equivariant model design: how to determine the object-level spatial support to extract locally equivariant features, and how to aggregate context information. The greater con-text (such as nearby objects) is helpful to recognize objects especially in noisy or incomplete raw point clouds. How-ever, the context information could easily break object-level rotation equivariance if not handled properly. For example, when detecting a chair, the presence of a nearby desk can provide useful context due to high co-occurrence probabil-ity. However, in case that the chair remains static while the desk changes its orientation, the chair features could also be affected unexpectedly.
We propose Equivariant Object detection Network (EON) to exploit object-level equivariance for 3D detection. Our core design is called rotation equivariance suspension.
To properly determine the object-level spatial support, we let our model extract equivariant features only up to an in-termediate stage. This is based upon the observation that most 3D detection networks extract features in a hierarchical manner [14, 17, 21] where early stages focus on local fea-tures while later stages cover more context-level information.
Computing equivariant features only up to an intermediate stage produces local spatial support to rotation equivariance, and the model can adaptively learn to adjust its effective spatial support [15]. To allow aggregating context infor-mation, we suspend equivariant feature computation at the previous intermediate stage by decomposing each equivari-ant feature into an object orientation hypothesis (orientation information) and an invariant object-frame feature (shape information). Our model keeps aggregating object-frame fea-tures in the latter stages, and ﬁnally resumes the orientation information for object proposals. Since only object-frame features (i.e., without object orientation information) are ag-gregated after the intermediate stage, the greater contexts can be modeled without breaking object-level equivariance.
Our approach follows the modular design adopted by most bottom-up detectors, so that it can be easily plugged into state-of-the-art 3D object detectors. We have tested our method using various backbones and models on both indoor and outdoor 3D object detection benchmarks. We
ﬁnd that EON signiﬁcantly boosts the performance of pre-vious state-of-the-art 3D object detectors (+9.0 mAP on
ScanNetV2, +3.1 mAP on SUN RGB-D, and +1.4 mAP on
KITTI Dataset). In summary, our contributions are threefold:
• To our best knowledge, this is the ﬁrst work to explore rotation equivariance for 3D object detection.
• We propose Equivariant Object detection Network (EON), incorporating a novel design dubbed rotation equivariance suspension to exploit object-level equivari-ance in 3D detection. Our EON can be easily plugged into state-of-the-art bottom-up 3D object detectors.
• On both indoor and outdoor datasets, we demonstrate the beneﬁts of object-level equivariance by boosting performances of previous state-of-the-art 3D detectors. 2.