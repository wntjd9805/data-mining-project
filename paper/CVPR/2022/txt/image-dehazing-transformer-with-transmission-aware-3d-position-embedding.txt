Abstract
Despite single image dehazing has been made promis-ing progress with Convolutional Neural Networks (CNNs), the inherent equivariance and locality of convolution still bottleneck dehazing performance. Though Transformer has occupied various computer vision tasks, directly leveraging
Transformer for image dehazing is challenging: 1) it tends to result in ambiguous and coarse details that are undesired for image reconstruction; 2) previous position embedding of Transformer is provided in logic or spatial position order that neglects the variational haze densities, which results in the sub-optimal dehazing performance.
The key insight of this study is to investigate how to combine CNN and Transformer for image dehazing. To solve the feature inconsistency issue between Transformer and CNN, we propose to modulate CNN features via learn-ing modulation matrices (i.e., coefficient matrix and bias matrix) conditioned on Transformer features instead of sim-ple feature addition or concatenation. The feature modula-tion naturally inherits the global context modeling capabil-ity of Transformer and the local representation capability of CNN. We bring a haze density-related prior into Trans-former via a novel transmission-aware 3D position embed-ding module, which not only provides the relative position but also suggests the haze density of different spatial re-gions. Extensive experiments demonstrate that our method,
DeHamer, attains state-of-the-art performance on several image dehazing benchmarks. 1.

Introduction
Single image dehazing aims to restore the haze-free im-age from the hazy counterpart that suffers from the reduced contrast and dull colors caused by spatial variant haze den-sities. This task has been a longstanding and challeng-ing problem with a wide range of applications, such as
*Chongyi Li (lichongyi25@gmail.com) is the corresponding author.
Figure 1. Thumbnail of main idea. Transformer is introduced into image dehazing via 1) transmission-aware 3D position em-bedding and 2) feature modulation. The proposed method com-bines the global modeling capability of Transformer and the local representation capability of CNN. surveillance systems and autonomous driving. To solve this ill-posed problem, prior-based methods like Dark Channel
Prior (DCP) [14] and Color Attenuation Prior (CAP) [37] adopt priors as external information to estimate the param-eters of the hazy image formation model. The robustness of these methods is limited, especially facing challenging scenes. With the learning capability of CNNs, CNN-based dehazing networks have achieved impressive performance by either estimating the imaging model’s parameters [25] or directly learning the haze-free counterpart [20]. However, these networks are still bottlenecked by the local nature of the convolution for modeling the long-range dependencies and the translation equivariance [12]. Global context and spatially variant operations are particularly important for haze removal [8].
Although Transformer has swept across many computer vision tasks [6, 21, 31], directly using it in image dehazing exits some inherent issues: 1) despite Transformer is able to provide long-distance feature dependencies via the cas-caded self-attention, even in the early stage, it lacks the ca-pability of retaining local feature details, thus leading to am-biguous and coarse details for image reconstruction; 2) pre-vious position embedding methods neglect the differences among the regions with variational haze densities, which affects image dehazing performance.
To overcome these barriers, we propose several novel de-signs to bring the power of Transformer to image dehazing.
The main idea is illustrated in Figure 1. Specifically, we attempt to combine the best world of the global modeling capability of Transformer and the local representation ca-pability of CNN for image dehazing. To achieve that, given a hazy image, we separately extract the hierarchical global features via a Transformer module while the corresponding hierarchical local features are obtained by a CNN module.
We propose a transmission (suggesting the haze density by prior information)-aware 3D position embedding module, which provides the relative position information and haze density information for the Transformer, thus improving
Instead of simply concate-image dehazing performance. nating or adding Transformer features and CNN features, we propose to integrate these features by a feature modu-lation module that learns the modulation matrices, which solves the feature inconsistency issue. With the modulated features, a CNN decoder module is utilized to enlarge image resolution and render local details of the haze-free image.
The inspired designs in this study can provide guid-ance for Transformer-based image reconstruction, espe-cially about how to 1) inherit the advantages of both Trans-former features and CNN features via feature modulation and 2) introduce prior information into Transformer via po-sition embedding. Experiments and comparisons demon-strate the superiority of our method (called DeHamer) over state-of-the-art image dehazing methods.
In a nutshell, our contributions are as follows:
• In comparison to pure CNN-based image dehazing networks, our work is the first to introduce the power of Transformer into image dehazing via novel designs.
• We propose a novel transmission-aware 3D position embedding to involve haze density-related prior infor-mation into Transformer.
• Extensive experiments on image dehazing benchmark datasets demonstrate the outstanding performance of our method against state-of-the-art methods. 2.