Abstract
Source-free object detection (SFOD) needs to adapt a detector pre-trained on a labeled source domain to a tar-get domain, with only unlabeled training data from the tar-get domain. Existing SFOD methods typically adopt the pseudo labeling paradigm with model adaption alternating between predicting pseudo labels and fine-tuning the model.
This approach suffers from both unsatisfactory accuracy of pseudo labels due to the presence of domain shift and lim-ited use of target domain training data. In this work, we present a novel Learning to Overlook Domain Style (LODS) method with such limitations solved in a principled man-ner. Our idea is to reduce the domain shift effect by en-forcing the model to overlook the target domain style, such that model adaptation is simplified and becomes easier to carry on. To that end, we enhance the style of each tar-get domain image and leverage the style degree difference between the original image and the enhanced image as a self-supervised signal for model adaptation. By treating the enhanced image as an auxiliary view, we exploit a student-teacher architecture for learning to overlook the style de-gree difference against the original image, also character-ized with a novel style enhancement algorithm and graph alignment constraint. Extensive experiments demonstrate that our LODS yields new state-of-the-art performance on four benchmarks. 1.

Introduction
The resurgence of deep convolutional neural networks has greatly promoted the development of object detection, for example, the one-stage YOLO [1] and two-stage Faster
R-CNN [27] have made a big splash. However, when ap-plied to a new scenario, a pre-trained detector often suffers a performance drop, due to the domain shift [5]. Moreover, considering to data privacy, distributed data storage, and in-convenient data transmission, Source-Free Object Detection (SFOD) [23] which assumes only the pre-trained model on the source domain is available and source data itself is un-Figure 1. The comparison of pseudo label strategy (above) and our proposed strategy (below). available, emerged recently as a promising topic.
At present, there do not exist much researches on SFOD problem. The community pays more attention to Source-Free Domain Adaptation (SFDA). The methods for SFDA can be roughly divided into two categories. The first cate-gory is based on the idea of sample generation [11, 19, 21, 30]. Since the source data is not accessible, traditional do-main adaptation techniques are not applicable. The labeled images with source domain style or target domain style, or the labeled features obeying the source distribution, are gen-erated. The key to success is the satisfied samples gener-ation which itself is sufficiently challenging and not well solved. Another category utilizes the self-training based pseudo labeling [18, 24, 25]. But obtaining reliable labels is not easy especially in the situation with large domain gap and always only high-confidence labeled samples are taken in the self-training process.
The domain adaptation methods for SFDA can not be applied to SFOD directly, owing to the complexity of back-ground, diversity of objects and numerous negative samples (background). Recently, several SFOD methods [13,23,36] based on pseudo-labeling or sample generation strategies
are proposed. They use better predicted pseudo labels or do-main noise perturbed images as the self-supervised signals.
The state-of-the-art performance has been achieved. Simi-lar as the SFDA methods, the unreliable pseudo labels and bad quality of generated samples limit their performance.
It is obvious that target domain style (e.g. imaging char-acteristics) contributes to a significant part of the domain shift against the source domain. Hence, minimizing the im-pact of target domain style on the model behaviour would be immediately effective in reducing the domain shift. On the basis of the above, as shown in Fig. 1, we propose a new domain adaption method, dubbed as Learning to Overlook
Domain Style (LODS). It first enhances the target domain style for each target image while maintaining the original style of target images. In this way, an auxiliary view based on the style enhanced images is constructed. With this aux-iliary view, our method lets object detector learn to overlook target domain style. The student-teacher framework is em-ployed to do this task.
Specifically, our method consists of style enhancement module and overlooking style module. For the style en-hancement module, to increase the degree of target domain style, it merges the target domain style in a non-linear way.
The overlooking style module is based on the Mean-Teacher architecture. The target sample is input to teacher model; while the corresponding style enhanced version is input to student model. Both models are initialized by the pre-trained source model. To help both of the teacher and stu-dent models have the ability of overlooking target domain style, we devise graph alignment constrains at instance and image levels. By requiring the consistency of the object in-stance and image patch feature relationships between the image and its corresponding style enhanced version, the ex-tracted feature will overlook the target domain style.
Our contributions are summarized as follows. (1) We propose a novel learning to overlook domain style strat-egy. Different from traditional pseudo label strategy, it not only makes a full use of all target data but also reduces the domain sensitivity of the object detector. Compared with the sample generation strategy, style enhancement is eas-ier. (2) A style enhancement method is proposed. Differ-ent from the existing style transfer methods, it retains the original target domain style, and further adds more target domain style to the target domain image. (3) We propose a new Mean-Teacher framework variant which achieves a two-way knowledge distillation. It overlooks domain style by two graph alignments without any help of source data. can access source data (the difference from SFOD). Meth-ods are roughly classified into four strategies. The first one is based on distribution alignment strategy, such as DA-Faster [5], SWDA [28], HTCN [4], SSA-DA [43], ICR-CCR [37], VDD [34], SGA-S [41], CST-DA [42]and DBGL
[3] etc. It aligns different types of features at different levels via domain classifiers or prototypes. The second one uses pseudo label strategy such as NL [16] and CDG [22], which exploits pseudo labels for target samples. The third one is sample generation strategy, such as DM [17], AFAN [32],
UMT [7], etc. They tend to transfer the style of source and target images by CycleGAN [44]. The final one is using auxiliary model strategy, which learns an auxiliary detector, multi-class classifier, or multi-label classifier to assist trans-ferring detector, such as NL [16], ICR-CCR [37], MTOR
[2], UMT [7]. The Mean-Teacher framework is a typical representative. Despite the great performance achieved, all of these methods need to access source domain data. 2.2. Source-free domain adaptation
Due to the lack of source data, Source-Free Domain
Adaptation (SFDA) only relying on the pre-trained source model is more difficult than traditional unsupervised do-main adaptation. There are two main routes to address this problem. One line is based on sample generation strat-egy. For example, 3C-GAN [21] and SDDA [19] gener-ate labeled samples with target domain style for training;
VDM-DA [30] generates source domain style features then aligns the generated features with target features; SFIT [11] utilizes the batch-norm layers of the source model to gen-erate images with source domain style and aligns the out-put predictions. Another line uses pseudo label strategy.
SHOT [24] and SHOT++ [25] use the centroid of each class to generate pseudo labels, and information maximization to ensure the balance between classes; DASD [18] constructs an adaptive prototype memory to exploit pseudo labels.
There are not many methods for Source-Free Object De-tection (SFOD). SED [23] searches a confident threshold for pseudo labels generation according to self-entropy descent policy. Except for pseudo labels, HCL [13] also proposes historical contrastive instance discrimination to pull the cur-rent representation to its positive key. Both achieve good performance, but unreliable pseudo labels and only (confi-dent) instance-level samples are used. SOAP [36] proposes to perturb the target images with domain noise and uses the adversarial learning technique to transfer the detector.
It does not work in the case of existing large domain gap. 2.