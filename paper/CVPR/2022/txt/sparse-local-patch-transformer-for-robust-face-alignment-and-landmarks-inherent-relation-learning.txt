Abstract
Heatmap regression methods have dominated face align-ment area in recent years while they ignore the inherent re-lation between different landmarks. In this paper, we pro-pose a Sparse Local Patch Transformer (SLPT) for learn-ing the inherent relation. The SLPT generates the repre-sentation of each single landmark from a local patch and aggregates them by an adaptive inherent relation based on the attention mechanism. The subpixel coordinate of each landmark is predicted independently based on the aggre-gated feature. Moreover, a coarse-to-fine framework is fur-ther introduced to incorporate with the SLPT, which enables the initial landmarks to gradually converge to the target facial landmarks using fine-grained features from dynam-ically resized local patches. Extensive experiments carried out on three popular benchmarks, including WFLW, 300W and COFW, demonstrate that the proposed method works at the state-of-the-art level with much less computational complexity by learning the inherent relation between facial landmarks. The code is available at the project website1. 1.

Introduction
Face alignment is aimed at locating a group of pre-defined facial landmarks from images. Robust face align-ment based on deep learning technology has attracted in-creasing attention in recent years and it is the fundamen-tal algorithm in many face-related applications such as face reenactment [40], face swapping [21] and driver fatigue de-tection [1]. Despite recent progress, it still remains a chal-lenging problem, especially for images with heavy occlu-sion, profile view and illumination variation.
The inherent relation between facial landmarks play an important role in face alignment since human face has a regular structure. Although heatmap regression methods
*Corresponding Author 1https://github.com/Jiahao-UTS/SLPT-master
Figure 1. The proposed coarse-to-fine framework leverages the sparse local patches for robust face alignment. The sparse lo-cal patches are cropped according to the landmarks in the previ-ous stage and fed into the same SLPT to predict the facial land-marks. Moreover, the patch size narrows down with the increasing of stages to enable the local features to evolve into a pyramidal form. achieve impressive performance [7, 18, 33–35] in recent years, they still ignore the inherent relation because convo-lutional neural network (CNN) kernels focus locally, thus failed to capture the relations of landmarks farther away in a global manner. In particular, they consider the pixel co-ordinate with highest intensity of the output heatmap as the optimal landmark, which inevitably introduces a quantiza-tion error, especially for common downsampled heatmap.
Coordinate regression methods [9,10,12,24,36,37,42] have an innate potential to learn the relation since it regresses the coordinates from global feature directly via fully-connected layers (FC). Nevertheless, a coherent relation should be learned together with local appearance while coordinate re-gression methods lose the local feature by projecting the
global feature into FC layers.
To address the aforementioned problems, we propose a
Sparse Local Patch Transformer (SLPT). Instead of predict-ing the coordinates from the full feature map like DETR
[5], the SLPT firstly generates the representation for each landmark from a local patch. Then, a series of learnable queries, which are called landmark queries, are used to ag-gregate the representations. Based on the cross-attention mechanism of transformer, the SPLT learns an adaptive ad-jacency matrix in each layer. Finally, the subpixel coordi-nate of each landmark in their corresponding patch is pre-dicted independently by a MLP. Due to the use of sparse local patches, the number of the input token decreases sig-nificantly compared to other vision transformer [5, 11].
To further improve the performance, a coarse-to-fine framework is introduced to incorporate with the SLPT, as shown in Fig.1. Similar to cascaded shape regression method [13, 17, 44], the proposed framework optimizes a group of initial landmarks to the target landmarks by sev-eral stages. The local patches in each stage are cropped based on the initial landmarks or the landmarks predicted in the former stage, and the patch size for a specific stage is 1/2 of its former stage. As a result, the local patches evolve in a pyramidal form and get closer to the target landmarks for the fine-grained local feature.
To verify the effectiveness of the SLPT and the pro-posed framework, we carry out experiments on three popu-lar benchmarks, WFLW [36], 300W [28] and COFW [4].
The results show the proposed method significantly out-performs other state-of-the-art methods in terms of diverse metrics with much lower computational complexity. More-over, we also visualize the attention map of SLPT and the inner product matrix of landmark queries to demonstrate the
SLPT can learn the inherent relation of facial landmarks.
The main contributions of this work can be summarized as:
• We introduce a novel transformer, Sparse Local Patch
Transformer, to explore the inherent relation between facial landmarks based on the attention mechanism.
The adaptive inherent relation learned by SLPT en-ables the model to achieve SOTA performance with much less computational complexity.
• We introduce a coarse-to-fine framework to incorpo-rate with the SLPT, which enables the local patch to evolve in a pyramidal form and get closer to the target landmark for the fine-grained feature.
• Extensive experiments are conducted on three popu-lar benchmarks, WFLW, 300W and COFW. The result illustrates the proposed method learns the inherent re-lation of facial landmarks by the attention mechanism and works at the SOTA level. 2.