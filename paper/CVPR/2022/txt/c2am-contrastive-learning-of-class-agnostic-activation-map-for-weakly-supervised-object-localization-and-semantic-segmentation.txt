Abstract
While class activation map (CAM) generated by image classiﬁcation network has been widely used for weakly su-pervised object localization (WSOL) and semantic segmen-tation (WSSS), such classiﬁers usually focus on discrimina-tive object regions. In this paper, we propose Contrastive learning for Class-agnostic Activation Map (C2AM) gen-eration only using unlabeled image data, without the in-volvement of image-level supervision. The core idea comes from the observation that i) semantic information of fore-ground objects usually differs from their backgrounds; ii) foreground objects with similar appearance or background with similar color/texture have similar representations in the feature space. We form the positive and negative pairs based on the above relations and force the network to dis-entangle foreground and background with a class-agnostic activation map using a novel contrastive loss. As the net-work is guided to discriminate cross-image foreground-background, the class-agnostic activation maps learned by our approach generate more complete object regions.
We successfully extracted from C2AM class-agnostic object bounding boxes for object localization and background cues to reﬁne CAM generated by classiﬁcation network for se-mantic segmentation. Extensive experiments on CUB-200-2011, ImageNet-1K, and PASCAL VOC2012 datasets show that both WSOL and WSSS can beneﬁt from the proposed
C2AM. Code will be available at https://github.com/CVI-SZU/CCAM. 1.

Introduction
Massive image data and manual annotations are usu-ally required to train deep neural networks for many vi-∗Corresponding Author
Figure 1. Feature manifold of foreground objects (blue) and back-grounds (green). As semantic information of foreground objects differs from that of backgrounds, the distribution of the represen-tation of foreground objects (blue) is far away from backgrounds (green). Foreground objects with similar appearance or back-grounds with similar color/texture also have similar representa-tions in the feature space. Based on these observations, posi-tive and negative pairs can be formed for contrastive learning. t-SNE [34] is used to reduce the dimensionality of features. sion tasks, e.g., object detection and semantic segmentation.
However, it is time-consuming and labor-intensive to obtain
In recent years, bounding box or pixel-level annotations. weaker supervision, e.g., image-level label, has been in-troduced in weakly supervised object localization (WSOL) and semantic segmentation (WSSS), which aims to achieve localization or segmentation with only image-level supervi-sion, i.e., without bounding box or pixel-level annotations.
Most previous WSOL and WSSS methods rely on class ac-tivation map (CAM) to estimate location of the target ob-ject. With image-level supervision, the classiﬁer tries to
ﬁnd discriminative regions of target objects. Thus, though image-level labels enable CAM to indicate the correct lo-cation of target objects, they also limit the focus of CAM
foregrounds with similar appearance or backgrounds with similar color/texture have similar representations in the fea-ture space, pairs of foreground-foreground or background-background sharing less similar semantics might affect the learning of network. To mitigate this problem, we design a feature similarity based rank weighting to automatically reduce the inﬂuence of those dissimilar positive pairs. As the activation head is randomly initialized, the initial class-agnostic activation maps are random as well at beginning.
When contrastive loss is applied to pull close and push apart the representations of positive and negative pairs, the class-agnostic activation map gradually separates the regions of foreground object and background in the image.
Extensive experiments conducted on the tasks of WSOL and WSSS show that the proposed C2AM can replace or re-ﬁne CAM for better performance. Speciﬁcally in WSOL, we follow [47] to divide WSOL into two tasks: class-agnostic object localization and object classiﬁcation, and thus the class-agnostic activation maps can be used to ex-tract class-agnostic object bounding boxes for localization.