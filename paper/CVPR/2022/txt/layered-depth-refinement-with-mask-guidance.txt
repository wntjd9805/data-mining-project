Abstract
Depth maps are used in a wide range of applications from 3D rendering to 2D image effects such as Bokeh. However, those predicted by single image depth estimation (SIDE) models often fail to capture isolated holes in objects and/or have inaccurate boundary regions. Meanwhile, high-quality masks are much easier to obtain, using commercial auto-masking tools or off-the-shelf methods of segmentation and matting or even by manual editing. Hence, in this paper, we formulate a novel problem of mask-guided depth reﬁnement that utilizes a generic mask to reﬁne the depth prediction of
SIDE models. Our framework performs layered reﬁnement and inpainting/outpainting, decomposing the depth map into two separate layers signiﬁed by the mask and the inverse mask. As datasets with both depth and mask annotations are scarce, we propose a self-supervised learning scheme that uses arbitrary masks and RGB-D datasets. We empirically show that our method is robust to different types of masks and initial depth predictions, accurately reﬁning depth values in inner and outer mask boundary regions. We further analyze our model with an ablation study and demonstrate results on real applications. More information can be found on our project page.1 1.

Introduction
Recent progress in deep learning has enabled the pre-diction of fairly reliable depth maps from single RGB im-ages [20, 31, 32, 47]. However, despite the specialized net-work architectures [11,29,31] and training strategies [32,46] in single image depth estimation (SIDE) models, the esti-mated depth maps are still inadequate in the following as-pects: (i) depth boundaries tend to be blurry and inaccurate; (ii) thin structures such as poles and wires are often miss-ing; and (iii) depth values in narrow or isolated background regions (e.g., between body parts in humans) are often im-precise, as shown in the initial depth estimation in Figure 1.
Addressing these issues within a single SIDE model can be 1https://sooyekim.github.io/MaskDepth/
RGB / Mask
Initial Depth with (cid:1839) with (cid:883) (cid:3398) (cid:1839)
Layered Outputs
Our Refined Depth
Figure 1. Our layered depth reﬁnement result on an initial predic-tion by DPT [31]. Aided by a high-quality mask M generated with an auto-masking tool [33], our method is able to accurately reﬁne mask boundaries and correct depth values in isolated hole regions between body parts. Regions in M and 1 − M are reﬁned and inpainted/outpainted separately with our layered approach. very challenging due to limited model capacity and the lack of high-quality RGB-D datasets.
Therefore, we take a novel approach of utilizing an ad-ditional cue of a high-quality mask to reﬁne depth maps predicted by SIDE methods. The provided mask can be hard (binary) or soft (e.g., from matting) and can be of objects or other parts of the image such as the sky. As high-quality auto-masking tools are very accessible nowadays, such masks can be easily obtained with commercial tools (e.g., removebg [33] or Photoshop) or off-the-shelf seg-mentation models [14, 30, 52, 57]. Segmentation masks can also be annotated by humans [7,41,49], and accurate datasets are easier to obtain than RGB-D data, which facilitates the training of auto-masking models.
(cid:2) (cid:1) (cid:3) (cid:2) (cid:2) (cid:1) (cid:3) (cid:2) (cid:2)(cid:15)(cid:3)(cid:1)(cid:12)(cid:7)(cid:5)(cid:1)(cid:8)(cid:26)(cid:15)(cid:21)(cid:19)(cid:1)(cid:4)(cid:1)(cid:10)(cid:15)(cid:31)(cid:24) (cid:2)(cid:16)(cid:3)(cid:1)(cid:8)(cid:27)(cid:23)(cid:32)(cid:23)(cid:15)(cid:25)(cid:1)(cid:6)(cid:19)(cid:29)(cid:32)(cid:22) (cid:2)(cid:17)(cid:3)(cid:1)(cid:6)(cid:23)(cid:30)(cid:19)(cid:17)(cid:32)(cid:1)(cid:12)(cid:19)(cid:20)(cid:23)(cid:27)(cid:19)(cid:26)(cid:19)(cid:27)(cid:32) (cid:2)(cid:14)(cid:23)(cid:32)(cid:22)(cid:28)(cid:33)(cid:32)(cid:1)(cid:9)(cid:15)(cid:35)(cid:19)(cid:30)(cid:23)(cid:27)(cid:21)(cid:3) (cid:2)(cid:18)(cid:3)(cid:1)(cid:9)(cid:15)(cid:35)(cid:19)(cid:30)(cid:19)(cid:18)(cid:1)(cid:12)(cid:19)(cid:20)(cid:23)(cid:27)(cid:19)(cid:26)(cid:19)(cid:27)(cid:32)(cid:1)(cid:34)(cid:23)(cid:32)(cid:22) (cid:13)(cid:30)(cid:15)(cid:18)(cid:23)(cid:32)(cid:23)(cid:28)(cid:27)(cid:15)(cid:25)(cid:1)(cid:8)(cid:27)(cid:4)(cid:11)(cid:33)(cid:32)(cid:29)(cid:15)(cid:23)(cid:27)(cid:32)(cid:23)(cid:27)(cid:21) (cid:2)(cid:19)(cid:3)(cid:1)(cid:11)(cid:33)(cid:30)(cid:1)(cid:9)(cid:15)(cid:35)(cid:19)(cid:30)(cid:19)(cid:18)(cid:1)(cid:12)(cid:19)(cid:20)(cid:23)(cid:27)(cid:19)(cid:26)(cid:19)(cid:27)(cid:32)
Figure 2. Reﬁned depth maps with the guidance of a high-quality mask. (b) The initial depth prediction [31] has blurry boundaries and misses isolated hole regions between human body parts. (c) Direct reﬁnement by training on a paired dataset [34] improves the initial depth but still has blurry boundaries. Layered reﬁnement results in sharp edges due to the ﬁnal compositing step using the mask, although (d) naive in/outpainting [36] generates artifacts in the background. (e) Our method successfully corrects the inaccurate depth values while in/outpainting each region with the guidance of the mask. Intermediate layered outputs are shown on the top right for the layered models.
However, even with such accurate masks, how to effec-tively train the depth reﬁnement model remains an open issue. As shown in Figure 2(c), directly adding the mask as an input channel to the reﬁnement model still results in blur-rier boundaries than the given mask. Therefore, we propose a layered reﬁnement strategy: The mask (M ) and inverse mask (1 − M ) regions are processed separately to interpolate or extrapolate the depth values beyond the mask boundary, leading to two layers of depth maps. As shown in Figure 2(e), the reﬁned output is the composite of the two layers using the mask M , which fully preserves the boundary details of the mask, as well as ﬁlling in the correct depth values for the isolated background regions.
A na¨ıve baseline for layered depth reﬁnement would be using an off-the-shelf inpainting method to generate the depth map layers for M and 1 − M . Unfortunately, as shown in Figure 2(d), generic inpainting may not work well for ﬁlling in large holes in a depth map. Moreover, deriving an appropriate region for hole-ﬁlling on an imperfect initial depth prediction based on the mask is a non-trivial problem.
The hole-ﬁlling region often needs to be expanded to cover uncertain regions along the mask boundary, as otherwise, the erroneous depth values may propagate in the hole. However, too much expansion will make the hole-ﬁlling task much more challenging as it may overwrite the original depth structure in the scene (see the 1 − M layer in Figure 2(d)).
To address the challenge, we propose a framework for degradation-aware layered depth completion and reﬁnement, which learns to identify and correct inaccurate regions based on the context of the mask and the image. Our framework does not require additional input or heuristics to expand the hole-ﬁlling region. Furthermore, we devise a self-supervised learning scheme that uses RGB-D training data without paired mask annotations. We demonstrate that our method is robust under various conditions by empirically validating it on synthetic datasets and real images in the wild. We further provide results on real-world downstream applications.
Our contributions are three-fold:
• We propose a novel mask-guided depth reﬁnement framework that reﬁnes the depth estimations of SIDE models guided by a generic high-quality mask.
• We propose a novel layered reﬁnement approach, gen-erating sharp and accurate results in challenging areas without additional input or heuristics.
• We devise a self-supervised learning scheme that uses
RGB-D training data without paired mask annotations. 2.