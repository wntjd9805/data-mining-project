Abstract
Focus control (FC) is crucial for cameras to capture sharp images in challenging real-world scenarios. The aut-ofocus (AF) facilitates the FC by automatically adjusting the focus settings. However, due to the lack of effective
AF methods for the recently introduced event cameras, their
FC still relies on naive AF like manual focus adjustments, leading to poor adaptation in challenging real-world condi-tions. In particular, the inherent differences between event and frame data in terms of sensing modality, noise, tem-poral resolutions, etc., bring many challenges in design-ing an effective AF method for event cameras. To address these challenges, we develop a novel event-based autofo-cus framework consisting of an event-specific focus measure called event rate (ER) and a robust search strategy called event-based golden search (EGS). To verify the perfor-mance of our method, we have collected an event-based aut-ofocus dataset (EAD) containing well-synchronized frames, events, and focal positions in a wide variety of challenging scenes with severe lighting and motion conditions. The ex-periments on this dataset and additional real-world scenar-ios demonstrated the superiority of our method over state-of-the-art approaches in terms of efficiency and accuracy. 1.

Introduction
Recently, a novel neuromorphic vision sensor called event camera [3, 24] has gained growing attention with its significant advantages like high dynamic range (HDR,
>130 dB [3]) and low latency (1 us [11]). Thus far, event cameras have been widely adopted in various applications, including robotics and computer vision [9], where the fo-cus control (FC) is essential for reliable perception. Simi-*J. Pan is the corresponding author. This project is supported by
HKSAR RGC GRF 11202119, 11207818, T42-717/20-R, HKSAR
Technology Commission under the InnoHK initiative, National Natural
Science Foundation of China, Grant 61871297, and the Natural Science
Foundation of Hubei Province, China, Grant 2021CFB467. 1{lsj2048, 2 ly.wd@whu.edu.cn, zyq507, panj}@connect.hku.hk, 3zhoubin@buaa.edu.cn, 4xiaowluo@cityu.edu.hk.
Figure 1. Our event-based autofocus system consists of an event camera and a motorized varifocal lens. It leverages the proposed event-based focus measure and search method to focus the camera to the optimal focal position. When appropriately focused, the event camera’s imaging result (b) is sharper and more informative than (a), (c) where it is defocused. lar to conventional frame-based cameras, the focused events (Fig. 1b) exhibit sharper textures and convey more informa-tion than the defocused ones (Fig. 1a and Fig. 1c). Thus, an effective autofocus (AF) method for event cameras is in demand, especially for challenging real-world scenarios.
Conventional AF methods facilitate FC by leveraging the inherent properties of image frames like image gradi-ent [6, 8, 12], image frequency [17, 44], and image statis-tics [6]. However, events have fundamental differences with frames in terms of modality, noise, temporal resolutions, etc., which make conventional frame-based AF methods not applicable. When developing AF methods specific for event cameras, four particular challenges are:
• Focus measure function: Focus measure is a critical function measuring the degree of defocus, but existing frame-based focus measures are designed for 2D im-age frames but not for the asynchronous event data.
• Data modality: Unlike images, events are a stream of four-attribute tuples captured asynchronously with high temporal resolution.
• Noise: Events contain noise that are poorly charac-terised [9] and difficult to be filtered out.
• Data sizes: During focusing, event-based AF needs to handle millions of events, making the real-time pro-cessing more challenging than conventional AF, which only needs to handle less than one hundred images.
A naive solution to the above challenges is to rely on ex-isting event-based image reconstruction methods [4, 28, 34] to convert events to images and then feed these images to conventional frame-based AF methods. However, the noise of events affects the quality of reconstructed frames and limits the performance of subsequent AF methods. In addi-tion, as a fundamental front-end for numerous event-based applications, AF must be time-efficient, but the learning-based reconstruction is time-consuming. We handle the above challenges by developing an event-based autofocus framework from scratch. First, we developed, according to our knowledge, the first event-based focus measure leverag-ing the statistics of even rate (ER), which is a simple metric effective for measuring the event data captured at different focal positions. Then, we propose the event-based golden search (EGS) to cooperate with our focus measure to find the optimal focal position. EGS is invariant to the param-eter of event accumulation interval and thus can robustly operate in challenging conditions, such as situations with extremely low lighting (<1 Lux) and violent camera shak-ing. In summary, our contributions are threefold:
• We propose a novel event-based focus measure, i.e., event rate (ER), to measure the focus score of event data at different focal positions. It is efficient, easy to implement, and robust to noise.
• Using our event-based focus measure, we propose a ro-bust and efficient method to focus the event camera by solving a 1-dimensional optimization, which works ex-cellently, especially in complex dynamic and low light-ing conditions.
• We collected an event-based autofocus dataset (EAD), containing data under a wide variety of motion and lighting conditions. Extensive evaluations and com-parisons have been conducted on EAD and real-world scenarios. 2.