Abstract
Augmentation
Augmentation
Existing person re-identiﬁcation (ReID) methods typi-cally load the pre-trained ImageNet weights for initial-ization directly. However, as a ﬁne-grained classiﬁcation task, ReID is more challenging and there exists a large domain gap between ImageNet classiﬁcation. Inspired by the great success of self-supervised representation learn-ing with contrastive objectives, in this paper, we design an
Unsupervised Pre-training framework for re-identiﬁcation (UP-ReID) based on the contrastive learning (CL) pipeline.
During the pre-training, we attempt to address two critical issues for learning ﬁne-grained ReID features: (1) the aug-mentations in the CL pipeline usually distort the discrimi-native clues in person images, and (2) the ﬁne-grained lo-cal features of person images are not fully-explored. There-fore, we introduce an intra-identity (I2-)regularization in the UP-ReID, which is instantiated as two constraints com-ing from the global image and local patch aspects, respec-tively. A global consistency constraint is enforced between augmented and original person images to increase robust-ness to augmentation, while an intrinsic contrastive con-straint among local patches of each image is employed to fully explore the local discriminative clues. Extensive ex-periments on multiple popular Re-ID datasets, PersonX,
Market1501, CUHK03, and MSMT17, demonstrate that our
UP-ReID pre-trained model can signiﬁcantly beneﬁt the downstream ReID ﬁne-tuning and achieve state-of-the-art performance. 1.

Introduction
As a ﬁne-grained classiﬁcation problem, person re-identiﬁcation (ReID) aims at identifying a speciﬁc person across non-overlapping camera views. Existing ReID meth-ods have achieved a remarkable success in both supervised
[25,27,35,37,42,46] and unsupervised [10,13,14,26,30,45] domains. Most of these approaches directly leverage the
*Corresponding Author.
Discriminative
Discriminative
Discriminative
Similar
Augmentation
Augmentation
Original
Pictures
Augmented
Pictures
Original
Pictures
Augmented
Pictures (a) Left: the two augmented images are still discriminative for general classiﬁ-cation tasks. Right: the discriminative attributes of the two person images are ruined by augmentation for person ReID.
...
Dissimilar
Similar
Positive Samples
Anchor
Negative Samples
...
Similar
Dissimilar
...
...
...
Positive Samples
Anchor
Negative Samples (b) Top: a case that uses the global features for a failed ReID, where the positive sam-ples share dissimilar appearance but the negative samples have a similar appearance instead. Bottom: a case that uses the ﬁne-grained discriminative attributes, such as backpacks and bags, for a successful ReID where the person images are distinguish-able and independent to clothing.
Figure 1. Two critical issues in the existing contrastive learning-based pre-training methods, which should be well solved in the
ReID-speciﬁc pre-training framework. weights pre-trained on ImageNet for model initialization, which may not be optimal for ReID tasks, resulting in poor
ﬁne-tuning performance and slow convergence [14, 42].
The main reasons stem from two aspects: inapplicable pre-training method (ImageNet is more like a coarse-grained classiﬁcation) and large domain gap between ImageNet and
ReID datasets. Thus, how to efﬁciently pre-train a good
ReID-speciﬁc initialization network is still under-explored.
Unsupervised pre-training has achieved a fast develop-ment with the great success of contrastive learning [1, 4, 6,
7,18], which is taken as a pretext work, serving for different downstream supervised or unsupervised ReID ﬁne-tuning algorithms. Beyond the general pre-training task, this pa-per aims to propose a ReID-speciﬁc pre-training framework (e.g., pre-training a ResNet50 [19] for learning discrim-inative ReID representations) on a large-scale unlabeled dataset. The pioneering work in [12] makes the ﬁrst attempt on ReID pre-training and introduces a new large-scale un-labeled ReID dataset LUPerson. However, it directly trans-fers the general pre-training process based on contrastive learning that designed for ImageNet classiﬁcation to ReID task, which ignores the fact that ReID is a ﬁne-grained clas-siﬁcation problem. This solution faces the following two critical issues:
The ﬁrst one comes from the used augmentations in the existing contrastive learning pipeline, which could possi-bly damage the discriminative attributes of person images.
As shown in Figure 1a, different from the coarse-grained classiﬁcation problem on ImageNet, the discriminative at-tributes of person images are prone to be destroyed by the augmentation operations. For example, in the ImageNet classiﬁcation, although the augmentations applied to the pictures (e.g., dogs and ships) may cause the lack of re-gional information, the remaining parts are still discrimi-native enough to support the model for distinguishing them.
However, when applying the same augmentations to person images in ReID, it will provoke a disaster, the most discrim-inative attributes (i.e., trousers color) of person images are destroyed, making them indistinguishable.
The second one is that the ﬁne-grained information of person images is not fully explored in previous pre-training methods. They typically only care about the learning of image-level global feature representations. Nevertheless, as a ﬁne-grained classiﬁcation task, ReID needs detailed local features in addition to global ones for the accurate identity matching [40, 42, 45]. As illustrated in Figure 1b, the lo-cal ﬁne-grained clues (e.g., backpacks, cross-body bags) are more helpful than global features w.r.t distinguishing differ-ent persons.
To address the above issues, we introduce an intra-identity (I2-) regularization in the proposed ReID-speciﬁc pre-training framework UP-ReID. It consists of a global consistency constraint between augmented and original per-son images, and an intrinsic contrastive constraint among local patches of each image. Speciﬁcally, we ﬁrst enforce a global consistency to make the pre-training model be more invariant to augmentations. We feed the augmented images as well as the original images into the model and then nar-row the similarity distance between them in distributions.
Second, we propose an intrinsic contrastive constraint for the local information exploration. Instead of directly feed-ing the holistic augmented images, we partition them into multiple patches and then send these patches along with the holistic images to the network. After that, we compute an intrinsic contrastive loss among patches to encourage the model to learn both ﬁne-grained and semantic-aware rep-resentations. Moreover, based on the prior knowledge that human body is horizontally symmetric, we establish a hard mining strategy for the calculation of this loss, which makes the training stable and thus improves the generalization abil-ity of the pre-trained model.
We summarize our main contributions as follows:
• To the best of our knowledge, the proposed UP-ReID is the ﬁrst attempt toward a ReID-speciﬁc pre-training framework by explicitly pinpointing the difference be-tween the general pre-training and ReID pre-training.
• Considering the particularity of ReID tasks, an intra-identity (I2-)regularization is introduced in our UP-ReID, which is instantiated from the global image level and local patch level.
• In the I2-regularization, a global consistency is ﬁrst en-forced to increase the robustness of pre-training to data augmentations. An intrinsic contrastive constraint with prior-based hard mining strategy among local patches of person images is further introduced to fully explore the local discriminative clues.
Extensive experiments on multiple widely-used ReID benchmarks demonstrate the effectiveness of the proposed
UP-ReID, which outperforms other state-of-the-art pre-training methods by prominent margins and could beneﬁt a series of downstream ReID-related tasks. 2.