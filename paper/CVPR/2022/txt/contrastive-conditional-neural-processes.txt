Abstract
Conditional Neural Processes (CNPs) bridge neural net-works with probabilistic inference to approximate func-tions of Stochastic Processes under meta-learning settings.
Given a batch of non-i.i.d function instantiations, CNPs are jointly optimized for in-instantiation observation predic-tion and cross-instantiation meta-representation adaptation within a generative reconstruction pipeline. There can be a challenge in tying together such two targets when the distri-bution of function observations scales to high-dimensional and noisy spaces.
Instead, noise contrastive estimation might be able to provide more robust representations by learning distributional matching objectives to combat such inherent limitation of generative models. In light of this, we propose to equip CNPs by 1) aligning prediction with en-coded ground-truth observation, and 2) decoupling meta-representation adaptation from generative reconstruction.
Specifically, two auxiliary contrastive branches are set up hierarchically, namely in-instantiation temporal contrastive learning (TCL) and cross-instantiation function contrastive learning (FCL), to facilitate local predictive alignment and global function consistency, respectively. We empirically show that TCL captures high-level abstraction of obser-vations, whereas FCL helps identify underlying functions, which in turn provides more efficient representations. Our model outperforms other CNPs variants when evaluating function distribution reconstruction and parameter identifi-cation across 1D, 2D and high-dimensional time-series. 1.

Introduction
Supervised generative models learn to reconstruct joint distribution with certain prior incorporated to achieve pa-rameter estimation. This brings in a natural fit to meta-learning [2, 12, 30] paradigm, where knowledge acquired from previous tasks can help fast adaptation in solving novel tasks drawn from the same task distribution. Conditional
Neural Processes [6, 9,16] (CNPs) lie at the intersection be-tween these two. Mathematically, for T steps of a func-T t=1 sampled from a time-tion instantiation D = (xt, yt)
}
{
⊆
C ⊆
C → series, where each time index x has an associated obser-Rd, CNPs learn to reconstruct the observation vation y of a given query index xq, with a set of time-observation
D as input. Specifically, CNPs are built upon an pairs encoder-decoder, where the encoder h : rC summa-rizes all the input as a contextual representation rC. The decoder takes rC and query index xq and outputs estimated yq. In a meta-learning con-observation g : rC, xq →
ˆyq ≈ text, CNPs may deal with some non-i.i.d function instan-tiations. If, for instance, given two function instantiations f2 = 8x + 1, the representa-D1 ∼ tion derived from f1 cannot be used directly to reconstruct observations of f2, but rather requires a cross-instantiation adaption step for meta-representation. In CNPs, the adapta-tion takes place implicitly along with data reconstruction. f1 = 5x + 10 and D2 ∼
The Bayesian principles enable CNPs to quantify un-certainties while performing predictive tasks under limited data volume. Moreover, CNPs are designed to model a dis-tribution over functions whereas conventional deep learn-ing models do not, suggesting better generalization when multiple functions are in play. These properties are desir-able in applications like traffic forecasting, trajectory pre-diction, and activity recognition [13, 21, 24], where obser-vations might be corrupted or sampled from different data-generation functions.
The CNP’s variants attempt to improve the encoder h by introducing a range of inductive biases [9, 15, 16] to learn appropriate structures from data. Despite the performance gains achieved, the inherent generative nature of these mod-els has raised some concerns, especially when they are considered together: 1) Correlations between observations are not modeled in CNPs. While introducing a global la-tent variable can yield more coherent predictions [4, 7, 16], these attempts are also fraught with intractable likelihood; 2) High-dimensional observations challenge the capacity of
CNPs since generative models reconstruct low-level details but hardly form high-level abstractions [17, 23]; and 3) Su-pervision collapse in meta-learning [3] occurs when predic-tion and transfer tasks are entangled in CNPs [8].
To address this, our first motivation centers on de-coupling model adaptation from generative reconstruction
tency across different partial views of the same instantiation to separate adaptation from reconstruction, thus improving the transferability of meta-representations.
Contributions. 1) We present an end-to-end generative-contrastive meta-learning model based on CNPs. 2) We demonstrate that incorporating proper contrastive objectives into generative CNPs contributes to complementary ben-efits, and hopefully leads to new avenues for research in
CNPs. 3) We empirically verify CCNP outperforms other
CNP baselines in terms of function distribution reconstruc-tion and parameter identification across diverse tasks, in-cluding 1D few-shot regression, 2D population dynamics prediction and high-dimensional sequences reconstructions. 2.