Abstract
Human trajectory prediction task aims to analyze human future movements given their past status, which is a crucial step for many autonomous systems such as self-driving cars and social robots. In real-world scenarios, it is unlikely to obtain sufficiently long observations at all times for predic-tion, considering inevitable factors such as tracking losses and sudden events. However, the problem of trajectory pre-diction with limited observations has not drawn much at-tention in previous work.
In this paper, we study a task named momentary trajectory prediction, which reduces the observed history from a long time sequence to an extreme situation of two frames, one frame for social and scene con-texts and both frames for the velocity of agents. We perform a rigorous study of existing state-of-the-art approaches in this challenging setting on two widely used benchmarks.
We further propose a unified feature extractor, along with a novel pre-training mechanism, to capture effective infor-mation within the momentary observation. Our extractor can be adopted in existing prediction models and substan-tially boost their performance of momentary trajectory pre-diction. We hope our work will pave the way for more re-sponsive, precise and robust prediction approaches, an im-portant step toward real-world autonomous systems. 1.

Introduction
Human trajectory prediction [2,9,15] plays an important role in the area of human behavior understanding [17, 18, 28, 40] and autonomous driving systems [3, 15, 31] by in-vestigating future movements of traffic agents given their past status observed from a video. Despite the good per-formance achieved by existing methods, these approaches are developed on historical observations over several sec-onds. However, accurate tracking over long periods of time is quite difficult, especially in congested traffic sce-narios [11, 16, 21, 25, 29]. Further, responsive and precise
§Cewu Lu is corresponding author, member of Qing Yuan Research
Institute and MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai
Jiao Tong University, China and Shanghai Qi Zhi Institute
Figure 1. The necessity of momentary prediction in emergency situations. The figures illustrate some sudden events, often occur-ring in highly occluded areas such as underground parking lots and congested roads. The pedestrian’s trajectory have to be precisely and immediately predicted to avoid the potential collision in a very short time. predictions are important and necessary for safety purposes when emergency situations suddenly come into view (see
Fig. 1). Therefore, a prediction task with momentary obser-vation is essential to be studied.
In this paper, we focus on the most extreme case that only two frames are available for observation, one frame for social and scene context and both frames for the veloc-ity of agents. We refer to the task as Momentary Trajec-tory Prediction. Note that we exclude the case of single-shot (one-frame observation) where the basic information, velocity magnitude, is missing. After reducing the obser-vation horizon in previous approaches, we observe obvious degradation of their performance (see Fig. 2).
Despite the lack of temporal features, three common types of information still widely exist between two adjacent frames and provide a large number of leads for trajectory prediction: i) velocity of agents, ii) social contexts, and iii) scene contexts. The velocity provides motion basis of hu-man short-term behavior, while context information implies enough clues to predict long-term trends and disturbances of movements. A fundamental aspect of momentary trajec-tory prediction is how to explore and integrate these poten-tial information implicit in the limited observations. In this paper, we raise a unified input formulation to join the three types of information as a whole (see Fig. 4), integrating all information at data level. The major insight of this input formulation is to consider scene restrictions as static inter-active objects while surrounding traffic agents as dynamic interactive objects with corresponding velocities. Then Mo-mentary Observation feature Extractor (MOE) (see Fig. 5)
Figure 2. Qualitative comparison of trajectory prediction between traditional and momentary observation time on [6,32,35], including state-of-the-art PCCSNet [35]. Lines in yellow denote ground truth trajectories in the past (8 frames/3.2 sec) and future (12 frames/4.8 sec), lines in cyan denote predictions with traditional observation time (8 frames/3.2 sec) and lines in red denote predictions with momentary observation time (2 frames/0.8 sec). The frame rate is 2.5fps. Obvious degradation occurs as the observation time reduces. is proposed to directly explore a joint historical representa-tion from the input. prediction frameworks to improve their momentary predic-tion performance.
Our feature extraction process enjoys a significant ad-vantage by avoiding the need for feature alignment between social and scene context. Previous work such as [12, 19, 30] models these different types of information by separately encoding them, then fusing them together with a fusion module or concatenation, and finally decoding the fused feature for prediction results. This paradigm in previous work adds a burden of feature alignment on the fusion mod-ule or the following decoder, since there is a big difference between the feature of trajectories (coordinate sequences) and scene contexts (RGB images). This burden is enlarged in the momentary observation setting, considering a good social feature is much harder to obtain due to the lack of historical trajectories. In comparison, by integrating these information at data level and encoding the input in a uni-fied manner, our approach subtly avoids the need of feature alignment and learns a better momentary observation repre-sentation.
Moreover, another potential problem resulting from the reduced observation is that prediction models become more difficult to fit, since they have to map the observation space with a much lower dimension to the original prediction space. We alleviate this by introducing a novel pre-training mechanism for the MOE, named soft pre-training, lever-aging ideas from multi-task learning and self-supervised learning.
In soft pre-training, the supervisions are sev-eral sub-tasks related to trajectory prediction yet much eas-ier. We raise masked trajectory complement and context restoration as two sub-tasks in our implementation. After pre-training, the MOE can be easily integrated into existing
Exhaustive experiments are conducted on ETH/UCY dataset [13,27] and SDD [28] (Stanford Drone Dataset). We first perform a rigorous study of the performance of exist-ing state-of-the-art approaches on this challenging setting.
Then, we adopt the MOE into multiple prediction frame-works to show substantial improvement can be brought with the aid of our approach. 2.