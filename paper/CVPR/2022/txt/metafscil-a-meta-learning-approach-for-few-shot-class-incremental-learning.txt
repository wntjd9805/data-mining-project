Abstract
In this paper, we tackle the problem of few-shot class in-cremental learning (FSCIL). FSCIL aims to incrementally learn new classes with only a few samples in each class.
Most existing methods only consider the incremental steps at test time. The learning objective of these methods is often hand-engineered and is not directly tied to the objective (i.e. incrementally learning new classes) during testing. Those methods are sub-optimal due to the misalignment between the training objectives and what the methods are expected to do during evaluation. In this work, we proposed a bi-level optimization based on meta-learning to directly op-timize the network to learn how to incrementally learn in the setting of FSCIL. Concretely, we propose to sample se-quences of incremental tasks from base classes for train-ing to simulate the evaluation protocol. For each task, the model is learned using a meta-objective such that it is ca-pable to perform fast adaptation without forgetting. Fur-thermore, we propose a bi-directional guided modulation, which is learned to automatically modulate the activations to reduce catastrophic forgetting. Extensive experimental results demonstrate that the proposed method outperforms the baseline and achieves the state-of-the-art results on CI-FAR100, MiniImageNet, and CUB200 datasets. 1.

Introduction
With the unprecedented increase in computational bud-get and data availability, deep models have achieved supe-rior performance in the recognition tasks [10, 26]. Typi-cally, those methods are offline trained on some pre-defined image categories and then deployed to target applications with fixed parameters. Such systems are not flexible enough since they cannot handle new classes that might emerge af-ter deployment. In contrast, humans are able to learn new concepts incrementally throughout their lifetime.
Recently, class incremental learning has been an active
Figure 1. Illustration of the evaluation protocol and our meta-training process. During the evaluation of FSCIL, at each in-cremental session, the model is trained only on new classes but is evaluated on all classes encountered so far. Our MetaFSCIL follows the same rule where the model adapted to new classes is validated using a meta-objective based on all encountered classes. area of research [2, 22, 25]. However, large-scale annotated data for the new classes are required, which leads to the well-known notorious catastrophic forgetting [19]. The for-getting issue becomes more severe when all the data for old classes are unavailable. Moreover, it is unrealistic for the end-users to collect and annotate numerous data. Thus, in this paper, we focus on a more practical and challenging setting: few-shot class incremental learning (FSCIL) [27].
FSCIL consists of an offline training stage and an online incremental learning stage. In the offline training stage, we have access to a large-scale dataset for some base classes.
FSCIL learns a model on these base classes. During the online incremental learning (i.e. evaluation) stage, we will encounter novel classes in a sequential manner, where a few novel classes are presented at each time step (called incre-mental session). For each novel class, we only have a few training examples. In addition, we can only access training examples corresponding to the novel classes at the current time step. In other words, we cannot store training exam-ples from previous time steps (e.g. due to limited storage
of deployment environment) during evaluation. The evalu-ation protocol is defined such that at each incremental ses-sion, after learning the novel classes, the model is evalu-ated on all encountered classes (including bases classes), as shown in Fig. 1. FSCIL is challenging due to two main reasons, namely catastrophic forgetting of old classes and adaptation ability of new classes. To mitigate the forgetting issue, some works [3, 7] use knowledge distillation-based methods. These methods typically require extra space to store exemplars from previous sessions. This is not realis-tic for memory-constrained devices when the incremental steps increase. Besides, the incremental learning process is only involved in the “evaluation phase” in [3, 7]. Thus, the model parameters are not directly optimized to handle for-getting and adaptation. In other words, these methods are sub-optimal due to the misalignment between their learning objective and the evaluation protocol.
Some recent works simulate the incremental process us-ing the available base classes to better match the evalua-tion protocol. A random task selection strategy is proposed to enhance the extensibility of representation for the novel classes [33]. However, during training, only one of the base classes is selected for sampling query images. The work in [32] randomly samples an incremental task to meta-train a classifier refiner such that it can incorporate the classifiers for old and new classes when learning new classes at de-ployment. During training, two non-overlapping and equal-sized subsets are sampled from the base classes as pseudo base and incremental classes. However, the imbalance be-tween the many-shot (base) and the few-shot (novel) classes is not considered. Furthermore, for both methods [32, 33], only one incremental session is considered. As a result, the model is not learned to incrementally learn in a longer hori-zon. The mismatch between the their sampling strategies for training and the incremental scenario at online evalua-tion leads to non-optimal solutions.
In addition, the aforesaid approaches involve hand-engineered heuristics (e.g. saving exemplars [3, 7], decou-pled learning [32], prototype refinement [33]) which are de-fective compared to the learned solutions [6]. For example, the backbones in [32, 33] are manually-designed to be fixed during incremental learning at deployment. The adaptation and generalization to novel classes is greatly restricted un-der distribution shift, as the backbone is not task-agnostic and is biased to seen (base) classes [8].
In this work, we propose a fully learned solution based on meta-learning (e.g. MAML [9]) to directly formulate forgetting alleviation and adaptation as the optimization ob-jective. We allow the model to learn how to incremen-tally learn through a nested optimization-based incremen-tal learning. Concretely, different from [32], we propose a longer sequential task sampling scheme to mimic the in-crease in catastrophic forgetting as time goes during eval-uation, as shown in Fig. 1 (learning addition to a 100-way classifier causes more forgetting than a 10-way classifier).
For each task, the model first performs quick adaptation to the new classes via a few gradient updates. Then the meta-objective is defined by validating the adapted model on the query images of previous encountered classes (test forgetting) and current classes (test adaptation). Our meta-objective follows the evaluation protocols at test time. The goal is to learn a model initialization such that it can adapt fast to new classes sequentially and is less prone to catas-trophic forgetting.
To further facilitate the optimization process, we build upon the selective activation mechanism [1] and propose a
Bi-directional Guided Modulation (BGM). BGM is meta-trained to automatically gate the activations of the clas-sification module conditioned on the current state (e.g. weights, learned knowledge) of the classification module and incoming images for new classes. The gated activa-tions during the forward pass indirectly affect the back-propagation when learning new classes. BGM is learned to accommodate the parameter update process such that adapt-ing to new knowledge causes less forgetting of old knowl-edge. Code will be available upon approval. The contribu-tions of this paper are manifold:
• We propose a sequential task sampling scheme to mimic the incremental learning process at evaluation.
• We propose a bi-directional guided modulation to strengthen the back-propagation such that the model can better preserve old knowledge while adapting to the new classes.
• A bi-level meta-learning-based optimization is pro-posed to directly optimize the model towards forget-ting alleviation and adaptation. Our method is fully learned with minimal manually designed components.
• Extensive experiments on standard benchmarks CI-FAR100, MiniImageNet, and CUB200 demonstrate that our method outperforms the baselines and achieves state-of-the-art. 2.