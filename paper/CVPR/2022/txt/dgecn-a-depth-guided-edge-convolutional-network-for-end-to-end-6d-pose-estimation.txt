Abstract
Monocular 6D pose estimation is a fundamental task in computer vision. Existing works often adopt a two-stage pipeline by establishing correspondences and utiliz-ing a RANSAC algorithm to calculate 6 degrees-of-freedom (6DoF) pose. Recent works try to integrate differentiable
RANSAC algorithms to achieve an end-to-end 6D pose es-timation. However, most of them hardly consider the geo-metric features in 3D space, and ignore the topology cues when performing differentiable RANSAC algorithms. To this end, we proposed a Depth-Guided Edge Convolutional
Network (DGECN) for 6D pose estimation task. We have made efforts from the following three aspects: 1) We take advantages of estimated depth information to guide both the correspondences-extraction process and the cascaded dif-ferentiable RANSAC algorithm with geometric information. 2) We leverage the uncertainty of the estimated depth map to improve accuracy and robustness of the output 6D pose. 3)
We propose a differentiable Perspective-n-Point(PnP) algo-rithm via edge convolution to explore the topology relations between 2D-3D correspondences. Experiments demon-strate that our proposed network outperforms current works on both effectiveness and efficiency. 1.

Introduction
Object pose estimation is a task of calculating the 6 de-grees of freedom (DoF) pose of a rigid object, including its location and orientation in an image. It is widely used in the three-dimensional registration of AR [1, 28, 45], robotic vision [27, 31] and 3D reconstruction [9, 10]. Due to the presence of noises and other influential factors, such as the occlusion, noisy background, and illumination variations, accurately estimating the 6DoF poses of the objects in the
RGB image is still a challenging problem.
*Chunxia Xiao and Fei Luo are co-corresponding authors
Figure 1. Pipeline of DGECN. With an input RGB image, we propose a novel DGECN to simultaneously predict segmentation and depth maps. After established 2D-3D correspondences, we replace the RANSAC/PnP with a learnable DG-PnP to regress 6D pose.
Current object pose estimation methods can be divided into two types: 1) the object poses are estimated using a sin-gle RGB image [17, 27, 28, 31, 45] or 2) an RGB image ac-companying a depth image [14,39,41]. For both RGB based and RGB-D based methods, the keypoints-based works are dominant in this field. On the other hand, methods based on direct regression are usually inferior to keypoints-based methods. The keypoints-based methods usually consist of two stages: firstly it predicts the 2D location of the key-points of the 3D model on RGB images via a modern neu-ral network. And then calculate the 6D pose parameters with the RANSAC-based Perspective-n-Point (PnP) method from 2D-3D correspondences. Although many representa-tive works [15, 22, 25, 33, 35, 36] have proven the validity of the two-stage pipeline, there are still many limitations in it.
Firstly, few methods can directly output the 6D pose param-eters. Most of the existing methods still use a variant of the
RANSAC-based PnP algorithm to estimate the pose param-eters. Secondly, RANSAC-based PnP can be very time-cost when the 2D-3D correspondences are dense. Thirdly, the
network in most two-stage works cannot directly output 6D pose, so their loss functions cannot optimize our expected pose estimation. Finally, the two-stage estimation may lead to significant accumulative error, which gradually increases among the two connected steps.
Recently, some works try to integrate a differentiable
RANSAC algorithm into the pipeline, so the network can be trained end-to-end. Brachmann et al. [3] proposed a differ-entiable PnP method. Hu et al. [16] leveraged PointNet [29] to approximate PnP for sparse correspondences. But these works either require a cumbersome training process or do not consider the geometry clues. Wang et al. [42] made an end-to-end framework by replacing RANSAC-based PnP with Patch-PnP, this method works well, but it relies on the
Dense Correspondences Map and Surface Region Attention
Map in their network.
It can hardly directly learning 6D pose from 2D-3D correspondences.
To this end, we propose Depth-Guided Edge Convolu-tional Network (DGECN), jointly handling the correspon-dences extraction and the 6D pose estimation. Our network leverages a depth guided network to establish 2D-3D cor-respondences and learn the 6D pose from the correspon-dences by a novel Dynamic Graph PnP (DG-PnP). On one hand, depth information allows us to make full use of the geometric constraint of rigid objects. On the other hand, we fully revisit the properties of correspondence set and find it can better handle complex textures by constructing a graph structure. Our end-to-end pipeline is shown in Fig. 1.
Experimental results on LM-O [2] and YCB-V [5, 45] demonstrate our network is comparable even superior to the state-of-the-art methods in terms of accuracy and efficiency.
Our contributions in this work can be summarized as fol-lows:
• We propose a Depth-guided network to directly learn the 6D pose from a monocular image without addi-tional information required. Furthermore, we pro-pose a Depth Refinement Network (DRN) to polish the quality of the estimated depth map.
• We explore the properties of 2D correspondence sets and discover that 6D pose parameters can be learned better from the 2D keypoint distributions by construct-ing a graph. We further propose a simple but effec-tive Dynamic Graph PnP (DG-PnP) to directly learn 6D pose from 2D-3D correspondences. 2.