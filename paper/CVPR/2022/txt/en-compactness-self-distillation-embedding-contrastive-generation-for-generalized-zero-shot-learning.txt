Abstract
Generalized zero-shot learning (GZSL) requires a clas-siﬁer trained on seen classes that can recognize objects from both seen and unseen classes. Due to the absence the classiﬁer tends to bias of unseen training samples, towards seen classes. To mitigate this problem, feature generation based models are proposed to synthesize visu-al features for unseen classes. However, these features are generated in the visual feature space which lacks of discriminative ability. Therefore, some methods turn to
ﬁnd a better embedding space for the classiﬁer training.
They emphasize the inter-class relationships of seen classes, leading the embedding space overﬁtted to seen classes and unfriendly to unseen classes.
Instead, in this paper, we propose an Intra-Class Compactness Enhancement method (ICCE) for GZSL. Our ICCE promotes intra-class com-pactness with inter-class separability on both seen and unseen classes in the embedding space and visual feature space. By promoting the intra-class relationships but the inter-class structures, we can distinguish different classes with better generalization. Speciﬁcally, we propose a Self-Distillation Embedding (SDE) module and a Semantic-Visual Contrastive Generation (SVCG) module. The former promotes intra-class compactness in the embedding space, while the latter accomplishes it in the visual feature space.
The experiments demonstrate that our ICCE outperforms the state-of-the-art methods on four datasets and achieves competitive results on the remaining dataset. 1.

Introduction
Image classiﬁcation tasks relying on large amounts of labeled data [6, 16, 23] have made tremendous progress due to the advancement of deep learning [13, 21, 55]. the data hunger nature of deep models leads
However, them to perform unsatisfyingly when some categories have
†Corresponding authors.
Figure 1. Motivation of this paper. (a) Existing methods such as CE-GZSL [14], produce discriminative embeddings for seen classes, but dispersed embeddings for unseen classes. (b)
Our ICCE promotes intra-class compactness with inter-class separability for both seen and unseen classes in the embedding space. scarce or even no labeled data [47]. Zero-Shot Learning (ZSL) [24, 35] is proposed to tackle this data absence issue by recognizing objects from unseen classes. They
ﬁrst learn a classiﬁcation model on the seen classes, of which the training samples are provided, then transfer the model to unseen classes using the class-level semantic descriptors [10, 24, 31, 32], such as visual attributes [10, 24] or word vectors [31, 32].
Unlike ZSL, Generalized Zero-Shot Learning (GZS-L) [7, 50] has been proposed to identify test samples from both seen and unseen classes, which is more challenging.
Since the training set only contains seen classes samples, during testing, GZSL methods tend to misclassify unseen classes samples into seen classes, which is the widespread strong bias problem.
Recently, feature generation based GZSL methods [11, 14, 15, 26, 28, 38] have been proposed to mitigate the strong bias problem by synthesizing training samples for unseen classes conditioned on the semantic descriptors. Merging the real seen training features and the synthetic unseen
in the above methods, features, they obtain a fully-observed dataset to train a
GZSL classiﬁcation model, such as a softmax classiﬁer.
Early feature generation methods [11, 26, 28, 38] synthe-size features in the visual features space which lacks of discriminative ability [8,14]. Lately, some methods [14,15] search for a new embedding space based on the inter-class relationships for GZSL classiﬁer training. Speciﬁcally,
RFF-GZSL [15] maps the visual features into a redundancy-free space and uses center loss [48] to strengthen seen classes relationships in that space. CE-GZSL [14] con-ducts instance-level and class-level contrastive supervision to improve the discrimination of the embedding space.
However, the embedding space is strictly constrained by the relationships between seen classes, which is unfriendly to the synthetic unseen classes features. Moreover, the synthetic features of unseen classes have various distributions, as a consequence, mapping them into the embedding space will form confusing distributions.
As depicted in Fig. 1 (a), the embeddings of seen classes have large inter-class distances, while the unseen classes embeddings are overlapping and lack of discrimination. training the GZSL classiﬁer in this kind of
Therefore, embedding space will end with inferior performance. In-stead, as the intra-class relationships are class-independent, if we strengthen these relationships of seen classes, the embedding space can also separate different classes but with better generalization ability on unseen classes. As depicted in Fig. 1 (b), although the inter-class relationships are not highly restricted, a compact intra-class distribution can help all the classes (seen and unseen) distinguish from each other.
In this paper, we propose an Intra-Class Compactness
Enhancement method (ICCE) for GZSL. Our ICCE pro-motes intra-class compactness with inter-class separability on both seen and unseen classes in the embedding space and visual feature space. By putting more emphasis on intra-class relationships but the inter-class structures, we can distinguish different classes with better generalization.
Speciﬁcally, we produce compact intra-class distributions via a Self-Distillation Embedding (SDE) module and a
Semantic-Visual Contrastive Generation (SVCG) module.
The SDE module is built with a teacher-student structure, which aligns the representations and the predicted logits between two different samples from the same class. Using
SDE, we can reduce the intra-class variations and obtain compact distribution for each class in the embedding s-pace. The SVCG module is a conditional GAN, which synthesizes compact distributed features for unseen classes in the visual feature space with instance-wise semantic-visual contrastive loss. The experiments demonstrate that our ICCE outperforms the state-of-the-arts on four datasets and achieves competitive results on the remaining dataset.
Our contributions are three-fold: (1) we propose an
Intra-Class Compactness Enhancement method (ICCE) for
GZSL. Our ICCE promotes intra-class compactness with inter-class separability on both seen and unseen classes in the embedding space and visual feature space; (2) we propose a Self-Distillation Embedding (SDE) module to learn an intra-class compact embedding space with repre-sentation distillation loss and normalized logits distillation loss; and (3) we propose a Semantic-Visual Contrastive
Generation (SVCG) module to synthesize compact intra-class distributed features for unseen classes, with instance-wise semantic-visual contrastive loss. 2.