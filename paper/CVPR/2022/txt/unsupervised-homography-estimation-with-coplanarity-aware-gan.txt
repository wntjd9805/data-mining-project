Abstract
Estimating homography from an image pair is a funda-mental problem in image alignment. Unsupervised learn-ing methods have received increasing attention in this field due to their promising performance and label-free train-ing. However, existing methods do not explicitly consider the problem of plane-induced parallax, which will make the predicted homography compromised on multiple planes.
In this work, we propose a novel method HomoGAN to guide unsupervised homography estimation to focus on the dominant plane. First, a multi-scale transformer network is designed to predict homography from the feature pyra-mids of input images in a coarse-to-fine fashion. More-over, we propose an unsupervised GAN to impose copla-narity constraint on the predicted homography, which is re-alized by using a generator to predict a mask of aligned regions, and then a discriminator to check if two masked feature maps are induced by a single homography. To val-idate the effectiveness of HomoGAN and its components, we conduct extensive experiments on a large-scale dataset, and results show that our matching error is 22% lower than the previous SOTA method. Code is available at https:
//github.com/megvii-research/HomoGAN 1.

Introduction
Homography estimation is a fundamental computer vi-sion problem that plays an important role in a wide range of applications, such as image/video stitching [14, 37], camera calibration [40], HDR imaging [12] and SLAM [24, 41]. It is defined as the estimation of the projective transformation between two views on the same plane in 3D space [28]. Tra-ditional methods typically address this problem by follow-ing a pipeline of feature extraction [2, 22, 26], correspon-dence matching, and solving direct linear transform [15] with outlier rejection [10]. But these methods often suf-fer from the lack of discriminative keypoints when dealing with textureless or blurry images.
Recently, unsupervised learning methods have gained
*Equal contribution. †Corresponding authors.
Figure 1. Predicting homography for images with a multi-plane scene will lead to virtual parallax. We propose an unsupervised homography estimation method that enforces the model to focus on the dominant plane by leveraging coplanarity constraint, thus significantly reducing the matching error. (c) and (d) are generated by superimposing the warped source image on the target image. popularity in homography estimation [8, 25, 28, 35, 39].
These methods directly predict the homography from a pair of source and target images using a neural network, of which an important optimization objective is to minimize the distance from the warped source image to the target im-age. They do not rely on keypoints, and could perform bet-ter than traditional methods in textureless scenarios. How-ever, when there exist multiple planes in the scene, optimiz-ing over the entire image will lead to a compromised result, i.e., the predicted homography is averaged on all planes and not accurate on the dominant plane, as shown in Fig. 1. Note that the planes of interest are not limited to rigid planes such as grounds, buildings, and walls, but also include planes that can be approximately induced by a homography, such as mountains in the distance. Some existing methods propose to remove large foregrounds or moving objects from the in-put images by predicting a mask [18, 39]. But their masks are implicitly optimized as a side product of homography estimation and lack explicit guidance, thus cannot address the plane-induced parallax.
In this work, we introduce an unsupervised approach to empower homography estimators to focus on a dominant
plane instead of the entire image. Assume a scene with multiple planes, we cannot align the entire image with one homography unless two images are related by a conjugate rotation [15]. Instead, we can obtain a mask to indicate if each pixel is well aligned by the predicted homography. If the homography is induced by the dominant plane, then the aligned regions should be on the same plane and occupy a significantly large area. With this knowledge, our main idea is to impose additional coplanarity constraint and area penalty on the aligned regions of the mask.
To achieve this goal, we propose a new method Homo-GAN with two unique designs. First, to guide the model to focus on the dominant plane, we introduce an unsupervised
GAN to impose coplanarity constraint, in which the gener-ator predicts soft masks of aligned regions from a pair of feature maps, while the discriminator checks if the masked features is coplanar. Together with the foreground area con-straint, the generated masks are expected to highlight the dominant plane, which can in turn guide the training of ho-mography estimator. Second, a multi-scale transformer net-work is designed to predict the homography from a pair of feature pyramids in a coarse-to-fine fashion. Compared to
CNN-based alternatives, the query-key correlation of trans-formers is more natural to establish local correspondence for homography estimation. In sum, this work makes the following contributions:
• We propose a coplanarity-aware GAN to address the problem of plane-induced parallax for homography es-timation without ground truth.
• We design a coarse-to-fine homography estimation transformer with self-attention encoders for capturing local correspondences and class-attention decoders for summarizing global information.
• Our method achieves the state-of-the-art performance on unsupervised homography estimation, and outper-forms previous methods by 22% on matching error. 2.