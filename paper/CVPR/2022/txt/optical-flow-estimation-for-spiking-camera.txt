Abstract
As a bio-inspired sensor with high temporal resolution, the spiking camera has an enormous potential in real ap-plications, especially for motion estimation in high-speed scenes. However, frame-based and event-based methods are not well suited to spike streams from the spiking camera due to the different data modalities. To this end, we present,
SCFlow, a tailored deep learning pipeline to estimate op-tical flow in high-speed scenes from spike streams. Impor-tantly, a novel input representation is introduced which can adaptively remove the motion blur in spike streams ac-cording to the prior motion. Further, for training SCFlow, we synthesize two sets of optical flow data for the spiking camera, SPIkingly Flying Things and Photo-realistic High-speed Motion, denoted as SPIFT and PHM respectively, corresponding to random high-speed and well-designed scenes. Experimental results show that the SCFlow can pre-dict optical flow from spike streams in different high-speed scenes. Moreover, SCFlow shows promising generalization on real spike streams. Codes and datasets refer to https:
//github.com/Acnext/Optical-Flow-For-Spiking-Camera. 1.

Introduction
Optical flow estimation has always been a popular topic in computer vision and played important roles in a wide range of applications, such as object segmentation [2], video enhancement [32], and action recognition [31]. How-ever, the breakthrough of this field in high-speed scenes is impeded by blurry images from traditional cameras with low frame rate. The emergence of neuromorphic cameras
[5, 6, 10, 13, 24, 30, 41] provides a new perspective for op-tical flow estimation in high-speed scenes. Some works
[17,38,40] raise the interest in event cameras [5,6,13,24,30] and show optical flow in high-speed scene can be directly estimated from an event stream. However, the event stream
*These authors contributed equally to this work.
†Corresponding author.
Figure 1. The optical flow estimation for a real spike stream which records a car traveling at a speed of 100 km/h. We com-pare our SCFlow to event-based method (Spike-FlowNet [17]) and frame-based method (RAFT [29]). All methods use spike streams as input and are trained on proposed dataset (SPIFT).
Results show that our proposed method has better performance which clearly distinguishes regions with different motion and ac-curately predict optical flow in each region. On the top right corner of results is a visualization of the color coding of the optical flow. that only encodes the change of luminance intensity might be insufficient for optical flow estimation in all regions of a scene, especially for regions with weak textures. Also as a neuromorphic camera, the spiking camera [10, 41] not only has high temporal resolution (40000Hz) but can report per-pixel luminance intensity by firing spikes asynchronously.
Specifically, each pixel in the spiking camera can accumu-late incoming light independently and persistently. At each timestamp, if luminance intensity accumulation at a pixel exceeds the predefined threshold, a spike is fired and the ac-cumulation is reset for that pixel, otherwise there is no spike at that position. Hence, instead of a grayscale image, the output of all pixels forms a binary matrix representing the presence of spikes, also known as a spike frame, and con-tinuous spike frames form a spike stream. Further, the sam-pled high-speed scene can be reconstructed from the spike stream [36, 37, 41–43]. Hence, the spiking camera that can record details of objects has an enormous potential for opti-cal flow estimation in high-speed scenes.
At present, there is no research about spike-based opti-cal flow estimation, one of the challenges is that the spike stream has a unique data modality so that frame-based and event-based methods are not directly applicable to it. For estimating optical flow from spike stream, an intuitive so-lution is to reconstruct image sequences from spike stream firstly, and then use frame-based methods to estimate optical flow. However, when the spike stream over a period of time is converted into a two-dimensional image, there is a time offset between the reconstructed image and the real scene which would bring additional errors to optical flow esti-mation. Besides, simple reconstruction methods [37, 41, 42] are difficult to filter out the motion blur in the spike stream while high-quality reconstruction methods [36, 43] would cost a lot of extra processing efforts. Therefore, it is nec-essary to design a tailored method to estimate optical flow directly from spike streams. Another challenge is there are no optical flow datasets for the spiking camera to properly evaluate the performance of spike-based optical flow meth-ods. In fact, it is difficult to build real optical flow datasets for the spiking camera since calibrating ground truth opti-cal flow is chanllenging in high-speed scenes [8,23]. Hence, synthetic spiking optical flow datasets seem to be the more feasible way to solve this challenge.
In this paper, we propose SCFlow, a neural network tai-lored to estimate optical flow directly from spike streams.
Different from previous work using deep learning [36, 43] where the spike stream in temporal windows with fixed di-rection is used as features, we propose a novel input repre-sentation for spike streams, Flow-guided Adaptive Window (FAW). By adaptively selecting temporal windows for each pixel based on the prior motion, FAW can avoid the motion blur [41] in the spike stream caused by static temporal win-dows. Besides, for training our network and evaluating the performance, we synthesize two spike-based optical flow datasets, SPIkingly Flying Things and Photo-realistic High-speed Motion, denoted as SPIFT and PHM respectively.
We show that SCFlow can estimate optical flow accu-rately in high-speed scenes and achieve the state-of-the-art performance in comparison with existing frame-based and event-based methods on our datasets. Importantly, SCFlow shows promising generalization on real spike streams as shown in Fig. 1.
In general, we attempt to exploit the potential of the spik-ing camera in high-speed motion estimation and our main contributions are summarized as follows: 1) We propose the first work to explore optical flow esti-mation in high-speed scenes with the spiking camera, and propose a tailored neural network architecture with a novel input representation, FAW, allowing adaptive temporal window selection is for handling the motion blur in a spike stream in temporal windows with fixed direction. 2) We synthesize the first spike-based optical flow datasets (SPIFT and PHM) to benchmark optical flow estimation for the spiking camera, which includes well-designed scenes with various motion, and to in-spire future research on spike-based vision tasks. 3) We demonstrate that SCFlow can estimate flow field from the spike stream on proposed datasets efficiently.
Importantly, SCFlow can be generalized well on real spike streams captured in real high-speed scenarios. 2.