Abstract can fully discover the potential structure hidden in multi-view data and achieve better clustering performance.
Multi-view clustering has been shown to boost cluster-ing performance by effectively mining the complementary information from multiple views. However, we observe that learning from data with more views is not guaranteed to achieve better clustering performance than from data with fewer views. To address this issue, we propose a general deep learning based framework that is guaranteed to re-duce the risk of performance degradation caused by view increase. Concretely, the model is trained to simultaneously extract complementary information and discard the mean-ingless noise by automatically selecting features. These two learning procedures are incorporated into one unified framework by the proposed optimization objective. In the-ory, the empirical clustering risk of the model is no higher than learning from data before the view increase and data of the new increased single view. Also, the expected clus-tering risk of the model under divergence-based loss is no higher than that with high probability. Comprehensive ex-periments on benchmark datasets demonstrate the effective-ness and superiority of the proposed framework in achiev-ing safe multi-view clustering. 1.

Introduction
Multi-view data, which contains data collected from dif-ferent sources, exists widely in real-world application sce-narios. For example, video can be represented by audible and visual information, and images can be characterized by different descriptors. As an important topic in multi-view learning, multi-view clustering (MVC) aims to par-tition similar instances into the same group and dissimilar instances into different groups by utilizing the complemen-tary information in multi-view data [35, 46]. Through the well-designed learning mechanism, multi-view clustering
∗Corresponding author.
Figure 1. Clustering performance degradation phenomenon.
However, in real-world scenarios, multi-view data are collected and constructed dynamically, which leads to an in-creasing number of views. For instance, a new view will be added to the original multi-view dataset after a new descrip-tion is proposed. Thus, a natural problem is, will the clus-tering performance of the multi-view model degrade when the number of views increases? Intuitively, data of the in-creased view contain both semantic features and meaning-less noise. The former can provide complementary infor-mation that is beneficial for improving clustering perfor-mance. The latter, however, may bring the risk of clustering performance degradation. That is, more views do not nec-essarily guarantee to promote the clustering performance.
Sometimes, on the contrary, conducting clustering on the dataset with more views may obtain worse results than that with fewer views. This performance degradation caused by view increase is observed in our experiments. As shown in
Figure 1, the clustering performance of some MVC meth-ods degenerates when the number of views increases, which verifies the fact that conducting clustering on datasets with more views will not always be better. Besides, single-view can be regarded as a special variant of multi-view. Thus, any multi-view model can be directly applied to obtain a single-view result on data of the new increased view. This result may perform better than the multi-view model, which has been verified and discussed in [34]. Therefore, how to re-duce the risk of clustering performance degradation caused by view increase should be considered from both single-view and multi-view aspects.
Although many solid MVC methods [25,28,30,42] have been proposed, the efforts to tackle the clustering perfor-mance degradation caused by view increase are still limited.
To this end, this work aims to design a new framework with theoretical guarantee that provides a lower bound perfor-mance guarantee for MVC methods, such that more views never hurt the clustering performance. We firstly give a for-mal and complete definition of safe multi-view clustering.
However, the main challenge of achieving safe multi-view clustering is that all the ground-truth labels are not avail-able. Thus, from the perspectives of empirical and expected clustering risk, we introduce the definitions of empirical and (ϵ, δ, δn)-expected safe multi-view clustering. Based on that, we propose a general deep learning based multi-view clustering framework. From the perspective of clus-tering and representation learning, the model is required to extract complementary information from multi-view data.
Meanwhile, from the perspective of safeness, the model is required to automatically select the features from a single view or multiple views, so that the features learned from the new increased view are discarded if it contains more meaningless noise than useful complementary information.
These two learning processes are cast as a unified optimiza-tion problem. In theory, the proposed framework is guaran-teed to achieve empirical safe multi-view clustering. Also, we discuss a special case of the proposed framework under divergence-based loss and prove that it can achieve the de-fined (ϵ, δ, δn)-expected safe multi-view clustering. Experi-ments on benchmark datasets demonstrate the effectiveness of the proposed learning mechanism to achieve safe multi-view clustering. 2.