Abstract
Attributed to both the development of deep networks and abundant data, automatic face recognition (FR) has quickly reached human-level capacity in the past few years. Howev-er, the FR problem is not perfectly solved in case of uncon-trolled illumination and pose. In this paper, we propose to enhance face recognition with a bypass of self-supervised 3D reconstruction, which enforces the neural backbone to focus on the identity-related depth and albedo information while neglects the identity-irrelevant pose and illumination information. Speciﬁcally, inspired by the physical model of image formation, we improve the backbone FR network by introducing a 3D face reconstruction loss with two auxiliary networks. The ﬁrst one estimates the pose and illumination from the input face image while the second one decodes the canonical depth and albedo from the intermediate feature of the FR backbone network. The whole network is trained in end-to-end manner with both classic face identiﬁcation loss and the loss of 3D face reconstruction with the physi-cal parameters. In this way, the self-supervised reconstruc-tion acts as a regularization that enables the recognition network to understand faces in 3D view, and the learnt fea-tures are forced to encode more information of canonical facial depth and albedo, which is more intrinsic and ben-eﬁcial to face recognition. Extensive experimental results on various face recognition benchmarks show that, without any cost of extra annotations and computations, our method outperforms state-of-the-art ones. Moreover, the learnt rep-resentations can also well generalize to other face-related downstream tasks such as the facial attribute recognition with limited labeled data. 1.

Introduction
With abundant data [2,8] and the development of margin-based loss functions [5, 17, 30, 31], great progresses have
Figure 1. Illustration of the proposed 3D bypass enhanced repre-sentation learning (3D-BERL). Inspired by the physical model of image formation, 3D-BERL incorporates a self-supervised 3D re-construction bypass to improve the face recognition. Besides, the shallow stages of the backbone can also serve as a good foundation model for downstream tasks such as facial attribute recognition with only limited labeled data. been achieved on face recognition. The accuracy on the fa-mous LFW benchmark [10] is almost perfect, e.g., 99.83% by ArcFace [5]. Even though, existing methods degenerate severely under large poses, various illuminations and partial occlusions. Face recognition under unconstrained scenarios still remains a challenging task. Unfortunately, convention-al methods with ﬁxed-margins do not ﬁt well with these fac-tors as they do not consider the difﬁcultness of each sample, and may result in convergence issue. To alleviate this prob-lem, AdaptiveFace [16], AdaCos [39], MagFace [20] and
CurricularFace [12] propose to dynamically tune the mar-gin during the training process. MagFace [20] proposes a quality assessment method to evaluate the face quality and then adaptively adjust its margins. To some extent, these adaptive margin methods have alleviated the convergence issue. However, the performance still degenerates when testing under large poses, various illuminations and occlu-sions as they do not explicitly consider kicking out identity-irrelevant features during training process.
An ideal solution is to annotate all the image factors of each face, and then disentangle these identity-irrelevant factors from the face embedding via multi-task supervised-learning. However, this kind of annotation is labor-intensive and is almost infeasible, especially when current face recog-nition training sets commonly contain millions of faces. To be free from this, we resort to another technology roadmap, namely self-supervise learning. Apart from supervised learning methods, it does not require manual annotation-s. Instead, the image representations are learnt via pretext tasks [7, 22] which commonly apply a transformation to the image and then enforce the neural network to predict the properties of the transformation. The self-supervised learn-ing has shown the potential to become an alternative ap-proach to learn feature representation. It even outperforms supervised learning methods on image classiﬁcation task.
However, the work in [27] has shown that the commonly used pretext tasks such as jigsaw puzzle [22] and rotation prediction [7] do not work well on face-related task. The possible reason is that it is hard to prevent existing pretex-t tasks collapse to trivial solutions for face images which have uniﬁed structure and similar textures.
In this paper, we propose a novel 3D Bypass Enhanced
Representation Learning (3D-BERL) method to improve face recognition under unconstrained scenarios. As shown in Fig 1, our 3D-BERL incorporates an auxiliary bypass of self-supervised 3D face reconstruction into traditional
Inspired by the physical 2D face recognition pathway. model of image formation, we carefully design two aux-iliary networks in the auxiliary bypass. The ﬁrst one es-timates the identity-irrelevant viewpoint (pose) and illumi-nation parameter, and the second one decodes the canon-ical depth and albedo from the intermediate block of ex-isting face recognition backbone (the stage 3 in ResNet).
The pose, illumination, depth and albedo are learnt by self-supervised 3D reconstruction, and the reconstruction pro-cess is based on the physical model of image formation.
Among these four factors, the learning of depth and albedo will enforce the shallow part of FR backbone (the stage 1, 2, 3 of ResNet [9]) to focus on the identity-relevant depth and albedo. Besides, as shown in our visualization in Fig 3, the image formation model has regularized both the depth and albedo to with a canonical view, meaning that the effect of pose and illumination is eliminated. Moreover, even if the face image is occluded, the prediction of depth is still good enough for face recognition. Then, the succeeding layers in the FR backbone can extract features robust to pose, illumi-nation and partial occlusion. Here, the self-supervised re-construction acts as a regularization that enables the recog-nition network to understand faces in 3D view. The whole network is trained in end-to-end manner with both classic face identiﬁcation loss and the loss of 3D face reconstruc-tion with the physical parameters. Extensive results on vari-ous face recognition benchmarks show that our method out-performs state-of-the-art methods without any cost of extra annotations.
Moreover, as seen in Fig 1, the deeper part of the back-bone (stage 4) acts as a face recognition speciﬁed head that focuses on learning the face embedding for recogniz-ing identities. In contrast, the shallow stages of the back-bone jointly supervised by both the FR task and the self-supervised 3D auxiliary task can provide a more founda-tional face representation. Here, we transfer these shallow stages to the facial attribute recognition task. Experiments show that it signiﬁcantly outperforms pervious method es-pecially when only limited labeled data are available.
Brieﬂy, the main contributions of this paper are summa-rized as follows:
• We propose a novel 3D bypass enhanced representa-tion learning (3D-BERL) method which improves face recognition by incorporating a self-supervised 3D re-construction bypass into traditional 2D face recogni-tion pathway.
• The self-supervised reconstruction in the proposed auxiliary bypass acts as a regularization that enables the recognition network to understand faces in 3D view and generate more robust face embedding under un-constrained scenarios.
• The proposed method outperforms state-of-the-art methods on various face recognition benchmarks, and the shallow stages of the backbone trained by our method can also serve as a good foundation model for downstream tasks such as facial attribute recognition with only limited labeled data. 2.