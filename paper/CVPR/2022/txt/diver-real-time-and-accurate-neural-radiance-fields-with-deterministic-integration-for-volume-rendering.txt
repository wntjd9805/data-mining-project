Abstract
DIVeR builds on the key ideas of NeRF and its variants – density models and volume rendering – to learn 3D object models that can be rendered realistically from small num-bers of images. In contrast to all previous NeRF methods,
DIVeR uses deterministic rather than stochastic estimates of the volume rendering integral. DIVeR’s representation is a voxel based field of features. To compute the volume rendering integral, a ray is broken into intervals, one per voxel; components of the volume rendering integral are es-timated from the features for each interval using an MLP, and the components are aggregated. As a result, DIVeR can render thin translucent structures that are missed by other integrators. Furthermore, DIVeR’s representation has se-mantics that is relatively exposed compared to other such methods – moving feature vectors around in the voxel space results in natural edits. Extensive qualitative and quantita-tive comparisons to current state-of-the-art methods show that DIVeR produces models that (1) render at or above state-of-the-art quality, (2) are very small without being baked, (3) render very fast without being baked, and (4) can be edited in natural ways. Our real-time code is available at: https://github.com/lwwu2/diver-rt 1.

Introduction
Turning a small set of images into a renderable model of a scene is an important step in scene generation, appearance modeling, relighting, and computational photography. The task is well-established and widely studied; what form the model should take is still very much open, with models rang-ing from explicit representations of geometry and material through plenoptic function models [1]. Plenoptic functions are hard to smooth, but neural radiance field (NeRF) [25] demonstrates that a Multi Layer Perceptron (MLP) with posi-tional encoding is an exceptionally good smoother, resulting in an explosion of variants (details in related work). All use one key trick: the scene is modeled as density and color functions, rendered using stochastic estimates of volume rendering integrals. We describe an alternative approach, de-terministic integration for volume rendering (DIVeR), which is competitive in speed and accuracy with the state of the art.
NeRF
PlenOctrees
DIVeR (Ours)
Ground Truth
Figure 1. Monte Carlo vs. feature integration. Methods like
NeRF [25] and PlenOctrees [55] that use Monte Carlo (stochastic) integrators fail to render the translucent drumhead; it is thin, and so is hit by few samples. NeRF’s estimator will not model it with practical numbers of samples. In contrast, our method uses a deterministic integrator which directly estimates the section of volume rendering integral near the drum plane through feature integration (Sec. 4.2); this uses fewer calls to the integrator and still successfully models the transparency.
We use a deterministic integrator because stochastic es-timates of integrals present problems. Samples may miss important effects (Fig. 1). Fixing this by increasing the sam-pling rate is costly: accuracy improves slowly in the number of samples N , (for Monte Carlo methods, standard devia-tion goes as 1/
N [4]), but the cost of computation grows linearly. In contrast, our integrator combines per-voxel esti-mates of the volume rendering integral into a single estimate using alpha blending (Sec. 4.2).
√
Like NSVF [21], we use a voxel based representation of the color and density. Rather than represent functions, we provide a feature vector at each voxel vertex. The feature vectors at the vertices of a given voxel are used by an MLP to compute the deterministic integrator estimate for the section of any ray passing through the voxel. Mainly, a model is
learned by gradient descent on feature vectors and MLP parameters to minimize the prediction error for the training views; it is rendered by querying the resulting structure with new rays. Sec. 4 provides the details.
Given similar computational resources, our model is ef-ficient to train, likely because the deterministic integration can fit the integral better, and there is no gradient noise pro-duced by stochastic integral estimates. As Sec. 5 shows, the procedure results in very small models (∼ 64MB) which render very fast (∼ 50 FPS on a single 1080 Ti GPU) and have comparable PSNR with the best NeRF models. 2.