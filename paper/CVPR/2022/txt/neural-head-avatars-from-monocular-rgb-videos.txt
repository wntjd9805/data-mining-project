Abstract 1.

Introduction
We present Neural Head Avatars, a novel neural repre-sentation that explicitly models the surface geometry and appearance of an animatable human avatar that can be used for teleconferencing in AR/VR or other applications in the movie or games industry that rely on a digital human.1
Our representation can be learned from a monocular RGB portrait video that features a range of different expressions and views. Speciﬁcally, we propose a hybrid representa-tion consisting of a morphable model for the coarse shape and expressions of the face, and two feed-forward networks, predicting vertex offsets of the underlying mesh as well as a view- and expression-dependent texture. We demonstrate that this representation is able to accurately extrapolate to unseen poses and view points, and generates natural ex-pressions while providing sharp texture details. Compared to previous works on head avatars, our method provides a disentangled shape and appearance model of the complete human head (including hair) that is compatible with the standard graphics pipeline. Moreover, it quantitatively and qualitatively outperforms current state of the art in terms of reconstruction quality and novel-view synthesis.
* Both authors contributed equally to the paper 1philgras.github.io/neural_head_avatars/neural_head_avatars.html
Reconstructing and reenacting human heads has been a long studied research problem and will be a key driver for future applications in VR/AR, teleconferencing, games and the movie industry. For those applications, it is of particular interest to get an accurate 3D shape and appearance model that provides 3D consistency and strong identity preserva-tion under novel view points, poses and expressions. Re-constructing such a model, especially from monocular input data (e.g., from a webcam), is difﬁcult due to the complex geometry of facial dynamics and the missing 3D informa-tion [86]. Indeed, several state-of-the-art methods for talk-ing head synthesis avoid explicit geometry reconstruction and rely on image or feature-based warping for motion con-trol and generative networks for image synthesis [64,74,82].
These methods are generalized and deliver impressive reen-actment results even with only a single input image of the subject. However, the quality of the approaches drops sig-niﬁcantly for larger changes in pose or view point as no 3D-consistent geometry representation is used. Shape proxies such as a 3D morphable model [9, 26] can be utilized to im-prove the 3D consistency of synthetic faces [15, 40, 69, 71] since the facial information is embedded on the proxy sur-face. Besides image- or surface-based representations, vol-umetric representations are used [29, 46]. While they show promising results without an explicit surface prior, these methods still lack a consistent full head shape reconstruc-tion from single view inputs and are not compatible with the standard rasterization pipelines.
In this work, we present Neural Head Avatars, an ex-plicit shape and appearance representation of the complete human head (including hair) which can be used in exist-ing graphics pipelines that use triangular meshes. Speciﬁ-cally, we employ coordinate-based multi-layer perceptrons (MLPs) to predict the 3D meshes and dynamic textures, de-pending on the facial expression and pose of real humans.
These networks are embedded on the surface of the FLAME morphable head model [43] which also serves as a coarse shape and expression proxy. We show that one can opti-mize such an explicit head representation based on a short monocular RGB video sequence. Using color-dependent and color-independent energy terms during optimization, we disentangle the reconstruction of surface geometry and color detail. The resulting controllable 4D avatar (3D model
+ motion) is subject-speciﬁc and generates novel poses and expressions while preserving high photo-realism. More-over, it demonstrates great visual quality under large view point changes and, therefore, addresses one of the main drawbacks of related approaches.
In summary, our contributions are:
• Neural Head Avatars, a novel, subject-speciﬁc repre-sentation for articulated human heads that explicitly re-constructs the full head geometry and produces photo-realistic results even under large view point changes,
• A fully differentiable optimization pipeline to optimize
Neural Head Avatars from a short, monocular RGB video with color-dependent and color-independent en-ergy terms that allow for the disentanglement of the surface shape and color detail. 2.