Abstract
Shadow removal, which aims to restore the background in the shadow regions, is challenging due to its highly ill-posed nature. Most existing deep learning-based meth-ods individually remove the shadow by only considering the content of the matched paired images, barely taking into account the auxiliary supervision of shadow genera-tion in the shadow removal procedure.
In this work, we argue that shadow removal and generation are interrelat-ed and could provide useful informative supervision for each other. Speciﬁcally, we propose a new Bijective Map-ping Network (BMNet), which couples the learning proce-dures of shadow removal and shadow generation in a u-niﬁed parameter-shared framework. With consistent two-way constraints and synchronous optimization of the two procedures, BMNet could effectively recover the underlying background contents during the forward shadow removal procedure. In addition, through statistical analysis of real-world datasets, we observe and verify that shadow appear-ances under different color spectrums are inconsistent. This motivates us to design a Shadow-Invariant Color Guidance
Module (SICGM), which can explicitly utilize the learned shadow-invariant color information to guide network col-or restoration, thereby further reducing color-bias effects.
Experiments on the representative ISTD, ISTD+ and SRD benchmarks show that our proposed network outperform-s the state-of-the-art method [11] in de-shadowing perfor-mance, while only using its 0.25% network parameters and 6.25% ﬂoating point operations (FLOPs). 1.

Introduction
Shadows are cast when light sources are fully or partial-ly blocked by objects and are common in various natural
∗Corresponding author, † co-ﬁrst authors contributed equally. This work was supported by the National Key R&D Program of China un-der Grant 2020AAA0105702, the National Natural Science Foundation of China (NSFC) under Grants U19B2038 and 61901433, the Universi-ty Synergy Innovation Program of Anhui Province under Grants GXXT-2019-025, the USTC Research Funds of the Double First-Class Initiative under Grant YD2100002003.
Figure 1. Visual comparisons with state-of-the-art methods on a real-world shadow scene. (a) to (c): Param+M+D-Net [28], Fu et al. [11], G2R [34]. (d) and (e) are the color map of the input image and our learned shadow-invariant color map, respectively. scenes. However, shadows often present challenges for a variety of existing computer vision tasks, e.g., object track-ing [38] and detection [35], face recognition [49], etc. Con-sequently, shadow removal has been studied for a long time as one of the fundamental computer vision tasks.
Currently, much attention has been drawn to recovering the shadow region contents from a shadow image. Existing traditional model-methods broadly come in two ﬂavors: based techniques and deep learning-based methods. Tradi-tional shadow removal methods rely on the priors of shadow images , e.g., image gradients [15], illumination [44] and regions [16, 39]. However, due to these priors limitations, the traditional methods often are not effective to handle the shadows in complicated real shadow scenes [23].
Recently, deep learning has achieved remarkable success in various computer vision tasks [6,12,13,21,22,36], which also includes shadow removal and gradually dominated this
ﬁeld. Le et al. [27, 28] attempt to build a linear shadow il-lumination model to characterize the mapping relationship between the shadow image Is and the shadow-free image
Isf . DSC [19] and DHAN [5] exploit the global and multi-context features to better remove shadows by designing the direction-aware spatial attention module or the growth dilat-ed convolutions. Moreover, recently some methods [5, 34] attempt to exploit the shadow generation to obtain a large number of pseudo shadow pairs as network training data to boost the de-shadowing performance. However, most of
these methods may easily ignore the shadow generation pro-cedure, as the inverse operation of shadow removal, could also provide auxiliary informative supervision for the shad-ow removal procedure.
In this paper, we propose a Bijective Mapping Network (BMNet) to accurately recover the underlying content in the shadow regions. Speciﬁcally, our BMNet is composed of the forward and backward mapping procedures with the help of conditional inputs C, i.e., shadow masks and col-or maps. Similar to previous methods [11, 34], the forward mapping process aims at learning a nonlinear function F(·) to transfer the shadow images Is to their shadow-free ver-sion Isf .
Ideally, if the forward mapping function Isf =
F(Is, C; θ) is optimal, the input shadow image Is should be reconstructed closely through the reverse mapping F−1(Isf ,
C; θ). Such reverse mapping procedure could provide the regular constraint and informational supervision to improve the forward mapping performance [17]. Our method u-tilizes such a supplementary mechanism to push the esti-mated shadow-free images ˆIsf close to the ground truth.
With respect to the above key idea, we naturally implemen-t it based on the advanced invertible frameworks [2, 4, 50].
In addition, we notice the shadow removed results of the many shadow removal methods exist obvious color-bias ef-fect, as shown in Figure 1. By conducting statistical analy-sis on real-world shadow datasets, we observe that shadow appearances are different under different color spectrums.
This observation motivates us to devise a Shadow-Invariant
Color Guidance Module (SICGM) to explicitly employ the learned shadow-invariant color information to guide the col-or restoration. Different from previous methods [11, 27, 34] using only a single scale of shadow mask information, our
SICGM integrates both the color and mask information in-to the network in a multi-scale fashion. With the guidance of the additional shadow-invariant color cues, our method could further reduce the color-bias effect. In summary, our contributions are as follows:
• We propose a new shadow removal framework, which couples the procedures of shadow removal (forward mapping) and generation (reverse mapping) in the same parameters-shared bijective mapping network (BMNet). Two procedures are synchronously op-timized with consistent two-way constraints, which could beneﬁt from each other and improve the overall de-shadowing performance.
• We propose a Shadow-Invariant Color Guidance Mod-ule in the BMNet, which explicitly incorporates the shadow-invariant color information to guide the de-sired color restoration of shadow regions, therefore further solving the color-bias issue.
• Comprehensive experiments on the public ISTD, IST-D+, and SRD datasets demonstrate that our proposed
Figure 2. (a) A simpliﬁed visual representation of one pair of real-world shadow images statistics process based on the Eqn. (1) and (2). We could ﬁnd that the attenuation appearances of the shadows under different RGB color spectrums are obviously different. (b)
Statistics of shadow effects of different RGB basic color spectrum-s on the real-world ISTD test dataset. Due to the space limitation, here we present the statistical results of the top 30% image pairs in order based on the Eqn. (3). To highlight the difference, the log-arithmic transformation is performed. It is clear that the shadow effects measurement values on the three RGB spectrums corre-sponding to most images are obviously different. Red, Green, and
Blue are the three primary colors of color space. Hence, we argue the degrees of shadow effects under different color spectrums are different based on the statistical results. (Best viewed on screen.) method achieves superior performance with very few network parameters and computational costs, e.g., on-ly 0.25% parameters and 6.85% the ﬂoating point op-erations of the SOTA method [11]. 2.