Abstract
This paper presents a high-quality human motion pre-diction method that accurately predicts future human poses given observed ones. Our method is based on the observa-tion that a good “initial guess” of the future poses is very helpful in improving the forecasting accuracy. This mo-tivates us to propose a novel two-stage prediction frame-work, including an init-prediction network that just com-putes the good guess and then a formal-prediction network that predicts the target future poses based on the guess.
More importantly, we extend this idea further and design a multi-stage prediction framework where each stage pre-dicts initial guess for the next stage, which brings more performance gain. To fulﬁll the prediction task at each stage, we propose a network comprising Spatial Dense
Graph Convolutional Networks (S-DGCN) and Temporal
Dense Graph Convolutional Networks (T-DGCN). Alterna-tively executing the two networks helps extract spatiotem-poral features over the global receptive ﬁeld of the whole pose sequence. All the above design choices cooperating together make our method outperform previous approaches by large margins: 6%-7% on Human3.6M, 5%-10% on
CMU-MoCap, and 13%-16% on 3DPW. Code is available at https://github.com/705062791/PGBIG. 1.

Introduction
Human Motion Prediction (HMP) is a fundamental re-search topic that beneﬁts many other applications such as intelligent security, autonomous driving, human-robot inter-action and so on. Early works employed nonlinear Markov models [24], Gaussian Process dynamical models [46], and
Restricted Boltzmann Machine [43] to tackle this problem, while recently a large number of methods based on deep
*Corresponding author: nieyongwei@scut.edu.cn (cid:1)(cid:7)(cid:3)(cid:2) (cid:1)(cid:7)(cid:2)(cid:2) (cid:1)(cid:6)(cid:2) (cid:13) (cid:14) (cid:13) (cid:13) (cid:12) (cid:11) (cid:8) (cid:1) (cid:1)(cid:5)(cid:2) (cid:22)(cid:15)(cid:11)(cid:1)(cid:19)(cid:5)(cid:6)(cid:23)(cid:2)(cid:6)(cid:21) (cid:22)(cid:15)(cid:11)(cid:1)(cid:24)(cid:16)(cid:25)(cid:26)(cid:1)(cid:27)(cid:18)(cid:28)(cid:29)(cid:30)(cid:9)(cid:1)(cid:19)(cid:9)(cid:4)(cid:23)(cid:8)(cid:10)(cid:21) (cid:22)(cid:15)(cid:11)(cid:1)(cid:24)(cid:16)(cid:25)(cid:26)(cid:1)(cid:27)(cid:18)(cid:28)(cid:29)(cid:30)(cid:7)(cid:2)(cid:1)(cid:19)(cid:4)(cid:4)(cid:23)(cid:9)(cid:6)(cid:21) (cid:22)(cid:15)(cid:11)(cid:1)(cid:24)(cid:16)(cid:25)(cid:26)(cid:1)(cid:27)(cid:18)(cid:28)(cid:29)(cid:30)(cid:7)(cid:9)(cid:1)(cid:19)(cid:8)(cid:10)(cid:23)(cid:7)(cid:5)(cid:21) (cid:22)(cid:15)(cid:11)(cid:1)(cid:24)(cid:16)(cid:25)(cid:26)(cid:1)(cid:27)(cid:18)(cid:28)(cid:29)(cid:30)(cid:3)(cid:2)(cid:1)(cid:19)(cid:8)(cid:3)(cid:23)(cid:2)(cid:10)(cid:21) (cid:22)(cid:15)(cid:11)(cid:1)(cid:24)(cid:16)(cid:25)(cid:26)(cid:1)(cid:27)(cid:18)(cid:28)(cid:29)(cid:30)(cid:3)(cid:9)(cid:1)(cid:19)(cid:3)(cid:31)(cid:23)(cid:10)(cid:5)(cid:21) (cid:1)(cid:4)(cid:2) (cid:1)(cid:3)(cid:2) (cid:1)(cid:2) (cid:6)(cid:2) (cid:7)(cid:5)(cid:2) (cid:8)(cid:3)(cid:2) (cid:4)(cid:2)(cid:2) (cid:9)(cid:5)(cid:2) (cid:10)(cid:3)(cid:2) (cid:6)(cid:6)(cid:2) (cid:7)(cid:2)(cid:2)(cid:2) (cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:17)(cid:20)(cid:21) (a)
Intermediate Target
Input
Init-Prediction 
Network
Initial 
Guess (b)
Formal 
Prediction 
Network
Output
Figure 1. (a) Toy experiments. Given 10 poses, we predict 25 poses. The frame rate is 25fps, and 25 poses last 1000ms. We use
LTD [33] as the baseline which uses the last observed pose as the initial guess. At test time, the average prediction error of LTD is 68.08. We conduct another 5 experiments training and testing LTD with Mean-x as the initial guess. That is, Mean-x is duplicated and appended to the past poses where “Mean-x” is the mean of the ﬁrst future x poses with x belonging to {5, 10, 15, 20, 25}. As x increases, the average prediction error signiﬁcantly decreases, meaning that when used as initial guess, “Mean-x” is better than the last observed pose, and the larger the x the better. The curves in the ﬁgure plot the prediction error at every forecasting time. (b)
Our two-stage prediction framework comprising an init-prediction network and a formal-prediction network. The init-prediction net-work is supervised by an intermediate target. learning have emerged, showing signiﬁcant merits.
Due to the sequential nature of pose sequences, HMP is mostly tackled with Recurrent Neural Networks (RNN)
[5, 6, 13–18, 22, 31, 34–36, 42]. However, RNN-based ap-proaches usually yield problems of discontinuity and er-ror accumulation which might be due to the training dif-ﬁculty of RNNs. There are a few works that employ Con-volutional Neural Networks (CNN) to solve the HMP prob-lem [3,8,26,39]. They treat a pose sequence as an image and apply 2D convolutions to the pose sequence, but poses are essentially not regular data which limits the effectiveness of the 2D convolutions. Recently, lots of works demonstrate that Graph Convolutional Networks (GCN) is very suitable for HMP [2, 7, 9, 10, 23, 25, 27–29, 32, 33]. They treat a hu-man pose as a graph by viewing each joint as a node of the graph and constructing edges between any pair of joints.
GCNs are then used to learn spatial relations between joints which beneﬁt the pose prediction.
We observe that starting from the seminal work of
LTD [33], all recent GCN-based approaches [9, 10, 32, 40] share the following preprocessing steps: (1) They duplicate the last observed pose as many times as the length of the future pose sequence, and append the duplicated poses to the observed sequence to form an extended input sequence. (2) Similarly, the ground truth future poses are appended to the observed poses to obtain the extended ground truth output sequence. Their proposed networks are used to pre-dict from the extended input sequence to the extended out-put sequence instead of from the original observed poses to the future poses. Ablation comparisons show that the pre-diction between the extended sequences is easier than be-tween the original sequences, and the former achieves sig-niﬁcantly better prediction accuracy than the latter. Dang et al. [10] ascribed this to the global residual connection between the extended input and output, while in this paper we interpret this phenomenon from another perspective: the last observed pose provides an “initial guess” for the target future poses. From the initial guess, the network just needs to move slightly such that it can reach the target positions.
However, we argue that the last observed pose is not the best initial guess. For example, the toy experiments in Figure 1 (a) show that the mean pose of future poses is better than the last observed pose as the initial guess.
The problem is that we do not really know the mean pose of the future poses. Thus as shown in Figure 1 (b), using the mean of future poses as intermediate target, we propose to predict the mean of the future poses ﬁrstly and then pre-dict the ﬁnal target future poses by viewing the predicted mean as the initial guess. Although the predicted mean is not as good as the ground truth mean when used as the ini-tial guess, it is better than the last observed pose. Further, for more accuracy gain, we extend the two-stage prediction strategy to a multi-stage version. To this end, we recur-sively smooth the ground truth output sequence, obtaining a set of sequences at different smoothing levels. By treating these smoothed results as intermediate targets at the mul-tiple stages, our multi-stage prediction framework progres-sively predicts better initial guesses towards the next stages until the ﬁnal target pose sequence obtained.
Any existing human motion prediction model such as
[26, 33, 34] can be used to accomplish the prediction task at each of our stages. Among them, we choose GCN as the buildingblock to construct our multi-stage framework.
Existing GCN-based approaches [9, 10, 33] only employ
GCN to extract spatial features. Instead of them, we pro-pose to process both spatial and temporal features by GCNs.
Speciﬁcally, we propose S-DGCN and T-DGCN. S-DGCN views each pose as a fully-connected graph and encodes global spatial dependencies in human pose, while T-DGCN views each joint trajectory as a fully-connected graph and encodes global temporal dependencies in motion trajectory.
S-DGCN and T-DGCN together extract global spatiotempo-ral features, which further improve our prediction accuracy.
In summary, the main contributions of this paper are three-fold:
• We propose a novel multi-stage human motion predic-tion framework utilizing recursively smoothed results of the ground truth target sequence as the intermediate targets, by which we progressively improve the initial guess of the ﬁnal target future poses for better predic-tion accuracy.
• We propose a network based on S-DGCN and T-DGCN that extracts global spatiotemporal features ef-fectively to fulﬁll the prediction task at each stage.
• We conduct extensive experiments showing that our method outperforms previous approaches by large margins on three public datasets. 2.