Abstract
Existing works have identiﬁed the limitation of top-1 at-tack success rate (ASR) as a metric to evaluate the attack strength but exclusively investigated it in the white-box set-ting, while our work extends it to a more practical black-box setting: transferable attack. It is widely reported that stronger I-FGSM transfers worse than simple FGSM, lead-ing to a popular belief that transferability is at odds with the white-box attack strength. Our work challenges this belief with empirical ﬁnding that stronger attack actually transfers better for the general top-k ASR indicated by the interest class rank (ICR) after attack. For increasing the attack strength, with an intuitive analysis on the logit gra-dient from the geometric perspective, we identify that the weakness of the commonly used losses lie in prioritizing the speed to fool the network instead of maximizing its strength.
To this end, we propose a new normalized CE loss that guides the logit to be updated in the direction of implicitly maximizing its rank distance from the ground-truth class.
Extensive results in various settings have veriﬁed that our proposed new loss is simple yet effective for top-k attack.
Code is available at: https://bit.ly/3uCiomP 1.

Introduction
Deep neural networks (DNNs) are widely known to be vulnerable to adversarial examples [15,16,39,43], which are crafted by adding imperceptible or quasi-imperceptible per-turbations to natural images. This intriguing phenomenon has inspired a vibrant ﬁeld of studying the model robust-ness [30, 32, 36, 40]. One intriguing property of adversarial examples is the widely known transferability from one (sur-rogate) model to another (target) model [12, 25]. This prop-erty has been exploited for the transferable black-box attack as well as enhancing query-based black-box attack [19].
It is widely reported that I-FGSM increases the attack strength of FGSM, but at the cost of a lower transfer rate.
This leads to a popular belief that the white-box strength of an attack is at odds with its transferability [22]. Lower transfer rates of I-FGSM are often attributed to the conjec-ture that longer iterations lead to over-ﬁtting to the surro-gate model [6, 22]. Partly due to this concern, convention-ally, existing works on transferable attack often adopt a lim-ited number of iterations T , typically set to (cid:15)/α where (cid:15) and α are the maximum L∞ budget and step size, respec-tively. In contrast, we show that this phenomenon can be at least partially explained by the lower perturbation magni-tude of I-FGSM and a larger T improves the transferability, eventually outperforming FGSM given a sufﬁciently large
T . We further demonstrate that complementary to existing techniques, increasing T consistently enhances the transfer-ability and then saturates to a plateau.
Conventionally, attack success rate (ASR), also called fooling ratio (FR), is commonly used for evaluating strength in white-box, and transferability in black-box attacks. How-ever, ASR does not provide an in-depth indication of attack strength.
In essence, ASR only indicates whether an in-terest class, ground-truth class in the non-targeted or target class in targeted setting, ranks top-1 in the adversarial ex-It would be interesting to know the ASR@k, i.e. ample. beyond from top-1 to top-k, to have a wide-range evalua-tion of attack strength. To this end, we introduce a new metric termed interest class rank (ICR), which facilitates the ASR@k evaluation and, more importantly constitutes a single uniﬁed value indicating the top-k attack strength.
Increasing T enhances both top-k adversarial strength and transferability, suggesting top-k attack strength is also transferable. However, simply increasing the T is not enough to lead to a strong top-k attack. We identify that the reason lies in the commonly used cross-entropy (CE) loss or C&W loss which prioritize the speed of fooling the network instead of maximizing its distance from the in-terest (ground-truth) class. To this end, we propose Rel-ative Cross-Entropy (RCE) loss for boosting stronger top-k attack. Our new loss achieves close-to-optimal top-k strength in white-box attack, outperforming existing losses by a large margin, consequently leading to a stronger top-k transferable attack.
Contributions. Our work is the ﬁrst to attempt the task of top-k transferable attack. A major obstacle towards this task is a popular belief on strength and transferability, which
we challenge by showing that increasing T enhances both and that top-k attack strength is transferable. We identify the limitation of existing losses and propose a new loss for achieving a strong top-k attack in both white-box and trans-ferable black-box settings. We extensively validate its ef-ﬁcacy for benchmarking top-k strength and transferability of adversarial examples on multiple datasets. Our proposed
ICR metric for evaluating top-k attack also provides a uni-ﬁed perspective for non-targeted and targeted setups. 2.