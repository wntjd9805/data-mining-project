Abstract
It is well known that deep neural networks (DNNs) pro-duce poorly calibrated estimates of class-posterior prob-abilities. We hypothesize that this is due to the limited calibration supervision provided by the cross-entropy loss, which places all emphasis on the probability of the true class and mostly ignores the remaining. We consider how each example can supervise all classes and show that the calibration of a C-way classification problem is equivalent to the calibration of C(C − 1)/2 pairwise binary classifi-cation problems that can be derived from it. This suggests the hypothesis that DNN calibration can be improved by providing calibration supervision to all such binary prob-lems. An implementation of this calibration by pairwise constraints (CPC) is then proposed, based on two types of binary calibration constraints. This is finally shown to be implementable with a very minimal increase in the complex-ity of cross-entropy training. Empirical evaluations of the proposed CPC method across multiple datasets and DNN architectures demonstrate state-of-the-art calibration per-formance. 1.

Introduction
Deep neural networks (DNNs), especially deep convo-lutional neural networks, have enabled significant advances in computer vision [17,23]. While achieving state-of-the-art accuracy in various tasks such as image recognition [8, 43] and segmentation [25, 41], DNNs do not excel at estimat-ing the confidence of their predictions. Although they out-put class-posterior probabilities via softmax regression, it is well known that these predictive probabilities are usually poorly calibrated. Frequently, DNNs tend be overconfident, assigning high confidence to incorrect predictions [5, 6, 34].
For many real-world applications (e.g. weather forecast-ing [3, 29, 30], medical diagnosis [13]), it is important that a classifier output not only accurate predictions but also sound estimates of confidence in these predictions. This is known as calibration. For a calibrated classifier, a poste-Figure 1. Efficiency of CPC supervision for calibration. Left: Un-der classic cross-entropy training, each training example only pro-vides significant supervision to the posterior probability of its class label. Right: Under CPC, each training example provides signifi-cant supervision to the probabilities of all classes. rior probability of p for a given class, implies that selecting the class will result in the correct classification p × 100% of the time. Consider, for example, a medical diagnosis setting where a diagnostic accuracy above 95% is required for any system to be considered “human equivalent”. A di-agnostic classifier with accuracy of 80% fails to meet this criterion. However, if the classifier can accurately predict the posterior probabilities associated with its predictions, it can still be useful: Predictions with posterior probabili-ties above 95% can be accepted automatically, and only the examples of predictions with lower confidence need to be routed to human doctors. Since all the “easy” cases tend to be in the first class, this can reduce the need for human inspection to a relatively small batch of “hard” examples, saving significant time and expense. For these reasons, the probability calibration of DNNs is attracting increasing at-tention in the computer vision and machine learning com-munities [18, 19, 21, 27, 35, 48, 52, 56].
Various methods have been proposed to calibrate DNN
to 1. Hence, a high probability for the true class implies low probabilities for all the alternative classes. This con-straint is quite strong for binary classification problems (C = 2), where there is only one alternative class, but de-grades as C increases, since it is diffused by C − 1 alter-native classes. This suggests the hypothesis that calibration can be strengthened by providing calibration supervision to all class pairs, namely the C(C − 1)/2 binary classification problems that can be derived from Y. We denote this as calibration by pairwise constraints (CPC). In this way, as illustrated in Figure 1, each training example can provide supervision to the posterior probabilities of all classes, sig-nificantly increasing the degree of supervision over that of cross-entropy training.
In this paper, we start by showing that the proposed
CPC has strong theoretical grounding, in that the multiclass posterior probability estimators {πy}y∈Y are calibrated if and only if all the derived binary posterior probability es-are calibrated. This pro-timators
βij = πi (cid:110) (cid:111)
πi+πj i̸=j∈Y vides a simple explanation as to why vanilla DNNs are poorly-calibrated, which is illustrated in Figure 2. The fig-ure shows that the binary posterior estimators {βij}ij of a cross-entropy DNN are poorly calibrated in two aspects.
First, as shown at the top, when binary estimators that in-volve the true class y make incorrect predictions, these pre-dictions tend to have high confidence. Second, for binary problems that do not involve the true class, estimators βij (y ̸= i, j) mostly assign examples to either class i or j with high confidence, instead of producing uncertain predictions.
We then argue that the calibration efficiency of cross-entropy training of a multiclass DNN can be increased by calibrating the binary posterior estimations {βij}ij, using losses of two types. For class pairs that include the true class y, i.e. {(i, j)|y ∈ {i, j}}, the binary cross-entropy loss is used to encourage βij to assign high probability to class y and low probability to the opposite class. For the remain-ing pairs {(i, j)|y /∈ {i, j}}, an alternative loss is used to encourage βij to give uncertain predictions, outputting the same posterior probability for classes i, j.
We finally show that this approach of CPC can be imple-mented with high computational simplicity. This follows from the fact that the bulk of the computations required by the proposed binary losses are already performed dur-ing the standard cross-entropy training of a multiclass net-work.
In fact, we show that the additional losses can be computed by a simple addition of C(C − 1)/2 sigmoid functions at the top of the network. Hence, CPC allows improved calibration with no increase of memory or time complexity during test and a minor increase in training com-plexity. Empirical evaluations show that, despite this, CPC calibration achieves state-of-the-art calibration performance across multiple datasets and DNN architectures. The cali-bration gains of CPC are also shown to increase with the
Figure 2. Histograms of the binary posterior probabilities βij(x) produced by a ResNet-101 on CIFAR-100. Top: Examples that belong to the class j and are assigned to the class i. Bottom: Ex-amples whose labels are neither class i nor j. probability estimates in the literature, including but not limited to post-processing [6, 38], Bayesian approxima-tion [2, 5], regularization [28, 47], and deep ensemble [22].
These methods have different trade-offs between calibra-tion performance, memory, and computation complexity, with no clear winner when all factors are considered. Their performances also tend to degrade drastically under data shifts [35], i.e. when test examples are corrupted or per-turbed [9], a common occurrence for practical applications.
Hence, there is a need for robust calibration strategies of low memory footprint and computational complexity.
In this work, we consider this problem, aiming to derive methods that regularize the training of a DNN to encour-age better calibration. We address the multiclass classifica-tion problem of label set Y = {1, 2, · · · , C} and hypoth-esize that poor calibration is due to the inefficient super-vision provided by the cross-entropy loss during network training. By establishing as the learning target for each ex-ample the one-hot code of the associated class label, this loss encourages myopic training algorithms, which place all emphasis on the posterior probability of the true class and mostly ignore the posterior probabilities of the remaining classes. This is illustrated in Figure 1 where, under classic cross-entropy training, each training example only provides explicit supervision to the posterior probability of the class of the example. While very effective in terms of classifi-cation accuracy, this is very inefficient supervision for the purposes of calibration.
To increase the amount of calibration supervision pro-vided per training example, we consider how an exam-ple can supervise the classes other than that of its true la-bel. We note that cross-entropy training does this through the constraint that class-posterior probabilities must sum
number of classes and example scarcity, i.e. they are larger for smaller training sets. These observations confirm that
CPC increases the rate of calibration supervision provided by each example.
Overall, this work makes five contributions. The first is the hypothesis, illustrated in Figures 1 and 2, that the limited supervision provided by the cross-entropy loss for calibration is an important reason for the poor calibration performance of DNNs. The second is the hypothesis that the problem can be addressed through the proposed CPC.
The third is theoretical evidence in support of this hypoth-esis, by showing that the multiclass problem can only be calibrated if all derived binary classifiers are. The fourth is showing that, for DNNs, CPC can be implemented with minimal complexity. Finally, it is shown that training with
CPC indeed enables significant improvements in calibration performance, is complementary to existing approaches such as deep ensembles, and enables state-of-the-art calibration performance for several network architectures and datasets. 2.