Abstract
Existing approaches for Structure from Motion (SfM) pro-duce impressive 3-D reconstruction results especially when using imagery captured with large parallax. However, to create engaging video-content in movies and TV shows, the amount by which a camera can be moved while ﬁlming a particular shot is often limited. The resulting small-motion parallax between video frames makes standard geometry-based SfM approaches not as effective for movies and TV shows. To address this challenge, we propose a simple yet effective approach that uses single-frame depth-prior ob-tained from a pretrained network to signiﬁcantly improve geometry-based SfM for our small-parallax setting. To this end, we ﬁrst use the depth-estimates of the detected key-points to reconstruct the point cloud and camera-pose for initial two-view reconstruction. We then perform depth-regularized optimization to register new images and trian-gulate the new points during incremental reconstruction.
To comprehensively evaluate our approach, we introduce a new dataset (StudioSfM) consisting of 130 shots with 21K frames from 15 studio-produced videos that are man-ually annotated by a professional CG studio. We demon-strate that our approach: (a) signiﬁcantly improves the quality of 3-D reconstruction for our small-parallax set-ting, (b) does not cause any degradation for data with large-parallax, and (c) maintains the generalizability and scalability of geometry-based sparse SfM. Our dataset can be obtained at https://github.com/amazon-research/small-baseline-camera-tracking. 1.

Introduction
Estimating camera motion and 3-D scene geometry in movies and TV shows is a standard task in video produc-tion. Existing Structure from Motion (SfM) approaches for 3-D scene reconstruction produce high-quality results espe-cially for images with large parallax [16, 6, 36, 34]. How-ever, creating engaging viewing experience in movies and
TV shows often constrains the amount of camera movement while ﬁlming a shot. This often leads to insufﬁcient paral-*This work was done when the author was an intern at Amazon.
Figure 1: Comparison of Parallax-Distribution: Parallax-distribution of ETH3D [34] is plotted with StudioSfM – a new dataset with 21K frames in 130 manually annotated shots from 15
TV episodes (see § 4.1 for details of data and computation of par-allax). The long-tail distribution of StudioSfM shows that small-motion parallax is signiﬁcantly more common in studio-produced content than in standard SfM datasets. lax compared to standard SfM datasets captured speciﬁcally for 3-D reconstruction (see Figure 1 for more details).
This insufﬁcient parallax is one of the key challenges [9] that limits the effectiveness of well-developed geometry-based SfM approaches [10, 2, 33, 1, 43, 28] that recover camera motion and geometry based on the principle of motion-parallax. Shots with small motion-parallax are ill-conditioned for 3-D reconstruction as algebraic methods for two-view reconstruction are numerically unstable in such situations [26]. Conventional SfM pipelines (e.g.,
COLMAP [33]) use various heuristics to handle small-parallax data, e.g., by using inlier ratio to decide the two-view motion type to prevent two-view reconstruction from using panoramic image pairs, and ﬁltering out points with small triangulation angles. These heuristics however re-quire careful tuning and can fail completely when using data which has no image pairs with sufﬁcient parallax.
In contrast, learning-based approaches [17, 47, 40, 42] are able to handle data with small parallax more effectively as they can learn to predict depth and pose from large-scale labelled datasets. However, as these methods do not incor-porate geometric-consistency constraints between images,
Figure 2: Proposed Pipeline – Given a set of input images (Step 1), we detect 2-D keypoints and match them across frames, i.e., correspondence search (Step 2-a), as well as use a pretrained network to obtain their single-frame based dense depth-maps (Step 2-b). We apply bi-linear interpolation to look-up the depths of the detected key-points from these dense depth-maps (Step 3). We use the detected 2-D keypoints along with their depth-priors to improve the initialization (Step 4) and incremental reconstruction steps (Step 5). their pose and depth estimates are not as accurate [19]. Fur-thermore, the generalizability of these approaches heavily depends on the scale of labeled data used for their training, which can be laborious and expensive to collect.
Recently proposed hybrid approaches [37, 38, 19] have achieved more accurate results than learning-based ap-proaches by employing learned depth priors as implicit constraints for geometric consistency. However, these ap-proaches do not use robust estimators thus making them heavily dependent on the quality of used optical ﬂow which can adversely affect their robustness. Moreover, these ap-proaches require heavy compute and memory resources.
This prevents them from scaling to larger problems.
Key Contributions: To address these challenges, we pro-pose a novel hybrid approach that combines the strengths of: (a) geometry-based SfM to achieve high-accuracy with-out requiring additional labelled data, and (b) learning-based SfM to effectively handle data with insufﬁcient par-allax. As illustrated in Figure 2, our approach builds on the standard geometry-based SfM pipeline and particularly improves its initialization and incremental reconstruction steps by leveraging single-frame depth-priors obtained from a pretrained deep network. Speciﬁcally:
• Instead of using epipolar geometry for initial two-view re-construction, we directly utilize monocular depth obtained from a pretrained model to accurately recover the initial camera pose and point cloud.
• During the incremental reconstruction step, we propose a depth-prior regularized objective function to be able to accurately register and triangulate new images and points.
We demonstrate that our approach is robust to a variety of pretrained networks used to obtain the depth-prior, and maintains the generalizability and scalability of geometry-based SfM pipeline by maximally relying on its well-engineered implementations (e.g. COLMAP [33]).
To comprehensively evaluate our approach, we collect a new dataset (StudioSfM) containing 130 shots with 21K frames from 15 TV-episodes. The ground truth camera pose and point clouds were created manually by professionals using commercial CG software (see § 4.1 for details). We use StudioSfM to demonstrate that our approach offers sig-niﬁcantly more accurate camera poses and scene geome-try over existing state-of-the-art approaches under small-parallax setting in studio-produced content, while does not cause any degradation on standard SfM datasets [34] with large parallax, and maintains the generalizability and scala-bility of standard SfM pipelines. 2.