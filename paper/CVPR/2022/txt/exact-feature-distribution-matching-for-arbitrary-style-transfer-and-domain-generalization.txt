Abstract
Arbitrary style transfer (AST) and domain generaliza-tion (DG) are important yet challenging visual learning tasks, which can be cast as a feature distribution match-ing problem. With the assumption of Gaussian feature dis-tribution, conventional feature distribution matching meth-ods usually match the mean and standard deviation of fea-tures. However, the feature distributions of real-world data are usually much more complicated than Gaussian, which cannot be accurately matched by using only the first-order and second-order statistics, while it is computationally pro-hibitive to use high-order statistics for distribution match-ing. In this work, we, for the first time to our best knowl-edge, propose to perform Exact Feature Distribution Match-ing (EFDM) by exactly matching the empirical Cumulative
Distribution Functions (eCDFs) of image features, which could be implemented by applying the Exact Histogram
Matching (EHM) in the image feature space. Particularly, a fast EHM algorithm, named Sort-Matching, is employed to perform EFDM in a plug-and-play manner with mini-mal cost. The effectiveness of our proposed EFDM method is verified on a variety of AST and DG tasks, demonstrat-ing new state-of-the-art results. Codes are available at https://github.com/YBZh/EFDM . 1.

Introduction
Distribution matching is a long-standing statistical learn-ing problem [39]. With the popularity of deep models
[20, 27], matching the distribution of deep features has at-tracted growing interest for its effectiveness in solving com-plex vision tasks. For instance, in arbitrary style transfer (AST) [12, 21], image styles can be interpreted as feature distributions and style transfer can be achieved by cross-distribution feature matching [25, 34]. Furthermore, by us-ing style transfer techniques to augment training data, one can address the domain generalization (DG) tasks [13, 72],
∗Corresponding author which target at generalizing the models learned in some source domains to other unseen domains. The most popular method of feature distribution matching is to match feature mean and standard deviation by assuming that features fol-low Gaussian distribution [21,32,37,41,72]. Unfortunately, the feature distributions of real-world data are usually too complicated to be modeled by Gaussian, as illustrated in
Fig. 1. Therefore, feature distribution matching by using only mean and standard deviation is less accurate. It is de-sired to find more effective methods for more accurate and even Exact Feature Distribution Matching (EFDM).
Intuitively, EFDM can be done by matching the high-order statistics of features. Actually, high-order central mo-ments have been explicitly introduced in [25, 63] to match distributions more precisely. However, considering high-order statistics in this way would introduce intensive com-putational overhead. Furthermore, the EFDM could only be theoretically achieved by matching central moments of infinite order [63], which is prohibitive in practice. Moti-vated by the Glivenko–Cantelli theorem [54], which states that the empirical Cumulative Distribution Function (eCDF) asymptotically converges to the Cumulative Distribution
Function when the number of samples approaches infinity,
Risser et al. [46] introduce the classical Histogram Match-ing (HM) [16, 58] method as an auxiliary measurement to minimize the feature distribution divergence. Unfortu-nately, HM can only approximately match eCDFs when there are equivalent feature values in inputs, since HM merges equivalent values as a single point and applies a point-wise transformation. (A toy example is illustrated in
Fig. 2). This commonly happens for digital images with dis-crete integer values (e.g., 8-bits digital images). For features generated by deep models, equivalent feature values are also ineluctable due to their dependency on discrete image pix-els and the use of activation functions, e.g., ReLU [42] and
ReLU6 [26] (please refer to Fig. 3 for more details). All these facts impede the effectiveness of EFDM via HM.
To solve the above mentioned problem, we, for the first time to our best knowledge, propose to perform EFDM by exactly matching the eCDFs of image features, resulting
(a) Art painting (b) Cartoon (c) Photo (d) Sketch
Figure 1. Histograms of feature values in a randomly selected channel, where features are computed from the first residual block of a
ResNet-18 [20] trained on the dataset of four domains [28]. We first normalize the mean and standard deviation of each channel to be 0 and 1, respectively, and then collect feature values among all test samples in each domain for visualization. One can clearly see that the feature distributions of real-world data are usually too complicated to be modeled by Gaussian. in exactly matched feature distributions (when the number of samples approaches infinity) and consequently exactly matched mean, standard deviation, and high-order statis-tics (see the toy example in Fig. 2). The exact matching of eCDFs can be implemented by applying the Exact His-togram Matching (EHM) algorithm [7, 18] in the feature space. Specifically, by distinguishing the equivalent fea-ture values and applying an element-wise transformation,
EHM conducts more fine-grained and more accurate match-ing of eCDFs than HM. In this paper, a fast EHM algorithm, named Sort-Matching [47], is adopted to perform EFDM in a plug-and-play manner with minimal cost.
With EFDM, we conduct cross-distribution feature matching in one shot (cf. Eq. (6)) and propose a new style loss (cf. Eq. (9)) to more accurately measure distribution divergence, producing more stable style-transfer images in
AST. Following [72], we extend EFDM to generate feature augmentations with mixed styles, leading to the Exact Fea-ture Distribution Mixing (EFDMix) (cf. Eq. (10)), which can provide more diverse feature augmentations for DG ap-plications. Our method achieves new state-of-the-arts on a variety of AST and DG tasks with high efficiency. 2.