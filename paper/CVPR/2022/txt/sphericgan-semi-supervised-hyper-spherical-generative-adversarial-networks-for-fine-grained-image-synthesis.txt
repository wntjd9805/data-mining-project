Abstract
Generative Adversarial Network (GAN)-based model-s have greatly facilitated image synthesis. However, the model performance may be degraded when applied to ﬁne-grained data, due to limited training samples and subtle distinction among categories. Different from generic GAN-s, we address the issue from a new perspective of discov-ering and utilizing the underlying structure of real data to explicitly regularize the spatial organization of latent s-pace. To reduce the dependence of generative models on la-beled data, we propose a semi-supervised hyper-spherical
GAN for class-conditional ﬁne-grained image generation, and our model is referred to as SphericGAN. By project-ing random vectors drawn from a prior distribution onto a hyper-sphere, we can model more complex distributions, while at the same time the similarity between the resulting latent vectors depends only on the angle, but not on their magnitudes. On the other hand, we also incorporate a map-ping network to map real images onto the hyper-sphere, and match latent vectors with the underlying structure of real data via real-fake cluster alignment. As a result, we ob-tain a spatially organized latent space, which is useful for capturing class-independent variation factors. The experi-mental results suggest that our SphericGAN achieves state-of-the-art performance in synthesizing high-ﬁdelity images with precise class semantics. 1.

Introduction
Generative learning aims to model complex real-world data distributions, such that high-ﬁdelity data can be synthe-sized from random vectors drawn from a prior distribution.
∗Corresponding author.
Figure 1. Illustration of our proposed hyper-spherical latent space.
By match with the prior clusters of real data, the distribution of latent vectors can be complex, which is useful for capturing the class-independent variation factors.
The existing generative methods can be roughly divided in-to three groups: autoregressive models [31, 36], Variation-al Auto-Encoders (VAE) [21] and Generative Adversarial
Networks (GANs) [14,41]. In particular, GAN-based meth-ods have achieved impressive performance in synthesizing high-quality images [9, 10, 17–19, 33]. A variety of condi-tional GAN architectures have been developed to regularize the data generation process, such as controlling class se-mantics of synthesized images [5, 6]. To reduce the depen-dence of class-conditional GANs on labeled training data, semi-supervised generative learning focuses on how to in-corporate unlabeled data in the adversarial training process
[4, 26, 27, 39]. However, most of the current GAN-based methods are unable to accommodate the ﬁne-grained data scenarios, since generic real-fake data distribution match-ing is inadequate to capture the subtle distinctions among
ﬁne-grained classes.
Enlarging the latent space is an effective way to improve a GAN in capturing the factors of variation in ﬁne-grained data. FineGAN [34] and MixNMatch [25] adopt hierarchi-Figure 2. An overview of SphericGAN. The generator G is divided into two parts {G1, G2}. G1 maps a random vector z onto a hyper-sphere, and G2 synthesizes a class-speciﬁc image xz from the resulting latent vector z◦ = G1(z) and class label yz. A mapping network F also maps real image x ∈ {xl, xu} in the hyper-spherical latent space, and a latent discriminator is incorporated to facilitate the distribution matching between z◦ and z◦ x = F (x) via adversarial training. Further, a set of latent prototypes P are learnt, and the corresponding latent clusters are aligned with the prior clusters of real data. The unlabeled data can be well utilized in this unsupervised learning process. On the other hand, the classiﬁer C is used to assign pseudo labels to unlabeled data. By competing with a prototypical discriminator Dprt and a class conditional discriminator Dclass, the generator is induced to capture class-independent and class-related variation factors. cal generator architectures to individually synthesize back-ground, mask (deﬁnes object shape) and object appearance, which are associated with different latent codes. Due to the limited expressiveness of the latent codes that are sam-pled from a prior distribution, StyleGAN [18, 19] adopts a nonlinear mapping network to map a random vector to a higher dimensional latent space W, and the resulting vec-tor is injected into different blocks of a generator to con-trol the data generation process. In [1], an extended laten-t space W + is used to further enhance the generalization capability of StyleGAN. Different from the above uncondi-tional GANs, we adopt an unsupervised strategy to learn a hyper-spherical latent space, which facilitates the learning of class-independent variation factors as shown in Figure 1.
More speciﬁcally, we propose a semi-supervised GAN with a hyper-spherical latent space for class-conditional generative learning on ﬁne-grained data, and our mod-el is referred to as SphericGAN. Compared to the typi-cal generator-classiﬁer-discriminator model of Triple-GAN
[24], there are two additional components in SphericGAN: a mapping network and a prototypical discriminator as shown in Figure 2.
In contrast to the existing semi-supervised
GANs that sample latent codes from a pre-deﬁned distri-bution, such as Gaussian, we learn a hyper-sphere from the pre-deﬁned space. In our hyper-spherical latent space, the statistics of resulting latent vectors can be complex, which is useful for capturing the class-independent variation fac-tors in real data. Toward this end, we divide the real in-stances into a set of groups via clustering. After adopting the mapping network to map real images on the sphere, a set of prototypes are learnt to associated with the prior cluster-s. By pushing latent vectors toward the nearest prototypes, the underlying structure of real data can be captured. On the other hand, to align the clusters of real and fake data in semantics, the prototypical discriminator is incorporat-ed to maximize the mutual information between the syn-thesized images and the ground-truth cluster code. Exten-sive experiments are conducted to verify the effectiveness of our hyper-spherical latent space in improving the class-conditional synthesis quality of ﬁne-grained data.
We summarize the contributions of this work as fol-lows: (1) We explore semi-supervised class-conditional
ﬁne-grained image generation from a new perspective: learning a hyper-spherical latent space to enhance the ca-pability of a generator in capturing class-independent vari-ation factors. (2) By incorporating a mapping network to map real data in the hyper-spherical latent space, the under-lying data structure is learnt by aligning the latent vectors with the prior clusters of real instances. (3) A prototypi-cal discriminator is designed and incorporated in the adver-sarial training process to further match the clusters of real and synthesized instances in semantics. (4) We judiciously design the optimization formulation of all the constituen-t networks to achieve superior performance over previous state-of-the-arts on multiple standard benchmarks. 2.