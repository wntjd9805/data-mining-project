Abstract
Visual private information leakage is an emerging key is-sue for the fast growing applications of video understanding like activity recognition. Existing approaches for mitigat-ing privacy leakage in action recognition require privacy labels along with the action labels from the video dataset.
However, annotating frames of video dataset for privacy la-bels is not feasible. Recent developments of self-supervised learning (SSL) have unleashed the untapped potential of the unlabeled data. For the first time, we present a novel train-ing framework which removes privacy information from in-put video in a self-supervised manner without requiring pri-vacy labels. Our training framework consists of three main components: anonymization function, self-supervised pri-vacy removal branch, and action recognition branch. We train our framework using a minimax optimization strategy to minimize the action recognition cost function and max-imize the privacy cost function through a contrastive self-supervised loss. Employing existing protocols of known-action and privacy attributes, our framework achieves a competitive action-privacy trade-off to the existing state-In addition, we introduce of-the-art supervised methods. a new protocol to evaluate the generalization of learned the anonymization function to novel-action and privacy at-tributes and show that our self-supervised framework out-performs existing supervised methods. Code available at: https://github.com/DAVEISHAN/SPAct 1.

Introduction
Recent advances in action recognition have enabled a wide range of real-world applications, e.g. video surveil-lance camera [7, 24, 35], smart shopping systems like Ama-zon Go, elderly person monitor systems [2, 22, 45]. Most of these video understanding applications involve extensive computation, for which a user needs to share the video data to the cloud computation server. While sharing the videos to the cloud server for the utility action recognition task, the user also ends up sharing the private visual information like gender, skin color, clothing, background objects etc. in the videos as shown in Fig. 1. Therefore, there is a pressing need for solutions to privacy preserving action recognition.
A simple-yet-effective solution for privacy preservation in action recognition is to utilize very low resolution videos (Fig. 1a) [5, 23, 37]. Although this downsampling method does not require any specialized training to remove privacy features, it does not provide a good trade-off between action recognition performance and privacy preservation.
Another set of methods use pretrained object-detectors to detect the privacy regions and then remove or modify the detected regions using synthesis [34] or blurring [47] as shown in Fig. 1b. The detection-based approaches re-quire the bounding-box level annotations for the privacy at-tributes, and removing the privacy features without an end-to-end learning framework may result in the performance drop of the action recognition task.
Wu et al. [41] propose a novel approach to remove the privacy features via learning an anonymization function through an adversarial training framework, which requires both action and privacy labels from the video. Although the method is able to get a good trade-off of action recognition and privacy preservation, it has two main problems. First, it is not feasible to annotate a video dataset for privacy at-tributes. For instance, Wu et al. [41] acknowledge the issue of privacy annotation time, where it takes immense efforts for them to annotate privacy attributes for even a small-scale (515 videos) video dataset PA-HMDB. Second, the learned anonymization function from the known privacy attributes may not generalize in anonymizing the novel privacy at-tributes. For example, in Fig. 1 the learned anonymization function for human-related privacy attributes (e.g. gender, skin color, clothing) may still leave other privacy informa-tion like scene or background objects un-anonymized.
The performance of the action recognition task depends on the spatio-temporal cues of the input video. Wu et al. [41] show that anonymizing the privacy features like face, gender, etc. in the input video does not lead to any reduction in the action recognition performance. Instead of just focusing on the cues based on the privacy annotations, our goal is twofold: 1) learning an anonymization function that can remove all spatial cues in all frames without sig-nificantly degrading action recognition performance; and
Figure 1. Overview of the existing privacy preserving action recognition approaches. The main goals of a framework include removing privacy information and maintaining action recognition performance at low cost of annotations. 2) learning the anonymization function without any privacy annotations.
Recently, self-supervised learning (SSL) methods have been successfully used to learn the representative features which are suitable for numerous downstream tasks includ-ing classification, segmentation, detection, etc. Towards our goal, we propose a novel frame-level SSL method to remove the semantic information from the input video, while main-taining the information that is useful for the action recog-nition task. We show that our proposed Self-supervised
Privacy-preserving Action recognition (SPAct) framework is able to anonymize the video without requiring any pri-vacy annotations in the training.
The learned anonymization function should provide a model-agnostic privacy preservation, hence, we first adopt the protocol from [41] to show the transferability of the anonymization function across different models. However, there are two aspects in terms of evaluating the generaliza-tion ability of the anonymization function, which are over-looked in previous works.
First, in the real-world scenario, the anonymization func-tion is expected to have generalization capability with do-main shift in action and privacy classes. To evaluate the generalization capabilities of the anonymization function across novel action and privacy attributes, we propose new protocols.
In our experiments, we show that since our model is not dependent on the predefined privacy features like existing supervised methods, and it achieves state-of-the-art generalization across novel privacy attributes.
Second, prior privacy-preserving action recognition works have solely focused on privacy attributes of hu-mans. In practical scenarios, privacy leakage can happen in terms of scene and background objects as well, which could reveal personal identifiable information. Therefore, the generalization ability of anonymization function to pre-serve privacy attributes beyond humans (e.g. scene and object privacy) is of paramount importance as well. To evaluate such ability, we propose P-HVU dataset, a sub-set of LSHVU dataset [8], which has multi-label annota-tions for actions, objects and scenes. Compared to exist-ing same-dataset privacy-action evaluation protocol on PA-HMDB [41], which consists of only 515 test videos, the proposed P-HVU dataset has about 16,000 test videos for robust evaluation of privacy-preserving action recognition.
The contributions of this work are summarized as follows:
• We introduce a novel self-supervised learning frame-work for privacy preserving action recognition without requiring any privacy attribute labels.
• On the existing UCF101-VISPR and PA-HMDB eval-uation protocols, our framework achieves a competi-tive performance compared to the state-of-the-art su-pervised methods which require privacy labels.
• We propose new evaluation protocols for the learned anonymization function to evaluate its generalization capability across novel action and novel privacy at-tributes. For these protocols, we also show that our method outperforms state-of-the art supervised meth-ods. Finally, we propose a new dataset split P-HVU to resolve the issue of smaller evaluation set and extend the privacy evaluation to non-human attributes like ac-tion scene and objects.
2.