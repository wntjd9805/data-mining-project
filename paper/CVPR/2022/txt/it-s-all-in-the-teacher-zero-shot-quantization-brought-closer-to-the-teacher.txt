Abstract
Model quantization is considered as a promising method to greatly reduce the resource requirements of deep neural networks. To deal with the performance drop induced by quantization errors, a popular method is to use training data to fine-tune quantized networks. In real-world environments, however, such a method is frequently infeasible because training data is unavailable due to security, privacy, or con-fidentiality concerns. Zero-shot quantization addresses such problems, usually by taking information from the weights of a full-precision teacher network to compensate the perfor-mance drop of the quantized networks. In this paper, we first analyze the loss surface of state-of-the-art zero-shot quanti-zation techniques and provide several findings. In contrast to usual knowledge distillation problems, zero-shot quantiza-tion often suffers from 1) the difficulty of optimizing multiple loss terms together, and 2) the poor generalization capability due to the use of synthetic samples. Furthermore, we observe that many weights fail to cross the rounding threshold during training the quantized networks even when it is necessary to do so for better performance. Based on the observations, we propose AIT, a simple yet powerful technique for zero-shot quantization, which addresses the aforementioned two problems in the following way: AIT i) uses a KL distance loss only without a cross-entropy loss, and ii) manipulates gradients to guarantee that a certain portion of weights are properly updated after crossing the rounding thresholds. Ex-periments show that AIT outperforms the performance of many existing methods by a great margin, taking over the overall state-of-the-art position in the field. 1.

Introduction
Deep neural network quantization [14,23,37,69] is a pow-erful tool for improving the computational efficiency of deep neural networks (DNNs). When being accompanied with the
*Corresponding author low-bitwidth hardware design [29, 50, 59], the latency and energy consumption of DNNs can be greatly reduced.
One problem of quantized models is, however, that they often suffer from the significant drop in accuracy, mainly due to quantization errors [37]. A popular way to address the problem is to further train or calibrate the model with training data [3, 9, 24, 53, 66, 69]. During the fine-tuning procedure, the forward pass is performed with quantized values whereas the backpropagation is done with floating-point values to recover the accuracy loss in the initial quantization.
Unfortunately, such fine-tuning methods, which assume the full availability of training data at the time of quanti-zation, are often not feasible in reality. Many models are disclosed to public only with their trained weights, and the dataset may contain proprietary, confidential, or sensitive data that fundamentally prohibit sharing.
Zero-shot quantization (or data-free quantization) [4, 5, 10, 11, 45, 62, 67, 68, 70] is therefore a necessary technique for quantization. It assumes that only the architecture and the pre-trained weights are available at the time of quan-tization. Current successful approaches are mainly led by generative approaches [5, 10, 39, 62, 67, 70]. Using synthetic samples from generators, knowledge distillation [22] is ap-plied against full-precision models. It is known that the state-of-the-art methodology achieves almost similar perfor-mance to that of the data-driven approaches (i.e., quantiza-tion with real samples) for 5-bit fixed-point quantization, and comparable performance on 4-bit fixed-point setting. [10].
However, the recipe of the fine-tuning in zero-shot quan-tization is mainly adopted from common knowledge distilla-tion problems [8, 20, 22] that consider neither quantization nor synthetic samples. As in the knowledge distillation, the loss function of the zero-shot quantization is habitually built as a combination of the cross-entropy (CE) against the hard label and the Kullback–Leibler (KL) divergence against the full-precision network’s output.1 It works well 1In the remainder of this paper, we refer to CE as the cross-entropy against the hard label and KL as the KL divergence against the full-precision network unless otherwise stated.
in practice, but there are no detailed studies to introspect the appropriateness of the loss in the context of zero-shot quantization. Therefore, more analyses on those solutions are needed. Moreover, the distribution of synthetic samples can be different from that of the original data. In such a case, they can be considered a type of adversarial samples (also see Fig. 6 for examples) and thus, the quantized network produces a huge generalization gap.
To our knowledge, we for the first time perform in-depth analyses on the loss surface of the zero-shot quantization problem. Through the analyses, we find several key observa-tions for better quantization. First, quantized models often have difficulty optimizing multiple loss terms, and the loss terms fail to cooperate — in other words, the angle between the gradients of CE and KL is quite large in many cases.
Second, KL usually has a much flatter loss surface than that of CE, having a better potential for generalizability.
To this end, we propose a method to address such prob-lems of the zero-shot quantization, called AIT (All In the
Teacher). While pursuing a flatter surface of the loss curve,
AIT lets the quantized student model get closer to the full-precision teacher model. To be more specific, we exclude CE from the loss, and apply our proposed gradient inundation with KL only. In addition, gradient inundation is designed to grow the gradients of KL in such a manner that a certain portion of weights are guaranteed to be updated in each layer.
As a result, the quantized model approaches closer to the full-precision teacher, and our method takes over the state-of-the-art position for various datasets. Our contributions can be summarized as follows:
• We analyze the first and second-order loss surfaces, i.e., gradient and Hessian, of the zero-shot quantization problem. To the best of our knowledge, we are the first to closely investigate the loss function in the zero-shot quantization problem.
• We identify that the gradients from CE and KL form a large angle from the beginning to the end of the fine-tuning. This implies that the quantized network is suf-fering from their trade-off instead of benefiting from them working in harmony.
• We analyze the local curvature of the loss surface and observe that the two losses of our interest exhibit a great amount of curvature difference.
• We observe that the quantized student suffers from in-frequent updates, where only a few layers are changing their integer weights and the remaining layers are stuck below rounding thresholds.
• Based on these findings, we propose AIT which ex-cludes the cross-entropy loss, and manipulates the gra-dients using our proposed gradient inundation method such that the quantized student model can faithfully resemble the full-precision teacher model.
• We perform a thorough evaluation of AIT. The results show that AIT outperforms the existing algorithms by a great margin, showing the state-of-the-art performance on the zero-shot quantization problem. 2.