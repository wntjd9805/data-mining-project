Abstract
Contour-based instance segmentation methods have de-veloped rapidly recently but feature rough and hand-crafted front-end contour initialization, which restricts the model performance, and an empirical and ﬁxed backend predicted-label vertex pairing, which contributes to the learning difﬁculty.
In this paper, we introduce a novel contour-based method, named E2EC, for high-quality in-stance segmentation. Firstly, E2EC applies a novel learn-able contour initialization architecture instead of hand-This consists of a con-crafted contour initialization. tour initialization module for constructing more explicit learning goals and a global contour deformation module for taking advantage of all of the vertices’ features bet-ter. Secondly, we propose a novel label sampling scheme, named multi-direction alignment, to reduce the learning dif-ﬁculty. Thirdly, to improve the quality of the boundary de-tails, we dynamically match the most appropriate predicted-ground truth vertex pairs and propose the corresponding loss function named dynamic matching loss. The experi-ments showed that E2EC can achieve a state-of-the-art per-formance on the KITTI INStance (KINS) dataset, the Se-mantic Boundaries Dataset (SBD), the Cityscapes and the
COCO dataset. E2EC is also efﬁcient for use in real-time applications, with an inference speed of 36 fps for 512×512 images on an NVIDIA A6000 GPU. Code will be released at https://github.com/zhang-tao-whu/e2ec. 1.

Introduction
Instance segmentation is a fundamental computer vision task and the cornerstone of many downstream computer vi-sion applications, such as autonomous driving and robotic grasping. The classic instance segmentation methods are based on a two-stage pipeline, where the bounding boxes (bboxes) of the instances are ﬁrst generated, and then pixel-wise segmentation is performed within the bboxes. Typi-cal examples are methods such as Mask R-CNN [14] and
Figure 1. The ideal deformation paths of several contour-based methods. White boundaries and points are the initial contours, blue lines are the deformation paths, and black points are the align-ment points.
PANet [23]. These methods can achieve an excellent ac-curacy, but are inefﬁcient, which restricts their applica-tion in real-time tasks. With the rapid development of one-stage detectors [29, 39], many one-stage mask-based instance segmentation methods have now been proposed, such as YOLACT [2], BlendMask [3], TensorMask [4], and
CenterMask [17]. However, these one-stage methods con-sume a lot of storage, require costly post-processing, and hardly perform in real time. The quality of the instance boundary prediction is also unsatisfactory as these methods usually use limited feature information (for example, Mask
R-CNN only segments instances in a 28×28 feature map).
The contour-based methods have recently received renewed attention and have shown great potential. Examples of such methods are Curve GCN [21], Deep Snake [27], Point-Set
Anchors [31], DANCE [25], PolarMask [33], and LSNet
[9]. The contour-based methods treat the instance segmen-tation as a regression task, i.e., regressing the vertex co-ordinates of a contour represented by a series of discrete vertices. A contour composed of N (e.g., N = 128) ver-tices is sufﬁcient to describe most of the instances well [27].
Compared with the mask-based methods, which require in-tensive processing of each pixel, the contour-based methods are simpler and require less calculation. The contour-based methods can also directly obtain the boundaries of the in-stances, without any complicated post-processing.
However, the existing contour-based methods still have
many obvious shortcomings. First, all of the existing multi-stage methods adopt a manually designed shape for the ini-tial contour. As shown in Figure 1, the difference between the manually designed initial contour and the ground-truth instance boundary can lead to many unreasonable defor-mation paths (the route from initial to ground-truth vertex) and huge training difﬁculty. It is also impossible to sam-ple the manually designed initial contour to achieve a uni-form angle and uniform vertex spacing at the same time.
The Point-Set Anchors and DANCE methods attempt to ad-dress this problem by changing the intuitive vertex pairing method [25, 31], but the results are not satisfactory.
Second, local or limited information is popularly applied in contour adjustment. For example, the one-stage Polar-Mask [33] and LSNet [9] methods directly regress the co-ordinates of the contour vertices based on only the limited features at the instance center, resulting in the loss of the predicted contour details. The multi-stage methods itera-tively adjust the initial contour based on the features of the contour vertices to obtain a more reﬁned segmentation re-sult. However, Curve GCN and Deep Snake utilize a lo-cal information aggregation mechanism that propagates the features of the local adjacent contour vertices to reﬁne the contour, which can fail in correcting large prediction errors.
Moreover, the local aggregation has to be inefﬁciently re-peated to access global information. Instead, we propose a global contour deformation method based on the features of all the contour vertices.
Third, the pairing of the ground-truth and predicted ver-tices in the current contour-based methods is ﬁxed, regard-less of the continuous position adjustment of a predicted vertex (e.g., it is already on the ground-truth boundary or close to another ground-truth vertex, but far from the given one). Hence, the pre-ﬁxed vertex pairing is not optimal, and can result in a slower convergence speed, and even wrong predictions.
In this paper, we propose a multi-stage and highly efﬁcient end-to-end contour-based instance segmentation model named E2EC, which can completely overcome these shortcomings. E2EC incorporates three novel components: 1) a learnable contour initialization architecture; 2) multi-direction alignment (MDA); and 3) a dynamic matching loss (DML) function.
E2EC replaces the manually designed initial contour with a learnable contour initialization architecture, which handles the ﬁrst and second problem. This architecture con-tains two novel modules: 1) a contour initialization module; and 2) a global contour deformation module. The contour initialization module directly regresses the complete initial contour based on the center point features, which differs from regressing lengths along given ﬁxed rays [33]. The global contour deformation module then reﬁnes the initial contour based on all of the features of the initial contour
Figure 2. Overview of E2EC. E2EC consists of a learnable con-tour initialization architecture including a contour initialization and a global deformation module that produces the coarse con-tour, and a contour reﬁnement module that produces the ﬁnal con-tour with the supervision of DML. vertices and center point instead of using features of local vertices. As shown in Figure 1, the learnable initial con-tour architecture does not rely on a manually designed ini-tial contour (e.g., the ellipse of Curve GCN or the octagon of Deep Snake), and directly deforms from the midpoint of the object instance to the contour with more reasonable paths.
The difﬁculty in predicted-label vertex pairing roots in the fact that no simple differentiable calculation can mea-sure the distance between the predicted and ground-truth boundaries. To address the third problem, on the one hand, we propose multi-direction alignment (MDA), which ﬁxes the directions of the selected multiple contour vertices with respect to the center point (the black points in Figure 1 (E2EC)), and then uniformly samples between the ﬁxed ver-tices to generate ground-truth vertices. MDA appropriately restricts the possible vertex pairing and deformation paths, and greatly reduces the difﬁculty of learning while ensur-ing the upper bound of the performance. The combination of the learnable initial contour architecture and MDA elim-inates the unreasonable deformation paths that commonly exist in the current contour-based methods.
On the other hand, we propose a matching strategy that dynamically matches the predicted vertices and the most ap-propriate label vertices instead of ﬁxed pairing, and the cor-responding dynamic matching loss (DML) function. DML eliminates the problems of an over-smooth boundary and poor ﬁtting of the inﬂection points in the contour-based methods, and greatly improves the quality of the predicted boundary details.
In the experiments conducted in this study, E2EC exhib-ited a state-of-the-art performance on the KITTI INStance (KINS) dataset [28], the Semantic Boundaries Dataset (SBD) [13] and the Cityscapes [6] dataset. For 512×512 images, E2EC achieved a 36 fps inference speed on an
NVIDIA A6000 GPU. If the iterative deformation module is disabled, E2EC can reach a speed of 50 fps, with an ac-curacy comparable to that of Deep Snake.
Figure 3. Global deformation (b) vs. circular convolution
[27] (a). The green points rep-resent the features of the contour vertices, the yellow points repre-sent the local kernel function of the circular convolution, and the blue points represent the offsets of the contour vertices, and red is
MLP.
Figure 4. Multi-direction alignment. M is the number of vertices
ﬁxed in the direction with respect to the center point. When M in-creases, the learning difﬁculty of the task gradually decreases, but the unevenness of the vertex distribution also gradually increases. 2.