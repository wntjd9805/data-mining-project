Abstract
To address the huge labeling cost in large-scale point cloud semantic segmentation, we propose a novel hy-brid contrastive regularization (HybridCR) framework in weakly-supervised setting, which obtains competitive per-formance compared to its fully-supervised counterpart.
Specifically, HybridCR is the first framework to leverage both point consistency and employ contrastive regulariza-tion with pseudo labeling in an end-to-end manner. Fun-damentally, HybridCR explicitly and effectively considers the semantic similarity between local neighboring points and global characteristics of 3D classes. We further de-sign a dynamic point cloud augmentor to generate diver-sity and robust sample views, whose transformation param-eter is jointly optimized with model training. Through ex-tensive experiments, HybridCR achieves significant perfor-mance improvement against the SOTA methods on both in-door and outdoor datasets, e.g., S3DIS, ScanNet-V2, Se-mantic3D, and SemanticKITTI. 1.

Introduction
Learning the precise semantic meanings of large-scale point clouds is a fundamental perception task for intelli-gent machines to understand complex 3D scenes. Exist-ing deep-learning-based methods heavily rely on the avail-ability and quantity of labeled point cloud data for train-ing [5, 21, 22, 29]. However, 3D point-wise labeling is time-consuming and labor-intensive. Hence, we aim to explore weakly-supervised learning to maximize the data efficiency and reduce efforts to annotate 3D point clouds.
Recently, several 3D point cloud weakly-supervised se-mantic segmentation methods have been emerged, which
† Corresponding authors.
Figure 1. Hybrid contrastive regularization at local and global.
Left: The anchor point is encouraged to be similar to the matched positive point and its neighbors (in green circle) while being dissimilar to negative points and their neighbors (in red circle).
Right: The anchor point is encouraged to be similar to the matched positive point and other points that belong to the same class (in green box) while being dissimilar to negative points of different classes (in red box). can be generally divided into three groups: (1) Consis-tency regularization [33, 38] employs consistency constrain from the distribution of prediction after randomly modify-ing the input or model function. (2) Pseudo labeling, a.k.a. self-training [4, 18, 37], uses the model predictions as su-pervision. (3) Contrastive pre-training [9, 32] focuses on model pre-trained, which is then followed by fine-tuning with fewer labels for downstream tasks.
Although the existing methods have achieved encourag-ing results, some limitations remain to be addressed. Firstly, they do not adequately consider the semantic properties of neighbors and global characteristics of 3D classes for large-scale scenarios, failing to fully exploit the limited yet valu-able annotations [33]. Secondly, many pipelines [33, 38] used fixed/handcrafted data augmentation to get multi-view representation resulting in sub-optimal learning, as the strength and types of the augmentation depends strongly on model and dataset size. Besides, the shape complexity of the samples is ignored in the fixed augmentation. Thirdly, the existing methods [9, 37] usually involve multiple stages pre-training and fine-tuning, which raise difficult training and deploy in practice compared to the end-to-end training scheme.
To address the above shortcomings, we explore to simul-taneously leverage the consistency and contrastive property in label space and feature space, respectively. Inspired by recent 3D PSD [38] and 2D FixMatch [27], we combine the pseudo label and consistency regularization strategy in an end-to-end training scheme for large-scale point clouds. To better use contrastive information, we redesign the positive pairs and negative pairs of anchor points. A key observation is that high-level semantic scene understanding requires not only local but also global geometric features, making point cloud instances contrasting more sufficiently Besides, mo-tivated by PointAugment [15] in the classification task, we further introduce dynamic point cloud augmentor to provide transformations for consistency and contrastive regulariza-tion with jointly optimization.
To implement the above idea, we propose a new paradigm, called hybrid contrastive regularization (Hy-bridCR), for weakly-supervised semantic segmentation on large-scale point clouds, which consists of local and global guidance contrastive learning along with dynamic point cloud transformations. As shown in Fig. 1, local guid-ance contrastive regularization forces data sample of differ-ent views to be close to their neighbors and far away from other points. For global guidance contrastive regularization, each sample is imposed to to be close to the prototype of its class and far away from different classes prototypes. Fun-damentally, HybridCR explicitly and effectively considers the semantic similarity among the local neighboring points and global characteristics of 3D point cloud classes. Fur-thermore, the proposed dynamic point cloud augmentor use multi-layer perceptrons (MLPs) and Gaussian noises to en-rich the data diversity in context-wise displacement, where the parameters of augmentor can be jointly optimized with model training. Extensive experiments show that HybridCR achieves the SOTA performance for both indoor scenes, i.e.,
S3DIS [1] and ScanNet-V2 [6], and outdoor scenes, i.e.,
Semantic3D [8] and SemanticKITTI [2], demonstrating the effectiveness of our proposed framework.
To summarize, our contributions are four-fold:
• We propose the first framework HybridCR to leverage both point consistency and contrastive properties for weakly-supervised point cloud semantic segmentation in an end-to-end manner.
• We introduce the local and global guidance con-trastive regularization to promote high-level 3D se-mantic scene understanding tasks.
• We design a novel dynamic point cloud augmentor to transform diverse and robust sample views, which is jointly optimized with the whole training process.
• HybridCR achieves significant performance over re-cent weakly-supervised methods and gains 2.4% and 1.0% AP improvements on average in indoor and out-door datasets, respectively. 2.