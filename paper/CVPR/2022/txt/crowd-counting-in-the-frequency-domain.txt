Abstract
This paper investigates crowd counting in the frequency domain, which is a novel direction compared to the tradi-tional view in the spatial domain. By transforming the den-sity map into the frequency domain and using the properties of the characteristic function, we propose a novel method that is simple, effective, and efﬁcient. The solid theoret-ical analysis ends up as an implementation-friendly loss function, which requires only standard tensor operations in the training process. We prove that our loss function is an upper bound of the pseudo sup norm metric between the ground truth and the prediction density map (over all of their sub-regions), and demonstrate its efﬁcacy and efﬁ-ciency versus other loss functions. The experimental results also show its competitiveness to the state-of-the-art on ﬁve benchmark data sets: ShanghaiTech A & B, UCF-QNRF,
JHU++, and NWPU. Our codes will be available at: wb-shu/Crowd Counting in the Frequency Domain 1.

Introduction
The research ﬁeld of image-based crowd counting has been ﬂourishing since the density map based method is proposed [12]. After the Multi-Column Neural Network (MCNN) shows the power of using the deep Convolution
Neural Network (CNN) to generate the density map [46], the combination of deep learning and density map learning has led the state-of-the-art. Among current state-of-the-art, the Bayesian Loss (BL) distinguishes itself by only chang-ing the loss function in the whole pipeline [21]. The BL used the ground truth dot map to calculate class conditional distributions (CCD) for each position rather than generating a discrete density map as supervision. This elegant method showed that how to exploit the ground truth to offer proper supervisory information (i.e., the loss function) has a large impact on the ﬁnal performance.
The ground truth dot map in itself has a large amount of useful information. Therefore, how to fully utilize the ground truth to provide high-quality supervisory informa-tion becomes one of the active issues in crowd counting.
This issue has yielded a number of prominent research works recently. Among them, the Distribution Matching (DMCount) [37] and the Generalized Loss (GL) [35] used the optimal transport (OT) distance as the loss function between predicted density maps and the ground truth dot maps. When the DNN adjusts one predicted pixel value according to the pixel-wise L2 loss, it only considers the in-ﬂuence on the same pixel in the ground truth. In contrast, when the DNN adjusts one predicted pixel value according to the OT loss, it must consider the inﬂuence of all nearby pixels in the ground-truth according to their distances – the
OT problem is a global optimization problem that jointly considers the transport of all pixels. Therefore, the family of OT losses is able to better exploit the position informa-tion of the ground truth to provide high-quality supervision.
Another approach that better used the groundtruth’s po-sition information is the Purely Point-Based Framework (P2PNet) [31], which directly taught the network to predict people’s head positions in the ground truth. The exact posi-tion information in the ground truth was used in training by calculating a one vs. one match between the prediction and the ground truth.
However, these SOTA methods also have some ﬂaws.
Firstly, both the OT loss [35, 37] and the P2PNet [31] re-quire inefﬁcient external algorithms to extract the spatial information from the ground truth in each training step.
For the OT loss, the Sinkhorn algorithm [22] is executed to obtain the optimal transport matrix, while for P2PNet, the
Hungarian algorithm [11] is required to get the one vs. one point matches. Both of these algorithms require a number of iterations and are carried out in each training step, which makes the OT/P2PNet training less efﬁcient. Furthermore, the complex logic of the Hungarian algorithm makes it hard to use the advantage of parallelization in GPU. Indeed the ofﬁcial codes of P2PNet implemented it in CPU, which fur-ther decreases the efﬁciency compared with methods whose pipelines are fully implemented in GPU.
Secondly, although the position information is fully used in OT/P2PNet, the counting information of the ground truth
liver all the information to the DNN for training (see Fig. 1).
The characteristic function is exactly a representation of the ﬁnite measure on the frequency domain. Although it is originally deﬁned for probability distributions, here we extend the deﬁnition to the ﬁnite measure so that some vital properties of the original deﬁnition are carried over. These properties play an important role throughout the analysis in the paper, and we will show their effects later. In summary, the contributions in the paper are:
• We extend the deﬁnition of the characteristic function from probability distributions to ﬁnite measures, as well as prove or intensify some of its vital properties. Thus, we transfer the learning problem from supervision with spa-tial density maps to supervision with frequency-domain characteristic functions, where the latter compactly sum-marizes the dispersed spatial information, which is more suitable for supervision. To the best of our knowledge, this is the ﬁrst work investigating crowd counting in the frequency domain.
• Using properties of the characteristic function, we pro-pose a simple, effective, and efﬁcient loss function that provides high-quality supervisory information for train-ing, and, in contrast to previous works, does not require external algorithms for extracting spatial information.
• We prove that minimizing our loss function will decrease the upper bound of a pseudo sup norm metric between the predicted and the ground truth density map (over all sub-regions), which is effective for crowd counting.
• The experimental results on ﬁve benchmark datasets show our method’s competitiveness, and our loss function out-performs a large number of baseline and SOTA loss func-tions, while also being more efﬁcient. 2.