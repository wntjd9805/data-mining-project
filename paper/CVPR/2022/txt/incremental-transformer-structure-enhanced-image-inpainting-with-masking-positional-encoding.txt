Abstract
Image inpainting has made significant advances in re-cent years. However, it is still challenging to recover corrupted images with both vivid textures and reasonable structures. Some specific methods only tackle regular tex-tures while losing holistic structures due to the limited re-ceptive fields of convolutional neural networks (CNNs). On the other hand, attention-based models can learn better long-range dependency for the structure recovery, but they are limited by the heavy computation for inference with large image sizes. To address these issues, we propose to leverage an additional structure restorer to facilitate the image inpainting incrementally. The proposed model re-stores holistic image structures with a powerful attention-based transformer model in a fixed low-resolution sketch space. Such a grayscale space is easy to be upsampled to larger scales to convey correct structural information. Our structure restorer can be integrated with other pretrained inpainting models efficiently with the zero-initialized resid-ual addition. Furthermore, a masking positional encod-ing strategy is utilized to improve the performance with large irregular masks. Extensive experiments on various datasets validate the efficacy of our model compared with other competitors. Our codes are released in https:
//github.com/DQiaole/ZITS_inpainting. 1.

Introduction
Image inpainting has been investigated as a long-standing challenge to address the difficulty of filling in missing areas of pictures.
It is very useful to various real-world applications, such as object removal [12], photo restoration, and image editing [25]. To achieve realistic out-comes, the inpainted images should remain both semanti-cally coherent textures and visually reasonable structures.
Many classical algorithms [3, 9, 19, 31, 42] search similar patches for the reconstruction heuristically. But preserving
*Equal contributions.
†Corresponding authors.
Figure 1. High quality 1024×1024 inpainted results. From left to right, masked inputs, results of LaMa [44], results of our method. good textures and holistic structures in large images is still non-trivial for these conventional methods.
Benefited from excellent capacities of Convolutional
Neural Networks (CNNs) [28] and Generative Adversar-ial Networks (GANs) [15], existing deep learning meth-ods [4,18,30,35,44,46,54,59] could efficiently conduct the image inpainting tasks in some common cases. However, (1) Limited recep-they still suffer from some dilemmas. tive fields. Learning semantically consistent textures is dif-ficult for traditional CNNs due to the local inductive priors and narrow receptive field of convolution operations. Even dilated convolutions [55] fail to tackle large corrupted re-gions or high-resolution images. (2) Missing holistic struc-tures. Recovering key edges and lines for scenes, especially ones with weak texture is difficult without the holistic un-derstanding of large images as shown in Fig. 1. (3) Heavy computations. Training GANs with large image sizes is still very tricky and costly [27]. And the inpainting perfor-mance may be degraded on high-resolution images. (4) No positional information in masked regions. The inpainting model tends to repeat meaningless artifacts in large irregu-lar masked regions without explicit positional clues.
Some pioneering works can partially solve these prob-lems. For the limited receptive fields, attention-based meth-ods [54, 56, 60] leverage the attention mechanism to extend the receptive fields. Suvorov et al. [44] utilize the Fast
Fourier Convolution (FFC) to encode features in frequency fields with global receptive fields for resolution-robust in-painting. But they fail to ensure the holistic structures and work inferior for the images of weak texture. Further-more, transformer-based methods [46, 58] with long-range dependency are utilized to firstly fill low-resolution tokens, and then upsample them with CNNs. Unfortunately, trans-formers demand huge memory footprint for large images.
And the resolution disparity between transformer and CNN causes serious error propagation. On the other hand, some methods utilize auxiliary information for structure recov-ery, e.g., edges [18, 38], segmentation [32, 43], and gra-dients [53]. Cao et al. [4] propose a sketch tensor space consisting of edges and wireframes [22] to facilitate holis-tic structure learning in man-made scenes. However, these sophisticated methods are usually based on multi-stage or multi-model designs, which are costly to be trained from scratch. Moreover, many researches [23, 33, 51] show that the position information is critical to learning the network, such as GANs [33, 51] and NeRF [36]. To our knowledge, there is no previous work that has explicitly discussed and utilized the position information in image inpainting.
Therefore, this motivates our work of incrementally in-ferring the holistic structural information and positional information to boost the performance of the inpainting model. Specifically, we leverage a transformer-based model to tackle holistic structures with edges and lines as the sketch tensor space [4]. Critically, such a normalized grayscale space can be easily upsampled by a simple CNN to higher resolutions without information loss. Further, we propose a novel incrementally training strategy with
Zero-initialized Residual Addition (ZeroRA) [2] to incor-porate the structural information into a pretrained inpaint-ing model. This incremental strategy enjoys fast conver-gence for much fewer steps compared with retraining a new auxiliary-based model. Furthermore, we introduce the po-sitional encoding for the mask region, which improves the performance of image restoration.
Formally, this paper proposes a novel ZeroRA based In-cremental Transformer Structure (ZITS) inpainting frame-work enhanced with Masking Positional Encoding (MPE).
Our ZITS has novel components of Masking Positional
Encoding (MPE), Transformer Structure Restorer (TSR),
Fourier CNN Texture Restoration (FTR), and Structure Fea-ture Encoder (SFE). The TSR is composed of alternating axial [21] and standard attention blocks for the balance be-tween the performance and the efficiency. Note that our
TSR can achieve much better structure recovery compared with CNNs [4, 38]. The output grayscale edges and lines are upsampled with a simple 4-layer CNN. Then, a gated convolutions [57] based SFE encodes features and transfers them to a FFC based inpainting model called FTR with Ze-roRA. Furthermore, we use MPE to express both distances and directions from unmasked regions to masked ones.
We highlight several contributions as follows. (1) We propose using a transformer to learn a normalized grayscale sketch tensor space for inpainting tasks. Such an attention-based model can learn substantially better holistic struc-tures with long-range dependency. (2) The auxiliary infor-mation can be incrementally incorporated into a pretrained (3) A novel mask-inpainting model without retraining. ing positional encoding is proposed to improve the gener-alization of the inpainting model for different masks. (4)
Extensive experiments on several datasets, which include
Places2 [63], ShanghaiTech [22], NYUDepthV2 [37], and
MatterPort3D [5] reveal that our proposed model outper-forms other state-of-the-art competitors. 2.