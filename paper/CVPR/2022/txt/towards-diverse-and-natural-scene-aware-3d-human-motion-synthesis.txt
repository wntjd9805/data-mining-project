Abstract 1.

Introduction
The ability to synthesize long-term human motion se-quences in real-world scenes can facilitate numerous ap-plications. Previous approaches for scene-aware motion synthesis are constrained by pre-deﬁned target objects or positions and thus limit the diversity of human-scene in-teractions for synthesized motions.
In this paper, we fo-cus on the problem of synthesizing diverse scene-aware hu-man motions under the guidance of target action sequences.
To achieve this, we ﬁrst decompose the diversity of scene-aware human motions into three aspects, namely interac-tion diversity (e.g. sitting on different objects with different poses in the given scenes), path diversity (e.g. moving to the target locations following different paths), and the mo-tion diversity (e.g. having various body movements during moving). Based on this factorized scheme, a hierarchical framework is proposed, with each sub-module responsible for modeling one aspect. We assess the effectiveness of our framework on two challenging datasets for scene-aware hu-man motion synthesis. The experiment results show that the proposed framework remarkably outperforms previous methods in terms of diversity and naturalness.
The capability of synthesizing long human motion se-quences is essential for a number of real-world applica-tions, such as virtual reality and robotics. Beyond early attempts that consider body movement synthesis in isola-tion [1, 2, 33, 35, 38], recent works [4, 11, 30, 31] begin to explore the inﬂuences of surrounding scenes on human mo-tion synthesis for different actions. Limited by the 2D rep-resentation of scene context [4, 31] or the reliance on man-ually assigned interacting targets [11, 30], these approaches mainly focus on modeling the body movements and fail to comprehensively investigate the inherent diversity of scene-In order to synthesize long-term aware human motions. human motions guided by the scene context and the target action sequence, we propose to model the inherent motion diversity across different granularities, each contributing to different aspects of human motion.
As shown in Figure 1, the diversity of scene-aware hu-man motions can be factorized into three levels, given the target action sequence (e.g. A man lies ﬁrst. Then he sits in different places. At last, he stands somewhere.). Firstly, given the surrounding scene context and the target action sequence, there exists a distribution of valid locations to re-alize the actual human-scene interactions for each of these actions (e.g. We can sit on any chairs or beds and stand on the ground). Different locations can be sampled from the distribution and serve as the anchors of the whole synthe-sized motion sequence. Based on those anchors, we can then follow various paths to bridge them one by one. Fi-nally, our body poses also differ from case to case when we move along the paths to connect all anchors. We demon-strate these three levels of diversity in Figure 1. Existing attempts for scene-aware human motion synthesis [11, 30] only emphasize the last level of diversity (e.g. walking to the pre-deﬁned object or position in the scene) via manually assigning the interaction locations and motion paths. Con-sequently, the importance of the scene semantics is substan-tially muted, as it mainly affects the distribution of valid in-teraction anchors and the distribution of valid motion paths.
To faithfully capture the diversity of scene-aware human motions, we propose a novel three-stage motion synthesis framework, each stage of which is responsible for modeling one level of the aforementioned diversity.
For diverse human-scene interaction anchors, we de-sign our pose placing framework for the given action se-quence. Different from [37, 39] which only consider the in-ﬂuence of scene context, we ﬁrst synthesize scene-agnostic poses according to the target action via a conditional VAE (CVAE) [25]. Then we follow the practice of POSA [13] to place these poses into the scene. To be speciﬁc, the 3D scene is uniformly split into a set of non-overlapping grids, each of which is associated with a validity score that mea-sures its compatibility as a candidate for placing the poses.
We make two modiﬁcations to the original placing method used by POSA First, we introduce the position relation-ship between poses with the same action label to enhance the placing diversity by avoiding them being placed to the nearby positions. Furthermore, we leverage another CVAE model as the placing reﬁner to produce diverse offsets for each discrete grid. Examples of generated anchors are de-picted in Figure 1 (a).
To produce diverse obstacle-free motion paths follow-ing the sampled anchors, we employ an adapted A∗ algo-rithm over the discrete 3D grids as the path planner. The standard A∗ algorithm used by previous works [11] only generates deterministic paths as they only consider colli-sion between objects and distances to the target locations.
To model the inherent diversity of motion paths, we amend the original algorithm with a trainable stochastic module learned in a data-driven manner. The new module, named
Neural Mapper, can provide dynamic scene-conditioned probabilistic guidance to the A∗ algorithm, so that the algo-rithm can automatically produce diverse yet natural paths given the deterministic scenes and location anchors. We show several examples of generated diverse paths given the same start and end locations in Figure 1 (b).
Lastly, we propose a novel Transformer-based CVAE, called motion completion network, to synthesize diverse body movements guided by the paths generated in the previous step. Inspired by [23], we leverage Transformer as the basic architecture for synthesizing continuous and smooth motions. Differently, we focus on diverse motion completion of poses with long-term distance and different actions, rather than synthesize motions for the single ac-tion [23]. Therefore, this motion completion network ﬁrst generates diverse moving trajectories, loosely following the paths sampled by the aforementioned A∗ algorithm. The body poses are then produced by taking the scene contexts, action labels, human-scene interaction anchors, and synthe-sized trajectories as inputs.
To summarize our contributions: 1) We analyze the in-herent diversity of the human motion and decompose it into three components, namely the diversity on human-scene interaction anchors, paths, and body poses. 2) We propose a novel three-stage framework to faithfully cap-ture the diversities of scene-aware human motions. This framework can automatically synthesize human motions following these diversities with the condition action la-bels. Qualitative and quantitative results on datasets such as
PROX [12]demonstrate that our method signiﬁcantly sur-passes previous approaches in terms of diversity and nat-uralness. 3) In the proposed framework, we make several technique contributions for this task, including the action conditioned pose placing framework for generating diverse human-scene interaction anchors, Neural Mapper for plan-ning diverse paths, and motion completion network for pro-ducing diverse and continuous motions. With our decom-position on motion diversity, these technique contributions can achieve our goal efﬁciently and effectively. 2.