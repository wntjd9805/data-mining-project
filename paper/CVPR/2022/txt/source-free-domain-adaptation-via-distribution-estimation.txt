Abstract
Domain Adaptation aims to transfer the knowledge learned from a labeled source domain to an unlabeled tar-get domain whose data distributions are different. How-ever, the training data in source domain required by most of the existing methods is usually unavailable in real-world applications due to privacy preserving policies. Recently,
Source-Free Domain Adaptation (SFDA) has drawn much attention, which tries to tackle domain adaptation prob-lem without using source data. In this work, we propose a novel framework called SFDA-DE to address SFDA task via source Distribution Estimation. Firstly, we produce ro-bust pseudo-labels for target data with spherical k-means clustering, whose initial class centers are the weight vec-tors (anchors) learned by the classifier of pretrained model.
Furthermore, we propose to estimate the class-conditioned feature distribution of source domain by exploiting target data and corresponding anchors. Finally, we sample surro-gate features from the estimated distribution, which are then utilized to align two domains by minimizing a contrastive adaptation loss function. Extensive experiments show that the proposed method achieves state-of-the-art performance on multiple DA benchmarks, and even outperforms tradi-tional DA methods which require plenty of source data. 1.

Introduction
In the past few years, deep Convolutional Neural Net-works (CNNs) have achieved remarkable performance on many visual tasks such as classification [19], object detec-tion [8], semantic segmentation [28], etc. However, the suc-cess of CNNs relies heavily on the hypothesis that the dis-tributions of the training data is identical to that of the test data. Thus, models trained with data from a certain sce-nario (source domain) can hardly generalize well to other real-world application scenarios (target domains), and may
* Corresponding author.
Figure 1. (Top) Traditional domain adaptation methods require data from both source domain and target domain simultaneously. (Bottom) In source-free domain adaptation, source data can only be used in the pretraining stage, and cannot be accessed in the later adaptation stage. Adaptation is achieved by utilizing target data and the model pretrained on source domain. suffer from severe performance drop. Moreover, the diffi-culty of collecting enough labeled training data also hinders
CNNs from directly learning with target domain data. Un-fortunately, CNNs deployed in real-world scenarios always encounter new situations, such as the change of weather and variation of illumination in autonomous driving.
Therefore, a lot of attention is paid to the domain shift problem [1, 43] mentioned above, and Domain Adaptation (DA) theory has been developed to solve it. DA algorithms directly help deep models transfer knowledge learned from a fully annotated source domain to a separately distributed target domain whose annotations are entirely unavailable.
Existing advances in deep learning-based DA methods [4, 24,30,34] generally achieve model transferability by means of mapping two different data distributions simultaneously into a mutual feature space shared across two domains.
However, people are getting more aware of the impor-tance of privacy data protection nowadays. Strict policies regarding data privacy concerns have been published all
around the world. More AI companies also choose to open source their pretrained models only, yet keep the source dataset used for training unreleased [46]. Therefore, most of the traditional DA methods become infeasible to transfer knowledge to target domain when source data is no longer accessible since these methods basically assume that data from both source domain and target domain is available.
To overcome this data-absent problem, some recent works [18, 20, 23, 25, 57] explored more general approaches to achieve domain adaptation without accessing source data.
Only unlabeled target domain data and the model pre-trained on source domain are required to accomplish the cross-domain knowledge transfer. Such a new unsuper-vised learning setting for domain adaptation task is called
Source-Free Domain Adaptation (SFDA). SHOT [25] uti-lizes information maximization and entropy minimization. 3C-GAN [23] uses a generative model to enrich target data to enhances model performance. G-SFDA [58] learns dif-ferent feature activations by exploiting neighborhood struc-ture of target data. A2Net [52] introduces a new classifier and adopt adversarial training to align two domains. De-spite the fact that these SFDA methods utilize the source domain knowledge contained by the pretrained model, none of them explicitly align the distributions between source do-main and target domain to achieve adaptation.
In this paper, we focus on image classification task under
SFDA setting. We manage to estimate the source distribu-tion without accessing source data. Specifically, we utilize the domain information captured by the model pretrained on source data and treat the weights learned by source clas-sifier as class anchors. Then, these anchors are used as the initialization of feature center for each class and spherical k-means is performed to cluster target features in order to produce robust pseudo-labels for target data. Furthermore, we dynamically estimate the feature distributions of source domain class-wisely by utilizing the semantic statistics of target data along with their corresponding anchors, which is called Source Distributions Estimation (SDE). Finally, we sample surrogate features from distributions derived from
SDE to simulate the real but unknown source features, and then align them with target features by minimizing a con-trastive adaptation loss function to facilitate source-free do-main adaptation. In short, if the feature distribution of target domain is well-aligned with source domain, the source clas-sifier will naturally adapt to the target domain data.
We validate our proposed SFDA-DE method on three public DA benchmarks: Office-31 [38], Office-Home [50] and VisDA-2017 [37].
Experiment results show that the proposed SFDA-DE method achieves state-of-the-art performance on Office-Home (72.9%) and VisDA-2017 (86.5%) among all SFDA methods, and is even superior to some recently proposed traditional DA methods that require accessing source domain data. 2.