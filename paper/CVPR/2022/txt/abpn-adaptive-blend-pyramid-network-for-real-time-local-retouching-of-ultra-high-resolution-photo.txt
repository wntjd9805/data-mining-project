Abstract
Photo retouching ﬁnds many applications in various
ﬁelds. However, most existing methods are designed for global retouching and seldom pay attention to the local region, while the latter is actually much more tedious and time-consuming in photography pipelines. In this pa-per, we propose a novel adaptive blend pyramid network, which aims to achieve fast local retouching on ultra high-resolution photos. The network is mainly composed of two components: a context-aware local retouching layer (LRL) and an adaptive blend pyramid layer (BPL). The
LRL is designed to implement local retouching on low-resolution images, giving full consideration of the global context and local texture information, and the BPL is then developed to progressively expand the low-resolution re-sults to the higher ones, with the help of the proposed adaptive blend module and reﬁning module. Our method outperforms the existing methods by a large margin on two local photo retouching tasks and exhibits excellent performance in terms of running speed, achieving real-time inference on 4K images with a single NVIDIA Tesla
P100 GPU. Moreover, we introduce the ﬁrst high-deﬁnition cloth retouching dataset CRHD-3K to promote the research on local photo retouching. The dataset is available at https://github.com/youngLBW/CRHD-3K. 1.

Introduction
Photo retouching [25], especially portrait photo retouch-ing, ﬁnds a vast range of applications in photography sce-narios including wedding, advertisement, personal record-ing, etc. While extensive works [5, 12, 14, 21, 46, 57] yield impressive results on photo retouching, most of them ma-nipulate the attributes of the entire image, such as color, illumination, and exposure. Few methods deal with the lo-cal region in photos (e.g., face, clothing, and commodity),
*This work was done while Xiefan Guo was an intern at the DAMO. (cid:1)(cid:6)(cid:2) (cid:3)(cid:11)(cid:12)(cid:16)(cid:15) (cid:1)(cid:7)(cid:2) (cid:4)(cid:16)(cid:13)(cid:14) (cid:1)(cid:8)(cid:2) (cid:5)(cid:6)(cid:13)(cid:10)(cid:9)(cid:15)
Figure 1. High-ﬁdelity retouched photos. From left to right: (a) raw photos, (b) our retouched results, and (c) ground-truth images. which is actually the most tedious and time-consuming step in professional photography pipelines.
To focus on this kind of problem, we summarize them as the Local Photo Retouching (LPR) task, whose goal is to edit the target region in the photo and keep the rest area unchanged. Different from general local image edit-ing tasks (such as image inpainting and rain removal), LPR pays more attention to enhancing the aesthetic perception and visual quality of the target object. Fig. 1 gives some
LPR examples.
We conclude three main challenges of the LPR task as: (1) accurate localization of the target region; (2) local gen-eration with global consistency and detail ﬁdelity; and (3) efﬁcient processing of ultra high-resolution images. The
ﬁrst two are brought by the characteristics of the task it-self, while the last one is determined by the application sce-narios of LPR. As ultra high-resolution photos have been widely used in various photographic scenes, the ability to process them becomes a key factor of LPR methods in prac-tice. Given these challenges above, we in this paper analyze the applicability of existing methods to the LPR task and attempt to propose a more suitable solution to it.
In recent years, massive works have devoted to the image-to-image translation task and achieve impressive re-sults in style transfer [11, 16, 19, 45], semantic image syn-thesis [7, 18, 37], etc. Most of them adopt a deep net-work with an encoding-decoding paradigm to fulﬁll faith-ful translation, which results in a heavy computational, thus severely limiting their applications in some high-resolution scenarios. Some methods [12, 25, 47, 52] try to accelerate the models by transferring the computational burden from high-resolution maps to low-resolution ones and success-fully accomplish global translation on high-resolution im-ages. However, due to the lack of attention to local regions, few of them well adapt to the LPR task.
Instead of performing global translation, a number of works focus on the local image editing task, such as im-age inpainting [28, 39, 55], shadow removal [15, 32, 33], and rain removal [40–42, 48, 49]. Most of them rely on the masks that indicate the target region as input, while in the
LPR task, accurately acquiring such masks is itself a quite challenging issue. Though some methods resort to the deep generative networks and perform local editing without spec-ifying the masks, they are hardly capable of processing ultra high-resolution images directly. Besides, AutoRetouch [46] employs a sliding window strategy to achieve local model-ing and retouching, but it fails to capture the global context, especially in the case of high resolution.
Based on the observations, we propose a novel adaptive blend pyramid network (ABPN) for local retouching of ul-tra high-resolution photos, as shown in Fig. 3. The network addresses the three challenges aforementioned via two com-ponents: a context-aware local retouching layer (LRL) and an adaptive blend pyramid layer (BPL). In general, given a high-resolution image, the LRL performs local retouch-ing on its thumbnail and the subsequent BPL expands the outputs of LRL to the original size of the input. For LRL, speciﬁcally, we design a novel multi-task architecture to ful-ﬁll mask prediction of the target region and local generation simultaneously. A local attentive module (LAM) is pro-posed, where the local semantics and texture of the target region and the global context can be fully captured and ag-gregated to achieve consistent local retouching. For BPL, inspired by the blend layer in digital image editing, we de-velop a light-weight adaptive blend module (ABM) and its reverse version (R-ABM) to implement the fast expansion from the low-resolution results to the higher ones, ensuring great extensibility and detail ﬁdelity. Extensive experiments on two LPR tasks reveal that our method outperforms the existing methods by a large margin in terms of retouching quality and processing efﬁciency, demonstrating its superi-ority in the LPR task.
Moreover, since the editing work is usually time-consuming and requires high image processing skills, there are few publicly available datasets for the LPR task. Ac-cordingly, we build and release the ﬁrst high-deﬁnition cloth retouching dataset (CRHD-3K) to facilitate the research.
Our main contributions in this work are as follows: (A) We propose a novel framework ABPN for local retouch-ing of ultra high-resolution photos, which exhibits the re-markable efﬁciency performance (real-time inference on 4K images with a single NVIDIA Tesla P100 GPU) and supe-rior retouching quality to the existing methods. (B) We present a local attentive module (LAM), which is ef-fective in capturing and aggregating the global context and local texture. (C) We design an adaptive blend module (ABM), which provides powerful extensibility to the framework, allowing the fast expansion from low-resolution results to the higher ones. (D) To boost the research on LPR (e.g., cloth retouch-ing), we introduce the ﬁrst high-deﬁnition cloth retouching dataset CRHD-3K. 2.