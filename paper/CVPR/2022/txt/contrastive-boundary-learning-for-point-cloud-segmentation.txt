Abstract
Point cloud segmentation is fundamental in understand-ing 3D environments. However, current 3D point cloud segmentation methods usually perform poorly on scene boundaries, which degenerates the overall segmentation performance. In this paper, we focus on the segmentation of scene boundaries. Accordingly, we ﬁrst explore met-rics to evaluate the segmentation performance on scene boundaries. To address the unsatisfactory performance on boundaries, we then propose a novel contrastive bound-ary learning (CBL) framework for point cloud segmenta-tion. Speciﬁcally, the proposed CBL enhances feature dis-crimination between points across boundaries by contrast-ing their representations with the assistance of scene con-texts at multiple scales. By applying CBL on three differ-ent baseline methods, we experimentally show that CBL consistently improves different baselines and assists them to achieve compelling performance on boundaries, as well as the overall performance, e.g. in mIoU. The experimen-tal results demonstrate the effectiveness of our method and the importance of boundaries for 3D point cloud segmen-tation. Code and model will be made publicly available at https://github.com/LiyaoTang/contrastBoundary. 1.

Introduction 3D point cloud semantic segmentation aims to assign semantic categories to each 3D data point, while robust 3D segmentation is very important for various applications
[19, 64], including autonomous driving, unmanned aerial vehicles, and augmented reality.
However, despite that various point cloud segmentation methods have been developed, little attention has been put on boundaries in 3D point clouds. Accurate segmentation on scene boundaries can be of great importance. Firstly, a clean boundary estimation can be beneﬁcial for overall seg-mentation performance. For example, in 2D image segmen-tation, accurate segmentation on boundary is the key to gen-erate high-ﬁdelity masks [8, 36, 69]. Secondly, compared
Figure 1. Contrastive Boundary Learning (top) discovers bound-ary from ground truth in each sub-sampled point cloud, i.e., sub-scene, through the sub-sampling procedure. By imposing con-trastive optimization on boundary areas at multiple scales, CBL enhances the feature discrimination across boundaries (middle).
Without an explicit boundary prediction, CBL improves boundary segmentation and achieves better scene segmentation results (bot-tom). The visualization is conducted on S3DIS testset Area 5. to object categories that usually have a large portion of 3D points, such as buildings and trees, erroneous boundary seg-mentation could affect the recognition of object categories with much fewer points (e.g., pedestrians and pillars) to a greater extent. This can be particularly hazardous for appli-cations like autonomous driving, e.g., crashing into curbs if boundaries are recognized inaccurately by a self-driving car.
Unfortunately, most previous 3D segmentation methods generally overlook the segmentation on scene boundaries.
Though a few methods have considered boundaries, they still lack an explicit and comprehensive investigation to analyze the segmentation performance on boundary areas.
They also perform unsatisfactorily on the overall segmenta-tion performance.
Therefore, to deliver a more thorough study of the seg-mentation on boundaries, we ﬁrst explore metrics to quan-tify the segmentation performance on scene boundaries. Af-ter revealing the unsatisfactory performance, we propose a novel Contrastive Boundary Learning (CBL) framework to help optimize the segmentation performance on boundaries particularly, which also consistently improves the overall performance for different baseline methods.
In particular, current popular segmentation metrics lack speciﬁc measurements on boundaries, making it difﬁcult to reveal the boundary segmentation quality in existing meth-ods. To make a clearer view on the performance on bound-aries, we calculate the popular mean intersection-over-union (mIoU) for boundary areas and inner (non-boundary) areas separately. By comparing the performance on types of areas as well as the overall performance, the unsatisfactory performance on boundary areas can be directly revealed.
Moreover, to describe the performance on boundaries more comprehensively, we consider the alignment between the boundary in the ground truth and the boundary in model segmentation results. Therefore, we introduce the popular boundary IoU [8] score (B-IoU) used in 2D instance seg-mentation for evaluation, which also gives a much lower score compared with the overall performance in mIoU.
After identifying the boundary segmentation difﬁculties, we further propose a novel contrastive boundary learning (CBL) framework to better align the boundaries of model predictions with ground-truth data’s boundaries. As shown in Fig. 1, CBL optimizes a model on the feature representa-tion of points in boundary areas, enhancing the feature dis-crimination across the scene boundaries. Furthermore, to make model better aware of the boundary areas at multiple semantic scales, we also develop a sub-scene boundary min-ing strategy, which leverages the sub-sampling procedure to discover boundary points in each sub-sampled point cloud, i.e., sub-scene. Speciﬁcally, CBL operates across different sub-sampling stages and facilitates 3D segmentation meth-ods to learn better feature representation around boundary areas.
Empirically, we experiment with three baselines across four datasets. We ﬁrst present the unsatisfactory perfor-mance on boundary areas when using current point cloud segmentation methods and then show that CBL can assist baseline in achieving promising boundary and overall per-formance. For example, the proposed CBL helps RandLA-Net surpass current state-of-the-art methods on the Seman-tic3D dataset and enables a basic ConvNet to achieve lead-ing performance on the S3DIS dataset.
Our contributions are as follows:
• We explore the boundary problem in current 3D point cloud segmentation and quantify it with metrics that consider boundary area, e.g., boundary IoU. The re-sults reveal that current methods deliver much worse accuracy in boundary areas than their overall perfor-mance.
• We propose a novel Contrastive Boundary Learning (CBL) framework, which improves the feature repre-sentation by contrasting the point features across the scene boundaries. It thus improves the segmentation performance around boundary areas and subsequently the overall performance.
• We conduct extensive experiments and show that CBL can bring signiﬁcant and consistent improvements on boundary area as well as overall performance across all baselines. These empirical results further demonstrate that CBL is effective for improving boundary segmen-tation performance, and accurate boundary segmenta-tion is important for robust 3D segmentation. 2.