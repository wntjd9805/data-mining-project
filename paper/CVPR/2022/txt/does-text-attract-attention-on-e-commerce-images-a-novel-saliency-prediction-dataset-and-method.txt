Abstract
E-commerce images are playing a central role in attract-ing people’s attention when retailing and shopping online, and an accurate attention prediction is of significant impor-tance for both customers and retailers, where its research is yet to start. In this paper, we establish the first dataset of saliency e-commerce images (SalECI), which allows for learning to predict saliency on the e-commerce images. We then provide specialized and thorough analysis by high-lighting the distinct features of e-commerce images, e.g., non-locality and correlation to text regions. Correspond-ingly, taking advantages of the non-local and self-attention mechanisms, we propose a salient SWin-Transformer back-bone, followed by a multi-task learning with saliency and text detection heads, where an information flow mechanism is proposed to further benefit both tasks. Experimental re-sults have verified the state-of-the-art performances of our work in the e-commerce scenario. 1.

Introduction
Nowadays, online retailing has revolutionized the shop-ping habits in daily life, which provides significantly im-proved efficiency and hands-on experiences for both cos-tumers and retailers. The sudden break of Coronavirus-19 further emphasized the importance and popularity of online shopping. Since “a picture is worth a thousand words”, the e-commerce image, exhibiting rich and heuristic content, has been a workhorse in promoting products on online shop-ping and it therefore plays a vital role in the shopping activ-ities, including introducing products, aiding visual search, attracting costumers, and affecting their final decisions.
Due to the intrinsic nature of retailing, the main goal of e-commerce images is to attract costumer attentions at a glimpse; this is mainly two-fold: 1) attracting costumers to focus on the product when they are wandering on shopping, and 2) attracting to focus on specific parts in images that highlight distinguishable and “have-to-buy” features of the
*Both authors contributed equally to this research.
†Corresponding authors: Shengxi Li (LiShengxi@buaa.edu.cn), Mai
Xu (MaiXu@buaa.edu.cn)
Figure 1. Saliency maps of ground-truth, DeepGace IIE [26],
UNISAL [7], and the proposed method. As shown, the exist-ing methods on natural images trend to over- or under-predict the saliency values of text regions in e-commerce images. product. Consequently, the e-commerce image is typically a combination of pictures and texts, to achieve the goal of both effectively attracting and introducing to the costumers.
Thus, saliency prediction on e-commerce images is of sig-nificant importance to provide both enhanced guiding infor-mation and shopping experience for costumers.
The existing works of saliency prediction almost focus on the natural images, from the perspective of either low-level handcrafted cues [14, 44] or data-driven deep neu-ral networks (DNNs) [7, 18, 27, 29]. However, with the fundamental goal of retailing, the e-commerce images are specially designed, especially with short but precise texts.
Thus, the e-commerce images are basically different from the widely analysed natural images, which for example, are created by the goals of beauty, recording, etc. Con-sequently, the existing methods are inadequate in predict-ing saliency of the e-commerce images. For example, the object region in natural images, one of the most important high-level cues when predicting saliency in existing meth-ods [13, 17], may be equally and even less salient than the text regions in e-commerce images that highlight key fea-tures and brands of products. Fig. 1 illustrates the limitation of the existing saliency prediction methods on e-commerce images, where the most recent methods on natural images, i.e., DeepGace IIE [26] and UNISAL [7], trend to over- or
under-predict the saliency value of the text regions. Thus, it is necessary and important to develop a new DNN for e-commerce images, by addressing the text priors. Mean-while, the lack of e-commerce image dataset also impedes applying DNN-based models for saliency prediction.
To this end, we propose a novel work on saliency pre-diction for e-commerce images. More specifically, we es-tablish the first eye-tracking dataset of e-commerce im-ages, called SalECI, with recorded fixations from the eye-tracking experiments. We further analyse the proposed dataset, obtaining 4 observations. Upon the observations, we validate the non-locality nature of saliency maps. Due to the fact that saliency explicitly points out human attentions when looking at e-commerce images, we take the advan-tages of non-local and attention mechanisms of Transform-ers [40], and propose a salient Swin-Transformer (SSwin-Transformer) backbone that incorporates the saliency infor-mation to improve the learnt self-attention maps. More im-portantly, our observations also point out a consistent and strong relationship between the salient and text regions.
Therefore, we propose to simultaneously predict saliency and detect text regions by two learnable heads, together with an information flow to let the two heads interact between each other. The experimental results have verified the state-of-the-art performance of our work. A further application to e-commerce image compression further achieves signifi-cant bit-rate saving. Our main contributions are as follows,
• We establish the first SalECI dataset, enabling ad-vanced data-driven architectures to predict saliency on e-commerce images;
• We provide thoroughgoing and comprehensive analy-sis on the SalECI dataset, paving the way of special-ized and insightful methods on e-commerce images;
• We propose a novel multi-task learning framework in-cluding the SSWin-Transformer, multiple heads and information flow mechanism, achieving the state-of-the-art performances on e-commerce scenarios. 2.