Abstract
We introduce CAPRI-Net, a self-supervised neural net-work for learning compact and interpretable implicit repre-sentations of 3D computer-aided design (CAD) models, in the form of adaptive primitive assemblies. Given an input 3D shape, our network reconstructs it by an assembly of quadric surface primitives via constructive solid geometry (CSG) operations. Without any ground-truth shape assem-blies, our self-supervised network is trained with a recon-struction loss, leading to faithful 3D reconstructions with sharp edges and plausible CSG trees. While the parametric nature of CAD models does make them more predictable locally, at the shape level, there is much structural and topological variation, which presents a significant general-izability challenge to state-of-the-art neural models for 3D shapes. Our network addresses this challenge by adaptive training with respect to each test shape, with which we fine-tune the network that was pre-trained on a model collection.
We evaluate our learning framework on both ShapeNet and
ABC, the largest and most diverse CAD dataset to date, in terms of reconstruction quality, sharp edges, compactness, and interpretability, to demonstrate superiority over current alternatives for neural CAD reconstruction. 1.

Introduction
Computer-Aided Design (CAD) models are ubiquitous in engineering and manufacturing to drive decision mak-ing and product evolution related to 3D shapes and ge-ometry. With the rapid advances in AI-powered solutions across all relevant fields, several CAD datasets [29, 50, 57] have emerged to support research in geometric deep learn-ing. A common characteristic of CAD models is that they are composed of well-defined parametric surfaces meeting along sharp edges. While the parametric nature of the CAD shapes do make them more predictable locally and at the primitive level, at the shape level, there is a great deal of structural and topological variations, which presents a sig-nificant generalizability challenge to current neural mod-els for 3D shapes [8, 10, 21, 30, 35, 37, 40, 59, 63]. On the
Figure 1. Our network learns compact and interpretable implicit representations of 3D CAD shapes in the form of primitive assem-blies via CSG operations, without any assembly supervision. other hand, existing networks for primitive fitting typically focus on abstractions with simple, hence limited, primi-tives [39, 42, 54, 64], hindering reconstruction quality.
In this paper, we develop a learning framework for 3D
CAD shapes to address these very challenges. Our goal is to design a neural network that can learn a compact and interpretable representation for CAD models, leading to high-quality 3D reconstruction, while the network general-izes well over ABC [29], the largest and most diverse CAD dataset to date. This dataset is a collection of one million
CAD models covering a wide range of structural, topolog-ical, and geometric variations, without any category labels, in contrast to other prominent repositories of man-made shapes such as ShapeNet [4] and ModelNet [60] which have only limited1 number of object categories. Hence, targeting the ABC dataset poses a real generalizability challenge.
Our network takes an input 3D shape as a point cloud or 1While the full ShapeNet dataset has 270 object categories, to the best of our knowledge, most learning methods only work with up to 13.
Figure 2. Overview of our network. Given an input 3D shape as a point cloud or voxels, we first map it into a latent code using an encoder.
This latent code is used to predict p primitives with parameters included in P. For any query point qj packed in matrix Q, we can obtain the matrix D indicating approximate signed distance from the query point to each primitive. A selection matrix T is used to select a small set of primitives from the primitive set to group convex shapes in matrix C which indicates inside/outside values for query points w.r.t convex shapes. Then, we perform min operation on each half of C (i.e. Cl and Cr) to union convex shapes into two (possibly) concave shapes and get inside/outside indication vectors al and ar for left and right concave shapes. Finally, we perform a difference operation as al − ar to obtain the final point-wise inside/outside indicator s. LT, LW, and Lrec are the loss functions we define for our network. voxel grids, and reconstructs it by a compact assembly of quadric surface primitives via constructive solid geometry (CSG) operations including intersection, union, and differ-ence. Specifically, the learned quadrics are assembled by a series of binary selection matrices. These matrices intersect the quadrics to form convex parts, with union operations to follow to obtain possibly concave shapes, and finally a difference operation naturally models holes present in high-genus models, which are frequently encountered in CAD.
The architecture of our network, shown in Figure 2, is in-spired by BSP-Net [8]. At the high level, it is a coordinate-based network trained with an occupancy loss reflecting the reconstruction error; we also add a novel loss to accommo-date a new difference operation. The reconstruction is per-formed in a latent space that is obtained by an encoder ap-plied to the input shape. The other learnable parameters of the network include matrices that define the parameters of the quadric surfaces and the CSG operations, respectively, as well as MLP weights which map the latent code to the primitive parameter matrix. The resulting reconstruction is in the form of a CSG assembly, while the network training does not require any ground-truth shape assemblies — the network is self-supervised with the reconstruction loss.
Due to the significant variations among CAD shapes in
ABC, we found that our network, when trained on a model collection only, does not generalize well. In fact, none of the existing reconstruction networks we tested, including
IM-Net [10], OccNet [35], DISN [63], BSP-Net [8], gen-eralized well on the ABC dataset. We tackle this issue by further fine-tuning the network, that is pre-trained on a train-ing set, to a test CAD shape, so that the resulting network is adaptive to the test shape. Both pre-training and fine-tuning are performed using the same network architecture, shown in Figure 2, except that the encoder is not re-trained during fine-tuning for efficiency. We coin our learning framework
CAPRI-Net, as it is trained to produce Compact and Adap-tive PRImitive assemblies for CAD shapes.
We evaluate CAPRI-Net on both ABC and ShapeNet, in terms of reconstruction quality, compactness as mea-sured by primitive counts, and interpretability as exam-ined by how natural the recovered primitive assemblies are. Qualitative and quantitative comparisons are made to
BSP-Net [8], UCSG [28], and CSGStump [12], a concur-rent work, all of which are representative of state-of-the-art learning methods suitable for CAD shapes. The results demonstrate superiority of CAPRI-Net on all fronts.
The primary application of CAPRI-Net is 3D shape re-construction, where the network produces a novel implicit field that is unlike those obtained by classical computer graphics methods [23], e.g., a radial basis function [3], or those learned by recent neural implicit models, e.g., IM-Net [10], OccNet [35], and SIREN [48], etc. Our implicit representation is structured, as a compact assembly, and leads to quality reconstruction of 3D CAD models. 2.