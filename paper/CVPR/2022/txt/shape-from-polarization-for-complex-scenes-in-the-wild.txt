Abstract
We present a new data-driven approach with physics-based priors to scene-level normal estimation from a single polarization image. Existing shape from polarization (SfP) works mainly focus on estimating the normal of a single ob-ject rather than complex scenes in the wild. A key barrier to high-quality scene-level SfP is the lack of real-world SfP data in complex scenes. Hence, we contribute the first real-world scene-level SfP dataset with paired input polarization images and ground-truth normal maps. Then we propose a learning-based framework with a multi-head self-attention module and viewing encoding, which is designed to handle increasing polarization ambiguities caused by complex ma-terials and non-orthographic projection in scene-level SfP.
Our trained model can be generalized to far-field outdoor scenes as the relationship between polarized light and sur-face normals is not affected by distance. Experimental re-sults demonstrate that our approach significantly outper-forms existing SfP models on two datasets. Our dataset and source code will be publicly available at https:
//github.com/ChenyangLEI/sfp-wild.
Input Iun
Input ϕ
Without pol.
With pol.
Figure 1. Our method can estimate dense scene-level surface nor-mals from a single polarization image. Polarization can provide effective cues for obtaining more accurate results. In the first row, polarization provides geometry cues for our model so that it is not fooled by objects in the printed image on a wall. In the second and third rows, polarization provides guidance for planes with dif-ferent surface normals even when their materials are quite similar.
Iun: unpolarized image; ϕ: angle of polarization. 1.

Introduction
Accurate surface normal estimation in the wild can pro-vide valuable information about a scene’s geometry and can be used in various computer vision tasks, including segmentation [19], 3D reconstruction [26], and many oth-ers [22, 33]. Therefore, normal estimation is an important task studied for a long time. However, estimating high-quality normals in the wild is still an open problem. Var-ious techniques such as photometric stereo [9, 10] can pro-duce high-frequency normals, but most of them only pro-vide short-range object-level normal maps. Active depth sensors can be another approach to obtaining normals from depth maps, but the corresponding depth maps are often sparse (LiDAR) or noisy (time-of-flight, structured light) so they can not estimate normals reliably. Also, the depth range of active sensors is limited.
*Joint first authors
In this work, we are interested in estimating surface nor-mal from a single polarization image for complex scenes in the wild. Since the polarization of light changes differently when the light interacts with the surfaces of different shapes and materials (governed by the Fresnel equations [12]), the polarization images can provide dense surface orientation cues from the polarized light perceived at each pixel. Also, compared with the active sensors and object-level normal estimation techniques (e.g., photometric stereo), the polar-ization camera is a passive sensor that is not constrained to a specific depth range. Thus polarization images are promis-ing data sources for accurate normal estimation in the wild.
However, estimating normals from a polarization image for complex scenes (scene-level SfP) is challenging. To the best of our knowledge, no existing SfP work focuses on complex scenes, and several challenges are yet to be solved. Firstly, polarization contains ambiguities from un-known information such as object materials and reflection
types [12]. Object-level SfP methods approach these am-biguities by utilizing various cues (e.g., shading [44]) or making restrictive assumptions (e.g., known albedo [35]), which are unfeasible for multiple-object scenes because of the variabilities of material properties and complexities of reflections. Secondly, while some works [4, 29] demon-strate the potential of combining convolutional neural net-works and polarization cues in estimating normals for un-known materials, there are only object-level [4] or synthetic data [29] for training, which are not sufficient for scene-level SfP. Finally, scene-level SfP brings up another chal-lenge. The viewing direction influences the measured polar-ization information. Previous object-level SfP approaches ignore the impact of viewing direction since they assume orthographic projection by placing objects at the center of an image, which does not hold for scene-level SfP.
To solve the challenge of lacking real-world scene-level polarization data, we construct the first real-world scene-level SfP dataset that contains diverse complex scenes.
Building such a new dataset is necessary because the ex-isting DeepSfP dataset [4] only contains a single object per image and the dataset by Kondo et al. [29] is synthetic and not publicly available.
Due to the challenges of scene-level SfP, the perfor-mances of previous learning-based SfP works [4,29] are not satisfactory when they are trained on our scene-level data.
To improve the performance of scene-level SfP in the wild, we adopt three novel designs in our model. First, we intro-duce multi-head self-attention [45] in a convolutional neural network (CNN) for SfP. Multi-head self-attention utilizes the global context of an image, which helps the CNN re-solve the local ambiguities in polarization cues. Second, to handle non-orthographic projection for scene-level SfP, the neural network must be aware of the viewing direction of each pixel since the convolution operation is translation in-variant. We thus propose a simple but critical technique that improves the performance of SfP methods on scene-level data: providing per-pixel viewing encoding to the neural network. Finally, as an additional contribution, we design a novel polarization representation, which is effective and considerably more efficient than the representations in prior work [4].
We compare our approach with various state-of-the-art methods. Experimental results show that our model can generate a high-quality normal map from a single polar-ization image (Fig. 1) and can generalize beyond the depth range of the training data. In summary, our contributions are as follows.
• We construct the first real-world SfP dataset contain-ing paired input polarization images and ground-truth normal maps in complex scenes.
• Our proposed shape-from-polarization approach is the first one trained on complex real-world scene-level data and also the best-performing one for normal es-timation from polarization in the wild.
• Technically, we introduce three novel designs to scene-level SfP: viewing encoding that can handle the chal-lenge of non-orthographic projection in scene-level
SfP, a dedicated network architecture that adopts multi-head self-attention for SfP, and a practical po-larization representation that is effective and efficient. 2.