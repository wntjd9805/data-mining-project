Abstract expression
Handwritten mathematical recognition (HMER) is a challenging task that has many potential applications. Recent methods for HMER have achieved outstanding performance with an encoder-decoder archi-tecture. However, these methods adhere to the paradigm that the prediction is made “from one character to an-other”, which inevitably yields prediction errors due to the complicated structures of mathematical expressions or crabbed handwritings.
In this paper, we propose a simple and efﬁcient method for HMER, which is the ﬁrst to incorporate syntax information into an encoder-decoder network. Speciﬁcally, we present a set of grammar rules for converting the LaTeX markup sequence of each expression into a parsing tree; then, we model the markup sequence prediction as a tree traverse process with a deep neural network. In this way, the proposed method can effectively describe the syntax context of expressions, alleviating the structure prediction errors of HMER. Experiments on three benchmark datasets demonstrate that our method achieves better recognition performance than prior arts. To further validate the effectiveness of our method, we create a large-scale dataset consisting of 100k handwritten mathematical expression images acquired from ten thousand writers. The source code, new dataset†, and pre-trained models of this work will be publicly available. 1.

Introduction
With the development of deep learning methods, the ex-isting text recognition approaches are good at handling text lines in an image-to-sequence manner [24–26, 35]. How-they may fail to deal with complicated structures ever, such as mathematical expressions (ME). This paper inves-tigates ofﬂine handwritten mathematical expression recog-nition (HMER), an important OCR task required by many
*Authors contribute equally.
†https://ai.100tal.com/dataset
‡Corresponding author 1 applications like ofﬁce automation, answer sheet correc-tion, and assistance for visually disabled persons to under-stand mathematics. HMER is quite challenging, as a 2D structure relationship is essential for understanding mathe-matical expressions, which is seldom considered in previ-ous deep learning-based methods. Besides, the ambiguities brought by handwritten input further increase the difﬁculty of HMER.
Early works have well studied ME’s syntax structures, and the proper grammars are deﬁned for HMER [1, 6, 14, 34]. These grammars are only used for grouping the rec-ognized symbols into a structural output, heavily relying on the performance of symbol recognition. Moreover, as these methods are mainly designed with handcraft features, their performance is far from the requirement of real-world ap-plications.
Due to the recent advancement of deep neural networks, some recent studies [8, 39, 43] handle HMER as an image-to-sequence prediction procedure using an encoder-decoder architecture, achieving signiﬁcant performance improve-ments. However, these methods more or less neglect the syntax information contained in MEs. To clearly illustrate this limitation, we take two recent network architectures as examples in Fig. 1. Zhang et al. [43] propose the Watch,
Attend and Parse (WAP) method that employs a fully con-volutional network to encode handwritten images and a re-current neural network as the string decoder to generate se-quence outputs (Fig. 1(a)). [42] (DWAP-TD) attempt to consider the syntax information by decomposing the target syntactic structure tree into a sequence of sub-trees, where each sub-tree is composed of a parent node and a child node (Fig. 1(b)). Though DWAP-TD can produce the output of a tree structure, it still follows the “from one character to an-other” paradigm that the next symbol prediction is mainly based on the current symbol. We argue that such methods don’t explicitly consider the syntactic relationship of MEs in the learning process, which lacks the syntax constraints for generating a reasonable tree prediction.
To solve structure prediction error and improve the com-plex syntax tree understanding, we propose an elaborate
Figure 1. Comparison of different architectures: (a) An encoder-decoder framework WAP (b) A tree decoder DWAP-TD (c) Our model Syntax-Aware Network (SAN) grammar, which can naturally divide a syntax tree into dif-ferent components and efﬁciently reduce tree structure am-biguity. Then, we establish an encoder-decoder network named syntax-aware network (SAN), which incorporates grammatical constraints and feature learning in a uniﬁed framework. Our intuition is that an ideal HMER model should parse handwritten mathematical expression images according to syntactic relationships, meanwhile effectively alleviating prediction errors caused by complex structures and crabbed writings. As shown in Fig. 1 (c), the prediction process of SAN follows the traverse process of a grammar tree, whose subtree is a signiﬁcant component of a math-ematical expression. In this manner, the syntactic relation-ship of adjacent components can be encoded in the proposed
SAN model. Consequently, the prediction of SAN is made from one component to another component during the pars-ing procedure.
To evaluate the proposed SAN, we conduct the experi-ments on the three popular datasets, CROHME 2014 [20],
CROHME 2016 [21] and CROHME 2019 [19]. To fur-ther conﬁrm the effectiveness of SAN, we collect and an-notate a large-scale dataset for the evaluation, termed as
HME100K. HME100K contains 100k handwritten math-ematical expression images from ten thousand writers, mainly captured by cameras. Compared with the CHROME datasets [19–21], the data size of HME100K is increased tenfold. The results on CHROME 2014, CHROME 2016,
CHROME 2019 and HME100K show that our method con-sistently achieves higher recognition rates over the state-of-the-art methods, demonstrating the advantage of embedding syntax cues for HMER.
The main contribution of this paper is the proposed syntax-aware network, which effectively embeds syntac-tic information into deep neural networks at the ﬁrst time.
Another contribution of this paper is the proposed large and diverse dataset HME100K. Compared with the exist-ing benchmark datasets, our dataset includes the HME with 2
Figure 2. Sample Recognition Results of SAN and DWAP-TD.
The SAN heatmaps indicate the model is focused on different components. The characters in red refer to the lost component during the prediction. longer lengths and more complicated structures, making it useful to promote more robust algorithms toward real-world applications. 2.