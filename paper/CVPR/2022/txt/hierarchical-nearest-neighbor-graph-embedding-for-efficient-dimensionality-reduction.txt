Abstract
Dimensionality reduction is crucial both for visualiza-tion and preprocessing high dimensional data for machine learning. We introduce a novel method based on a hierar-chy built on 1-nearest neighbor graphs in the original space which is used to preserve the grouping properties of the data distribution on multiple levels. The core of the proposal is an optimization-free projection that is competitive with the latest versions of t-SNE and UMAP in performance and vi-sualization quality while being an order of magnitude faster at run-time. Furthermore, its interpretable mechanics, the ability to project new data, and the natural separation of data clusters in visualizations make it a general purpose unsupervised dimension reduction technique. In the paper, we argue about the soundness of the proposed method and evaluate it on a diverse collection of datasets with sizes varying from 1K to 11M samples and dimensions from 28 to 16K. We perform comparisons with other state-of-the-art methods on multiple metrics and target dimensions high-lighting its efficiency and performance. Code is available at https://github.com/koulakis/h-nne 1.

Introduction
Dimensionality reduction techniques are now increas-ingly used in many fields of science and have to cope with an ever increasing size of real-world datasets. It plays an important role both for visualization and processing of high dimensional data. Much of current research is focused on finding unsupervised algorithms that are both scalable to massive data and are able to preserve the structure of data in less dimensions. Most of them attempt to retain the lo-cal or global structure of the data by optimizing over pair-wise distances in the target space. Two main directions for the current dimension reduction techniques can be iden-tified with respect to how such local or global neighbor-hood is preserved in terms of the distances. Methods such as PCA [15], MDS [18] and Sammom mapping [31] try
Figure 1. Visualization of the entire ImageNet dataset. Speed and embedding quality of dimension reduction methods. to preserve the global distances among all samples in the data. Whereas more recent popular methods such as t-SNE [35,36], LargeVis [33], and UMAP [26,30] seek to ad-ditionally preserve the local structure e.g. by preserving the distance relations in the k-neighborhood of each data sam-ple. To retain such relations, these methods generally have to solve an optimization problem with the goal of matching the distribution of distances in the target space with their distribution in the original space. For instance, t-SNE min-imizes the Kullback-Leibler divergence between distribu-tions of k-nearest neighbor (k-NN) distances fitted in the high and low-dimensional space. Similarly, the more recent method UMAP optimizes the embedding in the target space with the goal of preserving the 1-skeleton of fuzzy simpli-cial sets constructed in the original space. Such optimiza-tions are computationally expensive in nature and account
for the main complexity of these algorithms, thus limiting their run-time performance on large scale datasets.
In this paper, we present a different approach which in-stead of relying on point-level optimization, captures multi-stage NN properties of the data and, using those, projects points in a simple algorithmic way. The main tools used to build this structure are Nearest Neighbor Graphs (NNGs) which have been well studied. In [12] Epstein et al. show that for a 1-NNG, its NN relations are well preserved in a low dimensional space when the edges are placed on a monotone logical grid [8]. An effective strategy for embed-ding the NNG into an l-dimensional grid is to embed the individual components of the graph separately. The con-nected components of NNGs capture clusters of samples.
Recursively building 1-NNGs on the previously obtained connected components provides a hierarchical view on how samples are merged together at successive levels. Consid-ering each connected component as a node in the hierarchy one can identify complete paths on how these nodes and their associated samples successively merge together from bottom to top. Such a hierarchical node graph provides a view of data in terms of how the local neighborhood is dis-tributed in the high dimensional space. After an inexpen-sive preliminary projection of the high dimensional data on a desired low dimensional space we can use the original hi-erarchical node graph in the target space to enforce the local structure directly. We achieve this with a fast recursive top-down approach by moving the clusters of samples towards these nodes starting at the top level with the least number of nodes and moving progressively downward to reach the bottom i.e. the finer level.
Since our proposal is rooted in obtaining the Hierarchi-cal 1-Nearest Neighbor graph based Embedding, we term the method h-NNE. Figure 1 depicts an example of embed-ding the ResNet-50 features of the full ImageNet dataset.
As seen, in comparison to the current state-of-the-art meth-ods, not only do we achieve competitive embedding quality
- indicated by the trustworthiness metric - but also a signif-icantly faster run-time. To summarize, our main contribu-tion is an alternative dimensionality reduction and visual-ization method which does not rely on expensive optimiza-tion methods. This makes it operate at a magnitude faster than existing methods, without requiring hyperparameter tuning, and maintaining similar performance.
In the fol-lowing sections, before delving into the proposed method, we will discuss the related works to place it in context and followed by experiments and comparisons with the state-of-the-art on a diverse collection of datasets. 2.