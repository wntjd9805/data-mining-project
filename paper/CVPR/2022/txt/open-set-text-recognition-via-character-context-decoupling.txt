Abstract
The open-set text recognition task is an emerging chal-lenge that requires an extra capability to cognize novel characters during evaluation. We argue that a major cause of the limited performance for current methods is the con-founding effect of contextual information over the visual information of individual characters. Under open-set sce-narios, the intractable bias in contextual information can be passed down to visual information, consequently im-pairing the classiﬁcation performance.
In this paper, a
Character-Context Decoupling framework is proposed to alleviate this problem by separating contextual informa-tion and character-visual information. Contextual informa-tion can be decomposed into temporal information and lin-guistic information. Here, temporal information that mod-els character order and word length is isolated with a de-tached temporal attention module. Linguistic information that models n-gram and other linguistic statistics is sepa-rated with a decoupled context anchor mechanism. A va-riety of quantitative and qualitative experiments show that our method achieves promising performance on open-set, zero-shot, and close-set text recognition datasets. 1.

Introduction
Text recognition is a well-studied task and has been widely applied in various applications [7]. Most existing text recognition methods assume characters in the testing set are covered by the training set. Moreover, consistency of contextual information between the training set and the testing set is also assumed. These methods are not adapt-able to recognize unseen characters without retraining the model. However, as the language evolves, novel ligatures (e.g., rare characters, emoticons, and foreign characters) can be frequently used in a region during a certain period.
For example, foreign characters can be seen frequently in scene text images as a result of globalization. Hence, it is
Figure 1. Illustration of the “salience region” [37] of each times-tamp, showing where the models look at. Base model (top) tends to seek the help from the context, while our framework (bottom) focuses more on local character features. unfeasible if the model needs to be retrained whenever a
“new character” emerges. This task is deﬁned as the open-set text recognition task [23], as a speciﬁc ﬁeld of open-set recognition [33] and a typical case of robust pattern recog-nition [54]. Currently, a few visual-matching-based text recognition methods are capable to recognize novel char-acters in text lines [16, 23, 52].
However, these open-set text recognition methods tend to be affected by contextual information captured from the training set. This phenomenon can be seen in the salience map (Fig. 1) 1, and is also observed in [41]. In such cases, feature representation for each character is always mixed with linguistic information. This could beneﬁt close-set scenarios where the contextual information bias between training and evaluation is negligible, as some characters (e.g. ‘0’ and ‘O’) are hard to separate only by character vi-sual information (glyph shapes). However, under open-set scenarios, contextual information could be severely biased from the training set. Consequentially, existing models may mistakenly “correct” a character into a wrong one that ﬁts
“better” in the context according to the training set [41].
To alleviate the impact of contextual information over open-set text recognition, we propose a character-context decoupling framework allowing explicit separation of char-acter visual information and contextual information. Con-∗Corresponding authors. 1https://github.com/MisaOgura/flashtorch
textual information is further decomposed into temporal in-formation and linguistic information. In general, temporal information models the number and order of characters in a word, while linguistic information models n-gram and other linguistic statistics. Accordingly, a Detached Temporal At-tention module (DTA) is introduced to model temporal in-formation and isolate it from visual features. Also, a Decou-pled Context Anchor mechanism (DCA) is proposed to “ex-plain away [47]” the linguistic information from character visual information. In summary, our framework reduces the confounding effect of training-set contextual information on visual features, making it less vulnerable to the intractable contextual information bias under open-set scenarios.
The main contributions of this paper are summarized as follows: (1) Proposing a Character-Context Decoupling Frame-work that improves word-level open-set text recognition by reducing the effect of contextual information on the visual representation of novel characters in word-level samples. (2) Proposing a Detached Temporal Attention module that reduces the impact of temporal information over the visual feature extractor. (3) Proposing a Decoupled Context Anchor mechanism that enables the separation of linguistic information from the visual feature extractor. 2.