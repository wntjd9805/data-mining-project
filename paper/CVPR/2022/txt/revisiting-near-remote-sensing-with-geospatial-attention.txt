Abstract
This work addresses the task of overhead image segmen-tation when auxiliary ground-level images are available.
Recent work has shown that performing joint inference over these two modalities, often called near/remote sensing, can yield significant accuracy improvements. Extending this line of work, we introduce the concept of geospatial atten-tion, a geometry-aware attention mechanism that explicitly considers the geospatial relationship between the pixels in a ground-level image and a geographic location. We propose an approach for computing geospatial attention that incor-porates geometric features and the appearance of the over-head and ground-level imagery. We introduce a novel ar-chitecture for near/remote sensing that is based on geospa-tial attention and demonstrate its use for five segmentation tasks. The results demonstrate that our method significantly outperforms the previous state-of-the-art methods. 1.

Introduction
Accurately monitoring the Earth’s surface is critical to
Important many scientific fields and to society at large. applications include weather forecasting, disaster response, population density estimation, and environmental monitor-ing. Traditionally these applications have relied on re-mote sensing approaches applied to overhead imagery from satellite or airborne cameras. Computer vision techniques have long been applied to such imagery to automate var-ious tasks [14, 35, 48], including recent work on detect-ing roads [33], estimating land cover [39], understanding traffic flow [55], and constructing dynamic visual attribute maps [41].
In addition, the use of imagery from alternative sources, such as consumer devices [50] and webcams [17], has been explored for various monitoring applications. For exam-ple, geotagged ground-level images, including consumer photographs, have been used to monitor weather [50], estimate geo-informative attributes [23], and characterize safety [1]. Similarly, webcam imagery has been used for vegetation [44], snow cover [38], and marine debris [20] monitoring. This class of methods, often referred to as
Figure 1. We introduce a novel neural network architecture that uses geospatial attention in the setting of near/remote sensing.
Our approach operates on an overhead image and a set of nearby ground-level panoramas, enabling optimal feature extraction for a query location (square) from each ground-level image (circle) in a manner that is “geometry-aware”. proximate sensing [25] or image-driven mapping, uses large georeferenced photo collections to derive geospatial infor-mation.
These two strategies, remote and proximate sensing, of-fer complementary viewpoints of the world. Overhead im-agery is widely available at increasingly high resolutions and has dense coverage. However, fine-grained properties are often hard to characterize from only a top-down per-spective [57]. In contrast, geotagged ground-level images are sparsely distributed but capture high resolution, seman-tically rich details. To convert these sparse samples into a dense map, an additional process, such as geometric warp-ing or locally weighted averaging, is required. This means that using only ground-level imagery results in either miss-ing values for areas that are not imaged or low spatial reso-lution outputs [1].
Combining these two modalities, which we refer to as near/remote sensing, has emerged as a compelling research area that addresses weaknesses in methods that only use a single modality. Early techniques focused on building ex-plicit geometric models [9]. Our work is more closely re-lated to methods that attempt to extract semantic informa-tion, such as that of Luo et al. [31] on event recognition.
Other methods have been proposed that consider how to re-late information from pairs of co-located ground-level and overhead images [27, 53, 56]. Recently, network architec-tures have been proposed that allow for combining an over-head image with nearby ground-level images for general segmentation tasks [5, 58].
The standard approach is to extract image features from nearby ground-level images, fuse them to form a dense grid of features that is geospatially aligned with features ex-tracted from the overhead image, and concatenate the two feature sets for joint inference. Though this strategy has shown great promise versus single-modality alternatives, there remains significant room for improvement. One major limitation of current approaches is the use of global image features, which ignore important geometric information. A new approach is needed in order to extract meaningful geo-informative features from each sample for the given task.
In this work we introduce the concept of geospatial at-tention. As opposed to a standard spatial attention module (e.g., [52]), which operates solely on an input feature map to identify salient regions, geospatial attention additionally considers the geospatial relationship between the input and a target location, with the goal of identifying meaningful geo-informative regions. The key insight is that for many tasks, the position and orientation of the input relative to a location of interest is crucial for optimally fusing informa-tion from multiple sources (Figure 1). We propose a method for estimating geospatial attention that incorporates the se-mantic content of the input image in addition to geometry and overhead appearance, with the goal of identifying geo-informative regions of the input.
We introduce a novel neural network architecture that uses geospatial attention in the setting of near/remote sens-ing. Our approach operates on an overhead image and a set of nearby ground-level panoramas. It simultaneously learns to extract features from each image modality in an end-to-end fashion. To support evaluation, we extend an existing dataset with two new per-pixel labeling tasks. Extensive evaluation demonstrates the utility of our approach for five land use, building age, building function, labeling tasks: land cover, and height. Significant improvements in accu-racy are observed relative to previous work and an internal ablation study is used to highlight the most important com-ponents. 2.