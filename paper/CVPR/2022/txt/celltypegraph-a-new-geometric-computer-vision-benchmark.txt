Abstract
Classifying all cells in an organ is a relevant and dif-ficult problem from plant developmental biology. We here abstract the problem into a new benchmark for node clas-sification in a geo-referenced graph. Solving it requires learning the spatial layout of the organ including symme-tries. To allow the convenient testing of new geometrical learning methods, the benchmark of Arabidopsis thaliana ovules is made available as a PyTorch data loader, along with a large number of precomputed features. Finally, we benchmark eight recent graph neural network architectures, finding that DeeperGCN currently works best on this prob-lem. 1.

Introduction
Understanding morphogenesis, the generation of form, remains a major challenge in biology.
It requires a de-tailed quantitative description of the molecular and cellular processes of the underlying mechanism. 3D digital organs with cellular spatial resolution promise to help decipher the morphogenesis of complex organs in plants [19, 32, 36, 54].
They can be generated by 3D microscopic imaging followed by cell instance segmentation and tissue annotation. Plant organs lend themselves to this approach as they exhibit a relatively well-structured, layered organization and the tis-sues can be identified based on their positions and morphol-ogy. Thus, plant developmental biology is profiting from a growing body of 3D digital organs. However, automatic an-notation [31,32,40] of different tissue types within an organ remains a major problem in the field, particularly for plant organs of complex cellular architecture and shape such as ovules of Arabidopsis thaliana [51].
In medical image analysis, the analogous problem of to plant morphogenesis, segmenting whole-body scans has been addressed success-fully using 3D encoder-decoder CNN architectures [25,52].
In the images of interest this straightforward approach does not work as well: here, the semantic classes lack distinctive local and texture features helpful for convolution based architectures [13].
Instead, the task requires very long-range spatial awareness and good geometrical reasoning. In response, here we cast the problem as a node classification task. To succeed, any ap-proach requires informative input features, and indeed we show that a cell-adjacency graph with cell-level features is a powerful representation.
That said, our primary intent is twofold: first, to create a testing ground for machine learning on highly structured input. Indeed, it uniquely combines node classification typ-ical of popular datasets [14, 30, 42] with the requirement to generalize across geo-referenced graphs like in Quan-tum Chemistry [3, 16, 37, 56]. Our second intent is, by allowing computer vision and machine learning scientists to work on this problem without having to deal with data-processing issues that actually take the most time in many applied projects, to channel the creativity and resourceful-ness of our community to help solve a fascinating biological problem.
As a starting point, we present extensive experiments evaluating the performance of state-of-the-art and popular models.
In summary, we make the following contributions: 1. We propose a new benchmark for node classification in a geo-referenced graph. We release the bench-mark dataset together with a ready-to-use PyTorch [33] data loader. The source-code and usage instructions are available at https://github.com/hci-unihd/celltype-graph-benchmark.
2. We run comparative experiments using state-of-the-art graph neural networks and offer a study of feature rel-evance. 3. We provide an extensive set of precomputed features and an additional set of ground truth labels. 1.1.