Abstract
The wavelet scattering transform creates geometric in-variants and deformation stability. In multiple signal do-mains, it has been shown to yield more discriminative rep-resentations compared to other non-learned representations and to outperform learned representations in certain tasks, particularly on limited labeled data and highly structured signals. The wavelet ﬁlters used in the scattering trans-form are typically selected to create a tight frame via a pa-rameterized mother wavelet. In this work, we investigate whether this standard wavelet ﬁlterbank construction is op-timal. Focusing on Morlet wavelets, we propose to learn the scales, orientations, and aspect ratios of the ﬁlters to produce problem-speciﬁc parameterizations of the scatter-ing transform. We show that our learned versions of the scattering transform yield signiﬁcant performance gains in small-sample classiﬁcation settings over the standard scat-tering transform. Moreover, our empirical results suggest that traditional ﬁlterbank constructions may not always be necessary for scattering transforms to extract effective rep-resentations. 1.

Introduction
The scattering transform, proposed in [29], is a cascade of wavelets and complex modulus nonlinearities, which can be seen as a convolutional neural network (CNN) with ﬁxed, predetermined ﬁlters. This construction can be used to build representations with geometric invariants and is shown to be stable to deformations. It has been demonstrated to yield impressive results on problems involving highly structured
∗Equal contributions. †Equal senior author contribution. This research was partially funded by NSERC CGS-M [S.G.,L.A.] and URA [B.T.]
[E.B.]; scholarhips; NSERC Discovery Grant RGPIN-2021-04104.
IVADO PRF Grant [I.R.,E.B.,G.W.]; and CIFAR AI Chairs [I.R.,G.W.].
We acknowledge resources provided by Compute Canada and Calcul
Quebec. The content is solely the responsibility of the authors and does not necessarily represent the ofﬁcial views of funding agencies. eugene.belilovsky@concordia.ca,
Correspondence meickenberg@flatironinstitute.org, guy.wolf@umontreal.ca to: signals [2, 3, 12, 17, 20, 21, 32, 34, 37, 38], outperforming a number of other classic signal processing techniques. Since scattering transforms are instantiations of CNNs, they have been studied as mathematical models for understanding the impressive success of CNNs in image classiﬁcation [12,30].
As discussed in [12], ﬁrst-order scattering coefﬁcients are similar to SIFT descriptors [27], and higher-order scattering can provide insight into the information added with depth
[30]. Moreover, theoretical and empirical study of informa-tion encoded in scattering networks indicates that they often promote linear separability, which leads to effective repre-sentations for downstream classiﬁcation tasks [1,12,17,31].
Scattering-based models have been shown to be useful in several applications involving scarcely annotated or limited labeled data [12, 17, 33, 36].
Indeed, most breakthroughs in deep learning in general, and CNNs in particular, in-volve signiﬁcant effort in collecting massive amounts of well-annotated data to be used when training deep over-parameterized networks. While big data is becoming in-creasingly prevalent, there are numerous applications where the task of annotating more than a small number of sam-ples is infeasible, giving rise to increasing interest in small-sample learning tasks and deep-learning approaches to-wards them [8, 9, 43]. Recent work has shown that, in im-age classiﬁcation, state-of-the-art results can be achieved by hybrid networks that harness the scattering transform as their early layers followed by learned layers based on a wide residual network architecture [33]. Here, we further advance this research avenue by proposing to use the scat-tering paradigm not only as ﬁxed preprocessing layers in a concatenated architecture, but also as a parametric prior to learn ﬁlters in a CNN. This allows us to also shed light on whether the standard wavelet construction [28] is an optimal approach for building ﬁlterbanks from a mother-wavelet for discriminative tasks.
Recall that the scattering construction is based on com-plex wavelets, generated from a mother wavelet via dila-tions and rotations, aimed to cover the frequency plane while having the capacity to encode informative variabil-ity in input signals [12]. Further, discrete parameteriza-tion and indexing of these operations (i.e., by dilation scal-ing or rotation angle) have traditionally been carefully con-structed to ensure the resulting ﬁlter bank forms an efﬁcient tight frame [28, 29] with well-established energy preserva-tion properties. On the other hand, it has been observed that the ﬁrst layers of convolutional networks resemble wavelets but may not necessarily form a tight frame [24]. The ques-tion then arises: is it necessary to use the standard wavelet
ﬁlterbank construction? Here, we relax the standard con-struction by considering another alternative where a small number of wavelet parameters used to create the wavelet
ﬁlterbanks are optimized for the task at hand.
To our knowledge, this is the ﬁrst work that aims to learn the wavelet ﬁlters of scattering networks in 2D sig-nals.