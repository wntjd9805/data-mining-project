Abstract
Inferring human-scene contact (HSC) is the ﬁrst step to-ward understanding how humans interact with their sur-roundings. While detecting 2D human-object interaction (HOI) and reconstructing 3D human pose and shape (HPS) have enjoyed signiﬁcant progress, reasoning about 3D human-scene contact from a single image is still challeng-ing. Existing HSC detection methods consider only a few types of predeﬁned contact, often reduce the body and scene to a small number of primitives, and even overlook image evidence. To predict human-scene contact from a single image, we address the limitations above from both data and algorithmic perspectives. We capture a new dataset called RICH for “Real scenes, Interaction, Contact and
Humans.” RICH contains multiview outdoor/indoor video sequences at 4K resolution, ground-truth 3D human bod-ies captured using markerless motion capture, 3D body scans, and high resolution 3D scene scans. A key feature of RICH is that it also contains accurate vertex-level con-tact labels on the body. Using RICH, we train a network that predicts dense body-scene contacts from a single RGB image. Our key insight is that regions in contact are al-ways occluded so the network needs the ability to explore the whole image for evidence. We use a transformer to learn such non-local relationships and propose a new Body-Scene contact TRansfOrmer (BSTRO). Very few methods explore 3D contact; those that do focus on the feet only, detect foot contact as a post-processing step, or infer con-tact from body pose without looking at the scene. To our knowledge, BSTRO is the ﬁrst method to directly estimate 3D body-scene contact from a single image. We demon-strate that BSTRO signiﬁcantly outperforms the prior art.
Our code and dataset are available for research purposes at: https://rich.is.tue.mpg.de 1.

Introduction
Understanding human actions and behaviors has long been studied in computer vision, with applications in robotics, healthcare, virtual try-on, AR/VR, and beyond.
Remarkable progress has been made in both 2D human pose detection [7,28,32,42,67,82] and 3D human pose and shape estimation (HPS) from a single image [5, 36, 39, 40, 44, 56, 81, 95], thanks to realistic datasets annotated with 2D key-points [1,33,46] and 3D data [30,34,49,66,77]. Despite this progress, something important is missing. Even the most basic human activities, such as walking, involve interaction
with the surrounding environment. Fundamentally, human-scene interaction (HSI) involves the contact relationships between a 3D human and a 3D scene, i.e., human-scene contact (HSC). Existing HPS methods, however, largely ig-nore the scene and estimate human poses and/or shapes in isolation, often leading to physically implausible results.
Since reconstructing the full 3D scene from a single im-age is challenging, recent HPS methods tackle this problem by making several simplifying assumptions about the scene and/or body. Many methods consider only the contact be-tween feet and ground [61,64,83,89,90,93,101], or assume the ground is a even plane [60], which is often violated, e.g., walking up stairs. To infer contact, many state-of-the-art (SOTA) methods use MoCap datasets [48, 50] to train a contact detector [61, 93, 101]. Others exploit physics simu-lation [64,89] or physics-inspired objectives [83] but reduce the body representation to a small set of primitives. Surpris-ingly, none of these methods use image evidence when pre-dicting human-scene contact. This is primarily due to the lack of datasets with images and 3D contact ground truth.
Many methods do estimate human object interaction (HOI) from images but constrain the reasoning to 2D image regions [37,58,78,85,100]. That is, they estimate bounding boxes or heatmaps in the image corresponding to contact but do not relate these to the 3D body.
In this work, we address this problem with a framework that estimates 3D contact on the body directly from a single image. We make two main contributions. First, we create a new dataset that accurately captures human-scene con-tact by extending a markerless MoCap method to marker-less HSC capture. Speciﬁcally, we capture multiview video sequences at 4K resolution in both indoor and outdoor en-vironments. We also capture the precise 3D geometry of the scene using a laser scanner. Additionally, we capture high-resolution 3D scans of all subjects in minimal cloth-ing and ﬁt the SMPL-X body model [56] to the scans. Our markerless HSC approach allows us to compute accurate per-vertex scene contact, as visualized in Fig. 1c.
Compared to the PROX dataset [25], which captures
HSC with monocular RGB-D input, multiview data has two advantages: (1) it effectively resolves occlusions, leading to better reconstructed bodies and consequently more accu-rate scene contact; (2) it works for outdoor environments, as shown in Fig. 1.
The resulting dataset, called RICH (“Real scenes, In-teraction, Contact and Humans”), provides: (1) high-resolution multiview images of single or multiple subjects interacting with a scanned 3D scene, (2) dense full-body scene-contact labels, (3) high-quality outdoor/indoor scene scans, (4) high-quality 3D human shapes and poses, and (5) dynamic backgrounds and moving cameras.
To estimate vertex-level HSC from a single color image, we develop BSTRO (Body-Scene contact TRansfOrmer), and train it with RICH. Our key insight in building BSTRO is that contact is not directly observable in images due to oc-clusion; thus, to infer contact, the network architecture must be able to explore the whole image for evidence. The trans-former architecture enables BSTRO to learn non-local rela-tionships and use scene information to “hallucinate” unob-served contact. We employ a multi-layer transformer [75], which has been successfully employed for natural-language processing [11] and HPS estimation with occlusion [44].
In summary, our key contributions are: (1) We present
RICH, a novel dataset that captures people interacting with
It is the ﬁrst dataset that provides both complex scenes. scans of outdoor scenes and images for monocular HSC es-timation, unlike existing methods [24, 25], which lack one or the other. (2) We propose BSTRO, a monocular HSC detector. It is body-centric so it does not require 3D scene reconstructions to infer contact. Unlike POSA [26], which is also body-centric, BSTRO directly estimates dense scene contact from the input image without reconstructing bod-ies. (3) We evaluate recent HSC methods and show that
BSTRO gives SOTA results. (4) Since RICH has pseudo-ground-truth body ﬁts, we also evaluate SOTA HPS meth-ods and analyze their performance with respect to scene-contact, which is not supported by existing HPS datasets
[30, 55, 77]. We conﬁrm that the performance of a SOTA
HPS method [17] degrades in the presence of scene contact. 2.