Abstract
This paper proposes the first real-world rolling shut-ter (RS) correction dataset, BS-RSC, and a corresponding model to correct the RS frames in a distorted video. Mo-bile devices in the consumer market with CMOS-based sen-sors for video capture often result in rolling shutter effects when relative movements occur during the video acquisition process, calling for RS effect removal techniques. How-ever, current state-of-the-art RS correction methods often fail to remove RS effects in real scenarios since the mo-tions are various and hard to model. To address this issue, we propose a real-world RS correction dataset BS-RSC.
Real distorted videos with corresponding ground truth are recorded simultaneously via a well-designed beam-splitter-based acquisition system. BS-RSC contains various mo-tions of both camera and objects in dynamic scenes. Fur-ther, an RS correction model with adaptive warping is pro-posed. Our model can warp the learned RS features into global shutter counterparts adaptively with predicted mul-tiple displacement fields. These warped features are aggre-gated and then reconstructed into high-quality global shut-ter frames in a coarse-to-fine strategy. Experimental results demonstrate the effectiveness of the proposed method, and our dataset can improve the model’s ability to remove the
RS effects in the real world. The project is available at https://github.com/ljzycmd/BSRSC. 1.

Introduction
Most consumer cameras adopt CMOS sensors for imag-ing due to their low power consumption, compact design, and fast imaging. At the same time, most CMOS sensors have rolling shutter (RS) effects during imaging. Unlike a global shutter (GS) camera capturing all pixels simultane-ously, an RS camera sequentially captures the image pix-els row by row. Therefore, the RS distortions would oc-cur in the recorded images and videos when relative move-ments arise between the camera and objects. The RS distor-tions significantly impair the visual quality. Moreover, the distorted images and videos deteriorate the performance of some downstream tasks, like 3D reconstruction, pose esti-mation, and depth prediction [3, 8, 10, 16], leading to erro-neous, undesirable, and distorted results.
There are usually two ways to mitigate the performance gap of existing computer vision algorithms working on the
RS distorted and GS images. The first is to keep the orig-inal RS images unchanged and adapt the algorithms to the
RS distorted images. Thus, many RS-aware algorithms are proposed in 3D vision field, e.g., RS structure-from-motion reconstruction [13, 34], RS stereo [27], RS camera calibra-tion [22] and RS absolute camera pose [1, 3, 4, 18]. An ar-guable better way is to correct the RS distorted images into
In this way, we don’t need to modify exist-GS images. ing vision algorithms and can obtain visual-friendly images.
Therefore, correcting the rolling shutter (RSC) images is in-creasingly becoming significant in photography and has at-tracted considerable research attention recently [2,9,20,24].
Existing RS effect removal methods can be categorized into single-image- and multi-frame-based. When restoring the GS image from only one RS image, many external con-straints or priors (e.g., geometric priors) are adopted [17, 24, 25, 35] since it is a highly ill-posed problem. Compared to single-image-based correction, multi-frame-based meth-ods are more general and can utilize motion information for correction. Due to the great success of convolutional neural networks (CNNs) on various computer vision tasks and the proposed synthesized RSC datasets, researchers de-signed specific model architectures to remove the RS dis-tortions in an end-to-end manner based on multiple frames.
Usually, the motions across multiple frames are modeled first. Then the GS image corresponding to the reference
RS frame is restored by warping operations. For instance,
Liu et al. [20] predict velocity field from the correlation vol-ume, and Fan et al. [9] utilize PWC-Net framework [28] to estimate the undistortion flow to correct the RS frame. They both adopt forward warping to remove the RS effect, and have achieved some promising results. However, the cor-rected GS images still suffer from blurs and texture detail loss for the following reasons: 1) The modeled motions are inaccurate since there is no ground truth for supervision dur-(a) RS frame (b) DSUN [20] (c) JCD [33] (d) SUNet [9]
Figure 1. The real-world rolling shutter correction results of ex-isting state-of-the-art methods trained with synthesized data. We see that all methods failed to remove the RS effects and even in-troduced many artifacts into the corrected frame. ing the training process. 2) The warping operations are not learnable, which cannot aggregate the features adaptively. 3) Meanwhile, some regions in the potential GS frame do not appear in the input RS frames. Thereby, it is difficult for the model to generate unseen areas. 4) Moreover, these models are trained on the synthesized RSC datasets where the motions are rather monotonous. And many artifacts exist in the synthesized RS frames, greatly restricting the model’s performance on the natural RS image correction.
Fig. 1 shows some real-world RSC results of state-of-the-art methods trained with synthesized data.
To move beyond these limitations mentioned above, we propose a novel adaptive warping module and a real-world dataset for rolling shutter correction. Our model takes three consecutive frames as input, restoring the GS frame corre-sponding to the central RS frame at intermediate imaging time. We propose an adaptive warping module to better ex-ploit high-quality GS frame restoration by mitigating inac-curate RS motion estimation and warping problems. Firstly, multi-scale features of each RS frame are extracted. Then, we construct a correlation volume to build the correspon-dence between central and neighboring RS features. The volume is used to predict multiple motion fields rather than only one generated in previous works [9, 20]. After that, an adaptive attention mechanism is proposed to warp the RS features by aggregating the contextual features according to the predicted motion fields. The designed warping pro-cess is learnable, aggregating the features to the GS-aware features attentively and adaptively. Note that we perform adaptive warping at all scales. A decoder network further decodes these warped multi-scale features and reconstructs the corresponding GS frame. The proposed model can be trained in an end-to-end manner.
Considering the performance gap on the synthesized datasets and real RS distorted scenarios, we propose BS-RSC, the first dataset for real-world RSC with various motions in dynamic scenes, collected by a well-designed beam-splitter acquisition system. An RS camera and a GS camera are physically aligned to capture RS distorted and
GS frames simultaneously.
Our contributions can be summarized as follows:
• We propose a novel feature warping module for rolling shutter correction, which adaptively warps RS features into global counterparts for high-quality GS frame restoration.
• We contribute BS-RSC, the first real-world RSC dataset (devoid of motion blur) with various motions collected by a well-designed beam-splitter acquisition system, bridging the gap for real-world RSC task.
• The quantitative and qualitative experimental results on real-world and synthetic datasets show the excel-lent performance of the proposed method against the state-of-the-art methods. 2.