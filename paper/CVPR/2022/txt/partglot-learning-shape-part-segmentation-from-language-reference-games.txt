Abstract
We introduce PartGlot, a neural framework and asso-ciated architectures for learning semantic part segmenta-tion of 3D shape geometry, based solely on part referen-tial language. We exploit the fact that linguistic descrip-tions of a shape can provide priors on the shape’s parts – as natural language has evolved to reflect human percep-tion of the compositional structure of objects, essential to their recognition and use. For training we use ShapeGlot’s paired geometry / language data collected via a reference game where a speaker produces an utterance to differenti-ate a target shape from two distractors and the listener has to find the target based on this utterance [3]. Our network is designed to solve this target multi-modal recognition prob-lem, by carefully incorporating a Transformer-based atten-tion module so that the output attention can precisely high-light the semantic part or parts described in the language.
Remarkably, the network operates without any direct su-pervision on the 3D geometry itself. Furthermore, we also demonstrate that the learned part information is generaliz-able to shape classes unseen during training. Our approach opens the possibility of learning 3D shape parts from lan-guage alone, without the need for large-scale part geometry annotations, thus facilitating annotation acquisition. The code is available at https://github.com/63days/PartGlot. 1.

Introduction
Object perception is often based on structural abstrac-tions — the decomposition of an object into its parts and their inter-relationships [10, 11, 16]. Natural language re-flects this aspect of human perception of 3D shapes – when a human is asked to describe an object, the description usu-ally involves words naming parts and expressions about part attributes and their relationships. This implies that, con-versely, language descriptions of an object can provide pri-ors on the compositional structure of the object geometry, including the identity of its components or parts. In this pa-per, we study the interplay between these two very different modalities, geometry and language, and how it can guide 1
learning shape structure and parts.
ShapeGlot [3] explored the interplay between natural language and object geometry for the task of differentiat-ing objects. It proposed a way to design a crowd-sourcing task to elicit more part-related referential language (utter-ances) about objects from users, based on a reference game.
Specifically, one user (the speaker) is shown three related objects (a “target” shape and two “distractor” shapes) and is asked to describe how the target is different from the distrac-tors. A second user (the listener) is then asked to select the one described by the first user. An interesting aspect of this work is that even though in training the (referential) neural networks are only given holistic shape representations with no part information whatsoever, they learn to depend heav-ily on part-related words and the corresponding visual parts of objects.
Motivated by this initial observation and using the same data, our work investigates how well a neural network can connect part names in the utterances to specific regions in the geometry of the 3D shapes. We show the remark-able fact that geometric object part structure can emerge from language alone, without any direct geometric su-pervision on part segments, highlighting the deep ties be-tween language and geometry. In other words, we can dis-cover semantic part segments on the geometry by exploiting solely referential language data. Even the language data we use is pragmatic, not guided by any comprehensive parton-omy as done by previous work [17], but merely focusing on describing shape differences.
Our framework is based on a variant of the neural lis-tener pipeline in ShapeGlot, taking a language utterance plus three 3D shapes in point cloud format and predicting the probability of how likely each of the shapes is to be the target described by the utterance. For this learning task, we explore the application of a Transformer-based attention module [33] to learn the region corresponding to each part described in the utterance as attention focus. Simply plug-ging in an attention module, however, does not produce any meaningful regions aligned with the semantic parts. Hence, we make several important changes that lead the network to learn meaningful part segmentation masks as a byprod-uct of learning to identify the target shape. Our experi-mental results demonstrate that the essential architectural components in our network significantly improve the per-formance of part segmentation. Also, in the case when the full set of part names are given at training time, we show that this additional information can be leveraged to better detect and segment parts. Furthermore, we show that our network can generalize to out-of-distribution categories of shapes – specifically, with training done on Chairs, good semantic masks can be extracted out of instances of Tables and Lamps.
Beyond studying the capability of neural networks to jointly understand language and shape, this work also sug-gests a new potential way to collect data for object part seg-mentation. Object or scene segmentation is a fundamental problem in many vision tasks, but the advance of learning-based segmentation techniques is gated by the availability of large-scale human segmentation annotations of 2D im-ages or 3D models. Particularly for 3D, collecting manual annotations on 3D objects requires a huge amount of human effort and cost. In contrast to this, uttering a language de-scription is a much more natural way for people to provide information about object structure and geometry. We hope to see a lot more work on how 3D segmentation can be im-proved using the language description of objects, without direct geometry supervision. 2.