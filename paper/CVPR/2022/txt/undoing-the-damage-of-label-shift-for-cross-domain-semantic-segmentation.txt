Abstract
Existing works typically treat cross-domain semantic segmentation (CDSS) as a data distribution mismatch prob-lem and focus on aligning the marginal distribution or con-ditional distribution. However, the label shift issue is un-fortunately overlooked, which actually commonly exists in the CDSS task, and often causes a classifier bias in the learnt model. In this paper, we give an in-depth analysis and show that the damage of label shift can be overcome by aligning the data conditional distribution and correcting the posterior probability. To this end, we propose a novel approach to undo the damage of the label shift problem in CDSS. In implementation, we adopt class-level feature alignment for conditional distribution alignment, as well as two simple yet effective methods to rectify the classifier bias from source to target by remolding the classifier predic-tions. We conduct extensive experiments on the benchmark datasets of urban scenes, including GTA5 to Cityscapes and SYNTHIA to Cityscapes, where our proposed approach outperforms previous methods by a large margin. For instance, our model equipped with a self-training strat-egy reaches 59.3% mIoU on GTA5 to Cityscapes, push-ing to a new state-of-the-art. The code will be available at https://github.com/manmanjun/Undoing UDA. 1.

Introduction
Semantic segmentation aims to classify every pixel in a given image. As a fundamental visual perception problem, it is the basic module of many visual applications, such as autonomous driving systems. Remarkable progress in se-mantic segmentation has been made in recent years, driven by large-scale annotated datasets [5, 13, 53]. However, the massive and high-quality annotation, especially for seman-tic segmentation, can be costly and labor-intensive. Thus it is not always realistic to collect a sufficient number of well-annotated images for a new environment. Fortunately,
*The corresponding author we can obtain synthetic images with accurate pixel-level annotations rendered from the computer by a physical en-gine [36, 38]. However, the model trained with a synthetic domain often suffers from performance degradation since synthetic images (source domain) and testing images (target domain) are drawn from different distributions. This phe-nomenon commonly exists in cross-domain semantic seg-mentation (CDSS) tasks, and many unsupervised domain adaptation models have been proposed to address this issue by transferring the knowledge from a label-rich source do-main to the unlabeled target domain.
Most existing CDSS methods [11, 18, 29, 34, 42, 44] seek to learn domain-invariant representations via adversar-ial training to align marginal distributions (p(x)) or condi-tional distributions (p(x|y)). However, they ignore the label shift problem, which commonly exists in CDSS tasks, since the label distribution is often different across domains. As shown in Fig. 1, taking the GTA5 [36] to Cityscapes [13] as an example, the frequency of “truck” and “wall” in the source domain is higher than that in the target domain, and the frequency of “bicycle” is much lower than that in the target domain.
Therefore, in this work, we propose a novel approach to undo the damage of label shift in CDSS. First, we give an in-depth analysis and show that the classifier bias is the crit-ical factor leading to the poor generalization ability of the learnt semantic segmentation model on the target domain when a label shift problem exists. It is inevitable that the classifier will be biased towards the source domain because the supervision signal comes only from it. At the same time, we show that the damage of label shift can be overcome by aligning the data conditional distribution and correcting the posterior probability.
Then we adopt class-level feature alignment for condi-tional distribution alignment and propose two simple yet ef-fective methods to rectify the classifier bias from source to target by remolding the classifier predictions. In particular, after aligning the conditional distribution, we adjust the pre-dictions of the classifier either in the training stage or the in-ference stage using the source and target label distribution.
2.