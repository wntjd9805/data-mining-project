Abstract
Current attention-based methods for semantic segmen-tation mainly model pixel relation through pairwise affin-ity and coarse segmentation. For the first time, this paper explores modeling pixel relation via Class Activation Map (CAM). Beyond the previous CAM generated from image-level classification, we present Partial CAM, which sub-divides the task into region-level prediction and achieves better localization performance. In order to eliminate the intra-class inconsistency caused by the variances of local context, we further propose Partial Class Activation Atten-tion (PCAA) that simultaneously utilizes local and global class-level representations for attention calculation. Once obtained the partial CAM, PCAA collects local class cen-ters and computes pixel-to-class relation locally. Apply-ing local-specific representations ensures reliable results under different local contexts. To guarantee global con-sistency, we gather global representations from all local class centers and conduct feature aggregation. Experimen-tal results confirm that Partial CAM outperforms the pre-vious two strategies as pixel relation. Notably, our method achieves state-of-the-art performance on several challeng-ing benchmarks including Cityscapes, Pascal Context, and
ADE20K. Code is available at https://github.com/ lsa1997/PCAA.
Figure 1. Different methods to model pixel relation. Here, H × W denotes the spatial size of inputs and K is the number of classes.
Non-local uses dot product to calculate pairwise affinity, while
OCRNet adopts coarse prediction to obtain class-level relation.
This paper first introduces CAM to model pixel-to-class relation and proposes Partial CAM to subdivide the prediction task for bet-ter localization performance. Best viewed in color. 1.

Introduction
Scene parsing is a pixel-wise prediction task which aims to assign a class label to each pixel in a given image. The difficulty of this task is that the features of pixels belong-ing to the same category may vary dramatically due to the differences in texture, lighting, and position. Hence, in or-der to achieve precise segmentation, we need to eliminate this local specificity and generate features with global con-sistency. In recent years, models based on Convolutional
Neural Networks (CNNs) have adopted various strategies to handle this problem like pyramid pooling [40], dilated
*Corresponding author. convolution [2], and self-attention [9, 14, 34, 44].
Among these methods, attention-based models often show considerable performance. They generally include two steps: first calculate pixel relation, and then augment features via a weighted aggregation based on the relation maps. Current works mainly follow two strategies for pixel relation calculation: pairwise affinity and coarse segmenta-tion. The non-local models [26] use dot product as pairwise affinity to construct pixel-to-pixel relation. These methods are computationally intensive, and pixel-level aggregation can not guarantee the global consistency of the same cate-gory. In the first two attention maps of Fig. 1(d), the two pixels marked by red dots both belong to building but focus
on different areas. Features in these areas may differ, which will lead to intra-class inconsistency after aggregation. On the other hand, models like ACFNet [36] and OCRNet [32] introduce coarse segmentation maps to collect global class centers and model pixel-to-class relation. For each class, applying a global representation improves the intra-class consistency but ignores the local specificity. If features vary due to different local contexts, a single global center may be unable to model pixel relation of the whole image correctly.
Based on the analysis above, this paper focuses on two issues: (i) is there another way to model pixel relation in ad-dition to pairwise affinity and coarse segmentation, and (ii) how to improve global consistency while considering local specificity. For the first issue, our motivation comes from
Class Activation Map (CAM). The CAM method [41] is widely used in weakly supervised segmentation with only image-level annotations to localize objects for each class.
Intuitively, it can be used to represent pixel-to-class rela-tion similarly to coarse segmentation. However, as shown in Fig. 1(e), it is far from sufficient enough for attention cal-culation. Localizing objects from the whole image is rather difficult because image-level classification completely ig-nores spatial information. Therefore, we propose Partial
CAM as a subdivision of the original CAM. An input image is split into non-overlapped patches, and the activation maps will be generated from region-level prediction. Each partial
CAM can thus be seen as a smaller-scale CAM within one patch. Note that the region-level ground truth is available since pixel-wise annotations are provided for segmentation.
Compared with the conventional CAM, partial CAM forces the network to learn more spatial information and can pro-vide more reliable localization results. Fig. 1(f) illustrates partial CAMs with 4 × 4 patches.
To handle the second issue, we propose Partial Class Ac-tivation Attention (PCAA). In contrast to the previous works simply using pixel features or global centers, PCAA utilizes local and global representations simultaneously. Specifi-cally, it first gathers local class representations based on the partial CAMs and computes pixel-to-class similarity maps inside each patch. For each class, all local representations are then aggregated into one global class center which is used as the basis for feature augmentation. PCAA consid-ers the variances of local contexts by calculating pixel re-lation locally and ensures the consistency of final features through global class centers, which fits our purpose to im-prove global consistency while considering local specificity.
To the best of our knowledge, we are the first to intro-duce the CAM method to the attention mechanism for se-mantic segmentation. Extensive experiments demonstrate that our partial class activation attention outperforms the previous models based on pairwise affinity and coarse seg-mentation. It achieves state-of-the-art results on three chal-lenging public benchmarks including Cityscapes [5], Pascal
Context [20], and ADE20K [42]. We hope it can provide a different perspective for the attention mechanism.
Our main contributions are summarized as follows:
• We propose Partial Class Activation Map as a new strategy to represent pixel relation. It improves CAM generation by subdividing the image-level classifica-tion task into region-level prediction.
• We design Partial Class Activation Attention to en-hance feature representation.
It simultaneously con-siders local specificity and global consistency through local and global class centers.
• We validate the effectiveness of the proposed method through extensive experiments. Specifically, our ap-proach achieves 82.3% on Cityscapes, 55.6% on Pas-cal Context, and 46.74% on ADE20K. 2.