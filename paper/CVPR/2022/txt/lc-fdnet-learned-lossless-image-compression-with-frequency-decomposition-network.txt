Abstract
Recent learning-based lossless image compression meth-ods encode an image in the unit of subimages and achieve comparable performances to conventional non-learning al-gorithms. However, these methods do not consider the per-formance drop in the high-frequency region, giving equal consideration to the low and high-frequency areas.
In this paper, we propose a new lossless image compression method that proceeds the encoding in a coarse-to-ﬁne man-ner to separate and process low and high-frequency regions differently. We initially compress the low-frequency compo-nents and then use them as additional input for encoding the remaining high-frequency region. The low-frequency com-ponents act as a strong prior in this case, which leads to im-proved estimation in the high-frequency area. In addition, we design the frequency decomposition process to be adap-tive to color channel, spatial location, and image charac-teristics. As a result, our method derives an image-speciﬁc optimal ratio of low/high-frequency components. Experi-ments show that the proposed method achieves state-of-the-art performance for benchmark high-resolution datasets. 1.

Introduction
As the need for high-quality images is increasing, the importance of image compression is growing accord-ingly. Driven by the development of deep neural networks (DNNs), there has been remarkable progress in computer vision and image processing, including lossy [3,4,8,10–17, 21, 23–25, 27, 28, 30, 32–34, 40, 44–48, 53, 54] and lossless image compression [3,9,18,19,29,31,35,38,39,41,42,49].
Although lossy compression is generally preferred, loss-less compression is also necessary for many applications.
Lossless compression is especially required for medical im-ages, scientiﬁc images, technical drawings, and artistic pho-tos. While methods such as JPEG2000 (lossless mode) [37] employ transform coding with discrete wavelet transform
Figure 1. Our LC-FDNet consists of Adaptive Frequency Decom-position (AFD), Low-Frequency Compressor (LFC), and High-Frequency Compressor (HFC). The current subimage is split into low/high-frequency regions through the AFD. The LFC ﬁrst com-presses the low-frequency region, and then the HFC compresses the high-frequency area using the low-frequency as strong prior. (DWT), most of the standard/non-standard lossless com-pression methods [2, 5, 7, 51] use predictive coding. The standard predictive coding scheme uses a closed-loop pre-diction where the current pixel is estimated and compressed using the previously encoded samples.
In this sense, early learning-based lossless compression algorithms [29, 31, 35, 38, 41, 49] design DNNs as autore-gressive models. They rely on the strong power of DNNs in estimating the probability distribution of a pixel conditioned on the previous samples. For example, PixelRNN [49], Pix-elCNN [35], and PixelCNN++ [41] compress each pixel se-quentially, where the probability distribution is predicted conditioned on all previous pixels. However, these meth-ods require neural network computations for the number of whole pixels, leading to an impractical inference time.
To achieve practicality, recent works [29, 31, 38] pro-cess the encoding in the unit of an entire image or subim-ages rather than individual pixels. These methods de-rive the probability distribution of a subimage conditioned on the previously encoded subimages, or the distribution of a whole image conditioned on the lossy compressed image. They show reduced and practical computation
time compared to pixel-wise encoding methods. However, these methods consider the low and high-frequency regions equally, giving the same encoding strategies to the regions of different characteristics. In general, it is difﬁcult to ob-tain optimal performance in high-frequency regions near an edge or texture where the pixel values change rapidly.
We address this challenge and propose Lossless Com-pression with Frequency Decomposition Network (LC-FDNet) illustrated in Fig. 1, which consists of Adaptive
Frequency Decomposition (AFD), Low-Frequency Com-pressor (LFC), and High-Frequency Compressor (HFC).
We also decompose an image into subimages based on our unique decomposition scheme, where the ﬁrst subimage is compressed by a conventional lossless compressor. Then, the rest subimages are sequentially compressed by Fig. 1.
Using the previously encoded and current subimages as the input, the AFD decomposes the input subimage into low and high-frequency regions, and the compressors (LFC and
HFC) encode low and high-frequency regions differently.
Since the low-frequency region is typically well predicted, we ﬁrst compress the low-frequency components. On the other hand, high-frequency regions usually exhibit rela-tively large prediction errors, and hence we encode them separately with additional priors, which are the encoded low-frequency pixels. That is, we feed the low-frequency components as additional input for compressing the high-frequency region.
For the image-speciﬁc frequency decomposition, the
AFD generates error variance map and error variance thresholds. Error variance map can be comprehended as the magnitude of the prediction error produced by the net-work. By thresholding the error variance map with the error variance threshold, we can classify the pixels into low and high-frequency ones. Since the error variance differs de-pending on the channel, spatial location, and image charac-teristics, we design the threshold to be adaptive to those fac-tors. This drives the frequency decomposition process to be image-speciﬁc, where different threshold values are derived depending on the image property. Experiments show that the proposed method achieves state-of-the-art performance for benchmark high-resolution datasets with reasonable in-ference time.
In summary, the main contributions are as follows:
• We propose a lossless image compression framework that compresses in a coarse-to-ﬁne manner, using the low frequency components to boost the performance in high-frequency regions.
• We design the frequency decomposition process to be adaptive to channel, spatial location, and image characteristics. Hence, the encoding becomes image-speciﬁc, improving the compression performance.
• Our method achieves state-of-the-art performance for benchmark high-resolution datasets with reasonable inference time. 2.