Abstract
Existing studies in few-shot semantic segmentation only focus on mining the target object information, however, of-ten are hard to tell ambiguous regions, especially in non-target regions, which include background (BG) and Dis-tracting Objects (DOs). To alleviate this problem, we pro-pose a novel framework, namely Non-Target Region Elim-inating (NTRE) network, to explicitly mine and eliminate
BG and DO regions in the query. First, a BG Mining
Module (BGMM) is proposed to extract the BG region via learning a general BG prototype. To this end, we design a BG loss to supervise the learning of BGMM only using the known target object segmentation ground truth. Then, a BG Eliminating Module and a DO Eliminating Module are proposed to successively filter out the BG and DO in-formation from the query feature, based on which we can obtain a BG and DO-free target object segmentation result.
Furthermore, we propose a prototypical contrastive learn-ing algorithm to improve the model ability of distinguish-ing the target object from DOs. Extensive experiments on both PASCAL-5i and COCO-20i datasets show that our ap-proach is effective despite its simplicity. Code is available at https://github.com/LIUYUANWEI98/NERTNet 1.

Introduction
Due to the rapid development of fully convolutional net-work (FCN) [21] architectures, deep learning has made milestone progress in semantic segmentation. Most meth-ods adopt the fully-supervised learning scheme and require a mass of annotated data for training. Although they can achieve good performance, their data-hungry nature de-mands time and labor-consuming image annotations. To alleviate this problem, few-shot semantic segmentation was proposed to segment unseen object classes in query images with only a few annotated samples, namely supports.
Currently, there are many existing researches exploring
*Corresponding author.
Figure 1. Previous methods often show false positive predictions in non-target regions. Pixels in red indicate the target objects, while pixels in green mean false positive predictions.
Figure 2. Comparison between existing framework and ours for few-shot segmentation. The main difference is that the former only mines target category information, while we propose to eliminate co-existing pixels belonging to non-target regions, including the background (BG) and distracting objects (DO). various deep learning methods for few-shot semantic seg-mentation [14, 20, 29, 31, 33, 42]. They usually extract fea-tures from both query and support images first, and then extract the class-specific representation using the support masks. Finally, a matching network is leveraged to segment the target object in the query image using the class repre-sentation.
Most typically, prototypical learning methods [6, 31, 33, 42,44] use masked average pooling (MAP) on the target ob-ject regions of the support images to form a single or a few prototypes. Then, prototypes are used to segment the tar-get object in the query image via conducting dense feature
matching. get objects from DOs.
Although some achievements have been made, these methods all focus on digging out more effective target infor-mation from supports as much as possible, and then trans-ferring them to the query image to achieve segmentation (see Figure 2 (a)). However, as illustrated in Figure 1, they often suffer from the false positive prediction in back-grounds (BG) and co-existing objects belonging to other classes, namely, distracting objects (DOs). The main rea-son is that solely focusing on target objects in the few-shot setting makes their models hard on learning discriminative features and differentiating ambiguous regions.
To alleviate this problem, we rethink the few shot seman-tic segmentation task from a new perspective, that is, mining and excluding non-target regions, i.e., BG and DO regions, rather than directly segmenting the target object. From this point, in this paper, we propose a novel framework, namely non-target region eliminating (NTRE) network for few-shot semantic segmentation. As shown in Figure 2 (b), we first develop a BG mining module (BGMM) to obtain a BG pro-totype and segment the BG region. Then, a BG eliminating module (BGEM) is proposed to filter out the BG informa-tion from the query feature. Next, the target prototype from the support is utilized in a matching network to activate the target object in the query feature. Subsequently, we adopt a DO eliminating module (DOEM) to mine the DO region first and then filter out the DO information from the query feature. As such, finally, we can obtain an accurate target segmentation result without the distraction from the BG and
DO regions.
In the BGMM, obtaining the BG prototype is not straightforward as we obtain the support prototype. Con-sidering that BG regions universally exist in almost every image, such as sky, grass, walls, and etc, we propose to learn a general BG prototype from both query and support images in the training set. Based on this prototype, we can segment the BG regions for all images easily. Since having no ground truth BG segmentation masks to supervise the model learning, we specifically design a BG mining loss based on the known target segmentation masks.
Furthermore, considering that it’s hard to learn a good prototype feature embedding space to differentiate DOs from the target object under the few-shot setting, we pro-pose the prototypical contrastive learning (PCL) method to improve the object-discrimination ability of the network by refining the prototype feature embeddings. Specifically, for a query target prototype, we treat the corresponding support target prototype as the positive sample, while the DO proto-types both in query and support are considered as negative samples. We then propose a PCL loss to enforce the proto-type embeddings to be similar within the target prototypes and dissimilar between target and DO prototypes. As such, the PCL could effectively help the network distinguish tar-In summary, our contributions are as follows:
• To the best of our knowledge, this is the first time to mine and eliminate non-target regions, including BG and DOs, for few-shot semantic segmentation, which can effectively decrease false positive predictions.
• We propose the BGMM, BGEM, and DOEM for ef-fectively implementing the mining and eliminating of the BG and DO regions. A novel BG mining loss is also proposed for training the BGMM without using
BG ground truth.
• We propose a PCL method to improve the model abil-ity for better distinguishing target objects from DOs.
• Extensive experiments on PASCAL-5i and COCO-20i show that our proposed framework yields a new state-of-the-art performance, especially on the 1-shot set-ting.
Specifically, 2.