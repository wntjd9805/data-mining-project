Abstract
In this work, we focus on semi-supervised learning for video action detection which utilizes both labeled as well as unlabeled data. We propose a simple end-to-end con-sistency based approach which effectively utilizes the un-labeled data. Video action detection requires both, action class prediction as well as a spatio-temporal localization of actions. Therefore, we investigate two types of con-straints, classification consistency, and spatio-temporal consistency. The presence of predominant background and static regions in a video makes it challenging to uti-lize spatio-temporal consistency for action detection. To address this, we propose two novel regularization con-straints for spatio-temporal consistency; 1) temporal co-herency, and 2) gradient smoothness. Both these as-pects exploit the temporal continuity of action in videos and are found to be effective for utilizing unlabeled videos for action detection. We demonstrate the effectiveness of the proposed approach on two different action detection benchmark datasets, UCF101-24 and JHMDB-21. In ad-dition, we also show the effectiveness of the proposed ap-proach for video object segmentation on the Youtube-VOS which demonstrates its generalization capability The pro-posed approach achieves competitive performance by us-ing merely 20% of annotations on UCF101-24 when com-pared with recent fully supervised methods. On UCF101-24, it improves the score by +8.9% and +11% at 0.5 f-mAP and v-mAP respectively, compared to supervised approach.
The code and models will be made publicly available at: https://github.com/AKASH2907/End-to-End-Semi-Supervised-Learning-for-Video-Action-Detection. 1.

Introduction
We have seen a great progress in video action classi-fication [4, 6, 9, 39, 42–44, 46], where the availability of large-scale datasets is one of the enabling factor [18,20,38].
Video action detection on the other hand is much more chal-Figure 1. A comparison of proposed semi-supervised method with supervised baseline showing absolute gain in f-mAP and v-mAP for varying number of labeled samples on UCF-101-24 dataset.
The proposed method outperforms supervised baseline and using merely 20% of labeled samples, matches the performance of fully supervised method trained on 100% labels. Sup is supervised and
Sup100 is supervised with with 100% labels. lenging where spatio-temporal localization is performed on the video. In addition, obtaining large-scale datasets for this problem is even more challenging as annotating each frame is a huge time and cost intensive task.
In this work, we focus on semi-supervised learning for video action detection which makes use of a small set of an-notated samples along with several unlabeled samples. For annotated set, we have video-level class labels as well as frame-level localizations. To the best of our knowledge, this is the first work which focuses on semi-supervised learning for video action detection.
Semi-supervised learning has been successfully studied for image classification [3,36,45] with some recent works in object detection [10,16,17,41,47]. Pseudo-labeling [14,29] and consistency regularization [36, 45, 47] are two main ap-proaches used for semi-supervised learning. Where pseudo-labeling rely on several iterations, consistency regulariza-tion relies on single-step training. Since, training a video action detection model is already computationally expen-sive due to high-dimensional input, therefore we propose a consistency-based approach for an efficient solution.
Video action detection requires a sample level class pre-diction as well as a spatio-temporal localization on each
frame. Therefore, we investigate two different consistency constraints to utilize unlabeled samples; classification con-sistency and spatio-temporal localization consistency. Con-sistency regularization for classification has been found very effective [3, 36], however, it relies on a rich set of aug-mentations. Extending these augmentations to the video do-main for spatio-temporal consistency is not always feasible.
We propose a simple formulation for spatio-temporal consistency where it is computed for each pixel in the video. Extending traditional consistency objective to spatio-temporal domain could capture pixel level variations, but it fails to capture any temporal constraints as the consis-tency is computed independently for each pixel. To ad-dress this issue, we explore temporal continuity of actions in videos. We argue that motion has some temporal conti-nuity and we attempt to utilize this to regularize the spatio-temporal consistency. We investigate two different ways to capture motion continuity, temporal coherence and gradi-ent smoothness. Temporal coherence aims at refining the uncertain boundary regions that distinguish foreground and background, and, gradient smoothness enforces temporally consistent localization.
The proposed method is trained end-to-end utilizing both labeled and unlabeled samples without the need for any it-erations which makes it efficient. We demonstrate its ef-fectiveness with an extensive set of experiments on two dif-ferent datasets, UCF101-24 and JHMDB-21. We show that with limited labels it can achieve competitive performance when compared with fully-supervised methods outperform-ing all the weakly-supervised approaches. In addition, we also demonstrate the generalization capability of the pro-posed method on Youtube-VOS for video object segmenta-tion. We make the following contributions in this work,
• We propose a simple end-to-end approach for semi-supervised video action detection. To the best of our knowledge, this is the first work focusing on this prob-lem.
• We investigate two different consistency regularization approaches for video action detection; classification consistency and spatio-temporal consistency.
• We propose two novel regularization constraints for spatio-temporal consistency, temporal coherency and gradient smoothness, which focus on the temporal continuity of actions in videos. 2.