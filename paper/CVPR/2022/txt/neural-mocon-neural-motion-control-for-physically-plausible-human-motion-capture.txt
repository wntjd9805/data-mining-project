Abstract
Due to the visual ambiguity, purely kinematic formula-tions on monocular human motion capture are often phys-ically incorrect, biomechanically implausible, and can not reconstruct accurate interactions. In this work, we focus on exploiting the high-precision and non-differentiable physics simulator to incorporate dynamical constraints in motion capture. Our key-idea is to use real physical supervisions to train a target pose distribution prior for sampling-based motion control to capture physically plausible human mo-tion. To obtain accurate reference motion with terrain in-teractions for the sampling, we first introduce an interac-tion constraint based on SDF (Signed Distance Field) to enforce appropriate ground contact modeling. We then de-sign a novel two-branch decoder to avoid stochastic er-ror from pseudo ground-truth and train a distribution prior with the non-differentiable physics simulator. Finally, we regress the sampling distribution from the current state of the physical character with the trained prior and sample satisfied target poses to track the estimated reference mo-tion. Qualitative and quantitative results show that we can obtain physically plausible human motion with complex ter-rain interactions, human shape variations, and diverse be-haviors. More information can be found at https:// www.yangangwang.com/papers/HBZ-NM-2022-03.html 1.

Introduction
Recent years have witnessed significant development of marker-less motion capture, which promotes a wide va-riety of applications ranging from character animation to human-computer interaction, personal well-being, and hu-man behavior understanding. Extensive existing works can kinematically capture accurate human pose from monocular
*Corresponding author. E-mail: yangangwang@seu.edu.cn. This work was supported in part by the National Key R&D Program of China un-der Grant 2018YFB1403900, the National Natural Science Foundation of
China (No. 62076061), the “Young Elite Scientists Sponsorship Program by CAST” (No. YES20200025), and the “Zhishan Young Scholar” Pro-gram of Southeast University (No. 2242021R41083).
Figure 1. Our method captures physically plausible human motion from monocular RGB videos via neural motion control. videos and images via network regression [22,25,26,66,67] or optimization [6, 38, 41, 51]. However, they are often hard to leverage in real-world systems due to a series of artifacts that are not satisfied biomechanical and physical plausibil-ity (e.g., jitter and floor penetration).
To improve motion quality and physical plausibility, a few works focus on capturing human motion using physics-based constraints. [42, 46, 47, 53, 57] incorporate phys-ical laws as soft constraints in numerical optimization framework and reduce artifacts. To make optimization be tractable, they can only adopt simple and differentiable physical models, which may result in high approximation errors. Other methods [40, 60, 63] utilize non-differentiable physics simulators with deep reinforcement learning (DRL) to achieve accurate and physically plausible 3D human pose estimation. However, training a desirable policy re-quires complex configurations [1, 5, 31], and it may be sen-sitive to environmental changes [39, 60]. The limitations above make them be infeasible to estimate human pose with scene interactions and subject varieties for motion capture tasks. Nevertheless, motion control, typically sampling-based methods [35], have achieved an impressive perfor-mance in reproducing highly dynamic and acrobatic mo-tions and is robust to contact-rich scenarios, which shows a way for general physics-based motion capture.
In this paper, we aim to construct a physics-based motion
capture framework that is more general to complex terrains, shape variations, and diverse behaviors along sampling-based motion control. However, employing sampling-based motion control in monocular motion capture tasks faces sev-eral challenges. First, conventional sampling-based meth-ods [33, 35] often track the accurate reference motion from commercial motion capture systems, while the estimated motion from monocular RGB videos is noisy and physically implausible. An inaccurate contact results in an unnatural pose would even lead to an imbalance state for the char-acter. Second, it is complicated to find an optimal distri-bution for the sampling. Although CMA (Covariance Ma-trix Adaptation) [11] is proved to be able to adjust distribu-tion with black-box optimization [33], it requires evaluat-ing plenty of samples for the distribution adaption, which is time-consuming. Furthermore, the adaption relied on random samples from an initial distribution imposes uncer-tainty for the motion capture.
To address the obstacles, our key-idea is to train a mo-tion distribution prior with physical supervisions. The prior provides feasible solutions for sampling-based mo-tion control to capture physically plausible human mo-tion from a monocular color video, which is named as
Neural Motion Control (Neural MoCon). We first intro-duce a human-scene interaction constraint to obtain a ref-erence motion with appropriate contacts for sampling. Dif-ferent from existing works [42, 47] to detect foot-ground contact status, our proposed interaction constraint adjusts the distance between two disconnected meshes via SDF, enforcing the human model to be close to the ground sur-face. Then, we have tried to train an encoder to regress the distribution with KL divergence (Kullback-Leibler di-vergence) and pseudo ground-truth from CMA. However, for the same character state and reference pose, the CMA method obtains different distributions, thus the stochastic error of CMA results in network divergence and erroneous regression. Consequently, we propose a novel two-branch decoder to address this obstacle. As shown in Fig. 3, the target pose sampled from the estimated distribution is fed into a physical branch to verify the validity. Since the sim-ulator is non-differentiable, we use the output to supervise the pose decoder and enforce it to transfer the target pose to a dynamical pose like the simulator. Moreover, a recon-struction loss from the reference pose is applied to the de-coded pose to promote correct distribution encoding. When the encoder is convergent, we use it to encode distribution and sample target poses for the physical branch to capture physically plausible motion. The main contributions of this work are summarized as follows.
• We propose an explicit physics-based motion capture framework that is more general to complex terrain, body shape variations, and diverse behaviors.
• We propose a novel two-branch decoder to avoid stochastic error from pseudo ground-truth and train the distribution prior with a non-differentiable physics simulator.
• We propose an interaction constraint based on SDF to capture accurate human-scene contact from complex terrain scenarios. 2.