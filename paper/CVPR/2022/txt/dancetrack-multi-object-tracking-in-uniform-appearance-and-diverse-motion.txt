Abstract 1.

Introduction
A typical pipeline for multi-object tracking (MOT) is to use a detector for object localization, and following re-identification (re-ID) for object association. This pipeline is partially motivated by recent progress in both object detec-tion and re-ID, and partially motivated by biases in existing tracking datasets, where most objects tend to have distin-guishing appearance and re-ID models are sufficient for es-tablishing associations. In response to such bias, we would like to re-emphasize that methods for multi-object track-ing should also work when object appearance is not suffi-ciently discriminative. To this end, we propose a large-scale dataset for multi-human tracking, where humans have sim-ilar appearance, diverse motion and extreme articulation.
As the dataset contains mostly group dancing videos, we name it “DanceTrack”. We expect DanceTrack to provide a better platform to develop more MOT algorithms that rely less on visual discrimination and depend more on motion analysis. We benchmark several state-of-the-art trackers on our dataset and observe a significant performance drop on
DanceTrack when compared against existing benchmarks.
The dataset, project code and competition is released at: https://github.com/DanceTrack.
* indicates equal contribution.
Object tracking has been long studied and can be ben-eficial to applications such as autonomous driving, video analysis and robot planning [1,4,25,35]. Multi-object track-ing aims to localize and associate objects of interest along time. Interestingly, we observe that recent developments in multi-object tracking rely heavily on a paradigm of detec-tion followed by re-ID, where mostly appearance cues are used to associate objects. This trend in algorithmic devel-opment makes existing solutions fail catastrophically in sit-uations where objects share very similar appearance, e.g., group dancing where performers wear uniform clothes. It inspires us to propose more comprehensive solutions by tak-ing other cues into modeling, such as object motion patterns and temporal dynamics.
As with many other areas of computer vision, the de-velopment of multi-object tracking is influenced by bench-mark datasets. Based on specified datasets [9, 13, 22, 36], data-driven methods are sometimes argued to be biased to certain data distributions. In this work, we recognize the limitations of existing multi-object tracking datasets lie on that many objects have distinct appearance and the motion pattern of objects are very regular or even linear. Moti-vated by these dataset properties, most recently developed multi-object tracking methods [23, 32, 33, 39] highly rely
on appearance matching to associate detected objects while taking little other cues into consideration. The dominant paradigm will fail in situations out of the biased distribu-tion. This phenomenon is not what we expect if we aim to build more general and intelligent tracking algorithms.
To provide a new platform for more comprehensive multi-object tracking studies, we propose a new dataset in this paper. Because it mostly contains group dancing videos, we name it “DanceTrack”. The dataset contains over 100K image frames (almost 10× more than MOT17 datatset [22]). As shown in Figure 1, the emphasized prop-erties of this dataset are (1) uniform appearance: people in videos wear very similar or even the same clothes, making their visual features hard to be distinguished by re-ID model and (2) diverse motion: people usually have very large-range motion and complex body gesture variation, propos-ing higher requirements for motion modeling. The second property also brings occlusion and crossover as a side-effect that human body has a large ratio of overlap with each other and their relative position exchanges frequently.
With the proposed dataset, we build a new bench-mark including existing popular multi-object tracking meth-ods. The results prove that current state-of-the-art algo-rithms [23, 27, 33, 37–40] fail to make satisfactory perfor-mance when they simply use appearance matching or linear motion models to associate objects across frames. Consid-ering the cases focused on in this dataset happen frequently in our real life, we believe it shows the limitations of ex-isting multi-object tracking algorithms on practical applica-tions. To provide potential guidelines for further research, we analyze a range of choices in associating objects and achieve some beneficial conclusions: (1) fine-grained rep-resentations of objects, e.g., segmentation and pose, exhibit better ability than coarse bounding box; (2) depth informa-tion shows positive influence on associating objects, though we are solving a 2D tracking task; (3) motion modeling of temporal dynamics is important.
To conclude, the key contributions of our work to the object tracking community are as follows: 1. We build a new large-scale multi-object tracking dataset,
DanceTrack, covering the scenarios where tracking suf-fers from low distinguishability of object appearance and diverse non-linear motion patterns. 2. We benchmark baseline methods on this newly built dataset with various evaluation metrics, showing the lim-itation of existing multi-object tracking algorithms. 3. We provide comprehensive analysis to discover more cues for developing multi-object trackers that are more robust in complicated real-life situations. 2.