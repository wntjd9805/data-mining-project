Abstract
Many convolutional neural networks (CNNs) for single image deblurring employ a U-Net structure to estimate la-tent sharp images. Having long been proven to be effec-tive in image restoration tasks, a single lane of encoder-decoder architecture overlooks the characteristic of deblur-ring, where a blurry image is generated from complicated blur kernels caused by tangled motions. Toward an ef-fective network architecture for single image deblurring, we present complemental sub-solution learning with a one-encoder-two-decoder architecture. Observing that multi-ple decoders successfully learn to decompose encoded fea-ture information into directional components, we further improve both the network efficiency and the deblurring per-formance by rotating and sharing kernels exploited in the decoders, which prevents the decoders from separating un-necessary components such as color shift. As a result, our proposed network shows superior results compared to U-Net while preserving the network parameters, and using the proposed network as the base network can improve the per-formance of existing state-of-the-art deblurring networks. 1.

Introduction
Image deblurring is a fundamental image restoration problem in image processing and computer vision, which aims to recover a sharp image from a blurry image caused by a camera or objects in motion. Blurry images affect not only the perceptual image quality but also the performance of various applications such as object detection, image seg-mentation, and visual odometry. Therefore, despite it being a classical restoration task, image deblurring is still being actively researched.
In general, the degradation model is formulated as fol-lows: x = y ∗ k + n, (1)
*Equal contribution
†Corresponding author: Seung-Won Jung (swjung83@korea.ac.kr) where x, y, k, n, and ∗ denote the blurry image (ob-servation), sharp image (latent image), blur kernel, addi-tive random noise, and 2D convolution operation, respec-tively. Since only the blurry image x is given and the other terms unknown, solving Eq. (1) is considered to be
In tra-ill-posed, having multiple solutions to a problem. ditional studies, researchers employed blur kernel estima-tion followed by deconvolution or regularization using nat-ural image priors in attempts to handle the ill-posedness of the deblurring problem [8, 18, 28, 30, 32]. Thanks to the tremendous advances in deep learning and large-scale data accessibility, numerous methods using convolutional neu-ral networks (CNNs) have recently been proposed and have achieved great success [2, 9, 10, 16, 27, 29, 31, 33, 34]. Many deblurring methods adopt U-Net [25] as their base archi-tecture, which has achieved state-of-the-art performance.
U-Net consists of a common CNN-based encoder, succes-sively decreasing the feature resolution to extract high-level image context, and a symmetrically structured decoder, in-creasing the feature resolution back to the input resolution to generate a restored image. Since the local information at each feature resolution in the encoder is transferred to the one at the corresponding resolution in the decoder via skip connection, U-Net can effectively handle multi-scale degra-dation of images.
Motion blur is originated from multiple tangled motions of moving objects in the scene and/or camera shakes. We claim that the common standard of using the unitary lane of
U-Net is insufficient for handling the complicated nature of image blurs. We thus propose a simple but effective solution to this problem by dividing the original problem into mul-tiple sub-problems [21]. In terms of network design objec-tive, splitting a decoder can divide the deblurring problem into sub-problems; in other words, the solution space re-quired for deblurring can be decomposed by explicitly sep-arated decoder networks. The proposed network consists of a single encoder and two decoders as shown in Fig. 1, which induces two decoders to separately solve two sub-problems of deblurring. One decoder implicitly generates a principal residual in the given 2D scene, and the other one generates the complement residual of its separated decoder.
Figure 1. Detailed architecture of XYDeblur.
We observe that without any explicit supervision, the prin-cipal and its complement residuals contain blurred edges along the direction of horizontal and vertical axes in an im-age plane, respectively, which is why we call the proposed network XYDeblur. Based on this observation, we further improve the one-encoder-two-decoder structure of XYDe-blur by spatially rotating the convolutional kernels in one decoder and sharing the parameters with the other decoder.
Unlike conventional parameter sharing approaches in CNN that sacrifice the performance for network efficiency [1,17], the separated decoders with shared and rotated parameters not only reduce the number of parameters but also improve the performance by eliminating undesired disentanglement of features that are irrelevant to the deblurring task.
We demonstrate the effectiveness of XYDeblur as com-pared to U-Net while consuming the same network param-eters. We also show the extensibility of the proposed ap-proach by substituting the base structure in state-of-the-art deblurring networks with the proposed architecture. Ex-perimental results validate that the proposed approach suc-cessfully guides the network to learn complementary sub-solutions and improves the deblurring performance. The contribution of the proposed method can be summarized as follows: 1. To the best of our knowledge, we are the first to intro-duce a one-encoder-two-decoder architecture in image deblurring that derives each output from two decoders to have complementary sub-solutions, which are visu-ally orthogonal in the spatial domain. 2. XYDeblur shares rotated convolutional kernels from one decoder with the other, thereby substantially im-proving the deblurring performance while using the same number of parameters as the standard U-Net ar-chitecture. 3. The proposed network can be implemented in many
U-Net-based state-of-the-art networks without increas-ing the model size, and extensive experimental results show that substituting the U-Net with our proposed network can improve the deblurring performance. 2.