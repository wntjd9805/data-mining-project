Abstract
We propose an efficient plug-and-play acceleration framework for semi-supervised video object segmentation by exploiting the temporal redundancies in videos presented by the compressed bitstream. Specifically, we propose a motion vector-based warping method for propagating seg-mentation masks from keyframes to other frames in a bi-directional and multi-hop manner. Additionally, we in-troduce a residual-based correction module that can fix wrongly propagated segmentation masks from noisy or er-roneous motion vectors. Our approach is flexible and can be added on top of several existing video object segmenta-tion algorithms. We achieved highly competitive results on
DAVIS17 and YouTube-VOS on various base models with substantial speed-ups of up to 3.5X with minor drops in ac-curacy. 1 1.

Introduction
Video object segmentation (VOS) aims to obtain pixel-level masks of the objects in a video sequence. State-of-the-art methods [17,18,20,23] are highly accurate at segmenting the objects, but they can be slow, requiring as much as 0.2 seconds [20] to segment a frame. More efficient methods [3, 27, 37] typically trade off accuracy for speed.
To minimize this trade-off, we propose to leverage com-pressed videos for accelerating video object segmentation.
Most videos on the internet today are stored and transmit-ted in a compressed format. Video compression encoders take a sequence of raw images as input and exploit the in-herent spatial and temporal redundancies to compress the size by several magnitudes [14]. The encoding gives sev-eral sources of “free” information for VOS. Firstly, the bit-stream’s frame type (I- vs. P-/B-frames) gives some indica-tion for keyframes, as the encoder separates the frames ac-cording to their information content. Secondly, the motion compensation scheme used in compression provides motion vectors that serve as a cheap approximation to optical flow. 1Code: https://github.com/kai422/CoVOS 100 90
MiVOS [4]
STCN [5]
CFBI+ [43] 80
STM [20]
STCN+CoVOS
MiVOS+CoVOS
STM+CoVOS
F
&
J
FRTM-VOS [27] 70
RGMP [19]
Track-Seg [3]
TVOS [44] 60
OSVOS [2]
CVOS [32] 50 0 10 20
FPS 30 40
Figure 1. Comparison of VOS methods on the DAVIS 17 dataset.
We double the speed of STM, MiVOS, and STCN with mi-nor drops in accuracy. The other compressed video method
CVOS [32] achieves comparable speed but has a significant drop in accuracy.
Finally, the residuals give a strong indicator of problematic areas that may require refinement.
We aim to develop an accurate yet efficient VOS accel-eration framework. As our interest is in acceleration, it is natural to follow a propagation-based approach in which an (heavy) off-the-shelf base network is applied to only keyframes. Acceleration is then achieved by propagating the keyframe segmentations and features to non-keyframes.
In our framework, we leverage the information from the compressed video bitstream, specifically, the motion vec-tors and residuals, which are ideal for an efficient yet accu-rate propagation scheme.
Motion vectors are cheap to obtain – they simply need to be read out from the bitstream. However, they are also more challenging to work with than optical flow. Whereas optical flow fields are dense and defined on a pixel-wise basis, mo-tion vectors are sparse. For example in HEVC [30], they are defined only for blocks of pixels, which greatly reduces the resolution of the motion information and introduces block
artifacts. Furthermore, in cases where the coding bitrate limit is too low, the encoder may not estimate the motion correctly; this often happens in complex scenes or under fast motions. As such, we propose a dedicated soft propagation module that suppresses noise. For further improvement, we also propose a mask correction module based on the bit-stream residuals. Putting all of this together, we designed a new plug-and-play framework based on compressed videos to accelerate standard VOS methods [4, 5, 20]. We use these off-the-shelf methods as base networks to segment keyframes and then leverage the compressed videos’ mo-tion vectors for propagation and residuals for correction.
A key distinction between our motion vector propaga-tion module and existing optical flow propagation meth-ods [19, 22, 23, 45] is that our module is bi-directional. We take advantage of the inherent bi-directional nature of mo-tion vectors and propagate information both forwards and backwards. Our module is also multi-hop as we can prop-agate mask between non-keyframes. These features make our propagation scheme less prone to drift and occlusion errors.
A closely related work to ours is CVOS [32]. CVOS aims to develop a stand-alone VOS framework based on compressed videos, whereas we are proposing a plug-and-play acceleration module. A shortcoming of CVOS is that it considers only I- and P-frames but not B-frames in their framework. This setting is highly restrictive and uncom-mon, since B-frames were introduced to the default encod-ing setting specified by the MPEG-1 standard [14] over 30
In contrast, we consider I-, P- and B-frames, years ago. making our method more applicable and practical for mod-ern compressed video settings.
Our experiments demonstrate that our module offers considerable speed-ups on several image sequence-based models (see Fig. 1). As a by-product of the keyframe se-lection, our module also reduces the memory of existing memory-networks [20, 28], which are some of the fastest and most accurate state-of-the-art VOS methods. We sum-marize our contributions below:
• A novel VOS acceleration module that leverages infor-mation from the compressed video bitstream for seg-mentation mask propagation and correction.
• A soft propagation module that takes as input inaccu-rate and blocky motion vectors but yields highly accu-rate warps in a multi-hop and bi-directional manner.
• A mask correction module that refines propagation er-rors and artifacts based on motion residuals.
• Our plug-and-play module is flexible and can be ap-plied to off-the-shelf VOS methods to achieve up to 3.5×speed-ups with negligible drops in accuracy. 2.