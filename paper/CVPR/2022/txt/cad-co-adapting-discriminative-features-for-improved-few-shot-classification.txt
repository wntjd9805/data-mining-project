Abstract
Few-shot classification is a challenging problem that aims to learn a model that can adapt to unseen classes given a few labeled samples. Recent approaches pre-train a feature extractor, and then fine-tune for episodic meta-learning. Other methods leverage spatial features to learn pixel-level correspondence while jointly training a classi-fier. However, results using such approaches show marginal improvements.
In this paper, inspired by the transformer style self-attention mechanism, we propose a strategy to cross-attend and re-weight discriminative features for few-shot classification. Given a base representation of support and query images after global pooling, we introduce a sin-gle shared module that projects features and cross-attends in two aspects: (i) query to support, and (ii) support to query. The module computes attention scores between fea-tures to produce an attention pooled representation of fea-tures in the same class that is later added to the original representation followed by a projection head. This effec-tively re-weights features in both aspects (i & ii) to produce features that better facilitate improved metric-based meta-learning. Extensive experiments on public benchmarks show our approach outperforms state-of-the-art methods by 3%∼5%. 1.

Introduction
Deep learning has achieved remarkable success in nu-merous computer vision tasks, reaching human-level per-formance in domains with sufficiently large-scale labeled training data. However, large-scale data is not always read-ily available due to costly curation and labeling. Hence, there is a ongoing research effort to design models that can learn to solve tasks using a limited number of labeled examples to alleviate this requirement. While several ap-proaches such as transfer-, semi- and unsupervised learning have shown reasonable performance, learning to generalize with an extremely limited number of labeled samples is still
Figure 1. Visual intuition of the proposed framework compared to other approaches using attention. (a) Standard ProtoNet [43] architecture with nearest neighbour classifier (NN). (b) Adaptation of support embeddings only without using relations in the query sets, with backbone pre-training [54]. (c) Our method leverages attention from each set in a cross-relational perspective to improve classification performance by re-weighting features. a challenge. Motivated by the ability of humans to rapidly adapt to new tasks using prior knowledge, the field of few-shot learning shows promise in achieving this goal.
Few-shot learning [22, 36, 43] aims to classify unlabeled query samples from unseen classes using only limited la-beled support examples. Recent approaches have leveraged the meta-learning paradigm where transferable knowledge across a collection of tasks is learned and propagated to im-prove generalization.
In particular, one of the promising approaches have used the meta-learning framework to op-timize model parameters [11, 33, 36] with a few gradient steps, thus enabling neural network classifiers to quickly adapt to unseen classes. Other works employ similarity information between images (Fig. 1(a)), augmentation of
training data with generative techniques [15, 40], or two-stage approaches [7,35,42,53] that involve first pre-training the model on existing known classes and later use a meta-finetuning strategy. In the general meta-setup, tasks defined in the training phase mimic the testing phase to encourage generalization of models.
Though pre-training strategies show promising results,
Chen et al. [7] argued that fine-tuning shows marginal im-provements. Moreover, the standard technique of obtaining a base representation with global-average pooling is consid-ered limited, since it is sensitive to object pose and discards key semantic details, and may be difficult to learn gener-alizable embeddings without being distracted by spurious features [18, 20]. Thus, recent works focus on learning finer distinctions using spatial features only via spatial at-tention mechanisms [19] or other forms of relational learn-ing [20, 52] between query and support features to enhance performance. Nevertheless, methods leveraging this setting i.e., spatial feature-based learning, still report marginal im-provements over purely discriminative approaches with the exception of some works that provide insight into the model reasoning procedure by visualizing object attended regions for interpretability.
Here, we argue that meta-learning with instance embed-dings only is still viable and can improve few-shot perfor-mance when attending to the relevant features. For example,
Ye et al. [54] attempt to address this and show that optimally discriminative features can be meta-learned using a set-to-set function based on the transformer model [47] (Fig. 1(b)).
The self-attention mechanism in the Transformer presents several desirable properties for set based problems i.e., per-mutation invariance, interpolation, and contextualization.
As a consequence, any meta-learner can leverage such a set-based transformation to adapt instance embeddings relative to other classes for improved prototype generation, or to produce better embeddings. However, while Ye et al. [54] showed improvements, embedding adaptation is performed on support samples only without leveraging query informa-tion, a key distinction with recent spatial techniques using cross-attention [19, 20, 52] to learn better correspondences.
Moreover, the authors use a transfer-based approach requir-ing pre-training on base classes before meta-training.
In this work, we propose an end-to-end meta-learning strategy trained from scratch to co-attend to both support and query features using self-attention (Fig. 1(c)). This is useful to focus on common object features and avoid dis-In particular, we introduce tractors for better matching. a single shared attention module that first projects global pooled base representations and computes attention scores per k-shot task via scaled-dot product. Given the scores per shot, we take the mean of the scores to obtain an attention pooled feature (dot product of features and scores) that is later added to the initial projected features before produc-ing the final re-weighted features. Concretely, to improve support features i.e., query to support, attention scores be-tween query and support features are employed to pool the initial support features producing a support prototype con-catenated with the initial features, and vice versa for support to query to produce a query prototype that improves the ini-tial query features. This strategy is conceptually equivalent to spatial based cross-attention that implicitly re-weights the base spatial maps to attend to relevant object regions.
Finally, we employ a nearest neighbor classifier on the re-fined features for few-shot classification. The contributions of this paper can be summarized as follows:
• To improve model-based embedding adaptation, we pro-pose to cross-attend support and query embeddings by re-weighting each instance relative to the other via self-attention.
• We reveal that implicitly re-weighting features with their prototypes (support/query) via self-attention improves metric based few-shot performance and adds minimal over-head in learnable parameters.
• Extensive evaluation of the proposed components verify the effectiveness of our method. Moreover, we show com-petitive results over state-of-the-art methods on several benchmark datasets. 2.