Abstract 1.

Introduction
Burst denoising is now more relevant than ever, as com-putational photography helps overcome sensitivity issues inherent in mobile phones and small cameras. A major challenge in burst-denoising is in coping with pixel mis-alignment, which was so far handled with rather simplis-tic assumptions of simple motion, or the ability to align in pre-processing. Such assumptions are not realistic in the presence of large motion and high levels of noise.
We show that Neural Radiance Fields (NeRFs), orig-inally suggested for physics-based novel-view rendering, can serve as a powerful framework for burst denoising.
NeRFs have an inherent capability of handling noise as they integrate information from multiple images, but they are limited in doing so, mainly since they build on pixel-wise operations which are suitable to ideal imaging conditions.
Our approach, termed NAN1, leverages inter-view and spatial information in NeRFs to better deal with noise. It achieves state-of-the-art results in burst denoising and is especially successful in coping with large movement and occlusions, under very high levels of noise. With the rapid advances in accelerating NeRFs, it could provide a power-ful platform for denoising in challenging environments.
Burst denoising has become the de-facto method for low-light imaging, especially in handheld mobile devices that perform onboard processing [5, 9]. It is built on capturing multiple short-exposure (dark and noisy) frames, which are then integrated into a single coherent image. The main chal-lenge of compensating for motion and occlusion, especially under high noise, is evident in limitations of current applica-tions (e.g., mobile phone apps ask to “hold still” while cap-turing in night mode). Dealing with large parallax could sig-nificantly enhance denoising, by allowing the use of longer bursts than (the typical 8) currently common in cameras, and might enable more flexible imaging during movement (e.g., from a vehicle).
Recently, methods based on Neural Radiance Fields (NeRFs) have been demonstrated to be powerful in render-ing novel views of scenes, enabling the synthesis of intricate details due to reflections and occlusions, yet all these meth-ods consider clean high-resolution images as inputs. Since
NeRFs integrate information from multiple images, they have strong potential to be leveraged in multi-frame image restoration tasks - applications they were not designed for.
We show in this paper that they can be very powerful for burst denoising. 1Refer to the project website: noise-aware-nerf.github.io
NeRFs serve as implicit scene priors and thus can inher-ently handle noise [2, 14]. However, when using a small number of input images this capability is limited, since cur-rent architectures operate separately on each pixel with lo-cal computations that are highly prone to noise - imply-ing much room for improvement. We demonstrate that by adding inter-view and spatial awareness to the network we significantly improve its “noise-awareness” and produce
SOTA results in burst denoising, especially under large mo-tion and high noise (see Fig. 1). To avoid specific per-scene training, we build on the recently proposed IBRNet [29] that pre-trains on different image sets and is able to produce novel views during inference time in new unseen scenes, using as few as 8 images.
To summarize our contributions: (i) We achieve SOTA results in burst denoising; (ii) We successfully exploit the natural power of radiance fields as scene priors by augment-ing them with novel noise-awareness components, both in the spatial and cross-view domains; (iii) We demonstrate the advantages of our approach (NAN) over SOTA burst-denoising methods, which operate in the image plane, while
NAN, being NeRF based, explicitly works in 3D space - im-perative for dealing with large motion and high noise. 2.