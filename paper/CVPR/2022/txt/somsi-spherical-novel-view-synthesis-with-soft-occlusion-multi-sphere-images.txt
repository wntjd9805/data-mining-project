Abstract
Spherical novel view synthesis (SNVS) is the task of es-timating 360◦ views at dynamic novel views given a set of 360◦ input views. Prior arts learn multi-sphere image (MSI) representations that enable fast rendering times but are only limited to modelling low-dimensional color val-ues. Modelling high-dimensional appearance features in
MSI can result in better view synthesis, but it is not feasible to represent high-dimensional features in a large number (> 64) of MSI spheres. We propose a novel MSI representa-tion called Soft Occlusion MSI (SOMSI) that enables mod-elling high-dimensional appearance features in MSI while retaining the fast rendering times of a standard MSI. Our key insight is to model appearance features in a smaller set (e.g. 3) of occlusion levels instead of larger number of MSI levels. Experiments on both synthetic and real-world scenes demonstrate that using SOMSI can provide a good balance between accuracy and run-time. SOMSI can produce con-siderably better results compared to MSI based MODS [1], while having similar fast rendering time. SOMSI view syn-thesis quality is on-par with state-of-the-art NeRF [24] like model while being 2 orders of magnitude faster. For code, additional results and data, please visit https:
//tedyhabtegebrial.github.io/somsi. 1.

Introduction
The advent of low-cost 360◦ imaging devices makes spherical images a standard choice of representation for 3D scenes in comparison to more expensive 3D modelling with artists or depth sensors. Spherical images are widely used to capture and visualize 360◦ views of scenes with several ap-plications in virtual tourism, navigation, advertisement, etc.
However, a spherical image alone delivers a limited viewing experience with only rotations around the center. User navi-gation (translation) is usually enabled by capturing multiple spherical images thereby allowing the user to hop from one to another. Spherical novel view synthesis (SNVS) is the task of estimating in-between 360◦ views making it possi-ble for seamless continuous user navigation in a scene. See
Fig. 1 (left) for a sample illustration of the problem setting.
A practical SNVS system would have the following properties: 1. High-quality synthesis of disoccluded con-tent and view-dependent effects in novel views, 2. Fast synthesis time enabling realtime user navigation in a scene and, 3. Low memory consumption to run SNVS on mobile hardware such as VR headsets. Satisfying all these prop-erties is quite challenging. Current SNVS techniques are based on Multi-Sphere Image (MSI) representation [1, 4].
MSI can be seen as a spherical extension of Multi-Plane Im-ages (MPI) [32, 37], which are widely adopted in view syn-thesis of common perspective images. More specifically,
MSIs represent a scene as a set of textured spheres centered around a reference point. A key advantage of using MSIs is that rendering spheres is extremely efficient with standard rendering softwares. The simplicity of the rendering and seamless integration with graphics software makes MSIs an appealing choice for real-time rendering applications. On the other hand, current MSI based techniques such as Ma-tryODSHkha (MODS) [1] suffer from unsatisfactory qual-ity in synthesized novel views.
The use of Coordinate Multi-Layer Perceptrons (CMLP) is revolutionizing the field of novel view synthesis with very high-quality results such as in NeRF [24]. A key drawback of CMLP based techniques is the requirement of large num-ber of training views as well as slow rendering. Several very recent works try to improve NeRF-like techniques in different aspects: improving rendering speed [13, 19, 26], modelling reflectance properties [3], working with in-the-wild images [23], re-lighting [30], generalizing across scenes [36], etc. Even though one could adapt a NeRF-like technique for SNVS task, rendering novel 360◦ views would be prohibitively slow. Several concurrent techniques to improve rendering speed of NeRFs [13, 19, 26] are either specific to perspective images or did not demonstrate their use for spherical images in the SNVS task.
In this work, we propose a novel SNVS technique that provides a good trade-off between different favourable properties: high-quality view synthesis and fast runtime with low memory requirements. Following [1], we also
[1] make use of MSI representation for fast rendering.
Figure 1. High quality view synthesis with SOMSI. (Left) Illustration of sample input and held-out target spherical views of a scene. (right) Synthesized novel views and the corresponding error maps for SOMSI (Ours), MODS [1] and S-NeRF [24]. learns a CNN that takes spherical images as input and pro-duces an MSI representation where each point in each lay-ered sphere has an RGB color and an alpha value associated with it. Several recent MPI works [17, 21, 34] on view syn-thesis demonstrate the use of high-dimensional learned fea-tures in MPI planes instead of color MPIs. Following these approaches and coordinate MLPs, we propose to learn high-dimensional appearance features in MSI using coordinate
MLPs. In essence, we combine the strengths of coordinate
MLPs with MSI representation, thereby achieving both high quality and fast runtime (rendering). d
×
×
O (m
A key issue in representing high-dimensional features at each point in MSI is high memory consumption. For in-stance, representing f -dimensional features in d (usually
> 64) spheres with m points each leads to a memory com-plexity of f ). Since the number of points m in a 360◦ spherical image are usually high, the memory complexity will be prohibitively high if we represent high-dimensional features in each MSI sphere. We argue that representing dense features in MSI sphere is superfluous as much of the 3D space is empty. As a remedy, we propose a novel MSI scene representation where the scene appear-ance and geometry are factored into two separate data struc-tures. We call this novel MSI representation Soft Occlusion
MSI (SOMSI). SOMSI represents the scene geometry with standard MSI data structure, while the scene appearance is represented as a set of layered 2D feature maps. The key in SOMSI is to represent appearance feature maps using a smaller set of scene-specific occlusion levels instead of large set of predefined MSI spheres.
In essence, SOMSI representation takes k) memory for scene geom-f ) memory etry with soft occlusion masks and to represent scene appearance features, where k denotes the number of occlusion levels. This strategy scales much bet-(m (m
O
O
×
×
×
× k d ter in terms of memory with increasing feature dimension as the number of occlusion levels are significantly lower (k = 3 in our case) compared to spheres in MSI (usually d > 64). We also propose a novel SOMSI rendering formu-lation that allows the fast rendering of novel views like with standard MSI representation.
We demonstrate the effectiveness of our SOMSI tech-nique with results on both synthetic and real-world scenes.
Fig. 1 shows sample input and held-out spherical views along with sample results of different techniques. Results show that our approach can considerably outperform previ-ous MSI based techniques [1]. Our approach can produce high quality novel views that are on-par with spherical adap-tation of NeRF [24] technique (S-NeRF) while being 2 or-ders of magnitude faster, with rendering time close to MSI techniques [1]. We make the following contributions:
• We propose a novel Soft Occlusion Spherical Multi-Sphere (SOMSI) representation that can effectively scale to encode high-dimensional scene appearance features in
MSI representation using learnable occlusion layers.
• We propose an efficient way to render novel views from the learned SOMSI representation.
• Our approach effectively combines the advantages of dif-ferent techniques with high quality view synthesis that is on-par with implicit volumetric representations [24] while having fast runtime like with standard MSI repre-sentations [1]. 2.