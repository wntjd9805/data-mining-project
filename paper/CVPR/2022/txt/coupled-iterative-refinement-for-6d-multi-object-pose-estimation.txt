Abstract
We address the task of 6D multi-object pose: given a set of known 3D objects and an RGB or RGB-D input im-age, we detect and estimate the 6D pose of each object.
We propose a new approach to 6D object pose estimation which consists of an end-to-end differentiable architecture that makes use of geometric knowledge. Our approach it-eratively refines both pose and correspondence in a tightly coupled manner, allowing us to dynamically remove outliers to improve accuracy. We use a novel differentiable layer to perform pose refinement by solving an optimization problem we refer to as Bidirectional Depth-Augmented Perspective-N-Point (BD-PnP). Our method achieves state-of-the-art accuracy on standard 6D Object Pose benchmarks. Code is available at https://github.com/princeton-vl/Coupled-Iterative-Refinement. 1.

Introduction
Given an RGB or RGB-D image containing a set of ob-ject instances of known 3D shapes, 6D multi-object pose is the task of detecting and estimating the 6D pose—position and orientation—of each object instance. Accurate poses are important for robotics tasks such as grasping and aug-mented reality applications involving shape manipulation.
In the standard 6D multi-object pose setup, we are given a set of 3D models of known object instances. Given an
RGB or RGB-D input image, the goal is to jointly detect ob-ject instances and estimate their 6D object pose. Early work solved this problem by first estimating correspondences be-tween the 3D model and the image [22], producing a set of 2D-3D correspondences, which are then used to obtain 6D object pose using Perspective-n-Point (PnP) solvers [16,19] or iterative algorithms like Levenberg-Marquardt.
While 2D-3D correspondence is sufficient to solve for 6D pose, it is difficult to obtain accurate correspondence in practice. In many applications, we wish to estimate the pose of poorly textured objects where local feature matching is unreliable. Furthermore, problems such as heavy occlusion, object symmetry, and lighting variation can make detecting and matching local features near impossible. These prob-Figure 1. Given an image and collection of 3D models, our method outputs the position and orientation of each object instance. lems cause classical systems to be too brittle for many use cases which require a greater degree of robustness.
Recently, many of these issues have been partially ad-dressed using deep learning. A simple approach is to train a network to directly regress 6D poses [18, 20, 35]. Direct pose regression simply learns to map input to output, and makes no use of the fact that the pixels are a perspective pro-jection of a known 3D object. Although direct pose regres-sion can be quite effective in practice, an intriguing question is whether there exist better deep learning methods that take advantage of projective geometry.
Many works on 6D pose have attempted to combine deep learning and projective geometry. One approach is to train a deep network to detect keypoints of a known 3D object [12, 26–29, 33], producing a set of 2D-3D cor-respondences which can serve as input to a Perspective-n-Point (PnP) solver. Another approach is to impose ge-ometric knowledge in the form of implicit or declarative layers [5, 6]. These works showed that PnP could be im-plemented as a modular component in end-to-end differen-tiable architectures. However, both approaches are “one-shot” in the sense that correspondence is predicted once and then used to solve for pose through a PnP solver (differen-tiable or not); this makes the approaches sensitive to outliers and errors in the correspondences.
We propose a new approach to 6D object pose estima-tion. Our approach consists of an end-to-end differentiable architecture that makes use of geometric knowledge. The main novelty of our approach over prior work on 6D pose
is the use of “coupled iterative refinement”: unlike prior work which operates in a single shot setting, we iteratively refine pose and correspondence in a tightly coupled man-ner, allowing us to dynamically remove outliers to improve accuracy.
Our approach builds on top of the RAFT [31] architec-ture developed for optical flow (i.e. dense correspondence).
The basic idea is to estimate flow between the input image and a set of rendered images of the known 3D object, gen-erating 2D-3D correspondences that are used to solve for pose. Like RAFT, we use a GRU to perform recurrent iter-ative updates, but at each iteration we update not only flow but also object pose. The flow update and pose update are tightly coupled: the flow update is conditioned on the cur-rent pose, and the pose update is conditioned on the flow.
To perform the pose update, we introduce a novel dif-ferentiable layer we call “Bidirectional Depth-Augmented
PnP (BD-PnP)”. This layer is similar to a differentiable PnP solver in that it produces a Gauss-Newton update to object pose by minimizing reprojection error. However, it is novel in two aspects. First, it is bidirectional: it solves for a single pose update to simultaneously satisfy two sets of 2D-3D correspondences, one set defined on the input image, the other set defined on a rendered image. Second, our layer is “depth-augmented”: the optimization objective also in-cludes the reprojection error on inverse depth, which we show to be important for improving accuracy.
Our method achieves state-of-the-art accuracy on the
YCB-V [4], T-LESS [14] and Linemod (Occluded) [2]
RGB-D multi-object BOP [15] pose benchmarks, signifi-cantly outperforming prior work. A variant of our method can handle RGB-only input, with performance on par with the current state-of-the-art. 2.