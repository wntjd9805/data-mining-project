Abstract
In the field of computer vision, recent works show that a pure MLP architecture mainly stacked by fully-connected layers can achieve competing performance with CNN and transformer. An input image of vision MLP is usually split into multiple tokens (patches), while the existing MLP mod-els directly aggregate them with fixed weights, neglecting the varying semantic information of tokens from different images. To dynamically aggregate tokens, we propose to represent each token as a wave function with two parts, amplitude and phase. Amplitude is the original feature and the phase term is a complex value changing accord-ing to the semantic contents of input images. Introducing the phase term can dynamically modulate the relationship between tokens and fixed weights in MLP. Based on the wave-like token representation, we establish a novel Wave-MLP architecture for vision tasks. Extensive experiments demonstrate that the proposed Wave-MLP is superior to the state-of-the-art MLP architectures on various vision tasks such as image classification, object detection and seman-tic segmentation. The source code is available at https:
//github.com/huawei- noah/CV- Backbones/ tree/master/wavemlp_pytorch and https:// gitee.com/mindspore/models/tree/master/ research/cv/wave_mlp. 1.

Introduction
In computer vision, convolutional neural networks (CNNs) have been the mainstream architectures for a long time [19, 26, 36]. It is challenged by the recent works [9, 33, 47], in which a standard Transformer [46] model can also work well on various computer vision tasks, such as im-age classification, object detection and semantic segmenta-tion [16]. Considering the high complexity of self-attention modules in the vision transformer, more simple architec-∗Corresponding author. tures (e.g., MLP-Mixer [43], ResMLP [44]) stacking only multi-layer perceptrons (MLPs) have attracted much atten-tion. Compared with CNNs and Transformers, these vision
MLP architectures involve less inductive bias and have po-tential to be applied on more diverse tasks. (a) Accuracy w.r.t. FLOPs. (b) Accuracy w.r.t. throughput.
Figure 1. Performance comparison between the proposed Wave-MLP and existing architectures. Top-1 accuracies on ImageNet are reported.
Taking a sequence of image patches (tokens) as in-put, MLP-like models [43, 44] mainly contain two sepa-rable blocks, i.e., channel-mixing MLP and token-mixing
MLP, both composing of full-connected layers and activa-tion functions. The channel-mixing MLP transforms feature of each token and the token-mixing MLP tries to aggregate information from different tokens. By stacking these two types of MLP block alternatively, the simple MLP architec-ture could have sufficient capacity to extract features and achieve good performance on vision tasks.
However, the performance of MLP architecture is still in-ferior to that of SOTA Transformer and CNN architectures.
We point out that one of the bottlenecks for vision MLP lies in its manner of aggregating different tokens, i.e., mix-ing different tokens with fixed weights of fully-connected layers. Recall that Transformer [9, 46] aggregates tokens with weights dynamically adjusted by the attention mech-anism. The inner products between different tokens are calculated and tokens with higher similarities tend to have
82.6% top-1 accuracy on ImageNet with 4.5G FLOPs, which significantly surpasses Swin-T [33] with 81.3% ac-curacy and 4.5G FLOPs. Besides, Wave-MLP also achieves strong performance on the dense prediction tasks such as object detection and semantic segmentation.
The paper is organized as follows: Section 2 briefly re-views the existing works about designing model architec-tures, and Section 3 discusses the proposed Wave-MLP ar-chitecture detailedly. In Section 4, we empirically investi-gate the method’s effectiveness on multiple vision tasks and make conclusions in Section 5. 2.