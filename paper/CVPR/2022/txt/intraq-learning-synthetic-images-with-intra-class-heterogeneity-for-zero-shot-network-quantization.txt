Abstract
Learning to synthesize data has emerged as a promising direction in zero-shot quantization (ZSQ), which represents neural networks by low-bit integer without accessing any of the real data. In this paper, we observe an interesting phenomenon of intra-class heterogeneity in real data and show that existing methods fail to retain this property in their synthetic images, which causes a limited performance increase. To address this issue, we propose a novel zero-shot quantization method referred to as IntraQ. First, we propose a local object reinforcement that locates the target objects at different scales and positions of the synthetic im-ages. Second, we introduce a marginal distance constraint to form class-related features distributed in a coarse area.
Lastly, we devise a soft inception loss which injects a soft prior label to prevent the synthetic images from being over-fitting to a fixed object. Our IntraQ is demonstrated to well retain the intra-class heterogeneity in the synthetic images and also observed to perform state-of-the-art. For exam-ple, compared to the advanced ZSQ, our IntraQ obtains 9.17% increase of the top-1 accuracy on ImageNet when all layers of MobileNetV1 are quantized to 4-bit. Code is at https://github.com/zysxmu/IntraQ. 1.

Introduction
The increasing demands in computing power and mem-ory footprint of deep neural networks (DNNs) raise a chal-lenging application problem on edge computing devices such as smart phones or wearable gadgets, in which the lim-ited hardware resource fails to support the highly complex
DNNs. A variety of methods [12, 13, 20, 25] have been in-vestigated to reduce the model complexity. Network quan-tization, which represents the floating-point parameters and activations within the networks by low-bit integers, stands
*Corresponding Author: rrji@xmu.edu.cn out among these methods for its significant memory reduc-tion and more efficient integer operations.
Most existing methods explore quantization-aware train-ing (QAT) that builds a quantizer on the premise of ac-cessing the original complete training dataset [2, 8, 43]. In
[18, 23, 47], QAT is demonstrated to be comparable or even better than its floating-point counterpart since the weights could be adjusted to fit the quantization operations given the access to sufficient training data [40]. However, the draw-backs also stem from its reliance on training data. Specifi-cally, in real-world cases, the original training data is some-times prohibitive due to deteriorating privacy and security problems. For example, people may not wish their medi-cal records to be revealed to others, and business material is not expected to be transmitted via the internet. As such,
QAT is no longer applicable. Though recent studies on post-training quantization (PTQ) [24, 30, 40] directly quantizes
DNNs using a small portion of original data, for cases such as MLaas (e.g., Amazon AWS and Google Cloud), it may be impossible to reach any of the training data from users [3].
Fortunately, the research community recently has pro-posed zero-shot quantization (ZSQ) to quantize models without accessing real data. Existing studies on ZSQ can be categorized into two groups. The first group calibrates parameters without the involvement of any data. For ex-ample, DFQ [31] utilizes the shift and scale parameters β and γ stored in the batch normalization layers of the full-precision model to compute the expected biased error on the output. Nevertheless, a simple calibration of parameters results in severe performance degradation in ultra-low pre-cision. For instance, only 0.10% top-1 accuracy of DFQ on
ImageNet [36] is reported in the appendix of [41] if quan-tizing ResNet-18 to 4-bit.
The second group performs quantization by exploiting synthetic fake images. The involvement of fake images facilitates the training of quantized networks which are demonstrated to be superior in performance [11, 41, 46].
(a) Real data (b) ZeroQ (c) DSG (d) ZeroQ+IL (e) DSG+IL (f) IntraQ (Ours)
Figure 1. Feature visualization using t-SNE [39]. We randomly sample 1,000 synthetic/real images consisting of 5 classes with 200 images per class. For ZeroQ and DSG, label information is unavailable. The features are extracted from a pre-trained ResNet-18.
An intuitive solution is to deploy a generator to synthesize training data [4, 28, 41]. However, these generator-based methods suffer a heavy overhead on computation resources since the generator has to be trained from scratch for differ-ent bit-width settings. On the contrary, many studies such as ZeroQ [3] and DSG [46] formulate the data synthesis as an optimization problem where a random input data drawn from the standard Gaussian distribution is iteratively up-dated to fit the real-data distribution. This research line leads to a resource-friendly quantization as the synthetic images can be reused to calibrate or fine-tune networks in different bit widths. However, a non-ignorable quality gap in synthetic images still remains when comparing the fea-ture visualization of ZeroQ (Fig. 1b) and DSG (Fig. 1c) with the real data (Fig. 1a) since traditional Gaussian synthesis is towards fitting the whole dataset while ignoring a subtler class-wise decision boundary. Thus, the quantized models often bear large performance drops (see Sec. 3.1.2).
To ensure class-wise discrimination in the fake images, we apply the popular inception loss [9, 44] to ZeroQ and
DSG, which first chooses an arbitrary label, and then per-forms optimization to generate label-oriented images. As a result, we observe more class-wise separable distributions of synthetic data (Fig. 1d and Fig. 1e). This demonstrates the importance of injecting prior class information in syn-thetic data. Nevertheless, we observe that the synthetic data with the inception loss fail to capture the intra-class hetero-geneity. Specifically, images from the same class often con-tain different contents; thus features from the same class of real data scatter a lot as shown in in Fig. 1a. On the contrary, those in Fig. 1d and Fig. 1e are in a dense concentration, which indicates the synthetic images of the same class are mostly homogeneous. Consequently, the quantized model fine-tuned with these synthetic data fails to generalize well to the real-world test dataset featuring heterogeneity.
To retain the intra-class heterogeneity, in this paper, we propose a novel zero-shot quantization method, termed In-traQ. Motivated by the fact that the objects of interest bene-fiting the model learning are not always at the same scale or position in the images, we propose a local object reinforce-ment by randomly cropping a local patch from the synthetic image to locate the target objects, which mitigates synthe-sizing homogeneous images. Apart from heterogeneous im-ages, we also propose to retain the intra-class heterogeneity in their feature space. This is accomplished by introducing a marginal distance constraint to not only form class-related features but also avoid learning features concentrated on a dense area. In contrast to the traditional inception loss with one-hot label, we further devise a soft inception loss which injects a soft prior label to excavate images with more com-plex scenes and prevent the synthetic images from being overfitting to a fixed object. With the above three innova-tive solutions, the intra-class heterogeneity is well preserved in our synthetic images as shown in Fig. 1f and significant performance improvements are observed when using only 5,120 synthetic images to fine-tune the quantized models.
For instance, our IntraQ achieves 51.36% top-1 accuracy on
ImageNet when quantizing MobileNetV1 to 4-bit, leading to a increase of 9.17% when compared with the advanced
DSG [46] equipped with the traditional inception loss [9]. 2.