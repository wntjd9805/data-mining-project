Abstract
Deep learning has become an increasingly popular and powerful methodology for modern pattern recognition sys-tems. However, many deep neural networks have millions or billions of parameters, making them untenable for real-world applications due to constraints on memory size or latency requirements. As a result, efficient network com-pression techniques are often required for the widespread adoption of deep learning methods. We present DECORE, a reinforcement learning-based approach to automate the network compression process. DECORE assigns an agent to each channel in the network along with a light policy gradient method to learn which neurons or channels to be kept or removed. Each agent in the network has just one parameter (keep or drop) to learn, which leads to a much faster training process compared to existing approaches.
DECORE provides state-of-the-art compression results on various network architectures and various datasets. For ex-ample, on the ResNet-110 architecture, it achieves a 64.8% compression and 61.8% FLOPs reduction as compared to the baseline model without any accuracy loss on the CIFAR-10 dataset. It can reduce the size of regular architectures like the VGG network by up to 99% with just a small accu-racy drop of 2.28%. For a larger dataset like ImageNet with only 30 epochs of training, it can compress the ResNet-50 architecture by 44.7% and reduce FLOPs by 42.3%, with just a 0.69% drop on Top-5 accuracy of the uncompressed model. We also demonstrate that DECORE can be used to search for compressed network architectures based on var-ious constraints, such as memory and FLOPs. 1.

Introduction
Deep neural networks (DNNs) have led to significant advances in image recognition tasks, most notably bench-marked by the ImageNet challenge [42]. Recent trends suggest that deeper architectures with more parameters and more complex computational blocks lead to better re-sults [13, 47]. These increases in model size, however, in-cur a higher inference cost, making them difficult to be deployed in embedded systems or mobile devices. Ad-ditionally, real-world applications have memory, latency, or throughput constraints which make it difficult to use large convolutional neural networks (CNNs) as is. There-fore, lowering the inference time and memory consumption of large models would benefit the wider adoption of deep learning models for these real-world applications.
There has been a significant amount of work on reduc-ing the inference cost via a more efficient network architec-ture [5, 7, 27, 43]. Although much progress has been made, the process of finding efficient architectures often requires a lot of experience and manual design. The automation of this process is an active research area of great value, as newer, more powerful DNN architectures are rapidly be-ing discovered. Meanwhile, a large body of work has also been done in the direction of network compression, such as low-rank decomposition [5, 29, 30, 59], parameter quantiza-tion [22, 41, 61], and pruning [18, 27, 28, 31, 32, 56].
These compression techniques can be broadly divided into two categories: non-structured and structured prun-ing. Non-structured pruning methods [9–12] directly prune weights of CNN models to get sparse weight matrices.
Along with compression, these approaches can provide faster network inference using specialized software [8] or hardware [8, 21, 39]. However, they often cause irregular memory access that adversely affects the network inference on general-purpose hardware or BLAS libraries. Structured pruning overcomes these limitations by removing structured weights like 2D kernels and feature maps (channels) or lay-ers, which focuses on network architecture changes and can be supported by off-the-shelf deep learning libraries like
PyTorch [40], and TensorFlow [1] etc. Pruning structured weights is a complex problem as we have to find out which layers or channels are least important in the network and re-moving them will not affect the accuracy significantly. For example, in VGG16 [47] the first hidden layer has 64 chan-nels, an exhaustive search for which channels to remove without affecting accuracy involves 264 combinations. For the whole network with around 5, 000 channels in total, it is computationally infeasible to go through all combinations.
To overcome this problem many techniques have been pro-posed in the following categories.
Pruning using trained network statistics: These ap-proaches mostly consist of two steps, first pruning the weights using network statistics and then fine-tuning the compressed network to recover from accuracy loss. Among these techniques, magnitude-based pruning has been pro-posed to find filters [27] or channels (feature maps) [18] with the lowest l1-norm as they are least informative and can be removed. Yang et al. [15] calculates the geomet-ric median of each layer and prunes the filters close to it.
Greedy pruning [16, 35] is also a common strategy that prunes filters by considering statistics computed from the next layer in a greedy layer-wise manner. More recently,
Lin et al. [28] proposed to find the channel’s importance by calculating the rank of channels. All these methods cal-culate channel or filter importance at one or neighboring layers without considering all other layers in a deep neural network. Yu et al. [56] found that channels that were as-sumed less important and pruned in early layers could have a significant impact on the pruning of later layers. To ad-dress this issue, they calculate the importance score of the final layer and propagate it to each filter in the network to get its importance score.
Finding least important channels using trained network statistics is fairly straightforward, but finding how many channels or filters to drop from each layer (or the network) to achieve a certain compression rate requires manual effort.
For example, in [28,56] a fixed compression rate is used be-fore fine-tuning which limits exploration for different com-pression rates, as each combination requires fine-tuning to recover from accuracy loss which could be time-consuming.
Pruning by learning channel importance: Another group of techniques is learning which channels are impor-tant by applying compression constraints while retraining the network, such as sparse scaling parameters in batch nor-malization layers [34,52,60]. Extension to these approaches has also taken into account of resource constraints such as latency and computation [6, 7, 38]. Huang et al. [20] and
Lin et al. [32] introduced a new binary parameter to each channel (mask) to find out if the channel is important or not, but learning this binary mask involves an NP-hard opti-mization. This joint optimization for both compression and accuracy leads to higher accuracy performance but since the (combined) loss function is different than the original net-work, it requires specialized optimizers [20, 32] and needs iterative fine-tuning which increases time for both model training and manual adjustments.
Pruning by architecture search: Given that designing deep network architectures requires significant human ef-fort, there have been some explorations on automatically learning network architectures. These approaches build net-works from the ground up using a set of custom building blocks, relying on variations of a trial-and-error search to find promising architectures [23, 33, 51, 52, 62], or com-pressed ones. In [3, 14], Reinforcement Learning (RL) is used to find compressed architectures but these techniques often take a long time to train. For example, in [3] a knowl-edge distillation [4, 17] approach is used to find a com-pressed student network from a teacher network using RL.
The method utilizes the architecture search to reduce the depth of a network and size of layers which can take up to 2,500 epochs. This search cost is however prohibitively ex-pensive for regular deep learning practitioners and further exacerbated by the growth in the dataset and network com-plexities. To reduce the architecture search time, generative adversarial networks have been used in [32] to find com-pressed structures. It shortens the search time significantly but still needs many iterations to train both generative and adversarial networks. Although these methods have led to a high compression rate, they often require a large amount of
GPU time to obtain high-performing architectures.
Although the approaches mentioned above provide state-of-the-art results, they are computationally expensive and time-consuming as they require multiple iterations of prun-ing and fine-tuning, and often need a lot of manual effort.
In this paper, we present DECORE, a multi-agent reinforce-ment learning (RL) framework for network compression which overcomes these limitations. In RL, an agent learns to perform a sequence of actions in an environment that maximizes some notion of a cumulative reward [49].
In our approach, we assign dedicated agents to all channels in the network which take actions to drop or keep a channel in the network. The agent gets a positive reward when it drops the channel for higher compression, but it gets a neg-ative reward (penalty) if the accuracy is decreased due to pruning. Using the REINFORCE algorithm [54], we op-timize agents’ policies to find out which channels to drop at each layer without affecting accuracy significantly and in turn maximizing the reward. Training of agents using the REINFORCE algorithm is independent of the network training loss which helps speed up the compression process.
Our main contributions are summarized as follows:
• We propose DECORE, a flexible and powerful ap-proach to automating structure search and model com-pression. DECORE learns which channels are impor-tant by jointly training the network to provide high compression and FLOPs reduction rates.
• DECORE assigns an agent to each channel in the net-work (multi-agent learning) while each agent learns only one parameter, as opposed to other RL-based methods where the policy involves training another neural network. Learning a single parameter for each agent makes training much faster and more efficient.
• We demonstrate that our approach is able to find the
most important channels in the network which can be used to search for compressed network architectures.
• Results on both CIFAR-10 and ImageNet datasets are reported with various networks to demonstrate that
DECORE is able to achieve better accuracy, as well as higher compression and acceleration (FLOPs reduc-tion) rates, compared to other existing methods. 2.