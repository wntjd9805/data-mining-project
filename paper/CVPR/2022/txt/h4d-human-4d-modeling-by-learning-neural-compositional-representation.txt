Abstract
Despite the impressive results achieved by deep learning based 3D reconstruction, the techniques of directly learning to model 4D human captures with detailed geometry have been less studied. This work presents a novel framework that can effectively learn a compact and compositional rep-resentation for dynamic human by exploiting the human body prior from the widely used SMPL parametric model.
Particularly, our representation, named H4D, represents a dynamic 3D human over a temporal span with the SMPL parameters of shape and initial pose, and latent codes en-coding motion and auxiliary information. A simple yet ef-fective linear motion model is proposed to provide a rough and regularized motion estimation, followed by per-frame compensation for pose and geometry details with the resid-ual encoded in the auxiliary code. Technically, we intro-duce novel GRU-based architectures to facilitate learning and improve the representation capability. Extensive exper-iments demonstrate our method is not only efficacy in re-covering dynamic human with accurate motion and detailed geometry, but also amenable to various 4D human related tasks, including motion retargeting, motion completion and future prediction. 1.

Introduction
The vanilla SMPL based parametric representations have been extensively studied and widely utilized for modeling 3D human shapes, and thus shown critical impacts to many human-centric tasks, such as pose estimation [16,24,30,32, 34, 42] and body shape fitting [9, 18, 33, 48, 58]. However, these representations are arguably insufficient for applica-tions involving dynamic signals, e.g. 3D moving humans (Fig.1 top), since the temporal information is not captured.
As solutions, 4D representations are proposed and can be in general categorized into free-form and prior-based
∗ indicates equal contributions.
Boyan Jiang, Xingkui Wei and Xiangyang Xue are with the School of
Computer Science, Fudan University.
Yanwei Fu is with the School of Data Science, Fudan University, and
Fudan ISTBI—ZJNU Algorithm Centre for Brain-inspired Intelligence,
Zhejiang Normal University, Jinhua, China.
Figure 1. Comparison with existing 4D human representa-tions. Our representation supports faster inference and more com-plete reconstructions compared with free-form methods (Fig. 3).
And it provides long-range temporal context and additional fine-grained geometry controlled by low-dimensional SMPL parame-ters and latent codes, which is more compact compared with pre-vious SMPL-based methods. methods depending on the 3D representation of the output shape (Fig. 1). The free-form methods leveraging Neural
ODE [13] and deep implicit function [26, 44] often rely on computational expensive architectures to learn the compact latent spaces and reconstruct 4D sequences. Unfortunately, since the human body prior is not explicitly modeled, the re-construction results of these methods may contain obvious geometry artifacts such as missing hands, and their model-ing errors accumulate rapidly over time. On the other hand, prior-based methods [30,32,66] are mostly derived from the
SMPL parametric model [37], which typically employs one shape parameter and a series of pose parameters to model dynamic sequences. Although they produce plausible re-sults, their motion representations are not compact or only support a small time span, e.g. ± 5 frames [30].
In this paper, we propose H4D, which is a novel neural representation for Human 4D modeling that combines the merits of both the prior-based and free-form solutions. To reflect the compositional natures [60], we encode each dy-namic human sequence with SMPL parameters representing shape and initial pose, and a compact latent code represent-ing temporal motion, which can then be used to reconstruct the input sequence through a decoder. At the core of this decoder, a simple yet effective prior model extended from
SMPL [37] is designed to provide coarse but long-term esti-mation of the 3D human geometry and motion. This can en-sure more complete and plausible outputs compared to the prior arts of free-form reconstructions [26, 44], but poten-tially be inclined to suffer from the limited representation capability. To this end, we add an additional auxiliary la-tent code to our representation to compensate the inaccurate motion and enrich the geometry details. Such a representa-tion takes full advantage of parametric models by exploiting strong prior based regularization for plausible initialization and complement them with powerful deep learning compo-nents to facilitate the human 4D modeling with impressive motion and geometry accuracy.
Our representation is learned via an auto-encoding framework. The encoder predicts the SMPL parameters and latent codes for each aspect from densely sampled point clouds, which are fed into the decoder to reconstruct the identical input dynamic human sequence. Once trained, the encoder and decoder are both fixed to support various ap-plications, such as motion retargeting, completion, and pre-diction, through either forward propagation (feed-forward) or backward optimization (auto-decoding) depending on the inputs. We design novel Gated Recurrent Unit (GRU) [15] based architectures for both encoder and decoder to bene-fit the model performance while working in either mode.
In feed-forward mode, we do not require the input point clouds to be temporarily tracked, i.e. the point trajectories like in previous work [26, 44]. This simplifies the training requirements and enhances the applicability of high-level applications. In auto-decoding mode, our model leverages the temporal information for optimization, which is critical for robustness to recover detailed motion and geometry.
Contributions We propose H4D, a compact and composi-tional representation for 4D human captures, which com-bines a linear prior model with the residual encoded in a learned auxiliary code. The framework is learned via 4D re-construction, and the latent representation can be extracted from either nonregistered point clouds in a feed-forward fashion or auto-decoding through optimization. Extensive experiments show that our representation and GRU-based architecture are effective in recovering accurate dynamic human sequences and providing robust performance for a variety of 4D human related applications, including motion retargeting/completion and future prediction. 2.